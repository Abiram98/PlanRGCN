Removed 3 of 595
Removed 0 of 198
Removed 0 of 198
Model with variable positions in join nodes
Loss function: MSELoss
Optimizer: LR [0.01] weight decay [0.0005]
Epoch 1
--------------------------------------------------------------
Epoch:    1        1 Batch loss: 0.249003 Batch F1: 0.7012987012987013
Epoch:    1        2 Batch loss: 0.277065 Batch F1: 0.6301369863013699
Epoch:    1        3 Batch loss: 0.270772 Batch F1: 0.5714285714285715
Epoch:    1        4 Batch loss: 0.250308 Batch F1: 0.6111111111111112
Epoch:    1        5 Batch loss: 0.234843 Batch F1: 0.0
Epoch:    1        6 Batch loss: 0.257728 Batch F1: 0.0
Epoch:    1        7 Batch loss: 0.279773 Batch F1: 0.0
Epoch:    1        8 Batch loss: 0.243684 Batch F1: 0.0
Epoch:    1        9 Batch loss: 0.255996 Batch F1: 0.0
Epoch:    1       10 Batch loss: 0.227082 Batch F1: 0.0
Epoch:    1       11 Batch loss: 0.246381 Batch F1: 0.0
Epoch:    1       12 Batch loss: 0.256079 Batch F1: 0.0
Train Avg Loss    1: 0.254060

Train Avg F1    1: 0.20949794751164616

Val Avg Loss    1: 0.251126

Val Avg F1    1:  0.0

Optimal Val loss (Epoch 1): 0.2511264644563198

Epoch 2
--------------------------------------------------------------
Epoch:    2        1 Batch loss: 0.240187 Batch F1: 0.0
Epoch:    2        2 Batch loss: 0.233971 Batch F1: 0.0
Epoch:    2        3 Batch loss: 0.256338 Batch F1: 0.0
Epoch:    2        4 Batch loss: 0.254212 Batch F1: 0.0
Epoch:    2        5 Batch loss: 0.243771 Batch F1: 0.0
Epoch:    2        6 Batch loss: 0.238492 Batch F1: 0.0
Epoch:    2        7 Batch loss: 0.256863 Batch F1: 0.0
Epoch:    2        8 Batch loss: 0.253039 Batch F1: 0.0
Epoch:    2        9 Batch loss: 0.245853 Batch F1: 0.0
Epoch:    2       10 Batch loss: 0.246519 Batch F1: 0.0
Epoch:    2       11 Batch loss: 0.247688 Batch F1: 0.0
Epoch:    2       12 Batch loss: 0.251659 Batch F1: 0.0
Train Avg Loss    2: 0.247383

Train Avg F1    2: 0.0

Val Avg Loss    2: 0.248614

Val Avg F1    2:  0.6430556334625888

Optimal Val loss (Epoch 2): 0.24861379712820053

Epoch 3
--------------------------------------------------------------
Epoch:    3        1 Batch loss: 0.248070 Batch F1: 0.6440677966101694
Epoch:    3        2 Batch loss: 0.247690 Batch F1: 0.6111111111111112
Epoch:    3        3 Batch loss: 0.248031 Batch F1: 0.41025641025641024
Epoch:    3        4 Batch loss: 0.255828 Batch F1: 0.0
Epoch:    3        5 Batch loss: 0.244944 Batch F1: 0.0
Epoch:    3        6 Batch loss: 0.233459 Batch F1: 0.0
Epoch:    3        7 Batch loss: 0.261142 Batch F1: 0.0
Epoch:    3        8 Batch loss: 0.260697 Batch F1: 0.0
Epoch:    3        9 Batch loss: 0.248598 Batch F1: 0.0
Epoch:    3       10 Batch loss: 0.239975 Batch F1: 0.0
Epoch:    3       11 Batch loss: 0.244789 Batch F1: 0.0
Epoch:    3       12 Batch loss: 0.252154 Batch F1: 0.0
Train Avg Loss    3: 0.248781

Train Avg F1    3: 0.1387862764981409

Val Avg Loss    3: 0.247355

Val Avg F1    3:  0.0

Optimal Val loss (Epoch 3): 0.2473553754389286

Epoch 4
--------------------------------------------------------------
Epoch:    4        1 Batch loss: 0.247411 Batch F1: 0.0
Epoch:    4        2 Batch loss: 0.247480 Batch F1: 0.5217391304347826
Epoch:    4        3 Batch loss: 0.245976 Batch F1: 0.7462686567164178
Epoch:    4        4 Batch loss: 0.247847 Batch F1: 0.6486486486486487
Epoch:    4        5 Batch loss: 0.246815 Batch F1: 0.6301369863013699
Epoch:    4        6 Batch loss: 0.245294 Batch F1: 0.7352941176470588
Epoch:    4        7 Batch loss: 0.249249 Batch F1: 0.44000000000000006
Epoch:    4        8 Batch loss: 0.238018 Batch F1: 0.0
Epoch:    4        9 Batch loss: 0.237170 Batch F1: 0.0
Epoch:    4       10 Batch loss: 0.260492 Batch F1: 0.0
Epoch:    4       11 Batch loss: 0.244006 Batch F1: 0.0
Epoch:    4       12 Batch loss: 0.251608 Batch F1: 0.0
Train Avg Loss    4: 0.246780

Train Avg F1    4: 0.31017396164568983

Val Avg Loss    4: 0.257538

Val Avg F1    4:  0.0

Optimal Val loss (Epoch 3): 0.2473553754389286

Epoch 5
--------------------------------------------------------------
Epoch:    5        1 Batch loss: 0.252421 Batch F1: 0.0
Epoch:    5        2 Batch loss: 0.247469 Batch F1: 0.0
Epoch:    5        3 Batch loss: 0.284482 Batch F1: 0.0
Epoch:    5        4 Batch loss: 0.259939 Batch F1: 0.0
Epoch:    5        5 Batch loss: 0.256670 Batch F1: 0.0
Epoch:    5        6 Batch loss: 0.249021 Batch F1: 0.6301369863013699
Epoch:    5        7 Batch loss: 0.257875 Batch F1: 0.5915492957746479
Epoch:    5        8 Batch loss: 0.267152 Batch F1: 0.5294117647058824
Epoch:    5        9 Batch loss: 0.262887 Batch F1: 0.5714285714285715
Epoch:    5       10 Batch loss: 0.263108 Batch F1: 0.5294117647058824
Epoch:    5       11 Batch loss: 0.257051 Batch F1: 0.5294117647058824
Epoch:    5       12 Batch loss: 0.250976 Batch F1: 0.5333333333333333
Train Avg Loss    5: 0.259088

Train Avg F1    5: 0.3262236234129641

Val Avg Loss    5: 0.249126

Val Avg F1    5:  0.0

Optimal Val loss (Epoch 3): 0.2473553754389286

Epoch 6
--------------------------------------------------------------
Epoch:    6        1 Batch loss: 0.239385 Batch F1: 0.0
Epoch:    6        2 Batch loss: 0.248122 Batch F1: 0.0
Epoch:    6        3 Batch loss: 0.246428 Batch F1: 0.0
Epoch:    6        4 Batch loss: 0.259087 Batch F1: 0.0
Epoch:    6        5 Batch loss: 0.277358 Batch F1: 0.0
Epoch:    6        6 Batch loss: 0.248049 Batch F1: 0.0
Epoch:    6        7 Batch loss: 0.232132 Batch F1: 0.0
Epoch:    6        8 Batch loss: 0.258643 Batch F1: 0.0
Epoch:    6        9 Batch loss: 0.246772 Batch F1: 0.0
Epoch:    6       10 Batch loss: 0.246072 Batch F1: 0.0
Epoch:    6       11 Batch loss: 0.243395 Batch F1: 0.0
Epoch:    6       12 Batch loss: 0.257933 Batch F1: 0.0
Train Avg Loss    6: 0.250281

Train Avg F1    6: 0.0

Val Avg Loss    6: 0.249052

Val Avg F1    6:  0.0

Optimal Val loss (Epoch 3): 0.2473553754389286

Epoch 7
--------------------------------------------------------------
Epoch:    7        1 Batch loss: 0.253577 Batch F1: 0.0
Epoch:    7        2 Batch loss: 0.250043 Batch F1: 0.0
Epoch:    7        3 Batch loss: 0.252894 Batch F1: 0.5714285714285715
Epoch:    7        4 Batch loss: 0.254846 Batch F1: 0.5915492957746479
Epoch:    7        5 Batch loss: 0.250291 Batch F1: 0.6301369863013699
Epoch:    7        6 Batch loss: 0.245623 Batch F1: 0.7341772151898733
Epoch:    7        7 Batch loss: 0.252547 Batch F1: 0.5074626865671642
Epoch:    7        8 Batch loss: 0.246516 Batch F1: 0.3333333333333333
Epoch:    7        9 Batch loss: 0.245949 Batch F1: 0.0
Epoch:    7       10 Batch loss: 0.243126 Batch F1: 0.0
Epoch:    7       11 Batch loss: 0.227131 Batch F1: 0.0
Epoch:    7       12 Batch loss: 0.247958 Batch F1: 0.0
Train Avg Loss    7: 0.247542

Train Avg F1    7: 0.28067400738291337

Val Avg Loss    7: 0.257148

Val Avg F1    7:  0.0

Optimal Val loss (Epoch 3): 0.2473553754389286

Epoch 8
--------------------------------------------------------------
Epoch:    8        1 Batch loss: 0.238668 Batch F1: 0.0
Epoch:    8        2 Batch loss: 0.248782 Batch F1: 0.0
Epoch:    8        3 Batch loss: 0.262477 Batch F1: 0.0
Epoch:    8        4 Batch loss: 0.244758 Batch F1: 0.0
Epoch:    8        5 Batch loss: 0.250468 Batch F1: 0.0
Epoch:    8        6 Batch loss: 0.234827 Batch F1: 0.0
Epoch:    8        7 Batch loss: 0.234498 Batch F1: 0.0
Epoch:    8        8 Batch loss: 0.256087 Batch F1: 0.0
Epoch:    8        9 Batch loss: 0.241936 Batch F1: 0.0
Epoch:    8       10 Batch loss: 0.245833 Batch F1: 0.6249999999999999
Epoch:    8       11 Batch loss: 0.243674 Batch F1: 0.5909090909090909
Epoch:    8       12 Batch loss: 0.239960 Batch F1: 0.717948717948718
Train Avg Loss    8: 0.245164

Train Avg F1    8: 0.1611548174048174

Val Avg Loss    8: 0.243052

Val Avg F1    8:  0.5270342800830605

Optimal Val loss (Epoch 8): 0.24305175244808197

Epoch 9
--------------------------------------------------------------
Epoch:    9        1 Batch loss: 0.243354 Batch F1: 0.5306122448979592
Epoch:    9        2 Batch loss: 0.243671 Batch F1: 0.34285714285714286
Epoch:    9        3 Batch loss: 0.230844 Batch F1: 0.6666666666666666
Epoch:    9        4 Batch loss: 0.230364 Batch F1: 0.0
Epoch:    9        5 Batch loss: 0.257537 Batch F1: 0.0
Epoch:    9        6 Batch loss: 0.256444 Batch F1: 0.0
Epoch:    9        7 Batch loss: 0.230799 Batch F1: 0.0
Epoch:    9        8 Batch loss: 0.250146 Batch F1: 0.0
Epoch:    9        9 Batch loss: 0.273288 Batch F1: 0.0
Epoch:    9       10 Batch loss: 0.239992 Batch F1: 0.0
Epoch:    9       11 Batch loss: 0.236631 Batch F1: 0.0
Epoch:    9       12 Batch loss: 0.237064 Batch F1: 0.3333333333333333
Train Avg Loss    9: 0.244178

Train Avg F1    9: 0.15612244897959185

Val Avg Loss    9: 0.240768

Val Avg F1    9:  0.4725609756097561

Optimal Val loss (Epoch 9): 0.24076807498931885

Epoch 10
--------------------------------------------------------------
Epoch:   10        1 Batch loss: 0.234438 Batch F1: 0.3333333333333333
Epoch:   10        2 Batch loss: 0.238659 Batch F1: 0.47619047619047616
Epoch:   10        3 Batch loss: 0.257930 Batch F1: 0.19999999999999998
Epoch:   10        4 Batch loss: 0.241618 Batch F1: 0.3448275862068966
Epoch:   10        5 Batch loss: 0.225714 Batch F1: 0.6666666666666666
Epoch:   10        6 Batch loss: 0.224398 Batch F1: 0.32
Epoch:   10        7 Batch loss: 0.246635 Batch F1: 0.3846153846153846
Epoch:   10        8 Batch loss: 0.237475 Batch F1: 0.23076923076923078
Epoch:   10        9 Batch loss: 0.244795 Batch F1: 0.5499999999999999
Epoch:   10       10 Batch loss: 0.225657 Batch F1: 0.6222222222222223
Epoch:   10       11 Batch loss: 0.243655 Batch F1: 0.6122448979591837
Epoch:   10       12 Batch loss: 0.236261 Batch F1: 0.6666666666666666
Train Avg Loss   10: 0.238103

Train Avg F1   10: 0.45062803871917173

Val Avg Loss   10: 0.242381

Val Avg F1   10:  0.6448844466936572

Optimal Val loss (Epoch 9): 0.24076807498931885

Epoch 11
--------------------------------------------------------------
Epoch:   11        1 Batch loss: 0.245346 Batch F1: 0.6333333333333333
Epoch:   11        2 Batch loss: 0.228670 Batch F1: 0.7272727272727272
Epoch:   11        3 Batch loss: 0.238519 Batch F1: 0.5161290322580645
Epoch:   11        4 Batch loss: 0.232965 Batch F1: 0.0
Epoch:   11        5 Batch loss: 0.235647 Batch F1: 0.0
Epoch:   11        6 Batch loss: 0.250661 Batch F1: 0.0
Epoch:   11        7 Batch loss: 0.232550 Batch F1: 0.0
Epoch:   11        8 Batch loss: 0.250386 Batch F1: 0.0
Epoch:   11        9 Batch loss: 0.234117 Batch F1: 0.5882352941176471
Epoch:   11       10 Batch loss: 0.253117 Batch F1: 0.3333333333333333
Epoch:   11       11 Batch loss: 0.227307 Batch F1: 0.6046511627906976
Epoch:   11       12 Batch loss: 0.242472 Batch F1: 0.6808510638297872
Train Avg Loss   11: 0.239313

Train Avg F1   11: 0.34031716224463254

Val Avg Loss   11: 0.236898

Val Avg F1   11:  0.628923015723468

Optimal Val loss (Epoch 11): 0.23689765483140945

Epoch 12
--------------------------------------------------------------
Epoch:   12        1 Batch loss: 0.228961 Batch F1: 0.6538461538461537
Epoch:   12        2 Batch loss: 0.228193 Batch F1: 0.6363636363636365
Epoch:   12        3 Batch loss: 0.233075 Batch F1: 0.5652173913043478
Epoch:   12        4 Batch loss: 0.232981 Batch F1: 0.5490196078431373
Epoch:   12        5 Batch loss: 0.232222 Batch F1: 0.5581395348837209
Epoch:   12        6 Batch loss: 0.214718 Batch F1: 0.4571428571428572
Epoch:   12        7 Batch loss: 0.263014 Batch F1: 0.4799999999999999
Epoch:   12        8 Batch loss: 0.216741 Batch F1: 0.5
Epoch:   12        9 Batch loss: 0.244492 Batch F1: 0.29411764705882354
Epoch:   12       10 Batch loss: 0.234039 Batch F1: 0.2162162162162162
Epoch:   12       11 Batch loss: 0.246910 Batch F1: 0.5116279069767442
Epoch:   12       12 Batch loss: 0.225204 Batch F1: 0.6511627906976744
Train Avg Loss   12: 0.233379

Train Avg F1   12: 0.5060711451944427

Val Avg Loss   12: 0.233390

Val Avg F1   12:  0.6322219860793795

Optimal Val loss (Epoch 12): 0.23338963836431503

Epoch 13
--------------------------------------------------------------
Epoch:   13        1 Batch loss: 0.212198 Batch F1: 0.7083333333333333
Epoch:   13        2 Batch loss: 0.214099 Batch F1: 0.6976744186046512
Epoch:   13        3 Batch loss: 0.217301 Batch F1: 0.4166666666666667
Epoch:   13        4 Batch loss: 0.240580 Batch F1: 0.0
Epoch:   13        5 Batch loss: 0.286639 Batch F1: 0.0
Epoch:   13        6 Batch loss: 0.249010 Batch F1: 0.0
Epoch:   13        7 Batch loss: 0.255190 Batch F1: 0.0
Epoch:   13        8 Batch loss: 0.221594 Batch F1: 0.4242424242424242
Epoch:   13        9 Batch loss: 0.237044 Batch F1: 0.576923076923077
Epoch:   13       10 Batch loss: 0.265558 Batch F1: 0.40740740740740744
Epoch:   13       11 Batch loss: 0.249145 Batch F1: 0.6181818181818182
Epoch:   13       12 Batch loss: 0.237363 Batch F1: 0.6415094339622641
Train Avg Loss   13: 0.240477

Train Avg F1   13: 0.37424488161013686

Val Avg Loss   13: 0.239036

Val Avg F1   13:  0.6148396521808499

Optimal Val loss (Epoch 12): 0.23338963836431503

Epoch 14
--------------------------------------------------------------
Epoch:   14        1 Batch loss: 0.235736 Batch F1: 0.5882352941176471
Epoch:   14        2 Batch loss: 0.233397 Batch F1: 0.52
Epoch:   14        3 Batch loss: 0.234054 Batch F1: 0.34285714285714286
Epoch:   14        4 Batch loss: 0.226923 Batch F1: 0.4
Epoch:   14        5 Batch loss: 0.259750 Batch F1: 0.0
Epoch:   14        6 Batch loss: 0.241867 Batch F1: 0.0
Epoch:   14        7 Batch loss: 0.237274 Batch F1: 0.5517241379310345
Epoch:   14        8 Batch loss: 0.223566 Batch F1: 0.6956521739130435
Epoch:   14        9 Batch loss: 0.230889 Batch F1: 0.42105263157894735
Epoch:   14       10 Batch loss: 0.244504 Batch F1: 0.5217391304347826
Epoch:   14       11 Batch loss: 0.242608 Batch F1: 0.358974358974359
Epoch:   14       12 Batch loss: 0.228312 Batch F1: 0.6341463414634148
Train Avg Loss   14: 0.236573

Train Avg F1   14: 0.4195317676058643

Val Avg Loss   14: 0.234284

Val Avg F1   14:  0.6717719163136953

Optimal Val loss (Epoch 12): 0.23338963836431503

Epoch 15
--------------------------------------------------------------
Epoch:   15        1 Batch loss: 0.232944 Batch F1: 0.6956521739130435
Epoch:   15        2 Batch loss: 0.241584 Batch F1: 0.6666666666666667
Epoch:   15        3 Batch loss: 0.232639 Batch F1: 0.6785714285714286
Epoch:   15        4 Batch loss: 0.227205 Batch F1: 0.6666666666666667
Epoch:   15        5 Batch loss: 0.232568 Batch F1: 0.5217391304347826
Epoch:   15        6 Batch loss: 0.249063 Batch F1: 0.5599999999999999
Epoch:   15        7 Batch loss: 0.235476 Batch F1: 0.43902439024390244
Epoch:   15        8 Batch loss: 0.226299 Batch F1: 0.5405405405405405
Epoch:   15        9 Batch loss: 0.232001 Batch F1: 0.43243243243243246
Epoch:   15       10 Batch loss: 0.215871 Batch F1: 0.5925925925925926
Epoch:   15       11 Batch loss: 0.199253 Batch F1: 0.5
Epoch:   15       12 Batch loss: 0.252619 Batch F1: 0.0
Train Avg Loss   15: 0.231460

Train Avg F1   15: 0.5244905018385048

Val Avg Loss   15: 0.235643

Val Avg F1   15:  0.6113338902812586

Optimal Val loss (Epoch 12): 0.23338963836431503

Epoch 16
--------------------------------------------------------------
Epoch:   16        1 Batch loss: 0.229094 Batch F1: 0.5625000000000001
Epoch:   16        2 Batch loss: 0.223706 Batch F1: 0.5
Epoch:   16        3 Batch loss: 0.206163 Batch F1: 0.5714285714285715
Epoch:   16        4 Batch loss: 0.231799 Batch F1: 0.36363636363636365
Epoch:   16        5 Batch loss: 0.227464 Batch F1: 0.4444444444444445
Epoch:   16        6 Batch loss: 0.249799 Batch F1: 0.5
Epoch:   16        7 Batch loss: 0.231508 Batch F1: 0.6190476190476191
Epoch:   16        8 Batch loss: 0.224625 Batch F1: 0.41025641025641024
Epoch:   16        9 Batch loss: 0.227472 Batch F1: 0.6545454545454547
Epoch:   16       10 Batch loss: 0.215682 Batch F1: 0.7586206896551724
Epoch:   16       11 Batch loss: 0.222353 Batch F1: 0.6779661016949152
Epoch:   16       12 Batch loss: 0.260253 Batch F1: 0.3157894736842105
Train Avg Loss   16: 0.229160

Train Avg F1   16: 0.5315195940327635

Val Avg Loss   16: 0.229198

Val Avg F1   16:  0.6708938261443789

Optimal Val loss (Epoch 16): 0.22919847443699837

Epoch 17
--------------------------------------------------------------
Epoch:   17        1 Batch loss: 0.245542 Batch F1: 0.5333333333333332
Epoch:   17        2 Batch loss: 0.219134 Batch F1: 0.6938775510204083
Epoch:   17        3 Batch loss: 0.220809 Batch F1: 0.6666666666666666
Epoch:   17        4 Batch loss: 0.189284 Batch F1: 0.8510638297872339
Epoch:   17        5 Batch loss: 0.247324 Batch F1: 0.5
Epoch:   17        6 Batch loss: 0.227540 Batch F1: 0.42857142857142855
Epoch:   17        7 Batch loss: 0.227859 Batch F1: 0.4615384615384615
Epoch:   17        8 Batch loss: 0.214085 Batch F1: 0.5217391304347826
Epoch:   17        9 Batch loss: 0.250505 Batch F1: 0.6
Epoch:   17       10 Batch loss: 0.232864 Batch F1: 0.38095238095238093
Epoch:   17       11 Batch loss: 0.235986 Batch F1: 0.6153846153846153
Epoch:   17       12 Batch loss: 0.244864 Batch F1: 0.5454545454545454
Train Avg Loss   17: 0.229650

Train Avg F1   17: 0.5665484952619879

Val Avg Loss   17: 0.237699

Val Avg F1   17:  0.6449986425163867

Optimal Val loss (Epoch 16): 0.22919847443699837

Epoch 18
--------------------------------------------------------------
Epoch:   18        1 Batch loss: 0.234128 Batch F1: 0.5862068965517241
Epoch:   18        2 Batch loss: 0.260688 Batch F1: 0.5263157894736842
Epoch:   18        3 Batch loss: 0.218829 Batch F1: 0.7000000000000001
Epoch:   18        4 Batch loss: 0.263953 Batch F1: 0.375
Epoch:   18        5 Batch loss: 0.231660 Batch F1: 0.5957446808510639
Epoch:   18        6 Batch loss: 0.229762 Batch F1: 0.3684210526315789
Epoch:   18        7 Batch loss: 0.214120 Batch F1: 0.5294117647058824
Epoch:   18        8 Batch loss: 0.246227 Batch F1: 0.3888888888888889
Epoch:   18        9 Batch loss: 0.189212 Batch F1: 0.5454545454545454
Epoch:   18       10 Batch loss: 0.223646 Batch F1: 0.6
Epoch:   18       11 Batch loss: 0.198322 Batch F1: 0.8444444444444444
Epoch:   18       12 Batch loss: 0.226471 Batch F1: 0.7317073170731706
Train Avg Loss   18: 0.228085

Train Avg F1   18: 0.5659662816729152

Val Avg Loss   18: 0.226047

Val Avg F1   18:  0.6713672623199477

Optimal Val loss (Epoch 18): 0.22604676708579063

Epoch 19
--------------------------------------------------------------
Epoch:   19        1 Batch loss: 0.221918 Batch F1: 0.6666666666666666
Epoch:   19        2 Batch loss: 0.214646 Batch F1: 0.68
Epoch:   19        3 Batch loss: 0.249781 Batch F1: 0.380952380952381
Epoch:   19        4 Batch loss: 0.237544 Batch F1: 0.608695652173913
Epoch:   19        5 Batch loss: 0.219502 Batch F1: 0.5581395348837209
Epoch:   19        6 Batch loss: 0.223060 Batch F1: 0.5853658536585366
Epoch:   19        7 Batch loss: 0.209462 Batch F1: 0.7111111111111111
Epoch:   19        8 Batch loss: 0.228621 Batch F1: 0.627450980392157
Epoch:   19        9 Batch loss: 0.227844 Batch F1: 0.6909090909090909
Epoch:   19       10 Batch loss: 0.230328 Batch F1: 0.6086956521739131
Epoch:   19       11 Batch loss: 0.207895 Batch F1: 0.6511627906976744
Epoch:   19       12 Batch loss: 0.227588 Batch F1: 0.6666666666666667
Train Avg Loss   19: 0.224849

Train Avg F1   19: 0.6196513650238195

Val Avg Loss   19: 0.225946

Val Avg F1   19:  0.6085077620791907

Optimal Val loss (Epoch 19): 0.22594615444540977

Epoch 20
--------------------------------------------------------------
Epoch:   20        1 Batch loss: 0.224279 Batch F1: 0.4888888888888889
Epoch:   20        2 Batch loss: 0.214625 Batch F1: 0.5
Epoch:   20        3 Batch loss: 0.254026 Batch F1: 0.30303030303030304
Epoch:   20        4 Batch loss: 0.218125 Batch F1: 0.5142857142857142
Epoch:   20        5 Batch loss: 0.205827 Batch F1: 0.6666666666666666
Epoch:   20        6 Batch loss: 0.222434 Batch F1: 0.6530612244897959
Epoch:   20        7 Batch loss: 0.229405 Batch F1: 0.64
Epoch:   20        8 Batch loss: 0.212575 Batch F1: 0.64
Epoch:   20        9 Batch loss: 0.193397 Batch F1: 0.7555555555555556
Epoch:   20       10 Batch loss: 0.230443 Batch F1: 0.6415094339622641
Epoch:   20       11 Batch loss: 0.238406 Batch F1: 0.42857142857142855
Epoch:   20       12 Batch loss: 0.280131 Batch F1: 0.39999999999999997
Train Avg Loss   20: 0.226973

Train Avg F1   20: 0.5526307679542182

Val Avg Loss   20: 0.230561

Val Avg F1   20:  0.4965792506553376

Optimal Val loss (Epoch 19): 0.22594615444540977

Epoch 21
--------------------------------------------------------------
Epoch:   21        1 Batch loss: 0.207521 Batch F1: 0.5405405405405405
Epoch:   21        2 Batch loss: 0.227435 Batch F1: 0.35714285714285715
Epoch:   21        3 Batch loss: 0.224073 Batch F1: 0.48484848484848486
Epoch:   21        4 Batch loss: 0.240623 Batch F1: 0.1935483870967742
Epoch:   21        5 Batch loss: 0.250494 Batch F1: 0.41860465116279066
Epoch:   21        6 Batch loss: 0.215302 Batch F1: 0.6511627906976745
Epoch:   21        7 Batch loss: 0.210251 Batch F1: 0.6923076923076923
Epoch:   21        8 Batch loss: 0.225370 Batch F1: 0.6538461538461537
Epoch:   21        9 Batch loss: 0.218864 Batch F1: 0.7457627118644068
Epoch:   21       10 Batch loss: 0.221227 Batch F1: 0.6785714285714286
Epoch:   21       11 Batch loss: 0.230561 Batch F1: 0.5454545454545454
Epoch:   21       12 Batch loss: 0.221476 Batch F1: 0.6956521739130435
Train Avg Loss   21: 0.224433

Train Avg F1   21: 0.5547868681205327

Val Avg Loss   21: 0.223228

Val Avg F1   21:  0.6655978180745983

Optimal Val loss (Epoch 21): 0.22322776168584824

Epoch 22
--------------------------------------------------------------
Epoch:   22        1 Batch loss: 0.228562 Batch F1: 0.6382978723404256
Epoch:   22        2 Batch loss: 0.199746 Batch F1: 0.76
Epoch:   22        3 Batch loss: 0.243651 Batch F1: 0.5
Epoch:   22        4 Batch loss: 0.211958 Batch F1: 0.6
Epoch:   22        5 Batch loss: 0.225972 Batch F1: 0.5853658536585366
Epoch:   22        6 Batch loss: 0.226466 Batch F1: 0.4705882352941176
Epoch:   22        7 Batch loss: 0.255940 Batch F1: 0.2777777777777778
Epoch:   22        8 Batch loss: 0.235936 Batch F1: 0.5641025641025641
Epoch:   22        9 Batch loss: 0.237431 Batch F1: 0.6538461538461539
Epoch:   22       10 Batch loss: 0.205231 Batch F1: 0.7000000000000001
Epoch:   22       11 Batch loss: 0.225204 Batch F1: 0.6296296296296295
Epoch:   22       12 Batch loss: 0.209847 Batch F1: 0.6842105263157895
Train Avg Loss   22: 0.225495

Train Avg F1   22: 0.5886515510804163

Val Avg Loss   22: 0.228751

Val Avg F1   22:  0.48733921117642054

Optimal Val loss (Epoch 21): 0.22322776168584824

Epoch 23
--------------------------------------------------------------
Epoch:   23        1 Batch loss: 0.239989 Batch F1: 0.4897959183673469
Epoch:   23        2 Batch loss: 0.212650 Batch F1: 0.5
Epoch:   23        3 Batch loss: 0.213036 Batch F1: 0.45161290322580644
Epoch:   23        4 Batch loss: 0.266625 Batch F1: 0.5
Epoch:   23        5 Batch loss: 0.253257 Batch F1: 0.380952380952381
Epoch:   23        6 Batch loss: 0.250657 Batch F1: 0.5333333333333333
Epoch:   23        7 Batch loss: 0.189864 Batch F1: 0.7391304347826085
Epoch:   23        8 Batch loss: 0.245361 Batch F1: 0.5490196078431372
Epoch:   23        9 Batch loss: 0.220069 Batch F1: 0.5853658536585366
Epoch:   23       10 Batch loss: 0.201719 Batch F1: 0.7999999999999999
Epoch:   23       11 Batch loss: 0.238726 Batch F1: 0.5454545454545454
Epoch:   23       12 Batch loss: 0.216819 Batch F1: 0.5625
Train Avg Loss   23: 0.229064

Train Avg F1   23: 0.5530970814681413

Val Avg Loss   23: 0.229059

Val Avg F1   23:  0.5067579877479447

Optimal Val loss (Epoch 21): 0.22322776168584824

Epoch 24
--------------------------------------------------------------
Epoch:   24        1 Batch loss: 0.198331 Batch F1: 0.717948717948718
Epoch:   24        2 Batch loss: 0.191037 Batch F1: 0.6153846153846154
Epoch:   24        3 Batch loss: 0.224148 Batch F1: 0.3870967741935484
Epoch:   24        4 Batch loss: 0.229927 Batch F1: 0.5294117647058824
Epoch:   24        5 Batch loss: 0.220026 Batch F1: 0.5714285714285713
Epoch:   24        6 Batch loss: 0.240860 Batch F1: 0.5098039215686274
Epoch:   24        7 Batch loss: 0.237787 Batch F1: 0.6875000000000001
Epoch:   24        8 Batch loss: 0.254010 Batch F1: 0.5660377358490566
Epoch:   24        9 Batch loss: 0.217775 Batch F1: 0.7083333333333334
Epoch:   24       10 Batch loss: 0.237803 Batch F1: 0.6086956521739131
Epoch:   24       11 Batch loss: 0.237398 Batch F1: 0.48648648648648657
Epoch:   24       12 Batch loss: 0.228142 Batch F1: 0.6500000000000001
Train Avg Loss   24: 0.226437

Train Avg F1   24: 0.586510631089396

Val Avg Loss   24: 0.223719

Val Avg F1   24:  0.5594239922070111

Optimal Val loss (Epoch 21): 0.22322776168584824

Epoch 25
--------------------------------------------------------------
Epoch:   25        1 Batch loss: 0.204330 Batch F1: 0.5405405405405405
Epoch:   25        2 Batch loss: 0.246936 Batch F1: 0.5909090909090909
Epoch:   25        3 Batch loss: 0.207021 Batch F1: 0.5882352941176471
Epoch:   25        4 Batch loss: 0.224953 Batch F1: 0.5238095238095238
Epoch:   25        5 Batch loss: 0.245606 Batch F1: 0.47619047619047616
Epoch:   25        6 Batch loss: 0.202774 Batch F1: 0.7142857142857143
Epoch:   25        7 Batch loss: 0.234157 Batch F1: 0.6296296296296297
Epoch:   25        8 Batch loss: 0.240823 Batch F1: 0.45454545454545453
Epoch:   25        9 Batch loss: 0.225598 Batch F1: 0.5641025641025642
Epoch:   25       10 Batch loss: 0.239643 Batch F1: 0.6666666666666667
Epoch:   25       11 Batch loss: 0.195359 Batch F1: 0.7777777777777778
Epoch:   25       12 Batch loss: 0.207947 Batch F1: 0.7272727272727273
Train Avg Loss   25: 0.222929

Train Avg F1   25: 0.6044971216539844

Val Avg Loss   25: 0.222231

Val Avg F1   25:  0.7190150857914016

Optimal Val loss (Epoch 25): 0.2222307287156582

Epoch 26
--------------------------------------------------------------
Epoch:   26        1 Batch loss: 0.224089 Batch F1: 0.5806451612903226
Epoch:   26        2 Batch loss: 0.220459 Batch F1: 0.7142857142857142
Epoch:   26        3 Batch loss: 0.242021 Batch F1: 0.6551724137931035
Epoch:   26        4 Batch loss: 0.221206 Batch F1: 0.6938775510204083
Epoch:   26        5 Batch loss: 0.188035 Batch F1: 0.7727272727272727
Epoch:   26        6 Batch loss: 0.229659 Batch F1: 0.7058823529411765
Epoch:   26        7 Batch loss: 0.206233 Batch F1: 0.7450980392156863
Epoch:   26        8 Batch loss: 0.208609 Batch F1: 0.5714285714285713
Epoch:   26        9 Batch loss: 0.219180 Batch F1: 0.5238095238095238
Epoch:   26       10 Batch loss: 0.231907 Batch F1: 0.5142857142857143
Epoch:   26       11 Batch loss: 0.224841 Batch F1: 0.4666666666666667
Epoch:   26       12 Batch loss: 0.235173 Batch F1: 0.3333333333333333
Train Avg Loss   26: 0.220951

Train Avg F1   26: 0.6064343595664577

Val Avg Loss   26: 0.224795

Val Avg F1   26:  0.4971496866845704

Optimal Val loss (Epoch 25): 0.2222307287156582

Epoch 27
--------------------------------------------------------------
Epoch:   27        1 Batch loss: 0.235866 Batch F1: 0.5581395348837209
Epoch:   27        2 Batch loss: 0.223058 Batch F1: 0.47368421052631576
Epoch:   27        3 Batch loss: 0.240799 Batch F1: 0.28571428571428575
Epoch:   27        4 Batch loss: 0.233088 Batch F1: 0.5128205128205129
Epoch:   27        5 Batch loss: 0.169459 Batch F1: 0.6666666666666665
Epoch:   27        6 Batch loss: 0.250469 Batch F1: 0.46511627906976744
Epoch:   27        7 Batch loss: 0.201551 Batch F1: 0.45161290322580644
Epoch:   27        8 Batch loss: 0.227924 Batch F1: 0.6666666666666667
Epoch:   27        9 Batch loss: 0.210788 Batch F1: 0.7407407407407407
Epoch:   27       10 Batch loss: 0.207227 Batch F1: 0.7272727272727273
Epoch:   27       11 Batch loss: 0.242699 Batch F1: 0.576271186440678
Epoch:   27       12 Batch loss: 0.217981 Batch F1: 0.5625
Train Avg Loss   27: 0.221742

Train Avg F1   27: 0.5572671428356574

Val Avg Loss   27: 0.221520

Val Avg F1   27:  0.4613601352058748

Optimal Val loss (Epoch 27): 0.22151972725987434

Epoch 28
--------------------------------------------------------------
Epoch:   28        1 Batch loss: 0.224941 Batch F1: 0.46153846153846156
Epoch:   28        2 Batch loss: 0.209583 Batch F1: 0.3448275862068966
Epoch:   28        3 Batch loss: 0.211933 Batch F1: 0.5294117647058824
Epoch:   28        4 Batch loss: 0.194012 Batch F1: 0.5555555555555555
Epoch:   28        5 Batch loss: 0.222670 Batch F1: 0.4210526315789474
Epoch:   28        6 Batch loss: 0.232191 Batch F1: 0.3333333333333333
Epoch:   28        7 Batch loss: 0.208130 Batch F1: 0.6111111111111112
Epoch:   28        8 Batch loss: 0.232200 Batch F1: 0.6250000000000001
Epoch:   28        9 Batch loss: 0.223285 Batch F1: 0.6341463414634146
Epoch:   28       10 Batch loss: 0.212513 Batch F1: 0.6382978723404256
Epoch:   28       11 Batch loss: 0.232375 Batch F1: 0.5365853658536585
Epoch:   28       12 Batch loss: 0.247083 Batch F1: 0.5454545454545454
Train Avg Loss   28: 0.220910

Train Avg F1   28: 0.5196928807618527

Val Avg Loss   28: 0.219406

Val Avg F1   28:  0.6668454615888908

Optimal Val loss (Epoch 28): 0.21940558776259422

Epoch 29
--------------------------------------------------------------
Epoch:   29        1 Batch loss: 0.214450 Batch F1: 0.7083333333333334
Epoch:   29        2 Batch loss: 0.194189 Batch F1: 0.46153846153846156
Epoch:   29        3 Batch loss: 0.213341 Batch F1: 0.5789473684210527
Epoch:   29        4 Batch loss: 0.240292 Batch F1: 0.4324324324324324
Epoch:   29        5 Batch loss: 0.188687 Batch F1: 0.5882352941176471
Epoch:   29        6 Batch loss: 0.236258 Batch F1: 0.4444444444444444
Epoch:   29        7 Batch loss: 0.212095 Batch F1: 0.5263157894736842
Epoch:   29        8 Batch loss: 0.209133 Batch F1: 0.7659574468085107
Epoch:   29        9 Batch loss: 0.199204 Batch F1: 0.6341463414634146
Epoch:   29       10 Batch loss: 0.227701 Batch F1: 0.6122448979591836
Epoch:   29       11 Batch loss: 0.205028 Batch F1: 0.6666666666666667
Epoch:   29       12 Batch loss: 0.269311 Batch F1: 0.5116279069767442
Train Avg Loss   29: 0.217474

Train Avg F1   29: 0.577574198636298

Val Avg Loss   29: 0.216115

Val Avg F1   29:  0.6764626489862339

Optimal Val loss (Epoch 29): 0.21611540392041206

Epoch 30
--------------------------------------------------------------
Epoch:   30        1 Batch loss: 0.207362 Batch F1: 0.7450980392156864
Epoch:   30        2 Batch loss: 0.203254 Batch F1: 0.7346938775510203
Epoch:   30        3 Batch loss: 0.197848 Batch F1: 0.736842105263158
Epoch:   30        4 Batch loss: 0.221073 Batch F1: 0.6923076923076923
Epoch:   30        5 Batch loss: 0.236137 Batch F1: 0.6333333333333333
Epoch:   30        6 Batch loss: 0.227241 Batch F1: 0.6250000000000001
Epoch:   30        7 Batch loss: 0.216846 Batch F1: 0.6153846153846154
Epoch:   30        8 Batch loss: 0.203936 Batch F1: 0.7
Epoch:   30        9 Batch loss: 0.185811 Batch F1: 0.4444444444444445
Epoch:   30       10 Batch loss: 0.225979 Batch F1: 0.2727272727272727
Epoch:   30       11 Batch loss: 0.240843 Batch F1: 0.0
Epoch:   30       12 Batch loss: 0.269764 Batch F1: 0.0909090909090909
Train Avg Loss   30: 0.219675

Train Avg F1   30: 0.5242283725946929

Val Avg Loss   30: 0.221289

Val Avg F1   30:  0.4673877173877174

Optimal Val loss (Epoch 29): 0.21611540392041206

Epoch 31
--------------------------------------------------------------
Epoch:   31        1 Batch loss: 0.218923 Batch F1: 0.5263157894736842
Epoch:   31        2 Batch loss: 0.233401 Batch F1: 0.6122448979591837
Epoch:   31        3 Batch loss: 0.239840 Batch F1: 0.6415094339622641
Epoch:   31        4 Batch loss: 0.227852 Batch F1: 0.6666666666666666
Epoch:   31        5 Batch loss: 0.203833 Batch F1: 0.5882352941176471
Epoch:   31        6 Batch loss: 0.224194 Batch F1: 0.4705882352941177
Epoch:   31        7 Batch loss: 0.218027 Batch F1: 0.5238095238095238
Epoch:   31        8 Batch loss: 0.183781 Batch F1: 0.6470588235294118
Epoch:   31        9 Batch loss: 0.207844 Batch F1: 0.5853658536585366
Epoch:   31       10 Batch loss: 0.235278 Batch F1: 0.3888888888888889
Epoch:   31       11 Batch loss: 0.220851 Batch F1: 0.5853658536585367
Epoch:   31       12 Batch loss: 0.207377 Batch F1: 0.45161290322580644
Train Avg Loss   31: 0.218434

Train Avg F1   31: 0.5573051803536889

Val Avg Loss   31: 0.217870

Val Avg F1   31:  0.6855983772819474

Optimal Val loss (Epoch 29): 0.21611540392041206

Epoch 32
--------------------------------------------------------------
Epoch:   32        1 Batch loss: 0.215589 Batch F1: 0.7199999999999999
Epoch:   32        2 Batch loss: 0.219442 Batch F1: 0.6808510638297872
Epoch:   32        3 Batch loss: 0.254554 Batch F1: 0.36842105263157887
Epoch:   32        4 Batch loss: 0.202494 Batch F1: 0.36363636363636365
Epoch:   32        5 Batch loss: 0.222788 Batch F1: 0.4736842105263158
Epoch:   32        6 Batch loss: 0.261829 Batch F1: 0.4999999999999999
Epoch:   32        7 Batch loss: 0.214716 Batch F1: 0.5555555555555556
Epoch:   32        8 Batch loss: 0.202582 Batch F1: 0.6666666666666666
Epoch:   32        9 Batch loss: 0.201263 Batch F1: 0.7027027027027029
Epoch:   32       10 Batch loss: 0.214611 Batch F1: 0.4210526315789474
Epoch:   32       11 Batch loss: 0.203122 Batch F1: 0.7179487179487181
Epoch:   32       12 Batch loss: 0.192222 Batch F1: 0.7272727272727272
Train Avg Loss   32: 0.217101

Train Avg F1   32: 0.574815974362447

Val Avg Loss   32: 0.213780

Val Avg F1   32:  0.6793143486902957

Optimal Val loss (Epoch 32): 0.21378040313720703

Epoch 33
--------------------------------------------------------------
Epoch:   33        1 Batch loss: 0.200539 Batch F1: 0.6956521739130435
Epoch:   33        2 Batch loss: 0.188339 Batch F1: 0.631578947368421
Epoch:   33        3 Batch loss: 0.208052 Batch F1: 0.625
Epoch:   33        4 Batch loss: 0.222423 Batch F1: 0.6363636363636364
Epoch:   33        5 Batch loss: 0.225340 Batch F1: 0.5116279069767442
Epoch:   33        6 Batch loss: 0.211047 Batch F1: 0.6486486486486486
Epoch:   33        7 Batch loss: 0.216174 Batch F1: 0.6222222222222222
Epoch:   33        8 Batch loss: 0.202427 Batch F1: 0.68
Epoch:   33        9 Batch loss: 0.251869 Batch F1: 0.5333333333333333
Epoch:   33       10 Batch loss: 0.246709 Batch F1: 0.5217391304347826
Epoch:   33       11 Batch loss: 0.218727 Batch F1: 0.6666666666666666
Epoch:   33       12 Batch loss: 0.186817 Batch F1: 0.717948717948718
Train Avg Loss   33: 0.214872

Train Avg F1   33: 0.6242317819896847

Val Avg Loss   33: 0.212163

Val Avg F1   33:  0.6755535102520838

Optimal Val loss (Epoch 33): 0.2121625430881977

Epoch 34
--------------------------------------------------------------
Epoch:   34        1 Batch loss: 0.205465 Batch F1: 0.6666666666666667
Epoch:   34        2 Batch loss: 0.215571 Batch F1: 0.5925925925925926
Epoch:   34        3 Batch loss: 0.200530 Batch F1: 0.5333333333333333
Epoch:   34        4 Batch loss: 0.214094 Batch F1: 0.5
Epoch:   34        5 Batch loss: 0.234283 Batch F1: 0.5909090909090908
Epoch:   34        6 Batch loss: 0.205070 Batch F1: 0.6382978723404256
Epoch:   34        7 Batch loss: 0.205589 Batch F1: 0.6521739130434783
Epoch:   34        8 Batch loss: 0.223198 Batch F1: 0.39999999999999997
Epoch:   34        9 Batch loss: 0.202030 Batch F1: 0.4516129032258065
Epoch:   34       10 Batch loss: 0.210620 Batch F1: 0.5
Epoch:   34       11 Batch loss: 0.230114 Batch F1: 0.3783783783783784
Epoch:   34       12 Batch loss: 0.208833 Batch F1: 0.6666666666666666
Train Avg Loss   34: 0.212950

Train Avg F1   34: 0.54755261809637

Val Avg Loss   34: 0.213659

Val Avg F1   34:  0.6753108003108003

Optimal Val loss (Epoch 33): 0.2121625430881977

Epoch 35
--------------------------------------------------------------
Epoch:   35        1 Batch loss: 0.204356 Batch F1: 0.7857142857142856
Epoch:   35        2 Batch loss: 0.260512 Batch F1: 0.5283018867924528
Epoch:   35        3 Batch loss: 0.232286 Batch F1: 0.6451612903225806
Epoch:   35        4 Batch loss: 0.194848 Batch F1: 0.7
Epoch:   35        5 Batch loss: 0.193369 Batch F1: 0.65
Epoch:   35        6 Batch loss: 0.236226 Batch F1: 0.5263157894736842
Epoch:   35        7 Batch loss: 0.244369 Batch F1: 0.5405405405405406
Epoch:   35        8 Batch loss: 0.243500 Batch F1: 0.3888888888888889
Epoch:   35        9 Batch loss: 0.197873 Batch F1: 0.7391304347826085
Epoch:   35       10 Batch loss: 0.227100 Batch F1: 0.5789473684210527
Epoch:   35       11 Batch loss: 0.191098 Batch F1: 0.5806451612903226
Epoch:   35       12 Batch loss: 0.219598 Batch F1: 0.4666666666666666
Train Avg Loss   35: 0.220428

Train Avg F1   35: 0.5941926927410902

Val Avg Loss   35: 0.217381

Val Avg F1   35:  0.5276351255497234

Optimal Val loss (Epoch 33): 0.2121625430881977

Epoch 36
--------------------------------------------------------------
Epoch:   36        1 Batch loss: 0.233752 Batch F1: 0.3428571428571428
Epoch:   36        2 Batch loss: 0.211561 Batch F1: 0.7199999999999999
Epoch:   36        3 Batch loss: 0.230250 Batch F1: 0.6666666666666666
Epoch:   36        4 Batch loss: 0.196864 Batch F1: 0.6190476190476191
Epoch:   36        5 Batch loss: 0.203562 Batch F1: 0.7234042553191491
Epoch:   36        6 Batch loss: 0.212654 Batch F1: 0.6111111111111112
Epoch:   36        7 Batch loss: 0.213934 Batch F1: 0.3125
Epoch:   36        8 Batch loss: 0.209194 Batch F1: 0.4
Epoch:   36        9 Batch loss: 0.177987 Batch F1: 0.7222222222222223
Epoch:   36       10 Batch loss: 0.261137 Batch F1: 0.5333333333333332
Epoch:   36       11 Batch loss: 0.223185 Batch F1: 0.6779661016949152
Epoch:   36       12 Batch loss: 0.244498 Batch F1: 0.38709677419354843
Train Avg Loss   36: 0.218215

Train Avg F1   36: 0.5596837688704756

Val Avg Loss   36: 0.212230

Val Avg F1   36:  0.6125989609104403

Optimal Val loss (Epoch 33): 0.2121625430881977

Epoch 37
--------------------------------------------------------------
Epoch:   37        1 Batch loss: 0.207275 Batch F1: 0.5333333333333333
Epoch:   37        2 Batch loss: 0.209589 Batch F1: 0.5853658536585366
Epoch:   37        3 Batch loss: 0.215080 Batch F1: 0.5405405405405405
Epoch:   37        4 Batch loss: 0.213057 Batch F1: 0.6808510638297872
Epoch:   37        5 Batch loss: 0.256305 Batch F1: 0.3684210526315789
Epoch:   37        6 Batch loss: 0.207651 Batch F1: 0.7755102040816326
Epoch:   37        7 Batch loss: 0.225671 Batch F1: 0.5454545454545454
Epoch:   37        8 Batch loss: 0.217040 Batch F1: 0.5714285714285713
Epoch:   37        9 Batch loss: 0.195416 Batch F1: 0.6956521739130435
Epoch:   37       10 Batch loss: 0.230895 Batch F1: 0.46511627906976744
Epoch:   37       11 Batch loss: 0.186379 Batch F1: 0.4827586206896552
Epoch:   37       12 Batch loss: 0.224978 Batch F1: 0.4666666666666667
Train Avg Loss   37: 0.215778

Train Avg F1   37: 0.5592582421081381

Val Avg Loss   37: 0.225425

Val Avg F1   37:  0.49115922028635506

Optimal Val loss (Epoch 33): 0.2121625430881977

Epoch 38
--------------------------------------------------------------
Epoch:   38        1 Batch loss: 0.218831 Batch F1: 0.5454545454545455
Epoch:   38        2 Batch loss: 0.232794 Batch F1: 0.5238095238095237
Epoch:   38        3 Batch loss: 0.223188 Batch F1: 0.6666666666666666
Epoch:   38        4 Batch loss: 0.205591 Batch F1: 0.68
Epoch:   38        5 Batch loss: 0.207872 Batch F1: 0.7234042553191491
Epoch:   38        6 Batch loss: 0.196931 Batch F1: 0.7555555555555556
Epoch:   38        7 Batch loss: 0.222845 Batch F1: 0.75
Epoch:   38        8 Batch loss: 0.216228 Batch F1: 0.7500000000000001
Epoch:   38        9 Batch loss: 0.201507 Batch F1: 0.6842105263157895
Epoch:   38       10 Batch loss: 0.239738 Batch F1: 0.5128205128205129
Epoch:   38       11 Batch loss: 0.193927 Batch F1: 0.5454545454545455
Epoch:   38       12 Batch loss: 0.223003 Batch F1: 0.5294117647058824
Train Avg Loss   38: 0.215204

Train Avg F1   38: 0.6388989913418476

Val Avg Loss   38: 0.214714

Val Avg F1   38:  0.6115989830275544

Optimal Val loss (Epoch 33): 0.2121625430881977

Epoch 39
--------------------------------------------------------------
Epoch:   39        1 Batch loss: 0.208422 Batch F1: 0.6222222222222222
Epoch:   39        2 Batch loss: 0.202699 Batch F1: 0.72
Epoch:   39        3 Batch loss: 0.207189 Batch F1: 0.7272727272727272
Epoch:   39        4 Batch loss: 0.226063 Batch F1: 0.5217391304347826
Epoch:   39        5 Batch loss: 0.230462 Batch F1: 0.5909090909090908
Epoch:   39        6 Batch loss: 0.233242 Batch F1: 0.38888888888888895
Epoch:   39        7 Batch loss: 0.248044 Batch F1: 0.5128205128205128
Epoch:   39        8 Batch loss: 0.194510 Batch F1: 0.7234042553191491
Epoch:   39        9 Batch loss: 0.236521 Batch F1: 0.6415094339622641
Epoch:   39       10 Batch loss: 0.244896 Batch F1: 0.47058823529411764
Epoch:   39       11 Batch loss: 0.209354 Batch F1: 0.6
Epoch:   39       12 Batch loss: 0.194405 Batch F1: 0.5384615384615384
Train Avg Loss   39: 0.219651

Train Avg F1   39: 0.5881513362987745

Val Avg Loss   39: 0.226208

Val Avg F1   39:  0.3951948924731183

Optimal Val loss (Epoch 33): 0.2121625430881977

Epoch 40
--------------------------------------------------------------
Epoch:   40        1 Batch loss: 0.246452 Batch F1: 0.14814814814814814
Epoch:   40        2 Batch loss: 0.245368 Batch F1: 0.07142857142857142
Epoch:   40        3 Batch loss: 0.261319 Batch F1: 0.4
Epoch:   40        4 Batch loss: 0.216105 Batch F1: 0.3636363636363636
Epoch:   40        5 Batch loss: 0.235848 Batch F1: 0.5116279069767441
Epoch:   40        6 Batch loss: 0.207681 Batch F1: 0.6829268292682927
Epoch:   40        7 Batch loss: 0.197335 Batch F1: 0.7659574468085106
Epoch:   40        8 Batch loss: 0.226336 Batch F1: 0.6808510638297872
Epoch:   40        9 Batch loss: 0.192367 Batch F1: 0.7272727272727273
Epoch:   40       10 Batch loss: 0.186504 Batch F1: 0.7027027027027026
Epoch:   40       11 Batch loss: 0.204846 Batch F1: 0.65
Epoch:   40       12 Batch loss: 0.208098 Batch F1: 0.3333333333333333
Train Avg Loss   40: 0.219022

Train Avg F1   40: 0.5031570911170985

Val Avg Loss   40: 0.224964

Val Avg F1   40:  0.39193148523777327

Optimal Val loss (Epoch 33): 0.2121625430881977

Epoch 41
--------------------------------------------------------------
Epoch:   41        1 Batch loss: 0.191423 Batch F1: 0.5161290322580646
Epoch:   41        2 Batch loss: 0.233922 Batch F1: 0.2758620689655173
Epoch:   41        3 Batch loss: 0.230240 Batch F1: 0.27586206896551724
Epoch:   41        4 Batch loss: 0.208553 Batch F1: 0.4848484848484849
Epoch:   41        5 Batch loss: 0.241129 Batch F1: 0.5454545454545455
Epoch:   41        6 Batch loss: 0.206447 Batch F1: 0.64
Epoch:   41        7 Batch loss: 0.224176 Batch F1: 0.6249999999999999
Epoch:   41        8 Batch loss: 0.196538 Batch F1: 0.7857142857142856
Epoch:   41        9 Batch loss: 0.223582 Batch F1: 0.6666666666666666
Epoch:   41       10 Batch loss: 0.193198 Batch F1: 0.723404255319149
Epoch:   41       11 Batch loss: 0.216717 Batch F1: 0.5714285714285714
Epoch:   41       12 Batch loss: 0.221874 Batch F1: 0.5333333333333333
Train Avg Loss   41: 0.215650

Train Avg F1   41: 0.553641942746178

Val Avg Loss   41: 0.209975

Val Avg F1   41:  0.6735441841500482

Optimal Val loss (Epoch 41): 0.2099752500653267

Epoch 42
--------------------------------------------------------------
Epoch:   42        1 Batch loss: 0.216157 Batch F1: 0.6956521739130435
Epoch:   42        2 Batch loss: 0.232680 Batch F1: 0.4878048780487804
Epoch:   42        3 Batch loss: 0.201233 Batch F1: 0.48484848484848486
Epoch:   42        4 Batch loss: 0.199666 Batch F1: 0.4516129032258065
Epoch:   42        5 Batch loss: 0.218042 Batch F1: 0.43243243243243246
Epoch:   42        6 Batch loss: 0.208170 Batch F1: 0.606060606060606
Epoch:   42        7 Batch loss: 0.213521 Batch F1: 0.6486486486486486
Epoch:   42        8 Batch loss: 0.238555 Batch F1: 0.4736842105263157
Epoch:   42        9 Batch loss: 0.217406 Batch F1: 0.6190476190476191
Epoch:   42       10 Batch loss: 0.191538 Batch F1: 0.6666666666666666
Epoch:   42       11 Batch loss: 0.193884 Batch F1: 0.7000000000000001
Epoch:   42       12 Batch loss: 0.215182 Batch F1: 0.5555555555555556
Train Avg Loss   42: 0.212170

Train Avg F1   42: 0.5685011815811634

Val Avg Loss   42: 0.214607

Val Avg F1   42:  0.7598385780077939

Optimal Val loss (Epoch 41): 0.2099752500653267

Epoch 43
--------------------------------------------------------------
Epoch:   43        1 Batch loss: 0.196114 Batch F1: 0.7999999999999999
Epoch:   43        2 Batch loss: 0.245483 Batch F1: 0.6
Epoch:   43        3 Batch loss: 0.211770 Batch F1: 0.7391304347826088
Epoch:   43        4 Batch loss: 0.195006 Batch F1: 0.6842105263157896
Epoch:   43        5 Batch loss: 0.190435 Batch F1: 0.5641025641025642
Epoch:   43        6 Batch loss: 0.196352 Batch F1: 0.5333333333333333
Epoch:   43        7 Batch loss: 0.246172 Batch F1: 0.4210526315789474
Epoch:   43        8 Batch loss: 0.206780 Batch F1: 0.5945945945945946
Epoch:   43        9 Batch loss: 0.202000 Batch F1: 0.5555555555555555
Epoch:   43       10 Batch loss: 0.227888 Batch F1: 0.43243243243243246
Epoch:   43       11 Batch loss: 0.207152 Batch F1: 0.5581395348837208
Epoch:   43       12 Batch loss: 0.231460 Batch F1: 0.5263157894736841
Train Avg Loss   43: 0.213051

Train Avg F1   43: 0.5840722830877693

Val Avg Loss   43: 0.208877

Val Avg F1   43:  0.6737588652482269

Optimal Val loss (Epoch 43): 0.2088770605623722

Epoch 44
--------------------------------------------------------------
Epoch:   44        1 Batch loss: 0.204935 Batch F1: 0.6086956521739131
Epoch:   44        2 Batch loss: 0.204614 Batch F1: 0.7111111111111111
Epoch:   44        3 Batch loss: 0.206357 Batch F1: 0.7111111111111111
Epoch:   44        4 Batch loss: 0.224897 Batch F1: 0.5333333333333332
Epoch:   44        5 Batch loss: 0.205884 Batch F1: 0.6938775510204083
Epoch:   44        6 Batch loss: 0.193807 Batch F1: 0.8181818181818182
Epoch:   44        7 Batch loss: 0.240293 Batch F1: 0.4242424242424242
Epoch:   44        8 Batch loss: 0.200652 Batch F1: 0.6666666666666667
Epoch:   44        9 Batch loss: 0.206351 Batch F1: 0.7027027027027026
Epoch:   44       10 Batch loss: 0.233265 Batch F1: 0.5853658536585366
Epoch:   44       11 Batch loss: 0.189013 Batch F1: 0.6857142857142857
Epoch:   44       12 Batch loss: 0.222469 Batch F1: 0.5945945945945946
Train Avg Loss   44: 0.211045

Train Avg F1   44: 0.6446330920425755

Val Avg Loss   44: 0.208304

Val Avg F1   44:  0.5918100441757731

Optimal Val loss (Epoch 44): 0.20830358564853668

Epoch 45
--------------------------------------------------------------
Epoch:   45        1 Batch loss: 0.213726 Batch F1: 0.6956521739130435
Epoch:   45        2 Batch loss: 0.208919 Batch F1: 0.4444444444444444
Epoch:   45        3 Batch loss: 0.201054 Batch F1: 0.6666666666666666
Epoch:   45        4 Batch loss: 0.197496 Batch F1: 0.717948717948718
Epoch:   45        5 Batch loss: 0.200448 Batch F1: 0.7441860465116279
Epoch:   45        6 Batch loss: 0.216610 Batch F1: 0.5555555555555556
Epoch:   45        7 Batch loss: 0.208651 Batch F1: 0.6666666666666667
Epoch:   45        8 Batch loss: 0.230099 Batch F1: 0.5116279069767442
Epoch:   45        9 Batch loss: 0.212193 Batch F1: 0.717948717948718
Epoch:   45       10 Batch loss: 0.196835 Batch F1: 0.5806451612903226
Epoch:   45       11 Batch loss: 0.182868 Batch F1: 0.7000000000000001
Epoch:   45       12 Batch loss: 0.226912 Batch F1: 0.6808510638297872
Train Avg Loss   45: 0.207984

Train Avg F1   45: 0.6401827601460247

Val Avg Loss   45: 0.206153

Val Avg F1   45:  0.6742409560723515

Optimal Val loss (Epoch 45): 0.20615297183394432

Epoch 46
--------------------------------------------------------------
Epoch:   46        1 Batch loss: 0.202756 Batch F1: 0.6666666666666666
Epoch:   46        2 Batch loss: 0.205164 Batch F1: 0.6976744186046512
Epoch:   46        3 Batch loss: 0.215499 Batch F1: 0.5238095238095238
Epoch:   46        4 Batch loss: 0.209416 Batch F1: 0.6274509803921569
Epoch:   46        5 Batch loss: 0.199633 Batch F1: 0.5853658536585366
Epoch:   46        6 Batch loss: 0.198508 Batch F1: 0.7027027027027026
Epoch:   46        7 Batch loss: 0.239332 Batch F1: 0.4571428571428572
Epoch:   46        8 Batch loss: 0.196682 Batch F1: 0.6470588235294118
Epoch:   46        9 Batch loss: 0.229194 Batch F1: 0.6046511627906976
Epoch:   46       10 Batch loss: 0.203352 Batch F1: 0.631578947368421
Epoch:   46       11 Batch loss: 0.219417 Batch F1: 0.5
Epoch:   46       12 Batch loss: 0.170054 Batch F1: 0.6153846153846153
Train Avg Loss   46: 0.207417

Train Avg F1   46: 0.6049572126708535

Val Avg Loss   46: 0.205893

Val Avg F1   46:  0.5325497360381082

Optimal Val loss (Epoch 46): 0.2058934010565281

Epoch 47
--------------------------------------------------------------
Epoch:   47        1 Batch loss: 0.168193 Batch F1: 0.6976744186046512
Epoch:   47        2 Batch loss: 0.198455 Batch F1: 0.6666666666666667
Epoch:   47        3 Batch loss: 0.224054 Batch F1: 0.6792452830188679
Epoch:   47        4 Batch loss: 0.183414 Batch F1: 0.5925925925925927
Epoch:   47        5 Batch loss: 0.177945 Batch F1: 0.6842105263157895
Epoch:   47        6 Batch loss: 0.199367 Batch F1: 0.5945945945945946
Epoch:   47        7 Batch loss: 0.266739 Batch F1: 0.4545454545454546
Epoch:   47        8 Batch loss: 0.195874 Batch F1: 0.75
Epoch:   47        9 Batch loss: 0.206890 Batch F1: 0.6818181818181819
Epoch:   47       10 Batch loss: 0.217276 Batch F1: 0.5789473684210527
Epoch:   47       11 Batch loss: 0.231099 Batch F1: 0.6666666666666667
Epoch:   47       12 Batch loss: 0.223837 Batch F1: 0.5116279069767442
Train Avg Loss   47: 0.207762

Train Avg F1   47: 0.6298824716851051

Val Avg Loss   47: 0.203359

Val Avg F1   47:  0.6855888676540851

Optimal Val loss (Epoch 47): 0.203359242528677

Epoch 48
--------------------------------------------------------------
Epoch:   48        1 Batch loss: 0.168819 Batch F1: 0.7441860465116279
Epoch:   48        2 Batch loss: 0.192617 Batch F1: 0.6
Epoch:   48        3 Batch loss: 0.216339 Batch F1: 0.47058823529411764
Epoch:   48        4 Batch loss: 0.202388 Batch F1: 0.7555555555555555
Epoch:   48        5 Batch loss: 0.203021 Batch F1: 0.5882352941176471
Epoch:   48        6 Batch loss: 0.233042 Batch F1: 0.43902439024390244
Epoch:   48        7 Batch loss: 0.221163 Batch F1: 0.4242424242424242
Epoch:   48        8 Batch loss: 0.203053 Batch F1: 0.5777777777777778
Epoch:   48        9 Batch loss: 0.214596 Batch F1: 0.6829268292682926
Epoch:   48       10 Batch loss: 0.201665 Batch F1: 0.65
Epoch:   48       11 Batch loss: 0.239003 Batch F1: 0.5
Epoch:   48       12 Batch loss: 0.174971 Batch F1: 0.8333333333333334
Train Avg Loss   48: 0.205890

Train Avg F1   48: 0.6054891571953899

Val Avg Loss   48: 0.204922

Val Avg F1   48:  0.6771919206066548

Optimal Val loss (Epoch 47): 0.203359242528677

Epoch 49
--------------------------------------------------------------
Epoch:   49        1 Batch loss: 0.174720 Batch F1: 0.7567567567567567
Epoch:   49        2 Batch loss: 0.207120 Batch F1: 0.7499999999999999
Epoch:   49        3 Batch loss: 0.224908 Batch F1: 0.6938775510204083
Epoch:   49        4 Batch loss: 0.229396 Batch F1: 0.6666666666666667
Epoch:   49        5 Batch loss: 0.195091 Batch F1: 0.6190476190476191
Epoch:   49        6 Batch loss: 0.213899 Batch F1: 0.5
Epoch:   49        7 Batch loss: 0.191114 Batch F1: 0.6153846153846153
Epoch:   49        8 Batch loss: 0.238855 Batch F1: 0.3428571428571429
Epoch:   49        9 Batch loss: 0.199235 Batch F1: 0.7999999999999999
Epoch:   49       10 Batch loss: 0.197521 Batch F1: 0.5945945945945946
Epoch:   49       11 Batch loss: 0.219209 Batch F1: 0.6250000000000001
Epoch:   49       12 Batch loss: 0.174272 Batch F1: 0.5185185185185185
Train Avg Loss   49: 0.205445

Train Avg F1   49: 0.6235586220705268

Val Avg Loss   49: 0.208913

Val Avg F1   49:  0.5315637065637066

Optimal Val loss (Epoch 47): 0.203359242528677

Epoch 50
--------------------------------------------------------------
Epoch:   50        1 Batch loss: 0.172711 Batch F1: 0.4666666666666667
Epoch:   50        2 Batch loss: 0.261502 Batch F1: 0.4186046511627908
Epoch:   50        3 Batch loss: 0.216071 Batch F1: 0.5882352941176471
Epoch:   50        4 Batch loss: 0.218156 Batch F1: 0.6808510638297872
Epoch:   50        5 Batch loss: 0.194607 Batch F1: 0.8620689655172414
Epoch:   50        6 Batch loss: 0.218288 Batch F1: 0.711111111111111
Epoch:   50        7 Batch loss: 0.225466 Batch F1: 0.6829268292682927
Epoch:   50        8 Batch loss: 0.182433 Batch F1: 0.7441860465116279
Epoch:   50        9 Batch loss: 0.196639 Batch F1: 0.5161290322580645
Epoch:   50       10 Batch loss: 0.226046 Batch F1: 0.5882352941176471
Epoch:   50       11 Batch loss: 0.218452 Batch F1: 0.42105263157894735
Epoch:   50       12 Batch loss: 0.213522 Batch F1: 0.65
Train Avg Loss   50: 0.211991

Train Avg F1   50: 0.6108389655116518

Val Avg Loss   50: 0.218133

Val Avg F1   50:  0.6819870119585016

Optimal Val loss (Epoch 47): 0.203359242528677

Epoch 51
--------------------------------------------------------------
Epoch:   51        1 Batch loss: 0.220616 Batch F1: 0.6341463414634146
Epoch:   51        2 Batch loss: 0.229567 Batch F1: 0.5365853658536585
Epoch:   51        3 Batch loss: 0.223624 Batch F1: 0.5625
Epoch:   51        4 Batch loss: 0.216979 Batch F1: 0.5405405405405406
Epoch:   51        5 Batch loss: 0.202625 Batch F1: 0.7636363636363638
Epoch:   51        6 Batch loss: 0.189137 Batch F1: 0.888888888888889
Epoch:   51        7 Batch loss: 0.241452 Batch F1: 0.6538461538461539
Epoch:   51        8 Batch loss: 0.203576 Batch F1: 0.6046511627906977
Epoch:   51        9 Batch loss: 0.239759 Batch F1: 0.3888888888888889
Epoch:   51       10 Batch loss: 0.180668 Batch F1: 0.6060606060606061
Epoch:   51       11 Batch loss: 0.223938 Batch F1: 0.4
Epoch:   51       12 Batch loss: 0.192685 Batch F1: 0.6875000000000001
Train Avg Loss   51: 0.213719

Train Avg F1   51: 0.6056036926641012

Val Avg Loss   51: 0.210871

Val Avg F1   51:  0.5290287669319927

Optimal Val loss (Epoch 47): 0.203359242528677

Epoch 52
--------------------------------------------------------------
Epoch:   52        1 Batch loss: 0.205190 Batch F1: 0.5
Epoch:   52        2 Batch loss: 0.192663 Batch F1: 0.5454545454545454
Epoch:   52        3 Batch loss: 0.225528 Batch F1: 0.619047619047619
Epoch:   52        4 Batch loss: 0.206972 Batch F1: 0.6315789473684211
Epoch:   52        5 Batch loss: 0.195793 Batch F1: 0.7659574468085107
Epoch:   52        6 Batch loss: 0.204413 Batch F1: 0.68
Epoch:   52        7 Batch loss: 0.196526 Batch F1: 0.7058823529411765
Epoch:   52        8 Batch loss: 0.194086 Batch F1: 0.8275862068965517
Epoch:   52        9 Batch loss: 0.213918 Batch F1: 0.6808510638297872
Epoch:   52       10 Batch loss: 0.214340 Batch F1: 0.6363636363636364
Epoch:   52       11 Batch loss: 0.188985 Batch F1: 0.8205128205128205
Epoch:   52       12 Batch loss: 0.227677 Batch F1: 0.5925925925925927
Train Avg Loss   52: 0.205508

Train Avg F1   52: 0.6671522693179718

Val Avg Loss   52: 0.213281

Val Avg F1   52:  0.5630028508077288

Optimal Val loss (Epoch 47): 0.203359242528677

Epoch 53
--------------------------------------------------------------
Epoch:   53        1 Batch loss: 0.237514 Batch F1: 0.5
Epoch:   53        2 Batch loss: 0.231986 Batch F1: 0.375
Epoch:   53        3 Batch loss: 0.220199 Batch F1: 0.2
Epoch:   53        4 Batch loss: 0.201845 Batch F1: 0.6086956521739131
Epoch:   53        5 Batch loss: 0.179974 Batch F1: 0.8076923076923077
Epoch:   53        6 Batch loss: 0.194600 Batch F1: 0.5555555555555555
Epoch:   53        7 Batch loss: 0.215151 Batch F1: 0.5333333333333332
Epoch:   53        8 Batch loss: 0.176659 Batch F1: 0.6153846153846153
Epoch:   53        9 Batch loss: 0.195696 Batch F1: 0.819672131147541
Epoch:   53       10 Batch loss: 0.202511 Batch F1: 0.7450980392156863
Epoch:   53       11 Batch loss: 0.184938 Batch F1: 0.7924528301886793
Epoch:   53       12 Batch loss: 0.195809 Batch F1: 0.7272727272727272
Train Avg Loss   53: 0.203073

Train Avg F1   53: 0.6066797659970299

Val Avg Loss   53: 0.202270

Val Avg F1   53:  0.6247293098578288

Optimal Val loss (Epoch 53): 0.20226969942450523

Epoch 54
--------------------------------------------------------------
Epoch:   54        1 Batch loss: 0.209024 Batch F1: 0.6521739130434783
Epoch:   54        2 Batch loss: 0.179931 Batch F1: 0.7894736842105262
Epoch:   54        3 Batch loss: 0.207001 Batch F1: 0.5714285714285714
Epoch:   54        4 Batch loss: 0.186007 Batch F1: 0.8333333333333333
Epoch:   54        5 Batch loss: 0.191550 Batch F1: 0.5499999999999999
Epoch:   54        6 Batch loss: 0.213165 Batch F1: 0.6511627906976744
Epoch:   54        7 Batch loss: 0.215904 Batch F1: 0.375
Epoch:   54        8 Batch loss: 0.193871 Batch F1: 0.65
Epoch:   54        9 Batch loss: 0.204032 Batch F1: 0.6792452830188679
Epoch:   54       10 Batch loss: 0.219299 Batch F1: 0.6792452830188679
Epoch:   54       11 Batch loss: 0.225631 Batch F1: 0.6530612244897959
Epoch:   54       12 Batch loss: 0.167299 Batch F1: 0.7647058823529412
Train Avg Loss   54: 0.201060

Train Avg F1   54: 0.6540691637995047

Val Avg Loss   54: 0.199804

Val Avg F1   54:  0.670887445887446

Optimal Val loss (Epoch 54): 0.19980354607105255

Epoch 55
--------------------------------------------------------------
Epoch:   55        1 Batch loss: 0.184336 Batch F1: 0.6842105263157895
Epoch:   55        2 Batch loss: 0.205072 Batch F1: 0.7027027027027026
Epoch:   55        3 Batch loss: 0.198576 Batch F1: 0.7142857142857143
Epoch:   55        4 Batch loss: 0.186733 Batch F1: 0.6666666666666666
Epoch:   55        5 Batch loss: 0.205955 Batch F1: 0.7142857142857143
Epoch:   55        6 Batch loss: 0.179648 Batch F1: 0.761904761904762
Epoch:   55        7 Batch loss: 0.240082 Batch F1: 0.42857142857142855
Epoch:   55        8 Batch loss: 0.190521 Batch F1: 0.7199999999999999
Epoch:   55        9 Batch loss: 0.194563 Batch F1: 0.7234042553191491
Epoch:   55       10 Batch loss: 0.201697 Batch F1: 0.6956521739130435
Epoch:   55       11 Batch loss: 0.216894 Batch F1: 0.6521739130434783
Epoch:   55       12 Batch loss: 0.179773 Batch F1: 0.8095238095238095
Train Avg Loss   55: 0.198654

Train Avg F1   55: 0.6894484722110216

Val Avg Loss   55: 0.204562

Val Avg F1   55:  0.7943942536616129

Optimal Val loss (Epoch 54): 0.19980354607105255

Epoch 56
--------------------------------------------------------------
Epoch:   56        1 Batch loss: 0.216652 Batch F1: 0.72
Epoch:   56        2 Batch loss: 0.203875 Batch F1: 0.6808510638297872
Epoch:   56        3 Batch loss: 0.197905 Batch F1: 0.6829268292682926
Epoch:   56        4 Batch loss: 0.205584 Batch F1: 0.6046511627906976
Epoch:   56        5 Batch loss: 0.174379 Batch F1: 0.7027027027027027
Epoch:   56        6 Batch loss: 0.188066 Batch F1: 0.7777777777777779
Epoch:   56        7 Batch loss: 0.189287 Batch F1: 0.7272727272727272
Epoch:   56        8 Batch loss: 0.183453 Batch F1: 0.6341463414634148
Epoch:   56        9 Batch loss: 0.171957 Batch F1: 0.7391304347826088
Epoch:   56       10 Batch loss: 0.172457 Batch F1: 0.7391304347826088
Epoch:   56       11 Batch loss: 0.216449 Batch F1: 0.5957446808510639
Epoch:   56       12 Batch loss: 0.212982 Batch F1: 0.6666666666666667
Train Avg Loss   56: 0.194421

Train Avg F1   56: 0.6892500685156956

Val Avg Loss   56: 0.199478

Val Avg F1   56:  0.6333550490390112

Optimal Val loss (Epoch 56): 0.19947845861315727

Epoch 57
--------------------------------------------------------------
Epoch:   57        1 Batch loss: 0.183592 Batch F1: 0.5294117647058824
Epoch:   57        2 Batch loss: 0.172910 Batch F1: 0.7142857142857143
Epoch:   57        3 Batch loss: 0.177165 Batch F1: 0.7234042553191491
Epoch:   57        4 Batch loss: 0.216102 Batch F1: 0.6428571428571429
Epoch:   57        5 Batch loss: 0.199128 Batch F1: 0.5
Epoch:   57        6 Batch loss: 0.202158 Batch F1: 0.7199999999999999
Epoch:   57        7 Batch loss: 0.188230 Batch F1: 0.6382978723404256
Epoch:   57        8 Batch loss: 0.189752 Batch F1: 0.64
Epoch:   57        9 Batch loss: 0.192474 Batch F1: 0.7307692307692307
Epoch:   57       10 Batch loss: 0.182975 Batch F1: 0.711111111111111
Epoch:   57       11 Batch loss: 0.215107 Batch F1: 0.6296296296296297
Epoch:   57       12 Batch loss: 0.194978 Batch F1: 0.5882352941176471
Train Avg Loss   57: 0.192881

Train Avg F1   57: 0.6473335012613277

Val Avg Loss   57: 0.199719

Val Avg F1   57:  0.6309800492242665

Optimal Val loss (Epoch 56): 0.19947845861315727

Epoch 58
--------------------------------------------------------------
Epoch:   58        1 Batch loss: 0.188305 Batch F1: 0.6511627906976744
Epoch:   58        2 Batch loss: 0.176326 Batch F1: 0.7450980392156863
Epoch:   58        3 Batch loss: 0.184459 Batch F1: 0.75
Epoch:   58        4 Batch loss: 0.192054 Batch F1: 0.6976744186046512
Epoch:   58        5 Batch loss: 0.181730 Batch F1: 0.723404255319149
Epoch:   58        6 Batch loss: 0.163299 Batch F1: 0.7142857142857143
Epoch:   58        7 Batch loss: 0.167881 Batch F1: 0.7
Epoch:   58        8 Batch loss: 0.222000 Batch F1: 0.5531914893617021
Epoch:   58        9 Batch loss: 0.206023 Batch F1: 0.7636363636363636
Epoch:   58       10 Batch loss: 0.221382 Batch F1: 0.4999999999999999
Epoch:   58       11 Batch loss: 0.212086 Batch F1: 0.5416666666666666
Epoch:   58       12 Batch loss: 0.186951 Batch F1: 0.6666666666666666
Train Avg Loss   58: 0.191875

Train Avg F1   58: 0.6672322003711896

Val Avg Loss   58: 0.199659

Val Avg F1   58:  0.6618018018018018

Optimal Val loss (Epoch 56): 0.19947845861315727

Epoch 59
--------------------------------------------------------------
Epoch:   59        1 Batch loss: 0.174498 Batch F1: 0.6842105263157895
Epoch:   59        2 Batch loss: 0.191156 Batch F1: 0.7450980392156864
Epoch:   59        3 Batch loss: 0.187420 Batch F1: 0.7441860465116279
Epoch:   59        4 Batch loss: 0.195070 Batch F1: 0.6976744186046512
Epoch:   59        5 Batch loss: 0.143786 Batch F1: 0.8571428571428572
Epoch:   59        6 Batch loss: 0.174644 Batch F1: 0.7777777777777777
Epoch:   59        7 Batch loss: 0.191235 Batch F1: 0.7450980392156863
Epoch:   59        8 Batch loss: 0.222208 Batch F1: 0.5882352941176471
Epoch:   59        9 Batch loss: 0.194741 Batch F1: 0.6521739130434783
Epoch:   59       10 Batch loss: 0.190794 Batch F1: 0.6511627906976744
Epoch:   59       11 Batch loss: 0.201496 Batch F1: 0.5789473684210527
Epoch:   59       12 Batch loss: 0.218886 Batch F1: 0.6153846153846153
Train Avg Loss   59: 0.190495

Train Avg F1   59: 0.6947576405373787

Val Avg Loss   59: 0.200666

Val Avg F1   59:  0.6716843905480865

Optimal Val loss (Epoch 56): 0.19947845861315727

Epoch 60
--------------------------------------------------------------
Epoch:   60        1 Batch loss: 0.162508 Batch F1: 0.6666666666666667
Epoch:   60        2 Batch loss: 0.206683 Batch F1: 0.7058823529411765
Epoch:   60        3 Batch loss: 0.204703 Batch F1: 0.6511627906976744
Epoch:   60        4 Batch loss: 0.200744 Batch F1: 0.5263157894736841
Epoch:   60        5 Batch loss: 0.216812 Batch F1: 0.588235294117647
Epoch:   60        6 Batch loss: 0.211946 Batch F1: 0.5
Epoch:   60        7 Batch loss: 0.175460 Batch F1: 0.6818181818181818
Epoch:   60        8 Batch loss: 0.178107 Batch F1: 0.742857142857143
Epoch:   60        9 Batch loss: 0.167755 Batch F1: 0.8181818181818182
Epoch:   60       10 Batch loss: 0.201401 Batch F1: 0.72
Epoch:   60       11 Batch loss: 0.183789 Batch F1: 0.8076923076923077
Epoch:   60       12 Batch loss: 0.181350 Batch F1: 0.7555555555555555
Train Avg Loss   60: 0.190938

Train Avg F1   60: 0.680363991666821

Val Avg Loss   60: 0.201030

Val Avg F1   60:  0.6925356763631696

Optimal Val loss (Epoch 56): 0.19947845861315727

Epoch 61
--------------------------------------------------------------
Epoch:   61        1 Batch loss: 0.192769 Batch F1: 0.7346938775510204
Epoch:   61        2 Batch loss: 0.195623 Batch F1: 0.68
Epoch:   61        3 Batch loss: 0.195465 Batch F1: 0.7111111111111111
Epoch:   61        4 Batch loss: 0.199714 Batch F1: 0.6666666666666666
Epoch:   61        5 Batch loss: 0.205931 Batch F1: 0.6511627906976744
Epoch:   61        6 Batch loss: 0.196936 Batch F1: 0.6666666666666666
Epoch:   61        7 Batch loss: 0.199509 Batch F1: 0.5789473684210527
Epoch:   61        8 Batch loss: 0.175030 Batch F1: 0.7272727272727273
Epoch:   61        9 Batch loss: 0.175351 Batch F1: 0.7843137254901961
Epoch:   61       10 Batch loss: 0.182196 Batch F1: 0.7547169811320756
Epoch:   61       11 Batch loss: 0.208829 Batch F1: 0.7200000000000001
Epoch:   61       12 Batch loss: 0.206855 Batch F1: 0.5454545454545455
Train Avg Loss   61: 0.194517

Train Avg F1   61: 0.6850838717053113

Val Avg Loss   61: 0.205192

Val Avg F1   61:  0.6893544651903314

Optimal Val loss (Epoch 56): 0.19947845861315727

Epoch 62
--------------------------------------------------------------
Epoch:   62        1 Batch loss: 0.163519 Batch F1: 0.6857142857142857
Epoch:   62        2 Batch loss: 0.217492 Batch F1: 0.33333333333333337
Epoch:   62        3 Batch loss: 0.226012 Batch F1: 0.35294117647058826
Epoch:   62        4 Batch loss: 0.185301 Batch F1: 0.625
Epoch:   62        5 Batch loss: 0.196902 Batch F1: 0.5454545454545455
Epoch:   62        6 Batch loss: 0.213123 Batch F1: 0.7083333333333334
Epoch:   62        7 Batch loss: 0.203829 Batch F1: 0.7272727272727272
Epoch:   62        8 Batch loss: 0.214360 Batch F1: 0.68
Epoch:   62        9 Batch loss: 0.175904 Batch F1: 0.823529411764706
Epoch:   62       10 Batch loss: 0.200522 Batch F1: 0.7017543859649122
Epoch:   62       11 Batch loss: 0.190679 Batch F1: 0.6666666666666666
Epoch:   62       12 Batch loss: 0.171641 Batch F1: 0.7777777777777778
Train Avg Loss   62: 0.196607

Train Avg F1   62: 0.6356481369794063

Val Avg Loss   62: 0.198479

Val Avg F1   62:  0.6772093023255814

Optimal Val loss (Epoch 62): 0.19847945868968964

Epoch 63
--------------------------------------------------------------
Epoch:   63        1 Batch loss: 0.175240 Batch F1: 0.7659574468085107
Epoch:   63        2 Batch loss: 0.192561 Batch F1: 0.8000000000000002
Epoch:   63        3 Batch loss: 0.186216 Batch F1: 0.6521739130434783
Epoch:   63        4 Batch loss: 0.179242 Batch F1: 0.7555555555555556
Epoch:   63        5 Batch loss: 0.177784 Batch F1: 0.6956521739130435
Epoch:   63        6 Batch loss: 0.206270 Batch F1: 0.6122448979591836
Epoch:   63        7 Batch loss: 0.188500 Batch F1: 0.7346938775510203
Epoch:   63        8 Batch loss: 0.185305 Batch F1: 0.5714285714285713
Epoch:   63        9 Batch loss: 0.207469 Batch F1: 0.5652173913043478
Epoch:   63       10 Batch loss: 0.162197 Batch F1: 0.7
Epoch:   63       11 Batch loss: 0.203604 Batch F1: 0.5833333333333334
Epoch:   63       12 Batch loss: 0.202310 Batch F1: 0.717948717948718
Train Avg Loss   63: 0.188892

Train Avg F1   63: 0.6795171565704802

Val Avg Loss   63: 0.197053

Val Avg F1   63:  0.6764842300556586

Optimal Val loss (Epoch 63): 0.1970534287393093

Epoch 64
--------------------------------------------------------------
Epoch:   64        1 Batch loss: 0.199634 Batch F1: 0.7346938775510204
Epoch:   64        2 Batch loss: 0.171387 Batch F1: 0.7755102040816326
Epoch:   64        3 Batch loss: 0.197504 Batch F1: 0.6086956521739131
Epoch:   64        4 Batch loss: 0.180547 Batch F1: 0.711111111111111
Epoch:   64        5 Batch loss: 0.175825 Batch F1: 0.7391304347826088
Epoch:   64        6 Batch loss: 0.177190 Batch F1: 0.5806451612903226
Epoch:   64        7 Batch loss: 0.202158 Batch F1: 0.6808510638297872
Epoch:   64        8 Batch loss: 0.194016 Batch F1: 0.7083333333333334
Epoch:   64        9 Batch loss: 0.180904 Batch F1: 0.6842105263157895
Epoch:   64       10 Batch loss: 0.189526 Batch F1: 0.7200000000000001
Epoch:   64       11 Batch loss: 0.190879 Batch F1: 0.6666666666666666
Epoch:   64       12 Batch loss: 0.193747 Batch F1: 0.8292682926829269
Train Avg Loss   64: 0.187776

Train Avg F1   64: 0.7032596936515927

Val Avg Loss   64: 0.195235

Val Avg F1   64:  0.6645025100668761

Optimal Val loss (Epoch 64): 0.19523492828011513

Epoch 65
--------------------------------------------------------------
Epoch:   65        1 Batch loss: 0.201317 Batch F1: 0.6808510638297872
Epoch:   65        2 Batch loss: 0.215092 Batch F1: 0.5217391304347826
Epoch:   65        3 Batch loss: 0.183242 Batch F1: 0.6521739130434783
Epoch:   65        4 Batch loss: 0.200260 Batch F1: 0.5365853658536586
Epoch:   65        5 Batch loss: 0.183298 Batch F1: 0.76
Epoch:   65        6 Batch loss: 0.224055 Batch F1: 0.64
Epoch:   65        7 Batch loss: 0.159754 Batch F1: 0.8095238095238095
Epoch:   65        8 Batch loss: 0.152307 Batch F1: 0.8000000000000002
Epoch:   65        9 Batch loss: 0.205469 Batch F1: 0.619047619047619
Epoch:   65       10 Batch loss: 0.171522 Batch F1: 0.7999999999999999
Epoch:   65       11 Batch loss: 0.165854 Batch F1: 0.7906976744186046
Epoch:   65       12 Batch loss: 0.192911 Batch F1: 0.8571428571428571
Train Avg Loss   65: 0.187923

Train Avg F1   65: 0.705646786107883

Val Avg Loss   65: 0.193081

Val Avg F1   65:  0.6737806249458294

Optimal Val loss (Epoch 65): 0.19308088719844818

Epoch 66
--------------------------------------------------------------
Epoch:   66        1 Batch loss: 0.192813 Batch F1: 0.6666666666666666
Epoch:   66        2 Batch loss: 0.180486 Batch F1: 0.7346938775510204
Epoch:   66        3 Batch loss: 0.186067 Batch F1: 0.6153846153846153
Epoch:   66        4 Batch loss: 0.186323 Batch F1: 0.8
Epoch:   66        5 Batch loss: 0.176269 Batch F1: 0.7999999999999999
Epoch:   66        6 Batch loss: 0.175094 Batch F1: 0.7058823529411765
Epoch:   66        7 Batch loss: 0.186388 Batch F1: 0.6666666666666666
Epoch:   66        8 Batch loss: 0.198277 Batch F1: 0.5263157894736842
Epoch:   66        9 Batch loss: 0.189750 Batch F1: 0.5714285714285715
Epoch:   66       10 Batch loss: 0.189084 Batch F1: 0.7272727272727272
Epoch:   66       11 Batch loss: 0.179659 Batch F1: 0.761904761904762
Epoch:   66       12 Batch loss: 0.188936 Batch F1: 0.6842105263157895
Train Avg Loss   66: 0.185762

Train Avg F1   66: 0.6883688796338067

Val Avg Loss   66: 0.196115

Val Avg F1   66:  0.6276261869065467

Optimal Val loss (Epoch 65): 0.19308088719844818

Epoch 67
--------------------------------------------------------------
Epoch:   67        1 Batch loss: 0.201252 Batch F1: 0.64
Epoch:   67        2 Batch loss: 0.174761 Batch F1: 0.6190476190476191
Epoch:   67        3 Batch loss: 0.197488 Batch F1: 0.6382978723404256
Epoch:   67        4 Batch loss: 0.208760 Batch F1: 0.64
Epoch:   67        5 Batch loss: 0.197634 Batch F1: 0.68
Epoch:   67        6 Batch loss: 0.167247 Batch F1: 0.7441860465116279
Epoch:   67        7 Batch loss: 0.218801 Batch F1: 0.6122448979591837
Epoch:   67        8 Batch loss: 0.172670 Batch F1: 0.75
Epoch:   67        9 Batch loss: 0.180160 Batch F1: 0.7441860465116279
Epoch:   67       10 Batch loss: 0.168335 Batch F1: 0.7027027027027027
Epoch:   67       11 Batch loss: 0.211417 Batch F1: 0.6363636363636364
Epoch:   67       12 Batch loss: 0.188688 Batch F1: 0.6315789473684211
Train Avg Loss   67: 0.190601

Train Avg F1   67: 0.6698839807337703

Val Avg Loss   67: 0.198035

Val Avg F1   67:  0.6911231884057971

Optimal Val loss (Epoch 65): 0.19308088719844818

Epoch 68
--------------------------------------------------------------
Epoch:   68        1 Batch loss: 0.208018 Batch F1: 0.5128205128205129
Epoch:   68        2 Batch loss: 0.195939 Batch F1: 0.5777777777777778
Epoch:   68        3 Batch loss: 0.179295 Batch F1: 0.7924528301886793
Epoch:   68        4 Batch loss: 0.193396 Batch F1: 0.6976744186046512
Epoch:   68        5 Batch loss: 0.188829 Batch F1: 0.6829268292682926
Epoch:   68        6 Batch loss: 0.189006 Batch F1: 0.5555555555555555
Epoch:   68        7 Batch loss: 0.166502 Batch F1: 0.7441860465116279
Epoch:   68        8 Batch loss: 0.208964 Batch F1: 0.6428571428571429
Epoch:   68        9 Batch loss: 0.183149 Batch F1: 0.7307692307692308
Epoch:   68       10 Batch loss: 0.188427 Batch F1: 0.7083333333333334
Epoch:   68       11 Batch loss: 0.175305 Batch F1: 0.7111111111111111
Epoch:   68       12 Batch loss: 0.167889 Batch F1: 0.8260869565217391
Train Avg Loss   68: 0.187060

Train Avg F1   68: 0.6818793121099711

Val Avg Loss   68: 0.194826

Val Avg F1   68:  0.6403075960335034

Optimal Val loss (Epoch 65): 0.19308088719844818

Epoch 69
--------------------------------------------------------------
Epoch:   69        1 Batch loss: 0.171695 Batch F1: 0.6818181818181819
Epoch:   69        2 Batch loss: 0.171298 Batch F1: 0.6818181818181818
Epoch:   69        3 Batch loss: 0.163067 Batch F1: 0.76
Epoch:   69        4 Batch loss: 0.192617 Batch F1: 0.6399999999999999
Epoch:   69        5 Batch loss: 0.195623 Batch F1: 0.6530612244897959
Epoch:   69        6 Batch loss: 0.183240 Batch F1: 0.6666666666666666
Epoch:   69        7 Batch loss: 0.235786 Batch F1: 0.45
Epoch:   69        8 Batch loss: 0.158496 Batch F1: 0.7659574468085107
Epoch:   69        9 Batch loss: 0.194665 Batch F1: 0.7391304347826088
Epoch:   69       10 Batch loss: 0.236156 Batch F1: 0.358974358974359
Epoch:   69       11 Batch loss: 0.186645 Batch F1: 0.7111111111111111
Epoch:   69       12 Batch loss: 0.179748 Batch F1: 0.6285714285714286
Train Avg Loss   69: 0.189086

Train Avg F1   69: 0.6447590862534036

Val Avg Loss   69: 0.196291

Val Avg F1   69:  0.63747319409704

Optimal Val loss (Epoch 65): 0.19308088719844818

Epoch 70
--------------------------------------------------------------
Epoch:   70        1 Batch loss: 0.189249 Batch F1: 0.7037037037037037
Epoch:   70        2 Batch loss: 0.170749 Batch F1: 0.711111111111111
Epoch:   70        3 Batch loss: 0.177136 Batch F1: 0.6829268292682926
Epoch:   70        4 Batch loss: 0.203410 Batch F1: 0.693877551020408
Epoch:   70        5 Batch loss: 0.200686 Batch F1: 0.6666666666666666
Epoch:   70        6 Batch loss: 0.196414 Batch F1: 0.7450980392156864
Epoch:   70        7 Batch loss: 0.190215 Batch F1: 0.6190476190476191
Epoch:   70        8 Batch loss: 0.184235 Batch F1: 0.7199999999999999
Epoch:   70        9 Batch loss: 0.181346 Batch F1: 0.6363636363636365
Epoch:   70       10 Batch loss: 0.171966 Batch F1: 0.761904761904762
Epoch:   70       11 Batch loss: 0.202229 Batch F1: 0.68
Epoch:   70       12 Batch loss: 0.161777 Batch F1: 0.6666666666666667
Train Avg Loss   70: 0.185784

Train Avg F1   70: 0.6906138820807127

Val Avg Loss   70: 0.192357

Val Avg F1   70:  0.675694621850784

Optimal Val loss (Epoch 70): 0.1923569031059742

Epoch 71
--------------------------------------------------------------
Epoch:   71        1 Batch loss: 0.203746 Batch F1: 0.6222222222222223
Epoch:   71        2 Batch loss: 0.183796 Batch F1: 0.631578947368421
Epoch:   71        3 Batch loss: 0.155167 Batch F1: 0.8260869565217391
Epoch:   71        4 Batch loss: 0.174456 Batch F1: 0.7272727272727273
Epoch:   71        5 Batch loss: 0.190380 Batch F1: 0.7450980392156864
Epoch:   71        6 Batch loss: 0.163656 Batch F1: 0.8363636363636364
Epoch:   71        7 Batch loss: 0.148811 Batch F1: 0.8695652173913043
Epoch:   71        8 Batch loss: 0.174354 Batch F1: 0.6285714285714286
Epoch:   71        9 Batch loss: 0.202459 Batch F1: 0.6521739130434783
Epoch:   71       10 Batch loss: 0.202104 Batch F1: 0.6521739130434783
Epoch:   71       11 Batch loss: 0.184451 Batch F1: 0.5945945945945946
Epoch:   71       12 Batch loss: 0.182872 Batch F1: 0.6666666666666666
Train Avg Loss   71: 0.180521

Train Avg F1   71: 0.704364021856282

Val Avg Loss   71: 0.191038

Val Avg F1   71:  0.6746294307196563

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 72
--------------------------------------------------------------
Epoch:   72        1 Batch loss: 0.184731 Batch F1: 0.7346938775510203
Epoch:   72        2 Batch loss: 0.194973 Batch F1: 0.6222222222222223
Epoch:   72        3 Batch loss: 0.179300 Batch F1: 0.6666666666666666
Epoch:   72        4 Batch loss: 0.160591 Batch F1: 0.723404255319149
Epoch:   72        5 Batch loss: 0.167536 Batch F1: 0.65
Epoch:   72        6 Batch loss: 0.191070 Batch F1: 0.6666666666666666
Epoch:   72        7 Batch loss: 0.184450 Batch F1: 0.7142857142857142
Epoch:   72        8 Batch loss: 0.208558 Batch F1: 0.4736842105263158
Epoch:   72        9 Batch loss: 0.197646 Batch F1: 0.6341463414634148
Epoch:   72       10 Batch loss: 0.199686 Batch F1: 0.7241379310344829
Epoch:   72       11 Batch loss: 0.189846 Batch F1: 0.6666666666666667
Epoch:   72       12 Batch loss: 0.158940 Batch F1: 0.7500000000000001
Train Avg Loss   72: 0.184777

Train Avg F1   72: 0.6688812127001933

Val Avg Loss   72: 0.192535

Val Avg F1   72:  0.6957542457542457

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 73
--------------------------------------------------------------
Epoch:   73        1 Batch loss: 0.177910 Batch F1: 0.75
Epoch:   73        2 Batch loss: 0.198222 Batch F1: 0.6285714285714286
Epoch:   73        3 Batch loss: 0.175577 Batch F1: 0.631578947368421
Epoch:   73        4 Batch loss: 0.186400 Batch F1: 0.6190476190476191
Epoch:   73        5 Batch loss: 0.182706 Batch F1: 0.7222222222222223
Epoch:   73        6 Batch loss: 0.249594 Batch F1: 0.4102564102564102
Epoch:   73        7 Batch loss: 0.172109 Batch F1: 0.7567567567567567
Epoch:   73        8 Batch loss: 0.204331 Batch F1: 0.6363636363636364
Epoch:   73        9 Batch loss: 0.205310 Batch F1: 0.7777777777777778
Epoch:   73       10 Batch loss: 0.202328 Batch F1: 0.7659574468085106
Epoch:   73       11 Batch loss: 0.209963 Batch F1: 0.7037037037037037
Epoch:   73       12 Batch loss: 0.187707 Batch F1: 0.6486486486486486
Train Avg Loss   73: 0.196013

Train Avg F1   73: 0.6709070497937613

Val Avg Loss   73: 0.198868

Val Avg F1   73:  0.6896478346410311

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 74
--------------------------------------------------------------
Epoch:   74        1 Batch loss: 0.223331 Batch F1: 0.6190476190476191
Epoch:   74        2 Batch loss: 0.200980 Batch F1: 0.6
Epoch:   74        3 Batch loss: 0.186641 Batch F1: 0.5714285714285715
Epoch:   74        4 Batch loss: 0.193019 Batch F1: 0.45161290322580644
Epoch:   74        5 Batch loss: 0.205892 Batch F1: 0.5777777777777778
Epoch:   74        6 Batch loss: 0.235027 Batch F1: 0.7017543859649124
Epoch:   74        7 Batch loss: 0.213940 Batch F1: 0.5581395348837209
Epoch:   74        8 Batch loss: 0.166185 Batch F1: 0.4800000000000001
Epoch:   74        9 Batch loss: 0.231807 Batch F1: 0.0
Epoch:   74       10 Batch loss: 0.253941 Batch F1: 0.17647058823529416
Epoch:   74       11 Batch loss: 0.186245 Batch F1: 0.6285714285714286
Epoch:   74       12 Batch loss: 0.166981 Batch F1: 0.7659574468085107
Train Avg Loss   74: 0.205333

Train Avg F1   74: 0.5108966879953035

Val Avg Loss   74: 0.205325

Val Avg F1   74:  0.81357353515972

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 75
--------------------------------------------------------------
Epoch:   75        1 Batch loss: 0.172888 Batch F1: 0.8928571428571429
Epoch:   75        2 Batch loss: 0.200583 Batch F1: 0.8
Epoch:   75        3 Batch loss: 0.183497 Batch F1: 0.847457627118644
Epoch:   75        4 Batch loss: 0.202836 Batch F1: 0.5517241379310345
Epoch:   75        5 Batch loss: 0.216636 Batch F1: 0.47368421052631576
Epoch:   75        6 Batch loss: 0.266781 Batch F1: 0.4651162790697674
Epoch:   75        7 Batch loss: 0.209179 Batch F1: 0.5238095238095238
Epoch:   75        8 Batch loss: 0.195066 Batch F1: 0.608695652173913
Epoch:   75        9 Batch loss: 0.172244 Batch F1: 0.6666666666666666
Epoch:   75       10 Batch loss: 0.196866 Batch F1: 0.7272727272727274
Epoch:   75       11 Batch loss: 0.182245 Batch F1: 0.7058823529411765
Epoch:   75       12 Batch loss: 0.182771 Batch F1: 0.6315789473684211
Train Avg Loss   75: 0.198466

Train Avg F1   75: 0.6578954389779444

Val Avg Loss   75: 0.196296

Val Avg F1   75:  0.639575511055486

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 76
--------------------------------------------------------------
Epoch:   76        1 Batch loss: 0.170323 Batch F1: 0.6341463414634148
Epoch:   76        2 Batch loss: 0.205539 Batch F1: 0.5405405405405405
Epoch:   76        3 Batch loss: 0.231945 Batch F1: 0.6545454545454547
Epoch:   76        4 Batch loss: 0.163172 Batch F1: 0.9090909090909091
Epoch:   76        5 Batch loss: 0.203562 Batch F1: 0.6190476190476191
Epoch:   76        6 Batch loss: 0.183188 Batch F1: 0.7058823529411765
Epoch:   76        7 Batch loss: 0.187811 Batch F1: 0.6
Epoch:   76        8 Batch loss: 0.189785 Batch F1: 0.6511627906976744
Epoch:   76        9 Batch loss: 0.158894 Batch F1: 0.7692307692307692
Epoch:   76       10 Batch loss: 0.217911 Batch F1: 0.5
Epoch:   76       11 Batch loss: 0.176129 Batch F1: 0.8333333333333333
Epoch:   76       12 Batch loss: 0.165679 Batch F1: 0.8837209302325582
Train Avg Loss   76: 0.187828

Train Avg F1   76: 0.6917250867602874

Val Avg Loss   76: 0.196379

Val Avg F1   76:  0.6375409958258795

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 77
--------------------------------------------------------------
Epoch:   77        1 Batch loss: 0.186452 Batch F1: 0.6153846153846154
Epoch:   77        2 Batch loss: 0.192992 Batch F1: 0.5405405405405405
Epoch:   77        3 Batch loss: 0.190572 Batch F1: 0.7450980392156863
Epoch:   77        4 Batch loss: 0.191440 Batch F1: 0.7755102040816326
Epoch:   77        5 Batch loss: 0.177162 Batch F1: 0.631578947368421
Epoch:   77        6 Batch loss: 0.196899 Batch F1: 0.5116279069767442
Epoch:   77        7 Batch loss: 0.162970 Batch F1: 0.6285714285714286
Epoch:   77        8 Batch loss: 0.184061 Batch F1: 0.6363636363636364
Epoch:   77        9 Batch loss: 0.178111 Batch F1: 0.5
Epoch:   77       10 Batch loss: 0.214612 Batch F1: 0.5957446808510638
Epoch:   77       11 Batch loss: 0.219366 Batch F1: 0.6792452830188679
Epoch:   77       12 Batch loss: 0.220123 Batch F1: 0.5641025641025642
Train Avg Loss   77: 0.192897

Train Avg F1   77: 0.6186473205396001

Val Avg Loss   77: 0.200305

Val Avg F1   77:  0.6919501133786848

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 78
--------------------------------------------------------------
Epoch:   78        1 Batch loss: 0.198197 Batch F1: 0.7083333333333333
Epoch:   78        2 Batch loss: 0.205951 Batch F1: 0.6923076923076923
Epoch:   78        3 Batch loss: 0.184967 Batch F1: 0.7547169811320756
Epoch:   78        4 Batch loss: 0.192250 Batch F1: 0.6511627906976744
Epoch:   78        5 Batch loss: 0.186055 Batch F1: 0.711111111111111
Epoch:   78        6 Batch loss: 0.219091 Batch F1: 0.5116279069767442
Epoch:   78        7 Batch loss: 0.200197 Batch F1: 0.6363636363636364
Epoch:   78        8 Batch loss: 0.160787 Batch F1: 0.7804878048780488
Epoch:   78        9 Batch loss: 0.166348 Batch F1: 0.7916666666666667
Epoch:   78       10 Batch loss: 0.176253 Batch F1: 0.7222222222222222
Epoch:   78       11 Batch loss: 0.162298 Batch F1: 0.7500000000000001
Epoch:   78       12 Batch loss: 0.213881 Batch F1: 0.6666666666666666
Train Avg Loss   78: 0.188856

Train Avg F1   78: 0.6980555676963226

Val Avg Loss   78: 0.195868

Val Avg F1   78:  0.67425431711146

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 79
--------------------------------------------------------------
Epoch:   79        1 Batch loss: 0.185964 Batch F1: 0.6153846153846153
Epoch:   79        2 Batch loss: 0.158348 Batch F1: 0.8571428571428572
Epoch:   79        3 Batch loss: 0.200076 Batch F1: 0.6666666666666666
Epoch:   79        4 Batch loss: 0.190341 Batch F1: 0.6842105263157895
Epoch:   79        5 Batch loss: 0.186431 Batch F1: 0.723404255319149
Epoch:   79        6 Batch loss: 0.200693 Batch F1: 0.6363636363636364
Epoch:   79        7 Batch loss: 0.175709 Batch F1: 0.6060606060606061
Epoch:   79        8 Batch loss: 0.183883 Batch F1: 0.7500000000000001
Epoch:   79        9 Batch loss: 0.192479 Batch F1: 0.7547169811320754
Epoch:   79       10 Batch loss: 0.172566 Batch F1: 0.7755102040816326
Epoch:   79       11 Batch loss: 0.199188 Batch F1: 0.5714285714285714
Epoch:   79       12 Batch loss: 0.188723 Batch F1: 0.8
Train Avg Loss   79: 0.186200

Train Avg F1   79: 0.7034074099913

Val Avg Loss   79: 0.193530

Val Avg F1   79:  0.6767172704960325

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 80
--------------------------------------------------------------
Epoch:   80        1 Batch loss: 0.211868 Batch F1: 0.6399999999999999
Epoch:   80        2 Batch loss: 0.176344 Batch F1: 0.8363636363636363
Epoch:   80        3 Batch loss: 0.175990 Batch F1: 0.6111111111111112
Epoch:   80        4 Batch loss: 0.167533 Batch F1: 0.7843137254901961
Epoch:   80        5 Batch loss: 0.193873 Batch F1: 0.6808510638297872
Epoch:   80        6 Batch loss: 0.171538 Batch F1: 0.68
Epoch:   80        7 Batch loss: 0.142798 Batch F1: 0.8
Epoch:   80        8 Batch loss: 0.159939 Batch F1: 0.7346938775510203
Epoch:   80        9 Batch loss: 0.210628 Batch F1: 0.47619047619047616
Epoch:   80       10 Batch loss: 0.199140 Batch F1: 0.5333333333333332
Epoch:   80       11 Batch loss: 0.156994 Batch F1: 0.8085106382978724
Epoch:   80       12 Batch loss: 0.230773 Batch F1: 0.4864864864864865
Train Avg Loss   80: 0.183118

Train Avg F1   80: 0.6726545290544932

Val Avg Loss   80: 0.193919

Val Avg F1   80:  0.6723825379208288

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 81
--------------------------------------------------------------
Epoch:   81        1 Batch loss: 0.183194 Batch F1: 0.7547169811320754
Epoch:   81        2 Batch loss: 0.183616 Batch F1: 0.7692307692307692
Epoch:   81        3 Batch loss: 0.158558 Batch F1: 0.7804878048780488
Epoch:   81        4 Batch loss: 0.176701 Batch F1: 0.7391304347826088
Epoch:   81        5 Batch loss: 0.228469 Batch F1: 0.6229508196721312
Epoch:   81        6 Batch loss: 0.185145 Batch F1: 0.7037037037037038
Epoch:   81        7 Batch loss: 0.189607 Batch F1: 0.6046511627906976
Epoch:   81        8 Batch loss: 0.209872 Batch F1: 0.29411764705882354
Epoch:   81        9 Batch loss: 0.180453 Batch F1: 0.6341463414634148
Epoch:   81       10 Batch loss: 0.178250 Batch F1: 0.7499999999999999
Epoch:   81       11 Batch loss: 0.157609 Batch F1: 0.7692307692307692
Epoch:   81       12 Batch loss: 0.167940 Batch F1: 0.7272727272727272
Train Avg Loss   81: 0.183284

Train Avg F1   81: 0.6791365967679809

Val Avg Loss   81: 0.191827

Val Avg F1   81:  0.6552369677369678

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 82
--------------------------------------------------------------
Epoch:   82        1 Batch loss: 0.174955 Batch F1: 0.7
Epoch:   82        2 Batch loss: 0.180348 Batch F1: 0.6315789473684211
Epoch:   82        3 Batch loss: 0.204964 Batch F1: 0.68
Epoch:   82        4 Batch loss: 0.180734 Batch F1: 0.6956521739130435
Epoch:   82        5 Batch loss: 0.190517 Batch F1: 0.6923076923076924
Epoch:   82        6 Batch loss: 0.178477 Batch F1: 0.7547169811320756
Epoch:   82        7 Batch loss: 0.211436 Batch F1: 0.6153846153846154
Epoch:   82        8 Batch loss: 0.159973 Batch F1: 0.7142857142857143
Epoch:   82        9 Batch loss: 0.177794 Batch F1: 0.7843137254901961
Epoch:   82       10 Batch loss: 0.164381 Batch F1: 0.6666666666666667
Epoch:   82       11 Batch loss: 0.162235 Batch F1: 0.7500000000000001
Epoch:   82       12 Batch loss: 0.201102 Batch F1: 0.65
Train Avg Loss   82: 0.182243

Train Avg F1   82: 0.6945755430457021

Val Avg Loss   82: 0.193131

Val Avg F1   82:  0.6760313099598814

Optimal Val loss (Epoch 71): 0.19103754684329033

Epoch 83
--------------------------------------------------------------
Epoch:   83        1 Batch loss: 0.186020 Batch F1: 0.6938775510204083
Epoch:   83        2 Batch loss: 0.196830 Batch F1: 0.6521739130434783
Epoch:   83        3 Batch loss: 0.194234 Batch F1: 0.7272727272727274
Epoch:   83        4 Batch loss: 0.171568 Batch F1: 0.8
Epoch:   83        5 Batch loss: 0.187940 Batch F1: 0.6666666666666666
Epoch:   83        6 Batch loss: 0.208905 Batch F1: 0.6341463414634146
Epoch:   83        7 Batch loss: 0.206896 Batch F1: 0.5106382978723404
Epoch:   83        8 Batch loss: 0.163121 Batch F1: 0.8333333333333333
Epoch:   83        9 Batch loss: 0.197399 Batch F1: 0.7441860465116279
Epoch:   83       10 Batch loss: 0.165719 Batch F1: 0.7222222222222223
Epoch:   83       11 Batch loss: 0.168908 Batch F1: 0.6249999999999999
Epoch:   83       12 Batch loss: 0.174664 Batch F1: 0.7441860465116279
Train Avg Loss   83: 0.185184

Train Avg F1   83: 0.6961419288264873

Val Avg Loss   83: 0.189944

Val Avg F1   83:  0.6743088125381455

Optimal Val loss (Epoch 83): 0.1899438537657261

Epoch 84
--------------------------------------------------------------
Epoch:   84        1 Batch loss: 0.152362 Batch F1: 0.8108108108108109
Epoch:   84        2 Batch loss: 0.172985 Batch F1: 0.7924528301886793
Epoch:   84        3 Batch loss: 0.189674 Batch F1: 0.6511627906976744
Epoch:   84        4 Batch loss: 0.182805 Batch F1: 0.7450980392156863
Epoch:   84        5 Batch loss: 0.177619 Batch F1: 0.7692307692307692
Epoch:   84        6 Batch loss: 0.231694 Batch F1: 0.6382978723404256
Epoch:   84        7 Batch loss: 0.202698 Batch F1: 0.6
Epoch:   84        8 Batch loss: 0.195386 Batch F1: 0.6938775510204083
Epoch:   84        9 Batch loss: 0.179991 Batch F1: 0.6829268292682926
Epoch:   84       10 Batch loss: 0.191440 Batch F1: 0.65
Epoch:   84       11 Batch loss: 0.179185 Batch F1: 0.7058823529411764
Epoch:   84       12 Batch loss: 0.195159 Batch F1: 0.6470588235294118
Train Avg Loss   84: 0.187583

Train Avg F1   84: 0.6988998891036112

Val Avg Loss   84: 0.197803

Val Avg F1   84:  0.6903993304638928

Optimal Val loss (Epoch 83): 0.1899438537657261

Epoch 85
--------------------------------------------------------------
Epoch:   85        1 Batch loss: 0.218363 Batch F1: 0.6
Epoch:   85        2 Batch loss: 0.196862 Batch F1: 0.6500000000000001
Epoch:   85        3 Batch loss: 0.186403 Batch F1: 0.7719298245614034
Epoch:   85        4 Batch loss: 0.211363 Batch F1: 0.6666666666666666
Epoch:   85        5 Batch loss: 0.183669 Batch F1: 0.6666666666666666
Epoch:   85        6 Batch loss: 0.201343 Batch F1: 0.5405405405405405
Epoch:   85        7 Batch loss: 0.201680 Batch F1: 0.5714285714285714
Epoch:   85        8 Batch loss: 0.186242 Batch F1: 0.5217391304347825
Epoch:   85        9 Batch loss: 0.209646 Batch F1: 0.5555555555555556
Epoch:   85       10 Batch loss: 0.189866 Batch F1: 0.6666666666666667
Epoch:   85       11 Batch loss: 0.164292 Batch F1: 0.7777777777777778
Epoch:   85       12 Batch loss: 0.194221 Batch F1: 0.7317073170731706
Train Avg Loss   85: 0.195329

Train Avg F1   85: 0.6433898931143167

Val Avg Loss   85: 0.188635

Val Avg F1   85:  0.7212919789032202

Optimal Val loss (Epoch 85): 0.1886347271502018

Epoch 86
--------------------------------------------------------------
Epoch:   86        1 Batch loss: 0.208785 Batch F1: 0.5909090909090909
Epoch:   86        2 Batch loss: 0.173112 Batch F1: 0.7
Epoch:   86        3 Batch loss: 0.194887 Batch F1: 0.6818181818181818
Epoch:   86        4 Batch loss: 0.172892 Batch F1: 0.8085106382978724
Epoch:   86        5 Batch loss: 0.166257 Batch F1: 0.7843137254901961
Epoch:   86        6 Batch loss: 0.189961 Batch F1: 0.6666666666666666
Epoch:   86        7 Batch loss: 0.192553 Batch F1: 0.6
Epoch:   86        8 Batch loss: 0.199739 Batch F1: 0.7346938775510204
Epoch:   86        9 Batch loss: 0.195713 Batch F1: 0.6363636363636365
Epoch:   86       10 Batch loss: 0.162919 Batch F1: 0.816326530612245
Epoch:   86       11 Batch loss: 0.172858 Batch F1: 0.7500000000000001
Epoch:   86       12 Batch loss: 0.196339 Batch F1: 0.5789473684210527
Train Avg Loss   86: 0.185501

Train Avg F1   86: 0.6957124763441636

Val Avg Loss   86: 0.191216

Val Avg F1   86:  0.6374570264043948

Optimal Val loss (Epoch 85): 0.1886347271502018

Epoch 87
--------------------------------------------------------------
Epoch:   87        1 Batch loss: 0.182164 Batch F1: 0.68
Epoch:   87        2 Batch loss: 0.171192 Batch F1: 0.7555555555555555
Epoch:   87        3 Batch loss: 0.164939 Batch F1: 0.8076923076923077
Epoch:   87        4 Batch loss: 0.194567 Batch F1: 0.5957446808510638
Epoch:   87        5 Batch loss: 0.215398 Batch F1: 0.6153846153846153
Epoch:   87        6 Batch loss: 0.182896 Batch F1: 0.6060606060606061
Epoch:   87        7 Batch loss: 0.174537 Batch F1: 0.7555555555555555
Epoch:   87        8 Batch loss: 0.165872 Batch F1: 0.8163265306122449
Epoch:   87        9 Batch loss: 0.194921 Batch F1: 0.5945945945945946
Epoch:   87       10 Batch loss: 0.174233 Batch F1: 0.7500000000000001
Epoch:   87       11 Batch loss: 0.207922 Batch F1: 0.6086956521739131
Epoch:   87       12 Batch loss: 0.155334 Batch F1: 0.7741935483870968
Train Avg Loss   87: 0.181998

Train Avg F1   87: 0.6966503039056295

Val Avg Loss   87: 0.188628

Val Avg F1   87:  0.6765812708061949

Optimal Val loss (Epoch 87): 0.18862754106521606

Epoch 88
--------------------------------------------------------------
Epoch:   88        1 Batch loss: 0.190276 Batch F1: 0.6666666666666666
Epoch:   88        2 Batch loss: 0.193518 Batch F1: 0.6666666666666666
Epoch:   88        3 Batch loss: 0.180377 Batch F1: 0.7777777777777778
Epoch:   88        4 Batch loss: 0.181035 Batch F1: 0.6818181818181819
Epoch:   88        5 Batch loss: 0.155462 Batch F1: 0.8333333333333333
Epoch:   88        6 Batch loss: 0.203699 Batch F1: 0.5
Epoch:   88        7 Batch loss: 0.185124 Batch F1: 0.7636363636363638
Epoch:   88        8 Batch loss: 0.170318 Batch F1: 0.7317073170731706
Epoch:   88        9 Batch loss: 0.180699 Batch F1: 0.6956521739130435
Epoch:   88       10 Batch loss: 0.179695 Batch F1: 0.6666666666666667
Epoch:   88       11 Batch loss: 0.164237 Batch F1: 0.6857142857142857
Epoch:   88       12 Batch loss: 0.143784 Batch F1: 0.8235294117647058
Train Avg Loss   88: 0.177352

Train Avg F1   88: 0.7077640704192386

Val Avg Loss   88: 0.187814

Val Avg F1   88:  0.6694547382415234

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 89
--------------------------------------------------------------
Epoch:   89        1 Batch loss: 0.205229 Batch F1: 0.7037037037037037
Epoch:   89        2 Batch loss: 0.162779 Batch F1: 0.7441860465116279
Epoch:   89        3 Batch loss: 0.194445 Batch F1: 0.7407407407407407
Epoch:   89        4 Batch loss: 0.161792 Batch F1: 0.7428571428571428
Epoch:   89        5 Batch loss: 0.141305 Batch F1: 0.8205128205128205
Epoch:   89        6 Batch loss: 0.173782 Batch F1: 0.7555555555555555
Epoch:   89        7 Batch loss: 0.176811 Batch F1: 0.7272727272727273
Epoch:   89        8 Batch loss: 0.187331 Batch F1: 0.7083333333333333
Epoch:   89        9 Batch loss: 0.180452 Batch F1: 0.7391304347826085
Epoch:   89       10 Batch loss: 0.215127 Batch F1: 0.6
Epoch:   89       11 Batch loss: 0.185018 Batch F1: 0.6363636363636364
Epoch:   89       12 Batch loss: 0.185970 Batch F1: 0.5714285714285715
Train Avg Loss   89: 0.180837

Train Avg F1   89: 0.7075070594218723

Val Avg Loss   89: 0.192110

Val Avg F1   89:  0.6371129080563043

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 90
--------------------------------------------------------------
Epoch:   90        1 Batch loss: 0.173214 Batch F1: 0.6956521739130435
Epoch:   90        2 Batch loss: 0.192957 Batch F1: 0.5945945945945946
Epoch:   90        3 Batch loss: 0.176578 Batch F1: 0.7500000000000001
Epoch:   90        4 Batch loss: 0.197651 Batch F1: 0.6666666666666667
Epoch:   90        5 Batch loss: 0.176482 Batch F1: 0.7777777777777778
Epoch:   90        6 Batch loss: 0.144395 Batch F1: 0.8799999999999999
Epoch:   90        7 Batch loss: 0.164676 Batch F1: 0.7142857142857143
Epoch:   90        8 Batch loss: 0.206043 Batch F1: 0.6315789473684211
Epoch:   90        9 Batch loss: 0.182376 Batch F1: 0.7111111111111111
Epoch:   90       10 Batch loss: 0.181656 Batch F1: 0.5714285714285714
Epoch:   90       11 Batch loss: 0.184369 Batch F1: 0.6341463414634148
Epoch:   90       12 Batch loss: 0.184317 Batch F1: 0.6470588235294118
Train Avg Loss   90: 0.180393

Train Avg F1   90: 0.6895250601782271

Val Avg Loss   90: 0.189611

Val Avg F1   90:  0.6779891304347826

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 91
--------------------------------------------------------------
Epoch:   91        1 Batch loss: 0.171095 Batch F1: 0.7619047619047619
Epoch:   91        2 Batch loss: 0.211861 Batch F1: 0.6666666666666666
Epoch:   91        3 Batch loss: 0.176392 Batch F1: 0.6315789473684211
Epoch:   91        4 Batch loss: 0.201853 Batch F1: 0.6086956521739131
Epoch:   91        5 Batch loss: 0.143946 Batch F1: 0.761904761904762
Epoch:   91        6 Batch loss: 0.162513 Batch F1: 0.6111111111111112
Epoch:   91        7 Batch loss: 0.175651 Batch F1: 0.7142857142857143
Epoch:   91        8 Batch loss: 0.202578 Batch F1: 0.693877551020408
Epoch:   91        9 Batch loss: 0.176612 Batch F1: 0.6111111111111112
Epoch:   91       10 Batch loss: 0.152465 Batch F1: 0.8333333333333333
Epoch:   91       11 Batch loss: 0.199858 Batch F1: 0.7142857142857142
Epoch:   91       12 Batch loss: 0.192663 Batch F1: 0.7391304347826085
Train Avg Loss   91: 0.180624

Train Avg F1   91: 0.6956571466623771

Val Avg Loss   91: 0.192916

Val Avg F1   91:  0.6760565075086639

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 92
--------------------------------------------------------------
Epoch:   92        1 Batch loss: 0.185415 Batch F1: 0.7843137254901961
Epoch:   92        2 Batch loss: 0.192179 Batch F1: 0.6792452830188679
Epoch:   92        3 Batch loss: 0.208293 Batch F1: 0.6538461538461539
Epoch:   92        4 Batch loss: 0.167947 Batch F1: 0.7272727272727272
Epoch:   92        5 Batch loss: 0.142267 Batch F1: 0.7727272727272727
Epoch:   92        6 Batch loss: 0.163879 Batch F1: 0.717948717948718
Epoch:   92        7 Batch loss: 0.217900 Batch F1: 0.6086956521739131
Epoch:   92        8 Batch loss: 0.195171 Batch F1: 0.6046511627906976
Epoch:   92        9 Batch loss: 0.163064 Batch F1: 0.7222222222222222
Epoch:   92       10 Batch loss: 0.165497 Batch F1: 0.8
Epoch:   92       11 Batch loss: 0.205811 Batch F1: 0.4571428571428572
Epoch:   92       12 Batch loss: 0.195481 Batch F1: 0.6818181818181818
Train Avg Loss   92: 0.183575

Train Avg F1   92: 0.684156996370984

Val Avg Loss   92: 0.194399

Val Avg F1   92:  0.8127421307506053

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 93
--------------------------------------------------------------
Epoch:   93        1 Batch loss: 0.178634 Batch F1: 0.8
Epoch:   93        2 Batch loss: 0.189211 Batch F1: 0.8400000000000001
Epoch:   93        3 Batch loss: 0.171171 Batch F1: 0.6190476190476191
Epoch:   93        4 Batch loss: 0.184578 Batch F1: 0.6666666666666666
Epoch:   93        5 Batch loss: 0.208119 Batch F1: 0.6333333333333334
Epoch:   93        6 Batch loss: 0.161956 Batch F1: 0.8260869565217391
Epoch:   93        7 Batch loss: 0.175619 Batch F1: 0.7
Epoch:   93        8 Batch loss: 0.194086 Batch F1: 0.6341463414634148
Epoch:   93        9 Batch loss: 0.184981 Batch F1: 0.7843137254901961
Epoch:   93       10 Batch loss: 0.195872 Batch F1: 0.6956521739130435
Epoch:   93       11 Batch loss: 0.159034 Batch F1: 0.75
Epoch:   93       12 Batch loss: 0.211695 Batch F1: 0.5555555555555556
Train Avg Loss   93: 0.184580

Train Avg F1   93: 0.7087335309992974

Val Avg Loss   93: 0.188072

Val Avg F1   93:  0.6788003663003663

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 94
--------------------------------------------------------------
Epoch:   94        1 Batch loss: 0.162438 Batch F1: 0.744186046511628
Epoch:   94        2 Batch loss: 0.209736 Batch F1: 0.7536231884057971
Epoch:   94        3 Batch loss: 0.167724 Batch F1: 0.7
Epoch:   94        4 Batch loss: 0.194804 Batch F1: 0.5882352941176471
Epoch:   94        5 Batch loss: 0.163326 Batch F1: 0.7058823529411765
Epoch:   94        6 Batch loss: 0.185425 Batch F1: 0.7272727272727273
Epoch:   94        7 Batch loss: 0.189601 Batch F1: 0.7083333333333334
Epoch:   94        8 Batch loss: 0.183859 Batch F1: 0.7346938775510203
Epoch:   94        9 Batch loss: 0.176091 Batch F1: 0.65
Epoch:   94       10 Batch loss: 0.183177 Batch F1: 0.6363636363636364
Epoch:   94       11 Batch loss: 0.173475 Batch F1: 0.7111111111111111
Epoch:   94       12 Batch loss: 0.185965 Batch F1: 0.6818181818181818
Train Avg Loss   94: 0.181302

Train Avg F1   94: 0.6951266457855216

Val Avg Loss   94: 0.192224

Val Avg F1   94:  0.6260370303112738

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 95
--------------------------------------------------------------
Epoch:   95        1 Batch loss: 0.182592 Batch F1: 0.7307692307692306
Epoch:   95        2 Batch loss: 0.184618 Batch F1: 0.7346938775510204
Epoch:   95        3 Batch loss: 0.139251 Batch F1: 0.7500000000000001
Epoch:   95        4 Batch loss: 0.193822 Batch F1: 0.7719298245614034
Epoch:   95        5 Batch loss: 0.188162 Batch F1: 0.6153846153846154
Epoch:   95        6 Batch loss: 0.168653 Batch F1: 0.7555555555555556
Epoch:   95        7 Batch loss: 0.182846 Batch F1: 0.6341463414634146
Epoch:   95        8 Batch loss: 0.213803 Batch F1: 0.6122448979591836
Epoch:   95        9 Batch loss: 0.182231 Batch F1: 0.6315789473684211
Epoch:   95       10 Batch loss: 0.175308 Batch F1: 0.7111111111111111
Epoch:   95       11 Batch loss: 0.151510 Batch F1: 0.7647058823529412
Epoch:   95       12 Batch loss: 0.170803 Batch F1: 0.782608695652174
Train Avg Loss   95: 0.177800

Train Avg F1   95: 0.7078940816440893

Val Avg Loss   95: 0.188122

Val Avg F1   95:  0.6708474439606515

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 96
--------------------------------------------------------------
Epoch:   96        1 Batch loss: 0.194615 Batch F1: 0.6382978723404256
Epoch:   96        2 Batch loss: 0.186902 Batch F1: 0.631578947368421
Epoch:   96        3 Batch loss: 0.168174 Batch F1: 0.7317073170731707
Epoch:   96        4 Batch loss: 0.194622 Batch F1: 0.5714285714285715
Epoch:   96        5 Batch loss: 0.185213 Batch F1: 0.6666666666666666
Epoch:   96        6 Batch loss: 0.150380 Batch F1: 0.8799999999999999
Epoch:   96        7 Batch loss: 0.162664 Batch F1: 0.717948717948718
Epoch:   96        8 Batch loss: 0.170064 Batch F1: 0.7555555555555556
Epoch:   96        9 Batch loss: 0.201963 Batch F1: 0.5714285714285713
Epoch:   96       10 Batch loss: 0.184120 Batch F1: 0.72
Epoch:   96       11 Batch loss: 0.160947 Batch F1: 0.7999999999999999
Epoch:   96       12 Batch loss: 0.173853 Batch F1: 0.782608695652174
Train Avg Loss   96: 0.177793

Train Avg F1   96: 0.7056017429551895

Val Avg Loss   96: 0.188016

Val Avg F1   96:  0.6717201994068278

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 97
--------------------------------------------------------------
Epoch:   97        1 Batch loss: 0.173897 Batch F1: 0.7317073170731707
Epoch:   97        2 Batch loss: 0.191060 Batch F1: 0.6808510638297872
Epoch:   97        3 Batch loss: 0.186245 Batch F1: 0.5945945945945946
Epoch:   97        4 Batch loss: 0.192551 Batch F1: 0.7037037037037038
Epoch:   97        5 Batch loss: 0.180716 Batch F1: 0.6111111111111112
Epoch:   97        6 Batch loss: 0.173902 Batch F1: 0.7777777777777778
Epoch:   97        7 Batch loss: 0.149121 Batch F1: 0.8
Epoch:   97        8 Batch loss: 0.163943 Batch F1: 0.7755102040816326
Epoch:   97        9 Batch loss: 0.183349 Batch F1: 0.6521739130434783
Epoch:   97       10 Batch loss: 0.170338 Batch F1: 0.76
Epoch:   97       11 Batch loss: 0.164972 Batch F1: 0.7234042553191491
Epoch:   97       12 Batch loss: 0.241804 Batch F1: 0.4210526315789474
Train Avg Loss   97: 0.180992

Train Avg F1   97: 0.6859905476761127

Val Avg Loss   97: 0.190353

Val Avg F1   97:  0.6353240740740741

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 98
--------------------------------------------------------------
Epoch:   98        1 Batch loss: 0.178254 Batch F1: 0.7037037037037037
Epoch:   98        2 Batch loss: 0.179870 Batch F1: 0.711111111111111
Epoch:   98        3 Batch loss: 0.143084 Batch F1: 0.8181818181818182
Epoch:   98        4 Batch loss: 0.156570 Batch F1: 0.7906976744186046
Epoch:   98        5 Batch loss: 0.191086 Batch F1: 0.7307692307692306
Epoch:   98        6 Batch loss: 0.212469 Batch F1: 0.6274509803921569
Epoch:   98        7 Batch loss: 0.197371 Batch F1: 0.6956521739130435
Epoch:   98        8 Batch loss: 0.190810 Batch F1: 0.6382978723404256
Epoch:   98        9 Batch loss: 0.233848 Batch F1: 0.5098039215686274
Epoch:   98       10 Batch loss: 0.165139 Batch F1: 0.6976744186046512
Epoch:   98       11 Batch loss: 0.157043 Batch F1: 0.6857142857142857
Epoch:   98       12 Batch loss: 0.150397 Batch F1: 0.7857142857142857
Train Avg Loss   98: 0.179662

Train Avg F1   98: 0.699564289702662

Val Avg Loss   98: 0.191443

Val Avg F1   98:  0.6719641290039491

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 99
--------------------------------------------------------------
Epoch:   99        1 Batch loss: 0.169727 Batch F1: 0.7142857142857143
Epoch:   99        2 Batch loss: 0.192065 Batch F1: 0.7755102040816326
Epoch:   99        3 Batch loss: 0.194139 Batch F1: 0.72
Epoch:   99        4 Batch loss: 0.180648 Batch F1: 0.723404255319149
Epoch:   99        5 Batch loss: 0.172419 Batch F1: 0.6511627906976744
Epoch:   99        6 Batch loss: 0.171491 Batch F1: 0.711111111111111
Epoch:   99        7 Batch loss: 0.184734 Batch F1: 0.6521739130434783
Epoch:   99        8 Batch loss: 0.182817 Batch F1: 0.6486486486486486
Epoch:   99        9 Batch loss: 0.196799 Batch F1: 0.6666666666666666
Epoch:   99       10 Batch loss: 0.169606 Batch F1: 0.7
Epoch:   99       11 Batch loss: 0.178861 Batch F1: 0.7659574468085107
Epoch:   99       12 Batch loss: 0.198420 Batch F1: 0.5454545454545455
Train Avg Loss   99: 0.182644

Train Avg F1   99: 0.6895312746764276

Val Avg Loss   99: 0.191529

Val Avg F1   99:  0.6726296351731892

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 100
--------------------------------------------------------------
Epoch:  100        1 Batch loss: 0.211363 Batch F1: 0.6086956521739131
Epoch:  100        2 Batch loss: 0.191756 Batch F1: 0.6500000000000001
Epoch:  100        3 Batch loss: 0.191142 Batch F1: 0.7796610169491527
Epoch:  100        4 Batch loss: 0.197174 Batch F1: 0.5777777777777778
Epoch:  100        5 Batch loss: 0.171976 Batch F1: 0.6956521739130435
Epoch:  100        6 Batch loss: 0.150431 Batch F1: 0.8333333333333333
Epoch:  100        7 Batch loss: 0.158373 Batch F1: 0.723404255319149
Epoch:  100        8 Batch loss: 0.180763 Batch F1: 0.6808510638297872
Epoch:  100        9 Batch loss: 0.154079 Batch F1: 0.5925925925925927
Epoch:  100       10 Batch loss: 0.198147 Batch F1: 0.7169811320754718
Epoch:  100       11 Batch loss: 0.196929 Batch F1: 0.7083333333333334
Epoch:  100       12 Batch loss: 0.188802 Batch F1: 0.6111111111111112
Train Avg Loss  100: 0.182578

Train Avg F1  100: 0.6815327868673888

Val Avg Loss  100: 0.188573

Val Avg F1  100:  0.6732184169605948

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 101
--------------------------------------------------------------
Epoch:  101        1 Batch loss: 0.196573 Batch F1: 0.5714285714285715
Epoch:  101        2 Batch loss: 0.157059 Batch F1: 0.8333333333333333
Epoch:  101        3 Batch loss: 0.194427 Batch F1: 0.6285714285714286
Epoch:  101        4 Batch loss: 0.166672 Batch F1: 0.717948717948718
Epoch:  101        5 Batch loss: 0.200567 Batch F1: 0.6382978723404256
Epoch:  101        6 Batch loss: 0.196393 Batch F1: 0.6222222222222222
Epoch:  101        7 Batch loss: 0.155750 Batch F1: 0.8627450980392156
Epoch:  101        8 Batch loss: 0.231982 Batch F1: 0.43902439024390244
Epoch:  101        9 Batch loss: 0.144052 Batch F1: 0.823529411764706
Epoch:  101       10 Batch loss: 0.196621 Batch F1: 0.7037037037037037
Epoch:  101       11 Batch loss: 0.170697 Batch F1: 0.7659574468085107
Epoch:  101       12 Batch loss: 0.160857 Batch F1: 0.7567567567567567
Train Avg Loss  101: 0.180971

Train Avg F1  101: 0.6969599127634578

Val Avg Loss  101: 0.188375

Val Avg F1  101:  0.6682710820177127

Optimal Val loss (Epoch 88): 0.1878141202032566

Epoch 102
--------------------------------------------------------------
Epoch:  102        1 Batch loss: 0.177724 Batch F1: 0.65
Epoch:  102        2 Batch loss: 0.154177 Batch F1: 0.7826086956521738
Epoch:  102        3 Batch loss: 0.172791 Batch F1: 0.7916666666666666
Epoch:  102        4 Batch loss: 0.197881 Batch F1: 0.5405405405405405
Epoch:  102        5 Batch loss: 0.206328 Batch F1: 0.5714285714285715
Epoch:  102        6 Batch loss: 0.167288 Batch F1: 0.7659574468085107
Epoch:  102        7 Batch loss: 0.177401 Batch F1: 0.7755102040816326
Epoch:  102        8 Batch loss: 0.185147 Batch F1: 0.7234042553191489
Epoch:  102        9 Batch loss: 0.173207 Batch F1: 0.6976744186046512
Epoch:  102       10 Batch loss: 0.185943 Batch F1: 0.6382978723404256
Epoch:  102       11 Batch loss: 0.145953 Batch F1: 0.851063829787234
Epoch:  102       12 Batch loss: 0.180101 Batch F1: 0.6470588235294117
Train Avg Loss  102: 0.176995

Train Avg F1  102: 0.7029342770632474

Val Avg Loss  102: 0.187700

Val Avg F1  102:  0.6753122678782189

Optimal Val loss (Epoch 102): 0.18769998103380203

Epoch 103
--------------------------------------------------------------
Epoch:  103        1 Batch loss: 0.165169 Batch F1: 0.7441860465116279
Epoch:  103        2 Batch loss: 0.186753 Batch F1: 0.6938775510204083
Epoch:  103        3 Batch loss: 0.167270 Batch F1: 0.7755102040816326
Epoch:  103        4 Batch loss: 0.164996 Batch F1: 0.7555555555555555
Epoch:  103        5 Batch loss: 0.163009 Batch F1: 0.6428571428571429
Epoch:  103        6 Batch loss: 0.178954 Batch F1: 0.711111111111111
Epoch:  103        7 Batch loss: 0.176907 Batch F1: 0.6818181818181818
Epoch:  103        8 Batch loss: 0.209121 Batch F1: 0.6086956521739131
Epoch:  103        9 Batch loss: 0.147184 Batch F1: 0.7692307692307692
Epoch:  103       10 Batch loss: 0.202573 Batch F1: 0.5909090909090909
Epoch:  103       11 Batch loss: 0.195769 Batch F1: 0.7
Epoch:  103       12 Batch loss: 0.162929 Batch F1: 0.7894736842105263
Train Avg Loss  103: 0.176719

Train Avg F1  103: 0.7052687491233299

Val Avg Loss  103: 0.186395

Val Avg F1  103:  0.6758500208594076

Optimal Val loss (Epoch 103): 0.1863953024148941

Epoch 104
--------------------------------------------------------------
Epoch:  104        1 Batch loss: 0.171383 Batch F1: 0.6829268292682926
Epoch:  104        2 Batch loss: 0.192042 Batch F1: 0.6222222222222222
Epoch:  104        3 Batch loss: 0.166141 Batch F1: 0.7659574468085107
Epoch:  104        4 Batch loss: 0.152216 Batch F1: 0.7804878048780488
Epoch:  104        5 Batch loss: 0.170621 Batch F1: 0.6111111111111113
Epoch:  104        6 Batch loss: 0.186480 Batch F1: 0.6511627906976744
Epoch:  104        7 Batch loss: 0.172201 Batch F1: 0.7659574468085107
Epoch:  104        8 Batch loss: 0.149948 Batch F1: 0.8095238095238095
Epoch:  104        9 Batch loss: 0.192577 Batch F1: 0.7636363636363636
Epoch:  104       10 Batch loss: 0.207902 Batch F1: 0.6086956521739131
Epoch:  104       11 Batch loss: 0.154024 Batch F1: 0.816326530612245
Epoch:  104       12 Batch loss: 0.177174 Batch F1: 0.6250000000000001
Train Avg Loss  104: 0.174392

Train Avg F1  104: 0.7085840006450584

Val Avg Loss  104: 0.185327

Val Avg F1  104:  0.6739180126692766

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 105
--------------------------------------------------------------
Epoch:  105        1 Batch loss: 0.158092 Batch F1: 0.7804878048780488
Epoch:  105        2 Batch loss: 0.182322 Batch F1: 0.6521739130434783
Epoch:  105        3 Batch loss: 0.182184 Batch F1: 0.6153846153846153
Epoch:  105        4 Batch loss: 0.179804 Batch F1: 0.6829268292682926
Epoch:  105        5 Batch loss: 0.163001 Batch F1: 0.76
Epoch:  105        6 Batch loss: 0.143673 Batch F1: 0.851063829787234
Epoch:  105        7 Batch loss: 0.209674 Batch F1: 0.5777777777777778
Epoch:  105        8 Batch loss: 0.187703 Batch F1: 0.7111111111111111
Epoch:  105        9 Batch loss: 0.185133 Batch F1: 0.6808510638297872
Epoch:  105       10 Batch loss: 0.165855 Batch F1: 0.6666666666666667
Epoch:  105       11 Batch loss: 0.167939 Batch F1: 0.7916666666666667
Epoch:  105       12 Batch loss: 0.167745 Batch F1: 0.7500000000000001
Train Avg Loss  105: 0.174427

Train Avg F1  105: 0.7100091898678067

Val Avg Loss  105: 0.185502

Val Avg F1  105:  0.6783496007098492

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 106
--------------------------------------------------------------
Epoch:  106        1 Batch loss: 0.186391 Batch F1: 0.6341463414634146
Epoch:  106        2 Batch loss: 0.166752 Batch F1: 0.7843137254901961
Epoch:  106        3 Batch loss: 0.153681 Batch F1: 0.8461538461538461
Epoch:  106        4 Batch loss: 0.153755 Batch F1: 0.7222222222222222
Epoch:  106        5 Batch loss: 0.164641 Batch F1: 0.7441860465116279
Epoch:  106        6 Batch loss: 0.213293 Batch F1: 0.6222222222222222
Epoch:  106        7 Batch loss: 0.145933 Batch F1: 0.8333333333333334
Epoch:  106        8 Batch loss: 0.183296 Batch F1: 0.6666666666666666
Epoch:  106        9 Batch loss: 0.223735 Batch F1: 0.46511627906976744
Epoch:  106       10 Batch loss: 0.194811 Batch F1: 0.36363636363636365
Epoch:  106       11 Batch loss: 0.183289 Batch F1: 0.6976744186046512
Epoch:  106       12 Batch loss: 0.175199 Batch F1: 0.7317073170731706
Train Avg Loss  106: 0.178731

Train Avg F1  106: 0.6759482318706236

Val Avg Loss  106: 0.191446

Val Avg F1  106:  0.6674954100367196

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 107
--------------------------------------------------------------
Epoch:  107        1 Batch loss: 0.185207 Batch F1: 0.6956521739130435
Epoch:  107        2 Batch loss: 0.201988 Batch F1: 0.6222222222222222
Epoch:  107        3 Batch loss: 0.200599 Batch F1: 0.6382978723404256
Epoch:  107        4 Batch loss: 0.161081 Batch F1: 0.8260869565217391
Epoch:  107        5 Batch loss: 0.178804 Batch F1: 0.7391304347826089
Epoch:  107        6 Batch loss: 0.176665 Batch F1: 0.7058823529411765
Epoch:  107        7 Batch loss: 0.196677 Batch F1: 0.5957446808510638
Epoch:  107        8 Batch loss: 0.202482 Batch F1: 0.5
Epoch:  107        9 Batch loss: 0.158200 Batch F1: 0.7804878048780488
Epoch:  107       10 Batch loss: 0.149021 Batch F1: 0.8181818181818182
Epoch:  107       11 Batch loss: 0.166197 Batch F1: 0.7500000000000001
Epoch:  107       12 Batch loss: 0.192791 Batch F1: 0.6111111111111113
Train Avg Loss  107: 0.180809

Train Avg F1  107: 0.6902331189786048

Val Avg Loss  107: 0.188230

Val Avg F1  107:  0.6780018761726079

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 108
--------------------------------------------------------------
Epoch:  108        1 Batch loss: 0.159393 Batch F1: 0.7567567567567567
Epoch:  108        2 Batch loss: 0.190731 Batch F1: 0.7199999999999999
Epoch:  108        3 Batch loss: 0.209326 Batch F1: 0.5777777777777778
Epoch:  108        4 Batch loss: 0.197013 Batch F1: 0.6909090909090909
Epoch:  108        5 Batch loss: 0.161336 Batch F1: 0.6111111111111112
Epoch:  108        6 Batch loss: 0.220932 Batch F1: 0.41025641025641024
Epoch:  108        7 Batch loss: 0.194117 Batch F1: 0.7777777777777777
Epoch:  108        8 Batch loss: 0.161267 Batch F1: 0.7804878048780488
Epoch:  108        9 Batch loss: 0.196176 Batch F1: 0.7333333333333333
Epoch:  108       10 Batch loss: 0.157378 Batch F1: 0.7368421052631577
Epoch:  108       11 Batch loss: 0.164155 Batch F1: 0.782608695652174
Epoch:  108       12 Batch loss: 0.142559 Batch F1: 0.7586206896551724
Train Avg Loss  108: 0.179532

Train Avg F1  108: 0.6947067961142341

Val Avg Loss  108: 0.186834

Val Avg F1  108:  0.6818157181571816

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 109
--------------------------------------------------------------
Epoch:  109        1 Batch loss: 0.219348 Batch F1: 0.4878048780487805
Epoch:  109        2 Batch loss: 0.190962 Batch F1: 0.6190476190476191
Epoch:  109        3 Batch loss: 0.175513 Batch F1: 0.76
Epoch:  109        4 Batch loss: 0.194856 Batch F1: 0.6363636363636365
Epoch:  109        5 Batch loss: 0.161618 Batch F1: 0.8076923076923077
Epoch:  109        6 Batch loss: 0.185867 Batch F1: 0.6530612244897959
Epoch:  109        7 Batch loss: 0.168381 Batch F1: 0.7924528301886792
Epoch:  109        8 Batch loss: 0.154250 Batch F1: 0.8636363636363635
Epoch:  109        9 Batch loss: 0.155990 Batch F1: 0.6428571428571429
Epoch:  109       10 Batch loss: 0.205422 Batch F1: 0.6666666666666666
Epoch:  109       11 Batch loss: 0.150631 Batch F1: 0.8260869565217391
Epoch:  109       12 Batch loss: 0.188560 Batch F1: 0.6857142857142857
Train Avg Loss  109: 0.179283

Train Avg F1  109: 0.7034486592689181

Val Avg Loss  109: 0.189543

Val Avg F1  109:  0.6405626022913257

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 110
--------------------------------------------------------------
Epoch:  110        1 Batch loss: 0.183590 Batch F1: 0.6666666666666666
Epoch:  110        2 Batch loss: 0.183904 Batch F1: 0.6046511627906976
Epoch:  110        3 Batch loss: 0.186667 Batch F1: 0.7586206896551724
Epoch:  110        4 Batch loss: 0.184518 Batch F1: 0.6521739130434783
Epoch:  110        5 Batch loss: 0.190035 Batch F1: 0.5405405405405405
Epoch:  110        6 Batch loss: 0.174964 Batch F1: 0.7755102040816326
Epoch:  110        7 Batch loss: 0.187049 Batch F1: 0.7000000000000001
Epoch:  110        8 Batch loss: 0.200305 Batch F1: 0.6190476190476191
Epoch:  110        9 Batch loss: 0.163458 Batch F1: 0.7826086956521738
Epoch:  110       10 Batch loss: 0.185030 Batch F1: 0.5882352941176471
Epoch:  110       11 Batch loss: 0.167192 Batch F1: 0.7555555555555555
Epoch:  110       12 Batch loss: 0.164921 Batch F1: 0.8510638297872342
Train Avg Loss  110: 0.180969

Train Avg F1  110: 0.6912228475782013

Val Avg Loss  110: 0.189143

Val Avg F1  110:  0.6745880494297402

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 111
--------------------------------------------------------------
Epoch:  111        1 Batch loss: 0.172232 Batch F1: 0.717948717948718
Epoch:  111        2 Batch loss: 0.189320 Batch F1: 0.631578947368421
Epoch:  111        3 Batch loss: 0.172900 Batch F1: 0.7499999999999999
Epoch:  111        4 Batch loss: 0.204210 Batch F1: 0.6530612244897959
Epoch:  111        5 Batch loss: 0.192347 Batch F1: 0.5714285714285714
Epoch:  111        6 Batch loss: 0.161438 Batch F1: 0.6666666666666666
Epoch:  111        7 Batch loss: 0.148176 Batch F1: 0.6857142857142857
Epoch:  111        8 Batch loss: 0.158629 Batch F1: 0.8214285714285714
Epoch:  111        9 Batch loss: 0.191567 Batch F1: 0.7199999999999999
Epoch:  111       10 Batch loss: 0.167140 Batch F1: 0.7999999999999999
Epoch:  111       11 Batch loss: 0.179219 Batch F1: 0.6976744186046512
Epoch:  111       12 Batch loss: 0.178111 Batch F1: 0.6666666666666667
Train Avg Loss  111: 0.176274

Train Avg F1  111: 0.6985140058596956

Val Avg Loss  111: 0.189274

Val Avg F1  111:  0.6677483117852658

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 112
--------------------------------------------------------------
Epoch:  112        1 Batch loss: 0.180842 Batch F1: 0.6153846153846154
Epoch:  112        2 Batch loss: 0.178042 Batch F1: 0.847457627118644
Epoch:  112        3 Batch loss: 0.169882 Batch F1: 0.7272727272727272
Epoch:  112        4 Batch loss: 0.203565 Batch F1: 0.6
Epoch:  112        5 Batch loss: 0.183029 Batch F1: 0.65
Epoch:  112        6 Batch loss: 0.145833 Batch F1: 0.7272727272727272
Epoch:  112        7 Batch loss: 0.192937 Batch F1: 0.7111111111111111
Epoch:  112        8 Batch loss: 0.184324 Batch F1: 0.6956521739130435
Epoch:  112        9 Batch loss: 0.174216 Batch F1: 0.7916666666666666
Epoch:  112       10 Batch loss: 0.179729 Batch F1: 0.7317073170731706
Epoch:  112       11 Batch loss: 0.170063 Batch F1: 0.7346938775510204
Epoch:  112       12 Batch loss: 0.220395 Batch F1: 0.7234042553191489
Train Avg Loss  112: 0.181905

Train Avg F1  112: 0.7129685915569063

Val Avg Loss  112: 0.191491

Val Avg F1  112:  0.7245911949685535

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 113
--------------------------------------------------------------
Epoch:  113        1 Batch loss: 0.205962 Batch F1: 0.6909090909090909
Epoch:  113        2 Batch loss: 0.127556 Batch F1: 0.8444444444444444
Epoch:  113        3 Batch loss: 0.200849 Batch F1: 0.64
Epoch:  113        4 Batch loss: 0.164315 Batch F1: 0.7083333333333334
Epoch:  113        5 Batch loss: 0.197266 Batch F1: 0.5909090909090909
Epoch:  113        6 Batch loss: 0.178867 Batch F1: 0.7234042553191491
Epoch:  113        7 Batch loss: 0.148310 Batch F1: 0.7647058823529411
Epoch:  113        8 Batch loss: 0.182642 Batch F1: 0.76
Epoch:  113        9 Batch loss: 0.182175 Batch F1: 0.6666666666666666
Epoch:  113       10 Batch loss: 0.192127 Batch F1: 0.6521739130434783
Epoch:  113       11 Batch loss: 0.207786 Batch F1: 0.6363636363636365
Epoch:  113       12 Batch loss: 0.158131 Batch F1: 0.8108108108108109
Train Avg Loss  113: 0.178832

Train Avg F1  113: 0.7073934270127203

Val Avg Loss  113: 0.188189

Val Avg F1  113:  0.6768794326241135

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 114
--------------------------------------------------------------
Epoch:  114        1 Batch loss: 0.178825 Batch F1: 0.7
Epoch:  114        2 Batch loss: 0.164916 Batch F1: 0.7391304347826088
Epoch:  114        3 Batch loss: 0.169628 Batch F1: 0.7547169811320754
Epoch:  114        4 Batch loss: 0.167413 Batch F1: 0.7234042553191491
Epoch:  114        5 Batch loss: 0.188502 Batch F1: 0.6666666666666666
Epoch:  114        6 Batch loss: 0.218234 Batch F1: 0.5454545454545455
Epoch:  114        7 Batch loss: 0.183623 Batch F1: 0.6792452830188679
Epoch:  114        8 Batch loss: 0.159883 Batch F1: 0.7368421052631577
Epoch:  114        9 Batch loss: 0.167438 Batch F1: 0.7222222222222222
Epoch:  114       10 Batch loss: 0.186944 Batch F1: 0.6956521739130435
Epoch:  114       11 Batch loss: 0.213016 Batch F1: 0.6530612244897959
Epoch:  114       12 Batch loss: 0.168035 Batch F1: 0.7222222222222222
Train Avg Loss  114: 0.180538

Train Avg F1  114: 0.6948848428736962

Val Avg Loss  114: 0.189028

Val Avg F1  114:  0.6764880952380952

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 115
--------------------------------------------------------------
Epoch:  115        1 Batch loss: 0.178425 Batch F1: 0.7755102040816326
Epoch:  115        2 Batch loss: 0.150037 Batch F1: 0.8095238095238095
Epoch:  115        3 Batch loss: 0.183784 Batch F1: 0.7450980392156864
Epoch:  115        4 Batch loss: 0.196837 Batch F1: 0.6222222222222222
Epoch:  115        5 Batch loss: 0.177714 Batch F1: 0.6666666666666666
Epoch:  115        6 Batch loss: 0.212969 Batch F1: 0.4210526315789474
Epoch:  115        7 Batch loss: 0.183951 Batch F1: 0.7111111111111111
Epoch:  115        8 Batch loss: 0.189522 Batch F1: 0.8070175438596492
Epoch:  115        9 Batch loss: 0.178614 Batch F1: 0.6060606060606061
Epoch:  115       10 Batch loss: 0.171091 Batch F1: 0.6829268292682926
Epoch:  115       11 Batch loss: 0.168426 Batch F1: 0.6500000000000001
Epoch:  115       12 Batch loss: 0.216903 Batch F1: 0.6956521739130435
Train Avg Loss  115: 0.184023

Train Avg F1  115: 0.6827368197918057

Val Avg Loss  115: 0.191008

Val Avg F1  115:  0.6288902681231381

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 116
--------------------------------------------------------------
Epoch:  116        1 Batch loss: 0.210000 Batch F1: 0.6666666666666666
Epoch:  116        2 Batch loss: 0.170697 Batch F1: 0.6666666666666666
Epoch:  116        3 Batch loss: 0.181738 Batch F1: 0.6341463414634146
Epoch:  116        4 Batch loss: 0.190495 Batch F1: 0.65
Epoch:  116        5 Batch loss: 0.171039 Batch F1: 0.7555555555555555
Epoch:  116        6 Batch loss: 0.196220 Batch F1: 0.5641025641025642
Epoch:  116        7 Batch loss: 0.126626 Batch F1: 0.8648648648648649
Epoch:  116        8 Batch loss: 0.173980 Batch F1: 0.7843137254901961
Epoch:  116        9 Batch loss: 0.178000 Batch F1: 0.7346938775510204
Epoch:  116       10 Batch loss: 0.170324 Batch F1: 0.7843137254901961
Epoch:  116       11 Batch loss: 0.183524 Batch F1: 0.7307692307692307
Epoch:  116       12 Batch loss: 0.218757 Batch F1: 0.5294117647058824
Train Avg Loss  116: 0.180950

Train Avg F1  116: 0.6971254152771883

Val Avg Loss  116: 0.188425

Val Avg F1  116:  0.6817136989931109

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 117
--------------------------------------------------------------
Epoch:  117        1 Batch loss: 0.163861 Batch F1: 0.8163265306122449
Epoch:  117        2 Batch loss: 0.175518 Batch F1: 0.7391304347826088
Epoch:  117        3 Batch loss: 0.158389 Batch F1: 0.7692307692307692
Epoch:  117        4 Batch loss: 0.191951 Batch F1: 0.6818181818181819
Epoch:  117        5 Batch loss: 0.186047 Batch F1: 0.7083333333333333
Epoch:  117        6 Batch loss: 0.180399 Batch F1: 0.6382978723404256
Epoch:  117        7 Batch loss: 0.168990 Batch F1: 0.6956521739130435
Epoch:  117        8 Batch loss: 0.228921 Batch F1: 0.7317073170731707
Epoch:  117        9 Batch loss: 0.170014 Batch F1: 0.7843137254901961
Epoch:  117       10 Batch loss: 0.164821 Batch F1: 0.8085106382978724
Epoch:  117       11 Batch loss: 0.209300 Batch F1: 0.6
Epoch:  117       12 Batch loss: 0.216196 Batch F1: 0.6285714285714287
Train Avg Loss  117: 0.184534

Train Avg F1  117: 0.7168243671219395

Val Avg Loss  117: 0.195546

Val Avg F1  117:  0.6682792324767849

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 118
--------------------------------------------------------------
Epoch:  118        1 Batch loss: 0.199140 Batch F1: 0.7083333333333334
Epoch:  118        2 Batch loss: 0.182933 Batch F1: 0.7391304347826085
Epoch:  118        3 Batch loss: 0.162024 Batch F1: 0.7058823529411764
Epoch:  118        4 Batch loss: 0.190565 Batch F1: 0.6153846153846153
Epoch:  118        5 Batch loss: 0.190009 Batch F1: 0.6956521739130435
Epoch:  118        6 Batch loss: 0.193038 Batch F1: 0.7058823529411765
Epoch:  118        7 Batch loss: 0.163490 Batch F1: 0.7234042553191491
Epoch:  118        8 Batch loss: 0.200136 Batch F1: 0.5777777777777778
Epoch:  118        9 Batch loss: 0.149275 Batch F1: 0.8275862068965517
Epoch:  118       10 Batch loss: 0.168421 Batch F1: 0.6486486486486486
Epoch:  118       11 Batch loss: 0.206271 Batch F1: 0.6153846153846153
Epoch:  118       12 Batch loss: 0.168956 Batch F1: 0.6842105263157895
Train Avg Loss  118: 0.181188

Train Avg F1  118: 0.687273107803207

Val Avg Loss  118: 0.188502

Val Avg F1  118:  0.6586714124449973

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 119
--------------------------------------------------------------
Epoch:  119        1 Batch loss: 0.158951 Batch F1: 0.7441860465116279
Epoch:  119        2 Batch loss: 0.177535 Batch F1: 0.5882352941176471
Epoch:  119        3 Batch loss: 0.187235 Batch F1: 0.5499999999999999
Epoch:  119        4 Batch loss: 0.241514 Batch F1: 0.4444444444444444
Epoch:  119        5 Batch loss: 0.198121 Batch F1: 0.5714285714285714
Epoch:  119        6 Batch loss: 0.197912 Batch F1: 0.5581395348837209
Epoch:  119        7 Batch loss: 0.159209 Batch F1: 0.717948717948718
Epoch:  119        8 Batch loss: 0.183514 Batch F1: 0.7199999999999999
Epoch:  119        9 Batch loss: 0.153049 Batch F1: 0.7999999999999999
Epoch:  119       10 Batch loss: 0.195207 Batch F1: 0.6086956521739131
Epoch:  119       11 Batch loss: 0.171586 Batch F1: 0.7500000000000001
Epoch:  119       12 Batch loss: 0.195883 Batch F1: 0.5882352941176471
Train Avg Loss  119: 0.184976

Train Avg F1  119: 0.6367761296355241

Val Avg Loss  119: 0.192319

Val Avg F1  119:  0.6792126072465526

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 120
--------------------------------------------------------------
Epoch:  120        1 Batch loss: 0.177886 Batch F1: 0.717948717948718
Epoch:  120        2 Batch loss: 0.149447 Batch F1: 0.7647058823529411
Epoch:  120        3 Batch loss: 0.172464 Batch F1: 0.7659574468085107
Epoch:  120        4 Batch loss: 0.186817 Batch F1: 0.6666666666666667
Epoch:  120        5 Batch loss: 0.226126 Batch F1: 0.5957446808510638
Epoch:  120        6 Batch loss: 0.180647 Batch F1: 0.7547169811320754
Epoch:  120        7 Batch loss: 0.204331 Batch F1: 0.47058823529411764
Epoch:  120        8 Batch loss: 0.213558 Batch F1: 0.6792452830188679
Epoch:  120        9 Batch loss: 0.166281 Batch F1: 0.7317073170731706
Epoch:  120       10 Batch loss: 0.165869 Batch F1: 0.8000000000000002
Epoch:  120       11 Batch loss: 0.143594 Batch F1: 0.8627450980392156
Epoch:  120       12 Batch loss: 0.169944 Batch F1: 0.6428571428571429
Train Avg Loss  120: 0.179747

Train Avg F1  120: 0.7044069543368742

Val Avg Loss  120: 0.189644

Val Avg F1  120:  0.6241671272414641

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 121
--------------------------------------------------------------
Epoch:  121        1 Batch loss: 0.192179 Batch F1: 0.7169811320754716
Epoch:  121        2 Batch loss: 0.175297 Batch F1: 0.6190476190476191
Epoch:  121        3 Batch loss: 0.170484 Batch F1: 0.5555555555555556
Epoch:  121        4 Batch loss: 0.173410 Batch F1: 0.7391304347826088
Epoch:  121        5 Batch loss: 0.171142 Batch F1: 0.7
Epoch:  121        6 Batch loss: 0.175271 Batch F1: 0.7924528301886793
Epoch:  121        7 Batch loss: 0.199103 Batch F1: 0.5853658536585366
Epoch:  121        8 Batch loss: 0.175212 Batch F1: 0.7659574468085107
Epoch:  121        9 Batch loss: 0.173213 Batch F1: 0.7555555555555555
Epoch:  121       10 Batch loss: 0.192379 Batch F1: 0.6521739130434783
Epoch:  121       11 Batch loss: 0.174316 Batch F1: 0.8
Epoch:  121       12 Batch loss: 0.186362 Batch F1: 0.6285714285714287
Train Avg Loss  121: 0.179864

Train Avg F1  121: 0.6925659807739536

Val Avg Loss  121: 0.188114

Val Avg F1  121:  0.633255914777654

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 122
--------------------------------------------------------------
Epoch:  122        1 Batch loss: 0.175189 Batch F1: 0.5945945945945945
Epoch:  122        2 Batch loss: 0.206624 Batch F1: 0.5581395348837209
Epoch:  122        3 Batch loss: 0.161042 Batch F1: 0.761904761904762
Epoch:  122        4 Batch loss: 0.202035 Batch F1: 0.375
Epoch:  122        5 Batch loss: 0.172774 Batch F1: 0.7916666666666667
Epoch:  122        6 Batch loss: 0.181182 Batch F1: 0.6341463414634146
Epoch:  122        7 Batch loss: 0.174068 Batch F1: 0.723404255319149
Epoch:  122        8 Batch loss: 0.169601 Batch F1: 0.793103448275862
Epoch:  122        9 Batch loss: 0.188326 Batch F1: 0.6938775510204083
Epoch:  122       10 Batch loss: 0.204252 Batch F1: 0.7017543859649122
Epoch:  122       11 Batch loss: 0.167220 Batch F1: 0.6666666666666667
Epoch:  122       12 Batch loss: 0.169515 Batch F1: 0.717948717948718
Train Avg Loss  122: 0.180986

Train Avg F1  122: 0.6676839103924063

Val Avg Loss  122: 0.193896

Val Avg F1  122:  0.6358180560359737

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 123
--------------------------------------------------------------
Epoch:  123        1 Batch loss: 0.185919 Batch F1: 0.7272727272727272
Epoch:  123        2 Batch loss: 0.193544 Batch F1: 0.6538461538461539
Epoch:  123        3 Batch loss: 0.217785 Batch F1: 0.45
Epoch:  123        4 Batch loss: 0.183797 Batch F1: 0.6666666666666666
Epoch:  123        5 Batch loss: 0.182669 Batch F1: 0.75
Epoch:  123        6 Batch loss: 0.175723 Batch F1: 0.6818181818181818
Epoch:  123        7 Batch loss: 0.171054 Batch F1: 0.7142857142857143
Epoch:  123        8 Batch loss: 0.192247 Batch F1: 0.5581395348837208
Epoch:  123        9 Batch loss: 0.180355 Batch F1: 0.7307692307692308
Epoch:  123       10 Batch loss: 0.181996 Batch F1: 0.6666666666666666
Epoch:  123       11 Batch loss: 0.170452 Batch F1: 0.6842105263157895
Epoch:  123       12 Batch loss: 0.153001 Batch F1: 0.823529411764706
Train Avg Loss  123: 0.182378

Train Avg F1  123: 0.6756004011907965

Val Avg Loss  123: 0.190628

Val Avg F1  123:  0.6786167643128791

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 124
--------------------------------------------------------------
Epoch:  124        1 Batch loss: 0.187217 Batch F1: 0.5555555555555555
Epoch:  124        2 Batch loss: 0.212786 Batch F1: 0.5581395348837209
Epoch:  124        3 Batch loss: 0.186368 Batch F1: 0.7346938775510203
Epoch:  124        4 Batch loss: 0.141388 Batch F1: 0.8695652173913043
Epoch:  124        5 Batch loss: 0.172613 Batch F1: 0.68
Epoch:  124        6 Batch loss: 0.167420 Batch F1: 0.7083333333333334
Epoch:  124        7 Batch loss: 0.192788 Batch F1: 0.6909090909090909
Epoch:  124        8 Batch loss: 0.170629 Batch F1: 0.631578947368421
Epoch:  124        9 Batch loss: 0.191580 Batch F1: 0.6046511627906977
Epoch:  124       10 Batch loss: 0.187674 Batch F1: 0.711111111111111
Epoch:  124       11 Batch loss: 0.164902 Batch F1: 0.8235294117647058
Epoch:  124       12 Batch loss: 0.178670 Batch F1: 0.6857142857142857
Train Avg Loss  124: 0.179503

Train Avg F1  124: 0.6878151273644373

Val Avg Loss  124: 0.187886

Val Avg F1  124:  0.673886235345202

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 125
--------------------------------------------------------------
Epoch:  125        1 Batch loss: 0.161982 Batch F1: 0.7000000000000001
Epoch:  125        2 Batch loss: 0.186955 Batch F1: 0.5714285714285715
Epoch:  125        3 Batch loss: 0.204952 Batch F1: 0.6666666666666666
Epoch:  125        4 Batch loss: 0.170263 Batch F1: 0.7500000000000001
Epoch:  125        5 Batch loss: 0.165282 Batch F1: 0.7727272727272727
Epoch:  125        6 Batch loss: 0.181616 Batch F1: 0.7450980392156863
Epoch:  125        7 Batch loss: 0.182778 Batch F1: 0.6666666666666666
Epoch:  125        8 Batch loss: 0.181815 Batch F1: 0.5333333333333333
Epoch:  125        9 Batch loss: 0.164697 Batch F1: 0.7999999999999999
Epoch:  125       10 Batch loss: 0.177741 Batch F1: 0.6500000000000001
Epoch:  125       11 Batch loss: 0.185792 Batch F1: 0.7636363636363636
Epoch:  125       12 Batch loss: 0.149578 Batch F1: 0.7777777777777778
Train Avg Loss  125: 0.176121

Train Avg F1  125: 0.6997778909543616

Val Avg Loss  125: 0.190044

Val Avg F1  125:  0.632632112195382

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 126
--------------------------------------------------------------
Epoch:  126        1 Batch loss: 0.208978 Batch F1: 0.6153846153846154
Epoch:  126        2 Batch loss: 0.189527 Batch F1: 0.7169811320754718
Epoch:  126        3 Batch loss: 0.160104 Batch F1: 0.7272727272727272
Epoch:  126        4 Batch loss: 0.203869 Batch F1: 0.5599999999999999
Epoch:  126        5 Batch loss: 0.134334 Batch F1: 0.7741935483870969
Epoch:  126        6 Batch loss: 0.176303 Batch F1: 0.76
Epoch:  126        7 Batch loss: 0.178956 Batch F1: 0.6976744186046512
Epoch:  126        8 Batch loss: 0.194486 Batch F1: 0.7272727272727273
Epoch:  126        9 Batch loss: 0.176965 Batch F1: 0.711111111111111
Epoch:  126       10 Batch loss: 0.188613 Batch F1: 0.6818181818181818
Epoch:  126       11 Batch loss: 0.163463 Batch F1: 0.717948717948718
Epoch:  126       12 Batch loss: 0.177987 Batch F1: 0.6666666666666667
Train Avg Loss  126: 0.179465

Train Avg F1  126: 0.6963603205451641

Val Avg Loss  126: 0.185955

Val Avg F1  126:  0.6783182201830891

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 127
--------------------------------------------------------------
Epoch:  127        1 Batch loss: 0.184733 Batch F1: 0.631578947368421
Epoch:  127        2 Batch loss: 0.174968 Batch F1: 0.7272727272727272
Epoch:  127        3 Batch loss: 0.171851 Batch F1: 0.7391304347826088
Epoch:  127        4 Batch loss: 0.194096 Batch F1: 0.48484848484848486
Epoch:  127        5 Batch loss: 0.169796 Batch F1: 0.7999999999999999
Epoch:  127        6 Batch loss: 0.151525 Batch F1: 0.7317073170731707
Epoch:  127        7 Batch loss: 0.150016 Batch F1: 0.8000000000000002
Epoch:  127        8 Batch loss: 0.172521 Batch F1: 0.7272727272727272
Epoch:  127        9 Batch loss: 0.168171 Batch F1: 0.7
Epoch:  127       10 Batch loss: 0.189275 Batch F1: 0.7457627118644068
Epoch:  127       11 Batch loss: 0.210313 Batch F1: 0.5365853658536586
Epoch:  127       12 Batch loss: 0.169912 Batch F1: 0.8181818181818182
Train Avg Loss  127: 0.175598

Train Avg F1  127: 0.703528377876502

Val Avg Loss  127: 0.187694

Val Avg F1  127:  0.6787000439174352

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 128
--------------------------------------------------------------
Epoch:  128        1 Batch loss: 0.155486 Batch F1: 0.8627450980392156
Epoch:  128        2 Batch loss: 0.173285 Batch F1: 0.6666666666666667
Epoch:  128        3 Batch loss: 0.159047 Batch F1: 0.7727272727272727
Epoch:  128        4 Batch loss: 0.204557 Batch F1: 0.5263157894736842
Epoch:  128        5 Batch loss: 0.169044 Batch F1: 0.7317073170731707
Epoch:  128        6 Batch loss: 0.172648 Batch F1: 0.7499999999999999
Epoch:  128        7 Batch loss: 0.156739 Batch F1: 0.7999999999999999
Epoch:  128        8 Batch loss: 0.183414 Batch F1: 0.6808510638297872
Epoch:  128        9 Batch loss: 0.182943 Batch F1: 0.7142857142857143
Epoch:  128       10 Batch loss: 0.199115 Batch F1: 0.6415094339622641
Epoch:  128       11 Batch loss: 0.179603 Batch F1: 0.6486486486486486
Epoch:  128       12 Batch loss: 0.204489 Batch F1: 0.5142857142857143
Train Avg Loss  128: 0.178364

Train Avg F1  128: 0.6924785599160116

Val Avg Loss  128: 0.190090

Val Avg F1  128:  0.6769959656696476

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 129
--------------------------------------------------------------
Epoch:  129        1 Batch loss: 0.187313 Batch F1: 0.6666666666666666
Epoch:  129        2 Batch loss: 0.194607 Batch F1: 0.5909090909090909
Epoch:  129        3 Batch loss: 0.197619 Batch F1: 0.7058823529411765
Epoch:  129        4 Batch loss: 0.195858 Batch F1: 0.6818181818181819
Epoch:  129        5 Batch loss: 0.193121 Batch F1: 0.717948717948718
Epoch:  129        6 Batch loss: 0.164247 Batch F1: 0.8
Epoch:  129        7 Batch loss: 0.154224 Batch F1: 0.6666666666666667
Epoch:  129        8 Batch loss: 0.199614 Batch F1: 0.6938775510204083
Epoch:  129        9 Batch loss: 0.182262 Batch F1: 0.7804878048780488
Epoch:  129       10 Batch loss: 0.216299 Batch F1: 0.68
Epoch:  129       11 Batch loss: 0.196632 Batch F1: 0.6808510638297872
Epoch:  129       12 Batch loss: 0.173714 Batch F1: 0.8205128205128205
Train Avg Loss  129: 0.187959

Train Avg F1  129: 0.7071350764326305

Val Avg Loss  129: 0.204216

Val Avg F1  129:  0.7996535665864066

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 130
--------------------------------------------------------------
Epoch:  130        1 Batch loss: 0.228213 Batch F1: 0.7796610169491525
Epoch:  130        2 Batch loss: 0.174027 Batch F1: 0.7027027027027027
Epoch:  130        3 Batch loss: 0.166758 Batch F1: 0.761904761904762
Epoch:  130        4 Batch loss: 0.168529 Batch F1: 0.7
Epoch:  130        5 Batch loss: 0.181801 Batch F1: 0.5454545454545455
Epoch:  130        6 Batch loss: 0.149407 Batch F1: 0.8518518518518519
Epoch:  130        7 Batch loss: 0.190754 Batch F1: 0.6521739130434783
Epoch:  130        8 Batch loss: 0.183279 Batch F1: 0.7777777777777778
Epoch:  130        9 Batch loss: 0.215986 Batch F1: 0.6382978723404256
Epoch:  130       10 Batch loss: 0.184770 Batch F1: 0.711111111111111
Epoch:  130       11 Batch loss: 0.172954 Batch F1: 0.7111111111111111
Epoch:  130       12 Batch loss: 0.202282 Batch F1: 0.7368421052631577
Train Avg Loss  130: 0.184897

Train Avg F1  130: 0.7140740641258397

Val Avg Loss  130: 0.189343

Val Avg F1  130:  0.765450720438217

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 131
--------------------------------------------------------------
Epoch:  131        1 Batch loss: 0.162558 Batch F1: 0.8461538461538461
Epoch:  131        2 Batch loss: 0.228620 Batch F1: 0.6551724137931033
Epoch:  131        3 Batch loss: 0.171415 Batch F1: 0.6808510638297872
Epoch:  131        4 Batch loss: 0.162647 Batch F1: 0.7659574468085107
Epoch:  131        5 Batch loss: 0.238168 Batch F1: 0.5238095238095238
Epoch:  131        6 Batch loss: 0.188247 Batch F1: 0.6666666666666667
Epoch:  131        7 Batch loss: 0.207847 Batch F1: 0.5333333333333333
Epoch:  131        8 Batch loss: 0.174532 Batch F1: 0.6111111111111112
Epoch:  131        9 Batch loss: 0.185318 Batch F1: 0.6976744186046512
Epoch:  131       10 Batch loss: 0.198816 Batch F1: 0.5777777777777778
Epoch:  131       11 Batch loss: 0.161971 Batch F1: 0.723404255319149
Epoch:  131       12 Batch loss: 0.169319 Batch F1: 0.7391304347826088
Train Avg Loss  131: 0.187455

Train Avg F1  131: 0.6684201909991724

Val Avg Loss  131: 0.192491

Val Avg F1  131:  0.7152777777777778

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 132
--------------------------------------------------------------
Epoch:  132        1 Batch loss: 0.193837 Batch F1: 0.7666666666666666
Epoch:  132        2 Batch loss: 0.187170 Batch F1: 0.6666666666666666
Epoch:  132        3 Batch loss: 0.163397 Batch F1: 0.7727272727272727
Epoch:  132        4 Batch loss: 0.161192 Batch F1: 0.75
Epoch:  132        5 Batch loss: 0.173560 Batch F1: 0.7755102040816326
Epoch:  132        6 Batch loss: 0.211633 Batch F1: 0.5
Epoch:  132        7 Batch loss: 0.156667 Batch F1: 0.7499999999999999
Epoch:  132        8 Batch loss: 0.186105 Batch F1: 0.8076923076923076
Epoch:  132        9 Batch loss: 0.181187 Batch F1: 0.8214285714285715
Epoch:  132       10 Batch loss: 0.172190 Batch F1: 0.8214285714285714
Epoch:  132       11 Batch loss: 0.205529 Batch F1: 0.5128205128205129
Epoch:  132       12 Batch loss: 0.207237 Batch F1: 0.6
Train Avg Loss  132: 0.183309

Train Avg F1  132: 0.7120783977926836

Val Avg Loss  132: 0.196877

Val Avg F1  132:  0.6769556025369978

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 133
--------------------------------------------------------------
Epoch:  133        1 Batch loss: 0.185117 Batch F1: 0.7659574468085107
Epoch:  133        2 Batch loss: 0.181154 Batch F1: 0.8421052631578948
Epoch:  133        3 Batch loss: 0.180175 Batch F1: 0.76
Epoch:  133        4 Batch loss: 0.172056 Batch F1: 0.717948717948718
Epoch:  133        5 Batch loss: 0.178688 Batch F1: 0.711111111111111
Epoch:  133        6 Batch loss: 0.166644 Batch F1: 0.7755102040816326
Epoch:  133        7 Batch loss: 0.212196 Batch F1: 0.5128205128205129
Epoch:  133        8 Batch loss: 0.196076 Batch F1: 0.5853658536585366
Epoch:  133        9 Batch loss: 0.151277 Batch F1: 0.8181818181818182
Epoch:  133       10 Batch loss: 0.196968 Batch F1: 0.48484848484848486
Epoch:  133       11 Batch loss: 0.169994 Batch F1: 0.7142857142857143
Epoch:  133       12 Batch loss: 0.184723 Batch F1: 0.717948717948718
Train Avg Loss  133: 0.181256

Train Avg F1  133: 0.700506987070971

Val Avg Loss  133: 0.188681

Val Avg F1  133:  0.6656320287899233

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 134
--------------------------------------------------------------
Epoch:  134        1 Batch loss: 0.152874 Batch F1: 0.8510638297872339
Epoch:  134        2 Batch loss: 0.184400 Batch F1: 0.6666666666666666
Epoch:  134        3 Batch loss: 0.182797 Batch F1: 0.7083333333333334
Epoch:  134        4 Batch loss: 0.170213 Batch F1: 0.6486486486486486
Epoch:  134        5 Batch loss: 0.191548 Batch F1: 0.6666666666666667
Epoch:  134        6 Batch loss: 0.158083 Batch F1: 0.7916666666666667
Epoch:  134        7 Batch loss: 0.156343 Batch F1: 0.8260869565217391
Epoch:  134        8 Batch loss: 0.205894 Batch F1: 0.6666666666666666
Epoch:  134        9 Batch loss: 0.188986 Batch F1: 0.6341463414634146
Epoch:  134       10 Batch loss: 0.186396 Batch F1: 0.7058823529411765
Epoch:  134       11 Batch loss: 0.173526 Batch F1: 0.7555555555555556
Epoch:  134       12 Batch loss: 0.179185 Batch F1: 0.5
Train Avg Loss  134: 0.177520

Train Avg F1  134: 0.7017819737431474

Val Avg Loss  134: 0.185591

Val Avg F1  134:  0.6720518281308294

Optimal Val loss (Epoch 104): 0.1853272095322609

Epoch 135
--------------------------------------------------------------
Epoch:  135        1 Batch loss: 0.171591 Batch F1: 0.6486486486486486
Epoch:  135        2 Batch loss: 0.207333 Batch F1: 0.6122448979591837
Epoch:  135        3 Batch loss: 0.156966 Batch F1: 0.8399999999999999
Epoch:  135        4 Batch loss: 0.181470 Batch F1: 0.6153846153846153
Epoch:  135        5 Batch loss: 0.179416 Batch F1: 0.7142857142857143
Epoch:  135        6 Batch loss: 0.145562 Batch F1: 0.7804878048780488
Epoch:  135        7 Batch loss: 0.151754 Batch F1: 0.8620689655172413
Epoch:  135        8 Batch loss: 0.221335 Batch F1: 0.5833333333333334
Epoch:  135        9 Batch loss: 0.140053 Batch F1: 0.7777777777777778
Epoch:  135       10 Batch loss: 0.183427 Batch F1: 0.7346938775510203
Epoch:  135       11 Batch loss: 0.177629 Batch F1: 0.6818181818181819
Epoch:  135       12 Batch loss: 0.161611 Batch F1: 0.6451612903225806
Train Avg Loss  135: 0.173179

Train Avg F1  135: 0.7079920922896954

Val Avg Loss  135: 0.185117

Val Avg F1  135:  0.6739975450081834

Optimal Val loss (Epoch 135): 0.18511676043272018

Epoch 136
--------------------------------------------------------------
Epoch:  136        1 Batch loss: 0.181533 Batch F1: 0.7234042553191491
Epoch:  136        2 Batch loss: 0.186760 Batch F1: 0.6341463414634146
Epoch:  136        3 Batch loss: 0.182304 Batch F1: 0.6363636363636364
Epoch:  136        4 Batch loss: 0.162712 Batch F1: 0.7142857142857143
Epoch:  136        5 Batch loss: 0.170094 Batch F1: 0.7391304347826088
Epoch:  136        6 Batch loss: 0.173607 Batch F1: 0.7346938775510204
Epoch:  136        7 Batch loss: 0.173879 Batch F1: 0.6666666666666666
Epoch:  136        8 Batch loss: 0.164371 Batch F1: 0.830188679245283
Epoch:  136        9 Batch loss: 0.162430 Batch F1: 0.7317073170731707
Epoch:  136       10 Batch loss: 0.154856 Batch F1: 0.7027027027027027
Epoch:  136       11 Batch loss: 0.171929 Batch F1: 0.7999999999999999
Epoch:  136       12 Batch loss: 0.196865 Batch F1: 0.5
Train Avg Loss  136: 0.173445

Train Avg F1  136: 0.7011074687877805

Val Avg Loss  136: 0.185284

Val Avg F1  136:  0.6776437847866418

Optimal Val loss (Epoch 135): 0.18511676043272018

Epoch 137
--------------------------------------------------------------
Epoch:  137        1 Batch loss: 0.175767 Batch F1: 0.7083333333333334
Epoch:  137        2 Batch loss: 0.169002 Batch F1: 0.711111111111111
Epoch:  137        3 Batch loss: 0.140254 Batch F1: 0.7647058823529412
Epoch:  137        4 Batch loss: 0.180410 Batch F1: 0.7547169811320756
Epoch:  137        5 Batch loss: 0.202701 Batch F1: 0.6530612244897959
Epoch:  137        6 Batch loss: 0.163251 Batch F1: 0.7659574468085107
Epoch:  137        7 Batch loss: 0.148751 Batch F1: 0.7567567567567567
Epoch:  137        8 Batch loss: 0.179837 Batch F1: 0.6976744186046512
Epoch:  137        9 Batch loss: 0.171336 Batch F1: 0.7272727272727273
Epoch:  137       10 Batch loss: 0.166943 Batch F1: 0.6486486486486486
Epoch:  137       11 Batch loss: 0.190850 Batch F1: 0.7083333333333334
Epoch:  137       12 Batch loss: 0.193123 Batch F1: 0.6666666666666666
Train Avg Loss  137: 0.173519

Train Avg F1  137: 0.7136032108758793

Val Avg Loss  137: 0.184263

Val Avg F1  137:  0.6765847665847666

Optimal Val loss (Epoch 137): 0.18426310643553734

Epoch 138
--------------------------------------------------------------
Epoch:  138        1 Batch loss: 0.188948 Batch F1: 0.6956521739130435
Epoch:  138        2 Batch loss: 0.161518 Batch F1: 0.7916666666666667
Epoch:  138        3 Batch loss: 0.186371 Batch F1: 0.6666666666666666
Epoch:  138        4 Batch loss: 0.164926 Batch F1: 0.7727272727272727
Epoch:  138        5 Batch loss: 0.167445 Batch F1: 0.6285714285714286
Epoch:  138        6 Batch loss: 0.181387 Batch F1: 0.6808510638297872
Epoch:  138        7 Batch loss: 0.157378 Batch F1: 0.8421052631578947
Epoch:  138        8 Batch loss: 0.137980 Batch F1: 0.8372093023255814
Epoch:  138        9 Batch loss: 0.174356 Batch F1: 0.7
Epoch:  138       10 Batch loss: 0.199337 Batch F1: 0.5777777777777777
Epoch:  138       11 Batch loss: 0.210867 Batch F1: 0.5454545454545454
Epoch:  138       12 Batch loss: 0.148932 Batch F1: 0.7741935483870969
Train Avg Loss  138: 0.173287

Train Avg F1  138: 0.7094063091231466

Val Avg Loss  138: 0.184204

Val Avg F1  138:  0.6721626837480497

Optimal Val loss (Epoch 138): 0.18420378863811493

Epoch 139
--------------------------------------------------------------
Epoch:  139        1 Batch loss: 0.166132 Batch F1: 0.6842105263157895
Epoch:  139        2 Batch loss: 0.164024 Batch F1: 0.7272727272727272
Epoch:  139        3 Batch loss: 0.176179 Batch F1: 0.7450980392156863
Epoch:  139        4 Batch loss: 0.185342 Batch F1: 0.68
Epoch:  139        5 Batch loss: 0.183597 Batch F1: 0.6511627906976744
Epoch:  139        6 Batch loss: 0.188607 Batch F1: 0.631578947368421
Epoch:  139        7 Batch loss: 0.144076 Batch F1: 0.8333333333333333
Epoch:  139        8 Batch loss: 0.165980 Batch F1: 0.7916666666666667
Epoch:  139        9 Batch loss: 0.158621 Batch F1: 0.7555555555555556
Epoch:  139       10 Batch loss: 0.181426 Batch F1: 0.6315789473684211
Epoch:  139       11 Batch loss: 0.186826 Batch F1: 0.7083333333333333
Epoch:  139       12 Batch loss: 0.183196 Batch F1: 0.6470588235294118
Train Avg Loss  139: 0.173667

Train Avg F1  139: 0.7072374742214184

Val Avg Loss  139: 0.187103

Val Avg F1  139:  0.6769789014971741

Optimal Val loss (Epoch 138): 0.18420378863811493

Epoch 140
--------------------------------------------------------------
Epoch:  140        1 Batch loss: 0.168707 Batch F1: 0.7916666666666666
Epoch:  140        2 Batch loss: 0.166974 Batch F1: 0.8000000000000002
Epoch:  140        3 Batch loss: 0.158495 Batch F1: 0.823529411764706
Epoch:  140        4 Batch loss: 0.177635 Batch F1: 0.6666666666666666
Epoch:  140        5 Batch loss: 0.238238 Batch F1: 0.5384615384615384
Epoch:  140        6 Batch loss: 0.199786 Batch F1: 0.5909090909090908
Epoch:  140        7 Batch loss: 0.172269 Batch F1: 0.6808510638297872
Epoch:  140        8 Batch loss: 0.153951 Batch F1: 0.7804878048780488
Epoch:  140        9 Batch loss: 0.165896 Batch F1: 0.7499999999999999
Epoch:  140       10 Batch loss: 0.181715 Batch F1: 0.6190476190476191
Epoch:  140       11 Batch loss: 0.176868 Batch F1: 0.7222222222222223
Epoch:  140       12 Batch loss: 0.187329 Batch F1: 0.5333333333333333
Train Avg Loss  140: 0.178989

Train Avg F1  140: 0.6914312848149734

Val Avg Loss  140: 0.184789

Val Avg F1  140:  0.6687302042419132

Optimal Val loss (Epoch 138): 0.18420378863811493

Epoch 141
--------------------------------------------------------------
Epoch:  141        1 Batch loss: 0.191585 Batch F1: 0.7142857142857143
Epoch:  141        2 Batch loss: 0.165753 Batch F1: 0.717948717948718
Epoch:  141        3 Batch loss: 0.201720 Batch F1: 0.6
Epoch:  141        4 Batch loss: 0.146083 Batch F1: 0.7906976744186046
Epoch:  141        5 Batch loss: 0.187105 Batch F1: 0.6666666666666666
Epoch:  141        6 Batch loss: 0.171167 Batch F1: 0.7317073170731708
Epoch:  141        7 Batch loss: 0.206175 Batch F1: 0.5909090909090909
Epoch:  141        8 Batch loss: 0.184115 Batch F1: 0.6808510638297872
Epoch:  141        9 Batch loss: 0.135235 Batch F1: 0.8372093023255814
Epoch:  141       10 Batch loss: 0.219344 Batch F1: 0.608695652173913
Epoch:  141       11 Batch loss: 0.181055 Batch F1: 0.7307692307692308
Epoch:  141       12 Batch loss: 0.128462 Batch F1: 0.8717948717948718
Train Avg Loss  141: 0.176483

Train Avg F1  141: 0.7117946085162791

Val Avg Loss  141: 0.185627

Val Avg F1  141:  0.6762338440692099

Optimal Val loss (Epoch 138): 0.18420378863811493

Epoch 142
--------------------------------------------------------------
Epoch:  142        1 Batch loss: 0.162990 Batch F1: 0.7142857142857143
Epoch:  142        2 Batch loss: 0.176428 Batch F1: 0.7450980392156864
Epoch:  142        3 Batch loss: 0.179897 Batch F1: 0.7307692307692308
Epoch:  142        4 Batch loss: 0.175442 Batch F1: 0.7555555555555556
Epoch:  142        5 Batch loss: 0.187062 Batch F1: 0.6190476190476191
Epoch:  142        6 Batch loss: 0.159015 Batch F1: 0.7368421052631577
Epoch:  142        7 Batch loss: 0.158007 Batch F1: 0.7727272727272727
Epoch:  142        8 Batch loss: 0.166899 Batch F1: 0.7755102040816326
Epoch:  142        9 Batch loss: 0.202255 Batch F1: 0.6363636363636365
Epoch:  142       10 Batch loss: 0.196945 Batch F1: 0.6046511627906977
Epoch:  142       11 Batch loss: 0.184906 Batch F1: 0.65
Epoch:  142       12 Batch loss: 0.142169 Batch F1: 0.8235294117647058
Train Avg Loss  142: 0.174334

Train Avg F1  142: 0.7136983293220758

Val Avg Loss  142: 0.184833

Val Avg F1  142:  0.6746634645521219

Optimal Val loss (Epoch 138): 0.18420378863811493

Epoch 143
--------------------------------------------------------------
Epoch:  143        1 Batch loss: 0.153369 Batch F1: 0.7804878048780488
Epoch:  143        2 Batch loss: 0.168192 Batch F1: 0.7692307692307692
Epoch:  143        3 Batch loss: 0.212838 Batch F1: 0.5714285714285715
Epoch:  143        4 Batch loss: 0.197929 Batch F1: 0.6122448979591837
Epoch:  143        5 Batch loss: 0.191068 Batch F1: 0.7346938775510204
Epoch:  143        6 Batch loss: 0.184690 Batch F1: 0.7083333333333334
Epoch:  143        7 Batch loss: 0.146403 Batch F1: 0.7692307692307692
Epoch:  143        8 Batch loss: 0.165426 Batch F1: 0.7999999999999999
Epoch:  143        9 Batch loss: 0.159702 Batch F1: 0.7
Epoch:  143       10 Batch loss: 0.183040 Batch F1: 0.6111111111111113
Epoch:  143       11 Batch loss: 0.172783 Batch F1: 0.6666666666666666
Epoch:  143       12 Batch loss: 0.187841 Batch F1: 0.6829268292682926
Train Avg Loss  143: 0.176940

Train Avg F1  143: 0.7005295525548139

Val Avg Loss  143: 0.185343

Val Avg F1  143:  0.6729497354497355

Optimal Val loss (Epoch 138): 0.18420378863811493

Epoch 144
--------------------------------------------------------------
Epoch:  144        1 Batch loss: 0.181226 Batch F1: 0.6190476190476191
Epoch:  144        2 Batch loss: 0.148960 Batch F1: 0.8
Epoch:  144        3 Batch loss: 0.210429 Batch F1: 0.7058823529411765
Epoch:  144        4 Batch loss: 0.181634 Batch F1: 0.7636363636363636
Epoch:  144        5 Batch loss: 0.175247 Batch F1: 0.6666666666666667
Epoch:  144        6 Batch loss: 0.177304 Batch F1: 0.7391304347826085
Epoch:  144        7 Batch loss: 0.174094 Batch F1: 0.6976744186046512
Epoch:  144        8 Batch loss: 0.173493 Batch F1: 0.6666666666666667
Epoch:  144        9 Batch loss: 0.171760 Batch F1: 0.7441860465116279
Epoch:  144       10 Batch loss: 0.174115 Batch F1: 0.7391304347826088
Epoch:  144       11 Batch loss: 0.163184 Batch F1: 0.75
Epoch:  144       12 Batch loss: 0.182011 Batch F1: 0.606060606060606
Train Avg Loss  144: 0.176121

Train Avg F1  144: 0.7081734674750496

Val Avg Loss  144: 0.184401

Val Avg F1  144:  0.6804017005119714

Optimal Val loss (Epoch 138): 0.18420378863811493

Epoch 145
--------------------------------------------------------------
Epoch:  145        1 Batch loss: 0.188539 Batch F1: 0.6666666666666666
Epoch:  145        2 Batch loss: 0.166136 Batch F1: 0.75
Epoch:  145        3 Batch loss: 0.199246 Batch F1: 0.6382978723404256
Epoch:  145        4 Batch loss: 0.157688 Batch F1: 0.6666666666666666
Epoch:  145        5 Batch loss: 0.152017 Batch F1: 0.7272727272727272
Epoch:  145        6 Batch loss: 0.201381 Batch F1: 0.6666666666666667
Epoch:  145        7 Batch loss: 0.149479 Batch F1: 0.8333333333333333
Epoch:  145        8 Batch loss: 0.189786 Batch F1: 0.6
Epoch:  145        9 Batch loss: 0.136943 Batch F1: 0.8571428571428572
Epoch:  145       10 Batch loss: 0.178086 Batch F1: 0.7083333333333334
Epoch:  145       11 Batch loss: 0.197884 Batch F1: 0.6530612244897959
Epoch:  145       12 Batch loss: 0.182234 Batch F1: 0.7659574468085107
Train Avg Loss  145: 0.174952

Train Avg F1  145: 0.7111165662267486

Val Avg Loss  145: 0.185190

Val Avg F1  145:  0.6676789852901761

Optimal Val loss (Epoch 138): 0.18420378863811493

Epoch 146
--------------------------------------------------------------
Epoch:  146        1 Batch loss: 0.189098 Batch F1: 0.7407407407407408
Epoch:  146        2 Batch loss: 0.176205 Batch F1: 0.6956521739130435
Epoch:  146        3 Batch loss: 0.160558 Batch F1: 0.6818181818181818
Epoch:  146        4 Batch loss: 0.230255 Batch F1: 0.6818181818181819
Epoch:  146        5 Batch loss: 0.152931 Batch F1: 0.8076923076923077
Epoch:  146        6 Batch loss: 0.178708 Batch F1: 0.7307692307692306
Epoch:  146        7 Batch loss: 0.153526 Batch F1: 0.7692307692307692
Epoch:  146        8 Batch loss: 0.149244 Batch F1: 0.8095238095238095
Epoch:  146        9 Batch loss: 0.152216 Batch F1: 0.7692307692307692
Epoch:  146       10 Batch loss: 0.200447 Batch F1: 0.6363636363636365
Epoch:  146       11 Batch loss: 0.152396 Batch F1: 0.744186046511628
Epoch:  146       12 Batch loss: 0.198269 Batch F1: 0.4444444444444445
Train Avg Loss  146: 0.174488

Train Avg F1  146: 0.7092891910047285

Val Avg Loss  146: 0.183979

Val Avg F1  146:  0.6706613756613757

Optimal Val loss (Epoch 146): 0.1839793585240841

Epoch 147
--------------------------------------------------------------
Epoch:  147        1 Batch loss: 0.169376 Batch F1: 0.7272727272727273
Epoch:  147        2 Batch loss: 0.163494 Batch F1: 0.7272727272727272
Epoch:  147        3 Batch loss: 0.160607 Batch F1: 0.7659574468085107
Epoch:  147        4 Batch loss: 0.162012 Batch F1: 0.7826086956521738
Epoch:  147        5 Batch loss: 0.147195 Batch F1: 0.761904761904762
Epoch:  147        6 Batch loss: 0.202886 Batch F1: 0.619047619047619
Epoch:  147        7 Batch loss: 0.184492 Batch F1: 0.7058823529411765
Epoch:  147        8 Batch loss: 0.157287 Batch F1: 0.8095238095238096
Epoch:  147        9 Batch loss: 0.167327 Batch F1: 0.744186046511628
Epoch:  147       10 Batch loss: 0.164986 Batch F1: 0.7500000000000001
Epoch:  147       11 Batch loss: 0.210983 Batch F1: 0.5957446808510638
Epoch:  147       12 Batch loss: 0.193273 Batch F1: 0.4827586206896552
Train Avg Loss  147: 0.173660

Train Avg F1  147: 0.7060132907063211

Val Avg Loss  147: 0.184919

Val Avg F1  147:  0.6772572665429808

Optimal Val loss (Epoch 146): 0.1839793585240841

Epoch 148
--------------------------------------------------------------
Epoch:  148        1 Batch loss: 0.147120 Batch F1: 0.7058823529411765
Epoch:  148        2 Batch loss: 0.156333 Batch F1: 0.761904761904762
Epoch:  148        3 Batch loss: 0.162420 Batch F1: 0.7555555555555556
Epoch:  148        4 Batch loss: 0.199453 Batch F1: 0.6666666666666666
Epoch:  148        5 Batch loss: 0.172051 Batch F1: 0.6666666666666667
Epoch:  148        6 Batch loss: 0.173344 Batch F1: 0.7111111111111111
Epoch:  148        7 Batch loss: 0.204413 Batch F1: 0.5777777777777778
Epoch:  148        8 Batch loss: 0.158170 Batch F1: 0.7727272727272727
Epoch:  148        9 Batch loss: 0.146682 Batch F1: 0.8085106382978724
Epoch:  148       10 Batch loss: 0.184119 Batch F1: 0.6808510638297872
Epoch:  148       11 Batch loss: 0.166254 Batch F1: 0.782608695652174
Epoch:  148       12 Batch loss: 0.197574 Batch F1: 0.6666666666666666
Train Avg Loss  148: 0.172328

Train Avg F1  148: 0.7130774358164573

Val Avg Loss  148: 0.184258

Val Avg F1  148:  0.6800610976055762

Optimal Val loss (Epoch 146): 0.1839793585240841

Epoch 149
--------------------------------------------------------------
Epoch:  149        1 Batch loss: 0.166385 Batch F1: 0.75
Epoch:  149        2 Batch loss: 0.195905 Batch F1: 0.7058823529411765
Epoch:  149        3 Batch loss: 0.197401 Batch F1: 0.6521739130434783
Epoch:  149        4 Batch loss: 0.128111 Batch F1: 0.8695652173913043
Epoch:  149        5 Batch loss: 0.161477 Batch F1: 0.7317073170731707
Epoch:  149        6 Batch loss: 0.154459 Batch F1: 0.75
Epoch:  149        7 Batch loss: 0.169609 Batch F1: 0.7719298245614035
Epoch:  149        8 Batch loss: 0.197561 Batch F1: 0.55
Epoch:  149        9 Batch loss: 0.198211 Batch F1: 0.5641025641025641
Epoch:  149       10 Batch loss: 0.173733 Batch F1: 0.6976744186046512
Epoch:  149       11 Batch loss: 0.162455 Batch F1: 0.6666666666666667
Epoch:  149       12 Batch loss: 0.157891 Batch F1: 0.7804878048780487
Train Avg Loss  149: 0.171933

Train Avg F1  149: 0.7075158399385387

Val Avg Loss  149: 0.184577

Val Avg F1  149:  0.676992663449261

Optimal Val loss (Epoch 146): 0.1839793585240841

Epoch 150
--------------------------------------------------------------
Epoch:  150        1 Batch loss: 0.177139 Batch F1: 0.7346938775510204
Epoch:  150        2 Batch loss: 0.169247 Batch F1: 0.5625
Epoch:  150        3 Batch loss: 0.193604 Batch F1: 0.68
Epoch:  150        4 Batch loss: 0.164465 Batch F1: 0.6666666666666666
Epoch:  150        5 Batch loss: 0.186699 Batch F1: 0.5789473684210527
Epoch:  150        6 Batch loss: 0.171608 Batch F1: 0.7111111111111111
Epoch:  150        7 Batch loss: 0.187067 Batch F1: 0.6
Epoch:  150        8 Batch loss: 0.144682 Batch F1: 0.8679245283018868
Epoch:  150        9 Batch loss: 0.184982 Batch F1: 0.6046511627906976
Epoch:  150       10 Batch loss: 0.183297 Batch F1: 0.6938775510204083
Epoch:  150       11 Batch loss: 0.141323 Batch F1: 0.896551724137931
Epoch:  150       12 Batch loss: 0.148158 Batch F1: 0.8125
Train Avg Loss  150: 0.171023

Train Avg F1  150: 0.7007853325000646

Val Avg Loss  150: 0.182668

Val Avg F1  150:  0.676026844480662

Optimal Val loss (Epoch 150): 0.18266750499606133

Epoch 151
--------------------------------------------------------------
Epoch:  151        1 Batch loss: 0.176049 Batch F1: 0.6500000000000001
Epoch:  151        2 Batch loss: 0.156159 Batch F1: 0.8076923076923077
Epoch:  151        3 Batch loss: 0.150251 Batch F1: 0.7906976744186046
Epoch:  151        4 Batch loss: 0.183186 Batch F1: 0.7199999999999999
Epoch:  151        5 Batch loss: 0.177189 Batch F1: 0.7307692307692308
Epoch:  151        6 Batch loss: 0.160109 Batch F1: 0.7272727272727272
Epoch:  151        7 Batch loss: 0.172346 Batch F1: 0.7272727272727272
Epoch:  151        8 Batch loss: 0.171978 Batch F1: 0.6976744186046512
Epoch:  151        9 Batch loss: 0.171042 Batch F1: 0.6829268292682926
Epoch:  151       10 Batch loss: 0.155259 Batch F1: 0.7317073170731706
Epoch:  151       11 Batch loss: 0.235422 Batch F1: 0.4000000000000001
Epoch:  151       12 Batch loss: 0.130086 Batch F1: 0.8571428571428571
Train Avg Loss  151: 0.169923

Train Avg F1  151: 0.7102630074595475

Val Avg Loss  151: 0.181612

Val Avg F1  151:  0.6813846214760848

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 152
--------------------------------------------------------------
Epoch:  152        1 Batch loss: 0.206904 Batch F1: 0.64
Epoch:  152        2 Batch loss: 0.196557 Batch F1: 0.6666666666666666
Epoch:  152        3 Batch loss: 0.176281 Batch F1: 0.7450980392156863
Epoch:  152        4 Batch loss: 0.177349 Batch F1: 0.7027027027027027
Epoch:  152        5 Batch loss: 0.198276 Batch F1: 0.6521739130434783
Epoch:  152        6 Batch loss: 0.147934 Batch F1: 0.7368421052631577
Epoch:  152        7 Batch loss: 0.171773 Batch F1: 0.7200000000000001
Epoch:  152        8 Batch loss: 0.136348 Batch F1: 0.8205128205128205
Epoch:  152        9 Batch loss: 0.190526 Batch F1: 0.6511627906976744
Epoch:  152       10 Batch loss: 0.140889 Batch F1: 0.8444444444444444
Epoch:  152       11 Batch loss: 0.154962 Batch F1: 0.7142857142857143
Epoch:  152       12 Batch loss: 0.181669 Batch F1: 0.6666666666666665
Train Avg Loss  152: 0.173289

Train Avg F1  152: 0.7133796552915843

Val Avg Loss  152: 0.185375

Val Avg F1  152:  0.6781330371755904

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 153
--------------------------------------------------------------
Epoch:  153        1 Batch loss: 0.201472 Batch F1: 0.6
Epoch:  153        2 Batch loss: 0.208139 Batch F1: 0.5853658536585366
Epoch:  153        3 Batch loss: 0.143068 Batch F1: 0.7272727272727273
Epoch:  153        4 Batch loss: 0.163712 Batch F1: 0.7555555555555556
Epoch:  153        5 Batch loss: 0.181271 Batch F1: 0.7169811320754716
Epoch:  153        6 Batch loss: 0.161198 Batch F1: 0.7659574468085107
Epoch:  153        7 Batch loss: 0.169352 Batch F1: 0.7659574468085107
Epoch:  153        8 Batch loss: 0.183136 Batch F1: 0.7111111111111111
Epoch:  153        9 Batch loss: 0.175267 Batch F1: 0.7272727272727272
Epoch:  153       10 Batch loss: 0.172510 Batch F1: 0.6500000000000001
Epoch:  153       11 Batch loss: 0.151306 Batch F1: 0.8085106382978724
Epoch:  153       12 Batch loss: 0.192308 Batch F1: 0.6976744186046512
Train Avg Loss  153: 0.175228

Train Avg F1  153: 0.7093049214554729

Val Avg Loss  153: 0.184608

Val Avg F1  153:  0.6742867867867868

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 154
--------------------------------------------------------------
Epoch:  154        1 Batch loss: 0.187912 Batch F1: 0.6818181818181819
Epoch:  154        2 Batch loss: 0.176175 Batch F1: 0.6500000000000001
Epoch:  154        3 Batch loss: 0.135446 Batch F1: 0.8571428571428571
Epoch:  154        4 Batch loss: 0.168028 Batch F1: 0.7999999999999999
Epoch:  154        5 Batch loss: 0.199585 Batch F1: 0.5945945945945946
Epoch:  154        6 Batch loss: 0.202353 Batch F1: 0.6046511627906976
Epoch:  154        7 Batch loss: 0.169188 Batch F1: 0.6842105263157895
Epoch:  154        8 Batch loss: 0.182264 Batch F1: 0.6511627906976744
Epoch:  154        9 Batch loss: 0.179234 Batch F1: 0.6956521739130435
Epoch:  154       10 Batch loss: 0.148365 Batch F1: 0.8163265306122449
Epoch:  154       11 Batch loss: 0.171899 Batch F1: 0.7317073170731708
Epoch:  154       12 Batch loss: 0.177541 Batch F1: 0.7234042553191491
Train Avg Loss  154: 0.174833

Train Avg F1  154: 0.7075558658564503

Val Avg Loss  154: 0.190443

Val Avg F1  154:  0.6391623655902938

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 155
--------------------------------------------------------------
Epoch:  155        1 Batch loss: 0.153133 Batch F1: 0.7391304347826088
Epoch:  155        2 Batch loss: 0.190444 Batch F1: 0.6792452830188679
Epoch:  155        3 Batch loss: 0.182500 Batch F1: 0.6666666666666666
Epoch:  155        4 Batch loss: 0.172477 Batch F1: 0.76
Epoch:  155        5 Batch loss: 0.182470 Batch F1: 0.6666666666666666
Epoch:  155        6 Batch loss: 0.192070 Batch F1: 0.6222222222222222
Epoch:  155        7 Batch loss: 0.183101 Batch F1: 0.782608695652174
Epoch:  155        8 Batch loss: 0.205195 Batch F1: 0.5641025641025642
Epoch:  155        9 Batch loss: 0.178421 Batch F1: 0.7441860465116279
Epoch:  155       10 Batch loss: 0.208550 Batch F1: 0.6956521739130435
Epoch:  155       11 Batch loss: 0.167775 Batch F1: 0.8333333333333333
Epoch:  155       12 Batch loss: 0.158286 Batch F1: 0.7586206896551724
Train Avg Loss  155: 0.181202

Train Avg F1  155: 0.709369564710412

Val Avg Loss  155: 0.187037

Val Avg F1  155:  0.6781642960214389

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 156
--------------------------------------------------------------
Epoch:  156        1 Batch loss: 0.175094 Batch F1: 0.6976744186046512
Epoch:  156        2 Batch loss: 0.175251 Batch F1: 0.7307692307692308
Epoch:  156        3 Batch loss: 0.163624 Batch F1: 0.8235294117647058
Epoch:  156        4 Batch loss: 0.155780 Batch F1: 0.6666666666666667
Epoch:  156        5 Batch loss: 0.185680 Batch F1: 0.7755102040816326
Epoch:  156        6 Batch loss: 0.171223 Batch F1: 0.7659574468085107
Epoch:  156        7 Batch loss: 0.210376 Batch F1: 0.6923076923076923
Epoch:  156        8 Batch loss: 0.181197 Batch F1: 0.7346938775510204
Epoch:  156        9 Batch loss: 0.192203 Batch F1: 0.6315789473684211
Epoch:  156       10 Batch loss: 0.187935 Batch F1: 0.6511627906976744
Epoch:  156       11 Batch loss: 0.187177 Batch F1: 0.5714285714285715
Epoch:  156       12 Batch loss: 0.196630 Batch F1: 0.5882352941176471
Train Avg Loss  156: 0.181847

Train Avg F1  156: 0.6941262126805355

Val Avg Loss  156: 0.193162

Val Avg F1  156:  0.6770154870458822

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 157
--------------------------------------------------------------
Epoch:  157        1 Batch loss: 0.239720 Batch F1: 0.5217391304347826
Epoch:  157        2 Batch loss: 0.153077 Batch F1: 0.7027027027027029
Epoch:  157        3 Batch loss: 0.185698 Batch F1: 0.7346938775510203
Epoch:  157        4 Batch loss: 0.184893 Batch F1: 0.7500000000000001
Epoch:  157        5 Batch loss: 0.192155 Batch F1: 0.6341463414634146
Epoch:  157        6 Batch loss: 0.174478 Batch F1: 0.7555555555555555
Epoch:  157        7 Batch loss: 0.173547 Batch F1: 0.6285714285714287
Epoch:  157        8 Batch loss: 0.151586 Batch F1: 0.8679245283018868
Epoch:  157        9 Batch loss: 0.167020 Batch F1: 0.6666666666666667
Epoch:  157       10 Batch loss: 0.162047 Batch F1: 0.8076923076923077
Epoch:  157       11 Batch loss: 0.146345 Batch F1: 0.8085106382978724
Epoch:  157       12 Batch loss: 0.208158 Batch F1: 0.5555555555555556
Train Avg Loss  157: 0.178227

Train Avg F1  157: 0.7028132277327662

Val Avg Loss  157: 0.186036

Val Avg F1  157:  0.6756960082400105

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 158
--------------------------------------------------------------
Epoch:  158        1 Batch loss: 0.193507 Batch F1: 0.6976744186046512
Epoch:  158        2 Batch loss: 0.196022 Batch F1: 0.5142857142857142
Epoch:  158        3 Batch loss: 0.191596 Batch F1: 0.75
Epoch:  158        4 Batch loss: 0.178578 Batch F1: 0.7142857142857143
Epoch:  158        5 Batch loss: 0.158725 Batch F1: 0.782608695652174
Epoch:  158        6 Batch loss: 0.168207 Batch F1: 0.6666666666666666
Epoch:  158        7 Batch loss: 0.166915 Batch F1: 0.6829268292682926
Epoch:  158        8 Batch loss: 0.202489 Batch F1: 0.7
Epoch:  158        9 Batch loss: 0.163531 Batch F1: 0.693877551020408
Epoch:  158       10 Batch loss: 0.150210 Batch F1: 0.8679245283018867
Epoch:  158       11 Batch loss: 0.210556 Batch F1: 0.679245283018868
Epoch:  158       12 Batch loss: 0.169071 Batch F1: 0.7407407407407407
Train Avg Loss  158: 0.179117

Train Avg F1  158: 0.7075196784870931

Val Avg Loss  158: 0.187868

Val Avg F1  158:  0.6726079322545381

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 159
--------------------------------------------------------------
Epoch:  159        1 Batch loss: 0.150735 Batch F1: 0.8095238095238095
Epoch:  159        2 Batch loss: 0.192500 Batch F1: 0.5789473684210527
Epoch:  159        3 Batch loss: 0.159044 Batch F1: 0.6857142857142857
Epoch:  159        4 Batch loss: 0.185951 Batch F1: 0.8372093023255814
Epoch:  159        5 Batch loss: 0.199693 Batch F1: 0.7317073170731707
Epoch:  159        6 Batch loss: 0.203517 Batch F1: 0.5263157894736841
Epoch:  159        7 Batch loss: 0.160399 Batch F1: 0.8148148148148148
Epoch:  159        8 Batch loss: 0.185040 Batch F1: 0.7450980392156863
Epoch:  159        9 Batch loss: 0.232177 Batch F1: 0.6122448979591837
Epoch:  159       10 Batch loss: 0.156398 Batch F1: 0.7619047619047619
Epoch:  159       11 Batch loss: 0.212584 Batch F1: 0.68
Epoch:  159       12 Batch loss: 0.213296 Batch F1: 0.5294117647058824
Train Avg Loss  159: 0.187611

Train Avg F1  159: 0.6927410125943262

Val Avg Loss  159: 0.187381

Val Avg F1  159:  0.6345283967916072

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 160
--------------------------------------------------------------
Epoch:  160        1 Batch loss: 0.179378 Batch F1: 0.6363636363636365
Epoch:  160        2 Batch loss: 0.193333 Batch F1: 0.7058823529411765
Epoch:  160        3 Batch loss: 0.201965 Batch F1: 0.6122448979591836
Epoch:  160        4 Batch loss: 0.169110 Batch F1: 0.7659574468085107
Epoch:  160        5 Batch loss: 0.170352 Batch F1: 0.761904761904762
Epoch:  160        6 Batch loss: 0.159057 Batch F1: 0.782608695652174
Epoch:  160        7 Batch loss: 0.184109 Batch F1: 0.6976744186046512
Epoch:  160        8 Batch loss: 0.155738 Batch F1: 0.7906976744186046
Epoch:  160        9 Batch loss: 0.188804 Batch F1: 0.6808510638297872
Epoch:  160       10 Batch loss: 0.210407 Batch F1: 0.6046511627906976
Epoch:  160       11 Batch loss: 0.177337 Batch F1: 0.7555555555555556
Epoch:  160       12 Batch loss: 0.198726 Batch F1: 0.711111111111111
Train Avg Loss  160: 0.182360

Train Avg F1  160: 0.7087918981616542

Val Avg Loss  160: 0.196425

Val Avg F1  160:  0.6190263768888212

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 161
--------------------------------------------------------------
Epoch:  161        1 Batch loss: 0.190765 Batch F1: 0.7083333333333334
Epoch:  161        2 Batch loss: 0.181377 Batch F1: 0.6
Epoch:  161        3 Batch loss: 0.164462 Batch F1: 0.6666666666666667
Epoch:  161        4 Batch loss: 0.186609 Batch F1: 0.7755102040816326
Epoch:  161        5 Batch loss: 0.176720 Batch F1: 0.7555555555555555
Epoch:  161        6 Batch loss: 0.159070 Batch F1: 0.7391304347826088
Epoch:  161        7 Batch loss: 0.196575 Batch F1: 0.7547169811320756
Epoch:  161        8 Batch loss: 0.178248 Batch F1: 0.631578947368421
Epoch:  161        9 Batch loss: 0.174983 Batch F1: 0.7755102040816326
Epoch:  161       10 Batch loss: 0.188286 Batch F1: 0.6666666666666666
Epoch:  161       11 Batch loss: 0.176473 Batch F1: 0.6060606060606061
Epoch:  161       12 Batch loss: 0.191298 Batch F1: 0.7317073170731706
Train Avg Loss  161: 0.180406

Train Avg F1  161: 0.7009530764001976

Val Avg Loss  161: 0.191470

Val Avg F1  161:  0.6770631850419083

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 162
--------------------------------------------------------------
Epoch:  162        1 Batch loss: 0.161151 Batch F1: 0.717948717948718
Epoch:  162        2 Batch loss: 0.214712 Batch F1: 0.5833333333333334
Epoch:  162        3 Batch loss: 0.196319 Batch F1: 0.7407407407407408
Epoch:  162        4 Batch loss: 0.192501 Batch F1: 0.6976744186046512
Epoch:  162        5 Batch loss: 0.185077 Batch F1: 0.5333333333333333
Epoch:  162        6 Batch loss: 0.182763 Batch F1: 0.5945945945945946
Epoch:  162        7 Batch loss: 0.184754 Batch F1: 0.6511627906976744
Epoch:  162        8 Batch loss: 0.182959 Batch F1: 0.7636363636363636
Epoch:  162        9 Batch loss: 0.157267 Batch F1: 0.7999999999999999
Epoch:  162       10 Batch loss: 0.163042 Batch F1: 0.7916666666666667
Epoch:  162       11 Batch loss: 0.151294 Batch F1: 0.8085106382978724
Epoch:  162       12 Batch loss: 0.146953 Batch F1: 0.7777777777777777
Train Avg Loss  162: 0.176566

Train Avg F1  162: 0.7050316146359772

Val Avg Loss  162: 0.184906

Val Avg F1  162:  0.6758589012231473

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 163
--------------------------------------------------------------
Epoch:  163        1 Batch loss: 0.188146 Batch F1: 0.3571428571428571
Epoch:  163        2 Batch loss: 0.204565 Batch F1: 0.6666666666666666
Epoch:  163        3 Batch loss: 0.173363 Batch F1: 0.631578947368421
Epoch:  163        4 Batch loss: 0.192001 Batch F1: 0.7169811320754716
Epoch:  163        5 Batch loss: 0.185481 Batch F1: 0.6666666666666666
Epoch:  163        6 Batch loss: 0.150081 Batch F1: 0.8095238095238095
Epoch:  163        7 Batch loss: 0.211854 Batch F1: 0.5
Epoch:  163        8 Batch loss: 0.165295 Batch F1: 0.7272727272727272
Epoch:  163        9 Batch loss: 0.178525 Batch F1: 0.7857142857142856
Epoch:  163       10 Batch loss: 0.179174 Batch F1: 0.6666666666666666
Epoch:  163       11 Batch loss: 0.134350 Batch F1: 0.9333333333333332
Epoch:  163       12 Batch loss: 0.126892 Batch F1: 0.9090909090909091
Train Avg Loss  163: 0.174144

Train Avg F1  163: 0.6975531667934846

Val Avg Loss  163: 0.185797

Val Avg F1  163:  0.6759305350306362

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 164
--------------------------------------------------------------
Epoch:  164        1 Batch loss: 0.171891 Batch F1: 0.76
Epoch:  164        2 Batch loss: 0.175399 Batch F1: 0.65
Epoch:  164        3 Batch loss: 0.155402 Batch F1: 0.830188679245283
Epoch:  164        4 Batch loss: 0.171119 Batch F1: 0.717948717948718
Epoch:  164        5 Batch loss: 0.185585 Batch F1: 0.6341463414634146
Epoch:  164        6 Batch loss: 0.162050 Batch F1: 0.816326530612245
Epoch:  164        7 Batch loss: 0.179257 Batch F1: 0.6511627906976744
Epoch:  164        8 Batch loss: 0.153468 Batch F1: 0.8400000000000001
Epoch:  164        9 Batch loss: 0.183686 Batch F1: 0.6808510638297872
Epoch:  164       10 Batch loss: 0.178397 Batch F1: 0.6153846153846154
Epoch:  164       11 Batch loss: 0.178006 Batch F1: 0.6511627906976745
Epoch:  164       12 Batch loss: 0.183177 Batch F1: 0.5806451612903226
Train Avg Loss  164: 0.173120

Train Avg F1  164: 0.702318057597478

Val Avg Loss  164: 0.183551

Val Avg F1  164:  0.6605673775163159

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 165
--------------------------------------------------------------
Epoch:  165        1 Batch loss: 0.189869 Batch F1: 0.6808510638297872
Epoch:  165        2 Batch loss: 0.173850 Batch F1: 0.6976744186046512
Epoch:  165        3 Batch loss: 0.156999 Batch F1: 0.7804878048780488
Epoch:  165        4 Batch loss: 0.186875 Batch F1: 0.6046511627906976
Epoch:  165        5 Batch loss: 0.166646 Batch F1: 0.6829268292682927
Epoch:  165        6 Batch loss: 0.161658 Batch F1: 0.7
Epoch:  165        7 Batch loss: 0.162306 Batch F1: 0.7727272727272727
Epoch:  165        8 Batch loss: 0.181784 Batch F1: 0.7346938775510203
Epoch:  165        9 Batch loss: 0.150355 Batch F1: 0.7906976744186046
Epoch:  165       10 Batch loss: 0.181878 Batch F1: 0.6
Epoch:  165       11 Batch loss: 0.179788 Batch F1: 0.7547169811320754
Epoch:  165       12 Batch loss: 0.181276 Batch F1: 0.7317073170731708
Train Avg Loss  165: 0.172774

Train Avg F1  165: 0.7109278668561351

Val Avg Loss  165: 0.184412

Val Avg F1  165:  0.6634199054171694

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 166
--------------------------------------------------------------
Epoch:  166        1 Batch loss: 0.183226 Batch F1: 0.7547169811320754
Epoch:  166        2 Batch loss: 0.172410 Batch F1: 0.6111111111111112
Epoch:  166        3 Batch loss: 0.165124 Batch F1: 0.7727272727272727
Epoch:  166        4 Batch loss: 0.158892 Batch F1: 0.7441860465116279
Epoch:  166        5 Batch loss: 0.175336 Batch F1: 0.6666666666666666
Epoch:  166        6 Batch loss: 0.185581 Batch F1: 0.6666666666666667
Epoch:  166        7 Batch loss: 0.166793 Batch F1: 0.7755102040816326
Epoch:  166        8 Batch loss: 0.180845 Batch F1: 0.6666666666666666
Epoch:  166        9 Batch loss: 0.182629 Batch F1: 0.6111111111111113
Epoch:  166       10 Batch loss: 0.161706 Batch F1: 0.7441860465116279
Epoch:  166       11 Batch loss: 0.156750 Batch F1: 0.7659574468085107
Epoch:  166       12 Batch loss: 0.175132 Batch F1: 0.717948717948718
Train Avg Loss  166: 0.172035

Train Avg F1  166: 0.7081212448286406

Val Avg Loss  166: 0.184321

Val Avg F1  166:  0.6785103946441156

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 167
--------------------------------------------------------------
Epoch:  167        1 Batch loss: 0.162768 Batch F1: 0.7755102040816326
Epoch:  167        2 Batch loss: 0.189397 Batch F1: 0.6808510638297872
Epoch:  167        3 Batch loss: 0.160112 Batch F1: 0.717948717948718
Epoch:  167        4 Batch loss: 0.147882 Batch F1: 0.7317073170731707
Epoch:  167        5 Batch loss: 0.178433 Batch F1: 0.723404255319149
Epoch:  167        6 Batch loss: 0.161731 Batch F1: 0.7317073170731707
Epoch:  167        7 Batch loss: 0.173157 Batch F1: 0.7307692307692306
Epoch:  167        8 Batch loss: 0.191240 Batch F1: 0.6190476190476191
Epoch:  167        9 Batch loss: 0.176828 Batch F1: 0.6976744186046512
Epoch:  167       10 Batch loss: 0.175441 Batch F1: 0.6060606060606061
Epoch:  167       11 Batch loss: 0.165947 Batch F1: 0.7843137254901961
Epoch:  167       12 Batch loss: 0.181043 Batch F1: 0.717948717948718
Train Avg Loss  167: 0.171998

Train Avg F1  167: 0.7097452661038876

Val Avg Loss  167: 0.183105

Val Avg F1  167:  0.6764705882352942

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 168
--------------------------------------------------------------
Epoch:  168        1 Batch loss: 0.173358 Batch F1: 0.7391304347826088
Epoch:  168        2 Batch loss: 0.183622 Batch F1: 0.6938775510204083
Epoch:  168        3 Batch loss: 0.209094 Batch F1: 0.5365853658536586
Epoch:  168        4 Batch loss: 0.162583 Batch F1: 0.7000000000000001
Epoch:  168        5 Batch loss: 0.138685 Batch F1: 0.8510638297872342
Epoch:  168        6 Batch loss: 0.156766 Batch F1: 0.717948717948718
Epoch:  168        7 Batch loss: 0.171909 Batch F1: 0.7499999999999999
Epoch:  168        8 Batch loss: 0.209625 Batch F1: 0.5454545454545454
Epoch:  168        9 Batch loss: 0.179936 Batch F1: 0.6818181818181818
Epoch:  168       10 Batch loss: 0.150171 Batch F1: 0.8399999999999999
Epoch:  168       11 Batch loss: 0.163207 Batch F1: 0.7499999999999999
Epoch:  168       12 Batch loss: 0.164891 Batch F1: 0.7222222222222222
Train Avg Loss  168: 0.171987

Train Avg F1  168: 0.7106750707406313

Val Avg Loss  168: 0.183791

Val Avg F1  168:  0.6725272341656222

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 169
--------------------------------------------------------------
Epoch:  169        1 Batch loss: 0.141436 Batch F1: 0.742857142857143
Epoch:  169        2 Batch loss: 0.178488 Batch F1: 0.7719298245614034
Epoch:  169        3 Batch loss: 0.193639 Batch F1: 0.6046511627906977
Epoch:  169        4 Batch loss: 0.185907 Batch F1: 0.7636363636363636
Epoch:  169        5 Batch loss: 0.182699 Batch F1: 0.6808510638297872
Epoch:  169        6 Batch loss: 0.189455 Batch F1: 0.6666666666666666
Epoch:  169        7 Batch loss: 0.179985 Batch F1: 0.7083333333333334
Epoch:  169        8 Batch loss: 0.134216 Batch F1: 0.7142857142857142
Epoch:  169        9 Batch loss: 0.169723 Batch F1: 0.7
Epoch:  169       10 Batch loss: 0.140623 Batch F1: 0.7906976744186046
Epoch:  169       11 Batch loss: 0.194572 Batch F1: 0.693877551020408
Epoch:  169       12 Batch loss: 0.167572 Batch F1: 0.6857142857142857
Train Avg Loss  169: 0.171526

Train Avg F1  169: 0.7102917319262007

Val Avg Loss  169: 0.183395

Val Avg F1  169:  0.6774495066296639

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 170
--------------------------------------------------------------
Epoch:  170        1 Batch loss: 0.168412 Batch F1: 0.6486486486486486
Epoch:  170        2 Batch loss: 0.196489 Batch F1: 0.6521739130434783
Epoch:  170        3 Batch loss: 0.176314 Batch F1: 0.6818181818181818
Epoch:  170        4 Batch loss: 0.174954 Batch F1: 0.711111111111111
Epoch:  170        5 Batch loss: 0.142542 Batch F1: 0.8260869565217391
Epoch:  170        6 Batch loss: 0.169517 Batch F1: 0.6666666666666667
Epoch:  170        7 Batch loss: 0.212884 Batch F1: 0.6415094339622641
Epoch:  170        8 Batch loss: 0.163992 Batch F1: 0.7843137254901961
Epoch:  170        9 Batch loss: 0.170349 Batch F1: 0.7142857142857143
Epoch:  170       10 Batch loss: 0.150182 Batch F1: 0.7317073170731708
Epoch:  170       11 Batch loss: 0.167803 Batch F1: 0.7000000000000001
Epoch:  170       12 Batch loss: 0.155064 Batch F1: 0.7804878048780487
Train Avg Loss  170: 0.170708

Train Avg F1  170: 0.7115674561249351

Val Avg Loss  170: 0.182992

Val Avg F1  170:  0.6729097490787401

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 171
--------------------------------------------------------------
Epoch:  171        1 Batch loss: 0.177409 Batch F1: 0.631578947368421
Epoch:  171        2 Batch loss: 0.180483 Batch F1: 0.7719298245614034
Epoch:  171        3 Batch loss: 0.151185 Batch F1: 0.6857142857142857
Epoch:  171        4 Batch loss: 0.177270 Batch F1: 0.6956521739130435
Epoch:  171        5 Batch loss: 0.207267 Batch F1: 0.64
Epoch:  171        6 Batch loss: 0.195123 Batch F1: 0.68
Epoch:  171        7 Batch loss: 0.120621 Batch F1: 0.8571428571428571
Epoch:  171        8 Batch loss: 0.174790 Batch F1: 0.7391304347826089
Epoch:  171        9 Batch loss: 0.143722 Batch F1: 0.7894736842105263
Epoch:  171       10 Batch loss: 0.162453 Batch F1: 0.7142857142857143
Epoch:  171       11 Batch loss: 0.180711 Batch F1: 0.723404255319149
Epoch:  171       12 Batch loss: 0.184130 Batch F1: 0.606060606060606
Train Avg Loss  171: 0.171264

Train Avg F1  171: 0.7111977319465512

Val Avg Loss  171: 0.182937

Val Avg F1  171:  0.6769750948375393

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 172
--------------------------------------------------------------
Epoch:  172        1 Batch loss: 0.219639 Batch F1: 0.5116279069767442
Epoch:  172        2 Batch loss: 0.159263 Batch F1: 0.76
Epoch:  172        3 Batch loss: 0.138946 Batch F1: 0.742857142857143
Epoch:  172        4 Batch loss: 0.176668 Batch F1: 0.7391304347826088
Epoch:  172        5 Batch loss: 0.190573 Batch F1: 0.619047619047619
Epoch:  172        6 Batch loss: 0.172089 Batch F1: 0.7636363636363636
Epoch:  172        7 Batch loss: 0.153341 Batch F1: 0.782608695652174
Epoch:  172        8 Batch loss: 0.154920 Batch F1: 0.7916666666666667
Epoch:  172        9 Batch loss: 0.138059 Batch F1: 0.8421052631578948
Epoch:  172       10 Batch loss: 0.177319 Batch F1: 0.6666666666666666
Epoch:  172       11 Batch loss: 0.182106 Batch F1: 0.7346938775510204
Epoch:  172       12 Batch loss: 0.204534 Batch F1: 0.5161290322580646
Train Avg Loss  172: 0.172288

Train Avg F1  172: 0.7058474724377471

Val Avg Loss  172: 0.183359

Val Avg F1  172:  0.6777997844140304

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 173
--------------------------------------------------------------
Epoch:  173        1 Batch loss: 0.163771 Batch F1: 0.8070175438596492
Epoch:  173        2 Batch loss: 0.170112 Batch F1: 0.6511627906976745
Epoch:  173        3 Batch loss: 0.171116 Batch F1: 0.6363636363636364
Epoch:  173        4 Batch loss: 0.171588 Batch F1: 0.7441860465116279
Epoch:  173        5 Batch loss: 0.189694 Batch F1: 0.6666666666666666
Epoch:  173        6 Batch loss: 0.151263 Batch F1: 0.8181818181818182
Epoch:  173        7 Batch loss: 0.204865 Batch F1: 0.6415094339622641
Epoch:  173        8 Batch loss: 0.166453 Batch F1: 0.7142857142857143
Epoch:  173        9 Batch loss: 0.165199 Batch F1: 0.6666666666666666
Epoch:  173       10 Batch loss: 0.199300 Batch F1: 0.6511627906976744
Epoch:  173       11 Batch loss: 0.185896 Batch F1: 0.6341463414634146
Epoch:  173       12 Batch loss: 0.194971 Batch F1: 0.711111111111111
Train Avg Loss  173: 0.177852

Train Avg F1  173: 0.6952050467056599

Val Avg Loss  173: 0.186315

Val Avg F1  173:  0.6787777439951354

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 174
--------------------------------------------------------------
Epoch:  174        1 Batch loss: 0.172746 Batch F1: 0.7272727272727273
Epoch:  174        2 Batch loss: 0.166906 Batch F1: 0.6976744186046512
Epoch:  174        3 Batch loss: 0.173418 Batch F1: 0.6829268292682926
Epoch:  174        4 Batch loss: 0.174896 Batch F1: 0.6976744186046512
Epoch:  174        5 Batch loss: 0.180846 Batch F1: 0.6
Epoch:  174        6 Batch loss: 0.160570 Batch F1: 0.8076923076923077
Epoch:  174        7 Batch loss: 0.161372 Batch F1: 0.7272727272727272
Epoch:  174        8 Batch loss: 0.178788 Batch F1: 0.6666666666666667
Epoch:  174        9 Batch loss: 0.148854 Batch F1: 0.7804878048780488
Epoch:  174       10 Batch loss: 0.215002 Batch F1: 0.627450980392157
Epoch:  174       11 Batch loss: 0.180952 Batch F1: 0.7142857142857143
Epoch:  174       12 Batch loss: 0.199400 Batch F1: 0.7916666666666667
Train Avg Loss  174: 0.176146

Train Avg F1  174: 0.7100892718003843

Val Avg Loss  174: 0.188325

Val Avg F1  174:  0.6663898360326932

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 175
--------------------------------------------------------------
Epoch:  175        1 Batch loss: 0.157692 Batch F1: 0.7027027027027027
Epoch:  175        2 Batch loss: 0.205233 Batch F1: 0.6666666666666666
Epoch:  175        3 Batch loss: 0.176977 Batch F1: 0.6521739130434783
Epoch:  175        4 Batch loss: 0.185704 Batch F1: 0.619047619047619
Epoch:  175        5 Batch loss: 0.165723 Batch F1: 0.7547169811320754
Epoch:  175        6 Batch loss: 0.206782 Batch F1: 0.6000000000000001
Epoch:  175        7 Batch loss: 0.185265 Batch F1: 0.6086956521739131
Epoch:  175        8 Batch loss: 0.159647 Batch F1: 0.7142857142857143
Epoch:  175        9 Batch loss: 0.166579 Batch F1: 0.7843137254901961
Epoch:  175       10 Batch loss: 0.133193 Batch F1: 0.7777777777777778
Epoch:  175       11 Batch loss: 0.193265 Batch F1: 0.6808510638297872
Epoch:  175       12 Batch loss: 0.210023 Batch F1: 0.6666666666666667
Train Avg Loss  175: 0.178840

Train Avg F1  175: 0.6856582069013831

Val Avg Loss  175: 0.182279

Val Avg F1  175:  0.6730213053118674

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 176
--------------------------------------------------------------
Epoch:  176        1 Batch loss: 0.199079 Batch F1: 0.5945945945945946
Epoch:  176        2 Batch loss: 0.168323 Batch F1: 0.7555555555555556
Epoch:  176        3 Batch loss: 0.178891 Batch F1: 0.6956521739130435
Epoch:  176        4 Batch loss: 0.155977 Batch F1: 0.782608695652174
Epoch:  176        5 Batch loss: 0.179674 Batch F1: 0.7272727272727272
Epoch:  176        6 Batch loss: 0.161352 Batch F1: 0.7441860465116279
Epoch:  176        7 Batch loss: 0.181441 Batch F1: 0.7200000000000001
Epoch:  176        8 Batch loss: 0.194989 Batch F1: 0.6666666666666666
Epoch:  176        9 Batch loss: 0.170606 Batch F1: 0.606060606060606
Epoch:  176       10 Batch loss: 0.158492 Batch F1: 0.7659574468085107
Epoch:  176       11 Batch loss: 0.168150 Batch F1: 0.7843137254901961
Epoch:  176       12 Batch loss: 0.190936 Batch F1: 0.6285714285714287
Train Avg Loss  176: 0.175659

Train Avg F1  176: 0.7059533055914274

Val Avg Loss  176: 0.183170

Val Avg F1  176:  0.6724861983561335

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 177
--------------------------------------------------------------
Epoch:  177        1 Batch loss: 0.166252 Batch F1: 0.782608695652174
Epoch:  177        2 Batch loss: 0.163474 Batch F1: 0.75
Epoch:  177        3 Batch loss: 0.184101 Batch F1: 0.6222222222222222
Epoch:  177        4 Batch loss: 0.168847 Batch F1: 0.7058823529411765
Epoch:  177        5 Batch loss: 0.169041 Batch F1: 0.7391304347826088
Epoch:  177        6 Batch loss: 0.177463 Batch F1: 0.6829268292682926
Epoch:  177        7 Batch loss: 0.165998 Batch F1: 0.7142857142857143
Epoch:  177        8 Batch loss: 0.146094 Batch F1: 0.8333333333333334
Epoch:  177        9 Batch loss: 0.173679 Batch F1: 0.6829268292682926
Epoch:  177       10 Batch loss: 0.196366 Batch F1: 0.5263157894736842
Epoch:  177       11 Batch loss: 0.191856 Batch F1: 0.7586206896551724
Epoch:  177       12 Batch loss: 0.185987 Batch F1: 0.7027027027027027
Train Avg Loss  177: 0.174097

Train Avg F1  177: 0.7084129661321145

Val Avg Loss  177: 0.186301

Val Avg F1  177:  0.6772602706546299

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 178
--------------------------------------------------------------
Epoch:  178        1 Batch loss: 0.176642 Batch F1: 0.6486486486486486
Epoch:  178        2 Batch loss: 0.169143 Batch F1: 0.6666666666666666
Epoch:  178        3 Batch loss: 0.162591 Batch F1: 0.8085106382978724
Epoch:  178        4 Batch loss: 0.189167 Batch F1: 0.6521739130434783
Epoch:  178        5 Batch loss: 0.185725 Batch F1: 0.7450980392156864
Epoch:  178        6 Batch loss: 0.200541 Batch F1: 0.5
Epoch:  178        7 Batch loss: 0.178133 Batch F1: 0.7391304347826085
Epoch:  178        8 Batch loss: 0.202780 Batch F1: 0.6792452830188679
Epoch:  178        9 Batch loss: 0.176119 Batch F1: 0.7346938775510204
Epoch:  178       10 Batch loss: 0.163687 Batch F1: 0.7000000000000001
Epoch:  178       11 Batch loss: 0.140822 Batch F1: 0.8108108108108107
Epoch:  178       12 Batch loss: 0.149877 Batch F1: 0.8292682926829269
Train Avg Loss  178: 0.174602

Train Avg F1  178: 0.7095205503932155

Val Avg Loss  178: 0.185112

Val Avg F1  178:  0.677613320999075

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 179
--------------------------------------------------------------
Epoch:  179        1 Batch loss: 0.175990 Batch F1: 0.6818181818181818
Epoch:  179        2 Batch loss: 0.149760 Batch F1: 0.7999999999999999
Epoch:  179        3 Batch loss: 0.166164 Batch F1: 0.6511627906976744
Epoch:  179        4 Batch loss: 0.205023 Batch F1: 0.6785714285714285
Epoch:  179        5 Batch loss: 0.173409 Batch F1: 0.6666666666666666
Epoch:  179        6 Batch loss: 0.157865 Batch F1: 0.6666666666666667
Epoch:  179        7 Batch loss: 0.186072 Batch F1: 0.6818181818181818
Epoch:  179        8 Batch loss: 0.169288 Batch F1: 0.7
Epoch:  179        9 Batch loss: 0.169023 Batch F1: 0.7692307692307693
Epoch:  179       10 Batch loss: 0.178484 Batch F1: 0.7450980392156864
Epoch:  179       11 Batch loss: 0.162560 Batch F1: 0.717948717948718
Epoch:  179       12 Batch loss: 0.188372 Batch F1: 0.6829268292682926
Train Avg Loss  179: 0.173501

Train Avg F1  179: 0.7034923559918554

Val Avg Loss  179: 0.184147

Val Avg F1  179:  0.6763689272400073

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 180
--------------------------------------------------------------
Epoch:  180        1 Batch loss: 0.185264 Batch F1: 0.6808510638297872
Epoch:  180        2 Batch loss: 0.165997 Batch F1: 0.8148148148148148
Epoch:  180        3 Batch loss: 0.156454 Batch F1: 0.7727272727272727
Epoch:  180        4 Batch loss: 0.169432 Batch F1: 0.5625
Epoch:  180        5 Batch loss: 0.149129 Batch F1: 0.8461538461538461
Epoch:  180        6 Batch loss: 0.172110 Batch F1: 0.7272727272727272
Epoch:  180        7 Batch loss: 0.184448 Batch F1: 0.65
Epoch:  180        8 Batch loss: 0.150196 Batch F1: 0.7999999999999999
Epoch:  180        9 Batch loss: 0.164706 Batch F1: 0.6486486486486486
Epoch:  180       10 Batch loss: 0.153994 Batch F1: 0.782608695652174
Epoch:  180       11 Batch loss: 0.217661 Batch F1: 0.5333333333333332
Epoch:  180       12 Batch loss: 0.192413 Batch F1: 0.6153846153846154
Train Avg Loss  180: 0.171817

Train Avg F1  180: 0.7028579181514348

Val Avg Loss  180: 0.182856

Val Avg F1  180:  0.6805053072472926

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 181
--------------------------------------------------------------
Epoch:  181        1 Batch loss: 0.166334 Batch F1: 0.7391304347826088
Epoch:  181        2 Batch loss: 0.172501 Batch F1: 0.6666666666666667
Epoch:  181        3 Batch loss: 0.174843 Batch F1: 0.6976744186046512
Epoch:  181        4 Batch loss: 0.149179 Batch F1: 0.8085106382978724
Epoch:  181        5 Batch loss: 0.163567 Batch F1: 0.7391304347826085
Epoch:  181        6 Batch loss: 0.178223 Batch F1: 0.6976744186046512
Epoch:  181        7 Batch loss: 0.181731 Batch F1: 0.6956521739130435
Epoch:  181        8 Batch loss: 0.152208 Batch F1: 0.7906976744186046
Epoch:  181        9 Batch loss: 0.148959 Batch F1: 0.782608695652174
Epoch:  181       10 Batch loss: 0.184869 Batch F1: 0.6046511627906976
Epoch:  181       11 Batch loss: 0.184565 Batch F1: 0.6666666666666666
Epoch:  181       12 Batch loss: 0.190167 Batch F1: 0.631578947368421
Train Avg Loss  181: 0.170596

Train Avg F1  181: 0.7100535277123888

Val Avg Loss  181: 0.182307

Val Avg F1  181:  0.6723063973063973

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 182
--------------------------------------------------------------
Epoch:  182        1 Batch loss: 0.153119 Batch F1: 0.7727272727272727
Epoch:  182        2 Batch loss: 0.150071 Batch F1: 0.8
Epoch:  182        3 Batch loss: 0.164994 Batch F1: 0.6486486486486486
Epoch:  182        4 Batch loss: 0.170468 Batch F1: 0.6666666666666667
Epoch:  182        5 Batch loss: 0.190725 Batch F1: 0.7058823529411765
Epoch:  182        6 Batch loss: 0.191416 Batch F1: 0.6666666666666667
Epoch:  182        7 Batch loss: 0.229348 Batch F1: 0.6037735849056604
Epoch:  182        8 Batch loss: 0.153751 Batch F1: 0.823529411764706
Epoch:  182        9 Batch loss: 0.170019 Batch F1: 0.7391304347826088
Epoch:  182       10 Batch loss: 0.152470 Batch F1: 0.717948717948718
Epoch:  182       11 Batch loss: 0.172382 Batch F1: 0.6486486486486486
Epoch:  182       12 Batch loss: 0.147506 Batch F1: 0.7741935483870969
Train Avg Loss  182: 0.170523

Train Avg F1  182: 0.7139846628406558

Val Avg Loss  182: 0.186341

Val Avg F1  182:  0.6770430367504836

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 183
--------------------------------------------------------------
Epoch:  183        1 Batch loss: 0.157285 Batch F1: 0.7555555555555556
Epoch:  183        2 Batch loss: 0.208443 Batch F1: 0.6086956521739131
Epoch:  183        3 Batch loss: 0.183009 Batch F1: 0.7547169811320754
Epoch:  183        4 Batch loss: 0.190334 Batch F1: 0.6666666666666666
Epoch:  183        5 Batch loss: 0.169682 Batch F1: 0.606060606060606
Epoch:  183        6 Batch loss: 0.159834 Batch F1: 0.717948717948718
Epoch:  183        7 Batch loss: 0.165781 Batch F1: 0.7234042553191489
Epoch:  183        8 Batch loss: 0.157856 Batch F1: 0.7555555555555556
Epoch:  183        9 Batch loss: 0.156693 Batch F1: 0.7916666666666667
Epoch:  183       10 Batch loss: 0.188044 Batch F1: 0.7058823529411765
Epoch:  183       11 Batch loss: 0.176292 Batch F1: 0.7368421052631577
Epoch:  183       12 Batch loss: 0.172492 Batch F1: 0.6857142857142857
Train Avg Loss  183: 0.173812

Train Avg F1  183: 0.7090591167497938

Val Avg Loss  183: 0.181743

Val Avg F1  183:  0.6773352713178294

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 184
--------------------------------------------------------------
Epoch:  184        1 Batch loss: 0.194454 Batch F1: 0.7058823529411765
Epoch:  184        2 Batch loss: 0.186977 Batch F1: 0.6190476190476191
Epoch:  184        3 Batch loss: 0.144739 Batch F1: 0.7428571428571428
Epoch:  184        4 Batch loss: 0.133895 Batch F1: 0.8372093023255814
Epoch:  184        5 Batch loss: 0.156880 Batch F1: 0.7755102040816326
Epoch:  184        6 Batch loss: 0.185309 Batch F1: 0.7169811320754716
Epoch:  184        7 Batch loss: 0.194176 Batch F1: 0.7111111111111111
Epoch:  184        8 Batch loss: 0.184598 Batch F1: 0.6666666666666666
Epoch:  184        9 Batch loss: 0.146573 Batch F1: 0.8518518518518519
Epoch:  184       10 Batch loss: 0.188204 Batch F1: 0.45161290322580644
Epoch:  184       11 Batch loss: 0.163166 Batch F1: 0.8181818181818182
Epoch:  184       12 Batch loss: 0.207610 Batch F1: 0.5945945945945945
Train Avg Loss  184: 0.173882

Train Avg F1  184: 0.707625558246706

Val Avg Loss  184: 0.184533

Val Avg F1  184:  0.677219387755102

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 185
--------------------------------------------------------------
Epoch:  185        1 Batch loss: 0.107591 Batch F1: 0.9523809523809523
Epoch:  185        2 Batch loss: 0.200741 Batch F1: 0.6363636363636365
Epoch:  185        3 Batch loss: 0.163608 Batch F1: 0.6666666666666667
Epoch:  185        4 Batch loss: 0.197824 Batch F1: 0.55
Epoch:  185        5 Batch loss: 0.180106 Batch F1: 0.7083333333333333
Epoch:  185        6 Batch loss: 0.182829 Batch F1: 0.7083333333333334
Epoch:  185        7 Batch loss: 0.192168 Batch F1: 0.5909090909090909
Epoch:  185        8 Batch loss: 0.183226 Batch F1: 0.6341463414634146
Epoch:  185        9 Batch loss: 0.172752 Batch F1: 0.7659574468085107
Epoch:  185       10 Batch loss: 0.144493 Batch F1: 0.8695652173913043
Epoch:  185       11 Batch loss: 0.198512 Batch F1: 0.5909090909090909
Epoch:  185       12 Batch loss: 0.156547 Batch F1: 0.8181818181818182
Train Avg Loss  185: 0.173366

Train Avg F1  185: 0.7076455773117626

Val Avg Loss  185: 0.189115

Val Avg F1  185:  0.6377015711147038

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 186
--------------------------------------------------------------
Epoch:  186        1 Batch loss: 0.165280 Batch F1: 0.6818181818181818
Epoch:  186        2 Batch loss: 0.232841 Batch F1: 0.6885245901639344
Epoch:  186        3 Batch loss: 0.178968 Batch F1: 0.5454545454545455
Epoch:  186        4 Batch loss: 0.139335 Batch F1: 0.7567567567567567
Epoch:  186        5 Batch loss: 0.192068 Batch F1: 0.32
Epoch:  186        6 Batch loss: 0.207952 Batch F1: 0.4242424242424242
Epoch:  186        7 Batch loss: 0.195102 Batch F1: 0.5714285714285714
Epoch:  186        8 Batch loss: 0.176623 Batch F1: 0.75
Epoch:  186        9 Batch loss: 0.181595 Batch F1: 0.8571428571428572
Epoch:  186       10 Batch loss: 0.240855 Batch F1: 0.5964912280701755
Epoch:  186       11 Batch loss: 0.207915 Batch F1: 0.6779661016949152
Epoch:  186       12 Batch loss: 0.213424 Batch F1: 0.7272727272727272
Train Avg Loss  186: 0.194330

Train Avg F1  186: 0.633091498670424

Val Avg Loss  186: 0.194759

Val Avg F1  186:  0.570102455396573

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 187
--------------------------------------------------------------
Epoch:  187        1 Batch loss: 0.216495 Batch F1: 0.5
Epoch:  187        2 Batch loss: 0.246000 Batch F1: 0.5128205128205129
Epoch:  187        3 Batch loss: 0.200659 Batch F1: 0.4736842105263157
Epoch:  187        4 Batch loss: 0.171762 Batch F1: 0.5
Epoch:  187        5 Batch loss: 0.215733 Batch F1: 0.42105263157894735
Epoch:  187        6 Batch loss: 0.175228 Batch F1: 0.761904761904762
Epoch:  187        7 Batch loss: 0.143305 Batch F1: 0.7999999999999999
Epoch:  187        8 Batch loss: 0.186045 Batch F1: 0.6818181818181818
Epoch:  187        9 Batch loss: 0.166344 Batch F1: 0.7659574468085107
Epoch:  187       10 Batch loss: 0.180148 Batch F1: 0.7450980392156863
Epoch:  187       11 Batch loss: 0.173291 Batch F1: 0.6486486486486486
Epoch:  187       12 Batch loss: 0.159642 Batch F1: 0.8510638297872342
Train Avg Loss  187: 0.186221

Train Avg F1  187: 0.6385040219257332

Val Avg Loss  187: 0.182183

Val Avg F1  187:  0.6785554561717352

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 188
--------------------------------------------------------------
Epoch:  188        1 Batch loss: 0.165160 Batch F1: 0.7142857142857143
Epoch:  188        2 Batch loss: 0.164521 Batch F1: 0.7
Epoch:  188        3 Batch loss: 0.185103 Batch F1: 0.736842105263158
Epoch:  188        4 Batch loss: 0.170946 Batch F1: 0.6818181818181819
Epoch:  188        5 Batch loss: 0.174435 Batch F1: 0.7391304347826085
Epoch:  188        6 Batch loss: 0.180066 Batch F1: 0.76
Epoch:  188        7 Batch loss: 0.190959 Batch F1: 0.6938775510204083
Epoch:  188        8 Batch loss: 0.176293 Batch F1: 0.6666666666666666
Epoch:  188        9 Batch loss: 0.178187 Batch F1: 0.7391304347826088
Epoch:  188       10 Batch loss: 0.153223 Batch F1: 0.7567567567567567
Epoch:  188       11 Batch loss: 0.177497 Batch F1: 0.6341463414634146
Epoch:  188       12 Batch loss: 0.159638 Batch F1: 0.7272727272727272
Train Avg Loss  188: 0.173002

Train Avg F1  188: 0.7124939095093538

Val Avg Loss  188: 0.183464

Val Avg F1  188:  0.6648583423849381

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 189
--------------------------------------------------------------
Epoch:  189        1 Batch loss: 0.195951 Batch F1: 0.6530612244897959
Epoch:  189        2 Batch loss: 0.164550 Batch F1: 0.7804878048780488
Epoch:  189        3 Batch loss: 0.162148 Batch F1: 0.8
Epoch:  189        4 Batch loss: 0.168052 Batch F1: 0.7272727272727272
Epoch:  189        5 Batch loss: 0.137736 Batch F1: 0.8372093023255814
Epoch:  189        6 Batch loss: 0.164631 Batch F1: 0.7234042553191489
Epoch:  189        7 Batch loss: 0.162642 Batch F1: 0.744186046511628
Epoch:  189        8 Batch loss: 0.187249 Batch F1: 0.588235294117647
Epoch:  189        9 Batch loss: 0.157669 Batch F1: 0.7317073170731707
Epoch:  189       10 Batch loss: 0.190216 Batch F1: 0.6521739130434783
Epoch:  189       11 Batch loss: 0.196296 Batch F1: 0.6666666666666666
Epoch:  189       12 Batch loss: 0.186262 Batch F1: 0.5789473684210527
Train Avg Loss  189: 0.172783

Train Avg F1  189: 0.7069459933432455

Val Avg Loss  189: 0.191720

Val Avg F1  189:  0.5556866499083107

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 190
--------------------------------------------------------------
Epoch:  190        1 Batch loss: 0.231011 Batch F1: 0.5789473684210527
Epoch:  190        2 Batch loss: 0.190537 Batch F1: 0.43243243243243246
Epoch:  190        3 Batch loss: 0.171109 Batch F1: 0.5517241379310346
Epoch:  190        4 Batch loss: 0.171735 Batch F1: 0.7500000000000001
Epoch:  190        5 Batch loss: 0.166063 Batch F1: 0.8181818181818182
Epoch:  190        6 Batch loss: 0.186664 Batch F1: 0.7272727272727272
Epoch:  190        7 Batch loss: 0.157789 Batch F1: 0.7391304347826085
Epoch:  190        8 Batch loss: 0.184492 Batch F1: 0.6363636363636365
Epoch:  190        9 Batch loss: 0.185227 Batch F1: 0.6666666666666666
Epoch:  190       10 Batch loss: 0.201492 Batch F1: 0.6923076923076923
Epoch:  190       11 Batch loss: 0.163468 Batch F1: 0.7727272727272727
Epoch:  190       12 Batch loss: 0.166118 Batch F1: 0.6206896551724137
Train Avg Loss  190: 0.181309

Train Avg F1  190: 0.6655369868549463

Val Avg Loss  190: 0.192201

Val Avg F1  190:  0.5786109669607334

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 191
--------------------------------------------------------------
Epoch:  191        1 Batch loss: 0.160267 Batch F1: 0.6956521739130435
Epoch:  191        2 Batch loss: 0.178287 Batch F1: 0.6976744186046512
Epoch:  191        3 Batch loss: 0.193461 Batch F1: 0.5945945945945946
Epoch:  191        4 Batch loss: 0.190340 Batch F1: 0.6153846153846153
Epoch:  191        5 Batch loss: 0.158887 Batch F1: 0.7222222222222223
Epoch:  191        6 Batch loss: 0.153219 Batch F1: 0.75
Epoch:  191        7 Batch loss: 0.177953 Batch F1: 0.7083333333333334
Epoch:  191        8 Batch loss: 0.164662 Batch F1: 0.8
Epoch:  191        9 Batch loss: 0.193436 Batch F1: 0.7169811320754716
Epoch:  191       10 Batch loss: 0.180314 Batch F1: 0.65
Epoch:  191       11 Batch loss: 0.191157 Batch F1: 0.7058823529411765
Epoch:  191       12 Batch loss: 0.169385 Batch F1: 0.7368421052631579
Train Avg Loss  191: 0.175947

Train Avg F1  191: 0.6994639123610221

Val Avg Loss  191: 0.183479

Val Avg F1  191:  0.6763399339613794

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 192
--------------------------------------------------------------
Epoch:  192        1 Batch loss: 0.209012 Batch F1: 0.5853658536585366
Epoch:  192        2 Batch loss: 0.173262 Batch F1: 0.6666666666666667
Epoch:  192        3 Batch loss: 0.185359 Batch F1: 0.6818181818181819
Epoch:  192        4 Batch loss: 0.168608 Batch F1: 0.6666666666666666
Epoch:  192        5 Batch loss: 0.201811 Batch F1: 0.6938775510204083
Epoch:  192        6 Batch loss: 0.183590 Batch F1: 0.7234042553191491
Epoch:  192        7 Batch loss: 0.193283 Batch F1: 0.6086956521739131
Epoch:  192        8 Batch loss: 0.173154 Batch F1: 0.7083333333333334
Epoch:  192        9 Batch loss: 0.156948 Batch F1: 0.7843137254901961
Epoch:  192       10 Batch loss: 0.165174 Batch F1: 0.7142857142857143
Epoch:  192       11 Batch loss: 0.175011 Batch F1: 0.6666666666666666
Epoch:  192       12 Batch loss: 0.170190 Batch F1: 0.6829268292682926
Train Avg Loss  192: 0.179617

Train Avg F1  192: 0.6819184246973106

Val Avg Loss  192: 0.188250

Val Avg F1  192:  0.6300544608087137

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 193
--------------------------------------------------------------
Epoch:  193        1 Batch loss: 0.188461 Batch F1: 0.5909090909090909
Epoch:  193        2 Batch loss: 0.200764 Batch F1: 0.6666666666666666
Epoch:  193        3 Batch loss: 0.222720 Batch F1: 0.5238095238095238
Epoch:  193        4 Batch loss: 0.160825 Batch F1: 0.7058823529411765
Epoch:  193        5 Batch loss: 0.167407 Batch F1: 0.8627450980392156
Epoch:  193        6 Batch loss: 0.200871 Batch F1: 0.6511627906976745
Epoch:  193        7 Batch loss: 0.172433 Batch F1: 0.8076923076923077
Epoch:  193        8 Batch loss: 0.157602 Batch F1: 0.8085106382978724
Epoch:  193        9 Batch loss: 0.206100 Batch F1: 0.6153846153846154
Epoch:  193       10 Batch loss: 0.166288 Batch F1: 0.7083333333333334
Epoch:  193       11 Batch loss: 0.205542 Batch F1: 0.7234042553191489
Epoch:  193       12 Batch loss: 0.206219 Batch F1: 0.6341463414634146
Train Avg Loss  193: 0.187936

Train Avg F1  193: 0.6915539178795034

Val Avg Loss  193: 0.188582

Val Avg F1  193:  0.6735790753647896

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 194
--------------------------------------------------------------
Epoch:  194        1 Batch loss: 0.177403 Batch F1: 0.6956521739130435
Epoch:  194        2 Batch loss: 0.170222 Batch F1: 0.6976744186046512
Epoch:  194        3 Batch loss: 0.191016 Batch F1: 0.7346938775510203
Epoch:  194        4 Batch loss: 0.163737 Batch F1: 0.75
Epoch:  194        5 Batch loss: 0.192542 Batch F1: 0.6363636363636365
Epoch:  194        6 Batch loss: 0.175004 Batch F1: 0.7272727272727272
Epoch:  194        7 Batch loss: 0.211902 Batch F1: 0.6086956521739131
Epoch:  194        8 Batch loss: 0.168284 Batch F1: 0.7755102040816326
Epoch:  194        9 Batch loss: 0.197817 Batch F1: 0.5263157894736842
Epoch:  194       10 Batch loss: 0.138879 Batch F1: 0.875
Epoch:  194       11 Batch loss: 0.162899 Batch F1: 0.744186046511628
Epoch:  194       12 Batch loss: 0.160398 Batch F1: 0.742857142857143
Train Avg Loss  194: 0.175842

Train Avg F1  194: 0.7095184724002568

Val Avg Loss  194: 0.186367

Val Avg F1  194:  0.6689534412125245

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 195
--------------------------------------------------------------
Epoch:  195        1 Batch loss: 0.193363 Batch F1: 0.6500000000000001
Epoch:  195        2 Batch loss: 0.178127 Batch F1: 0.6842105263157895
Epoch:  195        3 Batch loss: 0.181604 Batch F1: 0.6285714285714287
Epoch:  195        4 Batch loss: 0.199912 Batch F1: 0.5500000000000002
Epoch:  195        5 Batch loss: 0.205030 Batch F1: 0.6666666666666667
Epoch:  195        6 Batch loss: 0.170066 Batch F1: 0.7272727272727273
Epoch:  195        7 Batch loss: 0.143631 Batch F1: 0.8444444444444444
Epoch:  195        8 Batch loss: 0.173808 Batch F1: 0.711111111111111
Epoch:  195        9 Batch loss: 0.141105 Batch F1: 0.7692307692307692
Epoch:  195       10 Batch loss: 0.169950 Batch F1: 0.7636363636363636
Epoch:  195       11 Batch loss: 0.168970 Batch F1: 0.7924528301886793
Epoch:  195       12 Batch loss: 0.199005 Batch F1: 0.6363636363636365
Train Avg Loss  195: 0.177048

Train Avg F1  195: 0.7019967086501347

Val Avg Loss  195: 0.185369

Val Avg F1  195:  0.6775511584275056

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 196
--------------------------------------------------------------
Epoch:  196        1 Batch loss: 0.152796 Batch F1: 0.8214285714285715
Epoch:  196        2 Batch loss: 0.184064 Batch F1: 0.6511627906976745
Epoch:  196        3 Batch loss: 0.150051 Batch F1: 0.7500000000000001
Epoch:  196        4 Batch loss: 0.187114 Batch F1: 0.7058823529411765
Epoch:  196        5 Batch loss: 0.195500 Batch F1: 0.6666666666666667
Epoch:  196        6 Batch loss: 0.174136 Batch F1: 0.7
Epoch:  196        7 Batch loss: 0.188171 Batch F1: 0.6938775510204083
Epoch:  196        8 Batch loss: 0.138581 Batch F1: 0.8444444444444444
Epoch:  196        9 Batch loss: 0.174264 Batch F1: 0.6976744186046512
Epoch:  196       10 Batch loss: 0.171874 Batch F1: 0.7111111111111111
Epoch:  196       11 Batch loss: 0.172713 Batch F1: 0.6285714285714287
Epoch:  196       12 Batch loss: 0.203756 Batch F1: 0.6153846153846153
Train Avg Loss  196: 0.174418

Train Avg F1  196: 0.7071836625725624

Val Avg Loss  196: 0.185837

Val Avg F1  196:  0.6766843971631206

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 197
--------------------------------------------------------------
Epoch:  197        1 Batch loss: 0.190738 Batch F1: 0.6190476190476191
Epoch:  197        2 Batch loss: 0.176814 Batch F1: 0.6666666666666667
Epoch:  197        3 Batch loss: 0.166124 Batch F1: 0.7999999999999999
Epoch:  197        4 Batch loss: 0.170923 Batch F1: 0.6842105263157895
Epoch:  197        5 Batch loss: 0.197810 Batch F1: 0.5714285714285713
Epoch:  197        6 Batch loss: 0.176879 Batch F1: 0.6956521739130435
Epoch:  197        7 Batch loss: 0.131808 Batch F1: 0.8636363636363636
Epoch:  197        8 Batch loss: 0.175837 Batch F1: 0.6818181818181819
Epoch:  197        9 Batch loss: 0.174872 Batch F1: 0.7659574468085107
Epoch:  197       10 Batch loss: 0.181601 Batch F1: 0.7272727272727273
Epoch:  197       11 Batch loss: 0.183368 Batch F1: 0.6956521739130435
Epoch:  197       12 Batch loss: 0.153178 Batch F1: 0.75
Train Avg Loss  197: 0.173329

Train Avg F1  197: 0.7101118709017097

Val Avg Loss  197: 0.182747

Val Avg F1  197:  0.6761242729465171

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 198
--------------------------------------------------------------
Epoch:  198        1 Batch loss: 0.178755 Batch F1: 0.7083333333333334
Epoch:  198        2 Batch loss: 0.182727 Batch F1: 0.6341463414634146
Epoch:  198        3 Batch loss: 0.157631 Batch F1: 0.7555555555555555
Epoch:  198        4 Batch loss: 0.165636 Batch F1: 0.7441860465116279
Epoch:  198        5 Batch loss: 0.179249 Batch F1: 0.6956521739130435
Epoch:  198        6 Batch loss: 0.178551 Batch F1: 0.6818181818181819
Epoch:  198        7 Batch loss: 0.187223 Batch F1: 0.7407407407407408
Epoch:  198        8 Batch loss: 0.158332 Batch F1: 0.7727272727272727
Epoch:  198        9 Batch loss: 0.175263 Batch F1: 0.7272727272727273
Epoch:  198       10 Batch loss: 0.161902 Batch F1: 0.7659574468085107
Epoch:  198       11 Batch loss: 0.171554 Batch F1: 0.6315789473684211
Epoch:  198       12 Batch loss: 0.171464 Batch F1: 0.6451612903225806
Train Avg Loss  198: 0.172357

Train Avg F1  198: 0.7085941714862841

Val Avg Loss  198: 0.183581

Val Avg F1  198:  0.6757318741450068

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 199
--------------------------------------------------------------
Epoch:  199        1 Batch loss: 0.188443 Batch F1: 0.75
Epoch:  199        2 Batch loss: 0.144340 Batch F1: 0.7999999999999999
Epoch:  199        3 Batch loss: 0.159193 Batch F1: 0.6666666666666666
Epoch:  199        4 Batch loss: 0.177460 Batch F1: 0.6341463414634148
Epoch:  199        5 Batch loss: 0.183599 Batch F1: 0.7058823529411765
Epoch:  199        6 Batch loss: 0.162977 Batch F1: 0.7272727272727273
Epoch:  199        7 Batch loss: 0.170557 Batch F1: 0.75
Epoch:  199        8 Batch loss: 0.161490 Batch F1: 0.717948717948718
Epoch:  199        9 Batch loss: 0.182303 Batch F1: 0.6153846153846154
Epoch:  199       10 Batch loss: 0.172929 Batch F1: 0.6829268292682926
Epoch:  199       11 Batch loss: 0.169349 Batch F1: 0.7027027027027027
Epoch:  199       12 Batch loss: 0.190458 Batch F1: 0.75
Train Avg Loss  199: 0.171925

Train Avg F1  199: 0.7085775794706928

Val Avg Loss  199: 0.183363

Val Avg F1  199:  0.676631962019793

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 200
--------------------------------------------------------------
Epoch:  200        1 Batch loss: 0.153996 Batch F1: 0.625
Epoch:  200        2 Batch loss: 0.202272 Batch F1: 0.6363636363636364
Epoch:  200        3 Batch loss: 0.152934 Batch F1: 0.7999999999999999
Epoch:  200        4 Batch loss: 0.154103 Batch F1: 0.8235294117647058
Epoch:  200        5 Batch loss: 0.198900 Batch F1: 0.72
Epoch:  200        6 Batch loss: 0.179996 Batch F1: 0.7692307692307692
Epoch:  200        7 Batch loss: 0.141998 Batch F1: 0.8292682926829269
Epoch:  200        8 Batch loss: 0.162150 Batch F1: 0.7368421052631577
Epoch:  200        9 Batch loss: 0.183388 Batch F1: 0.6923076923076923
Epoch:  200       10 Batch loss: 0.185638 Batch F1: 0.5909090909090908
Epoch:  200       11 Batch loss: 0.240138 Batch F1: 0.5
Epoch:  200       12 Batch loss: 0.165947 Batch F1: 0.7647058823529411
Train Avg Loss  200: 0.176788

Train Avg F1  200: 0.7073464067395766

Val Avg Loss  200: 0.185141

Val Avg F1  200:  0.6656928629962693

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 201
--------------------------------------------------------------
Epoch:  201        1 Batch loss: 0.185751 Batch F1: 0.7857142857142856
Epoch:  201        2 Batch loss: 0.191467 Batch F1: 0.6511627906976744
Epoch:  201        3 Batch loss: 0.146390 Batch F1: 0.7368421052631577
Epoch:  201        4 Batch loss: 0.172643 Batch F1: 0.8108108108108109
Epoch:  201        5 Batch loss: 0.164890 Batch F1: 0.6428571428571429
Epoch:  201        6 Batch loss: 0.169943 Batch F1: 0.5384615384615384
Epoch:  201        7 Batch loss: 0.241191 Batch F1: 0.5238095238095238
Epoch:  201        8 Batch loss: 0.172634 Batch F1: 0.7317073170731707
Epoch:  201        9 Batch loss: 0.182904 Batch F1: 0.8235294117647058
Epoch:  201       10 Batch loss: 0.213621 Batch F1: 0.7941176470588236
Epoch:  201       11 Batch loss: 0.228582 Batch F1: 0.6779661016949153
Epoch:  201       12 Batch loss: 0.202778 Batch F1: 0.5
Train Avg Loss  201: 0.189399

Train Avg F1  201: 0.6847482229338123

Val Avg Loss  201: 0.193857

Val Avg F1  201:  0.6740419538142421

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 202
--------------------------------------------------------------
Epoch:  202        1 Batch loss: 0.179553 Batch F1: 0.7755102040816326
Epoch:  202        2 Batch loss: 0.185494 Batch F1: 0.6511627906976744
Epoch:  202        3 Batch loss: 0.169775 Batch F1: 0.6206896551724137
Epoch:  202        4 Batch loss: 0.207109 Batch F1: 0.5882352941176471
Epoch:  202        5 Batch loss: 0.170726 Batch F1: 0.717948717948718
Epoch:  202        6 Batch loss: 0.159094 Batch F1: 0.7555555555555555
Epoch:  202        7 Batch loss: 0.182212 Batch F1: 0.6818181818181818
Epoch:  202        8 Batch loss: 0.181301 Batch F1: 0.6666666666666666
Epoch:  202        9 Batch loss: 0.172649 Batch F1: 0.8070175438596492
Epoch:  202       10 Batch loss: 0.173772 Batch F1: 0.7407407407407407
Epoch:  202       11 Batch loss: 0.249972 Batch F1: 0.5116279069767442
Epoch:  202       12 Batch loss: 0.226672 Batch F1: 0.75
Train Avg Loss  202: 0.188194

Train Avg F1  202: 0.6889144381363019

Val Avg Loss  202: 0.189523

Val Avg F1  202:  0.838052655124409

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 203
--------------------------------------------------------------
Epoch:  203        1 Batch loss: 0.188340 Batch F1: 0.8771929824561403
Epoch:  203        2 Batch loss: 0.180822 Batch F1: 0.8421052631578948
Epoch:  203        3 Batch loss: 0.176070 Batch F1: 0.6666666666666666
Epoch:  203        4 Batch loss: 0.239639 Batch F1: 0.5777777777777777
Epoch:  203        5 Batch loss: 0.179822 Batch F1: 0.5555555555555556
Epoch:  203        6 Batch loss: 0.187585 Batch F1: 0.8148148148148149
Epoch:  203        7 Batch loss: 0.158586 Batch F1: 0.8372093023255814
Epoch:  203        8 Batch loss: 0.159045 Batch F1: 0.7027027027027027
Epoch:  203        9 Batch loss: 0.217138 Batch F1: 0.6111111111111112
Epoch:  203       10 Batch loss: 0.198696 Batch F1: 0.5641025641025641
Epoch:  203       11 Batch loss: 0.184876 Batch F1: 0.6666666666666667
Epoch:  203       12 Batch loss: 0.211742 Batch F1: 0.6153846153846153
Train Avg Loss  203: 0.190197

Train Avg F1  203: 0.6942741685601743

Val Avg Loss  203: 0.188861

Val Avg F1  203:  0.6698352918615429

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 204
--------------------------------------------------------------
Epoch:  204        1 Batch loss: 0.188059 Batch F1: 0.6
Epoch:  204        2 Batch loss: 0.179190 Batch F1: 0.76
Epoch:  204        3 Batch loss: 0.195561 Batch F1: 0.6382978723404256
Epoch:  204        4 Batch loss: 0.196455 Batch F1: 0.7169811320754718
Epoch:  204        5 Batch loss: 0.167607 Batch F1: 0.7755102040816326
Epoch:  204        6 Batch loss: 0.156302 Batch F1: 0.6666666666666667
Epoch:  204        7 Batch loss: 0.198871 Batch F1: 0.6315789473684211
Epoch:  204        8 Batch loss: 0.171689 Batch F1: 0.7777777777777777
Epoch:  204        9 Batch loss: 0.160707 Batch F1: 0.7692307692307693
Epoch:  204       10 Batch loss: 0.176258 Batch F1: 0.6511627906976744
Epoch:  204       11 Batch loss: 0.204775 Batch F1: 0.6250000000000001
Epoch:  204       12 Batch loss: 0.166284 Batch F1: 0.6428571428571429
Train Avg Loss  204: 0.180146

Train Avg F1  204: 0.6879219419246652

Val Avg Loss  204: 0.188930

Val Avg F1  204:  0.6364696685428392

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 205
--------------------------------------------------------------
Epoch:  205        1 Batch loss: 0.170300 Batch F1: 0.6521739130434783
Epoch:  205        2 Batch loss: 0.163058 Batch F1: 0.8518518518518519
Epoch:  205        3 Batch loss: 0.153138 Batch F1: 0.7058823529411765
Epoch:  205        4 Batch loss: 0.187381 Batch F1: 0.6153846153846153
Epoch:  205        5 Batch loss: 0.180858 Batch F1: 0.7692307692307692
Epoch:  205        6 Batch loss: 0.185916 Batch F1: 0.6818181818181819
Epoch:  205        7 Batch loss: 0.162679 Batch F1: 0.7555555555555556
Epoch:  205        8 Batch loss: 0.169608 Batch F1: 0.7346938775510204
Epoch:  205        9 Batch loss: 0.187907 Batch F1: 0.68
Epoch:  205       10 Batch loss: 0.178463 Batch F1: 0.6046511627906976
Epoch:  205       11 Batch loss: 0.225859 Batch F1: 0.5777777777777778
Epoch:  205       12 Batch loss: 0.189443 Batch F1: 0.6486486486486486
Train Avg Loss  205: 0.179551

Train Avg F1  205: 0.689805725549481

Val Avg Loss  205: 0.194287

Val Avg F1  205:  0.5777919501133787

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 206
--------------------------------------------------------------
Epoch:  206        1 Batch loss: 0.185432 Batch F1: 0.6666666666666666
Epoch:  206        2 Batch loss: 0.177870 Batch F1: 0.6470588235294118
Epoch:  206        3 Batch loss: 0.186130 Batch F1: 0.6111111111111112
Epoch:  206        4 Batch loss: 0.174369 Batch F1: 0.7391304347826089
Epoch:  206        5 Batch loss: 0.165183 Batch F1: 0.816326530612245
Epoch:  206        6 Batch loss: 0.199516 Batch F1: 0.6521739130434783
Epoch:  206        7 Batch loss: 0.145055 Batch F1: 0.7999999999999999
Epoch:  206        8 Batch loss: 0.161342 Batch F1: 0.7999999999999999
Epoch:  206        9 Batch loss: 0.191941 Batch F1: 0.6222222222222223
Epoch:  206       10 Batch loss: 0.216148 Batch F1: 0.5106382978723404
Epoch:  206       11 Batch loss: 0.201324 Batch F1: 0.6250000000000001
Epoch:  206       12 Batch loss: 0.138020 Batch F1: 0.8421052631578947
Train Avg Loss  206: 0.178528

Train Avg F1  206: 0.6943694385831649

Val Avg Loss  206: 0.186063

Val Avg F1  206:  0.6798062618924061

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 207
--------------------------------------------------------------
Epoch:  207        1 Batch loss: 0.139334 Batch F1: 0.8636363636363635
Epoch:  207        2 Batch loss: 0.172165 Batch F1: 0.6486486486486486
Epoch:  207        3 Batch loss: 0.175930 Batch F1: 0.6666666666666667
Epoch:  207        4 Batch loss: 0.179113 Batch F1: 0.7450980392156863
Epoch:  207        5 Batch loss: 0.220725 Batch F1: 0.5365853658536586
Epoch:  207        6 Batch loss: 0.161974 Batch F1: 0.7317073170731706
Epoch:  207        7 Batch loss: 0.158455 Batch F1: 0.8363636363636364
Epoch:  207        8 Batch loss: 0.194979 Batch F1: 0.5263157894736842
Epoch:  207        9 Batch loss: 0.178936 Batch F1: 0.6956521739130435
Epoch:  207       10 Batch loss: 0.169564 Batch F1: 0.7346938775510204
Epoch:  207       11 Batch loss: 0.168569 Batch F1: 0.7272727272727272
Epoch:  207       12 Batch loss: 0.163335 Batch F1: 0.7500000000000001
Train Avg Loss  207: 0.173590

Train Avg F1  207: 0.7052200504723589

Val Avg Loss  207: 0.183383

Val Avg F1  207:  0.6739873581567933

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 208
--------------------------------------------------------------
Epoch:  208        1 Batch loss: 0.166281 Batch F1: 0.7659574468085107
Epoch:  208        2 Batch loss: 0.190630 Batch F1: 0.6938775510204083
Epoch:  208        3 Batch loss: 0.195638 Batch F1: 0.6538461538461539
Epoch:  208        4 Batch loss: 0.153004 Batch F1: 0.7647058823529412
Epoch:  208        5 Batch loss: 0.182426 Batch F1: 0.5945945945945946
Epoch:  208        6 Batch loss: 0.197274 Batch F1: 0.5641025641025642
Epoch:  208        7 Batch loss: 0.160044 Batch F1: 0.7317073170731706
Epoch:  208        8 Batch loss: 0.178367 Batch F1: 0.711111111111111
Epoch:  208        9 Batch loss: 0.165798 Batch F1: 0.7499999999999999
Epoch:  208       10 Batch loss: 0.164764 Batch F1: 0.7659574468085107
Epoch:  208       11 Batch loss: 0.166052 Batch F1: 0.76
Epoch:  208       12 Batch loss: 0.158671 Batch F1: 0.7777777777777778
Train Avg Loss  208: 0.173246

Train Avg F1  208: 0.7111364871246453

Val Avg Loss  208: 0.187065

Val Avg F1  208:  0.6402280092390578

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 209
--------------------------------------------------------------
Epoch:  209        1 Batch loss: 0.191287 Batch F1: 0.6086956521739131
Epoch:  209        2 Batch loss: 0.181623 Batch F1: 0.7111111111111111
Epoch:  209        3 Batch loss: 0.182557 Batch F1: 0.631578947368421
Epoch:  209        4 Batch loss: 0.165404 Batch F1: 0.8076923076923077
Epoch:  209        5 Batch loss: 0.197608 Batch F1: 0.6190476190476191
Epoch:  209        6 Batch loss: 0.168032 Batch F1: 0.7142857142857143
Epoch:  209        7 Batch loss: 0.177364 Batch F1: 0.723404255319149
Epoch:  209        8 Batch loss: 0.143623 Batch F1: 0.8
Epoch:  209        9 Batch loss: 0.160051 Batch F1: 0.761904761904762
Epoch:  209       10 Batch loss: 0.173944 Batch F1: 0.7346938775510204
Epoch:  209       11 Batch loss: 0.190109 Batch F1: 0.6923076923076923
Epoch:  209       12 Batch loss: 0.186666 Batch F1: 0.6470588235294118
Train Avg Loss  209: 0.176522

Train Avg F1  209: 0.7043150635242602

Val Avg Loss  209: 0.183188

Val Avg F1  209:  0.6612637362637362

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 210
--------------------------------------------------------------
Epoch:  210        1 Batch loss: 0.162565 Batch F1: 0.7391304347826085
Epoch:  210        2 Batch loss: 0.166076 Batch F1: 0.7142857142857143
Epoch:  210        3 Batch loss: 0.169843 Batch F1: 0.6666666666666667
Epoch:  210        4 Batch loss: 0.143282 Batch F1: 0.8461538461538461
Epoch:  210        5 Batch loss: 0.149704 Batch F1: 0.7804878048780488
Epoch:  210        6 Batch loss: 0.197560 Batch F1: 0.5853658536585366
Epoch:  210        7 Batch loss: 0.195378 Batch F1: 0.5853658536585366
Epoch:  210        8 Batch loss: 0.147109 Batch F1: 0.8205128205128205
Epoch:  210        9 Batch loss: 0.198552 Batch F1: 0.7142857142857143
Epoch:  210       10 Batch loss: 0.170313 Batch F1: 0.6666666666666667
Epoch:  210       11 Batch loss: 0.185652 Batch F1: 0.6923076923076924
Epoch:  210       12 Batch loss: 0.176775 Batch F1: 0.7027027027027027
Train Avg Loss  210: 0.171901

Train Avg F1  210: 0.7094943142132962

Val Avg Loss  210: 0.182661

Val Avg F1  210:  0.6751212112752077

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 211
--------------------------------------------------------------
Epoch:  211        1 Batch loss: 0.158955 Batch F1: 0.6666666666666666
Epoch:  211        2 Batch loss: 0.181631 Batch F1: 0.6341463414634146
Epoch:  211        3 Batch loss: 0.184303 Batch F1: 0.6808510638297872
Epoch:  211        4 Batch loss: 0.202872 Batch F1: 0.6792452830188679
Epoch:  211        5 Batch loss: 0.174667 Batch F1: 0.76
Epoch:  211        6 Batch loss: 0.154381 Batch F1: 0.7500000000000001
Epoch:  211        7 Batch loss: 0.147081 Batch F1: 0.8085106382978724
Epoch:  211        8 Batch loss: 0.139627 Batch F1: 0.7777777777777778
Epoch:  211        9 Batch loss: 0.215968 Batch F1: 0.6415094339622641
Epoch:  211       10 Batch loss: 0.146883 Batch F1: 0.8
Epoch:  211       11 Batch loss: 0.179055 Batch F1: 0.7307692307692306
Epoch:  211       12 Batch loss: 0.173746 Batch F1: 0.5714285714285715
Train Avg Loss  211: 0.171597

Train Avg F1  211: 0.7084087506012043

Val Avg Loss  211: 0.182690

Val Avg F1  211:  0.6788001348163129

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 212
--------------------------------------------------------------
Epoch:  212        1 Batch loss: 0.165152 Batch F1: 0.7
Epoch:  212        2 Batch loss: 0.185774 Batch F1: 0.6341463414634146
Epoch:  212        3 Batch loss: 0.189107 Batch F1: 0.6521739130434783
Epoch:  212        4 Batch loss: 0.192341 Batch F1: 0.7407407407407408
Epoch:  212        5 Batch loss: 0.143173 Batch F1: 0.8
Epoch:  212        6 Batch loss: 0.157748 Batch F1: 0.717948717948718
Epoch:  212        7 Batch loss: 0.159596 Batch F1: 0.75
Epoch:  212        8 Batch loss: 0.155596 Batch F1: 0.782608695652174
Epoch:  212        9 Batch loss: 0.195719 Batch F1: 0.5853658536585366
Epoch:  212       10 Batch loss: 0.179725 Batch F1: 0.5555555555555556
Epoch:  212       11 Batch loss: 0.140350 Batch F1: 0.8679245283018868
Epoch:  212       12 Batch loss: 0.187732 Batch F1: 0.6976744186046512
Train Avg Loss  212: 0.171001

Train Avg F1  212: 0.7070115637474296

Val Avg Loss  212: 0.182261

Val Avg F1  212:  0.6718315018315019

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 213
--------------------------------------------------------------
Epoch:  213        1 Batch loss: 0.153910 Batch F1: 0.7916666666666667
Epoch:  213        2 Batch loss: 0.150995 Batch F1: 0.7499999999999999
Epoch:  213        3 Batch loss: 0.133044 Batch F1: 0.8108108108108109
Epoch:  213        4 Batch loss: 0.171546 Batch F1: 0.6976744186046512
Epoch:  213        5 Batch loss: 0.166351 Batch F1: 0.717948717948718
Epoch:  213        6 Batch loss: 0.149693 Batch F1: 0.830188679245283
Epoch:  213        7 Batch loss: 0.213767 Batch F1: 0.6274509803921569
Epoch:  213        8 Batch loss: 0.183195 Batch F1: 0.68
Epoch:  213        9 Batch loss: 0.156394 Batch F1: 0.7555555555555555
Epoch:  213       10 Batch loss: 0.177286 Batch F1: 0.6666666666666667
Epoch:  213       11 Batch loss: 0.213784 Batch F1: 0.5714285714285714
Epoch:  213       12 Batch loss: 0.183950 Batch F1: 0.6666666666666666
Train Avg Loss  213: 0.171159

Train Avg F1  213: 0.7138381444988121

Val Avg Loss  213: 0.182532

Val Avg F1  213:  0.6780993333788364

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 214
--------------------------------------------------------------
Epoch:  214        1 Batch loss: 0.170028 Batch F1: 0.6829268292682926
Epoch:  214        2 Batch loss: 0.148592 Batch F1: 0.8292682926829269
Epoch:  214        3 Batch loss: 0.188961 Batch F1: 0.693877551020408
Epoch:  214        4 Batch loss: 0.171061 Batch F1: 0.6829268292682926
Epoch:  214        5 Batch loss: 0.194361 Batch F1: 0.6923076923076923
Epoch:  214        6 Batch loss: 0.168714 Batch F1: 0.7450980392156864
Epoch:  214        7 Batch loss: 0.184859 Batch F1: 0.5641025641025642
Epoch:  214        8 Batch loss: 0.170917 Batch F1: 0.761904761904762
Epoch:  214        9 Batch loss: 0.161689 Batch F1: 0.76
Epoch:  214       10 Batch loss: 0.162868 Batch F1: 0.7027027027027027
Epoch:  214       11 Batch loss: 0.162252 Batch F1: 0.6666666666666667
Epoch:  214       12 Batch loss: 0.168566 Batch F1: 0.7441860465116279
Train Avg Loss  214: 0.171072

Train Avg F1  214: 0.7104973313043018

Val Avg Loss  214: 0.182234

Val Avg F1  214:  0.6759996073584202

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 215
--------------------------------------------------------------
Epoch:  215        1 Batch loss: 0.158548 Batch F1: 0.7599999999999999
Epoch:  215        2 Batch loss: 0.187087 Batch F1: 0.6666666666666667
Epoch:  215        3 Batch loss: 0.202175 Batch F1: 0.6808510638297872
Epoch:  215        4 Batch loss: 0.173998 Batch F1: 0.6956521739130435
Epoch:  215        5 Batch loss: 0.163622 Batch F1: 0.7555555555555556
Epoch:  215        6 Batch loss: 0.184024 Batch F1: 0.6666666666666666
Epoch:  215        7 Batch loss: 0.160284 Batch F1: 0.7027027027027027
Epoch:  215        8 Batch loss: 0.166278 Batch F1: 0.7857142857142857
Epoch:  215        9 Batch loss: 0.163869 Batch F1: 0.6666666666666666
Epoch:  215       10 Batch loss: 0.162443 Batch F1: 0.7499999999999999
Epoch:  215       11 Batch loss: 0.176866 Batch F1: 0.5161290322580646
Epoch:  215       12 Batch loss: 0.140224 Batch F1: 0.8421052631578947
Train Avg Loss  215: 0.169951

Train Avg F1  215: 0.7073925064276111

Val Avg Loss  215: 0.182554

Val Avg F1  215:  0.6776133209990749

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 216
--------------------------------------------------------------
Epoch:  216        1 Batch loss: 0.161002 Batch F1: 0.7555555555555555
Epoch:  216        2 Batch loss: 0.169968 Batch F1: 0.6666666666666665
Epoch:  216        3 Batch loss: 0.179532 Batch F1: 0.6818181818181819
Epoch:  216        4 Batch loss: 0.171476 Batch F1: 0.8070175438596492
Epoch:  216        5 Batch loss: 0.184400 Batch F1: 0.6190476190476191
Epoch:  216        6 Batch loss: 0.189860 Batch F1: 0.5853658536585366
Epoch:  216        7 Batch loss: 0.173776 Batch F1: 0.7111111111111111
Epoch:  216        8 Batch loss: 0.159351 Batch F1: 0.7142857142857143
Epoch:  216        9 Batch loss: 0.158108 Batch F1: 0.7368421052631577
Epoch:  216       10 Batch loss: 0.139226 Batch F1: 0.8085106382978723
Epoch:  216       11 Batch loss: 0.171536 Batch F1: 0.7083333333333334
Epoch:  216       12 Batch loss: 0.183426 Batch F1: 0.717948717948718
Train Avg Loss  216: 0.170138

Train Avg F1  216: 0.7093752534038429

Val Avg Loss  216: 0.183084

Val Avg F1  216:  0.6747259832366215

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 217
--------------------------------------------------------------
Epoch:  217        1 Batch loss: 0.177452 Batch F1: 0.7450980392156863
Epoch:  217        2 Batch loss: 0.169046 Batch F1: 0.6842105263157895
Epoch:  217        3 Batch loss: 0.157167 Batch F1: 0.8333333333333334
Epoch:  217        4 Batch loss: 0.180418 Batch F1: 0.6956521739130435
Epoch:  217        5 Batch loss: 0.176285 Batch F1: 0.5333333333333333
Epoch:  217        6 Batch loss: 0.183816 Batch F1: 0.7346938775510204
Epoch:  217        7 Batch loss: 0.165236 Batch F1: 0.7317073170731708
Epoch:  217        8 Batch loss: 0.177754 Batch F1: 0.5882352941176471
Epoch:  217        9 Batch loss: 0.180401 Batch F1: 0.6818181818181819
Epoch:  217       10 Batch loss: 0.174341 Batch F1: 0.76
Epoch:  217       11 Batch loss: 0.163976 Batch F1: 0.6976744186046512
Epoch:  217       12 Batch loss: 0.187396 Batch F1: 0.717948717948718
Train Avg Loss  217: 0.174441

Train Avg F1  217: 0.7003087677687145

Val Avg Loss  217: 0.182975

Val Avg F1  217:  0.67804179305696

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 218
--------------------------------------------------------------
Epoch:  218        1 Batch loss: 0.197918 Batch F1: 0.6808510638297872
Epoch:  218        2 Batch loss: 0.185814 Batch F1: 0.65
Epoch:  218        3 Batch loss: 0.157383 Batch F1: 0.7547169811320754
Epoch:  218        4 Batch loss: 0.143405 Batch F1: 0.816326530612245
Epoch:  218        5 Batch loss: 0.207831 Batch F1: 0.6521739130434783
Epoch:  218        6 Batch loss: 0.156496 Batch F1: 0.7999999999999999
Epoch:  218        7 Batch loss: 0.146747 Batch F1: 0.761904761904762
Epoch:  218        8 Batch loss: 0.177439 Batch F1: 0.7111111111111111
Epoch:  218        9 Batch loss: 0.181216 Batch F1: 0.7346938775510204
Epoch:  218       10 Batch loss: 0.188849 Batch F1: 0.6666666666666666
Epoch:  218       11 Batch loss: 0.173500 Batch F1: 0.606060606060606
Epoch:  218       12 Batch loss: 0.184102 Batch F1: 0.5999999999999999
Train Avg Loss  218: 0.175058

Train Avg F1  218: 0.7028754593259793

Val Avg Loss  218: 0.186212

Val Avg F1  218:  0.6321751970701861

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 219
--------------------------------------------------------------
Epoch:  219        1 Batch loss: 0.190725 Batch F1: 0.5652173913043479
Epoch:  219        2 Batch loss: 0.184603 Batch F1: 0.7346938775510204
Epoch:  219        3 Batch loss: 0.176861 Batch F1: 0.7346938775510204
Epoch:  219        4 Batch loss: 0.182392 Batch F1: 0.72
Epoch:  219        5 Batch loss: 0.197462 Batch F1: 0.6046511627906976
Epoch:  219        6 Batch loss: 0.180850 Batch F1: 0.6486486486486486
Epoch:  219        7 Batch loss: 0.172875 Batch F1: 0.7777777777777779
Epoch:  219        8 Batch loss: 0.158149 Batch F1: 0.7619047619047619
Epoch:  219        9 Batch loss: 0.165157 Batch F1: 0.7111111111111111
Epoch:  219       10 Batch loss: 0.169883 Batch F1: 0.7142857142857143
Epoch:  219       11 Batch loss: 0.157229 Batch F1: 0.717948717948718
Epoch:  219       12 Batch loss: 0.160903 Batch F1: 0.7428571428571428
Train Avg Loss  219: 0.174757

Train Avg F1  219: 0.7028158486442467

Val Avg Loss  219: 0.183317

Val Avg F1  219:  0.6738677819470503

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 220
--------------------------------------------------------------
Epoch:  220        1 Batch loss: 0.203924 Batch F1: 0.5
Epoch:  220        2 Batch loss: 0.164798 Batch F1: 0.7142857142857143
Epoch:  220        3 Batch loss: 0.177680 Batch F1: 0.6285714285714286
Epoch:  220        4 Batch loss: 0.177916 Batch F1: 0.6285714285714286
Epoch:  220        5 Batch loss: 0.181692 Batch F1: 0.7547169811320754
Epoch:  220        6 Batch loss: 0.172969 Batch F1: 0.6285714285714286
Epoch:  220        7 Batch loss: 0.168815 Batch F1: 0.75
Epoch:  220        8 Batch loss: 0.127569 Batch F1: 0.9152542372881356
Epoch:  220        9 Batch loss: 0.198434 Batch F1: 0.6530612244897959
Epoch:  220       10 Batch loss: 0.178322 Batch F1: 0.7368421052631579
Epoch:  220       11 Batch loss: 0.187293 Batch F1: 0.6666666666666667
Epoch:  220       12 Batch loss: 0.173958 Batch F1: 0.6666666666666667
Train Avg Loss  220: 0.176114

Train Avg F1  220: 0.6869339901255415

Val Avg Loss  220: 0.184177

Val Avg F1  220:  0.6697039893904005

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 221
--------------------------------------------------------------
Epoch:  221        1 Batch loss: 0.178445 Batch F1: 0.6976744186046512
Epoch:  221        2 Batch loss: 0.195176 Batch F1: 0.5714285714285713
Epoch:  221        3 Batch loss: 0.165303 Batch F1: 0.6976744186046512
Epoch:  221        4 Batch loss: 0.183695 Batch F1: 0.6363636363636365
Epoch:  221        5 Batch loss: 0.175716 Batch F1: 0.6666666666666666
Epoch:  221        6 Batch loss: 0.200064 Batch F1: 0.5945945945945946
Epoch:  221        7 Batch loss: 0.156424 Batch F1: 0.8148148148148148
Epoch:  221        8 Batch loss: 0.145722 Batch F1: 0.8571428571428572
Epoch:  221        9 Batch loss: 0.157019 Batch F1: 0.7547169811320754
Epoch:  221       10 Batch loss: 0.223962 Batch F1: 0.7441860465116279
Epoch:  221       11 Batch loss: 0.178918 Batch F1: 0.7111111111111111
Epoch:  221       12 Batch loss: 0.196226 Batch F1: 0.6486486486486486
Train Avg Loss  221: 0.179722

Train Avg F1  221: 0.6995852304686587

Val Avg Loss  221: 0.187081

Val Avg F1  221:  0.6757037151280818

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 222
--------------------------------------------------------------
Epoch:  222        1 Batch loss: 0.171636 Batch F1: 0.847457627118644
Epoch:  222        2 Batch loss: 0.183879 Batch F1: 0.8076923076923077
Epoch:  222        3 Batch loss: 0.165059 Batch F1: 0.9090909090909091
Epoch:  222        4 Batch loss: 0.195820 Batch F1: 0.8095238095238095
Epoch:  222        5 Batch loss: 0.183201 Batch F1: 0.8615384615384616
Epoch:  222        6 Batch loss: 0.235445 Batch F1: 0.7499999999999999
Epoch:  222        7 Batch loss: 0.187465 Batch F1: 0.8085106382978724
Epoch:  222        8 Batch loss: 0.178318 Batch F1: 0.6976744186046512
Epoch:  222        9 Batch loss: 0.180429 Batch F1: 0.5714285714285714
Epoch:  222       10 Batch loss: 0.197742 Batch F1: 0.75
Epoch:  222       11 Batch loss: 0.194213 Batch F1: 0.7368421052631579
Epoch:  222       12 Batch loss: 0.167283 Batch F1: 0.7647058823529412
Train Avg Loss  222: 0.186707

Train Avg F1  222: 0.7762053942426106

Val Avg Loss  222: 0.194567

Val Avg F1  222:  0.6119311360908

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 223
--------------------------------------------------------------
Epoch:  223        1 Batch loss: 0.185449 Batch F1: 0.588235294117647
Epoch:  223        2 Batch loss: 0.177231 Batch F1: 0.5
Epoch:  223        3 Batch loss: 0.190632 Batch F1: 0.5777777777777778
Epoch:  223        4 Batch loss: 0.181734 Batch F1: 0.7083333333333334
Epoch:  223        5 Batch loss: 0.185448 Batch F1: 0.6046511627906976
Epoch:  223        6 Batch loss: 0.165364 Batch F1: 0.6956521739130435
Epoch:  223        7 Batch loss: 0.152418 Batch F1: 0.7777777777777777
Epoch:  223        8 Batch loss: 0.185353 Batch F1: 0.5789473684210527
Epoch:  223        9 Batch loss: 0.186356 Batch F1: 0.5777777777777778
Epoch:  223       10 Batch loss: 0.223991 Batch F1: 0.6976744186046512
Epoch:  223       11 Batch loss: 0.169025 Batch F1: 0.6956521739130435
Epoch:  223       12 Batch loss: 0.195388 Batch F1: 0.7843137254901961
Train Avg Loss  223: 0.183199

Train Avg F1  223: 0.6488994153264166

Val Avg Loss  223: 0.188218

Val Avg F1  223:  0.728184711655988

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 224
--------------------------------------------------------------
Epoch:  224        1 Batch loss: 0.190013 Batch F1: 0.7796610169491527
Epoch:  224        2 Batch loss: 0.191724 Batch F1: 0.723404255319149
Epoch:  224        3 Batch loss: 0.193643 Batch F1: 0.6818181818181818
Epoch:  224        4 Batch loss: 0.156460 Batch F1: 0.717948717948718
Epoch:  224        5 Batch loss: 0.178730 Batch F1: 0.711111111111111
Epoch:  224        6 Batch loss: 0.165025 Batch F1: 0.830188679245283
Epoch:  224        7 Batch loss: 0.198909 Batch F1: 0.625
Epoch:  224        8 Batch loss: 0.171587 Batch F1: 0.6842105263157895
Epoch:  224        9 Batch loss: 0.161815 Batch F1: 0.7755102040816326
Epoch:  224       10 Batch loss: 0.187878 Batch F1: 0.6956521739130435
Epoch:  224       11 Batch loss: 0.168534 Batch F1: 0.6842105263157895
Epoch:  224       12 Batch loss: 0.167074 Batch F1: 0.5925925925925927
Train Avg Loss  224: 0.177616

Train Avg F1  224: 0.7084423321342036

Val Avg Loss  224: 0.186963

Val Avg F1  224:  0.6757616089914226

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 225
--------------------------------------------------------------
Epoch:  225        1 Batch loss: 0.155322 Batch F1: 0.7906976744186046
Epoch:  225        2 Batch loss: 0.149947 Batch F1: 0.7222222222222223
Epoch:  225        3 Batch loss: 0.144603 Batch F1: 0.8372093023255814
Epoch:  225        4 Batch loss: 0.181607 Batch F1: 0.6956521739130435
Epoch:  225        5 Batch loss: 0.170582 Batch F1: 0.6666666666666666
Epoch:  225        6 Batch loss: 0.193704 Batch F1: 0.6666666666666666
Epoch:  225        7 Batch loss: 0.183760 Batch F1: 0.6153846153846153
Epoch:  225        8 Batch loss: 0.160492 Batch F1: 0.8076923076923077
Epoch:  225        9 Batch loss: 0.179469 Batch F1: 0.7346938775510203
Epoch:  225       10 Batch loss: 0.171474 Batch F1: 0.75
Epoch:  225       11 Batch loss: 0.180888 Batch F1: 0.6666666666666666
Epoch:  225       12 Batch loss: 0.190975 Batch F1: 0.5454545454545455
Train Avg Loss  225: 0.171902

Train Avg F1  225: 0.7082505599134951

Val Avg Loss  225: 0.182248

Val Avg F1  225:  0.6697505543237251

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 226
--------------------------------------------------------------
Epoch:  226        1 Batch loss: 0.155049 Batch F1: 0.7826086956521738
Epoch:  226        2 Batch loss: 0.166445 Batch F1: 0.717948717948718
Epoch:  226        3 Batch loss: 0.191152 Batch F1: 0.6046511627906976
Epoch:  226        4 Batch loss: 0.169616 Batch F1: 0.7659574468085107
Epoch:  226        5 Batch loss: 0.165959 Batch F1: 0.7499999999999999
Epoch:  226        6 Batch loss: 0.188746 Batch F1: 0.6938775510204083
Epoch:  226        7 Batch loss: 0.158806 Batch F1: 0.6857142857142857
Epoch:  226        8 Batch loss: 0.154224 Batch F1: 0.7804878048780487
Epoch:  226        9 Batch loss: 0.160068 Batch F1: 0.7659574468085107
Epoch:  226       10 Batch loss: 0.172858 Batch F1: 0.75
Epoch:  226       11 Batch loss: 0.201725 Batch F1: 0.5238095238095238
Epoch:  226       12 Batch loss: 0.171348 Batch F1: 0.717948717948718
Train Avg Loss  226: 0.171333

Train Avg F1  226: 0.7115801127816329

Val Avg Loss  226: 0.182159

Val Avg F1  226:  0.6614405331510593

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 227
--------------------------------------------------------------
Epoch:  227        1 Batch loss: 0.179837 Batch F1: 0.6666666666666665
Epoch:  227        2 Batch loss: 0.175685 Batch F1: 0.6976744186046512
Epoch:  227        3 Batch loss: 0.162425 Batch F1: 0.7659574468085107
Epoch:  227        4 Batch loss: 0.176868 Batch F1: 0.6956521739130435
Epoch:  227        5 Batch loss: 0.191187 Batch F1: 0.6
Epoch:  227        6 Batch loss: 0.156259 Batch F1: 0.717948717948718
Epoch:  227        7 Batch loss: 0.184555 Batch F1: 0.6341463414634146
Epoch:  227        8 Batch loss: 0.128910 Batch F1: 0.8500000000000001
Epoch:  227        9 Batch loss: 0.169561 Batch F1: 0.7317073170731708
Epoch:  227       10 Batch loss: 0.170272 Batch F1: 0.7555555555555556
Epoch:  227       11 Batch loss: 0.175245 Batch F1: 0.7234042553191491
Epoch:  227       12 Batch loss: 0.200044 Batch F1: 0.7058823529411765
Train Avg Loss  227: 0.172571

Train Avg F1  227: 0.7120496038578379

Val Avg Loss  227: 0.184028

Val Avg F1  227:  0.668647573927077

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 228
--------------------------------------------------------------
Epoch:  228        1 Batch loss: 0.174238 Batch F1: 0.7692307692307692
Epoch:  228        2 Batch loss: 0.165611 Batch F1: 0.7000000000000001
Epoch:  228        3 Batch loss: 0.174791 Batch F1: 0.7027027027027027
Epoch:  228        4 Batch loss: 0.160536 Batch F1: 0.7906976744186046
Epoch:  228        5 Batch loss: 0.147183 Batch F1: 0.7222222222222223
Epoch:  228        6 Batch loss: 0.156816 Batch F1: 0.7567567567567567
Epoch:  228        7 Batch loss: 0.206678 Batch F1: 0.5454545454545454
Epoch:  228        8 Batch loss: 0.182885 Batch F1: 0.6363636363636364
Epoch:  228        9 Batch loss: 0.166916 Batch F1: 0.723404255319149
Epoch:  228       10 Batch loss: 0.203545 Batch F1: 0.7719298245614035
Epoch:  228       11 Batch loss: 0.211954 Batch F1: 0.6086956521739131
Epoch:  228       12 Batch loss: 0.165429 Batch F1: 0.8205128205128205
Train Avg Loss  228: 0.176382

Train Avg F1  228: 0.7123309049763771

Val Avg Loss  228: 0.184077

Val Avg F1  228:  0.7297248423285148

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 229
--------------------------------------------------------------
Epoch:  229        1 Batch loss: 0.188559 Batch F1: 0.6111111111111112
Epoch:  229        2 Batch loss: 0.183229 Batch F1: 0.6500000000000001
Epoch:  229        3 Batch loss: 0.183056 Batch F1: 0.6341463414634146
Epoch:  229        4 Batch loss: 0.196138 Batch F1: 0.7083333333333333
Epoch:  229        5 Batch loss: 0.132833 Batch F1: 0.8108108108108107
Epoch:  229        6 Batch loss: 0.185642 Batch F1: 0.6666666666666666
Epoch:  229        7 Batch loss: 0.241558 Batch F1: 0.5531914893617021
Epoch:  229        8 Batch loss: 0.175959 Batch F1: 0.8148148148148148
Epoch:  229        9 Batch loss: 0.191129 Batch F1: 0.64
Epoch:  229       10 Batch loss: 0.219577 Batch F1: 0.6538461538461537
Epoch:  229       11 Batch loss: 0.159813 Batch F1: 0.7555555555555556
Epoch:  229       12 Batch loss: 0.175295 Batch F1: 0.782608695652174
Train Avg Loss  229: 0.186066

Train Avg F1  229: 0.6900904143846448

Val Avg Loss  229: 0.188146

Val Avg F1  229:  0.6730532870838226

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 230
--------------------------------------------------------------
Epoch:  230        1 Batch loss: 0.159100 Batch F1: 0.761904761904762
Epoch:  230        2 Batch loss: 0.168129 Batch F1: 0.7142857142857143
Epoch:  230        3 Batch loss: 0.190837 Batch F1: 0.6153846153846154
Epoch:  230        4 Batch loss: 0.155362 Batch F1: 0.7916666666666667
Epoch:  230        5 Batch loss: 0.167964 Batch F1: 0.6857142857142857
Epoch:  230        6 Batch loss: 0.182711 Batch F1: 0.7083333333333334
Epoch:  230        7 Batch loss: 0.192885 Batch F1: 0.6363636363636365
Epoch:  230        8 Batch loss: 0.178090 Batch F1: 0.7391304347826089
Epoch:  230        9 Batch loss: 0.170938 Batch F1: 0.761904761904762
Epoch:  230       10 Batch loss: 0.168806 Batch F1: 0.8070175438596491
Epoch:  230       11 Batch loss: 0.200435 Batch F1: 0.6530612244897959
Epoch:  230       12 Batch loss: 0.186481 Batch F1: 0.606060606060606
Train Avg Loss  230: 0.176811

Train Avg F1  230: 0.7067356320625362

Val Avg Loss  230: 0.186016

Val Avg F1  230:  0.674945035222327

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 231
--------------------------------------------------------------
Epoch:  231        1 Batch loss: 0.177791 Batch F1: 0.6956521739130435
Epoch:  231        2 Batch loss: 0.139062 Batch F1: 0.8799999999999999
Epoch:  231        3 Batch loss: 0.155745 Batch F1: 0.8
Epoch:  231        4 Batch loss: 0.203387 Batch F1: 0.6222222222222222
Epoch:  231        5 Batch loss: 0.173388 Batch F1: 0.7234042553191489
Epoch:  231        6 Batch loss: 0.189601 Batch F1: 0.611111111111111
Epoch:  231        7 Batch loss: 0.190957 Batch F1: 0.6792452830188679
Epoch:  231        8 Batch loss: 0.151700 Batch F1: 0.7058823529411765
Epoch:  231        9 Batch loss: 0.170502 Batch F1: 0.75
Epoch:  231       10 Batch loss: 0.172047 Batch F1: 0.6315789473684211
Epoch:  231       11 Batch loss: 0.186411 Batch F1: 0.6153846153846153
Epoch:  231       12 Batch loss: 0.165286 Batch F1: 0.7727272727272727
Train Avg Loss  231: 0.172990

Train Avg F1  231: 0.7072673528338232

Val Avg Loss  231: 0.183919

Val Avg F1  231:  0.6701304182235535

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 232
--------------------------------------------------------------
Epoch:  232        1 Batch loss: 0.156526 Batch F1: 0.761904761904762
Epoch:  232        2 Batch loss: 0.148282 Batch F1: 0.8333333333333334
Epoch:  232        3 Batch loss: 0.172837 Batch F1: 0.7199999999999999
Epoch:  232        4 Batch loss: 0.206962 Batch F1: 0.68
Epoch:  232        5 Batch loss: 0.194967 Batch F1: 0.6808510638297872
Epoch:  232        6 Batch loss: 0.175857 Batch F1: 0.6153846153846153
Epoch:  232        7 Batch loss: 0.171414 Batch F1: 0.6285714285714286
Epoch:  232        8 Batch loss: 0.188518 Batch F1: 0.47058823529411764
Epoch:  232        9 Batch loss: 0.173104 Batch F1: 0.7317073170731708
Epoch:  232       10 Batch loss: 0.155835 Batch F1: 0.8163265306122449
Epoch:  232       11 Batch loss: 0.188669 Batch F1: 0.7547169811320756
Epoch:  232       12 Batch loss: 0.175263 Batch F1: 0.6470588235294117
Train Avg Loss  232: 0.175686

Train Avg F1  232: 0.6950369242220789

Val Avg Loss  232: 0.184038

Val Avg F1  232:  0.6749482401656315

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 233
--------------------------------------------------------------
Epoch:  233        1 Batch loss: 0.152078 Batch F1: 0.8
Epoch:  233        2 Batch loss: 0.188911 Batch F1: 0.68
Epoch:  233        3 Batch loss: 0.165525 Batch F1: 0.7111111111111111
Epoch:  233        4 Batch loss: 0.185189 Batch F1: 0.6818181818181818
Epoch:  233        5 Batch loss: 0.186436 Batch F1: 0.7307692307692308
Epoch:  233        6 Batch loss: 0.170331 Batch F1: 0.6315789473684211
Epoch:  233        7 Batch loss: 0.187797 Batch F1: 0.6
Epoch:  233        8 Batch loss: 0.189223 Batch F1: 0.7037037037037038
Epoch:  233        9 Batch loss: 0.157262 Batch F1: 0.717948717948718
Epoch:  233       10 Batch loss: 0.166972 Batch F1: 0.7659574468085107
Epoch:  233       11 Batch loss: 0.159828 Batch F1: 0.75
Epoch:  233       12 Batch loss: 0.166063 Batch F1: 0.6857142857142857
Train Avg Loss  233: 0.172968

Train Avg F1  233: 0.7048834687701802

Val Avg Loss  233: 0.183191

Val Avg F1  233:  0.6756158524015667

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 234
--------------------------------------------------------------
Epoch:  234        1 Batch loss: 0.178432 Batch F1: 0.6111111111111112
Epoch:  234        2 Batch loss: 0.196822 Batch F1: 0.6923076923076923
Epoch:  234        3 Batch loss: 0.150376 Batch F1: 0.7804878048780488
Epoch:  234        4 Batch loss: 0.192209 Batch F1: 0.7058823529411765
Epoch:  234        5 Batch loss: 0.161758 Batch F1: 0.8148148148148148
Epoch:  234        6 Batch loss: 0.178031 Batch F1: 0.7142857142857143
Epoch:  234        7 Batch loss: 0.159360 Batch F1: 0.7317073170731706
Epoch:  234        8 Batch loss: 0.144343 Batch F1: 0.7692307692307692
Epoch:  234        9 Batch loss: 0.175390 Batch F1: 0.6511627906976745
Epoch:  234       10 Batch loss: 0.163080 Batch F1: 0.7142857142857143
Epoch:  234       11 Batch loss: 0.191864 Batch F1: 0.6222222222222222
Epoch:  234       12 Batch loss: 0.161219 Batch F1: 0.7368421052631579
Train Avg Loss  234: 0.171074

Train Avg F1  234: 0.7120283674259388

Val Avg Loss  234: 0.182713

Val Avg F1  234:  0.6698576427077267

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 235
--------------------------------------------------------------
Epoch:  235        1 Batch loss: 0.168710 Batch F1: 0.6818181818181819
Epoch:  235        2 Batch loss: 0.137864 Batch F1: 0.8333333333333333
Epoch:  235        3 Batch loss: 0.195821 Batch F1: 0.6521739130434783
Epoch:  235        4 Batch loss: 0.194852 Batch F1: 0.5853658536585366
Epoch:  235        5 Batch loss: 0.156873 Batch F1: 0.7058823529411765
Epoch:  235        6 Batch loss: 0.217668 Batch F1: 0.5238095238095238
Epoch:  235        7 Batch loss: 0.127979 Batch F1: 0.8780487804878048
Epoch:  235        8 Batch loss: 0.172254 Batch F1: 0.7391304347826085
Epoch:  235        9 Batch loss: 0.170629 Batch F1: 0.723404255319149
Epoch:  235       10 Batch loss: 0.168036 Batch F1: 0.75
Epoch:  235       11 Batch loss: 0.155830 Batch F1: 0.7755102040816326
Epoch:  235       12 Batch loss: 0.190300 Batch F1: 0.6666666666666667
Train Avg Loss  235: 0.171401

Train Avg F1  235: 0.709595291661841

Val Avg Loss  235: 0.182567

Val Avg F1  235:  0.6778286749482402

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 236
--------------------------------------------------------------
Epoch:  236        1 Batch loss: 0.186752 Batch F1: 0.7083333333333333
Epoch:  236        2 Batch loss: 0.179707 Batch F1: 0.6818181818181819
Epoch:  236        3 Batch loss: 0.156511 Batch F1: 0.5517241379310345
Epoch:  236        4 Batch loss: 0.155528 Batch F1: 0.7
Epoch:  236        5 Batch loss: 0.144127 Batch F1: 0.851063829787234
Epoch:  236        6 Batch loss: 0.162105 Batch F1: 0.7500000000000001
Epoch:  236        7 Batch loss: 0.184731 Batch F1: 0.6956521739130435
Epoch:  236        8 Batch loss: 0.174125 Batch F1: 0.6976744186046512
Epoch:  236        9 Batch loss: 0.165968 Batch F1: 0.7755102040816326
Epoch:  236       10 Batch loss: 0.199682 Batch F1: 0.6382978723404256
Epoch:  236       11 Batch loss: 0.173799 Batch F1: 0.711111111111111
Epoch:  236       12 Batch loss: 0.175738 Batch F1: 0.717948717948718
Train Avg Loss  236: 0.171564

Train Avg F1  236: 0.7065944984057806

Val Avg Loss  236: 0.181644

Val Avg F1  236:  0.6782819510783037

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 237
--------------------------------------------------------------
Epoch:  237        1 Batch loss: 0.158923 Batch F1: 0.7317073170731707
Epoch:  237        2 Batch loss: 0.174222 Batch F1: 0.6842105263157896
Epoch:  237        3 Batch loss: 0.159533 Batch F1: 0.7142857142857143
Epoch:  237        4 Batch loss: 0.181740 Batch F1: 0.7450980392156863
Epoch:  237        5 Batch loss: 0.181092 Batch F1: 0.6808510638297872
Epoch:  237        6 Batch loss: 0.186681 Batch F1: 0.6530612244897959
Epoch:  237        7 Batch loss: 0.157643 Batch F1: 0.717948717948718
Epoch:  237        8 Batch loss: 0.185974 Batch F1: 0.7407407407407408
Epoch:  237        9 Batch loss: 0.178012 Batch F1: 0.6818181818181818
Epoch:  237       10 Batch loss: 0.137232 Batch F1: 0.8444444444444444
Epoch:  237       11 Batch loss: 0.178876 Batch F1: 0.6511627906976744
Epoch:  237       12 Batch loss: 0.182572 Batch F1: 0.6875000000000001
Train Avg Loss  237: 0.171875

Train Avg F1  237: 0.7110690634049753

Val Avg Loss  237: 0.181693

Val Avg F1  237:  0.6796544446576256

Optimal Val loss (Epoch 151): 0.18161199986934662

Epoch 238
--------------------------------------------------------------
Epoch:  238        1 Batch loss: 0.140851 Batch F1: 0.8444444444444444
Epoch:  238        2 Batch loss: 0.173054 Batch F1: 0.75
Epoch:  238        3 Batch loss: 0.186318 Batch F1: 0.7083333333333334
Epoch:  238        4 Batch loss: 0.169796 Batch F1: 0.7843137254901961
Epoch:  238        5 Batch loss: 0.184906 Batch F1: 0.5641025641025642
Epoch:  238        6 Batch loss: 0.164135 Batch F1: 0.6470588235294118
Epoch:  238        7 Batch loss: 0.203021 Batch F1: 0.6666666666666666
Epoch:  238        8 Batch loss: 0.161172 Batch F1: 0.6666666666666667
Epoch:  238        9 Batch loss: 0.152936 Batch F1: 0.7826086956521738
Epoch:  238       10 Batch loss: 0.188906 Batch F1: 0.6382978723404256
Epoch:  238       11 Batch loss: 0.191480 Batch F1: 0.6046511627906977
Epoch:  238       12 Batch loss: 0.122501 Batch F1: 0.8888888888888888
Train Avg Loss  238: 0.169923

Train Avg F1  238: 0.7121694036587892

Val Avg Loss  238: 0.181428

Val Avg F1  238:  0.6781673114119923

Optimal Val loss (Epoch 238): 0.18142827600240707

Epoch 239
--------------------------------------------------------------
Epoch:  239        1 Batch loss: 0.137298 Batch F1: 0.8444444444444444
Epoch:  239        2 Batch loss: 0.172380 Batch F1: 0.7692307692307692
Epoch:  239        3 Batch loss: 0.179941 Batch F1: 0.72
Epoch:  239        4 Batch loss: 0.164877 Batch F1: 0.7142857142857143
Epoch:  239        5 Batch loss: 0.157242 Batch F1: 0.7391304347826088
Epoch:  239        6 Batch loss: 0.166117 Batch F1: 0.6976744186046512
Epoch:  239        7 Batch loss: 0.178608 Batch F1: 0.6341463414634146
Epoch:  239        8 Batch loss: 0.182150 Batch F1: 0.6
Epoch:  239        9 Batch loss: 0.177690 Batch F1: 0.7142857142857143
Epoch:  239       10 Batch loss: 0.197451 Batch F1: 0.7142857142857142
Epoch:  239       11 Batch loss: 0.134429 Batch F1: 0.8571428571428571
Epoch:  239       12 Batch loss: 0.193100 Batch F1: 0.4
Train Avg Loss  239: 0.170107

Train Avg F1  239: 0.7003855340438241

Val Avg Loss  239: 0.182649

Val Avg F1  239:  0.676151610017889

Optimal Val loss (Epoch 238): 0.18142827600240707

Epoch 240
--------------------------------------------------------------
Epoch:  240        1 Batch loss: 0.169369 Batch F1: 0.75
Epoch:  240        2 Batch loss: 0.134706 Batch F1: 0.7804878048780488
Epoch:  240        3 Batch loss: 0.144691 Batch F1: 0.75
Epoch:  240        4 Batch loss: 0.172426 Batch F1: 0.32000000000000006
Epoch:  240        5 Batch loss: 0.191741 Batch F1: 0.5806451612903226
Epoch:  240        6 Batch loss: 0.190585 Batch F1: 0.6808510638297872
Epoch:  240        7 Batch loss: 0.233989 Batch F1: 0.5238095238095238
Epoch:  240        8 Batch loss: 0.156627 Batch F1: 0.8085106382978724
Epoch:  240        9 Batch loss: 0.190158 Batch F1: 0.6086956521739131
Epoch:  240       10 Batch loss: 0.165744 Batch F1: 0.8363636363636364
Epoch:  240       11 Batch loss: 0.177984 Batch F1: 0.8163265306122449
Epoch:  240       12 Batch loss: 0.160482 Batch F1: 0.8636363636363636
Train Avg Loss  240: 0.174042

Train Avg F1  240: 0.6932771979076429

Val Avg Loss  240: 0.184749

Val Avg F1  240:  0.7676298937434587

Optimal Val loss (Epoch 238): 0.18142827600240707

Epoch 241
--------------------------------------------------------------
Epoch:  241        1 Batch loss: 0.163389 Batch F1: 0.8181818181818182
Epoch:  241        2 Batch loss: 0.165561 Batch F1: 0.8085106382978724
Epoch:  241        3 Batch loss: 0.174398 Batch F1: 0.7272727272727272
Epoch:  241        4 Batch loss: 0.164016 Batch F1: 0.7
Epoch:  241        5 Batch loss: 0.222374 Batch F1: 0.5416666666666667
Epoch:  241        6 Batch loss: 0.181401 Batch F1: 0.7083333333333333
Epoch:  241        7 Batch loss: 0.162553 Batch F1: 0.7441860465116279
Epoch:  241        8 Batch loss: 0.191014 Batch F1: 0.5789473684210527
Epoch:  241        9 Batch loss: 0.166216 Batch F1: 0.7
Epoch:  241       10 Batch loss: 0.173266 Batch F1: 0.7083333333333334
Epoch:  241       11 Batch loss: 0.152781 Batch F1: 0.8085106382978724
Epoch:  241       12 Batch loss: 0.162016 Batch F1: 0.8095238095238095
Train Avg Loss  241: 0.173249

Train Avg F1  241: 0.7211221983200095

Val Avg Loss  241: 0.183666

Val Avg F1  241:  0.6682030548068284

Optimal Val loss (Epoch 238): 0.18142827600240707

Epoch 242
--------------------------------------------------------------
Epoch:  242        1 Batch loss: 0.141378 Batch F1: 0.8095238095238095
Epoch:  242        2 Batch loss: 0.183547 Batch F1: 0.7169811320754718
Epoch:  242        3 Batch loss: 0.163821 Batch F1: 0.7499999999999999
Epoch:  242        4 Batch loss: 0.167413 Batch F1: 0.7391304347826085
Epoch:  242        5 Batch loss: 0.182199 Batch F1: 0.5882352941176471
Epoch:  242        6 Batch loss: 0.180950 Batch F1: 0.6153846153846154
Epoch:  242        7 Batch loss: 0.178383 Batch F1: 0.7391304347826088
Epoch:  242        8 Batch loss: 0.165585 Batch F1: 0.7142857142857143
Epoch:  242        9 Batch loss: 0.143144 Batch F1: 0.8333333333333333
Epoch:  242       10 Batch loss: 0.179585 Batch F1: 0.6511627906976744
Epoch:  242       11 Batch loss: 0.224797 Batch F1: 0.5490196078431373
Epoch:  242       12 Batch loss: 0.165549 Batch F1: 0.7906976744186046
Train Avg Loss  242: 0.173029

Train Avg F1  242: 0.7080737367704354

Val Avg Loss  242: 0.181565

Val Avg F1  242:  0.6689465408805031

Optimal Val loss (Epoch 238): 0.18142827600240707

Epoch 243
--------------------------------------------------------------
Epoch:  243        1 Batch loss: 0.178807 Batch F1: 0.6818181818181818
Epoch:  243        2 Batch loss: 0.153968 Batch F1: 0.7826086956521738
Epoch:  243        3 Batch loss: 0.148304 Batch F1: 0.84
Epoch:  243        4 Batch loss: 0.186802 Batch F1: 0.6
Epoch:  243        5 Batch loss: 0.178041 Batch F1: 0.6511627906976745
Epoch:  243        6 Batch loss: 0.168362 Batch F1: 0.6666666666666666
Epoch:  243        7 Batch loss: 0.203175 Batch F1: 0.6296296296296297
Epoch:  243        8 Batch loss: 0.166357 Batch F1: 0.7555555555555556
Epoch:  243        9 Batch loss: 0.144409 Batch F1: 0.8095238095238095
Epoch:  243       10 Batch loss: 0.174783 Batch F1: 0.6857142857142857
Epoch:  243       11 Batch loss: 0.172229 Batch F1: 0.7272727272727272
Epoch:  243       12 Batch loss: 0.186826 Batch F1: 0.7000000000000001
Train Avg Loss  243: 0.171838

Train Avg F1  243: 0.7108293618775586

Val Avg Loss  243: 0.187445

Val Avg F1  243:  0.6756649147953496

Optimal Val loss (Epoch 238): 0.18142827600240707

Epoch 244
--------------------------------------------------------------
Epoch:  244        1 Batch loss: 0.159076 Batch F1: 0.7916666666666667
Epoch:  244        2 Batch loss: 0.174058 Batch F1: 0.7777777777777778
Epoch:  244        3 Batch loss: 0.163118 Batch F1: 0.7555555555555556
Epoch:  244        4 Batch loss: 0.213105 Batch F1: 0.5957446808510639
Epoch:  244        5 Batch loss: 0.158077 Batch F1: 0.7272727272727272
Epoch:  244        6 Batch loss: 0.162344 Batch F1: 0.7391304347826088
Epoch:  244        7 Batch loss: 0.156432 Batch F1: 0.717948717948718
Epoch:  244        8 Batch loss: 0.184618 Batch F1: 0.6956521739130435
Epoch:  244        9 Batch loss: 0.170495 Batch F1: 0.7142857142857143
Epoch:  244       10 Batch loss: 0.163888 Batch F1: 0.6842105263157896
Epoch:  244       11 Batch loss: 0.163434 Batch F1: 0.7000000000000001
Epoch:  244       12 Batch loss: 0.198832 Batch F1: 0.6111111111111112
Train Avg Loss  244: 0.172290

Train Avg F1  244: 0.7091963405400646

Val Avg Loss  244: 0.183936

Val Avg F1  244:  0.6678356163650282

Optimal Val loss (Epoch 238): 0.18142827600240707

Epoch 245
--------------------------------------------------------------
Epoch:  245        1 Batch loss: 0.157338 Batch F1: 0.7272727272727272
Epoch:  245        2 Batch loss: 0.152411 Batch F1: 0.816326530612245
Epoch:  245        3 Batch loss: 0.193905 Batch F1: 0.5
Epoch:  245        4 Batch loss: 0.181244 Batch F1: 0.7547169811320754
Epoch:  245        5 Batch loss: 0.183819 Batch F1: 0.7307692307692308
Epoch:  245        6 Batch loss: 0.144467 Batch F1: 0.8000000000000002
Epoch:  245        7 Batch loss: 0.185141 Batch F1: 0.6
Epoch:  245        8 Batch loss: 0.176228 Batch F1: 0.6666666666666665
Epoch:  245        9 Batch loss: 0.166944 Batch F1: 0.6829268292682926
Epoch:  245       10 Batch loss: 0.170701 Batch F1: 0.6315789473684211
Epoch:  245       11 Batch loss: 0.181901 Batch F1: 0.7346938775510203
Epoch:  245       12 Batch loss: 0.141016 Batch F1: 0.8421052631578948
Train Avg Loss  245: 0.169593

Train Avg F1  245: 0.7072547544832144

Val Avg Loss  245: 0.181165

Val Avg F1  245:  0.6686582809224318

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 246
--------------------------------------------------------------
Epoch:  246        1 Batch loss: 0.174440 Batch F1: 0.7083333333333334
Epoch:  246        2 Batch loss: 0.157744 Batch F1: 0.7027027027027026
Epoch:  246        3 Batch loss: 0.180225 Batch F1: 0.6666666666666666
Epoch:  246        4 Batch loss: 0.176380 Batch F1: 0.711111111111111
Epoch:  246        5 Batch loss: 0.164073 Batch F1: 0.7924528301886792
Epoch:  246        6 Batch loss: 0.144137 Batch F1: 0.823529411764706
Epoch:  246        7 Batch loss: 0.183882 Batch F1: 0.6500000000000001
Epoch:  246        8 Batch loss: 0.158778 Batch F1: 0.7096774193548387
Epoch:  246        9 Batch loss: 0.182395 Batch F1: 0.693877551020408
Epoch:  246       10 Batch loss: 0.160750 Batch F1: 0.7659574468085107
Epoch:  246       11 Batch loss: 0.184269 Batch F1: 0.6511627906976744
Epoch:  246       12 Batch loss: 0.177438 Batch F1: 0.606060606060606
Train Avg Loss  246: 0.170376

Train Avg F1  246: 0.7067943224757699

Val Avg Loss  246: 0.182085

Val Avg F1  246:  0.6722456116902789

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 247
--------------------------------------------------------------
Epoch:  247        1 Batch loss: 0.171170 Batch F1: 0.6829268292682927
Epoch:  247        2 Batch loss: 0.174519 Batch F1: 0.6818181818181818
Epoch:  247        3 Batch loss: 0.198325 Batch F1: 0.6666666666666666
Epoch:  247        4 Batch loss: 0.161691 Batch F1: 0.7272727272727274
Epoch:  247        5 Batch loss: 0.167077 Batch F1: 0.7755102040816326
Epoch:  247        6 Batch loss: 0.158395 Batch F1: 0.7755102040816326
Epoch:  247        7 Batch loss: 0.144238 Batch F1: 0.8
Epoch:  247        8 Batch loss: 0.205198 Batch F1: 0.5116279069767442
Epoch:  247        9 Batch loss: 0.188625 Batch F1: 0.6666666666666666
Epoch:  247       10 Batch loss: 0.167758 Batch F1: 0.6666666666666666
Epoch:  247       11 Batch loss: 0.168591 Batch F1: 0.7755102040816326
Epoch:  247       12 Batch loss: 0.159524 Batch F1: 0.7428571428571428
Train Avg Loss  247: 0.172093

Train Avg F1  247: 0.7060861167031655

Val Avg Loss  247: 0.183174

Val Avg F1  247:  0.6696395389058264

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 248
--------------------------------------------------------------
Epoch:  248        1 Batch loss: 0.143945 Batch F1: 0.8181818181818182
Epoch:  248        2 Batch loss: 0.143301 Batch F1: 0.8372093023255814
Epoch:  248        3 Batch loss: 0.162710 Batch F1: 0.7234042553191491
Epoch:  248        4 Batch loss: 0.174616 Batch F1: 0.7272727272727272
Epoch:  248        5 Batch loss: 0.177075 Batch F1: 0.6938775510204083
Epoch:  248        6 Batch loss: 0.179292 Batch F1: 0.6666666666666666
Epoch:  248        7 Batch loss: 0.206308 Batch F1: 0.5833333333333334
Epoch:  248        8 Batch loss: 0.182988 Batch F1: 0.6956521739130435
Epoch:  248        9 Batch loss: 0.169440 Batch F1: 0.6111111111111113
Epoch:  248       10 Batch loss: 0.160774 Batch F1: 0.7555555555555555
Epoch:  248       11 Batch loss: 0.159041 Batch F1: 0.7499999999999999
Epoch:  248       12 Batch loss: 0.193921 Batch F1: 0.6829268292682926
Train Avg Loss  248: 0.171118

Train Avg F1  248: 0.7120992769973072

Val Avg Loss  248: 0.184338

Val Avg F1  248:  0.6747565165723733

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 249
--------------------------------------------------------------
Epoch:  249        1 Batch loss: 0.180736 Batch F1: 0.7083333333333333
Epoch:  249        2 Batch loss: 0.201091 Batch F1: 0.7037037037037037
Epoch:  249        3 Batch loss: 0.166173 Batch F1: 0.761904761904762
Epoch:  249        4 Batch loss: 0.167676 Batch F1: 0.7500000000000001
Epoch:  249        5 Batch loss: 0.152430 Batch F1: 0.7906976744186046
Epoch:  249        6 Batch loss: 0.178162 Batch F1: 0.5641025641025641
Epoch:  249        7 Batch loss: 0.162830 Batch F1: 0.7555555555555555
Epoch:  249        8 Batch loss: 0.161158 Batch F1: 0.7
Epoch:  249        9 Batch loss: 0.186654 Batch F1: 0.7272727272727274
Epoch:  249       10 Batch loss: 0.164930 Batch F1: 0.6500000000000001
Epoch:  249       11 Batch loss: 0.167251 Batch F1: 0.606060606060606
Epoch:  249       12 Batch loss: 0.156304 Batch F1: 0.7894736842105262
Train Avg Loss  249: 0.170450

Train Avg F1  249: 0.7089253842135319

Val Avg Loss  249: 0.181495

Val Avg F1  249:  0.6654984799498143

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 250
--------------------------------------------------------------
Epoch:  250        1 Batch loss: 0.146760 Batch F1: 0.7804878048780488
Epoch:  250        2 Batch loss: 0.165913 Batch F1: 0.7450980392156864
Epoch:  250        3 Batch loss: 0.130583 Batch F1: 0.8292682926829269
Epoch:  250        4 Batch loss: 0.147524 Batch F1: 0.8
Epoch:  250        5 Batch loss: 0.179729 Batch F1: 0.7796610169491527
Epoch:  250        6 Batch loss: 0.205810 Batch F1: 0.5833333333333334
Epoch:  250        7 Batch loss: 0.152007 Batch F1: 0.8148148148148148
Epoch:  250        8 Batch loss: 0.205658 Batch F1: 0.5
Epoch:  250        9 Batch loss: 0.186707 Batch F1: 0.6190476190476191
Epoch:  250       10 Batch loss: 0.181549 Batch F1: 0.5641025641025641
Epoch:  250       11 Batch loss: 0.174410 Batch F1: 0.6666666666666667
Epoch:  250       12 Batch loss: 0.149527 Batch F1: 0.7647058823529411
Train Avg Loss  250: 0.168848

Train Avg F1  250: 0.7039321695036462

Val Avg Loss  250: 0.185581

Val Avg F1  250:  0.6533973273103708

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 251
--------------------------------------------------------------
Epoch:  251        1 Batch loss: 0.169564 Batch F1: 0.6470588235294118
Epoch:  251        2 Batch loss: 0.178878 Batch F1: 0.7272727272727272
Epoch:  251        3 Batch loss: 0.180886 Batch F1: 0.6
Epoch:  251        4 Batch loss: 0.181252 Batch F1: 0.48484848484848486
Epoch:  251        5 Batch loss: 0.181050 Batch F1: 0.5
Epoch:  251        6 Batch loss: 0.209938 Batch F1: 0.32
Epoch:  251        7 Batch loss: 0.180371 Batch F1: 0.6470588235294118
Epoch:  251        8 Batch loss: 0.210522 Batch F1: 0.6190476190476191
Epoch:  251        9 Batch loss: 0.182764 Batch F1: 0.6909090909090909
Epoch:  251       10 Batch loss: 0.212031 Batch F1: 0.7076923076923077
Epoch:  251       11 Batch loss: 0.159455 Batch F1: 0.7931034482758621
Epoch:  251       12 Batch loss: 0.177252 Batch F1: 0.6250000000000001
Train Avg Loss  251: 0.185330

Train Avg F1  251: 0.6134992770920763

Val Avg Loss  251: 0.189044

Val Avg F1  251:  0.6797889610389609

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 252
--------------------------------------------------------------
Epoch:  252        1 Batch loss: 0.167327 Batch F1: 0.7826086956521738
Epoch:  252        2 Batch loss: 0.205880 Batch F1: 0.7058823529411765
Epoch:  252        3 Batch loss: 0.170976 Batch F1: 0.7027027027027027
Epoch:  252        4 Batch loss: 0.172320 Batch F1: 0.7
Epoch:  252        5 Batch loss: 0.199589 Batch F1: 0.6923076923076923
Epoch:  252        6 Batch loss: 0.184231 Batch F1: 0.7234042553191491
Epoch:  252        7 Batch loss: 0.165254 Batch F1: 0.7755102040816326
Epoch:  252        8 Batch loss: 0.166950 Batch F1: 0.6486486486486486
Epoch:  252        9 Batch loss: 0.176278 Batch F1: 0.5161290322580645
Epoch:  252       10 Batch loss: 0.176072 Batch F1: 0.7659574468085107
Epoch:  252       11 Batch loss: 0.189721 Batch F1: 0.782608695652174
Epoch:  252       12 Batch loss: 0.200019 Batch F1: 0.6666666666666667
Train Avg Loss  252: 0.181218

Train Avg F1  252: 0.7052021994198826

Val Avg Loss  252: 0.185092

Val Avg F1  252:  0.6642857142857143

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 253
--------------------------------------------------------------
Epoch:  253        1 Batch loss: 0.179668 Batch F1: 0.6956521739130435
Epoch:  253        2 Batch loss: 0.200428 Batch F1: 0.6382978723404256
Epoch:  253        3 Batch loss: 0.179487 Batch F1: 0.7234042553191489
Epoch:  253        4 Batch loss: 0.175622 Batch F1: 0.761904761904762
Epoch:  253        5 Batch loss: 0.173381 Batch F1: 0.6818181818181819
Epoch:  253        6 Batch loss: 0.157363 Batch F1: 0.782608695652174
Epoch:  253        7 Batch loss: 0.150150 Batch F1: 0.7500000000000001
Epoch:  253        8 Batch loss: 0.167217 Batch F1: 0.6666666666666667
Epoch:  253        9 Batch loss: 0.178966 Batch F1: 0.7000000000000001
Epoch:  253       10 Batch loss: 0.154202 Batch F1: 0.7999999999999999
Epoch:  253       11 Batch loss: 0.165903 Batch F1: 0.7843137254901961
Epoch:  253       12 Batch loss: 0.229668 Batch F1: 0.5263157894736842
Train Avg Loss  253: 0.176005

Train Avg F1  253: 0.7092485102148568

Val Avg Loss  253: 0.185692

Val Avg F1  253:  0.6707076529006907

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 254
--------------------------------------------------------------
Epoch:  254        1 Batch loss: 0.198974 Batch F1: 0.6399999999999999
Epoch:  254        2 Batch loss: 0.191861 Batch F1: 0.7083333333333334
Epoch:  254        3 Batch loss: 0.175324 Batch F1: 0.7234042553191491
Epoch:  254        4 Batch loss: 0.156417 Batch F1: 0.7894736842105262
Epoch:  254        5 Batch loss: 0.176121 Batch F1: 0.7027027027027027
Epoch:  254        6 Batch loss: 0.177906 Batch F1: 0.6486486486486486
Epoch:  254        7 Batch loss: 0.189523 Batch F1: 0.7407407407407407
Epoch:  254        8 Batch loss: 0.160287 Batch F1: 0.8333333333333333
Epoch:  254        9 Batch loss: 0.176023 Batch F1: 0.6938775510204083
Epoch:  254       10 Batch loss: 0.165484 Batch F1: 0.7999999999999999
Epoch:  254       11 Batch loss: 0.196696 Batch F1: 0.5853658536585366
Epoch:  254       12 Batch loss: 0.196651 Batch F1: 0.7222222222222222
Train Avg Loss  254: 0.180106

Train Avg F1  254: 0.7156751937657999

Val Avg Loss  254: 0.189966

Val Avg F1  254:  0.6700370744860128

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 255
--------------------------------------------------------------
Epoch:  255        1 Batch loss: 0.189260 Batch F1: 0.7083333333333333
Epoch:  255        2 Batch loss: 0.174160 Batch F1: 0.6111111111111112
Epoch:  255        3 Batch loss: 0.184613 Batch F1: 0.7755102040816326
Epoch:  255        4 Batch loss: 0.196358 Batch F1: 0.6818181818181818
Epoch:  255        5 Batch loss: 0.169187 Batch F1: 0.711111111111111
Epoch:  255        6 Batch loss: 0.202793 Batch F1: 0.5142857142857142
Epoch:  255        7 Batch loss: 0.165062 Batch F1: 0.75
Epoch:  255        8 Batch loss: 0.172305 Batch F1: 0.7
Epoch:  255        9 Batch loss: 0.175328 Batch F1: 0.7843137254901961
Epoch:  255       10 Batch loss: 0.203533 Batch F1: 0.6363636363636365
Epoch:  255       11 Batch loss: 0.175360 Batch F1: 0.72
Epoch:  255       12 Batch loss: 0.146390 Batch F1: 0.8205128205128205
Train Avg Loss  255: 0.179529

Train Avg F1  255: 0.7011133198423115

Val Avg Loss  255: 0.185349

Val Avg F1  255:  0.6769134755404778

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 256
--------------------------------------------------------------
Epoch:  256        1 Batch loss: 0.181499 Batch F1: 0.631578947368421
Epoch:  256        2 Batch loss: 0.184454 Batch F1: 0.7199999999999999
Epoch:  256        3 Batch loss: 0.154881 Batch F1: 0.7826086956521738
Epoch:  256        4 Batch loss: 0.172373 Batch F1: 0.5625000000000001
Epoch:  256        5 Batch loss: 0.176141 Batch F1: 0.7450980392156864
Epoch:  256        6 Batch loss: 0.182038 Batch F1: 0.6153846153846153
Epoch:  256        7 Batch loss: 0.168505 Batch F1: 0.75
Epoch:  256        8 Batch loss: 0.186308 Batch F1: 0.6956521739130435
Epoch:  256        9 Batch loss: 0.159670 Batch F1: 0.8148148148148148
Epoch:  256       10 Batch loss: 0.174094 Batch F1: 0.7391304347826088
Epoch:  256       11 Batch loss: 0.166490 Batch F1: 0.7555555555555556
Epoch:  256       12 Batch loss: 0.161612 Batch F1: 0.6206896551724139
Train Avg Loss  256: 0.172339

Train Avg F1  256: 0.7027510776549444

Val Avg Loss  256: 0.183629

Val Avg F1  256:  0.6769750948375393

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 257
--------------------------------------------------------------
Epoch:  257        1 Batch loss: 0.161028 Batch F1: 0.7659574468085107
Epoch:  257        2 Batch loss: 0.169972 Batch F1: 0.7857142857142857
Epoch:  257        3 Batch loss: 0.157247 Batch F1: 0.7843137254901961
Epoch:  257        4 Batch loss: 0.190016 Batch F1: 0.6666666666666666
Epoch:  257        5 Batch loss: 0.216580 Batch F1: 0.4864864864864865
Epoch:  257        6 Batch loss: 0.191350 Batch F1: 0.5714285714285715
Epoch:  257        7 Batch loss: 0.179470 Batch F1: 0.6666666666666666
Epoch:  257        8 Batch loss: 0.171433 Batch F1: 0.7317073170731707
Epoch:  257        9 Batch loss: 0.171032 Batch F1: 0.7346938775510204
Epoch:  257       10 Batch loss: 0.159324 Batch F1: 0.7368421052631579
Epoch:  257       11 Batch loss: 0.151133 Batch F1: 0.7906976744186046
Epoch:  257       12 Batch loss: 0.139396 Batch F1: 0.7741935483870969
Train Avg Loss  257: 0.171498

Train Avg F1  257: 0.7079473643295361

Val Avg Loss  257: 0.182856

Val Avg F1  257:  0.6749887617920334

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 258
--------------------------------------------------------------
Epoch:  258        1 Batch loss: 0.158489 Batch F1: 0.7755102040816326
Epoch:  258        2 Batch loss: 0.189912 Batch F1: 0.6363636363636365
Epoch:  258        3 Batch loss: 0.131161 Batch F1: 0.7647058823529411
Epoch:  258        4 Batch loss: 0.152987 Batch F1: 0.7499999999999999
Epoch:  258        5 Batch loss: 0.181162 Batch F1: 0.5789473684210527
Epoch:  258        6 Batch loss: 0.154602 Batch F1: 0.761904761904762
Epoch:  258        7 Batch loss: 0.214005 Batch F1: 0.5714285714285715
Epoch:  258        8 Batch loss: 0.185762 Batch F1: 0.7843137254901961
Epoch:  258        9 Batch loss: 0.177726 Batch F1: 0.7547169811320754
Epoch:  258       10 Batch loss: 0.195176 Batch F1: 0.6666666666666666
Epoch:  258       11 Batch loss: 0.185127 Batch F1: 0.6829268292682926
Epoch:  258       12 Batch loss: 0.183481 Batch F1: 0.625
Train Avg Loss  258: 0.175799

Train Avg F1  258: 0.6960403855924856

Val Avg Loss  258: 0.189092

Val Avg F1  258:  0.6641011443337025

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 259
--------------------------------------------------------------
Epoch:  259        1 Batch loss: 0.201414 Batch F1: 0.6046511627906976
Epoch:  259        2 Batch loss: 0.196356 Batch F1: 0.6153846153846154
Epoch:  259        3 Batch loss: 0.139698 Batch F1: 0.8979591836734694
Epoch:  259        4 Batch loss: 0.152420 Batch F1: 0.851063829787234
Epoch:  259        5 Batch loss: 0.202533 Batch F1: 0.6363636363636365
Epoch:  259        6 Batch loss: 0.176330 Batch F1: 0.8
Epoch:  259        7 Batch loss: 0.193939 Batch F1: 0.6341463414634148
Epoch:  259        8 Batch loss: 0.181090 Batch F1: 0.7692307692307692
Epoch:  259        9 Batch loss: 0.176518 Batch F1: 0.6666666666666667
Epoch:  259       10 Batch loss: 0.202664 Batch F1: 0.6222222222222223
Epoch:  259       11 Batch loss: 0.165990 Batch F1: 0.7555555555555555
Epoch:  259       12 Batch loss: 0.183166 Batch F1: 0.5806451612903225
Train Avg Loss  259: 0.181010

Train Avg F1  259: 0.7028240953690502

Val Avg Loss  259: 0.187279

Val Avg F1  259:  0.6736821537125488

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 260
--------------------------------------------------------------
Epoch:  260        1 Batch loss: 0.189683 Batch F1: 0.6666666666666666
Epoch:  260        2 Batch loss: 0.177597 Batch F1: 0.6956521739130435
Epoch:  260        3 Batch loss: 0.179127 Batch F1: 0.7500000000000001
Epoch:  260        4 Batch loss: 0.168032 Batch F1: 0.7441860465116279
Epoch:  260        5 Batch loss: 0.192133 Batch F1: 0.6190476190476191
Epoch:  260        6 Batch loss: 0.173598 Batch F1: 0.6829268292682926
Epoch:  260        7 Batch loss: 0.186187 Batch F1: 0.6190476190476191
Epoch:  260        8 Batch loss: 0.168273 Batch F1: 0.7555555555555555
Epoch:  260        9 Batch loss: 0.151229 Batch F1: 0.75
Epoch:  260       10 Batch loss: 0.179812 Batch F1: 0.7234042553191491
Epoch:  260       11 Batch loss: 0.178141 Batch F1: 0.6666666666666666
Epoch:  260       12 Batch loss: 0.144210 Batch F1: 0.8636363636363636
Train Avg Loss  260: 0.174002

Train Avg F1  260: 0.7113991496360503

Val Avg Loss  260: 0.183495

Val Avg F1  260:  0.6709666639980228

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 261
--------------------------------------------------------------
Epoch:  261        1 Batch loss: 0.158094 Batch F1: 0.7142857142857143
Epoch:  261        2 Batch loss: 0.198375 Batch F1: 0.7037037037037037
Epoch:  261        3 Batch loss: 0.212852 Batch F1: 0.6
Epoch:  261        4 Batch loss: 0.128272 Batch F1: 0.888888888888889
Epoch:  261        5 Batch loss: 0.205082 Batch F1: 0.6363636363636365
Epoch:  261        6 Batch loss: 0.165231 Batch F1: 0.6857142857142857
Epoch:  261        7 Batch loss: 0.186708 Batch F1: 0.6666666666666666
Epoch:  261        8 Batch loss: 0.155020 Batch F1: 0.8260869565217391
Epoch:  261        9 Batch loss: 0.173663 Batch F1: 0.6511627906976745
Epoch:  261       10 Batch loss: 0.155966 Batch F1: 0.7555555555555555
Epoch:  261       11 Batch loss: 0.158684 Batch F1: 0.6842105263157895
Epoch:  261       12 Batch loss: 0.174177 Batch F1: 0.7317073170731706
Train Avg Loss  261: 0.172677

Train Avg F1  261: 0.7120288368155688

Val Avg Loss  261: 0.183403

Val Avg F1  261:  0.6720125786163522

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 262
--------------------------------------------------------------
Epoch:  262        1 Batch loss: 0.181436 Batch F1: 0.7142857142857143
Epoch:  262        2 Batch loss: 0.189800 Batch F1: 0.6382978723404256
Epoch:  262        3 Batch loss: 0.166487 Batch F1: 0.6829268292682926
Epoch:  262        4 Batch loss: 0.153829 Batch F1: 0.7441860465116279
Epoch:  262        5 Batch loss: 0.189419 Batch F1: 0.7307692307692308
Epoch:  262        6 Batch loss: 0.194361 Batch F1: 0.6923076923076923
Epoch:  262        7 Batch loss: 0.171879 Batch F1: 0.7272727272727272
Epoch:  262        8 Batch loss: 0.147014 Batch F1: 0.7906976744186046
Epoch:  262        9 Batch loss: 0.144296 Batch F1: 0.8108108108108109
Epoch:  262       10 Batch loss: 0.169984 Batch F1: 0.7450980392156863
Epoch:  262       11 Batch loss: 0.176356 Batch F1: 0.6666666666666666
Epoch:  262       12 Batch loss: 0.178395 Batch F1: 0.5806451612903225
Train Avg Loss  262: 0.171938

Train Avg F1  262: 0.7103303720964834

Val Avg Loss  262: 0.185650

Val Avg F1  262:  0.645195366282106

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 263
--------------------------------------------------------------
Epoch:  263        1 Batch loss: 0.167617 Batch F1: 0.7
Epoch:  263        2 Batch loss: 0.145757 Batch F1: 0.689655172413793
Epoch:  263        3 Batch loss: 0.190159 Batch F1: 0.6666666666666666
Epoch:  263        4 Batch loss: 0.186121 Batch F1: 0.72
Epoch:  263        5 Batch loss: 0.211253 Batch F1: 0.6122448979591836
Epoch:  263        6 Batch loss: 0.184597 Batch F1: 0.711111111111111
Epoch:  263        7 Batch loss: 0.139847 Batch F1: 0.8636363636363636
Epoch:  263        8 Batch loss: 0.198771 Batch F1: 0.6086956521739131
Epoch:  263        9 Batch loss: 0.150635 Batch F1: 0.8
Epoch:  263       10 Batch loss: 0.189669 Batch F1: 0.5641025641025641
Epoch:  263       11 Batch loss: 0.155457 Batch F1: 0.816326530612245
Epoch:  263       12 Batch loss: 0.160436 Batch F1: 0.7692307692307692
Train Avg Loss  263: 0.173360

Train Avg F1  263: 0.7101391439922174

Val Avg Loss  263: 0.182767

Val Avg F1  263:  0.6786184392456169

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 264
--------------------------------------------------------------
Epoch:  264        1 Batch loss: 0.145106 Batch F1: 0.7692307692307692
Epoch:  264        2 Batch loss: 0.186415 Batch F1: 0.6153846153846153
Epoch:  264        3 Batch loss: 0.166608 Batch F1: 0.7659574468085107
Epoch:  264        4 Batch loss: 0.188221 Batch F1: 0.6363636363636365
Epoch:  264        5 Batch loss: 0.165790 Batch F1: 0.7
Epoch:  264        6 Batch loss: 0.193937 Batch F1: 0.7037037037037037
Epoch:  264        7 Batch loss: 0.186896 Batch F1: 0.6511627906976744
Epoch:  264        8 Batch loss: 0.143074 Batch F1: 0.8181818181818182
Epoch:  264        9 Batch loss: 0.193170 Batch F1: 0.68
Epoch:  264       10 Batch loss: 0.163849 Batch F1: 0.7499999999999999
Epoch:  264       11 Batch loss: 0.167398 Batch F1: 0.76
Epoch:  264       12 Batch loss: 0.151821 Batch F1: 0.6923076923076923
Train Avg Loss  264: 0.171024

Train Avg F1  264: 0.7118577060565351

Val Avg Loss  264: 0.184509

Val Avg F1  264:  0.6766525273948392

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 265
--------------------------------------------------------------
Epoch:  265        1 Batch loss: 0.172370 Batch F1: 0.7142857142857143
Epoch:  265        2 Batch loss: 0.163769 Batch F1: 0.7391304347826088
Epoch:  265        3 Batch loss: 0.171589 Batch F1: 0.6857142857142857
Epoch:  265        4 Batch loss: 0.174819 Batch F1: 0.7499999999999999
Epoch:  265        5 Batch loss: 0.137801 Batch F1: 0.8260869565217391
Epoch:  265        6 Batch loss: 0.177784 Batch F1: 0.5333333333333333
Epoch:  265        7 Batch loss: 0.165854 Batch F1: 0.7391304347826088
Epoch:  265        8 Batch loss: 0.180496 Batch F1: 0.723404255319149
Epoch:  265        9 Batch loss: 0.182693 Batch F1: 0.7199999999999999
Epoch:  265       10 Batch loss: 0.171959 Batch F1: 0.6666666666666666
Epoch:  265       11 Batch loss: 0.198175 Batch F1: 0.6382978723404256
Epoch:  265       12 Batch loss: 0.166636 Batch F1: 0.7500000000000001
Train Avg Loss  265: 0.171995

Train Avg F1  265: 0.7071708294788777

Val Avg Loss  265: 0.181191

Val Avg F1  265:  0.6722036995521541

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 266
--------------------------------------------------------------
Epoch:  266        1 Batch loss: 0.168760 Batch F1: 0.7755102040816326
Epoch:  266        2 Batch loss: 0.174586 Batch F1: 0.6341463414634148
Epoch:  266        3 Batch loss: 0.176926 Batch F1: 0.7692307692307692
Epoch:  266        4 Batch loss: 0.164032 Batch F1: 0.7027027027027027
Epoch:  266        5 Batch loss: 0.158788 Batch F1: 0.75
Epoch:  266        6 Batch loss: 0.156109 Batch F1: 0.7272727272727272
Epoch:  266        7 Batch loss: 0.194152 Batch F1: 0.6666666666666666
Epoch:  266        8 Batch loss: 0.152466 Batch F1: 0.7804878048780488
Epoch:  266        9 Batch loss: 0.202917 Batch F1: 0.5263157894736842
Epoch:  266       10 Batch loss: 0.145492 Batch F1: 0.8
Epoch:  266       11 Batch loss: 0.176469 Batch F1: 0.6808510638297872
Epoch:  266       12 Batch loss: 0.178730 Batch F1: 0.7
Train Avg Loss  266: 0.170786

Train Avg F1  266: 0.7094320057999527

Val Avg Loss  266: 0.181288

Val Avg F1  266:  0.6680495341542207

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 267
--------------------------------------------------------------
Epoch:  267        1 Batch loss: 0.170921 Batch F1: 0.7391304347826088
Epoch:  267        2 Batch loss: 0.173653 Batch F1: 0.7083333333333334
Epoch:  267        3 Batch loss: 0.162758 Batch F1: 0.76
Epoch:  267        4 Batch loss: 0.181003 Batch F1: 0.6976744186046512
Epoch:  267        5 Batch loss: 0.174017 Batch F1: 0.7450980392156864
Epoch:  267        6 Batch loss: 0.161778 Batch F1: 0.7272727272727273
Epoch:  267        7 Batch loss: 0.159983 Batch F1: 0.7441860465116279
Epoch:  267        8 Batch loss: 0.176441 Batch F1: 0.6666666666666666
Epoch:  267        9 Batch loss: 0.160177 Batch F1: 0.7272727272727272
Epoch:  267       10 Batch loss: 0.187028 Batch F1: 0.6341463414634146
Epoch:  267       11 Batch loss: 0.166147 Batch F1: 0.6486486486486486
Epoch:  267       12 Batch loss: 0.160341 Batch F1: 0.7222222222222222
Train Avg Loss  267: 0.169521

Train Avg F1  267: 0.7100543004995261

Val Avg Loss  267: 0.181772

Val Avg F1  267:  0.677679167152071

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 268
--------------------------------------------------------------
Epoch:  268        1 Batch loss: 0.179832 Batch F1: 0.7083333333333334
Epoch:  268        2 Batch loss: 0.230692 Batch F1: 0.5957446808510638
Epoch:  268        3 Batch loss: 0.145594 Batch F1: 0.8372093023255814
Epoch:  268        4 Batch loss: 0.155498 Batch F1: 0.7924528301886793
Epoch:  268        5 Batch loss: 0.189704 Batch F1: 0.7346938775510204
Epoch:  268        6 Batch loss: 0.174025 Batch F1: 0.6341463414634148
Epoch:  268        7 Batch loss: 0.185366 Batch F1: 0.6829268292682926
Epoch:  268        8 Batch loss: 0.168006 Batch F1: 0.6976744186046512
Epoch:  268        9 Batch loss: 0.165785 Batch F1: 0.6829268292682926
Epoch:  268       10 Batch loss: 0.151428 Batch F1: 0.7999999999999999
Epoch:  268       11 Batch loss: 0.188034 Batch F1: 0.6511627906976744
Epoch:  268       12 Batch loss: 0.181197 Batch F1: 0.6285714285714286
Train Avg Loss  268: 0.176264

Train Avg F1  268: 0.7038202218436194

Val Avg Loss  268: 0.185865

Val Avg F1  268:  0.6720199344788221

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 269
--------------------------------------------------------------
Epoch:  269        1 Batch loss: 0.172464 Batch F1: 0.7083333333333333
Epoch:  269        2 Batch loss: 0.200781 Batch F1: 0.7058823529411764
Epoch:  269        3 Batch loss: 0.184491 Batch F1: 0.7499999999999999
Epoch:  269        4 Batch loss: 0.130465 Batch F1: 0.8275862068965518
Epoch:  269        5 Batch loss: 0.197179 Batch F1: 0.6829268292682927
Epoch:  269        6 Batch loss: 0.150782 Batch F1: 0.7027027027027027
Epoch:  269        7 Batch loss: 0.166594 Batch F1: 0.7391304347826088
Epoch:  269        8 Batch loss: 0.171301 Batch F1: 0.6111111111111113
Epoch:  269        9 Batch loss: 0.193497 Batch F1: 0.7931034482758621
Epoch:  269       10 Batch loss: 0.217078 Batch F1: 0.4864864864864865
Epoch:  269       11 Batch loss: 0.161609 Batch F1: 0.8
Epoch:  269       12 Batch loss: 0.198424 Batch F1: 0.6666666666666666
Train Avg Loss  269: 0.178722

Train Avg F1  269: 0.7061607977053993

Val Avg Loss  269: 0.197818

Val Avg F1  269:  0.7163568215892053

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 270
--------------------------------------------------------------
Epoch:  270        1 Batch loss: 0.184297 Batch F1: 0.7142857142857143
Epoch:  270        2 Batch loss: 0.196314 Batch F1: 0.6938775510204083
Epoch:  270        3 Batch loss: 0.150555 Batch F1: 0.8235294117647058
Epoch:  270        4 Batch loss: 0.177375 Batch F1: 0.5454545454545455
Epoch:  270        5 Batch loss: 0.199524 Batch F1: 0.72
Epoch:  270        6 Batch loss: 0.161476 Batch F1: 0.8085106382978723
Epoch:  270        7 Batch loss: 0.155479 Batch F1: 0.8085106382978724
Epoch:  270        8 Batch loss: 0.185731 Batch F1: 0.6666666666666666
Epoch:  270        9 Batch loss: 0.161647 Batch F1: 0.6842105263157895
Epoch:  270       10 Batch loss: 0.198403 Batch F1: 0.55
Epoch:  270       11 Batch loss: 0.190787 Batch F1: 0.7169811320754718
Epoch:  270       12 Batch loss: 0.187205 Batch F1: 0.6829268292682926
Train Avg Loss  270: 0.179066

Train Avg F1  270: 0.7012461377872783

Val Avg Loss  270: 0.182877

Val Avg F1  270:  0.6767459611882765

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 271
--------------------------------------------------------------
Epoch:  271        1 Batch loss: 0.153360 Batch F1: 0.8
Epoch:  271        2 Batch loss: 0.154326 Batch F1: 0.8181818181818182
Epoch:  271        3 Batch loss: 0.186363 Batch F1: 0.6190476190476191
Epoch:  271        4 Batch loss: 0.170491 Batch F1: 0.6842105263157895
Epoch:  271        5 Batch loss: 0.171772 Batch F1: 0.65
Epoch:  271        6 Batch loss: 0.177278 Batch F1: 0.5806451612903226
Epoch:  271        7 Batch loss: 0.142272 Batch F1: 0.8181818181818182
Epoch:  271        8 Batch loss: 0.184307 Batch F1: 0.6808510638297872
Epoch:  271        9 Batch loss: 0.168700 Batch F1: 0.7999999999999999
Epoch:  271       10 Batch loss: 0.207520 Batch F1: 0.5909090909090909
Epoch:  271       11 Batch loss: 0.183460 Batch F1: 0.6666666666666666
Epoch:  271       12 Batch loss: 0.172781 Batch F1: 0.7727272727272727
Train Avg Loss  271: 0.172719

Train Avg F1  271: 0.7067850864291821

Val Avg Loss  271: 0.182877

Val Avg F1  271:  0.6730434782608696

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 272
--------------------------------------------------------------
Epoch:  272        1 Batch loss: 0.190977 Batch F1: 0.6
Epoch:  272        2 Batch loss: 0.152399 Batch F1: 0.7500000000000001
Epoch:  272        3 Batch loss: 0.195983 Batch F1: 0.5777777777777778
Epoch:  272        4 Batch loss: 0.204428 Batch F1: 0.5714285714285713
Epoch:  272        5 Batch loss: 0.167591 Batch F1: 0.7391304347826085
Epoch:  272        6 Batch loss: 0.177557 Batch F1: 0.6511627906976744
Epoch:  272        7 Batch loss: 0.142632 Batch F1: 0.8636363636363636
Epoch:  272        8 Batch loss: 0.164968 Batch F1: 0.7555555555555556
Epoch:  272        9 Batch loss: 0.167824 Batch F1: 0.7777777777777777
Epoch:  272       10 Batch loss: 0.204691 Batch F1: 0.5909090909090909
Epoch:  272       11 Batch loss: 0.138440 Batch F1: 0.8510638297872342
Epoch:  272       12 Batch loss: 0.147249 Batch F1: 0.823529411764706
Train Avg Loss  272: 0.171228

Train Avg F1  272: 0.7126643003431133

Val Avg Loss  272: 0.183529

Val Avg F1  272:  0.6657328708525517

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 273
--------------------------------------------------------------
Epoch:  273        1 Batch loss: 0.156444 Batch F1: 0.6842105263157895
Epoch:  273        2 Batch loss: 0.146009 Batch F1: 0.8444444444444444
Epoch:  273        3 Batch loss: 0.169014 Batch F1: 0.723404255319149
Epoch:  273        4 Batch loss: 0.186699 Batch F1: 0.6666666666666666
Epoch:  273        5 Batch loss: 0.175166 Batch F1: 0.631578947368421
Epoch:  273        6 Batch loss: 0.177376 Batch F1: 0.72
Epoch:  273        7 Batch loss: 0.183215 Batch F1: 0.7169811320754718
Epoch:  273        8 Batch loss: 0.186083 Batch F1: 0.6
Epoch:  273        9 Batch loss: 0.173819 Batch F1: 0.7317073170731707
Epoch:  273       10 Batch loss: 0.165350 Batch F1: 0.7843137254901961
Epoch:  273       11 Batch loss: 0.185928 Batch F1: 0.6190476190476191
Epoch:  273       12 Batch loss: 0.136280 Batch F1: 0.823529411764706
Train Avg Loss  273: 0.170115

Train Avg F1  273: 0.7121570037971362

Val Avg Loss  273: 0.182885

Val Avg F1  273:  0.6723523523523525

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 274
--------------------------------------------------------------
Epoch:  274        1 Batch loss: 0.158742 Batch F1: 0.5806451612903226
Epoch:  274        2 Batch loss: 0.169550 Batch F1: 0.7272727272727272
Epoch:  274        3 Batch loss: 0.164325 Batch F1: 0.7659574468085107
Epoch:  274        4 Batch loss: 0.179919 Batch F1: 0.6666666666666666
Epoch:  274        5 Batch loss: 0.181585 Batch F1: 0.6666666666666665
Epoch:  274        6 Batch loss: 0.192009 Batch F1: 0.6666666666666666
Epoch:  274        7 Batch loss: 0.150875 Batch F1: 0.7619047619047619
Epoch:  274        8 Batch loss: 0.168976 Batch F1: 0.7111111111111111
Epoch:  274        9 Batch loss: 0.143129 Batch F1: 0.7692307692307692
Epoch:  274       10 Batch loss: 0.169156 Batch F1: 0.819672131147541
Epoch:  274       11 Batch loss: 0.163549 Batch F1: 0.7843137254901961
Epoch:  274       12 Batch loss: 0.202684 Batch F1: 0.4827586206896552
Train Avg Loss  274: 0.170375

Train Avg F1  274: 0.7002388712454662

Val Avg Loss  274: 0.182170

Val Avg F1  274:  0.6772084958783782

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 275
--------------------------------------------------------------
Epoch:  275        1 Batch loss: 0.183474 Batch F1: 0.6530612244897959
Epoch:  275        2 Batch loss: 0.150911 Batch F1: 0.7368421052631577
Epoch:  275        3 Batch loss: 0.144614 Batch F1: 0.8000000000000002
Epoch:  275        4 Batch loss: 0.205573 Batch F1: 0.6399999999999999
Epoch:  275        5 Batch loss: 0.185611 Batch F1: 0.6808510638297872
Epoch:  275        6 Batch loss: 0.170296 Batch F1: 0.7450980392156864
Epoch:  275        7 Batch loss: 0.183502 Batch F1: 0.631578947368421
Epoch:  275        8 Batch loss: 0.161052 Batch F1: 0.6829268292682926
Epoch:  275        9 Batch loss: 0.156741 Batch F1: 0.7317073170731708
Epoch:  275       10 Batch loss: 0.149580 Batch F1: 0.8444444444444444
Epoch:  275       11 Batch loss: 0.177984 Batch F1: 0.7547169811320754
Epoch:  275       12 Batch loss: 0.188530 Batch F1: 0.6250000000000001
Train Avg Loss  275: 0.171489

Train Avg F1  275: 0.710518912673736

Val Avg Loss  275: 0.183819

Val Avg F1  275:  0.6710465406117581

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 276
--------------------------------------------------------------
Epoch:  276        1 Batch loss: 0.199656 Batch F1: 0.5957446808510638
Epoch:  276        2 Batch loss: 0.163641 Batch F1: 0.6666666666666666
Epoch:  276        3 Batch loss: 0.188576 Batch F1: 0.6
Epoch:  276        4 Batch loss: 0.184334 Batch F1: 0.5945945945945946
Epoch:  276        5 Batch loss: 0.164424 Batch F1: 0.7727272727272727
Epoch:  276        6 Batch loss: 0.147186 Batch F1: 0.8095238095238095
Epoch:  276        7 Batch loss: 0.177717 Batch F1: 0.7586206896551724
Epoch:  276        8 Batch loss: 0.167463 Batch F1: 0.7500000000000001
Epoch:  276        9 Batch loss: 0.165193 Batch F1: 0.7
Epoch:  276       10 Batch loss: 0.182552 Batch F1: 0.6842105263157895
Epoch:  276       11 Batch loss: 0.174888 Batch F1: 0.723404255319149
Epoch:  276       12 Batch loss: 0.151901 Batch F1: 0.8444444444444444
Train Avg Loss  276: 0.172294

Train Avg F1  276: 0.708328078341497

Val Avg Loss  276: 0.184141

Val Avg F1  276:  0.6714069264069265

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 277
--------------------------------------------------------------
Epoch:  277        1 Batch loss: 0.184676 Batch F1: 0.6
Epoch:  277        2 Batch loss: 0.154025 Batch F1: 0.6206896551724138
Epoch:  277        3 Batch loss: 0.162491 Batch F1: 0.717948717948718
Epoch:  277        4 Batch loss: 0.183464 Batch F1: 0.6666666666666666
Epoch:  277        5 Batch loss: 0.164568 Batch F1: 0.6842105263157895
Epoch:  277        6 Batch loss: 0.166504 Batch F1: 0.8070175438596492
Epoch:  277        7 Batch loss: 0.146910 Batch F1: 0.7999999999999999
Epoch:  277        8 Batch loss: 0.217737 Batch F1: 0.6037735849056605
Epoch:  277        9 Batch loss: 0.139878 Batch F1: 0.8333333333333333
Epoch:  277       10 Batch loss: 0.203477 Batch F1: 0.6222222222222223
Epoch:  277       11 Batch loss: 0.182654 Batch F1: 0.76
Epoch:  277       12 Batch loss: 0.150048 Batch F1: 0.7777777777777778
Train Avg Loss  277: 0.171369

Train Avg F1  277: 0.7078033356835193

Val Avg Loss  277: 0.181451

Val Avg F1  277:  0.6748247178213662

Optimal Val loss (Epoch 245): 0.1811654418706894

Epoch 278
--------------------------------------------------------------
Epoch:  278        1 Batch loss: 0.154125 Batch F1: 0.717948717948718
Epoch:  278        2 Batch loss: 0.183252 Batch F1: 0.5142857142857142
Epoch:  278        3 Batch loss: 0.174075 Batch F1: 0.6956521739130435
Epoch:  278        4 Batch loss: 0.134882 Batch F1: 0.8444444444444444
Epoch:  278        5 Batch loss: 0.149094 Batch F1: 0.6666666666666666
Epoch:  278        6 Batch loss: 0.174789 Batch F1: 0.7547169811320754
Epoch:  278        7 Batch loss: 0.146038 Batch F1: 0.8260869565217391
Epoch:  278        8 Batch loss: 0.184408 Batch F1: 0.6511627906976744
Epoch:  278        9 Batch loss: 0.194093 Batch F1: 0.6666666666666666
Epoch:  278       10 Batch loss: 0.184233 Batch F1: 0.6938775510204083
Epoch:  278       11 Batch loss: 0.194001 Batch F1: 0.6363636363636364
Epoch:  278       12 Batch loss: 0.153039 Batch F1: 0.8085106382978724
Train Avg Loss  278: 0.168836

Train Avg F1  278: 0.7063652448298884

Val Avg Loss  278: 0.180351

Val Avg F1  278:  0.6800154023873701

Optimal Val loss (Epoch 278): 0.1803506799042225

Epoch 279
--------------------------------------------------------------
Epoch:  279        1 Batch loss: 0.145607 Batch F1: 0.6875000000000001
Epoch:  279        2 Batch loss: 0.188093 Batch F1: 0.5641025641025641
Epoch:  279        3 Batch loss: 0.180963 Batch F1: 0.7083333333333333
Epoch:  279        4 Batch loss: 0.180968 Batch F1: 0.5789473684210527
Epoch:  279        5 Batch loss: 0.166376 Batch F1: 0.7391304347826089
Epoch:  279        6 Batch loss: 0.156562 Batch F1: 0.7555555555555555
Epoch:  279        7 Batch loss: 0.191360 Batch F1: 0.6341463414634148
Epoch:  279        8 Batch loss: 0.172135 Batch F1: 0.75
Epoch:  279        9 Batch loss: 0.177402 Batch F1: 0.7058823529411765
Epoch:  279       10 Batch loss: 0.173833 Batch F1: 0.7547169811320754
Epoch:  279       11 Batch loss: 0.131879 Batch F1: 0.8571428571428572
Epoch:  279       12 Batch loss: 0.167826 Batch F1: 0.7804878048780488
Train Avg Loss  279: 0.169417

Train Avg F1  279: 0.7096621328127241

Val Avg Loss  279: 0.180175

Val Avg F1  279:  0.6761497660804935

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 280
--------------------------------------------------------------
Epoch:  280        1 Batch loss: 0.178262 Batch F1: 0.7777777777777779
Epoch:  280        2 Batch loss: 0.144965 Batch F1: 0.8095238095238095
Epoch:  280        3 Batch loss: 0.192574 Batch F1: 0.6250000000000001
Epoch:  280        4 Batch loss: 0.163374 Batch F1: 0.7142857142857143
Epoch:  280        5 Batch loss: 0.152917 Batch F1: 0.7826086956521738
Epoch:  280        6 Batch loss: 0.173445 Batch F1: 0.6829268292682926
Epoch:  280        7 Batch loss: 0.189999 Batch F1: 0.6530612244897959
Epoch:  280        8 Batch loss: 0.167751 Batch F1: 0.7083333333333334
Epoch:  280        9 Batch loss: 0.178174 Batch F1: 0.5945945945945946
Epoch:  280       10 Batch loss: 0.145927 Batch F1: 0.7727272727272727
Epoch:  280       11 Batch loss: 0.177808 Batch F1: 0.7234042553191489
Epoch:  280       12 Batch loss: 0.160826 Batch F1: 0.6666666666666666
Train Avg Loss  280: 0.168835

Train Avg F1  280: 0.7092425144698816

Val Avg Loss  280: 0.180923

Val Avg F1  280:  0.6773235376374158

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 281
--------------------------------------------------------------
Epoch:  281        1 Batch loss: 0.150445 Batch F1: 0.7368421052631579
Epoch:  281        2 Batch loss: 0.175738 Batch F1: 0.7272727272727274
Epoch:  281        3 Batch loss: 0.202592 Batch F1: 0.5777777777777778
Epoch:  281        4 Batch loss: 0.162993 Batch F1: 0.7391304347826089
Epoch:  281        5 Batch loss: 0.192465 Batch F1: 0.5641025641025642
Epoch:  281        6 Batch loss: 0.166688 Batch F1: 0.75
Epoch:  281        7 Batch loss: 0.175640 Batch F1: 0.6666666666666667
Epoch:  281        8 Batch loss: 0.146021 Batch F1: 0.8095238095238095
Epoch:  281        9 Batch loss: 0.190411 Batch F1: 0.7142857142857142
Epoch:  281       10 Batch loss: 0.173152 Batch F1: 0.7391304347826085
Epoch:  281       11 Batch loss: 0.134344 Batch F1: 0.8695652173913043
Epoch:  281       12 Batch loss: 0.164980 Batch F1: 0.56
Train Avg Loss  281: 0.169623

Train Avg F1  281: 0.7045247876540784

Val Avg Loss  281: 0.180842

Val Avg F1  281:  0.6772280720798958

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 282
--------------------------------------------------------------
Epoch:  282        1 Batch loss: 0.201105 Batch F1: 0.5405405405405405
Epoch:  282        2 Batch loss: 0.175500 Batch F1: 0.6666666666666666
Epoch:  282        3 Batch loss: 0.155694 Batch F1: 0.7659574468085107
Epoch:  282        4 Batch loss: 0.152291 Batch F1: 0.7906976744186046
Epoch:  282        5 Batch loss: 0.208122 Batch F1: 0.5777777777777778
Epoch:  282        6 Batch loss: 0.186097 Batch F1: 0.7058823529411765
Epoch:  282        7 Batch loss: 0.165806 Batch F1: 0.7111111111111111
Epoch:  282        8 Batch loss: 0.144046 Batch F1: 0.8163265306122449
Epoch:  282        9 Batch loss: 0.166062 Batch F1: 0.7391304347826088
Epoch:  282       10 Batch loss: 0.171116 Batch F1: 0.6511627906976745
Epoch:  282       11 Batch loss: 0.168883 Batch F1: 0.744186046511628
Epoch:  282       12 Batch loss: 0.143184 Batch F1: 0.8235294117647058
Train Avg Loss  282: 0.169825

Train Avg F1  282: 0.7110807320527709

Val Avg Loss  282: 0.180518

Val Avg F1  282:  0.6795287297308861

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 283
--------------------------------------------------------------
Epoch:  283        1 Batch loss: 0.175079 Batch F1: 0.6341463414634148
Epoch:  283        2 Batch loss: 0.175116 Batch F1: 0.76
Epoch:  283        3 Batch loss: 0.160554 Batch F1: 0.6857142857142857
Epoch:  283        4 Batch loss: 0.163312 Batch F1: 0.6976744186046512
Epoch:  283        5 Batch loss: 0.183880 Batch F1: 0.7450980392156864
Epoch:  283        6 Batch loss: 0.168711 Batch F1: 0.8
Epoch:  283        7 Batch loss: 0.194706 Batch F1: 0.5500000000000002
Epoch:  283        8 Batch loss: 0.130682 Batch F1: 0.8679245283018867
Epoch:  283        9 Batch loss: 0.195064 Batch F1: 0.7200000000000001
Epoch:  283       10 Batch loss: 0.217986 Batch F1: 0.52
Epoch:  283       11 Batch loss: 0.184105 Batch F1: 0.6818181818181818
Epoch:  283       12 Batch loss: 0.156994 Batch F1: 0.7222222222222223
Train Avg Loss  283: 0.175516

Train Avg F1  283: 0.6987165014450273

Val Avg Loss  283: 0.188610

Val Avg F1  283:  0.724426947423463

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 284
--------------------------------------------------------------
Epoch:  284        1 Batch loss: 0.189727 Batch F1: 0.6111111111111112
Epoch:  284        2 Batch loss: 0.156665 Batch F1: 0.8205128205128205
Epoch:  284        3 Batch loss: 0.197490 Batch F1: 0.6363636363636364
Epoch:  284        4 Batch loss: 0.183890 Batch F1: 0.76
Epoch:  284        5 Batch loss: 0.227553 Batch F1: 0.6785714285714286
Epoch:  284        6 Batch loss: 0.210223 Batch F1: 0.6956521739130435
Epoch:  284        7 Batch loss: 0.163662 Batch F1: 0.8085106382978724
Epoch:  284        8 Batch loss: 0.192561 Batch F1: 0.5957446808510638
Epoch:  284        9 Batch loss: 0.161184 Batch F1: 0.7317073170731706
Epoch:  284       10 Batch loss: 0.155967 Batch F1: 0.6857142857142857
Epoch:  284       11 Batch loss: 0.185744 Batch F1: 0.5142857142857142
Epoch:  284       12 Batch loss: 0.167848 Batch F1: 0.8372093023255814
Train Avg Loss  284: 0.182709

Train Avg F1  284: 0.6979485924183106

Val Avg Loss  284: 0.190831

Val Avg F1  284:  0.7483223233487739

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 285
--------------------------------------------------------------
Epoch:  285        1 Batch loss: 0.151692 Batch F1: 0.8813559322033899
Epoch:  285        2 Batch loss: 0.193094 Batch F1: 0.6956521739130435
Epoch:  285        3 Batch loss: 0.218661 Batch F1: 0.55
Epoch:  285        4 Batch loss: 0.177030 Batch F1: 0.6666666666666666
Epoch:  285        5 Batch loss: 0.213874 Batch F1: 0.6885245901639343
Epoch:  285        6 Batch loss: 0.172225 Batch F1: 0.7843137254901961
Epoch:  285        7 Batch loss: 0.158789 Batch F1: 0.8
Epoch:  285        8 Batch loss: 0.223613 Batch F1: 0.6976744186046512
Epoch:  285        9 Batch loss: 0.158844 Batch F1: 0.7727272727272727
Epoch:  285       10 Batch loss: 0.141293 Batch F1: 0.7567567567567567
Epoch:  285       11 Batch loss: 0.183241 Batch F1: 0.6829268292682926
Epoch:  285       12 Batch loss: 0.170220 Batch F1: 0.717948717948718
Train Avg Loss  285: 0.180215

Train Avg F1  285: 0.7245455903119101

Val Avg Loss  285: 0.184710

Val Avg F1  285:  0.6669109028347767

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 286
--------------------------------------------------------------
Epoch:  286        1 Batch loss: 0.198143 Batch F1: 0.6190476190476191
Epoch:  286        2 Batch loss: 0.148876 Batch F1: 0.7272727272727272
Epoch:  286        3 Batch loss: 0.154712 Batch F1: 0.7368421052631577
Epoch:  286        4 Batch loss: 0.186766 Batch F1: 0.7058823529411765
Epoch:  286        5 Batch loss: 0.174674 Batch F1: 0.6111111111111113
Epoch:  286        6 Batch loss: 0.182278 Batch F1: 0.6938775510204083
Epoch:  286        7 Batch loss: 0.172630 Batch F1: 0.7391304347826085
Epoch:  286        8 Batch loss: 0.202870 Batch F1: 0.64
Epoch:  286        9 Batch loss: 0.149376 Batch F1: 0.8
Epoch:  286       10 Batch loss: 0.156069 Batch F1: 0.8
Epoch:  286       11 Batch loss: 0.178531 Batch F1: 0.7346938775510203
Epoch:  286       12 Batch loss: 0.153849 Batch F1: 0.7428571428571429
Train Avg Loss  286: 0.171565

Train Avg F1  286: 0.7125595768205809

Val Avg Loss  286: 0.182614

Val Avg F1  286:  0.6769311122106767

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 287
--------------------------------------------------------------
Epoch:  287        1 Batch loss: 0.173312 Batch F1: 0.7142857142857143
Epoch:  287        2 Batch loss: 0.153019 Batch F1: 0.744186046511628
Epoch:  287        3 Batch loss: 0.149375 Batch F1: 0.6666666666666665
Epoch:  287        4 Batch loss: 0.181550 Batch F1: 0.5945945945945946
Epoch:  287        5 Batch loss: 0.174571 Batch F1: 0.6956521739130435
Epoch:  287        6 Batch loss: 0.165602 Batch F1: 0.6976744186046512
Epoch:  287        7 Batch loss: 0.153770 Batch F1: 0.8
Epoch:  287        8 Batch loss: 0.168668 Batch F1: 0.7843137254901961
Epoch:  287        9 Batch loss: 0.166160 Batch F1: 0.7272727272727273
Epoch:  287       10 Batch loss: 0.195014 Batch F1: 0.6222222222222223
Epoch:  287       11 Batch loss: 0.167276 Batch F1: 0.7843137254901961
Epoch:  287       12 Batch loss: 0.191459 Batch F1: 0.6829268292682926
Train Avg Loss  287: 0.169981

Train Avg F1  287: 0.7095090703599944

Val Avg Loss  287: 0.181330

Val Avg F1  287:  0.6734316975687052

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 288
--------------------------------------------------------------
Epoch:  288        1 Batch loss: 0.171004 Batch F1: 0.7000000000000001
Epoch:  288        2 Batch loss: 0.177702 Batch F1: 0.7307692307692306
Epoch:  288        3 Batch loss: 0.154988 Batch F1: 0.8363636363636364
Epoch:  288        4 Batch loss: 0.168363 Batch F1: 0.6486486486486486
Epoch:  288        5 Batch loss: 0.183520 Batch F1: 0.6511627906976744
Epoch:  288        6 Batch loss: 0.194624 Batch F1: 0.68
Epoch:  288        7 Batch loss: 0.163427 Batch F1: 0.7499999999999999
Epoch:  288        8 Batch loss: 0.185927 Batch F1: 0.6923076923076923
Epoch:  288        9 Batch loss: 0.166505 Batch F1: 0.6666666666666667
Epoch:  288       10 Batch loss: 0.145567 Batch F1: 0.8
Epoch:  288       11 Batch loss: 0.153893 Batch F1: 0.7441860465116279
Epoch:  288       12 Batch loss: 0.164590 Batch F1: 0.5599999999999999
Train Avg Loss  288: 0.169176

Train Avg F1  288: 0.7050087259970982

Val Avg Loss  288: 0.182417

Val Avg F1  288:  0.6767127799736495

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 289
--------------------------------------------------------------
Epoch:  289        1 Batch loss: 0.189946 Batch F1: 0.6046511627906976
Epoch:  289        2 Batch loss: 0.163743 Batch F1: 0.6842105263157895
Epoch:  289        3 Batch loss: 0.167221 Batch F1: 0.75
Epoch:  289        4 Batch loss: 0.182263 Batch F1: 0.6341463414634146
Epoch:  289        5 Batch loss: 0.140153 Batch F1: 0.7692307692307692
Epoch:  289        6 Batch loss: 0.151743 Batch F1: 0.8181818181818182
Epoch:  289        7 Batch loss: 0.171558 Batch F1: 0.7777777777777778
Epoch:  289        8 Batch loss: 0.172405 Batch F1: 0.6486486486486486
Epoch:  289        9 Batch loss: 0.152142 Batch F1: 0.7916666666666666
Epoch:  289       10 Batch loss: 0.187251 Batch F1: 0.6190476190476191
Epoch:  289       11 Batch loss: 0.176327 Batch F1: 0.7200000000000001
Epoch:  289       12 Batch loss: 0.175273 Batch F1: 0.7
Train Avg Loss  289: 0.169169

Train Avg F1  289: 0.7097967775102667

Val Avg Loss  289: 0.181324

Val Avg F1  289:  0.6779749020820449

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 290
--------------------------------------------------------------
Epoch:  290        1 Batch loss: 0.174759 Batch F1: 0.631578947368421
Epoch:  290        2 Batch loss: 0.168179 Batch F1: 0.7272727272727273
Epoch:  290        3 Batch loss: 0.158159 Batch F1: 0.7555555555555555
Epoch:  290        4 Batch loss: 0.177697 Batch F1: 0.6111111111111113
Epoch:  290        5 Batch loss: 0.201523 Batch F1: 0.5957446808510638
Epoch:  290        6 Batch loss: 0.152017 Batch F1: 0.6842105263157895
Epoch:  290        7 Batch loss: 0.173009 Batch F1: 0.7234042553191491
Epoch:  290        8 Batch loss: 0.168521 Batch F1: 0.7692307692307693
Epoch:  290        9 Batch loss: 0.156728 Batch F1: 0.7441860465116279
Epoch:  290       10 Batch loss: 0.190963 Batch F1: 0.6363636363636364
Epoch:  290       11 Batch loss: 0.138240 Batch F1: 0.8333333333333334
Epoch:  290       12 Batch loss: 0.164649 Batch F1: 0.8095238095238095
Train Avg Loss  290: 0.168704

Train Avg F1  290: 0.7101262832297496

Val Avg Loss  290: 0.180681

Val Avg F1  290:  0.6757977914003739

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 291
--------------------------------------------------------------
Epoch:  291        1 Batch loss: 0.134723 Batch F1: 0.851851851851852
Epoch:  291        2 Batch loss: 0.179541 Batch F1: 0.6666666666666666
Epoch:  291        3 Batch loss: 0.180339 Batch F1: 0.6666666666666666
Epoch:  291        4 Batch loss: 0.207769 Batch F1: 0.5238095238095238
Epoch:  291        5 Batch loss: 0.172345 Batch F1: 0.7058823529411765
Epoch:  291        6 Batch loss: 0.170255 Batch F1: 0.7317073170731708
Epoch:  291        7 Batch loss: 0.175715 Batch F1: 0.6842105263157895
Epoch:  291        8 Batch loss: 0.177870 Batch F1: 0.7659574468085107
Epoch:  291        9 Batch loss: 0.221209 Batch F1: 0.64
Epoch:  291       10 Batch loss: 0.180107 Batch F1: 0.6829268292682926
Epoch:  291       11 Batch loss: 0.156412 Batch F1: 0.7567567567567567
Epoch:  291       12 Batch loss: 0.165180 Batch F1: 0.7500000000000001
Train Avg Loss  291: 0.176789

Train Avg F1  291: 0.7022029948465338

Val Avg Loss  291: 0.189884

Val Avg F1  291:  0.6754689754689754

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 292
--------------------------------------------------------------
Epoch:  292        1 Batch loss: 0.183496 Batch F1: 0.7317073170731706
Epoch:  292        2 Batch loss: 0.164357 Batch F1: 0.782608695652174
Epoch:  292        3 Batch loss: 0.169125 Batch F1: 0.6060606060606061
Epoch:  292        4 Batch loss: 0.193110 Batch F1: 0.6530612244897959
Epoch:  292        5 Batch loss: 0.200175 Batch F1: 0.608695652173913
Epoch:  292        6 Batch loss: 0.176872 Batch F1: 0.7058823529411765
Epoch:  292        7 Batch loss: 0.186502 Batch F1: 0.7916666666666667
Epoch:  292        8 Batch loss: 0.166653 Batch F1: 0.8085106382978723
Epoch:  292        9 Batch loss: 0.204086 Batch F1: 0.5777777777777778
Epoch:  292       10 Batch loss: 0.141344 Batch F1: 0.8627450980392156
Epoch:  292       11 Batch loss: 0.171801 Batch F1: 0.6315789473684211
Epoch:  292       12 Batch loss: 0.154901 Batch F1: 0.6666666666666666
Train Avg Loss  292: 0.176035

Train Avg F1  292: 0.7022468036006213

Val Avg Loss  292: 0.187744

Val Avg F1  292:  0.5736130867709814

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 293
--------------------------------------------------------------
Epoch:  293        1 Batch loss: 0.238383 Batch F1: 0.3888888888888889
Epoch:  293        2 Batch loss: 0.133953 Batch F1: 0.8235294117647058
Epoch:  293        3 Batch loss: 0.162359 Batch F1: 0.84
Epoch:  293        4 Batch loss: 0.174766 Batch F1: 0.782608695652174
Epoch:  293        5 Batch loss: 0.218590 Batch F1: 0.7083333333333334
Epoch:  293        6 Batch loss: 0.200862 Batch F1: 0.7391304347826088
Epoch:  293        7 Batch loss: 0.189385 Batch F1: 0.5641025641025642
Epoch:  293        8 Batch loss: 0.162164 Batch F1: 0.782608695652174
Epoch:  293        9 Batch loss: 0.170821 Batch F1: 0.8000000000000002
Epoch:  293       10 Batch loss: 0.198538 Batch F1: 0.6382978723404256
Epoch:  293       11 Batch loss: 0.156435 Batch F1: 0.7916666666666667
Epoch:  293       12 Batch loss: 0.162829 Batch F1: 0.64
Train Avg Loss  293: 0.180757

Train Avg F1  293: 0.7082638802652951

Val Avg Loss  293: 0.181710

Val Avg F1  293:  0.6649074456846263

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 294
--------------------------------------------------------------
Epoch:  294        1 Batch loss: 0.222534 Batch F1: 0.5714285714285714
Epoch:  294        2 Batch loss: 0.154186 Batch F1: 0.8333333333333333
Epoch:  294        3 Batch loss: 0.149843 Batch F1: 0.7906976744186046
Epoch:  294        4 Batch loss: 0.155243 Batch F1: 0.717948717948718
Epoch:  294        5 Batch loss: 0.171343 Batch F1: 0.7777777777777778
Epoch:  294        6 Batch loss: 0.172495 Batch F1: 0.7083333333333334
Epoch:  294        7 Batch loss: 0.183458 Batch F1: 0.7666666666666667
Epoch:  294        8 Batch loss: 0.151886 Batch F1: 0.7027027027027027
Epoch:  294        9 Batch loss: 0.157547 Batch F1: 0.6451612903225806
Epoch:  294       10 Batch loss: 0.183477 Batch F1: 0.693877551020408
Epoch:  294       11 Batch loss: 0.174945 Batch F1: 0.606060606060606
Epoch:  294       12 Batch loss: 0.176871 Batch F1: 0.6470588235294117
Train Avg Loss  294: 0.171152

Train Avg F1  294: 0.7050872540452261

Val Avg Loss  294: 0.180874

Val Avg F1  294:  0.6731968017773644

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 295
--------------------------------------------------------------
Epoch:  295        1 Batch loss: 0.158450 Batch F1: 0.7692307692307692
Epoch:  295        2 Batch loss: 0.156398 Batch F1: 0.7906976744186046
Epoch:  295        3 Batch loss: 0.148308 Batch F1: 0.7659574468085107
Epoch:  295        4 Batch loss: 0.174263 Batch F1: 0.7199999999999999
Epoch:  295        5 Batch loss: 0.180651 Batch F1: 0.7199999999999999
Epoch:  295        6 Batch loss: 0.183352 Batch F1: 0.6666666666666666
Epoch:  295        7 Batch loss: 0.179049 Batch F1: 0.7083333333333334
Epoch:  295        8 Batch loss: 0.185994 Batch F1: 0.6153846153846153
Epoch:  295        9 Batch loss: 0.162484 Batch F1: 0.6829268292682927
Epoch:  295       10 Batch loss: 0.174513 Batch F1: 0.6956521739130435
Epoch:  295       11 Batch loss: 0.152621 Batch F1: 0.7727272727272727
Epoch:  295       12 Batch loss: 0.194512 Batch F1: 0.631578947368421
Train Avg Loss  295: 0.170883

Train Avg F1  295: 0.7115963107599607

Val Avg Loss  295: 0.183370

Val Avg F1  295:  0.6753944324344827

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 296
--------------------------------------------------------------
Epoch:  296        1 Batch loss: 0.159418 Batch F1: 0.8148148148148148
Epoch:  296        2 Batch loss: 0.161436 Batch F1: 0.782608695652174
Epoch:  296        3 Batch loss: 0.161545 Batch F1: 0.6976744186046512
Epoch:  296        4 Batch loss: 0.160744 Batch F1: 0.7027027027027027
Epoch:  296        5 Batch loss: 0.163057 Batch F1: 0.7755102040816326
Epoch:  296        6 Batch loss: 0.188041 Batch F1: 0.5142857142857143
Epoch:  296        7 Batch loss: 0.172105 Batch F1: 0.631578947368421
Epoch:  296        8 Batch loss: 0.155818 Batch F1: 0.7027027027027027
Epoch:  296        9 Batch loss: 0.206031 Batch F1: 0.625
Epoch:  296       10 Batch loss: 0.161283 Batch F1: 0.7500000000000001
Epoch:  296       11 Batch loss: 0.157622 Batch F1: 0.8214285714285715
Epoch:  296       12 Batch loss: 0.190699 Batch F1: 0.5882352941176471
Train Avg Loss  296: 0.169817

Train Avg F1  296: 0.700545172146586

Val Avg Loss  296: 0.181297

Val Avg F1  296:  0.6752952842056846

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 297
--------------------------------------------------------------
Epoch:  297        1 Batch loss: 0.154929 Batch F1: 0.6666666666666665
Epoch:  297        2 Batch loss: 0.168604 Batch F1: 0.7924528301886792
Epoch:  297        3 Batch loss: 0.153300 Batch F1: 0.8000000000000002
Epoch:  297        4 Batch loss: 0.175697 Batch F1: 0.7272727272727272
Epoch:  297        5 Batch loss: 0.191937 Batch F1: 0.6190476190476191
Epoch:  297        6 Batch loss: 0.181679 Batch F1: 0.5454545454545454
Epoch:  297        7 Batch loss: 0.154959 Batch F1: 0.7906976744186046
Epoch:  297        8 Batch loss: 0.147536 Batch F1: 0.8333333333333334
Epoch:  297        9 Batch loss: 0.158716 Batch F1: 0.717948717948718
Epoch:  297       10 Batch loss: 0.178839 Batch F1: 0.72
Epoch:  297       11 Batch loss: 0.217130 Batch F1: 0.5882352941176471
Epoch:  297       12 Batch loss: 0.169146 Batch F1: 0.6666666666666667
Train Avg Loss  297: 0.171039

Train Avg F1  297: 0.7056480062596004

Val Avg Loss  297: 0.184001

Val Avg F1  297:  0.6749381570810142

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 298
--------------------------------------------------------------
Epoch:  298        1 Batch loss: 0.165616 Batch F1: 0.7222222222222222
Epoch:  298        2 Batch loss: 0.153161 Batch F1: 0.7027027027027026
Epoch:  298        3 Batch loss: 0.213528 Batch F1: 0.6885245901639345
Epoch:  298        4 Batch loss: 0.160918 Batch F1: 0.8085106382978724
Epoch:  298        5 Batch loss: 0.177471 Batch F1: 0.6976744186046512
Epoch:  298        6 Batch loss: 0.202326 Batch F1: 0.608695652173913
Epoch:  298        7 Batch loss: 0.153583 Batch F1: 0.7555555555555556
Epoch:  298        8 Batch loss: 0.197948 Batch F1: 0.6222222222222222
Epoch:  298        9 Batch loss: 0.155003 Batch F1: 0.6857142857142857
Epoch:  298       10 Batch loss: 0.137204 Batch F1: 0.8372093023255814
Epoch:  298       11 Batch loss: 0.159728 Batch F1: 0.7727272727272727
Epoch:  298       12 Batch loss: 0.195908 Batch F1: 0.6666666666666666
Train Avg Loss  298: 0.172700

Train Avg F1  298: 0.7140354607814067

Val Avg Loss  298: 0.182459

Val Avg F1  298:  0.6708187095922944

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 299
--------------------------------------------------------------
Epoch:  299        1 Batch loss: 0.161953 Batch F1: 0.761904761904762
Epoch:  299        2 Batch loss: 0.197611 Batch F1: 0.5641025641025642
Epoch:  299        3 Batch loss: 0.164630 Batch F1: 0.6000000000000001
Epoch:  299        4 Batch loss: 0.149308 Batch F1: 0.8301886792452831
Epoch:  299        5 Batch loss: 0.179413 Batch F1: 0.7058823529411765
Epoch:  299        6 Batch loss: 0.179833 Batch F1: 0.6521739130434783
Epoch:  299        7 Batch loss: 0.175163 Batch F1: 0.723404255319149
Epoch:  299        8 Batch loss: 0.149837 Batch F1: 0.8085106382978724
Epoch:  299        9 Batch loss: 0.198617 Batch F1: 0.6666666666666667
Epoch:  299       10 Batch loss: 0.145440 Batch F1: 0.8
Epoch:  299       11 Batch loss: 0.189313 Batch F1: 0.6521739130434783
Epoch:  299       12 Batch loss: 0.166125 Batch F1: 0.7272727272727272
Train Avg Loss  299: 0.171437

Train Avg F1  299: 0.7076900393197633

Val Avg Loss  299: 0.182301

Val Avg F1  299:  0.6769195189639223

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 300
--------------------------------------------------------------
Epoch:  300        1 Batch loss: 0.163636 Batch F1: 0.7142857142857143
Epoch:  300        2 Batch loss: 0.145810 Batch F1: 0.7894736842105263
Epoch:  300        3 Batch loss: 0.160673 Batch F1: 0.6285714285714286
Epoch:  300        4 Batch loss: 0.184397 Batch F1: 0.6938775510204083
Epoch:  300        5 Batch loss: 0.169219 Batch F1: 0.7843137254901961
Epoch:  300        6 Batch loss: 0.184788 Batch F1: 0.7058823529411765
Epoch:  300        7 Batch loss: 0.185044 Batch F1: 0.7058823529411765
Epoch:  300        8 Batch loss: 0.160697 Batch F1: 0.7
Epoch:  300        9 Batch loss: 0.161321 Batch F1: 0.7317073170731707
Epoch:  300       10 Batch loss: 0.155994 Batch F1: 0.7500000000000001
Epoch:  300       11 Batch loss: 0.192736 Batch F1: 0.6363636363636365
Epoch:  300       12 Batch loss: 0.174915 Batch F1: 0.7058823529411765
Train Avg Loss  300: 0.169936

Train Avg F1  300: 0.7121866763198842

Val Avg Loss  300: 0.180847

Val Avg F1  300:  0.677464156394265

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 301
--------------------------------------------------------------
Epoch:  301        1 Batch loss: 0.195052 Batch F1: 0.6382978723404256
Epoch:  301        2 Batch loss: 0.107137 Batch F1: 0.9333333333333333
Epoch:  301        3 Batch loss: 0.182820 Batch F1: 0.711111111111111
Epoch:  301        4 Batch loss: 0.184633 Batch F1: 0.6511627906976745
Epoch:  301        5 Batch loss: 0.151212 Batch F1: 0.830188679245283
Epoch:  301        6 Batch loss: 0.158979 Batch F1: 0.7317073170731707
Epoch:  301        7 Batch loss: 0.211621 Batch F1: 0.6122448979591836
Epoch:  301        8 Batch loss: 0.148270 Batch F1: 0.8085106382978723
Epoch:  301        9 Batch loss: 0.158288 Batch F1: 0.7
Epoch:  301       10 Batch loss: 0.179496 Batch F1: 0.68
Epoch:  301       11 Batch loss: 0.164816 Batch F1: 0.7555555555555556
Epoch:  301       12 Batch loss: 0.211009 Batch F1: 0.5142857142857143
Train Avg Loss  301: 0.171111

Train Avg F1  301: 0.7138664924916104

Val Avg Loss  301: 0.181940

Val Avg F1  301:  0.6812062428896868

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 302
--------------------------------------------------------------
Epoch:  302        1 Batch loss: 0.197513 Batch F1: 0.55
Epoch:  302        2 Batch loss: 0.167243 Batch F1: 0.6976744186046512
Epoch:  302        3 Batch loss: 0.175579 Batch F1: 0.7692307692307692
Epoch:  302        4 Batch loss: 0.184413 Batch F1: 0.7
Epoch:  302        5 Batch loss: 0.164456 Batch F1: 0.7142857142857143
Epoch:  302        6 Batch loss: 0.169245 Batch F1: 0.7391304347826088
Epoch:  302        7 Batch loss: 0.180282 Batch F1: 0.7407407407407408
Epoch:  302        8 Batch loss: 0.155961 Batch F1: 0.761904761904762
Epoch:  302        9 Batch loss: 0.156230 Batch F1: 0.7317073170731707
Epoch:  302       10 Batch loss: 0.189845 Batch F1: 0.6153846153846153
Epoch:  302       11 Batch loss: 0.136116 Batch F1: 0.7906976744186046
Epoch:  302       12 Batch loss: 0.187062 Batch F1: 0.6976744186046512
Train Avg Loss  302: 0.171995

Train Avg F1  302: 0.7090359054191905

Val Avg Loss  302: 0.183169

Val Avg F1  302:  0.6788308618095852

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 303
--------------------------------------------------------------
Epoch:  303        1 Batch loss: 0.165931 Batch F1: 0.625
Epoch:  303        2 Batch loss: 0.163459 Batch F1: 0.7555555555555556
Epoch:  303        3 Batch loss: 0.170546 Batch F1: 0.6829268292682926
Epoch:  303        4 Batch loss: 0.155070 Batch F1: 0.7659574468085107
Epoch:  303        5 Batch loss: 0.204588 Batch F1: 0.48648648648648646
Epoch:  303        6 Batch loss: 0.190064 Batch F1: 0.7234042553191489
Epoch:  303        7 Batch loss: 0.153820 Batch F1: 0.7027027027027027
Epoch:  303        8 Batch loss: 0.160442 Batch F1: 0.7755102040816326
Epoch:  303        9 Batch loss: 0.171793 Batch F1: 0.7924528301886793
Epoch:  303       10 Batch loss: 0.170688 Batch F1: 0.7755102040816326
Epoch:  303       11 Batch loss: 0.190648 Batch F1: 0.6530612244897959
Epoch:  303       12 Batch loss: 0.150961 Batch F1: 0.8095238095238095
Train Avg Loss  303: 0.170668

Train Avg F1  303: 0.7123409623755205

Val Avg Loss  303: 0.183477

Val Avg F1  303:  0.6577205882352941

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 304
--------------------------------------------------------------
Epoch:  304        1 Batch loss: 0.179714 Batch F1: 0.7450980392156864
Epoch:  304        2 Batch loss: 0.170991 Batch F1: 0.5
Epoch:  304        3 Batch loss: 0.177546 Batch F1: 0.65
Epoch:  304        4 Batch loss: 0.174426 Batch F1: 0.6153846153846153
Epoch:  304        5 Batch loss: 0.178856 Batch F1: 0.6818181818181818
Epoch:  304        6 Batch loss: 0.138430 Batch F1: 0.8979591836734693
Epoch:  304        7 Batch loss: 0.153876 Batch F1: 0.7
Epoch:  304        8 Batch loss: 0.185608 Batch F1: 0.7058823529411765
Epoch:  304        9 Batch loss: 0.144387 Batch F1: 0.8333333333333334
Epoch:  304       10 Batch loss: 0.184313 Batch F1: 0.6521739130434783
Epoch:  304       11 Batch loss: 0.167862 Batch F1: 0.723404255319149
Epoch:  304       12 Batch loss: 0.190473 Batch F1: 0.7142857142857143
Train Avg Loss  304: 0.170540

Train Avg F1  304: 0.7016116324179004

Val Avg Loss  304: 0.180850

Val Avg F1  304:  0.6711375661375663

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 305
--------------------------------------------------------------
Epoch:  305        1 Batch loss: 0.156772 Batch F1: 0.6666666666666665
Epoch:  305        2 Batch loss: 0.187389 Batch F1: 0.48484848484848486
Epoch:  305        3 Batch loss: 0.176652 Batch F1: 0.6829268292682926
Epoch:  305        4 Batch loss: 0.158462 Batch F1: 0.7142857142857143
Epoch:  305        5 Batch loss: 0.160466 Batch F1: 0.7391304347826085
Epoch:  305        6 Batch loss: 0.205555 Batch F1: 0.6222222222222222
Epoch:  305        7 Batch loss: 0.130441 Batch F1: 0.8979591836734695
Epoch:  305        8 Batch loss: 0.173446 Batch F1: 0.7450980392156863
Epoch:  305        9 Batch loss: 0.158523 Batch F1: 0.7500000000000001
Epoch:  305       10 Batch loss: 0.181760 Batch F1: 0.7450980392156864
Epoch:  305       11 Batch loss: 0.183933 Batch F1: 0.6938775510204083
Epoch:  305       12 Batch loss: 0.170163 Batch F1: 0.7058823529411765
Train Avg Loss  305: 0.170297

Train Avg F1  305: 0.7039996265117012

Val Avg Loss  305: 0.181475

Val Avg F1  305:  0.6773352713178293

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 306
--------------------------------------------------------------
Epoch:  306        1 Batch loss: 0.153652 Batch F1: 0.7906976744186046
Epoch:  306        2 Batch loss: 0.165312 Batch F1: 0.76
Epoch:  306        3 Batch loss: 0.168563 Batch F1: 0.7
Epoch:  306        4 Batch loss: 0.181801 Batch F1: 0.6818181818181819
Epoch:  306        5 Batch loss: 0.177788 Batch F1: 0.6521739130434783
Epoch:  306        6 Batch loss: 0.168307 Batch F1: 0.76
Epoch:  306        7 Batch loss: 0.145229 Batch F1: 0.7906976744186046
Epoch:  306        8 Batch loss: 0.173962 Batch F1: 0.6666666666666666
Epoch:  306        9 Batch loss: 0.160345 Batch F1: 0.7619047619047619
Epoch:  306       10 Batch loss: 0.184953 Batch F1: 0.5789473684210527
Epoch:  306       11 Batch loss: 0.175337 Batch F1: 0.7499999999999999
Epoch:  306       12 Batch loss: 0.198681 Batch F1: 0.6153846153846154
Train Avg Loss  306: 0.171161

Train Avg F1  306: 0.7090242380063304

Val Avg Loss  306: 0.184080

Val Avg F1  306:  0.6682012717045732

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 307
--------------------------------------------------------------
Epoch:  307        1 Batch loss: 0.171862 Batch F1: 0.7272727272727272
Epoch:  307        2 Batch loss: 0.174116 Batch F1: 0.7391304347826089
Epoch:  307        3 Batch loss: 0.210128 Batch F1: 0.64
Epoch:  307        4 Batch loss: 0.154918 Batch F1: 0.7027027027027027
Epoch:  307        5 Batch loss: 0.173766 Batch F1: 0.76
Epoch:  307        6 Batch loss: 0.154406 Batch F1: 0.7727272727272727
Epoch:  307        7 Batch loss: 0.161551 Batch F1: 0.8076923076923077
Epoch:  307        8 Batch loss: 0.152989 Batch F1: 0.782608695652174
Epoch:  307        9 Batch loss: 0.196621 Batch F1: 0.5777777777777778
Epoch:  307       10 Batch loss: 0.158713 Batch F1: 0.5806451612903226
Epoch:  307       11 Batch loss: 0.169590 Batch F1: 0.6976744186046512
Epoch:  307       12 Batch loss: 0.161591 Batch F1: 0.7222222222222222
Train Avg Loss  307: 0.170021

Train Avg F1  307: 0.7092044767270639

Val Avg Loss  307: 0.182287

Val Avg F1  307:  0.6781538208168643

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 308
--------------------------------------------------------------
Epoch:  308        1 Batch loss: 0.151249 Batch F1: 0.7441860465116279
Epoch:  308        2 Batch loss: 0.169276 Batch F1: 0.7450980392156864
Epoch:  308        3 Batch loss: 0.190978 Batch F1: 0.7037037037037038
Epoch:  308        4 Batch loss: 0.183944 Batch F1: 0.68
Epoch:  308        5 Batch loss: 0.182695 Batch F1: 0.7407407407407408
Epoch:  308        6 Batch loss: 0.176263 Batch F1: 0.7142857142857143
Epoch:  308        7 Batch loss: 0.183823 Batch F1: 0.631578947368421
Epoch:  308        8 Batch loss: 0.154551 Batch F1: 0.7441860465116279
Epoch:  308        9 Batch loss: 0.157732 Batch F1: 0.7
Epoch:  308       10 Batch loss: 0.161134 Batch F1: 0.7727272727272727
Epoch:  308       11 Batch loss: 0.162307 Batch F1: 0.65
Epoch:  308       12 Batch loss: 0.153303 Batch F1: 0.6923076923076924
Train Avg Loss  308: 0.168938

Train Avg F1  308: 0.7099011836143739

Val Avg Loss  308: 0.182592

Val Avg F1  308:  0.6787013991513485

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 309
--------------------------------------------------------------
Epoch:  309        1 Batch loss: 0.174346 Batch F1: 0.7692307692307692
Epoch:  309        2 Batch loss: 0.207026 Batch F1: 0.6415094339622641
Epoch:  309        3 Batch loss: 0.169290 Batch F1: 0.6486486486486486
Epoch:  309        4 Batch loss: 0.138034 Batch F1: 0.8444444444444444
Epoch:  309        5 Batch loss: 0.187643 Batch F1: 0.5853658536585366
Epoch:  309        6 Batch loss: 0.168128 Batch F1: 0.7
Epoch:  309        7 Batch loss: 0.188701 Batch F1: 0.6046511627906977
Epoch:  309        8 Batch loss: 0.141042 Batch F1: 0.7804878048780488
Epoch:  309        9 Batch loss: 0.157264 Batch F1: 0.7755102040816326
Epoch:  309       10 Batch loss: 0.191763 Batch F1: 0.5789473684210527
Epoch:  309       11 Batch loss: 0.166520 Batch F1: 0.7692307692307692
Epoch:  309       12 Batch loss: 0.138325 Batch F1: 0.8235294117647058
Train Avg Loss  309: 0.169007

Train Avg F1  309: 0.7101296559259641

Val Avg Loss  309: 0.182865

Val Avg F1  309:  0.656288873339553

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 310
--------------------------------------------------------------
Epoch:  310        1 Batch loss: 0.175181 Batch F1: 0.723404255319149
Epoch:  310        2 Batch loss: 0.167561 Batch F1: 0.7441860465116279
Epoch:  310        3 Batch loss: 0.190743 Batch F1: 0.68
Epoch:  310        4 Batch loss: 0.165265 Batch F1: 0.6666666666666667
Epoch:  310        5 Batch loss: 0.137381 Batch F1: 0.8372093023255814
Epoch:  310        6 Batch loss: 0.185836 Batch F1: 0.6190476190476191
Epoch:  310        7 Batch loss: 0.180169 Batch F1: 0.6666666666666666
Epoch:  310        8 Batch loss: 0.162152 Batch F1: 0.6956521739130435
Epoch:  310        9 Batch loss: 0.179102 Batch F1: 0.7083333333333334
Epoch:  310       10 Batch loss: 0.184695 Batch F1: 0.65
Epoch:  310       11 Batch loss: 0.151911 Batch F1: 0.7441860465116279
Epoch:  310       12 Batch loss: 0.146635 Batch F1: 0.8205128205128205
Train Avg Loss  310: 0.168886

Train Avg F1  310: 0.7129887442340115

Val Avg Loss  310: 0.180397

Val Avg F1  310:  0.6698569687830825

Optimal Val loss (Epoch 279): 0.18017501384019852

Epoch 311
--------------------------------------------------------------
Epoch:  311        1 Batch loss: 0.146084 Batch F1: 0.7826086956521738
Epoch:  311        2 Batch loss: 0.155499 Batch F1: 0.8
Epoch:  311        3 Batch loss: 0.166767 Batch F1: 0.7843137254901961
Epoch:  311        4 Batch loss: 0.183930 Batch F1: 0.6363636363636364
Epoch:  311        5 Batch loss: 0.177977 Batch F1: 0.7307692307692308
Epoch:  311        6 Batch loss: 0.153261 Batch F1: 0.6250000000000001
Epoch:  311        7 Batch loss: 0.176251 Batch F1: 0.6511627906976744
Epoch:  311        8 Batch loss: 0.173903 Batch F1: 0.6341463414634148
Epoch:  311        9 Batch loss: 0.173312 Batch F1: 0.6976744186046512
Epoch:  311       10 Batch loss: 0.188911 Batch F1: 0.6363636363636365
Epoch:  311       11 Batch loss: 0.130930 Batch F1: 0.8205128205128205
Epoch:  311       12 Batch loss: 0.195531 Batch F1: 0.7111111111111111
Train Avg Loss  311: 0.168530

Train Avg F1  311: 0.7091688672523788

Val Avg Loss  311: 0.179904

Val Avg F1  311:  0.6727931488801054

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 312
--------------------------------------------------------------
Epoch:  312        1 Batch loss: 0.139688 Batch F1: 0.8181818181818182
Epoch:  312        2 Batch loss: 0.143586 Batch F1: 0.8163265306122449
Epoch:  312        3 Batch loss: 0.172980 Batch F1: 0.7142857142857143
Epoch:  312        4 Batch loss: 0.175716 Batch F1: 0.6511627906976744
Epoch:  312        5 Batch loss: 0.172460 Batch F1: 0.7083333333333334
Epoch:  312        6 Batch loss: 0.168891 Batch F1: 0.6666666666666666
Epoch:  312        7 Batch loss: 0.149855 Batch F1: 0.8
Epoch:  312        8 Batch loss: 0.188237 Batch F1: 0.6
Epoch:  312        9 Batch loss: 0.186513 Batch F1: 0.7083333333333333
Epoch:  312       10 Batch loss: 0.182189 Batch F1: 0.6808510638297872
Epoch:  312       11 Batch loss: 0.177253 Batch F1: 0.5714285714285715
Epoch:  312       12 Batch loss: 0.166509 Batch F1: 0.761904761904762
Train Avg Loss  312: 0.168656

Train Avg F1  312: 0.7081228820228255

Val Avg Loss  312: 0.181690

Val Avg F1  312:  0.6829791388510369

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 313
--------------------------------------------------------------
Epoch:  313        1 Batch loss: 0.171245 Batch F1: 0.7
Epoch:  313        2 Batch loss: 0.156291 Batch F1: 0.7755102040816326
Epoch:  313        3 Batch loss: 0.170572 Batch F1: 0.7450980392156864
Epoch:  313        4 Batch loss: 0.174301 Batch F1: 0.6666666666666666
Epoch:  313        5 Batch loss: 0.152065 Batch F1: 0.64
Epoch:  313        6 Batch loss: 0.152593 Batch F1: 0.7142857142857143
Epoch:  313        7 Batch loss: 0.195719 Batch F1: 0.6122448979591836
Epoch:  313        8 Batch loss: 0.170385 Batch F1: 0.6976744186046512
Epoch:  313        9 Batch loss: 0.158967 Batch F1: 0.7916666666666667
Epoch:  313       10 Batch loss: 0.176807 Batch F1: 0.6511627906976744
Epoch:  313       11 Batch loss: 0.195763 Batch F1: 0.7142857142857143
Epoch:  313       12 Batch loss: 0.149303 Batch F1: 0.8108108108108109
Train Avg Loss  313: 0.168668

Train Avg F1  313: 0.7099504936062001

Val Avg Loss  313: 0.181232

Val Avg F1  313:  0.6758293503957242

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 314
--------------------------------------------------------------
Epoch:  314        1 Batch loss: 0.173737 Batch F1: 0.5714285714285715
Epoch:  314        2 Batch loss: 0.168898 Batch F1: 0.7777777777777778
Epoch:  314        3 Batch loss: 0.163150 Batch F1: 0.7272727272727272
Epoch:  314        4 Batch loss: 0.144363 Batch F1: 0.823529411764706
Epoch:  314        5 Batch loss: 0.180265 Batch F1: 0.7727272727272727
Epoch:  314        6 Batch loss: 0.180118 Batch F1: 0.6956521739130435
Epoch:  314        7 Batch loss: 0.147084 Batch F1: 0.6206896551724138
Epoch:  314        8 Batch loss: 0.174802 Batch F1: 0.6666666666666666
Epoch:  314        9 Batch loss: 0.168222 Batch F1: 0.7499999999999999
Epoch:  314       10 Batch loss: 0.177100 Batch F1: 0.7636363636363636
Epoch:  314       11 Batch loss: 0.182759 Batch F1: 0.5945945945945946
Epoch:  314       12 Batch loss: 0.179293 Batch F1: 0.7142857142857143
Train Avg Loss  314: 0.169983

Train Avg F1  314: 0.706521744103321

Val Avg Loss  314: 0.180434

Val Avg F1  314:  0.6766061332099068

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 315
--------------------------------------------------------------
Epoch:  315        1 Batch loss: 0.144768 Batch F1: 0.84
Epoch:  315        2 Batch loss: 0.184859 Batch F1: 0.6666666666666666
Epoch:  315        3 Batch loss: 0.184600 Batch F1: 0.6666666666666666
Epoch:  315        4 Batch loss: 0.183422 Batch F1: 0.6808510638297872
Epoch:  315        5 Batch loss: 0.139404 Batch F1: 0.8372093023255814
Epoch:  315        6 Batch loss: 0.181274 Batch F1: 0.6341463414634146
Epoch:  315        7 Batch loss: 0.175212 Batch F1: 0.6842105263157895
Epoch:  315        8 Batch loss: 0.190350 Batch F1: 0.6923076923076924
Epoch:  315        9 Batch loss: 0.189139 Batch F1: 0.65
Epoch:  315       10 Batch loss: 0.133168 Batch F1: 0.8444444444444444
Epoch:  315       11 Batch loss: 0.158255 Batch F1: 0.7500000000000001
Epoch:  315       12 Batch loss: 0.201165 Batch F1: 0.5454545454545455
Train Avg Loss  315: 0.172135

Train Avg F1  315: 0.7076631041228824

Val Avg Loss  315: 0.184573

Val Avg F1  315:  0.6462696920873613

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 316
--------------------------------------------------------------
Epoch:  316        1 Batch loss: 0.178114 Batch F1: 0.6976744186046512
Epoch:  316        2 Batch loss: 0.204592 Batch F1: 0.5365853658536585
Epoch:  316        3 Batch loss: 0.164684 Batch F1: 0.6666666666666665
Epoch:  316        4 Batch loss: 0.160322 Batch F1: 0.6842105263157895
Epoch:  316        5 Batch loss: 0.204610 Batch F1: 0.5777777777777778
Epoch:  316        6 Batch loss: 0.167956 Batch F1: 0.7619047619047619
Epoch:  316        7 Batch loss: 0.183033 Batch F1: 0.7037037037037037
Epoch:  316        8 Batch loss: 0.170648 Batch F1: 0.6818181818181818
Epoch:  316        9 Batch loss: 0.176156 Batch F1: 0.736842105263158
Epoch:  316       10 Batch loss: 0.160339 Batch F1: 0.6976744186046512
Epoch:  316       11 Batch loss: 0.152575 Batch F1: 0.8085106382978724
Epoch:  316       12 Batch loss: 0.148712 Batch F1: 0.8372093023255814
Train Avg Loss  316: 0.172645

Train Avg F1  316: 0.6992148222613711

Val Avg Loss  316: 0.183790

Val Avg F1  316:  0.677964703941943

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 317
--------------------------------------------------------------
Epoch:  317        1 Batch loss: 0.197201 Batch F1: 0.6521739130434783
Epoch:  317        2 Batch loss: 0.165674 Batch F1: 0.7555555555555555
Epoch:  317        3 Batch loss: 0.171085 Batch F1: 0.7027027027027027
Epoch:  317        4 Batch loss: 0.135433 Batch F1: 0.8444444444444444
Epoch:  317        5 Batch loss: 0.157238 Batch F1: 0.6857142857142857
Epoch:  317        6 Batch loss: 0.187974 Batch F1: 0.68
Epoch:  317        7 Batch loss: 0.178575 Batch F1: 0.6808510638297872
Epoch:  317        8 Batch loss: 0.176090 Batch F1: 0.6666666666666666
Epoch:  317        9 Batch loss: 0.176215 Batch F1: 0.7058823529411765
Epoch:  317       10 Batch loss: 0.164204 Batch F1: 0.7346938775510203
Epoch:  317       11 Batch loss: 0.164128 Batch F1: 0.7391304347826088
Epoch:  317       12 Batch loss: 0.183196 Batch F1: 0.6285714285714286
Train Avg Loss  317: 0.171418

Train Avg F1  317: 0.7063655604835962

Val Avg Loss  317: 0.181940

Val Avg F1  317:  0.660715871254162

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 318
--------------------------------------------------------------
Epoch:  318        1 Batch loss: 0.157882 Batch F1: 0.816326530612245
Epoch:  318        2 Batch loss: 0.179510 Batch F1: 0.7083333333333334
Epoch:  318        3 Batch loss: 0.151218 Batch F1: 0.8181818181818182
Epoch:  318        4 Batch loss: 0.202656 Batch F1: 0.6382978723404256
Epoch:  318        5 Batch loss: 0.140329 Batch F1: 0.7777777777777777
Epoch:  318        6 Batch loss: 0.201838 Batch F1: 0.5853658536585366
Epoch:  318        7 Batch loss: 0.172948 Batch F1: 0.6153846153846154
Epoch:  318        8 Batch loss: 0.186176 Batch F1: 0.5853658536585366
Epoch:  318        9 Batch loss: 0.118907 Batch F1: 0.9166666666666666
Epoch:  318       10 Batch loss: 0.188452 Batch F1: 0.693877551020408
Epoch:  318       11 Batch loss: 0.171338 Batch F1: 0.7111111111111111
Epoch:  318       12 Batch loss: 0.182832 Batch F1: 0.631578947368421
Train Avg Loss  318: 0.171174

Train Avg F1  318: 0.7081889942594913

Val Avg Loss  318: 0.181154

Val Avg F1  318:  0.6739020042606844

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 319
--------------------------------------------------------------
Epoch:  319        1 Batch loss: 0.172123 Batch F1: 0.6976744186046512
Epoch:  319        2 Batch loss: 0.179606 Batch F1: 0.5945945945945945
Epoch:  319        3 Batch loss: 0.152061 Batch F1: 0.7916666666666667
Epoch:  319        4 Batch loss: 0.168838 Batch F1: 0.6285714285714287
Epoch:  319        5 Batch loss: 0.179099 Batch F1: 0.7547169811320754
Epoch:  319        6 Batch loss: 0.192366 Batch F1: 0.6363636363636365
Epoch:  319        7 Batch loss: 0.150440 Batch F1: 0.7441860465116279
Epoch:  319        8 Batch loss: 0.160146 Batch F1: 0.7659574468085107
Epoch:  319        9 Batch loss: 0.167043 Batch F1: 0.7777777777777777
Epoch:  319       10 Batch loss: 0.155502 Batch F1: 0.8076923076923077
Epoch:  319       11 Batch loss: 0.196908 Batch F1: 0.5714285714285715
Epoch:  319       12 Batch loss: 0.179601 Batch F1: 0.6470588235294118
Train Avg Loss  319: 0.171144

Train Avg F1  319: 0.7014740583067716

Val Avg Loss  319: 0.184269

Val Avg F1  319:  0.6743816519742908

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 320
--------------------------------------------------------------
Epoch:  320        1 Batch loss: 0.162064 Batch F1: 0.7555555555555555
Epoch:  320        2 Batch loss: 0.174937 Batch F1: 0.7924528301886793
Epoch:  320        3 Batch loss: 0.142096 Batch F1: 0.7894736842105262
Epoch:  320        4 Batch loss: 0.180119 Batch F1: 0.7307692307692308
Epoch:  320        5 Batch loss: 0.199602 Batch F1: 0.55
Epoch:  320        6 Batch loss: 0.191898 Batch F1: 0.5909090909090908
Epoch:  320        7 Batch loss: 0.167305 Batch F1: 0.6666666666666667
Epoch:  320        8 Batch loss: 0.180361 Batch F1: 0.6511627906976744
Epoch:  320        9 Batch loss: 0.181148 Batch F1: 0.7346938775510204
Epoch:  320       10 Batch loss: 0.151233 Batch F1: 0.6857142857142857
Epoch:  320       11 Batch loss: 0.169030 Batch F1: 0.8076923076923077
Epoch:  320       12 Batch loss: 0.212687 Batch F1: 0.7111111111111111
Train Avg Loss  320: 0.176040

Train Avg F1  320: 0.7055167859221791

Val Avg Loss  320: 0.182648

Val Avg F1  320:  0.7574490420034086

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 321
--------------------------------------------------------------
Epoch:  321        1 Batch loss: 0.154004 Batch F1: 0.8928571428571429
Epoch:  321        2 Batch loss: 0.176047 Batch F1: 0.6938775510204083
Epoch:  321        3 Batch loss: 0.152577 Batch F1: 0.761904761904762
Epoch:  321        4 Batch loss: 0.185693 Batch F1: 0.723404255319149
Epoch:  321        5 Batch loss: 0.148471 Batch F1: 0.7692307692307692
Epoch:  321        6 Batch loss: 0.166729 Batch F1: 0.7111111111111111
Epoch:  321        7 Batch loss: 0.165477 Batch F1: 0.6829268292682927
Epoch:  321        8 Batch loss: 0.130517 Batch F1: 0.8205128205128205
Epoch:  321        9 Batch loss: 0.183534 Batch F1: 0.7083333333333334
Epoch:  321       10 Batch loss: 0.189062 Batch F1: 0.6666666666666666
Epoch:  321       11 Batch loss: 0.185004 Batch F1: 0.6511627906976744
Epoch:  321       12 Batch loss: 0.192967 Batch F1: 0.5161290322580646
Train Avg Loss  321: 0.169174

Train Avg F1  321: 0.7165097553483495

Val Avg Loss  321: 0.182716

Val Avg F1  321:  0.6765354211006385

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 322
--------------------------------------------------------------
Epoch:  322        1 Batch loss: 0.168787 Batch F1: 0.6486486486486486
Epoch:  322        2 Batch loss: 0.151681 Batch F1: 0.7804878048780488
Epoch:  322        3 Batch loss: 0.188299 Batch F1: 0.6190476190476191
Epoch:  322        4 Batch loss: 0.171969 Batch F1: 0.7346938775510204
Epoch:  322        5 Batch loss: 0.194589 Batch F1: 0.5909090909090908
Epoch:  322        6 Batch loss: 0.135553 Batch F1: 0.8749999999999999
Epoch:  322        7 Batch loss: 0.181370 Batch F1: 0.6511627906976744
Epoch:  322        8 Batch loss: 0.174319 Batch F1: 0.6938775510204083
Epoch:  322        9 Batch loss: 0.174151 Batch F1: 0.6341463414634148
Epoch:  322       10 Batch loss: 0.171187 Batch F1: 0.7346938775510203
Epoch:  322       11 Batch loss: 0.158299 Batch F1: 0.782608695652174
Epoch:  322       12 Batch loss: 0.155723 Batch F1: 0.7777777777777778
Train Avg Loss  322: 0.168827

Train Avg F1  322: 0.7102545062664082

Val Avg Loss  322: 0.181182

Val Avg F1  322:  0.6753782505910166

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 323
--------------------------------------------------------------
Epoch:  323        1 Batch loss: 0.158309 Batch F1: 0.7727272727272727
Epoch:  323        2 Batch loss: 0.183847 Batch F1: 0.6363636363636365
Epoch:  323        3 Batch loss: 0.160314 Batch F1: 0.7692307692307692
Epoch:  323        4 Batch loss: 0.197099 Batch F1: 0.5641025641025641
Epoch:  323        5 Batch loss: 0.165712 Batch F1: 0.717948717948718
Epoch:  323        6 Batch loss: 0.176973 Batch F1: 0.7234042553191489
Epoch:  323        7 Batch loss: 0.142249 Batch F1: 0.8999999999999999
Epoch:  323        8 Batch loss: 0.157605 Batch F1: 0.782608695652174
Epoch:  323        9 Batch loss: 0.190867 Batch F1: 0.6521739130434783
Epoch:  323       10 Batch loss: 0.156036 Batch F1: 0.6857142857142857
Epoch:  323       11 Batch loss: 0.169586 Batch F1: 0.65
Epoch:  323       12 Batch loss: 0.197242 Batch F1: 0.5454545454545455
Train Avg Loss  323: 0.171320

Train Avg F1  323: 0.6999773879630494

Val Avg Loss  323: 0.182864

Val Avg F1  323:  0.6660263495369878

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 324
--------------------------------------------------------------
Epoch:  324        1 Batch loss: 0.173874 Batch F1: 0.7234042553191489
Epoch:  324        2 Batch loss: 0.176901 Batch F1: 0.6956521739130435
Epoch:  324        3 Batch loss: 0.163396 Batch F1: 0.7391304347826088
Epoch:  324        4 Batch loss: 0.150779 Batch F1: 0.8518518518518519
Epoch:  324        5 Batch loss: 0.172154 Batch F1: 0.7
Epoch:  324        6 Batch loss: 0.179870 Batch F1: 0.6666666666666666
Epoch:  324        7 Batch loss: 0.147314 Batch F1: 0.7499999999999999
Epoch:  324        8 Batch loss: 0.141816 Batch F1: 0.7826086956521738
Epoch:  324        9 Batch loss: 0.201034 Batch F1: 0.5777777777777778
Epoch:  324       10 Batch loss: 0.201880 Batch F1: 0.5555555555555556
Epoch:  324       11 Batch loss: 0.167268 Batch F1: 0.7659574468085107
Epoch:  324       12 Batch loss: 0.172893 Batch F1: 0.6666666666666666
Train Avg Loss  324: 0.170765

Train Avg F1  324: 0.7062726270828336

Val Avg Loss  324: 0.182566

Val Avg F1  324:  0.678108003108003

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 325
--------------------------------------------------------------
Epoch:  325        1 Batch loss: 0.136232 Batch F1: 0.8372093023255814
Epoch:  325        2 Batch loss: 0.171901 Batch F1: 0.7272727272727272
Epoch:  325        3 Batch loss: 0.204709 Batch F1: 0.6666666666666666
Epoch:  325        4 Batch loss: 0.207116 Batch F1: 0.4615384615384615
Epoch:  325        5 Batch loss: 0.189921 Batch F1: 0.7083333333333334
Epoch:  325        6 Batch loss: 0.183026 Batch F1: 0.6382978723404256
Epoch:  325        7 Batch loss: 0.189909 Batch F1: 0.7407407407407408
Epoch:  325        8 Batch loss: 0.147332 Batch F1: 0.816326530612245
Epoch:  325        9 Batch loss: 0.166528 Batch F1: 0.6666666666666666
Epoch:  325       10 Batch loss: 0.140438 Batch F1: 0.8333333333333334
Epoch:  325       11 Batch loss: 0.170379 Batch F1: 0.6976744186046512
Epoch:  325       12 Batch loss: 0.155578 Batch F1: 0.7567567567567567
Train Avg Loss  325: 0.171922

Train Avg F1  325: 0.7125680675159658

Val Avg Loss  325: 0.187715

Val Avg F1  325:  0.6822334854385788

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 326
--------------------------------------------------------------
Epoch:  326        1 Batch loss: 0.167692 Batch F1: 0.6829268292682926
Epoch:  326        2 Batch loss: 0.194061 Batch F1: 0.6382978723404256
Epoch:  326        3 Batch loss: 0.178478 Batch F1: 0.6111111111111113
Epoch:  326        4 Batch loss: 0.167780 Batch F1: 0.8148148148148148
Epoch:  326        5 Batch loss: 0.137047 Batch F1: 0.7906976744186046
Epoch:  326        6 Batch loss: 0.161122 Batch F1: 0.7555555555555556
Epoch:  326        7 Batch loss: 0.146748 Batch F1: 0.8181818181818182
Epoch:  326        8 Batch loss: 0.201637 Batch F1: 0.5853658536585366
Epoch:  326        9 Batch loss: 0.204681 Batch F1: 0.6545454545454545
Epoch:  326       10 Batch loss: 0.185576 Batch F1: 0.7368421052631579
Epoch:  326       11 Batch loss: 0.168209 Batch F1: 0.625
Epoch:  326       12 Batch loss: 0.147456 Batch F1: 0.75
Train Avg Loss  326: 0.171707

Train Avg F1  326: 0.7052782574298142

Val Avg Loss  326: 0.181391

Val Avg F1  326:  0.6764539007092198

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 327
--------------------------------------------------------------
Epoch:  327        1 Batch loss: 0.156348 Batch F1: 0.8085106382978724
Epoch:  327        2 Batch loss: 0.162892 Batch F1: 0.6956521739130435
Epoch:  327        3 Batch loss: 0.181857 Batch F1: 0.693877551020408
Epoch:  327        4 Batch loss: 0.174467 Batch F1: 0.7450980392156863
Epoch:  327        5 Batch loss: 0.164200 Batch F1: 0.8235294117647058
Epoch:  327        6 Batch loss: 0.168527 Batch F1: 0.7692307692307692
Epoch:  327        7 Batch loss: 0.174650 Batch F1: 0.6829268292682926
Epoch:  327        8 Batch loss: 0.161103 Batch F1: 0.7317073170731706
Epoch:  327        9 Batch loss: 0.172835 Batch F1: 0.5294117647058824
Epoch:  327       10 Batch loss: 0.165309 Batch F1: 0.7272727272727272
Epoch:  327       11 Batch loss: 0.162698 Batch F1: 0.7391304347826089
Epoch:  327       12 Batch loss: 0.205493 Batch F1: 0.65
Train Avg Loss  327: 0.170865

Train Avg F1  327: 0.7163623047120972

Val Avg Loss  327: 0.181347

Val Avg F1  327:  0.676473090748202

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 328
--------------------------------------------------------------
Epoch:  328        1 Batch loss: 0.170229 Batch F1: 0.7272727272727272
Epoch:  328        2 Batch loss: 0.179260 Batch F1: 0.6956521739130435
Epoch:  328        3 Batch loss: 0.185309 Batch F1: 0.68
Epoch:  328        4 Batch loss: 0.186120 Batch F1: 0.8214285714285714
Epoch:  328        5 Batch loss: 0.187789 Batch F1: 0.7727272727272727
Epoch:  328        6 Batch loss: 0.185620 Batch F1: 0.6
Epoch:  328        7 Batch loss: 0.174863 Batch F1: 0.7111111111111111
Epoch:  328        8 Batch loss: 0.176487 Batch F1: 0.7441860465116279
Epoch:  328        9 Batch loss: 0.177307 Batch F1: 0.7027027027027027
Epoch:  328       10 Batch loss: 0.162334 Batch F1: 0.7916666666666667
Epoch:  328       11 Batch loss: 0.165842 Batch F1: 0.7272727272727273
Epoch:  328       12 Batch loss: 0.170532 Batch F1: 0.7692307692307692
Train Avg Loss  328: 0.176808

Train Avg F1  328: 0.728604230736435

Val Avg Loss  328: 0.182518

Val Avg F1  328:  0.680090822798464

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 329
--------------------------------------------------------------
Epoch:  329        1 Batch loss: 0.175521 Batch F1: 0.711111111111111
Epoch:  329        2 Batch loss: 0.186551 Batch F1: 0.6666666666666666
Epoch:  329        3 Batch loss: 0.162700 Batch F1: 0.6666666666666665
Epoch:  329        4 Batch loss: 0.147401 Batch F1: 0.8333333333333333
Epoch:  329        5 Batch loss: 0.158569 Batch F1: 0.717948717948718
Epoch:  329        6 Batch loss: 0.212412 Batch F1: 0.6037735849056605
Epoch:  329        7 Batch loss: 0.167361 Batch F1: 0.7111111111111111
Epoch:  329        8 Batch loss: 0.170202 Batch F1: 0.7692307692307693
Epoch:  329        9 Batch loss: 0.162048 Batch F1: 0.7500000000000001
Epoch:  329       10 Batch loss: 0.193955 Batch F1: 0.6938775510204083
Epoch:  329       11 Batch loss: 0.140540 Batch F1: 0.8108108108108107
Epoch:  329       12 Batch loss: 0.193931 Batch F1: 0.6060606060606061
Train Avg Loss  329: 0.172599

Train Avg F1  329: 0.7117159107388217

Val Avg Loss  329: 0.184517

Val Avg F1  329:  0.67420806706521

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 330
--------------------------------------------------------------
Epoch:  330        1 Batch loss: 0.167448 Batch F1: 0.6976744186046512
Epoch:  330        2 Batch loss: 0.176963 Batch F1: 0.65
Epoch:  330        3 Batch loss: 0.179760 Batch F1: 0.6341463414634146
Epoch:  330        4 Batch loss: 0.200361 Batch F1: 0.64
Epoch:  330        5 Batch loss: 0.150292 Batch F1: 0.8
Epoch:  330        6 Batch loss: 0.160273 Batch F1: 0.7027027027027027
Epoch:  330        7 Batch loss: 0.131458 Batch F1: 0.8333333333333334
Epoch:  330        8 Batch loss: 0.195480 Batch F1: 0.6222222222222222
Epoch:  330        9 Batch loss: 0.176199 Batch F1: 0.6666666666666667
Epoch:  330       10 Batch loss: 0.146401 Batch F1: 0.7999999999999999
Epoch:  330       11 Batch loss: 0.191294 Batch F1: 0.7450980392156864
Epoch:  330       12 Batch loss: 0.184527 Batch F1: 0.75
Train Avg Loss  330: 0.171705

Train Avg F1  330: 0.7118203103507229

Val Avg Loss  330: 0.182278

Val Avg F1  330:  0.6767646983245965

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 331
--------------------------------------------------------------
Epoch:  331        1 Batch loss: 0.164014 Batch F1: 0.8000000000000002
Epoch:  331        2 Batch loss: 0.171451 Batch F1: 0.7199999999999999
Epoch:  331        3 Batch loss: 0.174820 Batch F1: 0.6190476190476191
Epoch:  331        4 Batch loss: 0.168041 Batch F1: 0.6829268292682926
Epoch:  331        5 Batch loss: 0.146956 Batch F1: 0.7647058823529411
Epoch:  331        6 Batch loss: 0.156324 Batch F1: 0.8
Epoch:  331        7 Batch loss: 0.188453 Batch F1: 0.7666666666666667
Epoch:  331        8 Batch loss: 0.160280 Batch F1: 0.7555555555555556
Epoch:  331        9 Batch loss: 0.200985 Batch F1: 0.6274509803921569
Epoch:  331       10 Batch loss: 0.169662 Batch F1: 0.7027027027027027
Epoch:  331       11 Batch loss: 0.193997 Batch F1: 0.5555555555555556
Epoch:  331       12 Batch loss: 0.161887 Batch F1: 0.625
Train Avg Loss  331: 0.171406

Train Avg F1  331: 0.7016343159617907

Val Avg Loss  331: 0.182285

Val Avg F1  331:  0.677671650055371

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 332
--------------------------------------------------------------
Epoch:  332        1 Batch loss: 0.183713 Batch F1: 0.6808510638297872
Epoch:  332        2 Batch loss: 0.168105 Batch F1: 0.75
Epoch:  332        3 Batch loss: 0.168941 Batch F1: 0.6829268292682926
Epoch:  332        4 Batch loss: 0.169583 Batch F1: 0.6285714285714287
Epoch:  332        5 Batch loss: 0.179167 Batch F1: 0.7500000000000001
Epoch:  332        6 Batch loss: 0.166159 Batch F1: 0.7547169811320755
Epoch:  332        7 Batch loss: 0.164442 Batch F1: 0.8936170212765957
Epoch:  332        8 Batch loss: 0.227431 Batch F1: 0.7272727272727272
Epoch:  332        9 Batch loss: 0.144214 Batch F1: 0.8
Epoch:  332       10 Batch loss: 0.192018 Batch F1: 0.5853658536585366
Epoch:  332       11 Batch loss: 0.184637 Batch F1: 0.6808510638297872
Epoch:  332       12 Batch loss: 0.139770 Batch F1: 0.8421052631578948
Train Avg Loss  332: 0.174015

Train Avg F1  332: 0.7313565193330938

Val Avg Loss  332: 0.182885

Val Avg F1  332:  0.6796148634563269

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 333
--------------------------------------------------------------
Epoch:  333        1 Batch loss: 0.153834 Batch F1: 0.7906976744186046
Epoch:  333        2 Batch loss: 0.165194 Batch F1: 0.7555555555555556
Epoch:  333        3 Batch loss: 0.161169 Batch F1: 0.7272727272727272
Epoch:  333        4 Batch loss: 0.174583 Batch F1: 0.76
Epoch:  333        5 Batch loss: 0.165807 Batch F1: 0.6486486486486487
Epoch:  333        6 Batch loss: 0.188413 Batch F1: 0.6829268292682927
Epoch:  333        7 Batch loss: 0.196937 Batch F1: 0.55
Epoch:  333        8 Batch loss: 0.184612 Batch F1: 0.7272727272727274
Epoch:  333        9 Batch loss: 0.182808 Batch F1: 0.6153846153846154
Epoch:  333       10 Batch loss: 0.194670 Batch F1: 0.5405405405405405
Epoch:  333       11 Batch loss: 0.185520 Batch F1: 0.6938775510204083
Epoch:  333       12 Batch loss: 0.150658 Batch F1: 0.8181818181818182
Train Avg Loss  333: 0.175351

Train Avg F1  333: 0.6925298906303282

Val Avg Loss  333: 0.208077

Val Avg F1  333:  0.8082170030811796

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 334
--------------------------------------------------------------
Epoch:  334        1 Batch loss: 0.218655 Batch F1: 0.7916666666666666
Epoch:  334        2 Batch loss: 0.188871 Batch F1: 0.6222222222222222
Epoch:  334        3 Batch loss: 0.173988 Batch F1: 0.7272727272727273
Epoch:  334        4 Batch loss: 0.163907 Batch F1: 0.8260869565217391
Epoch:  334        5 Batch loss: 0.188543 Batch F1: 0.6285714285714286
Epoch:  334        6 Batch loss: 0.180771 Batch F1: 0.6341463414634146
Epoch:  334        7 Batch loss: 0.199209 Batch F1: 0.6938775510204083
Epoch:  334        8 Batch loss: 0.189314 Batch F1: 0.6785714285714285
Epoch:  334        9 Batch loss: 0.167556 Batch F1: 0.7999999999999999
Epoch:  334       10 Batch loss: 0.184859 Batch F1: 0.7234042553191491
Epoch:  334       11 Batch loss: 0.175953 Batch F1: 0.7142857142857143
Epoch:  334       12 Batch loss: 0.171257 Batch F1: 0.7058823529411765
Train Avg Loss  334: 0.183574

Train Avg F1  334: 0.7121656370713397

Val Avg Loss  334: 0.193856

Val Avg F1  334:  0.673565924283944

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 335
--------------------------------------------------------------
Epoch:  335        1 Batch loss: 0.169267 Batch F1: 0.7659574468085107
Epoch:  335        2 Batch loss: 0.194332 Batch F1: 0.6938775510204083
Epoch:  335        3 Batch loss: 0.182879 Batch F1: 0.6923076923076923
Epoch:  335        4 Batch loss: 0.143080 Batch F1: 0.8717948717948718
Epoch:  335        5 Batch loss: 0.161708 Batch F1: 0.7555555555555555
Epoch:  335        6 Batch loss: 0.177017 Batch F1: 0.6285714285714287
Epoch:  335        7 Batch loss: 0.205584 Batch F1: 0.47058823529411764
Epoch:  335        8 Batch loss: 0.201874 Batch F1: 0.6666666666666667
Epoch:  335        9 Batch loss: 0.186390 Batch F1: 0.7307692307692308
Epoch:  335       10 Batch loss: 0.164371 Batch F1: 0.7272727272727272
Epoch:  335       11 Batch loss: 0.197583 Batch F1: 0.6666666666666666
Epoch:  335       12 Batch loss: 0.146175 Batch F1: 0.7878787878787877
Train Avg Loss  335: 0.177522

Train Avg F1  335: 0.704825571717222

Val Avg Loss  335: 0.183593

Val Avg F1  335:  0.674335504312621

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 336
--------------------------------------------------------------
Epoch:  336        1 Batch loss: 0.176908 Batch F1: 0.6976744186046512
Epoch:  336        2 Batch loss: 0.159438 Batch F1: 0.7555555555555556
Epoch:  336        3 Batch loss: 0.195928 Batch F1: 0.6222222222222222
Epoch:  336        4 Batch loss: 0.183943 Batch F1: 0.5365853658536586
Epoch:  336        5 Batch loss: 0.152406 Batch F1: 0.8095238095238095
Epoch:  336        6 Batch loss: 0.153640 Batch F1: 0.7567567567567567
Epoch:  336        7 Batch loss: 0.169922 Batch F1: 0.7924528301886793
Epoch:  336        8 Batch loss: 0.187180 Batch F1: 0.693877551020408
Epoch:  336        9 Batch loss: 0.192493 Batch F1: 0.7169811320754716
Epoch:  336       10 Batch loss: 0.157200 Batch F1: 0.7368421052631577
Epoch:  336       11 Batch loss: 0.200816 Batch F1: 0.6190476190476191
Epoch:  336       12 Batch loss: 0.188697 Batch F1: 0.6976744186046512
Train Avg Loss  336: 0.176548

Train Avg F1  336: 0.7029328153930535

Val Avg Loss  336: 0.183027

Val Avg F1  336:  0.6768006993006994

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 337
--------------------------------------------------------------
Epoch:  337        1 Batch loss: 0.161135 Batch F1: 0.7619047619047619
Epoch:  337        2 Batch loss: 0.152399 Batch F1: 0.7692307692307692
Epoch:  337        3 Batch loss: 0.188565 Batch F1: 0.5714285714285714
Epoch:  337        4 Batch loss: 0.182869 Batch F1: 0.6666666666666666
Epoch:  337        5 Batch loss: 0.168994 Batch F1: 0.7499999999999999
Epoch:  337        6 Batch loss: 0.170646 Batch F1: 0.7200000000000001
Epoch:  337        7 Batch loss: 0.168545 Batch F1: 0.723404255319149
Epoch:  337        8 Batch loss: 0.179908 Batch F1: 0.72
Epoch:  337        9 Batch loss: 0.158872 Batch F1: 0.7222222222222222
Epoch:  337       10 Batch loss: 0.182640 Batch F1: 0.6938775510204083
Epoch:  337       11 Batch loss: 0.178377 Batch F1: 0.7111111111111111
Epoch:  337       12 Batch loss: 0.186813 Batch F1: 0.7142857142857143
Train Avg Loss  337: 0.173314

Train Avg F1  337: 0.7103443019324479

Val Avg Loss  337: 0.182171

Val Avg F1  337:  0.6778741856150493

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 338
--------------------------------------------------------------
Epoch:  338        1 Batch loss: 0.185546 Batch F1: 0.6363636363636365
Epoch:  338        2 Batch loss: 0.165764 Batch F1: 0.7659574468085107
Epoch:  338        3 Batch loss: 0.182198 Batch F1: 0.7450980392156864
Epoch:  338        4 Batch loss: 0.178772 Batch F1: 0.6111111111111112
Epoch:  338        5 Batch loss: 0.135852 Batch F1: 0.7804878048780487
Epoch:  338        6 Batch loss: 0.170798 Batch F1: 0.6829268292682926
Epoch:  338        7 Batch loss: 0.189545 Batch F1: 0.6190476190476191
Epoch:  338        8 Batch loss: 0.186924 Batch F1: 0.7307692307692306
Epoch:  338        9 Batch loss: 0.157494 Batch F1: 0.7428571428571428
Epoch:  338       10 Batch loss: 0.166694 Batch F1: 0.7500000000000001
Epoch:  338       11 Batch loss: 0.170085 Batch F1: 0.6956521739130435
Epoch:  338       12 Batch loss: 0.163310 Batch F1: 0.7619047619047619
Train Avg Loss  338: 0.171082

Train Avg F1  338: 0.710181316344757

Val Avg Loss  338: 0.183348

Val Avg F1  338:  0.6701388888888888

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 339
--------------------------------------------------------------
Epoch:  339        1 Batch loss: 0.184554 Batch F1: 0.6382978723404256
Epoch:  339        2 Batch loss: 0.171859 Batch F1: 0.7692307692307693
Epoch:  339        3 Batch loss: 0.157832 Batch F1: 0.7317073170731708
Epoch:  339        4 Batch loss: 0.151359 Batch F1: 0.7999999999999999
Epoch:  339        5 Batch loss: 0.197288 Batch F1: 0.5945945945945946
Epoch:  339        6 Batch loss: 0.158033 Batch F1: 0.7755102040816326
Epoch:  339        7 Batch loss: 0.166682 Batch F1: 0.7659574468085107
Epoch:  339        8 Batch loss: 0.171346 Batch F1: 0.7450980392156864
Epoch:  339        9 Batch loss: 0.180615 Batch F1: 0.65
Epoch:  339       10 Batch loss: 0.166034 Batch F1: 0.7619047619047621
Epoch:  339       11 Batch loss: 0.185312 Batch F1: 0.6190476190476191
Epoch:  339       12 Batch loss: 0.163794 Batch F1: 0.5925925925925927
Train Avg Loss  339: 0.171226

Train Avg F1  339: 0.7036617680741469

Val Avg Loss  339: 0.182271

Val Avg F1  339:  0.6758364665811474

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 340
--------------------------------------------------------------
Epoch:  340        1 Batch loss: 0.177802 Batch F1: 0.6511627906976744
Epoch:  340        2 Batch loss: 0.152138 Batch F1: 0.6875
Epoch:  340        3 Batch loss: 0.171121 Batch F1: 0.6486486486486486
Epoch:  340        4 Batch loss: 0.178503 Batch F1: 0.6818181818181818
Epoch:  340        5 Batch loss: 0.219327 Batch F1: 0.5882352941176471
Epoch:  340        6 Batch loss: 0.137274 Batch F1: 0.8444444444444444
Epoch:  340        7 Batch loss: 0.139903 Batch F1: 0.8444444444444444
Epoch:  340        8 Batch loss: 0.165441 Batch F1: 0.8076923076923077
Epoch:  340        9 Batch loss: 0.194139 Batch F1: 0.6046511627906977
Epoch:  340       10 Batch loss: 0.190127 Batch F1: 0.68
Epoch:  340       11 Batch loss: 0.168624 Batch F1: 0.7142857142857143
Epoch:  340       12 Batch loss: 0.151295 Batch F1: 0.7999999999999999
Train Avg Loss  340: 0.170474

Train Avg F1  340: 0.7127402490783133

Val Avg Loss  340: 0.182784

Val Avg F1  340:  0.6747835497835497

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 341
--------------------------------------------------------------
Epoch:  341        1 Batch loss: 0.160548 Batch F1: 0.75
Epoch:  341        2 Batch loss: 0.170583 Batch F1: 0.76
Epoch:  341        3 Batch loss: 0.147975 Batch F1: 0.7317073170731708
Epoch:  341        4 Batch loss: 0.153294 Batch F1: 0.8000000000000002
Epoch:  341        5 Batch loss: 0.163359 Batch F1: 0.7317073170731706
Epoch:  341        6 Batch loss: 0.160710 Batch F1: 0.7391304347826085
Epoch:  341        7 Batch loss: 0.207245 Batch F1: 0.608695652173913
Epoch:  341        8 Batch loss: 0.170619 Batch F1: 0.7777777777777779
Epoch:  341        9 Batch loss: 0.165125 Batch F1: 0.7755102040816326
Epoch:  341       10 Batch loss: 0.171347 Batch F1: 0.6976744186046512
Epoch:  341       11 Batch loss: 0.195972 Batch F1: 0.45714285714285713
Epoch:  341       12 Batch loss: 0.178305 Batch F1: 0.6206896551724139
Train Avg Loss  341: 0.170423

Train Avg F1  341: 0.7041696361568497

Val Avg Loss  341: 0.182645

Val Avg F1  341:  0.6764013911620295

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 342
--------------------------------------------------------------
Epoch:  342        1 Batch loss: 0.180418 Batch F1: 0.7586206896551724
Epoch:  342        2 Batch loss: 0.184156 Batch F1: 0.6363636363636364
Epoch:  342        3 Batch loss: 0.168138 Batch F1: 0.6818181818181818
Epoch:  342        4 Batch loss: 0.188346 Batch F1: 0.6382978723404256
Epoch:  342        5 Batch loss: 0.149480 Batch F1: 0.7692307692307692
Epoch:  342        6 Batch loss: 0.132097 Batch F1: 0.8444444444444444
Epoch:  342        7 Batch loss: 0.166365 Batch F1: 0.7555555555555555
Epoch:  342        8 Batch loss: 0.188464 Batch F1: 0.6521739130434783
Epoch:  342        9 Batch loss: 0.155790 Batch F1: 0.7692307692307692
Epoch:  342       10 Batch loss: 0.162011 Batch F1: 0.6285714285714287
Epoch:  342       11 Batch loss: 0.199430 Batch F1: 0.6511627906976744
Epoch:  342       12 Batch loss: 0.163302 Batch F1: 0.7692307692307692
Train Avg Loss  342: 0.169833

Train Avg F1  342: 0.7128917350151921

Val Avg Loss  342: 0.181306

Val Avg F1  342:  0.6767832167832167

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 343
--------------------------------------------------------------
Epoch:  343        1 Batch loss: 0.162638 Batch F1: 0.76
Epoch:  343        2 Batch loss: 0.180745 Batch F1: 0.6153846153846154
Epoch:  343        3 Batch loss: 0.141863 Batch F1: 0.7777777777777778
Epoch:  343        4 Batch loss: 0.200640 Batch F1: 0.6222222222222223
Epoch:  343        5 Batch loss: 0.204183 Batch F1: 0.6785714285714285
Epoch:  343        6 Batch loss: 0.151648 Batch F1: 0.7826086956521738
Epoch:  343        7 Batch loss: 0.180479 Batch F1: 0.6315789473684211
Epoch:  343        8 Batch loss: 0.178043 Batch F1: 0.6666666666666666
Epoch:  343        9 Batch loss: 0.188097 Batch F1: 0.6818181818181818
Epoch:  343       10 Batch loss: 0.148089 Batch F1: 0.8
Epoch:  343       11 Batch loss: 0.160395 Batch F1: 0.7391304347826088
Epoch:  343       12 Batch loss: 0.137090 Batch F1: 0.8108108108108107
Train Avg Loss  343: 0.169493

Train Avg F1  343: 0.7138808150879089

Val Avg Loss  343: 0.182664

Val Avg F1  343:  0.6754875283446712

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 344
--------------------------------------------------------------
Epoch:  344        1 Batch loss: 0.181174 Batch F1: 0.6818181818181819
Epoch:  344        2 Batch loss: 0.176739 Batch F1: 0.7450980392156863
Epoch:  344        3 Batch loss: 0.135062 Batch F1: 0.823529411764706
Epoch:  344        4 Batch loss: 0.151448 Batch F1: 0.7317073170731708
Epoch:  344        5 Batch loss: 0.162385 Batch F1: 0.7499999999999999
Epoch:  344        6 Batch loss: 0.167600 Batch F1: 0.7441860465116279
Epoch:  344        7 Batch loss: 0.184898 Batch F1: 0.6511627906976745
Epoch:  344        8 Batch loss: 0.199681 Batch F1: 0.625
Epoch:  344        9 Batch loss: 0.152062 Batch F1: 0.7727272727272727
Epoch:  344       10 Batch loss: 0.174703 Batch F1: 0.723404255319149
Epoch:  344       11 Batch loss: 0.169430 Batch F1: 0.6666666666666666
Epoch:  344       12 Batch loss: 0.197795 Batch F1: 0.65
Train Avg Loss  344: 0.171081

Train Avg F1  344: 0.7137749984828446

Val Avg Loss  344: 0.181144

Val Avg F1  344:  0.6754657791583334

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 345
--------------------------------------------------------------
Epoch:  345        1 Batch loss: 0.171853 Batch F1: 0.7636363636363638
Epoch:  345        2 Batch loss: 0.143680 Batch F1: 0.7317073170731708
Epoch:  345        3 Batch loss: 0.155890 Batch F1: 0.8135593220338982
Epoch:  345        4 Batch loss: 0.156698 Batch F1: 0.8421052631578948
Epoch:  345        5 Batch loss: 0.173498 Batch F1: 0.6666666666666666
Epoch:  345        6 Batch loss: 0.183897 Batch F1: 0.5789473684210527
Epoch:  345        7 Batch loss: 0.198509 Batch F1: 0.6250000000000001
Epoch:  345        8 Batch loss: 0.194223 Batch F1: 0.6363636363636365
Epoch:  345        9 Batch loss: 0.203800 Batch F1: 0.6046511627906977
Epoch:  345       10 Batch loss: 0.181579 Batch F1: 0.6486486486486486
Epoch:  345       11 Batch loss: 0.154730 Batch F1: 0.7906976744186047
Epoch:  345       12 Batch loss: 0.167015 Batch F1: 0.6666666666666667
Train Avg Loss  345: 0.173781

Train Avg F1  345: 0.6973875074897751

Val Avg Loss  345: 0.185677

Val Avg F1  345:  0.6770833333333334

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 346
--------------------------------------------------------------
Epoch:  346        1 Batch loss: 0.182995 Batch F1: 0.5789473684210527
Epoch:  346        2 Batch loss: 0.188595 Batch F1: 0.7936507936507938
Epoch:  346        3 Batch loss: 0.182557 Batch F1: 0.7199999999999999
Epoch:  346        4 Batch loss: 0.161826 Batch F1: 0.7916666666666667
Epoch:  346        5 Batch loss: 0.190341 Batch F1: 0.6808510638297872
Epoch:  346        6 Batch loss: 0.167577 Batch F1: 0.6153846153846153
Epoch:  346        7 Batch loss: 0.188775 Batch F1: 0.5853658536585366
Epoch:  346        8 Batch loss: 0.155818 Batch F1: 0.7999999999999999
Epoch:  346        9 Batch loss: 0.151130 Batch F1: 0.7924528301886793
Epoch:  346       10 Batch loss: 0.166001 Batch F1: 0.5806451612903226
Epoch:  346       11 Batch loss: 0.176681 Batch F1: 0.6829268292682926
Epoch:  346       12 Batch loss: 0.160123 Batch F1: 0.7567567567567567
Train Avg Loss  346: 0.172702

Train Avg F1  346: 0.6982206615929586

Val Avg Loss  346: 0.184102

Val Avg F1  346:  0.6714424141749722

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 347
--------------------------------------------------------------
Epoch:  347        1 Batch loss: 0.218074 Batch F1: 0.6296296296296297
Epoch:  347        2 Batch loss: 0.175242 Batch F1: 0.7857142857142857
Epoch:  347        3 Batch loss: 0.149109 Batch F1: 0.7692307692307692
Epoch:  347        4 Batch loss: 0.161284 Batch F1: 0.6666666666666667
Epoch:  347        5 Batch loss: 0.161110 Batch F1: 0.7027027027027027
Epoch:  347        6 Batch loss: 0.177762 Batch F1: 0.6666666666666666
Epoch:  347        7 Batch loss: 0.170469 Batch F1: 0.6956521739130435
Epoch:  347        8 Batch loss: 0.183708 Batch F1: 0.8108108108108109
Epoch:  347        9 Batch loss: 0.196810 Batch F1: 0.5142857142857143
Epoch:  347       10 Batch loss: 0.151257 Batch F1: 0.6666666666666667
Epoch:  347       11 Batch loss: 0.237832 Batch F1: 0.5789473684210525
Epoch:  347       12 Batch loss: 0.164481 Batch F1: 0.7368421052631579
Train Avg Loss  347: 0.178928

Train Avg F1  347: 0.6853179633309305

Val Avg Loss  347: 0.182417

Val Avg F1  347:  0.7262959706399572

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 348
--------------------------------------------------------------
Epoch:  348        1 Batch loss: 0.199818 Batch F1: 0.6363636363636365
Epoch:  348        2 Batch loss: 0.183456 Batch F1: 0.7391304347826089
Epoch:  348        3 Batch loss: 0.166529 Batch F1: 0.7317073170731706
Epoch:  348        4 Batch loss: 0.179207 Batch F1: 0.6666666666666666
Epoch:  348        5 Batch loss: 0.179626 Batch F1: 0.7346938775510204
Epoch:  348        6 Batch loss: 0.179647 Batch F1: 0.6818181818181818
Epoch:  348        7 Batch loss: 0.183755 Batch F1: 0.6976744186046512
Epoch:  348        8 Batch loss: 0.152699 Batch F1: 0.7906976744186046
Epoch:  348        9 Batch loss: 0.164980 Batch F1: 0.7826086956521738
Epoch:  348       10 Batch loss: 0.183215 Batch F1: 0.6545454545454547
Epoch:  348       11 Batch loss: 0.206269 Batch F1: 0.5306122448979592
Epoch:  348       12 Batch loss: 0.158908 Batch F1: 0.7647058823529412
Train Avg Loss  348: 0.178176

Train Avg F1  348: 0.7009353737272558

Val Avg Loss  348: 0.183002

Val Avg F1  348:  0.6728191192865106

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 349
--------------------------------------------------------------
Epoch:  349        1 Batch loss: 0.152976 Batch F1: 0.8
Epoch:  349        2 Batch loss: 0.143435 Batch F1: 0.6451612903225806
Epoch:  349        3 Batch loss: 0.195948 Batch F1: 0.6808510638297872
Epoch:  349        4 Batch loss: 0.216458 Batch F1: 0.6046511627906976
Epoch:  349        5 Batch loss: 0.177919 Batch F1: 0.631578947368421
Epoch:  349        6 Batch loss: 0.174757 Batch F1: 0.6956521739130435
Epoch:  349        7 Batch loss: 0.178609 Batch F1: 0.7346938775510204
Epoch:  349        8 Batch loss: 0.165112 Batch F1: 0.7999999999999999
Epoch:  349        9 Batch loss: 0.155984 Batch F1: 0.7755102040816326
Epoch:  349       10 Batch loss: 0.186317 Batch F1: 0.5294117647058824
Epoch:  349       11 Batch loss: 0.201958 Batch F1: 0.6341463414634146
Epoch:  349       12 Batch loss: 0.143574 Batch F1: 0.8627450980392156
Train Avg Loss  349: 0.174421

Train Avg F1  349: 0.6995334936721412

Val Avg Loss  349: 0.184124

Val Avg F1  349:  0.6601251611755814

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 350
--------------------------------------------------------------
Epoch:  350        1 Batch loss: 0.188876 Batch F1: 0.611111111111111
Epoch:  350        2 Batch loss: 0.156785 Batch F1: 0.8000000000000002
Epoch:  350        3 Batch loss: 0.171052 Batch F1: 0.5625000000000001
Epoch:  350        4 Batch loss: 0.161855 Batch F1: 0.7555555555555555
Epoch:  350        5 Batch loss: 0.172106 Batch F1: 0.7272727272727272
Epoch:  350        6 Batch loss: 0.170821 Batch F1: 0.7719298245614034
Epoch:  350        7 Batch loss: 0.158958 Batch F1: 0.7272727272727272
Epoch:  350        8 Batch loss: 0.201866 Batch F1: 0.4864864864864865
Epoch:  350        9 Batch loss: 0.158140 Batch F1: 0.7272727272727272
Epoch:  350       10 Batch loss: 0.163981 Batch F1: 0.6818181818181818
Epoch:  350       11 Batch loss: 0.166907 Batch F1: 0.8
Epoch:  350       12 Batch loss: 0.188855 Batch F1: 0.6111111111111113
Train Avg Loss  350: 0.171683

Train Avg F1  350: 0.6885275377051694

Val Avg Loss  350: 0.181147

Val Avg F1  350:  0.6732804232804233

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 351
--------------------------------------------------------------
Epoch:  351        1 Batch loss: 0.187640 Batch F1: 0.6153846153846153
Epoch:  351        2 Batch loss: 0.164259 Batch F1: 0.7272727272727272
Epoch:  351        3 Batch loss: 0.162104 Batch F1: 0.7755102040816326
Epoch:  351        4 Batch loss: 0.168678 Batch F1: 0.6829268292682927
Epoch:  351        5 Batch loss: 0.167691 Batch F1: 0.7272727272727273
Epoch:  351        6 Batch loss: 0.178223 Batch F1: 0.7307692307692308
Epoch:  351        7 Batch loss: 0.185097 Batch F1: 0.7307692307692307
Epoch:  351        8 Batch loss: 0.147718 Batch F1: 0.7368421052631577
Epoch:  351        9 Batch loss: 0.211903 Batch F1: 0.5
Epoch:  351       10 Batch loss: 0.164217 Batch F1: 0.7659574468085107
Epoch:  351       11 Batch loss: 0.154623 Batch F1: 0.7727272727272727
Epoch:  351       12 Batch loss: 0.139878 Batch F1: 0.7741935483870969
Train Avg Loss  351: 0.169336

Train Avg F1  351: 0.7116354948337079

Val Avg Loss  351: 0.182231

Val Avg F1  351:  0.6774628879892037

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 352
--------------------------------------------------------------
Epoch:  352        1 Batch loss: 0.161200 Batch F1: 0.7000000000000001
Epoch:  352        2 Batch loss: 0.183927 Batch F1: 0.7058823529411765
Epoch:  352        3 Batch loss: 0.192078 Batch F1: 0.6521739130434783
Epoch:  352        4 Batch loss: 0.158853 Batch F1: 0.7391304347826088
Epoch:  352        5 Batch loss: 0.169671 Batch F1: 0.7083333333333333
Epoch:  352        6 Batch loss: 0.182165 Batch F1: 0.6666666666666666
Epoch:  352        7 Batch loss: 0.181112 Batch F1: 0.723404255319149
Epoch:  352        8 Batch loss: 0.172815 Batch F1: 0.6153846153846154
Epoch:  352        9 Batch loss: 0.155713 Batch F1: 0.7368421052631577
Epoch:  352       10 Batch loss: 0.154070 Batch F1: 0.851063829787234
Epoch:  352       11 Batch loss: 0.179155 Batch F1: 0.631578947368421
Epoch:  352       12 Batch loss: 0.157435 Batch F1: 0.8095238095238095
Train Avg Loss  352: 0.170683

Train Avg F1  352: 0.7116653552844711

Val Avg Loss  352: 0.184862

Val Avg F1  352:  0.6757129774986917

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 353
--------------------------------------------------------------
Epoch:  353        1 Batch loss: 0.171073 Batch F1: 0.7111111111111111
Epoch:  353        2 Batch loss: 0.155411 Batch F1: 0.7755102040816326
Epoch:  353        3 Batch loss: 0.163961 Batch F1: 0.5555555555555556
Epoch:  353        4 Batch loss: 0.182484 Batch F1: 0.6909090909090909
Epoch:  353        5 Batch loss: 0.187082 Batch F1: 0.5161290322580646
Epoch:  353        6 Batch loss: 0.175024 Batch F1: 0.723404255319149
Epoch:  353        7 Batch loss: 0.161540 Batch F1: 0.7916666666666667
Epoch:  353        8 Batch loss: 0.185883 Batch F1: 0.6808510638297872
Epoch:  353        9 Batch loss: 0.156782 Batch F1: 0.7647058823529413
Epoch:  353       10 Batch loss: 0.224120 Batch F1: 0.68
Epoch:  353       11 Batch loss: 0.194165 Batch F1: 0.68
Epoch:  353       12 Batch loss: 0.159916 Batch F1: 0.9375
Train Avg Loss  353: 0.176453

Train Avg F1  353: 0.7089452385069999

Val Avg Loss  353: 0.182986

Val Avg F1  353:  0.6720261437908497

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 354
--------------------------------------------------------------
Epoch:  354        1 Batch loss: 0.172449 Batch F1: 0.7234042553191491
Epoch:  354        2 Batch loss: 0.166505 Batch F1: 0.8214285714285715
Epoch:  354        3 Batch loss: 0.196726 Batch F1: 0.6666666666666666
Epoch:  354        4 Batch loss: 0.179641 Batch F1: 0.7083333333333333
Epoch:  354        5 Batch loss: 0.171168 Batch F1: 0.7547169811320754
Epoch:  354        6 Batch loss: 0.172027 Batch F1: 0.6666666666666667
Epoch:  354        7 Batch loss: 0.168485 Batch F1: 0.7272727272727272
Epoch:  354        8 Batch loss: 0.159678 Batch F1: 0.6829268292682927
Epoch:  354        9 Batch loss: 0.169557 Batch F1: 0.6666666666666666
Epoch:  354       10 Batch loss: 0.158937 Batch F1: 0.6
Epoch:  354       11 Batch loss: 0.180494 Batch F1: 0.6938775510204083
Epoch:  354       12 Batch loss: 0.165609 Batch F1: 0.7567567567567567
Train Avg Loss  354: 0.171773

Train Avg F1  354: 0.7057264171276095

Val Avg Loss  354: 0.182699

Val Avg F1  354:  0.6770833333333334

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 355
--------------------------------------------------------------
Epoch:  355        1 Batch loss: 0.161970 Batch F1: 0.8000000000000002
Epoch:  355        2 Batch loss: 0.153707 Batch F1: 0.7555555555555555
Epoch:  355        3 Batch loss: 0.179884 Batch F1: 0.6818181818181818
Epoch:  355        4 Batch loss: 0.167667 Batch F1: 0.711111111111111
Epoch:  355        5 Batch loss: 0.150957 Batch F1: 0.7826086956521738
Epoch:  355        6 Batch loss: 0.178638 Batch F1: 0.6808510638297872
Epoch:  355        7 Batch loss: 0.185004 Batch F1: 0.5945945945945946
Epoch:  355        8 Batch loss: 0.159981 Batch F1: 0.7999999999999999
Epoch:  355        9 Batch loss: 0.163586 Batch F1: 0.6857142857142857
Epoch:  355       10 Batch loss: 0.163963 Batch F1: 0.6976744186046512
Epoch:  355       11 Batch loss: 0.187932 Batch F1: 0.6818181818181818
Epoch:  355       12 Batch loss: 0.187400 Batch F1: 0.5882352941176471
Train Avg Loss  355: 0.170057

Train Avg F1  355: 0.7049984485680142

Val Avg Loss  355: 0.184151

Val Avg F1  355:  0.6739991526876297

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 356
--------------------------------------------------------------
Epoch:  356        1 Batch loss: 0.148577 Batch F1: 0.8620689655172414
Epoch:  356        2 Batch loss: 0.165396 Batch F1: 0.6666666666666667
Epoch:  356        3 Batch loss: 0.187167 Batch F1: 0.5555555555555556
Epoch:  356        4 Batch loss: 0.166411 Batch F1: 0.6470588235294118
Epoch:  356        5 Batch loss: 0.148593 Batch F1: 0.8000000000000002
Epoch:  356        6 Batch loss: 0.192824 Batch F1: 0.6190476190476191
Epoch:  356        7 Batch loss: 0.168837 Batch F1: 0.7843137254901961
Epoch:  356        8 Batch loss: 0.155763 Batch F1: 0.8260869565217391
Epoch:  356        9 Batch loss: 0.192429 Batch F1: 0.6190476190476191
Epoch:  356       10 Batch loss: 0.175714 Batch F1: 0.65
Epoch:  356       11 Batch loss: 0.187617 Batch F1: 0.68
Epoch:  356       12 Batch loss: 0.173640 Batch F1: 0.7027027027027026
Train Avg Loss  356: 0.171914

Train Avg F1  356: 0.7010457195065625

Val Avg Loss  356: 0.181845

Val Avg F1  356:  0.6785436589281928

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 357
--------------------------------------------------------------
Epoch:  357        1 Batch loss: 0.159421 Batch F1: 0.7272727272727272
Epoch:  357        2 Batch loss: 0.185458 Batch F1: 0.5294117647058824
Epoch:  357        3 Batch loss: 0.153715 Batch F1: 0.8260869565217391
Epoch:  357        4 Batch loss: 0.209765 Batch F1: 0.6086956521739131
Epoch:  357        5 Batch loss: 0.146776 Batch F1: 0.7368421052631577
Epoch:  357        6 Batch loss: 0.161868 Batch F1: 0.6666666666666665
Epoch:  357        7 Batch loss: 0.154187 Batch F1: 0.7555555555555555
Epoch:  357        8 Batch loss: 0.167822 Batch F1: 0.7777777777777777
Epoch:  357        9 Batch loss: 0.182451 Batch F1: 0.7692307692307693
Epoch:  357       10 Batch loss: 0.162052 Batch F1: 0.7317073170731707
Epoch:  357       11 Batch loss: 0.185920 Batch F1: 0.68
Epoch:  357       12 Batch loss: 0.167137 Batch F1: 0.6842105263157895
Train Avg Loss  357: 0.169714

Train Avg F1  357: 0.707788151546429

Val Avg Loss  357: 0.182172

Val Avg F1  357:  0.6674445131587988

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 358
--------------------------------------------------------------
Epoch:  358        1 Batch loss: 0.144778 Batch F1: 0.7804878048780488
Epoch:  358        2 Batch loss: 0.156294 Batch F1: 0.7555555555555555
Epoch:  358        3 Batch loss: 0.182926 Batch F1: 0.65
Epoch:  358        4 Batch loss: 0.167988 Batch F1: 0.75
Epoch:  358        5 Batch loss: 0.166983 Batch F1: 0.723404255319149
Epoch:  358        6 Batch loss: 0.201176 Batch F1: 0.5500000000000002
Epoch:  358        7 Batch loss: 0.167109 Batch F1: 0.6285714285714286
Epoch:  358        8 Batch loss: 0.189972 Batch F1: 0.5853658536585366
Epoch:  358        9 Batch loss: 0.148732 Batch F1: 0.7368421052631579
Epoch:  358       10 Batch loss: 0.169920 Batch F1: 0.7924528301886793
Epoch:  358       11 Batch loss: 0.151458 Batch F1: 0.8363636363636363
Epoch:  358       12 Batch loss: 0.191810 Batch F1: 0.6829268292682927
Train Avg Loss  358: 0.169929

Train Avg F1  358: 0.705997524922207

Val Avg Loss  358: 0.180809

Val Avg F1  358:  0.6634065109297307

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 359
--------------------------------------------------------------
Epoch:  359        1 Batch loss: 0.167653 Batch F1: 0.7234042553191489
Epoch:  359        2 Batch loss: 0.160651 Batch F1: 0.717948717948718
Epoch:  359        3 Batch loss: 0.163463 Batch F1: 0.7999999999999999
Epoch:  359        4 Batch loss: 0.173293 Batch F1: 0.6956521739130435
Epoch:  359        5 Batch loss: 0.193835 Batch F1: 0.6086956521739131
Epoch:  359        6 Batch loss: 0.143193 Batch F1: 0.8260869565217391
Epoch:  359        7 Batch loss: 0.182739 Batch F1: 0.6341463414634148
Epoch:  359        8 Batch loss: 0.184324 Batch F1: 0.6938775510204083
Epoch:  359        9 Batch loss: 0.179566 Batch F1: 0.6818181818181818
Epoch:  359       10 Batch loss: 0.161360 Batch F1: 0.7317073170731706
Epoch:  359       11 Batch loss: 0.154660 Batch F1: 0.7317073170731708
Epoch:  359       12 Batch loss: 0.178881 Batch F1: 0.7
Train Avg Loss  359: 0.170302

Train Avg F1  359: 0.7120870386937423

Val Avg Loss  359: 0.181341

Val Avg F1  359:  0.670665878644602

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 360
--------------------------------------------------------------
Epoch:  360        1 Batch loss: 0.185714 Batch F1: 0.6666666666666666
Epoch:  360        2 Batch loss: 0.145584 Batch F1: 0.761904761904762
Epoch:  360        3 Batch loss: 0.144244 Batch F1: 0.8163265306122449
Epoch:  360        4 Batch loss: 0.179287 Batch F1: 0.631578947368421
Epoch:  360        5 Batch loss: 0.137068 Batch F1: 0.7777777777777778
Epoch:  360        6 Batch loss: 0.156700 Batch F1: 0.8163265306122449
Epoch:  360        7 Batch loss: 0.161744 Batch F1: 0.75
Epoch:  360        8 Batch loss: 0.161485 Batch F1: 0.7843137254901961
Epoch:  360        9 Batch loss: 0.182025 Batch F1: 0.6
Epoch:  360       10 Batch loss: 0.198375 Batch F1: 0.5909090909090909
Epoch:  360       11 Batch loss: 0.186213 Batch F1: 0.6808510638297872
Epoch:  360       12 Batch loss: 0.192924 Batch F1: 0.6285714285714287
Train Avg Loss  360: 0.169280

Train Avg F1  360: 0.7087688769785516

Val Avg Loss  360: 0.180803

Val Avg F1  360:  0.6735294117647059

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 361
--------------------------------------------------------------
Epoch:  361        1 Batch loss: 0.167799 Batch F1: 0.7346938775510204
Epoch:  361        2 Batch loss: 0.155907 Batch F1: 0.6842105263157895
Epoch:  361        3 Batch loss: 0.163627 Batch F1: 0.711111111111111
Epoch:  361        4 Batch loss: 0.178316 Batch F1: 0.76
Epoch:  361        5 Batch loss: 0.170109 Batch F1: 0.7692307692307692
Epoch:  361        6 Batch loss: 0.165445 Batch F1: 0.6285714285714286
Epoch:  361        7 Batch loss: 0.172029 Batch F1: 0.7391304347826088
Epoch:  361        8 Batch loss: 0.170803 Batch F1: 0.6511627906976745
Epoch:  361        9 Batch loss: 0.185694 Batch F1: 0.6190476190476191
Epoch:  361       10 Batch loss: 0.184327 Batch F1: 0.7037037037037037
Epoch:  361       11 Batch loss: 0.162666 Batch F1: 0.7317073170731706
Epoch:  361       12 Batch loss: 0.140728 Batch F1: 0.7999999999999999
Train Avg Loss  361: 0.168121

Train Avg F1  361: 0.7110474648404078

Val Avg Loss  361: 0.180609

Val Avg F1  361:  0.6761390937571529

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 362
--------------------------------------------------------------
Epoch:  362        1 Batch loss: 0.154401 Batch F1: 0.7906976744186046
Epoch:  362        2 Batch loss: 0.165668 Batch F1: 0.6666666666666666
Epoch:  362        3 Batch loss: 0.179217 Batch F1: 0.7346938775510204
Epoch:  362        4 Batch loss: 0.199489 Batch F1: 0.5833333333333334
Epoch:  362        5 Batch loss: 0.190711 Batch F1: 0.6341463414634146
Epoch:  362        6 Batch loss: 0.167317 Batch F1: 0.7547169811320755
Epoch:  362        7 Batch loss: 0.164399 Batch F1: 0.7
Epoch:  362        8 Batch loss: 0.164499 Batch F1: 0.7142857142857143
Epoch:  362        9 Batch loss: 0.168915 Batch F1: 0.6857142857142857
Epoch:  362       10 Batch loss: 0.141679 Batch F1: 0.7906976744186046
Epoch:  362       11 Batch loss: 0.161141 Batch F1: 0.7755102040816326
Epoch:  362       12 Batch loss: 0.171779 Batch F1: 0.717948717948718
Train Avg Loss  362: 0.169101

Train Avg F1  362: 0.7123676225845058

Val Avg Loss  362: 0.180825

Val Avg F1  362:  0.6764473308962692

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 363
--------------------------------------------------------------
Epoch:  363        1 Batch loss: 0.151252 Batch F1: 0.761904761904762
Epoch:  363        2 Batch loss: 0.185604 Batch F1: 0.6511627906976745
Epoch:  363        3 Batch loss: 0.166931 Batch F1: 0.7307692307692308
Epoch:  363        4 Batch loss: 0.182274 Batch F1: 0.6818181818181818
Epoch:  363        5 Batch loss: 0.181962 Batch F1: 0.65
Epoch:  363        6 Batch loss: 0.127081 Batch F1: 0.8333333333333333
Epoch:  363        7 Batch loss: 0.168056 Batch F1: 0.7317073170731707
Epoch:  363        8 Batch loss: 0.171541 Batch F1: 0.6818181818181818
Epoch:  363        9 Batch loss: 0.186006 Batch F1: 0.6808510638297872
Epoch:  363       10 Batch loss: 0.163536 Batch F1: 0.8196721311475409
Epoch:  363       11 Batch loss: 0.172589 Batch F1: 0.5142857142857143
Epoch:  363       12 Batch loss: 0.195963 Batch F1: 0.6666666666666666
Train Avg Loss  363: 0.171066

Train Avg F1  363: 0.700332447778687

Val Avg Loss  363: 0.189134

Val Avg F1  363:  0.6384255625327053

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 364
--------------------------------------------------------------
Epoch:  364        1 Batch loss: 0.216777 Batch F1: 0.4878048780487805
Epoch:  364        2 Batch loss: 0.172665 Batch F1: 0.7058823529411765
Epoch:  364        3 Batch loss: 0.154982 Batch F1: 0.819672131147541
Epoch:  364        4 Batch loss: 0.190759 Batch F1: 0.6046511627906977
Epoch:  364        5 Batch loss: 0.171238 Batch F1: 0.6153846153846154
Epoch:  364        6 Batch loss: 0.148873 Batch F1: 0.717948717948718
Epoch:  364        7 Batch loss: 0.171014 Batch F1: 0.6938775510204083
Epoch:  364        8 Batch loss: 0.194140 Batch F1: 0.679245283018868
Epoch:  364        9 Batch loss: 0.165283 Batch F1: 0.7826086956521738
Epoch:  364       10 Batch loss: 0.168535 Batch F1: 0.6829268292682926
Epoch:  364       11 Batch loss: 0.183142 Batch F1: 0.5957446808510638
Epoch:  364       12 Batch loss: 0.208130 Batch F1: 0.6086956521739131
Train Avg Loss  364: 0.178795

Train Avg F1  364: 0.6662035458538541

Val Avg Loss  364: 0.187502

Val Avg F1  364:  0.6304739389845773

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 365
--------------------------------------------------------------
Epoch:  365        1 Batch loss: 0.176265 Batch F1: 0.6956521739130435
Epoch:  365        2 Batch loss: 0.169011 Batch F1: 0.7058823529411765
Epoch:  365        3 Batch loss: 0.149004 Batch F1: 0.7222222222222223
Epoch:  365        4 Batch loss: 0.169843 Batch F1: 0.7272727272727272
Epoch:  365        5 Batch loss: 0.172353 Batch F1: 0.6829268292682926
Epoch:  365        6 Batch loss: 0.191675 Batch F1: 0.7169811320754716
Epoch:  365        7 Batch loss: 0.172386 Batch F1: 0.7142857142857143
Epoch:  365        8 Batch loss: 0.174173 Batch F1: 0.7499999999999999
Epoch:  365        9 Batch loss: 0.171220 Batch F1: 0.76
Epoch:  365       10 Batch loss: 0.170918 Batch F1: 0.7142857142857143
Epoch:  365       11 Batch loss: 0.173739 Batch F1: 0.6315789473684211
Epoch:  365       12 Batch loss: 0.213607 Batch F1: 0.6153846153846153
Train Avg Loss  365: 0.175350

Train Avg F1  365: 0.7030393690847833

Val Avg Loss  365: 0.185314

Val Avg F1  365:  0.662122892635315

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 366
--------------------------------------------------------------
Epoch:  366        1 Batch loss: 0.176260 Batch F1: 0.7636363636363638
Epoch:  366        2 Batch loss: 0.151659 Batch F1: 0.8333333333333333
Epoch:  366        3 Batch loss: 0.187245 Batch F1: 0.7169811320754716
Epoch:  366        4 Batch loss: 0.160358 Batch F1: 0.7
Epoch:  366        5 Batch loss: 0.184963 Batch F1: 0.5853658536585366
Epoch:  366        6 Batch loss: 0.157254 Batch F1: 0.7317073170731706
Epoch:  366        7 Batch loss: 0.197994 Batch F1: 0.6122448979591837
Epoch:  366        8 Batch loss: 0.193389 Batch F1: 0.6046511627906976
Epoch:  366        9 Batch loss: 0.189830 Batch F1: 0.5238095238095238
Epoch:  366       10 Batch loss: 0.203025 Batch F1: 0.5777777777777778
Epoch:  366       11 Batch loss: 0.177614 Batch F1: 0.7659574468085107
Epoch:  366       12 Batch loss: 0.196301 Batch F1: 0.7272727272727272
Train Avg Loss  366: 0.181324

Train Avg F1  366: 0.678561461349608

Val Avg Loss  366: 0.189878

Val Avg F1  366:  0.6724613860553602

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 367
--------------------------------------------------------------
Epoch:  367        1 Batch loss: 0.171953 Batch F1: 0.7391304347826089
Epoch:  367        2 Batch loss: 0.142738 Batch F1: 0.8205128205128205
Epoch:  367        3 Batch loss: 0.177595 Batch F1: 0.7317073170731708
Epoch:  367        4 Batch loss: 0.175060 Batch F1: 0.7391304347826088
Epoch:  367        5 Batch loss: 0.173652 Batch F1: 0.7843137254901961
Epoch:  367        6 Batch loss: 0.213787 Batch F1: 0.64
Epoch:  367        7 Batch loss: 0.173953 Batch F1: 0.65
Epoch:  367        8 Batch loss: 0.208701 Batch F1: 0.6122448979591836
Epoch:  367        9 Batch loss: 0.163339 Batch F1: 0.7441860465116279
Epoch:  367       10 Batch loss: 0.190070 Batch F1: 0.7346938775510204
Epoch:  367       11 Batch loss: 0.180330 Batch F1: 0.8085106382978724
Epoch:  367       12 Batch loss: 0.186304 Batch F1: 0.7222222222222223
Train Avg Loss  367: 0.179790

Train Avg F1  367: 0.7272210345986109

Val Avg Loss  367: 0.186219

Val Avg F1  367:  0.7596874473356908

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 368
--------------------------------------------------------------
Epoch:  368        1 Batch loss: 0.191780 Batch F1: 0.6857142857142857
Epoch:  368        2 Batch loss: 0.198464 Batch F1: 0.6363636363636365
Epoch:  368        3 Batch loss: 0.182408 Batch F1: 0.6666666666666666
Epoch:  368        4 Batch loss: 0.160786 Batch F1: 0.6666666666666667
Epoch:  368        5 Batch loss: 0.189960 Batch F1: 0.6818181818181819
Epoch:  368        6 Batch loss: 0.164420 Batch F1: 0.8
Epoch:  368        7 Batch loss: 0.179765 Batch F1: 0.7234042553191491
Epoch:  368        8 Batch loss: 0.191909 Batch F1: 0.7058823529411765
Epoch:  368        9 Batch loss: 0.162933 Batch F1: 0.7755102040816326
Epoch:  368       10 Batch loss: 0.173361 Batch F1: 0.76
Epoch:  368       11 Batch loss: 0.149437 Batch F1: 0.8571428571428571
Epoch:  368       12 Batch loss: 0.188393 Batch F1: 0.6666666666666667
Train Avg Loss  368: 0.177801

Train Avg F1  368: 0.7188196477817432

Val Avg Loss  368: 0.185098

Val Avg F1  368:  0.6802629680634796

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 369
--------------------------------------------------------------
Epoch:  369        1 Batch loss: 0.156827 Batch F1: 0.7619047619047619
Epoch:  369        2 Batch loss: 0.195203 Batch F1: 0.5853658536585366
Epoch:  369        3 Batch loss: 0.187045 Batch F1: 0.723404255319149
Epoch:  369        4 Batch loss: 0.179047 Batch F1: 0.6976744186046512
Epoch:  369        5 Batch loss: 0.175171 Batch F1: 0.7659574468085107
Epoch:  369        6 Batch loss: 0.183814 Batch F1: 0.5945945945945946
Epoch:  369        7 Batch loss: 0.159700 Batch F1: 0.717948717948718
Epoch:  369        8 Batch loss: 0.176593 Batch F1: 0.7346938775510204
Epoch:  369        9 Batch loss: 0.175032 Batch F1: 0.6818181818181818
Epoch:  369       10 Batch loss: 0.154335 Batch F1: 0.7
Epoch:  369       11 Batch loss: 0.167877 Batch F1: 0.7843137254901961
Epoch:  369       12 Batch loss: 0.163747 Batch F1: 0.7727272727272727
Train Avg Loss  369: 0.172866

Train Avg F1  369: 0.7100335922021328

Val Avg Loss  369: 0.184578

Val Avg F1  369:  0.677479057457087

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 370
--------------------------------------------------------------
Epoch:  370        1 Batch loss: 0.189665 Batch F1: 0.631578947368421
Epoch:  370        2 Batch loss: 0.197818 Batch F1: 0.5853658536585366
Epoch:  370        3 Batch loss: 0.168591 Batch F1: 0.7499999999999999
Epoch:  370        4 Batch loss: 0.172548 Batch F1: 0.6976744186046512
Epoch:  370        5 Batch loss: 0.186531 Batch F1: 0.6666666666666667
Epoch:  370        6 Batch loss: 0.173621 Batch F1: 0.75
Epoch:  370        7 Batch loss: 0.181989 Batch F1: 0.6666666666666666
Epoch:  370        8 Batch loss: 0.164168 Batch F1: 0.7826086956521738
Epoch:  370        9 Batch loss: 0.168601 Batch F1: 0.7234042553191489
Epoch:  370       10 Batch loss: 0.140680 Batch F1: 0.8727272727272727
Epoch:  370       11 Batch loss: 0.162770 Batch F1: 0.6666666666666667
Epoch:  370       12 Batch loss: 0.155786 Batch F1: 0.6896551724137931
Train Avg Loss  370: 0.171897

Train Avg F1  370: 0.7069178846453331

Val Avg Loss  370: 0.182433

Val Avg F1  370:  0.6789159253444967

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 371
--------------------------------------------------------------
Epoch:  371        1 Batch loss: 0.199024 Batch F1: 0.6086956521739131
Epoch:  371        2 Batch loss: 0.169701 Batch F1: 0.7692307692307693
Epoch:  371        3 Batch loss: 0.160449 Batch F1: 0.7843137254901961
Epoch:  371        4 Batch loss: 0.190748 Batch F1: 0.6341463414634148
Epoch:  371        5 Batch loss: 0.187596 Batch F1: 0.6808510638297872
Epoch:  371        6 Batch loss: 0.165495 Batch F1: 0.7391304347826089
Epoch:  371        7 Batch loss: 0.179173 Batch F1: 0.65
Epoch:  371        8 Batch loss: 0.163159 Batch F1: 0.7555555555555556
Epoch:  371        9 Batch loss: 0.171845 Batch F1: 0.606060606060606
Epoch:  371       10 Batch loss: 0.164380 Batch F1: 0.6470588235294118
Epoch:  371       11 Batch loss: 0.142763 Batch F1: 0.8780487804878048
Epoch:  371       12 Batch loss: 0.195369 Batch F1: 0.7346938775510203
Train Avg Loss  371: 0.174142

Train Avg F1  371: 0.7073154691795907

Val Avg Loss  371: 0.182383

Val Avg F1  371:  0.6723916837558358

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 372
--------------------------------------------------------------
Epoch:  372        1 Batch loss: 0.196686 Batch F1: 0.7169811320754718
Epoch:  372        2 Batch loss: 0.167871 Batch F1: 0.6842105263157895
Epoch:  372        3 Batch loss: 0.155799 Batch F1: 0.7999999999999999
Epoch:  372        4 Batch loss: 0.165281 Batch F1: 0.6666666666666667
Epoch:  372        5 Batch loss: 0.195001 Batch F1: 0.6086956521739131
Epoch:  372        6 Batch loss: 0.191128 Batch F1: 0.6341463414634146
Epoch:  372        7 Batch loss: 0.162785 Batch F1: 0.7142857142857143
Epoch:  372        8 Batch loss: 0.192279 Batch F1: 0.7599999999999999
Epoch:  372        9 Batch loss: 0.171603 Batch F1: 0.7777777777777778
Epoch:  372       10 Batch loss: 0.154733 Batch F1: 0.8333333333333333
Epoch:  372       11 Batch loss: 0.192898 Batch F1: 0.619047619047619
Epoch:  372       12 Batch loss: 0.157343 Batch F1: 0.6666666666666666
Train Avg Loss  372: 0.175284

Train Avg F1  372: 0.7068176191505304

Val Avg Loss  372: 0.185553

Val Avg F1  372:  0.6787878787878788

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 373
--------------------------------------------------------------
Epoch:  373        1 Batch loss: 0.198997 Batch F1: 0.6382978723404256
Epoch:  373        2 Batch loss: 0.171347 Batch F1: 0.7272727272727273
Epoch:  373        3 Batch loss: 0.187622 Batch F1: 0.7199999999999999
Epoch:  373        4 Batch loss: 0.162631 Batch F1: 0.6666666666666667
Epoch:  373        5 Batch loss: 0.171416 Batch F1: 0.7234042553191491
Epoch:  373        6 Batch loss: 0.196749 Batch F1: 0.6285714285714287
Epoch:  373        7 Batch loss: 0.212045 Batch F1: 0.75
Epoch:  373        8 Batch loss: 0.182763 Batch F1: 0.7142857142857143
Epoch:  373        9 Batch loss: 0.158933 Batch F1: 0.7027027027027027
Epoch:  373       10 Batch loss: 0.185288 Batch F1: 0.6153846153846154
Epoch:  373       11 Batch loss: 0.168030 Batch F1: 0.8461538461538461
Epoch:  373       12 Batch loss: 0.151971 Batch F1: 0.8260869565217391
Train Avg Loss  373: 0.178983

Train Avg F1  373: 0.713235565434918

Val Avg Loss  373: 0.188160

Val Avg F1  373:  0.6755364379794472

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 374
--------------------------------------------------------------
Epoch:  374        1 Batch loss: 0.194575 Batch F1: 0.6382978723404256
Epoch:  374        2 Batch loss: 0.182078 Batch F1: 0.6808510638297872
Epoch:  374        3 Batch loss: 0.147337 Batch F1: 0.8085106382978724
Epoch:  374        4 Batch loss: 0.178301 Batch F1: 0.7843137254901961
Epoch:  374        5 Batch loss: 0.168293 Batch F1: 0.7272727272727273
Epoch:  374        6 Batch loss: 0.136805 Batch F1: 0.75
Epoch:  374        7 Batch loss: 0.190472 Batch F1: 0.7058823529411765
Epoch:  374        8 Batch loss: 0.162431 Batch F1: 0.7317073170731707
Epoch:  374        9 Batch loss: 0.199288 Batch F1: 0.6086956521739131
Epoch:  374       10 Batch loss: 0.157743 Batch F1: 0.625
Epoch:  374       11 Batch loss: 0.182547 Batch F1: 0.6956521739130435
Epoch:  374       12 Batch loss: 0.173942 Batch F1: 0.7368421052631579
Train Avg Loss  374: 0.172818

Train Avg F1  374: 0.7077521357162891

Val Avg Loss  374: 0.184025

Val Avg F1  374:  0.6769195189639223

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 375
--------------------------------------------------------------
Epoch:  375        1 Batch loss: 0.175740 Batch F1: 0.6486486486486486
Epoch:  375        2 Batch loss: 0.175036 Batch F1: 0.7547169811320755
Epoch:  375        3 Batch loss: 0.194963 Batch F1: 0.6530612244897959
Epoch:  375        4 Batch loss: 0.163457 Batch F1: 0.7441860465116279
Epoch:  375        5 Batch loss: 0.170181 Batch F1: 0.6842105263157895
Epoch:  375        6 Batch loss: 0.130030 Batch F1: 0.8648648648648648
Epoch:  375        7 Batch loss: 0.143225 Batch F1: 0.8095238095238095
Epoch:  375        8 Batch loss: 0.166887 Batch F1: 0.7272727272727273
Epoch:  375        9 Batch loss: 0.153594 Batch F1: 0.7027027027027027
Epoch:  375       10 Batch loss: 0.205071 Batch F1: 0.6538461538461539
Epoch:  375       11 Batch loss: 0.186296 Batch F1: 0.7058823529411765
Epoch:  375       12 Batch loss: 0.206285 Batch F1: 0.6190476190476191
Train Avg Loss  375: 0.172564

Train Avg F1  375: 0.7139969714414159

Val Avg Loss  375: 0.183814

Val Avg F1  375:  0.6691007191105371

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 376
--------------------------------------------------------------
Epoch:  376        1 Batch loss: 0.162588 Batch F1: 0.6666666666666667
Epoch:  376        2 Batch loss: 0.147065 Batch F1: 0.782608695652174
Epoch:  376        3 Batch loss: 0.183897 Batch F1: 0.68
Epoch:  376        4 Batch loss: 0.159300 Batch F1: 0.8148148148148148
Epoch:  376        5 Batch loss: 0.188661 Batch F1: 0.6666666666666665
Epoch:  376        6 Batch loss: 0.189526 Batch F1: 0.6818181818181818
Epoch:  376        7 Batch loss: 0.150824 Batch F1: 0.7906976744186046
Epoch:  376        8 Batch loss: 0.204171 Batch F1: 0.5714285714285713
Epoch:  376        9 Batch loss: 0.199563 Batch F1: 0.6046511627906976
Epoch:  376       10 Batch loss: 0.177982 Batch F1: 0.7450980392156864
Epoch:  376       11 Batch loss: 0.153246 Batch F1: 0.7368421052631577
Epoch:  376       12 Batch loss: 0.157055 Batch F1: 0.7777777777777778
Train Avg Loss  376: 0.172823

Train Avg F1  376: 0.7099225297094166

Val Avg Loss  376: 0.184112

Val Avg F1  376:  0.6697386407274444

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 377
--------------------------------------------------------------
Epoch:  377        1 Batch loss: 0.167672 Batch F1: 0.7659574468085107
Epoch:  377        2 Batch loss: 0.179727 Batch F1: 0.6666666666666666
Epoch:  377        3 Batch loss: 0.166836 Batch F1: 0.7727272727272727
Epoch:  377        4 Batch loss: 0.128062 Batch F1: 0.8695652173913043
Epoch:  377        5 Batch loss: 0.200072 Batch F1: 0.693877551020408
Epoch:  377        6 Batch loss: 0.178736 Batch F1: 0.7777777777777779
Epoch:  377        7 Batch loss: 0.148742 Batch F1: 0.7222222222222223
Epoch:  377        8 Batch loss: 0.194061 Batch F1: 0.6046511627906976
Epoch:  377        9 Batch loss: 0.164478 Batch F1: 0.7
Epoch:  377       10 Batch loss: 0.177153 Batch F1: 0.6818181818181818
Epoch:  377       11 Batch loss: 0.197483 Batch F1: 0.5945945945945946
Epoch:  377       12 Batch loss: 0.172881 Batch F1: 0.6842105263157895
Train Avg Loss  377: 0.172992

Train Avg F1  377: 0.7111723850111189

Val Avg Loss  377: 0.183137

Val Avg F1  377:  0.6761948831238619

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 378
--------------------------------------------------------------
Epoch:  378        1 Batch loss: 0.156898 Batch F1: 0.8518518518518519
Epoch:  378        2 Batch loss: 0.164312 Batch F1: 0.7000000000000001
Epoch:  378        3 Batch loss: 0.178725 Batch F1: 0.6666666666666666
Epoch:  378        4 Batch loss: 0.180089 Batch F1: 0.6511627906976744
Epoch:  378        5 Batch loss: 0.173897 Batch F1: 0.7111111111111111
Epoch:  378        6 Batch loss: 0.138187 Batch F1: 0.8333333333333333
Epoch:  378        7 Batch loss: 0.206432 Batch F1: 0.5853658536585366
Epoch:  378        8 Batch loss: 0.165234 Batch F1: 0.5806451612903225
Epoch:  378        9 Batch loss: 0.166040 Batch F1: 0.7755102040816326
Epoch:  378       10 Batch loss: 0.186374 Batch F1: 0.6363636363636364
Epoch:  378       11 Batch loss: 0.154800 Batch F1: 0.8163265306122449
Epoch:  378       12 Batch loss: 0.190684 Batch F1: 0.6111111111111112
Train Avg Loss  378: 0.171806

Train Avg F1  378: 0.7016206875648434

Val Avg Loss  378: 0.182746

Val Avg F1  378:  0.6792718934844266

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 379
--------------------------------------------------------------
Epoch:  379        1 Batch loss: 0.187353 Batch F1: 0.6341463414634146
Epoch:  379        2 Batch loss: 0.164614 Batch F1: 0.7755102040816326
Epoch:  379        3 Batch loss: 0.151161 Batch F1: 0.6875
Epoch:  379        4 Batch loss: 0.196840 Batch F1: 0.6222222222222223
Epoch:  379        5 Batch loss: 0.176531 Batch F1: 0.6500000000000001
Epoch:  379        6 Batch loss: 0.188888 Batch F1: 0.6521739130434783
Epoch:  379        7 Batch loss: 0.165316 Batch F1: 0.7142857142857143
Epoch:  379        8 Batch loss: 0.184699 Batch F1: 0.7169811320754716
Epoch:  379        9 Batch loss: 0.153515 Batch F1: 0.8363636363636364
Epoch:  379       10 Batch loss: 0.149656 Batch F1: 0.7499999999999999
Epoch:  379       11 Batch loss: 0.152240 Batch F1: 0.8
Epoch:  379       12 Batch loss: 0.176847 Batch F1: 0.6486486486486486
Train Avg Loss  379: 0.170638

Train Avg F1  379: 0.7073193176820182

Val Avg Loss  379: 0.181876

Val Avg F1  379:  0.6758451865594721

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 380
--------------------------------------------------------------
Epoch:  380        1 Batch loss: 0.170392 Batch F1: 0.7599999999999999
Epoch:  380        2 Batch loss: 0.176169 Batch F1: 0.7234042553191491
Epoch:  380        3 Batch loss: 0.212510 Batch F1: 0.6122448979591837
Epoch:  380        4 Batch loss: 0.187148 Batch F1: 0.5789473684210527
Epoch:  380        5 Batch loss: 0.171237 Batch F1: 0.744186046511628
Epoch:  380        6 Batch loss: 0.168334 Batch F1: 0.5333333333333333
Epoch:  380        7 Batch loss: 0.178486 Batch F1: 0.6511627906976744
Epoch:  380        8 Batch loss: 0.170280 Batch F1: 0.7692307692307692
Epoch:  380        9 Batch loss: 0.134020 Batch F1: 0.8800000000000001
Epoch:  380       10 Batch loss: 0.161093 Batch F1: 0.6666666666666666
Epoch:  380       11 Batch loss: 0.171966 Batch F1: 0.7499999999999999
Epoch:  380       12 Batch loss: 0.142295 Batch F1: 0.7777777777777777
Train Avg Loss  380: 0.170327

Train Avg F1  380: 0.703912825493103

Val Avg Loss  380: 0.181975

Val Avg F1  380:  0.6700535252860834

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 381
--------------------------------------------------------------
Epoch:  381        1 Batch loss: 0.151359 Batch F1: 0.782608695652174
Epoch:  381        2 Batch loss: 0.189219 Batch F1: 0.6938775510204083
Epoch:  381        3 Batch loss: 0.158109 Batch F1: 0.7924528301886793
Epoch:  381        4 Batch loss: 0.140431 Batch F1: 0.7894736842105263
Epoch:  381        5 Batch loss: 0.164422 Batch F1: 0.8076923076923077
Epoch:  381        6 Batch loss: 0.161171 Batch F1: 0.7391304347826088
Epoch:  381        7 Batch loss: 0.158562 Batch F1: 0.6666666666666666
Epoch:  381        8 Batch loss: 0.154744 Batch F1: 0.7142857142857143
Epoch:  381        9 Batch loss: 0.191707 Batch F1: 0.6818181818181819
Epoch:  381       10 Batch loss: 0.193975 Batch F1: 0.6382978723404255
Epoch:  381       11 Batch loss: 0.174003 Batch F1: 0.5714285714285715
Epoch:  381       12 Batch loss: 0.208964 Batch F1: 0.6
Train Avg Loss  381: 0.170556

Train Avg F1  381: 0.7064777091738553

Val Avg Loss  381: 0.183218

Val Avg F1  381:  0.6712922403003755

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 382
--------------------------------------------------------------
Epoch:  382        1 Batch loss: 0.172755 Batch F1: 0.711111111111111
Epoch:  382        2 Batch loss: 0.150095 Batch F1: 0.7368421052631577
Epoch:  382        3 Batch loss: 0.175859 Batch F1: 0.7307692307692306
Epoch:  382        4 Batch loss: 0.177668 Batch F1: 0.65
Epoch:  382        5 Batch loss: 0.185630 Batch F1: 0.5945945945945946
Epoch:  382        6 Batch loss: 0.155784 Batch F1: 0.7916666666666666
Epoch:  382        7 Batch loss: 0.136560 Batch F1: 0.8181818181818181
Epoch:  382        8 Batch loss: 0.144805 Batch F1: 0.8205128205128205
Epoch:  382        9 Batch loss: 0.193559 Batch F1: 0.6666666666666667
Epoch:  382       10 Batch loss: 0.175224 Batch F1: 0.5454545454545454
Epoch:  382       11 Batch loss: 0.187670 Batch F1: 0.7272727272727273
Epoch:  382       12 Batch loss: 0.187386 Batch F1: 0.7142857142857143
Train Avg Loss  382: 0.170250

Train Avg F1  382: 0.7089465000649211

Val Avg Loss  382: 0.182534

Val Avg F1  382:  0.6729726690883929

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 383
--------------------------------------------------------------
Epoch:  383        1 Batch loss: 0.170518 Batch F1: 0.7272727272727273
Epoch:  383        2 Batch loss: 0.175013 Batch F1: 0.6486486486486486
Epoch:  383        3 Batch loss: 0.169560 Batch F1: 0.7142857142857143
Epoch:  383        4 Batch loss: 0.163177 Batch F1: 0.6486486486486486
Epoch:  383        5 Batch loss: 0.163367 Batch F1: 0.7659574468085107
Epoch:  383        6 Batch loss: 0.171907 Batch F1: 0.7692307692307692
Epoch:  383        7 Batch loss: 0.156808 Batch F1: 0.7142857142857143
Epoch:  383        8 Batch loss: 0.182856 Batch F1: 0.6818181818181818
Epoch:  383        9 Batch loss: 0.193114 Batch F1: 0.6530612244897959
Epoch:  383       10 Batch loss: 0.151662 Batch F1: 0.7999999999999999
Epoch:  383       11 Batch loss: 0.173931 Batch F1: 0.6521739130434783
Epoch:  383       12 Batch loss: 0.160730 Batch F1: 0.7500000000000001
Train Avg Loss  383: 0.169387

Train Avg F1  383: 0.7104485823776825

Val Avg Loss  383: 0.180994

Val Avg F1  383:  0.6736221152327513

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 384
--------------------------------------------------------------
Epoch:  384        1 Batch loss: 0.177501 Batch F1: 0.7083333333333334
Epoch:  384        2 Batch loss: 0.156993 Batch F1: 0.7391304347826088
Epoch:  384        3 Batch loss: 0.187151 Batch F1: 0.6808510638297872
Epoch:  384        4 Batch loss: 0.164696 Batch F1: 0.76
Epoch:  384        5 Batch loss: 0.164163 Batch F1: 0.7272727272727273
Epoch:  384        6 Batch loss: 0.168542 Batch F1: 0.7391304347826085
Epoch:  384        7 Batch loss: 0.151066 Batch F1: 0.7222222222222223
Epoch:  384        8 Batch loss: 0.157431 Batch F1: 0.7906976744186046
Epoch:  384        9 Batch loss: 0.180114 Batch F1: 0.6818181818181819
Epoch:  384       10 Batch loss: 0.181068 Batch F1: 0.5789473684210527
Epoch:  384       11 Batch loss: 0.177060 Batch F1: 0.7111111111111111
Epoch:  384       12 Batch loss: 0.184358 Batch F1: 0.6842105263157895
Train Avg Loss  384: 0.170845

Train Avg F1  384: 0.7103104231923356

Val Avg Loss  384: 0.182708

Val Avg F1  384:  0.6724051255722414

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 385
--------------------------------------------------------------
Epoch:  385        1 Batch loss: 0.176505 Batch F1: 0.6153846153846153
Epoch:  385        2 Batch loss: 0.194355 Batch F1: 0.5263157894736842
Epoch:  385        3 Batch loss: 0.190737 Batch F1: 0.7058823529411765
Epoch:  385        4 Batch loss: 0.158292 Batch F1: 0.6470588235294118
Epoch:  385        5 Batch loss: 0.202905 Batch F1: 0.6923076923076923
Epoch:  385        6 Batch loss: 0.163156 Batch F1: 0.6666666666666666
Epoch:  385        7 Batch loss: 0.161741 Batch F1: 0.6666666666666666
Epoch:  385        8 Batch loss: 0.164535 Batch F1: 0.761904761904762
Epoch:  385        9 Batch loss: 0.170188 Batch F1: 0.7777777777777777
Epoch:  385       10 Batch loss: 0.159673 Batch F1: 0.7500000000000001
Epoch:  385       11 Batch loss: 0.132992 Batch F1: 0.8292682926829269
Epoch:  385       12 Batch loss: 0.163399 Batch F1: 0.8333333333333333
Train Avg Loss  385: 0.169873

Train Avg F1  385: 0.7060472310557261

Val Avg Loss  385: 0.183985

Val Avg F1  385:  0.680313776058457

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 386
--------------------------------------------------------------
Epoch:  386        1 Batch loss: 0.164433 Batch F1: 0.7000000000000001
Epoch:  386        2 Batch loss: 0.189526 Batch F1: 0.6250000000000001
Epoch:  386        3 Batch loss: 0.203738 Batch F1: 0.6530612244897959
Epoch:  386        4 Batch loss: 0.181978 Batch F1: 0.5714285714285715
Epoch:  386        5 Batch loss: 0.176115 Batch F1: 0.7555555555555556
Epoch:  386        6 Batch loss: 0.151379 Batch F1: 0.8510638297872342
Epoch:  386        7 Batch loss: 0.170538 Batch F1: 0.7636363636363638
Epoch:  386        8 Batch loss: 0.170775 Batch F1: 0.6857142857142857
Epoch:  386        9 Batch loss: 0.172578 Batch F1: 0.7142857142857142
Epoch:  386       10 Batch loss: 0.179421 Batch F1: 0.8076923076923077
Epoch:  386       11 Batch loss: 0.177014 Batch F1: 0.8214285714285715
Epoch:  386       12 Batch loss: 0.184818 Batch F1: 0.7647058823529413
Train Avg Loss  386: 0.176860

Train Avg F1  386: 0.7261310255309451

Val Avg Loss  386: 0.180793

Val Avg F1  386:  0.675625233296006

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 387
--------------------------------------------------------------
Epoch:  387        1 Batch loss: 0.132861 Batch F1: 0.8421052631578948
Epoch:  387        2 Batch loss: 0.192947 Batch F1: 0.6909090909090909
Epoch:  387        3 Batch loss: 0.186657 Batch F1: 0.5789473684210527
Epoch:  387        4 Batch loss: 0.185793 Batch F1: 0.7200000000000001
Epoch:  387        5 Batch loss: 0.164415 Batch F1: 0.7692307692307693
Epoch:  387        6 Batch loss: 0.189319 Batch F1: 0.7111111111111111
Epoch:  387        7 Batch loss: 0.171440 Batch F1: 0.6666666666666667
Epoch:  387        8 Batch loss: 0.181017 Batch F1: 0.761904761904762
Epoch:  387        9 Batch loss: 0.169723 Batch F1: 0.6842105263157895
Epoch:  387       10 Batch loss: 0.188097 Batch F1: 0.6530612244897959
Epoch:  387       11 Batch loss: 0.161734 Batch F1: 0.761904761904762
Epoch:  387       12 Batch loss: 0.185599 Batch F1: 0.717948717948718
Train Avg Loss  387: 0.175800

Train Avg F1  387: 0.7131666885050344

Val Avg Loss  387: 0.182347

Val Avg F1  387:  0.6723545605533184

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 388
--------------------------------------------------------------
Epoch:  388        1 Batch loss: 0.146410 Batch F1: 0.8444444444444444
Epoch:  388        2 Batch loss: 0.160116 Batch F1: 0.717948717948718
Epoch:  388        3 Batch loss: 0.190942 Batch F1: 0.7272727272727273
Epoch:  388        4 Batch loss: 0.187713 Batch F1: 0.47058823529411764
Epoch:  388        5 Batch loss: 0.180839 Batch F1: 0.7169811320754716
Epoch:  388        6 Batch loss: 0.156112 Batch F1: 0.851063829787234
Epoch:  388        7 Batch loss: 0.181876 Batch F1: 0.7222222222222222
Epoch:  388        8 Batch loss: 0.199319 Batch F1: 0.5365853658536585
Epoch:  388        9 Batch loss: 0.169459 Batch F1: 0.6818181818181819
Epoch:  388       10 Batch loss: 0.167805 Batch F1: 0.8363636363636363
Epoch:  388       11 Batch loss: 0.177159 Batch F1: 0.6363636363636364
Epoch:  388       12 Batch loss: 0.141076 Batch F1: 0.8648648648648648
Train Avg Loss  388: 0.171569

Train Avg F1  388: 0.7172097495257427

Val Avg Loss  388: 0.185615

Val Avg F1  388:  0.6785554561717353

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 389
--------------------------------------------------------------
Epoch:  389        1 Batch loss: 0.170411 Batch F1: 0.7755102040816326
Epoch:  389        2 Batch loss: 0.149426 Batch F1: 0.8235294117647058
Epoch:  389        3 Batch loss: 0.162399 Batch F1: 0.7027027027027027
Epoch:  389        4 Batch loss: 0.164479 Batch F1: 0.6666666666666666
Epoch:  389        5 Batch loss: 0.154896 Batch F1: 0.7804878048780488
Epoch:  389        6 Batch loss: 0.202342 Batch F1: 0.5909090909090909
Epoch:  389        7 Batch loss: 0.189391 Batch F1: 0.6938775510204083
Epoch:  389        8 Batch loss: 0.221566 Batch F1: 0.576923076923077
Epoch:  389        9 Batch loss: 0.182389 Batch F1: 0.75
Epoch:  389       10 Batch loss: 0.166953 Batch F1: 0.6486486486486486
Epoch:  389       11 Batch loss: 0.136007 Batch F1: 0.7804878048780488
Epoch:  389       12 Batch loss: 0.156030 Batch F1: 0.7428571428571428
Train Avg Loss  389: 0.171357

Train Avg F1  389: 0.7110500087775143

Val Avg Loss  389: 0.181200

Val Avg F1  389:  0.6738084284615224

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 390
--------------------------------------------------------------
Epoch:  390        1 Batch loss: 0.178312 Batch F1: 0.6521739130434783
Epoch:  390        2 Batch loss: 0.175523 Batch F1: 0.717948717948718
Epoch:  390        3 Batch loss: 0.180735 Batch F1: 0.5294117647058824
Epoch:  390        4 Batch loss: 0.164939 Batch F1: 0.6842105263157895
Epoch:  390        5 Batch loss: 0.185989 Batch F1: 0.7307692307692308
Epoch:  390        6 Batch loss: 0.171163 Batch F1: 0.6153846153846154
Epoch:  390        7 Batch loss: 0.178960 Batch F1: 0.6222222222222222
Epoch:  390        8 Batch loss: 0.152696 Batch F1: 0.7727272727272727
Epoch:  390        9 Batch loss: 0.169257 Batch F1: 0.7234042553191491
Epoch:  390       10 Batch loss: 0.183042 Batch F1: 0.7213114754098361
Epoch:  390       11 Batch loss: 0.155156 Batch F1: 0.7441860465116279
Epoch:  390       12 Batch loss: 0.182954 Batch F1: 0.6666666666666666
Train Avg Loss  390: 0.173227

Train Avg F1  390: 0.6817013922520406

Val Avg Loss  390: 0.182778

Val Avg F1  390:  0.6764027142205657

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 391
--------------------------------------------------------------
Epoch:  391        1 Batch loss: 0.139396 Batch F1: 0.7999999999999999
Epoch:  391        2 Batch loss: 0.157491 Batch F1: 0.7727272727272727
Epoch:  391        3 Batch loss: 0.176814 Batch F1: 0.7234042553191491
Epoch:  391        4 Batch loss: 0.203442 Batch F1: 0.6666666666666666
Epoch:  391        5 Batch loss: 0.199436 Batch F1: 0.6399999999999999
Epoch:  391        6 Batch loss: 0.192862 Batch F1: 0.6666666666666666
Epoch:  391        7 Batch loss: 0.147846 Batch F1: 0.7916666666666666
Epoch:  391        8 Batch loss: 0.153283 Batch F1: 0.7000000000000001
Epoch:  391        9 Batch loss: 0.190173 Batch F1: 0.65
Epoch:  391       10 Batch loss: 0.163679 Batch F1: 0.7499999999999999
Epoch:  391       11 Batch loss: 0.166660 Batch F1: 0.7096774193548386
Epoch:  391       12 Batch loss: 0.180426 Batch F1: 0.6842105263157895
Train Avg Loss  391: 0.172626

Train Avg F1  391: 0.7129182894764209

Val Avg Loss  391: 0.188446

Val Avg F1  391:  0.6695992468645616

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 392
--------------------------------------------------------------
Epoch:  392        1 Batch loss: 0.176947 Batch F1: 0.7555555555555555
Epoch:  392        2 Batch loss: 0.175400 Batch F1: 0.7346938775510203
Epoch:  392        3 Batch loss: 0.195575 Batch F1: 0.6086956521739131
Epoch:  392        4 Batch loss: 0.197834 Batch F1: 0.6382978723404256
Epoch:  392        5 Batch loss: 0.139836 Batch F1: 0.9019607843137256
Epoch:  392        6 Batch loss: 0.131296 Batch F1: 0.8292682926829269
Epoch:  392        7 Batch loss: 0.166014 Batch F1: 0.8400000000000001
Epoch:  392        8 Batch loss: 0.158321 Batch F1: 0.8260869565217391
Epoch:  392        9 Batch loss: 0.165516 Batch F1: 0.7272727272727273
Epoch:  392       10 Batch loss: 0.220276 Batch F1: 0.5853658536585366
Epoch:  392       11 Batch loss: 0.224879 Batch F1: 0.47619047619047616
Epoch:  392       12 Batch loss: 0.163267 Batch F1: 0.7647058823529413
Train Avg Loss  392: 0.176263

Train Avg F1  392: 0.7240078275511657

Val Avg Loss  392: 0.184880

Val Avg F1  392:  0.6694190834228428

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 393
--------------------------------------------------------------
Epoch:  393        1 Batch loss: 0.165872 Batch F1: 0.6486486486486486
Epoch:  393        2 Batch loss: 0.206856 Batch F1: 0.6296296296296297
Epoch:  393        3 Batch loss: 0.171151 Batch F1: 0.7906976744186046
Epoch:  393        4 Batch loss: 0.158821 Batch F1: 0.8085106382978723
Epoch:  393        5 Batch loss: 0.173290 Batch F1: 0.6666666666666666
Epoch:  393        6 Batch loss: 0.178459 Batch F1: 0.6500000000000001
Epoch:  393        7 Batch loss: 0.175225 Batch F1: 0.6818181818181818
Epoch:  393        8 Batch loss: 0.170808 Batch F1: 0.65
Epoch:  393        9 Batch loss: 0.150078 Batch F1: 0.8095238095238095
Epoch:  393       10 Batch loss: 0.197483 Batch F1: 0.6521739130434783
Epoch:  393       11 Batch loss: 0.146676 Batch F1: 0.8260869565217391
Epoch:  393       12 Batch loss: 0.174669 Batch F1: 0.7755102040816326
Train Avg Loss  393: 0.172449

Train Avg F1  393: 0.7157721935541886

Val Avg Loss  393: 0.183596

Val Avg F1  393:  0.6718060069738435

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 394
--------------------------------------------------------------
Epoch:  394        1 Batch loss: 0.157997 Batch F1: 0.7272727272727273
Epoch:  394        2 Batch loss: 0.161867 Batch F1: 0.7692307692307693
Epoch:  394        3 Batch loss: 0.185234 Batch F1: 0.7547169811320754
Epoch:  394        4 Batch loss: 0.146227 Batch F1: 0.8695652173913043
Epoch:  394        5 Batch loss: 0.175469 Batch F1: 0.7692307692307692
Epoch:  394        6 Batch loss: 0.183728 Batch F1: 0.6666666666666666
Epoch:  394        7 Batch loss: 0.179216 Batch F1: 0.6153846153846153
Epoch:  394        8 Batch loss: 0.167980 Batch F1: 0.7391304347826088
Epoch:  394        9 Batch loss: 0.175563 Batch F1: 0.6666666666666667
Epoch:  394       10 Batch loss: 0.165522 Batch F1: 0.6111111111111113
Epoch:  394       11 Batch loss: 0.179193 Batch F1: 0.7083333333333334
Epoch:  394       12 Batch loss: 0.195442 Batch F1: 0.5
Train Avg Loss  394: 0.172787

Train Avg F1  394: 0.6997757743502205

Val Avg Loss  394: 0.181994

Val Avg F1  394:  0.6662941444520392

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 395
--------------------------------------------------------------
Epoch:  395        1 Batch loss: 0.172879 Batch F1: 0.6315789473684211
Epoch:  395        2 Batch loss: 0.215461 Batch F1: 0.5652173913043478
Epoch:  395        3 Batch loss: 0.163650 Batch F1: 0.8214285714285715
Epoch:  395        4 Batch loss: 0.147162 Batch F1: 0.8260869565217391
Epoch:  395        5 Batch loss: 0.169592 Batch F1: 0.6666666666666667
Epoch:  395        6 Batch loss: 0.170622 Batch F1: 0.6666666666666666
Epoch:  395        7 Batch loss: 0.160773 Batch F1: 0.8333333333333334
Epoch:  395        8 Batch loss: 0.188770 Batch F1: 0.6190476190476191
Epoch:  395        9 Batch loss: 0.159323 Batch F1: 0.7317073170731706
Epoch:  395       10 Batch loss: 0.180736 Batch F1: 0.6486486486486486
Epoch:  395       11 Batch loss: 0.150098 Batch F1: 0.7441860465116279
Epoch:  395       12 Batch loss: 0.186962 Batch F1: 0.6842105263157895
Train Avg Loss  395: 0.172169

Train Avg F1  395: 0.7032315575738833

Val Avg Loss  395: 0.182258

Val Avg F1  395:  0.6779343745955041

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 396
--------------------------------------------------------------
Epoch:  396        1 Batch loss: 0.187223 Batch F1: 0.6511627906976744
Epoch:  396        2 Batch loss: 0.172411 Batch F1: 0.7142857142857143
Epoch:  396        3 Batch loss: 0.162963 Batch F1: 0.7555555555555555
Epoch:  396        4 Batch loss: 0.170281 Batch F1: 0.7111111111111111
Epoch:  396        5 Batch loss: 0.178529 Batch F1: 0.723404255319149
Epoch:  396        6 Batch loss: 0.154831 Batch F1: 0.7692307692307692
Epoch:  396        7 Batch loss: 0.171530 Batch F1: 0.76
Epoch:  396        8 Batch loss: 0.155208 Batch F1: 0.75
Epoch:  396        9 Batch loss: 0.213174 Batch F1: 0.5531914893617023
Epoch:  396       10 Batch loss: 0.186441 Batch F1: 0.7058823529411764
Epoch:  396       11 Batch loss: 0.133999 Batch F1: 0.8695652173913043
Epoch:  396       12 Batch loss: 0.184001 Batch F1: 0.5333333333333333
Train Avg Loss  396: 0.172549

Train Avg F1  396: 0.7080602157689575

Val Avg Loss  396: 0.182530

Val Avg F1  396:  0.6670172955279337

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 397
--------------------------------------------------------------
Epoch:  397        1 Batch loss: 0.170025 Batch F1: 0.76
Epoch:  397        2 Batch loss: 0.173977 Batch F1: 0.6666666666666667
Epoch:  397        3 Batch loss: 0.188428 Batch F1: 0.68
Epoch:  397        4 Batch loss: 0.161691 Batch F1: 0.6285714285714286
Epoch:  397        5 Batch loss: 0.193473 Batch F1: 0.6222222222222222
Epoch:  397        6 Batch loss: 0.172629 Batch F1: 0.6666666666666667
Epoch:  397        7 Batch loss: 0.160752 Batch F1: 0.7843137254901961
Epoch:  397        8 Batch loss: 0.169537 Batch F1: 0.6956521739130435
Epoch:  397        9 Batch loss: 0.177367 Batch F1: 0.6818181818181819
Epoch:  397       10 Batch loss: 0.151126 Batch F1: 0.8
Epoch:  397       11 Batch loss: 0.195152 Batch F1: 0.6511627906976745
Epoch:  397       12 Batch loss: 0.122783 Batch F1: 0.878048780487805
Train Avg Loss  397: 0.169745

Train Avg F1  397: 0.7095935530444905

Val Avg Loss  397: 0.182932

Val Avg F1  397:  0.6775427854639846

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 398
--------------------------------------------------------------
Epoch:  398        1 Batch loss: 0.173754 Batch F1: 0.7346938775510204
Epoch:  398        2 Batch loss: 0.154193 Batch F1: 0.7692307692307693
Epoch:  398        3 Batch loss: 0.179092 Batch F1: 0.6956521739130435
Epoch:  398        4 Batch loss: 0.176503 Batch F1: 0.6666666666666666
Epoch:  398        5 Batch loss: 0.150546 Batch F1: 0.6857142857142857
Epoch:  398        6 Batch loss: 0.181488 Batch F1: 0.5789473684210527
Epoch:  398        7 Batch loss: 0.183462 Batch F1: 0.6808510638297872
Epoch:  398        8 Batch loss: 0.146281 Batch F1: 0.8260869565217391
Epoch:  398        9 Batch loss: 0.180734 Batch F1: 0.7666666666666667
Epoch:  398       10 Batch loss: 0.179074 Batch F1: 0.6808510638297872
Epoch:  398       11 Batch loss: 0.159125 Batch F1: 0.761904761904762
Epoch:  398       12 Batch loss: 0.175161 Batch F1: 0.6451612903225806
Train Avg Loss  398: 0.169951

Train Avg F1  398: 0.7077022453810135

Val Avg Loss  398: 0.180422

Val Avg F1  398:  0.6758287079864322

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 399
--------------------------------------------------------------
Epoch:  399        1 Batch loss: 0.172915 Batch F1: 0.7450980392156864
Epoch:  399        2 Batch loss: 0.179866 Batch F1: 0.7199999999999999
Epoch:  399        3 Batch loss: 0.184946 Batch F1: 0.6818181818181818
Epoch:  399        4 Batch loss: 0.167196 Batch F1: 0.5625
Epoch:  399        5 Batch loss: 0.160078 Batch F1: 0.7000000000000001
Epoch:  399        6 Batch loss: 0.187963 Batch F1: 0.6363636363636365
Epoch:  399        7 Batch loss: 0.177318 Batch F1: 0.6666666666666666
Epoch:  399        8 Batch loss: 0.158389 Batch F1: 0.7755102040816326
Epoch:  399        9 Batch loss: 0.146792 Batch F1: 0.7368421052631577
Epoch:  399       10 Batch loss: 0.161220 Batch F1: 0.7
Epoch:  399       11 Batch loss: 0.159604 Batch F1: 0.8421052631578947
Epoch:  399       12 Batch loss: 0.169792 Batch F1: 0.6857142857142857
Train Avg Loss  399: 0.168840

Train Avg F1  399: 0.7043848651900951

Val Avg Loss  399: 0.181837

Val Avg F1  399:  0.6806680161943319

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 400
--------------------------------------------------------------
Epoch:  400        1 Batch loss: 0.165760 Batch F1: 0.6666666666666667
Epoch:  400        2 Batch loss: 0.175005 Batch F1: 0.7659574468085107
Epoch:  400        3 Batch loss: 0.184417 Batch F1: 0.5945945945945946
Epoch:  400        4 Batch loss: 0.150503 Batch F1: 0.8085106382978724
Epoch:  400        5 Batch loss: 0.162749 Batch F1: 0.7692307692307692
Epoch:  400        6 Batch loss: 0.185724 Batch F1: 0.76
Epoch:  400        7 Batch loss: 0.173907 Batch F1: 0.5806451612903225
Epoch:  400        8 Batch loss: 0.196297 Batch F1: 0.6222222222222222
Epoch:  400        9 Batch loss: 0.178794 Batch F1: 0.7111111111111111
Epoch:  400       10 Batch loss: 0.179253 Batch F1: 0.6808510638297872
Epoch:  400       11 Batch loss: 0.152356 Batch F1: 0.782608695652174
Epoch:  400       12 Batch loss: 0.171532 Batch F1: 0.717948717948718
Train Avg Loss  400: 0.173025

Train Avg F1  400: 0.7050289239710623

Val Avg Loss  400: 0.184370

Val Avg F1  400:  0.678969178969179

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 401
--------------------------------------------------------------
Epoch:  401        1 Batch loss: 0.181233 Batch F1: 0.7083333333333334
Epoch:  401        2 Batch loss: 0.149877 Batch F1: 0.8235294117647058
Epoch:  401        3 Batch loss: 0.189308 Batch F1: 0.6111111111111112
Epoch:  401        4 Batch loss: 0.184260 Batch F1: 0.6808510638297872
Epoch:  401        5 Batch loss: 0.139528 Batch F1: 0.8108108108108109
Epoch:  401        6 Batch loss: 0.183238 Batch F1: 0.6190476190476191
Epoch:  401        7 Batch loss: 0.166155 Batch F1: 0.7843137254901961
Epoch:  401        8 Batch loss: 0.152511 Batch F1: 0.7619047619047619
Epoch:  401        9 Batch loss: 0.149062 Batch F1: 0.761904761904762
Epoch:  401       10 Batch loss: 0.154807 Batch F1: 0.717948717948718
Epoch:  401       11 Batch loss: 0.231255 Batch F1: 0.5777777777777778
Epoch:  401       12 Batch loss: 0.187090 Batch F1: 0.6818181818181818
Train Avg Loss  401: 0.172360

Train Avg F1  401: 0.7116126063951471

Val Avg Loss  401: 0.180054

Val Avg F1  401:  0.6798062618924061

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 402
--------------------------------------------------------------
Epoch:  402        1 Batch loss: 0.183818 Batch F1: 0.6818181818181818
Epoch:  402        2 Batch loss: 0.160948 Batch F1: 0.7924528301886792
Epoch:  402        3 Batch loss: 0.210543 Batch F1: 0.6
Epoch:  402        4 Batch loss: 0.165624 Batch F1: 0.7659574468085107
Epoch:  402        5 Batch loss: 0.173117 Batch F1: 0.6111111111111112
Epoch:  402        6 Batch loss: 0.164863 Batch F1: 0.7391304347826088
Epoch:  402        7 Batch loss: 0.177880 Batch F1: 0.76
Epoch:  402        8 Batch loss: 0.153720 Batch F1: 0.7317073170731707
Epoch:  402        9 Batch loss: 0.178700 Batch F1: 0.6829268292682926
Epoch:  402       10 Batch loss: 0.153890 Batch F1: 0.7659574468085107
Epoch:  402       11 Batch loss: 0.154641 Batch F1: 0.6060606060606061
Epoch:  402       12 Batch loss: 0.162103 Batch F1: 0.7567567567567567
Train Avg Loss  402: 0.169987

Train Avg F1  402: 0.7078232467230356

Val Avg Loss  402: 0.180847

Val Avg F1  402:  0.6708266879319511

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 403
--------------------------------------------------------------
Epoch:  403        1 Batch loss: 0.207506 Batch F1: 0.5714285714285715
Epoch:  403        2 Batch loss: 0.182796 Batch F1: 0.7083333333333334
Epoch:  403        3 Batch loss: 0.196962 Batch F1: 0.5128205128205129
Epoch:  403        4 Batch loss: 0.175850 Batch F1: 0.5789473684210527
Epoch:  403        5 Batch loss: 0.153663 Batch F1: 0.830188679245283
Epoch:  403        6 Batch loss: 0.145438 Batch F1: 0.830188679245283
Epoch:  403        7 Batch loss: 0.172446 Batch F1: 0.6486486486486486
Epoch:  403        8 Batch loss: 0.167837 Batch F1: 0.7346938775510204
Epoch:  403        9 Batch loss: 0.141710 Batch F1: 0.7999999999999999
Epoch:  403       10 Batch loss: 0.180455 Batch F1: 0.6818181818181819
Epoch:  403       11 Batch loss: 0.164144 Batch F1: 0.7555555555555555
Epoch:  403       12 Batch loss: 0.149440 Batch F1: 0.8095238095238095
Train Avg Loss  403: 0.169854

Train Avg F1  403: 0.705178934799271

Val Avg Loss  403: 0.181306

Val Avg F1  403:  0.6740874215298768

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 404
--------------------------------------------------------------
Epoch:  404        1 Batch loss: 0.182116 Batch F1: 0.6666666666666666
Epoch:  404        2 Batch loss: 0.166000 Batch F1: 0.7499999999999999
Epoch:  404        3 Batch loss: 0.162918 Batch F1: 0.7272727272727272
Epoch:  404        4 Batch loss: 0.148775 Batch F1: 0.7692307692307693
Epoch:  404        5 Batch loss: 0.203163 Batch F1: 0.6250000000000001
Epoch:  404        6 Batch loss: 0.202388 Batch F1: 0.5714285714285714
Epoch:  404        7 Batch loss: 0.160969 Batch F1: 0.7441860465116279
Epoch:  404        8 Batch loss: 0.167108 Batch F1: 0.6976744186046512
Epoch:  404        9 Batch loss: 0.158666 Batch F1: 0.7906976744186046
Epoch:  404       10 Batch loss: 0.145340 Batch F1: 0.7906976744186046
Epoch:  404       11 Batch loss: 0.166400 Batch F1: 0.7659574468085107
Epoch:  404       12 Batch loss: 0.204014 Batch F1: 0.5581395348837209
Train Avg Loss  404: 0.172321

Train Avg F1  404: 0.7047459608537044

Val Avg Loss  404: 0.184221

Val Avg F1  404:  0.6762584450589841

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 405
--------------------------------------------------------------
Epoch:  405        1 Batch loss: 0.174003 Batch F1: 0.6818181818181818
Epoch:  405        2 Batch loss: 0.164713 Batch F1: 0.7234042553191491
Epoch:  405        3 Batch loss: 0.176624 Batch F1: 0.7346938775510203
Epoch:  405        4 Batch loss: 0.155268 Batch F1: 0.7428571428571428
Epoch:  405        5 Batch loss: 0.142207 Batch F1: 0.7692307692307692
Epoch:  405        6 Batch loss: 0.184123 Batch F1: 0.6666666666666666
Epoch:  405        7 Batch loss: 0.177739 Batch F1: 0.6153846153846153
Epoch:  405        8 Batch loss: 0.171746 Batch F1: 0.6956521739130435
Epoch:  405        9 Batch loss: 0.169543 Batch F1: 0.6829268292682926
Epoch:  405       10 Batch loss: 0.178558 Batch F1: 0.723404255319149
Epoch:  405       11 Batch loss: 0.174419 Batch F1: 0.7307692307692308
Epoch:  405       12 Batch loss: 0.176117 Batch F1: 0.7804878048780488
Train Avg Loss  405: 0.170422

Train Avg F1  405: 0.7122746502479426

Val Avg Loss  405: 0.185380

Val Avg F1  405:  0.6285079812370917

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 406
--------------------------------------------------------------
Epoch:  406        1 Batch loss: 0.170500 Batch F1: 0.6511627906976745
Epoch:  406        2 Batch loss: 0.157049 Batch F1: 0.7142857142857143
Epoch:  406        3 Batch loss: 0.169831 Batch F1: 0.7083333333333333
Epoch:  406        4 Batch loss: 0.195861 Batch F1: 0.6666666666666666
Epoch:  406        5 Batch loss: 0.172911 Batch F1: 0.6808510638297872
Epoch:  406        6 Batch loss: 0.169238 Batch F1: 0.717948717948718
Epoch:  406        7 Batch loss: 0.199259 Batch F1: 0.75
Epoch:  406        8 Batch loss: 0.176768 Batch F1: 0.6666666666666666
Epoch:  406        9 Batch loss: 0.159813 Batch F1: 0.7755102040816326
Epoch:  406       10 Batch loss: 0.158136 Batch F1: 0.9166666666666666
Epoch:  406       11 Batch loss: 0.209822 Batch F1: 0.6808510638297872
Epoch:  406       12 Batch loss: 0.194742 Batch F1: 0.717948717948718
Train Avg Loss  406: 0.177827

Train Avg F1  406: 0.7205743004962804

Val Avg Loss  406: 0.184394

Val Avg F1  406:  0.6702380952380952

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 407
--------------------------------------------------------------
Epoch:  407        1 Batch loss: 0.175901 Batch F1: 0.7499999999999999
Epoch:  407        2 Batch loss: 0.173190 Batch F1: 0.606060606060606
Epoch:  407        3 Batch loss: 0.137702 Batch F1: 0.6428571428571429
Epoch:  407        4 Batch loss: 0.202419 Batch F1: 0.6530612244897959
Epoch:  407        5 Batch loss: 0.179385 Batch F1: 0.75
Epoch:  407        6 Batch loss: 0.142932 Batch F1: 0.7727272727272727
Epoch:  407        7 Batch loss: 0.155051 Batch F1: 0.7000000000000001
Epoch:  407        8 Batch loss: 0.206320 Batch F1: 0.6666666666666667
Epoch:  407        9 Batch loss: 0.202729 Batch F1: 0.6296296296296297
Epoch:  407       10 Batch loss: 0.230997 Batch F1: 0.5306122448979592
Epoch:  407       11 Batch loss: 0.172352 Batch F1: 0.7636363636363638
Epoch:  407       12 Batch loss: 0.156602 Batch F1: 0.7894736842105262
Train Avg Loss  407: 0.177965

Train Avg F1  407: 0.6878937362646637

Val Avg Loss  407: 0.188953

Val Avg F1  407:  0.674056603773585

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 408
--------------------------------------------------------------
Epoch:  408        1 Batch loss: 0.183217 Batch F1: 0.6190476190476191
Epoch:  408        2 Batch loss: 0.170469 Batch F1: 0.6666666666666666
Epoch:  408        3 Batch loss: 0.187312 Batch F1: 0.793103448275862
Epoch:  408        4 Batch loss: 0.189701 Batch F1: 0.6511627906976745
Epoch:  408        5 Batch loss: 0.162764 Batch F1: 0.717948717948718
Epoch:  408        6 Batch loss: 0.179969 Batch F1: 0.7692307692307693
Epoch:  408        7 Batch loss: 0.184830 Batch F1: 0.7272727272727272
Epoch:  408        8 Batch loss: 0.167768 Batch F1: 0.7272727272727272
Epoch:  408        9 Batch loss: 0.170254 Batch F1: 0.7027027027027027
Epoch:  408       10 Batch loss: 0.185765 Batch F1: 0.6666666666666666
Epoch:  408       11 Batch loss: 0.178126 Batch F1: 0.6153846153846154
Epoch:  408       12 Batch loss: 0.186786 Batch F1: 0.7000000000000001
Train Avg Loss  408: 0.178913

Train Avg F1  408: 0.6963716209305625

Val Avg Loss  408: 0.188890

Val Avg F1  408:  0.7442803881286768

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 409
--------------------------------------------------------------
Epoch:  409        1 Batch loss: 0.186026 Batch F1: 0.7659574468085107
Epoch:  409        2 Batch loss: 0.178411 Batch F1: 0.761904761904762
Epoch:  409        3 Batch loss: 0.194925 Batch F1: 0.5714285714285713
Epoch:  409        4 Batch loss: 0.182239 Batch F1: 0.6818181818181819
Epoch:  409        5 Batch loss: 0.176690 Batch F1: 0.7317073170731708
Epoch:  409        6 Batch loss: 0.177642 Batch F1: 0.6956521739130435
Epoch:  409        7 Batch loss: 0.173208 Batch F1: 0.6666666666666667
Epoch:  409        8 Batch loss: 0.194363 Batch F1: 0.6666666666666666
Epoch:  409        9 Batch loss: 0.139001 Batch F1: 0.8679245283018867
Epoch:  409       10 Batch loss: 0.143326 Batch F1: 0.8500000000000001
Epoch:  409       11 Batch loss: 0.165180 Batch F1: 0.7924528301886792
Epoch:  409       12 Batch loss: 0.174752 Batch F1: 0.7222222222222222
Train Avg Loss  409: 0.173814

Train Avg F1  409: 0.7312001139160302

Val Avg Loss  409: 0.180939

Val Avg F1  409:  0.6716027564637704

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 410
--------------------------------------------------------------
Epoch:  410        1 Batch loss: 0.176506 Batch F1: 0.6341463414634148
Epoch:  410        2 Batch loss: 0.169513 Batch F1: 0.8260869565217391
Epoch:  410        3 Batch loss: 0.164036 Batch F1: 0.7499999999999999
Epoch:  410        4 Batch loss: 0.175115 Batch F1: 0.7346938775510203
Epoch:  410        5 Batch loss: 0.156892 Batch F1: 0.7804878048780488
Epoch:  410        6 Batch loss: 0.180960 Batch F1: 0.6808510638297872
Epoch:  410        7 Batch loss: 0.151900 Batch F1: 0.7727272727272727
Epoch:  410        8 Batch loss: 0.173438 Batch F1: 0.6829268292682927
Epoch:  410        9 Batch loss: 0.159305 Batch F1: 0.606060606060606
Epoch:  410       10 Batch loss: 0.186744 Batch F1: 0.6938775510204083
Epoch:  410       11 Batch loss: 0.197416 Batch F1: 0.7037037037037038
Epoch:  410       12 Batch loss: 0.158882 Batch F1: 0.742857142857143
Train Avg Loss  410: 0.170892

Train Avg F1  410: 0.7173682624901199

Val Avg Loss  410: 0.181672

Val Avg F1  410:  0.6742680077397686

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 411
--------------------------------------------------------------
Epoch:  411        1 Batch loss: 0.166272 Batch F1: 0.6829268292682926
Epoch:  411        2 Batch loss: 0.190761 Batch F1: 0.6
Epoch:  411        3 Batch loss: 0.173725 Batch F1: 0.711111111111111
Epoch:  411        4 Batch loss: 0.148509 Batch F1: 0.8620689655172414
Epoch:  411        5 Batch loss: 0.172072 Batch F1: 0.6829268292682926
Epoch:  411        6 Batch loss: 0.192729 Batch F1: 0.6382978723404256
Epoch:  411        7 Batch loss: 0.166728 Batch F1: 0.7441860465116279
Epoch:  411        8 Batch loss: 0.181648 Batch F1: 0.5789473684210527
Epoch:  411        9 Batch loss: 0.173907 Batch F1: 0.711111111111111
Epoch:  411       10 Batch loss: 0.163595 Batch F1: 0.7272727272727272
Epoch:  411       11 Batch loss: 0.155208 Batch F1: 0.8333333333333333
Epoch:  411       12 Batch loss: 0.149751 Batch F1: 0.7058823529411764
Train Avg Loss  411: 0.169575

Train Avg F1  411: 0.7065053789246994

Val Avg Loss  411: 0.181774

Val Avg F1  411:  0.6758005587792822

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 412
--------------------------------------------------------------
Epoch:  412        1 Batch loss: 0.170669 Batch F1: 0.7450980392156863
Epoch:  412        2 Batch loss: 0.174838 Batch F1: 0.6829268292682926
Epoch:  412        3 Batch loss: 0.174671 Batch F1: 0.7659574468085107
Epoch:  412        4 Batch loss: 0.189671 Batch F1: 0.6666666666666666
Epoch:  412        5 Batch loss: 0.177690 Batch F1: 0.6666666666666665
Epoch:  412        6 Batch loss: 0.170546 Batch F1: 0.7272727272727272
Epoch:  412        7 Batch loss: 0.169463 Batch F1: 0.7142857142857143
Epoch:  412        8 Batch loss: 0.158298 Batch F1: 0.717948717948718
Epoch:  412        9 Batch loss: 0.172703 Batch F1: 0.6829268292682926
Epoch:  412       10 Batch loss: 0.173324 Batch F1: 0.7111111111111111
Epoch:  412       11 Batch loss: 0.190228 Batch F1: 0.6530612244897959
Epoch:  412       12 Batch loss: 0.149373 Batch F1: 0.8205128205128205
Train Avg Loss  412: 0.172623

Train Avg F1  412: 0.7128695661262502

Val Avg Loss  412: 0.184142

Val Avg F1  412:  0.6820103655210037

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 413
--------------------------------------------------------------
Epoch:  413        1 Batch loss: 0.133258 Batch F1: 0.8372093023255814
Epoch:  413        2 Batch loss: 0.191695 Batch F1: 0.6
Epoch:  413        3 Batch loss: 0.149902 Batch F1: 0.8181818181818182
Epoch:  413        4 Batch loss: 0.180981 Batch F1: 0.6666666666666666
Epoch:  413        5 Batch loss: 0.182164 Batch F1: 0.7307692307692308
Epoch:  413        6 Batch loss: 0.189224 Batch F1: 0.6153846153846153
Epoch:  413        7 Batch loss: 0.156125 Batch F1: 0.7500000000000001
Epoch:  413        8 Batch loss: 0.178026 Batch F1: 0.7111111111111111
Epoch:  413        9 Batch loss: 0.200924 Batch F1: 0.6511627906976744
Epoch:  413       10 Batch loss: 0.211772 Batch F1: 0.5957446808510638
Epoch:  413       11 Batch loss: 0.165892 Batch F1: 0.7272727272727272
Epoch:  413       12 Batch loss: 0.155167 Batch F1: 0.8444444444444444
Train Avg Loss  413: 0.174594

Train Avg F1  413: 0.7123289489754111

Val Avg Loss  413: 0.183572

Val Avg F1  413:  0.6747562661428208

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 414
--------------------------------------------------------------
Epoch:  414        1 Batch loss: 0.194616 Batch F1: 0.5789473684210527
Epoch:  414        2 Batch loss: 0.186562 Batch F1: 0.7111111111111111
Epoch:  414        3 Batch loss: 0.163882 Batch F1: 0.7931034482758621
Epoch:  414        4 Batch loss: 0.204222 Batch F1: 0.5789473684210527
Epoch:  414        5 Batch loss: 0.161324 Batch F1: 0.7826086956521738
Epoch:  414        6 Batch loss: 0.176227 Batch F1: 0.5853658536585366
Epoch:  414        7 Batch loss: 0.203520 Batch F1: 0.5405405405405405
Epoch:  414        8 Batch loss: 0.163921 Batch F1: 0.75
Epoch:  414        9 Batch loss: 0.155199 Batch F1: 0.7500000000000001
Epoch:  414       10 Batch loss: 0.176271 Batch F1: 0.717948717948718
Epoch:  414       11 Batch loss: 0.151632 Batch F1: 0.8333333333333333
Epoch:  414       12 Batch loss: 0.158946 Batch F1: 0.8085106382978724
Train Avg Loss  414: 0.174693

Train Avg F1  414: 0.7025347563050209

Val Avg Loss  414: 0.183985

Val Avg F1  414:  0.6736354804813736

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 415
--------------------------------------------------------------
Epoch:  415        1 Batch loss: 0.151433 Batch F1: 0.84
Epoch:  415        2 Batch loss: 0.178995 Batch F1: 0.7346938775510204
Epoch:  415        3 Batch loss: 0.179412 Batch F1: 0.6341463414634146
Epoch:  415        4 Batch loss: 0.163881 Batch F1: 0.7272727272727272
Epoch:  415        5 Batch loss: 0.166890 Batch F1: 0.6976744186046512
Epoch:  415        6 Batch loss: 0.153455 Batch F1: 0.7619047619047619
Epoch:  415        7 Batch loss: 0.172895 Batch F1: 0.6666666666666666
Epoch:  415        8 Batch loss: 0.173096 Batch F1: 0.7083333333333333
Epoch:  415        9 Batch loss: 0.181929 Batch F1: 0.7450980392156864
Epoch:  415       10 Batch loss: 0.168279 Batch F1: 0.6818181818181819
Epoch:  415       11 Batch loss: 0.196954 Batch F1: 0.45161290322580644
Epoch:  415       12 Batch loss: 0.158904 Batch F1: 0.8000000000000002
Train Avg Loss  415: 0.170510

Train Avg F1  415: 0.7041017709213541

Val Avg Loss  415: 0.182379

Val Avg F1  415:  0.6710868918315727

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 416
--------------------------------------------------------------
Epoch:  416        1 Batch loss: 0.182930 Batch F1: 0.7083333333333333
Epoch:  416        2 Batch loss: 0.187792 Batch F1: 0.6808510638297872
Epoch:  416        3 Batch loss: 0.159920 Batch F1: 0.7555555555555555
Epoch:  416        4 Batch loss: 0.156275 Batch F1: 0.7317073170731706
Epoch:  416        5 Batch loss: 0.191521 Batch F1: 0.6222222222222222
Epoch:  416        6 Batch loss: 0.179396 Batch F1: 0.7083333333333333
Epoch:  416        7 Batch loss: 0.180803 Batch F1: 0.5882352941176471
Epoch:  416        8 Batch loss: 0.143909 Batch F1: 0.851063829787234
Epoch:  416        9 Batch loss: 0.164841 Batch F1: 0.7659574468085107
Epoch:  416       10 Batch loss: 0.165618 Batch F1: 0.611111111111111
Epoch:  416       11 Batch loss: 0.170821 Batch F1: 0.7307692307692306
Epoch:  416       12 Batch loss: 0.149966 Batch F1: 0.7647058823529411
Train Avg Loss  416: 0.169483

Train Avg F1  416: 0.7099038016911731

Val Avg Loss  416: 0.181699

Val Avg F1  416:  0.6769096914445751

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 417
--------------------------------------------------------------
Epoch:  417        1 Batch loss: 0.166143 Batch F1: 0.7450980392156864
Epoch:  417        2 Batch loss: 0.187641 Batch F1: 0.6521739130434783
Epoch:  417        3 Batch loss: 0.157171 Batch F1: 0.8085106382978724
Epoch:  417        4 Batch loss: 0.163115 Batch F1: 0.7499999999999999
Epoch:  417        5 Batch loss: 0.181135 Batch F1: 0.6341463414634148
Epoch:  417        6 Batch loss: 0.161341 Batch F1: 0.7
Epoch:  417        7 Batch loss: 0.164988 Batch F1: 0.7368421052631577
Epoch:  417        8 Batch loss: 0.198745 Batch F1: 0.6222222222222222
Epoch:  417        9 Batch loss: 0.178896 Batch F1: 0.7547169811320754
Epoch:  417       10 Batch loss: 0.179690 Batch F1: 0.65
Epoch:  417       11 Batch loss: 0.157161 Batch F1: 0.6976744186046512
Epoch:  417       12 Batch loss: 0.136113 Batch F1: 0.7878787878787877
Train Avg Loss  417: 0.169345

Train Avg F1  417: 0.7116052872601122

Val Avg Loss  417: 0.182799

Val Avg F1  417:  0.6758363362361895

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 418
--------------------------------------------------------------
Epoch:  418        1 Batch loss: 0.145902 Batch F1: 0.8518518518518519
Epoch:  418        2 Batch loss: 0.146994 Batch F1: 0.7727272727272727
Epoch:  418        3 Batch loss: 0.184285 Batch F1: 0.5714285714285714
Epoch:  418        4 Batch loss: 0.178484 Batch F1: 0.5945945945945946
Epoch:  418        5 Batch loss: 0.184741 Batch F1: 0.6046511627906976
Epoch:  418        6 Batch loss: 0.192442 Batch F1: 0.6666666666666666
Epoch:  418        7 Batch loss: 0.179638 Batch F1: 0.6666666666666666
Epoch:  418        8 Batch loss: 0.172953 Batch F1: 0.7692307692307692
Epoch:  418        9 Batch loss: 0.173462 Batch F1: 0.7555555555555555
Epoch:  418       10 Batch loss: 0.162150 Batch F1: 0.761904761904762
Epoch:  418       11 Batch loss: 0.173006 Batch F1: 0.6486486486486486
Epoch:  418       12 Batch loss: 0.142852 Batch F1: 0.8108108108108107
Train Avg Loss  418: 0.169742

Train Avg F1  418: 0.7062281110730724

Val Avg Loss  418: 0.181863

Val Avg F1  418:  0.6731692162285154

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 419
--------------------------------------------------------------
Epoch:  419        1 Batch loss: 0.176337 Batch F1: 0.6500000000000001
Epoch:  419        2 Batch loss: 0.138404 Batch F1: 0.8372093023255814
Epoch:  419        3 Batch loss: 0.178265 Batch F1: 0.6521739130434783
Epoch:  419        4 Batch loss: 0.193192 Batch F1: 0.7083333333333333
Epoch:  419        5 Batch loss: 0.140474 Batch F1: 0.8292682926829269
Epoch:  419        6 Batch loss: 0.160939 Batch F1: 0.7
Epoch:  419        7 Batch loss: 0.155799 Batch F1: 0.7804878048780487
Epoch:  419        8 Batch loss: 0.200965 Batch F1: 0.6
Epoch:  419        9 Batch loss: 0.166023 Batch F1: 0.6829268292682927
Epoch:  419       10 Batch loss: 0.175812 Batch F1: 0.7272727272727272
Epoch:  419       11 Batch loss: 0.168757 Batch F1: 0.7450980392156863
Epoch:  419       12 Batch loss: 0.192074 Batch F1: 0.631578947368421
Train Avg Loss  419: 0.170587

Train Avg F1  419: 0.7120290991157079

Val Avg Loss  419: 0.182314

Val Avg F1  419:  0.6767938558402083

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 420
--------------------------------------------------------------
Epoch:  420        1 Batch loss: 0.177204 Batch F1: 0.6285714285714286
Epoch:  420        2 Batch loss: 0.180012 Batch F1: 0.7547169811320754
Epoch:  420        3 Batch loss: 0.165338 Batch F1: 0.7
Epoch:  420        4 Batch loss: 0.171536 Batch F1: 0.7692307692307692
Epoch:  420        5 Batch loss: 0.157836 Batch F1: 0.7027027027027027
Epoch:  420        6 Batch loss: 0.148680 Batch F1: 0.6666666666666667
Epoch:  420        7 Batch loss: 0.152819 Batch F1: 0.7916666666666667
Epoch:  420        8 Batch loss: 0.179658 Batch F1: 0.7083333333333334
Epoch:  420        9 Batch loss: 0.199817 Batch F1: 0.5500000000000002
Epoch:  420       10 Batch loss: 0.159280 Batch F1: 0.8363636363636363
Epoch:  420       11 Batch loss: 0.169371 Batch F1: 0.6666666666666666
Epoch:  420       12 Batch loss: 0.187550 Batch F1: 0.6666666666666666
Train Avg Loss  420: 0.170758

Train Avg F1  420: 0.7034654598333843

Val Avg Loss  420: 0.180708

Val Avg F1  420:  0.6678571428571429

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 421
--------------------------------------------------------------
Epoch:  421        1 Batch loss: 0.141204 Batch F1: 0.8095238095238095
Epoch:  421        2 Batch loss: 0.161960 Batch F1: 0.7755102040816326
Epoch:  421        3 Batch loss: 0.175072 Batch F1: 0.72
Epoch:  421        4 Batch loss: 0.178507 Batch F1: 0.6956521739130435
Epoch:  421        5 Batch loss: 0.183380 Batch F1: 0.5789473684210527
Epoch:  421        6 Batch loss: 0.203060 Batch F1: 0.5909090909090909
Epoch:  421        7 Batch loss: 0.169257 Batch F1: 0.7547169811320754
Epoch:  421        8 Batch loss: 0.149440 Batch F1: 0.8
Epoch:  421        9 Batch loss: 0.170116 Batch F1: 0.6976744186046512
Epoch:  421       10 Batch loss: 0.171059 Batch F1: 0.6666666666666667
Epoch:  421       11 Batch loss: 0.159441 Batch F1: 0.7441860465116279
Epoch:  421       12 Batch loss: 0.170150 Batch F1: 0.7027027027027027
Train Avg Loss  421: 0.169387

Train Avg F1  421: 0.7113741218721962

Val Avg Loss  421: 0.183420

Val Avg F1  421:  0.6728008833271991

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 422
--------------------------------------------------------------
Epoch:  422        1 Batch loss: 0.158295 Batch F1: 0.7916666666666666
Epoch:  422        2 Batch loss: 0.176992 Batch F1: 0.6818181818181819
Epoch:  422        3 Batch loss: 0.165763 Batch F1: 0.7777777777777779
Epoch:  422        4 Batch loss: 0.173491 Batch F1: 0.6842105263157896
Epoch:  422        5 Batch loss: 0.191939 Batch F1: 0.6938775510204083
Epoch:  422        6 Batch loss: 0.163862 Batch F1: 0.7317073170731707
Epoch:  422        7 Batch loss: 0.207010 Batch F1: 0.6086956521739131
Epoch:  422        8 Batch loss: 0.129878 Batch F1: 0.7500000000000001
Epoch:  422        9 Batch loss: 0.167760 Batch F1: 0.7083333333333333
Epoch:  422       10 Batch loss: 0.152337 Batch F1: 0.7826086956521738
Epoch:  422       11 Batch loss: 0.180115 Batch F1: 0.7391304347826089
Epoch:  422       12 Batch loss: 0.179843 Batch F1: 0.5625
Train Avg Loss  422: 0.170607

Train Avg F1  422: 0.709360511384502

Val Avg Loss  422: 0.181618

Val Avg F1  422:  0.6694947209653092

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 423
--------------------------------------------------------------
Epoch:  423        1 Batch loss: 0.179488 Batch F1: 0.6500000000000001
Epoch:  423        2 Batch loss: 0.164534 Batch F1: 0.6486486486486486
Epoch:  423        3 Batch loss: 0.141822 Batch F1: 0.8372093023255814
Epoch:  423        4 Batch loss: 0.180984 Batch F1: 0.6956521739130435
Epoch:  423        5 Batch loss: 0.227101 Batch F1: 0.5882352941176471
Epoch:  423        6 Batch loss: 0.163149 Batch F1: 0.7916666666666666
Epoch:  423        7 Batch loss: 0.150348 Batch F1: 0.8163265306122449
Epoch:  423        8 Batch loss: 0.182193 Batch F1: 0.68
Epoch:  423        9 Batch loss: 0.144744 Batch F1: 0.761904761904762
Epoch:  423       10 Batch loss: 0.166285 Batch F1: 0.7391304347826085
Epoch:  423       11 Batch loss: 0.168518 Batch F1: 0.631578947368421
Epoch:  423       12 Batch loss: 0.166875 Batch F1: 0.6857142857142857
Train Avg Loss  423: 0.169670

Train Avg F1  423: 0.7105055871711591

Val Avg Loss  423: 0.180687

Val Avg F1  423:  0.6772147001934236

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 424
--------------------------------------------------------------
Epoch:  424        1 Batch loss: 0.176028 Batch F1: 0.631578947368421
Epoch:  424        2 Batch loss: 0.161856 Batch F1: 0.7499999999999999
Epoch:  424        3 Batch loss: 0.153351 Batch F1: 0.7659574468085107
Epoch:  424        4 Batch loss: 0.186746 Batch F1: 0.6363636363636365
Epoch:  424        5 Batch loss: 0.174653 Batch F1: 0.5806451612903225
Epoch:  424        6 Batch loss: 0.158503 Batch F1: 0.7555555555555555
Epoch:  424        7 Batch loss: 0.192802 Batch F1: 0.693877551020408
Epoch:  424        8 Batch loss: 0.171404 Batch F1: 0.631578947368421
Epoch:  424        9 Batch loss: 0.163747 Batch F1: 0.76
Epoch:  424       10 Batch loss: 0.156141 Batch F1: 0.8214285714285715
Epoch:  424       11 Batch loss: 0.180545 Batch F1: 0.6976744186046512
Epoch:  424       12 Batch loss: 0.161854 Batch F1: 0.7428571428571428
Train Avg Loss  424: 0.169803

Train Avg F1  424: 0.7056264482221368

Val Avg Loss  424: 0.180915

Val Avg F1  424:  0.6744186046511628

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 425
--------------------------------------------------------------
Epoch:  425        1 Batch loss: 0.168162 Batch F1: 0.6976744186046512
Epoch:  425        2 Batch loss: 0.168308 Batch F1: 0.6829268292682926
Epoch:  425        3 Batch loss: 0.149138 Batch F1: 0.717948717948718
Epoch:  425        4 Batch loss: 0.169930 Batch F1: 0.75
Epoch:  425        5 Batch loss: 0.159951 Batch F1: 0.7441860465116279
Epoch:  425        6 Batch loss: 0.160540 Batch F1: 0.830188679245283
Epoch:  425        7 Batch loss: 0.155046 Batch F1: 0.7916666666666667
Epoch:  425        8 Batch loss: 0.185914 Batch F1: 0.7058823529411765
Epoch:  425        9 Batch loss: 0.160888 Batch F1: 0.625
Epoch:  425       10 Batch loss: 0.178882 Batch F1: 0.6666666666666667
Epoch:  425       11 Batch loss: 0.214156 Batch F1: 0.5365853658536585
Epoch:  425       12 Batch loss: 0.165487 Batch F1: 0.7000000000000001
Train Avg Loss  425: 0.169700

Train Avg F1  425: 0.7040604786422285

Val Avg Loss  425: 0.185678

Val Avg F1  425:  0.6348450491307635

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 426
--------------------------------------------------------------
Epoch:  426        1 Batch loss: 0.167032 Batch F1: 0.7200000000000001
Epoch:  426        2 Batch loss: 0.137066 Batch F1: 0.8571428571428571
Epoch:  426        3 Batch loss: 0.171360 Batch F1: 0.7
Epoch:  426        4 Batch loss: 0.161327 Batch F1: 0.7111111111111111
Epoch:  426        5 Batch loss: 0.192286 Batch F1: 0.5853658536585366
Epoch:  426        6 Batch loss: 0.192525 Batch F1: 0.6511627906976745
Epoch:  426        7 Batch loss: 0.183617 Batch F1: 0.6190476190476191
Epoch:  426        8 Batch loss: 0.184617 Batch F1: 0.7199999999999999
Epoch:  426        9 Batch loss: 0.164960 Batch F1: 0.7755102040816326
Epoch:  426       10 Batch loss: 0.193992 Batch F1: 0.6046511627906976
Epoch:  426       11 Batch loss: 0.164787 Batch F1: 0.7317073170731707
Epoch:  426       12 Batch loss: 0.140840 Batch F1: 0.8292682926829269
Train Avg Loss  426: 0.171201

Train Avg F1  426: 0.7087472673571856

Val Avg Loss  426: 0.180833

Val Avg F1  426:  0.6729510425162599

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 427
--------------------------------------------------------------
Epoch:  427        1 Batch loss: 0.188379 Batch F1: 0.5142857142857143
Epoch:  427        2 Batch loss: 0.175146 Batch F1: 0.6341463414634148
Epoch:  427        3 Batch loss: 0.144585 Batch F1: 0.851063829787234
Epoch:  427        4 Batch loss: 0.170697 Batch F1: 0.72
Epoch:  427        5 Batch loss: 0.193769 Batch F1: 0.6190476190476191
Epoch:  427        6 Batch loss: 0.163471 Batch F1: 0.7027027027027027
Epoch:  427        7 Batch loss: 0.169580 Batch F1: 0.7692307692307692
Epoch:  427        8 Batch loss: 0.160451 Batch F1: 0.8076923076923077
Epoch:  427        9 Batch loss: 0.151302 Batch F1: 0.7906976744186046
Epoch:  427       10 Batch loss: 0.165966 Batch F1: 0.6666666666666666
Epoch:  427       11 Batch loss: 0.162524 Batch F1: 0.7142857142857143
Epoch:  427       12 Batch loss: 0.188579 Batch F1: 0.6829268292682926
Train Avg Loss  427: 0.169538

Train Avg F1  427: 0.70606218073742

Val Avg Loss  427: 0.180690

Val Avg F1  427:  0.6551470588235295

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 428
--------------------------------------------------------------
Epoch:  428        1 Batch loss: 0.186867 Batch F1: 0.6046511627906977
Epoch:  428        2 Batch loss: 0.150929 Batch F1: 0.7142857142857143
Epoch:  428        3 Batch loss: 0.178680 Batch F1: 0.6808510638297872
Epoch:  428        4 Batch loss: 0.173869 Batch F1: 0.6486486486486486
Epoch:  428        5 Batch loss: 0.181621 Batch F1: 0.6153846153846153
Epoch:  428        6 Batch loss: 0.175996 Batch F1: 0.7083333333333334
Epoch:  428        7 Batch loss: 0.177460 Batch F1: 0.7083333333333334
Epoch:  428        8 Batch loss: 0.155138 Batch F1: 0.8260869565217392
Epoch:  428        9 Batch loss: 0.177885 Batch F1: 0.7169811320754718
Epoch:  428       10 Batch loss: 0.177550 Batch F1: 0.7586206896551724
Epoch:  428       11 Batch loss: 0.140393 Batch F1: 0.8108108108108109
Epoch:  428       12 Batch loss: 0.141961 Batch F1: 0.7407407407407408
Train Avg Loss  428: 0.168196

Train Avg F1  428: 0.7111440167841722

Val Avg Loss  428: 0.180496

Val Avg F1  428:  0.6614320462146549

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 429
--------------------------------------------------------------
Epoch:  429        1 Batch loss: 0.191014 Batch F1: 0.4117647058823529
Epoch:  429        2 Batch loss: 0.166140 Batch F1: 0.7826086956521738
Epoch:  429        3 Batch loss: 0.175141 Batch F1: 0.693877551020408
Epoch:  429        4 Batch loss: 0.171663 Batch F1: 0.7083333333333333
Epoch:  429        5 Batch loss: 0.195019 Batch F1: 0.6046511627906977
Epoch:  429        6 Batch loss: 0.157201 Batch F1: 0.7755102040816326
Epoch:  429        7 Batch loss: 0.177977 Batch F1: 0.6511627906976744
Epoch:  429        8 Batch loss: 0.152406 Batch F1: 0.7804878048780488
Epoch:  429        9 Batch loss: 0.174656 Batch F1: 0.7234042553191491
Epoch:  429       10 Batch loss: 0.165385 Batch F1: 0.717948717948718
Epoch:  429       11 Batch loss: 0.158177 Batch F1: 0.8076923076923077
Epoch:  429       12 Batch loss: 0.136009 Batch F1: 0.823529411764706
Train Avg Loss  429: 0.168399

Train Avg F1  429: 0.7067475784217668

Val Avg Loss  429: 0.183035

Val Avg F1  429:  0.6802721088435374

Optimal Val loss (Epoch 311): 0.17990439012646675

Epoch 430
--------------------------------------------------------------
Epoch:  430        1 Batch loss: 0.157656 Batch F1: 0.8085106382978724
Epoch:  430        2 Batch loss: 0.177233 Batch F1: 0.711111111111111
Epoch:  430        3 Batch loss: 0.199063 Batch F1: 0.5581395348837209
Epoch:  430        4 Batch loss: 0.142499 Batch F1: 0.8571428571428572
Epoch:  430        5 Batch loss: 0.171432 Batch F1: 0.711111111111111
Epoch:  430        6 Batch loss: 0.155579 Batch F1: 0.717948717948718
Epoch:  430        7 Batch loss: 0.177817 Batch F1: 0.723404255319149
Epoch:  430        8 Batch loss: 0.155155 Batch F1: 0.7441860465116279
Epoch:  430        9 Batch loss: 0.175009 Batch F1: 0.6818181818181818
Epoch:  430       10 Batch loss: 0.165646 Batch F1: 0.7391304347826088
Epoch:  430       11 Batch loss: 0.179142 Batch F1: 0.6
Epoch:  430       12 Batch loss: 0.182322 Batch F1: 0.6486486486486486
Train Avg Loss  430: 0.169879

Train Avg F1  430: 0.7084292947979671

Val Avg Loss  430: 0.179773

Val Avg F1  430:  0.6764102564102564

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 431
--------------------------------------------------------------
Epoch:  431        1 Batch loss: 0.158536 Batch F1: 0.7027027027027027
Epoch:  431        2 Batch loss: 0.184905 Batch F1: 0.68
Epoch:  431        3 Batch loss: 0.194324 Batch F1: 0.5853658536585366
Epoch:  431        4 Batch loss: 0.168720 Batch F1: 0.6470588235294117
Epoch:  431        5 Batch loss: 0.154678 Batch F1: 0.830188679245283
Epoch:  431        6 Batch loss: 0.167446 Batch F1: 0.6829268292682926
Epoch:  431        7 Batch loss: 0.171756 Batch F1: 0.7346938775510204
Epoch:  431        8 Batch loss: 0.159742 Batch F1: 0.76
Epoch:  431        9 Batch loss: 0.176432 Batch F1: 0.6511627906976745
Epoch:  431       10 Batch loss: 0.154107 Batch F1: 0.7368421052631577
Epoch:  431       11 Batch loss: 0.183439 Batch F1: 0.7407407407407408
Epoch:  431       12 Batch loss: 0.163307 Batch F1: 0.7428571428571429
Train Avg Loss  431: 0.169783

Train Avg F1  431: 0.7078782954594969

Val Avg Loss  431: 0.181796

Val Avg F1  431:  0.6733045525902669

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 432
--------------------------------------------------------------
Epoch:  432        1 Batch loss: 0.184087 Batch F1: 0.6923076923076923
Epoch:  432        2 Batch loss: 0.171238 Batch F1: 0.7391304347826089
Epoch:  432        3 Batch loss: 0.170952 Batch F1: 0.6976744186046512
Epoch:  432        4 Batch loss: 0.161449 Batch F1: 0.7
Epoch:  432        5 Batch loss: 0.159975 Batch F1: 0.7692307692307692
Epoch:  432        6 Batch loss: 0.174078 Batch F1: 0.744186046511628
Epoch:  432        7 Batch loss: 0.173765 Batch F1: 0.6341463414634148
Epoch:  432        8 Batch loss: 0.151936 Batch F1: 0.7804878048780488
Epoch:  432        9 Batch loss: 0.173122 Batch F1: 0.711111111111111
Epoch:  432       10 Batch loss: 0.151717 Batch F1: 0.717948717948718
Epoch:  432       11 Batch loss: 0.195807 Batch F1: 0.55
Epoch:  432       12 Batch loss: 0.166299 Batch F1: 0.7906976744186046
Train Avg Loss  432: 0.169535

Train Avg F1  432: 0.7105767509381039

Val Avg Loss  432: 0.180224

Val Avg F1  432:  0.6753633271490415

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 433
--------------------------------------------------------------
Epoch:  433        1 Batch loss: 0.170338 Batch F1: 0.6285714285714286
Epoch:  433        2 Batch loss: 0.140893 Batch F1: 0.7906976744186046
Epoch:  433        3 Batch loss: 0.148704 Batch F1: 0.75
Epoch:  433        4 Batch loss: 0.167384 Batch F1: 0.7755102040816326
Epoch:  433        5 Batch loss: 0.171671 Batch F1: 0.6976744186046512
Epoch:  433        6 Batch loss: 0.166028 Batch F1: 0.6666666666666667
Epoch:  433        7 Batch loss: 0.197297 Batch F1: 0.6
Epoch:  433        8 Batch loss: 0.159840 Batch F1: 0.8275862068965518
Epoch:  433        9 Batch loss: 0.188261 Batch F1: 0.6938775510204083
Epoch:  433       10 Batch loss: 0.170592 Batch F1: 0.7111111111111111
Epoch:  433       11 Batch loss: 0.151790 Batch F1: 0.7499999999999999
Epoch:  433       12 Batch loss: 0.217398 Batch F1: 0.5909090909090909
Train Avg Loss  433: 0.170850

Train Avg F1  433: 0.7068836960233456

Val Avg Loss  433: 0.180363

Val Avg F1  433:  0.674738390123852

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 434
--------------------------------------------------------------
Epoch:  434        1 Batch loss: 0.187023 Batch F1: 0.6666666666666666
Epoch:  434        2 Batch loss: 0.172835 Batch F1: 0.711111111111111
Epoch:  434        3 Batch loss: 0.148720 Batch F1: 0.8076923076923077
Epoch:  434        4 Batch loss: 0.164673 Batch F1: 0.7500000000000001
Epoch:  434        5 Batch loss: 0.157441 Batch F1: 0.7555555555555555
Epoch:  434        6 Batch loss: 0.179524 Batch F1: 0.6511627906976744
Epoch:  434        7 Batch loss: 0.197801 Batch F1: 0.5641025641025641
Epoch:  434        8 Batch loss: 0.173546 Batch F1: 0.6818181818181818
Epoch:  434        9 Batch loss: 0.165227 Batch F1: 0.6486486486486486
Epoch:  434       10 Batch loss: 0.186052 Batch F1: 0.6808510638297872
Epoch:  434       11 Batch loss: 0.155047 Batch F1: 0.8333333333333333
Epoch:  434       12 Batch loss: 0.152344 Batch F1: 0.75
Train Avg Loss  434: 0.170019

Train Avg F1  434: 0.7084118519546525

Val Avg Loss  434: 0.186447

Val Avg F1  434:  0.6387278582930757

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 435
--------------------------------------------------------------
Epoch:  435        1 Batch loss: 0.184785 Batch F1: 0.5294117647058824
Epoch:  435        2 Batch loss: 0.187777 Batch F1: 0.6909090909090909
Epoch:  435        3 Batch loss: 0.177369 Batch F1: 0.6153846153846154
Epoch:  435        4 Batch loss: 0.180019 Batch F1: 0.65
Epoch:  435        5 Batch loss: 0.173219 Batch F1: 0.7272727272727272
Epoch:  435        6 Batch loss: 0.168075 Batch F1: 0.7857142857142857
Epoch:  435        7 Batch loss: 0.173612 Batch F1: 0.6818181818181818
Epoch:  435        8 Batch loss: 0.156443 Batch F1: 0.7755102040816326
Epoch:  435        9 Batch loss: 0.181052 Batch F1: 0.6486486486486486
Epoch:  435       10 Batch loss: 0.175119 Batch F1: 0.6818181818181819
Epoch:  435       11 Batch loss: 0.161131 Batch F1: 0.7843137254901961
Epoch:  435       12 Batch loss: 0.170999 Batch F1: 0.7500000000000001
Train Avg Loss  435: 0.174133

Train Avg F1  435: 0.6934001188202868

Val Avg Loss  435: 0.190133

Val Avg F1  435:  0.6403601565087922

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 436
--------------------------------------------------------------
Epoch:  436        1 Batch loss: 0.147214 Batch F1: 0.6486486486486486
Epoch:  436        2 Batch loss: 0.174840 Batch F1: 0.6956521739130435
Epoch:  436        3 Batch loss: 0.156775 Batch F1: 0.7692307692307692
Epoch:  436        4 Batch loss: 0.184447 Batch F1: 0.7241379310344827
Epoch:  436        5 Batch loss: 0.178688 Batch F1: 0.7037037037037037
Epoch:  436        6 Batch loss: 0.190093 Batch F1: 0.5365853658536586
Epoch:  436        7 Batch loss: 0.190244 Batch F1: 0.6530612244897959
Epoch:  436        8 Batch loss: 0.167550 Batch F1: 0.7441860465116279
Epoch:  436        9 Batch loss: 0.193824 Batch F1: 0.6382978723404256
Epoch:  436       10 Batch loss: 0.196187 Batch F1: 0.5263157894736842
Epoch:  436       11 Batch loss: 0.173968 Batch F1: 0.6829268292682926
Epoch:  436       12 Batch loss: 0.151458 Batch F1: 0.8292682926829269
Train Avg Loss  436: 0.175441

Train Avg F1  436: 0.6793345539292549

Val Avg Loss  436: 0.183094

Val Avg F1  436:  0.6679810081927507

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 437
--------------------------------------------------------------
Epoch:  437        1 Batch loss: 0.165679 Batch F1: 0.625
Epoch:  437        2 Batch loss: 0.183139 Batch F1: 0.5853658536585366
Epoch:  437        3 Batch loss: 0.150582 Batch F1: 0.7555555555555555
Epoch:  437        4 Batch loss: 0.183129 Batch F1: 0.711111111111111
Epoch:  437        5 Batch loss: 0.204731 Batch F1: 0.5128205128205129
Epoch:  437        6 Batch loss: 0.206002 Batch F1: 0.7142857142857142
Epoch:  437        7 Batch loss: 0.152803 Batch F1: 0.8679245283018868
Epoch:  437        8 Batch loss: 0.171271 Batch F1: 0.7111111111111111
Epoch:  437        9 Batch loss: 0.156985 Batch F1: 0.7441860465116279
Epoch:  437       10 Batch loss: 0.181175 Batch F1: 0.6363636363636365
Epoch:  437       11 Batch loss: 0.144282 Batch F1: 0.8085106382978724
Epoch:  437       12 Batch loss: 0.190495 Batch F1: 0.6829268292682926
Train Avg Loss  437: 0.174189

Train Avg F1  437: 0.6962634614404881

Val Avg Loss  437: 0.182928

Val Avg F1  437:  0.6743336450783259

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 438
--------------------------------------------------------------
Epoch:  438        1 Batch loss: 0.184052 Batch F1: 0.7083333333333334
Epoch:  438        2 Batch loss: 0.168903 Batch F1: 0.723404255319149
Epoch:  438        3 Batch loss: 0.188763 Batch F1: 0.6818181818181818
Epoch:  438        4 Batch loss: 0.175101 Batch F1: 0.7450980392156864
Epoch:  438        5 Batch loss: 0.164710 Batch F1: 0.7555555555555555
Epoch:  438        6 Batch loss: 0.177783 Batch F1: 0.6521739130434783
Epoch:  438        7 Batch loss: 0.195311 Batch F1: 0.5853658536585366
Epoch:  438        8 Batch loss: 0.168001 Batch F1: 0.7
Epoch:  438        9 Batch loss: 0.186756 Batch F1: 0.6
Epoch:  438       10 Batch loss: 0.162422 Batch F1: 0.7317073170731706
Epoch:  438       11 Batch loss: 0.128258 Batch F1: 0.8780487804878049
Epoch:  438       12 Batch loss: 0.161807 Batch F1: 0.7804878048780488
Train Avg Loss  438: 0.171822

Train Avg F1  438: 0.7118327528652454

Val Avg Loss  438: 0.183889

Val Avg F1  438:  0.658263551120694

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 439
--------------------------------------------------------------
Epoch:  439        1 Batch loss: 0.180580 Batch F1: 0.72
Epoch:  439        2 Batch loss: 0.180706 Batch F1: 0.6818181818181819
Epoch:  439        3 Batch loss: 0.168673 Batch F1: 0.65
Epoch:  439        4 Batch loss: 0.192582 Batch F1: 0.6808510638297872
Epoch:  439        5 Batch loss: 0.160240 Batch F1: 0.7567567567567567
Epoch:  439        6 Batch loss: 0.190711 Batch F1: 0.6521739130434783
Epoch:  439        7 Batch loss: 0.165821 Batch F1: 0.6842105263157895
Epoch:  439        8 Batch loss: 0.167413 Batch F1: 0.7346938775510204
Epoch:  439        9 Batch loss: 0.173007 Batch F1: 0.8260869565217392
Epoch:  439       10 Batch loss: 0.229104 Batch F1: 0.6530612244897959
Epoch:  439       11 Batch loss: 0.161861 Batch F1: 0.7843137254901961
Epoch:  439       12 Batch loss: 0.160866 Batch F1: 0.8292682926829269
Train Avg Loss  439: 0.177630

Train Avg F1  439: 0.7211028765416393

Val Avg Loss  439: 0.184404

Val Avg F1  439:  0.6780898208339939

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 440
--------------------------------------------------------------
Epoch:  440        1 Batch loss: 0.168201 Batch F1: 0.7555555555555556
Epoch:  440        2 Batch loss: 0.191486 Batch F1: 0.64
Epoch:  440        3 Batch loss: 0.196770 Batch F1: 0.7555555555555556
Epoch:  440        4 Batch loss: 0.152761 Batch F1: 0.8085106382978723
Epoch:  440        5 Batch loss: 0.179955 Batch F1: 0.7058823529411765
Epoch:  440        6 Batch loss: 0.212150 Batch F1: 0.689655172413793
Epoch:  440        7 Batch loss: 0.165239 Batch F1: 0.6842105263157895
Epoch:  440        8 Batch loss: 0.131572 Batch F1: 0.7499999999999999
Epoch:  440        9 Batch loss: 0.174682 Batch F1: 0.7346938775510204
Epoch:  440       10 Batch loss: 0.182838 Batch F1: 0.6111111111111112
Epoch:  440       11 Batch loss: 0.159110 Batch F1: 0.7555555555555555
Epoch:  440       12 Batch loss: 0.179303 Batch F1: 0.6666666666666666
Train Avg Loss  440: 0.174506

Train Avg F1  440: 0.7131164176636747

Val Avg Loss  440: 0.183824

Val Avg F1  440:  0.6726325757575758

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 441
--------------------------------------------------------------
Epoch:  441        1 Batch loss: 0.148314 Batch F1: 0.7500000000000001
Epoch:  441        2 Batch loss: 0.187725 Batch F1: 0.6818181818181819
Epoch:  441        3 Batch loss: 0.202471 Batch F1: 0.608695652173913
Epoch:  441        4 Batch loss: 0.164377 Batch F1: 0.7368421052631577
Epoch:  441        5 Batch loss: 0.170010 Batch F1: 0.7272727272727272
Epoch:  441        6 Batch loss: 0.177775 Batch F1: 0.7857142857142856
Epoch:  441        7 Batch loss: 0.182216 Batch F1: 0.7391304347826088
Epoch:  441        8 Batch loss: 0.174721 Batch F1: 0.6956521739130435
Epoch:  441        9 Batch loss: 0.169272 Batch F1: 0.631578947368421
Epoch:  441       10 Batch loss: 0.158191 Batch F1: 0.8
Epoch:  441       11 Batch loss: 0.173811 Batch F1: 0.6486486486486486
Epoch:  441       12 Batch loss: 0.189008 Batch F1: 0.7
Train Avg Loss  441: 0.174824

Train Avg F1  441: 0.708779429746249

Val Avg Loss  441: 0.181877

Val Avg F1  441:  0.6705672532998115

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 442
--------------------------------------------------------------
Epoch:  442        1 Batch loss: 0.186290 Batch F1: 0.6511627906976744
Epoch:  442        2 Batch loss: 0.169088 Batch F1: 0.7659574468085107
Epoch:  442        3 Batch loss: 0.162692 Batch F1: 0.76
Epoch:  442        4 Batch loss: 0.180976 Batch F1: 0.6511627906976744
Epoch:  442        5 Batch loss: 0.182063 Batch F1: 0.6666666666666665
Epoch:  442        6 Batch loss: 0.169308 Batch F1: 0.7659574468085106
Epoch:  442        7 Batch loss: 0.174514 Batch F1: 0.6111111111111112
Epoch:  442        8 Batch loss: 0.168002 Batch F1: 0.7142857142857143
Epoch:  442        9 Batch loss: 0.178328 Batch F1: 0.7272727272727273
Epoch:  442       10 Batch loss: 0.133752 Batch F1: 0.8695652173913043
Epoch:  442       11 Batch loss: 0.168334 Batch F1: 0.6956521739130435
Epoch:  442       12 Batch loss: 0.169695 Batch F1: 0.6111111111111112
Train Avg Loss  442: 0.170253

Train Avg F1  442: 0.7074920997303372

Val Avg Loss  442: 0.184656

Val Avg F1  442:  0.6814989517819706

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 443
--------------------------------------------------------------
Epoch:  443        1 Batch loss: 0.168915 Batch F1: 0.782608695652174
Epoch:  443        2 Batch loss: 0.176154 Batch F1: 0.7555555555555555
Epoch:  443        3 Batch loss: 0.202042 Batch F1: 0.5555555555555556
Epoch:  443        4 Batch loss: 0.159887 Batch F1: 0.6486486486486486
Epoch:  443        5 Batch loss: 0.171279 Batch F1: 0.7659574468085107
Epoch:  443        6 Batch loss: 0.171576 Batch F1: 0.7499999999999999
Epoch:  443        7 Batch loss: 0.175625 Batch F1: 0.7391304347826089
Epoch:  443        8 Batch loss: 0.171981 Batch F1: 0.7924528301886792
Epoch:  443        9 Batch loss: 0.227031 Batch F1: 0.576923076923077
Epoch:  443       10 Batch loss: 0.139476 Batch F1: 0.7999999999999999
Epoch:  443       11 Batch loss: 0.150794 Batch F1: 0.7391304347826088
Epoch:  443       12 Batch loss: 0.183248 Batch F1: 0.6285714285714286
Train Avg Loss  443: 0.174834

Train Avg F1  443: 0.7112111756224038

Val Avg Loss  443: 0.184564

Val Avg F1  443:  0.6586144555741513

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 444
--------------------------------------------------------------
Epoch:  444        1 Batch loss: 0.143027 Batch F1: 0.7727272727272727
Epoch:  444        2 Batch loss: 0.185469 Batch F1: 0.6086956521739131
Epoch:  444        3 Batch loss: 0.161590 Batch F1: 0.7659574468085107
Epoch:  444        4 Batch loss: 0.199987 Batch F1: 0.7037037037037038
Epoch:  444        5 Batch loss: 0.157873 Batch F1: 0.761904761904762
Epoch:  444        6 Batch loss: 0.159337 Batch F1: 0.7555555555555556
Epoch:  444        7 Batch loss: 0.175255 Batch F1: 0.711111111111111
Epoch:  444        8 Batch loss: 0.148181 Batch F1: 0.8
Epoch:  444        9 Batch loss: 0.214680 Batch F1: 0.4736842105263158
Epoch:  444       10 Batch loss: 0.185980 Batch F1: 0.6341463414634146
Epoch:  444       11 Batch loss: 0.180891 Batch F1: 0.7346938775510204
Epoch:  444       12 Batch loss: 0.154723 Batch F1: 0.7777777777777778
Train Avg Loss  444: 0.172249

Train Avg F1  444: 0.7083298092752798

Val Avg Loss  444: 0.183139

Val Avg F1  444:  0.6726970458525477

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 445
--------------------------------------------------------------
Epoch:  445        1 Batch loss: 0.150243 Batch F1: 0.8085106382978724
Epoch:  445        2 Batch loss: 0.174941 Batch F1: 0.7457627118644068
Epoch:  445        3 Batch loss: 0.157851 Batch F1: 0.8571428571428571
Epoch:  445        4 Batch loss: 0.153420 Batch F1: 0.8085106382978724
Epoch:  445        5 Batch loss: 0.202310 Batch F1: 0.5581395348837209
Epoch:  445        6 Batch loss: 0.177587 Batch F1: 0.6521739130434783
Epoch:  445        7 Batch loss: 0.184250 Batch F1: 0.7499999999999999
Epoch:  445        8 Batch loss: 0.182699 Batch F1: 0.5882352941176471
Epoch:  445        9 Batch loss: 0.222158 Batch F1: 0.5238095238095238
Epoch:  445       10 Batch loss: 0.147461 Batch F1: 0.830188679245283
Epoch:  445       11 Batch loss: 0.197849 Batch F1: 0.7000000000000001
Epoch:  445       12 Batch loss: 0.180565 Batch F1: 0.7027027027027027
Train Avg Loss  445: 0.177611

Train Avg F1  445: 0.710431374450447

Val Avg Loss  445: 0.182164

Val Avg F1  445:  0.6754875283446712

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 446
--------------------------------------------------------------
Epoch:  446        1 Batch loss: 0.170285 Batch F1: 0.6451612903225806
Epoch:  446        2 Batch loss: 0.174757 Batch F1: 0.7346938775510203
Epoch:  446        3 Batch loss: 0.183044 Batch F1: 0.631578947368421
Epoch:  446        4 Batch loss: 0.151764 Batch F1: 0.8181818181818182
Epoch:  446        5 Batch loss: 0.206172 Batch F1: 0.5714285714285713
Epoch:  446        6 Batch loss: 0.188316 Batch F1: 0.7169811320754716
Epoch:  446        7 Batch loss: 0.159459 Batch F1: 0.8076923076923077
Epoch:  446        8 Batch loss: 0.177328 Batch F1: 0.6808510638297872
Epoch:  446        9 Batch loss: 0.148842 Batch F1: 0.7368421052631577
Epoch:  446       10 Batch loss: 0.173817 Batch F1: 0.7450980392156863
Epoch:  446       11 Batch loss: 0.168561 Batch F1: 0.7317073170731706
Epoch:  446       12 Batch loss: 0.203154 Batch F1: 0.5945945945945946
Train Avg Loss  446: 0.175458

Train Avg F1  446: 0.7012342553830488

Val Avg Loss  446: 0.184075

Val Avg F1  446:  0.6797826086956521

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 447
--------------------------------------------------------------
Epoch:  447        1 Batch loss: 0.159988 Batch F1: 0.782608695652174
Epoch:  447        2 Batch loss: 0.174292 Batch F1: 0.6666666666666667
Epoch:  447        3 Batch loss: 0.180406 Batch F1: 0.7407407407407408
Epoch:  447        4 Batch loss: 0.194064 Batch F1: 0.6808510638297872
Epoch:  447        5 Batch loss: 0.174464 Batch F1: 0.6470588235294117
Epoch:  447        6 Batch loss: 0.179287 Batch F1: 0.7083333333333334
Epoch:  447        7 Batch loss: 0.130565 Batch F1: 0.8333333333333334
Epoch:  447        8 Batch loss: 0.188410 Batch F1: 0.6382978723404256
Epoch:  447        9 Batch loss: 0.176733 Batch F1: 0.6818181818181819
Epoch:  447       10 Batch loss: 0.137158 Batch F1: 0.8750000000000001
Epoch:  447       11 Batch loss: 0.174760 Batch F1: 0.6666666666666666
Epoch:  447       12 Batch loss: 0.191285 Batch F1: 0.6111111111111113
Train Avg Loss  447: 0.171785

Train Avg F1  447: 0.7110405407518193

Val Avg Loss  447: 0.182749

Val Avg F1  447:  0.6765660921839411

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 448
--------------------------------------------------------------
Epoch:  448        1 Batch loss: 0.202475 Batch F1: 0.6222222222222223
Epoch:  448        2 Batch loss: 0.192992 Batch F1: 0.6222222222222222
Epoch:  448        3 Batch loss: 0.167621 Batch F1: 0.7450980392156863
Epoch:  448        4 Batch loss: 0.158888 Batch F1: 0.6842105263157896
Epoch:  448        5 Batch loss: 0.171857 Batch F1: 0.7272727272727273
Epoch:  448        6 Batch loss: 0.177989 Batch F1: 0.65
Epoch:  448        7 Batch loss: 0.160289 Batch F1: 0.8214285714285715
Epoch:  448        8 Batch loss: 0.133525 Batch F1: 0.8648648648648649
Epoch:  448        9 Batch loss: 0.150815 Batch F1: 0.7727272727272727
Epoch:  448       10 Batch loss: 0.150733 Batch F1: 0.8095238095238095
Epoch:  448       11 Batch loss: 0.184465 Batch F1: 0.6046511627906976
Epoch:  448       12 Batch loss: 0.212733 Batch F1: 0.6
Train Avg Loss  448: 0.172032

Train Avg F1  448: 0.7103517848819886

Val Avg Loss  448: 0.181380

Val Avg F1  448:  0.6710789210789211

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 449
--------------------------------------------------------------
Epoch:  449        1 Batch loss: 0.167187 Batch F1: 0.7142857142857143
Epoch:  449        2 Batch loss: 0.174396 Batch F1: 0.6842105263157895
Epoch:  449        3 Batch loss: 0.204327 Batch F1: 0.6122448979591837
Epoch:  449        4 Batch loss: 0.140514 Batch F1: 0.742857142857143
Epoch:  449        5 Batch loss: 0.182811 Batch F1: 0.7307692307692308
Epoch:  449        6 Batch loss: 0.161565 Batch F1: 0.6285714285714286
Epoch:  449        7 Batch loss: 0.150475 Batch F1: 0.8181818181818182
Epoch:  449        8 Batch loss: 0.150168 Batch F1: 0.8235294117647058
Epoch:  449        9 Batch loss: 0.181225 Batch F1: 0.6666666666666666
Epoch:  449       10 Batch loss: 0.163624 Batch F1: 0.7272727272727272
Epoch:  449       11 Batch loss: 0.202547 Batch F1: 0.6222222222222222
Epoch:  449       12 Batch loss: 0.203676 Batch F1: 0.65
Train Avg Loss  449: 0.173543

Train Avg F1  449: 0.7017343155722192

Val Avg Loss  449: 0.185109

Val Avg F1  449:  0.6744378306878307

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 450
--------------------------------------------------------------
Epoch:  450        1 Batch loss: 0.173135 Batch F1: 0.6976744186046512
Epoch:  450        2 Batch loss: 0.151399 Batch F1: 0.816326530612245
Epoch:  450        3 Batch loss: 0.168922 Batch F1: 0.6111111111111112
Epoch:  450        4 Batch loss: 0.177208 Batch F1: 0.6511627906976744
Epoch:  450        5 Batch loss: 0.182344 Batch F1: 0.7307692307692308
Epoch:  450        6 Batch loss: 0.190053 Batch F1: 0.6538461538461539
Epoch:  450        7 Batch loss: 0.193550 Batch F1: 0.6666666666666666
Epoch:  450        8 Batch loss: 0.149099 Batch F1: 0.6666666666666667
Epoch:  450        9 Batch loss: 0.184020 Batch F1: 0.619047619047619
Epoch:  450       10 Batch loss: 0.157192 Batch F1: 0.8666666666666666
Epoch:  450       11 Batch loss: 0.162850 Batch F1: 0.717948717948718
Epoch:  450       12 Batch loss: 0.178886 Batch F1: 0.6857142857142857
Train Avg Loss  450: 0.172388

Train Avg F1  450: 0.6986334048626407

Val Avg Loss  450: 0.181036

Val Avg F1  450:  0.680024685459468

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 451
--------------------------------------------------------------
Epoch:  451        1 Batch loss: 0.169495 Batch F1: 0.6666666666666666
Epoch:  451        2 Batch loss: 0.210789 Batch F1: 0.6122448979591836
Epoch:  451        3 Batch loss: 0.173685 Batch F1: 0.7272727272727272
Epoch:  451        4 Batch loss: 0.173208 Batch F1: 0.76
Epoch:  451        5 Batch loss: 0.147259 Batch F1: 0.830188679245283
Epoch:  451        6 Batch loss: 0.207716 Batch F1: 0.625
Epoch:  451        7 Batch loss: 0.163472 Batch F1: 0.7272727272727272
Epoch:  451        8 Batch loss: 0.150363 Batch F1: 0.7368421052631577
Epoch:  451        9 Batch loss: 0.189751 Batch F1: 0.5294117647058824
Epoch:  451       10 Batch loss: 0.148776 Batch F1: 0.8181818181818182
Epoch:  451       11 Batch loss: 0.161449 Batch F1: 0.7555555555555555
Epoch:  451       12 Batch loss: 0.153372 Batch F1: 0.7096774193548386
Train Avg Loss  451: 0.170778

Train Avg F1  451: 0.7081928634564867

Val Avg Loss  451: 0.184248

Val Avg F1  451:  0.6790939293264875

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 452
--------------------------------------------------------------
Epoch:  452        1 Batch loss: 0.150888 Batch F1: 0.823529411764706
Epoch:  452        2 Batch loss: 0.154887 Batch F1: 0.823529411764706
Epoch:  452        3 Batch loss: 0.167476 Batch F1: 0.6842105263157895
Epoch:  452        4 Batch loss: 0.185640 Batch F1: 0.6341463414634146
Epoch:  452        5 Batch loss: 0.158355 Batch F1: 0.7142857142857143
Epoch:  452        6 Batch loss: 0.184850 Batch F1: 0.6046511627906976
Epoch:  452        7 Batch loss: 0.157927 Batch F1: 0.8214285714285714
Epoch:  452        8 Batch loss: 0.199657 Batch F1: 0.6382978723404256
Epoch:  452        9 Batch loss: 0.189609 Batch F1: 0.6808510638297872
Epoch:  452       10 Batch loss: 0.157723 Batch F1: 0.6842105263157895
Epoch:  452       11 Batch loss: 0.171489 Batch F1: 0.6829268292682926
Epoch:  452       12 Batch loss: 0.163268 Batch F1: 0.6666666666666666
Train Avg Loss  452: 0.170147

Train Avg F1  452: 0.7048945081862134

Val Avg Loss  452: 0.181235

Val Avg F1  452:  0.6774482401656315

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 453
--------------------------------------------------------------
Epoch:  453        1 Batch loss: 0.136566 Batch F1: 0.8888888888888888
Epoch:  453        2 Batch loss: 0.169108 Batch F1: 0.6818181818181818
Epoch:  453        3 Batch loss: 0.168456 Batch F1: 0.7142857142857143
Epoch:  453        4 Batch loss: 0.199898 Batch F1: 0.6382978723404256
Epoch:  453        5 Batch loss: 0.181713 Batch F1: 0.6500000000000001
Epoch:  453        6 Batch loss: 0.172284 Batch F1: 0.5945945945945946
Epoch:  453        7 Batch loss: 0.149894 Batch F1: 0.7368421052631579
Epoch:  453        8 Batch loss: 0.183231 Batch F1: 0.72
Epoch:  453        9 Batch loss: 0.156013 Batch F1: 0.7916666666666667
Epoch:  453       10 Batch loss: 0.191107 Batch F1: 0.6
Epoch:  453       11 Batch loss: 0.151296 Batch F1: 0.744186046511628
Epoch:  453       12 Batch loss: 0.171457 Batch F1: 0.7317073170731707
Train Avg Loss  453: 0.169252

Train Avg F1  453: 0.7076906156202024

Val Avg Loss  453: 0.181738

Val Avg F1  453:  0.6694849984323669

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 454
--------------------------------------------------------------
Epoch:  454        1 Batch loss: 0.186300 Batch F1: 0.693877551020408
Epoch:  454        2 Batch loss: 0.188007 Batch F1: 0.7058823529411765
Epoch:  454        3 Batch loss: 0.149100 Batch F1: 0.7142857142857142
Epoch:  454        4 Batch loss: 0.156301 Batch F1: 0.7826086956521738
Epoch:  454        5 Batch loss: 0.161149 Batch F1: 0.7317073170731708
Epoch:  454        6 Batch loss: 0.183635 Batch F1: 0.7407407407407408
Epoch:  454        7 Batch loss: 0.199696 Batch F1: 0.6792452830188679
Epoch:  454        8 Batch loss: 0.188131 Batch F1: 0.6511627906976744
Epoch:  454        9 Batch loss: 0.163334 Batch F1: 0.7142857142857143
Epoch:  454       10 Batch loss: 0.170130 Batch F1: 0.76
Epoch:  454       11 Batch loss: 0.149192 Batch F1: 0.7499999999999999
Epoch:  454       12 Batch loss: 0.171678 Batch F1: 0.5925925925925927
Train Avg Loss  454: 0.172221

Train Avg F1  454: 0.7096990626923528

Val Avg Loss  454: 0.183692

Val Avg F1  454:  0.6736847520712919

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 455
--------------------------------------------------------------
Epoch:  455        1 Batch loss: 0.187543 Batch F1: 0.6046511627906976
Epoch:  455        2 Batch loss: 0.200937 Batch F1: 0.47058823529411764
Epoch:  455        3 Batch loss: 0.157138 Batch F1: 0.7441860465116279
Epoch:  455        4 Batch loss: 0.184604 Batch F1: 0.7636363636363636
Epoch:  455        5 Batch loss: 0.168261 Batch F1: 0.7272727272727272
Epoch:  455        6 Batch loss: 0.173114 Batch F1: 0.6666666666666666
Epoch:  455        7 Batch loss: 0.175726 Batch F1: 0.6818181818181819
Epoch:  455        8 Batch loss: 0.164996 Batch F1: 0.7999999999999999
Epoch:  455        9 Batch loss: 0.165012 Batch F1: 0.631578947368421
Epoch:  455       10 Batch loss: 0.168498 Batch F1: 0.8000000000000002
Epoch:  455       11 Batch loss: 0.137614 Batch F1: 0.7999999999999999
Epoch:  455       12 Batch loss: 0.154081 Batch F1: 0.7500000000000001
Train Avg Loss  455: 0.169794

Train Avg F1  455: 0.7033665276132336

Val Avg Loss  455: 0.181402

Val Avg F1  455:  0.675542223321788

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 456
--------------------------------------------------------------
Epoch:  456        1 Batch loss: 0.162991 Batch F1: 0.7346938775510203
Epoch:  456        2 Batch loss: 0.158600 Batch F1: 0.8275862068965518
Epoch:  456        3 Batch loss: 0.163693 Batch F1: 0.6976744186046512
Epoch:  456        4 Batch loss: 0.170798 Batch F1: 0.7441860465116279
Epoch:  456        5 Batch loss: 0.186869 Batch F1: 0.7450980392156864
Epoch:  456        6 Batch loss: 0.183011 Batch F1: 0.619047619047619
Epoch:  456        7 Batch loss: 0.161510 Batch F1: 0.7111111111111111
Epoch:  456        8 Batch loss: 0.157150 Batch F1: 0.6842105263157896
Epoch:  456        9 Batch loss: 0.170636 Batch F1: 0.7
Epoch:  456       10 Batch loss: 0.193416 Batch F1: 0.6
Epoch:  456       11 Batch loss: 0.180222 Batch F1: 0.6666666666666666
Epoch:  456       12 Batch loss: 0.144701 Batch F1: 0.7741935483870969
Train Avg Loss  456: 0.169466

Train Avg F1  456: 0.7087056716923184

Val Avg Loss  456: 0.180601

Val Avg F1  456:  0.6625234521575986

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 457
--------------------------------------------------------------
Epoch:  457        1 Batch loss: 0.175824 Batch F1: 0.631578947368421
Epoch:  457        2 Batch loss: 0.150092 Batch F1: 0.7804878048780488
Epoch:  457        3 Batch loss: 0.155496 Batch F1: 0.7317073170731708
Epoch:  457        4 Batch loss: 0.160326 Batch F1: 0.7142857142857143
Epoch:  457        5 Batch loss: 0.176609 Batch F1: 0.711111111111111
Epoch:  457        6 Batch loss: 0.173029 Batch F1: 0.7083333333333334
Epoch:  457        7 Batch loss: 0.162274 Batch F1: 0.7555555555555555
Epoch:  457        8 Batch loss: 0.195133 Batch F1: 0.7037037037037038
Epoch:  457        9 Batch loss: 0.147691 Batch F1: 0.7999999999999999
Epoch:  457       10 Batch loss: 0.156706 Batch F1: 0.7317073170731706
Epoch:  457       11 Batch loss: 0.206967 Batch F1: 0.5333333333333332
Epoch:  457       12 Batch loss: 0.170563 Batch F1: 0.7499999999999999
Train Avg Loss  457: 0.169226

Train Avg F1  457: 0.7126503448096302

Val Avg Loss  457: 0.181580

Val Avg F1  457:  0.6769543258673694

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 458
--------------------------------------------------------------
Epoch:  458        1 Batch loss: 0.171758 Batch F1: 0.723404255319149
Epoch:  458        2 Batch loss: 0.161973 Batch F1: 0.6976744186046512
Epoch:  458        3 Batch loss: 0.168935 Batch F1: 0.8
Epoch:  458        4 Batch loss: 0.183965 Batch F1: 0.7241379310344829
Epoch:  458        5 Batch loss: 0.157702 Batch F1: 0.7826086956521738
Epoch:  458        6 Batch loss: 0.155471 Batch F1: 0.7000000000000001
Epoch:  458        7 Batch loss: 0.160956 Batch F1: 0.7428571428571429
Epoch:  458        8 Batch loss: 0.184242 Batch F1: 0.6363636363636365
Epoch:  458        9 Batch loss: 0.176814 Batch F1: 0.6976744186046512
Epoch:  458       10 Batch loss: 0.173248 Batch F1: 0.6666666666666666
Epoch:  458       11 Batch loss: 0.156414 Batch F1: 0.6470588235294118
Epoch:  458       12 Batch loss: 0.174593 Batch F1: 0.6842105263157895
Train Avg Loss  458: 0.168839

Train Avg F1  458: 0.7085547095789798

Val Avg Loss  458: 0.183420

Val Avg F1  458:  0.6712714523773454

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 459
--------------------------------------------------------------
Epoch:  459        1 Batch loss: 0.147809 Batch F1: 0.7999999999999999
Epoch:  459        2 Batch loss: 0.154801 Batch F1: 0.7727272727272727
Epoch:  459        3 Batch loss: 0.182576 Batch F1: 0.6341463414634148
Epoch:  459        4 Batch loss: 0.168425 Batch F1: 0.7547169811320754
Epoch:  459        5 Batch loss: 0.191551 Batch F1: 0.6190476190476191
Epoch:  459        6 Batch loss: 0.141604 Batch F1: 0.8163265306122449
Epoch:  459        7 Batch loss: 0.164774 Batch F1: 0.7142857142857143
Epoch:  459        8 Batch loss: 0.178905 Batch F1: 0.7027027027027026
Epoch:  459        9 Batch loss: 0.155480 Batch F1: 0.7
Epoch:  459       10 Batch loss: 0.196050 Batch F1: 0.6190476190476191
Epoch:  459       11 Batch loss: 0.179607 Batch F1: 0.7407407407407408
Epoch:  459       12 Batch loss: 0.166727 Batch F1: 0.7499999999999999
Train Avg Loss  459: 0.169026

Train Avg F1  459: 0.7186451268132837

Val Avg Loss  459: 0.181165

Val Avg F1  459:  0.6741136222268298

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 460
--------------------------------------------------------------
Epoch:  460        1 Batch loss: 0.145971 Batch F1: 0.8333333333333334
Epoch:  460        2 Batch loss: 0.154509 Batch F1: 0.8076923076923077
Epoch:  460        3 Batch loss: 0.193547 Batch F1: 0.6666666666666666
Epoch:  460        4 Batch loss: 0.163663 Batch F1: 0.6666666666666667
Epoch:  460        5 Batch loss: 0.176654 Batch F1: 0.6341463414634148
Epoch:  460        6 Batch loss: 0.187534 Batch F1: 0.6923076923076923
Epoch:  460        7 Batch loss: 0.154389 Batch F1: 0.7826086956521738
Epoch:  460        8 Batch loss: 0.176518 Batch F1: 0.72
Epoch:  460        9 Batch loss: 0.174819 Batch F1: 0.65
Epoch:  460       10 Batch loss: 0.144692 Batch F1: 0.7692307692307692
Epoch:  460       11 Batch loss: 0.159348 Batch F1: 0.6666666666666667
Epoch:  460       12 Batch loss: 0.198782 Batch F1: 0.6
Train Avg Loss  460: 0.169202

Train Avg F1  460: 0.7074432616399743

Val Avg Loss  460: 0.183179

Val Avg F1  460:  0.6727462154328739

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 461
--------------------------------------------------------------
Epoch:  461        1 Batch loss: 0.158754 Batch F1: 0.744186046511628
Epoch:  461        2 Batch loss: 0.154914 Batch F1: 0.8076923076923077
Epoch:  461        3 Batch loss: 0.134792 Batch F1: 0.8108108108108109
Epoch:  461        4 Batch loss: 0.174204 Batch F1: 0.6153846153846153
Epoch:  461        5 Batch loss: 0.172606 Batch F1: 0.5882352941176471
Epoch:  461        6 Batch loss: 0.146410 Batch F1: 0.8510638297872342
Epoch:  461        7 Batch loss: 0.180553 Batch F1: 0.6666666666666667
Epoch:  461        8 Batch loss: 0.223676 Batch F1: 0.5128205128205129
Epoch:  461        9 Batch loss: 0.191268 Batch F1: 0.7636363636363636
Epoch:  461       10 Batch loss: 0.161468 Batch F1: 0.6486486486486486
Epoch:  461       11 Batch loss: 0.153182 Batch F1: 0.8076923076923076
Epoch:  461       12 Batch loss: 0.196988 Batch F1: 0.6666666666666666
Train Avg Loss  461: 0.170735

Train Avg F1  461: 0.7069586725362841

Val Avg Loss  461: 0.183392

Val Avg F1  461:  0.6777777777777778

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 462
--------------------------------------------------------------
Epoch:  462        1 Batch loss: 0.160433 Batch F1: 0.7659574468085106
Epoch:  462        2 Batch loss: 0.194435 Batch F1: 0.6818181818181818
Epoch:  462        3 Batch loss: 0.171033 Batch F1: 0.7083333333333333
Epoch:  462        4 Batch loss: 0.174930 Batch F1: 0.6956521739130435
Epoch:  462        5 Batch loss: 0.191495 Batch F1: 0.6315789473684211
Epoch:  462        6 Batch loss: 0.175431 Batch F1: 0.7555555555555556
Epoch:  462        7 Batch loss: 0.146323 Batch F1: 0.7058823529411765
Epoch:  462        8 Batch loss: 0.184298 Batch F1: 0.65
Epoch:  462        9 Batch loss: 0.159988 Batch F1: 0.7111111111111111
Epoch:  462       10 Batch loss: 0.163728 Batch F1: 0.7391304347826088
Epoch:  462       11 Batch loss: 0.168162 Batch F1: 0.693877551020408
Epoch:  462       12 Batch loss: 0.175617 Batch F1: 0.7906976744186046
Train Avg Loss  462: 0.172156

Train Avg F1  462: 0.7107995635892462

Val Avg Loss  462: 0.183307

Val Avg F1  462:  0.6759049773755657

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 463
--------------------------------------------------------------
Epoch:  463        1 Batch loss: 0.130672 Batch F1: 0.7741935483870969
Epoch:  463        2 Batch loss: 0.179616 Batch F1: 0.7199999999999999
Epoch:  463        3 Batch loss: 0.168050 Batch F1: 0.7391304347826088
Epoch:  463        4 Batch loss: 0.172959 Batch F1: 0.65
Epoch:  463        5 Batch loss: 0.158785 Batch F1: 0.7826086956521738
Epoch:  463        6 Batch loss: 0.213851 Batch F1: 0.6037735849056604
Epoch:  463        7 Batch loss: 0.189076 Batch F1: 0.6341463414634148
Epoch:  463        8 Batch loss: 0.157639 Batch F1: 0.7843137254901961
Epoch:  463        9 Batch loss: 0.148355 Batch F1: 0.7999999999999999
Epoch:  463       10 Batch loss: 0.199154 Batch F1: 0.693877551020408
Epoch:  463       11 Batch loss: 0.165947 Batch F1: 0.7142857142857143
Epoch:  463       12 Batch loss: 0.177038 Batch F1: 0.6451612903225806
Train Avg Loss  463: 0.171762

Train Avg F1  463: 0.7117909071924878

Val Avg Loss  463: 0.181798

Val Avg F1  463:  0.6702175052410901

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 464
--------------------------------------------------------------
Epoch:  464        1 Batch loss: 0.148945 Batch F1: 0.7027027027027027
Epoch:  464        2 Batch loss: 0.136301 Batch F1: 0.8372093023255814
Epoch:  464        3 Batch loss: 0.167305 Batch F1: 0.8076923076923077
Epoch:  464        4 Batch loss: 0.166194 Batch F1: 0.75
Epoch:  464        5 Batch loss: 0.193121 Batch F1: 0.6511627906976744
Epoch:  464        6 Batch loss: 0.141829 Batch F1: 0.7906976744186046
Epoch:  464        7 Batch loss: 0.220309 Batch F1: 0.5714285714285714
Epoch:  464        8 Batch loss: 0.137136 Batch F1: 0.8085106382978724
Epoch:  464        9 Batch loss: 0.197888 Batch F1: 0.5909090909090909
Epoch:  464       10 Batch loss: 0.174419 Batch F1: 0.6818181818181818
Epoch:  464       11 Batch loss: 0.181350 Batch F1: 0.6086956521739131
Epoch:  464       12 Batch loss: 0.202163 Batch F1: 0.6111111111111113
Train Avg Loss  464: 0.172247

Train Avg F1  464: 0.7009948352979677

Val Avg Loss  464: 0.184482

Val Avg F1  464:  0.6712579632696272

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 465
--------------------------------------------------------------
Epoch:  465        1 Batch loss: 0.161637 Batch F1: 0.7659574468085107
Epoch:  465        2 Batch loss: 0.144905 Batch F1: 0.8372093023255814
Epoch:  465        3 Batch loss: 0.156147 Batch F1: 0.7027027027027027
Epoch:  465        4 Batch loss: 0.179684 Batch F1: 0.6500000000000001
Epoch:  465        5 Batch loss: 0.187854 Batch F1: 0.6511627906976744
Epoch:  465        6 Batch loss: 0.170721 Batch F1: 0.6153846153846154
Epoch:  465        7 Batch loss: 0.165096 Batch F1: 0.7843137254901961
Epoch:  465        8 Batch loss: 0.185461 Batch F1: 0.6909090909090909
Epoch:  465        9 Batch loss: 0.178663 Batch F1: 0.7096774193548386
Epoch:  465       10 Batch loss: 0.193266 Batch F1: 0.6857142857142857
Epoch:  465       11 Batch loss: 0.161742 Batch F1: 0.7346938775510203
Epoch:  465       12 Batch loss: 0.177969 Batch F1: 0.717948717948718
Train Avg Loss  465: 0.171929

Train Avg F1  465: 0.7121394979072696

Val Avg Loss  465: 0.184849

Val Avg F1  465:  0.6769863295302703

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 466
--------------------------------------------------------------
Epoch:  466        1 Batch loss: 0.171981 Batch F1: 0.6666666666666666
Epoch:  466        2 Batch loss: 0.142713 Batch F1: 0.8181818181818182
Epoch:  466        3 Batch loss: 0.160445 Batch F1: 0.7755102040816326
Epoch:  466        4 Batch loss: 0.201367 Batch F1: 0.7037037037037038
Epoch:  466        5 Batch loss: 0.201459 Batch F1: 0.6341463414634146
Epoch:  466        6 Batch loss: 0.164115 Batch F1: 0.723404255319149
Epoch:  466        7 Batch loss: 0.161658 Batch F1: 0.7727272727272727
Epoch:  466        8 Batch loss: 0.163787 Batch F1: 0.7317073170731706
Epoch:  466        9 Batch loss: 0.184609 Batch F1: 0.5945945945945945
Epoch:  466       10 Batch loss: 0.159279 Batch F1: 0.7500000000000001
Epoch:  466       11 Batch loss: 0.192973 Batch F1: 0.6666666666666666
Epoch:  466       12 Batch loss: 0.181749 Batch F1: 0.6842105263157895
Train Avg Loss  466: 0.173845

Train Avg F1  466: 0.7101266138994901

Val Avg Loss  466: 0.181738

Val Avg F1  466:  0.6681623931623932

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 467
--------------------------------------------------------------
Epoch:  467        1 Batch loss: 0.154304 Batch F1: 0.7906976744186046
Epoch:  467        2 Batch loss: 0.185057 Batch F1: 0.6808510638297872
Epoch:  467        3 Batch loss: 0.163732 Batch F1: 0.7111111111111111
Epoch:  467        4 Batch loss: 0.179282 Batch F1: 0.6153846153846154
Epoch:  467        5 Batch loss: 0.176681 Batch F1: 0.7346938775510204
Epoch:  467        6 Batch loss: 0.176646 Batch F1: 0.6511627906976744
Epoch:  467        7 Batch loss: 0.170823 Batch F1: 0.7391304347826088
Epoch:  467        8 Batch loss: 0.155572 Batch F1: 0.8095238095238095
Epoch:  467        9 Batch loss: 0.180433 Batch F1: 0.7391304347826088
Epoch:  467       10 Batch loss: 0.168941 Batch F1: 0.7547169811320754
Epoch:  467       11 Batch loss: 0.162334 Batch F1: 0.7000000000000001
Epoch:  467       12 Batch loss: 0.193719 Batch F1: 0.5625000000000001
Train Avg Loss  467: 0.172294

Train Avg F1  467: 0.7074085661011597

Val Avg Loss  467: 0.182362

Val Avg F1  467:  0.658550463783022

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 468
--------------------------------------------------------------
Epoch:  468        1 Batch loss: 0.170100 Batch F1: 0.6818181818181819
Epoch:  468        2 Batch loss: 0.165664 Batch F1: 0.7
Epoch:  468        3 Batch loss: 0.154691 Batch F1: 0.6666666666666665
Epoch:  468        4 Batch loss: 0.227453 Batch F1: 0.5833333333333333
Epoch:  468        5 Batch loss: 0.158651 Batch F1: 0.8
Epoch:  468        6 Batch loss: 0.172150 Batch F1: 0.6521739130434783
Epoch:  468        7 Batch loss: 0.213239 Batch F1: 0.5714285714285714
Epoch:  468        8 Batch loss: 0.162411 Batch F1: 0.723404255319149
Epoch:  468        9 Batch loss: 0.180913 Batch F1: 0.6341463414634146
Epoch:  468       10 Batch loss: 0.190858 Batch F1: 0.6666666666666666
Epoch:  468       11 Batch loss: 0.165412 Batch F1: 0.7555555555555555
Epoch:  468       12 Batch loss: 0.132758 Batch F1: 0.8484848484848485
Train Avg Loss  468: 0.174525

Train Avg F1  468: 0.6903065278149888

Val Avg Loss  468: 0.186225

Val Avg F1  468:  0.6775129198966409

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 469
--------------------------------------------------------------
Epoch:  469        1 Batch loss: 0.172220 Batch F1: 0.7317073170731708
Epoch:  469        2 Batch loss: 0.183964 Batch F1: 0.7586206896551724
Epoch:  469        3 Batch loss: 0.150178 Batch F1: 0.7916666666666666
Epoch:  469        4 Batch loss: 0.179700 Batch F1: 0.5405405405405405
Epoch:  469        5 Batch loss: 0.183766 Batch F1: 0.5405405405405405
Epoch:  469        6 Batch loss: 0.182249 Batch F1: 0.7169811320754716
Epoch:  469        7 Batch loss: 0.190956 Batch F1: 0.7307692307692307
Epoch:  469        8 Batch loss: 0.186355 Batch F1: 0.5714285714285713
Epoch:  469        9 Batch loss: 0.169727 Batch F1: 0.6842105263157895
Epoch:  469       10 Batch loss: 0.185572 Batch F1: 0.7058823529411764
Epoch:  469       11 Batch loss: 0.199956 Batch F1: 0.6808510638297872
Epoch:  469       12 Batch loss: 0.154786 Batch F1: 0.7777777777777778
Train Avg Loss  469: 0.178286

Train Avg F1  469: 0.6859147008011579

Val Avg Loss  469: 0.186662

Val Avg F1  469:  0.6800999245852186

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 470
--------------------------------------------------------------
Epoch:  470        1 Batch loss: 0.128951 Batch F1: 0.8695652173913043
Epoch:  470        2 Batch loss: 0.174681 Batch F1: 0.761904761904762
Epoch:  470        3 Batch loss: 0.183450 Batch F1: 0.6818181818181819
Epoch:  470        4 Batch loss: 0.211818 Batch F1: 0.5581395348837208
Epoch:  470        5 Batch loss: 0.150435 Batch F1: 0.7727272727272727
Epoch:  470        6 Batch loss: 0.193069 Batch F1: 0.6521739130434783
Epoch:  470        7 Batch loss: 0.202649 Batch F1: 0.6086956521739131
Epoch:  470        8 Batch loss: 0.194602 Batch F1: 0.6363636363636364
Epoch:  470        9 Batch loss: 0.141392 Batch F1: 0.8
Epoch:  470       10 Batch loss: 0.156368 Batch F1: 0.7999999999999999
Epoch:  470       11 Batch loss: 0.196533 Batch F1: 0.693877551020408
Epoch:  470       12 Batch loss: 0.164143 Batch F1: 0.7222222222222222
Train Avg Loss  470: 0.174841

Train Avg F1  470: 0.7131239952957417

Val Avg Loss  470: 0.182957

Val Avg F1  470:  0.6735306233786477

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 471
--------------------------------------------------------------
Epoch:  471        1 Batch loss: 0.187410 Batch F1: 0.55
Epoch:  471        2 Batch loss: 0.162235 Batch F1: 0.723404255319149
Epoch:  471        3 Batch loss: 0.177234 Batch F1: 0.6818181818181819
Epoch:  471        4 Batch loss: 0.148208 Batch F1: 0.84
Epoch:  471        5 Batch loss: 0.176436 Batch F1: 0.6976744186046512
Epoch:  471        6 Batch loss: 0.164840 Batch F1: 0.7368421052631577
Epoch:  471        7 Batch loss: 0.174295 Batch F1: 0.6511627906976744
Epoch:  471        8 Batch loss: 0.178147 Batch F1: 0.6
Epoch:  471        9 Batch loss: 0.160169 Batch F1: 0.761904761904762
Epoch:  471       10 Batch loss: 0.159671 Batch F1: 0.8571428571428571
Epoch:  471       11 Batch loss: 0.200016 Batch F1: 0.6382978723404256
Epoch:  471       12 Batch loss: 0.168428 Batch F1: 0.7027027027027027
Train Avg Loss  471: 0.171424

Train Avg F1  471: 0.7034124954827967

Val Avg Loss  471: 0.182850

Val Avg F1  471:  0.6706591415830546

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 472
--------------------------------------------------------------
Epoch:  472        1 Batch loss: 0.159940 Batch F1: 0.7659574468085107
Epoch:  472        2 Batch loss: 0.203320 Batch F1: 0.5714285714285715
Epoch:  472        3 Batch loss: 0.164431 Batch F1: 0.5
Epoch:  472        4 Batch loss: 0.185724 Batch F1: 0.6818181818181819
Epoch:  472        5 Batch loss: 0.169538 Batch F1: 0.7111111111111111
Epoch:  472        6 Batch loss: 0.185735 Batch F1: 0.6956521739130435
Epoch:  472        7 Batch loss: 0.172205 Batch F1: 0.8
Epoch:  472        8 Batch loss: 0.144399 Batch F1: 0.8461538461538461
Epoch:  472        9 Batch loss: 0.159845 Batch F1: 0.76
Epoch:  472       10 Batch loss: 0.145225 Batch F1: 0.8
Epoch:  472       11 Batch loss: 0.173385 Batch F1: 0.6666666666666666
Epoch:  472       12 Batch loss: 0.187932 Batch F1: 0.5882352941176471
Train Avg Loss  472: 0.170973

Train Avg F1  472: 0.6989186076681316

Val Avg Loss  472: 0.181172

Val Avg F1  472:  0.6799443907156674

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 473
--------------------------------------------------------------
Epoch:  473        1 Batch loss: 0.185194 Batch F1: 0.75
Epoch:  473        2 Batch loss: 0.188766 Batch F1: 0.6530612244897959
Epoch:  473        3 Batch loss: 0.190293 Batch F1: 0.7346938775510203
Epoch:  473        4 Batch loss: 0.168926 Batch F1: 0.6666666666666666
Epoch:  473        5 Batch loss: 0.148660 Batch F1: 0.8333333333333333
Epoch:  473        6 Batch loss: 0.187872 Batch F1: 0.6666666666666667
Epoch:  473        7 Batch loss: 0.170914 Batch F1: 0.6666666666666667
Epoch:  473        8 Batch loss: 0.145854 Batch F1: 0.8181818181818182
Epoch:  473        9 Batch loss: 0.188488 Batch F1: 0.619047619047619
Epoch:  473       10 Batch loss: 0.175374 Batch F1: 0.6829268292682926
Epoch:  473       11 Batch loss: 0.164157 Batch F1: 0.7441860465116279
Epoch:  473       12 Batch loss: 0.190864 Batch F1: 0.5999999999999999
Train Avg Loss  473: 0.175447

Train Avg F1  473: 0.7029525623652922

Val Avg Loss  473: 0.184166

Val Avg F1  473:  0.6777729384436701

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 474
--------------------------------------------------------------
Epoch:  474        1 Batch loss: 0.151693 Batch F1: 0.761904761904762
Epoch:  474        2 Batch loss: 0.188773 Batch F1: 0.6382978723404256
Epoch:  474        3 Batch loss: 0.153401 Batch F1: 0.6428571428571429
Epoch:  474        4 Batch loss: 0.190745 Batch F1: 0.7169811320754716
Epoch:  474        5 Batch loss: 0.150803 Batch F1: 0.8085106382978724
Epoch:  474        6 Batch loss: 0.164117 Batch F1: 0.6842105263157895
Epoch:  474        7 Batch loss: 0.191545 Batch F1: 0.7368421052631577
Epoch:  474        8 Batch loss: 0.191810 Batch F1: 0.7307692307692307
Epoch:  474        9 Batch loss: 0.167224 Batch F1: 0.6666666666666667
Epoch:  474       10 Batch loss: 0.164252 Batch F1: 0.7142857142857143
Epoch:  474       11 Batch loss: 0.169702 Batch F1: 0.6829268292682926
Epoch:  474       12 Batch loss: 0.163053 Batch F1: 0.7368421052631577
Train Avg Loss  474: 0.170593

Train Avg F1  474: 0.7100912271089737

Val Avg Loss  474: 0.181810

Val Avg F1  474:  0.6601456065408111

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 475
--------------------------------------------------------------
Epoch:  475        1 Batch loss: 0.185783 Batch F1: 0.6382978723404255
Epoch:  475        2 Batch loss: 0.168373 Batch F1: 0.7234042553191491
Epoch:  475        3 Batch loss: 0.166702 Batch F1: 0.7924528301886793
Epoch:  475        4 Batch loss: 0.139672 Batch F1: 0.8372093023255814
Epoch:  475        5 Batch loss: 0.189650 Batch F1: 0.6808510638297872
Epoch:  475        6 Batch loss: 0.133010 Batch F1: 0.8717948717948718
Epoch:  475        7 Batch loss: 0.187372 Batch F1: 0.6666666666666667
Epoch:  475        8 Batch loss: 0.170706 Batch F1: 0.7391304347826088
Epoch:  475        9 Batch loss: 0.174234 Batch F1: 0.6060606060606061
Epoch:  475       10 Batch loss: 0.176395 Batch F1: 0.7111111111111111
Epoch:  475       11 Batch loss: 0.209381 Batch F1: 0.5116279069767442
Epoch:  475       12 Batch loss: 0.153856 Batch F1: 0.7647058823529411
Train Avg Loss  475: 0.171261

Train Avg F1  475: 0.7119427336457645

Val Avg Loss  475: 0.183886

Val Avg F1  475:  0.6755527210884353

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 476
--------------------------------------------------------------
Epoch:  476        1 Batch loss: 0.187759 Batch F1: 0.6382978723404256
Epoch:  476        2 Batch loss: 0.203924 Batch F1: 0.5777777777777778
Epoch:  476        3 Batch loss: 0.159850 Batch F1: 0.7555555555555556
Epoch:  476        4 Batch loss: 0.167149 Batch F1: 0.7391304347826088
Epoch:  476        5 Batch loss: 0.165130 Batch F1: 0.7857142857142856
Epoch:  476        6 Batch loss: 0.161906 Batch F1: 0.7317073170731706
Epoch:  476        7 Batch loss: 0.152366 Batch F1: 0.7804878048780488
Epoch:  476        8 Batch loss: 0.179504 Batch F1: 0.6842105263157896
Epoch:  476        9 Batch loss: 0.164149 Batch F1: 0.7755102040816326
Epoch:  476       10 Batch loss: 0.186239 Batch F1: 0.6341463414634148
Epoch:  476       11 Batch loss: 0.166395 Batch F1: 0.7111111111111111
Epoch:  476       12 Batch loss: 0.151124 Batch F1: 0.7096774193548386
Train Avg Loss  476: 0.170458

Train Avg F1  476: 0.7102772208707216

Val Avg Loss  476: 0.184174

Val Avg F1  476:  0.6720893266624974

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 477
--------------------------------------------------------------
Epoch:  477        1 Batch loss: 0.203465 Batch F1: 0.6792452830188679
Epoch:  477        2 Batch loss: 0.172301 Batch F1: 0.6829268292682926
Epoch:  477        3 Batch loss: 0.151885 Batch F1: 0.7727272727272727
Epoch:  477        4 Batch loss: 0.181143 Batch F1: 0.7111111111111111
Epoch:  477        5 Batch loss: 0.163638 Batch F1: 0.7
Epoch:  477        6 Batch loss: 0.148968 Batch F1: 0.6875
Epoch:  477        7 Batch loss: 0.162036 Batch F1: 0.76
Epoch:  477        8 Batch loss: 0.179321 Batch F1: 0.7692307692307693
Epoch:  477        9 Batch loss: 0.164195 Batch F1: 0.6666666666666667
Epoch:  477       10 Batch loss: 0.172269 Batch F1: 0.6956521739130435
Epoch:  477       11 Batch loss: 0.196810 Batch F1: 0.5909090909090908
Epoch:  477       12 Batch loss: 0.145727 Batch F1: 0.8205128205128205
Train Avg Loss  477: 0.170147

Train Avg F1  477: 0.7113735014464946

Val Avg Loss  477: 0.181165

Val Avg F1  477:  0.6696745801033592

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 478
--------------------------------------------------------------
Epoch:  478        1 Batch loss: 0.159780 Batch F1: 0.7
Epoch:  478        2 Batch loss: 0.164323 Batch F1: 0.6829268292682926
Epoch:  478        3 Batch loss: 0.189978 Batch F1: 0.6
Epoch:  478        4 Batch loss: 0.190562 Batch F1: 0.7058823529411765
Epoch:  478        5 Batch loss: 0.190958 Batch F1: 0.7058823529411765
Epoch:  478        6 Batch loss: 0.145739 Batch F1: 0.851063829787234
Epoch:  478        7 Batch loss: 0.174575 Batch F1: 0.6818181818181819
Epoch:  478        8 Batch loss: 0.159884 Batch F1: 0.723404255319149
Epoch:  478        9 Batch loss: 0.197317 Batch F1: 0.6530612244897959
Epoch:  478       10 Batch loss: 0.152554 Batch F1: 0.7692307692307692
Epoch:  478       11 Batch loss: 0.189539 Batch F1: 0.6521739130434783
Epoch:  478       12 Batch loss: 0.146556 Batch F1: 0.823529411764706
Train Avg Loss  478: 0.171814

Train Avg F1  478: 0.7124144267169967

Val Avg Loss  478: 0.185677

Val Avg F1  478:  0.6711662365905513

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 479
--------------------------------------------------------------
Epoch:  479        1 Batch loss: 0.191754 Batch F1: 0.7719298245614034
Epoch:  479        2 Batch loss: 0.218476 Batch F1: 0.5333333333333332
Epoch:  479        3 Batch loss: 0.162322 Batch F1: 0.8163265306122449
Epoch:  479        4 Batch loss: 0.174188 Batch F1: 0.7450980392156864
Epoch:  479        5 Batch loss: 0.152005 Batch F1: 0.7142857142857143
Epoch:  479        6 Batch loss: 0.154673 Batch F1: 0.851851851851852
Epoch:  479        7 Batch loss: 0.157844 Batch F1: 0.7804878048780488
Epoch:  479        8 Batch loss: 0.162827 Batch F1: 0.6486486486486486
Epoch:  479        9 Batch loss: 0.183036 Batch F1: 0.6511627906976744
Epoch:  479       10 Batch loss: 0.159149 Batch F1: 0.6470588235294118
Epoch:  479       11 Batch loss: 0.176558 Batch F1: 0.606060606060606
Epoch:  479       12 Batch loss: 0.187708 Batch F1: 0.6842105263157895
Train Avg Loss  479: 0.173378

Train Avg F1  479: 0.7042045411658678

Val Avg Loss  479: 0.186177

Val Avg F1  479:  0.6821891771019678

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 480
--------------------------------------------------------------
Epoch:  480        1 Batch loss: 0.169185 Batch F1: 0.6829268292682926
Epoch:  480        2 Batch loss: 0.171673 Batch F1: 0.6842105263157895
Epoch:  480        3 Batch loss: 0.178040 Batch F1: 0.6153846153846154
Epoch:  480        4 Batch loss: 0.142000 Batch F1: 0.85
Epoch:  480        5 Batch loss: 0.153129 Batch F1: 0.8
Epoch:  480        6 Batch loss: 0.192993 Batch F1: 0.6530612244897959
Epoch:  480        7 Batch loss: 0.172109 Batch F1: 0.75
Epoch:  480        8 Batch loss: 0.149068 Batch F1: 0.7599999999999999
Epoch:  480        9 Batch loss: 0.225370 Batch F1: 0.6829268292682927
Epoch:  480       10 Batch loss: 0.193725 Batch F1: 0.5142857142857143
Epoch:  480       11 Batch loss: 0.169542 Batch F1: 0.7407407407407408
Epoch:  480       12 Batch loss: 0.175806 Batch F1: 0.8085106382978723
Train Avg Loss  480: 0.174387

Train Avg F1  480: 0.7118372598375927

Val Avg Loss  480: 0.184328

Val Avg F1  480:  0.6745320855614974

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 481
--------------------------------------------------------------
Epoch:  481        1 Batch loss: 0.184612 Batch F1: 0.6153846153846153
Epoch:  481        2 Batch loss: 0.196841 Batch F1: 0.6363636363636364
Epoch:  481        3 Batch loss: 0.144447 Batch F1: 0.7894736842105263
Epoch:  481        4 Batch loss: 0.135869 Batch F1: 0.8400000000000001
Epoch:  481        5 Batch loss: 0.173835 Batch F1: 0.6956521739130435
Epoch:  481        6 Batch loss: 0.182393 Batch F1: 0.6285714285714286
Epoch:  481        7 Batch loss: 0.146001 Batch F1: 0.7916666666666667
Epoch:  481        8 Batch loss: 0.189046 Batch F1: 0.6666666666666666
Epoch:  481        9 Batch loss: 0.164376 Batch F1: 0.6842105263157895
Epoch:  481       10 Batch loss: 0.196498 Batch F1: 0.5641025641025642
Epoch:  481       11 Batch loss: 0.174840 Batch F1: 0.793103448275862
Epoch:  481       12 Batch loss: 0.173553 Batch F1: 0.7727272727272727
Train Avg Loss  481: 0.171859

Train Avg F1  481: 0.7064935569331726

Val Avg Loss  481: 0.184291

Val Avg F1  481:  0.6757761437908497

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 482
--------------------------------------------------------------
Epoch:  482        1 Batch loss: 0.170493 Batch F1: 0.693877551020408
Epoch:  482        2 Batch loss: 0.160730 Batch F1: 0.8
Epoch:  482        3 Batch loss: 0.168460 Batch F1: 0.6938775510204083
Epoch:  482        4 Batch loss: 0.165522 Batch F1: 0.7547169811320754
Epoch:  482        5 Batch loss: 0.204192 Batch F1: 0.7083333333333333
Epoch:  482        6 Batch loss: 0.171732 Batch F1: 0.7555555555555556
Epoch:  482        7 Batch loss: 0.181727 Batch F1: 0.7307692307692308
Epoch:  482        8 Batch loss: 0.182364 Batch F1: 0.5
Epoch:  482        9 Batch loss: 0.156466 Batch F1: 0.6666666666666666
Epoch:  482       10 Batch loss: 0.175599 Batch F1: 0.7692307692307692
Epoch:  482       11 Batch loss: 0.143769 Batch F1: 0.8292682926829269
Epoch:  482       12 Batch loss: 0.205264 Batch F1: 0.42857142857142855
Train Avg Loss  482: 0.173860

Train Avg F1  482: 0.6942389466652336

Val Avg Loss  482: 0.181728

Val Avg F1  482:  0.6737507840906907

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 483
--------------------------------------------------------------
Epoch:  483        1 Batch loss: 0.152500 Batch F1: 0.7916666666666667
Epoch:  483        2 Batch loss: 0.180454 Batch F1: 0.5555555555555555
Epoch:  483        3 Batch loss: 0.214582 Batch F1: 0.5581395348837209
Epoch:  483        4 Batch loss: 0.167405 Batch F1: 0.744186046511628
Epoch:  483        5 Batch loss: 0.171950 Batch F1: 0.6956521739130435
Epoch:  483        6 Batch loss: 0.161529 Batch F1: 0.6842105263157895
Epoch:  483        7 Batch loss: 0.170926 Batch F1: 0.7450980392156864
Epoch:  483        8 Batch loss: 0.165635 Batch F1: 0.7
Epoch:  483        9 Batch loss: 0.146128 Batch F1: 0.7804878048780488
Epoch:  483       10 Batch loss: 0.169157 Batch F1: 0.7924528301886792
Epoch:  483       11 Batch loss: 0.185991 Batch F1: 0.7083333333333334
Epoch:  483       12 Batch loss: 0.160649 Batch F1: 0.7567567567567567
Train Avg Loss  483: 0.170575

Train Avg F1  483: 0.7093782723515757

Val Avg Loss  483: 0.181913

Val Avg F1  483:  0.6724011107106145

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 484
--------------------------------------------------------------
Epoch:  484        1 Batch loss: 0.162667 Batch F1: 0.7317073170731706
Epoch:  484        2 Batch loss: 0.164260 Batch F1: 0.723404255319149
Epoch:  484        3 Batch loss: 0.190295 Batch F1: 0.7692307692307692
Epoch:  484        4 Batch loss: 0.181315 Batch F1: 0.72
Epoch:  484        5 Batch loss: 0.180724 Batch F1: 0.6818181818181818
Epoch:  484        6 Batch loss: 0.202392 Batch F1: 0.5853658536585366
Epoch:  484        7 Batch loss: 0.173237 Batch F1: 0.6829268292682926
Epoch:  484        8 Batch loss: 0.183215 Batch F1: 0.631578947368421
Epoch:  484        9 Batch loss: 0.143992 Batch F1: 0.7906976744186046
Epoch:  484       10 Batch loss: 0.136154 Batch F1: 0.7096774193548387
Epoch:  484       11 Batch loss: 0.156160 Batch F1: 0.7755102040816326
Epoch:  484       12 Batch loss: 0.179215 Batch F1: 0.6857142857142857
Train Avg Loss  484: 0.171136

Train Avg F1  484: 0.7073026447754901

Val Avg Loss  484: 0.180660

Val Avg F1  484:  0.6785241334011357

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 485
--------------------------------------------------------------
Epoch:  485        1 Batch loss: 0.161032 Batch F1: 0.7843137254901961
Epoch:  485        2 Batch loss: 0.153573 Batch F1: 0.7441860465116279
Epoch:  485        3 Batch loss: 0.183657 Batch F1: 0.5882352941176471
Epoch:  485        4 Batch loss: 0.171014 Batch F1: 0.8695652173913043
Epoch:  485        5 Batch loss: 0.167062 Batch F1: 0.7027027027027027
Epoch:  485        6 Batch loss: 0.153632 Batch F1: 0.6896551724137931
Epoch:  485        7 Batch loss: 0.174345 Batch F1: 0.6486486486486486
Epoch:  485        8 Batch loss: 0.193996 Batch F1: 0.6521739130434783
Epoch:  485        9 Batch loss: 0.188893 Batch F1: 0.7058823529411765
Epoch:  485       10 Batch loss: 0.175737 Batch F1: 0.6829268292682926
Epoch:  485       11 Batch loss: 0.172352 Batch F1: 0.7777777777777779
Epoch:  485       12 Batch loss: 0.185878 Batch F1: 0.6486486486486486
Train Avg Loss  485: 0.173431

Train Avg F1  485: 0.7078930274129411

Val Avg Loss  485: 0.182275

Val Avg F1  485:  0.6707924168030551

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 486
--------------------------------------------------------------
Epoch:  486        1 Batch loss: 0.166477 Batch F1: 0.7317073170731706
Epoch:  486        2 Batch loss: 0.171652 Batch F1: 0.8135593220338982
Epoch:  486        3 Batch loss: 0.151457 Batch F1: 0.8085106382978724
Epoch:  486        4 Batch loss: 0.200437 Batch F1: 0.6382978723404256
Epoch:  486        5 Batch loss: 0.166467 Batch F1: 0.6666666666666666
Epoch:  486        6 Batch loss: 0.162630 Batch F1: 0.7391304347826089
Epoch:  486        7 Batch loss: 0.172917 Batch F1: 0.6511627906976745
Epoch:  486        8 Batch loss: 0.162879 Batch F1: 0.761904761904762
Epoch:  486        9 Batch loss: 0.196760 Batch F1: 0.5263157894736842
Epoch:  486       10 Batch loss: 0.153788 Batch F1: 0.7692307692307692
Epoch:  486       11 Batch loss: 0.162003 Batch F1: 0.7317073170731708
Epoch:  486       12 Batch loss: 0.189977 Batch F1: 0.6666666666666667
Train Avg Loss  486: 0.171454

Train Avg F1  486: 0.7087383621867808

Val Avg Loss  486: 0.182212

Val Avg F1  486:  0.6758578431372549

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 487
--------------------------------------------------------------
Epoch:  487        1 Batch loss: 0.170296 Batch F1: 0.6666666666666666
Epoch:  487        2 Batch loss: 0.193566 Batch F1: 0.6530612244897959
Epoch:  487        3 Batch loss: 0.151989 Batch F1: 0.7619047619047619
Epoch:  487        4 Batch loss: 0.153459 Batch F1: 0.8095238095238095
Epoch:  487        5 Batch loss: 0.145533 Batch F1: 0.8399999999999999
Epoch:  487        6 Batch loss: 0.191272 Batch F1: 0.5945945945945946
Epoch:  487        7 Batch loss: 0.161978 Batch F1: 0.7441860465116279
Epoch:  487        8 Batch loss: 0.203192 Batch F1: 0.5365853658536586
Epoch:  487        9 Batch loss: 0.177241 Batch F1: 0.6511627906976744
Epoch:  487       10 Batch loss: 0.137513 Batch F1: 0.8461538461538461
Epoch:  487       11 Batch loss: 0.162184 Batch F1: 0.7346938775510203
Epoch:  487       12 Batch loss: 0.191253 Batch F1: 0.6285714285714286
Train Avg Loss  487: 0.169956

Train Avg F1  487: 0.7055920343765737

Val Avg Loss  487: 0.182434

Val Avg F1  487:  0.6763427489619862

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 488
--------------------------------------------------------------
Epoch:  488        1 Batch loss: 0.161187 Batch F1: 0.7391304347826088
Epoch:  488        2 Batch loss: 0.181363 Batch F1: 0.7407407407407408
Epoch:  488        3 Batch loss: 0.168106 Batch F1: 0.6486486486486486
Epoch:  488        4 Batch loss: 0.154580 Batch F1: 0.75
Epoch:  488        5 Batch loss: 0.176677 Batch F1: 0.7450980392156863
Epoch:  488        6 Batch loss: 0.172542 Batch F1: 0.7142857142857143
Epoch:  488        7 Batch loss: 0.157394 Batch F1: 0.717948717948718
Epoch:  488        8 Batch loss: 0.166672 Batch F1: 0.7450980392156864
Epoch:  488        9 Batch loss: 0.167983 Batch F1: 0.6486486486486486
Epoch:  488       10 Batch loss: 0.179522 Batch F1: 0.6666666666666666
Epoch:  488       11 Batch loss: 0.166093 Batch F1: 0.6666666666666666
Epoch:  488       12 Batch loss: 0.184308 Batch F1: 0.7272727272727272
Train Avg Loss  488: 0.169702

Train Avg F1  488: 0.709183753674376

Val Avg Loss  488: 0.181567

Val Avg F1  488:  0.6568537768537768

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 489
--------------------------------------------------------------
Epoch:  489        1 Batch loss: 0.189790 Batch F1: 0.6923076923076924
Epoch:  489        2 Batch loss: 0.142055 Batch F1: 0.8181818181818182
Epoch:  489        3 Batch loss: 0.172721 Batch F1: 0.6511627906976745
Epoch:  489        4 Batch loss: 0.144260 Batch F1: 0.8163265306122449
Epoch:  489        5 Batch loss: 0.159084 Batch F1: 0.7555555555555555
Epoch:  489        6 Batch loss: 0.181548 Batch F1: 0.6956521739130435
Epoch:  489        7 Batch loss: 0.209136 Batch F1: 0.608695652173913
Epoch:  489        8 Batch loss: 0.153620 Batch F1: 0.7222222222222222
Epoch:  489        9 Batch loss: 0.152067 Batch F1: 0.7999999999999999
Epoch:  489       10 Batch loss: 0.182176 Batch F1: 0.5789473684210527
Epoch:  489       11 Batch loss: 0.164352 Batch F1: 0.7272727272727272
Epoch:  489       12 Batch loss: 0.185168 Batch F1: 0.6486486486486486
Train Avg Loss  489: 0.169665

Train Avg F1  489: 0.7095810983338827

Val Avg Loss  489: 0.180539

Val Avg F1  489:  0.6772272330146983

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 490
--------------------------------------------------------------
Epoch:  490        1 Batch loss: 0.170635 Batch F1: 0.6818181818181818
Epoch:  490        2 Batch loss: 0.177029 Batch F1: 0.6341463414634146
Epoch:  490        3 Batch loss: 0.200833 Batch F1: 0.5909090909090909
Epoch:  490        4 Batch loss: 0.193157 Batch F1: 0.6956521739130435
Epoch:  490        5 Batch loss: 0.207407 Batch F1: 0.6923076923076923
Epoch:  490        6 Batch loss: 0.154500 Batch F1: 0.761904761904762
Epoch:  490        7 Batch loss: 0.137525 Batch F1: 0.8461538461538461
Epoch:  490        8 Batch loss: 0.149845 Batch F1: 0.7692307692307692
Epoch:  490        9 Batch loss: 0.184824 Batch F1: 0.6486486486486486
Epoch:  490       10 Batch loss: 0.151000 Batch F1: 0.782608695652174
Epoch:  490       11 Batch loss: 0.191999 Batch F1: 0.6222222222222222
Epoch:  490       12 Batch loss: 0.143890 Batch F1: 0.8108108108108109
Train Avg Loss  490: 0.171887

Train Avg F1  490: 0.7113677695862212

Val Avg Loss  490: 0.183657

Val Avg F1  490:  0.6774110671936759

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 491
--------------------------------------------------------------
Epoch:  491        1 Batch loss: 0.179342 Batch F1: 0.6818181818181818
Epoch:  491        2 Batch loss: 0.177162 Batch F1: 0.7450980392156863
Epoch:  491        3 Batch loss: 0.163750 Batch F1: 0.7441860465116279
Epoch:  491        4 Batch loss: 0.140236 Batch F1: 0.85
Epoch:  491        5 Batch loss: 0.173289 Batch F1: 0.6818181818181818
Epoch:  491        6 Batch loss: 0.164290 Batch F1: 0.7391304347826088
Epoch:  491        7 Batch loss: 0.167339 Batch F1: 0.7659574468085107
Epoch:  491        8 Batch loss: 0.177240 Batch F1: 0.6956521739130435
Epoch:  491        9 Batch loss: 0.194727 Batch F1: 0.5263157894736842
Epoch:  491       10 Batch loss: 0.171684 Batch F1: 0.7636363636363638
Epoch:  491       11 Batch loss: 0.170923 Batch F1: 0.7272727272727272
Epoch:  491       12 Batch loss: 0.168647 Batch F1: 0.5185185185185186
Train Avg Loss  491: 0.170719

Train Avg F1  491: 0.7032836586474279

Val Avg Loss  491: 0.181022

Val Avg F1  491:  0.6708550228371201

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 492
--------------------------------------------------------------
Epoch:  492        1 Batch loss: 0.163742 Batch F1: 0.7636363636363636
Epoch:  492        2 Batch loss: 0.187755 Batch F1: 0.6222222222222222
Epoch:  492        3 Batch loss: 0.180091 Batch F1: 0.6666666666666666
Epoch:  492        4 Batch loss: 0.159114 Batch F1: 0.6857142857142857
Epoch:  492        5 Batch loss: 0.166812 Batch F1: 0.7083333333333333
Epoch:  492        6 Batch loss: 0.168767 Batch F1: 0.6666666666666666
Epoch:  492        7 Batch loss: 0.157561 Batch F1: 0.7894736842105263
Epoch:  492        8 Batch loss: 0.184507 Batch F1: 0.6808510638297872
Epoch:  492        9 Batch loss: 0.151511 Batch F1: 0.75
Epoch:  492       10 Batch loss: 0.176460 Batch F1: 0.7450980392156864
Epoch:  492       11 Batch loss: 0.164183 Batch F1: 0.7659574468085107
Epoch:  492       12 Batch loss: 0.186682 Batch F1: 0.6829268292682926
Train Avg Loss  492: 0.170599

Train Avg F1  492: 0.7106288834643618

Val Avg Loss  492: 0.182393

Val Avg F1  492:  0.6732675727858385

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 493
--------------------------------------------------------------
Epoch:  493        1 Batch loss: 0.182837 Batch F1: 0.7407407407407408
Epoch:  493        2 Batch loss: 0.162596 Batch F1: 0.7843137254901961
Epoch:  493        3 Batch loss: 0.149074 Batch F1: 0.7999999999999999
Epoch:  493        4 Batch loss: 0.168763 Batch F1: 0.7
Epoch:  493        5 Batch loss: 0.199091 Batch F1: 0.6
Epoch:  493        6 Batch loss: 0.189191 Batch F1: 0.5853658536585366
Epoch:  493        7 Batch loss: 0.145602 Batch F1: 0.8205128205128205
Epoch:  493        8 Batch loss: 0.203765 Batch F1: 0.5909090909090909
Epoch:  493        9 Batch loss: 0.165316 Batch F1: 0.7692307692307692
Epoch:  493       10 Batch loss: 0.179775 Batch F1: 0.6666666666666666
Epoch:  493       11 Batch loss: 0.192341 Batch F1: 0.6341463414634146
Epoch:  493       12 Batch loss: 0.159564 Batch F1: 0.8292682926829269
Train Avg Loss  493: 0.174826

Train Avg F1  493: 0.7100961917795968

Val Avg Loss  493: 0.185305

Val Avg F1  493:  0.673853519668737

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 494
--------------------------------------------------------------
Epoch:  494        1 Batch loss: 0.174153 Batch F1: 0.7272727272727272
Epoch:  494        2 Batch loss: 0.197490 Batch F1: 0.6666666666666666
Epoch:  494        3 Batch loss: 0.168863 Batch F1: 0.6060606060606061
Epoch:  494        4 Batch loss: 0.176305 Batch F1: 0.7368421052631577
Epoch:  494        5 Batch loss: 0.150994 Batch F1: 0.7555555555555555
Epoch:  494        6 Batch loss: 0.165674 Batch F1: 0.7407407407407408
Epoch:  494        7 Batch loss: 0.134061 Batch F1: 0.7906976744186046
Epoch:  494        8 Batch loss: 0.200264 Batch F1: 0.6153846153846154
Epoch:  494        9 Batch loss: 0.198840 Batch F1: 0.6
Epoch:  494       10 Batch loss: 0.186085 Batch F1: 0.6382978723404256
Epoch:  494       11 Batch loss: 0.194284 Batch F1: 0.5405405405405405
Epoch:  494       12 Batch loss: 0.147866 Batch F1: 0.8235294117647058
Train Avg Loss  494: 0.174573

Train Avg F1  494: 0.6867990430006955

Val Avg Loss  494: 0.192546

Val Avg F1  494:  0.6629109477946687

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 495
--------------------------------------------------------------
Epoch:  495        1 Batch loss: 0.160804 Batch F1: 0.6666666666666666
Epoch:  495        2 Batch loss: 0.210621 Batch F1: 0.6190476190476191
Epoch:  495        3 Batch loss: 0.172527 Batch F1: 0.6976744186046512
Epoch:  495        4 Batch loss: 0.181244 Batch F1: 0.6829268292682927
Epoch:  495        5 Batch loss: 0.204796 Batch F1: 0.6808510638297872
Epoch:  495        6 Batch loss: 0.178466 Batch F1: 0.7111111111111111
Epoch:  495        7 Batch loss: 0.215011 Batch F1: 0.6415094339622641
Epoch:  495        8 Batch loss: 0.180746 Batch F1: 0.7083333333333334
Epoch:  495        9 Batch loss: 0.120163 Batch F1: 0.8947368421052632
Epoch:  495       10 Batch loss: 0.140774 Batch F1: 0.8181818181818182
Epoch:  495       11 Batch loss: 0.172760 Batch F1: 0.7450980392156864
Epoch:  495       12 Batch loss: 0.185804 Batch F1: 0.717948717948718
Train Avg Loss  495: 0.176976

Train Avg F1  495: 0.7153404911062675

Val Avg Loss  495: 0.184924

Val Avg F1  495:  0.6693154229491439

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 496
--------------------------------------------------------------
Epoch:  496        1 Batch loss: 0.195978 Batch F1: 0.6808510638297872
Epoch:  496        2 Batch loss: 0.178230 Batch F1: 0.6666666666666666
Epoch:  496        3 Batch loss: 0.167127 Batch F1: 0.7391304347826088
Epoch:  496        4 Batch loss: 0.198227 Batch F1: 0.6521739130434783
Epoch:  496        5 Batch loss: 0.181256 Batch F1: 0.6500000000000001
Epoch:  496        6 Batch loss: 0.173406 Batch F1: 0.7272727272727272
Epoch:  496        7 Batch loss: 0.152347 Batch F1: 0.8085106382978724
Epoch:  496        8 Batch loss: 0.141397 Batch F1: 0.7894736842105262
Epoch:  496        9 Batch loss: 0.174777 Batch F1: 0.65
Epoch:  496       10 Batch loss: 0.188709 Batch F1: 0.7407407407407408
Epoch:  496       11 Batch loss: 0.167114 Batch F1: 0.6956521739130435
Epoch:  496       12 Batch loss: 0.171865 Batch F1: 0.742857142857143
Train Avg Loss  496: 0.174203

Train Avg F1  496: 0.7119440988012163

Val Avg Loss  496: 0.186980

Val Avg F1  496:  0.7500481974166184

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 497
--------------------------------------------------------------
Epoch:  497        1 Batch loss: 0.171349 Batch F1: 0.8846153846153846
Epoch:  497        2 Batch loss: 0.179967 Batch F1: 0.8163265306122449
Epoch:  497        3 Batch loss: 0.186266 Batch F1: 0.6829268292682927
Epoch:  497        4 Batch loss: 0.180952 Batch F1: 0.6153846153846153
Epoch:  497        5 Batch loss: 0.186401 Batch F1: 0.7796610169491527
Epoch:  497        6 Batch loss: 0.197005 Batch F1: 0.6341463414634146
Epoch:  497        7 Batch loss: 0.166025 Batch F1: 0.782608695652174
Epoch:  497        8 Batch loss: 0.170548 Batch F1: 0.8214285714285715
Epoch:  497        9 Batch loss: 0.170563 Batch F1: 0.6153846153846153
Epoch:  497       10 Batch loss: 0.168426 Batch F1: 0.6486486486486486
Epoch:  497       11 Batch loss: 0.165023 Batch F1: 0.75
Epoch:  497       12 Batch loss: 0.180993 Batch F1: 0.7027027027027027
Train Avg Loss  497: 0.176960

Train Avg F1  497: 0.7278194960091514

Val Avg Loss  497: 0.183006

Val Avg F1  497:  0.6728341331930839

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 498
--------------------------------------------------------------
Epoch:  498        1 Batch loss: 0.174465 Batch F1: 0.7083333333333333
Epoch:  498        2 Batch loss: 0.155252 Batch F1: 0.7727272727272727
Epoch:  498        3 Batch loss: 0.183823 Batch F1: 0.5945945945945946
Epoch:  498        4 Batch loss: 0.154038 Batch F1: 0.8363636363636363
Epoch:  498        5 Batch loss: 0.178026 Batch F1: 0.6666666666666666
Epoch:  498        6 Batch loss: 0.169163 Batch F1: 0.6341463414634146
Epoch:  498        7 Batch loss: 0.181056 Batch F1: 0.6666666666666667
Epoch:  498        8 Batch loss: 0.197907 Batch F1: 0.55
Epoch:  498        9 Batch loss: 0.156261 Batch F1: 0.7659574468085107
Epoch:  498       10 Batch loss: 0.189142 Batch F1: 0.7307692307692308
Epoch:  498       11 Batch loss: 0.157582 Batch F1: 0.8444444444444444
Epoch:  498       12 Batch loss: 0.179687 Batch F1: 0.6857142857142857
Train Avg Loss  498: 0.173034

Train Avg F1  498: 0.7046986599626713

Val Avg Loss  498: 0.185477

Val Avg F1  498:  0.6726633986928104

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 499
--------------------------------------------------------------
Epoch:  499        1 Batch loss: 0.171253 Batch F1: 0.7659574468085107
Epoch:  499        2 Batch loss: 0.177345 Batch F1: 0.6666666666666666
Epoch:  499        3 Batch loss: 0.162809 Batch F1: 0.7441860465116279
Epoch:  499        4 Batch loss: 0.171595 Batch F1: 0.75
Epoch:  499        5 Batch loss: 0.162001 Batch F1: 0.744186046511628
Epoch:  499        6 Batch loss: 0.158518 Batch F1: 0.625
Epoch:  499        7 Batch loss: 0.176387 Batch F1: 0.76
Epoch:  499        8 Batch loss: 0.211388 Batch F1: 0.5833333333333334
Epoch:  499        9 Batch loss: 0.155867 Batch F1: 0.6470588235294117
Epoch:  499       10 Batch loss: 0.167373 Batch F1: 0.7659574468085107
Epoch:  499       11 Batch loss: 0.164094 Batch F1: 0.7924528301886792
Epoch:  499       12 Batch loss: 0.181351 Batch F1: 0.8444444444444444
Train Avg Loss  499: 0.171665

Train Avg F1  499: 0.7241035904002344

Val Avg Loss  499: 0.189735

Val Avg F1  499:  0.8707658302400827

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 500
--------------------------------------------------------------
Epoch:  500        1 Batch loss: 0.193804 Batch F1: 0.911764705882353
Epoch:  500        2 Batch loss: 0.193725 Batch F1: 0.8666666666666666
Epoch:  500        3 Batch loss: 0.178869 Batch F1: 0.8771929824561403
Epoch:  500        4 Batch loss: 0.167912 Batch F1: 0.7096774193548386
Epoch:  500        5 Batch loss: 0.168243 Batch F1: 0.7692307692307692
Epoch:  500        6 Batch loss: 0.149724 Batch F1: 0.8461538461538461
Epoch:  500        7 Batch loss: 0.170096 Batch F1: 0.6666666666666666
Epoch:  500        8 Batch loss: 0.149135 Batch F1: 0.7894736842105263
Epoch:  500        9 Batch loss: 0.186300 Batch F1: 0.5405405405405405
Epoch:  500       10 Batch loss: 0.163286 Batch F1: 0.7222222222222222
Epoch:  500       11 Batch loss: 0.188425 Batch F1: 0.6938775510204083
Epoch:  500       12 Batch loss: 0.191897 Batch F1: 0.717948717948718
Train Avg Loss  500: 0.175118

Train Avg F1  500: 0.7592846476961412

Val Avg Loss  500: 0.186544

Val Avg F1  500:  0.675175656713646

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 501
--------------------------------------------------------------
Epoch:  501        1 Batch loss: 0.195184 Batch F1: 0.6382978723404256
Epoch:  501        2 Batch loss: 0.165272 Batch F1: 0.6842105263157895
Epoch:  501        3 Batch loss: 0.179324 Batch F1: 0.6521739130434783
Epoch:  501        4 Batch loss: 0.185789 Batch F1: 0.6666666666666666
Epoch:  501        5 Batch loss: 0.176784 Batch F1: 0.6
Epoch:  501        6 Batch loss: 0.171845 Batch F1: 0.7499999999999999
Epoch:  501        7 Batch loss: 0.167206 Batch F1: 0.76
Epoch:  501        8 Batch loss: 0.183403 Batch F1: 0.6500000000000001
Epoch:  501        9 Batch loss: 0.180740 Batch F1: 0.7777777777777778
Epoch:  501       10 Batch loss: 0.159932 Batch F1: 0.6842105263157895
Epoch:  501       11 Batch loss: 0.181416 Batch F1: 0.6808510638297872
Epoch:  501       12 Batch loss: 0.199006 Batch F1: 0.7391304347826088
Train Avg Loss  501: 0.178825

Train Avg F1  501: 0.6902765650893604

Val Avg Loss  501: 0.187609

Val Avg F1  501:  0.6357508912655971

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 502
--------------------------------------------------------------
Epoch:  502        1 Batch loss: 0.180665 Batch F1: 0.7241379310344827
Epoch:  502        2 Batch loss: 0.172856 Batch F1: 0.7272727272727272
Epoch:  502        3 Batch loss: 0.160255 Batch F1: 0.7555555555555555
Epoch:  502        4 Batch loss: 0.176691 Batch F1: 0.723404255319149
Epoch:  502        5 Batch loss: 0.151794 Batch F1: 0.7500000000000001
Epoch:  502        6 Batch loss: 0.168446 Batch F1: 0.7659574468085107
Epoch:  502        7 Batch loss: 0.180788 Batch F1: 0.5161290322580646
Epoch:  502        8 Batch loss: 0.194677 Batch F1: 0.6808510638297872
Epoch:  502        9 Batch loss: 0.171671 Batch F1: 0.7142857142857143
Epoch:  502       10 Batch loss: 0.180258 Batch F1: 0.6956521739130435
Epoch:  502       11 Batch loss: 0.141775 Batch F1: 0.7567567567567567
Epoch:  502       12 Batch loss: 0.198063 Batch F1: 0.6666666666666666
Train Avg Loss  502: 0.173162

Train Avg F1  502: 0.7063891103083716

Val Avg Loss  502: 0.182824

Val Avg F1  502:  0.6755374416524242

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 503
--------------------------------------------------------------
Epoch:  503        1 Batch loss: 0.195462 Batch F1: 0.6666666666666666
Epoch:  503        2 Batch loss: 0.184134 Batch F1: 0.6808510638297872
Epoch:  503        3 Batch loss: 0.131991 Batch F1: 0.8421052631578947
Epoch:  503        4 Batch loss: 0.175478 Batch F1: 0.7450980392156864
Epoch:  503        5 Batch loss: 0.143859 Batch F1: 0.7906976744186046
Epoch:  503        6 Batch loss: 0.187957 Batch F1: 0.6666666666666666
Epoch:  503        7 Batch loss: 0.148220 Batch F1: 0.8181818181818182
Epoch:  503        8 Batch loss: 0.131036 Batch F1: 0.8292682926829269
Epoch:  503        9 Batch loss: 0.194269 Batch F1: 0.6511627906976745
Epoch:  503       10 Batch loss: 0.189465 Batch F1: 0.6190476190476191
Epoch:  503       11 Batch loss: 0.178731 Batch F1: 0.7346938775510203
Epoch:  503       12 Batch loss: 0.209111 Batch F1: 0.45161290322580644
Train Avg Loss  503: 0.172476

Train Avg F1  503: 0.7080043896118476

Val Avg Loss  503: 0.186284

Val Avg F1  503:  0.6748484363432641

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 504
--------------------------------------------------------------
Epoch:  504        1 Batch loss: 0.146283 Batch F1: 0.8444444444444444
Epoch:  504        2 Batch loss: 0.196882 Batch F1: 0.5909090909090909
Epoch:  504        3 Batch loss: 0.186309 Batch F1: 0.693877551020408
Epoch:  504        4 Batch loss: 0.160817 Batch F1: 0.7
Epoch:  504        5 Batch loss: 0.142910 Batch F1: 0.8400000000000001
Epoch:  504        6 Batch loss: 0.216564 Batch F1: 0.5833333333333334
Epoch:  504        7 Batch loss: 0.177099 Batch F1: 0.7111111111111111
Epoch:  504        8 Batch loss: 0.185254 Batch F1: 0.5945945945945946
Epoch:  504        9 Batch loss: 0.162400 Batch F1: 0.7142857142857143
Epoch:  504       10 Batch loss: 0.157876 Batch F1: 0.7916666666666666
Epoch:  504       11 Batch loss: 0.164139 Batch F1: 0.6666666666666667
Epoch:  504       12 Batch loss: 0.164935 Batch F1: 0.7804878048780488
Train Avg Loss  504: 0.171789

Train Avg F1  504: 0.7092814148258401

Val Avg Loss  504: 0.183000

Val Avg F1  504:  0.6786398699134548

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 505
--------------------------------------------------------------
Epoch:  505        1 Batch loss: 0.173142 Batch F1: 0.711111111111111
Epoch:  505        2 Batch loss: 0.184456 Batch F1: 0.693877551020408
Epoch:  505        3 Batch loss: 0.138174 Batch F1: 0.8292682926829269
Epoch:  505        4 Batch loss: 0.196176 Batch F1: 0.6382978723404256
Epoch:  505        5 Batch loss: 0.164406 Batch F1: 0.7659574468085106
Epoch:  505        6 Batch loss: 0.187527 Batch F1: 0.5405405405405405
Epoch:  505        7 Batch loss: 0.168126 Batch F1: 0.7692307692307692
Epoch:  505        8 Batch loss: 0.169948 Batch F1: 0.6285714285714286
Epoch:  505        9 Batch loss: 0.171758 Batch F1: 0.7659574468085107
Epoch:  505       10 Batch loss: 0.160190 Batch F1: 0.75
Epoch:  505       11 Batch loss: 0.160758 Batch F1: 0.7599999999999999
Epoch:  505       12 Batch loss: 0.184873 Batch F1: 0.6285714285714286
Train Avg Loss  505: 0.171628

Train Avg F1  505: 0.706781990640505

Val Avg Loss  505: 0.181925

Val Avg F1  505:  0.6774607625755402

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 506
--------------------------------------------------------------
Epoch:  506        1 Batch loss: 0.159497 Batch F1: 0.7500000000000001
Epoch:  506        2 Batch loss: 0.151628 Batch F1: 0.7222222222222222
Epoch:  506        3 Batch loss: 0.170320 Batch F1: 0.7234042553191489
Epoch:  506        4 Batch loss: 0.163526 Batch F1: 0.7555555555555555
Epoch:  506        5 Batch loss: 0.178526 Batch F1: 0.6808510638297872
Epoch:  506        6 Batch loss: 0.159108 Batch F1: 0.7727272727272727
Epoch:  506        7 Batch loss: 0.191760 Batch F1: 0.5853658536585366
Epoch:  506        8 Batch loss: 0.165255 Batch F1: 0.7659574468085107
Epoch:  506        9 Batch loss: 0.184100 Batch F1: 0.7346938775510203
Epoch:  506       10 Batch loss: 0.179631 Batch F1: 0.6341463414634148
Epoch:  506       11 Batch loss: 0.156873 Batch F1: 0.8076923076923077
Epoch:  506       12 Batch loss: 0.198743 Batch F1: 0.5
Train Avg Loss  506: 0.171581

Train Avg F1  506: 0.7027180164023147

Val Avg Loss  506: 0.182093

Val Avg F1  506:  0.6755494907668821

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 507
--------------------------------------------------------------
Epoch:  507        1 Batch loss: 0.175663 Batch F1: 0.6666666666666666
Epoch:  507        2 Batch loss: 0.156904 Batch F1: 0.7916666666666667
Epoch:  507        3 Batch loss: 0.177780 Batch F1: 0.75
Epoch:  507        4 Batch loss: 0.177303 Batch F1: 0.6341463414634146
Epoch:  507        5 Batch loss: 0.156629 Batch F1: 0.7027027027027027
Epoch:  507        6 Batch loss: 0.155356 Batch F1: 0.75
Epoch:  507        7 Batch loss: 0.164897 Batch F1: 0.7999999999999999
Epoch:  507        8 Batch loss: 0.160757 Batch F1: 0.7755102040816326
Epoch:  507        9 Batch loss: 0.176706 Batch F1: 0.6486486486486486
Epoch:  507       10 Batch loss: 0.189352 Batch F1: 0.6666666666666667
Epoch:  507       11 Batch loss: 0.161727 Batch F1: 0.7555555555555556
Epoch:  507       12 Batch loss: 0.195818 Batch F1: 0.5
Train Avg Loss  507: 0.170741

Train Avg F1  507: 0.7034636210376629

Val Avg Loss  507: 0.181263

Val Avg F1  507:  0.6782720825274018

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 508
--------------------------------------------------------------
Epoch:  508        1 Batch loss: 0.128071 Batch F1: 0.7894736842105263
Epoch:  508        2 Batch loss: 0.159387 Batch F1: 0.7142857142857143
Epoch:  508        3 Batch loss: 0.186837 Batch F1: 0.6046511627906976
Epoch:  508        4 Batch loss: 0.185397 Batch F1: 0.7083333333333334
Epoch:  508        5 Batch loss: 0.154256 Batch F1: 0.7727272727272727
Epoch:  508        6 Batch loss: 0.169004 Batch F1: 0.7555555555555555
Epoch:  508        7 Batch loss: 0.197365 Batch F1: 0.6222222222222222
Epoch:  508        8 Batch loss: 0.159640 Batch F1: 0.6829268292682926
Epoch:  508        9 Batch loss: 0.183250 Batch F1: 0.723404255319149
Epoch:  508       10 Batch loss: 0.183728 Batch F1: 0.6666666666666667
Epoch:  508       11 Batch loss: 0.161682 Batch F1: 0.7555555555555555
Epoch:  508       12 Batch loss: 0.160850 Batch F1: 0.7692307692307692
Train Avg Loss  508: 0.169122

Train Avg F1  508: 0.7137527517638129

Val Avg Loss  508: 0.182025

Val Avg F1  508:  0.6742930982061416

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 509
--------------------------------------------------------------
Epoch:  509        1 Batch loss: 0.184376 Batch F1: 0.6808510638297872
Epoch:  509        2 Batch loss: 0.177707 Batch F1: 0.6818181818181818
Epoch:  509        3 Batch loss: 0.166473 Batch F1: 0.7555555555555555
Epoch:  509        4 Batch loss: 0.162815 Batch F1: 0.7142857142857143
Epoch:  509        5 Batch loss: 0.181825 Batch F1: 0.7142857142857143
Epoch:  509        6 Batch loss: 0.136451 Batch F1: 0.8636363636363636
Epoch:  509        7 Batch loss: 0.179217 Batch F1: 0.7169811320754716
Epoch:  509        8 Batch loss: 0.160669 Batch F1: 0.7
Epoch:  509        9 Batch loss: 0.153594 Batch F1: 0.75
Epoch:  509       10 Batch loss: 0.186385 Batch F1: 0.6976744186046512
Epoch:  509       11 Batch loss: 0.160265 Batch F1: 0.717948717948718
Epoch:  509       12 Batch loss: 0.198025 Batch F1: 0.5
Train Avg Loss  509: 0.170650

Train Avg F1  509: 0.7077530718366799

Val Avg Loss  509: 0.182790

Val Avg F1  509:  0.6781141385504361

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 510
--------------------------------------------------------------
Epoch:  510        1 Batch loss: 0.170505 Batch F1: 0.7142857142857143
Epoch:  510        2 Batch loss: 0.151597 Batch F1: 0.6857142857142857
Epoch:  510        3 Batch loss: 0.181353 Batch F1: 0.5500000000000002
Epoch:  510        4 Batch loss: 0.192098 Batch F1: 0.5263157894736842
Epoch:  510        5 Batch loss: 0.167672 Batch F1: 0.6976744186046512
Epoch:  510        6 Batch loss: 0.186200 Batch F1: 0.7999999999999999
Epoch:  510        7 Batch loss: 0.147802 Batch F1: 0.8372093023255814
Epoch:  510        8 Batch loss: 0.169759 Batch F1: 0.7391304347826088
Epoch:  510        9 Batch loss: 0.164424 Batch F1: 0.7727272727272727
Epoch:  510       10 Batch loss: 0.175134 Batch F1: 0.6666666666666666
Epoch:  510       11 Batch loss: 0.172796 Batch F1: 0.7499999999999999
Epoch:  510       12 Batch loss: 0.165394 Batch F1: 0.7500000000000001
Train Avg Loss  510: 0.170395

Train Avg F1  510: 0.7074769903817054

Val Avg Loss  510: 0.184023

Val Avg F1  510:  0.6771507863089732

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 511
--------------------------------------------------------------
Epoch:  511        1 Batch loss: 0.184712 Batch F1: 0.6923076923076924
Epoch:  511        2 Batch loss: 0.168265 Batch F1: 0.7692307692307692
Epoch:  511        3 Batch loss: 0.169859 Batch F1: 0.6818181818181818
Epoch:  511        4 Batch loss: 0.170057 Batch F1: 0.6976744186046512
Epoch:  511        5 Batch loss: 0.147600 Batch F1: 0.816326530612245
Epoch:  511        6 Batch loss: 0.170057 Batch F1: 0.7391304347826085
Epoch:  511        7 Batch loss: 0.166631 Batch F1: 0.761904761904762
Epoch:  511        8 Batch loss: 0.190203 Batch F1: 0.5142857142857143
Epoch:  511        9 Batch loss: 0.141019 Batch F1: 0.7999999999999999
Epoch:  511       10 Batch loss: 0.213728 Batch F1: 0.7111111111111111
Epoch:  511       11 Batch loss: 0.169839 Batch F1: 0.6666666666666667
Epoch:  511       12 Batch loss: 0.164211 Batch F1: 0.6857142857142857
Train Avg Loss  511: 0.171348

Train Avg F1  511: 0.711347547253224

Val Avg Loss  511: 0.186491

Val Avg F1  511:  0.6665654520917679

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 512
--------------------------------------------------------------
Epoch:  512        1 Batch loss: 0.205963 Batch F1: 0.5365853658536585
Epoch:  512        2 Batch loss: 0.161546 Batch F1: 0.7619047619047619
Epoch:  512        3 Batch loss: 0.180449 Batch F1: 0.5945945945945946
Epoch:  512        4 Batch loss: 0.188559 Batch F1: 0.5365853658536585
Epoch:  512        5 Batch loss: 0.197983 Batch F1: 0.679245283018868
Epoch:  512        6 Batch loss: 0.166020 Batch F1: 0.8400000000000001
Epoch:  512        7 Batch loss: 0.155282 Batch F1: 0.8800000000000001
Epoch:  512        8 Batch loss: 0.165060 Batch F1: 0.7222222222222222
Epoch:  512        9 Batch loss: 0.168464 Batch F1: 0.6666666666666667
Epoch:  512       10 Batch loss: 0.175807 Batch F1: 0.7407407407407408
Epoch:  512       11 Batch loss: 0.154482 Batch F1: 0.75
Epoch:  512       12 Batch loss: 0.152857 Batch F1: 0.7894736842105263
Train Avg Loss  512: 0.172706

Train Avg F1  512: 0.7081682237554747

Val Avg Loss  512: 0.180882

Val Avg F1  512:  0.6752212214844521

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 513
--------------------------------------------------------------
Epoch:  513        1 Batch loss: 0.152764 Batch F1: 0.7826086956521738
Epoch:  513        2 Batch loss: 0.174502 Batch F1: 0.6976744186046512
Epoch:  513        3 Batch loss: 0.179761 Batch F1: 0.6818181818181818
Epoch:  513        4 Batch loss: 0.158631 Batch F1: 0.7916666666666666
Epoch:  513        5 Batch loss: 0.166428 Batch F1: 0.6486486486486486
Epoch:  513        6 Batch loss: 0.148202 Batch F1: 0.7567567567567567
Epoch:  513        7 Batch loss: 0.156336 Batch F1: 0.7755102040816326
Epoch:  513        8 Batch loss: 0.202793 Batch F1: 0.6885245901639345
Epoch:  513        9 Batch loss: 0.211673 Batch F1: 0.6341463414634146
Epoch:  513       10 Batch loss: 0.160613 Batch F1: 0.76
Epoch:  513       11 Batch loss: 0.172316 Batch F1: 0.65
Epoch:  513       12 Batch loss: 0.163760 Batch F1: 0.6206896551724138
Train Avg Loss  513: 0.170648

Train Avg F1  513: 0.7073370132523729

Val Avg Loss  513: 0.184803

Val Avg F1  513:  0.6709368530020704

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 514
--------------------------------------------------------------
Epoch:  514        1 Batch loss: 0.161968 Batch F1: 0.7441860465116279
Epoch:  514        2 Batch loss: 0.161778 Batch F1: 0.7
Epoch:  514        3 Batch loss: 0.153906 Batch F1: 0.7916666666666666
Epoch:  514        4 Batch loss: 0.167230 Batch F1: 0.7450980392156864
Epoch:  514        5 Batch loss: 0.152097 Batch F1: 0.8333333333333333
Epoch:  514        6 Batch loss: 0.208660 Batch F1: 0.5
Epoch:  514        7 Batch loss: 0.140939 Batch F1: 0.7567567567567567
Epoch:  514        8 Batch loss: 0.204105 Batch F1: 0.5128205128205129
Epoch:  514        9 Batch loss: 0.198979 Batch F1: 0.6829268292682927
Epoch:  514       10 Batch loss: 0.176154 Batch F1: 0.7346938775510204
Epoch:  514       11 Batch loss: 0.177844 Batch F1: 0.6829268292682926
Epoch:  514       12 Batch loss: 0.178037 Batch F1: 0.7999999999999999
Train Avg Loss  514: 0.173475

Train Avg F1  514: 0.7070340742826824

Val Avg Loss  514: 0.182761

Val Avg F1  514:  0.6729510425162599

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 515
--------------------------------------------------------------
Epoch:  515        1 Batch loss: 0.161104 Batch F1: 0.7924528301886792
Epoch:  515        2 Batch loss: 0.147851 Batch F1: 0.631578947368421
Epoch:  515        3 Batch loss: 0.185778 Batch F1: 0.6341463414634148
Epoch:  515        4 Batch loss: 0.180137 Batch F1: 0.6923076923076924
Epoch:  515        5 Batch loss: 0.189117 Batch F1: 0.72
Epoch:  515        6 Batch loss: 0.180077 Batch F1: 0.6666666666666667
Epoch:  515        7 Batch loss: 0.176322 Batch F1: 0.723404255319149
Epoch:  515        8 Batch loss: 0.174295 Batch F1: 0.6976744186046512
Epoch:  515        9 Batch loss: 0.174077 Batch F1: 0.6153846153846153
Epoch:  515       10 Batch loss: 0.164992 Batch F1: 0.7142857142857143
Epoch:  515       11 Batch loss: 0.177335 Batch F1: 0.6842105263157895
Epoch:  515       12 Batch loss: 0.159593 Batch F1: 0.851063829787234
Train Avg Loss  515: 0.172556

Train Avg F1  515: 0.701931319807669

Val Avg Loss  515: 0.181206

Val Avg F1  515:  0.6761566332218506

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 516
--------------------------------------------------------------
Epoch:  516        1 Batch loss: 0.170730 Batch F1: 0.7450980392156863
Epoch:  516        2 Batch loss: 0.204292 Batch F1: 0.6250000000000001
Epoch:  516        3 Batch loss: 0.186596 Batch F1: 0.6956521739130435
Epoch:  516        4 Batch loss: 0.127301 Batch F1: 0.8888888888888888
Epoch:  516        5 Batch loss: 0.155904 Batch F1: 0.6250000000000001
Epoch:  516        6 Batch loss: 0.169004 Batch F1: 0.7916666666666667
Epoch:  516        7 Batch loss: 0.207015 Batch F1: 0.6086956521739131
Epoch:  516        8 Batch loss: 0.139352 Batch F1: 0.8108108108108109
Epoch:  516        9 Batch loss: 0.173574 Batch F1: 0.7199999999999999
Epoch:  516       10 Batch loss: 0.180956 Batch F1: 0.6976744186046512
Epoch:  516       11 Batch loss: 0.191781 Batch F1: 0.6666666666666666
Epoch:  516       12 Batch loss: 0.179781 Batch F1: 0.7027027027027027
Train Avg Loss  516: 0.173857

Train Avg F1  516: 0.7148213349702526

Val Avg Loss  516: 0.183433

Val Avg F1  516:  0.6573593073593074

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 517
--------------------------------------------------------------
Epoch:  517        1 Batch loss: 0.188875 Batch F1: 0.6046511627906976
Epoch:  517        2 Batch loss: 0.153239 Batch F1: 0.8399999999999999
Epoch:  517        3 Batch loss: 0.141452 Batch F1: 0.742857142857143
Epoch:  517        4 Batch loss: 0.157489 Batch F1: 0.7999999999999999
Epoch:  517        5 Batch loss: 0.175877 Batch F1: 0.723404255319149
Epoch:  517        6 Batch loss: 0.202629 Batch F1: 0.5714285714285714
Epoch:  517        7 Batch loss: 0.160857 Batch F1: 0.830188679245283
Epoch:  517        8 Batch loss: 0.175513 Batch F1: 0.7407407407407408
Epoch:  517        9 Batch loss: 0.186649 Batch F1: 0.6222222222222222
Epoch:  517       10 Batch loss: 0.173482 Batch F1: 0.6111111111111112
Epoch:  517       11 Batch loss: 0.149778 Batch F1: 0.742857142857143
Epoch:  517       12 Batch loss: 0.189021 Batch F1: 0.6285714285714287
Train Avg Loss  517: 0.171239

Train Avg F1  517: 0.7048360380952907

Val Avg Loss  517: 0.184009

Val Avg F1  517:  0.6640297906602255

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 518
--------------------------------------------------------------
Epoch:  518        1 Batch loss: 0.215907 Batch F1: 0.5333333333333333
Epoch:  518        2 Batch loss: 0.156556 Batch F1: 0.7222222222222222
Epoch:  518        3 Batch loss: 0.164186 Batch F1: 0.7843137254901961
Epoch:  518        4 Batch loss: 0.153146 Batch F1: 0.816326530612245
Epoch:  518        5 Batch loss: 0.193890 Batch F1: 0.6382978723404256
Epoch:  518        6 Batch loss: 0.153001 Batch F1: 0.8163265306122449
Epoch:  518        7 Batch loss: 0.166811 Batch F1: 0.761904761904762
Epoch:  518        8 Batch loss: 0.155376 Batch F1: 0.8085106382978724
Epoch:  518        9 Batch loss: 0.171189 Batch F1: 0.6285714285714287
Epoch:  518       10 Batch loss: 0.177312 Batch F1: 0.6511627906976744
Epoch:  518       11 Batch loss: 0.200457 Batch F1: 0.5714285714285714
Epoch:  518       12 Batch loss: 0.158143 Batch F1: 0.7692307692307692
Train Avg Loss  518: 0.172165

Train Avg F1  518: 0.7084690978951453

Val Avg Loss  518: 0.186361

Val Avg F1  518:  0.6758471760797342

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 519
--------------------------------------------------------------
Epoch:  519        1 Batch loss: 0.197784 Batch F1: 0.6666666666666667
Epoch:  519        2 Batch loss: 0.177221 Batch F1: 0.7111111111111111
Epoch:  519        3 Batch loss: 0.192700 Batch F1: 0.5714285714285715
Epoch:  519        4 Batch loss: 0.162927 Batch F1: 0.7441860465116279
Epoch:  519        5 Batch loss: 0.153169 Batch F1: 0.7999999999999999
Epoch:  519        6 Batch loss: 0.201834 Batch F1: 0.6923076923076924
Epoch:  519        7 Batch loss: 0.150219 Batch F1: 0.761904761904762
Epoch:  519        8 Batch loss: 0.178466 Batch F1: 0.7111111111111111
Epoch:  519        9 Batch loss: 0.143084 Batch F1: 0.8260869565217391
Epoch:  519       10 Batch loss: 0.167043 Batch F1: 0.7555555555555555
Epoch:  519       11 Batch loss: 0.186168 Batch F1: 0.5405405405405405
Epoch:  519       12 Batch loss: 0.164548 Batch F1: 0.7500000000000001
Train Avg Loss  519: 0.172930

Train Avg F1  519: 0.7109082511382815

Val Avg Loss  519: 0.181211

Val Avg F1  519:  0.6731941031941032

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 520
--------------------------------------------------------------
Epoch:  520        1 Batch loss: 0.164770 Batch F1: 0.7317073170731708
Epoch:  520        2 Batch loss: 0.198715 Batch F1: 0.5909090909090909
Epoch:  520        3 Batch loss: 0.181694 Batch F1: 0.7307692307692307
Epoch:  520        4 Batch loss: 0.141366 Batch F1: 0.8095238095238095
Epoch:  520        5 Batch loss: 0.160739 Batch F1: 0.7755102040816326
Epoch:  520        6 Batch loss: 0.194032 Batch F1: 0.6666666666666667
Epoch:  520        7 Batch loss: 0.160073 Batch F1: 0.76
Epoch:  520        8 Batch loss: 0.185535 Batch F1: 0.6341463414634146
Epoch:  520        9 Batch loss: 0.181215 Batch F1: 0.6842105263157894
Epoch:  520       10 Batch loss: 0.188680 Batch F1: 0.6046511627906976
Epoch:  520       11 Batch loss: 0.152262 Batch F1: 0.7619047619047619
Epoch:  520       12 Batch loss: 0.149792 Batch F1: 0.823529411764706
Train Avg Loss  520: 0.171573

Train Avg F1  520: 0.7144607102719142

Val Avg Loss  520: 0.182778

Val Avg F1  520:  0.6768966733034678

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 521
--------------------------------------------------------------
Epoch:  521        1 Batch loss: 0.164784 Batch F1: 0.7142857142857143
Epoch:  521        2 Batch loss: 0.174575 Batch F1: 0.7391304347826088
Epoch:  521        3 Batch loss: 0.186264 Batch F1: 0.6341463414634148
Epoch:  521        4 Batch loss: 0.163849 Batch F1: 0.7924528301886792
Epoch:  521        5 Batch loss: 0.164887 Batch F1: 0.7755102040816326
Epoch:  521        6 Batch loss: 0.177510 Batch F1: 0.5555555555555556
Epoch:  521        7 Batch loss: 0.177760 Batch F1: 0.7307692307692307
Epoch:  521        8 Batch loss: 0.170404 Batch F1: 0.711111111111111
Epoch:  521        9 Batch loss: 0.156135 Batch F1: 0.7755102040816326
Epoch:  521       10 Batch loss: 0.169348 Batch F1: 0.7317073170731708
Epoch:  521       11 Batch loss: 0.172034 Batch F1: 0.6976744186046512
Epoch:  521       12 Batch loss: 0.172844 Batch F1: 0.5714285714285714
Train Avg Loss  521: 0.170866

Train Avg F1  521: 0.702440161118831

Val Avg Loss  521: 0.188620

Val Avg F1  521:  0.6469168636721828

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 522
--------------------------------------------------------------
Epoch:  522        1 Batch loss: 0.189403 Batch F1: 0.5555555555555555
Epoch:  522        2 Batch loss: 0.134961 Batch F1: 0.6666666666666666
Epoch:  522        3 Batch loss: 0.211837 Batch F1: 0.5294117647058824
Epoch:  522        4 Batch loss: 0.184675 Batch F1: 0.7111111111111111
Epoch:  522        5 Batch loss: 0.209872 Batch F1: 0.7037037037037038
Epoch:  522        6 Batch loss: 0.151087 Batch F1: 0.7619047619047619
Epoch:  522        7 Batch loss: 0.169609 Batch F1: 0.76
Epoch:  522        8 Batch loss: 0.159853 Batch F1: 0.6956521739130435
Epoch:  522        9 Batch loss: 0.196332 Batch F1: 0.5853658536585366
Epoch:  522       10 Batch loss: 0.198098 Batch F1: 0.48484848484848486
Epoch:  522       11 Batch loss: 0.152958 Batch F1: 0.8085106382978724
Epoch:  522       12 Batch loss: 0.167216 Batch F1: 0.7999999999999999
Train Avg Loss  522: 0.177158

Train Avg F1  522: 0.6718942261971349

Val Avg Loss  522: 0.185726

Val Avg F1  522:  0.682689299123905

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 523
--------------------------------------------------------------
Epoch:  523        1 Batch loss: 0.181948 Batch F1: 0.7058823529411765
Epoch:  523        2 Batch loss: 0.154322 Batch F1: 0.9056603773584904
Epoch:  523        3 Batch loss: 0.175726 Batch F1: 0.8000000000000002
Epoch:  523        4 Batch loss: 0.166377 Batch F1: 0.8888888888888888
Epoch:  523        5 Batch loss: 0.199455 Batch F1: 0.68
Epoch:  523        6 Batch loss: 0.156435 Batch F1: 0.761904761904762
Epoch:  523        7 Batch loss: 0.193187 Batch F1: 0.6511627906976745
Epoch:  523        8 Batch loss: 0.143855 Batch F1: 0.7894736842105263
Epoch:  523        9 Batch loss: 0.157478 Batch F1: 0.7
Epoch:  523       10 Batch loss: 0.150048 Batch F1: 0.8260869565217391
Epoch:  523       11 Batch loss: 0.215475 Batch F1: 0.627450980392157
Epoch:  523       12 Batch loss: 0.197762 Batch F1: 0.5945945945945946
Train Avg Loss  523: 0.174339

Train Avg F1  523: 0.7442587822925009

Val Avg Loss  523: 0.182901

Val Avg F1  523:  0.6729734064064483

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 524
--------------------------------------------------------------
Epoch:  524        1 Batch loss: 0.167079 Batch F1: 0.7
Epoch:  524        2 Batch loss: 0.188807 Batch F1: 0.6190476190476191
Epoch:  524        3 Batch loss: 0.144628 Batch F1: 0.6857142857142857
Epoch:  524        4 Batch loss: 0.171434 Batch F1: 0.723404255319149
Epoch:  524        5 Batch loss: 0.139682 Batch F1: 0.7096774193548386
Epoch:  524        6 Batch loss: 0.161103 Batch F1: 0.7317073170731707
Epoch:  524        7 Batch loss: 0.158614 Batch F1: 0.717948717948718
Epoch:  524        8 Batch loss: 0.206556 Batch F1: 0.625
Epoch:  524        9 Batch loss: 0.152469 Batch F1: 0.8620689655172413
Epoch:  524       10 Batch loss: 0.185009 Batch F1: 0.6521739130434783
Epoch:  524       11 Batch loss: 0.189100 Batch F1: 0.6923076923076923
Epoch:  524       12 Batch loss: 0.156122 Batch F1: 0.8571428571428572
Train Avg Loss  524: 0.168384

Train Avg F1  524: 0.7146827535390875

Val Avg Loss  524: 0.199483

Val Avg F1  524:  0.8108219176451636

Optimal Val loss (Epoch 430): 0.17977261543273926

Epoch 525
--------------------------------------------------------------
Epoch:  525        1 Batch loss: 0.193859 Batch F1: 0.8518518518518519
Epoch:  525        2 Batch loss: 0.135021 Batch F1: 0.8979591836734694
Epoch:  525        3 Batch loss: 0.167958 Batch F1: 0.7555555555555555
Epoch:  525        4 Batch loss: 0.198115 Batch F1: 0.6792452830188679
Epoch:  525        5 Batch loss: 0.170045 Batch F1: 0.6829268292682926
Epoch:  525        6 Batch loss: 0.212761 Batch F1: 0.5238095238095238
Epoch:  525        7 Batch loss: 0.159349 Batch F1: 0.6486486486486486
Epoch:  525        8 Batch loss: 0.168175 Batch F1: 0.8
Epoch:  525        9 Batch loss: 0.163792 Batch F1: 0.7142857142857143
Epoch:  525       10 Batch loss: 0.166083 Batch F1: 0.6842105263157895
Epoch:  525       11 Batch loss: 0.170159 Batch F1: 0.7142857142857143
Epoch:  525       12 Batch loss: 0.168471 Batch F1: 0.6666666666666667
Train Avg Loss  525: 0.172816

Train Avg F1  525: 0.7182871247816744

Val Avg Loss  525: 0.179496

Val Avg F1  525:  0.6770833333333334

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 526
--------------------------------------------------------------
Epoch:  526        1 Batch loss: 0.184716 Batch F1: 0.5853658536585366
Epoch:  526        2 Batch loss: 0.165803 Batch F1: 0.7391304347826088
Epoch:  526        3 Batch loss: 0.198593 Batch F1: 0.6808510638297872
Epoch:  526        4 Batch loss: 0.163367 Batch F1: 0.7659574468085107
Epoch:  526        5 Batch loss: 0.156925 Batch F1: 0.7441860465116279
Epoch:  526        6 Batch loss: 0.180155 Batch F1: 0.6666666666666666
Epoch:  526        7 Batch loss: 0.148853 Batch F1: 0.8085106382978723
Epoch:  526        8 Batch loss: 0.155350 Batch F1: 0.7659574468085107
Epoch:  526        9 Batch loss: 0.196855 Batch F1: 0.6222222222222222
Epoch:  526       10 Batch loss: 0.144417 Batch F1: 0.7567567567567567
Epoch:  526       11 Batch loss: 0.163046 Batch F1: 0.7317073170731707
Epoch:  526       12 Batch loss: 0.176177 Batch F1: 0.6829268292682926
Train Avg Loss  526: 0.169521

Train Avg F1  526: 0.7125198935570469

Val Avg Loss  526: 0.182626

Val Avg F1  526:  0.6780173396725685

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 527
--------------------------------------------------------------
Epoch:  527        1 Batch loss: 0.198057 Batch F1: 0.5777777777777777
Epoch:  527        2 Batch loss: 0.176467 Batch F1: 0.6976744186046512
Epoch:  527        3 Batch loss: 0.166112 Batch F1: 0.76
Epoch:  527        4 Batch loss: 0.158252 Batch F1: 0.6666666666666666
Epoch:  527        5 Batch loss: 0.138213 Batch F1: 0.8749999999999999
Epoch:  527        6 Batch loss: 0.161527 Batch F1: 0.7111111111111111
Epoch:  527        7 Batch loss: 0.206713 Batch F1: 0.5365853658536585
Epoch:  527        8 Batch loss: 0.163210 Batch F1: 0.717948717948718
Epoch:  527        9 Batch loss: 0.176241 Batch F1: 0.7499999999999999
Epoch:  527       10 Batch loss: 0.177902 Batch F1: 0.76
Epoch:  527       11 Batch loss: 0.162654 Batch F1: 0.6666666666666666
Epoch:  527       12 Batch loss: 0.159827 Batch F1: 0.7804878048780487
Train Avg Loss  527: 0.170431

Train Avg F1  527: 0.7083265441256081

Val Avg Loss  527: 0.182229

Val Avg F1  527:  0.6741770014375821

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 528
--------------------------------------------------------------
Epoch:  528        1 Batch loss: 0.167546 Batch F1: 0.7083333333333333
Epoch:  528        2 Batch loss: 0.175451 Batch F1: 0.6666666666666666
Epoch:  528        3 Batch loss: 0.205631 Batch F1: 0.6222222222222222
Epoch:  528        4 Batch loss: 0.155039 Batch F1: 0.8363636363636363
Epoch:  528        5 Batch loss: 0.180400 Batch F1: 0.7
Epoch:  528        6 Batch loss: 0.158559 Batch F1: 0.8085106382978724
Epoch:  528        7 Batch loss: 0.186235 Batch F1: 0.6
Epoch:  528        8 Batch loss: 0.150705 Batch F1: 0.7222222222222222
Epoch:  528        9 Batch loss: 0.173366 Batch F1: 0.711111111111111
Epoch:  528       10 Batch loss: 0.163668 Batch F1: 0.7272727272727273
Epoch:  528       11 Batch loss: 0.186736 Batch F1: 0.6222222222222222
Epoch:  528       12 Batch loss: 0.153461 Batch F1: 0.7894736842105262
Train Avg Loss  528: 0.171400

Train Avg F1  528: 0.7095332053268782

Val Avg Loss  528: 0.183805

Val Avg F1  528:  0.6751381232278242

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 529
--------------------------------------------------------------
Epoch:  529        1 Batch loss: 0.169910 Batch F1: 0.7142857142857143
Epoch:  529        2 Batch loss: 0.168515 Batch F1: 0.6842105263157895
Epoch:  529        3 Batch loss: 0.198881 Batch F1: 0.6521739130434783
Epoch:  529        4 Batch loss: 0.169442 Batch F1: 0.7272727272727272
Epoch:  529        5 Batch loss: 0.163084 Batch F1: 0.6842105263157895
Epoch:  529        6 Batch loss: 0.158697 Batch F1: 0.8163265306122449
Epoch:  529        7 Batch loss: 0.159318 Batch F1: 0.7555555555555556
Epoch:  529        8 Batch loss: 0.180512 Batch F1: 0.6666666666666666
Epoch:  529        9 Batch loss: 0.174587 Batch F1: 0.6808510638297872
Epoch:  529       10 Batch loss: 0.175422 Batch F1: 0.7391304347826088
Epoch:  529       11 Batch loss: 0.176905 Batch F1: 0.7555555555555555
Epoch:  529       12 Batch loss: 0.182962 Batch F1: 0.6976744186046512
Train Avg Loss  529: 0.173186

Train Avg F1  529: 0.714492802736714

Val Avg Loss  529: 0.184187

Val Avg F1  529:  0.6691864589503407

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 530
--------------------------------------------------------------
Epoch:  530        1 Batch loss: 0.174319 Batch F1: 0.6666666666666666
Epoch:  530        2 Batch loss: 0.171872 Batch F1: 0.7441860465116279
Epoch:  530        3 Batch loss: 0.167891 Batch F1: 0.7755102040816326
Epoch:  530        4 Batch loss: 0.169129 Batch F1: 0.7555555555555556
Epoch:  530        5 Batch loss: 0.184087 Batch F1: 0.5641025641025642
Epoch:  530        6 Batch loss: 0.151769 Batch F1: 0.782608695652174
Epoch:  530        7 Batch loss: 0.155627 Batch F1: 0.7924528301886793
Epoch:  530        8 Batch loss: 0.158224 Batch F1: 0.7368421052631579
Epoch:  530        9 Batch loss: 0.193589 Batch F1: 0.6
Epoch:  530       10 Batch loss: 0.203092 Batch F1: 0.6190476190476191
Epoch:  530       11 Batch loss: 0.176765 Batch F1: 0.6956521739130435
Epoch:  530       12 Batch loss: 0.175791 Batch F1: 0.761904761904762
Train Avg Loss  530: 0.173513

Train Avg F1  530: 0.7078774352406235

Val Avg Loss  530: 0.191821

Val Avg F1  530:  0.6728191192865107

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 531
--------------------------------------------------------------
Epoch:  531        1 Batch loss: 0.168909 Batch F1: 0.7555555555555556
Epoch:  531        2 Batch loss: 0.151325 Batch F1: 0.8518518518518519
Epoch:  531        3 Batch loss: 0.182079 Batch F1: 0.5714285714285714
Epoch:  531        4 Batch loss: 0.182599 Batch F1: 0.723404255319149
Epoch:  531        5 Batch loss: 0.168738 Batch F1: 0.7843137254901961
Epoch:  531        6 Batch loss: 0.178376 Batch F1: 0.6829268292682926
Epoch:  531        7 Batch loss: 0.160177 Batch F1: 0.7659574468085107
Epoch:  531        8 Batch loss: 0.176906 Batch F1: 0.6956521739130435
Epoch:  531        9 Batch loss: 0.165523 Batch F1: 0.7317073170731707
Epoch:  531       10 Batch loss: 0.166609 Batch F1: 0.6285714285714286
Epoch:  531       11 Batch loss: 0.193582 Batch F1: 0.6382978723404256
Epoch:  531       12 Batch loss: 0.186917 Batch F1: 0.6111111111111112
Train Avg Loss  531: 0.173478

Train Avg F1  531: 0.7033981782276088

Val Avg Loss  531: 0.181968

Val Avg F1  531:  0.6710635283861828

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 532
--------------------------------------------------------------
Epoch:  532        1 Batch loss: 0.174597 Batch F1: 0.7692307692307692
Epoch:  532        2 Batch loss: 0.156936 Batch F1: 0.7555555555555555
Epoch:  532        3 Batch loss: 0.201965 Batch F1: 0.55
Epoch:  532        4 Batch loss: 0.178951 Batch F1: 0.6956521739130435
Epoch:  532        5 Batch loss: 0.162208 Batch F1: 0.7727272727272727
Epoch:  532        6 Batch loss: 0.165214 Batch F1: 0.7659574468085107
Epoch:  532        7 Batch loss: 0.177489 Batch F1: 0.5555555555555556
Epoch:  532        8 Batch loss: 0.171659 Batch F1: 0.7272727272727273
Epoch:  532        9 Batch loss: 0.172915 Batch F1: 0.6956521739130435
Epoch:  532       10 Batch loss: 0.167799 Batch F1: 0.7111111111111111
Epoch:  532       11 Batch loss: 0.154192 Batch F1: 0.7727272727272727
Epoch:  532       12 Batch loss: 0.159058 Batch F1: 0.7222222222222223
Train Avg Loss  532: 0.170249

Train Avg F1  532: 0.7078053567530903

Val Avg Loss  532: 0.180512

Val Avg F1  532:  0.6747866804150822

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 533
--------------------------------------------------------------
Epoch:  533        1 Batch loss: 0.178016 Batch F1: 0.7272727272727272
Epoch:  533        2 Batch loss: 0.174430 Batch F1: 0.7346938775510204
Epoch:  533        3 Batch loss: 0.162191 Batch F1: 0.6486486486486486
Epoch:  533        4 Batch loss: 0.141791 Batch F1: 0.8
Epoch:  533        5 Batch loss: 0.182644 Batch F1: 0.6666666666666666
Epoch:  533        6 Batch loss: 0.165870 Batch F1: 0.7555555555555555
Epoch:  533        7 Batch loss: 0.144274 Batch F1: 0.8627450980392156
Epoch:  533        8 Batch loss: 0.170772 Batch F1: 0.72
Epoch:  533        9 Batch loss: 0.158026 Batch F1: 0.6285714285714286
Epoch:  533       10 Batch loss: 0.175680 Batch F1: 0.6341463414634148
Epoch:  533       11 Batch loss: 0.190586 Batch F1: 0.6808510638297872
Epoch:  533       12 Batch loss: 0.185295 Batch F1: 0.606060606060606
Train Avg Loss  533: 0.169131

Train Avg F1  533: 0.7054343344715891

Val Avg Loss  533: 0.182440

Val Avg F1  533:  0.676705336748834

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 534
--------------------------------------------------------------
Epoch:  534        1 Batch loss: 0.181010 Batch F1: 0.6956521739130435
Epoch:  534        2 Batch loss: 0.162716 Batch F1: 0.6976744186046512
Epoch:  534        3 Batch loss: 0.138321 Batch F1: 0.8095238095238095
Epoch:  534        4 Batch loss: 0.170862 Batch F1: 0.7234042553191491
Epoch:  534        5 Batch loss: 0.198624 Batch F1: 0.6222222222222223
Epoch:  534        6 Batch loss: 0.148177 Batch F1: 0.7500000000000001
Epoch:  534        7 Batch loss: 0.157194 Batch F1: 0.7441860465116279
Epoch:  534        8 Batch loss: 0.171288 Batch F1: 0.6666666666666666
Epoch:  534        9 Batch loss: 0.166268 Batch F1: 0.6285714285714286
Epoch:  534       10 Batch loss: 0.164750 Batch F1: 0.7692307692307693
Epoch:  534       11 Batch loss: 0.178863 Batch F1: 0.6808510638297872
Epoch:  534       12 Batch loss: 0.187393 Batch F1: 0.7441860465116279
Train Avg Loss  534: 0.168789

Train Avg F1  534: 0.7110140750753987

Val Avg Loss  534: 0.180673

Val Avg F1  534:  0.6728428513505084

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 535
--------------------------------------------------------------
Epoch:  535        1 Batch loss: 0.142459 Batch F1: 0.7804878048780488
Epoch:  535        2 Batch loss: 0.202040 Batch F1: 0.627450980392157
Epoch:  535        3 Batch loss: 0.193949 Batch F1: 0.6363636363636365
Epoch:  535        4 Batch loss: 0.167213 Batch F1: 0.7307692307692306
Epoch:  535        5 Batch loss: 0.150255 Batch F1: 0.6896551724137931
Epoch:  535        6 Batch loss: 0.192050 Batch F1: 0.6
Epoch:  535        7 Batch loss: 0.158886 Batch F1: 0.7
Epoch:  535        8 Batch loss: 0.152598 Batch F1: 0.851851851851852
Epoch:  535        9 Batch loss: 0.182882 Batch F1: 0.6808510638297872
Epoch:  535       10 Batch loss: 0.179423 Batch F1: 0.7200000000000001
Epoch:  535       11 Batch loss: 0.160347 Batch F1: 0.7804878048780488
Epoch:  535       12 Batch loss: 0.163519 Batch F1: 0.7222222222222222
Train Avg Loss  535: 0.170468

Train Avg F1  535: 0.710011647299898

Val Avg Loss  535: 0.183265

Val Avg F1  535:  0.6737983431297385

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 536
--------------------------------------------------------------
Epoch:  536        1 Batch loss: 0.146978 Batch F1: 0.7222222222222222
Epoch:  536        2 Batch loss: 0.169448 Batch F1: 0.7346938775510204
Epoch:  536        3 Batch loss: 0.169133 Batch F1: 0.7916666666666666
Epoch:  536        4 Batch loss: 0.175135 Batch F1: 0.7307692307692307
Epoch:  536        5 Batch loss: 0.174237 Batch F1: 0.7083333333333334
Epoch:  536        6 Batch loss: 0.172172 Batch F1: 0.75
Epoch:  536        7 Batch loss: 0.185342 Batch F1: 0.6530612244897959
Epoch:  536        8 Batch loss: 0.159167 Batch F1: 0.7272727272727272
Epoch:  536        9 Batch loss: 0.153397 Batch F1: 0.7368421052631579
Epoch:  536       10 Batch loss: 0.207446 Batch F1: 0.625
Epoch:  536       11 Batch loss: 0.163880 Batch F1: 0.6829268292682926
Epoch:  536       12 Batch loss: 0.155486 Batch F1: 0.6857142857142857
Train Avg Loss  536: 0.169318

Train Avg F1  536: 0.7123752085458944

Val Avg Loss  536: 0.183118

Val Avg F1  536:  0.6728569370657771

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 537
--------------------------------------------------------------
Epoch:  537        1 Batch loss: 0.177321 Batch F1: 0.7346938775510204
Epoch:  537        2 Batch loss: 0.166687 Batch F1: 0.6486486486486486
Epoch:  537        3 Batch loss: 0.166307 Batch F1: 0.7924528301886792
Epoch:  537        4 Batch loss: 0.146799 Batch F1: 0.7428571428571428
Epoch:  537        5 Batch loss: 0.185563 Batch F1: 0.6500000000000001
Epoch:  537        6 Batch loss: 0.172196 Batch F1: 0.75
Epoch:  537        7 Batch loss: 0.161414 Batch F1: 0.76
Epoch:  537        8 Batch loss: 0.182404 Batch F1: 0.6521739130434783
Epoch:  537        9 Batch loss: 0.170337 Batch F1: 0.7843137254901961
Epoch:  537       10 Batch loss: 0.156452 Batch F1: 0.9166666666666666
Epoch:  537       11 Batch loss: 0.192561 Batch F1: 0.5500000000000002
Epoch:  537       12 Batch loss: 0.171780 Batch F1: 0.7222222222222222
Train Avg Loss  537: 0.170818

Train Avg F1  537: 0.7253357522223379

Val Avg Loss  537: 0.182141

Val Avg F1  537:  0.6772834512976069

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 538
--------------------------------------------------------------
Epoch:  538        1 Batch loss: 0.156776 Batch F1: 0.7441860465116279
Epoch:  538        2 Batch loss: 0.178722 Batch F1: 0.7083333333333334
Epoch:  538        3 Batch loss: 0.164786 Batch F1: 0.7499999999999999
Epoch:  538        4 Batch loss: 0.155498 Batch F1: 0.761904761904762
Epoch:  538        5 Batch loss: 0.213208 Batch F1: 0.5652173913043478
Epoch:  538        6 Batch loss: 0.171581 Batch F1: 0.6829268292682926
Epoch:  538        7 Batch loss: 0.174459 Batch F1: 0.744186046511628
Epoch:  538        8 Batch loss: 0.192410 Batch F1: 0.6382978723404256
Epoch:  538        9 Batch loss: 0.175501 Batch F1: 0.6511627906976744
Epoch:  538       10 Batch loss: 0.168154 Batch F1: 0.7755102040816326
Epoch:  538       11 Batch loss: 0.144340 Batch F1: 0.8163265306122449
Epoch:  538       12 Batch loss: 0.158962 Batch F1: 0.6923076923076924
Train Avg Loss  538: 0.171200

Train Avg F1  538: 0.7108632915728051

Val Avg Loss  538: 0.180856

Val Avg F1  538:  0.6751096396005211

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 539
--------------------------------------------------------------
Epoch:  539        1 Batch loss: 0.164392 Batch F1: 0.6976744186046512
Epoch:  539        2 Batch loss: 0.164728 Batch F1: 0.8214285714285715
Epoch:  539        3 Batch loss: 0.191724 Batch F1: 0.6530612244897959
Epoch:  539        4 Batch loss: 0.153758 Batch F1: 0.7906976744186046
Epoch:  539        5 Batch loss: 0.169316 Batch F1: 0.72
Epoch:  539        6 Batch loss: 0.153868 Batch F1: 0.625
Epoch:  539        7 Batch loss: 0.159636 Batch F1: 0.7317073170731706
Epoch:  539        8 Batch loss: 0.180569 Batch F1: 0.6666666666666666
Epoch:  539        9 Batch loss: 0.176459 Batch F1: 0.7111111111111111
Epoch:  539       10 Batch loss: 0.171287 Batch F1: 0.6341463414634146
Epoch:  539       11 Batch loss: 0.140401 Batch F1: 0.8444444444444444
Epoch:  539       12 Batch loss: 0.199475 Batch F1: 0.5714285714285714
Train Avg Loss  539: 0.168801

Train Avg F1  539: 0.7056138617607502

Val Avg Loss  539: 0.180126

Val Avg F1  539:  0.6750156445556946

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 540
--------------------------------------------------------------
Epoch:  540        1 Batch loss: 0.159301 Batch F1: 0.717948717948718
Epoch:  540        2 Batch loss: 0.208406 Batch F1: 0.6545454545454547
Epoch:  540        3 Batch loss: 0.172756 Batch F1: 0.723404255319149
Epoch:  540        4 Batch loss: 0.162097 Batch F1: 0.7111111111111111
Epoch:  540        5 Batch loss: 0.193842 Batch F1: 0.6521739130434783
Epoch:  540        6 Batch loss: 0.149555 Batch F1: 0.717948717948718
Epoch:  540        7 Batch loss: 0.162508 Batch F1: 0.7000000000000001
Epoch:  540        8 Batch loss: 0.160980 Batch F1: 0.6829268292682926
Epoch:  540        9 Batch loss: 0.180063 Batch F1: 0.7058823529411765
Epoch:  540       10 Batch loss: 0.164349 Batch F1: 0.7391304347826089
Epoch:  540       11 Batch loss: 0.140442 Batch F1: 0.787878787878788
Epoch:  540       12 Batch loss: 0.169014 Batch F1: 0.7906976744186046
Train Avg Loss  540: 0.168609

Train Avg F1  540: 0.7153040207671751

Val Avg Loss  540: 0.180358

Val Avg F1  540:  0.6744318181818181

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 541
--------------------------------------------------------------
Epoch:  541        1 Batch loss: 0.136269 Batch F1: 0.6875
Epoch:  541        2 Batch loss: 0.167587 Batch F1: 0.8076923076923076
Epoch:  541        3 Batch loss: 0.208928 Batch F1: 0.6
Epoch:  541        4 Batch loss: 0.177378 Batch F1: 0.693877551020408
Epoch:  541        5 Batch loss: 0.165360 Batch F1: 0.717948717948718
Epoch:  541        6 Batch loss: 0.164814 Batch F1: 0.7843137254901961
Epoch:  541        7 Batch loss: 0.176560 Batch F1: 0.7346938775510204
Epoch:  541        8 Batch loss: 0.190946 Batch F1: 0.6
Epoch:  541        9 Batch loss: 0.155950 Batch F1: 0.7317073170731707
Epoch:  541       10 Batch loss: 0.159733 Batch F1: 0.6060606060606061
Epoch:  541       11 Batch loss: 0.144378 Batch F1: 0.7727272727272727
Epoch:  541       12 Batch loss: 0.186353 Batch F1: 0.7555555555555555
Train Avg Loss  541: 0.169521

Train Avg F1  541: 0.7076730775932711

Val Avg Loss  541: 0.181603

Val Avg F1  541:  0.6777519379844961

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 542
--------------------------------------------------------------
Epoch:  542        1 Batch loss: 0.158559 Batch F1: 0.7843137254901961
Epoch:  542        2 Batch loss: 0.199209 Batch F1: 0.6666666666666667
Epoch:  542        3 Batch loss: 0.178573 Batch F1: 0.7234042553191491
Epoch:  542        4 Batch loss: 0.173281 Batch F1: 0.6
Epoch:  542        5 Batch loss: 0.160780 Batch F1: 0.7317073170731706
Epoch:  542        6 Batch loss: 0.172375 Batch F1: 0.7083333333333334
Epoch:  542        7 Batch loss: 0.149849 Batch F1: 0.6451612903225806
Epoch:  542        8 Batch loss: 0.168532 Batch F1: 0.6829268292682926
Epoch:  542        9 Batch loss: 0.159532 Batch F1: 0.7555555555555555
Epoch:  542       10 Batch loss: 0.145860 Batch F1: 0.8
Epoch:  542       11 Batch loss: 0.170279 Batch F1: 0.7450980392156864
Epoch:  542       12 Batch loss: 0.184385 Batch F1: 0.6842105263157895
Train Avg Loss  542: 0.168434

Train Avg F1  542: 0.7106147948800351

Val Avg Loss  542: 0.181714

Val Avg F1  542:  0.6727837711069419

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 543
--------------------------------------------------------------
Epoch:  543        1 Batch loss: 0.180536 Batch F1: 0.6500000000000001
Epoch:  543        2 Batch loss: 0.178928 Batch F1: 0.7692307692307692
Epoch:  543        3 Batch loss: 0.147986 Batch F1: 0.8
Epoch:  543        4 Batch loss: 0.156052 Batch F1: 0.7027027027027027
Epoch:  543        5 Batch loss: 0.165180 Batch F1: 0.7441860465116279
Epoch:  543        6 Batch loss: 0.167589 Batch F1: 0.7
Epoch:  543        7 Batch loss: 0.199258 Batch F1: 0.6
Epoch:  543        8 Batch loss: 0.186419 Batch F1: 0.679245283018868
Epoch:  543        9 Batch loss: 0.169775 Batch F1: 0.7
Epoch:  543       10 Batch loss: 0.189892 Batch F1: 0.6938775510204083
Epoch:  543       11 Batch loss: 0.159917 Batch F1: 0.7499999999999999
Epoch:  543       12 Batch loss: 0.157963 Batch F1: 0.7368421052631577
Train Avg Loss  543: 0.171625

Train Avg F1  543: 0.7105070381456278

Val Avg Loss  543: 0.180992

Val Avg F1  543:  0.672991452991453

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 544
--------------------------------------------------------------
Epoch:  544        1 Batch loss: 0.161168 Batch F1: 0.6829268292682927
Epoch:  544        2 Batch loss: 0.157521 Batch F1: 0.717948717948718
Epoch:  544        3 Batch loss: 0.183421 Batch F1: 0.6363636363636365
Epoch:  544        4 Batch loss: 0.151063 Batch F1: 0.8
Epoch:  544        5 Batch loss: 0.184031 Batch F1: 0.6511627906976744
Epoch:  544        6 Batch loss: 0.175780 Batch F1: 0.7391304347826085
Epoch:  544        7 Batch loss: 0.162143 Batch F1: 0.76
Epoch:  544        8 Batch loss: 0.170400 Batch F1: 0.6829268292682926
Epoch:  544        9 Batch loss: 0.183338 Batch F1: 0.5945945945945946
Epoch:  544       10 Batch loss: 0.157664 Batch F1: 0.7916666666666667
Epoch:  544       11 Batch loss: 0.178189 Batch F1: 0.7719298245614034
Epoch:  544       12 Batch loss: 0.180616 Batch F1: 0.6470588235294118
Train Avg Loss  544: 0.170444

Train Avg F1  544: 0.7063090956401082

Val Avg Loss  544: 0.182881

Val Avg F1  544:  0.6729545454545454

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 545
--------------------------------------------------------------
Epoch:  545        1 Batch loss: 0.188926 Batch F1: 0.6923076923076923
Epoch:  545        2 Batch loss: 0.202431 Batch F1: 0.5789473684210527
Epoch:  545        3 Batch loss: 0.183843 Batch F1: 0.6190476190476191
Epoch:  545        4 Batch loss: 0.191861 Batch F1: 0.7169811320754716
Epoch:  545        5 Batch loss: 0.182326 Batch F1: 0.4848484848484849
Epoch:  545        6 Batch loss: 0.168857 Batch F1: 0.6829268292682927
Epoch:  545        7 Batch loss: 0.184321 Batch F1: 0.7692307692307692
Epoch:  545        8 Batch loss: 0.141818 Batch F1: 0.7894736842105263
Epoch:  545        9 Batch loss: 0.175551 Batch F1: 0.631578947368421
Epoch:  545       10 Batch loss: 0.138226 Batch F1: 0.8461538461538461
Epoch:  545       11 Batch loss: 0.147230 Batch F1: 0.7804878048780488
Epoch:  545       12 Batch loss: 0.162283 Batch F1: 0.7222222222222222
Train Avg Loss  545: 0.172306

Train Avg F1  545: 0.6928505333360372

Val Avg Loss  545: 0.181407

Val Avg F1  545:  0.6751685562463696

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 546
--------------------------------------------------------------
Epoch:  546        1 Batch loss: 0.154861 Batch F1: 0.8214285714285714
Epoch:  546        2 Batch loss: 0.196132 Batch F1: 0.6382978723404256
Epoch:  546        3 Batch loss: 0.152222 Batch F1: 0.7804878048780488
Epoch:  546        4 Batch loss: 0.149283 Batch F1: 0.7906976744186046
Epoch:  546        5 Batch loss: 0.192341 Batch F1: 0.6363636363636365
Epoch:  546        6 Batch loss: 0.166301 Batch F1: 0.7391304347826085
Epoch:  546        7 Batch loss: 0.180382 Batch F1: 0.6976744186046512
Epoch:  546        8 Batch loss: 0.189041 Batch F1: 0.5405405405405405
Epoch:  546        9 Batch loss: 0.152687 Batch F1: 0.7027027027027026
Epoch:  546       10 Batch loss: 0.165242 Batch F1: 0.6976744186046512
Epoch:  546       11 Batch loss: 0.160460 Batch F1: 0.7843137254901961
Epoch:  546       12 Batch loss: 0.161498 Batch F1: 0.6666666666666665
Train Avg Loss  546: 0.168371

Train Avg F1  546: 0.7079982055684421

Val Avg Loss  546: 0.189930

Val Avg F1  546:  0.8507568711399818

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 547
--------------------------------------------------------------
Epoch:  547        1 Batch loss: 0.157894 Batch F1: 0.9333333333333332
Epoch:  547        2 Batch loss: 0.168035 Batch F1: 0.8571428571428572
Epoch:  547        3 Batch loss: 0.154915 Batch F1: 0.7441860465116279
Epoch:  547        4 Batch loss: 0.169758 Batch F1: 0.6486486486486486
Epoch:  547        5 Batch loss: 0.207304 Batch F1: 0.5957446808510638
Epoch:  547        6 Batch loss: 0.165591 Batch F1: 0.7999999999999999
Epoch:  547        7 Batch loss: 0.187185 Batch F1: 0.7272727272727272
Epoch:  547        8 Batch loss: 0.174196 Batch F1: 0.723404255319149
Epoch:  547        9 Batch loss: 0.184352 Batch F1: 0.723404255319149
Epoch:  547       10 Batch loss: 0.184181 Batch F1: 0.6666666666666666
Epoch:  547       11 Batch loss: 0.173638 Batch F1: 0.7169811320754718
Epoch:  547       12 Batch loss: 0.150390 Batch F1: 0.6206896551724138
Train Avg Loss  547: 0.173120

Train Avg F1  547: 0.7297895215260924

Val Avg Loss  547: 0.185604

Val Avg F1  547:  0.67675395256917

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 548
--------------------------------------------------------------
Epoch:  548        1 Batch loss: 0.182773 Batch F1: 0.619047619047619
Epoch:  548        2 Batch loss: 0.180844 Batch F1: 0.6511627906976745
Epoch:  548        3 Batch loss: 0.182122 Batch F1: 0.7083333333333334
Epoch:  548        4 Batch loss: 0.176525 Batch F1: 0.6666666666666667
Epoch:  548        5 Batch loss: 0.183800 Batch F1: 0.5
Epoch:  548        6 Batch loss: 0.163207 Batch F1: 0.7317073170731708
Epoch:  548        7 Batch loss: 0.178028 Batch F1: 0.7450980392156864
Epoch:  548        8 Batch loss: 0.157825 Batch F1: 0.7916666666666667
Epoch:  548        9 Batch loss: 0.145541 Batch F1: 0.7567567567567567
Epoch:  548       10 Batch loss: 0.167479 Batch F1: 0.7346938775510204
Epoch:  548       11 Batch loss: 0.179931 Batch F1: 0.6956521739130435
Epoch:  548       12 Batch loss: 0.134414 Batch F1: 0.888888888888889
Train Avg Loss  548: 0.169374

Train Avg F1  548: 0.7074728441508773

Val Avg Loss  548: 0.183746

Val Avg F1  548:  0.6780429276973947

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 549
--------------------------------------------------------------
Epoch:  549        1 Batch loss: 0.192380 Batch F1: 0.6363636363636365
Epoch:  549        2 Batch loss: 0.150144 Batch F1: 0.84
Epoch:  549        3 Batch loss: 0.181777 Batch F1: 0.5555555555555555
Epoch:  549        4 Batch loss: 0.147256 Batch F1: 0.761904761904762
Epoch:  549        5 Batch loss: 0.179804 Batch F1: 0.6818181818181818
Epoch:  549        6 Batch loss: 0.164022 Batch F1: 0.7391304347826085
Epoch:  549        7 Batch loss: 0.187811 Batch F1: 0.6190476190476191
Epoch:  549        8 Batch loss: 0.167352 Batch F1: 0.6976744186046512
Epoch:  549        9 Batch loss: 0.188937 Batch F1: 0.6521739130434783
Epoch:  549       10 Batch loss: 0.148643 Batch F1: 0.7692307692307693
Epoch:  549       11 Batch loss: 0.159179 Batch F1: 0.8148148148148148
Epoch:  549       12 Batch loss: 0.174766 Batch F1: 0.717948717948718
Train Avg Loss  549: 0.170172

Train Avg F1  549: 0.7071385685928995

Val Avg Loss  549: 0.181791

Val Avg F1  549:  0.6752812404986319

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 550
--------------------------------------------------------------
Epoch:  550        1 Batch loss: 0.171982 Batch F1: 0.6060606060606061
Epoch:  550        2 Batch loss: 0.183410 Batch F1: 0.7111111111111111
Epoch:  550        3 Batch loss: 0.168960 Batch F1: 0.6818181818181818
Epoch:  550        4 Batch loss: 0.153090 Batch F1: 0.8235294117647058
Epoch:  550        5 Batch loss: 0.182280 Batch F1: 0.6808510638297872
Epoch:  550        6 Batch loss: 0.152423 Batch F1: 0.8235294117647058
Epoch:  550        7 Batch loss: 0.196164 Batch F1: 0.619047619047619
Epoch:  550        8 Batch loss: 0.172296 Batch F1: 0.6829268292682926
Epoch:  550        9 Batch loss: 0.174560 Batch F1: 0.6521739130434783
Epoch:  550       10 Batch loss: 0.157003 Batch F1: 0.7500000000000001
Epoch:  550       11 Batch loss: 0.168312 Batch F1: 0.7272727272727273
Epoch:  550       12 Batch loss: 0.171113 Batch F1: 0.7317073170731706
Train Avg Loss  550: 0.170966

Train Avg F1  550: 0.7075023493378655

Val Avg Loss  550: 0.180768

Val Avg F1  550:  0.6769326537490629

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 551
--------------------------------------------------------------
Epoch:  551        1 Batch loss: 0.167904 Batch F1: 0.7142857142857143
Epoch:  551        2 Batch loss: 0.160519 Batch F1: 0.7234042553191489
Epoch:  551        3 Batch loss: 0.152772 Batch F1: 0.7755102040816326
Epoch:  551        4 Batch loss: 0.160941 Batch F1: 0.7843137254901961
Epoch:  551        5 Batch loss: 0.206111 Batch F1: 0.5714285714285715
Epoch:  551        6 Batch loss: 0.198610 Batch F1: 0.6666666666666666
Epoch:  551        7 Batch loss: 0.170029 Batch F1: 0.7391304347826085
Epoch:  551        8 Batch loss: 0.166328 Batch F1: 0.7499999999999999
Epoch:  551        9 Batch loss: 0.174211 Batch F1: 0.6111111111111113
Epoch:  551       10 Batch loss: 0.183299 Batch F1: 0.6956521739130435
Epoch:  551       11 Batch loss: 0.131479 Batch F1: 0.787878787878788
Epoch:  551       12 Batch loss: 0.164350 Batch F1: 0.7058823529411764
Train Avg Loss  551: 0.169713

Train Avg F1  551: 0.7104386664915548

Val Avg Loss  551: 0.182791

Val Avg F1  551:  0.6757490230134606

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 552
--------------------------------------------------------------
Epoch:  552        1 Batch loss: 0.156728 Batch F1: 0.6842105263157895
Epoch:  552        2 Batch loss: 0.158108 Batch F1: 0.7142857142857143
Epoch:  552        3 Batch loss: 0.161881 Batch F1: 0.7027027027027027
Epoch:  552        4 Batch loss: 0.187812 Batch F1: 0.6511627906976744
Epoch:  552        5 Batch loss: 0.165007 Batch F1: 0.7234042553191491
Epoch:  552        6 Batch loss: 0.146027 Batch F1: 0.8510638297872342
Epoch:  552        7 Batch loss: 0.189797 Batch F1: 0.6792452830188679
Epoch:  552        8 Batch loss: 0.197286 Batch F1: 0.6382978723404256
Epoch:  552        9 Batch loss: 0.149718 Batch F1: 0.7727272727272727
Epoch:  552       10 Batch loss: 0.159108 Batch F1: 0.7826086956521738
Epoch:  552       11 Batch loss: 0.183583 Batch F1: 0.6956521739130435
Epoch:  552       12 Batch loss: 0.184960 Batch F1: 0.6285714285714287
Train Avg Loss  552: 0.170001

Train Avg F1  552: 0.7103277121109562

Val Avg Loss  552: 0.180321

Val Avg F1  552:  0.6770186625339595

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 553
--------------------------------------------------------------
Epoch:  553        1 Batch loss: 0.148602 Batch F1: 0.7368421052631577
Epoch:  553        2 Batch loss: 0.237743 Batch F1: 0.6071428571428571
Epoch:  553        3 Batch loss: 0.171155 Batch F1: 0.76
Epoch:  553        4 Batch loss: 0.152261 Batch F1: 0.717948717948718
Epoch:  553        5 Batch loss: 0.167221 Batch F1: 0.75
Epoch:  553        6 Batch loss: 0.158439 Batch F1: 0.7317073170731706
Epoch:  553        7 Batch loss: 0.147519 Batch F1: 0.75
Epoch:  553        8 Batch loss: 0.156108 Batch F1: 0.8
Epoch:  553        9 Batch loss: 0.180108 Batch F1: 0.6808510638297872
Epoch:  553       10 Batch loss: 0.225127 Batch F1: 0.4210526315789474
Epoch:  553       11 Batch loss: 0.137115 Batch F1: 0.7999999999999999
Epoch:  553       12 Batch loss: 0.154265 Batch F1: 0.8095238095238095
Train Avg Loss  553: 0.169638

Train Avg F1  553: 0.7137557085300373

Val Avg Loss  553: 0.181611

Val Avg F1  553:  0.6747286148501954

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 554
--------------------------------------------------------------
Epoch:  554        1 Batch loss: 0.165463 Batch F1: 0.7083333333333333
Epoch:  554        2 Batch loss: 0.166955 Batch F1: 0.7500000000000001
Epoch:  554        3 Batch loss: 0.176423 Batch F1: 0.7317073170731708
Epoch:  554        4 Batch loss: 0.181348 Batch F1: 0.5714285714285714
Epoch:  554        5 Batch loss: 0.136770 Batch F1: 0.8813559322033899
Epoch:  554        6 Batch loss: 0.178254 Batch F1: 0.6818181818181819
Epoch:  554        7 Batch loss: 0.206484 Batch F1: 0.6122448979591836
Epoch:  554        8 Batch loss: 0.175936 Batch F1: 0.5853658536585367
Epoch:  554        9 Batch loss: 0.188697 Batch F1: 0.6511627906976744
Epoch:  554       10 Batch loss: 0.133591 Batch F1: 0.8695652173913043
Epoch:  554       11 Batch loss: 0.146146 Batch F1: 0.8
Epoch:  554       12 Batch loss: 0.177931 Batch F1: 0.6
Train Avg Loss  554: 0.169500

Train Avg F1  554: 0.7035818412969456

Val Avg Loss  554: 0.184020

Val Avg F1  554:  0.6786693465264894

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 555
--------------------------------------------------------------
Epoch:  555        1 Batch loss: 0.154236 Batch F1: 0.8461538461538461
Epoch:  555        2 Batch loss: 0.206497 Batch F1: 0.6666666666666666
Epoch:  555        3 Batch loss: 0.156295 Batch F1: 0.8
Epoch:  555        4 Batch loss: 0.185038 Batch F1: 0.5641025641025642
Epoch:  555        5 Batch loss: 0.201198 Batch F1: 0.6046511627906976
Epoch:  555        6 Batch loss: 0.168345 Batch F1: 0.7083333333333334
Epoch:  555        7 Batch loss: 0.173985 Batch F1: 0.631578947368421
Epoch:  555        8 Batch loss: 0.151716 Batch F1: 0.7727272727272727
Epoch:  555        9 Batch loss: 0.168690 Batch F1: 0.6666666666666666
Epoch:  555       10 Batch loss: 0.158257 Batch F1: 0.7222222222222222
Epoch:  555       11 Batch loss: 0.177493 Batch F1: 0.6808510638297872
Epoch:  555       12 Batch loss: 0.129040 Batch F1: 0.8571428571428572
Train Avg Loss  555: 0.169233

Train Avg F1  555: 0.7100913835836945

Val Avg Loss  555: 0.182462

Val Avg F1  555:  0.6759259259259259

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 556
--------------------------------------------------------------
Epoch:  556        1 Batch loss: 0.196444 Batch F1: 0.6086956521739131
Epoch:  556        2 Batch loss: 0.162126 Batch F1: 0.7441860465116279
Epoch:  556        3 Batch loss: 0.173135 Batch F1: 0.7450980392156864
Epoch:  556        4 Batch loss: 0.151178 Batch F1: 0.7000000000000001
Epoch:  556        5 Batch loss: 0.160659 Batch F1: 0.7
Epoch:  556        6 Batch loss: 0.171862 Batch F1: 0.7
Epoch:  556        7 Batch loss: 0.194822 Batch F1: 0.6341463414634146
Epoch:  556        8 Batch loss: 0.180654 Batch F1: 0.7307692307692307
Epoch:  556        9 Batch loss: 0.149070 Batch F1: 0.830188679245283
Epoch:  556       10 Batch loss: 0.164228 Batch F1: 0.7142857142857143
Epoch:  556       11 Batch loss: 0.163375 Batch F1: 0.7142857142857143
Epoch:  556       12 Batch loss: 0.183356 Batch F1: 0.6857142857142857
Train Avg Loss  556: 0.170909

Train Avg F1  556: 0.7089474753054058

Val Avg Loss  556: 0.184856

Val Avg F1  556:  0.6785103946441157

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 557
--------------------------------------------------------------
Epoch:  557        1 Batch loss: 0.172015 Batch F1: 0.6666666666666667
Epoch:  557        2 Batch loss: 0.190702 Batch F1: 0.7307692307692308
Epoch:  557        3 Batch loss: 0.170782 Batch F1: 0.7234042553191491
Epoch:  557        4 Batch loss: 0.158675 Batch F1: 0.7441860465116279
Epoch:  557        5 Batch loss: 0.196291 Batch F1: 0.55
Epoch:  557        6 Batch loss: 0.139562 Batch F1: 0.8181818181818182
Epoch:  557        7 Batch loss: 0.183659 Batch F1: 0.6363636363636365
Epoch:  557        8 Batch loss: 0.189129 Batch F1: 0.736842105263158
Epoch:  557        9 Batch loss: 0.139105 Batch F1: 0.8181818181818182
Epoch:  557       10 Batch loss: 0.180224 Batch F1: 0.6976744186046512
Epoch:  557       11 Batch loss: 0.173379 Batch F1: 0.7272727272727272
Epoch:  557       12 Batch loss: 0.152219 Batch F1: 0.7647058823529412
Train Avg Loss  557: 0.170478

Train Avg F1  557: 0.7178540504572856

Val Avg Loss  557: 0.181070

Val Avg F1  557:  0.6772891963109354

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 558
--------------------------------------------------------------
Epoch:  558        1 Batch loss: 0.162456 Batch F1: 0.6976744186046512
Epoch:  558        2 Batch loss: 0.130279 Batch F1: 0.8627450980392156
Epoch:  558        3 Batch loss: 0.182739 Batch F1: 0.6808510638297872
Epoch:  558        4 Batch loss: 0.168012 Batch F1: 0.6842105263157895
Epoch:  558        5 Batch loss: 0.191545 Batch F1: 0.6341463414634148
Epoch:  558        6 Batch loss: 0.154486 Batch F1: 0.6470588235294118
Epoch:  558        7 Batch loss: 0.148072 Batch F1: 0.816326530612245
Epoch:  558        8 Batch loss: 0.178717 Batch F1: 0.6808510638297872
Epoch:  558        9 Batch loss: 0.182980 Batch F1: 0.7407407407407408
Epoch:  558       10 Batch loss: 0.203299 Batch F1: 0.5263157894736842
Epoch:  558       11 Batch loss: 0.165029 Batch F1: 0.7441860465116279
Epoch:  558       12 Batch loss: 0.162043 Batch F1: 0.7500000000000001
Train Avg Loss  558: 0.169138

Train Avg F1  558: 0.7054255369125295

Val Avg Loss  558: 0.180512

Val Avg F1  558:  0.6755597202025774

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 559
--------------------------------------------------------------
Epoch:  559        1 Batch loss: 0.204667 Batch F1: 0.5365853658536585
Epoch:  559        2 Batch loss: 0.176835 Batch F1: 0.7234042553191489
Epoch:  559        3 Batch loss: 0.176558 Batch F1: 0.6111111111111113
Epoch:  559        4 Batch loss: 0.127400 Batch F1: 0.851063829787234
Epoch:  559        5 Batch loss: 0.181629 Batch F1: 0.7636363636363636
Epoch:  559        6 Batch loss: 0.162233 Batch F1: 0.6486486486486486
Epoch:  559        7 Batch loss: 0.181001 Batch F1: 0.6666666666666666
Epoch:  559        8 Batch loss: 0.156194 Batch F1: 0.7999999999999999
Epoch:  559        9 Batch loss: 0.137957 Batch F1: 0.8333333333333333
Epoch:  559       10 Batch loss: 0.172450 Batch F1: 0.6666666666666666
Epoch:  559       11 Batch loss: 0.171808 Batch F1: 0.7272727272727272
Epoch:  559       12 Batch loss: 0.186781 Batch F1: 0.6486486486486486
Train Avg Loss  559: 0.169626

Train Avg F1  559: 0.7064198014120172

Val Avg Loss  559: 0.180661

Val Avg F1  559:  0.6787505614937555

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 560
--------------------------------------------------------------
Epoch:  560        1 Batch loss: 0.191001 Batch F1: 0.5405405405405405
Epoch:  560        2 Batch loss: 0.158974 Batch F1: 0.8076923076923077
Epoch:  560        3 Batch loss: 0.192116 Batch F1: 0.6666666666666666
Epoch:  560        4 Batch loss: 0.141470 Batch F1: 0.8163265306122449
Epoch:  560        5 Batch loss: 0.166835 Batch F1: 0.723404255319149
Epoch:  560        6 Batch loss: 0.152772 Batch F1: 0.7727272727272727
Epoch:  560        7 Batch loss: 0.166129 Batch F1: 0.7391304347826085
Epoch:  560        8 Batch loss: 0.181001 Batch F1: 0.6190476190476191
Epoch:  560        9 Batch loss: 0.148844 Batch F1: 0.7916666666666667
Epoch:  560       10 Batch loss: 0.174216 Batch F1: 0.7111111111111111
Epoch:  560       11 Batch loss: 0.172553 Batch F1: 0.6666666666666667
Epoch:  560       12 Batch loss: 0.186231 Batch F1: 0.5882352941176471
Train Avg Loss  560: 0.169345

Train Avg F1  560: 0.7036012804958752

Val Avg Loss  560: 0.181233

Val Avg F1  560:  0.661727632865154

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 561
--------------------------------------------------------------
Epoch:  561        1 Batch loss: 0.173006 Batch F1: 0.6500000000000001
Epoch:  561        2 Batch loss: 0.165072 Batch F1: 0.7924528301886792
Epoch:  561        3 Batch loss: 0.167491 Batch F1: 0.6111111111111113
Epoch:  561        4 Batch loss: 0.139852 Batch F1: 0.8372093023255814
Epoch:  561        5 Batch loss: 0.167498 Batch F1: 0.76
Epoch:  561        6 Batch loss: 0.151471 Batch F1: 0.761904761904762
Epoch:  561        7 Batch loss: 0.198845 Batch F1: 0.5714285714285713
Epoch:  561        8 Batch loss: 0.189569 Batch F1: 0.6956521739130435
Epoch:  561        9 Batch loss: 0.169235 Batch F1: 0.6976744186046512
Epoch:  561       10 Batch loss: 0.151489 Batch F1: 0.7659574468085107
Epoch:  561       11 Batch loss: 0.176325 Batch F1: 0.6956521739130435
Epoch:  561       12 Batch loss: 0.193374 Batch F1: 0.6153846153846153
Train Avg Loss  561: 0.170269

Train Avg F1  561: 0.7045356171318807

Val Avg Loss  561: 0.185519

Val Avg F1  561:  0.6368355481727576

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 562
--------------------------------------------------------------
Epoch:  562        1 Batch loss: 0.181741 Batch F1: 0.7169811320754716
Epoch:  562        2 Batch loss: 0.193019 Batch F1: 0.6666666666666666
Epoch:  562        3 Batch loss: 0.180625 Batch F1: 0.5454545454545455
Epoch:  562        4 Batch loss: 0.182175 Batch F1: 0.6190476190476191
Epoch:  562        5 Batch loss: 0.156243 Batch F1: 0.7906976744186046
Epoch:  562        6 Batch loss: 0.173165 Batch F1: 0.7307692307692306
Epoch:  562        7 Batch loss: 0.188105 Batch F1: 0.6666666666666666
Epoch:  562        8 Batch loss: 0.159387 Batch F1: 0.7142857142857143
Epoch:  562        9 Batch loss: 0.177851 Batch F1: 0.6285714285714286
Epoch:  562       10 Batch loss: 0.172538 Batch F1: 0.6666666666666667
Epoch:  562       11 Batch loss: 0.146823 Batch F1: 0.8461538461538461
Epoch:  562       12 Batch loss: 0.154876 Batch F1: 0.8372093023255814
Train Avg Loss  562: 0.172212

Train Avg F1  562: 0.7024308744251702

Val Avg Loss  562: 0.180852

Val Avg F1  562:  0.6736764667755568

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 563
--------------------------------------------------------------
Epoch:  563        1 Batch loss: 0.164190 Batch F1: 0.625
Epoch:  563        2 Batch loss: 0.171488 Batch F1: 0.7450980392156863
Epoch:  563        3 Batch loss: 0.183372 Batch F1: 0.711111111111111
Epoch:  563        4 Batch loss: 0.187977 Batch F1: 0.6938775510204083
Epoch:  563        5 Batch loss: 0.145214 Batch F1: 0.7142857142857143
Epoch:  563        6 Batch loss: 0.157867 Batch F1: 0.7755102040816326
Epoch:  563        7 Batch loss: 0.205407 Batch F1: 0.6808510638297872
Epoch:  563        8 Batch loss: 0.179709 Batch F1: 0.8421052631578947
Epoch:  563        9 Batch loss: 0.161143 Batch F1: 0.7906976744186046
Epoch:  563       10 Batch loss: 0.148128 Batch F1: 0.7272727272727272
Epoch:  563       11 Batch loss: 0.167633 Batch F1: 0.7000000000000001
Epoch:  563       12 Batch loss: 0.199694 Batch F1: 0.7111111111111111
Train Avg Loss  563: 0.172652

Train Avg F1  563: 0.7264100382920565

Val Avg Loss  563: 0.187542

Val Avg F1  563:  0.6793446271566788

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 564
--------------------------------------------------------------
Epoch:  564        1 Batch loss: 0.162291 Batch F1: 0.8085106382978724
Epoch:  564        2 Batch loss: 0.188205 Batch F1: 0.7058823529411765
Epoch:  564        3 Batch loss: 0.190033 Batch F1: 0.6046511627906976
Epoch:  564        4 Batch loss: 0.193086 Batch F1: 0.6363636363636364
Epoch:  564        5 Batch loss: 0.161945 Batch F1: 0.761904761904762
Epoch:  564        6 Batch loss: 0.166894 Batch F1: 0.6285714285714286
Epoch:  564        7 Batch loss: 0.176855 Batch F1: 0.5555555555555556
Epoch:  564        8 Batch loss: 0.139214 Batch F1: 0.7906976744186046
Epoch:  564        9 Batch loss: 0.177799 Batch F1: 0.7199999999999999
Epoch:  564       10 Batch loss: 0.190024 Batch F1: 0.793103448275862
Epoch:  564       11 Batch loss: 0.196123 Batch F1: 0.6938775510204083
Epoch:  564       12 Batch loss: 0.165630 Batch F1: 0.7096774193548386
Train Avg Loss  564: 0.175675

Train Avg F1  564: 0.7007329691245702

Val Avg Loss  564: 0.182500

Val Avg F1  564:  0.6734319154785751

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 565
--------------------------------------------------------------
Epoch:  565        1 Batch loss: 0.172860 Batch F1: 0.6829268292682926
Epoch:  565        2 Batch loss: 0.142372 Batch F1: 0.7567567567567567
Epoch:  565        3 Batch loss: 0.167966 Batch F1: 0.6818181818181818
Epoch:  565        4 Batch loss: 0.179542 Batch F1: 0.723404255319149
Epoch:  565        5 Batch loss: 0.134157 Batch F1: 0.8461538461538461
Epoch:  565        6 Batch loss: 0.181980 Batch F1: 0.76
Epoch:  565        7 Batch loss: 0.195636 Batch F1: 0.6938775510204083
Epoch:  565        8 Batch loss: 0.200279 Batch F1: 0.5909090909090909
Epoch:  565        9 Batch loss: 0.164830 Batch F1: 0.7111111111111111
Epoch:  565       10 Batch loss: 0.169548 Batch F1: 0.7142857142857143
Epoch:  565       11 Batch loss: 0.149927 Batch F1: 0.6857142857142857
Epoch:  565       12 Batch loss: 0.218939 Batch F1: 0.6666666666666666
Train Avg Loss  565: 0.173170

Train Avg F1  565: 0.7094686907519586

Val Avg Loss  565: 0.183085

Val Avg F1  565:  0.6789654144305307

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 566
--------------------------------------------------------------
Epoch:  566        1 Batch loss: 0.150611 Batch F1: 0.8085106382978724
Epoch:  566        2 Batch loss: 0.188618 Batch F1: 0.64
Epoch:  566        3 Batch loss: 0.180545 Batch F1: 0.7857142857142857
Epoch:  566        4 Batch loss: 0.175687 Batch F1: 0.6808510638297872
Epoch:  566        5 Batch loss: 0.157365 Batch F1: 0.7755102040816326
Epoch:  566        6 Batch loss: 0.175013 Batch F1: 0.65
Epoch:  566        7 Batch loss: 0.183398 Batch F1: 0.6829268292682926
Epoch:  566        8 Batch loss: 0.176237 Batch F1: 0.7450980392156863
Epoch:  566        9 Batch loss: 0.200652 Batch F1: 0.5294117647058824
Epoch:  566       10 Batch loss: 0.175776 Batch F1: 0.75
Epoch:  566       11 Batch loss: 0.183488 Batch F1: 0.6956521739130435
Epoch:  566       12 Batch loss: 0.162455 Batch F1: 0.6666666666666666
Train Avg Loss  566: 0.175820

Train Avg F1  566: 0.7008618054744291

Val Avg Loss  566: 0.185526

Val Avg F1  566:  0.6712092435752972

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 567
--------------------------------------------------------------
Epoch:  567        1 Batch loss: 0.178903 Batch F1: 0.6976744186046512
Epoch:  567        2 Batch loss: 0.143329 Batch F1: 0.7777777777777777
Epoch:  567        3 Batch loss: 0.177687 Batch F1: 0.723404255319149
Epoch:  567        4 Batch loss: 0.194298 Batch F1: 0.619047619047619
Epoch:  567        5 Batch loss: 0.170682 Batch F1: 0.7142857142857143
Epoch:  567        6 Batch loss: 0.160623 Batch F1: 0.6875
Epoch:  567        7 Batch loss: 0.177333 Batch F1: 0.631578947368421
Epoch:  567        8 Batch loss: 0.180072 Batch F1: 0.7636363636363636
Epoch:  567        9 Batch loss: 0.195818 Batch F1: 0.64
Epoch:  567       10 Batch loss: 0.161022 Batch F1: 0.7619047619047619
Epoch:  567       11 Batch loss: 0.168625 Batch F1: 0.7931034482758621
Epoch:  567       12 Batch loss: 0.170756 Batch F1: 0.7
Train Avg Loss  567: 0.173262

Train Avg F1  567: 0.7091594421850266

Val Avg Loss  567: 0.186861

Val Avg F1  567:  0.762537845296466

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 568
--------------------------------------------------------------
Epoch:  568        1 Batch loss: 0.157894 Batch F1: 0.8749999999999999
Epoch:  568        2 Batch loss: 0.190478 Batch F1: 0.6382978723404256
Epoch:  568        3 Batch loss: 0.197362 Batch F1: 0.6
Epoch:  568        4 Batch loss: 0.165179 Batch F1: 0.8000000000000002
Epoch:  568        5 Batch loss: 0.153999 Batch F1: 0.7555555555555556
Epoch:  568        6 Batch loss: 0.183910 Batch F1: 0.6818181818181818
Epoch:  568        7 Batch loss: 0.148733 Batch F1: 0.7906976744186046
Epoch:  568        8 Batch loss: 0.171828 Batch F1: 0.6666666666666666
Epoch:  568        9 Batch loss: 0.178855 Batch F1: 0.711111111111111
Epoch:  568       10 Batch loss: 0.178532 Batch F1: 0.6976744186046512
Epoch:  568       11 Batch loss: 0.195073 Batch F1: 0.6486486486486486
Epoch:  568       12 Batch loss: 0.176461 Batch F1: 0.7027027027027027
Train Avg Loss  568: 0.174859

Train Avg F1  568: 0.7140144026555456

Val Avg Loss  568: 0.184581

Val Avg F1  568:  0.670904549518641

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 569
--------------------------------------------------------------
Epoch:  569        1 Batch loss: 0.178791 Batch F1: 0.7234042553191489
Epoch:  569        2 Batch loss: 0.172053 Batch F1: 0.7999999999999999
Epoch:  569        3 Batch loss: 0.168607 Batch F1: 0.8571428571428571
Epoch:  569        4 Batch loss: 0.151799 Batch F1: 0.7727272727272727
Epoch:  569        5 Batch loss: 0.154918 Batch F1: 0.8085106382978724
Epoch:  569        6 Batch loss: 0.179330 Batch F1: 0.6666666666666666
Epoch:  569        7 Batch loss: 0.178399 Batch F1: 0.6666666666666666
Epoch:  569        8 Batch loss: 0.200422 Batch F1: 0.6190476190476191
Epoch:  569        9 Batch loss: 0.182898 Batch F1: 0.711111111111111
Epoch:  569       10 Batch loss: 0.144003 Batch F1: 0.7567567567567567
Epoch:  569       11 Batch loss: 0.191582 Batch F1: 0.6521739130434783
Epoch:  569       12 Batch loss: 0.183546 Batch F1: 0.6285714285714286
Train Avg Loss  569: 0.173862

Train Avg F1  569: 0.7218982654459065

Val Avg Loss  569: 0.181651

Val Avg F1  569:  0.6786132384212301

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 570
--------------------------------------------------------------
Epoch:  570        1 Batch loss: 0.177540 Batch F1: 0.7450980392156864
Epoch:  570        2 Batch loss: 0.152229 Batch F1: 0.75
Epoch:  570        3 Batch loss: 0.151915 Batch F1: 0.8
Epoch:  570        4 Batch loss: 0.186425 Batch F1: 0.6938775510204083
Epoch:  570        5 Batch loss: 0.168620 Batch F1: 0.6976744186046512
Epoch:  570        6 Batch loss: 0.213248 Batch F1: 0.627450980392157
Epoch:  570        7 Batch loss: 0.172312 Batch F1: 0.723404255319149
Epoch:  570        8 Batch loss: 0.175945 Batch F1: 0.6976744186046512
Epoch:  570        9 Batch loss: 0.156972 Batch F1: 0.7027027027027026
Epoch:  570       10 Batch loss: 0.151086 Batch F1: 0.7317073170731708
Epoch:  570       11 Batch loss: 0.169772 Batch F1: 0.7
Epoch:  570       12 Batch loss: 0.169212 Batch F1: 0.7027027027027026
Train Avg Loss  570: 0.170440

Train Avg F1  570: 0.71435769880294

Val Avg Loss  570: 0.183664

Val Avg F1  570:  0.677015306122449

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 571
--------------------------------------------------------------
Epoch:  571        1 Batch loss: 0.164915 Batch F1: 0.711111111111111
Epoch:  571        2 Batch loss: 0.198306 Batch F1: 0.6938775510204083
Epoch:  571        3 Batch loss: 0.148342 Batch F1: 0.7368421052631579
Epoch:  571        4 Batch loss: 0.180539 Batch F1: 0.6976744186046512
Epoch:  571        5 Batch loss: 0.178577 Batch F1: 0.7547169811320755
Epoch:  571        6 Batch loss: 0.180272 Batch F1: 0.6808510638297872
Epoch:  571        7 Batch loss: 0.165614 Batch F1: 0.7272727272727272
Epoch:  571        8 Batch loss: 0.168648 Batch F1: 0.6842105263157895
Epoch:  571        9 Batch loss: 0.126619 Batch F1: 0.8571428571428571
Epoch:  571       10 Batch loss: 0.185318 Batch F1: 0.6521739130434783
Epoch:  571       11 Batch loss: 0.176499 Batch F1: 0.631578947368421
Epoch:  571       12 Batch loss: 0.179397 Batch F1: 0.7142857142857143
Train Avg Loss  571: 0.171087

Train Avg F1  571: 0.7118114930325149

Val Avg Loss  571: 0.181462

Val Avg F1  571:  0.6624471192495025

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 572
--------------------------------------------------------------
Epoch:  572        1 Batch loss: 0.219196 Batch F1: 0.5
Epoch:  572        2 Batch loss: 0.167248 Batch F1: 0.7
Epoch:  572        3 Batch loss: 0.185197 Batch F1: 0.75
Epoch:  572        4 Batch loss: 0.182615 Batch F1: 0.6818181818181819
Epoch:  572        5 Batch loss: 0.178904 Batch F1: 0.7037037037037038
Epoch:  572        6 Batch loss: 0.143387 Batch F1: 0.7555555555555555
Epoch:  572        7 Batch loss: 0.155687 Batch F1: 0.7368421052631579
Epoch:  572        8 Batch loss: 0.147779 Batch F1: 0.7894736842105262
Epoch:  572        9 Batch loss: 0.155687 Batch F1: 0.7727272727272727
Epoch:  572       10 Batch loss: 0.155873 Batch F1: 0.782608695652174
Epoch:  572       11 Batch loss: 0.187028 Batch F1: 0.6956521739130435
Epoch:  572       12 Batch loss: 0.167817 Batch F1: 0.6896551724137931
Train Avg Loss  572: 0.170535

Train Avg F1  572: 0.7131697121047841

Val Avg Loss  572: 0.183746

Val Avg F1  572:  0.6757500537287772

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 573
--------------------------------------------------------------
Epoch:  573        1 Batch loss: 0.139612 Batch F1: 0.8372093023255814
Epoch:  573        2 Batch loss: 0.168770 Batch F1: 0.8076923076923077
Epoch:  573        3 Batch loss: 0.184909 Batch F1: 0.5945945945945946
Epoch:  573        4 Batch loss: 0.203797 Batch F1: 0.5652173913043478
Epoch:  573        5 Batch loss: 0.154191 Batch F1: 0.8
Epoch:  573        6 Batch loss: 0.185563 Batch F1: 0.6
Epoch:  573        7 Batch loss: 0.177787 Batch F1: 0.6818181818181818
Epoch:  573        8 Batch loss: 0.163768 Batch F1: 0.6486486486486486
Epoch:  573        9 Batch loss: 0.176909 Batch F1: 0.7692307692307693
Epoch:  573       10 Batch loss: 0.169767 Batch F1: 0.5882352941176471
Epoch:  573       11 Batch loss: 0.162797 Batch F1: 0.76
Epoch:  573       12 Batch loss: 0.147291 Batch F1: 0.8000000000000002
Train Avg Loss  573: 0.169597

Train Avg F1  573: 0.704387207477673

Val Avg Loss  573: 0.181028

Val Avg F1  573:  0.6724853762589612

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 574
--------------------------------------------------------------
Epoch:  574        1 Batch loss: 0.157643 Batch F1: 0.6000000000000001
Epoch:  574        2 Batch loss: 0.179209 Batch F1: 0.7234042553191491
Epoch:  574        3 Batch loss: 0.175527 Batch F1: 0.6956521739130435
Epoch:  574        4 Batch loss: 0.185224 Batch F1: 0.7368421052631579
Epoch:  574        5 Batch loss: 0.173328 Batch F1: 0.7924528301886793
Epoch:  574        6 Batch loss: 0.164471 Batch F1: 0.6341463414634148
Epoch:  574        7 Batch loss: 0.180854 Batch F1: 0.68
Epoch:  574        8 Batch loss: 0.142119 Batch F1: 0.7894736842105262
Epoch:  574        9 Batch loss: 0.167097 Batch F1: 0.7727272727272727
Epoch:  574       10 Batch loss: 0.148270 Batch F1: 0.7222222222222222
Epoch:  574       11 Batch loss: 0.156576 Batch F1: 0.7755102040816326
Epoch:  574       12 Batch loss: 0.198218 Batch F1: 0.5454545454545455
Train Avg Loss  574: 0.169045

Train Avg F1  574: 0.7056571362369702

Val Avg Loss  574: 0.181067

Val Avg F1  574:  0.6765251095382541

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 575
--------------------------------------------------------------
Epoch:  575        1 Batch loss: 0.163637 Batch F1: 0.625
Epoch:  575        2 Batch loss: 0.142861 Batch F1: 0.8260869565217391
Epoch:  575        3 Batch loss: 0.178468 Batch F1: 0.6341463414634146
Epoch:  575        4 Batch loss: 0.195507 Batch F1: 0.7142857142857142
Epoch:  575        5 Batch loss: 0.165479 Batch F1: 0.76
Epoch:  575        6 Batch loss: 0.197185 Batch F1: 0.5714285714285713
Epoch:  575        7 Batch loss: 0.161834 Batch F1: 0.7555555555555556
Epoch:  575        8 Batch loss: 0.155939 Batch F1: 0.7727272727272727
Epoch:  575        9 Batch loss: 0.142957 Batch F1: 0.8095238095238095
Epoch:  575       10 Batch loss: 0.161501 Batch F1: 0.6666666666666666
Epoch:  575       11 Batch loss: 0.175070 Batch F1: 0.6341463414634146
Epoch:  575       12 Batch loss: 0.184486 Batch F1: 0.7272727272727273
Train Avg Loss  575: 0.168744

Train Avg F1  575: 0.7080699964090736

Val Avg Loss  575: 0.180835

Val Avg F1  575:  0.6746789624940885

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 576
--------------------------------------------------------------
Epoch:  576        1 Batch loss: 0.178567 Batch F1: 0.6666666666666666
Epoch:  576        2 Batch loss: 0.187063 Batch F1: 0.5641025641025641
Epoch:  576        3 Batch loss: 0.188577 Batch F1: 0.6
Epoch:  576        4 Batch loss: 0.189181 Batch F1: 0.6222222222222222
Epoch:  576        5 Batch loss: 0.159284 Batch F1: 0.7142857142857143
Epoch:  576        6 Batch loss: 0.147824 Batch F1: 0.7916666666666666
Epoch:  576        7 Batch loss: 0.166757 Batch F1: 0.6666666666666667
Epoch:  576        8 Batch loss: 0.159362 Batch F1: 0.830188679245283
Epoch:  576        9 Batch loss: 0.152991 Batch F1: 0.7727272727272727
Epoch:  576       10 Batch loss: 0.213118 Batch F1: 0.5652173913043478
Epoch:  576       11 Batch loss: 0.117822 Batch F1: 0.8636363636363635
Epoch:  576       12 Batch loss: 0.162195 Batch F1: 0.8260869565217391
Train Avg Loss  576: 0.168562

Train Avg F1  576: 0.7069555970037921

Val Avg Loss  576: 0.179688

Val Avg F1  576:  0.6760888069229678

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 577
--------------------------------------------------------------
Epoch:  577        1 Batch loss: 0.139203 Batch F1: 0.8
Epoch:  577        2 Batch loss: 0.192258 Batch F1: 0.5641025641025641
Epoch:  577        3 Batch loss: 0.181621 Batch F1: 0.6530612244897959
Epoch:  577        4 Batch loss: 0.186469 Batch F1: 0.6382978723404256
Epoch:  577        5 Batch loss: 0.149693 Batch F1: 0.7727272727272727
Epoch:  577        6 Batch loss: 0.176663 Batch F1: 0.7
Epoch:  577        7 Batch loss: 0.183502 Batch F1: 0.7586206896551724
Epoch:  577        8 Batch loss: 0.164827 Batch F1: 0.6818181818181818
Epoch:  577        9 Batch loss: 0.166880 Batch F1: 0.7027027027027027
Epoch:  577       10 Batch loss: 0.169011 Batch F1: 0.7692307692307692
Epoch:  577       11 Batch loss: 0.172801 Batch F1: 0.6829268292682926
Epoch:  577       12 Batch loss: 0.135916 Batch F1: 0.8235294117647058
Train Avg Loss  577: 0.168237

Train Avg F1  577: 0.7122514598416569

Val Avg Loss  577: 0.180973

Val Avg F1  577:  0.6656906906906906

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 578
--------------------------------------------------------------
Epoch:  578        1 Batch loss: 0.161560 Batch F1: 0.75
Epoch:  578        2 Batch loss: 0.168724 Batch F1: 0.6666666666666666
Epoch:  578        3 Batch loss: 0.196350 Batch F1: 0.6222222222222222
Epoch:  578        4 Batch loss: 0.174695 Batch F1: 0.6956521739130435
Epoch:  578        5 Batch loss: 0.165317 Batch F1: 0.7317073170731706
Epoch:  578        6 Batch loss: 0.151965 Batch F1: 0.7058823529411765
Epoch:  578        7 Batch loss: 0.173579 Batch F1: 0.7666666666666667
Epoch:  578        8 Batch loss: 0.161502 Batch F1: 0.7555555555555556
Epoch:  578        9 Batch loss: 0.177779 Batch F1: 0.6486486486486486
Epoch:  578       10 Batch loss: 0.158596 Batch F1: 0.75
Epoch:  578       11 Batch loss: 0.144227 Batch F1: 0.8000000000000002
Epoch:  578       12 Batch loss: 0.194313 Batch F1: 0.6153846153846153
Train Avg Loss  578: 0.169051

Train Avg F1  578: 0.7090321849226471

Val Avg Loss  578: 0.180819

Val Avg F1  578:  0.6670354131990961

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 579
--------------------------------------------------------------
Epoch:  579        1 Batch loss: 0.168285 Batch F1: 0.76
Epoch:  579        2 Batch loss: 0.198951 Batch F1: 0.5714285714285713
Epoch:  579        3 Batch loss: 0.139459 Batch F1: 0.8000000000000002
Epoch:  579        4 Batch loss: 0.190748 Batch F1: 0.6382978723404256
Epoch:  579        5 Batch loss: 0.175088 Batch F1: 0.6341463414634146
Epoch:  579        6 Batch loss: 0.144160 Batch F1: 0.7222222222222223
Epoch:  579        7 Batch loss: 0.211240 Batch F1: 0.5909090909090909
Epoch:  579        8 Batch loss: 0.172740 Batch F1: 0.7317073170731708
Epoch:  579        9 Batch loss: 0.139850 Batch F1: 0.8
Epoch:  579       10 Batch loss: 0.135988 Batch F1: 0.8571428571428571
Epoch:  579       11 Batch loss: 0.172114 Batch F1: 0.7547169811320754
Epoch:  579       12 Batch loss: 0.177552 Batch F1: 0.7317073170731707
Train Avg Loss  579: 0.168848

Train Avg F1  579: 0.7160232142320831

Val Avg Loss  579: 0.184666

Val Avg F1  579:  0.6350564468211527

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 580
--------------------------------------------------------------
Epoch:  580        1 Batch loss: 0.155111 Batch F1: 0.72
Epoch:  580        2 Batch loss: 0.181866 Batch F1: 0.6274509803921569
Epoch:  580        3 Batch loss: 0.185974 Batch F1: 0.7241379310344827
Epoch:  580        4 Batch loss: 0.178319 Batch F1: 0.8235294117647057
Epoch:  580        5 Batch loss: 0.159508 Batch F1: 0.8695652173913043
Epoch:  580        6 Batch loss: 0.174150 Batch F1: 0.7555555555555556
Epoch:  580        7 Batch loss: 0.181868 Batch F1: 0.7547169811320755
Epoch:  580        8 Batch loss: 0.167262 Batch F1: 0.7272727272727272
Epoch:  580        9 Batch loss: 0.171520 Batch F1: 0.6470588235294118
Epoch:  580       10 Batch loss: 0.167033 Batch F1: 0.7027027027027026
Epoch:  580       11 Batch loss: 0.196598 Batch F1: 0.6808510638297872
Epoch:  580       12 Batch loss: 0.143760 Batch F1: 0.7741935483870969
Train Avg Loss  580: 0.171914

Train Avg F1  580: 0.7339195785826672

Val Avg Loss  580: 0.186062

Val Avg F1  580:  0.6650588032575611

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 581
--------------------------------------------------------------
Epoch:  581        1 Batch loss: 0.172798 Batch F1: 0.711111111111111
Epoch:  581        2 Batch loss: 0.143357 Batch F1: 0.7368421052631577
Epoch:  581        3 Batch loss: 0.168830 Batch F1: 0.76
Epoch:  581        4 Batch loss: 0.186755 Batch F1: 0.6046511627906976
Epoch:  581        5 Batch loss: 0.161290 Batch F1: 0.76
Epoch:  581        6 Batch loss: 0.155044 Batch F1: 0.7346938775510204
Epoch:  581        7 Batch loss: 0.160610 Batch F1: 0.8148148148148148
Epoch:  581        8 Batch loss: 0.192542 Batch F1: 0.6382978723404256
Epoch:  581        9 Batch loss: 0.178668 Batch F1: 0.6829268292682926
Epoch:  581       10 Batch loss: 0.189696 Batch F1: 0.5789473684210527
Epoch:  581       11 Batch loss: 0.196305 Batch F1: 0.6530612244897959
Epoch:  581       12 Batch loss: 0.159891 Batch F1: 0.6666666666666666
Train Avg Loss  581: 0.172149

Train Avg F1  581: 0.6951677527264195

Val Avg Loss  581: 0.192037

Val Avg F1  581:  0.6674241325404118

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 582
--------------------------------------------------------------
Epoch:  582        1 Batch loss: 0.197095 Batch F1: 0.5161290322580645
Epoch:  582        2 Batch loss: 0.126140 Batch F1: 0.9500000000000001
Epoch:  582        3 Batch loss: 0.207529 Batch F1: 0.7368421052631579
Epoch:  582        4 Batch loss: 0.198877 Batch F1: 0.4375
Epoch:  582        5 Batch loss: 0.198736 Batch F1: 0.6086956521739131
Epoch:  582        6 Batch loss: 0.195770 Batch F1: 0.5853658536585366
Epoch:  582        7 Batch loss: 0.177696 Batch F1: 0.7307692307692307
Epoch:  582        8 Batch loss: 0.156959 Batch F1: 0.717948717948718
Epoch:  582        9 Batch loss: 0.183432 Batch F1: 0.7083333333333334
Epoch:  582       10 Batch loss: 0.163695 Batch F1: 0.7659574468085107
Epoch:  582       11 Batch loss: 0.189025 Batch F1: 0.7307692307692308
Epoch:  582       12 Batch loss: 0.120090 Batch F1: 0.923076923076923
Train Avg Loss  582: 0.176254

Train Avg F1  582: 0.7009489605049682

Val Avg Loss  582: 0.187210

Val Avg F1  582:  0.8106216203870246

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 583
--------------------------------------------------------------
Epoch:  583        1 Batch loss: 0.180026 Batch F1: 0.7999999999999999
Epoch:  583        2 Batch loss: 0.160111 Batch F1: 0.7755102040816326
Epoch:  583        3 Batch loss: 0.160543 Batch F1: 0.7
Epoch:  583        4 Batch loss: 0.165424 Batch F1: 0.7441860465116279
Epoch:  583        5 Batch loss: 0.197215 Batch F1: 0.5555555555555556
Epoch:  583        6 Batch loss: 0.183065 Batch F1: 0.7083333333333333
Epoch:  583        7 Batch loss: 0.199583 Batch F1: 0.6086956521739131
Epoch:  583        8 Batch loss: 0.149179 Batch F1: 0.8163265306122449
Epoch:  583        9 Batch loss: 0.177978 Batch F1: 0.8163265306122449
Epoch:  583       10 Batch loss: 0.198330 Batch F1: 0.6521739130434783
Epoch:  583       11 Batch loss: 0.143319 Batch F1: 0.7692307692307692
Epoch:  583       12 Batch loss: 0.174713 Batch F1: 0.717948717948718
Train Avg Loss  583: 0.174124

Train Avg F1  583: 0.7220239377586264

Val Avg Loss  583: 0.187059

Val Avg F1  583:  0.6727890419858694

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 584
--------------------------------------------------------------
Epoch:  584        1 Batch loss: 0.150619 Batch F1: 0.7906976744186046
Epoch:  584        2 Batch loss: 0.183348 Batch F1: 0.5945945945945946
Epoch:  584        3 Batch loss: 0.174897 Batch F1: 0.711111111111111
Epoch:  584        4 Batch loss: 0.177673 Batch F1: 0.6956521739130435
Epoch:  584        5 Batch loss: 0.175193 Batch F1: 0.6829268292682926
Epoch:  584        6 Batch loss: 0.160585 Batch F1: 0.7843137254901961
Epoch:  584        7 Batch loss: 0.178088 Batch F1: 0.693877551020408
Epoch:  584        8 Batch loss: 0.143461 Batch F1: 0.8679245283018868
Epoch:  584        9 Batch loss: 0.177612 Batch F1: 0.6511627906976745
Epoch:  584       10 Batch loss: 0.172240 Batch F1: 0.7083333333333334
Epoch:  584       11 Batch loss: 0.193924 Batch F1: 0.5500000000000002
Epoch:  584       12 Batch loss: 0.180123 Batch F1: 0.6875
Train Avg Loss  584: 0.172313

Train Avg F1  584: 0.7015078593457621

Val Avg Loss  584: 0.183548

Val Avg F1  584:  0.6783333333333333

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 585
--------------------------------------------------------------
Epoch:  585        1 Batch loss: 0.192713 Batch F1: 0.6190476190476191
Epoch:  585        2 Batch loss: 0.162353 Batch F1: 0.7555555555555556
Epoch:  585        3 Batch loss: 0.179978 Batch F1: 0.6511627906976744
Epoch:  585        4 Batch loss: 0.206297 Batch F1: 0.6530612244897959
Epoch:  585        5 Batch loss: 0.177134 Batch F1: 0.7659574468085107
Epoch:  585        6 Batch loss: 0.157244 Batch F1: 0.7441860465116279
Epoch:  585        7 Batch loss: 0.155899 Batch F1: 0.7906976744186046
Epoch:  585        8 Batch loss: 0.197403 Batch F1: 0.6545454545454545
Epoch:  585        9 Batch loss: 0.163116 Batch F1: 0.65
Epoch:  585       10 Batch loss: 0.188042 Batch F1: 0.631578947368421
Epoch:  585       11 Batch loss: 0.144621 Batch F1: 0.7999999999999999
Epoch:  585       12 Batch loss: 0.181019 Batch F1: 0.717948717948718
Train Avg Loss  585: 0.175485

Train Avg F1  585: 0.7028117897826651

Val Avg Loss  585: 0.183283

Val Avg F1  585:  0.6764705882352942

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 586
--------------------------------------------------------------
Epoch:  586        1 Batch loss: 0.180811 Batch F1: 0.7199999999999999
Epoch:  586        2 Batch loss: 0.164767 Batch F1: 0.7346938775510203
Epoch:  586        3 Batch loss: 0.156370 Batch F1: 0.7916666666666666
Epoch:  586        4 Batch loss: 0.144994 Batch F1: 0.8292682926829269
Epoch:  586        5 Batch loss: 0.211298 Batch F1: 0.64
Epoch:  586        6 Batch loss: 0.178293 Batch F1: 0.6521739130434783
Epoch:  586        7 Batch loss: 0.143378 Batch F1: 0.7727272727272727
Epoch:  586        8 Batch loss: 0.148801 Batch F1: 0.8260869565217391
Epoch:  586        9 Batch loss: 0.179568 Batch F1: 0.65
Epoch:  586       10 Batch loss: 0.188439 Batch F1: 0.65
Epoch:  586       11 Batch loss: 0.183443 Batch F1: 0.6190476190476191
Epoch:  586       12 Batch loss: 0.172230 Batch F1: 0.6206896551724138
Train Avg Loss  586: 0.171033

Train Avg F1  586: 0.7088628544510948

Val Avg Loss  586: 0.183343

Val Avg F1  586:  0.6769169960474308

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 587
--------------------------------------------------------------
Epoch:  587        1 Batch loss: 0.127792 Batch F1: 0.8372093023255814
Epoch:  587        2 Batch loss: 0.178877 Batch F1: 0.6666666666666666
Epoch:  587        3 Batch loss: 0.195882 Batch F1: 0.6530612244897959
Epoch:  587        4 Batch loss: 0.139622 Batch F1: 0.8095238095238095
Epoch:  587        5 Batch loss: 0.154487 Batch F1: 0.7804878048780488
Epoch:  587        6 Batch loss: 0.168661 Batch F1: 0.7111111111111111
Epoch:  587        7 Batch loss: 0.180602 Batch F1: 0.6341463414634146
Epoch:  587        8 Batch loss: 0.193252 Batch F1: 0.7058823529411765
Epoch:  587        9 Batch loss: 0.158696 Batch F1: 0.7441860465116279
Epoch:  587       10 Batch loss: 0.178124 Batch F1: 0.6956521739130435
Epoch:  587       11 Batch loss: 0.188546 Batch F1: 0.6808510638297872
Epoch:  587       12 Batch loss: 0.178280 Batch F1: 0.6285714285714286
Train Avg Loss  587: 0.170235

Train Avg F1  587: 0.712279110518791

Val Avg Loss  587: 0.181163

Val Avg F1  587:  0.6774997558832144

Optimal Val loss (Epoch 525): 0.17949579656124115

Epoch 588
--------------------------------------------------------------
Epoch:  588        1 Batch loss: 0.137654 Batch F1: 0.8627450980392156
Epoch:  588        2 Batch loss: 0.197363 Batch F1: 0.7111111111111111
Epoch:  588        3 Batch loss: 0.183413 Batch F1: 0.7391304347826089
Epoch:  588        4 Batch loss: 0.178541 Batch F1: 0.631578947368421
Epoch:  588        5 Batch loss: 0.228649 Batch F1: 0.46511627906976744
Epoch:  588        6 Batch loss: 0.150043 Batch F1: 0.7441860465116279
Epoch:  588        7 Batch loss: 0.182386 Batch F1: 0.72
Epoch:  588        8 Batch loss: 0.146619 Batch F1: 0.7727272727272727
Epoch:  588        9 Batch loss: 0.146391 Batch F1: 0.7428571428571428
Epoch:  588       10 Batch loss: 0.155774 Batch F1: 0.830188679245283
Epoch:  588       11 Batch loss: 0.168581 Batch F1: 0.6111111111111112
Epoch:  588       12 Batch loss: 0.182813 Batch F1: 0.7272727272727272
Train Avg Loss  588: 0.171519

Train Avg F1  588: 0.713168737508024

Val Avg Loss  588: 0.178927

Val Avg F1  588:  0.6783441637524575

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 589
--------------------------------------------------------------
Epoch:  589        1 Batch loss: 0.178403 Batch F1: 0.6818181818181819
Epoch:  589        2 Batch loss: 0.178257 Batch F1: 0.6666666666666666
Epoch:  589        3 Batch loss: 0.191019 Batch F1: 0.6521739130434783
Epoch:  589        4 Batch loss: 0.148887 Batch F1: 0.7222222222222222
Epoch:  589        5 Batch loss: 0.135684 Batch F1: 0.8444444444444444
Epoch:  589        6 Batch loss: 0.163849 Batch F1: 0.6976744186046512
Epoch:  589        7 Batch loss: 0.162762 Batch F1: 0.7659574468085107
Epoch:  589        8 Batch loss: 0.157885 Batch F1: 0.7843137254901961
Epoch:  589        9 Batch loss: 0.198201 Batch F1: 0.6086956521739131
Epoch:  589       10 Batch loss: 0.200969 Batch F1: 0.6190476190476191
Epoch:  589       11 Batch loss: 0.143576 Batch F1: 0.7368421052631577
Epoch:  589       12 Batch loss: 0.173078 Batch F1: 0.7555555555555555
Train Avg Loss  589: 0.169381

Train Avg F1  589: 0.7112843292615496

Val Avg Loss  589: 0.181453

Val Avg F1  589:  0.6688714421077243

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 590
--------------------------------------------------------------
Epoch:  590        1 Batch loss: 0.144557 Batch F1: 0.7999999999999999
Epoch:  590        2 Batch loss: 0.166360 Batch F1: 0.631578947368421
Epoch:  590        3 Batch loss: 0.159433 Batch F1: 0.6666666666666667
Epoch:  590        4 Batch loss: 0.195365 Batch F1: 0.6909090909090909
Epoch:  590        5 Batch loss: 0.168231 Batch F1: 0.7
Epoch:  590        6 Batch loss: 0.159324 Batch F1: 0.8076923076923077
Epoch:  590        7 Batch loss: 0.172621 Batch F1: 0.5789473684210527
Epoch:  590        8 Batch loss: 0.185547 Batch F1: 0.6511627906976744
Epoch:  590        9 Batch loss: 0.173392 Batch F1: 0.6956521739130435
Epoch:  590       10 Batch loss: 0.163159 Batch F1: 0.75
Epoch:  590       11 Batch loss: 0.160781 Batch F1: 0.7916666666666667
Epoch:  590       12 Batch loss: 0.186100 Batch F1: 0.717948717948718
Train Avg Loss  590: 0.169572

Train Avg F1  590: 0.7068520608569702

Val Avg Loss  590: 0.180197

Val Avg F1  590:  0.6785473542298618

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 591
--------------------------------------------------------------
Epoch:  591        1 Batch loss: 0.143776 Batch F1: 0.7804878048780488
Epoch:  591        2 Batch loss: 0.150492 Batch F1: 0.6451612903225806
Epoch:  591        3 Batch loss: 0.193392 Batch F1: 0.6666666666666666
Epoch:  591        4 Batch loss: 0.177257 Batch F1: 0.6190476190476191
Epoch:  591        5 Batch loss: 0.147866 Batch F1: 0.7999999999999999
Epoch:  591        6 Batch loss: 0.179975 Batch F1: 0.6923076923076923
Epoch:  591        7 Batch loss: 0.189527 Batch F1: 0.5714285714285714
Epoch:  591        8 Batch loss: 0.187352 Batch F1: 0.6808510638297872
Epoch:  591        9 Batch loss: 0.151220 Batch F1: 0.7894736842105262
Epoch:  591       10 Batch loss: 0.155446 Batch F1: 0.7391304347826089
Epoch:  591       11 Batch loss: 0.185472 Batch F1: 0.7272727272727272
Epoch:  591       12 Batch loss: 0.192736 Batch F1: 0.6060606060606061
Train Avg Loss  591: 0.171209

Train Avg F1  591: 0.6931573467339529

Val Avg Loss  591: 0.181592

Val Avg F1  591:  0.6730081300813008

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 592
--------------------------------------------------------------
Epoch:  592        1 Batch loss: 0.153021 Batch F1: 0.8085106382978723
Epoch:  592        2 Batch loss: 0.181566 Batch F1: 0.723404255319149
Epoch:  592        3 Batch loss: 0.201816 Batch F1: 0.5909090909090908
Epoch:  592        4 Batch loss: 0.166470 Batch F1: 0.6976744186046512
Epoch:  592        5 Batch loss: 0.190167 Batch F1: 0.6222222222222223
Epoch:  592        6 Batch loss: 0.140617 Batch F1: 0.8076923076923076
Epoch:  592        7 Batch loss: 0.198562 Batch F1: 0.5641025641025642
Epoch:  592        8 Batch loss: 0.166054 Batch F1: 0.7555555555555556
Epoch:  592        9 Batch loss: 0.165373 Batch F1: 0.7142857142857143
Epoch:  592       10 Batch loss: 0.184807 Batch F1: 0.7636363636363638
Epoch:  592       11 Batch loss: 0.194585 Batch F1: 0.55
Epoch:  592       12 Batch loss: 0.178510 Batch F1: 0.7027027027027027
Train Avg Loss  592: 0.176796

Train Avg F1  592: 0.6917246527773494

Val Avg Loss  592: 0.182599

Val Avg F1  592:  0.6748453697491721

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 593
--------------------------------------------------------------
Epoch:  593        1 Batch loss: 0.177548 Batch F1: 0.6818181818181818
Epoch:  593        2 Batch loss: 0.167746 Batch F1: 0.7727272727272727
Epoch:  593        3 Batch loss: 0.163563 Batch F1: 0.744186046511628
Epoch:  593        4 Batch loss: 0.157835 Batch F1: 0.6060606060606061
Epoch:  593        5 Batch loss: 0.190435 Batch F1: 0.6153846153846153
Epoch:  593        6 Batch loss: 0.196327 Batch F1: 0.6538461538461539
Epoch:  593        7 Batch loss: 0.189326 Batch F1: 0.6363636363636364
Epoch:  593        8 Batch loss: 0.153686 Batch F1: 0.8928571428571429
Epoch:  593        9 Batch loss: 0.156301 Batch F1: 0.9130434782608696
Epoch:  593       10 Batch loss: 0.170259 Batch F1: 0.75
Epoch:  593       11 Batch loss: 0.175749 Batch F1: 0.6938775510204083
Epoch:  593       12 Batch loss: 0.168252 Batch F1: 0.7058823529411765
Train Avg Loss  593: 0.172252

Train Avg F1  593: 0.722170586482641

Val Avg Loss  593: 0.181952

Val Avg F1  593:  0.6712969001347767

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 594
--------------------------------------------------------------
Epoch:  594        1 Batch loss: 0.166669 Batch F1: 0.7555555555555556
Epoch:  594        2 Batch loss: 0.184779 Batch F1: 0.6666666666666666
Epoch:  594        3 Batch loss: 0.187561 Batch F1: 0.5405405405405406
Epoch:  594        4 Batch loss: 0.162211 Batch F1: 0.7755102040816326
Epoch:  594        5 Batch loss: 0.154839 Batch F1: 0.7567567567567567
Epoch:  594        6 Batch loss: 0.157032 Batch F1: 0.7272727272727272
Epoch:  594        7 Batch loss: 0.174096 Batch F1: 0.7450980392156863
Epoch:  594        8 Batch loss: 0.193626 Batch F1: 0.6046511627906977
Epoch:  594        9 Batch loss: 0.192971 Batch F1: 0.5641025641025641
Epoch:  594       10 Batch loss: 0.132923 Batch F1: 0.8979591836734695
Epoch:  594       11 Batch loss: 0.177519 Batch F1: 0.6938775510204083
Epoch:  594       12 Batch loss: 0.174781 Batch F1: 0.7500000000000001
Train Avg Loss  594: 0.171584

Train Avg F1  594: 0.7064992459730588

Val Avg Loss  594: 0.181307

Val Avg F1  594:  0.6751359106010268

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 595
--------------------------------------------------------------
Epoch:  595        1 Batch loss: 0.165167 Batch F1: 0.7142857142857143
Epoch:  595        2 Batch loss: 0.171185 Batch F1: 0.6666666666666666
Epoch:  595        3 Batch loss: 0.152577 Batch F1: 0.8235294117647058
Epoch:  595        4 Batch loss: 0.189417 Batch F1: 0.6666666666666666
Epoch:  595        5 Batch loss: 0.153246 Batch F1: 0.761904761904762
Epoch:  595        6 Batch loss: 0.168670 Batch F1: 0.7000000000000001
Epoch:  595        7 Batch loss: 0.177945 Batch F1: 0.5945945945945946
Epoch:  595        8 Batch loss: 0.140216 Batch F1: 0.8
Epoch:  595        9 Batch loss: 0.170671 Batch F1: 0.723404255319149
Epoch:  595       10 Batch loss: 0.165691 Batch F1: 0.7317073170731707
Epoch:  595       11 Batch loss: 0.180770 Batch F1: 0.6666666666666667
Epoch:  595       12 Batch loss: 0.194803 Batch F1: 0.6666666666666666
Train Avg Loss  595: 0.169197

Train Avg F1  595: 0.7096743934673969

Val Avg Loss  595: 0.180428

Val Avg F1  595:  0.6771136900924135

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 596
--------------------------------------------------------------
Epoch:  596        1 Batch loss: 0.169735 Batch F1: 0.6486486486486486
Epoch:  596        2 Batch loss: 0.178674 Batch F1: 0.631578947368421
Epoch:  596        3 Batch loss: 0.171225 Batch F1: 0.7407407407407408
Epoch:  596        4 Batch loss: 0.153874 Batch F1: 0.8148148148148148
Epoch:  596        5 Batch loss: 0.166380 Batch F1: 0.7234042553191489
Epoch:  596        6 Batch loss: 0.206459 Batch F1: 0.5909090909090909
Epoch:  596        7 Batch loss: 0.150244 Batch F1: 0.7027027027027027
Epoch:  596        8 Batch loss: 0.209549 Batch F1: 0.6274509803921569
Epoch:  596        9 Batch loss: 0.183867 Batch F1: 0.6829268292682926
Epoch:  596       10 Batch loss: 0.152017 Batch F1: 0.8461538461538461
Epoch:  596       11 Batch loss: 0.131686 Batch F1: 0.7647058823529411
Epoch:  596       12 Batch loss: 0.172026 Batch F1: 0.7222222222222222
Train Avg Loss  596: 0.170478

Train Avg F1  596: 0.7080215800744188

Val Avg Loss  596: 0.181111

Val Avg F1  596:  0.676779802830223

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 597
--------------------------------------------------------------
Epoch:  597        1 Batch loss: 0.137991 Batch F1: 0.8181818181818182
Epoch:  597        2 Batch loss: 0.176731 Batch F1: 0.7692307692307692
Epoch:  597        3 Batch loss: 0.222157 Batch F1: 0.5652173913043478
Epoch:  597        4 Batch loss: 0.168530 Batch F1: 0.76
Epoch:  597        5 Batch loss: 0.201170 Batch F1: 0.6938775510204083
Epoch:  597        6 Batch loss: 0.175696 Batch F1: 0.7868852459016394
Epoch:  597        7 Batch loss: 0.184463 Batch F1: 0.6153846153846153
Epoch:  597        8 Batch loss: 0.176627 Batch F1: 0.7111111111111111
Epoch:  597        9 Batch loss: 0.160694 Batch F1: 0.6666666666666666
Epoch:  597       10 Batch loss: 0.171653 Batch F1: 0.588235294117647
Epoch:  597       11 Batch loss: 0.148959 Batch F1: 0.8
Epoch:  597       12 Batch loss: 0.143297 Batch F1: 0.5
Train Avg Loss  597: 0.172331

Train Avg F1  597: 0.6895658719099185

Val Avg Loss  597: 0.182105

Val Avg F1  597:  0.6793050193050193

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 598
--------------------------------------------------------------
Epoch:  598        1 Batch loss: 0.165046 Batch F1: 0.6666666666666666
Epoch:  598        2 Batch loss: 0.171710 Batch F1: 0.723404255319149
Epoch:  598        3 Batch loss: 0.135573 Batch F1: 0.7200000000000001
Epoch:  598        4 Batch loss: 0.175486 Batch F1: 0.7234042553191489
Epoch:  598        5 Batch loss: 0.172430 Batch F1: 0.6956521739130435
Epoch:  598        6 Batch loss: 0.182893 Batch F1: 0.693877551020408
Epoch:  598        7 Batch loss: 0.161794 Batch F1: 0.6976744186046512
Epoch:  598        8 Batch loss: 0.190520 Batch F1: 0.7457627118644068
Epoch:  598        9 Batch loss: 0.208984 Batch F1: 0.6415094339622641
Epoch:  598       10 Batch loss: 0.159577 Batch F1: 0.6976744186046512
Epoch:  598       11 Batch loss: 0.190020 Batch F1: 0.6818181818181819
Epoch:  598       12 Batch loss: 0.146287 Batch F1: 0.8108108108108109
Train Avg Loss  598: 0.171693

Train Avg F1  598: 0.7081879064919486

Val Avg Loss  598: 0.181878

Val Avg F1  598:  0.6824276540974795

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 599
--------------------------------------------------------------
Epoch:  599        1 Batch loss: 0.142901 Batch F1: 0.7222222222222223
Epoch:  599        2 Batch loss: 0.182098 Batch F1: 0.6818181818181818
Epoch:  599        3 Batch loss: 0.159164 Batch F1: 0.7755102040816326
Epoch:  599        4 Batch loss: 0.180434 Batch F1: 0.7346938775510204
Epoch:  599        5 Batch loss: 0.167954 Batch F1: 0.6666666666666666
Epoch:  599        6 Batch loss: 0.181635 Batch F1: 0.6511627906976744
Epoch:  599        7 Batch loss: 0.158329 Batch F1: 0.8214285714285715
Epoch:  599        8 Batch loss: 0.199350 Batch F1: 0.6046511627906976
Epoch:  599        9 Batch loss: 0.188743 Batch F1: 0.6190476190476191
Epoch:  599       10 Batch loss: 0.137112 Batch F1: 0.7804878048780487
Epoch:  599       11 Batch loss: 0.149175 Batch F1: 0.7999999999999999
Epoch:  599       12 Batch loss: 0.207914 Batch F1: 0.6341463414634146
Train Avg Loss  599: 0.171234

Train Avg F1  599: 0.7076529535538124

Val Avg Loss  599: 0.181460

Val Avg F1  599:  0.6686601307189541

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 600
--------------------------------------------------------------
Epoch:  600        1 Batch loss: 0.171509 Batch F1: 0.6500000000000001
Epoch:  600        2 Batch loss: 0.189162 Batch F1: 0.6808510638297872
Epoch:  600        3 Batch loss: 0.171579 Batch F1: 0.7999999999999999
Epoch:  600        4 Batch loss: 0.176546 Batch F1: 0.7636363636363638
Epoch:  600        5 Batch loss: 0.153610 Batch F1: 0.7027027027027027
Epoch:  600        6 Batch loss: 0.160178 Batch F1: 0.7272727272727272
Epoch:  600        7 Batch loss: 0.169986 Batch F1: 0.6666666666666666
Epoch:  600        8 Batch loss: 0.185297 Batch F1: 0.6153846153846154
Epoch:  600        9 Batch loss: 0.166544 Batch F1: 0.6976744186046512
Epoch:  600       10 Batch loss: 0.169700 Batch F1: 0.6818181818181819
Epoch:  600       11 Batch loss: 0.149470 Batch F1: 0.8163265306122449
Epoch:  600       12 Batch loss: 0.163188 Batch F1: 0.6666666666666667
Train Avg Loss  600: 0.168897

Train Avg F1  600: 0.7057499947662172

Val Avg Loss  600: 0.181158

Val Avg F1  600:  0.6749801424534813

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 601
--------------------------------------------------------------
Epoch:  601        1 Batch loss: 0.152363 Batch F1: 0.717948717948718
Epoch:  601        2 Batch loss: 0.192931 Batch F1: 0.68
Epoch:  601        3 Batch loss: 0.162585 Batch F1: 0.7
Epoch:  601        4 Batch loss: 0.161999 Batch F1: 0.7272727272727274
Epoch:  601        5 Batch loss: 0.178228 Batch F1: 0.7083333333333333
Epoch:  601        6 Batch loss: 0.195756 Batch F1: 0.6909090909090909
Epoch:  601        7 Batch loss: 0.166049 Batch F1: 0.6976744186046512
Epoch:  601        8 Batch loss: 0.160323 Batch F1: 0.75
Epoch:  601        9 Batch loss: 0.168600 Batch F1: 0.6938775510204082
Epoch:  601       10 Batch loss: 0.176935 Batch F1: 0.75
Epoch:  601       11 Batch loss: 0.139663 Batch F1: 0.8095238095238095
Epoch:  601       12 Batch loss: 0.177888 Batch F1: 0.5925925925925926
Train Avg Loss  601: 0.169443

Train Avg F1  601: 0.7098443534337777

Val Avg Loss  601: 0.181173

Val Avg F1  601:  0.6776437847866419

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 602
--------------------------------------------------------------
Epoch:  602        1 Batch loss: 0.179261 Batch F1: 0.7619047619047619
Epoch:  602        2 Batch loss: 0.166267 Batch F1: 0.75
Epoch:  602        3 Batch loss: 0.194090 Batch F1: 0.744186046511628
Epoch:  602        4 Batch loss: 0.166332 Batch F1: 0.7755102040816326
Epoch:  602        5 Batch loss: 0.166657 Batch F1: 0.7
Epoch:  602        6 Batch loss: 0.181691 Batch F1: 0.5789473684210527
Epoch:  602        7 Batch loss: 0.170122 Batch F1: 0.7111111111111111
Epoch:  602        8 Batch loss: 0.158038 Batch F1: 0.7826086956521738
Epoch:  602        9 Batch loss: 0.162361 Batch F1: 0.6842105263157895
Epoch:  602       10 Batch loss: 0.163044 Batch F1: 0.7027027027027027
Epoch:  602       11 Batch loss: 0.169880 Batch F1: 0.6818181818181819
Epoch:  602       12 Batch loss: 0.167711 Batch F1: 0.6896551724137931
Train Avg Loss  602: 0.170455

Train Avg F1  602: 0.7135545642444022

Val Avg Loss  602: 0.182911

Val Avg F1  602:  0.6762493513233004

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 603
--------------------------------------------------------------
Epoch:  603        1 Batch loss: 0.207194 Batch F1: 0.3888888888888889
Epoch:  603        2 Batch loss: 0.192217 Batch F1: 0.5641025641025641
Epoch:  603        3 Batch loss: 0.156279 Batch F1: 0.830188679245283
Epoch:  603        4 Batch loss: 0.165363 Batch F1: 0.8000000000000002
Epoch:  603        5 Batch loss: 0.161770 Batch F1: 0.6829268292682926
Epoch:  603        6 Batch loss: 0.152976 Batch F1: 0.7659574468085107
Epoch:  603        7 Batch loss: 0.176110 Batch F1: 0.6818181818181818
Epoch:  603        8 Batch loss: 0.166965 Batch F1: 0.6818181818181818
Epoch:  603        9 Batch loss: 0.155954 Batch F1: 0.8235294117647058
Epoch:  603       10 Batch loss: 0.186447 Batch F1: 0.6666666666666667
Epoch:  603       11 Batch loss: 0.147786 Batch F1: 0.816326530612245
Epoch:  603       12 Batch loss: 0.162165 Batch F1: 0.6875
Train Avg Loss  603: 0.169269

Train Avg F1  603: 0.6991436150827933

Val Avg Loss  603: 0.186884

Val Avg F1  603:  0.6783531497705465

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 604
--------------------------------------------------------------
Epoch:  604        1 Batch loss: 0.182906 Batch F1: 0.6511627906976744
Epoch:  604        2 Batch loss: 0.154396 Batch F1: 0.7555555555555556
Epoch:  604        3 Batch loss: 0.184237 Batch F1: 0.5789473684210527
Epoch:  604        4 Batch loss: 0.191894 Batch F1: 0.6222222222222222
Epoch:  604        5 Batch loss: 0.159570 Batch F1: 0.7843137254901961
Epoch:  604        6 Batch loss: 0.159224 Batch F1: 0.6842105263157895
Epoch:  604        7 Batch loss: 0.169636 Batch F1: 0.6060606060606061
Epoch:  604        8 Batch loss: 0.166529 Batch F1: 0.7755102040816326
Epoch:  604        9 Batch loss: 0.185012 Batch F1: 0.7450980392156863
Epoch:  604       10 Batch loss: 0.157713 Batch F1: 0.7391304347826088
Epoch:  604       11 Batch loss: 0.159173 Batch F1: 0.8076923076923076
Epoch:  604       12 Batch loss: 0.173211 Batch F1: 0.7058823529411764
Train Avg Loss  604: 0.170292

Train Avg F1  604: 0.7046488444563757

Val Avg Loss  604: 0.180632

Val Avg F1  604:  0.6640579113227756

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 605
--------------------------------------------------------------
Epoch:  605        1 Batch loss: 0.183047 Batch F1: 0.5714285714285714
Epoch:  605        2 Batch loss: 0.163376 Batch F1: 0.7843137254901961
Epoch:  605        3 Batch loss: 0.141764 Batch F1: 0.8260869565217391
Epoch:  605        4 Batch loss: 0.199815 Batch F1: 0.6153846153846153
Epoch:  605        5 Batch loss: 0.142943 Batch F1: 0.896551724137931
Epoch:  605        6 Batch loss: 0.200008 Batch F1: 0.5416666666666667
Epoch:  605        7 Batch loss: 0.169217 Batch F1: 0.8518518518518519
Epoch:  605        8 Batch loss: 0.197657 Batch F1: 0.75
Epoch:  605        9 Batch loss: 0.188526 Batch F1: 0.47058823529411764
Epoch:  605       10 Batch loss: 0.198757 Batch F1: 0.7441860465116279
Epoch:  605       11 Batch loss: 0.196847 Batch F1: 0.48484848484848486
Epoch:  605       12 Batch loss: 0.160592 Batch F1: 0.7368421052631577
Train Avg Loss  605: 0.178546

Train Avg F1  605: 0.6894790819499134

Val Avg Loss  605: 0.206395

Val Avg F1  605:  0.7777355476603598

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 606
--------------------------------------------------------------
Epoch:  606        1 Batch loss: 0.231566 Batch F1: 0.608695652173913
Epoch:  606        2 Batch loss: 0.188033 Batch F1: 0.744186046511628
Epoch:  606        3 Batch loss: 0.190217 Batch F1: 0.631578947368421
Epoch:  606        4 Batch loss: 0.194582 Batch F1: 0.6046511627906977
Epoch:  606        5 Batch loss: 0.177249 Batch F1: 0.7317073170731707
Epoch:  606        6 Batch loss: 0.171936 Batch F1: 0.8627450980392156
Epoch:  606        7 Batch loss: 0.165579 Batch F1: 0.6666666666666666
Epoch:  606        8 Batch loss: 0.166695 Batch F1: 0.6829268292682927
Epoch:  606        9 Batch loss: 0.166859 Batch F1: 0.7659574468085107
Epoch:  606       10 Batch loss: 0.171531 Batch F1: 0.7
Epoch:  606       11 Batch loss: 0.218624 Batch F1: 0.5499999999999999
Epoch:  606       12 Batch loss: 0.183745 Batch F1: 0.6818181818181819
Train Avg Loss  606: 0.185551

Train Avg F1  606: 0.6859111123765581

Val Avg Loss  606: 0.189670

Val Avg F1  606:  0.6407575757575759

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 607
--------------------------------------------------------------
Epoch:  607        1 Batch loss: 0.168294 Batch F1: 0.6666666666666666
Epoch:  607        2 Batch loss: 0.190305 Batch F1: 0.7272727272727272
Epoch:  607        3 Batch loss: 0.187763 Batch F1: 0.6153846153846154
Epoch:  607        4 Batch loss: 0.167757 Batch F1: 0.7391304347826088
Epoch:  607        5 Batch loss: 0.157016 Batch F1: 0.7692307692307692
Epoch:  607        6 Batch loss: 0.197806 Batch F1: 0.6382978723404256
Epoch:  607        7 Batch loss: 0.177369 Batch F1: 0.6956521739130435
Epoch:  607        8 Batch loss: 0.144197 Batch F1: 0.8695652173913043
Epoch:  607        9 Batch loss: 0.214943 Batch F1: 0.6046511627906977
Epoch:  607       10 Batch loss: 0.145996 Batch F1: 0.7826086956521738
Epoch:  607       11 Batch loss: 0.185725 Batch F1: 0.7755102040816326
Epoch:  607       12 Batch loss: 0.169603 Batch F1: 0.625
Train Avg Loss  607: 0.175564

Train Avg F1  607: 0.7090808782922222

Val Avg Loss  607: 0.186685

Val Avg F1  607:  0.6755806105230864

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 608
--------------------------------------------------------------
Epoch:  608        1 Batch loss: 0.196554 Batch F1: 0.693877551020408
Epoch:  608        2 Batch loss: 0.160872 Batch F1: 0.7755102040816326
Epoch:  608        3 Batch loss: 0.209078 Batch F1: 0.6923076923076923
Epoch:  608        4 Batch loss: 0.173727 Batch F1: 0.7391304347826089
Epoch:  608        5 Batch loss: 0.155681 Batch F1: 0.816326530612245
Epoch:  608        6 Batch loss: 0.185354 Batch F1: 0.5294117647058824
Epoch:  608        7 Batch loss: 0.166536 Batch F1: 0.7317073170731707
Epoch:  608        8 Batch loss: 0.191769 Batch F1: 0.6511627906976744
Epoch:  608        9 Batch loss: 0.164260 Batch F1: 0.7391304347826088
Epoch:  608       10 Batch loss: 0.152012 Batch F1: 0.8163265306122449
Epoch:  608       11 Batch loss: 0.220283 Batch F1: 0.5263157894736842
Epoch:  608       12 Batch loss: 0.142914 Batch F1: 0.7586206896551724
Train Avg Loss  608: 0.176587

Train Avg F1  608: 0.705818977483752

Val Avg Loss  608: 0.186974

Val Avg F1  608:  0.6790992136910268

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 609
--------------------------------------------------------------
Epoch:  609        1 Batch loss: 0.171604 Batch F1: 0.7346938775510204
Epoch:  609        2 Batch loss: 0.159283 Batch F1: 0.7804878048780488
Epoch:  609        3 Batch loss: 0.163790 Batch F1: 0.7
Epoch:  609        4 Batch loss: 0.136331 Batch F1: 0.8292682926829269
Epoch:  609        5 Batch loss: 0.166494 Batch F1: 0.7843137254901961
Epoch:  609        6 Batch loss: 0.182637 Batch F1: 0.7307692307692306
Epoch:  609        7 Batch loss: 0.179631 Batch F1: 0.7346938775510203
Epoch:  609        8 Batch loss: 0.185375 Batch F1: 0.64
Epoch:  609        9 Batch loss: 0.204416 Batch F1: 0.6086956521739131
Epoch:  609       10 Batch loss: 0.181158 Batch F1: 0.6818181818181818
Epoch:  609       11 Batch loss: 0.194350 Batch F1: 0.5499999999999999
Epoch:  609       12 Batch loss: 0.170409 Batch F1: 0.6451612903225806
Train Avg Loss  609: 0.174623

Train Avg F1  609: 0.7016584944364265

Val Avg Loss  609: 0.186027

Val Avg F1  609:  0.676894073288559

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 610
--------------------------------------------------------------
Epoch:  610        1 Batch loss: 0.174167 Batch F1: 0.7142857142857143
Epoch:  610        2 Batch loss: 0.166334 Batch F1: 0.6976744186046512
Epoch:  610        3 Batch loss: 0.214963 Batch F1: 0.5454545454545454
Epoch:  610        4 Batch loss: 0.160151 Batch F1: 0.7804878048780488
Epoch:  610        5 Batch loss: 0.157368 Batch F1: 0.7804878048780488
Epoch:  610        6 Batch loss: 0.159956 Batch F1: 0.7826086956521738
Epoch:  610        7 Batch loss: 0.167172 Batch F1: 0.8235294117647057
Epoch:  610        8 Batch loss: 0.186797 Batch F1: 0.6521739130434783
Epoch:  610        9 Batch loss: 0.150260 Batch F1: 0.851063829787234
Epoch:  610       10 Batch loss: 0.181868 Batch F1: 0.5777777777777778
Epoch:  610       11 Batch loss: 0.198842 Batch F1: 0.6511627906976744
Epoch:  610       12 Batch loss: 0.208837 Batch F1: 0.6666666666666666
Train Avg Loss  610: 0.177226

Train Avg F1  610: 0.7102811144575599

Val Avg Loss  610: 0.188624

Val Avg F1  610:  0.6786376902230562

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 611
--------------------------------------------------------------
Epoch:  611        1 Batch loss: 0.137685 Batch F1: 0.8510638297872339
Epoch:  611        2 Batch loss: 0.200132 Batch F1: 0.7096774193548386
Epoch:  611        3 Batch loss: 0.164276 Batch F1: 0.6818181818181819
Epoch:  611        4 Batch loss: 0.193055 Batch F1: 0.6086956521739131
Epoch:  611        5 Batch loss: 0.174229 Batch F1: 0.7999999999999999
Epoch:  611        6 Batch loss: 0.207502 Batch F1: 0.5714285714285714
Epoch:  611        7 Batch loss: 0.181236 Batch F1: 0.6938775510204083
Epoch:  611        8 Batch loss: 0.201625 Batch F1: 0.5581395348837208
Epoch:  611        9 Batch loss: 0.200003 Batch F1: 0.6296296296296297
Epoch:  611       10 Batch loss: 0.208369 Batch F1: 0.5263157894736842
Epoch:  611       11 Batch loss: 0.153610 Batch F1: 0.7058823529411765
Epoch:  611       12 Batch loss: 0.165850 Batch F1: 0.75
Train Avg Loss  611: 0.182298

Train Avg F1  611: 0.6738773760426131

Val Avg Loss  611: 0.187531

Val Avg F1  611:  0.6768027210884353

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 612
--------------------------------------------------------------
Epoch:  612        1 Batch loss: 0.210305 Batch F1: 0.5128205128205129
Epoch:  612        2 Batch loss: 0.183268 Batch F1: 0.6666666666666666
Epoch:  612        3 Batch loss: 0.162513 Batch F1: 0.7906976744186046
Epoch:  612        4 Batch loss: 0.190082 Batch F1: 0.6666666666666666
Epoch:  612        5 Batch loss: 0.173827 Batch F1: 0.7346938775510204
Epoch:  612        6 Batch loss: 0.219462 Batch F1: 0.5652173913043478
Epoch:  612        7 Batch loss: 0.203164 Batch F1: 0.6666666666666667
Epoch:  612        8 Batch loss: 0.159585 Batch F1: 0.7555555555555556
Epoch:  612        9 Batch loss: 0.169257 Batch F1: 0.7441860465116279
Epoch:  612       10 Batch loss: 0.148188 Batch F1: 0.8
Epoch:  612       11 Batch loss: 0.149216 Batch F1: 0.816326530612245
Epoch:  612       12 Batch loss: 0.138566 Batch F1: 0.8387096774193549
Train Avg Loss  612: 0.175619

Train Avg F1  612: 0.713183938849439

Val Avg Loss  612: 0.183621

Val Avg F1  612:  0.6738357577073383

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 613
--------------------------------------------------------------
Epoch:  613        1 Batch loss: 0.180358 Batch F1: 0.6511627906976744
Epoch:  613        2 Batch loss: 0.160613 Batch F1: 0.7555555555555555
Epoch:  613        3 Batch loss: 0.146976 Batch F1: 0.7272727272727272
Epoch:  613        4 Batch loss: 0.178107 Batch F1: 0.7547169811320754
Epoch:  613        5 Batch loss: 0.158809 Batch F1: 0.7727272727272727
Epoch:  613        6 Batch loss: 0.176222 Batch F1: 0.7407407407407408
Epoch:  613        7 Batch loss: 0.165540 Batch F1: 0.7500000000000001
Epoch:  613        8 Batch loss: 0.197936 Batch F1: 0.5909090909090909
Epoch:  613        9 Batch loss: 0.197908 Batch F1: 0.5405405405405405
Epoch:  613       10 Batch loss: 0.178306 Batch F1: 0.6666666666666666
Epoch:  613       11 Batch loss: 0.162352 Batch F1: 0.782608695652174
Epoch:  613       12 Batch loss: 0.155298 Batch F1: 0.7777777777777777
Train Avg Loss  613: 0.171535

Train Avg F1  613: 0.7092232366393579

Val Avg Loss  613: 0.183454

Val Avg F1  613:  0.6762987012987013

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 614
--------------------------------------------------------------
Epoch:  614        1 Batch loss: 0.202880 Batch F1: 0.6382978723404256
Epoch:  614        2 Batch loss: 0.179740 Batch F1: 0.6938775510204083
Epoch:  614        3 Batch loss: 0.181972 Batch F1: 0.5945945945945946
Epoch:  614        4 Batch loss: 0.164386 Batch F1: 0.7142857142857143
Epoch:  614        5 Batch loss: 0.170420 Batch F1: 0.7391304347826088
Epoch:  614        6 Batch loss: 0.138111 Batch F1: 0.8627450980392156
Epoch:  614        7 Batch loss: 0.135745 Batch F1: 0.8372093023255814
Epoch:  614        8 Batch loss: 0.179405 Batch F1: 0.723404255319149
Epoch:  614        9 Batch loss: 0.194757 Batch F1: 0.6363636363636364
Epoch:  614       10 Batch loss: 0.162421 Batch F1: 0.717948717948718
Epoch:  614       11 Batch loss: 0.164877 Batch F1: 0.7555555555555556
Epoch:  614       12 Batch loss: 0.184473 Batch F1: 0.588235294117647
Train Avg Loss  614: 0.171599

Train Avg F1  614: 0.7084706688911045

Val Avg Loss  614: 0.182669

Val Avg F1  614:  0.6763102012205179

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 615
--------------------------------------------------------------
Epoch:  615        1 Batch loss: 0.185462 Batch F1: 0.7407407407407408
Epoch:  615        2 Batch loss: 0.165701 Batch F1: 0.625
Epoch:  615        3 Batch loss: 0.186613 Batch F1: 0.6363636363636364
Epoch:  615        4 Batch loss: 0.180251 Batch F1: 0.6511627906976744
Epoch:  615        5 Batch loss: 0.183606 Batch F1: 0.7169811320754716
Epoch:  615        6 Batch loss: 0.167670 Batch F1: 0.7555555555555555
Epoch:  615        7 Batch loss: 0.189177 Batch F1: 0.6222222222222222
Epoch:  615        8 Batch loss: 0.171507 Batch F1: 0.5161290322580646
Epoch:  615        9 Batch loss: 0.155245 Batch F1: 0.7027027027027027
Epoch:  615       10 Batch loss: 0.142371 Batch F1: 0.8372093023255814
Epoch:  615       11 Batch loss: 0.150303 Batch F1: 0.8076923076923077
Epoch:  615       12 Batch loss: 0.158609 Batch F1: 0.8260869565217391
Train Avg Loss  615: 0.169709

Train Avg F1  615: 0.7031538649296413

Val Avg Loss  615: 0.181485

Val Avg F1  615:  0.6718449877918317

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 616
--------------------------------------------------------------
Epoch:  616        1 Batch loss: 0.179962 Batch F1: 0.6153846153846153
Epoch:  616        2 Batch loss: 0.161189 Batch F1: 0.6829268292682926
Epoch:  616        3 Batch loss: 0.161904 Batch F1: 0.7317073170731706
Epoch:  616        4 Batch loss: 0.155021 Batch F1: 0.8235294117647058
Epoch:  616        5 Batch loss: 0.202970 Batch F1: 0.68
Epoch:  616        6 Batch loss: 0.176929 Batch F1: 0.6808510638297872
Epoch:  616        7 Batch loss: 0.202518 Batch F1: 0.64
Epoch:  616        8 Batch loss: 0.152646 Batch F1: 0.7804878048780488
Epoch:  616        9 Batch loss: 0.150535 Batch F1: 0.7500000000000001
Epoch:  616       10 Batch loss: 0.157174 Batch F1: 0.717948717948718
Epoch:  616       11 Batch loss: 0.172500 Batch F1: 0.711111111111111
Epoch:  616       12 Batch loss: 0.168146 Batch F1: 0.7500000000000001
Train Avg Loss  616: 0.170125

Train Avg F1  616: 0.7136622392715375

Val Avg Loss  616: 0.182414

Val Avg F1  616:  0.6759924472690431

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 617
--------------------------------------------------------------
Epoch:  617        1 Batch loss: 0.190870 Batch F1: 0.6190476190476191
Epoch:  617        2 Batch loss: 0.178143 Batch F1: 0.7547169811320754
Epoch:  617        3 Batch loss: 0.172689 Batch F1: 0.7111111111111111
Epoch:  617        4 Batch loss: 0.161811 Batch F1: 0.7142857142857143
Epoch:  617        5 Batch loss: 0.143838 Batch F1: 0.7777777777777778
Epoch:  617        6 Batch loss: 0.165477 Batch F1: 0.7272727272727272
Epoch:  617        7 Batch loss: 0.165676 Batch F1: 0.711111111111111
Epoch:  617        8 Batch loss: 0.184749 Batch F1: 0.7058823529411765
Epoch:  617        9 Batch loss: 0.144860 Batch F1: 0.7843137254901961
Epoch:  617       10 Batch loss: 0.169122 Batch F1: 0.75
Epoch:  617       11 Batch loss: 0.208832 Batch F1: 0.5217391304347826
Epoch:  617       12 Batch loss: 0.168770 Batch F1: 0.7142857142857143
Train Avg Loss  617: 0.171236

Train Avg F1  617: 0.7076286637408337

Val Avg Loss  617: 0.180755

Val Avg F1  617:  0.6773895035915084

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 618
--------------------------------------------------------------
Epoch:  618        1 Batch loss: 0.144608 Batch F1: 0.8333333333333333
Epoch:  618        2 Batch loss: 0.150076 Batch F1: 0.7906976744186046
Epoch:  618        3 Batch loss: 0.169227 Batch F1: 0.7346938775510203
Epoch:  618        4 Batch loss: 0.182268 Batch F1: 0.5454545454545455
Epoch:  618        5 Batch loss: 0.171731 Batch F1: 0.7111111111111111
Epoch:  618        6 Batch loss: 0.199320 Batch F1: 0.6538461538461539
Epoch:  618        7 Batch loss: 0.158652 Batch F1: 0.7659574468085107
Epoch:  618        8 Batch loss: 0.145588 Batch F1: 0.8085106382978724
Epoch:  618        9 Batch loss: 0.214401 Batch F1: 0.5714285714285715
Epoch:  618       10 Batch loss: 0.192029 Batch F1: 0.6792452830188679
Epoch:  618       11 Batch loss: 0.159512 Batch F1: 0.6451612903225806
Epoch:  618       12 Batch loss: 0.161464 Batch F1: 0.7428571428571428
Train Avg Loss  618: 0.170740

Train Avg F1  618: 0.7068580890373596

Val Avg Loss  618: 0.181412

Val Avg F1  618:  0.6736711470099492

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 619
--------------------------------------------------------------
Epoch:  619        1 Batch loss: 0.143085 Batch F1: 0.8260869565217391
Epoch:  619        2 Batch loss: 0.184066 Batch F1: 0.5789473684210527
Epoch:  619        3 Batch loss: 0.158631 Batch F1: 0.7659574468085107
Epoch:  619        4 Batch loss: 0.167759 Batch F1: 0.7692307692307692
Epoch:  619        5 Batch loss: 0.183505 Batch F1: 0.6511627906976744
Epoch:  619        6 Batch loss: 0.164178 Batch F1: 0.7843137254901961
Epoch:  619        7 Batch loss: 0.162519 Batch F1: 0.6956521739130435
Epoch:  619        8 Batch loss: 0.167780 Batch F1: 0.7111111111111111
Epoch:  619        9 Batch loss: 0.181676 Batch F1: 0.6153846153846154
Epoch:  619       10 Batch loss: 0.158399 Batch F1: 0.7368421052631577
Epoch:  619       11 Batch loss: 0.173597 Batch F1: 0.711111111111111
Epoch:  619       12 Batch loss: 0.182364 Batch F1: 0.6285714285714286
Train Avg Loss  619: 0.168963

Train Avg F1  619: 0.7061976335437009

Val Avg Loss  619: 0.181935

Val Avg F1  619:  0.6654984799498143

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 620
--------------------------------------------------------------
Epoch:  620        1 Batch loss: 0.169699 Batch F1: 0.6666666666666666
Epoch:  620        2 Batch loss: 0.193298 Batch F1: 0.5909090909090909
Epoch:  620        3 Batch loss: 0.161986 Batch F1: 0.7843137254901961
Epoch:  620        4 Batch loss: 0.153204 Batch F1: 0.7727272727272727
Epoch:  620        5 Batch loss: 0.185260 Batch F1: 0.6190476190476191
Epoch:  620        6 Batch loss: 0.161086 Batch F1: 0.606060606060606
Epoch:  620        7 Batch loss: 0.152119 Batch F1: 0.7906976744186046
Epoch:  620        8 Batch loss: 0.146342 Batch F1: 0.8400000000000001
Epoch:  620        9 Batch loss: 0.216018 Batch F1: 0.5777777777777778
Epoch:  620       10 Batch loss: 0.161596 Batch F1: 0.7843137254901961
Epoch:  620       11 Batch loss: 0.144224 Batch F1: 0.7826086956521738
Epoch:  620       12 Batch loss: 0.192441 Batch F1: 0.65
Train Avg Loss  620: 0.169773

Train Avg F1  620: 0.7054269045200169

Val Avg Loss  620: 0.180445

Val Avg F1  620:  0.6700264812975835

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 621
--------------------------------------------------------------
Epoch:  621        1 Batch loss: 0.196250 Batch F1: 0.5128205128205129
Epoch:  621        2 Batch loss: 0.202506 Batch F1: 0.6222222222222222
Epoch:  621        3 Batch loss: 0.181001 Batch F1: 0.6511627906976744
Epoch:  621        4 Batch loss: 0.166182 Batch F1: 0.7547169811320756
Epoch:  621        5 Batch loss: 0.147058 Batch F1: 0.7727272727272727
Epoch:  621        6 Batch loss: 0.166276 Batch F1: 0.7441860465116279
Epoch:  621        7 Batch loss: 0.161217 Batch F1: 0.7
Epoch:  621        8 Batch loss: 0.199012 Batch F1: 0.6666666666666666
Epoch:  621        9 Batch loss: 0.140128 Batch F1: 0.8181818181818182
Epoch:  621       10 Batch loss: 0.140021 Batch F1: 0.7692307692307693
Epoch:  621       11 Batch loss: 0.165768 Batch F1: 0.76
Epoch:  621       12 Batch loss: 0.164290 Batch F1: 0.7500000000000001
Train Avg Loss  621: 0.169142

Train Avg F1  621: 0.7101595900158868

Val Avg Loss  621: 0.180826

Val Avg F1  621:  0.672781713900135

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 622
--------------------------------------------------------------
Epoch:  622        1 Batch loss: 0.154323 Batch F1: 0.7027027027027027
Epoch:  622        2 Batch loss: 0.154809 Batch F1: 0.7916666666666667
Epoch:  622        3 Batch loss: 0.205939 Batch F1: 0.5333333333333333
Epoch:  622        4 Batch loss: 0.154098 Batch F1: 0.717948717948718
Epoch:  622        5 Batch loss: 0.155341 Batch F1: 0.7906976744186046
Epoch:  622        6 Batch loss: 0.153297 Batch F1: 0.7499999999999999
Epoch:  622        7 Batch loss: 0.175086 Batch F1: 0.6666666666666666
Epoch:  622        8 Batch loss: 0.202316 Batch F1: 0.5909090909090909
Epoch:  622        9 Batch loss: 0.160660 Batch F1: 0.7272727272727273
Epoch:  622       10 Batch loss: 0.167009 Batch F1: 0.8524590163934426
Epoch:  622       11 Batch loss: 0.180060 Batch F1: 0.631578947368421
Epoch:  622       12 Batch loss: 0.199321 Batch F1: 0.7272727272727272
Train Avg Loss  622: 0.171855

Train Avg F1  622: 0.7068756892460918

Val Avg Loss  622: 0.181551

Val Avg F1  622:  0.671353065539112

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 623
--------------------------------------------------------------
Epoch:  623        1 Batch loss: 0.211076 Batch F1: 0.6222222222222222
Epoch:  623        2 Batch loss: 0.145755 Batch F1: 0.761904761904762
Epoch:  623        3 Batch loss: 0.141639 Batch F1: 0.8181818181818182
Epoch:  623        4 Batch loss: 0.161344 Batch F1: 0.6956521739130435
Epoch:  623        5 Batch loss: 0.140164 Batch F1: 0.8260869565217391
Epoch:  623        6 Batch loss: 0.191994 Batch F1: 0.6530612244897959
Epoch:  623        7 Batch loss: 0.181086 Batch F1: 0.6363636363636364
Epoch:  623        8 Batch loss: 0.158412 Batch F1: 0.7027027027027026
Epoch:  623        9 Batch loss: 0.172099 Batch F1: 0.7692307692307693
Epoch:  623       10 Batch loss: 0.168391 Batch F1: 0.6829268292682927
Epoch:  623       11 Batch loss: 0.165460 Batch F1: 0.7272727272727273
Epoch:  623       12 Batch loss: 0.184428 Batch F1: 0.6285714285714287
Train Avg Loss  623: 0.168487

Train Avg F1  623: 0.7103481042202447

Val Avg Loss  623: 0.180627

Val Avg F1  623:  0.6643206854345165

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 624
--------------------------------------------------------------
Epoch:  624        1 Batch loss: 0.224910 Batch F1: 0.5660377358490566
Epoch:  624        2 Batch loss: 0.212136 Batch F1: 0.5777777777777778
Epoch:  624        3 Batch loss: 0.172774 Batch F1: 0.7058823529411765
Epoch:  624        4 Batch loss: 0.166589 Batch F1: 0.7547169811320754
Epoch:  624        5 Batch loss: 0.135328 Batch F1: 0.7647058823529412
Epoch:  624        6 Batch loss: 0.149333 Batch F1: 0.8108108108108107
Epoch:  624        7 Batch loss: 0.151453 Batch F1: 0.7906976744186046
Epoch:  624        8 Batch loss: 0.180283 Batch F1: 0.6818181818181819
Epoch:  624        9 Batch loss: 0.191010 Batch F1: 0.7200000000000001
Epoch:  624       10 Batch loss: 0.151390 Batch F1: 0.7727272727272727
Epoch:  624       11 Batch loss: 0.145257 Batch F1: 0.7368421052631577
Epoch:  624       12 Batch loss: 0.168226 Batch F1: 0.7272727272727272
Train Avg Loss  624: 0.170724

Train Avg F1  624: 0.7174407918636484

Val Avg Loss  624: 0.180724

Val Avg F1  624:  0.6791522762951334

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 625
--------------------------------------------------------------
Epoch:  625        1 Batch loss: 0.154694 Batch F1: 0.8085106382978724
Epoch:  625        2 Batch loss: 0.193148 Batch F1: 0.6666666666666667
Epoch:  625        3 Batch loss: 0.161307 Batch F1: 0.7659574468085107
Epoch:  625        4 Batch loss: 0.141636 Batch F1: 0.7906976744186047
Epoch:  625        5 Batch loss: 0.206602 Batch F1: 0.6250000000000001
Epoch:  625        6 Batch loss: 0.156455 Batch F1: 0.782608695652174
Epoch:  625        7 Batch loss: 0.173595 Batch F1: 0.6956521739130435
Epoch:  625        8 Batch loss: 0.163043 Batch F1: 0.5882352941176471
Epoch:  625        9 Batch loss: 0.151375 Batch F1: 0.7555555555555555
Epoch:  625       10 Batch loss: 0.179439 Batch F1: 0.6222222222222222
Epoch:  625       11 Batch loss: 0.166309 Batch F1: 0.8085106382978723
Epoch:  625       12 Batch loss: 0.206738 Batch F1: 0.6190476190476191
Train Avg Loss  625: 0.171195

Train Avg F1  625: 0.7107220520831491

Val Avg Loss  625: 0.182367

Val Avg F1  625:  0.6707418816583237

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 626
--------------------------------------------------------------
Epoch:  626        1 Batch loss: 0.163434 Batch F1: 0.7755102040816326
Epoch:  626        2 Batch loss: 0.172730 Batch F1: 0.6956521739130435
Epoch:  626        3 Batch loss: 0.177199 Batch F1: 0.7083333333333334
Epoch:  626        4 Batch loss: 0.151920 Batch F1: 0.7027027027027027
Epoch:  626        5 Batch loss: 0.180554 Batch F1: 0.6363636363636365
Epoch:  626        6 Batch loss: 0.159360 Batch F1: 0.8235294117647058
Epoch:  626        7 Batch loss: 0.207945 Batch F1: 0.68
Epoch:  626        8 Batch loss: 0.161238 Batch F1: 0.7441860465116279
Epoch:  626        9 Batch loss: 0.182637 Batch F1: 0.6666666666666667
Epoch:  626       10 Batch loss: 0.155269 Batch F1: 0.782608695652174
Epoch:  626       11 Batch loss: 0.171448 Batch F1: 0.6500000000000001
Epoch:  626       12 Batch loss: 0.180489 Batch F1: 0.625
Train Avg Loss  626: 0.172019

Train Avg F1  626: 0.7075460725824602

Val Avg Loss  626: 0.184524

Val Avg F1  626:  0.6747286148501954

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 627
--------------------------------------------------------------
Epoch:  627        1 Batch loss: 0.171667 Batch F1: 0.6
Epoch:  627        2 Batch loss: 0.167163 Batch F1: 0.7916666666666666
Epoch:  627        3 Batch loss: 0.165454 Batch F1: 0.7272727272727272
Epoch:  627        4 Batch loss: 0.165153 Batch F1: 0.6956521739130435
Epoch:  627        5 Batch loss: 0.160345 Batch F1: 0.7857142857142857
Epoch:  627        6 Batch loss: 0.192064 Batch F1: 0.68
Epoch:  627        7 Batch loss: 0.182985 Batch F1: 0.7916666666666667
Epoch:  627        8 Batch loss: 0.165819 Batch F1: 0.7916666666666667
Epoch:  627        9 Batch loss: 0.170861 Batch F1: 0.7659574468085107
Epoch:  627       10 Batch loss: 0.171048 Batch F1: 0.6829268292682926
Epoch:  627       11 Batch loss: 0.160107 Batch F1: 0.606060606060606
Epoch:  627       12 Batch loss: 0.180495 Batch F1: 0.7659574468085107
Train Avg Loss  627: 0.171097

Train Avg F1  627: 0.7237117929871646

Val Avg Loss  627: 0.183816

Val Avg F1  627:  0.6697014545851755

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 628
--------------------------------------------------------------
Epoch:  628        1 Batch loss: 0.155880 Batch F1: 0.6486486486486486
Epoch:  628        2 Batch loss: 0.177954 Batch F1: 0.6153846153846153
Epoch:  628        3 Batch loss: 0.164938 Batch F1: 0.8076923076923077
Epoch:  628        4 Batch loss: 0.179402 Batch F1: 0.711111111111111
Epoch:  628        5 Batch loss: 0.182488 Batch F1: 0.6363636363636365
Epoch:  628        6 Batch loss: 0.155321 Batch F1: 0.7428571428571428
Epoch:  628        7 Batch loss: 0.178972 Batch F1: 0.6666666666666666
Epoch:  628        8 Batch loss: 0.163342 Batch F1: 0.782608695652174
Epoch:  628        9 Batch loss: 0.178779 Batch F1: 0.6842105263157895
Epoch:  628       10 Batch loss: 0.210450 Batch F1: 0.5238095238095238
Epoch:  628       11 Batch loss: 0.191529 Batch F1: 0.6923076923076923
Epoch:  628       12 Batch loss: 0.168567 Batch F1: 0.7894736842105263
Train Avg Loss  628: 0.175635

Train Avg F1  628: 0.6917611875849863

Val Avg Loss  628: 0.182088

Val Avg F1  628:  0.6770833333333334

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 629
--------------------------------------------------------------
Epoch:  629        1 Batch loss: 0.158444 Batch F1: 0.7755102040816326
Epoch:  629        2 Batch loss: 0.190321 Batch F1: 0.6363636363636365
Epoch:  629        3 Batch loss: 0.172004 Batch F1: 0.7931034482758621
Epoch:  629        4 Batch loss: 0.203694 Batch F1: 0.5853658536585366
Epoch:  629        5 Batch loss: 0.162259 Batch F1: 0.7441860465116279
Epoch:  629        6 Batch loss: 0.178524 Batch F1: 0.6
Epoch:  629        7 Batch loss: 0.155198 Batch F1: 0.7619047619047619
Epoch:  629        8 Batch loss: 0.128927 Batch F1: 0.8372093023255814
Epoch:  629        9 Batch loss: 0.162852 Batch F1: 0.6829268292682926
Epoch:  629       10 Batch loss: 0.171929 Batch F1: 0.6976744186046512
Epoch:  629       11 Batch loss: 0.187309 Batch F1: 0.6341463414634148
Epoch:  629       12 Batch loss: 0.162481 Batch F1: 0.7500000000000001
Train Avg Loss  629: 0.169495

Train Avg F1  629: 0.7081992368714998

Val Avg Loss  629: 0.180996

Val Avg F1  629:  0.6722396650968079

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 630
--------------------------------------------------------------
Epoch:  630        1 Batch loss: 0.159089 Batch F1: 0.717948717948718
Epoch:  630        2 Batch loss: 0.172230 Batch F1: 0.6666666666666666
Epoch:  630        3 Batch loss: 0.194506 Batch F1: 0.6666666666666667
Epoch:  630        4 Batch loss: 0.177953 Batch F1: 0.6521739130434783
Epoch:  630        5 Batch loss: 0.186565 Batch F1: 0.6808510638297872
Epoch:  630        6 Batch loss: 0.169694 Batch F1: 0.7391304347826085
Epoch:  630        7 Batch loss: 0.136891 Batch F1: 0.7894736842105262
Epoch:  630        8 Batch loss: 0.165782 Batch F1: 0.8070175438596491
Epoch:  630        9 Batch loss: 0.158956 Batch F1: 0.6842105263157895
Epoch:  630       10 Batch loss: 0.165462 Batch F1: 0.7142857142857143
Epoch:  630       11 Batch loss: 0.168389 Batch F1: 0.723404255319149
Epoch:  630       12 Batch loss: 0.173141 Batch F1: 0.6857142857142857
Train Avg Loss  630: 0.169055

Train Avg F1  630: 0.7106286227202533

Val Avg Loss  630: 0.181022

Val Avg F1  630:  0.6737666875260743

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 631
--------------------------------------------------------------
Epoch:  631        1 Batch loss: 0.165082 Batch F1: 0.7391304347826088
Epoch:  631        2 Batch loss: 0.171529 Batch F1: 0.6666666666666667
Epoch:  631        3 Batch loss: 0.169692 Batch F1: 0.7499999999999999
Epoch:  631        4 Batch loss: 0.170316 Batch F1: 0.7999999999999999
Epoch:  631        5 Batch loss: 0.165477 Batch F1: 0.76
Epoch:  631        6 Batch loss: 0.202168 Batch F1: 0.5777777777777778
Epoch:  631        7 Batch loss: 0.164020 Batch F1: 0.7317073170731707
Epoch:  631        8 Batch loss: 0.186332 Batch F1: 0.5263157894736842
Epoch:  631        9 Batch loss: 0.160947 Batch F1: 0.6842105263157895
Epoch:  631       10 Batch loss: 0.174357 Batch F1: 0.6829268292682927
Epoch:  631       11 Batch loss: 0.157806 Batch F1: 0.75
Epoch:  631       12 Batch loss: 0.136277 Batch F1: 0.8333333333333334
Train Avg Loss  631: 0.168667

Train Avg F1  631: 0.7085057228909436

Val Avg Loss  631: 0.183612

Val Avg F1  631:  0.67353298875038

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 632
--------------------------------------------------------------
Epoch:  632        1 Batch loss: 0.199789 Batch F1: 0.5957446808510638
Epoch:  632        2 Batch loss: 0.180705 Batch F1: 0.5945945945945946
Epoch:  632        3 Batch loss: 0.170682 Batch F1: 0.7272727272727273
Epoch:  632        4 Batch loss: 0.173785 Batch F1: 0.7547169811320756
Epoch:  632        5 Batch loss: 0.140044 Batch F1: 0.8444444444444444
Epoch:  632        6 Batch loss: 0.156853 Batch F1: 0.84
Epoch:  632        7 Batch loss: 0.193715 Batch F1: 0.6046511627906977
Epoch:  632        8 Batch loss: 0.154561 Batch F1: 0.761904761904762
Epoch:  632        9 Batch loss: 0.183266 Batch F1: 0.72
Epoch:  632       10 Batch loss: 0.148488 Batch F1: 0.7368421052631577
Epoch:  632       11 Batch loss: 0.180464 Batch F1: 0.6808510638297872
Epoch:  632       12 Batch loss: 0.177200 Batch F1: 0.6206896551724138
Train Avg Loss  632: 0.171629

Train Avg F1  632: 0.7068093481046437

Val Avg Loss  632: 0.182186

Val Avg F1  632:  0.6752566708359391

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 633
--------------------------------------------------------------
Epoch:  633        1 Batch loss: 0.194287 Batch F1: 0.6250000000000001
Epoch:  633        2 Batch loss: 0.154168 Batch F1: 0.7428571428571429
Epoch:  633        3 Batch loss: 0.196607 Batch F1: 0.5777777777777778
Epoch:  633        4 Batch loss: 0.158865 Batch F1: 0.8333333333333333
Epoch:  633        5 Batch loss: 0.179197 Batch F1: 0.8444444444444443
Epoch:  633        6 Batch loss: 0.160177 Batch F1: 0.7555555555555555
Epoch:  633        7 Batch loss: 0.163506 Batch F1: 0.7346938775510203
Epoch:  633        8 Batch loss: 0.171095 Batch F1: 0.6842105263157895
Epoch:  633        9 Batch loss: 0.141098 Batch F1: 0.8000000000000002
Epoch:  633       10 Batch loss: 0.219622 Batch F1: 0.6296296296296297
Epoch:  633       11 Batch loss: 0.170037 Batch F1: 0.7659574468085107
Epoch:  633       12 Batch loss: 0.169806 Batch F1: 0.7058823529411765
Train Avg Loss  633: 0.173205

Train Avg F1  633: 0.7249451739345316

Val Avg Loss  633: 0.184532

Val Avg F1  633:  0.6767550621852195

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 634
--------------------------------------------------------------
Epoch:  634        1 Batch loss: 0.145148 Batch F1: 0.7916666666666667
Epoch:  634        2 Batch loss: 0.146895 Batch F1: 0.8260869565217391
Epoch:  634        3 Batch loss: 0.196231 Batch F1: 0.6222222222222222
Epoch:  634        4 Batch loss: 0.165699 Batch F1: 0.7916666666666667
Epoch:  634        5 Batch loss: 0.164952 Batch F1: 0.7843137254901961
Epoch:  634        6 Batch loss: 0.192073 Batch F1: 0.5853658536585366
Epoch:  634        7 Batch loss: 0.161863 Batch F1: 0.6842105263157895
Epoch:  634        8 Batch loss: 0.182043 Batch F1: 0.6666666666666666
Epoch:  634        9 Batch loss: 0.196521 Batch F1: 0.6666666666666666
Epoch:  634       10 Batch loss: 0.167777 Batch F1: 0.6666666666666667
Epoch:  634       11 Batch loss: 0.133228 Batch F1: 0.8260869565217392
Epoch:  634       12 Batch loss: 0.189705 Batch F1: 0.5625
Train Avg Loss  634: 0.170178

Train Avg F1  634: 0.7061766311719632

Val Avg Loss  634: 0.180303

Val Avg F1  634:  0.6756719367588933

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 635
--------------------------------------------------------------
Epoch:  635        1 Batch loss: 0.146284 Batch F1: 0.8235294117647058
Epoch:  635        2 Batch loss: 0.155828 Batch F1: 0.7317073170731706
Epoch:  635        3 Batch loss: 0.213507 Batch F1: 0.4761904761904762
Epoch:  635        4 Batch loss: 0.163860 Batch F1: 0.6060606060606061
Epoch:  635        5 Batch loss: 0.172005 Batch F1: 0.7346938775510204
Epoch:  635        6 Batch loss: 0.174351 Batch F1: 0.7234042553191491
Epoch:  635        7 Batch loss: 0.168889 Batch F1: 0.7499999999999999
Epoch:  635        8 Batch loss: 0.200721 Batch F1: 0.6382978723404256
Epoch:  635        9 Batch loss: 0.159390 Batch F1: 0.6285714285714286
Epoch:  635       10 Batch loss: 0.148326 Batch F1: 0.8
Epoch:  635       11 Batch loss: 0.162558 Batch F1: 0.8076923076923077
Epoch:  635       12 Batch loss: 0.148286 Batch F1: 0.7428571428571428
Train Avg Loss  635: 0.167834

Train Avg F1  635: 0.705250391285036

Val Avg Loss  635: 0.182972

Val Avg F1  635:  0.6773305006805724

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 636
--------------------------------------------------------------
Epoch:  636        1 Batch loss: 0.190157 Batch F1: 0.6363636363636365
Epoch:  636        2 Batch loss: 0.161153 Batch F1: 0.7727272727272727
Epoch:  636        3 Batch loss: 0.166923 Batch F1: 0.6666666666666666
Epoch:  636        4 Batch loss: 0.150314 Batch F1: 0.7826086956521738
Epoch:  636        5 Batch loss: 0.162973 Batch F1: 0.7500000000000001
Epoch:  636        6 Batch loss: 0.141309 Batch F1: 0.7272727272727273
Epoch:  636        7 Batch loss: 0.174875 Batch F1: 0.7200000000000001
Epoch:  636        8 Batch loss: 0.178043 Batch F1: 0.7719298245614035
Epoch:  636        9 Batch loss: 0.164885 Batch F1: 0.7499999999999999
Epoch:  636       10 Batch loss: 0.182004 Batch F1: 0.6956521739130435
Epoch:  636       11 Batch loss: 0.185801 Batch F1: 0.5294117647058824
Epoch:  636       12 Batch loss: 0.163681 Batch F1: 0.6666666666666667
Train Avg Loss  636: 0.168510

Train Avg F1  636: 0.7057749523774559

Val Avg Loss  636: 0.180641

Val Avg F1  636:  0.675886109892253

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 637
--------------------------------------------------------------
Epoch:  637        1 Batch loss: 0.202531 Batch F1: 0.5581395348837209
Epoch:  637        2 Batch loss: 0.170621 Batch F1: 0.7755102040816326
Epoch:  637        3 Batch loss: 0.179363 Batch F1: 0.7307692307692307
Epoch:  637        4 Batch loss: 0.160431 Batch F1: 0.5999999999999999
Epoch:  637        5 Batch loss: 0.142254 Batch F1: 0.7804878048780488
Epoch:  637        6 Batch loss: 0.182945 Batch F1: 0.6153846153846153
Epoch:  637        7 Batch loss: 0.167713 Batch F1: 0.7391304347826088
Epoch:  637        8 Batch loss: 0.142536 Batch F1: 0.8333333333333333
Epoch:  637        9 Batch loss: 0.141871 Batch F1: 0.8399999999999999
Epoch:  637       10 Batch loss: 0.194143 Batch F1: 0.558139534883721
Epoch:  637       11 Batch loss: 0.177591 Batch F1: 0.6956521739130435
Epoch:  637       12 Batch loss: 0.153194 Batch F1: 0.7567567567567567
Train Avg Loss  637: 0.167933

Train Avg F1  637: 0.7069419686388926

Val Avg Loss  637: 0.181970

Val Avg F1  637:  0.6748702135050177

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 638
--------------------------------------------------------------
Epoch:  638        1 Batch loss: 0.182259 Batch F1: 0.6666666666666666
Epoch:  638        2 Batch loss: 0.173713 Batch F1: 0.7142857142857143
Epoch:  638        3 Batch loss: 0.200316 Batch F1: 0.5957446808510638
Epoch:  638        4 Batch loss: 0.146244 Batch F1: 0.7058823529411765
Epoch:  638        5 Batch loss: 0.197800 Batch F1: 0.6046511627906976
Epoch:  638        6 Batch loss: 0.172777 Batch F1: 0.7547169811320756
Epoch:  638        7 Batch loss: 0.159061 Batch F1: 0.823529411764706
Epoch:  638        8 Batch loss: 0.159438 Batch F1: 0.717948717948718
Epoch:  638        9 Batch loss: 0.150186 Batch F1: 0.816326530612245
Epoch:  638       10 Batch loss: 0.188218 Batch F1: 0.627450980392157
Epoch:  638       11 Batch loss: 0.198287 Batch F1: 0.5833333333333334
Epoch:  638       12 Batch loss: 0.146895 Batch F1: 0.7777777777777778
Train Avg Loss  638: 0.172933

Train Avg F1  638: 0.699026192541361

Val Avg Loss  638: 0.183331

Val Avg F1  638:  0.675868377654092

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 639
--------------------------------------------------------------
Epoch:  639        1 Batch loss: 0.158981 Batch F1: 0.761904761904762
Epoch:  639        2 Batch loss: 0.182217 Batch F1: 0.6938775510204083
Epoch:  639        3 Batch loss: 0.215760 Batch F1: 0.6122448979591836
Epoch:  639        4 Batch loss: 0.177223 Batch F1: 0.7659574468085107
Epoch:  639        5 Batch loss: 0.172274 Batch F1: 0.7272727272727272
Epoch:  639        6 Batch loss: 0.203008 Batch F1: 0.5909090909090909
Epoch:  639        7 Batch loss: 0.209211 Batch F1: 0.6122448979591836
Epoch:  639        8 Batch loss: 0.144816 Batch F1: 0.7647058823529412
Epoch:  639        9 Batch loss: 0.145532 Batch F1: 0.8163265306122449
Epoch:  639       10 Batch loss: 0.161530 Batch F1: 0.761904761904762
Epoch:  639       11 Batch loss: 0.145516 Batch F1: 0.7692307692307692
Epoch:  639       12 Batch loss: 0.179304 Batch F1: 0.7027027027027027
Train Avg Loss  639: 0.174614

Train Avg F1  639: 0.7149401683864406

Val Avg Loss  639: 0.185082

Val Avg F1  639:  0.6790219626778922

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 640
--------------------------------------------------------------
Epoch:  640        1 Batch loss: 0.171623 Batch F1: 0.8135593220338982
Epoch:  640        2 Batch loss: 0.191571 Batch F1: 0.5641025641025641
Epoch:  640        3 Batch loss: 0.186238 Batch F1: 0.7450980392156863
Epoch:  640        4 Batch loss: 0.180100 Batch F1: 0.6976744186046512
Epoch:  640        5 Batch loss: 0.166203 Batch F1: 0.7027027027027027
Epoch:  640        6 Batch loss: 0.175296 Batch F1: 0.6500000000000001
Epoch:  640        7 Batch loss: 0.165529 Batch F1: 0.7826086956521738
Epoch:  640        8 Batch loss: 0.169870 Batch F1: 0.7
Epoch:  640        9 Batch loss: 0.183238 Batch F1: 0.6666666666666666
Epoch:  640       10 Batch loss: 0.157581 Batch F1: 0.7272727272727274
Epoch:  640       11 Batch loss: 0.152981 Batch F1: 0.744186046511628
Epoch:  640       12 Batch loss: 0.177810 Batch F1: 0.6666666666666666
Train Avg Loss  640: 0.173170

Train Avg F1  640: 0.7050448207857806

Val Avg Loss  640: 0.187534

Val Avg F1  640:  0.6373594511800492

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 641
--------------------------------------------------------------
Epoch:  641        1 Batch loss: 0.177400 Batch F1: 0.6818181818181818
Epoch:  641        2 Batch loss: 0.154461 Batch F1: 0.7441860465116279
Epoch:  641        3 Batch loss: 0.188930 Batch F1: 0.6666666666666666
Epoch:  641        4 Batch loss: 0.197459 Batch F1: 0.6
Epoch:  641        5 Batch loss: 0.176493 Batch F1: 0.7916666666666667
Epoch:  641        6 Batch loss: 0.173378 Batch F1: 0.6818181818181818
Epoch:  641        7 Batch loss: 0.165953 Batch F1: 0.7142857142857143
Epoch:  641        8 Batch loss: 0.162998 Batch F1: 0.7317073170731706
Epoch:  641        9 Batch loss: 0.198735 Batch F1: 0.4242424242424242
Epoch:  641       10 Batch loss: 0.161200 Batch F1: 0.7272727272727272
Epoch:  641       11 Batch loss: 0.150457 Batch F1: 0.8474576271186439
Epoch:  641       12 Batch loss: 0.198033 Batch F1: 0.7272727272727273
Train Avg Loss  641: 0.175458

Train Avg F1  641: 0.6948661900622276

Val Avg Loss  641: 0.183226

Val Avg F1  641:  0.6797727272727273

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 642
--------------------------------------------------------------
Epoch:  642        1 Batch loss: 0.154288 Batch F1: 0.7727272727272727
Epoch:  642        2 Batch loss: 0.162389 Batch F1: 0.7692307692307692
Epoch:  642        3 Batch loss: 0.180417 Batch F1: 0.7234042553191491
Epoch:  642        4 Batch loss: 0.177956 Batch F1: 0.5714285714285714
Epoch:  642        5 Batch loss: 0.160589 Batch F1: 0.7272727272727273
Epoch:  642        6 Batch loss: 0.165218 Batch F1: 0.625
Epoch:  642        7 Batch loss: 0.178191 Batch F1: 0.7391304347826085
Epoch:  642        8 Batch loss: 0.185092 Batch F1: 0.7307692307692307
Epoch:  642        9 Batch loss: 0.176324 Batch F1: 0.6956521739130435
Epoch:  642       10 Batch loss: 0.187265 Batch F1: 0.6666666666666666
Epoch:  642       11 Batch loss: 0.167559 Batch F1: 0.6666666666666666
Epoch:  642       12 Batch loss: 0.169580 Batch F1: 0.7906976744186046
Train Avg Loss  642: 0.172072

Train Avg F1  642: 0.7065538702662759

Val Avg Loss  642: 0.180603

Val Avg F1  642:  0.6774114447730147

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 643
--------------------------------------------------------------
Epoch:  643        1 Batch loss: 0.167143 Batch F1: 0.75
Epoch:  643        2 Batch loss: 0.184809 Batch F1: 0.5945945945945946
Epoch:  643        3 Batch loss: 0.167808 Batch F1: 0.6976744186046512
Epoch:  643        4 Batch loss: 0.172799 Batch F1: 0.6666666666666666
Epoch:  643        5 Batch loss: 0.176563 Batch F1: 0.6956521739130435
Epoch:  643        6 Batch loss: 0.135285 Batch F1: 0.896551724137931
Epoch:  643        7 Batch loss: 0.176791 Batch F1: 0.5806451612903226
Epoch:  643        8 Batch loss: 0.181065 Batch F1: 0.7346938775510203
Epoch:  643        9 Batch loss: 0.156278 Batch F1: 0.7500000000000001
Epoch:  643       10 Batch loss: 0.207435 Batch F1: 0.627450980392157
Epoch:  643       11 Batch loss: 0.181355 Batch F1: 0.7307692307692308
Epoch:  643       12 Batch loss: 0.155174 Batch F1: 0.7142857142857143
Train Avg Loss  643: 0.171875

Train Avg F1  643: 0.7032487118504444

Val Avg Loss  643: 0.182938

Val Avg F1  643:  0.6644110275689223

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 644
--------------------------------------------------------------
Epoch:  644        1 Batch loss: 0.173288 Batch F1: 0.6829268292682926
Epoch:  644        2 Batch loss: 0.169354 Batch F1: 0.7857142857142857
Epoch:  644        3 Batch loss: 0.185471 Batch F1: 0.6666666666666665
Epoch:  644        4 Batch loss: 0.170384 Batch F1: 0.7547169811320755
Epoch:  644        5 Batch loss: 0.147121 Batch F1: 0.7500000000000001
Epoch:  644        6 Batch loss: 0.162861 Batch F1: 0.8085106382978724
Epoch:  644        7 Batch loss: 0.169156 Batch F1: 0.6808510638297872
Epoch:  644        8 Batch loss: 0.183218 Batch F1: 0.6486486486486486
Epoch:  644        9 Batch loss: 0.164746 Batch F1: 0.717948717948718
Epoch:  644       10 Batch loss: 0.192009 Batch F1: 0.5
Epoch:  644       11 Batch loss: 0.159553 Batch F1: 0.7441860465116279
Epoch:  644       12 Batch loss: 0.171040 Batch F1: 0.7317073170731706
Train Avg Loss  644: 0.170684

Train Avg F1  644: 0.7059897662575955

Val Avg Loss  644: 0.183031

Val Avg F1  644:  0.6767522160379305

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 645
--------------------------------------------------------------
Epoch:  645        1 Batch loss: 0.204984 Batch F1: 0.6792452830188679
Epoch:  645        2 Batch loss: 0.143612 Batch F1: 0.7692307692307692
Epoch:  645        3 Batch loss: 0.173413 Batch F1: 0.7636363636363636
Epoch:  645        4 Batch loss: 0.150963 Batch F1: 0.717948717948718
Epoch:  645        5 Batch loss: 0.185659 Batch F1: 0.7826086956521738
Epoch:  645        6 Batch loss: 0.206286 Batch F1: 0.7346938775510204
Epoch:  645        7 Batch loss: 0.181944 Batch F1: 0.7450980392156864
Epoch:  645        8 Batch loss: 0.159557 Batch F1: 0.6842105263157895
Epoch:  645        9 Batch loss: 0.186897 Batch F1: 0.6
Epoch:  645       10 Batch loss: 0.162699 Batch F1: 0.6666666666666665
Epoch:  645       11 Batch loss: 0.158436 Batch F1: 0.7804878048780488
Epoch:  645       12 Batch loss: 0.178179 Batch F1: 0.7142857142857143
Train Avg Loss  645: 0.174386

Train Avg F1  645: 0.7198427048666515

Val Avg Loss  645: 0.183888

Val Avg F1  645:  0.6777858061061445

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 646
--------------------------------------------------------------
Epoch:  646        1 Batch loss: 0.189407 Batch F1: 0.6153846153846154
Epoch:  646        2 Batch loss: 0.189336 Batch F1: 0.6666666666666666
Epoch:  646        3 Batch loss: 0.142393 Batch F1: 0.8181818181818182
Epoch:  646        4 Batch loss: 0.173078 Batch F1: 0.6666666666666667
Epoch:  646        5 Batch loss: 0.156924 Batch F1: 0.7555555555555556
Epoch:  646        6 Batch loss: 0.155215 Batch F1: 0.7727272727272727
Epoch:  646        7 Batch loss: 0.190063 Batch F1: 0.6153846153846154
Epoch:  646        8 Batch loss: 0.198646 Batch F1: 0.6792452830188679
Epoch:  646        9 Batch loss: 0.167009 Batch F1: 0.7272727272727273
Epoch:  646       10 Batch loss: 0.176609 Batch F1: 0.7450980392156864
Epoch:  646       11 Batch loss: 0.187217 Batch F1: 0.7058823529411765
Epoch:  646       12 Batch loss: 0.153466 Batch F1: 0.7777777777777778
Train Avg Loss  646: 0.173280

Train Avg F1  646: 0.7121536158994539

Val Avg Loss  646: 0.183528

Val Avg F1  646:  0.6708480150340616

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 647
--------------------------------------------------------------
Epoch:  647        1 Batch loss: 0.175929 Batch F1: 0.7755102040816326
Epoch:  647        2 Batch loss: 0.127231 Batch F1: 0.875
Epoch:  647        3 Batch loss: 0.160030 Batch F1: 0.75
Epoch:  647        4 Batch loss: 0.174551 Batch F1: 0.6666666666666666
Epoch:  647        5 Batch loss: 0.177940 Batch F1: 0.7636363636363636
Epoch:  647        6 Batch loss: 0.175085 Batch F1: 0.7111111111111111
Epoch:  647        7 Batch loss: 0.129205 Batch F1: 0.8421052631578948
Epoch:  647        8 Batch loss: 0.206108 Batch F1: 0.5777777777777778
Epoch:  647        9 Batch loss: 0.188198 Batch F1: 0.5142857142857142
Epoch:  647       10 Batch loss: 0.179551 Batch F1: 0.5555555555555556
Epoch:  647       11 Batch loss: 0.176421 Batch F1: 0.6666666666666666
Epoch:  647       12 Batch loss: 0.184101 Batch F1: 0.6842105263157895
Train Avg Loss  647: 0.171196

Train Avg F1  647: 0.6985438207712643

Val Avg Loss  647: 0.183186

Val Avg F1  647:  0.6783567327640276

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 648
--------------------------------------------------------------
Epoch:  648        1 Batch loss: 0.182431 Batch F1: 0.6190476190476191
Epoch:  648        2 Batch loss: 0.162033 Batch F1: 0.7659574468085107
Epoch:  648        3 Batch loss: 0.165689 Batch F1: 0.7272727272727273
Epoch:  648        4 Batch loss: 0.170702 Batch F1: 0.76
Epoch:  648        5 Batch loss: 0.167773 Batch F1: 0.6956521739130435
Epoch:  648        6 Batch loss: 0.158814 Batch F1: 0.782608695652174
Epoch:  648        7 Batch loss: 0.156971 Batch F1: 0.7727272727272727
Epoch:  648        8 Batch loss: 0.178267 Batch F1: 0.7111111111111111
Epoch:  648        9 Batch loss: 0.193764 Batch F1: 0.5853658536585366
Epoch:  648       10 Batch loss: 0.159539 Batch F1: 0.7142857142857143
Epoch:  648       11 Batch loss: 0.178049 Batch F1: 0.6341463414634148
Epoch:  648       12 Batch loss: 0.157626 Batch F1: 0.7567567567567567
Train Avg Loss  648: 0.169305

Train Avg F1  648: 0.7104109760580734

Val Avg Loss  648: 0.182162

Val Avg F1  648:  0.6744408074195308

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 649
--------------------------------------------------------------
Epoch:  649        1 Batch loss: 0.195947 Batch F1: 0.5500000000000002
Epoch:  649        2 Batch loss: 0.162238 Batch F1: 0.7555555555555556
Epoch:  649        3 Batch loss: 0.169455 Batch F1: 0.7755102040816326
Epoch:  649        4 Batch loss: 0.148885 Batch F1: 0.7999999999999999
Epoch:  649        5 Batch loss: 0.164763 Batch F1: 0.717948717948718
Epoch:  649        6 Batch loss: 0.168082 Batch F1: 0.723404255319149
Epoch:  649        7 Batch loss: 0.157986 Batch F1: 0.8076923076923077
Epoch:  649        8 Batch loss: 0.157623 Batch F1: 0.625
Epoch:  649        9 Batch loss: 0.180183 Batch F1: 0.6511627906976744
Epoch:  649       10 Batch loss: 0.154053 Batch F1: 0.7916666666666667
Epoch:  649       11 Batch loss: 0.187350 Batch F1: 0.6521739130434783
Epoch:  649       12 Batch loss: 0.181232 Batch F1: 0.6060606060606061
Train Avg Loss  649: 0.168983

Train Avg F1  649: 0.7046812514221491

Val Avg Loss  649: 0.181445

Val Avg F1  649:  0.6819051362683438

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 650
--------------------------------------------------------------
Epoch:  650        1 Batch loss: 0.159171 Batch F1: 0.7555555555555555
Epoch:  650        2 Batch loss: 0.199528 Batch F1: 0.5714285714285713
Epoch:  650        3 Batch loss: 0.190457 Batch F1: 0.7368421052631579
Epoch:  650        4 Batch loss: 0.153983 Batch F1: 0.6666666666666667
Epoch:  650        5 Batch loss: 0.169036 Batch F1: 0.7
Epoch:  650        6 Batch loss: 0.151188 Batch F1: 0.75
Epoch:  650        7 Batch loss: 0.170266 Batch F1: 0.7
Epoch:  650        8 Batch loss: 0.169859 Batch F1: 0.7692307692307692
Epoch:  650        9 Batch loss: 0.168595 Batch F1: 0.7234042553191491
Epoch:  650       10 Batch loss: 0.164558 Batch F1: 0.6829268292682926
Epoch:  650       11 Batch loss: 0.150672 Batch F1: 0.7555555555555556
Epoch:  650       12 Batch loss: 0.174836 Batch F1: 0.7142857142857143
Train Avg Loss  650: 0.168512

Train Avg F1  650: 0.7104913352144527

Val Avg Loss  650: 0.181346

Val Avg F1  650:  0.6759046639991838

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 651
--------------------------------------------------------------
Epoch:  651        1 Batch loss: 0.166752 Batch F1: 0.7234042553191491
Epoch:  651        2 Batch loss: 0.174237 Batch F1: 0.6829268292682926
Epoch:  651        3 Batch loss: 0.147719 Batch F1: 0.7692307692307692
Epoch:  651        4 Batch loss: 0.158319 Batch F1: 0.7924528301886793
Epoch:  651        5 Batch loss: 0.192824 Batch F1: 0.608695652173913
Epoch:  651        6 Batch loss: 0.177293 Batch F1: 0.6666666666666667
Epoch:  651        7 Batch loss: 0.171515 Batch F1: 0.711111111111111
Epoch:  651        8 Batch loss: 0.157705 Batch F1: 0.7428571428571429
Epoch:  651        9 Batch loss: 0.161746 Batch F1: 0.7843137254901961
Epoch:  651       10 Batch loss: 0.170194 Batch F1: 0.7547169811320754
Epoch:  651       11 Batch loss: 0.188086 Batch F1: 0.5641025641025641
Epoch:  651       12 Batch loss: 0.160662 Batch F1: 0.7027027027027027
Train Avg Loss  651: 0.168921

Train Avg F1  651: 0.7085984358536052

Val Avg Loss  651: 0.180866

Val Avg F1  651:  0.6585978604532886

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 652
--------------------------------------------------------------
Epoch:  652        1 Batch loss: 0.158322 Batch F1: 0.8148148148148148
Epoch:  652        2 Batch loss: 0.174296 Batch F1: 0.6500000000000001
Epoch:  652        3 Batch loss: 0.180670 Batch F1: 0.6808510638297872
Epoch:  652        4 Batch loss: 0.183230 Batch F1: 0.7083333333333334
Epoch:  652        5 Batch loss: 0.172806 Batch F1: 0.6111111111111113
Epoch:  652        6 Batch loss: 0.166581 Batch F1: 0.7555555555555555
Epoch:  652        7 Batch loss: 0.171094 Batch F1: 0.6976744186046512
Epoch:  652        8 Batch loss: 0.161740 Batch F1: 0.7499999999999999
Epoch:  652        9 Batch loss: 0.160575 Batch F1: 0.7659574468085107
Epoch:  652       10 Batch loss: 0.188306 Batch F1: 0.6046511627906977
Epoch:  652       11 Batch loss: 0.148420 Batch F1: 0.7692307692307692
Epoch:  652       12 Batch loss: 0.164625 Batch F1: 0.7058823529411765
Train Avg Loss  652: 0.169222

Train Avg F1  652: 0.709505169085034

Val Avg Loss  652: 0.180481

Val Avg F1  652:  0.6671663015488681

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 653
--------------------------------------------------------------
Epoch:  653        1 Batch loss: 0.153941 Batch F1: 0.7222222222222222
Epoch:  653        2 Batch loss: 0.188075 Batch F1: 0.5405405405405405
Epoch:  653        3 Batch loss: 0.174762 Batch F1: 0.723404255319149
Epoch:  653        4 Batch loss: 0.167731 Batch F1: 0.711111111111111
Epoch:  653        5 Batch loss: 0.188833 Batch F1: 0.631578947368421
Epoch:  653        6 Batch loss: 0.177280 Batch F1: 0.6808510638297872
Epoch:  653        7 Batch loss: 0.152038 Batch F1: 0.7755102040816326
Epoch:  653        8 Batch loss: 0.156398 Batch F1: 0.7924528301886793
Epoch:  653        9 Batch loss: 0.152913 Batch F1: 0.8260869565217391
Epoch:  653       10 Batch loss: 0.177369 Batch F1: 0.7111111111111111
Epoch:  653       11 Batch loss: 0.187638 Batch F1: 0.6222222222222223
Epoch:  653       12 Batch loss: 0.160565 Batch F1: 0.7567567567567567
Train Avg Loss  653: 0.169795

Train Avg F1  653: 0.7078206851061144

Val Avg Loss  653: 0.180915

Val Avg F1  653:  0.6709163144503778

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 654
--------------------------------------------------------------
Epoch:  654        1 Batch loss: 0.143933 Batch F1: 0.8333333333333333
Epoch:  654        2 Batch loss: 0.157656 Batch F1: 0.723404255319149
Epoch:  654        3 Batch loss: 0.178723 Batch F1: 0.723404255319149
Epoch:  654        4 Batch loss: 0.173071 Batch F1: 0.6666666666666666
Epoch:  654        5 Batch loss: 0.171608 Batch F1: 0.6976744186046512
Epoch:  654        6 Batch loss: 0.212069 Batch F1: 0.5365853658536585
Epoch:  654        7 Batch loss: 0.165104 Batch F1: 0.7346938775510203
Epoch:  654        8 Batch loss: 0.164470 Batch F1: 0.723404255319149
Epoch:  654        9 Batch loss: 0.149172 Batch F1: 0.8510638297872342
Epoch:  654       10 Batch loss: 0.171432 Batch F1: 0.7111111111111111
Epoch:  654       11 Batch loss: 0.144383 Batch F1: 0.7999999999999999
Epoch:  654       12 Batch loss: 0.214970 Batch F1: 0.43749999999999994
Train Avg Loss  654: 0.170549

Train Avg F1  654: 0.7032367807387603

Val Avg Loss  654: 0.180165

Val Avg F1  654:  0.6747307587135315

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 655
--------------------------------------------------------------
Epoch:  655        1 Batch loss: 0.179533 Batch F1: 0.6486486486486486
Epoch:  655        2 Batch loss: 0.169938 Batch F1: 0.723404255319149
Epoch:  655        3 Batch loss: 0.160563 Batch F1: 0.8076923076923077
Epoch:  655        4 Batch loss: 0.174835 Batch F1: 0.7058823529411765
Epoch:  655        5 Batch loss: 0.168282 Batch F1: 0.7142857142857143
Epoch:  655        6 Batch loss: 0.188126 Batch F1: 0.6521739130434783
Epoch:  655        7 Batch loss: 0.147781 Batch F1: 0.7368421052631577
Epoch:  655        8 Batch loss: 0.165132 Batch F1: 0.7391304347826085
Epoch:  655        9 Batch loss: 0.149482 Batch F1: 0.7317073170731707
Epoch:  655       10 Batch loss: 0.182800 Batch F1: 0.72
Epoch:  655       11 Batch loss: 0.183698 Batch F1: 0.6808510638297872
Epoch:  655       12 Batch loss: 0.167539 Batch F1: 0.6428571428571429
Train Avg Loss  655: 0.169809

Train Avg F1  655: 0.7086229379780283

Val Avg Loss  655: 0.181753

Val Avg F1  655:  0.6762121212121212

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 656
--------------------------------------------------------------
Epoch:  656        1 Batch loss: 0.171425 Batch F1: 0.711111111111111
Epoch:  656        2 Batch loss: 0.130867 Batch F1: 0.8444444444444444
Epoch:  656        3 Batch loss: 0.186950 Batch F1: 0.6956521739130435
Epoch:  656        4 Batch loss: 0.176905 Batch F1: 0.6666666666666666
Epoch:  656        5 Batch loss: 0.162278 Batch F1: 0.7441860465116279
Epoch:  656        6 Batch loss: 0.171415 Batch F1: 0.5945945945945946
Epoch:  656        7 Batch loss: 0.166567 Batch F1: 0.5806451612903225
Epoch:  656        8 Batch loss: 0.122825 Batch F1: 0.8780487804878049
Epoch:  656        9 Batch loss: 0.191285 Batch F1: 0.7586206896551724
Epoch:  656       10 Batch loss: 0.204748 Batch F1: 0.5777777777777778
Epoch:  656       11 Batch loss: 0.180297 Batch F1: 0.6666666666666666
Epoch:  656       12 Batch loss: 0.174665 Batch F1: 0.7727272727272727
Train Avg Loss  656: 0.170019

Train Avg F1  656: 0.7075951154872088

Val Avg Loss  656: 0.180390

Val Avg F1  656:  0.6789306104523496

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 657
--------------------------------------------------------------
Epoch:  657        1 Batch loss: 0.148551 Batch F1: 0.7777777777777778
Epoch:  657        2 Batch loss: 0.176501 Batch F1: 0.6666666666666665
Epoch:  657        3 Batch loss: 0.142403 Batch F1: 0.8846153846153846
Epoch:  657        4 Batch loss: 0.162731 Batch F1: 0.7843137254901961
Epoch:  657        5 Batch loss: 0.179407 Batch F1: 0.5882352941176471
Epoch:  657        6 Batch loss: 0.168250 Batch F1: 0.7346938775510204
Epoch:  657        7 Batch loss: 0.184435 Batch F1: 0.72
Epoch:  657        8 Batch loss: 0.185828 Batch F1: 0.6666666666666666
Epoch:  657        9 Batch loss: 0.174162 Batch F1: 0.7391304347826088
Epoch:  657       10 Batch loss: 0.161219 Batch F1: 0.6829268292682926
Epoch:  657       11 Batch loss: 0.192034 Batch F1: 0.5333333333333332
Epoch:  657       12 Batch loss: 0.183543 Batch F1: 0.6486486486486486
Train Avg Loss  657: 0.171589

Train Avg F1  657: 0.7022507199098534

Val Avg Loss  657: 0.182133

Val Avg F1  657:  0.6744885586369854

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 658
--------------------------------------------------------------
Epoch:  658        1 Batch loss: 0.164026 Batch F1: 0.6818181818181819
Epoch:  658        2 Batch loss: 0.161116 Batch F1: 0.7924528301886793
Epoch:  658        3 Batch loss: 0.163128 Batch F1: 0.7547169811320755
Epoch:  658        4 Batch loss: 0.190293 Batch F1: 0.8095238095238095
Epoch:  658        5 Batch loss: 0.152132 Batch F1: 0.8571428571428572
Epoch:  658        6 Batch loss: 0.174767 Batch F1: 0.7719298245614036
Epoch:  658        7 Batch loss: 0.201853 Batch F1: 0.6190476190476191
Epoch:  658        8 Batch loss: 0.196496 Batch F1: 0.5365853658536586
Epoch:  658        9 Batch loss: 0.187281 Batch F1: 0.5641025641025642
Epoch:  658       10 Batch loss: 0.126002 Batch F1: 0.8936170212765958
Epoch:  658       11 Batch loss: 0.163020 Batch F1: 0.6666666666666666
Epoch:  658       12 Batch loss: 0.182246 Batch F1: 0.6470588235294118
Train Avg Loss  658: 0.171863

Train Avg F1  658: 0.7162218787369602

Val Avg Loss  658: 0.180663

Val Avg F1  658:  0.6789291045032776

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 659
--------------------------------------------------------------
Epoch:  659        1 Batch loss: 0.156686 Batch F1: 0.7027027027027026
Epoch:  659        2 Batch loss: 0.198946 Batch F1: 0.7058823529411765
Epoch:  659        3 Batch loss: 0.175201 Batch F1: 0.6818181818181818
Epoch:  659        4 Batch loss: 0.157148 Batch F1: 0.6842105263157895
Epoch:  659        5 Batch loss: 0.167452 Batch F1: 0.7843137254901961
Epoch:  659        6 Batch loss: 0.175735 Batch F1: 0.65
Epoch:  659        7 Batch loss: 0.152837 Batch F1: 0.7555555555555555
Epoch:  659        8 Batch loss: 0.173682 Batch F1: 0.6666666666666666
Epoch:  659        9 Batch loss: 0.158313 Batch F1: 0.7142857142857143
Epoch:  659       10 Batch loss: 0.188757 Batch F1: 0.736842105263158
Epoch:  659       11 Batch loss: 0.164504 Batch F1: 0.7916666666666667
Epoch:  659       12 Batch loss: 0.175000 Batch F1: 0.6
Train Avg Loss  659: 0.170355

Train Avg F1  659: 0.706162016475484

Val Avg Loss  659: 0.180346

Val Avg F1  659:  0.674844955180321

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 660
--------------------------------------------------------------
Epoch:  660        1 Batch loss: 0.158079 Batch F1: 0.7027027027027026
Epoch:  660        2 Batch loss: 0.160741 Batch F1: 0.6111111111111112
Epoch:  660        3 Batch loss: 0.168185 Batch F1: 0.6341463414634146
Epoch:  660        4 Batch loss: 0.189019 Batch F1: 0.6666666666666666
Epoch:  660        5 Batch loss: 0.202374 Batch F1: 0.5957446808510639
Epoch:  660        6 Batch loss: 0.168070 Batch F1: 0.8076923076923077
Epoch:  660        7 Batch loss: 0.170704 Batch F1: 0.7500000000000001
Epoch:  660        8 Batch loss: 0.160581 Batch F1: 0.7555555555555556
Epoch:  660        9 Batch loss: 0.166006 Batch F1: 0.7083333333333334
Epoch:  660       10 Batch loss: 0.125479 Batch F1: 0.8780487804878049
Epoch:  660       11 Batch loss: 0.154103 Batch F1: 0.7727272727272727
Epoch:  660       12 Batch loss: 0.209596 Batch F1: 0.6363636363636365
Train Avg Loss  660: 0.169412

Train Avg F1  660: 0.7099243657462391

Val Avg Loss  660: 0.180093

Val Avg F1  660:  0.6675677435316483

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 661
--------------------------------------------------------------
Epoch:  661        1 Batch loss: 0.155942 Batch F1: 0.7317073170731708
Epoch:  661        2 Batch loss: 0.164992 Batch F1: 0.7500000000000001
Epoch:  661        3 Batch loss: 0.181350 Batch F1: 0.65
Epoch:  661        4 Batch loss: 0.162989 Batch F1: 0.7317073170731706
Epoch:  661        5 Batch loss: 0.185174 Batch F1: 0.6666666666666666
Epoch:  661        6 Batch loss: 0.186716 Batch F1: 0.6222222222222223
Epoch:  661        7 Batch loss: 0.173839 Batch F1: 0.6511627906976745
Epoch:  661        8 Batch loss: 0.164428 Batch F1: 0.717948717948718
Epoch:  661        9 Batch loss: 0.155506 Batch F1: 0.8214285714285714
Epoch:  661       10 Batch loss: 0.146656 Batch F1: 0.7804878048780488
Epoch:  661       11 Batch loss: 0.162820 Batch F1: 0.717948717948718
Epoch:  661       12 Batch loss: 0.197730 Batch F1: 0.6818181818181819
Train Avg Loss  661: 0.169845

Train Avg F1  661: 0.7102581923129286

Val Avg Loss  661: 0.181630

Val Avg F1  661:  0.6725374310480693

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 662
--------------------------------------------------------------
Epoch:  662        1 Batch loss: 0.131471 Batch F1: 0.8648648648648649
Epoch:  662        2 Batch loss: 0.171752 Batch F1: 0.7450980392156864
Epoch:  662        3 Batch loss: 0.179797 Batch F1: 0.6956521739130435
Epoch:  662        4 Batch loss: 0.176164 Batch F1: 0.7083333333333333
Epoch:  662        5 Batch loss: 0.178076 Batch F1: 0.6153846153846154
Epoch:  662        6 Batch loss: 0.182813 Batch F1: 0.6363636363636365
Epoch:  662        7 Batch loss: 0.160918 Batch F1: 0.7826086956521738
Epoch:  662        8 Batch loss: 0.161949 Batch F1: 0.6842105263157895
Epoch:  662        9 Batch loss: 0.193132 Batch F1: 0.65
Epoch:  662       10 Batch loss: 0.154650 Batch F1: 0.8235294117647058
Epoch:  662       11 Batch loss: 0.191295 Batch F1: 0.6382978723404256
Epoch:  662       12 Batch loss: 0.160634 Batch F1: 0.6842105263157894
Train Avg Loss  662: 0.170221

Train Avg F1  662: 0.7107128079553386

Val Avg Loss  662: 0.184414

Val Avg F1  662:  0.6732879818594105

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 663
--------------------------------------------------------------
Epoch:  663        1 Batch loss: 0.199356 Batch F1: 0.5714285714285715
Epoch:  663        2 Batch loss: 0.180317 Batch F1: 0.7058823529411765
Epoch:  663        3 Batch loss: 0.174741 Batch F1: 0.6976744186046512
Epoch:  663        4 Batch loss: 0.156198 Batch F1: 0.7916666666666666
Epoch:  663        5 Batch loss: 0.197294 Batch F1: 0.7058823529411765
Epoch:  663        6 Batch loss: 0.163795 Batch F1: 0.7906976744186046
Epoch:  663        7 Batch loss: 0.196942 Batch F1: 0.6666666666666666
Epoch:  663        8 Batch loss: 0.162413 Batch F1: 0.7450980392156863
Epoch:  663        9 Batch loss: 0.167270 Batch F1: 0.7692307692307693
Epoch:  663       10 Batch loss: 0.168161 Batch F1: 0.7317073170731708
Epoch:  663       11 Batch loss: 0.161206 Batch F1: 0.6666666666666666
Epoch:  663       12 Batch loss: 0.161513 Batch F1: 0.608695652173913
Train Avg Loss  663: 0.174101

Train Avg F1  663: 0.7042747623356433

Val Avg Loss  663: 0.189395

Val Avg F1  663:  0.6450988987326197

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 664
--------------------------------------------------------------
Epoch:  664        1 Batch loss: 0.153921 Batch F1: 0.7333333333333334
Epoch:  664        2 Batch loss: 0.237501 Batch F1: 0.5555555555555556
Epoch:  664        3 Batch loss: 0.200954 Batch F1: 0.5142857142857142
Epoch:  664        4 Batch loss: 0.203504 Batch F1: 0.6086956521739131
Epoch:  664        5 Batch loss: 0.177356 Batch F1: 0.6341463414634146
Epoch:  664        6 Batch loss: 0.180443 Batch F1: 0.7241379310344829
Epoch:  664        7 Batch loss: 0.159965 Batch F1: 0.7199999999999999
Epoch:  664        8 Batch loss: 0.161615 Batch F1: 0.6666666666666666
Epoch:  664        9 Batch loss: 0.157928 Batch F1: 0.6956521739130435
Epoch:  664       10 Batch loss: 0.191754 Batch F1: 0.6666666666666666
Epoch:  664       11 Batch loss: 0.180191 Batch F1: 0.7346938775510204
Epoch:  664       12 Batch loss: 0.193663 Batch F1: 0.6111111111111113
Train Avg Loss  664: 0.183233

Train Avg F1  664: 0.6554120853129102

Val Avg Loss  664: 0.186242

Val Avg F1  664:  0.6753083967781088

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 665
--------------------------------------------------------------
Epoch:  665        1 Batch loss: 0.179288 Batch F1: 0.7916666666666666
Epoch:  665        2 Batch loss: 0.172747 Batch F1: 0.588235294117647
Epoch:  665        3 Batch loss: 0.183286 Batch F1: 0.6521739130434783
Epoch:  665        4 Batch loss: 0.173301 Batch F1: 0.8148148148148148
Epoch:  665        5 Batch loss: 0.164482 Batch F1: 0.7894736842105263
Epoch:  665        6 Batch loss: 0.188798 Batch F1: 0.6666666666666666
Epoch:  665        7 Batch loss: 0.165732 Batch F1: 0.6486486486486486
Epoch:  665        8 Batch loss: 0.182912 Batch F1: 0.5882352941176471
Epoch:  665        9 Batch loss: 0.177785 Batch F1: 0.7659574468085107
Epoch:  665       10 Batch loss: 0.155882 Batch F1: 0.9152542372881356
Epoch:  665       11 Batch loss: 0.200366 Batch F1: 0.8363636363636363
Epoch:  665       12 Batch loss: 0.173317 Batch F1: 0.7391304347826089
Train Avg Loss  665: 0.176491

Train Avg F1  665: 0.7330517281274157

Val Avg Loss  665: 0.188442

Val Avg F1  665:  0.6398471094123268

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 666
--------------------------------------------------------------
Epoch:  666        1 Batch loss: 0.168443 Batch F1: 0.7346938775510203
Epoch:  666        2 Batch loss: 0.194257 Batch F1: 0.6666666666666665
Epoch:  666        3 Batch loss: 0.150737 Batch F1: 0.8076923076923077
Epoch:  666        4 Batch loss: 0.157138 Batch F1: 0.7027027027027027
Epoch:  666        5 Batch loss: 0.175549 Batch F1: 0.6222222222222222
Epoch:  666        6 Batch loss: 0.203835 Batch F1: 0.6190476190476191
Epoch:  666        7 Batch loss: 0.165655 Batch F1: 0.7391304347826089
Epoch:  666        8 Batch loss: 0.199287 Batch F1: 0.6382978723404256
Epoch:  666        9 Batch loss: 0.188512 Batch F1: 0.744186046511628
Epoch:  666       10 Batch loss: 0.166260 Batch F1: 0.7142857142857143
Epoch:  666       11 Batch loss: 0.164548 Batch F1: 0.7027027027027027
Epoch:  666       12 Batch loss: 0.213340 Batch F1: 0.6222222222222222
Train Avg Loss  666: 0.178963

Train Avg F1  666: 0.6928208657273202

Val Avg Loss  666: 0.185562

Val Avg F1  666:  0.6733142379758921

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 667
--------------------------------------------------------------
Epoch:  667        1 Batch loss: 0.169588 Batch F1: 0.6666666666666666
Epoch:  667        2 Batch loss: 0.188474 Batch F1: 0.68
Epoch:  667        3 Batch loss: 0.161481 Batch F1: 0.7659574468085107
Epoch:  667        4 Batch loss: 0.161168 Batch F1: 0.6486486486486486
Epoch:  667        5 Batch loss: 0.143371 Batch F1: 0.7804878048780488
Epoch:  667        6 Batch loss: 0.179000 Batch F1: 0.6285714285714287
Epoch:  667        7 Batch loss: 0.202711 Batch F1: 0.64
Epoch:  667        8 Batch loss: 0.168084 Batch F1: 0.6976744186046512
Epoch:  667        9 Batch loss: 0.167649 Batch F1: 0.8
Epoch:  667       10 Batch loss: 0.171197 Batch F1: 0.7777777777777779
Epoch:  667       11 Batch loss: 0.163562 Batch F1: 0.7727272727272727
Epoch:  667       12 Batch loss: 0.184589 Batch F1: 0.6285714285714286
Train Avg Loss  667: 0.171740

Train Avg F1  667: 0.7072569077712028

Val Avg Loss  667: 0.181630

Val Avg F1  667:  0.6706609300948924

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 668
--------------------------------------------------------------
Epoch:  668        1 Batch loss: 0.161228 Batch F1: 0.7916666666666666
Epoch:  668        2 Batch loss: 0.152406 Batch F1: 0.7555555555555556
Epoch:  668        3 Batch loss: 0.198471 Batch F1: 0.4848484848484849
Epoch:  668        4 Batch loss: 0.163908 Batch F1: 0.5806451612903226
Epoch:  668        5 Batch loss: 0.174950 Batch F1: 0.6111111111111112
Epoch:  668        6 Batch loss: 0.183144 Batch F1: 0.793103448275862
Epoch:  668        7 Batch loss: 0.192861 Batch F1: 0.6222222222222222
Epoch:  668        8 Batch loss: 0.195316 Batch F1: 0.5714285714285714
Epoch:  668        9 Batch loss: 0.178024 Batch F1: 0.7272727272727272
Epoch:  668       10 Batch loss: 0.159003 Batch F1: 0.6666666666666667
Epoch:  668       11 Batch loss: 0.184621 Batch F1: 0.6511627906976744
Epoch:  668       12 Batch loss: 0.162069 Batch F1: 0.8
Train Avg Loss  668: 0.175500

Train Avg F1  668: 0.6713069505029887

Val Avg Loss  668: 0.183534

Val Avg F1  668:  0.6777541741204531

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 669
--------------------------------------------------------------
Epoch:  669        1 Batch loss: 0.155004 Batch F1: 0.7804878048780488
Epoch:  669        2 Batch loss: 0.167964 Batch F1: 0.7924528301886792
Epoch:  669        3 Batch loss: 0.168194 Batch F1: 0.72
Epoch:  669        4 Batch loss: 0.169001 Batch F1: 0.7547169811320756
Epoch:  669        5 Batch loss: 0.162597 Batch F1: 0.7272727272727272
Epoch:  669        6 Batch loss: 0.170947 Batch F1: 0.6956521739130435
Epoch:  669        7 Batch loss: 0.193720 Batch F1: 0.6285714285714286
Epoch:  669        8 Batch loss: 0.152529 Batch F1: 0.7999999999999999
Epoch:  669        9 Batch loss: 0.170759 Batch F1: 0.6666666666666667
Epoch:  669       10 Batch loss: 0.169447 Batch F1: 0.65
Epoch:  669       11 Batch loss: 0.184697 Batch F1: 0.6808510638297872
Epoch:  669       12 Batch loss: 0.199487 Batch F1: 0.5625
Train Avg Loss  669: 0.172029

Train Avg F1  669: 0.7049309730377047

Val Avg Loss  669: 0.183625

Val Avg F1  669:  0.673195238424349

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 670
--------------------------------------------------------------
Epoch:  670        1 Batch loss: 0.167378 Batch F1: 0.6470588235294117
Epoch:  670        2 Batch loss: 0.191567 Batch F1: 0.7058823529411765
Epoch:  670        3 Batch loss: 0.185006 Batch F1: 0.6938775510204083
Epoch:  670        4 Batch loss: 0.175174 Batch F1: 0.75
Epoch:  670        5 Batch loss: 0.161952 Batch F1: 0.7027027027027027
Epoch:  670        6 Batch loss: 0.168835 Batch F1: 0.6666666666666666
Epoch:  670        7 Batch loss: 0.191401 Batch F1: 0.7346938775510204
Epoch:  670        8 Batch loss: 0.148474 Batch F1: 0.8461538461538461
Epoch:  670        9 Batch loss: 0.145924 Batch F1: 0.761904761904762
Epoch:  670       10 Batch loss: 0.165469 Batch F1: 0.7111111111111111
Epoch:  670       11 Batch loss: 0.191340 Batch F1: 0.6363636363636365
Epoch:  670       12 Batch loss: 0.167340 Batch F1: 0.625
Train Avg Loss  670: 0.171655

Train Avg F1  670: 0.7067846108287285

Val Avg Loss  670: 0.181536

Val Avg F1  670:  0.6769810420076378

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 671
--------------------------------------------------------------
Epoch:  671        1 Batch loss: 0.193671 Batch F1: 0.6530612244897959
Epoch:  671        2 Batch loss: 0.161097 Batch F1: 0.7441860465116279
Epoch:  671        3 Batch loss: 0.182244 Batch F1: 0.7199999999999999
Epoch:  671        4 Batch loss: 0.165098 Batch F1: 0.7441860465116279
Epoch:  671        5 Batch loss: 0.155669 Batch F1: 0.7027027027027027
Epoch:  671        6 Batch loss: 0.190244 Batch F1: 0.6666666666666667
Epoch:  671        7 Batch loss: 0.154133 Batch F1: 0.6857142857142857
Epoch:  671        8 Batch loss: 0.153822 Batch F1: 0.8000000000000002
Epoch:  671        9 Batch loss: 0.198202 Batch F1: 0.6399999999999999
Epoch:  671       10 Batch loss: 0.161645 Batch F1: 0.7441860465116279
Epoch:  671       11 Batch loss: 0.148481 Batch F1: 0.8
Epoch:  671       12 Batch loss: 0.179415 Batch F1: 0.6206896551724138
Train Avg Loss  671: 0.170310

Train Avg F1  671: 0.7101160561900622

Val Avg Loss  671: 0.181512

Val Avg F1  671:  0.6736238991819811

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 672
--------------------------------------------------------------
Epoch:  672        1 Batch loss: 0.141449 Batch F1: 0.7999999999999999
Epoch:  672        2 Batch loss: 0.169213 Batch F1: 0.7111111111111111
Epoch:  672        3 Batch loss: 0.158846 Batch F1: 0.717948717948718
Epoch:  672        4 Batch loss: 0.159903 Batch F1: 0.8076923076923077
Epoch:  672        5 Batch loss: 0.178769 Batch F1: 0.7346938775510204
Epoch:  672        6 Batch loss: 0.159199 Batch F1: 0.6857142857142857
Epoch:  672        7 Batch loss: 0.164353 Batch F1: 0.7499999999999999
Epoch:  672        8 Batch loss: 0.189582 Batch F1: 0.6363636363636365
Epoch:  672        9 Batch loss: 0.156333 Batch F1: 0.6857142857142857
Epoch:  672       10 Batch loss: 0.161200 Batch F1: 0.76
Epoch:  672       11 Batch loss: 0.213727 Batch F1: 0.5416666666666667
Epoch:  672       12 Batch loss: 0.181570 Batch F1: 0.717948717948718
Train Avg Loss  672: 0.169512

Train Avg F1  672: 0.7124044672258959

Val Avg Loss  672: 0.181787

Val Avg F1  672:  0.6639319014319015

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 673
--------------------------------------------------------------
Epoch:  673        1 Batch loss: 0.175176 Batch F1: 0.5945945945945945
Epoch:  673        2 Batch loss: 0.187292 Batch F1: 0.6923076923076923
Epoch:  673        3 Batch loss: 0.186895 Batch F1: 0.6
Epoch:  673        4 Batch loss: 0.193991 Batch F1: 0.6666666666666666
Epoch:  673        5 Batch loss: 0.157780 Batch F1: 0.717948717948718
Epoch:  673        6 Batch loss: 0.170872 Batch F1: 0.6153846153846153
Epoch:  673        7 Batch loss: 0.183037 Batch F1: 0.7111111111111111
Epoch:  673        8 Batch loss: 0.153951 Batch F1: 0.8771929824561403
Epoch:  673        9 Batch loss: 0.140718 Batch F1: 0.8260869565217391
Epoch:  673       10 Batch loss: 0.188914 Batch F1: 0.6976744186046512
Epoch:  673       11 Batch loss: 0.139916 Batch F1: 0.84
Epoch:  673       12 Batch loss: 0.186539 Batch F1: 0.5625000000000001
Train Avg Loss  673: 0.172090

Train Avg F1  673: 0.7001223129663274

Val Avg Loss  673: 0.184189

Val Avg F1  673:  0.6768848378061398

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 674
--------------------------------------------------------------
Epoch:  674        1 Batch loss: 0.174970 Batch F1: 0.6666666666666666
Epoch:  674        2 Batch loss: 0.169720 Batch F1: 0.7391304347826088
Epoch:  674        3 Batch loss: 0.169811 Batch F1: 0.6956521739130435
Epoch:  674        4 Batch loss: 0.157488 Batch F1: 0.717948717948718
Epoch:  674        5 Batch loss: 0.181207 Batch F1: 0.8518518518518519
Epoch:  674        6 Batch loss: 0.178738 Batch F1: 0.7450980392156864
Epoch:  674        7 Batch loss: 0.178355 Batch F1: 0.6666666666666667
Epoch:  674        8 Batch loss: 0.161522 Batch F1: 0.7857142857142856
Epoch:  674        9 Batch loss: 0.177934 Batch F1: 0.5945945945945946
Epoch:  674       10 Batch loss: 0.188463 Batch F1: 0.6511627906976744
Epoch:  674       11 Batch loss: 0.160767 Batch F1: 0.7727272727272727
Epoch:  674       12 Batch loss: 0.165154 Batch F1: 0.6857142857142857
Train Avg Loss  674: 0.172011

Train Avg F1  674: 0.7144106483744462

Val Avg Loss  674: 0.184566

Val Avg F1  674:  0.6760906163080076

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 675
--------------------------------------------------------------
Epoch:  675        1 Batch loss: 0.171512 Batch F1: 0.7111111111111111
Epoch:  675        2 Batch loss: 0.163713 Batch F1: 0.6285714285714286
Epoch:  675        3 Batch loss: 0.204746 Batch F1: 0.6250000000000001
Epoch:  675        4 Batch loss: 0.157106 Batch F1: 0.7843137254901961
Epoch:  675        5 Batch loss: 0.140601 Batch F1: 0.8095238095238095
Epoch:  675        6 Batch loss: 0.167601 Batch F1: 0.7499999999999999
Epoch:  675        7 Batch loss: 0.177962 Batch F1: 0.6842105263157895
Epoch:  675        8 Batch loss: 0.175285 Batch F1: 0.7111111111111111
Epoch:  675        9 Batch loss: 0.170944 Batch F1: 0.6666666666666666
Epoch:  675       10 Batch loss: 0.191694 Batch F1: 0.6530612244897959
Epoch:  675       11 Batch loss: 0.160963 Batch F1: 0.7727272727272727
Epoch:  675       12 Batch loss: 0.167673 Batch F1: 0.7567567567567567
Train Avg Loss  675: 0.170817

Train Avg F1  675: 0.7127544693969948

Val Avg Loss  675: 0.182187

Val Avg F1  675:  0.6701479282383984

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 676
--------------------------------------------------------------
Epoch:  676        1 Batch loss: 0.164927 Batch F1: 0.7450980392156864
Epoch:  676        2 Batch loss: 0.158063 Batch F1: 0.7441860465116279
Epoch:  676        3 Batch loss: 0.170934 Batch F1: 0.744186046511628
Epoch:  676        4 Batch loss: 0.206654 Batch F1: 0.5128205128205129
Epoch:  676        5 Batch loss: 0.170588 Batch F1: 0.7234042553191491
Epoch:  676        6 Batch loss: 0.195305 Batch F1: 0.6666666666666666
Epoch:  676        7 Batch loss: 0.159258 Batch F1: 0.8076923076923077
Epoch:  676        8 Batch loss: 0.180533 Batch F1: 0.7083333333333334
Epoch:  676        9 Batch loss: 0.156924 Batch F1: 0.7826086956521738
Epoch:  676       10 Batch loss: 0.153557 Batch F1: 0.717948717948718
Epoch:  676       11 Batch loss: 0.177869 Batch F1: 0.5454545454545454
Epoch:  676       12 Batch loss: 0.166515 Batch F1: 0.761904761904762
Train Avg Loss  676: 0.171761

Train Avg F1  676: 0.7050253274192593

Val Avg Loss  676: 0.181072

Val Avg F1  676:  0.6741901028704165

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 677
--------------------------------------------------------------
Epoch:  677        1 Batch loss: 0.160537 Batch F1: 0.8148148148148148
Epoch:  677        2 Batch loss: 0.148564 Batch F1: 0.7906976744186046
Epoch:  677        3 Batch loss: 0.188003 Batch F1: 0.6190476190476191
Epoch:  677        4 Batch loss: 0.176042 Batch F1: 0.7307692307692306
Epoch:  677        5 Batch loss: 0.187526 Batch F1: 0.5405405405405405
Epoch:  677        6 Batch loss: 0.205658 Batch F1: 0.553191489361702
Epoch:  677        7 Batch loss: 0.148039 Batch F1: 0.7906976744186046
Epoch:  677        8 Batch loss: 0.175331 Batch F1: 0.6285714285714286
Epoch:  677        9 Batch loss: 0.157385 Batch F1: 0.7916666666666666
Epoch:  677       10 Batch loss: 0.158517 Batch F1: 0.782608695652174
Epoch:  677       11 Batch loss: 0.177988 Batch F1: 0.7199999999999999
Epoch:  677       12 Batch loss: 0.147684 Batch F1: 0.7142857142857143
Train Avg Loss  677: 0.169273

Train Avg F1  677: 0.7064076290455916

Val Avg Loss  677: 0.181598

Val Avg F1  677:  0.6745694522868437

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 678
--------------------------------------------------------------
Epoch:  678        1 Batch loss: 0.198070 Batch F1: 0.6666666666666667
Epoch:  678        2 Batch loss: 0.187402 Batch F1: 0.7272727272727274
Epoch:  678        3 Batch loss: 0.176808 Batch F1: 0.6956521739130435
Epoch:  678        4 Batch loss: 0.197979 Batch F1: 0.5263157894736842
Epoch:  678        5 Batch loss: 0.163260 Batch F1: 0.723404255319149
Epoch:  678        6 Batch loss: 0.163295 Batch F1: 0.7391304347826088
Epoch:  678        7 Batch loss: 0.172111 Batch F1: 0.6666666666666666
Epoch:  678        8 Batch loss: 0.137479 Batch F1: 0.7804878048780488
Epoch:  678        9 Batch loss: 0.158965 Batch F1: 0.75
Epoch:  678       10 Batch loss: 0.135011 Batch F1: 0.85
Epoch:  678       11 Batch loss: 0.155285 Batch F1: 0.7727272727272727
Epoch:  678       12 Batch loss: 0.187098 Batch F1: 0.6285714285714287
Train Avg Loss  678: 0.169397

Train Avg F1  678: 0.7105746016892747

Val Avg Loss  678: 0.182143

Val Avg F1  678:  0.6720880131901366

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 679
--------------------------------------------------------------
Epoch:  679        1 Batch loss: 0.181849 Batch F1: 0.6046511627906976
Epoch:  679        2 Batch loss: 0.159458 Batch F1: 0.7659574468085107
Epoch:  679        3 Batch loss: 0.150108 Batch F1: 0.8163265306122449
Epoch:  679        4 Batch loss: 0.168158 Batch F1: 0.7346938775510204
Epoch:  679        5 Batch loss: 0.190127 Batch F1: 0.5909090909090909
Epoch:  679        6 Batch loss: 0.180817 Batch F1: 0.7200000000000001
Epoch:  679        7 Batch loss: 0.208766 Batch F1: 0.6190476190476191
Epoch:  679        8 Batch loss: 0.146649 Batch F1: 0.8181818181818182
Epoch:  679        9 Batch loss: 0.171634 Batch F1: 0.631578947368421
Epoch:  679       10 Batch loss: 0.164856 Batch F1: 0.7142857142857143
Epoch:  679       11 Batch loss: 0.179998 Batch F1: 0.7346938775510204
Epoch:  679       12 Batch loss: 0.139229 Batch F1: 0.7857142857142856
Train Avg Loss  679: 0.170137

Train Avg F1  679: 0.7113366975683703

Val Avg Loss  679: 0.181591

Val Avg F1  679:  0.6769169960474308

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 680
--------------------------------------------------------------
Epoch:  680        1 Batch loss: 0.215607 Batch F1: 0.6
Epoch:  680        2 Batch loss: 0.185115 Batch F1: 0.75
Epoch:  680        3 Batch loss: 0.161379 Batch F1: 0.7142857142857143
Epoch:  680        4 Batch loss: 0.190828 Batch F1: 0.5641025641025641
Epoch:  680        5 Batch loss: 0.179217 Batch F1: 0.6666666666666666
Epoch:  680        6 Batch loss: 0.169493 Batch F1: 0.7272727272727272
Epoch:  680        7 Batch loss: 0.139962 Batch F1: 0.8627450980392156
Epoch:  680        8 Batch loss: 0.149839 Batch F1: 0.7317073170731707
Epoch:  680        9 Batch loss: 0.162072 Batch F1: 0.717948717948718
Epoch:  680       10 Batch loss: 0.151745 Batch F1: 0.7027027027027027
Epoch:  680       11 Batch loss: 0.150952 Batch F1: 0.75
Epoch:  680       12 Batch loss: 0.189288 Batch F1: 0.7272727272727272
Train Avg Loss  680: 0.170458

Train Avg F1  680: 0.7095586862803506

Val Avg Loss  680: 0.180853

Val Avg F1  680:  0.6788228180697465

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 681
--------------------------------------------------------------
Epoch:  681        1 Batch loss: 0.175028 Batch F1: 0.6808510638297872
Epoch:  681        2 Batch loss: 0.141364 Batch F1: 0.7894736842105262
Epoch:  681        3 Batch loss: 0.185733 Batch F1: 0.693877551020408
Epoch:  681        4 Batch loss: 0.169139 Batch F1: 0.6285714285714287
Epoch:  681        5 Batch loss: 0.158261 Batch F1: 0.8148148148148148
Epoch:  681        6 Batch loss: 0.166851 Batch F1: 0.8076923076923077
Epoch:  681        7 Batch loss: 0.163058 Batch F1: 0.7777777777777779
Epoch:  681        8 Batch loss: 0.194993 Batch F1: 0.6382978723404256
Epoch:  681        9 Batch loss: 0.179040 Batch F1: 0.5945945945945946
Epoch:  681       10 Batch loss: 0.162430 Batch F1: 0.6857142857142857
Epoch:  681       11 Batch loss: 0.155029 Batch F1: 0.7000000000000001
Epoch:  681       12 Batch loss: 0.182541 Batch F1: 0.6486486486486486
Train Avg Loss  681: 0.169456

Train Avg F1  681: 0.7050261691012505

Val Avg Loss  681: 0.181845

Val Avg F1  681:  0.6777885235332044

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 682
--------------------------------------------------------------
Epoch:  682        1 Batch loss: 0.206163 Batch F1: 0.6274509803921569
Epoch:  682        2 Batch loss: 0.153229 Batch F1: 0.8
Epoch:  682        3 Batch loss: 0.173705 Batch F1: 0.6956521739130435
Epoch:  682        4 Batch loss: 0.153384 Batch F1: 0.7000000000000001
Epoch:  682        5 Batch loss: 0.207383 Batch F1: 0.6122448979591837
Epoch:  682        6 Batch loss: 0.166806 Batch F1: 0.7272727272727272
Epoch:  682        7 Batch loss: 0.152570 Batch F1: 0.7555555555555555
Epoch:  682        8 Batch loss: 0.136817 Batch F1: 0.8780487804878048
Epoch:  682        9 Batch loss: 0.166616 Batch F1: 0.7142857142857143
Epoch:  682       10 Batch loss: 0.184470 Batch F1: 0.6046511627906977
Epoch:  682       11 Batch loss: 0.166413 Batch F1: 0.7659574468085107
Epoch:  682       12 Batch loss: 0.159753 Batch F1: 0.6875
Train Avg Loss  682: 0.168942

Train Avg F1  682: 0.7140516199554495

Val Avg Loss  682: 0.181909

Val Avg F1  682:  0.6738271122402449

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 683
--------------------------------------------------------------
Epoch:  683        1 Batch loss: 0.178365 Batch F1: 0.7083333333333333
Epoch:  683        2 Batch loss: 0.163137 Batch F1: 0.7391304347826088
Epoch:  683        3 Batch loss: 0.184370 Batch F1: 0.7307692307692307
Epoch:  683        4 Batch loss: 0.165612 Batch F1: 0.6666666666666667
Epoch:  683        5 Batch loss: 0.168512 Batch F1: 0.7083333333333334
Epoch:  683        6 Batch loss: 0.175886 Batch F1: 0.6111111111111112
Epoch:  683        7 Batch loss: 0.142406 Batch F1: 0.7894736842105262
Epoch:  683        8 Batch loss: 0.195029 Batch F1: 0.6222222222222223
Epoch:  683        9 Batch loss: 0.168099 Batch F1: 0.6818181818181819
Epoch:  683       10 Batch loss: 0.174962 Batch F1: 0.7346938775510204
Epoch:  683       11 Batch loss: 0.163000 Batch F1: 0.7391304347826088
Epoch:  683       12 Batch loss: 0.140489 Batch F1: 0.8108108108108109
Train Avg Loss  683: 0.168322

Train Avg F1  683: 0.7118744434493046

Val Avg Loss  683: 0.180427

Val Avg F1  683:  0.6668655299913323

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 684
--------------------------------------------------------------
Epoch:  684        1 Batch loss: 0.151722 Batch F1: 0.7142857142857143
Epoch:  684        2 Batch loss: 0.140477 Batch F1: 0.7647058823529413
Epoch:  684        3 Batch loss: 0.183370 Batch F1: 0.7058823529411765
Epoch:  684        4 Batch loss: 0.150895 Batch F1: 0.8148148148148148
Epoch:  684        5 Batch loss: 0.157149 Batch F1: 0.7555555555555555
Epoch:  684        6 Batch loss: 0.166825 Batch F1: 0.6842105263157895
Epoch:  684        7 Batch loss: 0.185878 Batch F1: 0.6190476190476191
Epoch:  684        8 Batch loss: 0.159581 Batch F1: 0.6470588235294117
Epoch:  684        9 Batch loss: 0.172160 Batch F1: 0.7391304347826085
Epoch:  684       10 Batch loss: 0.226481 Batch F1: 0.6181818181818183
Epoch:  684       11 Batch loss: 0.162635 Batch F1: 0.711111111111111
Epoch:  684       12 Batch loss: 0.157023 Batch F1: 0.7692307692307692
Train Avg Loss  684: 0.167850

Train Avg F1  684: 0.7119346185124441

Val Avg Loss  684: 0.180312

Val Avg F1  684:  0.6758116696122087

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 685
--------------------------------------------------------------
Epoch:  685        1 Batch loss: 0.150202 Batch F1: 0.8
Epoch:  685        2 Batch loss: 0.148216 Batch F1: 0.744186046511628
Epoch:  685        3 Batch loss: 0.166306 Batch F1: 0.6666666666666665
Epoch:  685        4 Batch loss: 0.171586 Batch F1: 0.6818181818181819
Epoch:  685        5 Batch loss: 0.148917 Batch F1: 0.8461538461538461
Epoch:  685        6 Batch loss: 0.160115 Batch F1: 0.7843137254901961
Epoch:  685        7 Batch loss: 0.159405 Batch F1: 0.6829268292682927
Epoch:  685        8 Batch loss: 0.172870 Batch F1: 0.6976744186046512
Epoch:  685        9 Batch loss: 0.219724 Batch F1: 0.6
Epoch:  685       10 Batch loss: 0.187505 Batch F1: 0.6
Epoch:  685       11 Batch loss: 0.182112 Batch F1: 0.6363636363636365
Epoch:  685       12 Batch loss: 0.145337 Batch F1: 0.7741935483870968
Train Avg Loss  685: 0.167691

Train Avg F1  685: 0.7095247416053496

Val Avg Loss  685: 0.180056

Val Avg F1  685:  0.6726844583987441

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 686
--------------------------------------------------------------
Epoch:  686        1 Batch loss: 0.148841 Batch F1: 0.75
Epoch:  686        2 Batch loss: 0.143427 Batch F1: 0.7804878048780488
Epoch:  686        3 Batch loss: 0.223113 Batch F1: 0.5599999999999999
Epoch:  686        4 Batch loss: 0.161532 Batch F1: 0.7499999999999999
Epoch:  686        5 Batch loss: 0.165999 Batch F1: 0.7391304347826089
Epoch:  686        6 Batch loss: 0.164763 Batch F1: 0.7727272727272727
Epoch:  686        7 Batch loss: 0.136602 Batch F1: 0.7777777777777778
Epoch:  686        8 Batch loss: 0.152735 Batch F1: 0.823529411764706
Epoch:  686        9 Batch loss: 0.201201 Batch F1: 0.7017543859649122
Epoch:  686       10 Batch loss: 0.196571 Batch F1: 0.7499999999999999
Epoch:  686       11 Batch loss: 0.168304 Batch F1: 0.8292682926829269
Epoch:  686       12 Batch loss: 0.190061 Batch F1: 0.742857142857143
Train Avg Loss  686: 0.171096

Train Avg F1  686: 0.748127710286283

Val Avg Loss  686: 0.182976

Val Avg F1  686:  0.6744833782569631

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 687
--------------------------------------------------------------
Epoch:  687        1 Batch loss: 0.172858 Batch F1: 0.7878787878787877
Epoch:  687        2 Batch loss: 0.197784 Batch F1: 0.6181818181818182
Epoch:  687        3 Batch loss: 0.152216 Batch F1: 0.8095238095238095
Epoch:  687        4 Batch loss: 0.158311 Batch F1: 0.8
Epoch:  687        5 Batch loss: 0.182578 Batch F1: 0.5882352941176471
Epoch:  687        6 Batch loss: 0.176379 Batch F1: 0.7755102040816326
Epoch:  687        7 Batch loss: 0.184010 Batch F1: 0.6808510638297872
Epoch:  687        8 Batch loss: 0.175205 Batch F1: 0.631578947368421
Epoch:  687        9 Batch loss: 0.155742 Batch F1: 0.6060606060606061
Epoch:  687       10 Batch loss: 0.190591 Batch F1: 0.7199999999999999
Epoch:  687       11 Batch loss: 0.178942 Batch F1: 0.6060606060606061
Epoch:  687       12 Batch loss: 0.144343 Batch F1: 0.7567567567567567
Train Avg Loss  687: 0.172413

Train Avg F1  687: 0.6983864911549894

Val Avg Loss  687: 0.186275

Val Avg F1  687:  0.6675219434653398

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 688
--------------------------------------------------------------
Epoch:  688        1 Batch loss: 0.197016 Batch F1: 0.5581395348837209
Epoch:  688        2 Batch loss: 0.169254 Batch F1: 0.7272727272727272
Epoch:  688        3 Batch loss: 0.165076 Batch F1: 0.7
Epoch:  688        4 Batch loss: 0.161360 Batch F1: 0.7317073170731707
Epoch:  688        5 Batch loss: 0.178149 Batch F1: 0.6341463414634148
Epoch:  688        6 Batch loss: 0.158869 Batch F1: 0.761904761904762
Epoch:  688        7 Batch loss: 0.185345 Batch F1: 0.6829268292682927
Epoch:  688        8 Batch loss: 0.166290 Batch F1: 0.7777777777777777
Epoch:  688        9 Batch loss: 0.187501 Batch F1: 0.78125
Epoch:  688       10 Batch loss: 0.161927 Batch F1: 0.8461538461538461
Epoch:  688       11 Batch loss: 0.202411 Batch F1: 0.6666666666666666
Epoch:  688       12 Batch loss: 0.171324 Batch F1: 0.5925925925925927
Train Avg Loss  688: 0.175377

Train Avg F1  688: 0.7050448662547476

Val Avg Loss  688: 0.189194

Val Avg F1  688:  0.6715452083099143

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 689
--------------------------------------------------------------
Epoch:  689        1 Batch loss: 0.196587 Batch F1: 0.5
Epoch:  689        2 Batch loss: 0.137655 Batch F1: 0.7428571428571428
Epoch:  689        3 Batch loss: 0.195603 Batch F1: 0.6938775510204083
Epoch:  689        4 Batch loss: 0.182033 Batch F1: 0.7391304347826089
Epoch:  689        5 Batch loss: 0.170478 Batch F1: 0.8085106382978724
Epoch:  689        6 Batch loss: 0.175740 Batch F1: 0.8771929824561403
Epoch:  689        7 Batch loss: 0.178613 Batch F1: 0.8399999999999999
Epoch:  689        8 Batch loss: 0.207790 Batch F1: 0.7796610169491526
Epoch:  689        9 Batch loss: 0.156927 Batch F1: 0.6451612903225806
Epoch:  689       10 Batch loss: 0.174449 Batch F1: 0.7924528301886792
Epoch:  689       11 Batch loss: 0.178556 Batch F1: 0.7234042553191489
Epoch:  689       12 Batch loss: 0.157625 Batch F1: 0.6666666666666667
Train Avg Loss  689: 0.176005

Train Avg F1  689: 0.7340762340717001

Val Avg Loss  689: 0.180482

Val Avg F1  689:  0.6741071428571429

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 690
--------------------------------------------------------------
Epoch:  690        1 Batch loss: 0.189786 Batch F1: 0.619047619047619
Epoch:  690        2 Batch loss: 0.160611 Batch F1: 0.6976744186046512
Epoch:  690        3 Batch loss: 0.176316 Batch F1: 0.7346938775510204
Epoch:  690        4 Batch loss: 0.138282 Batch F1: 0.8095238095238095
Epoch:  690        5 Batch loss: 0.158226 Batch F1: 0.7924528301886792
Epoch:  690        6 Batch loss: 0.172833 Batch F1: 0.7234042553191491
Epoch:  690        7 Batch loss: 0.195056 Batch F1: 0.631578947368421
Epoch:  690        8 Batch loss: 0.184587 Batch F1: 0.6666666666666666
Epoch:  690        9 Batch loss: 0.183171 Batch F1: 0.6666666666666666
Epoch:  690       10 Batch loss: 0.170665 Batch F1: 0.6976744186046512
Epoch:  690       11 Batch loss: 0.173081 Batch F1: 0.5882352941176471
Epoch:  690       12 Batch loss: 0.144607 Batch F1: 0.851063829787234
Train Avg Loss  690: 0.170602

Train Avg F1  690: 0.7065568861205179

Val Avg Loss  690: 0.181937

Val Avg F1  690:  0.679607117688513

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 691
--------------------------------------------------------------
Epoch:  691        1 Batch loss: 0.204108 Batch F1: 0.5789473684210527
Epoch:  691        2 Batch loss: 0.139484 Batch F1: 0.8333333333333333
Epoch:  691        3 Batch loss: 0.177976 Batch F1: 0.5789473684210527
Epoch:  691        4 Batch loss: 0.195627 Batch F1: 0.6666666666666666
Epoch:  691        5 Batch loss: 0.186334 Batch F1: 0.7307692307692307
Epoch:  691        6 Batch loss: 0.154567 Batch F1: 0.6666666666666667
Epoch:  691        7 Batch loss: 0.161398 Batch F1: 0.7500000000000001
Epoch:  691        8 Batch loss: 0.172889 Batch F1: 0.7843137254901961
Epoch:  691        9 Batch loss: 0.158123 Batch F1: 0.7272727272727272
Epoch:  691       10 Batch loss: 0.163596 Batch F1: 0.7843137254901961
Epoch:  691       11 Batch loss: 0.186299 Batch F1: 0.6511627906976745
Epoch:  691       12 Batch loss: 0.156558 Batch F1: 0.7272727272727272
Train Avg Loss  691: 0.171413

Train Avg F1  691: 0.7066388608751271

Val Avg Loss  691: 0.182995

Val Avg F1  691:  0.6795724227816344

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 692
--------------------------------------------------------------
Epoch:  692        1 Batch loss: 0.164863 Batch F1: 0.7555555555555556
Epoch:  692        2 Batch loss: 0.161981 Batch F1: 0.7391304347826085
Epoch:  692        3 Batch loss: 0.174041 Batch F1: 0.6666666666666666
Epoch:  692        4 Batch loss: 0.194832 Batch F1: 0.68
Epoch:  692        5 Batch loss: 0.170082 Batch F1: 0.7391304347826089
Epoch:  692        6 Batch loss: 0.150710 Batch F1: 0.7368421052631579
Epoch:  692        7 Batch loss: 0.196554 Batch F1: 0.6190476190476191
Epoch:  692        8 Batch loss: 0.204952 Batch F1: 0.5581395348837209
Epoch:  692        9 Batch loss: 0.159181 Batch F1: 0.6486486486486486
Epoch:  692       10 Batch loss: 0.179002 Batch F1: 0.7547169811320755
Epoch:  692       11 Batch loss: 0.141922 Batch F1: 0.8510638297872342
Epoch:  692       12 Batch loss: 0.146826 Batch F1: 0.787878787878788
Train Avg Loss  692: 0.170412

Train Avg F1  692: 0.7114017165357236

Val Avg Loss  692: 0.180728

Val Avg F1  692:  0.6506657268170426

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 693
--------------------------------------------------------------
Epoch:  693        1 Batch loss: 0.163819 Batch F1: 0.7755102040816326
Epoch:  693        2 Batch loss: 0.169434 Batch F1: 0.7307692307692308
Epoch:  693        3 Batch loss: 0.161799 Batch F1: 0.6666666666666667
Epoch:  693        4 Batch loss: 0.160086 Batch F1: 0.7826086956521738
Epoch:  693        5 Batch loss: 0.196128 Batch F1: 0.68
Epoch:  693        6 Batch loss: 0.179700 Batch F1: 0.7407407407407408
Epoch:  693        7 Batch loss: 0.147380 Batch F1: 0.7619047619047619
Epoch:  693        8 Batch loss: 0.197358 Batch F1: 0.5
Epoch:  693        9 Batch loss: 0.174849 Batch F1: 0.7083333333333334
Epoch:  693       10 Batch loss: 0.174521 Batch F1: 0.5714285714285715
Epoch:  693       11 Batch loss: 0.164823 Batch F1: 0.7391304347826088
Epoch:  693       12 Batch loss: 0.152537 Batch F1: 0.7894736842105263
Train Avg Loss  693: 0.170203

Train Avg F1  693: 0.7038805269641871

Val Avg Loss  693: 0.182801

Val Avg F1  693:  0.6786030595813205

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 694
--------------------------------------------------------------
Epoch:  694        1 Batch loss: 0.177521 Batch F1: 0.6111111111111113
Epoch:  694        2 Batch loss: 0.162482 Batch F1: 0.48000000000000004
Epoch:  694        3 Batch loss: 0.169141 Batch F1: 0.76
Epoch:  694        4 Batch loss: 0.180653 Batch F1: 0.6938775510204083
Epoch:  694        5 Batch loss: 0.166488 Batch F1: 0.7499999999999999
Epoch:  694        6 Batch loss: 0.186423 Batch F1: 0.6046511627906976
Epoch:  694        7 Batch loss: 0.173369 Batch F1: 0.723404255319149
Epoch:  694        8 Batch loss: 0.148844 Batch F1: 0.816326530612245
Epoch:  694        9 Batch loss: 0.169088 Batch F1: 0.723404255319149
Epoch:  694       10 Batch loss: 0.179515 Batch F1: 0.75
Epoch:  694       11 Batch loss: 0.179224 Batch F1: 0.6842105263157895
Epoch:  694       12 Batch loss: 0.138259 Batch F1: 0.8108108108108109
Train Avg Loss  694: 0.169251

Train Avg F1  694: 0.7006496836082801

Val Avg Loss  694: 0.182960

Val Avg F1  694:  0.6713777021491145

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 695
--------------------------------------------------------------
Epoch:  695        1 Batch loss: 0.160997 Batch F1: 0.7916666666666667
Epoch:  695        2 Batch loss: 0.188019 Batch F1: 0.6
Epoch:  695        3 Batch loss: 0.146179 Batch F1: 0.8800000000000001
Epoch:  695        4 Batch loss: 0.158418 Batch F1: 0.717948717948718
Epoch:  695        5 Batch loss: 0.133820 Batch F1: 0.7999999999999999
Epoch:  695        6 Batch loss: 0.183003 Batch F1: 0.6521739130434783
Epoch:  695        7 Batch loss: 0.190689 Batch F1: 0.6363636363636365
Epoch:  695        8 Batch loss: 0.135467 Batch F1: 0.8181818181818182
Epoch:  695        9 Batch loss: 0.242898 Batch F1: 0.5660377358490567
Epoch:  695       10 Batch loss: 0.163388 Batch F1: 0.7142857142857143
Epoch:  695       11 Batch loss: 0.174590 Batch F1: 0.5789473684210527
Epoch:  695       12 Batch loss: 0.155719 Batch F1: 0.7804878048780488
Train Avg Loss  695: 0.169432

Train Avg F1  695: 0.711341114636516

Val Avg Loss  695: 0.180995

Val Avg F1  695:  0.6758156028368795

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 696
--------------------------------------------------------------
Epoch:  696        1 Batch loss: 0.175790 Batch F1: 0.6190476190476191
Epoch:  696        2 Batch loss: 0.151376 Batch F1: 0.7999999999999999
Epoch:  696        3 Batch loss: 0.142221 Batch F1: 0.7647058823529412
Epoch:  696        4 Batch loss: 0.170638 Batch F1: 0.7441860465116279
Epoch:  696        5 Batch loss: 0.157485 Batch F1: 0.717948717948718
Epoch:  696        6 Batch loss: 0.187750 Batch F1: 0.7407407407407408
Epoch:  696        7 Batch loss: 0.159670 Batch F1: 0.7555555555555556
Epoch:  696        8 Batch loss: 0.154032 Batch F1: 0.7999999999999999
Epoch:  696        9 Batch loss: 0.174402 Batch F1: 0.6521739130434783
Epoch:  696       10 Batch loss: 0.184276 Batch F1: 0.6521739130434783
Epoch:  696       11 Batch loss: 0.169811 Batch F1: 0.723404255319149
Epoch:  696       12 Batch loss: 0.204493 Batch F1: 0.5641025641025641
Train Avg Loss  696: 0.169329

Train Avg F1  696: 0.711169933972156

Val Avg Loss  696: 0.187095

Val Avg F1  696:  0.6290061633281973

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 697
--------------------------------------------------------------
Epoch:  697        1 Batch loss: 0.161682 Batch F1: 0.7346938775510203
Epoch:  697        2 Batch loss: 0.181692 Batch F1: 0.6250000000000001
Epoch:  697        3 Batch loss: 0.187977 Batch F1: 0.64
Epoch:  697        4 Batch loss: 0.152587 Batch F1: 0.7659574468085106
Epoch:  697        5 Batch loss: 0.217715 Batch F1: 0.6274509803921569
Epoch:  697        6 Batch loss: 0.125713 Batch F1: 0.8500000000000001
Epoch:  697        7 Batch loss: 0.153356 Batch F1: 0.7692307692307692
Epoch:  697        8 Batch loss: 0.197187 Batch F1: 0.6363636363636364
Epoch:  697        9 Batch loss: 0.158208 Batch F1: 0.7659574468085107
Epoch:  697       10 Batch loss: 0.170939 Batch F1: 0.6829268292682926
Epoch:  697       11 Batch loss: 0.186919 Batch F1: 0.6808510638297872
Epoch:  697       12 Batch loss: 0.173637 Batch F1: 0.6666666666666666
Train Avg Loss  697: 0.172301

Train Avg F1  697: 0.7037582264099459

Val Avg Loss  697: 0.183406

Val Avg F1  697:  0.671421774097172

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 698
--------------------------------------------------------------
Epoch:  698        1 Batch loss: 0.170707 Batch F1: 0.7083333333333334
Epoch:  698        2 Batch loss: 0.178900 Batch F1: 0.7272727272727272
Epoch:  698        3 Batch loss: 0.176931 Batch F1: 0.631578947368421
Epoch:  698        4 Batch loss: 0.194435 Batch F1: 0.6530612244897959
Epoch:  698        5 Batch loss: 0.139140 Batch F1: 0.8780487804878049
Epoch:  698        6 Batch loss: 0.154590 Batch F1: 0.7826086956521738
Epoch:  698        7 Batch loss: 0.174172 Batch F1: 0.7317073170731707
Epoch:  698        8 Batch loss: 0.183238 Batch F1: 0.693877551020408
Epoch:  698        9 Batch loss: 0.202818 Batch F1: 0.6382978723404256
Epoch:  698       10 Batch loss: 0.152820 Batch F1: 0.761904761904762
Epoch:  698       11 Batch loss: 0.166865 Batch F1: 0.6818181818181818
Epoch:  698       12 Batch loss: 0.169764 Batch F1: 0.6666666666666667
Train Avg Loss  698: 0.172032

Train Avg F1  698: 0.7129313382856558

Val Avg Loss  698: 0.182574

Val Avg F1  698:  0.6673472910753206

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 699
--------------------------------------------------------------
Epoch:  699        1 Batch loss: 0.156804 Batch F1: 0.8363636363636363
Epoch:  699        2 Batch loss: 0.169756 Batch F1: 0.76
Epoch:  699        3 Batch loss: 0.176316 Batch F1: 0.6808510638297872
Epoch:  699        4 Batch loss: 0.192863 Batch F1: 0.3703703703703703
Epoch:  699        5 Batch loss: 0.186562 Batch F1: 0.6808510638297872
Epoch:  699        6 Batch loss: 0.184433 Batch F1: 0.6666666666666667
Epoch:  699        7 Batch loss: 0.176942 Batch F1: 0.65
Epoch:  699        8 Batch loss: 0.154346 Batch F1: 0.7027027027027027
Epoch:  699        9 Batch loss: 0.160116 Batch F1: 0.7272727272727272
Epoch:  699       10 Batch loss: 0.149228 Batch F1: 0.7692307692307693
Epoch:  699       11 Batch loss: 0.160582 Batch F1: 0.7843137254901961
Epoch:  699       12 Batch loss: 0.161625 Batch F1: 0.75
Train Avg Loss  699: 0.169131

Train Avg F1  699: 0.6982185604797202

Val Avg Loss  699: 0.181285

Val Avg F1  699:  0.6679571268597024

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 700
--------------------------------------------------------------
Epoch:  700        1 Batch loss: 0.175237 Batch F1: 0.6808510638297872
Epoch:  700        2 Batch loss: 0.185417 Batch F1: 0.736842105263158
Epoch:  700        3 Batch loss: 0.156403 Batch F1: 0.7659574468085107
Epoch:  700        4 Batch loss: 0.175324 Batch F1: 0.7083333333333334
Epoch:  700        5 Batch loss: 0.188761 Batch F1: 0.6666666666666666
Epoch:  700        6 Batch loss: 0.188170 Batch F1: 0.7307692307692307
Epoch:  700        7 Batch loss: 0.168883 Batch F1: 0.7272727272727272
Epoch:  700        8 Batch loss: 0.147944 Batch F1: 0.7499999999999999
Epoch:  700        9 Batch loss: 0.147665 Batch F1: 0.8260869565217391
Epoch:  700       10 Batch loss: 0.141198 Batch F1: 0.7567567567567567
Epoch:  700       11 Batch loss: 0.190129 Batch F1: 0.5142857142857143
Epoch:  700       12 Batch loss: 0.166062 Batch F1: 0.6
Train Avg Loss  700: 0.169266

Train Avg F1  700: 0.7053185001256354

Val Avg Loss  700: 0.180861

Val Avg F1  700:  0.6762358985268355

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 701
--------------------------------------------------------------
Epoch:  701        1 Batch loss: 0.177404 Batch F1: 0.6956521739130435
Epoch:  701        2 Batch loss: 0.176121 Batch F1: 0.6976744186046512
Epoch:  701        3 Batch loss: 0.188048 Batch F1: 0.72
Epoch:  701        4 Batch loss: 0.143401 Batch F1: 0.8000000000000002
Epoch:  701        5 Batch loss: 0.177684 Batch F1: 0.6666666666666666
Epoch:  701        6 Batch loss: 0.178157 Batch F1: 0.6829268292682927
Epoch:  701        7 Batch loss: 0.200947 Batch F1: 0.6222222222222223
Epoch:  701        8 Batch loss: 0.158548 Batch F1: 0.7555555555555556
Epoch:  701        9 Batch loss: 0.144423 Batch F1: 0.8095238095238095
Epoch:  701       10 Batch loss: 0.191614 Batch F1: 0.6222222222222223
Epoch:  701       11 Batch loss: 0.154219 Batch F1: 0.7441860465116279
Epoch:  701       12 Batch loss: 0.156970 Batch F1: 0.7692307692307692
Train Avg Loss  701: 0.170628

Train Avg F1  701: 0.7154883928099052

Val Avg Loss  701: 0.181384

Val Avg F1  701:  0.6727177537681739

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 702
--------------------------------------------------------------
Epoch:  702        1 Batch loss: 0.154414 Batch F1: 0.717948717948718
Epoch:  702        2 Batch loss: 0.170646 Batch F1: 0.7111111111111111
Epoch:  702        3 Batch loss: 0.157755 Batch F1: 0.8363636363636364
Epoch:  702        4 Batch loss: 0.200194 Batch F1: 0.6250000000000001
Epoch:  702        5 Batch loss: 0.167630 Batch F1: 0.7441860465116279
Epoch:  702        6 Batch loss: 0.188185 Batch F1: 0.68
Epoch:  702        7 Batch loss: 0.175667 Batch F1: 0.7083333333333334
Epoch:  702        8 Batch loss: 0.165041 Batch F1: 0.6315789473684211
Epoch:  702        9 Batch loss: 0.156798 Batch F1: 0.7659574468085107
Epoch:  702       10 Batch loss: 0.154291 Batch F1: 0.7027027027027027
Epoch:  702       11 Batch loss: 0.170465 Batch F1: 0.7027027027027027
Epoch:  702       12 Batch loss: 0.181398 Batch F1: 0.6842105263157895
Train Avg Loss  702: 0.170207

Train Avg F1  702: 0.7091745975972127

Val Avg Loss  702: 0.182857

Val Avg F1  702:  0.6512986696724277

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 703
--------------------------------------------------------------
Epoch:  703        1 Batch loss: 0.153726 Batch F1: 0.7142857142857143
Epoch:  703        2 Batch loss: 0.192948 Batch F1: 0.7906976744186046
Epoch:  703        3 Batch loss: 0.172117 Batch F1: 0.7755102040816326
Epoch:  703        4 Batch loss: 0.153767 Batch F1: 0.8627450980392156
Epoch:  703        5 Batch loss: 0.163883 Batch F1: 0.888888888888889
Epoch:  703        6 Batch loss: 0.244835 Batch F1: 0.6792452830188679
Epoch:  703        7 Batch loss: 0.170072 Batch F1: 0.65
Epoch:  703        8 Batch loss: 0.161132 Batch F1: 0.7916666666666667
Epoch:  703        9 Batch loss: 0.176119 Batch F1: 0.6666666666666667
Epoch:  703       10 Batch loss: 0.151108 Batch F1: 0.6896551724137931
Epoch:  703       11 Batch loss: 0.198641 Batch F1: 0.5789473684210527
Epoch:  703       12 Batch loss: 0.219038 Batch F1: 0.7727272727272727
Train Avg Loss  703: 0.179782

Train Avg F1  703: 0.7384196674690315

Val Avg Loss  703: 0.186204

Val Avg F1  703:  0.7926341589267285

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 704
--------------------------------------------------------------
Epoch:  704        1 Batch loss: 0.182044 Batch F1: 0.8421052631578947
Epoch:  704        2 Batch loss: 0.244092 Batch F1: 0.6440677966101694
Epoch:  704        3 Batch loss: 0.158827 Batch F1: 0.9433962264150945
Epoch:  704        4 Batch loss: 0.178838 Batch F1: 0.782608695652174
Epoch:  704        5 Batch loss: 0.164578 Batch F1: 0.7142857142857143
Epoch:  704        6 Batch loss: 0.161974 Batch F1: 0.5
Epoch:  704        7 Batch loss: 0.175526 Batch F1: 0.42857142857142855
Epoch:  704        8 Batch loss: 0.175058 Batch F1: 0.6470588235294118
Epoch:  704        9 Batch loss: 0.224540 Batch F1: 0.4897959183673469
Epoch:  704       10 Batch loss: 0.154021 Batch F1: 0.9152542372881356
Epoch:  704       11 Batch loss: 0.224905 Batch F1: 0.7037037037037037
Epoch:  704       12 Batch loss: 0.163403 Batch F1: 0.8372093023255814
Train Avg Loss  704: 0.183984

Train Avg F1  704: 0.7040047591588879

Val Avg Loss  704: 0.192390

Val Avg F1  704:  0.8339466337234194

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 705
--------------------------------------------------------------
Epoch:  705        1 Batch loss: 0.193300 Batch F1: 0.8076923076923076
Epoch:  705        2 Batch loss: 0.199064 Batch F1: 0.6
Epoch:  705        3 Batch loss: 0.208204 Batch F1: 0.7547169811320755
Epoch:  705        4 Batch loss: 0.218842 Batch F1: 0.6122448979591837
Epoch:  705        5 Batch loss: 0.173317 Batch F1: 0.8846153846153846
Epoch:  705        6 Batch loss: 0.149027 Batch F1: 0.8260869565217391
Epoch:  705        7 Batch loss: 0.177126 Batch F1: 0.65
Epoch:  705        8 Batch loss: 0.181366 Batch F1: 0.7692307692307692
Epoch:  705        9 Batch loss: 0.170173 Batch F1: 0.6486486486486486
Epoch:  705       10 Batch loss: 0.191558 Batch F1: 0.6046511627906976
Epoch:  705       11 Batch loss: 0.150698 Batch F1: 0.7428571428571428
Epoch:  705       12 Batch loss: 0.160748 Batch F1: 0.6666666666666667
Train Avg Loss  705: 0.181118

Train Avg F1  705: 0.7139509098428847

Val Avg Loss  705: 0.186784

Val Avg F1  705:  0.6765240917834254

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 706
--------------------------------------------------------------
Epoch:  706        1 Batch loss: 0.179817 Batch F1: 0.7777777777777779
Epoch:  706        2 Batch loss: 0.160712 Batch F1: 0.6060606060606061
Epoch:  706        3 Batch loss: 0.188465 Batch F1: 0.6363636363636364
Epoch:  706        4 Batch loss: 0.177682 Batch F1: 0.6938775510204083
Epoch:  706        5 Batch loss: 0.175322 Batch F1: 0.8
Epoch:  706        6 Batch loss: 0.186558 Batch F1: 0.6341463414634148
Epoch:  706        7 Batch loss: 0.165387 Batch F1: 0.7391304347826085
Epoch:  706        8 Batch loss: 0.172982 Batch F1: 0.6315789473684211
Epoch:  706        9 Batch loss: 0.171161 Batch F1: 0.7391304347826088
Epoch:  706       10 Batch loss: 0.152405 Batch F1: 0.7804878048780488
Epoch:  706       11 Batch loss: 0.170435 Batch F1: 0.7391304347826089
Epoch:  706       12 Batch loss: 0.197125 Batch F1: 0.6666666666666667
Train Avg Loss  706: 0.174838

Train Avg F1  706: 0.7036958863289003

Val Avg Loss  706: 0.183626

Val Avg F1  706:  0.6734159314997404

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 707
--------------------------------------------------------------
Epoch:  707        1 Batch loss: 0.166550 Batch F1: 0.6285714285714286
Epoch:  707        2 Batch loss: 0.165250 Batch F1: 0.7555555555555556
Epoch:  707        3 Batch loss: 0.195108 Batch F1: 0.55
Epoch:  707        4 Batch loss: 0.193165 Batch F1: 0.5714285714285713
Epoch:  707        5 Batch loss: 0.172220 Batch F1: 0.6956521739130435
Epoch:  707        6 Batch loss: 0.188722 Batch F1: 0.7234042553191489
Epoch:  707        7 Batch loss: 0.160214 Batch F1: 0.7142857142857143
Epoch:  707        8 Batch loss: 0.161132 Batch F1: 0.7317073170731706
Epoch:  707        9 Batch loss: 0.158361 Batch F1: 0.8076923076923077
Epoch:  707       10 Batch loss: 0.175369 Batch F1: 0.7391304347826089
Epoch:  707       11 Batch loss: 0.169917 Batch F1: 0.7499999999999999
Epoch:  707       12 Batch loss: 0.145544 Batch F1: 0.8292682926829269
Train Avg Loss  707: 0.170963

Train Avg F1  707: 0.7080580042753731

Val Avg Loss  707: 0.181594

Val Avg F1  707:  0.6736921651796596

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 708
--------------------------------------------------------------
Epoch:  708        1 Batch loss: 0.159955 Batch F1: 0.782608695652174
Epoch:  708        2 Batch loss: 0.126739 Batch F1: 0.7999999999999999
Epoch:  708        3 Batch loss: 0.206312 Batch F1: 0.6250000000000001
Epoch:  708        4 Batch loss: 0.200079 Batch F1: 0.5500000000000002
Epoch:  708        5 Batch loss: 0.187338 Batch F1: 0.6666666666666666
Epoch:  708        6 Batch loss: 0.167384 Batch F1: 0.76
Epoch:  708        7 Batch loss: 0.170817 Batch F1: 0.7450980392156864
Epoch:  708        8 Batch loss: 0.151432 Batch F1: 0.7999999999999999
Epoch:  708        9 Batch loss: 0.194157 Batch F1: 0.7037037037037038
Epoch:  708       10 Batch loss: 0.172428 Batch F1: 0.6470588235294118
Epoch:  708       11 Batch loss: 0.177125 Batch F1: 0.6818181818181818
Epoch:  708       12 Batch loss: 0.149231 Batch F1: 0.7894736842105263
Train Avg Loss  708: 0.171916

Train Avg F1  708: 0.7126189828996959

Val Avg Loss  708: 0.184132

Val Avg F1  708:  0.672191347935055

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 709
--------------------------------------------------------------
Epoch:  709        1 Batch loss: 0.125154 Batch F1: 0.8292682926829269
Epoch:  709        2 Batch loss: 0.157051 Batch F1: 0.8
Epoch:  709        3 Batch loss: 0.194274 Batch F1: 0.5405405405405405
Epoch:  709        4 Batch loss: 0.178246 Batch F1: 0.6818181818181819
Epoch:  709        5 Batch loss: 0.185853 Batch F1: 0.5789473684210527
Epoch:  709        6 Batch loss: 0.169866 Batch F1: 0.6666666666666667
Epoch:  709        7 Batch loss: 0.162096 Batch F1: 0.717948717948718
Epoch:  709        8 Batch loss: 0.172818 Batch F1: 0.7083333333333334
Epoch:  709        9 Batch loss: 0.171453 Batch F1: 0.6666666666666667
Epoch:  709       10 Batch loss: 0.180904 Batch F1: 0.7777777777777777
Epoch:  709       11 Batch loss: 0.182727 Batch F1: 0.7547169811320754
Epoch:  709       12 Batch loss: 0.187294 Batch F1: 0.7499999999999999
Train Avg Loss  709: 0.172311

Train Avg F1  709: 0.7060570439156616

Val Avg Loss  709: 0.181605

Val Avg F1  709:  0.6760178313749742

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 710
--------------------------------------------------------------
Epoch:  710        1 Batch loss: 0.180816 Batch F1: 0.5789473684210527
Epoch:  710        2 Batch loss: 0.155145 Batch F1: 0.8235294117647058
Epoch:  710        3 Batch loss: 0.176185 Batch F1: 0.6111111111111113
Epoch:  710        4 Batch loss: 0.150397 Batch F1: 0.8181818181818182
Epoch:  710        5 Batch loss: 0.195357 Batch F1: 0.6808510638297872
Epoch:  710        6 Batch loss: 0.167998 Batch F1: 0.7234042553191491
Epoch:  710        7 Batch loss: 0.164293 Batch F1: 0.7450980392156864
Epoch:  710        8 Batch loss: 0.177473 Batch F1: 0.7111111111111111
Epoch:  710        9 Batch loss: 0.166882 Batch F1: 0.6808510638297872
Epoch:  710       10 Batch loss: 0.174631 Batch F1: 0.6486486486486486
Epoch:  710       11 Batch loss: 0.169231 Batch F1: 0.7142857142857143
Epoch:  710       12 Batch loss: 0.174885 Batch F1: 0.7500000000000001
Train Avg Loss  710: 0.171108

Train Avg F1  710: 0.7071683004765478

Val Avg Loss  710: 0.181861

Val Avg F1  710:  0.6704215499947208

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 711
--------------------------------------------------------------
Epoch:  711        1 Batch loss: 0.181356 Batch F1: 0.7083333333333334
Epoch:  711        2 Batch loss: 0.189478 Batch F1: 0.6190476190476191
Epoch:  711        3 Batch loss: 0.178176 Batch F1: 0.7547169811320755
Epoch:  711        4 Batch loss: 0.176776 Batch F1: 0.7083333333333334
Epoch:  711        5 Batch loss: 0.172077 Batch F1: 0.6842105263157895
Epoch:  711        6 Batch loss: 0.176909 Batch F1: 0.5945945945945946
Epoch:  711        7 Batch loss: 0.144469 Batch F1: 0.7567567567567567
Epoch:  711        8 Batch loss: 0.166463 Batch F1: 0.6315789473684211
Epoch:  711        9 Batch loss: 0.154278 Batch F1: 0.8148148148148148
Epoch:  711       10 Batch loss: 0.161878 Batch F1: 0.7272727272727272
Epoch:  711       11 Batch loss: 0.171581 Batch F1: 0.7234042553191489
Epoch:  711       12 Batch loss: 0.159517 Batch F1: 0.7692307692307693
Train Avg Loss  711: 0.169413

Train Avg F1  711: 0.707691221543282

Val Avg Loss  711: 0.181649

Val Avg F1  711:  0.67421926910299

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 712
--------------------------------------------------------------
Epoch:  712        1 Batch loss: 0.179373 Batch F1: 0.5945945945945946
Epoch:  712        2 Batch loss: 0.158008 Batch F1: 0.6666666666666665
Epoch:  712        3 Batch loss: 0.159142 Batch F1: 0.7555555555555556
Epoch:  712        4 Batch loss: 0.177261 Batch F1: 0.7692307692307692
Epoch:  712        5 Batch loss: 0.147621 Batch F1: 0.8163265306122449
Epoch:  712        6 Batch loss: 0.179307 Batch F1: 0.6818181818181819
Epoch:  712        7 Batch loss: 0.171261 Batch F1: 0.7450980392156863
Epoch:  712        8 Batch loss: 0.158976 Batch F1: 0.761904761904762
Epoch:  712        9 Batch loss: 0.170994 Batch F1: 0.6818181818181819
Epoch:  712       10 Batch loss: 0.185089 Batch F1: 0.6511627906976744
Epoch:  712       11 Batch loss: 0.162717 Batch F1: 0.6976744186046512
Epoch:  712       12 Batch loss: 0.176921 Batch F1: 0.6842105263157895
Train Avg Loss  712: 0.168889

Train Avg F1  712: 0.7088384180862298

Val Avg Loss  712: 0.180706

Val Avg F1  712:  0.677205672655622

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 713
--------------------------------------------------------------
Epoch:  713        1 Batch loss: 0.198210 Batch F1: 0.6666666666666665
Epoch:  713        2 Batch loss: 0.173506 Batch F1: 0.7450980392156864
Epoch:  713        3 Batch loss: 0.174238 Batch F1: 0.6829268292682926
Epoch:  713        4 Batch loss: 0.184036 Batch F1: 0.5555555555555555
Epoch:  713        5 Batch loss: 0.148960 Batch F1: 0.7755102040816326
Epoch:  713        6 Batch loss: 0.170365 Batch F1: 0.6666666666666667
Epoch:  713        7 Batch loss: 0.147585 Batch F1: 0.8163265306122449
Epoch:  713        8 Batch loss: 0.132812 Batch F1: 0.8260869565217391
Epoch:  713        9 Batch loss: 0.167970 Batch F1: 0.76
Epoch:  713       10 Batch loss: 0.189715 Batch F1: 0.4827586206896552
Epoch:  713       11 Batch loss: 0.177349 Batch F1: 0.7083333333333334
Epoch:  713       12 Batch loss: 0.159125 Batch F1: 0.7272727272727272
Train Avg Loss  713: 0.168656

Train Avg F1  713: 0.7011001774903499

Val Avg Loss  713: 0.180928

Val Avg F1  713:  0.67072940287226

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 714
--------------------------------------------------------------
Epoch:  714        1 Batch loss: 0.154133 Batch F1: 0.7499999999999999
Epoch:  714        2 Batch loss: 0.166431 Batch F1: 0.6857142857142857
Epoch:  714        3 Batch loss: 0.193196 Batch F1: 0.7307692307692306
Epoch:  714        4 Batch loss: 0.166252 Batch F1: 0.7555555555555556
Epoch:  714        5 Batch loss: 0.189206 Batch F1: 0.6190476190476191
Epoch:  714        6 Batch loss: 0.149934 Batch F1: 0.8421052631578948
Epoch:  714        7 Batch loss: 0.151851 Batch F1: 0.7659574468085107
Epoch:  714        8 Batch loss: 0.177494 Batch F1: 0.6153846153846153
Epoch:  714        9 Batch loss: 0.209153 Batch F1: 0.35897435897435903
Epoch:  714       10 Batch loss: 0.163158 Batch F1: 0.76
Epoch:  714       11 Batch loss: 0.175928 Batch F1: 0.7317073170731708
Epoch:  714       12 Batch loss: 0.163766 Batch F1: 0.7441860465116279
Train Avg Loss  714: 0.171708

Train Avg F1  714: 0.6966168115830724

Val Avg Loss  714: 0.181087

Val Avg F1  714:  0.6759514920536154

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 715
--------------------------------------------------------------
Epoch:  715        1 Batch loss: 0.169801 Batch F1: 0.6842105263157895
Epoch:  715        2 Batch loss: 0.212343 Batch F1: 0.6792452830188679
Epoch:  715        3 Batch loss: 0.164368 Batch F1: 0.7234042553191489
Epoch:  715        4 Batch loss: 0.169511 Batch F1: 0.7727272727272727
Epoch:  715        5 Batch loss: 0.175769 Batch F1: 0.7555555555555555
Epoch:  715        6 Batch loss: 0.157544 Batch F1: 0.75
Epoch:  715        7 Batch loss: 0.157444 Batch F1: 0.7
Epoch:  715        8 Batch loss: 0.150915 Batch F1: 0.823529411764706
Epoch:  715        9 Batch loss: 0.164234 Batch F1: 0.8214285714285715
Epoch:  715       10 Batch loss: 0.164180 Batch F1: 0.6842105263157895
Epoch:  715       11 Batch loss: 0.202094 Batch F1: 0.5454545454545454
Epoch:  715       12 Batch loss: 0.194111 Batch F1: 0.4827586206896552
Train Avg Loss  715: 0.173526

Train Avg F1  715: 0.7018770473824918

Val Avg Loss  715: 0.182694

Val Avg F1  715:  0.6750422214367072

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 716
--------------------------------------------------------------
Epoch:  716        1 Batch loss: 0.165483 Batch F1: 0.6060606060606061
Epoch:  716        2 Batch loss: 0.179092 Batch F1: 0.631578947368421
Epoch:  716        3 Batch loss: 0.186224 Batch F1: 0.6808510638297872
Epoch:  716        4 Batch loss: 0.171821 Batch F1: 0.7499999999999999
Epoch:  716        5 Batch loss: 0.187566 Batch F1: 0.6666666666666666
Epoch:  716        6 Batch loss: 0.173449 Batch F1: 0.6829268292682927
Epoch:  716        7 Batch loss: 0.144668 Batch F1: 0.8799999999999999
Epoch:  716        8 Batch loss: 0.178146 Batch F1: 0.6829268292682926
Epoch:  716        9 Batch loss: 0.150198 Batch F1: 0.8095238095238096
Epoch:  716       10 Batch loss: 0.188475 Batch F1: 0.6521739130434783
Epoch:  716       11 Batch loss: 0.166229 Batch F1: 0.7346938775510204
Epoch:  716       12 Batch loss: 0.178706 Batch F1: 0.7142857142857143
Train Avg Loss  716: 0.172505

Train Avg F1  716: 0.707640688072174

Val Avg Loss  716: 0.181645

Val Avg F1  716:  0.6753205128205128

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 717
--------------------------------------------------------------
Epoch:  717        1 Batch loss: 0.150937 Batch F1: 0.7843137254901961
Epoch:  717        2 Batch loss: 0.160568 Batch F1: 0.717948717948718
Epoch:  717        3 Batch loss: 0.152257 Batch F1: 0.7500000000000001
Epoch:  717        4 Batch loss: 0.166190 Batch F1: 0.6976744186046512
Epoch:  717        5 Batch loss: 0.175918 Batch F1: 0.7636363636363636
Epoch:  717        6 Batch loss: 0.155998 Batch F1: 0.7804878048780488
Epoch:  717        7 Batch loss: 0.177066 Batch F1: 0.6976744186046512
Epoch:  717        8 Batch loss: 0.162726 Batch F1: 0.7391304347826089
Epoch:  717        9 Batch loss: 0.196953 Batch F1: 0.627450980392157
Epoch:  717       10 Batch loss: 0.178867 Batch F1: 0.5945945945945946
Epoch:  717       11 Batch loss: 0.185479 Batch F1: 0.5294117647058824
Epoch:  717       12 Batch loss: 0.159466 Batch F1: 0.7999999999999999
Train Avg Loss  717: 0.168535

Train Avg F1  717: 0.7068602686364893

Val Avg Loss  717: 0.181212

Val Avg F1  717:  0.6746951440150528

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 718
--------------------------------------------------------------
Epoch:  718        1 Batch loss: 0.171051 Batch F1: 0.6829268292682926
Epoch:  718        2 Batch loss: 0.171159 Batch F1: 0.723404255319149
Epoch:  718        3 Batch loss: 0.152710 Batch F1: 0.6666666666666667
Epoch:  718        4 Batch loss: 0.157963 Batch F1: 0.7727272727272727
Epoch:  718        5 Batch loss: 0.153742 Batch F1: 0.717948717948718
Epoch:  718        6 Batch loss: 0.180633 Batch F1: 0.6521739130434783
Epoch:  718        7 Batch loss: 0.179107 Batch F1: 0.7058823529411765
Epoch:  718        8 Batch loss: 0.147825 Batch F1: 0.782608695652174
Epoch:  718        9 Batch loss: 0.191396 Batch F1: 0.6666666666666666
Epoch:  718       10 Batch loss: 0.161090 Batch F1: 0.7755102040816326
Epoch:  718       11 Batch loss: 0.178221 Batch F1: 0.6976744186046512
Epoch:  718       12 Batch loss: 0.172121 Batch F1: 0.6842105263157895
Train Avg Loss  718: 0.168085

Train Avg F1  718: 0.7107000432696391

Val Avg Loss  718: 0.181768

Val Avg F1  718:  0.6769492579640551

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 719
--------------------------------------------------------------
Epoch:  719        1 Batch loss: 0.172894 Batch F1: 0.6938775510204083
Epoch:  719        2 Batch loss: 0.178741 Batch F1: 0.6666666666666666
Epoch:  719        3 Batch loss: 0.181983 Batch F1: 0.68
Epoch:  719        4 Batch loss: 0.168850 Batch F1: 0.5882352941176471
Epoch:  719        5 Batch loss: 0.206597 Batch F1: 0.45714285714285713
Epoch:  719        6 Batch loss: 0.178168 Batch F1: 0.6530612244897959
Epoch:  719        7 Batch loss: 0.171782 Batch F1: 0.7391304347826085
Epoch:  719        8 Batch loss: 0.167521 Batch F1: 0.8000000000000002
Epoch:  719        9 Batch loss: 0.145711 Batch F1: 0.8444444444444444
Epoch:  719       10 Batch loss: 0.145051 Batch F1: 0.7906976744186046
Epoch:  719       11 Batch loss: 0.151272 Batch F1: 0.7317073170731707
Epoch:  719       12 Batch loss: 0.152173 Batch F1: 0.8292682926829269
Train Avg Loss  719: 0.168395

Train Avg F1  719: 0.7061859797365941

Val Avg Loss  719: 0.180147

Val Avg F1  719:  0.6783417702101548

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 720
--------------------------------------------------------------
Epoch:  720        1 Batch loss: 0.164224 Batch F1: 0.8
Epoch:  720        2 Batch loss: 0.175445 Batch F1: 0.6666666666666666
Epoch:  720        3 Batch loss: 0.203851 Batch F1: 0.5957446808510638
Epoch:  720        4 Batch loss: 0.171537 Batch F1: 0.6285714285714286
Epoch:  720        5 Batch loss: 0.212095 Batch F1: 0.5652173913043478
Epoch:  720        6 Batch loss: 0.160228 Batch F1: 0.7027027027027027
Epoch:  720        7 Batch loss: 0.155083 Batch F1: 0.7843137254901961
Epoch:  720        8 Batch loss: 0.143158 Batch F1: 0.7692307692307692
Epoch:  720        9 Batch loss: 0.153750 Batch F1: 0.8000000000000002
Epoch:  720       10 Batch loss: 0.154940 Batch F1: 0.7755102040816326
Epoch:  720       11 Batch loss: 0.140573 Batch F1: 0.7906976744186046
Epoch:  720       12 Batch loss: 0.189915 Batch F1: 0.6111111111111112
Train Avg Loss  720: 0.168733

Train Avg F1  720: 0.7074805295357102

Val Avg Loss  720: 0.180403

Val Avg F1  720:  0.6765231524308767

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 721
--------------------------------------------------------------
Epoch:  721        1 Batch loss: 0.159098 Batch F1: 0.76
Epoch:  721        2 Batch loss: 0.172950 Batch F1: 0.7272727272727272
Epoch:  721        3 Batch loss: 0.153253 Batch F1: 0.7391304347826089
Epoch:  721        4 Batch loss: 0.151196 Batch F1: 0.7916666666666667
Epoch:  721        5 Batch loss: 0.140722 Batch F1: 0.8095238095238095
Epoch:  721        6 Batch loss: 0.194642 Batch F1: 0.68
Epoch:  721        7 Batch loss: 0.148318 Batch F1: 0.8260869565217391
Epoch:  721        8 Batch loss: 0.153955 Batch F1: 0.6666666666666667
Epoch:  721        9 Batch loss: 0.173538 Batch F1: 0.5294117647058824
Epoch:  721       10 Batch loss: 0.197164 Batch F1: 0.64
Epoch:  721       11 Batch loss: 0.188061 Batch F1: 0.6363636363636365
Epoch:  721       12 Batch loss: 0.178538 Batch F1: 0.6842105263157895
Train Avg Loss  721: 0.167619

Train Avg F1  721: 0.7075277657349606

Val Avg Loss  721: 0.181676

Val Avg F1  721:  0.6721416098047123

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 722
--------------------------------------------------------------
Epoch:  722        1 Batch loss: 0.204774 Batch F1: 0.6923076923076923
Epoch:  722        2 Batch loss: 0.153728 Batch F1: 0.761904761904762
Epoch:  722        3 Batch loss: 0.173512 Batch F1: 0.7346938775510204
Epoch:  722        4 Batch loss: 0.150313 Batch F1: 0.742857142857143
Epoch:  722        5 Batch loss: 0.192865 Batch F1: 0.5777777777777778
Epoch:  722        6 Batch loss: 0.176373 Batch F1: 0.693877551020408
Epoch:  722        7 Batch loss: 0.170550 Batch F1: 0.7111111111111111
Epoch:  722        8 Batch loss: 0.153418 Batch F1: 0.782608695652174
Epoch:  722        9 Batch loss: 0.160769 Batch F1: 0.7692307692307692
Epoch:  722       10 Batch loss: 0.159198 Batch F1: 0.7272727272727272
Epoch:  722       11 Batch loss: 0.147775 Batch F1: 0.7272727272727272
Epoch:  722       12 Batch loss: 0.169379 Batch F1: 0.625
Train Avg Loss  722: 0.167721

Train Avg F1  722: 0.7121595694965261

Val Avg Loss  722: 0.180478

Val Avg F1  722:  0.6742408906882592

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 723
--------------------------------------------------------------
Epoch:  723        1 Batch loss: 0.164811 Batch F1: 0.7111111111111111
Epoch:  723        2 Batch loss: 0.192993 Batch F1: 0.6792452830188679
Epoch:  723        3 Batch loss: 0.151928 Batch F1: 0.7027027027027027
Epoch:  723        4 Batch loss: 0.165002 Batch F1: 0.7272727272727272
Epoch:  723        5 Batch loss: 0.164535 Batch F1: 0.7692307692307692
Epoch:  723        6 Batch loss: 0.167674 Batch F1: 0.76
Epoch:  723        7 Batch loss: 0.186196 Batch F1: 0.6818181818181818
Epoch:  723        8 Batch loss: 0.164245 Batch F1: 0.6829268292682926
Epoch:  723        9 Batch loss: 0.143460 Batch F1: 0.8181818181818182
Epoch:  723       10 Batch loss: 0.168143 Batch F1: 0.6829268292682926
Epoch:  723       11 Batch loss: 0.179833 Batch F1: 0.6818181818181819
Epoch:  723       12 Batch loss: 0.182261 Batch F1: 0.6
Train Avg Loss  723: 0.169257

Train Avg F1  723: 0.7081028694742454

Val Avg Loss  723: 0.180397

Val Avg F1  723:  0.6778004535147393

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 724
--------------------------------------------------------------
Epoch:  724        1 Batch loss: 0.156480 Batch F1: 0.7659574468085107
Epoch:  724        2 Batch loss: 0.152015 Batch F1: 0.7222222222222223
Epoch:  724        3 Batch loss: 0.172749 Batch F1: 0.7346938775510204
Epoch:  724        4 Batch loss: 0.162382 Batch F1: 0.606060606060606
Epoch:  724        5 Batch loss: 0.136500 Batch F1: 0.8461538461538461
Epoch:  724        6 Batch loss: 0.191934 Batch F1: 0.68
Epoch:  724        7 Batch loss: 0.187061 Batch F1: 0.6511627906976744
Epoch:  724        8 Batch loss: 0.183342 Batch F1: 0.5714285714285714
Epoch:  724        9 Batch loss: 0.151497 Batch F1: 0.717948717948718
Epoch:  724       10 Batch loss: 0.156544 Batch F1: 0.7555555555555555
Epoch:  724       11 Batch loss: 0.194878 Batch F1: 0.6666666666666666
Epoch:  724       12 Batch loss: 0.179691 Batch F1: 0.7555555555555555
Train Avg Loss  724: 0.168756

Train Avg F1  724: 0.7061171547207458

Val Avg Loss  724: 0.180829

Val Avg F1  724:  0.6767646983245966

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 725
--------------------------------------------------------------
Epoch:  725        1 Batch loss: 0.168269 Batch F1: 0.7142857142857143
Epoch:  725        2 Batch loss: 0.154715 Batch F1: 0.7317073170731706
Epoch:  725        3 Batch loss: 0.155421 Batch F1: 0.7924528301886793
Epoch:  725        4 Batch loss: 0.166811 Batch F1: 0.6666666666666667
Epoch:  725        5 Batch loss: 0.186273 Batch F1: 0.5853658536585366
Epoch:  725        6 Batch loss: 0.179821 Batch F1: 0.6511627906976744
Epoch:  725        7 Batch loss: 0.182284 Batch F1: 0.6511627906976745
Epoch:  725        8 Batch loss: 0.159696 Batch F1: 0.8148148148148148
Epoch:  725        9 Batch loss: 0.157390 Batch F1: 0.7727272727272727
Epoch:  725       10 Batch loss: 0.183509 Batch F1: 0.7307692307692307
Epoch:  725       11 Batch loss: 0.169488 Batch F1: 0.7142857142857143
Epoch:  725       12 Batch loss: 0.149000 Batch F1: 0.6666666666666667
Train Avg Loss  725: 0.167723

Train Avg F1  725: 0.7076723052109847

Val Avg Loss  725: 0.179895

Val Avg F1  725:  0.6712131943078236

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 726
--------------------------------------------------------------
Epoch:  726        1 Batch loss: 0.184403 Batch F1: 0.6341463414634146
Epoch:  726        2 Batch loss: 0.166447 Batch F1: 0.6829268292682926
Epoch:  726        3 Batch loss: 0.175350 Batch F1: 0.6153846153846154
Epoch:  726        4 Batch loss: 0.173774 Batch F1: 0.7142857142857143
Epoch:  726        5 Batch loss: 0.178763 Batch F1: 0.7368421052631579
Epoch:  726        6 Batch loss: 0.143986 Batch F1: 0.8292682926829269
Epoch:  726        7 Batch loss: 0.189360 Batch F1: 0.5
Epoch:  726        8 Batch loss: 0.185216 Batch F1: 0.7058823529411765
Epoch:  726        9 Batch loss: 0.139660 Batch F1: 0.8679245283018867
Epoch:  726       10 Batch loss: 0.142468 Batch F1: 0.8260869565217391
Epoch:  726       11 Batch loss: 0.172727 Batch F1: 0.7200000000000001
Epoch:  726       12 Batch loss: 0.183168 Batch F1: 0.5625
Train Avg Loss  726: 0.169610

Train Avg F1  726: 0.6996039780094104

Val Avg Loss  726: 0.183609

Val Avg F1  726:  0.6760895445134576

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 727
--------------------------------------------------------------
Epoch:  727        1 Batch loss: 0.188501 Batch F1: 0.6
Epoch:  727        2 Batch loss: 0.185276 Batch F1: 0.7083333333333334
Epoch:  727        3 Batch loss: 0.206975 Batch F1: 0.5714285714285713
Epoch:  727        4 Batch loss: 0.170031 Batch F1: 0.7843137254901961
Epoch:  727        5 Batch loss: 0.158930 Batch F1: 0.7999999999999999
Epoch:  727        6 Batch loss: 0.157731 Batch F1: 0.7058823529411765
Epoch:  727        7 Batch loss: 0.198904 Batch F1: 0.6666666666666666
Epoch:  727        8 Batch loss: 0.162024 Batch F1: 0.7499999999999999
Epoch:  727        9 Batch loss: 0.164450 Batch F1: 0.8571428571428571
Epoch:  727       10 Batch loss: 0.187834 Batch F1: 0.7450980392156863
Epoch:  727       11 Batch loss: 0.128487 Batch F1: 0.9090909090909091
Epoch:  727       12 Batch loss: 0.155418 Batch F1: 0.8095238095238095
Train Avg Loss  727: 0.172047

Train Avg F1  727: 0.7422900220694338

Val Avg Loss  727: 0.183576

Val Avg F1  727:  0.6777006886627608

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 728
--------------------------------------------------------------
Epoch:  728        1 Batch loss: 0.198260 Batch F1: 0.48484848484848486
Epoch:  728        2 Batch loss: 0.177417 Batch F1: 0.7083333333333333
Epoch:  728        3 Batch loss: 0.169194 Batch F1: 0.7
Epoch:  728        4 Batch loss: 0.151141 Batch F1: 0.7441860465116279
Epoch:  728        5 Batch loss: 0.173530 Batch F1: 0.6842105263157895
Epoch:  728        6 Batch loss: 0.184973 Batch F1: 0.6153846153846153
Epoch:  728        7 Batch loss: 0.164209 Batch F1: 0.7027027027027029
Epoch:  728        8 Batch loss: 0.173438 Batch F1: 0.7391304347826088
Epoch:  728        9 Batch loss: 0.153878 Batch F1: 0.8333333333333334
Epoch:  728       10 Batch loss: 0.192966 Batch F1: 0.7450980392156863
Epoch:  728       11 Batch loss: 0.167860 Batch F1: 0.7111111111111111
Epoch:  728       12 Batch loss: 0.190471 Batch F1: 0.7500000000000001
Train Avg Loss  728: 0.174778

Train Avg F1  728: 0.7015282189616078

Val Avg Loss  728: 0.185025

Val Avg F1  728:  0.6770309477756286

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 729
--------------------------------------------------------------
Epoch:  729        1 Batch loss: 0.175483 Batch F1: 0.631578947368421
Epoch:  729        2 Batch loss: 0.186392 Batch F1: 0.6956521739130435
Epoch:  729        3 Batch loss: 0.179030 Batch F1: 0.6666666666666667
Epoch:  729        4 Batch loss: 0.170442 Batch F1: 0.7719298245614034
Epoch:  729        5 Batch loss: 0.171627 Batch F1: 0.6829268292682926
Epoch:  729        6 Batch loss: 0.161391 Batch F1: 0.7142857142857143
Epoch:  729        7 Batch loss: 0.173510 Batch F1: 0.7499999999999999
Epoch:  729        8 Batch loss: 0.188277 Batch F1: 0.6808510638297872
Epoch:  729        9 Batch loss: 0.160730 Batch F1: 0.7500000000000001
Epoch:  729       10 Batch loss: 0.180958 Batch F1: 0.65
Epoch:  729       11 Batch loss: 0.128775 Batch F1: 0.8108108108108109
Epoch:  729       12 Batch loss: 0.182039 Batch F1: 0.7317073170731706
Train Avg Loss  729: 0.171555

Train Avg F1  729: 0.7113674456481092

Val Avg Loss  729: 0.182740

Val Avg F1  729:  0.6742481203007519

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 730
--------------------------------------------------------------
Epoch:  730        1 Batch loss: 0.177103 Batch F1: 0.6818181818181818
Epoch:  730        2 Batch loss: 0.190646 Batch F1: 0.5789473684210527
Epoch:  730        3 Batch loss: 0.188281 Batch F1: 0.5641025641025642
Epoch:  730        4 Batch loss: 0.169958 Batch F1: 0.7111111111111111
Epoch:  730        5 Batch loss: 0.131239 Batch F1: 0.9130434782608695
Epoch:  730        6 Batch loss: 0.156490 Batch F1: 0.7142857142857143
Epoch:  730        7 Batch loss: 0.204060 Batch F1: 0.5957446808510638
Epoch:  730        8 Batch loss: 0.183089 Batch F1: 0.6511627906976744
Epoch:  730        9 Batch loss: 0.154931 Batch F1: 0.782608695652174
Epoch:  730       10 Batch loss: 0.167421 Batch F1: 0.8085106382978724
Epoch:  730       11 Batch loss: 0.160837 Batch F1: 0.7826086956521738
Epoch:  730       12 Batch loss: 0.152871 Batch F1: 0.7317073170731708
Train Avg Loss  730: 0.169744

Train Avg F1  730: 0.7096376030186353

Val Avg Loss  730: 0.210272

Val Avg F1  730:  0.7650979844528232

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 731
--------------------------------------------------------------
Epoch:  731        1 Batch loss: 0.205891 Batch F1: 0.761904761904762
Epoch:  731        2 Batch loss: 0.161440 Batch F1: 0.6938775510204083
Epoch:  731        3 Batch loss: 0.179505 Batch F1: 0.7083333333333334
Epoch:  731        4 Batch loss: 0.192813 Batch F1: 0.68
Epoch:  731        5 Batch loss: 0.172589 Batch F1: 0.7692307692307693
Epoch:  731        6 Batch loss: 0.170271 Batch F1: 0.7317073170731706
Epoch:  731        7 Batch loss: 0.141589 Batch F1: 0.888888888888889
Epoch:  731        8 Batch loss: 0.179022 Batch F1: 0.7272727272727272
Epoch:  731        9 Batch loss: 0.176288 Batch F1: 0.5161290322580646
Epoch:  731       10 Batch loss: 0.153819 Batch F1: 0.7727272727272727
Epoch:  731       11 Batch loss: 0.206194 Batch F1: 0.6222222222222223
Epoch:  731       12 Batch loss: 0.220060 Batch F1: 0.2962962962962963
Train Avg Loss  731: 0.179957

Train Avg F1  731: 0.6807158476856597

Val Avg Loss  731: 0.187602

Val Avg F1  731:  0.6226484350707954

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 732
--------------------------------------------------------------
Epoch:  732        1 Batch loss: 0.196973 Batch F1: 0.6666666666666666
Epoch:  732        2 Batch loss: 0.183568 Batch F1: 0.6808510638297872
Epoch:  732        3 Batch loss: 0.158664 Batch F1: 0.816326530612245
Epoch:  732        4 Batch loss: 0.158870 Batch F1: 0.7555555555555555
Epoch:  732        5 Batch loss: 0.165527 Batch F1: 0.7111111111111111
Epoch:  732        6 Batch loss: 0.179966 Batch F1: 0.7111111111111111
Epoch:  732        7 Batch loss: 0.143746 Batch F1: 0.8095238095238095
Epoch:  732        8 Batch loss: 0.186591 Batch F1: 0.5789473684210527
Epoch:  732        9 Batch loss: 0.163317 Batch F1: 0.6976744186046512
Epoch:  732       10 Batch loss: 0.155147 Batch F1: 0.8085106382978724
Epoch:  732       11 Batch loss: 0.181578 Batch F1: 0.6153846153846153
Epoch:  732       12 Batch loss: 0.213140 Batch F1: 0.5641025641025642
Train Avg Loss  732: 0.173924

Train Avg F1  732: 0.7013137877684201

Val Avg Loss  732: 0.182006

Val Avg F1  732:  0.6757523522229405

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 733
--------------------------------------------------------------
Epoch:  733        1 Batch loss: 0.160690 Batch F1: 0.6842105263157895
Epoch:  733        2 Batch loss: 0.178112 Batch F1: 0.6818181818181819
Epoch:  733        3 Batch loss: 0.185018 Batch F1: 0.6341463414634146
Epoch:  733        4 Batch loss: 0.195449 Batch F1: 0.6808510638297872
Epoch:  733        5 Batch loss: 0.148027 Batch F1: 0.7692307692307692
Epoch:  733        6 Batch loss: 0.144691 Batch F1: 0.7906976744186046
Epoch:  733        7 Batch loss: 0.173113 Batch F1: 0.7346938775510204
Epoch:  733        8 Batch loss: 0.184189 Batch F1: 0.75
Epoch:  733        9 Batch loss: 0.211094 Batch F1: 0.6666666666666667
Epoch:  733       10 Batch loss: 0.186193 Batch F1: 0.6153846153846153
Epoch:  733       11 Batch loss: 0.178871 Batch F1: 0.7346938775510204
Epoch:  733       12 Batch loss: 0.155390 Batch F1: 0.7500000000000001
Train Avg Loss  733: 0.175070

Train Avg F1  733: 0.7076994661858226

Val Avg Loss  733: 0.185183

Val Avg F1  733:  0.6723310023310023

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 734
--------------------------------------------------------------
Epoch:  734        1 Batch loss: 0.185793 Batch F1: 0.6956521739130435
Epoch:  734        2 Batch loss: 0.187923 Batch F1: 0.6222222222222222
Epoch:  734        3 Batch loss: 0.159726 Batch F1: 0.7659574468085107
Epoch:  734        4 Batch loss: 0.157677 Batch F1: 0.8163265306122449
Epoch:  734        5 Batch loss: 0.170761 Batch F1: 0.7441860465116279
Epoch:  734        6 Batch loss: 0.173364 Batch F1: 0.75
Epoch:  734        7 Batch loss: 0.138574 Batch F1: 0.7804878048780488
Epoch:  734        8 Batch loss: 0.202774 Batch F1: 0.5909090909090909
Epoch:  734        9 Batch loss: 0.157999 Batch F1: 0.7500000000000001
Epoch:  734       10 Batch loss: 0.204465 Batch F1: 0.5957446808510639
Epoch:  734       11 Batch loss: 0.198016 Batch F1: 0.6792452830188679
Epoch:  734       12 Batch loss: 0.167840 Batch F1: 0.6666666666666666
Train Avg Loss  734: 0.175409

Train Avg F1  734: 0.7047831621992823

Val Avg Loss  734: 0.188315

Val Avg F1  734:  0.6383335986131632

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 735
--------------------------------------------------------------
Epoch:  735        1 Batch loss: 0.196501 Batch F1: 0.608695652173913
Epoch:  735        2 Batch loss: 0.181224 Batch F1: 0.6521739130434783
Epoch:  735        3 Batch loss: 0.178970 Batch F1: 0.6842105263157895
Epoch:  735        4 Batch loss: 0.200281 Batch F1: 0.7169811320754716
Epoch:  735        5 Batch loss: 0.149445 Batch F1: 0.830188679245283
Epoch:  735        6 Batch loss: 0.212376 Batch F1: 0.7096774193548387
Epoch:  735        7 Batch loss: 0.208260 Batch F1: 0.7599999999999999
Epoch:  735        8 Batch loss: 0.144415 Batch F1: 0.7692307692307692
Epoch:  735        9 Batch loss: 0.188440 Batch F1: 0.6666666666666666
Epoch:  735       10 Batch loss: 0.168665 Batch F1: 0.6976744186046512
Epoch:  735       11 Batch loss: 0.165073 Batch F1: 0.7391304347826088
Epoch:  735       12 Batch loss: 0.180019 Batch F1: 0.6666666666666666
Train Avg Loss  735: 0.181139

Train Avg F1  735: 0.7084413565133447

Val Avg Loss  735: 0.181738

Val Avg F1  735:  0.6736427626973633

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 736
--------------------------------------------------------------
Epoch:  736        1 Batch loss: 0.157225 Batch F1: 0.8
Epoch:  736        2 Batch loss: 0.202750 Batch F1: 0.5333333333333333
Epoch:  736        3 Batch loss: 0.188149 Batch F1: 0.6341463414634146
Epoch:  736        4 Batch loss: 0.169252 Batch F1: 0.7500000000000001
Epoch:  736        5 Batch loss: 0.161798 Batch F1: 0.761904761904762
Epoch:  736        6 Batch loss: 0.154409 Batch F1: 0.8000000000000002
Epoch:  736        7 Batch loss: 0.185404 Batch F1: 0.6190476190476191
Epoch:  736        8 Batch loss: 0.169890 Batch F1: 0.7317073170731706
Epoch:  736        9 Batch loss: 0.165290 Batch F1: 0.7804878048780488
Epoch:  736       10 Batch loss: 0.211136 Batch F1: 0.6
Epoch:  736       11 Batch loss: 0.199899 Batch F1: 0.7037037037037037
Epoch:  736       12 Batch loss: 0.175785 Batch F1: 0.7804878048780488
Train Avg Loss  736: 0.178416

Train Avg F1  736: 0.7079015571901751

Val Avg Loss  736: 0.200415

Val Avg F1  736:  0.81417004048583

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 737
--------------------------------------------------------------
Epoch:  737        1 Batch loss: 0.155043 Batch F1: 0.9056603773584906
Epoch:  737        2 Batch loss: 0.170471 Batch F1: 0.65
Epoch:  737        3 Batch loss: 0.177066 Batch F1: 0.6666666666666666
Epoch:  737        4 Batch loss: 0.223109 Batch F1: 0.5599999999999999
Epoch:  737        5 Batch loss: 0.137799 Batch F1: 0.8666666666666666
Epoch:  737        6 Batch loss: 0.222124 Batch F1: 0.5777777777777777
Epoch:  737        7 Batch loss: 0.169069 Batch F1: 0.7142857142857143
Epoch:  737        8 Batch loss: 0.205643 Batch F1: 0.6
Epoch:  737        9 Batch loss: 0.152629 Batch F1: 0.8205128205128205
Epoch:  737       10 Batch loss: 0.177288 Batch F1: 0.7142857142857143
Epoch:  737       11 Batch loss: 0.186245 Batch F1: 0.6341463414634146
Epoch:  737       12 Batch loss: 0.188582 Batch F1: 0.7317073170731706
Train Avg Loss  737: 0.180422

Train Avg F1  737: 0.7034757830075363

Val Avg Loss  737: 0.188834

Val Avg F1  737:  0.6706996434937611

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 738
--------------------------------------------------------------
Epoch:  738        1 Batch loss: 0.198033 Batch F1: 0.7457627118644068
Epoch:  738        2 Batch loss: 0.223697 Batch F1: 0.5531914893617021
Epoch:  738        3 Batch loss: 0.172380 Batch F1: 0.8363636363636364
Epoch:  738        4 Batch loss: 0.169216 Batch F1: 0.7450980392156863
Epoch:  738        5 Batch loss: 0.191884 Batch F1: 0.6382978723404256
Epoch:  738        6 Batch loss: 0.169292 Batch F1: 0.5925925925925927
Epoch:  738        7 Batch loss: 0.222889 Batch F1: 0.6530612244897959
Epoch:  738        8 Batch loss: 0.170570 Batch F1: 0.7142857142857143
Epoch:  738        9 Batch loss: 0.156550 Batch F1: 0.7727272727272727
Epoch:  738       10 Batch loss: 0.141592 Batch F1: 0.8095238095238095
Epoch:  738       11 Batch loss: 0.187907 Batch F1: 0.5405405405405405
Epoch:  738       12 Batch loss: 0.184675 Batch F1: 0.6153846153846153
Train Avg Loss  738: 0.182390

Train Avg F1  738: 0.6847357932241831

Val Avg Loss  738: 0.187024

Val Avg F1  738:  0.6691053511705686

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 739
--------------------------------------------------------------
Epoch:  739        1 Batch loss: 0.180561 Batch F1: 0.7
Epoch:  739        2 Batch loss: 0.163961 Batch F1: 0.8076923076923077
Epoch:  739        3 Batch loss: 0.163849 Batch F1: 0.7826086956521738
Epoch:  739        4 Batch loss: 0.168833 Batch F1: 0.7826086956521738
Epoch:  739        5 Batch loss: 0.161834 Batch F1: 0.6666666666666667
Epoch:  739        6 Batch loss: 0.212632 Batch F1: 0.5714285714285715
Epoch:  739        7 Batch loss: 0.170000 Batch F1: 0.6976744186046512
Epoch:  739        8 Batch loss: 0.197319 Batch F1: 0.5853658536585366
Epoch:  739        9 Batch loss: 0.157686 Batch F1: 0.7727272727272727
Epoch:  739       10 Batch loss: 0.165011 Batch F1: 0.7368421052631577
Epoch:  739       11 Batch loss: 0.183381 Batch F1: 0.7200000000000001
Epoch:  739       12 Batch loss: 0.173058 Batch F1: 0.7000000000000001
Train Avg Loss  739: 0.174844

Train Avg F1  739: 0.7103012156121259

Val Avg Loss  739: 0.185340

Val Avg F1  739:  0.666284424795063

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 740
--------------------------------------------------------------
Epoch:  740        1 Batch loss: 0.140869 Batch F1: 0.7692307692307692
Epoch:  740        2 Batch loss: 0.169307 Batch F1: 0.7924528301886793
Epoch:  740        3 Batch loss: 0.171640 Batch F1: 0.6956521739130435
Epoch:  740        4 Batch loss: 0.201587 Batch F1: 0.6530612244897959
Epoch:  740        5 Batch loss: 0.155571 Batch F1: 0.7692307692307692
Epoch:  740        6 Batch loss: 0.177872 Batch F1: 0.6666666666666666
Epoch:  740        7 Batch loss: 0.162719 Batch F1: 0.7441860465116279
Epoch:  740        8 Batch loss: 0.158867 Batch F1: 0.7555555555555555
Epoch:  740        9 Batch loss: 0.203717 Batch F1: 0.6530612244897959
Epoch:  740       10 Batch loss: 0.165853 Batch F1: 0.7441860465116279
Epoch:  740       11 Batch loss: 0.169815 Batch F1: 0.6829268292682927
Epoch:  740       12 Batch loss: 0.193720 Batch F1: 0.6111111111111112
Train Avg Loss  740: 0.172628

Train Avg F1  740: 0.7114434372639779

Val Avg Loss  740: 0.183013

Val Avg F1  740:  0.6699372056514914

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 741
--------------------------------------------------------------
Epoch:  741        1 Batch loss: 0.140783 Batch F1: 0.8095238095238095
Epoch:  741        2 Batch loss: 0.179042 Batch F1: 0.6956521739130435
Epoch:  741        3 Batch loss: 0.178961 Batch F1: 0.711111111111111
Epoch:  741        4 Batch loss: 0.194354 Batch F1: 0.5263157894736842
Epoch:  741        5 Batch loss: 0.212039 Batch F1: 0.6249999999999999
Epoch:  741        6 Batch loss: 0.168743 Batch F1: 0.7272727272727272
Epoch:  741        7 Batch loss: 0.183992 Batch F1: 0.72
Epoch:  741        8 Batch loss: 0.174123 Batch F1: 0.7083333333333334
Epoch:  741        9 Batch loss: 0.168589 Batch F1: 0.7441860465116279
Epoch:  741       10 Batch loss: 0.162545 Batch F1: 0.816326530612245
Epoch:  741       11 Batch loss: 0.149819 Batch F1: 0.6666666666666667
Epoch:  741       12 Batch loss: 0.167513 Batch F1: 0.7692307692307692
Train Avg Loss  741: 0.173375

Train Avg F1  741: 0.7099682464707513

Val Avg Loss  741: 0.184690

Val Avg F1  741:  0.6706487917907977

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 742
--------------------------------------------------------------
Epoch:  742        1 Batch loss: 0.172283 Batch F1: 0.7999999999999999
Epoch:  742        2 Batch loss: 0.125018 Batch F1: 0.8421052631578947
Epoch:  742        3 Batch loss: 0.206348 Batch F1: 0.5957446808510638
Epoch:  742        4 Batch loss: 0.185617 Batch F1: 0.5625000000000001
Epoch:  742        5 Batch loss: 0.176020 Batch F1: 0.7500000000000001
Epoch:  742        6 Batch loss: 0.174244 Batch F1: 0.6341463414634148
Epoch:  742        7 Batch loss: 0.153611 Batch F1: 0.8085106382978724
Epoch:  742        8 Batch loss: 0.171212 Batch F1: 0.7500000000000001
Epoch:  742        9 Batch loss: 0.173632 Batch F1: 0.717948717948718
Epoch:  742       10 Batch loss: 0.174511 Batch F1: 0.6818181818181818
Epoch:  742       11 Batch loss: 0.164489 Batch F1: 0.6829268292682927
Epoch:  742       12 Batch loss: 0.209643 Batch F1: 0.65
Train Avg Loss  742: 0.173886

Train Avg F1  742: 0.7063083877337865

Val Avg Loss  742: 0.183213

Val Avg F1  742:  0.6809079531232222

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 743
--------------------------------------------------------------
Epoch:  743        1 Batch loss: 0.177500 Batch F1: 0.6666666666666667
Epoch:  743        2 Batch loss: 0.156678 Batch F1: 0.744186046511628
Epoch:  743        3 Batch loss: 0.159998 Batch F1: 0.7441860465116279
Epoch:  743        4 Batch loss: 0.179296 Batch F1: 0.72
Epoch:  743        5 Batch loss: 0.179965 Batch F1: 0.6341463414634146
Epoch:  743        6 Batch loss: 0.165724 Batch F1: 0.7441860465116279
Epoch:  743        7 Batch loss: 0.199318 Batch F1: 0.5714285714285715
Epoch:  743        8 Batch loss: 0.178483 Batch F1: 0.7450980392156864
Epoch:  743        9 Batch loss: 0.186505 Batch F1: 0.6666666666666667
Epoch:  743       10 Batch loss: 0.139776 Batch F1: 0.8260869565217391
Epoch:  743       11 Batch loss: 0.164235 Batch F1: 0.7027027027027027
Epoch:  743       12 Batch loss: 0.176813 Batch F1: 0.7555555555555556
Train Avg Loss  743: 0.172024

Train Avg F1  743: 0.7100758033129906

Val Avg Loss  743: 0.182689

Val Avg F1  743:  0.6752906976744185

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 744
--------------------------------------------------------------
Epoch:  744        1 Batch loss: 0.191117 Batch F1: 0.5555555555555555
Epoch:  744        2 Batch loss: 0.213661 Batch F1: 0.64
Epoch:  744        3 Batch loss: 0.174885 Batch F1: 0.6956521739130435
Epoch:  744        4 Batch loss: 0.205071 Batch F1: 0.6538461538461539
Epoch:  744        5 Batch loss: 0.151254 Batch F1: 0.7567567567567567
Epoch:  744        6 Batch loss: 0.158783 Batch F1: 0.6857142857142857
Epoch:  744        7 Batch loss: 0.171653 Batch F1: 0.6285714285714287
Epoch:  744        8 Batch loss: 0.149653 Batch F1: 0.8085106382978724
Epoch:  744        9 Batch loss: 0.150878 Batch F1: 0.8518518518518519
Epoch:  744       10 Batch loss: 0.154025 Batch F1: 0.7727272727272727
Epoch:  744       11 Batch loss: 0.155217 Batch F1: 0.7659574468085107
Epoch:  744       12 Batch loss: 0.183429 Batch F1: 0.6666666666666666
Train Avg Loss  744: 0.171635

Train Avg F1  744: 0.7068175192257832

Val Avg Loss  744: 0.185987

Val Avg F1  744:  0.6399319727891156

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 745
--------------------------------------------------------------
Epoch:  745        1 Batch loss: 0.167104 Batch F1: 0.6666666666666667
Epoch:  745        2 Batch loss: 0.202464 Batch F1: 0.6296296296296297
Epoch:  745        3 Batch loss: 0.216606 Batch F1: 0.6222222222222222
Epoch:  745        4 Batch loss: 0.177593 Batch F1: 0.6285714285714287
Epoch:  745        5 Batch loss: 0.199922 Batch F1: 0.6046511627906977
Epoch:  745        6 Batch loss: 0.163789 Batch F1: 0.7272727272727272
Epoch:  745        7 Batch loss: 0.129279 Batch F1: 0.8695652173913043
Epoch:  745        8 Batch loss: 0.176513 Batch F1: 0.76
Epoch:  745        9 Batch loss: 0.177149 Batch F1: 0.65
Epoch:  745       10 Batch loss: 0.196305 Batch F1: 0.6808510638297872
Epoch:  745       11 Batch loss: 0.174640 Batch F1: 0.7391304347826088
Epoch:  745       12 Batch loss: 0.148717 Batch F1: 0.7777777777777777
Train Avg Loss  745: 0.177507

Train Avg F1  745: 0.6963615275779041

Val Avg Loss  745: 0.183106

Val Avg F1  745:  0.6769895295949205

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 746
--------------------------------------------------------------
Epoch:  746        1 Batch loss: 0.162358 Batch F1: 0.7843137254901961
Epoch:  746        2 Batch loss: 0.154134 Batch F1: 0.75
Epoch:  746        3 Batch loss: 0.158514 Batch F1: 0.6470588235294118
Epoch:  746        4 Batch loss: 0.185999 Batch F1: 0.6666666666666666
Epoch:  746        5 Batch loss: 0.159246 Batch F1: 0.717948717948718
Epoch:  746        6 Batch loss: 0.152702 Batch F1: 0.7500000000000001
Epoch:  746        7 Batch loss: 0.193325 Batch F1: 0.7307692307692308
Epoch:  746        8 Batch loss: 0.175091 Batch F1: 0.7234042553191491
Epoch:  746        9 Batch loss: 0.214377 Batch F1: 0.6122448979591836
Epoch:  746       10 Batch loss: 0.166395 Batch F1: 0.7755102040816326
Epoch:  746       11 Batch loss: 0.157722 Batch F1: 0.717948717948718
Epoch:  746       12 Batch loss: 0.177070 Batch F1: 0.6486486486486486
Train Avg Loss  746: 0.171411

Train Avg F1  746: 0.7103761573634629

Val Avg Loss  746: 0.182653

Val Avg F1  746:  0.6809464193046186

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 747
--------------------------------------------------------------
Epoch:  747        1 Batch loss: 0.172356 Batch F1: 0.723404255319149
Epoch:  747        2 Batch loss: 0.174336 Batch F1: 0.5625
Epoch:  747        3 Batch loss: 0.166796 Batch F1: 0.744186046511628
Epoch:  747        4 Batch loss: 0.155656 Batch F1: 0.761904761904762
Epoch:  747        5 Batch loss: 0.161312 Batch F1: 0.7027027027027027
Epoch:  747        6 Batch loss: 0.189742 Batch F1: 0.5853658536585366
Epoch:  747        7 Batch loss: 0.163145 Batch F1: 0.7692307692307692
Epoch:  747        8 Batch loss: 0.159195 Batch F1: 0.8070175438596492
Epoch:  747        9 Batch loss: 0.189307 Batch F1: 0.6521739130434783
Epoch:  747       10 Batch loss: 0.191599 Batch F1: 0.68
Epoch:  747       11 Batch loss: 0.161498 Batch F1: 0.7906976744186047
Epoch:  747       12 Batch loss: 0.171812 Batch F1: 0.6857142857142857
Train Avg Loss  747: 0.171396

Train Avg F1  747: 0.7054081505302969

Val Avg Loss  747: 0.182257

Val Avg F1  747:  0.6791588443888192

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 748
--------------------------------------------------------------
Epoch:  748        1 Batch loss: 0.197072 Batch F1: 0.48648648648648646
Epoch:  748        2 Batch loss: 0.142070 Batch F1: 0.9032258064516129
Epoch:  748        3 Batch loss: 0.163936 Batch F1: 0.6829268292682926
Epoch:  748        4 Batch loss: 0.137502 Batch F1: 0.851063829787234
Epoch:  748        5 Batch loss: 0.171390 Batch F1: 0.7450980392156864
Epoch:  748        6 Batch loss: 0.186036 Batch F1: 0.6341463414634146
Epoch:  748        7 Batch loss: 0.197543 Batch F1: 0.6511627906976745
Epoch:  748        8 Batch loss: 0.188499 Batch F1: 0.5789473684210527
Epoch:  748        9 Batch loss: 0.168990 Batch F1: 0.6111111111111112
Epoch:  748       10 Batch loss: 0.170275 Batch F1: 0.6956521739130435
Epoch:  748       11 Batch loss: 0.173985 Batch F1: 0.7272727272727273
Epoch:  748       12 Batch loss: 0.150358 Batch F1: 0.8205128205128205
Train Avg Loss  748: 0.170638

Train Avg F1  748: 0.6989671937167631

Val Avg Loss  748: 0.181845

Val Avg F1  748:  0.676485260770975

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 749
--------------------------------------------------------------
Epoch:  749        1 Batch loss: 0.157654 Batch F1: 0.7755102040816326
Epoch:  749        2 Batch loss: 0.168786 Batch F1: 0.5806451612903225
Epoch:  749        3 Batch loss: 0.178842 Batch F1: 0.6938775510204083
Epoch:  749        4 Batch loss: 0.159253 Batch F1: 0.75
Epoch:  749        5 Batch loss: 0.164111 Batch F1: 0.7843137254901961
Epoch:  749        6 Batch loss: 0.153005 Batch F1: 0.761904761904762
Epoch:  749        7 Batch loss: 0.189391 Batch F1: 0.6511627906976745
Epoch:  749        8 Batch loss: 0.171256 Batch F1: 0.6511627906976744
Epoch:  749        9 Batch loss: 0.163166 Batch F1: 0.7441860465116279
Epoch:  749       10 Batch loss: 0.185094 Batch F1: 0.6
Epoch:  749       11 Batch loss: 0.147081 Batch F1: 0.8363636363636364
Epoch:  749       12 Batch loss: 0.185244 Batch F1: 0.6153846153846153
Train Avg Loss  749: 0.168574

Train Avg F1  749: 0.7037092736202125

Val Avg Loss  749: 0.180855

Val Avg F1  749:  0.675420364753024

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 750
--------------------------------------------------------------
Epoch:  750        1 Batch loss: 0.167745 Batch F1: 0.7391304347826085
Epoch:  750        2 Batch loss: 0.205673 Batch F1: 0.6382978723404256
Epoch:  750        3 Batch loss: 0.142187 Batch F1: 0.8
Epoch:  750        4 Batch loss: 0.169181 Batch F1: 0.7027027027027026
Epoch:  750        5 Batch loss: 0.184266 Batch F1: 0.6666666666666666
Epoch:  750        6 Batch loss: 0.174987 Batch F1: 0.7692307692307692
Epoch:  750        7 Batch loss: 0.182683 Batch F1: 0.5714285714285714
Epoch:  750        8 Batch loss: 0.162305 Batch F1: 0.6842105263157895
Epoch:  750        9 Batch loss: 0.170681 Batch F1: 0.7755102040816326
Epoch:  750       10 Batch loss: 0.183516 Batch F1: 0.68
Epoch:  750       11 Batch loss: 0.185624 Batch F1: 0.6190476190476191
Epoch:  750       12 Batch loss: 0.137871 Batch F1: 0.8636363636363636
Train Avg Loss  750: 0.172227

Train Avg F1  750: 0.7091551441860956

Val Avg Loss  750: 0.181418

Val Avg F1  750:  0.6764018087855297

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 751
--------------------------------------------------------------
Epoch:  751        1 Batch loss: 0.169456 Batch F1: 0.75
Epoch:  751        2 Batch loss: 0.156557 Batch F1: 0.7
Epoch:  751        3 Batch loss: 0.160998 Batch F1: 0.7924528301886793
Epoch:  751        4 Batch loss: 0.216273 Batch F1: 0.5599999999999999
Epoch:  751        5 Batch loss: 0.143056 Batch F1: 0.7804878048780488
Epoch:  751        6 Batch loss: 0.181983 Batch F1: 0.7317073170731707
Epoch:  751        7 Batch loss: 0.195648 Batch F1: 0.6530612244897959
Epoch:  751        8 Batch loss: 0.170214 Batch F1: 0.7755102040816326
Epoch:  751        9 Batch loss: 0.188025 Batch F1: 0.6046511627906977
Epoch:  751       10 Batch loss: 0.148976 Batch F1: 0.742857142857143
Epoch:  751       11 Batch loss: 0.153313 Batch F1: 0.8085106382978723
Epoch:  751       12 Batch loss: 0.175187 Batch F1: 0.6206896551724138
Train Avg Loss  751: 0.171640

Train Avg F1  751: 0.7099939983191211

Val Avg Loss  751: 0.181848

Val Avg F1  751:  0.6746718104362452

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 752
--------------------------------------------------------------
Epoch:  752        1 Batch loss: 0.156083 Batch F1: 0.7000000000000001
Epoch:  752        2 Batch loss: 0.191265 Batch F1: 0.6521739130434783
Epoch:  752        3 Batch loss: 0.189179 Batch F1: 0.6521739130434783
Epoch:  752        4 Batch loss: 0.159655 Batch F1: 0.8363636363636363
Epoch:  752        5 Batch loss: 0.173320 Batch F1: 0.631578947368421
Epoch:  752        6 Batch loss: 0.148697 Batch F1: 0.7755102040816326
Epoch:  752        7 Batch loss: 0.170559 Batch F1: 0.7441860465116279
Epoch:  752        8 Batch loss: 0.164894 Batch F1: 0.7142857142857143
Epoch:  752        9 Batch loss: 0.149671 Batch F1: 0.7441860465116279
Epoch:  752       10 Batch loss: 0.181381 Batch F1: 0.6153846153846153
Epoch:  752       11 Batch loss: 0.188884 Batch F1: 0.6363636363636364
Epoch:  752       12 Batch loss: 0.160774 Batch F1: 0.7999999999999999
Train Avg Loss  752: 0.169530

Train Avg F1  752: 0.708517222746489

Val Avg Loss  752: 0.181717

Val Avg F1  752:  0.6763422266139657

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 753
--------------------------------------------------------------
Epoch:  753        1 Batch loss: 0.161471 Batch F1: 0.7916666666666667
Epoch:  753        2 Batch loss: 0.180629 Batch F1: 0.72
Epoch:  753        3 Batch loss: 0.168950 Batch F1: 0.7924528301886793
Epoch:  753        4 Batch loss: 0.163762 Batch F1: 0.744186046511628
Epoch:  753        5 Batch loss: 0.193366 Batch F1: 0.55
Epoch:  753        6 Batch loss: 0.180821 Batch F1: 0.6153846153846154
Epoch:  753        7 Batch loss: 0.171102 Batch F1: 0.6153846153846154
Epoch:  753        8 Batch loss: 0.154925 Batch F1: 0.8399999999999999
Epoch:  753        9 Batch loss: 0.139030 Batch F1: 0.8571428571428572
Epoch:  753       10 Batch loss: 0.185485 Batch F1: 0.6382978723404256
Epoch:  753       11 Batch loss: 0.156877 Batch F1: 0.606060606060606
Epoch:  753       12 Batch loss: 0.168021 Batch F1: 0.6666666666666667
Train Avg Loss  753: 0.168703

Train Avg F1  753: 0.7031035646955632

Val Avg Loss  753: 0.180417

Val Avg F1  753:  0.6749702478975914

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 754
--------------------------------------------------------------
Epoch:  754        1 Batch loss: 0.168771 Batch F1: 0.7636363636363638
Epoch:  754        2 Batch loss: 0.182322 Batch F1: 0.5454545454545454
Epoch:  754        3 Batch loss: 0.198249 Batch F1: 0.5957446808510639
Epoch:  754        4 Batch loss: 0.155968 Batch F1: 0.7555555555555556
Epoch:  754        5 Batch loss: 0.145356 Batch F1: 0.8444444444444444
Epoch:  754        6 Batch loss: 0.186964 Batch F1: 0.6666666666666665
Epoch:  754        7 Batch loss: 0.169531 Batch F1: 0.7272727272727273
Epoch:  754        8 Batch loss: 0.136433 Batch F1: 0.8108108108108109
Epoch:  754        9 Batch loss: 0.194980 Batch F1: 0.5581395348837208
Epoch:  754       10 Batch loss: 0.171970 Batch F1: 0.6818181818181818
Epoch:  754       11 Batch loss: 0.170146 Batch F1: 0.7234042553191489
Epoch:  754       12 Batch loss: 0.148378 Batch F1: 0.8500000000000001
Train Avg Loss  754: 0.169089

Train Avg F1  754: 0.7102456472261024

Val Avg Loss  754: 0.180868

Val Avg F1  754:  0.6673113689920412

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 755
--------------------------------------------------------------
Epoch:  755        1 Batch loss: 0.178186 Batch F1: 0.7000000000000001
Epoch:  755        2 Batch loss: 0.180545 Batch F1: 0.7936507936507936
Epoch:  755        3 Batch loss: 0.171365 Batch F1: 0.6341463414634148
Epoch:  755        4 Batch loss: 0.181613 Batch F1: 0.5945945945945946
Epoch:  755        5 Batch loss: 0.179208 Batch F1: 0.7307692307692306
Epoch:  755        6 Batch loss: 0.142382 Batch F1: 0.8260869565217391
Epoch:  755        7 Batch loss: 0.192345 Batch F1: 0.6363636363636365
Epoch:  755        8 Batch loss: 0.161963 Batch F1: 0.7441860465116279
Epoch:  755        9 Batch loss: 0.147241 Batch F1: 0.6451612903225806
Epoch:  755       10 Batch loss: 0.173449 Batch F1: 0.723404255319149
Epoch:  755       11 Batch loss: 0.158894 Batch F1: 0.7391304347826089
Epoch:  755       12 Batch loss: 0.154579 Batch F1: 0.6857142857142857
Train Avg Loss  755: 0.168481

Train Avg F1  755: 0.7044339888344718

Val Avg Loss  755: 0.180709

Val Avg F1  755:  0.6554904568784731

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 756
--------------------------------------------------------------
Epoch:  756        1 Batch loss: 0.164998 Batch F1: 0.7924528301886792
Epoch:  756        2 Batch loss: 0.182693 Batch F1: 0.6666666666666667
Epoch:  756        3 Batch loss: 0.185351 Batch F1: 0.5909090909090908
Epoch:  756        4 Batch loss: 0.132722 Batch F1: 0.8695652173913043
Epoch:  756        5 Batch loss: 0.173698 Batch F1: 0.6341463414634146
Epoch:  756        6 Batch loss: 0.146421 Batch F1: 0.7826086956521738
Epoch:  756        7 Batch loss: 0.164171 Batch F1: 0.7222222222222222
Epoch:  756        8 Batch loss: 0.167322 Batch F1: 0.7407407407407408
Epoch:  756        9 Batch loss: 0.155858 Batch F1: 0.7755102040816326
Epoch:  756       10 Batch loss: 0.160610 Batch F1: 0.5806451612903226
Epoch:  756       11 Batch loss: 0.182742 Batch F1: 0.7083333333333334
Epoch:  756       12 Batch loss: 0.203415 Batch F1: 0.5789473684210527
Train Avg Loss  756: 0.168334

Train Avg F1  756: 0.7035623226967195

Val Avg Loss  756: 0.180499

Val Avg F1  756:  0.6731965513478119

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 757
--------------------------------------------------------------
Epoch:  757        1 Batch loss: 0.186589 Batch F1: 0.5641025641025641
Epoch:  757        2 Batch loss: 0.148139 Batch F1: 0.8679245283018868
Epoch:  757        3 Batch loss: 0.180516 Batch F1: 0.6341463414634146
Epoch:  757        4 Batch loss: 0.173059 Batch F1: 0.7499999999999999
Epoch:  757        5 Batch loss: 0.144258 Batch F1: 0.8333333333333334
Epoch:  757        6 Batch loss: 0.158573 Batch F1: 0.6666666666666666
Epoch:  757        7 Batch loss: 0.171743 Batch F1: 0.6666666666666666
Epoch:  757        8 Batch loss: 0.181821 Batch F1: 0.7169811320754716
Epoch:  757        9 Batch loss: 0.173515 Batch F1: 0.5789473684210527
Epoch:  757       10 Batch loss: 0.156931 Batch F1: 0.717948717948718
Epoch:  757       11 Batch loss: 0.181062 Batch F1: 0.6511627906976744
Epoch:  757       12 Batch loss: 0.150206 Batch F1: 0.8205128205128205
Train Avg Loss  757: 0.167201

Train Avg F1  757: 0.7056994108491893

Val Avg Loss  757: 0.180670

Val Avg F1  757:  0.6604063878458596

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 758
--------------------------------------------------------------
Epoch:  758        1 Batch loss: 0.155613 Batch F1: 0.7659574468085107
Epoch:  758        2 Batch loss: 0.158995 Batch F1: 0.6857142857142857
Epoch:  758        3 Batch loss: 0.165704 Batch F1: 0.7272727272727272
Epoch:  758        4 Batch loss: 0.163350 Batch F1: 0.7692307692307693
Epoch:  758        5 Batch loss: 0.157215 Batch F1: 0.7
Epoch:  758        6 Batch loss: 0.193292 Batch F1: 0.6521739130434783
Epoch:  758        7 Batch loss: 0.204322 Batch F1: 0.5365853658536586
Epoch:  758        8 Batch loss: 0.183599 Batch F1: 0.6666666666666666
Epoch:  758        9 Batch loss: 0.158035 Batch F1: 0.7368421052631577
Epoch:  758       10 Batch loss: 0.148959 Batch F1: 0.8
Epoch:  758       11 Batch loss: 0.149165 Batch F1: 0.75
Epoch:  758       12 Batch loss: 0.172627 Batch F1: 0.7555555555555555
Train Avg Loss  758: 0.167573

Train Avg F1  758: 0.7121665696174008

Val Avg Loss  758: 0.180396

Val Avg F1  758:  0.6681750420122513

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 759
--------------------------------------------------------------
Epoch:  759        1 Batch loss: 0.185411 Batch F1: 0.6153846153846154
Epoch:  759        2 Batch loss: 0.166985 Batch F1: 0.723404255319149
Epoch:  759        3 Batch loss: 0.156505 Batch F1: 0.7843137254901961
Epoch:  759        4 Batch loss: 0.162919 Batch F1: 0.7500000000000001
Epoch:  759        5 Batch loss: 0.149037 Batch F1: 0.7317073170731708
Epoch:  759        6 Batch loss: 0.179330 Batch F1: 0.6341463414634146
Epoch:  759        7 Batch loss: 0.142716 Batch F1: 0.8181818181818182
Epoch:  759        8 Batch loss: 0.152776 Batch F1: 0.7499999999999999
Epoch:  759        9 Batch loss: 0.148154 Batch F1: 0.717948717948718
Epoch:  759       10 Batch loss: 0.212322 Batch F1: 0.5333333333333332
Epoch:  759       11 Batch loss: 0.202135 Batch F1: 0.6046511627906976
Epoch:  759       12 Batch loss: 0.145470 Batch F1: 0.8510638297872339
Train Avg Loss  759: 0.166980

Train Avg F1  759: 0.709511259731029

Val Avg Loss  759: 0.180910

Val Avg F1  759:  0.6763143631436315

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 760
--------------------------------------------------------------
Epoch:  760        1 Batch loss: 0.183535 Batch F1: 0.6938775510204083
Epoch:  760        2 Batch loss: 0.175164 Batch F1: 0.6818181818181818
Epoch:  760        3 Batch loss: 0.160766 Batch F1: 0.7692307692307692
Epoch:  760        4 Batch loss: 0.143294 Batch F1: 0.8333333333333333
Epoch:  760        5 Batch loss: 0.184409 Batch F1: 0.6938775510204083
Epoch:  760        6 Batch loss: 0.157880 Batch F1: 0.8421052631578947
Epoch:  760        7 Batch loss: 0.204866 Batch F1: 0.4324324324324324
Epoch:  760        8 Batch loss: 0.163780 Batch F1: 0.6285714285714287
Epoch:  760        9 Batch loss: 0.183394 Batch F1: 0.5789473684210527
Epoch:  760       10 Batch loss: 0.149107 Batch F1: 0.8571428571428572
Epoch:  760       11 Batch loss: 0.174339 Batch F1: 0.625
Epoch:  760       12 Batch loss: 0.152723 Batch F1: 0.7428571428571428
Train Avg Loss  760: 0.169438

Train Avg F1  760: 0.6982661565838257

Val Avg Loss  760: 0.180234

Val Avg F1  760:  0.6767046917692542

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 761
--------------------------------------------------------------
Epoch:  761        1 Batch loss: 0.184580 Batch F1: 0.6956521739130435
Epoch:  761        2 Batch loss: 0.177920 Batch F1: 0.7346938775510204
Epoch:  761        3 Batch loss: 0.149463 Batch F1: 0.8163265306122449
Epoch:  761        4 Batch loss: 0.169482 Batch F1: 0.7142857142857143
Epoch:  761        5 Batch loss: 0.146807 Batch F1: 0.7804878048780488
Epoch:  761        6 Batch loss: 0.167597 Batch F1: 0.6190476190476191
Epoch:  761        7 Batch loss: 0.174102 Batch F1: 0.7441860465116279
Epoch:  761        8 Batch loss: 0.164968 Batch F1: 0.7777777777777777
Epoch:  761        9 Batch loss: 0.183426 Batch F1: 0.5714285714285715
Epoch:  761       10 Batch loss: 0.184080 Batch F1: 0.5714285714285715
Epoch:  761       11 Batch loss: 0.167151 Batch F1: 0.711111111111111
Epoch:  761       12 Batch loss: 0.179173 Batch F1: 0.7272727272727272
Train Avg Loss  761: 0.170729

Train Avg F1  761: 0.7053082104848397

Val Avg Loss  761: 0.181001

Val Avg F1  761:  0.6767309725158562

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 762
--------------------------------------------------------------
Epoch:  762        1 Batch loss: 0.204232 Batch F1: 0.5555555555555555
Epoch:  762        2 Batch loss: 0.139724 Batch F1: 0.7222222222222222
Epoch:  762        3 Batch loss: 0.177306 Batch F1: 0.6818181818181818
Epoch:  762        4 Batch loss: 0.205420 Batch F1: 0.5777777777777778
Epoch:  762        5 Batch loss: 0.210594 Batch F1: 0.5238095238095238
Epoch:  762        6 Batch loss: 0.144023 Batch F1: 0.8518518518518519
Epoch:  762        7 Batch loss: 0.142720 Batch F1: 0.830188679245283
Epoch:  762        8 Batch loss: 0.201271 Batch F1: 0.5882352941176471
Epoch:  762        9 Batch loss: 0.164653 Batch F1: 0.8363636363636363
Epoch:  762       10 Batch loss: 0.162839 Batch F1: 0.6829268292682926
Epoch:  762       11 Batch loss: 0.170768 Batch F1: 0.7234042553191491
Epoch:  762       12 Batch loss: 0.131392 Batch F1: 0.8421052631578947
Train Avg Loss  762: 0.171245

Train Avg F1  762: 0.7013549225422512

Val Avg Loss  762: 0.181663

Val Avg F1  762:  0.6786688488816148

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 763
--------------------------------------------------------------
Epoch:  763        1 Batch loss: 0.174844 Batch F1: 0.6956521739130435
Epoch:  763        2 Batch loss: 0.194027 Batch F1: 0.7391304347826088
Epoch:  763        3 Batch loss: 0.169994 Batch F1: 0.6829268292682926
Epoch:  763        4 Batch loss: 0.185677 Batch F1: 0.6923076923076923
Epoch:  763        5 Batch loss: 0.186090 Batch F1: 0.5641025641025641
Epoch:  763        6 Batch loss: 0.133037 Batch F1: 0.8205128205128205
Epoch:  763        7 Batch loss: 0.193834 Batch F1: 0.7307692307692307
Epoch:  763        8 Batch loss: 0.170819 Batch F1: 0.7636363636363638
Epoch:  763        9 Batch loss: 0.175642 Batch F1: 0.5882352941176471
Epoch:  763       10 Batch loss: 0.149211 Batch F1: 0.7906976744186046
Epoch:  763       11 Batch loss: 0.162105 Batch F1: 0.75
Epoch:  763       12 Batch loss: 0.160439 Batch F1: 0.6666666666666666
Train Avg Loss  763: 0.171310

Train Avg F1  763: 0.7070531453746277

Val Avg Loss  763: 0.182946

Val Avg F1  763:  0.6766462579761813

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 764
--------------------------------------------------------------
Epoch:  764        1 Batch loss: 0.193609 Batch F1: 0.6666666666666666
Epoch:  764        2 Batch loss: 0.171274 Batch F1: 0.7924528301886792
Epoch:  764        3 Batch loss: 0.145911 Batch F1: 0.717948717948718
Epoch:  764        4 Batch loss: 0.181959 Batch F1: 0.6666666666666666
Epoch:  764        5 Batch loss: 0.186048 Batch F1: 0.6818181818181818
Epoch:  764        6 Batch loss: 0.173746 Batch F1: 0.6829268292682926
Epoch:  764        7 Batch loss: 0.156383 Batch F1: 0.7755102040816326
Epoch:  764        8 Batch loss: 0.176352 Batch F1: 0.7346938775510204
Epoch:  764        9 Batch loss: 0.166684 Batch F1: 0.6315789473684211
Epoch:  764       10 Batch loss: 0.174630 Batch F1: 0.7272727272727272
Epoch:  764       11 Batch loss: 0.157962 Batch F1: 0.7
Epoch:  764       12 Batch loss: 0.152007 Batch F1: 0.7647058823529412
Train Avg Loss  764: 0.169714

Train Avg F1  764: 0.7118534609319958

Val Avg Loss  764: 0.181449

Val Avg F1  764:  0.6729716960780084

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 765
--------------------------------------------------------------
Epoch:  765        1 Batch loss: 0.148267 Batch F1: 0.7317073170731706
Epoch:  765        2 Batch loss: 0.158707 Batch F1: 0.7843137254901961
Epoch:  765        3 Batch loss: 0.204821 Batch F1: 0.6086956521739131
Epoch:  765        4 Batch loss: 0.164858 Batch F1: 0.7000000000000001
Epoch:  765        5 Batch loss: 0.150225 Batch F1: 0.8085106382978724
Epoch:  765        6 Batch loss: 0.163976 Batch F1: 0.6511627906976744
Epoch:  765        7 Batch loss: 0.165397 Batch F1: 0.6857142857142857
Epoch:  765        8 Batch loss: 0.158755 Batch F1: 0.8076923076923077
Epoch:  765        9 Batch loss: 0.177444 Batch F1: 0.7083333333333334
Epoch:  765       10 Batch loss: 0.177848 Batch F1: 0.6818181818181818
Epoch:  765       11 Batch loss: 0.177847 Batch F1: 0.6938775510204083
Epoch:  765       12 Batch loss: 0.167550 Batch F1: 0.6206896551724138
Train Avg Loss  765: 0.167975

Train Avg F1  765: 0.7068762865403131

Val Avg Loss  765: 0.180026

Val Avg F1  765:  0.6751984126984126

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 766
--------------------------------------------------------------
Epoch:  766        1 Batch loss: 0.178740 Batch F1: 0.6341463414634146
Epoch:  766        2 Batch loss: 0.167672 Batch F1: 0.7755102040816326
Epoch:  766        3 Batch loss: 0.155144 Batch F1: 0.6842105263157896
Epoch:  766        4 Batch loss: 0.148498 Batch F1: 0.8085106382978724
Epoch:  766        5 Batch loss: 0.191938 Batch F1: 0.6521739130434783
Epoch:  766        6 Batch loss: 0.172846 Batch F1: 0.6808510638297872
Epoch:  766        7 Batch loss: 0.158467 Batch F1: 0.6842105263157896
Epoch:  766        8 Batch loss: 0.153897 Batch F1: 0.7843137254901961
Epoch:  766        9 Batch loss: 0.200629 Batch F1: 0.6382978723404256
Epoch:  766       10 Batch loss: 0.151379 Batch F1: 0.7727272727272727
Epoch:  766       11 Batch loss: 0.180949 Batch F1: 0.6341463414634148
Epoch:  766       12 Batch loss: 0.148059 Batch F1: 0.7777777777777778
Train Avg Loss  766: 0.167352

Train Avg F1  766: 0.7105730169289043

Val Avg Loss  766: 0.182605

Val Avg F1  766:  0.6756916099773242

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 767
--------------------------------------------------------------
Epoch:  767        1 Batch loss: 0.167454 Batch F1: 0.717948717948718
Epoch:  767        2 Batch loss: 0.174148 Batch F1: 0.723404255319149
Epoch:  767        3 Batch loss: 0.156211 Batch F1: 0.8
Epoch:  767        4 Batch loss: 0.161208 Batch F1: 0.7555555555555555
Epoch:  767        5 Batch loss: 0.152951 Batch F1: 0.7317073170731707
Epoch:  767        6 Batch loss: 0.146479 Batch F1: 0.7727272727272727
Epoch:  767        7 Batch loss: 0.183715 Batch F1: 0.6938775510204083
Epoch:  767        8 Batch loss: 0.178731 Batch F1: 0.7083333333333334
Epoch:  767        9 Batch loss: 0.162894 Batch F1: 0.6808510638297872
Epoch:  767       10 Batch loss: 0.190578 Batch F1: 0.6511627906976745
Epoch:  767       11 Batch loss: 0.186448 Batch F1: 0.6341463414634146
Epoch:  767       12 Batch loss: 0.162958 Batch F1: 0.6451612903225806
Train Avg Loss  767: 0.168648

Train Avg F1  767: 0.7095729574409221

Val Avg Loss  767: 0.180932

Val Avg F1  767:  0.6671884317233154

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 768
--------------------------------------------------------------
Epoch:  768        1 Batch loss: 0.200594 Batch F1: 0.4444444444444445
Epoch:  768        2 Batch loss: 0.146972 Batch F1: 0.8518518518518519
Epoch:  768        3 Batch loss: 0.183485 Batch F1: 0.7169811320754718
Epoch:  768        4 Batch loss: 0.149277 Batch F1: 0.6666666666666665
Epoch:  768        5 Batch loss: 0.174044 Batch F1: 0.6818181818181819
Epoch:  768        6 Batch loss: 0.161547 Batch F1: 0.7441860465116279
Epoch:  768        7 Batch loss: 0.143330 Batch F1: 0.8333333333333333
Epoch:  768        8 Batch loss: 0.178161 Batch F1: 0.5714285714285715
Epoch:  768        9 Batch loss: 0.161411 Batch F1: 0.7317073170731706
Epoch:  768       10 Batch loss: 0.178732 Batch F1: 0.6808510638297872
Epoch:  768       11 Batch loss: 0.159885 Batch F1: 0.744186046511628
Epoch:  768       12 Batch loss: 0.185100 Batch F1: 0.7555555555555555
Train Avg Loss  768: 0.168545

Train Avg F1  768: 0.7019175175916909

Val Avg Loss  768: 0.181230

Val Avg F1  768:  0.6702038845227699

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 769
--------------------------------------------------------------
Epoch:  769        1 Batch loss: 0.175437 Batch F1: 0.5945945945945946
Epoch:  769        2 Batch loss: 0.196069 Batch F1: 0.5909090909090909
Epoch:  769        3 Batch loss: 0.161626 Batch F1: 0.7391304347826088
Epoch:  769        4 Batch loss: 0.182536 Batch F1: 0.6956521739130435
Epoch:  769        5 Batch loss: 0.167453 Batch F1: 0.7234042553191489
Epoch:  769        6 Batch loss: 0.196073 Batch F1: 0.6382978723404256
Epoch:  769        7 Batch loss: 0.176602 Batch F1: 0.7083333333333334
Epoch:  769        8 Batch loss: 0.162085 Batch F1: 0.7999999999999999
Epoch:  769        9 Batch loss: 0.134349 Batch F1: 0.8421052631578947
Epoch:  769       10 Batch loss: 0.134976 Batch F1: 0.7894736842105262
Epoch:  769       11 Batch loss: 0.167959 Batch F1: 0.6829268292682926
Epoch:  769       12 Batch loss: 0.168853 Batch F1: 0.7368421052631577
Train Avg Loss  769: 0.168668

Train Avg F1  769: 0.7118058030910097

Val Avg Loss  769: 0.181285

Val Avg F1  769:  0.6727011494252872

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 770
--------------------------------------------------------------
Epoch:  770        1 Batch loss: 0.135141 Batch F1: 0.8108108108108109
Epoch:  770        2 Batch loss: 0.189341 Batch F1: 0.6382978723404256
Epoch:  770        3 Batch loss: 0.170621 Batch F1: 0.6976744186046512
Epoch:  770        4 Batch loss: 0.173201 Batch F1: 0.7450980392156863
Epoch:  770        5 Batch loss: 0.184350 Batch F1: 0.6666666666666666
Epoch:  770        6 Batch loss: 0.146268 Batch F1: 0.7916666666666666
Epoch:  770        7 Batch loss: 0.174950 Batch F1: 0.6938775510204083
Epoch:  770        8 Batch loss: 0.177956 Batch F1: 0.7142857142857143
Epoch:  770        9 Batch loss: 0.177985 Batch F1: 0.7272727272727273
Epoch:  770       10 Batch loss: 0.167684 Batch F1: 0.6315789473684211
Epoch:  770       11 Batch loss: 0.160084 Batch F1: 0.7272727272727273
Epoch:  770       12 Batch loss: 0.187177 Batch F1: 0.7
Train Avg Loss  770: 0.170396

Train Avg F1  770: 0.7120418451270755

Val Avg Loss  770: 0.189113

Val Avg F1  770:  0.6836700336700336

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 771
--------------------------------------------------------------
Epoch:  771        1 Batch loss: 0.168092 Batch F1: 0.7755102040816326
Epoch:  771        2 Batch loss: 0.173139 Batch F1: 0.6666666666666666
Epoch:  771        3 Batch loss: 0.166302 Batch F1: 0.7027027027027027
Epoch:  771        4 Batch loss: 0.191967 Batch F1: 0.6086956521739131
Epoch:  771        5 Batch loss: 0.166561 Batch F1: 0.611111111111111
Epoch:  771        6 Batch loss: 0.162156 Batch F1: 0.782608695652174
Epoch:  771        7 Batch loss: 0.192756 Batch F1: 0.6
Epoch:  771        8 Batch loss: 0.168982 Batch F1: 0.7391304347826085
Epoch:  771        9 Batch loss: 0.144340 Batch F1: 0.8095238095238095
Epoch:  771       10 Batch loss: 0.170593 Batch F1: 0.6486486486486486
Epoch:  771       11 Batch loss: 0.163176 Batch F1: 0.8076923076923077
Epoch:  771       12 Batch loss: 0.195384 Batch F1: 0.7346938775510203
Train Avg Loss  771: 0.171954

Train Avg F1  771: 0.7072486758822162

Val Avg Loss  771: 0.180423

Val Avg F1  771:  0.6729166666666666

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 772
--------------------------------------------------------------
Epoch:  772        1 Batch loss: 0.158363 Batch F1: 0.6285714285714286
Epoch:  772        2 Batch loss: 0.148931 Batch F1: 0.7916666666666666
Epoch:  772        3 Batch loss: 0.188431 Batch F1: 0.64
Epoch:  772        4 Batch loss: 0.199214 Batch F1: 0.6122448979591837
Epoch:  772        5 Batch loss: 0.146114 Batch F1: 0.8181818181818182
Epoch:  772        6 Batch loss: 0.162478 Batch F1: 0.7142857142857143
Epoch:  772        7 Batch loss: 0.169375 Batch F1: 0.6842105263157895
Epoch:  772        8 Batch loss: 0.183729 Batch F1: 0.6666666666666666
Epoch:  772        9 Batch loss: 0.213305 Batch F1: 0.5641025641025642
Epoch:  772       10 Batch loss: 0.152530 Batch F1: 0.7924528301886793
Epoch:  772       11 Batch loss: 0.173573 Batch F1: 0.7346938775510204
Epoch:  772       12 Batch loss: 0.144673 Batch F1: 0.8108108108108109
Train Avg Loss  772: 0.170060

Train Avg F1  772: 0.7048239834416953

Val Avg Loss  772: 0.180970

Val Avg F1  772:  0.6716727716727716

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 773
--------------------------------------------------------------
Epoch:  773        1 Batch loss: 0.171723 Batch F1: 0.7547169811320755
Epoch:  773        2 Batch loss: 0.133831 Batch F1: 0.8695652173913043
Epoch:  773        3 Batch loss: 0.179644 Batch F1: 0.723404255319149
Epoch:  773        4 Batch loss: 0.187163 Batch F1: 0.7083333333333334
Epoch:  773        5 Batch loss: 0.169832 Batch F1: 0.7111111111111111
Epoch:  773        6 Batch loss: 0.150378 Batch F1: 0.7222222222222222
Epoch:  773        7 Batch loss: 0.191413 Batch F1: 0.5853658536585366
Epoch:  773        8 Batch loss: 0.164447 Batch F1: 0.7391304347826085
Epoch:  773        9 Batch loss: 0.203257 Batch F1: 0.5238095238095238
Epoch:  773       10 Batch loss: 0.148484 Batch F1: 0.782608695652174
Epoch:  773       11 Batch loss: 0.153885 Batch F1: 0.7222222222222222
Epoch:  773       12 Batch loss: 0.174710 Batch F1: 0.6666666666666667
Train Avg Loss  773: 0.169064

Train Avg F1  773: 0.7090963764417438

Val Avg Loss  773: 0.180247

Val Avg F1  773:  0.6739988957939969

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 774
--------------------------------------------------------------
Epoch:  774        1 Batch loss: 0.187309 Batch F1: 0.6190476190476191
Epoch:  774        2 Batch loss: 0.167751 Batch F1: 0.6666666666666667
Epoch:  774        3 Batch loss: 0.183837 Batch F1: 0.6808510638297872
Epoch:  774        4 Batch loss: 0.159515 Batch F1: 0.7727272727272727
Epoch:  774        5 Batch loss: 0.165470 Batch F1: 0.7441860465116279
Epoch:  774        6 Batch loss: 0.154145 Batch F1: 0.7659574468085107
Epoch:  774        7 Batch loss: 0.187134 Batch F1: 0.6363636363636365
Epoch:  774        8 Batch loss: 0.133120 Batch F1: 0.7428571428571429
Epoch:  774        9 Batch loss: 0.173644 Batch F1: 0.6976744186046512
Epoch:  774       10 Batch loss: 0.186376 Batch F1: 0.6511627906976744
Epoch:  774       11 Batch loss: 0.150809 Batch F1: 0.8076923076923077
Epoch:  774       12 Batch loss: 0.160443 Batch F1: 0.7500000000000001
Train Avg Loss  774: 0.167463

Train Avg F1  774: 0.7112655343172415

Val Avg Loss  774: 0.180292

Val Avg F1  774:  0.6713663446781619

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 775
--------------------------------------------------------------
Epoch:  775        1 Batch loss: 0.135831 Batch F1: 0.7894736842105262
Epoch:  775        2 Batch loss: 0.164568 Batch F1: 0.72
Epoch:  775        3 Batch loss: 0.173336 Batch F1: 0.6956521739130435
Epoch:  775        4 Batch loss: 0.172090 Batch F1: 0.6470588235294118
Epoch:  775        5 Batch loss: 0.157263 Batch F1: 0.8076923076923077
Epoch:  775        6 Batch loss: 0.163000 Batch F1: 0.6666666666666667
Epoch:  775        7 Batch loss: 0.181520 Batch F1: 0.6363636363636365
Epoch:  775        8 Batch loss: 0.167749 Batch F1: 0.7450980392156863
Epoch:  775        9 Batch loss: 0.199350 Batch F1: 0.6666666666666666
Epoch:  775       10 Batch loss: 0.164683 Batch F1: 0.744186046511628
Epoch:  775       11 Batch loss: 0.179583 Batch F1: 0.7636363636363638
Epoch:  775       12 Batch loss: 0.177967 Batch F1: 0.5806451612903226
Train Avg Loss  775: 0.169745

Train Avg F1  775: 0.7052616308080216

Val Avg Loss  775: 0.182611

Val Avg F1  775:  0.6766856173444142

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 776
--------------------------------------------------------------
Epoch:  776        1 Batch loss: 0.193192 Batch F1: 0.68
Epoch:  776        2 Batch loss: 0.179849 Batch F1: 0.6666666666666667
Epoch:  776        3 Batch loss: 0.175034 Batch F1: 0.75
Epoch:  776        4 Batch loss: 0.177906 Batch F1: 0.6511627906976744
Epoch:  776        5 Batch loss: 0.171012 Batch F1: 0.6363636363636364
Epoch:  776        6 Batch loss: 0.167213 Batch F1: 0.7
Epoch:  776        7 Batch loss: 0.154289 Batch F1: 0.7
Epoch:  776        8 Batch loss: 0.180705 Batch F1: 0.7083333333333334
Epoch:  776        9 Batch loss: 0.173463 Batch F1: 0.7500000000000001
Epoch:  776       10 Batch loss: 0.167695 Batch F1: 0.7272727272727272
Epoch:  776       11 Batch loss: 0.164521 Batch F1: 0.7027027027027027
Epoch:  776       12 Batch loss: 0.144683 Batch F1: 0.8571428571428572
Train Avg Loss  776: 0.170797

Train Avg F1  776: 0.7108037261816332

Val Avg Loss  776: 0.181630

Val Avg F1  776:  0.7556686046511628

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 777
--------------------------------------------------------------
Epoch:  777        1 Batch loss: 0.193379 Batch F1: 0.7692307692307693
Epoch:  777        2 Batch loss: 0.158312 Batch F1: 0.8928571428571428
Epoch:  777        3 Batch loss: 0.191059 Batch F1: 0.830188679245283
Epoch:  777        4 Batch loss: 0.183918 Batch F1: 0.723404255319149
Epoch:  777        5 Batch loss: 0.159520 Batch F1: 0.7500000000000001
Epoch:  777        6 Batch loss: 0.161974 Batch F1: 0.717948717948718
Epoch:  777        7 Batch loss: 0.187924 Batch F1: 0.7307692307692308
Epoch:  777        8 Batch loss: 0.177078 Batch F1: 0.7307692307692308
Epoch:  777        9 Batch loss: 0.149496 Batch F1: 0.5925925925925926
Epoch:  777       10 Batch loss: 0.155792 Batch F1: 0.717948717948718
Epoch:  777       11 Batch loss: 0.180391 Batch F1: 0.6666666666666666
Epoch:  777       12 Batch loss: 0.157151 Batch F1: 0.8181818181818182
Train Avg Loss  777: 0.171333

Train Avg F1  777: 0.7450464851274433

Val Avg Loss  777: 0.181693

Val Avg F1  777:  0.6750494513818253

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 778
--------------------------------------------------------------
Epoch:  778        1 Batch loss: 0.138550 Batch F1: 0.8292682926829269
Epoch:  778        2 Batch loss: 0.166365 Batch F1: 0.711111111111111
Epoch:  778        3 Batch loss: 0.158814 Batch F1: 0.6976744186046512
Epoch:  778        4 Batch loss: 0.167127 Batch F1: 0.75
Epoch:  778        5 Batch loss: 0.163002 Batch F1: 0.7727272727272727
Epoch:  778        6 Batch loss: 0.160821 Batch F1: 0.7499999999999999
Epoch:  778        7 Batch loss: 0.185401 Batch F1: 0.6666666666666666
Epoch:  778        8 Batch loss: 0.187233 Batch F1: 0.6521739130434783
Epoch:  778        9 Batch loss: 0.179965 Batch F1: 0.6808510638297872
Epoch:  778       10 Batch loss: 0.154065 Batch F1: 0.761904761904762
Epoch:  778       11 Batch loss: 0.184515 Batch F1: 0.6666666666666666
Epoch:  778       12 Batch loss: 0.176495 Batch F1: 0.5882352941176471
Train Avg Loss  778: 0.168529

Train Avg F1  778: 0.7106066217795809

Val Avg Loss  778: 0.182693

Val Avg F1  778:  0.6741281492834288

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 779
--------------------------------------------------------------
Epoch:  779        1 Batch loss: 0.199845 Batch F1: 0.6666666666666667
Epoch:  779        2 Batch loss: 0.179311 Batch F1: 0.7719298245614034
Epoch:  779        3 Batch loss: 0.176342 Batch F1: 0.7391304347826089
Epoch:  779        4 Batch loss: 0.163465 Batch F1: 0.588235294117647
Epoch:  779        5 Batch loss: 0.152438 Batch F1: 0.7999999999999999
Epoch:  779        6 Batch loss: 0.138501 Batch F1: 0.7999999999999999
Epoch:  779        7 Batch loss: 0.171637 Batch F1: 0.7142857142857143
Epoch:  779        8 Batch loss: 0.151194 Batch F1: 0.7567567567567567
Epoch:  779        9 Batch loss: 0.190403 Batch F1: 0.6923076923076924
Epoch:  779       10 Batch loss: 0.164815 Batch F1: 0.75
Epoch:  779       11 Batch loss: 0.209102 Batch F1: 0.375
Epoch:  779       12 Batch loss: 0.151240 Batch F1: 0.7741935483870969
Train Avg Loss  779: 0.170691

Train Avg F1  779: 0.7023754943221322

Val Avg Loss  779: 0.184944

Val Avg F1  779:  0.6702740254526687

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 780
--------------------------------------------------------------
Epoch:  780        1 Batch loss: 0.142598 Batch F1: 0.7692307692307692
Epoch:  780        2 Batch loss: 0.149469 Batch F1: 0.7692307692307692
Epoch:  780        3 Batch loss: 0.173401 Batch F1: 0.6956521739130435
Epoch:  780        4 Batch loss: 0.201298 Batch F1: 0.5909090909090909
Epoch:  780        5 Batch loss: 0.185815 Batch F1: 0.7169811320754716
Epoch:  780        6 Batch loss: 0.171643 Batch F1: 0.7272727272727274
Epoch:  780        7 Batch loss: 0.155795 Batch F1: 0.8148148148148148
Epoch:  780        8 Batch loss: 0.251897 Batch F1: 0.3902439024390244
Epoch:  780        9 Batch loss: 0.149102 Batch F1: 0.7555555555555556
Epoch:  780       10 Batch loss: 0.179125 Batch F1: 0.5957446808510638
Epoch:  780       11 Batch loss: 0.176681 Batch F1: 0.6486486486486486
Epoch:  780       12 Batch loss: 0.195423 Batch F1: 0.5454545454545454
Train Avg Loss  780: 0.177687

Train Avg F1  780: 0.6683115675329604

Val Avg Loss  780: 0.192264

Val Avg F1  780:  0.7230880174194128

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 781
--------------------------------------------------------------
Epoch:  781        1 Batch loss: 0.222580 Batch F1: 0.75
Epoch:  781        2 Batch loss: 0.170277 Batch F1: 0.8214285714285714
Epoch:  781        3 Batch loss: 0.171046 Batch F1: 0.7916666666666667
Epoch:  781        4 Batch loss: 0.179534 Batch F1: 0.76
Epoch:  781        5 Batch loss: 0.165727 Batch F1: 0.65
Epoch:  781        6 Batch loss: 0.186806 Batch F1: 0.5714285714285715
Epoch:  781        7 Batch loss: 0.183123 Batch F1: 0.5853658536585367
Epoch:  781        8 Batch loss: 0.237970 Batch F1: 0.6222222222222222
Epoch:  781        9 Batch loss: 0.211225 Batch F1: 0.6
Epoch:  781       10 Batch loss: 0.170846 Batch F1: 0.7906976744186046
Epoch:  781       11 Batch loss: 0.137343 Batch F1: 0.8108108108108109
Epoch:  781       12 Batch loss: 0.159087 Batch F1: 0.7999999999999999
Train Avg Loss  781: 0.182964

Train Avg F1  781: 0.7128016975528318

Val Avg Loss  781: 0.183858

Val Avg F1  781:  0.6749399005541631

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 782
--------------------------------------------------------------
Epoch:  782        1 Batch loss: 0.173655 Batch F1: 0.7547169811320754
Epoch:  782        2 Batch loss: 0.195372 Batch F1: 0.5
Epoch:  782        3 Batch loss: 0.184351 Batch F1: 0.6938775510204083
Epoch:  782        4 Batch loss: 0.161701 Batch F1: 0.7727272727272727
Epoch:  782        5 Batch loss: 0.155684 Batch F1: 0.7368421052631577
Epoch:  782        6 Batch loss: 0.198460 Batch F1: 0.5500000000000002
Epoch:  782        7 Batch loss: 0.172596 Batch F1: 0.7083333333333334
Epoch:  782        8 Batch loss: 0.176433 Batch F1: 0.8518518518518519
Epoch:  782        9 Batch loss: 0.159278 Batch F1: 0.7727272727272727
Epoch:  782       10 Batch loss: 0.170205 Batch F1: 0.7083333333333334
Epoch:  782       11 Batch loss: 0.169217 Batch F1: 0.6829268292682926
Epoch:  782       12 Batch loss: 0.149786 Batch F1: 0.8108108108108107
Train Avg Loss  782: 0.172228

Train Avg F1  782: 0.7119289451223173

Val Avg Loss  782: 0.183924

Val Avg F1  782:  0.6747685185185185

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 783
--------------------------------------------------------------
Epoch:  783        1 Batch loss: 0.168555 Batch F1: 0.6976744186046512
Epoch:  783        2 Batch loss: 0.163413 Batch F1: 0.7924528301886793
Epoch:  783        3 Batch loss: 0.157746 Batch F1: 0.7999999999999999
Epoch:  783        4 Batch loss: 0.173642 Batch F1: 0.6829268292682926
Epoch:  783        5 Batch loss: 0.155471 Batch F1: 0.7826086956521738
Epoch:  783        6 Batch loss: 0.200510 Batch F1: 0.5405405405405405
Epoch:  783        7 Batch loss: 0.171325 Batch F1: 0.6470588235294118
Epoch:  783        8 Batch loss: 0.202235 Batch F1: 0.6046511627906976
Epoch:  783        9 Batch loss: 0.177879 Batch F1: 0.76
Epoch:  783       10 Batch loss: 0.159078 Batch F1: 0.7916666666666666
Epoch:  783       11 Batch loss: 0.181895 Batch F1: 0.6808510638297872
Epoch:  783       12 Batch loss: 0.170346 Batch F1: 0.6666666666666666
Train Avg Loss  783: 0.173508

Train Avg F1  783: 0.7039248081447974

Val Avg Loss  783: 0.182142

Val Avg F1  783:  0.6782505910165485

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 784
--------------------------------------------------------------
Epoch:  784        1 Batch loss: 0.191049 Batch F1: 0.6792452830188679
Epoch:  784        2 Batch loss: 0.160457 Batch F1: 0.7317073170731707
Epoch:  784        3 Batch loss: 0.172779 Batch F1: 0.717948717948718
Epoch:  784        4 Batch loss: 0.132388 Batch F1: 0.8695652173913043
Epoch:  784        5 Batch loss: 0.167549 Batch F1: 0.7692307692307692
Epoch:  784        6 Batch loss: 0.158823 Batch F1: 0.7916666666666666
Epoch:  784        7 Batch loss: 0.186850 Batch F1: 0.6363636363636365
Epoch:  784        8 Batch loss: 0.202442 Batch F1: 0.5365853658536586
Epoch:  784        9 Batch loss: 0.177982 Batch F1: 0.6341463414634148
Epoch:  784       10 Batch loss: 0.186479 Batch F1: 0.72
Epoch:  784       11 Batch loss: 0.159779 Batch F1: 0.717948717948718
Epoch:  784       12 Batch loss: 0.151739 Batch F1: 0.7096774193548386
Train Avg Loss  784: 0.170693

Train Avg F1  784: 0.7095071210261469

Val Avg Loss  784: 0.182453

Val Avg F1  784:  0.6755200203908956

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 785
--------------------------------------------------------------
Epoch:  785        1 Batch loss: 0.192650 Batch F1: 0.68
Epoch:  785        2 Batch loss: 0.185325 Batch F1: 0.5853658536585366
Epoch:  785        3 Batch loss: 0.158686 Batch F1: 0.7727272727272727
Epoch:  785        4 Batch loss: 0.160917 Batch F1: 0.7727272727272727
Epoch:  785        5 Batch loss: 0.171831 Batch F1: 0.6818181818181819
Epoch:  785        6 Batch loss: 0.156083 Batch F1: 0.7804878048780488
Epoch:  785        7 Batch loss: 0.203844 Batch F1: 0.6122448979591836
Epoch:  785        8 Batch loss: 0.141637 Batch F1: 0.8333333333333334
Epoch:  785        9 Batch loss: 0.192828 Batch F1: 0.693877551020408
Epoch:  785       10 Batch loss: 0.139771 Batch F1: 0.8181818181818182
Epoch:  785       11 Batch loss: 0.174138 Batch F1: 0.6511627906976744
Epoch:  785       12 Batch loss: 0.168763 Batch F1: 0.6428571428571428
Train Avg Loss  785: 0.170539

Train Avg F1  785: 0.7103986599882394

Val Avg Loss  785: 0.183081

Val Avg F1  785:  0.676470588235294

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 786
--------------------------------------------------------------
Epoch:  786        1 Batch loss: 0.175151 Batch F1: 0.7450980392156864
Epoch:  786        2 Batch loss: 0.163806 Batch F1: 0.7924528301886792
Epoch:  786        3 Batch loss: 0.175565 Batch F1: 0.6829268292682927
Epoch:  786        4 Batch loss: 0.182035 Batch F1: 0.6511627906976744
Epoch:  786        5 Batch loss: 0.169264 Batch F1: 0.7272727272727272
Epoch:  786        6 Batch loss: 0.167503 Batch F1: 0.7659574468085107
Epoch:  786        7 Batch loss: 0.155804 Batch F1: 0.7317073170731706
Epoch:  786        8 Batch loss: 0.169967 Batch F1: 0.6666666666666666
Epoch:  786        9 Batch loss: 0.205275 Batch F1: 0.4864864864864865
Epoch:  786       10 Batch loss: 0.167823 Batch F1: 0.7755102040816326
Epoch:  786       11 Batch loss: 0.181677 Batch F1: 0.7200000000000001
Epoch:  786       12 Batch loss: 0.154813 Batch F1: 0.7407407407407408
Train Avg Loss  786: 0.172390

Train Avg F1  786: 0.7071651732083556

Val Avg Loss  786: 0.181497

Val Avg F1  786:  0.6709823045421116

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 787
--------------------------------------------------------------
Epoch:  787        1 Batch loss: 0.141417 Batch F1: 0.8292682926829269
Epoch:  787        2 Batch loss: 0.158644 Batch F1: 0.7555555555555555
Epoch:  787        3 Batch loss: 0.174223 Batch F1: 0.7692307692307692
Epoch:  787        4 Batch loss: 0.172989 Batch F1: 0.7346938775510204
Epoch:  787        5 Batch loss: 0.209736 Batch F1: 0.5128205128205129
Epoch:  787        6 Batch loss: 0.191210 Batch F1: 0.6923076923076923
Epoch:  787        7 Batch loss: 0.173336 Batch F1: 0.65
Epoch:  787        8 Batch loss: 0.146291 Batch F1: 0.717948717948718
Epoch:  787        9 Batch loss: 0.157702 Batch F1: 0.75
Epoch:  787       10 Batch loss: 0.185351 Batch F1: 0.6511627906976745
Epoch:  787       11 Batch loss: 0.162862 Batch F1: 0.7111111111111111
Epoch:  787       12 Batch loss: 0.186587 Batch F1: 0.7500000000000001
Train Avg Loss  787: 0.171696

Train Avg F1  787: 0.7103416099921652

Val Avg Loss  787: 0.180791

Val Avg F1  787:  0.6730705186731012

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 788
--------------------------------------------------------------
Epoch:  788        1 Batch loss: 0.191769 Batch F1: 0.6046511627906977
Epoch:  788        2 Batch loss: 0.142778 Batch F1: 0.8181818181818182
Epoch:  788        3 Batch loss: 0.192009 Batch F1: 0.6923076923076923
Epoch:  788        4 Batch loss: 0.158730 Batch F1: 0.7916666666666666
Epoch:  788        5 Batch loss: 0.150677 Batch F1: 0.7826086956521738
Epoch:  788        6 Batch loss: 0.189743 Batch F1: 0.7083333333333334
Epoch:  788        7 Batch loss: 0.160456 Batch F1: 0.7027027027027027
Epoch:  788        8 Batch loss: 0.175159 Batch F1: 0.6842105263157895
Epoch:  788        9 Batch loss: 0.190253 Batch F1: 0.6222222222222222
Epoch:  788       10 Batch loss: 0.174160 Batch F1: 0.7826086956521738
Epoch:  788       11 Batch loss: 0.198484 Batch F1: 0.6363636363636364
Epoch:  788       12 Batch loss: 0.173506 Batch F1: 0.8571428571428571
Train Avg Loss  788: 0.174810

Train Avg F1  788: 0.7235833341109803

Val Avg Loss  788: 0.189301

Val Avg F1  788:  0.7883324382384533

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 789
--------------------------------------------------------------
Epoch:  789        1 Batch loss: 0.179224 Batch F1: 0.8461538461538461
Epoch:  789        2 Batch loss: 0.170644 Batch F1: 0.7692307692307692
Epoch:  789        3 Batch loss: 0.187003 Batch F1: 0.6666666666666666
Epoch:  789        4 Batch loss: 0.169479 Batch F1: 0.7391304347826088
Epoch:  789        5 Batch loss: 0.174136 Batch F1: 0.6666666666666667
Epoch:  789        6 Batch loss: 0.197449 Batch F1: 0.5909090909090909
Epoch:  789        7 Batch loss: 0.196301 Batch F1: 0.6521739130434783
Epoch:  789        8 Batch loss: 0.218547 Batch F1: 0.5833333333333334
Epoch:  789        9 Batch loss: 0.160978 Batch F1: 0.723404255319149
Epoch:  789       10 Batch loss: 0.146632 Batch F1: 0.8695652173913043
Epoch:  789       11 Batch loss: 0.151542 Batch F1: 0.8292682926829269
Epoch:  789       12 Batch loss: 0.163786 Batch F1: 0.7567567567567567
Train Avg Loss  789: 0.176310

Train Avg F1  789: 0.7244382702447164

Val Avg Loss  789: 0.190966

Val Avg F1  789:  0.6802441198208773

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 790
--------------------------------------------------------------
Epoch:  790        1 Batch loss: 0.153477 Batch F1: 0.7500000000000001
Epoch:  790        2 Batch loss: 0.181921 Batch F1: 0.8076923076923077
Epoch:  790        3 Batch loss: 0.178878 Batch F1: 0.6153846153846154
Epoch:  790        4 Batch loss: 0.172532 Batch F1: 0.6666666666666666
Epoch:  790        5 Batch loss: 0.168951 Batch F1: 0.6976744186046512
Epoch:  790        6 Batch loss: 0.134441 Batch F1: 0.7777777777777778
Epoch:  790        7 Batch loss: 0.157845 Batch F1: 0.6470588235294118
Epoch:  790        8 Batch loss: 0.149028 Batch F1: 0.8292682926829268
Epoch:  790        9 Batch loss: 0.189420 Batch F1: 0.5454545454545454
Epoch:  790       10 Batch loss: 0.199678 Batch F1: 0.7037037037037037
Epoch:  790       11 Batch loss: 0.215964 Batch F1: 0.6250000000000001
Epoch:  790       12 Batch loss: 0.180369 Batch F1: 0.7924528301886793
Train Avg Loss  790: 0.173542

Train Avg F1  790: 0.7048444984737738

Val Avg Loss  790: 0.181933

Val Avg F1  790:  0.6629515070773165

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 791
--------------------------------------------------------------
Epoch:  791        1 Batch loss: 0.143366 Batch F1: 0.7272727272727274
Epoch:  791        2 Batch loss: 0.178952 Batch F1: 0.7083333333333334
Epoch:  791        3 Batch loss: 0.151558 Batch F1: 0.7222222222222222
Epoch:  791        4 Batch loss: 0.170247 Batch F1: 0.7843137254901961
Epoch:  791        5 Batch loss: 0.202408 Batch F1: 0.5500000000000002
Epoch:  791        6 Batch loss: 0.153041 Batch F1: 0.8
Epoch:  791        7 Batch loss: 0.197885 Batch F1: 0.6382978723404256
Epoch:  791        8 Batch loss: 0.166204 Batch F1: 0.6818181818181818
Epoch:  791        9 Batch loss: 0.173565 Batch F1: 0.7692307692307693
Epoch:  791       10 Batch loss: 0.169965 Batch F1: 0.7391304347826088
Epoch:  791       11 Batch loss: 0.183967 Batch F1: 0.6666666666666666
Epoch:  791       12 Batch loss: 0.152955 Batch F1: 0.7428571428571428
Train Avg Loss  791: 0.170343

Train Avg F1  791: 0.7108452563345228

Val Avg Loss  791: 0.182226

Val Avg F1  791:  0.6726256467110125

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 792
--------------------------------------------------------------
Epoch:  792        1 Batch loss: 0.183596 Batch F1: 0.6666666666666667
Epoch:  792        2 Batch loss: 0.159717 Batch F1: 0.8
Epoch:  792        3 Batch loss: 0.170943 Batch F1: 0.7346938775510204
Epoch:  792        4 Batch loss: 0.167581 Batch F1: 0.6470588235294117
Epoch:  792        5 Batch loss: 0.148256 Batch F1: 0.7272727272727272
Epoch:  792        6 Batch loss: 0.163990 Batch F1: 0.7142857142857143
Epoch:  792        7 Batch loss: 0.167180 Batch F1: 0.7142857142857143
Epoch:  792        8 Batch loss: 0.161614 Batch F1: 0.7755102040816326
Epoch:  792        9 Batch loss: 0.182587 Batch F1: 0.7307692307692308
Epoch:  792       10 Batch loss: 0.139963 Batch F1: 0.8181818181818182
Epoch:  792       11 Batch loss: 0.214400 Batch F1: 0.5454545454545454
Epoch:  792       12 Batch loss: 0.193722 Batch F1: 0.631578947368421
Train Avg Loss  792: 0.171129

Train Avg F1  792: 0.7088131891205753

Val Avg Loss  792: 0.181135

Val Avg F1  792:  0.6768592349385033

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 793
--------------------------------------------------------------
Epoch:  793        1 Batch loss: 0.159893 Batch F1: 0.7441860465116279
Epoch:  793        2 Batch loss: 0.160603 Batch F1: 0.7272727272727272
Epoch:  793        3 Batch loss: 0.154231 Batch F1: 0.717948717948718
Epoch:  793        4 Batch loss: 0.173032 Batch F1: 0.65
Epoch:  793        5 Batch loss: 0.163277 Batch F1: 0.7555555555555555
Epoch:  793        6 Batch loss: 0.182894 Batch F1: 0.6341463414634146
Epoch:  793        7 Batch loss: 0.196127 Batch F1: 0.7272727272727273
Epoch:  793        8 Batch loss: 0.168521 Batch F1: 0.6486486486486486
Epoch:  793        9 Batch loss: 0.186077 Batch F1: 0.6808510638297872
Epoch:  793       10 Batch loss: 0.172442 Batch F1: 0.6666666666666666
Epoch:  793       11 Batch loss: 0.162618 Batch F1: 0.7391304347826088
Epoch:  793       12 Batch loss: 0.154467 Batch F1: 0.8260869565217391
Train Avg Loss  793: 0.169515

Train Avg F1  793: 0.7098138238728517

Val Avg Loss  793: 0.181269

Val Avg F1  793:  0.6785466194934634

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 794
--------------------------------------------------------------
Epoch:  794        1 Batch loss: 0.181335 Batch F1: 0.6818181818181819
Epoch:  794        2 Batch loss: 0.179206 Batch F1: 0.6808510638297872
Epoch:  794        3 Batch loss: 0.131645 Batch F1: 0.8333333333333333
Epoch:  794        4 Batch loss: 0.202690 Batch F1: 0.5454545454545454
Epoch:  794        5 Batch loss: 0.154992 Batch F1: 0.7692307692307692
Epoch:  794        6 Batch loss: 0.168821 Batch F1: 0.7346938775510204
Epoch:  794        7 Batch loss: 0.150916 Batch F1: 0.8095238095238095
Epoch:  794        8 Batch loss: 0.194986 Batch F1: 0.6792452830188679
Epoch:  794        9 Batch loss: 0.167688 Batch F1: 0.7999999999999999
Epoch:  794       10 Batch loss: 0.180355 Batch F1: 0.5714285714285714
Epoch:  794       11 Batch loss: 0.150593 Batch F1: 0.7222222222222222
Epoch:  794       12 Batch loss: 0.166742 Batch F1: 0.7027027027027026
Train Avg Loss  794: 0.169164

Train Avg F1  794: 0.7108753633428174

Val Avg Loss  794: 0.181413

Val Avg F1  794:  0.6714219114219114

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 795
--------------------------------------------------------------
Epoch:  795        1 Batch loss: 0.187931 Batch F1: 0.6808510638297872
Epoch:  795        2 Batch loss: 0.160703 Batch F1: 0.6666666666666666
Epoch:  795        3 Batch loss: 0.166015 Batch F1: 0.72
Epoch:  795        4 Batch loss: 0.163214 Batch F1: 0.7567567567567568
Epoch:  795        5 Batch loss: 0.192560 Batch F1: 0.6382978723404256
Epoch:  795        6 Batch loss: 0.135597 Batch F1: 0.8205128205128205
Epoch:  795        7 Batch loss: 0.180290 Batch F1: 0.7307692307692306
Epoch:  795        8 Batch loss: 0.168108 Batch F1: 0.7027027027027027
Epoch:  795        9 Batch loss: 0.183242 Batch F1: 0.5806451612903225
Epoch:  795       10 Batch loss: 0.181082 Batch F1: 0.723404255319149
Epoch:  795       11 Batch loss: 0.155008 Batch F1: 0.8214285714285715
Epoch:  795       12 Batch loss: 0.207412 Batch F1: 0.5
Train Avg Loss  795: 0.173430

Train Avg F1  795: 0.6951695918013695

Val Avg Loss  795: 0.183257

Val Avg F1  795:  0.6712718299566843

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 796
--------------------------------------------------------------
Epoch:  796        1 Batch loss: 0.180332 Batch F1: 0.6363636363636364
Epoch:  796        2 Batch loss: 0.169321 Batch F1: 0.7272727272727272
Epoch:  796        3 Batch loss: 0.162217 Batch F1: 0.8076923076923077
Epoch:  796        4 Batch loss: 0.163710 Batch F1: 0.6486486486486486
Epoch:  796        5 Batch loss: 0.158265 Batch F1: 0.782608695652174
Epoch:  796        6 Batch loss: 0.171197 Batch F1: 0.6976744186046512
Epoch:  796        7 Batch loss: 0.168272 Batch F1: 0.717948717948718
Epoch:  796        8 Batch loss: 0.188982 Batch F1: 0.693877551020408
Epoch:  796        9 Batch loss: 0.184702 Batch F1: 0.6341463414634146
Epoch:  796       10 Batch loss: 0.186146 Batch F1: 0.6818181818181818
Epoch:  796       11 Batch loss: 0.179340 Batch F1: 0.6976744186046512
Epoch:  796       12 Batch loss: 0.164418 Batch F1: 0.7906976744186047
Train Avg Loss  796: 0.173075

Train Avg F1  796: 0.7097019432923436

Val Avg Loss  796: 0.181388

Val Avg F1  796:  0.6802312451419088

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 797
--------------------------------------------------------------
Epoch:  797        1 Batch loss: 0.169939 Batch F1: 0.6341463414634146
Epoch:  797        2 Batch loss: 0.187258 Batch F1: 0.75
Epoch:  797        3 Batch loss: 0.176124 Batch F1: 0.6818181818181819
Epoch:  797        4 Batch loss: 0.163024 Batch F1: 0.742857142857143
Epoch:  797        5 Batch loss: 0.171104 Batch F1: 0.7843137254901961
Epoch:  797        6 Batch loss: 0.211660 Batch F1: 0.5714285714285714
Epoch:  797        7 Batch loss: 0.175438 Batch F1: 0.6857142857142857
Epoch:  797        8 Batch loss: 0.168197 Batch F1: 0.7924528301886793
Epoch:  797        9 Batch loss: 0.182512 Batch F1: 0.7083333333333334
Epoch:  797       10 Batch loss: 0.188509 Batch F1: 0.7272727272727272
Epoch:  797       11 Batch loss: 0.196684 Batch F1: 0.6382978723404256
Epoch:  797       12 Batch loss: 0.158919 Batch F1: 0.6857142857142857
Train Avg Loss  797: 0.179114

Train Avg F1  797: 0.7001957748017703

Val Avg Loss  797: 0.183509

Val Avg F1  797:  0.6764705882352942

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 798
--------------------------------------------------------------
Epoch:  798        1 Batch loss: 0.183834 Batch F1: 0.5789473684210527
Epoch:  798        2 Batch loss: 0.185619 Batch F1: 0.6956521739130435
Epoch:  798        3 Batch loss: 0.171896 Batch F1: 0.7441860465116279
Epoch:  798        4 Batch loss: 0.175918 Batch F1: 0.7777777777777777
Epoch:  798        5 Batch loss: 0.147894 Batch F1: 0.7906976744186046
Epoch:  798        6 Batch loss: 0.171928 Batch F1: 0.6486486486486486
Epoch:  798        7 Batch loss: 0.184574 Batch F1: 0.7547169811320754
Epoch:  798        8 Batch loss: 0.154373 Batch F1: 0.7999999999999999
Epoch:  798        9 Batch loss: 0.166428 Batch F1: 0.76
Epoch:  798       10 Batch loss: 0.166169 Batch F1: 0.5714285714285714
Epoch:  798       11 Batch loss: 0.202824 Batch F1: 0.5714285714285715
Epoch:  798       12 Batch loss: 0.152940 Batch F1: 0.7692307692307692
Train Avg Loss  798: 0.172033

Train Avg F1  798: 0.7052262152425618

Val Avg Loss  798: 0.185105

Val Avg F1  798:  0.6745101731289077

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 799
--------------------------------------------------------------
Epoch:  799        1 Batch loss: 0.190637 Batch F1: 0.5142857142857143
Epoch:  799        2 Batch loss: 0.144538 Batch F1: 0.8292682926829269
Epoch:  799        3 Batch loss: 0.181439 Batch F1: 0.7200000000000001
Epoch:  799        4 Batch loss: 0.157681 Batch F1: 0.7555555555555555
Epoch:  799        5 Batch loss: 0.189512 Batch F1: 0.6808510638297872
Epoch:  799        6 Batch loss: 0.163204 Batch F1: 0.7
Epoch:  799        7 Batch loss: 0.224694 Batch F1: 0.47619047619047616
Epoch:  799        8 Batch loss: 0.157002 Batch F1: 0.7843137254901961
Epoch:  799        9 Batch loss: 0.154551 Batch F1: 0.8076923076923077
Epoch:  799       10 Batch loss: 0.155347 Batch F1: 0.7916666666666667
Epoch:  799       11 Batch loss: 0.190662 Batch F1: 0.6976744186046512
Epoch:  799       12 Batch loss: 0.150030 Batch F1: 0.7096774193548386
Train Avg Loss  799: 0.171608

Train Avg F1  799: 0.7055979700294267

Val Avg Loss  799: 0.183879

Val Avg F1  799:  0.676794398610508

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 800
--------------------------------------------------------------
Epoch:  800        1 Batch loss: 0.183732 Batch F1: 0.5555555555555556
Epoch:  800        2 Batch loss: 0.182445 Batch F1: 0.6153846153846153
Epoch:  800        3 Batch loss: 0.169612 Batch F1: 0.7111111111111111
Epoch:  800        4 Batch loss: 0.208122 Batch F1: 0.6530612244897959
Epoch:  800        5 Batch loss: 0.163604 Batch F1: 0.761904761904762
Epoch:  800        6 Batch loss: 0.178465 Batch F1: 0.6666666666666666
Epoch:  800        7 Batch loss: 0.167478 Batch F1: 0.7826086956521738
Epoch:  800        8 Batch loss: 0.133983 Batch F1: 0.8846153846153846
Epoch:  800        9 Batch loss: 0.191495 Batch F1: 0.68
Epoch:  800       10 Batch loss: 0.179402 Batch F1: 0.619047619047619
Epoch:  800       11 Batch loss: 0.142293 Batch F1: 0.7555555555555556
Epoch:  800       12 Batch loss: 0.169825 Batch F1: 0.7317073170731708
Train Avg Loss  800: 0.172538

Train Avg F1  800: 0.7014348755880341

Val Avg Loss  800: 0.183765

Val Avg F1  800:  0.6789631782945736

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 801
--------------------------------------------------------------
Epoch:  801        1 Batch loss: 0.182870 Batch F1: 0.6153846153846153
Epoch:  801        2 Batch loss: 0.155520 Batch F1: 0.75
Epoch:  801        3 Batch loss: 0.156812 Batch F1: 0.6666666666666665
Epoch:  801        4 Batch loss: 0.178545 Batch F1: 0.5945945945945946
Epoch:  801        5 Batch loss: 0.169664 Batch F1: 0.7999999999999999
Epoch:  801        6 Batch loss: 0.208904 Batch F1: 0.7346938775510204
Epoch:  801        7 Batch loss: 0.199187 Batch F1: 0.68
Epoch:  801        8 Batch loss: 0.131382 Batch F1: 0.7999999999999999
Epoch:  801        9 Batch loss: 0.153648 Batch F1: 0.7999999999999999
Epoch:  801       10 Batch loss: 0.170166 Batch F1: 0.711111111111111
Epoch:  801       11 Batch loss: 0.168251 Batch F1: 0.7843137254901961
Epoch:  801       12 Batch loss: 0.215468 Batch F1: 0.6521739130434783
Train Avg Loss  801: 0.174201

Train Avg F1  801: 0.7157448753201402

Val Avg Loss  801: 0.182708

Val Avg F1  801:  0.6750924590986022

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 802
--------------------------------------------------------------
Epoch:  802        1 Batch loss: 0.167736 Batch F1: 0.7843137254901961
Epoch:  802        2 Batch loss: 0.168724 Batch F1: 0.7272727272727272
Epoch:  802        3 Batch loss: 0.171596 Batch F1: 0.5714285714285715
Epoch:  802        4 Batch loss: 0.185030 Batch F1: 0.7407407407407408
Epoch:  802        5 Batch loss: 0.149473 Batch F1: 0.761904761904762
Epoch:  802        6 Batch loss: 0.200648 Batch F1: 0.5853658536585366
Epoch:  802        7 Batch loss: 0.174083 Batch F1: 0.6829268292682926
Epoch:  802        8 Batch loss: 0.170388 Batch F1: 0.7924528301886792
Epoch:  802        9 Batch loss: 0.174735 Batch F1: 0.723404255319149
Epoch:  802       10 Batch loss: 0.201192 Batch F1: 0.6666666666666666
Epoch:  802       11 Batch loss: 0.140675 Batch F1: 0.8510638297872339
Epoch:  802       12 Batch loss: 0.175282 Batch F1: 0.4615384615384615
Train Avg Loss  802: 0.173297

Train Avg F1  802: 0.6957566044386682

Val Avg Loss  802: 0.184072

Val Avg F1  802:  0.6612460815047022

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 803
--------------------------------------------------------------
Epoch:  803        1 Batch loss: 0.179362 Batch F1: 0.6808510638297872
Epoch:  803        2 Batch loss: 0.173705 Batch F1: 0.65
Epoch:  803        3 Batch loss: 0.169571 Batch F1: 0.711111111111111
Epoch:  803        4 Batch loss: 0.147732 Batch F1: 0.7317073170731707
Epoch:  803        5 Batch loss: 0.171765 Batch F1: 0.8148148148148148
Epoch:  803        6 Batch loss: 0.142312 Batch F1: 0.8
Epoch:  803        7 Batch loss: 0.161371 Batch F1: 0.7555555555555556
Epoch:  803        8 Batch loss: 0.163652 Batch F1: 0.717948717948718
Epoch:  803        9 Batch loss: 0.200834 Batch F1: 0.6222222222222222
Epoch:  803       10 Batch loss: 0.173020 Batch F1: 0.6315789473684211
Epoch:  803       11 Batch loss: 0.172610 Batch F1: 0.7692307692307693
Epoch:  803       12 Batch loss: 0.208728 Batch F1: 0.6153846153846153
Train Avg Loss  803: 0.172055

Train Avg F1  803: 0.7083670945449322

Val Avg Loss  803: 0.181757

Val Avg F1  803:  0.6716634429400387

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 804
--------------------------------------------------------------
Epoch:  804        1 Batch loss: 0.156647 Batch F1: 0.717948717948718
Epoch:  804        2 Batch loss: 0.170208 Batch F1: 0.7692307692307692
Epoch:  804        3 Batch loss: 0.157284 Batch F1: 0.7727272727272727
Epoch:  804        4 Batch loss: 0.177903 Batch F1: 0.6153846153846153
Epoch:  804        5 Batch loss: 0.178726 Batch F1: 0.7037037037037038
Epoch:  804        6 Batch loss: 0.177234 Batch F1: 0.6818181818181819
Epoch:  804        7 Batch loss: 0.170960 Batch F1: 0.7843137254901961
Epoch:  804        8 Batch loss: 0.181610 Batch F1: 0.6956521739130435
Epoch:  804        9 Batch loss: 0.208201 Batch F1: 0.627450980392157
Epoch:  804       10 Batch loss: 0.137271 Batch F1: 0.7567567567567567
Epoch:  804       11 Batch loss: 0.151383 Batch F1: 0.7222222222222222
Epoch:  804       12 Batch loss: 0.159294 Batch F1: 0.6875
Train Avg Loss  804: 0.168893

Train Avg F1  804: 0.7112257599656363

Val Avg Loss  804: 0.181722

Val Avg F1  804:  0.6674319727891157

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 805
--------------------------------------------------------------
Epoch:  805        1 Batch loss: 0.145789 Batch F1: 0.7804878048780488
Epoch:  805        2 Batch loss: 0.141867 Batch F1: 0.8260869565217391
Epoch:  805        3 Batch loss: 0.158497 Batch F1: 0.8070175438596492
Epoch:  805        4 Batch loss: 0.158460 Batch F1: 0.7000000000000001
Epoch:  805        5 Batch loss: 0.196731 Batch F1: 0.6382978723404256
Epoch:  805        6 Batch loss: 0.176989 Batch F1: 0.6808510638297872
Epoch:  805        7 Batch loss: 0.146150 Batch F1: 0.8095238095238095
Epoch:  805        8 Batch loss: 0.175696 Batch F1: 0.65
Epoch:  805        9 Batch loss: 0.182347 Batch F1: 0.6153846153846153
Epoch:  805       10 Batch loss: 0.152220 Batch F1: 0.7500000000000001
Epoch:  805       11 Batch loss: 0.184271 Batch F1: 0.6521739130434783
Epoch:  805       12 Batch loss: 0.218868 Batch F1: 0.6
Train Avg Loss  805: 0.169824

Train Avg F1  805: 0.7091519649484628

Val Avg Loss  805: 0.181505

Val Avg F1  805:  0.6767992027764417

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 806
--------------------------------------------------------------
Epoch:  806        1 Batch loss: 0.160044 Batch F1: 0.717948717948718
Epoch:  806        2 Batch loss: 0.158001 Batch F1: 0.7659574468085107
Epoch:  806        3 Batch loss: 0.156290 Batch F1: 0.6842105263157895
Epoch:  806        4 Batch loss: 0.158743 Batch F1: 0.7916666666666667
Epoch:  806        5 Batch loss: 0.174819 Batch F1: 0.7083333333333334
Epoch:  806        6 Batch loss: 0.181054 Batch F1: 0.6808510638297872
Epoch:  806        7 Batch loss: 0.171204 Batch F1: 0.8135593220338982
Epoch:  806        8 Batch loss: 0.167111 Batch F1: 0.6829268292682926
Epoch:  806        9 Batch loss: 0.174099 Batch F1: 0.6818181818181819
Epoch:  806       10 Batch loss: 0.172886 Batch F1: 0.6666666666666666
Epoch:  806       11 Batch loss: 0.178451 Batch F1: 0.6808510638297872
Epoch:  806       12 Batch loss: 0.179931 Batch F1: 0.5714285714285715
Train Avg Loss  806: 0.169386

Train Avg F1  806: 0.7038515324956837

Val Avg Loss  806: 0.183000

Val Avg F1  806:  0.6755200630977028

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 807
--------------------------------------------------------------
Epoch:  807        1 Batch loss: 0.168164 Batch F1: 0.7199999999999999
Epoch:  807        2 Batch loss: 0.173442 Batch F1: 0.6666666666666666
Epoch:  807        3 Batch loss: 0.139094 Batch F1: 0.8205128205128205
Epoch:  807        4 Batch loss: 0.199800 Batch F1: 0.6086956521739131
Epoch:  807        5 Batch loss: 0.151813 Batch F1: 0.6666666666666667
Epoch:  807        6 Batch loss: 0.173576 Batch F1: 0.7391304347826085
Epoch:  807        7 Batch loss: 0.187427 Batch F1: 0.7272727272727273
Epoch:  807        8 Batch loss: 0.190022 Batch F1: 0.5714285714285714
Epoch:  807        9 Batch loss: 0.204567 Batch F1: 0.6046511627906976
Epoch:  807       10 Batch loss: 0.156364 Batch F1: 0.830188679245283
Epoch:  807       11 Batch loss: 0.162445 Batch F1: 0.7317073170731706
Epoch:  807       12 Batch loss: 0.121596 Batch F1: 0.8571428571428571
Train Avg Loss  807: 0.169026

Train Avg F1  807: 0.7120052963129986

Val Avg Loss  807: 0.181174

Val Avg F1  807:  0.6685030395136778

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 808
--------------------------------------------------------------
Epoch:  808        1 Batch loss: 0.159526 Batch F1: 0.7659574468085106
Epoch:  808        2 Batch loss: 0.161124 Batch F1: 0.6976744186046512
Epoch:  808        3 Batch loss: 0.153819 Batch F1: 0.7368421052631577
Epoch:  808        4 Batch loss: 0.184960 Batch F1: 0.6808510638297872
Epoch:  808        5 Batch loss: 0.189792 Batch F1: 0.4848484848484848
Epoch:  808        6 Batch loss: 0.155921 Batch F1: 0.7659574468085107
Epoch:  808        7 Batch loss: 0.172150 Batch F1: 0.7111111111111111
Epoch:  808        8 Batch loss: 0.184433 Batch F1: 0.6938775510204083
Epoch:  808        9 Batch loss: 0.192102 Batch F1: 0.7307692307692308
Epoch:  808       10 Batch loss: 0.136075 Batch F1: 0.8444444444444444
Epoch:  808       11 Batch loss: 0.157227 Batch F1: 0.7555555555555555
Epoch:  808       12 Batch loss: 0.183836 Batch F1: 0.5882352941176471
Train Avg Loss  808: 0.169247

Train Avg F1  808: 0.7046770127651251

Val Avg Loss  808: 0.181190

Val Avg F1  808:  0.6785714285714285

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 809
--------------------------------------------------------------
Epoch:  809        1 Batch loss: 0.201619 Batch F1: 0.5365853658536586
Epoch:  809        2 Batch loss: 0.166649 Batch F1: 0.6976744186046512
Epoch:  809        3 Batch loss: 0.163082 Batch F1: 0.65
Epoch:  809        4 Batch loss: 0.172943 Batch F1: 0.6829268292682927
Epoch:  809        5 Batch loss: 0.166806 Batch F1: 0.7636363636363638
Epoch:  809        6 Batch loss: 0.146690 Batch F1: 0.7894736842105263
Epoch:  809        7 Batch loss: 0.187809 Batch F1: 0.6808510638297872
Epoch:  809        8 Batch loss: 0.187283 Batch F1: 0.6666666666666666
Epoch:  809        9 Batch loss: 0.138420 Batch F1: 0.888888888888889
Epoch:  809       10 Batch loss: 0.187953 Batch F1: 0.6666666666666666
Epoch:  809       11 Batch loss: 0.166397 Batch F1: 0.76
Epoch:  809       12 Batch loss: 0.159548 Batch F1: 0.7428571428571429
Train Avg Loss  809: 0.170433

Train Avg F1  809: 0.7105189242068871

Val Avg Loss  809: 0.183564

Val Avg F1  809:  0.6792035743247458

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 810
--------------------------------------------------------------
Epoch:  810        1 Batch loss: 0.175691 Batch F1: 0.711111111111111
Epoch:  810        2 Batch loss: 0.195054 Batch F1: 0.5263157894736842
Epoch:  810        3 Batch loss: 0.144458 Batch F1: 0.7692307692307692
Epoch:  810        4 Batch loss: 0.169265 Batch F1: 0.7777777777777779
Epoch:  810        5 Batch loss: 0.194402 Batch F1: 0.6122448979591838
Epoch:  810        6 Batch loss: 0.160588 Batch F1: 0.7391304347826085
Epoch:  810        7 Batch loss: 0.192941 Batch F1: 0.6222222222222222
Epoch:  810        8 Batch loss: 0.183830 Batch F1: 0.7307692307692308
Epoch:  810        9 Batch loss: 0.156549 Batch F1: 0.7659574468085107
Epoch:  810       10 Batch loss: 0.156442 Batch F1: 0.7142857142857143
Epoch:  810       11 Batch loss: 0.165909 Batch F1: 0.7441860465116279
Epoch:  810       12 Batch loss: 0.156241 Batch F1: 0.7096774193548386
Train Avg Loss  810: 0.170947

Train Avg F1  810: 0.7019090716906065

Val Avg Loss  810: 0.181864

Val Avg F1  810:  0.6775344284055086

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 811
--------------------------------------------------------------
Epoch:  811        1 Batch loss: 0.157603 Batch F1: 0.744186046511628
Epoch:  811        2 Batch loss: 0.166060 Batch F1: 0.7272727272727273
Epoch:  811        3 Batch loss: 0.165621 Batch F1: 0.7346938775510204
Epoch:  811        4 Batch loss: 0.158876 Batch F1: 0.717948717948718
Epoch:  811        5 Batch loss: 0.172447 Batch F1: 0.7346938775510204
Epoch:  811        6 Batch loss: 0.192180 Batch F1: 0.5555555555555555
Epoch:  811        7 Batch loss: 0.146824 Batch F1: 0.7692307692307692
Epoch:  811        8 Batch loss: 0.192533 Batch F1: 0.7142857142857143
Epoch:  811        9 Batch loss: 0.170159 Batch F1: 0.75
Epoch:  811       10 Batch loss: 0.183476 Batch F1: 0.6363636363636365
Epoch:  811       11 Batch loss: 0.180012 Batch F1: 0.5945945945945946
Epoch:  811       12 Batch loss: 0.155811 Batch F1: 0.8292682926829269
Train Avg Loss  811: 0.170133

Train Avg F1  811: 0.7090078174623593

Val Avg Loss  811: 0.181454

Val Avg F1  811:  0.6681671790367443

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 812
--------------------------------------------------------------
Epoch:  812        1 Batch loss: 0.133687 Batch F1: 0.7567567567567567
Epoch:  812        2 Batch loss: 0.181750 Batch F1: 0.7457627118644068
Epoch:  812        3 Batch loss: 0.181887 Batch F1: 0.6956521739130435
Epoch:  812        4 Batch loss: 0.192121 Batch F1: 0.6521739130434783
Epoch:  812        5 Batch loss: 0.175026 Batch F1: 0.7142857142857143
Epoch:  812        6 Batch loss: 0.203457 Batch F1: 0.6190476190476191
Epoch:  812        7 Batch loss: 0.188580 Batch F1: 0.6842105263157896
Epoch:  812        8 Batch loss: 0.168228 Batch F1: 0.5517241379310345
Epoch:  812        9 Batch loss: 0.179789 Batch F1: 0.4615384615384615
Epoch:  812       10 Batch loss: 0.178810 Batch F1: 0.6666666666666667
Epoch:  812       11 Batch loss: 0.148327 Batch F1: 0.8571428571428571
Epoch:  812       12 Batch loss: 0.181597 Batch F1: 0.6666666666666667
Train Avg Loss  812: 0.176105

Train Avg F1  812: 0.6726356837643745

Val Avg Loss  812: 0.202196

Val Avg F1  812:  0.7956832627118644

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 813
--------------------------------------------------------------
Epoch:  813        1 Batch loss: 0.239001 Batch F1: 0.7241379310344828
Epoch:  813        2 Batch loss: 0.173255 Batch F1: 0.7999999999999999
Epoch:  813        3 Batch loss: 0.194204 Batch F1: 0.5833333333333334
Epoch:  813        4 Batch loss: 0.181794 Batch F1: 0.6938775510204083
Epoch:  813        5 Batch loss: 0.186509 Batch F1: 0.7058823529411765
Epoch:  813        6 Batch loss: 0.186152 Batch F1: 0.6222222222222222
Epoch:  813        7 Batch loss: 0.160593 Batch F1: 0.717948717948718
Epoch:  813        8 Batch loss: 0.177473 Batch F1: 0.6341463414634148
Epoch:  813        9 Batch loss: 0.183793 Batch F1: 0.76
Epoch:  813       10 Batch loss: 0.180044 Batch F1: 0.6153846153846153
Epoch:  813       11 Batch loss: 0.153680 Batch F1: 0.8
Epoch:  813       12 Batch loss: 0.154952 Batch F1: 0.888888888888889
Train Avg Loss  813: 0.180954

Train Avg F1  813: 0.7121518295197715

Val Avg Loss  813: 0.189210

Val Avg F1  813:  0.6727161431948665

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 814
--------------------------------------------------------------
Epoch:  814        1 Batch loss: 0.197183 Batch F1: 0.6666666666666666
Epoch:  814        2 Batch loss: 0.189278 Batch F1: 0.6530612244897959
Epoch:  814        3 Batch loss: 0.162756 Batch F1: 0.7659574468085107
Epoch:  814        4 Batch loss: 0.156863 Batch F1: 0.7777777777777778
Epoch:  814        5 Batch loss: 0.172844 Batch F1: 0.6153846153846154
Epoch:  814        6 Batch loss: 0.191596 Batch F1: 0.7555555555555555
Epoch:  814        7 Batch loss: 0.182310 Batch F1: 0.6976744186046512
Epoch:  814        8 Batch loss: 0.177216 Batch F1: 0.6818181818181818
Epoch:  814        9 Batch loss: 0.171809 Batch F1: 0.8070175438596492
Epoch:  814       10 Batch loss: 0.161319 Batch F1: 0.816326530612245
Epoch:  814       11 Batch loss: 0.177568 Batch F1: 0.6500000000000001
Epoch:  814       12 Batch loss: 0.200523 Batch F1: 0.631578947368421
Train Avg Loss  814: 0.178439

Train Avg F1  814: 0.7099015757455058

Val Avg Loss  814: 0.182955

Val Avg F1  814:  0.6796963824289405

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 815
--------------------------------------------------------------
Epoch:  815        1 Batch loss: 0.170150 Batch F1: 0.6285714285714287
Epoch:  815        2 Batch loss: 0.147572 Batch F1: 0.7368421052631577
Epoch:  815        3 Batch loss: 0.206971 Batch F1: 0.6122448979591836
Epoch:  815        4 Batch loss: 0.173008 Batch F1: 0.7777777777777778
Epoch:  815        5 Batch loss: 0.143525 Batch F1: 0.8518518518518519
Epoch:  815        6 Batch loss: 0.169450 Batch F1: 0.7391304347826085
Epoch:  815        7 Batch loss: 0.156602 Batch F1: 0.6829268292682927
Epoch:  815        8 Batch loss: 0.201229 Batch F1: 0.5957446808510639
Epoch:  815        9 Batch loss: 0.180015 Batch F1: 0.7441860465116279
Epoch:  815       10 Batch loss: 0.197104 Batch F1: 0.7058823529411765
Epoch:  815       11 Batch loss: 0.159519 Batch F1: 0.5714285714285714
Epoch:  815       12 Batch loss: 0.145189 Batch F1: 0.72
Train Avg Loss  815: 0.170861

Train Avg F1  815: 0.6972155814338951

Val Avg Loss  815: 0.186721

Val Avg F1  815:  0.7091351407389144

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 816
--------------------------------------------------------------
Epoch:  816        1 Batch loss: 0.181610 Batch F1: 0.7
Epoch:  816        2 Batch loss: 0.202660 Batch F1: 0.6666666666666667
Epoch:  816        3 Batch loss: 0.147156 Batch F1: 0.8260869565217391
Epoch:  816        4 Batch loss: 0.165752 Batch F1: 0.7499999999999999
Epoch:  816        5 Batch loss: 0.195776 Batch F1: 0.6382978723404256
Epoch:  816        6 Batch loss: 0.179248 Batch F1: 0.5294117647058824
Epoch:  816        7 Batch loss: 0.158306 Batch F1: 0.7826086956521738
Epoch:  816        8 Batch loss: 0.147128 Batch F1: 0.7222222222222222
Epoch:  816        9 Batch loss: 0.147808 Batch F1: 0.8163265306122449
Epoch:  816       10 Batch loss: 0.197478 Batch F1: 0.7540983606557378
Epoch:  816       11 Batch loss: 0.186075 Batch F1: 0.6842105263157895
Epoch:  816       12 Batch loss: 0.170930 Batch F1: 0.606060606060606
Train Avg Loss  816: 0.173327

Train Avg F1  816: 0.7063325168127906

Val Avg Loss  816: 0.180336

Val Avg F1  816:  0.6739998507239887

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 817
--------------------------------------------------------------
Epoch:  817        1 Batch loss: 0.167786 Batch F1: 0.6250000000000001
Epoch:  817        2 Batch loss: 0.139896 Batch F1: 0.7272727272727272
Epoch:  817        3 Batch loss: 0.154837 Batch F1: 0.717948717948718
Epoch:  817        4 Batch loss: 0.172410 Batch F1: 0.7659574468085107
Epoch:  817        5 Batch loss: 0.165536 Batch F1: 0.7843137254901961
Epoch:  817        6 Batch loss: 0.162045 Batch F1: 0.7027027027027027
Epoch:  817        7 Batch loss: 0.195090 Batch F1: 0.6222222222222222
Epoch:  817        8 Batch loss: 0.166073 Batch F1: 0.761904761904762
Epoch:  817        9 Batch loss: 0.188626 Batch F1: 0.6538461538461539
Epoch:  817       10 Batch loss: 0.202399 Batch F1: 0.5909090909090909
Epoch:  817       11 Batch loss: 0.193693 Batch F1: 0.7241379310344828
Epoch:  817       12 Batch loss: 0.143750 Batch F1: 0.8444444444444444
Train Avg Loss  817: 0.171012

Train Avg F1  817: 0.7100549937153343

Val Avg Loss  817: 0.181436

Val Avg F1  817:  0.6735646795543094

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 818
--------------------------------------------------------------
Epoch:  818        1 Batch loss: 0.160121 Batch F1: 0.7924528301886792
Epoch:  818        2 Batch loss: 0.180469 Batch F1: 0.5789473684210527
Epoch:  818        3 Batch loss: 0.154742 Batch F1: 0.8000000000000002
Epoch:  818        4 Batch loss: 0.177317 Batch F1: 0.6938775510204083
Epoch:  818        5 Batch loss: 0.181605 Batch F1: 0.6976744186046512
Epoch:  818        6 Batch loss: 0.169788 Batch F1: 0.7346938775510203
Epoch:  818        7 Batch loss: 0.164239 Batch F1: 0.6000000000000001
Epoch:  818        8 Batch loss: 0.175169 Batch F1: 0.7777777777777777
Epoch:  818        9 Batch loss: 0.138047 Batch F1: 0.8400000000000001
Epoch:  818       10 Batch loss: 0.204752 Batch F1: 0.6
Epoch:  818       11 Batch loss: 0.157703 Batch F1: 0.7804878048780488
Epoch:  818       12 Batch loss: 0.204523 Batch F1: 0.5263157894736842
Train Avg Loss  818: 0.172373

Train Avg F1  818: 0.7018522848262768

Val Avg Loss  818: 0.182026

Val Avg F1  818:  0.6706808333591527

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 819
--------------------------------------------------------------
Epoch:  819        1 Batch loss: 0.183667 Batch F1: 0.7058823529411765
Epoch:  819        2 Batch loss: 0.192961 Batch F1: 0.64
Epoch:  819        3 Batch loss: 0.170005 Batch F1: 0.6956521739130435
Epoch:  819        4 Batch loss: 0.165513 Batch F1: 0.7179487179487181
Epoch:  819        5 Batch loss: 0.179202 Batch F1: 0.744186046511628
Epoch:  819        6 Batch loss: 0.173295 Batch F1: 0.6976744186046512
Epoch:  819        7 Batch loss: 0.173334 Batch F1: 0.7857142857142857
Epoch:  819        8 Batch loss: 0.174400 Batch F1: 0.65
Epoch:  819        9 Batch loss: 0.179132 Batch F1: 0.65
Epoch:  819       10 Batch loss: 0.126689 Batch F1: 0.9047619047619048
Epoch:  819       11 Batch loss: 0.178050 Batch F1: 0.711111111111111
Epoch:  819       12 Batch loss: 0.215239 Batch F1: 0.6
Train Avg Loss  819: 0.175957

Train Avg F1  819: 0.7085775842922101

Val Avg Loss  819: 0.184677

Val Avg F1  819:  0.6786854005167959

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 820
--------------------------------------------------------------
Epoch:  820        1 Batch loss: 0.187116 Batch F1: 0.6511627906976744
Epoch:  820        2 Batch loss: 0.188239 Batch F1: 0.6938775510204083
Epoch:  820        3 Batch loss: 0.170259 Batch F1: 0.7659574468085107
Epoch:  820        4 Batch loss: 0.168691 Batch F1: 0.7234042553191489
Epoch:  820        5 Batch loss: 0.168725 Batch F1: 0.6976744186046512
Epoch:  820        6 Batch loss: 0.177606 Batch F1: 0.6956521739130435
Epoch:  820        7 Batch loss: 0.146076 Batch F1: 0.7804878048780488
Epoch:  820        8 Batch loss: 0.156951 Batch F1: 0.7755102040816326
Epoch:  820        9 Batch loss: 0.127272 Batch F1: 0.9166666666666666
Epoch:  820       10 Batch loss: 0.201309 Batch F1: 0.5714285714285714
Epoch:  820       11 Batch loss: 0.197698 Batch F1: 0.5853658536585366
Epoch:  820       12 Batch loss: 0.170735 Batch F1: 0.6206896551724138
Train Avg Loss  820: 0.171723

Train Avg F1  820: 0.7064897826874423

Val Avg Loss  820: 0.181446

Val Avg F1  820:  0.6651301459964202

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 821
--------------------------------------------------------------
Epoch:  821        1 Batch loss: 0.171381 Batch F1: 0.7777777777777778
Epoch:  821        2 Batch loss: 0.193087 Batch F1: 0.6530612244897959
Epoch:  821        3 Batch loss: 0.162361 Batch F1: 0.6470588235294118
Epoch:  821        4 Batch loss: 0.150251 Batch F1: 0.7692307692307692
Epoch:  821        5 Batch loss: 0.176385 Batch F1: 0.7346938775510204
Epoch:  821        6 Batch loss: 0.149714 Batch F1: 0.8
Epoch:  821        7 Batch loss: 0.164892 Batch F1: 0.711111111111111
Epoch:  821        8 Batch loss: 0.168502 Batch F1: 0.7441860465116279
Epoch:  821        9 Batch loss: 0.178384 Batch F1: 0.72
Epoch:  821       10 Batch loss: 0.140468 Batch F1: 0.8000000000000002
Epoch:  821       11 Batch loss: 0.182934 Batch F1: 0.5142857142857143
Epoch:  821       12 Batch loss: 0.198911 Batch F1: 0.6190476190476191
Train Avg Loss  821: 0.169773

Train Avg F1  821: 0.7075377469612372

Val Avg Loss  821: 0.183959

Val Avg F1  821:  0.6689575970334528

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 822
--------------------------------------------------------------
Epoch:  822        1 Batch loss: 0.180382 Batch F1: 0.6666666666666666
Epoch:  822        2 Batch loss: 0.144280 Batch F1: 0.6666666666666667
Epoch:  822        3 Batch loss: 0.176089 Batch F1: 0.7857142857142857
Epoch:  822        4 Batch loss: 0.171692 Batch F1: 0.723404255319149
Epoch:  822        5 Batch loss: 0.168351 Batch F1: 0.7272727272727272
Epoch:  822        6 Batch loss: 0.163085 Batch F1: 0.8148148148148148
Epoch:  822        7 Batch loss: 0.191795 Batch F1: 0.5714285714285714
Epoch:  822        8 Batch loss: 0.202893 Batch F1: 0.5
Epoch:  822        9 Batch loss: 0.149193 Batch F1: 0.8181818181818181
Epoch:  822       10 Batch loss: 0.179421 Batch F1: 0.6938775510204083
Epoch:  822       11 Batch loss: 0.166049 Batch F1: 0.7142857142857143
Epoch:  822       12 Batch loss: 0.155351 Batch F1: 0.7692307692307693
Train Avg Loss  822: 0.170715

Train Avg F1  822: 0.7042953200501326

Val Avg Loss  822: 0.182010

Val Avg F1  822:  0.6800737554573872

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 823
--------------------------------------------------------------
Epoch:  823        1 Batch loss: 0.176408 Batch F1: 0.6956521739130435
Epoch:  823        2 Batch loss: 0.149340 Batch F1: 0.75
Epoch:  823        3 Batch loss: 0.177995 Batch F1: 0.6829268292682926
Epoch:  823        4 Batch loss: 0.198027 Batch F1: 0.6122448979591838
Epoch:  823        5 Batch loss: 0.182012 Batch F1: 0.6666666666666666
Epoch:  823        6 Batch loss: 0.156235 Batch F1: 0.7692307692307692
Epoch:  823        7 Batch loss: 0.177617 Batch F1: 0.72
Epoch:  823        8 Batch loss: 0.194003 Batch F1: 0.5641025641025642
Epoch:  823        9 Batch loss: 0.142477 Batch F1: 0.8095238095238095
Epoch:  823       10 Batch loss: 0.177194 Batch F1: 0.7636363636363638
Epoch:  823       11 Batch loss: 0.170455 Batch F1: 0.7391304347826088
Epoch:  823       12 Batch loss: 0.140112 Batch F1: 0.7777777777777777
Train Avg Loss  823: 0.170156

Train Avg F1  823: 0.7125743572384232

Val Avg Loss  823: 0.183013

Val Avg F1  823:  0.6750111198325485

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 824
--------------------------------------------------------------
Epoch:  824        1 Batch loss: 0.163933 Batch F1: 0.6500000000000001
Epoch:  824        2 Batch loss: 0.183098 Batch F1: 0.723404255319149
Epoch:  824        3 Batch loss: 0.198929 Batch F1: 0.711864406779661
Epoch:  824        4 Batch loss: 0.174433 Batch F1: 0.6976744186046512
Epoch:  824        5 Batch loss: 0.161269 Batch F1: 0.6060606060606061
Epoch:  824        6 Batch loss: 0.178667 Batch F1: 0.6818181818181818
Epoch:  824        7 Batch loss: 0.156920 Batch F1: 0.8235294117647058
Epoch:  824        8 Batch loss: 0.185360 Batch F1: 0.6521739130434783
Epoch:  824        9 Batch loss: 0.160141 Batch F1: 0.7916666666666666
Epoch:  824       10 Batch loss: 0.159059 Batch F1: 0.7317073170731706
Epoch:  824       11 Batch loss: 0.142872 Batch F1: 0.7894736842105262
Epoch:  824       12 Batch loss: 0.183986 Batch F1: 0.6285714285714287
Train Avg Loss  824: 0.170722

Train Avg F1  824: 0.7073286908260189

Val Avg Loss  824: 0.181550

Val Avg F1  824:  0.6605386443621737

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 825
--------------------------------------------------------------
Epoch:  825        1 Batch loss: 0.167364 Batch F1: 0.6666666666666666
Epoch:  825        2 Batch loss: 0.186286 Batch F1: 0.7407407407407408
Epoch:  825        3 Batch loss: 0.197828 Batch F1: 0.5365853658536586
Epoch:  825        4 Batch loss: 0.155856 Batch F1: 0.7999999999999999
Epoch:  825        5 Batch loss: 0.134477 Batch F1: 0.8333333333333333
Epoch:  825        6 Batch loss: 0.161600 Batch F1: 0.7659574468085107
Epoch:  825        7 Batch loss: 0.152370 Batch F1: 0.7368421052631577
Epoch:  825        8 Batch loss: 0.167362 Batch F1: 0.7555555555555556
Epoch:  825        9 Batch loss: 0.175084 Batch F1: 0.6060606060606061
Epoch:  825       10 Batch loss: 0.171058 Batch F1: 0.6666666666666666
Epoch:  825       11 Batch loss: 0.172838 Batch F1: 0.7692307692307692
Epoch:  825       12 Batch loss: 0.192870 Batch F1: 0.5945945945945946
Train Avg Loss  825: 0.169583

Train Avg F1  825: 0.7060194875645216

Val Avg Loss  825: 0.180617

Val Avg F1  825:  0.667506616363534

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 826
--------------------------------------------------------------
Epoch:  826        1 Batch loss: 0.178190 Batch F1: 0.6666666666666666
Epoch:  826        2 Batch loss: 0.186932 Batch F1: 0.78125
Epoch:  826        3 Batch loss: 0.162436 Batch F1: 0.6666666666666667
Epoch:  826        4 Batch loss: 0.173624 Batch F1: 0.6808510638297872
Epoch:  826        5 Batch loss: 0.187162 Batch F1: 0.7111111111111111
Epoch:  826        6 Batch loss: 0.181720 Batch F1: 0.6666666666666666
Epoch:  826        7 Batch loss: 0.155850 Batch F1: 0.76
Epoch:  826        8 Batch loss: 0.157685 Batch F1: 0.7317073170731706
Epoch:  826        9 Batch loss: 0.178547 Batch F1: 0.6153846153846153
Epoch:  826       10 Batch loss: 0.155129 Batch F1: 0.6666666666666666
Epoch:  826       11 Batch loss: 0.133697 Batch F1: 0.8205128205128205
Epoch:  826       12 Batch loss: 0.171939 Batch F1: 0.7317073170731707
Train Avg Loss  826: 0.168576

Train Avg F1  826: 0.7082659093042785

Val Avg Loss  826: 0.180954

Val Avg F1  826:  0.6775636254114407

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 827
--------------------------------------------------------------
Epoch:  827        1 Batch loss: 0.147672 Batch F1: 0.6428571428571428
Epoch:  827        2 Batch loss: 0.155052 Batch F1: 0.7000000000000001
Epoch:  827        3 Batch loss: 0.142438 Batch F1: 0.888888888888889
Epoch:  827        4 Batch loss: 0.169158 Batch F1: 0.6842105263157895
Epoch:  827        5 Batch loss: 0.180035 Batch F1: 0.7346938775510204
Epoch:  827        6 Batch loss: 0.168516 Batch F1: 0.6976744186046512
Epoch:  827        7 Batch loss: 0.191363 Batch F1: 0.7272727272727273
Epoch:  827        8 Batch loss: 0.201292 Batch F1: 0.47058823529411764
Epoch:  827        9 Batch loss: 0.185803 Batch F1: 0.7142857142857142
Epoch:  827       10 Batch loss: 0.174271 Batch F1: 0.6976744186046512
Epoch:  827       11 Batch loss: 0.140498 Batch F1: 0.8461538461538461
Epoch:  827       12 Batch loss: 0.182038 Batch F1: 0.6857142857142857
Train Avg Loss  827: 0.169845

Train Avg F1  827: 0.7075011734619029

Val Avg Loss  827: 0.182028

Val Avg F1  827:  0.7504910438751772

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 828
--------------------------------------------------------------
Epoch:  828        1 Batch loss: 0.171263 Batch F1: 0.823529411764706
Epoch:  828        2 Batch loss: 0.209055 Batch F1: 0.6530612244897959
Epoch:  828        3 Batch loss: 0.141025 Batch F1: 0.8636363636363636
Epoch:  828        4 Batch loss: 0.218661 Batch F1: 0.5
Epoch:  828        5 Batch loss: 0.182194 Batch F1: 0.6666666666666666
Epoch:  828        6 Batch loss: 0.142241 Batch F1: 0.8181818181818182
Epoch:  828        7 Batch loss: 0.175568 Batch F1: 0.4666666666666667
Epoch:  828        8 Batch loss: 0.164441 Batch F1: 0.65
Epoch:  828        9 Batch loss: 0.167057 Batch F1: 0.7391304347826088
Epoch:  828       10 Batch loss: 0.185582 Batch F1: 0.6666666666666667
Epoch:  828       11 Batch loss: 0.185482 Batch F1: 0.6666666666666667
Epoch:  828       12 Batch loss: 0.162277 Batch F1: 0.8372093023255814
Train Avg Loss  828: 0.175404

Train Avg F1  828: 0.695951268487295

Val Avg Loss  828: 0.183797

Val Avg F1  828:  0.6724393107625661

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 829
--------------------------------------------------------------
Epoch:  829        1 Batch loss: 0.185943 Batch F1: 0.7272727272727272
Epoch:  829        2 Batch loss: 0.159267 Batch F1: 0.7999999999999999
Epoch:  829        3 Batch loss: 0.155658 Batch F1: 0.7906976744186046
Epoch:  829        4 Batch loss: 0.198917 Batch F1: 0.45714285714285713
Epoch:  829        5 Batch loss: 0.196542 Batch F1: 0.6666666666666666
Epoch:  829        6 Batch loss: 0.183985 Batch F1: 0.72
Epoch:  829        7 Batch loss: 0.169934 Batch F1: 0.7441860465116279
Epoch:  829        8 Batch loss: 0.163910 Batch F1: 0.7368421052631579
Epoch:  829        9 Batch loss: 0.172288 Batch F1: 0.6956521739130435
Epoch:  829       10 Batch loss: 0.171395 Batch F1: 0.6666666666666665
Epoch:  829       11 Batch loss: 0.196596 Batch F1: 0.75
Epoch:  829       12 Batch loss: 0.157780 Batch F1: 0.7567567567567567
Train Avg Loss  829: 0.176018

Train Avg F1  829: 0.7093236395510089

Val Avg Loss  829: 0.187847

Val Avg F1  829:  0.7511194666915005

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 830
--------------------------------------------------------------
Epoch:  830        1 Batch loss: 0.202787 Batch F1: 0.6956521739130435
Epoch:  830        2 Batch loss: 0.160281 Batch F1: 0.6818181818181819
Epoch:  830        3 Batch loss: 0.163976 Batch F1: 0.6956521739130435
Epoch:  830        4 Batch loss: 0.176741 Batch F1: 0.6829268292682926
Epoch:  830        5 Batch loss: 0.163483 Batch F1: 0.7755102040816326
Epoch:  830        6 Batch loss: 0.151266 Batch F1: 0.8095238095238095
Epoch:  830        7 Batch loss: 0.184871 Batch F1: 0.7419354838709677
Epoch:  830        8 Batch loss: 0.168425 Batch F1: 0.7547169811320756
Epoch:  830        9 Batch loss: 0.183096 Batch F1: 0.5641025641025641
Epoch:  830       10 Batch loss: 0.212996 Batch F1: 0.723404255319149
Epoch:  830       11 Batch loss: 0.222612 Batch F1: 0.7272727272727272
Epoch:  830       12 Batch loss: 0.164972 Batch F1: 0.6451612903225806
Train Avg Loss  830: 0.179625

Train Avg F1  830: 0.7081397228781724

Val Avg Loss  830: 0.185642

Val Avg F1  830:  0.6745212400973115

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 831
--------------------------------------------------------------
Epoch:  831        1 Batch loss: 0.182846 Batch F1: 0.6666666666666665
Epoch:  831        2 Batch loss: 0.153449 Batch F1: 0.8571428571428572
Epoch:  831        3 Batch loss: 0.172961 Batch F1: 0.7272727272727273
Epoch:  831        4 Batch loss: 0.191487 Batch F1: 0.7307692307692306
Epoch:  831        5 Batch loss: 0.178136 Batch F1: 0.7272727272727272
Epoch:  831        6 Batch loss: 0.162401 Batch F1: 0.7500000000000001
Epoch:  831        7 Batch loss: 0.163458 Batch F1: 0.9090909090909091
Epoch:  831        8 Batch loss: 0.236985 Batch F1: 0.7843137254901961
Epoch:  831        9 Batch loss: 0.181583 Batch F1: 0.6486486486486486
Epoch:  831       10 Batch loss: 0.168632 Batch F1: 0.7142857142857143
Epoch:  831       11 Batch loss: 0.162228 Batch F1: 0.41379310344827586
Epoch:  831       12 Batch loss: 0.197133 Batch F1: 0.6666666666666666
Train Avg Loss  831: 0.179275

Train Avg F1  831: 0.7163269147295517

Val Avg Loss  831: 0.194922

Val Avg F1  831:  0.6329522683436702

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 832
--------------------------------------------------------------
Epoch:  832        1 Batch loss: 0.202326 Batch F1: 0.6086956521739131
Epoch:  832        2 Batch loss: 0.193836 Batch F1: 0.7111111111111111
Epoch:  832        3 Batch loss: 0.191696 Batch F1: 0.7777777777777779
Epoch:  832        4 Batch loss: 0.186033 Batch F1: 0.7272727272727273
Epoch:  832        5 Batch loss: 0.174258 Batch F1: 0.7936507936507936
Epoch:  832        6 Batch loss: 0.168586 Batch F1: 0.8679245283018867
Epoch:  832        7 Batch loss: 0.177834 Batch F1: 0.8214285714285715
Epoch:  832        8 Batch loss: 0.188714 Batch F1: 0.5945945945945946
Epoch:  832        9 Batch loss: 0.192914 Batch F1: 0.631578947368421
Epoch:  832       10 Batch loss: 0.131856 Batch F1: 0.3333333333333333
Epoch:  832       11 Batch loss: 0.206946 Batch F1: 0.5405405405405406
Epoch:  832       12 Batch loss: 0.184987 Batch F1: 0.6
Train Avg Loss  832: 0.183332

Train Avg F1  832: 0.6673257147961392

Val Avg Loss  832: 0.193692

Val Avg F1  832:  0.6874527588813304

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 833
--------------------------------------------------------------
Epoch:  833        1 Batch loss: 0.168850 Batch F1: 0.7200000000000001
Epoch:  833        2 Batch loss: 0.214486 Batch F1: 0.42105263157894735
Epoch:  833        3 Batch loss: 0.190159 Batch F1: 0.7083333333333334
Epoch:  833        4 Batch loss: 0.195377 Batch F1: 0.7272727272727273
Epoch:  833        5 Batch loss: 0.172325 Batch F1: 0.7391304347826089
Epoch:  833        6 Batch loss: 0.182278 Batch F1: 0.6956521739130435
Epoch:  833        7 Batch loss: 0.175490 Batch F1: 0.7058823529411765
Epoch:  833        8 Batch loss: 0.163399 Batch F1: 0.75
Epoch:  833        9 Batch loss: 0.185760 Batch F1: 0.7083333333333334
Epoch:  833       10 Batch loss: 0.166694 Batch F1: 0.7916666666666666
Epoch:  833       11 Batch loss: 0.149384 Batch F1: 0.7567567567567567
Epoch:  833       12 Batch loss: 0.190752 Batch F1: 0.6829268292682927
Train Avg Loss  833: 0.179580

Train Avg F1  833: 0.7005839366539073

Val Avg Loss  833: 0.184488

Val Avg F1  833:  0.6635190701503569

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 834
--------------------------------------------------------------
Epoch:  834        1 Batch loss: 0.159242 Batch F1: 0.7317073170731708
Epoch:  834        2 Batch loss: 0.191439 Batch F1: 0.65
Epoch:  834        3 Batch loss: 0.184164 Batch F1: 0.7234042553191491
Epoch:  834        4 Batch loss: 0.175239 Batch F1: 0.7234042553191491
Epoch:  834        5 Batch loss: 0.149639 Batch F1: 0.7804878048780488
Epoch:  834        6 Batch loss: 0.168421 Batch F1: 0.7391304347826088
Epoch:  834        7 Batch loss: 0.132961 Batch F1: 0.8636363636363636
Epoch:  834        8 Batch loss: 0.165305 Batch F1: 0.7272727272727272
Epoch:  834        9 Batch loss: 0.208992 Batch F1: 0.5581395348837208
Epoch:  834       10 Batch loss: 0.183503 Batch F1: 0.631578947368421
Epoch:  834       11 Batch loss: 0.178510 Batch F1: 0.7058823529411765
Epoch:  834       12 Batch loss: 0.179824 Batch F1: 0.6976744186046512
Train Avg Loss  834: 0.173103

Train Avg F1  834: 0.7110265343399322

Val Avg Loss  834: 0.181949

Val Avg F1  834:  0.662207105064248

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 835
--------------------------------------------------------------
Epoch:  835        1 Batch loss: 0.165858 Batch F1: 0.711111111111111
Epoch:  835        2 Batch loss: 0.157739 Batch F1: 0.7391304347826088
Epoch:  835        3 Batch loss: 0.189355 Batch F1: 0.6909090909090909
Epoch:  835        4 Batch loss: 0.145671 Batch F1: 0.7804878048780488
Epoch:  835        5 Batch loss: 0.191399 Batch F1: 0.6046511627906977
Epoch:  835        6 Batch loss: 0.144456 Batch F1: 0.8205128205128205
Epoch:  835        7 Batch loss: 0.159254 Batch F1: 0.7
Epoch:  835        8 Batch loss: 0.171204 Batch F1: 0.65
Epoch:  835        9 Batch loss: 0.177815 Batch F1: 0.7142857142857143
Epoch:  835       10 Batch loss: 0.173783 Batch F1: 0.76
Epoch:  835       11 Batch loss: 0.162597 Batch F1: 0.7441860465116279
Epoch:  835       12 Batch loss: 0.204063 Batch F1: 0.6341463414634148
Train Avg Loss  835: 0.170266

Train Avg F1  835: 0.7124517106037613

Val Avg Loss  835: 0.181131

Val Avg F1  835:  0.6655804367201426

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 836
--------------------------------------------------------------
Epoch:  836        1 Batch loss: 0.172738 Batch F1: 0.6
Epoch:  836        2 Batch loss: 0.187986 Batch F1: 0.6818181818181818
Epoch:  836        3 Batch loss: 0.168251 Batch F1: 0.7692307692307693
Epoch:  836        4 Batch loss: 0.173171 Batch F1: 0.631578947368421
Epoch:  836        5 Batch loss: 0.162217 Batch F1: 0.7272727272727272
Epoch:  836        6 Batch loss: 0.161679 Batch F1: 0.7441860465116279
Epoch:  836        7 Batch loss: 0.174054 Batch F1: 0.7391304347826089
Epoch:  836        8 Batch loss: 0.174735 Batch F1: 0.65
Epoch:  836        9 Batch loss: 0.179399 Batch F1: 0.6511627906976745
Epoch:  836       10 Batch loss: 0.135160 Batch F1: 0.7999999999999999
Epoch:  836       11 Batch loss: 0.181694 Batch F1: 0.7272727272727272
Epoch:  836       12 Batch loss: 0.158132 Batch F1: 0.8181818181818182
Train Avg Loss  836: 0.169101

Train Avg F1  836: 0.7116528702613797

Val Avg Loss  836: 0.181598

Val Avg F1  836:  0.6623626373626375

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 837
--------------------------------------------------------------
Epoch:  837        1 Batch loss: 0.183133 Batch F1: 0.6818181818181819
Epoch:  837        2 Batch loss: 0.159190 Batch F1: 0.7441860465116279
Epoch:  837        3 Batch loss: 0.150365 Batch F1: 0.830188679245283
Epoch:  837        4 Batch loss: 0.191009 Batch F1: 0.6382978723404256
Epoch:  837        5 Batch loss: 0.172493 Batch F1: 0.6341463414634148
Epoch:  837        6 Batch loss: 0.167643 Batch F1: 0.7272727272727272
Epoch:  837        7 Batch loss: 0.170141 Batch F1: 0.7450980392156864
Epoch:  837        8 Batch loss: 0.169143 Batch F1: 0.7234042553191491
Epoch:  837        9 Batch loss: 0.195625 Batch F1: 0.5500000000000002
Epoch:  837       10 Batch loss: 0.149367 Batch F1: 0.7567567567567567
Epoch:  837       11 Batch loss: 0.160183 Batch F1: 0.7500000000000001
Epoch:  837       12 Batch loss: 0.158331 Batch F1: 0.7567567567567567
Train Avg Loss  837: 0.168885

Train Avg F1  837: 0.7114938047250008

Val Avg Loss  837: 0.180791

Val Avg F1  837:  0.6707567809732589

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 838
--------------------------------------------------------------
Epoch:  838        1 Batch loss: 0.165563 Batch F1: 0.717948717948718
Epoch:  838        2 Batch loss: 0.149467 Batch F1: 0.8
Epoch:  838        3 Batch loss: 0.153660 Batch F1: 0.7
Epoch:  838        4 Batch loss: 0.169725 Batch F1: 0.6829268292682926
Epoch:  838        5 Batch loss: 0.190147 Batch F1: 0.6808510638297872
Epoch:  838        6 Batch loss: 0.201784 Batch F1: 0.5
Epoch:  838        7 Batch loss: 0.156481 Batch F1: 0.6285714285714286
Epoch:  838        8 Batch loss: 0.190192 Batch F1: 0.6222222222222223
Epoch:  838        9 Batch loss: 0.150116 Batch F1: 0.870967741935484
Epoch:  838       10 Batch loss: 0.160334 Batch F1: 0.7924528301886793
Epoch:  838       11 Batch loss: 0.157982 Batch F1: 0.761904761904762
Epoch:  838       12 Batch loss: 0.178012 Batch F1: 0.6470588235294118
Train Avg Loss  838: 0.168622

Train Avg F1  838: 0.7004087016165655

Val Avg Loss  838: 0.180833

Val Avg F1  838:  0.6768397955744482

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 839
--------------------------------------------------------------
Epoch:  839        1 Batch loss: 0.171835 Batch F1: 0.6808510638297872
Epoch:  839        2 Batch loss: 0.157783 Batch F1: 0.7727272727272727
Epoch:  839        3 Batch loss: 0.161682 Batch F1: 0.7499999999999999
Epoch:  839        4 Batch loss: 0.190578 Batch F1: 0.5789473684210527
Epoch:  839        5 Batch loss: 0.161810 Batch F1: 0.7272727272727272
Epoch:  839        6 Batch loss: 0.167322 Batch F1: 0.7391304347826088
Epoch:  839        7 Batch loss: 0.176610 Batch F1: 0.6956521739130435
Epoch:  839        8 Batch loss: 0.197500 Batch F1: 0.5128205128205129
Epoch:  839        9 Batch loss: 0.175654 Batch F1: 0.6956521739130435
Epoch:  839       10 Batch loss: 0.137329 Batch F1: 0.8205128205128205
Epoch:  839       11 Batch loss: 0.153277 Batch F1: 0.7916666666666666
Epoch:  839       12 Batch loss: 0.164495 Batch F1: 0.7499999999999999
Train Avg Loss  839: 0.167990

Train Avg F1  839: 0.7096027679049612

Val Avg Loss  839: 0.180923

Val Avg F1  839:  0.6658400985987193

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 840
--------------------------------------------------------------
Epoch:  840        1 Batch loss: 0.165980 Batch F1: 0.723404255319149
Epoch:  840        2 Batch loss: 0.174410 Batch F1: 0.6666666666666666
Epoch:  840        3 Batch loss: 0.176539 Batch F1: 0.7547169811320754
Epoch:  840        4 Batch loss: 0.165428 Batch F1: 0.65
Epoch:  840        5 Batch loss: 0.169464 Batch F1: 0.717948717948718
Epoch:  840        6 Batch loss: 0.164130 Batch F1: 0.7317073170731708
Epoch:  840        7 Batch loss: 0.162054 Batch F1: 0.7555555555555555
Epoch:  840        8 Batch loss: 0.160859 Batch F1: 0.6829268292682927
Epoch:  840        9 Batch loss: 0.193625 Batch F1: 0.68
Epoch:  840       10 Batch loss: 0.169885 Batch F1: 0.6511627906976745
Epoch:  840       11 Batch loss: 0.165630 Batch F1: 0.7924528301886792
Epoch:  840       12 Batch loss: 0.154198 Batch F1: 0.7333333333333334
Train Avg Loss  840: 0.168517

Train Avg F1  840: 0.7116562730986096

Val Avg Loss  840: 0.181373

Val Avg F1  840:  0.6675617615467239

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 841
--------------------------------------------------------------
Epoch:  841        1 Batch loss: 0.172791 Batch F1: 0.7111111111111111
Epoch:  841        2 Batch loss: 0.133864 Batch F1: 0.896551724137931
Epoch:  841        3 Batch loss: 0.198355 Batch F1: 0.5
Epoch:  841        4 Batch loss: 0.175513 Batch F1: 0.6808510638297872
Epoch:  841        5 Batch loss: 0.171181 Batch F1: 0.7659574468085107
Epoch:  841        6 Batch loss: 0.186500 Batch F1: 0.7169811320754718
Epoch:  841        7 Batch loss: 0.173654 Batch F1: 0.7000000000000001
Epoch:  841        8 Batch loss: 0.182081 Batch F1: 0.6829268292682927
Epoch:  841        9 Batch loss: 0.153668 Batch F1: 0.7755102040816326
Epoch:  841       10 Batch loss: 0.150222 Batch F1: 0.7027027027027027
Epoch:  841       11 Batch loss: 0.193312 Batch F1: 0.5714285714285713
Epoch:  841       12 Batch loss: 0.137812 Batch F1: 0.7333333333333334
Train Avg Loss  841: 0.169079

Train Avg F1  841: 0.7031128432314454

Val Avg Loss  841: 0.180983

Val Avg F1  841:  0.6766269841269841

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 842
--------------------------------------------------------------
Epoch:  842        1 Batch loss: 0.179438 Batch F1: 0.65
Epoch:  842        2 Batch loss: 0.152389 Batch F1: 0.761904761904762
Epoch:  842        3 Batch loss: 0.154933 Batch F1: 0.7555555555555555
Epoch:  842        4 Batch loss: 0.178772 Batch F1: 0.6500000000000001
Epoch:  842        5 Batch loss: 0.180322 Batch F1: 0.631578947368421
Epoch:  842        6 Batch loss: 0.139093 Batch F1: 0.7058823529411764
Epoch:  842        7 Batch loss: 0.199617 Batch F1: 0.711864406779661
Epoch:  842        8 Batch loss: 0.169054 Batch F1: 0.8000000000000002
Epoch:  842        9 Batch loss: 0.190710 Batch F1: 0.6111111111111112
Epoch:  842       10 Batch loss: 0.184571 Batch F1: 0.7083333333333334
Epoch:  842       11 Batch loss: 0.177716 Batch F1: 0.7307692307692307
Epoch:  842       12 Batch loss: 0.144784 Batch F1: 0.7741935483870969
Train Avg Loss  842: 0.170950

Train Avg F1  842: 0.7075994373458623

Val Avg Loss  842: 0.182081

Val Avg F1  842:  0.6765450366192989

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 843
--------------------------------------------------------------
Epoch:  843        1 Batch loss: 0.173125 Batch F1: 0.7
Epoch:  843        2 Batch loss: 0.174087 Batch F1: 0.7719298245614036
Epoch:  843        3 Batch loss: 0.163472 Batch F1: 0.7659574468085107
Epoch:  843        4 Batch loss: 0.181741 Batch F1: 0.6341463414634146
Epoch:  843        5 Batch loss: 0.157885 Batch F1: 0.7826086956521738
Epoch:  843        6 Batch loss: 0.168656 Batch F1: 0.7857142857142856
Epoch:  843        7 Batch loss: 0.192686 Batch F1: 0.5500000000000002
Epoch:  843        8 Batch loss: 0.165968 Batch F1: 0.65
Epoch:  843        9 Batch loss: 0.166415 Batch F1: 0.6956521739130435
Epoch:  843       10 Batch loss: 0.181891 Batch F1: 0.6341463414634148
Epoch:  843       11 Batch loss: 0.159226 Batch F1: 0.7804878048780488
Epoch:  843       12 Batch loss: 0.152368 Batch F1: 0.7333333333333334
Train Avg Loss  843: 0.169793

Train Avg F1  843: 0.7069980206489691

Val Avg Loss  843: 0.181769

Val Avg F1  843:  0.6755580880068788

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 844
--------------------------------------------------------------
Epoch:  844        1 Batch loss: 0.156612 Batch F1: 0.7441860465116279
Epoch:  844        2 Batch loss: 0.183259 Batch F1: 0.6521739130434783
Epoch:  844        3 Batch loss: 0.189778 Batch F1: 0.6046511627906977
Epoch:  844        4 Batch loss: 0.183381 Batch F1: 0.6818181818181819
Epoch:  844        5 Batch loss: 0.170781 Batch F1: 0.7391304347826088
Epoch:  844        6 Batch loss: 0.147842 Batch F1: 0.75
Epoch:  844        7 Batch loss: 0.161118 Batch F1: 0.7142857142857143
Epoch:  844        8 Batch loss: 0.176047 Batch F1: 0.7499999999999999
Epoch:  844        9 Batch loss: 0.164484 Batch F1: 0.7450980392156864
Epoch:  844       10 Batch loss: 0.170312 Batch F1: 0.7272727272727272
Epoch:  844       11 Batch loss: 0.171587 Batch F1: 0.711111111111111
Epoch:  844       12 Batch loss: 0.135747 Batch F1: 0.7499999999999999
Train Avg Loss  844: 0.167579

Train Avg F1  844: 0.7141439442359862

Val Avg Loss  844: 0.179877

Val Avg F1  844:  0.6792273613326245

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 845
--------------------------------------------------------------
Epoch:  845        1 Batch loss: 0.152010 Batch F1: 0.8095238095238095
Epoch:  845        2 Batch loss: 0.164304 Batch F1: 0.7272727272727273
Epoch:  845        3 Batch loss: 0.162166 Batch F1: 0.7368421052631579
Epoch:  845        4 Batch loss: 0.179136 Batch F1: 0.6222222222222223
Epoch:  845        5 Batch loss: 0.184566 Batch F1: 0.6666666666666667
Epoch:  845        6 Batch loss: 0.153644 Batch F1: 0.7555555555555556
Epoch:  845        7 Batch loss: 0.184117 Batch F1: 0.4444444444444444
Epoch:  845        8 Batch loss: 0.179335 Batch F1: 0.7272727272727272
Epoch:  845        9 Batch loss: 0.203189 Batch F1: 0.6808510638297872
Epoch:  845       10 Batch loss: 0.154482 Batch F1: 0.7346938775510204
Epoch:  845       11 Batch loss: 0.194592 Batch F1: 0.7826086956521738
Epoch:  845       12 Batch loss: 0.189907 Batch F1: 0.761904761904762
Train Avg Loss  845: 0.175121

Train Avg F1  845: 0.7041548880965879

Val Avg Loss  845: 0.184681

Val Avg F1  845:  0.6719053999406429

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 846
--------------------------------------------------------------
Epoch:  846        1 Batch loss: 0.191999 Batch F1: 0.6
Epoch:  846        2 Batch loss: 0.162320 Batch F1: 0.7368421052631577
Epoch:  846        3 Batch loss: 0.190091 Batch F1: 0.631578947368421
Epoch:  846        4 Batch loss: 0.161965 Batch F1: 0.7441860465116279
Epoch:  846        5 Batch loss: 0.157078 Batch F1: 0.8571428571428572
Epoch:  846        6 Batch loss: 0.221988 Batch F1: 0.5714285714285714
Epoch:  846        7 Batch loss: 0.200064 Batch F1: 0.6923076923076923
Epoch:  846        8 Batch loss: 0.175813 Batch F1: 0.6666666666666666
Epoch:  846        9 Batch loss: 0.186022 Batch F1: 0.72
Epoch:  846       10 Batch loss: 0.195238 Batch F1: 0.6923076923076923
Epoch:  846       11 Batch loss: 0.150358 Batch F1: 0.8260869565217391
Epoch:  846       12 Batch loss: 0.133424 Batch F1: 0.7647058823529411
Train Avg Loss  846: 0.177197

Train Avg F1  846: 0.7086044514892805

Val Avg Loss  846: 0.191883

Val Avg F1  846:  0.6359990217657129

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 847
--------------------------------------------------------------
Epoch:  847        1 Batch loss: 0.205925 Batch F1: 0.6666666666666666
Epoch:  847        2 Batch loss: 0.140149 Batch F1: 0.7999999999999999
Epoch:  847        3 Batch loss: 0.189025 Batch F1: 0.7241379310344828
Epoch:  847        4 Batch loss: 0.173026 Batch F1: 0.7457627118644068
Epoch:  847        5 Batch loss: 0.239449 Batch F1: 0.5128205128205129
Epoch:  847        6 Batch loss: 0.156670 Batch F1: 0.711111111111111
Epoch:  847        7 Batch loss: 0.152125 Batch F1: 0.8000000000000002
Epoch:  847        8 Batch loss: 0.176525 Batch F1: 0.723404255319149
Epoch:  847        9 Batch loss: 0.153091 Batch F1: 0.7692307692307692
Epoch:  847       10 Batch loss: 0.193775 Batch F1: 0.6222222222222222
Epoch:  847       11 Batch loss: 0.165368 Batch F1: 0.7499999999999999
Epoch:  847       12 Batch loss: 0.173435 Batch F1: 0.5925925925925927
Train Avg Loss  847: 0.176547

Train Avg F1  847: 0.7014957310718262

Val Avg Loss  847: 0.193360

Val Avg F1  847:  0.5698309626881055

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 848
--------------------------------------------------------------
Epoch:  848        1 Batch loss: 0.196787 Batch F1: 0.5454545454545454
Epoch:  848        2 Batch loss: 0.200329 Batch F1: 0.5500000000000002
Epoch:  848        3 Batch loss: 0.185717 Batch F1: 0.6341463414634146
Epoch:  848        4 Batch loss: 0.155248 Batch F1: 0.7317073170731708
Epoch:  848        5 Batch loss: 0.165905 Batch F1: 0.7826086956521738
Epoch:  848        6 Batch loss: 0.183102 Batch F1: 0.65
Epoch:  848        7 Batch loss: 0.176698 Batch F1: 0.7111111111111111
Epoch:  848        8 Batch loss: 0.186725 Batch F1: 0.7234042553191491
Epoch:  848        9 Batch loss: 0.160085 Batch F1: 0.7500000000000001
Epoch:  848       10 Batch loss: 0.169355 Batch F1: 0.7499999999999999
Epoch:  848       11 Batch loss: 0.155645 Batch F1: 0.7567567567567567
Epoch:  848       12 Batch loss: 0.191590 Batch F1: 0.7500000000000001
Train Avg Loss  848: 0.177266

Train Avg F1  848: 0.6945990852358602

Val Avg Loss  848: 0.185840

Val Avg F1  848:  0.6744444444444444

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 849
--------------------------------------------------------------
Epoch:  849        1 Batch loss: 0.195197 Batch F1: 0.6666666666666666
Epoch:  849        2 Batch loss: 0.144231 Batch F1: 0.8085106382978724
Epoch:  849        3 Batch loss: 0.213212 Batch F1: 0.5365853658536586
Epoch:  849        4 Batch loss: 0.170457 Batch F1: 0.631578947368421
Epoch:  849        5 Batch loss: 0.166690 Batch F1: 0.6818181818181818
Epoch:  849        6 Batch loss: 0.156775 Batch F1: 0.782608695652174
Epoch:  849        7 Batch loss: 0.151907 Batch F1: 0.7027027027027027
Epoch:  849        8 Batch loss: 0.165941 Batch F1: 0.7555555555555556
Epoch:  849        9 Batch loss: 0.167016 Batch F1: 0.6976744186046512
Epoch:  849       10 Batch loss: 0.169879 Batch F1: 0.7755102040816326
Epoch:  849       11 Batch loss: 0.176684 Batch F1: 0.7450980392156864
Epoch:  849       12 Batch loss: 0.170349 Batch F1: 0.7222222222222223
Train Avg Loss  849: 0.170695

Train Avg F1  849: 0.7088776365032854

Val Avg Loss  849: 0.180744

Val Avg F1  849:  0.6777777777777778

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 850
--------------------------------------------------------------
Epoch:  850        1 Batch loss: 0.151055 Batch F1: 0.7906976744186046
Epoch:  850        2 Batch loss: 0.171642 Batch F1: 0.6666666666666667
Epoch:  850        3 Batch loss: 0.180971 Batch F1: 0.5
Epoch:  850        4 Batch loss: 0.168460 Batch F1: 0.7692307692307693
Epoch:  850        5 Batch loss: 0.182921 Batch F1: 0.7
Epoch:  850        6 Batch loss: 0.197682 Batch F1: 0.6341463414634146
Epoch:  850        7 Batch loss: 0.184566 Batch F1: 0.75
Epoch:  850        8 Batch loss: 0.149494 Batch F1: 0.7368421052631579
Epoch:  850        9 Batch loss: 0.183405 Batch F1: 0.7391304347826088
Epoch:  850       10 Batch loss: 0.167619 Batch F1: 0.6938775510204083
Epoch:  850       11 Batch loss: 0.182265 Batch F1: 0.7234042553191491
Epoch:  850       12 Batch loss: 0.179572 Batch F1: 0.6666666666666667
Train Avg Loss  850: 0.174971

Train Avg F1  850: 0.6975552054026205

Val Avg Loss  850: 0.186170

Val Avg F1  850:  0.67884803165793

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 851
--------------------------------------------------------------
Epoch:  851        1 Batch loss: 0.169346 Batch F1: 0.75
Epoch:  851        2 Batch loss: 0.170429 Batch F1: 0.7391304347826088
Epoch:  851        3 Batch loss: 0.181173 Batch F1: 0.6666666666666666
Epoch:  851        4 Batch loss: 0.161327 Batch F1: 0.7317073170731707
Epoch:  851        5 Batch loss: 0.200551 Batch F1: 0.6666666666666666
Epoch:  851        6 Batch loss: 0.154941 Batch F1: 0.8181818181818182
Epoch:  851        7 Batch loss: 0.180233 Batch F1: 0.6153846153846153
Epoch:  851        8 Batch loss: 0.190163 Batch F1: 0.6521739130434783
Epoch:  851        9 Batch loss: 0.160166 Batch F1: 0.7916666666666667
Epoch:  851       10 Batch loss: 0.185384 Batch F1: 0.6511627906976744
Epoch:  851       11 Batch loss: 0.168120 Batch F1: 0.7
Epoch:  851       12 Batch loss: 0.173945 Batch F1: 0.7500000000000001
Train Avg Loss  851: 0.174648

Train Avg F1  851: 0.7110617407636138

Val Avg Loss  851: 0.183110

Val Avg F1  851:  0.6760977118119975

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 852
--------------------------------------------------------------
Epoch:  852        1 Batch loss: 0.167640 Batch F1: 0.7999999999999999
Epoch:  852        2 Batch loss: 0.161942 Batch F1: 0.7441860465116279
Epoch:  852        3 Batch loss: 0.186936 Batch F1: 0.6222222222222222
Epoch:  852        4 Batch loss: 0.165659 Batch F1: 0.7272727272727273
Epoch:  852        5 Batch loss: 0.133730 Batch F1: 0.8333333333333334
Epoch:  852        6 Batch loss: 0.137965 Batch F1: 0.742857142857143
Epoch:  852        7 Batch loss: 0.180500 Batch F1: 0.6808510638297872
Epoch:  852        8 Batch loss: 0.201315 Batch F1: 0.5555555555555556
Epoch:  852        9 Batch loss: 0.139430 Batch F1: 0.8510638297872342
Epoch:  852       10 Batch loss: 0.187408 Batch F1: 0.6666666666666666
Epoch:  852       11 Batch loss: 0.202040 Batch F1: 0.64
Epoch:  852       12 Batch loss: 0.192016 Batch F1: 0.6818181818181819
Train Avg Loss  852: 0.171382

Train Avg F1  852: 0.7121522308212067

Val Avg Loss  852: 0.182132

Val Avg F1  852:  0.6683760683760683

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 853
--------------------------------------------------------------
Epoch:  853        1 Batch loss: 0.177767 Batch F1: 0.6808510638297872
Epoch:  853        2 Batch loss: 0.159524 Batch F1: 0.7777777777777778
Epoch:  853        3 Batch loss: 0.202801 Batch F1: 0.6530612244897959
Epoch:  853        4 Batch loss: 0.186372 Batch F1: 0.6938775510204083
Epoch:  853        5 Batch loss: 0.158833 Batch F1: 0.7727272727272727
Epoch:  853        6 Batch loss: 0.175788 Batch F1: 0.7450980392156864
Epoch:  853        7 Batch loss: 0.158513 Batch F1: 0.5517241379310345
Epoch:  853        8 Batch loss: 0.174891 Batch F1: 0.7499999999999999
Epoch:  853        9 Batch loss: 0.155126 Batch F1: 0.76
Epoch:  853       10 Batch loss: 0.168645 Batch F1: 0.6956521739130435
Epoch:  853       11 Batch loss: 0.178028 Batch F1: 0.76
Epoch:  853       12 Batch loss: 0.186114 Batch F1: 0.6153846153846153
Train Avg Loss  853: 0.173533

Train Avg F1  853: 0.7046794880241184

Val Avg Loss  853: 0.183689

Val Avg F1  853:  0.6781060606060605

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 854
--------------------------------------------------------------
Epoch:  854        1 Batch loss: 0.161534 Batch F1: 0.7555555555555555
Epoch:  854        2 Batch loss: 0.205655 Batch F1: 0.6399999999999999
Epoch:  854        3 Batch loss: 0.129832 Batch F1: 0.6923076923076924
Epoch:  854        4 Batch loss: 0.184160 Batch F1: 0.7407407407407408
Epoch:  854        5 Batch loss: 0.187940 Batch F1: 0.6808510638297872
Epoch:  854        6 Batch loss: 0.175597 Batch F1: 0.72
Epoch:  854        7 Batch loss: 0.144719 Batch F1: 0.7222222222222222
Epoch:  854        8 Batch loss: 0.179518 Batch F1: 0.6956521739130435
Epoch:  854        9 Batch loss: 0.174316 Batch F1: 0.7547169811320754
Epoch:  854       10 Batch loss: 0.185980 Batch F1: 0.5789473684210527
Epoch:  854       11 Batch loss: 0.166987 Batch F1: 0.7317073170731706
Epoch:  854       12 Batch loss: 0.153848 Batch F1: 0.8205128205128205
Train Avg Loss  854: 0.170841

Train Avg F1  854: 0.7111011613090135

Val Avg Loss  854: 0.183777

Val Avg F1  854:  0.6744851372764777

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 855
--------------------------------------------------------------
Epoch:  855        1 Batch loss: 0.165167 Batch F1: 0.7924528301886792
Epoch:  855        2 Batch loss: 0.175274 Batch F1: 0.7692307692307692
Epoch:  855        3 Batch loss: 0.132150 Batch F1: 0.8444444444444444
Epoch:  855        4 Batch loss: 0.200155 Batch F1: 0.6
Epoch:  855        5 Batch loss: 0.150309 Batch F1: 0.7441860465116279
Epoch:  855        6 Batch loss: 0.199763 Batch F1: 0.5714285714285715
Epoch:  855        7 Batch loss: 0.182076 Batch F1: 0.6808510638297872
Epoch:  855        8 Batch loss: 0.151369 Batch F1: 0.8076923076923077
Epoch:  855        9 Batch loss: 0.175601 Batch F1: 0.7142857142857143
Epoch:  855       10 Batch loss: 0.155131 Batch F1: 0.6666666666666667
Epoch:  855       11 Batch loss: 0.187412 Batch F1: 0.5789473684210527
Epoch:  855       12 Batch loss: 0.166075 Batch F1: 0.6857142857142857
Train Avg Loss  855: 0.170040

Train Avg F1  855: 0.7046583390344922

Val Avg Loss  855: 0.181996

Val Avg F1  855:  0.6797727272727272

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 856
--------------------------------------------------------------
Epoch:  856        1 Batch loss: 0.199700 Batch F1: 0.5714285714285713
Epoch:  856        2 Batch loss: 0.136537 Batch F1: 0.8205128205128205
Epoch:  856        3 Batch loss: 0.167027 Batch F1: 0.75
Epoch:  856        4 Batch loss: 0.158112 Batch F1: 0.7441860465116279
Epoch:  856        5 Batch loss: 0.168612 Batch F1: 0.76
Epoch:  856        6 Batch loss: 0.171918 Batch F1: 0.7391304347826085
Epoch:  856        7 Batch loss: 0.170124 Batch F1: 0.7391304347826088
Epoch:  856        8 Batch loss: 0.200157 Batch F1: 0.6538461538461539
Epoch:  856        9 Batch loss: 0.180453 Batch F1: 0.6046511627906976
Epoch:  856       10 Batch loss: 0.156731 Batch F1: 0.7826086956521738
Epoch:  856       11 Batch loss: 0.153495 Batch F1: 0.7027027027027027
Epoch:  856       12 Batch loss: 0.180716 Batch F1: 0.6666666666666667
Train Avg Loss  856: 0.170299

Train Avg F1  856: 0.711238640806386

Val Avg Loss  856: 0.180642

Val Avg F1  856:  0.6784707540521494

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 857
--------------------------------------------------------------
Epoch:  857        1 Batch loss: 0.160349 Batch F1: 0.7368421052631577
Epoch:  857        2 Batch loss: 0.152640 Batch F1: 0.8076923076923077
Epoch:  857        3 Batch loss: 0.178132 Batch F1: 0.65
Epoch:  857        4 Batch loss: 0.153619 Batch F1: 0.7727272727272727
Epoch:  857        5 Batch loss: 0.186141 Batch F1: 0.6666666666666666
Epoch:  857        6 Batch loss: 0.172557 Batch F1: 0.7636363636363638
Epoch:  857        7 Batch loss: 0.158016 Batch F1: 0.7500000000000001
Epoch:  857        8 Batch loss: 0.163344 Batch F1: 0.7142857142857143
Epoch:  857        9 Batch loss: 0.153079 Batch F1: 0.6470588235294117
Epoch:  857       10 Batch loss: 0.204887 Batch F1: 0.5777777777777778
Epoch:  857       11 Batch loss: 0.177601 Batch F1: 0.7450980392156864
Epoch:  857       12 Batch loss: 0.164595 Batch F1: 0.6857142857142857
Train Avg Loss  857: 0.168747

Train Avg F1  857: 0.709791613042387

Val Avg Loss  857: 0.181424

Val Avg F1  857:  0.6698420359806934

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 858
--------------------------------------------------------------
Epoch:  858        1 Batch loss: 0.145970 Batch F1: 0.8085106382978724
Epoch:  858        2 Batch loss: 0.179985 Batch F1: 0.6
Epoch:  858        3 Batch loss: 0.149498 Batch F1: 0.7916666666666667
Epoch:  858        4 Batch loss: 0.205368 Batch F1: 0.6122448979591837
Epoch:  858        5 Batch loss: 0.167950 Batch F1: 0.7450980392156864
Epoch:  858        6 Batch loss: 0.145080 Batch F1: 0.8260869565217391
Epoch:  858        7 Batch loss: 0.159890 Batch F1: 0.7555555555555555
Epoch:  858        8 Batch loss: 0.138442 Batch F1: 0.8095238095238095
Epoch:  858        9 Batch loss: 0.201116 Batch F1: 0.5789473684210527
Epoch:  858       10 Batch loss: 0.176182 Batch F1: 0.7111111111111111
Epoch:  858       11 Batch loss: 0.192379 Batch F1: 0.5263157894736842
Epoch:  858       12 Batch loss: 0.163035 Batch F1: 0.7428571428571429
Train Avg Loss  858: 0.168741

Train Avg F1  858: 0.7089931646336254

Val Avg Loss  858: 0.181493

Val Avg F1  858:  0.6768289275736085

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 859
--------------------------------------------------------------
Epoch:  859        1 Batch loss: 0.185316 Batch F1: 0.7058823529411765
Epoch:  859        2 Batch loss: 0.144799 Batch F1: 0.8260869565217391
Epoch:  859        3 Batch loss: 0.161589 Batch F1: 0.7916666666666666
Epoch:  859        4 Batch loss: 0.159545 Batch F1: 0.6666666666666667
Epoch:  859        5 Batch loss: 0.151483 Batch F1: 0.7826086956521738
Epoch:  859        6 Batch loss: 0.177712 Batch F1: 0.5882352941176471
Epoch:  859        7 Batch loss: 0.159065 Batch F1: 0.7555555555555556
Epoch:  859        8 Batch loss: 0.177198 Batch F1: 0.6341463414634148
Epoch:  859        9 Batch loss: 0.188110 Batch F1: 0.7058823529411765
Epoch:  859       10 Batch loss: 0.182888 Batch F1: 0.7083333333333334
Epoch:  859       11 Batch loss: 0.161096 Batch F1: 0.6666666666666666
Epoch:  859       12 Batch loss: 0.180610 Batch F1: 0.6486486486486486
Train Avg Loss  859: 0.169118

Train Avg F1  859: 0.7066982942645721

Val Avg Loss  859: 0.181479

Val Avg F1  859:  0.6750755638223669

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 860
--------------------------------------------------------------
Epoch:  860        1 Batch loss: 0.132725 Batch F1: 0.8205128205128205
Epoch:  860        2 Batch loss: 0.169712 Batch F1: 0.723404255319149
Epoch:  860        3 Batch loss: 0.181859 Batch F1: 0.68
Epoch:  860        4 Batch loss: 0.147554 Batch F1: 0.7999999999999999
Epoch:  860        5 Batch loss: 0.180003 Batch F1: 0.7692307692307693
Epoch:  860        6 Batch loss: 0.169731 Batch F1: 0.7441860465116279
Epoch:  860        7 Batch loss: 0.174982 Batch F1: 0.7450980392156863
Epoch:  860        8 Batch loss: 0.163063 Batch F1: 0.7272727272727272
Epoch:  860        9 Batch loss: 0.186257 Batch F1: 0.723404255319149
Epoch:  860       10 Batch loss: 0.196696 Batch F1: 0.5
Epoch:  860       11 Batch loss: 0.174616 Batch F1: 0.5945945945945946
Epoch:  860       12 Batch loss: 0.185184 Batch F1: 0.6470588235294117
Train Avg Loss  860: 0.171865

Train Avg F1  860: 0.7062301942921613

Val Avg Loss  860: 0.190145

Val Avg F1  860:  0.6682495501574449

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 861
--------------------------------------------------------------
Epoch:  861        1 Batch loss: 0.176208 Batch F1: 0.6666666666666666
Epoch:  861        2 Batch loss: 0.147454 Batch F1: 0.8000000000000002
Epoch:  861        3 Batch loss: 0.167244 Batch F1: 0.7441860465116279
Epoch:  861        4 Batch loss: 0.160003 Batch F1: 0.5384615384615384
Epoch:  861        5 Batch loss: 0.210683 Batch F1: 0.5581395348837209
Epoch:  861        6 Batch loss: 0.178261 Batch F1: 0.744186046511628
Epoch:  861        7 Batch loss: 0.189960 Batch F1: 0.6938775510204083
Epoch:  861        8 Batch loss: 0.158573 Batch F1: 0.782608695652174
Epoch:  861        9 Batch loss: 0.191407 Batch F1: 0.68
Epoch:  861       10 Batch loss: 0.218486 Batch F1: 0.6046511627906976
Epoch:  861       11 Batch loss: 0.201886 Batch F1: 0.5882352941176471
Epoch:  861       12 Batch loss: 0.157709 Batch F1: 0.7727272727272727
Train Avg Loss  861: 0.179823

Train Avg F1  861: 0.6811449841119485

Val Avg Loss  861: 0.184935

Val Avg F1  861:  0.6679126134873722

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 862
--------------------------------------------------------------
Epoch:  862        1 Batch loss: 0.174612 Batch F1: 0.7142857142857143
Epoch:  862        2 Batch loss: 0.176409 Batch F1: 0.6341463414634146
Epoch:  862        3 Batch loss: 0.192582 Batch F1: 0.8666666666666666
Epoch:  862        4 Batch loss: 0.190487 Batch F1: 0.7741935483870968
Epoch:  862        5 Batch loss: 0.177398 Batch F1: 0.8363636363636364
Epoch:  862        6 Batch loss: 0.186405 Batch F1: 0.5641025641025641
Epoch:  862        7 Batch loss: 0.173432 Batch F1: 0.5789473684210527
Epoch:  862        8 Batch loss: 0.161660 Batch F1: 0.7906976744186046
Epoch:  862        9 Batch loss: 0.161912 Batch F1: 0.723404255319149
Epoch:  862       10 Batch loss: 0.152308 Batch F1: 0.8260869565217391
Epoch:  862       11 Batch loss: 0.212467 Batch F1: 0.5777777777777777
Epoch:  862       12 Batch loss: 0.172837 Batch F1: 0.75
Train Avg Loss  862: 0.177709

Train Avg F1  862: 0.7197227086439512

Val Avg Loss  862: 0.185891

Val Avg F1  862:  0.6676322043969103

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 863
--------------------------------------------------------------
Epoch:  863        1 Batch loss: 0.160719 Batch F1: 0.7555555555555556
Epoch:  863        2 Batch loss: 0.183674 Batch F1: 0.631578947368421
Epoch:  863        3 Batch loss: 0.173479 Batch F1: 0.6153846153846153
Epoch:  863        4 Batch loss: 0.179597 Batch F1: 0.7391304347826088
Epoch:  863        5 Batch loss: 0.188237 Batch F1: 0.7307692307692307
Epoch:  863        6 Batch loss: 0.185052 Batch F1: 0.816326530612245
Epoch:  863        7 Batch loss: 0.194014 Batch F1: 0.8679245283018869
Epoch:  863        8 Batch loss: 0.141862 Batch F1: 0.8846153846153846
Epoch:  863        9 Batch loss: 0.156541 Batch F1: 0.8181818181818182
Epoch:  863       10 Batch loss: 0.186641 Batch F1: 0.6976744186046512
Epoch:  863       11 Batch loss: 0.198038 Batch F1: 0.6363636363636364
Epoch:  863       12 Batch loss: 0.184953 Batch F1: 0.7222222222222222
Train Avg Loss  863: 0.177734

Train Avg F1  863: 0.7429772768968563

Val Avg Loss  863: 0.184036

Val Avg F1  863:  0.6604742375419068

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 864
--------------------------------------------------------------
Epoch:  864        1 Batch loss: 0.169193 Batch F1: 0.7111111111111111
Epoch:  864        2 Batch loss: 0.168976 Batch F1: 0.7555555555555555
Epoch:  864        3 Batch loss: 0.191582 Batch F1: 0.76
Epoch:  864        4 Batch loss: 0.166490 Batch F1: 0.7391304347826088
Epoch:  864        5 Batch loss: 0.164044 Batch F1: 0.6666666666666666
Epoch:  864        6 Batch loss: 0.209322 Batch F1: 0.7307692307692307
Epoch:  864        7 Batch loss: 0.169619 Batch F1: 0.8000000000000002
Epoch:  864        8 Batch loss: 0.164751 Batch F1: 0.7142857142857143
Epoch:  864        9 Batch loss: 0.202471 Batch F1: 0.5641025641025642
Epoch:  864       10 Batch loss: 0.151966 Batch F1: 0.7317073170731707
Epoch:  864       11 Batch loss: 0.155546 Batch F1: 0.7916666666666667
Epoch:  864       12 Batch loss: 0.191388 Batch F1: 0.6666666666666665
Train Avg Loss  864: 0.175446

Train Avg F1  864: 0.7193051606399963

Val Avg Loss  864: 0.182248

Val Avg F1  864:  0.674352185262376

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 865
--------------------------------------------------------------
Epoch:  865        1 Batch loss: 0.196855 Batch F1: 0.608695652173913
Epoch:  865        2 Batch loss: 0.154232 Batch F1: 0.8163265306122449
Epoch:  865        3 Batch loss: 0.159605 Batch F1: 0.6976744186046512
Epoch:  865        4 Batch loss: 0.155045 Batch F1: 0.816326530612245
Epoch:  865        5 Batch loss: 0.174103 Batch F1: 0.7391304347826085
Epoch:  865        6 Batch loss: 0.137608 Batch F1: 0.7999999999999999
Epoch:  865        7 Batch loss: 0.171519 Batch F1: 0.7317073170731707
Epoch:  865        8 Batch loss: 0.175725 Batch F1: 0.6153846153846153
Epoch:  865        9 Batch loss: 0.195566 Batch F1: 0.5405405405405405
Epoch:  865       10 Batch loss: 0.184876 Batch F1: 0.6818181818181819
Epoch:  865       11 Batch loss: 0.163634 Batch F1: 0.6976744186046512
Epoch:  865       12 Batch loss: 0.176261 Batch F1: 0.744186046511628
Train Avg Loss  865: 0.170419

Train Avg F1  865: 0.7074553905598707

Val Avg Loss  865: 0.181429

Val Avg F1  865:  0.6722222222222222

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 866
--------------------------------------------------------------
Epoch:  866        1 Batch loss: 0.129135 Batch F1: 0.7999999999999999
Epoch:  866        2 Batch loss: 0.175624 Batch F1: 0.6666666666666666
Epoch:  866        3 Batch loss: 0.210960 Batch F1: 0.6399999999999999
Epoch:  866        4 Batch loss: 0.172491 Batch F1: 0.7777777777777777
Epoch:  866        5 Batch loss: 0.210027 Batch F1: 0.4444444444444444
Epoch:  866        6 Batch loss: 0.135003 Batch F1: 0.8571428571428571
Epoch:  866        7 Batch loss: 0.186432 Batch F1: 0.6666666666666666
Epoch:  866        8 Batch loss: 0.170052 Batch F1: 0.6976744186046512
Epoch:  866        9 Batch loss: 0.159217 Batch F1: 0.7755102040816326
Epoch:  866       10 Batch loss: 0.142987 Batch F1: 0.8260869565217391
Epoch:  866       11 Batch loss: 0.199951 Batch F1: 0.6363636363636364
Epoch:  866       12 Batch loss: 0.141534 Batch F1: 0.7499999999999999
Train Avg Loss  866: 0.169451

Train Avg F1  866: 0.7115278023558393

Val Avg Loss  866: 0.181376

Val Avg F1  866:  0.6754327055160414

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 867
--------------------------------------------------------------
Epoch:  867        1 Batch loss: 0.167608 Batch F1: 0.717948717948718
Epoch:  867        2 Batch loss: 0.169326 Batch F1: 0.711111111111111
Epoch:  867        3 Batch loss: 0.166365 Batch F1: 0.7111111111111111
Epoch:  867        4 Batch loss: 0.171245 Batch F1: 0.6666666666666667
Epoch:  867        5 Batch loss: 0.178241 Batch F1: 0.7083333333333334
Epoch:  867        6 Batch loss: 0.150813 Batch F1: 0.7317073170731707
Epoch:  867        7 Batch loss: 0.177257 Batch F1: 0.6956521739130435
Epoch:  867        8 Batch loss: 0.160302 Batch F1: 0.7441860465116279
Epoch:  867        9 Batch loss: 0.153053 Batch F1: 0.8085106382978724
Epoch:  867       10 Batch loss: 0.171890 Batch F1: 0.6341463414634146
Epoch:  867       11 Batch loss: 0.182969 Batch F1: 0.72
Epoch:  867       12 Batch loss: 0.181678 Batch F1: 0.7000000000000001
Train Avg Loss  867: 0.169229

Train Avg F1  867: 0.7124477881191723

Val Avg Loss  867: 0.180833

Val Avg F1  867:  0.6738758135389462

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 868
--------------------------------------------------------------
Epoch:  868        1 Batch loss: 0.183055 Batch F1: 0.6818181818181818
Epoch:  868        2 Batch loss: 0.144285 Batch F1: 0.7906976744186046
Epoch:  868        3 Batch loss: 0.135036 Batch F1: 0.8095238095238095
Epoch:  868        4 Batch loss: 0.171474 Batch F1: 0.6511627906976745
Epoch:  868        5 Batch loss: 0.175771 Batch F1: 0.6666666666666666
Epoch:  868        6 Batch loss: 0.183158 Batch F1: 0.6818181818181819
Epoch:  868        7 Batch loss: 0.192100 Batch F1: 0.6792452830188679
Epoch:  868        8 Batch loss: 0.175898 Batch F1: 0.7547169811320754
Epoch:  868        9 Batch loss: 0.182795 Batch F1: 0.5882352941176471
Epoch:  868       10 Batch loss: 0.142896 Batch F1: 0.7727272727272727
Epoch:  868       11 Batch loss: 0.150016 Batch F1: 0.8085106382978724
Epoch:  868       12 Batch loss: 0.192392 Batch F1: 0.6285714285714286
Train Avg Loss  868: 0.169073

Train Avg F1  868: 0.7094745169006903

Val Avg Loss  868: 0.181348

Val Avg F1  868:  0.6765105492514131

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 869
--------------------------------------------------------------
Epoch:  869        1 Batch loss: 0.174118 Batch F1: 0.6666666666666666
Epoch:  869        2 Batch loss: 0.176637 Batch F1: 0.6666666666666666
Epoch:  869        3 Batch loss: 0.201934 Batch F1: 0.6122448979591836
Epoch:  869        4 Batch loss: 0.180505 Batch F1: 0.6956521739130435
Epoch:  869        5 Batch loss: 0.188784 Batch F1: 0.6511627906976745
Epoch:  869        6 Batch loss: 0.169206 Batch F1: 0.7391304347826088
Epoch:  869        7 Batch loss: 0.174720 Batch F1: 0.6111111111111113
Epoch:  869        8 Batch loss: 0.167366 Batch F1: 0.6976744186046512
Epoch:  869        9 Batch loss: 0.132548 Batch F1: 0.8846153846153847
Epoch:  869       10 Batch loss: 0.138830 Batch F1: 0.7567567567567567
Epoch:  869       11 Batch loss: 0.159040 Batch F1: 0.76
Epoch:  869       12 Batch loss: 0.159349 Batch F1: 0.7777777777777778
Train Avg Loss  869: 0.168586

Train Avg F1  869: 0.7099549232959604

Val Avg Loss  869: 0.180649

Val Avg F1  869:  0.6743613935499969

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 870
--------------------------------------------------------------
Epoch:  870        1 Batch loss: 0.159275 Batch F1: 0.717948717948718
Epoch:  870        2 Batch loss: 0.155420 Batch F1: 0.8163265306122449
Epoch:  870        3 Batch loss: 0.179277 Batch F1: 0.6956521739130435
Epoch:  870        4 Batch loss: 0.176341 Batch F1: 0.6666666666666666
Epoch:  870        5 Batch loss: 0.164351 Batch F1: 0.7755102040816326
Epoch:  870        6 Batch loss: 0.149427 Batch F1: 0.717948717948718
Epoch:  870        7 Batch loss: 0.138441 Batch F1: 0.8181818181818182
Epoch:  870        8 Batch loss: 0.183599 Batch F1: 0.6511627906976744
Epoch:  870        9 Batch loss: 0.169609 Batch F1: 0.723404255319149
Epoch:  870       10 Batch loss: 0.176424 Batch F1: 0.6666666666666666
Epoch:  870       11 Batch loss: 0.185110 Batch F1: 0.5789473684210527
Epoch:  870       12 Batch loss: 0.184614 Batch F1: 0.6829268292682926
Train Avg Loss  870: 0.168491

Train Avg F1  870: 0.7092785616438065

Val Avg Loss  870: 0.180793

Val Avg F1  870:  0.6762121212121213

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 871
--------------------------------------------------------------
Epoch:  871        1 Batch loss: 0.161674 Batch F1: 0.7391304347826088
Epoch:  871        2 Batch loss: 0.171618 Batch F1: 0.6976744186046512
Epoch:  871        3 Batch loss: 0.200288 Batch F1: 0.5909090909090909
Epoch:  871        4 Batch loss: 0.142003 Batch F1: 0.8333333333333333
Epoch:  871        5 Batch loss: 0.153254 Batch F1: 0.6666666666666667
Epoch:  871        6 Batch loss: 0.168384 Batch F1: 0.7843137254901961
Epoch:  871        7 Batch loss: 0.173705 Batch F1: 0.6818181818181819
Epoch:  871        8 Batch loss: 0.153226 Batch F1: 0.8148148148148148
Epoch:  871        9 Batch loss: 0.165136 Batch F1: 0.6111111111111113
Epoch:  871       10 Batch loss: 0.182408 Batch F1: 0.65
Epoch:  871       11 Batch loss: 0.173851 Batch F1: 0.6666666666666666
Epoch:  871       12 Batch loss: 0.171376 Batch F1: 0.7272727272727272
Train Avg Loss  871: 0.168077

Train Avg F1  871: 0.7053092642891707

Val Avg Loss  871: 0.181025

Val Avg F1  871:  0.6740808251167618

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 872
--------------------------------------------------------------
Epoch:  872        1 Batch loss: 0.142255 Batch F1: 0.7999999999999999
Epoch:  872        2 Batch loss: 0.177178 Batch F1: 0.72
Epoch:  872        3 Batch loss: 0.168350 Batch F1: 0.625
Epoch:  872        4 Batch loss: 0.176890 Batch F1: 0.6521739130434783
Epoch:  872        5 Batch loss: 0.194935 Batch F1: 0.6
Epoch:  872        6 Batch loss: 0.182474 Batch F1: 0.6190476190476191
Epoch:  872        7 Batch loss: 0.168832 Batch F1: 0.6666666666666666
Epoch:  872        8 Batch loss: 0.159399 Batch F1: 0.7317073170731706
Epoch:  872        9 Batch loss: 0.169652 Batch F1: 0.6842105263157895
Epoch:  872       10 Batch loss: 0.176568 Batch F1: 0.7547169811320754
Epoch:  872       11 Batch loss: 0.156262 Batch F1: 0.8
Epoch:  872       12 Batch loss: 0.147084 Batch F1: 0.8292682926829269
Train Avg Loss  872: 0.168323

Train Avg F1  872: 0.7068992763301439

Val Avg Loss  872: 0.181424

Val Avg F1  872:  0.6663096567153263

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 873
--------------------------------------------------------------
Epoch:  873        1 Batch loss: 0.149956 Batch F1: 0.7727272727272727
Epoch:  873        2 Batch loss: 0.178675 Batch F1: 0.7586206896551724
Epoch:  873        3 Batch loss: 0.183020 Batch F1: 0.6666666666666666
Epoch:  873        4 Batch loss: 0.160720 Batch F1: 0.761904761904762
Epoch:  873        5 Batch loss: 0.183561 Batch F1: 0.6315789473684211
Epoch:  873        6 Batch loss: 0.168762 Batch F1: 0.6666666666666666
Epoch:  873        7 Batch loss: 0.161997 Batch F1: 0.7142857142857143
Epoch:  873        8 Batch loss: 0.157846 Batch F1: 0.7500000000000001
Epoch:  873        9 Batch loss: 0.153395 Batch F1: 0.6666666666666667
Epoch:  873       10 Batch loss: 0.130280 Batch F1: 0.8461538461538461
Epoch:  873       11 Batch loss: 0.206376 Batch F1: 0.6250000000000001
Epoch:  873       12 Batch loss: 0.205755 Batch F1: 0.631578947368421
Train Avg Loss  873: 0.170029

Train Avg F1  873: 0.7076541816219675

Val Avg Loss  873: 0.183207

Val Avg F1  873:  0.6776143936676513

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 874
--------------------------------------------------------------
Epoch:  874        1 Batch loss: 0.181296 Batch F1: 0.6363636363636364
Epoch:  874        2 Batch loss: 0.176044 Batch F1: 0.6666666666666666
Epoch:  874        3 Batch loss: 0.174845 Batch F1: 0.6511627906976745
Epoch:  874        4 Batch loss: 0.182303 Batch F1: 0.6511627906976744
Epoch:  874        5 Batch loss: 0.154364 Batch F1: 0.7619047619047619
Epoch:  874        6 Batch loss: 0.123944 Batch F1: 0.8750000000000001
Epoch:  874        7 Batch loss: 0.175146 Batch F1: 0.7142857142857143
Epoch:  874        8 Batch loss: 0.165204 Batch F1: 0.7659574468085107
Epoch:  874        9 Batch loss: 0.193378 Batch F1: 0.7037037037037038
Epoch:  874       10 Batch loss: 0.196136 Batch F1: 0.5853658536585366
Epoch:  874       11 Batch loss: 0.144948 Batch F1: 0.7906976744186046
Epoch:  874       12 Batch loss: 0.158106 Batch F1: 0.7222222222222222
Train Avg Loss  874: 0.168810

Train Avg F1  874: 0.7103744384523089

Val Avg Loss  874: 0.181738

Val Avg F1  874:  0.6773144040224786

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 875
--------------------------------------------------------------
Epoch:  875        1 Batch loss: 0.201710 Batch F1: 0.6909090909090909
Epoch:  875        2 Batch loss: 0.167893 Batch F1: 0.8
Epoch:  875        3 Batch loss: 0.179534 Batch F1: 0.5789473684210527
Epoch:  875        4 Batch loss: 0.175532 Batch F1: 0.7391304347826088
Epoch:  875        5 Batch loss: 0.153924 Batch F1: 0.8275862068965518
Epoch:  875        6 Batch loss: 0.135030 Batch F1: 0.8000000000000002
Epoch:  875        7 Batch loss: 0.183347 Batch F1: 0.6
Epoch:  875        8 Batch loss: 0.150823 Batch F1: 0.7027027027027027
Epoch:  875        9 Batch loss: 0.165792 Batch F1: 0.6285714285714286
Epoch:  875       10 Batch loss: 0.171932 Batch F1: 0.7083333333333334
Epoch:  875       11 Batch loss: 0.158310 Batch F1: 0.7317073170731706
Epoch:  875       12 Batch loss: 0.182261 Batch F1: 0.6250000000000001
Train Avg Loss  875: 0.168841

Train Avg F1  875: 0.7027406568908282

Val Avg Loss  875: 0.180348

Val Avg F1  875:  0.6675272713008561

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 876
--------------------------------------------------------------
Epoch:  876        1 Batch loss: 0.138970 Batch F1: 0.8
Epoch:  876        2 Batch loss: 0.186481 Batch F1: 0.7058823529411765
Epoch:  876        3 Batch loss: 0.171116 Batch F1: 0.7111111111111111
Epoch:  876        4 Batch loss: 0.160451 Batch F1: 0.6486486486486486
Epoch:  876        5 Batch loss: 0.150269 Batch F1: 0.7619047619047619
Epoch:  876        6 Batch loss: 0.161901 Batch F1: 0.7272727272727272
Epoch:  876        7 Batch loss: 0.166092 Batch F1: 0.7391304347826088
Epoch:  876        8 Batch loss: 0.203272 Batch F1: 0.7
Epoch:  876        9 Batch loss: 0.182118 Batch F1: 0.7692307692307692
Epoch:  876       10 Batch loss: 0.187470 Batch F1: 0.6190476190476191
Epoch:  876       11 Batch loss: 0.150068 Batch F1: 0.6206896551724138
Epoch:  876       12 Batch loss: 0.159459 Batch F1: 0.7222222222222222
Train Avg Loss  876: 0.168139

Train Avg F1  876: 0.7104283585278383

Val Avg Loss  876: 0.181857

Val Avg F1  876:  0.6767539525691699

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 877
--------------------------------------------------------------
Epoch:  877        1 Batch loss: 0.162859 Batch F1: 0.7
Epoch:  877        2 Batch loss: 0.153037 Batch F1: 0.816326530612245
Epoch:  877        3 Batch loss: 0.169218 Batch F1: 0.6111111111111112
Epoch:  877        4 Batch loss: 0.181872 Batch F1: 0.6190476190476191
Epoch:  877        5 Batch loss: 0.176958 Batch F1: 0.7586206896551724
Epoch:  877        6 Batch loss: 0.162405 Batch F1: 0.6666666666666667
Epoch:  877        7 Batch loss: 0.162960 Batch F1: 0.76
Epoch:  877        8 Batch loss: 0.184690 Batch F1: 0.5714285714285714
Epoch:  877        9 Batch loss: 0.201903 Batch F1: 0.6956521739130435
Epoch:  877       10 Batch loss: 0.143541 Batch F1: 0.782608695652174
Epoch:  877       11 Batch loss: 0.170636 Batch F1: 0.7272727272727273
Epoch:  877       12 Batch loss: 0.151447 Batch F1: 0.7586206896551724
Train Avg Loss  877: 0.168461

Train Avg F1  877: 0.7056129562512085

Val Avg Loss  877: 0.179320

Val Avg F1  877:  0.6727728325372702

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 878
--------------------------------------------------------------
Epoch:  878        1 Batch loss: 0.173244 Batch F1: 0.6956521739130435
Epoch:  878        2 Batch loss: 0.183293 Batch F1: 0.6521739130434783
Epoch:  878        3 Batch loss: 0.152740 Batch F1: 0.8181818181818182
Epoch:  878        4 Batch loss: 0.157984 Batch F1: 0.7727272727272727
Epoch:  878        5 Batch loss: 0.150997 Batch F1: 0.8085106382978724
Epoch:  878        6 Batch loss: 0.167313 Batch F1: 0.723404255319149
Epoch:  878        7 Batch loss: 0.200811 Batch F1: 0.6122448979591837
Epoch:  878        8 Batch loss: 0.157713 Batch F1: 0.7755102040816326
Epoch:  878        9 Batch loss: 0.170497 Batch F1: 0.84
Epoch:  878       10 Batch loss: 0.181312 Batch F1: 0.7272727272727272
Epoch:  878       11 Batch loss: 0.180233 Batch F1: 0.7058823529411765
Epoch:  878       12 Batch loss: 0.203539 Batch F1: 0.631578947368421
Train Avg Loss  878: 0.173306

Train Avg F1  878: 0.730261600092148

Val Avg Loss  878: 0.184934

Val Avg F1  878:  0.6779343745955042

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 879
--------------------------------------------------------------
Epoch:  879        1 Batch loss: 0.167439 Batch F1: 0.75
Epoch:  879        2 Batch loss: 0.206060 Batch F1: 0.6909090909090909
Epoch:  879        3 Batch loss: 0.147892 Batch F1: 0.8000000000000002
Epoch:  879        4 Batch loss: 0.152907 Batch F1: 0.7692307692307692
Epoch:  879        5 Batch loss: 0.158945 Batch F1: 0.6000000000000001
Epoch:  879        6 Batch loss: 0.164127 Batch F1: 0.7391304347826089
Epoch:  879        7 Batch loss: 0.189513 Batch F1: 0.6250000000000001
Epoch:  879        8 Batch loss: 0.177269 Batch F1: 0.7659574468085107
Epoch:  879        9 Batch loss: 0.177299 Batch F1: 0.7441860465116279
Epoch:  879       10 Batch loss: 0.183718 Batch F1: 0.6829268292682927
Epoch:  879       11 Batch loss: 0.167307 Batch F1: 0.7692307692307692
Epoch:  879       12 Batch loss: 0.173974 Batch F1: 0.7317073170731707
Train Avg Loss  879: 0.172204

Train Avg F1  879: 0.7223565586512367

Val Avg Loss  879: 0.182091

Val Avg F1  879:  0.6761302244796978

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 880
--------------------------------------------------------------
Epoch:  880        1 Batch loss: 0.167602 Batch F1: 0.7692307692307693
Epoch:  880        2 Batch loss: 0.196014 Batch F1: 0.5909090909090909
Epoch:  880        3 Batch loss: 0.173871 Batch F1: 0.7500000000000001
Epoch:  880        4 Batch loss: 0.155968 Batch F1: 0.7391304347826089
Epoch:  880        5 Batch loss: 0.215903 Batch F1: 0.5
Epoch:  880        6 Batch loss: 0.174207 Batch F1: 0.631578947368421
Epoch:  880        7 Batch loss: 0.223694 Batch F1: 0.5333333333333333
Epoch:  880        8 Batch loss: 0.146669 Batch F1: 0.8852459016393444
Epoch:  880        9 Batch loss: 0.201086 Batch F1: 0.6222222222222222
Epoch:  880       10 Batch loss: 0.160985 Batch F1: 0.6976744186046512
Epoch:  880       11 Batch loss: 0.158853 Batch F1: 0.7500000000000001
Epoch:  880       12 Batch loss: 0.174189 Batch F1: 0.6250000000000001
Train Avg Loss  880: 0.179087

Train Avg F1  880: 0.6745270931742035

Val Avg Loss  880: 0.187917

Val Avg F1  880:  0.6089482821268521

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 881
--------------------------------------------------------------
Epoch:  881        1 Batch loss: 0.187030 Batch F1: 0.6341463414634146
Epoch:  881        2 Batch loss: 0.212501 Batch F1: 0.5454545454545454
Epoch:  881        3 Batch loss: 0.179177 Batch F1: 0.8135593220338982
Epoch:  881        4 Batch loss: 0.144116 Batch F1: 0.7428571428571428
Epoch:  881        5 Batch loss: 0.168997 Batch F1: 0.6511627906976745
Epoch:  881        6 Batch loss: 0.154698 Batch F1: 0.7804878048780488
Epoch:  881        7 Batch loss: 0.140876 Batch F1: 0.8799999999999999
Epoch:  881        8 Batch loss: 0.222093 Batch F1: 0.5957446808510638
Epoch:  881        9 Batch loss: 0.183251 Batch F1: 0.6666666666666666
Epoch:  881       10 Batch loss: 0.185336 Batch F1: 0.7307692307692308
Epoch:  881       11 Batch loss: 0.186775 Batch F1: 0.693877551020408
Epoch:  881       12 Batch loss: 0.143428 Batch F1: 0.8125
Train Avg Loss  881: 0.175690

Train Avg F1  881: 0.7122688397243412

Val Avg Loss  881: 0.180732

Val Avg F1  881:  0.6761352657004831

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 882
--------------------------------------------------------------
Epoch:  882        1 Batch loss: 0.171726 Batch F1: 0.7272727272727272
Epoch:  882        2 Batch loss: 0.187287 Batch F1: 0.693877551020408
Epoch:  882        3 Batch loss: 0.188472 Batch F1: 0.76
Epoch:  882        4 Batch loss: 0.158393 Batch F1: 0.7999999999999999
Epoch:  882        5 Batch loss: 0.175914 Batch F1: 0.6341463414634146
Epoch:  882        6 Batch loss: 0.169375 Batch F1: 0.7391304347826088
Epoch:  882        7 Batch loss: 0.188885 Batch F1: 0.6923076923076923
Epoch:  882        8 Batch loss: 0.153491 Batch F1: 0.7727272727272727
Epoch:  882        9 Batch loss: 0.168342 Batch F1: 0.5945945945945946
Epoch:  882       10 Batch loss: 0.181442 Batch F1: 0.6956521739130435
Epoch:  882       11 Batch loss: 0.145660 Batch F1: 0.761904761904762
Epoch:  882       12 Batch loss: 0.200397 Batch F1: 0.6666666666666667
Train Avg Loss  882: 0.174115

Train Avg F1  882: 0.7115233513877658

Val Avg Loss  882: 0.185484

Val Avg F1  882:  0.6740903169778549

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 883
--------------------------------------------------------------
Epoch:  883        1 Batch loss: 0.161358 Batch F1: 0.8076923076923077
Epoch:  883        2 Batch loss: 0.183376 Batch F1: 0.6500000000000001
Epoch:  883        3 Batch loss: 0.189082 Batch F1: 0.6666666666666666
Epoch:  883        4 Batch loss: 0.181075 Batch F1: 0.6808510638297872
Epoch:  883        5 Batch loss: 0.174431 Batch F1: 0.5806451612903225
Epoch:  883        6 Batch loss: 0.150823 Batch F1: 0.717948717948718
Epoch:  883        7 Batch loss: 0.162694 Batch F1: 0.7368421052631577
Epoch:  883        8 Batch loss: 0.166962 Batch F1: 0.711111111111111
Epoch:  883        9 Batch loss: 0.186072 Batch F1: 0.693877551020408
Epoch:  883       10 Batch loss: 0.158578 Batch F1: 0.76
Epoch:  883       11 Batch loss: 0.170330 Batch F1: 0.72
Epoch:  883       12 Batch loss: 0.164393 Batch F1: 0.7692307692307692
Train Avg Loss  883: 0.170764

Train Avg F1  883: 0.7079054545044373

Val Avg Loss  883: 0.181755

Val Avg F1  883:  0.6742832167832168

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 884
--------------------------------------------------------------
Epoch:  884        1 Batch loss: 0.153221 Batch F1: 0.7619047619047619
Epoch:  884        2 Batch loss: 0.172363 Batch F1: 0.7857142857142857
Epoch:  884        3 Batch loss: 0.153834 Batch F1: 0.7727272727272727
Epoch:  884        4 Batch loss: 0.186206 Batch F1: 0.6315789473684211
Epoch:  884        5 Batch loss: 0.162349 Batch F1: 0.6976744186046512
Epoch:  884        6 Batch loss: 0.185001 Batch F1: 0.6190476190476191
Epoch:  884        7 Batch loss: 0.138673 Batch F1: 0.7894736842105263
Epoch:  884        8 Batch loss: 0.201434 Batch F1: 0.5128205128205129
Epoch:  884        9 Batch loss: 0.199345 Batch F1: 0.5909090909090909
Epoch:  884       10 Batch loss: 0.154715 Batch F1: 0.7924528301886792
Epoch:  884       11 Batch loss: 0.148806 Batch F1: 0.7916666666666666
Epoch:  884       12 Batch loss: 0.172303 Batch F1: 0.7368421052631579
Train Avg Loss  884: 0.169021

Train Avg F1  884: 0.7069010162854705

Val Avg Loss  884: 0.180827

Val Avg F1  884:  0.6745814926761218

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 885
--------------------------------------------------------------
Epoch:  885        1 Batch loss: 0.201784 Batch F1: 0.7017543859649122
Epoch:  885        2 Batch loss: 0.169174 Batch F1: 0.7692307692307693
Epoch:  885        3 Batch loss: 0.175124 Batch F1: 0.5945945945945946
Epoch:  885        4 Batch loss: 0.147649 Batch F1: 0.7027027027027026
Epoch:  885        5 Batch loss: 0.175969 Batch F1: 0.75
Epoch:  885        6 Batch loss: 0.154466 Batch F1: 0.7843137254901961
Epoch:  885        7 Batch loss: 0.192714 Batch F1: 0.5454545454545454
Epoch:  885        8 Batch loss: 0.171575 Batch F1: 0.6000000000000001
Epoch:  885        9 Batch loss: 0.149881 Batch F1: 0.7567567567567567
Epoch:  885       10 Batch loss: 0.196101 Batch F1: 0.6363636363636364
Epoch:  885       11 Batch loss: 0.171898 Batch F1: 0.717948717948718
Epoch:  885       12 Batch loss: 0.185110 Batch F1: 0.7755102040816326
Train Avg Loss  885: 0.174287

Train Avg F1  885: 0.6945525032157054

Val Avg Loss  885: 0.187911

Val Avg F1  885:  0.7344374267659988

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 886
--------------------------------------------------------------
Epoch:  886        1 Batch loss: 0.206331 Batch F1: 0.5853658536585366
Epoch:  886        2 Batch loss: 0.202308 Batch F1: 0.68
Epoch:  886        3 Batch loss: 0.115343 Batch F1: 0.9142857142857143
Epoch:  886        4 Batch loss: 0.178699 Batch F1: 0.7450980392156863
Epoch:  886        5 Batch loss: 0.183665 Batch F1: 0.7142857142857142
Epoch:  886        6 Batch loss: 0.192823 Batch F1: 0.6122448979591837
Epoch:  886        7 Batch loss: 0.177729 Batch F1: 0.65
Epoch:  886        8 Batch loss: 0.181074 Batch F1: 0.5945945945945946
Epoch:  886        9 Batch loss: 0.189802 Batch F1: 0.7843137254901961
Epoch:  886       10 Batch loss: 0.173085 Batch F1: 0.6111111111111113
Epoch:  886       11 Batch loss: 0.198191 Batch F1: 0.4848484848484848
Epoch:  886       12 Batch loss: 0.142111 Batch F1: 0.8571428571428572
Train Avg Loss  886: 0.178430

Train Avg F1  886: 0.6861075827160067

Val Avg Loss  886: 0.184206

Val Avg F1  886:  0.6764266210085111

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 887
--------------------------------------------------------------
Epoch:  887        1 Batch loss: 0.188856 Batch F1: 0.68
Epoch:  887        2 Batch loss: 0.171751 Batch F1: 0.6956521739130435
Epoch:  887        3 Batch loss: 0.164807 Batch F1: 0.8235294117647057
Epoch:  887        4 Batch loss: 0.153033 Batch F1: 0.7428571428571428
Epoch:  887        5 Batch loss: 0.199130 Batch F1: 0.46153846153846156
Epoch:  887        6 Batch loss: 0.183017 Batch F1: 0.6956521739130435
Epoch:  887        7 Batch loss: 0.189185 Batch F1: 0.6382978723404256
Epoch:  887        8 Batch loss: 0.168624 Batch F1: 0.6842105263157896
Epoch:  887        9 Batch loss: 0.157460 Batch F1: 0.7906976744186046
Epoch:  887       10 Batch loss: 0.194119 Batch F1: 0.72
Epoch:  887       11 Batch loss: 0.147220 Batch F1: 0.823529411764706
Epoch:  887       12 Batch loss: 0.160017 Batch F1: 0.5999999999999999
Train Avg Loss  887: 0.173101

Train Avg F1  887: 0.6963304040688268

Val Avg Loss  887: 0.186934

Val Avg F1  887:  0.6356606131424769

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 888
--------------------------------------------------------------
Epoch:  888        1 Batch loss: 0.157286 Batch F1: 0.6285714285714286
Epoch:  888        2 Batch loss: 0.205824 Batch F1: 0.64
Epoch:  888        3 Batch loss: 0.177351 Batch F1: 0.7547169811320754
Epoch:  888        4 Batch loss: 0.189794 Batch F1: 0.7450980392156864
Epoch:  888        5 Batch loss: 0.190652 Batch F1: 0.7636363636363636
Epoch:  888        6 Batch loss: 0.179638 Batch F1: 0.6818181818181819
Epoch:  888        7 Batch loss: 0.175865 Batch F1: 0.6486486486486486
Epoch:  888        8 Batch loss: 0.173043 Batch F1: 0.7636363636363638
Epoch:  888        9 Batch loss: 0.156045 Batch F1: 0.6451612903225806
Epoch:  888       10 Batch loss: 0.171018 Batch F1: 0.6842105263157896
Epoch:  888       11 Batch loss: 0.178057 Batch F1: 0.6341463414634146
Epoch:  888       12 Batch loss: 0.159869 Batch F1: 0.7804878048780488
Train Avg Loss  888: 0.176203

Train Avg F1  888: 0.6975109974698818

Val Avg Loss  888: 0.183096

Val Avg F1  888:  0.6765969643671422

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 889
--------------------------------------------------------------
Epoch:  889        1 Batch loss: 0.130947 Batch F1: 0.8717948717948718
Epoch:  889        2 Batch loss: 0.162102 Batch F1: 0.6666666666666666
Epoch:  889        3 Batch loss: 0.194996 Batch F1: 0.5909090909090909
Epoch:  889        4 Batch loss: 0.163789 Batch F1: 0.8000000000000002
Epoch:  889        5 Batch loss: 0.180118 Batch F1: 0.631578947368421
Epoch:  889        6 Batch loss: 0.142329 Batch F1: 0.8627450980392156
Epoch:  889        7 Batch loss: 0.186366 Batch F1: 0.6521739130434783
Epoch:  889        8 Batch loss: 0.183826 Batch F1: 0.5641025641025642
Epoch:  889        9 Batch loss: 0.162973 Batch F1: 0.7555555555555555
Epoch:  889       10 Batch loss: 0.156355 Batch F1: 0.6666666666666667
Epoch:  889       11 Batch loss: 0.202055 Batch F1: 0.7037037037037037
Epoch:  889       12 Batch loss: 0.195020 Batch F1: 0.7272727272727272
Train Avg Loss  889: 0.171740

Train Avg F1  889: 0.7077641504269133

Val Avg Loss  889: 0.181795

Val Avg F1  889:  0.6787742116995261

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 890
--------------------------------------------------------------
Epoch:  890        1 Batch loss: 0.183088 Batch F1: 0.6818181818181818
Epoch:  890        2 Batch loss: 0.180920 Batch F1: 0.5853658536585366
Epoch:  890        3 Batch loss: 0.194015 Batch F1: 0.6938775510204083
Epoch:  890        4 Batch loss: 0.145111 Batch F1: 0.8000000000000002
Epoch:  890        5 Batch loss: 0.180667 Batch F1: 0.7547169811320754
Epoch:  890        6 Batch loss: 0.168180 Batch F1: 0.8
Epoch:  890        7 Batch loss: 0.172042 Batch F1: 0.7391304347826088
Epoch:  890        8 Batch loss: 0.125971 Batch F1: 0.8846153846153847
Epoch:  890        9 Batch loss: 0.177197 Batch F1: 0.6818181818181818
Epoch:  890       10 Batch loss: 0.186383 Batch F1: 0.5454545454545454
Epoch:  890       11 Batch loss: 0.180703 Batch F1: 0.6153846153846153
Epoch:  890       12 Batch loss: 0.194956 Batch F1: 0.5625
Train Avg Loss  890: 0.174103

Train Avg F1  890: 0.6953901441403781

Val Avg Loss  890: 0.186337

Val Avg F1  890:  0.6734128333900238

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 891
--------------------------------------------------------------
Epoch:  891        1 Batch loss: 0.157553 Batch F1: 0.7727272727272727
Epoch:  891        2 Batch loss: 0.181966 Batch F1: 0.7083333333333334
Epoch:  891        3 Batch loss: 0.181510 Batch F1: 0.6976744186046512
Epoch:  891        4 Batch loss: 0.168897 Batch F1: 0.6666666666666666
Epoch:  891        5 Batch loss: 0.171644 Batch F1: 0.7843137254901961
Epoch:  891        6 Batch loss: 0.199269 Batch F1: 0.6046511627906976
Epoch:  891        7 Batch loss: 0.141677 Batch F1: 0.8181818181818182
Epoch:  891        8 Batch loss: 0.175183 Batch F1: 0.6341463414634146
Epoch:  891        9 Batch loss: 0.168544 Batch F1: 0.7
Epoch:  891       10 Batch loss: 0.176316 Batch F1: 0.6666666666666666
Epoch:  891       11 Batch loss: 0.171225 Batch F1: 0.76
Epoch:  891       12 Batch loss: 0.184634 Batch F1: 0.6956521739130435
Train Avg Loss  891: 0.173202

Train Avg F1  891: 0.7090844649864799

Val Avg Loss  891: 0.190591

Val Avg F1  891:  0.7506999705275567

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 892
--------------------------------------------------------------
Epoch:  892        1 Batch loss: 0.150577 Batch F1: 0.8627450980392156
Epoch:  892        2 Batch loss: 0.187237 Batch F1: 0.7692307692307692
Epoch:  892        3 Batch loss: 0.168326 Batch F1: 0.75
Epoch:  892        4 Batch loss: 0.185362 Batch F1: 0.6190476190476191
Epoch:  892        5 Batch loss: 0.165230 Batch F1: 0.625
Epoch:  892        6 Batch loss: 0.165242 Batch F1: 0.8
Epoch:  892        7 Batch loss: 0.185903 Batch F1: 0.6341463414634148
Epoch:  892        8 Batch loss: 0.164450 Batch F1: 0.761904761904762
Epoch:  892        9 Batch loss: 0.187386 Batch F1: 0.7450980392156864
Epoch:  892       10 Batch loss: 0.180386 Batch F1: 0.6923076923076923
Epoch:  892       11 Batch loss: 0.218345 Batch F1: 0.6153846153846153
Epoch:  892       12 Batch loss: 0.223300 Batch F1: 0.5128205128205129
Train Avg Loss  892: 0.181812

Train Avg F1  892: 0.6989737874511907

Val Avg Loss  892: 0.181673

Val Avg F1  892:  0.6674232751690546

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 893
--------------------------------------------------------------
Epoch:  893        1 Batch loss: 0.178091 Batch F1: 0.7234042553191489
Epoch:  893        2 Batch loss: 0.191730 Batch F1: 0.6046511627906977
Epoch:  893        3 Batch loss: 0.168935 Batch F1: 0.7317073170731706
Epoch:  893        4 Batch loss: 0.164012 Batch F1: 0.7659574468085107
Epoch:  893        5 Batch loss: 0.204107 Batch F1: 0.6666666666666667
Epoch:  893        6 Batch loss: 0.179514 Batch F1: 0.6486486486486486
Epoch:  893        7 Batch loss: 0.198415 Batch F1: 0.5853658536585366
Epoch:  893        8 Batch loss: 0.175534 Batch F1: 0.8064516129032258
Epoch:  893        9 Batch loss: 0.147298 Batch F1: 0.75
Epoch:  893       10 Batch loss: 0.178490 Batch F1: 0.6363636363636364
Epoch:  893       11 Batch loss: 0.150261 Batch F1: 0.8085106382978724
Epoch:  893       12 Batch loss: 0.163241 Batch F1: 0.6666666666666667
Train Avg Loss  893: 0.174969

Train Avg F1  893: 0.699532825433065

Val Avg Loss  893: 0.182168

Val Avg F1  893:  0.663100008759252

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 894
--------------------------------------------------------------
Epoch:  894        1 Batch loss: 0.158455 Batch F1: 0.8070175438596492
Epoch:  894        2 Batch loss: 0.186214 Batch F1: 0.6153846153846153
Epoch:  894        3 Batch loss: 0.198970 Batch F1: 0.7407407407407408
Epoch:  894        4 Batch loss: 0.184199 Batch F1: 0.5641025641025642
Epoch:  894        5 Batch loss: 0.175306 Batch F1: 0.6486486486486486
Epoch:  894        6 Batch loss: 0.165496 Batch F1: 0.7441860465116279
Epoch:  894        7 Batch loss: 0.168465 Batch F1: 0.76
Epoch:  894        8 Batch loss: 0.178444 Batch F1: 0.693877551020408
Epoch:  894        9 Batch loss: 0.166434 Batch F1: 0.7111111111111111
Epoch:  894       10 Batch loss: 0.176317 Batch F1: 0.7142857142857143
Epoch:  894       11 Batch loss: 0.135990 Batch F1: 0.7894736842105262
Epoch:  894       12 Batch loss: 0.168842 Batch F1: 0.6875
Train Avg Loss  894: 0.171928

Train Avg F1  894: 0.706360684989634

Val Avg Loss  894: 0.182037

Val Avg F1  894:  0.6786355125604618

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 895
--------------------------------------------------------------
Epoch:  895        1 Batch loss: 0.164857 Batch F1: 0.7391304347826088
Epoch:  895        2 Batch loss: 0.136161 Batch F1: 0.8292682926829269
Epoch:  895        3 Batch loss: 0.166947 Batch F1: 0.7
Epoch:  895        4 Batch loss: 0.181310 Batch F1: 0.6956521739130435
Epoch:  895        5 Batch loss: 0.161016 Batch F1: 0.7499999999999999
Epoch:  895        6 Batch loss: 0.168269 Batch F1: 0.6486486486486486
Epoch:  895        7 Batch loss: 0.186937 Batch F1: 0.6956521739130435
Epoch:  895        8 Batch loss: 0.165597 Batch F1: 0.5625000000000001
Epoch:  895        9 Batch loss: 0.159722 Batch F1: 0.7555555555555555
Epoch:  895       10 Batch loss: 0.178230 Batch F1: 0.7199999999999999
Epoch:  895       11 Batch loss: 0.204234 Batch F1: 0.627450980392157
Epoch:  895       12 Batch loss: 0.173388 Batch F1: 0.7906976744186046
Train Avg Loss  895: 0.170556

Train Avg F1  895: 0.7095463278588824

Val Avg Loss  895: 0.183068

Val Avg F1  895:  0.6724358974358974

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 896
--------------------------------------------------------------
Epoch:  896        1 Batch loss: 0.179059 Batch F1: 0.6341463414634148
Epoch:  896        2 Batch loss: 0.170626 Batch F1: 0.65
Epoch:  896        3 Batch loss: 0.155972 Batch F1: 0.7317073170731706
Epoch:  896        4 Batch loss: 0.190937 Batch F1: 0.6363636363636365
Epoch:  896        5 Batch loss: 0.130322 Batch F1: 0.8979591836734694
Epoch:  896        6 Batch loss: 0.163473 Batch F1: 0.7
Epoch:  896        7 Batch loss: 0.160369 Batch F1: 0.7755102040816326
Epoch:  896        8 Batch loss: 0.197958 Batch F1: 0.6399999999999999
Epoch:  896        9 Batch loss: 0.174684 Batch F1: 0.7692307692307692
Epoch:  896       10 Batch loss: 0.185448 Batch F1: 0.6111111111111112
Epoch:  896       11 Batch loss: 0.163481 Batch F1: 0.7111111111111111
Epoch:  896       12 Batch loss: 0.165766 Batch F1: 0.7368421052631577
Train Avg Loss  896: 0.169841

Train Avg F1  896: 0.7078318149476228

Val Avg Loss  896: 0.181245

Val Avg F1  896:  0.6808795269770881

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 897
--------------------------------------------------------------
Epoch:  897        1 Batch loss: 0.181337 Batch F1: 0.7346938775510204
Epoch:  897        2 Batch loss: 0.174595 Batch F1: 0.5
Epoch:  897        3 Batch loss: 0.188235 Batch F1: 0.6521739130434783
Epoch:  897        4 Batch loss: 0.182552 Batch F1: 0.7407407407407408
Epoch:  897        5 Batch loss: 0.161439 Batch F1: 0.8214285714285715
Epoch:  897        6 Batch loss: 0.187324 Batch F1: 0.6938775510204083
Epoch:  897        7 Batch loss: 0.165927 Batch F1: 0.625
Epoch:  897        8 Batch loss: 0.178826 Batch F1: 0.6666666666666666
Epoch:  897        9 Batch loss: 0.155256 Batch F1: 0.7391304347826085
Epoch:  897       10 Batch loss: 0.147228 Batch F1: 0.870967741935484
Epoch:  897       11 Batch loss: 0.142540 Batch F1: 0.7647058823529411
Epoch:  897       12 Batch loss: 0.176990 Batch F1: 0.43478260869565216
Train Avg Loss  897: 0.170187

Train Avg F1  897: 0.6870139990181309

Val Avg Loss  897: 0.181861

Val Avg F1  897:  0.6754891103728313

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 898
--------------------------------------------------------------
Epoch:  898        1 Batch loss: 0.173257 Batch F1: 0.6956521739130435
Epoch:  898        2 Batch loss: 0.146725 Batch F1: 0.7804878048780488
Epoch:  898        3 Batch loss: 0.194451 Batch F1: 0.55
Epoch:  898        4 Batch loss: 0.186536 Batch F1: 0.68
Epoch:  898        5 Batch loss: 0.171380 Batch F1: 0.7450980392156864
Epoch:  898        6 Batch loss: 0.141612 Batch F1: 0.7368421052631579
Epoch:  898        7 Batch loss: 0.206418 Batch F1: 0.6808510638297872
Epoch:  898        8 Batch loss: 0.180157 Batch F1: 0.7586206896551724
Epoch:  898        9 Batch loss: 0.191700 Batch F1: 0.6511627906976745
Epoch:  898       10 Batch loss: 0.156914 Batch F1: 0.7027027027027027
Epoch:  898       11 Batch loss: 0.127598 Batch F1: 0.823529411764706
Epoch:  898       12 Batch loss: 0.159602 Batch F1: 0.7500000000000001
Train Avg Loss  898: 0.169696

Train Avg F1  898: 0.7129122318266651

Val Avg Loss  898: 0.181205

Val Avg F1  898:  0.6760809626881055

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 899
--------------------------------------------------------------
Epoch:  899        1 Batch loss: 0.155619 Batch F1: 0.7391304347826088
Epoch:  899        2 Batch loss: 0.183100 Batch F1: 0.6808510638297872
Epoch:  899        3 Batch loss: 0.186863 Batch F1: 0.6938775510204083
Epoch:  899        4 Batch loss: 0.199893 Batch F1: 0.6122448979591837
Epoch:  899        5 Batch loss: 0.173365 Batch F1: 0.7346938775510203
Epoch:  899        6 Batch loss: 0.156931 Batch F1: 0.6666666666666667
Epoch:  899        7 Batch loss: 0.165324 Batch F1: 0.7027027027027027
Epoch:  899        8 Batch loss: 0.162218 Batch F1: 0.6976744186046512
Epoch:  899        9 Batch loss: 0.151311 Batch F1: 0.742857142857143
Epoch:  899       10 Batch loss: 0.201435 Batch F1: 0.64
Epoch:  899       11 Batch loss: 0.140991 Batch F1: 0.8695652173913043
Epoch:  899       12 Batch loss: 0.154542 Batch F1: 0.7804878048780488
Train Avg Loss  899: 0.169300

Train Avg F1  899: 0.7133959815202938

Val Avg Loss  899: 0.181862

Val Avg F1  899:  0.6799242424242424

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 900
--------------------------------------------------------------
Epoch:  900        1 Batch loss: 0.159029 Batch F1: 0.7142857142857143
Epoch:  900        2 Batch loss: 0.137444 Batch F1: 0.8627450980392156
Epoch:  900        3 Batch loss: 0.194691 Batch F1: 0.6382978723404256
Epoch:  900        4 Batch loss: 0.157797 Batch F1: 0.7441860465116279
Epoch:  900        5 Batch loss: 0.187996 Batch F1: 0.6666666666666666
Epoch:  900        6 Batch loss: 0.196154 Batch F1: 0.5909090909090908
Epoch:  900        7 Batch loss: 0.158135 Batch F1: 0.7555555555555556
Epoch:  900        8 Batch loss: 0.195881 Batch F1: 0.6046511627906976
Epoch:  900        9 Batch loss: 0.166854 Batch F1: 0.7
Epoch:  900       10 Batch loss: 0.159050 Batch F1: 0.717948717948718
Epoch:  900       11 Batch loss: 0.149924 Batch F1: 0.8
Epoch:  900       12 Batch loss: 0.159915 Batch F1: 0.7222222222222222
Train Avg Loss  900: 0.168573

Train Avg F1  900: 0.7097890122724945

Val Avg Loss  900: 0.181006

Val Avg F1  900:  0.6717728758169935

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 901
--------------------------------------------------------------
Epoch:  901        1 Batch loss: 0.189654 Batch F1: 0.6666666666666666
Epoch:  901        2 Batch loss: 0.148295 Batch F1: 0.7499999999999999
Epoch:  901        3 Batch loss: 0.189215 Batch F1: 0.6666666666666667
Epoch:  901        4 Batch loss: 0.182317 Batch F1: 0.6341463414634146
Epoch:  901        5 Batch loss: 0.168476 Batch F1: 0.6976744186046512
Epoch:  901        6 Batch loss: 0.161585 Batch F1: 0.7
Epoch:  901        7 Batch loss: 0.167302 Batch F1: 0.7692307692307692
Epoch:  901        8 Batch loss: 0.156395 Batch F1: 0.7916666666666667
Epoch:  901        9 Batch loss: 0.162180 Batch F1: 0.7
Epoch:  901       10 Batch loss: 0.155265 Batch F1: 0.7659574468085107
Epoch:  901       11 Batch loss: 0.144709 Batch F1: 0.7368421052631577
Epoch:  901       12 Batch loss: 0.193314 Batch F1: 0.6666666666666666
Train Avg Loss  901: 0.168226

Train Avg F1  901: 0.7121264790030976

Val Avg Loss  901: 0.180874

Val Avg F1  901:  0.6726536042573777

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 902
--------------------------------------------------------------
Epoch:  902        1 Batch loss: 0.186293 Batch F1: 0.6792452830188679
Epoch:  902        2 Batch loss: 0.146702 Batch F1: 0.6428571428571429
Epoch:  902        3 Batch loss: 0.168182 Batch F1: 0.7083333333333334
Epoch:  902        4 Batch loss: 0.179393 Batch F1: 0.5882352941176471
Epoch:  902        5 Batch loss: 0.155567 Batch F1: 0.7
Epoch:  902        6 Batch loss: 0.189005 Batch F1: 0.6923076923076924
Epoch:  902        7 Batch loss: 0.140482 Batch F1: 0.8
Epoch:  902        8 Batch loss: 0.169531 Batch F1: 0.7142857142857143
Epoch:  902        9 Batch loss: 0.185457 Batch F1: 0.693877551020408
Epoch:  902       10 Batch loss: 0.170431 Batch F1: 0.723404255319149
Epoch:  902       11 Batch loss: 0.152403 Batch F1: 0.8214285714285714
Epoch:  902       12 Batch loss: 0.172643 Batch F1: 0.7222222222222222
Train Avg Loss  902: 0.168007

Train Avg F1  902: 0.7071830883258956

Val Avg Loss  902: 0.181406

Val Avg F1  902:  0.6776619143003024

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 903
--------------------------------------------------------------
Epoch:  903        1 Batch loss: 0.212601 Batch F1: 0.5
Epoch:  903        2 Batch loss: 0.169075 Batch F1: 0.7083333333333334
Epoch:  903        3 Batch loss: 0.138911 Batch F1: 0.8372093023255814
Epoch:  903        4 Batch loss: 0.149033 Batch F1: 0.7272727272727272
Epoch:  903        5 Batch loss: 0.217431 Batch F1: 0.6181818181818182
Epoch:  903        6 Batch loss: 0.175543 Batch F1: 0.6341463414634146
Epoch:  903        7 Batch loss: 0.169021 Batch F1: 0.6976744186046512
Epoch:  903        8 Batch loss: 0.162698 Batch F1: 0.6829268292682927
Epoch:  903        9 Batch loss: 0.153437 Batch F1: 0.7916666666666667
Epoch:  903       10 Batch loss: 0.155129 Batch F1: 0.7826086956521738
Epoch:  903       11 Batch loss: 0.150172 Batch F1: 0.7906976744186046
Epoch:  903       12 Batch loss: 0.168717 Batch F1: 0.7727272727272727
Train Avg Loss  903: 0.168481

Train Avg F1  903: 0.7119537566595447

Val Avg Loss  903: 0.180585

Val Avg F1  903:  0.6750799541990762

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 904
--------------------------------------------------------------
Epoch:  904        1 Batch loss: 0.175572 Batch F1: 0.7547169811320754
Epoch:  904        2 Batch loss: 0.182557 Batch F1: 0.5405405405405405
Epoch:  904        3 Batch loss: 0.160998 Batch F1: 0.7199999999999999
Epoch:  904        4 Batch loss: 0.153713 Batch F1: 0.7894736842105262
Epoch:  904        5 Batch loss: 0.156673 Batch F1: 0.7317073170731706
Epoch:  904        6 Batch loss: 0.174864 Batch F1: 0.7083333333333333
Epoch:  904        7 Batch loss: 0.186658 Batch F1: 0.7083333333333334
Epoch:  904        8 Batch loss: 0.191191 Batch F1: 0.5263157894736842
Epoch:  904        9 Batch loss: 0.144009 Batch F1: 0.8461538461538461
Epoch:  904       10 Batch loss: 0.178905 Batch F1: 0.6818181818181819
Epoch:  904       11 Batch loss: 0.145415 Batch F1: 0.7916666666666666
Epoch:  904       12 Batch loss: 0.173314 Batch F1: 0.6428571428571429
Train Avg Loss  904: 0.168656

Train Avg F1  904: 0.703493068049375

Val Avg Loss  904: 0.179847

Val Avg F1  904:  0.6770446815089671

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 905
--------------------------------------------------------------
Epoch:  905        1 Batch loss: 0.149398 Batch F1: 0.8333333333333333
Epoch:  905        2 Batch loss: 0.172378 Batch F1: 0.6511627906976744
Epoch:  905        3 Batch loss: 0.183212 Batch F1: 0.6938775510204083
Epoch:  905        4 Batch loss: 0.151271 Batch F1: 0.761904761904762
Epoch:  905        5 Batch loss: 0.170521 Batch F1: 0.6
Epoch:  905        6 Batch loss: 0.167963 Batch F1: 0.6829268292682927
Epoch:  905        7 Batch loss: 0.191311 Batch F1: 0.7547169811320756
Epoch:  905        8 Batch loss: 0.161431 Batch F1: 0.7391304347826089
Epoch:  905        9 Batch loss: 0.163597 Batch F1: 0.7
Epoch:  905       10 Batch loss: 0.160483 Batch F1: 0.7027027027027027
Epoch:  905       11 Batch loss: 0.185239 Batch F1: 0.6956521739130435
Epoch:  905       12 Batch loss: 0.173030 Batch F1: 0.7
Train Avg Loss  905: 0.169153

Train Avg F1  905: 0.7096172965629083

Val Avg Loss  905: 0.181002

Val Avg F1  905:  0.6737166647028789

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 906
--------------------------------------------------------------
Epoch:  906        1 Batch loss: 0.165564 Batch F1: 0.6842105263157895
Epoch:  906        2 Batch loss: 0.175836 Batch F1: 0.723404255319149
Epoch:  906        3 Batch loss: 0.144397 Batch F1: 0.7499999999999999
Epoch:  906        4 Batch loss: 0.163283 Batch F1: 0.782608695652174
Epoch:  906        5 Batch loss: 0.176334 Batch F1: 0.7083333333333334
Epoch:  906        6 Batch loss: 0.164222 Batch F1: 0.7857142857142856
Epoch:  906        7 Batch loss: 0.143261 Batch F1: 0.8444444444444444
Epoch:  906        8 Batch loss: 0.149863 Batch F1: 0.717948717948718
Epoch:  906        9 Batch loss: 0.188227 Batch F1: 0.5641025641025641
Epoch:  906       10 Batch loss: 0.171786 Batch F1: 0.6818181818181819
Epoch:  906       11 Batch loss: 0.196857 Batch F1: 0.64
Epoch:  906       12 Batch loss: 0.179496 Batch F1: 0.6060606060606061
Train Avg Loss  906: 0.168260

Train Avg F1  906: 0.7073871342257704

Val Avg Loss  906: 0.181184

Val Avg F1  906:  0.665993265993266

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 907
--------------------------------------------------------------
Epoch:  907        1 Batch loss: 0.159920 Batch F1: 0.761904761904762
Epoch:  907        2 Batch loss: 0.157558 Batch F1: 0.7916666666666666
Epoch:  907        3 Batch loss: 0.164208 Batch F1: 0.7346938775510204
Epoch:  907        4 Batch loss: 0.193966 Batch F1: 0.7058823529411765
Epoch:  907        5 Batch loss: 0.173468 Batch F1: 0.6511627906976744
Epoch:  907        6 Batch loss: 0.195669 Batch F1: 0.5365853658536586
Epoch:  907        7 Batch loss: 0.173622 Batch F1: 0.631578947368421
Epoch:  907        8 Batch loss: 0.178691 Batch F1: 0.5294117647058824
Epoch:  907        9 Batch loss: 0.131964 Batch F1: 0.8571428571428571
Epoch:  907       10 Batch loss: 0.176257 Batch F1: 0.7857142857142857
Epoch:  907       11 Batch loss: 0.160483 Batch F1: 0.7619047619047619
Epoch:  907       12 Batch loss: 0.162730 Batch F1: 0.717948717948718
Train Avg Loss  907: 0.169045

Train Avg F1  907: 0.7054664291999903

Val Avg Loss  907: 0.180469

Val Avg F1  907:  0.6746212121212121

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 908
--------------------------------------------------------------
Epoch:  908        1 Batch loss: 0.198774 Batch F1: 0.5263157894736842
Epoch:  908        2 Batch loss: 0.150482 Batch F1: 0.8085106382978724
Epoch:  908        3 Batch loss: 0.163704 Batch F1: 0.7555555555555556
Epoch:  908        4 Batch loss: 0.167929 Batch F1: 0.7058823529411765
Epoch:  908        5 Batch loss: 0.185591 Batch F1: 0.6530612244897959
Epoch:  908        6 Batch loss: 0.200115 Batch F1: 0.6250000000000001
Epoch:  908        7 Batch loss: 0.149012 Batch F1: 0.8399999999999999
Epoch:  908        8 Batch loss: 0.152910 Batch F1: 0.7317073170731707
Epoch:  908        9 Batch loss: 0.156498 Batch F1: 0.7111111111111111
Epoch:  908       10 Batch loss: 0.144138 Batch F1: 0.8095238095238095
Epoch:  908       11 Batch loss: 0.183071 Batch F1: 0.6666666666666666
Epoch:  908       12 Batch loss: 0.178784 Batch F1: 0.6842105263157895
Train Avg Loss  908: 0.169251

Train Avg F1  908: 0.7097954159540527

Val Avg Loss  908: 0.182494

Val Avg F1  908:  0.6770390904776287

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 909
--------------------------------------------------------------
Epoch:  909        1 Batch loss: 0.191982 Batch F1: 0.5641025641025642
Epoch:  909        2 Batch loss: 0.183184 Batch F1: 0.7407407407407408
Epoch:  909        3 Batch loss: 0.179282 Batch F1: 0.5555555555555555
Epoch:  909        4 Batch loss: 0.146409 Batch F1: 0.816326530612245
Epoch:  909        5 Batch loss: 0.173152 Batch F1: 0.6842105263157895
Epoch:  909        6 Batch loss: 0.198357 Batch F1: 0.64
Epoch:  909        7 Batch loss: 0.163880 Batch F1: 0.7142857142857143
Epoch:  909        8 Batch loss: 0.158801 Batch F1: 0.7843137254901961
Epoch:  909        9 Batch loss: 0.161473 Batch F1: 0.7555555555555556
Epoch:  909       10 Batch loss: 0.164703 Batch F1: 0.7500000000000001
Epoch:  909       11 Batch loss: 0.139795 Batch F1: 0.7058823529411764
Epoch:  909       12 Batch loss: 0.155586 Batch F1: 0.7692307692307692
Train Avg Loss  909: 0.168050

Train Avg F1  909: 0.7066836695691922

Val Avg Loss  909: 0.180126

Val Avg F1  909:  0.672562358276644

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 910
--------------------------------------------------------------
Epoch:  910        1 Batch loss: 0.159098 Batch F1: 0.744186046511628
Epoch:  910        2 Batch loss: 0.192413 Batch F1: 0.6666666666666667
Epoch:  910        3 Batch loss: 0.150004 Batch F1: 0.7368421052631579
Epoch:  910        4 Batch loss: 0.154444 Batch F1: 0.7142857142857143
Epoch:  910        5 Batch loss: 0.171367 Batch F1: 0.7083333333333333
Epoch:  910        6 Batch loss: 0.146163 Batch F1: 0.8148148148148148
Epoch:  910        7 Batch loss: 0.152280 Batch F1: 0.7000000000000001
Epoch:  910        8 Batch loss: 0.177931 Batch F1: 0.6808510638297872
Epoch:  910        9 Batch loss: 0.167148 Batch F1: 0.7317073170731708
Epoch:  910       10 Batch loss: 0.209924 Batch F1: 0.64
Epoch:  910       11 Batch loss: 0.155032 Batch F1: 0.7692307692307692
Epoch:  910       12 Batch loss: 0.180268 Batch F1: 0.625
Train Avg Loss  910: 0.168006

Train Avg F1  910: 0.7109931525840869

Val Avg Loss  910: 0.180637

Val Avg F1  910:  0.6773989898989901

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 911
--------------------------------------------------------------
Epoch:  911        1 Batch loss: 0.180880 Batch F1: 0.6222222222222222
Epoch:  911        2 Batch loss: 0.154580 Batch F1: 0.6285714285714286
Epoch:  911        3 Batch loss: 0.169639 Batch F1: 0.7857142857142857
Epoch:  911        4 Batch loss: 0.165843 Batch F1: 0.7142857142857143
Epoch:  911        5 Batch loss: 0.173329 Batch F1: 0.7
Epoch:  911        6 Batch loss: 0.152972 Batch F1: 0.6285714285714286
Epoch:  911        7 Batch loss: 0.193455 Batch F1: 0.7058823529411765
Epoch:  911        8 Batch loss: 0.155194 Batch F1: 0.8275862068965517
Epoch:  911        9 Batch loss: 0.156026 Batch F1: 0.7555555555555555
Epoch:  911       10 Batch loss: 0.137596 Batch F1: 0.7727272727272727
Epoch:  911       11 Batch loss: 0.198059 Batch F1: 0.6808510638297872
Epoch:  911       12 Batch loss: 0.178596 Batch F1: 0.5925925925925927
Train Avg Loss  911: 0.168014

Train Avg F1  911: 0.7012133436590013

Val Avg Loss  911: 0.180064

Val Avg F1  911:  0.6774472537429348

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 912
--------------------------------------------------------------
Epoch:  912        1 Batch loss: 0.161936 Batch F1: 0.7111111111111111
Epoch:  912        2 Batch loss: 0.128107 Batch F1: 0.8717948717948718
Epoch:  912        3 Batch loss: 0.191660 Batch F1: 0.5714285714285713
Epoch:  912        4 Batch loss: 0.158752 Batch F1: 0.7659574468085107
Epoch:  912        5 Batch loss: 0.182169 Batch F1: 0.6153846153846153
Epoch:  912        6 Batch loss: 0.214501 Batch F1: 0.5306122448979592
Epoch:  912        7 Batch loss: 0.154632 Batch F1: 0.7916666666666666
Epoch:  912        8 Batch loss: 0.192420 Batch F1: 0.6341463414634146
Epoch:  912        9 Batch loss: 0.166231 Batch F1: 0.7931034482758621
Epoch:  912       10 Batch loss: 0.149203 Batch F1: 0.7272727272727272
Epoch:  912       11 Batch loss: 0.164666 Batch F1: 0.7659574468085107
Epoch:  912       12 Batch loss: 0.159979 Batch F1: 0.7567567567567567
Train Avg Loss  912: 0.168688

Train Avg F1  912: 0.7112660207224648

Val Avg Loss  912: 0.182015

Val Avg F1  912:  0.6782990083905415

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 913
--------------------------------------------------------------
Epoch:  913        1 Batch loss: 0.150972 Batch F1: 0.8085106382978723
Epoch:  913        2 Batch loss: 0.220868 Batch F1: 0.5416666666666667
Epoch:  913        3 Batch loss: 0.162231 Batch F1: 0.7142857142857143
Epoch:  913        4 Batch loss: 0.184054 Batch F1: 0.693877551020408
Epoch:  913        5 Batch loss: 0.180631 Batch F1: 0.7142857142857143
Epoch:  913        6 Batch loss: 0.164729 Batch F1: 0.6829268292682927
Epoch:  913        7 Batch loss: 0.187488 Batch F1: 0.6956521739130435
Epoch:  913        8 Batch loss: 0.174081 Batch F1: 0.7307692307692308
Epoch:  913        9 Batch loss: 0.193240 Batch F1: 0.8135593220338982
Epoch:  913       10 Batch loss: 0.178839 Batch F1: 0.6808510638297872
Epoch:  913       11 Batch loss: 0.166852 Batch F1: 0.6500000000000001
Epoch:  913       12 Batch loss: 0.151636 Batch F1: 0.7500000000000001
Train Avg Loss  913: 0.176302

Train Avg F1  913: 0.7063654086975523

Val Avg Loss  913: 0.181927

Val Avg F1  913:  0.677244068359051

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 914
--------------------------------------------------------------
Epoch:  914        1 Batch loss: 0.151460 Batch F1: 0.7659574468085107
Epoch:  914        2 Batch loss: 0.147590 Batch F1: 0.8636363636363636
Epoch:  914        3 Batch loss: 0.154169 Batch F1: 0.7906976744186046
Epoch:  914        4 Batch loss: 0.184063 Batch F1: 0.6666666666666666
Epoch:  914        5 Batch loss: 0.158062 Batch F1: 0.7111111111111111
Epoch:  914        6 Batch loss: 0.183814 Batch F1: 0.7058823529411765
Epoch:  914        7 Batch loss: 0.198164 Batch F1: 0.6086956521739131
Epoch:  914        8 Batch loss: 0.172431 Batch F1: 0.6486486486486486
Epoch:  914        9 Batch loss: 0.191225 Batch F1: 0.68
Epoch:  914       10 Batch loss: 0.151041 Batch F1: 0.8
Epoch:  914       11 Batch loss: 0.164409 Batch F1: 0.7027027027027027
Epoch:  914       12 Batch loss: 0.180576 Batch F1: 0.625
Train Avg Loss  914: 0.169750

Train Avg F1  914: 0.7140832182589746

Val Avg Loss  914: 0.181013

Val Avg F1  914:  0.6723595629621454

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 915
--------------------------------------------------------------
Epoch:  915        1 Batch loss: 0.155255 Batch F1: 0.8
Epoch:  915        2 Batch loss: 0.170820 Batch F1: 0.6976744186046512
Epoch:  915        3 Batch loss: 0.187185 Batch F1: 0.6222222222222223
Epoch:  915        4 Batch loss: 0.166653 Batch F1: 0.6976744186046512
Epoch:  915        5 Batch loss: 0.172270 Batch F1: 0.7234042553191491
Epoch:  915        6 Batch loss: 0.166452 Batch F1: 0.6976744186046512
Epoch:  915        7 Batch loss: 0.164353 Batch F1: 0.7222222222222222
Epoch:  915        8 Batch loss: 0.144876 Batch F1: 0.7906976744186046
Epoch:  915        9 Batch loss: 0.181506 Batch F1: 0.7111111111111111
Epoch:  915       10 Batch loss: 0.195059 Batch F1: 0.6086956521739131
Epoch:  915       11 Batch loss: 0.165609 Batch F1: 0.7272727272727272
Epoch:  915       12 Batch loss: 0.180405 Batch F1: 0.7555555555555556
Train Avg Loss  915: 0.170870

Train Avg F1  915: 0.7128503896757884

Val Avg Loss  915: 0.181997

Val Avg F1  915:  0.6752952842056846

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 916
--------------------------------------------------------------
Epoch:  916        1 Batch loss: 0.150028 Batch F1: 0.8
Epoch:  916        2 Batch loss: 0.175860 Batch F1: 0.7857142857142856
Epoch:  916        3 Batch loss: 0.188841 Batch F1: 0.6222222222222222
Epoch:  916        4 Batch loss: 0.184688 Batch F1: 0.6363636363636365
Epoch:  916        5 Batch loss: 0.167974 Batch F1: 0.6976744186046512
Epoch:  916        6 Batch loss: 0.162426 Batch F1: 0.7499999999999999
Epoch:  916        7 Batch loss: 0.176234 Batch F1: 0.5517241379310345
Epoch:  916        8 Batch loss: 0.171752 Batch F1: 0.6486486486486486
Epoch:  916        9 Batch loss: 0.184265 Batch F1: 0.65
Epoch:  916       10 Batch loss: 0.171928 Batch F1: 0.7272727272727273
Epoch:  916       11 Batch loss: 0.172012 Batch F1: 0.7111111111111111
Epoch:  916       12 Batch loss: 0.141668 Batch F1: 0.8636363636363636
Train Avg Loss  916: 0.170640

Train Avg F1  916: 0.7036972959587234

Val Avg Loss  916: 0.182758

Val Avg F1  916:  0.6767846130126426

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 917
--------------------------------------------------------------
Epoch:  917        1 Batch loss: 0.172116 Batch F1: 0.6976744186046512
Epoch:  917        2 Batch loss: 0.199625 Batch F1: 0.5581395348837208
Epoch:  917        3 Batch loss: 0.176239 Batch F1: 0.7547169811320756
Epoch:  917        4 Batch loss: 0.186348 Batch F1: 0.6938775510204083
Epoch:  917        5 Batch loss: 0.143109 Batch F1: 0.7058823529411765
Epoch:  917        6 Batch loss: 0.179882 Batch F1: 0.7796610169491525
Epoch:  917        7 Batch loss: 0.170565 Batch F1: 0.7346938775510204
Epoch:  917        8 Batch loss: 0.153992 Batch F1: 0.7727272727272727
Epoch:  917        9 Batch loss: 0.163886 Batch F1: 0.7441860465116279
Epoch:  917       10 Batch loss: 0.194730 Batch F1: 0.6923076923076923
Epoch:  917       11 Batch loss: 0.160536 Batch F1: 0.7368421052631577
Epoch:  917       12 Batch loss: 0.134546 Batch F1: 0.5555555555555556
Train Avg Loss  917: 0.169631

Train Avg F1  917: 0.7021887004539593

Val Avg Loss  917: 0.181566

Val Avg F1  917:  0.6740975459951422

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 918
--------------------------------------------------------------
Epoch:  918        1 Batch loss: 0.157615 Batch F1: 0.7916666666666667
Epoch:  918        2 Batch loss: 0.171024 Batch F1: 0.6829268292682926
Epoch:  918        3 Batch loss: 0.180762 Batch F1: 0.6153846153846154
Epoch:  918        4 Batch loss: 0.208870 Batch F1: 0.6415094339622641
Epoch:  918        5 Batch loss: 0.167224 Batch F1: 0.65
Epoch:  918        6 Batch loss: 0.153052 Batch F1: 0.7692307692307692
Epoch:  918        7 Batch loss: 0.164530 Batch F1: 0.7499999999999999
Epoch:  918        8 Batch loss: 0.164548 Batch F1: 0.6976744186046512
Epoch:  918        9 Batch loss: 0.167663 Batch F1: 0.7500000000000001
Epoch:  918       10 Batch loss: 0.163204 Batch F1: 0.7755102040816326
Epoch:  918       11 Batch loss: 0.151980 Batch F1: 0.7804878048780488
Epoch:  918       12 Batch loss: 0.185743 Batch F1: 0.611111111111111
Train Avg Loss  918: 0.169685

Train Avg F1  918: 0.7096251544323376

Val Avg Loss  918: 0.180608

Val Avg F1  918:  0.6765566167811623

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 919
--------------------------------------------------------------
Epoch:  919        1 Batch loss: 0.160940 Batch F1: 0.6666666666666667
Epoch:  919        2 Batch loss: 0.152508 Batch F1: 0.8076923076923077
Epoch:  919        3 Batch loss: 0.187393 Batch F1: 0.6341463414634148
Epoch:  919        4 Batch loss: 0.200203 Batch F1: 0.5714285714285713
Epoch:  919        5 Batch loss: 0.177985 Batch F1: 0.7500000000000001
Epoch:  919        6 Batch loss: 0.183952 Batch F1: 0.6808510638297872
Epoch:  919        7 Batch loss: 0.174866 Batch F1: 0.6818181818181818
Epoch:  919        8 Batch loss: 0.155652 Batch F1: 0.7755102040816326
Epoch:  919        9 Batch loss: 0.170185 Batch F1: 0.7659574468085107
Epoch:  919       10 Batch loss: 0.147836 Batch F1: 0.7555555555555556
Epoch:  919       11 Batch loss: 0.156949 Batch F1: 0.75
Epoch:  919       12 Batch loss: 0.175694 Batch F1: 0.6470588235294118
Train Avg Loss  919: 0.170347

Train Avg F1  919: 0.7072237635728366

Val Avg Loss  919: 0.182354

Val Avg F1  919:  0.6759780720798958

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 920
--------------------------------------------------------------
Epoch:  920        1 Batch loss: 0.164736 Batch F1: 0.7692307692307692
Epoch:  920        2 Batch loss: 0.181176 Batch F1: 0.6666666666666665
Epoch:  920        3 Batch loss: 0.157367 Batch F1: 0.717948717948718
Epoch:  920        4 Batch loss: 0.192700 Batch F1: 0.6060606060606061
Epoch:  920        5 Batch loss: 0.170111 Batch F1: 0.6666666666666667
Epoch:  920        6 Batch loss: 0.158396 Batch F1: 0.7
Epoch:  920        7 Batch loss: 0.166840 Batch F1: 0.7500000000000001
Epoch:  920        8 Batch loss: 0.171793 Batch F1: 0.7234042553191491
Epoch:  920        9 Batch loss: 0.195639 Batch F1: 0.6909090909090909
Epoch:  920       10 Batch loss: 0.168880 Batch F1: 0.7659574468085107
Epoch:  920       11 Batch loss: 0.172734 Batch F1: 0.8095238095238095
Epoch:  920       12 Batch loss: 0.183984 Batch F1: 0.7
Train Avg Loss  920: 0.173696

Train Avg F1  920: 0.7138640024278322

Val Avg Loss  920: 0.185134

Val Avg F1  920:  0.6803921568627451

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 921
--------------------------------------------------------------
Epoch:  921        1 Batch loss: 0.190656 Batch F1: 0.7636363636363638
Epoch:  921        2 Batch loss: 0.155861 Batch F1: 0.717948717948718
Epoch:  921        3 Batch loss: 0.186969 Batch F1: 0.6521739130434783
Epoch:  921        4 Batch loss: 0.142557 Batch F1: 0.8181818181818182
Epoch:  921        5 Batch loss: 0.179450 Batch F1: 0.7719298245614036
Epoch:  921        6 Batch loss: 0.183163 Batch F1: 0.6486486486486486
Epoch:  921        7 Batch loss: 0.147946 Batch F1: 0.7058823529411765
Epoch:  921        8 Batch loss: 0.187480 Batch F1: 0.5789473684210527
Epoch:  921        9 Batch loss: 0.166035 Batch F1: 0.6976744186046512
Epoch:  921       10 Batch loss: 0.197010 Batch F1: 0.5641025641025642
Epoch:  921       11 Batch loss: 0.169442 Batch F1: 0.7307692307692308
Epoch:  921       12 Batch loss: 0.157558 Batch F1: 0.8292682926829269
Train Avg Loss  921: 0.172011

Train Avg F1  921: 0.7065969594618361

Val Avg Loss  921: 0.181466

Val Avg F1  921:  0.6670950230380722

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 922
--------------------------------------------------------------
Epoch:  922        1 Batch loss: 0.119835 Batch F1: 0.8421052631578948
Epoch:  922        2 Batch loss: 0.164579 Batch F1: 0.6842105263157895
Epoch:  922        3 Batch loss: 0.139246 Batch F1: 0.8000000000000002
Epoch:  922        4 Batch loss: 0.179766 Batch F1: 0.6190476190476191
Epoch:  922        5 Batch loss: 0.199418 Batch F1: 0.5500000000000002
Epoch:  922        6 Batch loss: 0.187494 Batch F1: 0.6511627906976745
Epoch:  922        7 Batch loss: 0.174403 Batch F1: 0.7755102040816326
Epoch:  922        8 Batch loss: 0.141484 Batch F1: 0.8333333333333334
Epoch:  922        9 Batch loss: 0.201242 Batch F1: 0.6538461538461539
Epoch:  922       10 Batch loss: 0.159051 Batch F1: 0.8
Epoch:  922       11 Batch loss: 0.184672 Batch F1: 0.7058823529411765
Epoch:  922       12 Batch loss: 0.187637 Batch F1: 0.5882352941176471
Train Avg Loss  922: 0.169902

Train Avg F1  922: 0.7086111281282435

Val Avg Loss  922: 0.180694

Val Avg F1  922:  0.6774156471099078

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 923
--------------------------------------------------------------
Epoch:  923        1 Batch loss: 0.142308 Batch F1: 0.7368421052631577
Epoch:  923        2 Batch loss: 0.168070 Batch F1: 0.7111111111111111
Epoch:  923        3 Batch loss: 0.186439 Batch F1: 0.6666666666666666
Epoch:  923        4 Batch loss: 0.163274 Batch F1: 0.8070175438596492
Epoch:  923        5 Batch loss: 0.189642 Batch F1: 0.6341463414634146
Epoch:  923        6 Batch loss: 0.182040 Batch F1: 0.5263157894736842
Epoch:  923        7 Batch loss: 0.133251 Batch F1: 0.8749999999999999
Epoch:  923        8 Batch loss: 0.154420 Batch F1: 0.7272727272727272
Epoch:  923        9 Batch loss: 0.157975 Batch F1: 0.761904761904762
Epoch:  923       10 Batch loss: 0.170689 Batch F1: 0.6829268292682926
Epoch:  923       11 Batch loss: 0.189875 Batch F1: 0.6046511627906976
Epoch:  923       12 Batch loss: 0.184592 Batch F1: 0.7555555555555556
Train Avg Loss  923: 0.168548

Train Avg F1  923: 0.7074508828858099

Val Avg Loss  923: 0.181020

Val Avg F1  923:  0.6755213713392334

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 924
--------------------------------------------------------------
Epoch:  924        1 Batch loss: 0.159503 Batch F1: 0.717948717948718
Epoch:  924        2 Batch loss: 0.167508 Batch F1: 0.6666666666666667
Epoch:  924        3 Batch loss: 0.142285 Batch F1: 0.7727272727272727
Epoch:  924        4 Batch loss: 0.161561 Batch F1: 0.6486486486486486
Epoch:  924        5 Batch loss: 0.180960 Batch F1: 0.6500000000000001
Epoch:  924        6 Batch loss: 0.181303 Batch F1: 0.72
Epoch:  924        7 Batch loss: 0.185333 Batch F1: 0.6666666666666666
Epoch:  924        8 Batch loss: 0.147112 Batch F1: 0.8571428571428572
Epoch:  924        9 Batch loss: 0.147063 Batch F1: 0.8333333333333333
Epoch:  924       10 Batch loss: 0.192934 Batch F1: 0.6222222222222222
Epoch:  924       11 Batch loss: 0.175970 Batch F1: 0.7547169811320754
Epoch:  924       12 Batch loss: 0.191171 Batch F1: 0.5714285714285714
Train Avg Loss  924: 0.169392

Train Avg F1  924: 0.7067918281597527

Val Avg Loss  924: 0.181662

Val Avg F1  924:  0.6727029038093436

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 925
--------------------------------------------------------------
Epoch:  925        1 Batch loss: 0.165056 Batch F1: 0.6666666666666667
Epoch:  925        2 Batch loss: 0.159094 Batch F1: 0.6486486486486486
Epoch:  925        3 Batch loss: 0.216172 Batch F1: 0.6296296296296295
Epoch:  925        4 Batch loss: 0.123513 Batch F1: 0.8979591836734693
Epoch:  925        5 Batch loss: 0.171100 Batch F1: 0.6976744186046512
Epoch:  925        6 Batch loss: 0.169330 Batch F1: 0.7272727272727273
Epoch:  925        7 Batch loss: 0.152768 Batch F1: 0.7647058823529411
Epoch:  925        8 Batch loss: 0.180264 Batch F1: 0.6956521739130435
Epoch:  925        9 Batch loss: 0.193220 Batch F1: 0.68
Epoch:  925       10 Batch loss: 0.157874 Batch F1: 0.7843137254901961
Epoch:  925       11 Batch loss: 0.180313 Batch F1: 0.6666666666666666
Epoch:  925       12 Batch loss: 0.167973 Batch F1: 0.6666666666666666
Train Avg Loss  925: 0.169723

Train Avg F1  925: 0.7104880324654421

Val Avg Loss  925: 0.181632

Val Avg F1  925:  0.6735458003405426

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 926
--------------------------------------------------------------
Epoch:  926        1 Batch loss: 0.158075 Batch F1: 0.7317073170731707
Epoch:  926        2 Batch loss: 0.164119 Batch F1: 0.7500000000000001
Epoch:  926        3 Batch loss: 0.201930 Batch F1: 0.5500000000000002
Epoch:  926        4 Batch loss: 0.166538 Batch F1: 0.7499999999999999
Epoch:  926        5 Batch loss: 0.147390 Batch F1: 0.816326530612245
Epoch:  926        6 Batch loss: 0.153534 Batch F1: 0.7441860465116279
Epoch:  926        7 Batch loss: 0.175393 Batch F1: 0.6829268292682927
Epoch:  926        8 Batch loss: 0.181793 Batch F1: 0.7307692307692306
Epoch:  926        9 Batch loss: 0.182358 Batch F1: 0.6511627906976744
Epoch:  926       10 Batch loss: 0.176090 Batch F1: 0.65
Epoch:  926       11 Batch loss: 0.131063 Batch F1: 0.7272727272727273
Epoch:  926       12 Batch loss: 0.183356 Batch F1: 0.723404255319149
Train Avg Loss  926: 0.168470

Train Avg F1  926: 0.7089796439603432

Val Avg Loss  926: 0.180799

Val Avg F1  926:  0.6790315320189582

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 927
--------------------------------------------------------------
Epoch:  927        1 Batch loss: 0.180566 Batch F1: 0.6818181818181819
Epoch:  927        2 Batch loss: 0.182336 Batch F1: 0.7199999999999999
Epoch:  927        3 Batch loss: 0.164040 Batch F1: 0.7555555555555555
Epoch:  927        4 Batch loss: 0.136421 Batch F1: 0.8333333333333333
Epoch:  927        5 Batch loss: 0.137578 Batch F1: 0.7567567567567567
Epoch:  927        6 Batch loss: 0.171602 Batch F1: 0.7272727272727273
Epoch:  927        7 Batch loss: 0.202771 Batch F1: 0.5777777777777778
Epoch:  927        8 Batch loss: 0.169233 Batch F1: 0.7636363636363636
Epoch:  927        9 Batch loss: 0.158965 Batch F1: 0.7441860465116279
Epoch:  927       10 Batch loss: 0.174939 Batch F1: 0.6666666666666667
Epoch:  927       11 Batch loss: 0.160169 Batch F1: 0.723404255319149
Epoch:  927       12 Batch loss: 0.186614 Batch F1: 0.5
Train Avg Loss  927: 0.168770

Train Avg F1  927: 0.7042006387206783

Val Avg Loss  927: 0.180654

Val Avg F1  927:  0.6726765614446513

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 928
--------------------------------------------------------------
Epoch:  928        1 Batch loss: 0.162117 Batch F1: 0.7727272727272727
Epoch:  928        2 Batch loss: 0.178572 Batch F1: 0.6666666666666666
Epoch:  928        3 Batch loss: 0.159556 Batch F1: 0.7659574468085107
Epoch:  928        4 Batch loss: 0.180953 Batch F1: 0.6363636363636365
Epoch:  928        5 Batch loss: 0.160081 Batch F1: 0.7111111111111111
Epoch:  928        6 Batch loss: 0.175493 Batch F1: 0.782608695652174
Epoch:  928        7 Batch loss: 0.163156 Batch F1: 0.7234042553191489
Epoch:  928        8 Batch loss: 0.179610 Batch F1: 0.6666666666666666
Epoch:  928        9 Batch loss: 0.159025 Batch F1: 0.7843137254901961
Epoch:  928       10 Batch loss: 0.199199 Batch F1: 0.5365853658536586
Epoch:  928       11 Batch loss: 0.176508 Batch F1: 0.6976744186046512
Epoch:  928       12 Batch loss: 0.142061 Batch F1: 0.787878787878788
Train Avg Loss  928: 0.169694

Train Avg F1  928: 0.7109965040952068

Val Avg Loss  928: 0.182459

Val Avg F1  928:  0.6770154870458822

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 929
--------------------------------------------------------------
Epoch:  929        1 Batch loss: 0.186890 Batch F1: 0.6666666666666666
Epoch:  929        2 Batch loss: 0.174937 Batch F1: 0.6956521739130435
Epoch:  929        3 Batch loss: 0.175267 Batch F1: 0.6808510638297872
Epoch:  929        4 Batch loss: 0.148470 Batch F1: 0.823529411764706
Epoch:  929        5 Batch loss: 0.190996 Batch F1: 0.5789473684210527
Epoch:  929        6 Batch loss: 0.172172 Batch F1: 0.7755102040816326
Epoch:  929        7 Batch loss: 0.140818 Batch F1: 0.8181818181818182
Epoch:  929        8 Batch loss: 0.181155 Batch F1: 0.6222222222222223
Epoch:  929        9 Batch loss: 0.151649 Batch F1: 0.8
Epoch:  929       10 Batch loss: 0.167155 Batch F1: 0.7083333333333334
Epoch:  929       11 Batch loss: 0.181959 Batch F1: 0.6111111111111112
Epoch:  929       12 Batch loss: 0.154119 Batch F1: 0.7222222222222223
Train Avg Loss  929: 0.168799

Train Avg F1  929: 0.708602299645633

Val Avg Loss  929: 0.181053

Val Avg F1  929:  0.6720245332175424

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 930
--------------------------------------------------------------
Epoch:  930        1 Batch loss: 0.145366 Batch F1: 0.8363636363636363
Epoch:  930        2 Batch loss: 0.188988 Batch F1: 0.7307692307692306
Epoch:  930        3 Batch loss: 0.185191 Batch F1: 0.6341463414634146
Epoch:  930        4 Batch loss: 0.153261 Batch F1: 0.7826086956521738
Epoch:  930        5 Batch loss: 0.198848 Batch F1: 0.5853658536585366
Epoch:  930        6 Batch loss: 0.150700 Batch F1: 0.7027027027027027
Epoch:  930        7 Batch loss: 0.172615 Batch F1: 0.5454545454545455
Epoch:  930        8 Batch loss: 0.196710 Batch F1: 0.6909090909090909
Epoch:  930        9 Batch loss: 0.143608 Batch F1: 0.8679245283018868
Epoch:  930       10 Batch loss: 0.143370 Batch F1: 0.7222222222222223
Epoch:  930       11 Batch loss: 0.193736 Batch F1: 0.6382978723404256
Epoch:  930       12 Batch loss: 0.164846 Batch F1: 0.689655172413793
Train Avg Loss  930: 0.169770

Train Avg F1  930: 0.7022016576876383

Val Avg Loss  930: 0.180383

Val Avg F1  930:  0.6777777777777778

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 931
--------------------------------------------------------------
Epoch:  931        1 Batch loss: 0.182114 Batch F1: 0.5853658536585366
Epoch:  931        2 Batch loss: 0.196262 Batch F1: 0.6190476190476191
Epoch:  931        3 Batch loss: 0.173025 Batch F1: 0.6829268292682926
Epoch:  931        4 Batch loss: 0.153620 Batch F1: 0.782608695652174
Epoch:  931        5 Batch loss: 0.158524 Batch F1: 0.7368421052631577
Epoch:  931        6 Batch loss: 0.159083 Batch F1: 0.717948717948718
Epoch:  931        7 Batch loss: 0.155466 Batch F1: 0.8421052631578948
Epoch:  931        8 Batch loss: 0.164106 Batch F1: 0.7843137254901961
Epoch:  931        9 Batch loss: 0.172663 Batch F1: 0.7199999999999999
Epoch:  931       10 Batch loss: 0.174308 Batch F1: 0.6666666666666666
Epoch:  931       11 Batch loss: 0.180802 Batch F1: 0.5945945945945946
Epoch:  931       12 Batch loss: 0.166675 Batch F1: 0.7317073170731706
Train Avg Loss  931: 0.169721

Train Avg F1  931: 0.7053439489850851

Val Avg Loss  931: 0.181454

Val Avg F1  931:  0.6616367069063447

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 932
--------------------------------------------------------------
Epoch:  932        1 Batch loss: 0.169396 Batch F1: 0.75
Epoch:  932        2 Batch loss: 0.183877 Batch F1: 0.6153846153846153
Epoch:  932        3 Batch loss: 0.184563 Batch F1: 0.6521739130434783
Epoch:  932        4 Batch loss: 0.165745 Batch F1: 0.7555555555555555
Epoch:  932        5 Batch loss: 0.169760 Batch F1: 0.6285714285714287
Epoch:  932        6 Batch loss: 0.154961 Batch F1: 0.7317073170731706
Epoch:  932        7 Batch loss: 0.165164 Batch F1: 0.8148148148148148
Epoch:  932        8 Batch loss: 0.152049 Batch F1: 0.7727272727272727
Epoch:  932        9 Batch loss: 0.179052 Batch F1: 0.7407407407407408
Epoch:  932       10 Batch loss: 0.178817 Batch F1: 0.6923076923076923
Epoch:  932       11 Batch loss: 0.171849 Batch F1: 0.6818181818181818
Epoch:  932       12 Batch loss: 0.194424 Batch F1: 0.5
Train Avg Loss  932: 0.172471

Train Avg F1  932: 0.6946501276697458

Val Avg Loss  932: 0.183610

Val Avg F1  932:  0.6756372549019608

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 933
--------------------------------------------------------------
Epoch:  933        1 Batch loss: 0.156096 Batch F1: 0.7906976744186046
Epoch:  933        2 Batch loss: 0.190388 Batch F1: 0.76
Epoch:  933        3 Batch loss: 0.165410 Batch F1: 0.7272727272727272
Epoch:  933        4 Batch loss: 0.182780 Batch F1: 0.6190476190476191
Epoch:  933        5 Batch loss: 0.179819 Batch F1: 0.6808510638297872
Epoch:  933        6 Batch loss: 0.197923 Batch F1: 0.6818181818181819
Epoch:  933        7 Batch loss: 0.170690 Batch F1: 0.7142857142857143
Epoch:  933        8 Batch loss: 0.137043 Batch F1: 0.8
Epoch:  933        9 Batch loss: 0.159079 Batch F1: 0.7317073170731707
Epoch:  933       10 Batch loss: 0.184523 Batch F1: 0.6521739130434783
Epoch:  933       11 Batch loss: 0.172838 Batch F1: 0.6956521739130435
Epoch:  933       12 Batch loss: 0.169879 Batch F1: 0.6857142857142857
Train Avg Loss  933: 0.172206

Train Avg F1  933: 0.7116017225347177

Val Avg Loss  933: 0.181548

Val Avg F1  933:  0.6714752567693744

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 934
--------------------------------------------------------------
Epoch:  934        1 Batch loss: 0.157975 Batch F1: 0.7843137254901961
Epoch:  934        2 Batch loss: 0.161298 Batch F1: 0.75
Epoch:  934        3 Batch loss: 0.177521 Batch F1: 0.7547169811320754
Epoch:  934        4 Batch loss: 0.162773 Batch F1: 0.7727272727272727
Epoch:  934        5 Batch loss: 0.185204 Batch F1: 0.6666666666666666
Epoch:  934        6 Batch loss: 0.174286 Batch F1: 0.6666666666666666
Epoch:  934        7 Batch loss: 0.164589 Batch F1: 0.5625000000000001
Epoch:  934        8 Batch loss: 0.191540 Batch F1: 0.5641025641025642
Epoch:  934        9 Batch loss: 0.184951 Batch F1: 0.6923076923076923
Epoch:  934       10 Batch loss: 0.169564 Batch F1: 0.8444444444444444
Epoch:  934       11 Batch loss: 0.152375 Batch F1: 0.85
Epoch:  934       12 Batch loss: 0.176735 Batch F1: 0.7272727272727272
Train Avg Loss  934: 0.171568

Train Avg F1  934: 0.7196432284008587

Val Avg Loss  934: 0.182238

Val Avg F1  934:  0.672639996169408

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 935
--------------------------------------------------------------
Epoch:  935        1 Batch loss: 0.143740 Batch F1: 0.8444444444444444
Epoch:  935        2 Batch loss: 0.158441 Batch F1: 0.6666666666666667
Epoch:  935        3 Batch loss: 0.172653 Batch F1: 0.7058823529411765
Epoch:  935        4 Batch loss: 0.178583 Batch F1: 0.7083333333333334
Epoch:  935        5 Batch loss: 0.193957 Batch F1: 0.5853658536585366
Epoch:  935        6 Batch loss: 0.186334 Batch F1: 0.6923076923076923
Epoch:  935        7 Batch loss: 0.160975 Batch F1: 0.7555555555555556
Epoch:  935        8 Batch loss: 0.157215 Batch F1: 0.7659574468085107
Epoch:  935        9 Batch loss: 0.162733 Batch F1: 0.6976744186046512
Epoch:  935       10 Batch loss: 0.174970 Batch F1: 0.7169811320754718
Epoch:  935       11 Batch loss: 0.205166 Batch F1: 0.7924528301886793
Epoch:  935       12 Batch loss: 0.161516 Batch F1: 0.6875
Train Avg Loss  935: 0.171357

Train Avg F1  935: 0.7182601438820599

Val Avg Loss  935: 0.184873

Val Avg F1  935:  0.6791693421554669

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 936
--------------------------------------------------------------
Epoch:  936        1 Batch loss: 0.190007 Batch F1: 0.5945945945945946
Epoch:  936        2 Batch loss: 0.170667 Batch F1: 0.7391304347826089
Epoch:  936        3 Batch loss: 0.189563 Batch F1: 0.75
Epoch:  936        4 Batch loss: 0.213995 Batch F1: 0.7164179104477612
Epoch:  936        5 Batch loss: 0.181768 Batch F1: 0.7272727272727274
Epoch:  936        6 Batch loss: 0.179857 Batch F1: 0.6341463414634146
Epoch:  936        7 Batch loss: 0.167919 Batch F1: 0.6857142857142857
Epoch:  936        8 Batch loss: 0.200332 Batch F1: 0.5365853658536586
Epoch:  936        9 Batch loss: 0.174447 Batch F1: 0.7
Epoch:  936       10 Batch loss: 0.180378 Batch F1: 0.6285714285714287
Epoch:  936       11 Batch loss: 0.154927 Batch F1: 0.8235294117647058
Epoch:  936       12 Batch loss: 0.130852 Batch F1: 0.8636363636363636
Train Avg Loss  936: 0.177893

Train Avg F1  936: 0.6999665720084626

Val Avg Loss  936: 0.196149

Val Avg F1  936:  0.8349476381953957

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 937
--------------------------------------------------------------
Epoch:  937        1 Batch loss: 0.222347 Batch F1: 0.7272727272727273
Epoch:  937        2 Batch loss: 0.185913 Batch F1: 0.723404255319149
Epoch:  937        3 Batch loss: 0.185546 Batch F1: 0.6666666666666666
Epoch:  937        4 Batch loss: 0.169740 Batch F1: 0.8260869565217391
Epoch:  937        5 Batch loss: 0.180646 Batch F1: 0.6341463414634146
Epoch:  937        6 Batch loss: 0.168186 Batch F1: 0.8399999999999999
Epoch:  937        7 Batch loss: 0.188912 Batch F1: 0.7804878048780487
Epoch:  937        8 Batch loss: 0.156561 Batch F1: 0.8461538461538461
Epoch:  937        9 Batch loss: 0.182266 Batch F1: 0.723404255319149
Epoch:  937       10 Batch loss: 0.162230 Batch F1: 0.8333333333333334
Epoch:  937       11 Batch loss: 0.192546 Batch F1: 0.6666666666666667
Epoch:  937       12 Batch loss: 0.175818 Batch F1: 0.7027027027027026
Train Avg Loss  937: 0.180893

Train Avg F1  937: 0.7475271296914535

Val Avg Loss  937: 0.185162

Val Avg F1  937:  0.6735319545878551

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 938
--------------------------------------------------------------
Epoch:  938        1 Batch loss: 0.173694 Batch F1: 0.7857142857142857
Epoch:  938        2 Batch loss: 0.175672 Batch F1: 0.7234042553191491
Epoch:  938        3 Batch loss: 0.166610 Batch F1: 0.7234042553191491
Epoch:  938        4 Batch loss: 0.163160 Batch F1: 0.6923076923076923
Epoch:  938        5 Batch loss: 0.187827 Batch F1: 0.6666666666666667
Epoch:  938        6 Batch loss: 0.164039 Batch F1: 0.717948717948718
Epoch:  938        7 Batch loss: 0.205449 Batch F1: 0.48648648648648646
Epoch:  938        8 Batch loss: 0.183472 Batch F1: 0.7142857142857143
Epoch:  938        9 Batch loss: 0.192728 Batch F1: 0.5499999999999999
Epoch:  938       10 Batch loss: 0.157844 Batch F1: 0.7619047619047619
Epoch:  938       11 Batch loss: 0.187076 Batch F1: 0.5142857142857143
Epoch:  938       12 Batch loss: 0.162029 Batch F1: 0.7058823529411765
Train Avg Loss  938: 0.176633

Train Avg F1  938: 0.6701909085982929

Val Avg Loss  938: 0.181777

Val Avg F1  938:  0.672736636868631

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 939
--------------------------------------------------------------
Epoch:  939        1 Batch loss: 0.164368 Batch F1: 0.7659574468085107
Epoch:  939        2 Batch loss: 0.173523 Batch F1: 0.7142857142857143
Epoch:  939        3 Batch loss: 0.164161 Batch F1: 0.6486486486486486
Epoch:  939        4 Batch loss: 0.172294 Batch F1: 0.7346938775510204
Epoch:  939        5 Batch loss: 0.150657 Batch F1: 0.782608695652174
Epoch:  939        6 Batch loss: 0.151921 Batch F1: 0.761904761904762
Epoch:  939        7 Batch loss: 0.160274 Batch F1: 0.7317073170731706
Epoch:  939        8 Batch loss: 0.191071 Batch F1: 0.7272727272727274
Epoch:  939        9 Batch loss: 0.182693 Batch F1: 0.5945945945945946
Epoch:  939       10 Batch loss: 0.187052 Batch F1: 0.6153846153846154
Epoch:  939       11 Batch loss: 0.171905 Batch F1: 0.7346938775510204
Epoch:  939       12 Batch loss: 0.180985 Batch F1: 0.6829268292682926
Train Avg Loss  939: 0.170909

Train Avg F1  939: 0.7078899254996043

Val Avg Loss  939: 0.183703

Val Avg F1  939:  0.6695769216777621

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 940
--------------------------------------------------------------
Epoch:  940        1 Batch loss: 0.163124 Batch F1: 0.7142857142857143
Epoch:  940        2 Batch loss: 0.200888 Batch F1: 0.5
Epoch:  940        3 Batch loss: 0.176120 Batch F1: 0.6956521739130435
Epoch:  940        4 Batch loss: 0.140891 Batch F1: 0.7692307692307693
Epoch:  940        5 Batch loss: 0.139286 Batch F1: 0.851063829787234
Epoch:  940        6 Batch loss: 0.167621 Batch F1: 0.7272727272727272
Epoch:  940        7 Batch loss: 0.193480 Batch F1: 0.5853658536585366
Epoch:  940        8 Batch loss: 0.179774 Batch F1: 0.6956521739130435
Epoch:  940        9 Batch loss: 0.216829 Batch F1: 0.6415094339622641
Epoch:  940       10 Batch loss: 0.149108 Batch F1: 0.7692307692307692
Epoch:  940       11 Batch loss: 0.143947 Batch F1: 0.8571428571428571
Epoch:  940       12 Batch loss: 0.164609 Batch F1: 0.7096774193548386
Train Avg Loss  940: 0.169640

Train Avg F1  940: 0.7096736434793164

Val Avg Loss  940: 0.183581

Val Avg F1  940:  0.6656738226368438

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 941
--------------------------------------------------------------
Epoch:  941        1 Batch loss: 0.162851 Batch F1: 0.625
Epoch:  941        2 Batch loss: 0.168874 Batch F1: 0.847457627118644
Epoch:  941        3 Batch loss: 0.180518 Batch F1: 0.6818181818181819
Epoch:  941        4 Batch loss: 0.168075 Batch F1: 0.6842105263157895
Epoch:  941        5 Batch loss: 0.174937 Batch F1: 0.7450980392156864
Epoch:  941        6 Batch loss: 0.162490 Batch F1: 0.6666666666666667
Epoch:  941        7 Batch loss: 0.161085 Batch F1: 0.6285714285714287
Epoch:  941        8 Batch loss: 0.170797 Batch F1: 0.711111111111111
Epoch:  941        9 Batch loss: 0.171144 Batch F1: 0.631578947368421
Epoch:  941       10 Batch loss: 0.158110 Batch F1: 0.7659574468085107
Epoch:  941       11 Batch loss: 0.169542 Batch F1: 0.7843137254901961
Epoch:  941       12 Batch loss: 0.213741 Batch F1: 0.6530612244897959
Train Avg Loss  941: 0.171847

Train Avg F1  941: 0.7020704104145361

Val Avg Loss  941: 0.181695

Val Avg F1  941:  0.6757616089914226

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 942
--------------------------------------------------------------
Epoch:  942        1 Batch loss: 0.191367 Batch F1: 0.6521739130434783
Epoch:  942        2 Batch loss: 0.163962 Batch F1: 0.7027027027027027
Epoch:  942        3 Batch loss: 0.164524 Batch F1: 0.7924528301886793
Epoch:  942        4 Batch loss: 0.206193 Batch F1: 0.5833333333333334
Epoch:  942        5 Batch loss: 0.214726 Batch F1: 0.5909090909090909
Epoch:  942        6 Batch loss: 0.147131 Batch F1: 0.7826086956521738
Epoch:  942        7 Batch loss: 0.191343 Batch F1: 0.7142857142857142
Epoch:  942        8 Batch loss: 0.144350 Batch F1: 0.8571428571428572
Epoch:  942        9 Batch loss: 0.168945 Batch F1: 0.7
Epoch:  942       10 Batch loss: 0.175187 Batch F1: 0.7142857142857143
Epoch:  942       11 Batch loss: 0.165931 Batch F1: 0.7058823529411765
Epoch:  942       12 Batch loss: 0.145830 Batch F1: 0.7333333333333333
Train Avg Loss  942: 0.173291

Train Avg F1  942: 0.7107592114848545

Val Avg Loss  942: 0.184663

Val Avg F1  942:  0.6719824890556597

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 943
--------------------------------------------------------------
Epoch:  943        1 Batch loss: 0.156382 Batch F1: 0.6857142857142857
Epoch:  943        2 Batch loss: 0.213578 Batch F1: 0.5714285714285713
Epoch:  943        3 Batch loss: 0.181259 Batch F1: 0.64
Epoch:  943        4 Batch loss: 0.185695 Batch F1: 0.6250000000000001
Epoch:  943        5 Batch loss: 0.198026 Batch F1: 0.56
Epoch:  943        6 Batch loss: 0.141457 Batch F1: 0.8181818181818182
Epoch:  943        7 Batch loss: 0.179014 Batch F1: 0.7796610169491527
Epoch:  943        8 Batch loss: 0.175625 Batch F1: 0.7428571428571429
Epoch:  943        9 Batch loss: 0.171938 Batch F1: 0.6486486486486486
Epoch:  943       10 Batch loss: 0.156327 Batch F1: 0.8571428571428571
Epoch:  943       11 Batch loss: 0.160930 Batch F1: 0.7391304347826088
Epoch:  943       12 Batch loss: 0.192608 Batch F1: 0.6818181818181819
Train Avg Loss  943: 0.176070

Train Avg F1  943: 0.6957985797936055

Val Avg Loss  943: 0.182254

Val Avg F1  943:  0.6776701039823962

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 944
--------------------------------------------------------------
Epoch:  944        1 Batch loss: 0.170232 Batch F1: 0.6666666666666666
Epoch:  944        2 Batch loss: 0.187639 Batch F1: 0.6938775510204083
Epoch:  944        3 Batch loss: 0.176487 Batch F1: 0.6111111111111112
Epoch:  944        4 Batch loss: 0.169372 Batch F1: 0.6976744186046512
Epoch:  944        5 Batch loss: 0.165953 Batch F1: 0.7142857142857143
Epoch:  944        6 Batch loss: 0.143734 Batch F1: 0.8333333333333333
Epoch:  944        7 Batch loss: 0.188083 Batch F1: 0.72
Epoch:  944        8 Batch loss: 0.170146 Batch F1: 0.6829268292682926
Epoch:  944        9 Batch loss: 0.191277 Batch F1: 0.6046511627906976
Epoch:  944       10 Batch loss: 0.134337 Batch F1: 0.7647058823529412
Epoch:  944       11 Batch loss: 0.171361 Batch F1: 0.7391304347826085
Epoch:  944       12 Batch loss: 0.176111 Batch F1: 0.7916666666666666
Train Avg Loss  944: 0.170394

Train Avg F1  944: 0.7100024809069243

Val Avg Loss  944: 0.182233

Val Avg F1  944:  0.6745985657135483

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 945
--------------------------------------------------------------
Epoch:  945        1 Batch loss: 0.164348 Batch F1: 0.7441860465116279
Epoch:  945        2 Batch loss: 0.191630 Batch F1: 0.6222222222222222
Epoch:  945        3 Batch loss: 0.207973 Batch F1: 0.5714285714285714
Epoch:  945        4 Batch loss: 0.158562 Batch F1: 0.7391304347826088
Epoch:  945        5 Batch loss: 0.167153 Batch F1: 0.6470588235294118
Epoch:  945        6 Batch loss: 0.164770 Batch F1: 0.7441860465116279
Epoch:  945        7 Batch loss: 0.191735 Batch F1: 0.6909090909090909
Epoch:  945        8 Batch loss: 0.162456 Batch F1: 0.7272727272727272
Epoch:  945        9 Batch loss: 0.148808 Batch F1: 0.7368421052631577
Epoch:  945       10 Batch loss: 0.135298 Batch F1: 0.8372093023255814
Epoch:  945       11 Batch loss: 0.167417 Batch F1: 0.7547169811320756
Epoch:  945       12 Batch loss: 0.175950 Batch F1: 0.717948717948718
Train Avg Loss  945: 0.169675

Train Avg F1  945: 0.7110925891531185

Val Avg Loss  945: 0.181199

Val Avg F1  945:  0.6623619606993991

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 946
--------------------------------------------------------------
Epoch:  946        1 Batch loss: 0.148228 Batch F1: 0.8214285714285715
Epoch:  946        2 Batch loss: 0.183482 Batch F1: 0.6808510638297872
Epoch:  946        3 Batch loss: 0.152584 Batch F1: 0.7843137254901961
Epoch:  946        4 Batch loss: 0.164230 Batch F1: 0.6666666666666667
Epoch:  946        5 Batch loss: 0.167307 Batch F1: 0.7111111111111111
Epoch:  946        6 Batch loss: 0.164290 Batch F1: 0.717948717948718
Epoch:  946        7 Batch loss: 0.188812 Batch F1: 0.711864406779661
Epoch:  946        8 Batch loss: 0.164198 Batch F1: 0.717948717948718
Epoch:  946        9 Batch loss: 0.161670 Batch F1: 0.761904761904762
Epoch:  946       10 Batch loss: 0.148846 Batch F1: 0.7222222222222223
Epoch:  946       11 Batch loss: 0.178039 Batch F1: 0.5625
Epoch:  946       12 Batch loss: 0.217746 Batch F1: 0.6
Train Avg Loss  946: 0.169953

Train Avg F1  946: 0.7048966637775345

Val Avg Loss  946: 0.181918

Val Avg F1  946:  0.6725494743351886

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 947
--------------------------------------------------------------
Epoch:  947        1 Batch loss: 0.179636 Batch F1: 0.7407407407407408
Epoch:  947        2 Batch loss: 0.161911 Batch F1: 0.7567567567567567
Epoch:  947        3 Batch loss: 0.169805 Batch F1: 0.6500000000000001
Epoch:  947        4 Batch loss: 0.182985 Batch F1: 0.5454545454545454
Epoch:  947        5 Batch loss: 0.212326 Batch F1: 0.6885245901639343
Epoch:  947        6 Batch loss: 0.158444 Batch F1: 0.7142857142857143
Epoch:  947        7 Batch loss: 0.144769 Batch F1: 0.75
Epoch:  947        8 Batch loss: 0.149272 Batch F1: 0.7906976744186046
Epoch:  947        9 Batch loss: 0.154176 Batch F1: 0.7142857142857143
Epoch:  947       10 Batch loss: 0.184447 Batch F1: 0.6
Epoch:  947       11 Batch loss: 0.161467 Batch F1: 0.7755102040816326
Epoch:  947       12 Batch loss: 0.162949 Batch F1: 0.7906976744186046
Train Avg Loss  947: 0.168515

Train Avg F1  947: 0.7097461345505206

Val Avg Loss  947: 0.181204

Val Avg F1  947:  0.6722689075630253

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 948
--------------------------------------------------------------
Epoch:  948        1 Batch loss: 0.172309 Batch F1: 0.7083333333333334
Epoch:  948        2 Batch loss: 0.175793 Batch F1: 0.6111111111111112
Epoch:  948        3 Batch loss: 0.171675 Batch F1: 0.7199999999999999
Epoch:  948        4 Batch loss: 0.189981 Batch F1: 0.6666666666666666
Epoch:  948        5 Batch loss: 0.171937 Batch F1: 0.7692307692307692
Epoch:  948        6 Batch loss: 0.174963 Batch F1: 0.6666666666666666
Epoch:  948        7 Batch loss: 0.149087 Batch F1: 0.7906976744186046
Epoch:  948        8 Batch loss: 0.155113 Batch F1: 0.7317073170731706
Epoch:  948        9 Batch loss: 0.151814 Batch F1: 0.8
Epoch:  948       10 Batch loss: 0.163309 Batch F1: 0.7391304347826088
Epoch:  948       11 Batch loss: 0.178237 Batch F1: 0.6829268292682927
Epoch:  948       12 Batch loss: 0.176680 Batch F1: 0.6000000000000001
Train Avg Loss  948: 0.169241

Train Avg F1  948: 0.7072059002126019

Val Avg Loss  948: 0.180528

Val Avg F1  948:  0.6771829831298269

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 949
--------------------------------------------------------------
Epoch:  949        1 Batch loss: 0.171219 Batch F1: 0.6666666666666666
Epoch:  949        2 Batch loss: 0.163118 Batch F1: 0.6842105263157895
Epoch:  949        3 Batch loss: 0.138247 Batch F1: 0.8571428571428572
Epoch:  949        4 Batch loss: 0.157306 Batch F1: 0.7555555555555555
Epoch:  949        5 Batch loss: 0.181856 Batch F1: 0.6363636363636364
Epoch:  949        6 Batch loss: 0.172587 Batch F1: 0.7450980392156863
Epoch:  949        7 Batch loss: 0.192048 Batch F1: 0.5789473684210527
Epoch:  949        8 Batch loss: 0.174418 Batch F1: 0.6818181818181818
Epoch:  949        9 Batch loss: 0.167645 Batch F1: 0.76
Epoch:  949       10 Batch loss: 0.154802 Batch F1: 0.6842105263157895
Epoch:  949       11 Batch loss: 0.191263 Batch F1: 0.6363636363636365
Epoch:  949       12 Batch loss: 0.157386 Batch F1: 0.8
Train Avg Loss  949: 0.168491

Train Avg F1  949: 0.7071980828482377

Val Avg Loss  949: 0.180205

Val Avg F1  949:  0.674034299034299

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 950
--------------------------------------------------------------
Epoch:  950        1 Batch loss: 0.180460 Batch F1: 0.6046511627906976
Epoch:  950        2 Batch loss: 0.179746 Batch F1: 0.6666666666666666
Epoch:  950        3 Batch loss: 0.164318 Batch F1: 0.7500000000000001
Epoch:  950        4 Batch loss: 0.171163 Batch F1: 0.7441860465116279
Epoch:  950        5 Batch loss: 0.195892 Batch F1: 0.5909090909090909
Epoch:  950        6 Batch loss: 0.159058 Batch F1: 0.717948717948718
Epoch:  950        7 Batch loss: 0.164096 Batch F1: 0.7755102040816326
Epoch:  950        8 Batch loss: 0.155879 Batch F1: 0.7317073170731706
Epoch:  950        9 Batch loss: 0.175056 Batch F1: 0.6956521739130435
Epoch:  950       10 Batch loss: 0.174048 Batch F1: 0.6500000000000001
Epoch:  950       11 Batch loss: 0.180980 Batch F1: 0.7058823529411765
Epoch:  950       12 Batch loss: 0.127314 Batch F1: 0.9047619047619048
Train Avg Loss  950: 0.169001

Train Avg F1  950: 0.7114896364664774

Val Avg Loss  950: 0.180723

Val Avg F1  950:  0.6685509315925472

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 951
--------------------------------------------------------------
Epoch:  951        1 Batch loss: 0.161839 Batch F1: 0.7
Epoch:  951        2 Batch loss: 0.142054 Batch F1: 0.8
Epoch:  951        3 Batch loss: 0.172022 Batch F1: 0.7346938775510204
Epoch:  951        4 Batch loss: 0.158736 Batch F1: 0.8
Epoch:  951        5 Batch loss: 0.172233 Batch F1: 0.7868852459016394
Epoch:  951        6 Batch loss: 0.145682 Batch F1: 0.7272727272727272
Epoch:  951        7 Batch loss: 0.176617 Batch F1: 0.5945945945945946
Epoch:  951        8 Batch loss: 0.150274 Batch F1: 0.8076923076923077
Epoch:  951        9 Batch loss: 0.187230 Batch F1: 0.6666666666666666
Epoch:  951       10 Batch loss: 0.187213 Batch F1: 0.6046511627906976
Epoch:  951       11 Batch loss: 0.184608 Batch F1: 0.5945945945945946
Epoch:  951       12 Batch loss: 0.189933 Batch F1: 0.6060606060606061
Train Avg Loss  951: 0.169037

Train Avg F1  951: 0.7019259819270712

Val Avg Loss  951: 0.182305

Val Avg F1  951:  0.6770833333333334

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 952
--------------------------------------------------------------
Epoch:  952        1 Batch loss: 0.204506 Batch F1: 0.6274509803921569
Epoch:  952        2 Batch loss: 0.139660 Batch F1: 0.6666666666666666
Epoch:  952        3 Batch loss: 0.170674 Batch F1: 0.6818181818181818
Epoch:  952        4 Batch loss: 0.165558 Batch F1: 0.7441860465116279
Epoch:  952        5 Batch loss: 0.164460 Batch F1: 0.7659574468085107
Epoch:  952        6 Batch loss: 0.145654 Batch F1: 0.7755102040816326
Epoch:  952        7 Batch loss: 0.210143 Batch F1: 0.5909090909090908
Epoch:  952        8 Batch loss: 0.202790 Batch F1: 0.5909090909090908
Epoch:  952        9 Batch loss: 0.177613 Batch F1: 0.5714285714285714
Epoch:  952       10 Batch loss: 0.186253 Batch F1: 0.6923076923076923
Epoch:  952       11 Batch loss: 0.178602 Batch F1: 0.7199999999999999
Epoch:  952       12 Batch loss: 0.172144 Batch F1: 0.7272727272727272
Train Avg Loss  952: 0.176505

Train Avg F1  952: 0.6795347249254956

Val Avg Loss  952: 0.188567

Val Avg F1  952:  0.7514530812324929

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 953
--------------------------------------------------------------
Epoch:  953        1 Batch loss: 0.190358 Batch F1: 0.7659574468085106
Epoch:  953        2 Batch loss: 0.159946 Batch F1: 0.8727272727272728
Epoch:  953        3 Batch loss: 0.172910 Batch F1: 0.7999999999999999
Epoch:  953        4 Batch loss: 0.174324 Batch F1: 0.7272727272727273
Epoch:  953        5 Batch loss: 0.153511 Batch F1: 0.7826086956521738
Epoch:  953        6 Batch loss: 0.169121 Batch F1: 0.6666666666666666
Epoch:  953        7 Batch loss: 0.171417 Batch F1: 0.7391304347826085
Epoch:  953        8 Batch loss: 0.197040 Batch F1: 0.6666666666666665
Epoch:  953        9 Batch loss: 0.198805 Batch F1: 0.4864864864864865
Epoch:  953       10 Batch loss: 0.198888 Batch F1: 0.6382978723404256
Epoch:  953       11 Batch loss: 0.161481 Batch F1: 0.717948717948718
Epoch:  953       12 Batch loss: 0.165286 Batch F1: 0.782608695652174
Train Avg Loss  953: 0.176091

Train Avg F1  953: 0.7205309735837025

Val Avg Loss  953: 0.189565

Val Avg F1  953:  0.6363257575757577

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 954
--------------------------------------------------------------
Epoch:  954        1 Batch loss: 0.161030 Batch F1: 0.6842105263157895
Epoch:  954        2 Batch loss: 0.192674 Batch F1: 0.75
Epoch:  954        3 Batch loss: 0.190902 Batch F1: 0.5714285714285714
Epoch:  954        4 Batch loss: 0.205297 Batch F1: 0.5405405405405405
Epoch:  954        5 Batch loss: 0.193652 Batch F1: 0.6190476190476191
Epoch:  954        6 Batch loss: 0.199847 Batch F1: 0.7142857142857143
Epoch:  954        7 Batch loss: 0.180109 Batch F1: 0.6666666666666666
Epoch:  954        8 Batch loss: 0.190754 Batch F1: 0.6896551724137931
Epoch:  954        9 Batch loss: 0.145741 Batch F1: 0.84
Epoch:  954       10 Batch loss: 0.172675 Batch F1: 0.6666666666666666
Epoch:  954       11 Batch loss: 0.150927 Batch F1: 0.8260869565217391
Epoch:  954       12 Batch loss: 0.153961 Batch F1: 0.6428571428571429
Train Avg Loss  954: 0.178131

Train Avg F1  954: 0.6842871313953536

Val Avg Loss  954: 0.189671

Val Avg F1  954:  0.6716063941299791

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 955
--------------------------------------------------------------
Epoch:  955        1 Batch loss: 0.166271 Batch F1: 0.761904761904762
Epoch:  955        2 Batch loss: 0.158592 Batch F1: 0.8076923076923077
Epoch:  955        3 Batch loss: 0.207367 Batch F1: 0.7999999999999999
Epoch:  955        4 Batch loss: 0.175158 Batch F1: 0.717948717948718
Epoch:  955        5 Batch loss: 0.201417 Batch F1: 0.68
Epoch:  955        6 Batch loss: 0.176859 Batch F1: 0.7692307692307693
Epoch:  955        7 Batch loss: 0.169267 Batch F1: 0.7
Epoch:  955        8 Batch loss: 0.188979 Batch F1: 0.7346938775510203
Epoch:  955        9 Batch loss: 0.195966 Batch F1: 0.6382978723404256
Epoch:  955       10 Batch loss: 0.163894 Batch F1: 0.7999999999999999
Epoch:  955       11 Batch loss: 0.186794 Batch F1: 0.5945945945945946
Epoch:  955       12 Batch loss: 0.169749 Batch F1: 0.7027027027027027
Train Avg Loss  955: 0.180026

Train Avg F1  955: 0.7255888003304417

Val Avg Loss  955: 0.181396

Val Avg F1  955:  0.680117501546073

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 956
--------------------------------------------------------------
Epoch:  956        1 Batch loss: 0.177075 Batch F1: 0.6938775510204083
Epoch:  956        2 Batch loss: 0.197611 Batch F1: 0.6785714285714286
Epoch:  956        3 Batch loss: 0.180119 Batch F1: 0.7567567567567567
Epoch:  956        4 Batch loss: 0.176466 Batch F1: 0.6818181818181818
Epoch:  956        5 Batch loss: 0.191519 Batch F1: 0.6792452830188679
Epoch:  956        6 Batch loss: 0.154976 Batch F1: 0.7499999999999999
Epoch:  956        7 Batch loss: 0.180878 Batch F1: 0.6818181818181819
Epoch:  956        8 Batch loss: 0.143470 Batch F1: 0.7428571428571428
Epoch:  956        9 Batch loss: 0.173011 Batch F1: 0.631578947368421
Epoch:  956       10 Batch loss: 0.169210 Batch F1: 0.6976744186046512
Epoch:  956       11 Batch loss: 0.174566 Batch F1: 0.6842105263157895
Epoch:  956       12 Batch loss: 0.156553 Batch F1: 0.8095238095238095
Train Avg Loss  956: 0.172954

Train Avg F1  956: 0.7073276856394699

Val Avg Loss  956: 0.184875

Val Avg F1  956:  0.6711877036691023

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 957
--------------------------------------------------------------
Epoch:  957        1 Batch loss: 0.147808 Batch F1: 0.7096774193548386
Epoch:  957        2 Batch loss: 0.187175 Batch F1: 0.6666666666666666
Epoch:  957        3 Batch loss: 0.154033 Batch F1: 0.7727272727272727
Epoch:  957        4 Batch loss: 0.174376 Batch F1: 0.6976744186046512
Epoch:  957        5 Batch loss: 0.165584 Batch F1: 0.8214285714285714
Epoch:  957        6 Batch loss: 0.152527 Batch F1: 0.717948717948718
Epoch:  957        7 Batch loss: 0.153949 Batch F1: 0.761904761904762
Epoch:  957        8 Batch loss: 0.185336 Batch F1: 0.6829268292682927
Epoch:  957        9 Batch loss: 0.156151 Batch F1: 0.7317073170731706
Epoch:  957       10 Batch loss: 0.191518 Batch F1: 0.68
Epoch:  957       11 Batch loss: 0.206714 Batch F1: 0.6000000000000001
Epoch:  957       12 Batch loss: 0.184816 Batch F1: 0.717948717948718
Train Avg Loss  957: 0.171666

Train Avg F1  957: 0.7133842244104717

Val Avg Loss  957: 0.181909

Val Avg F1  957:  0.6730584110632588

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 958
--------------------------------------------------------------
Epoch:  958        1 Batch loss: 0.168210 Batch F1: 0.7755102040816326
Epoch:  958        2 Batch loss: 0.182316 Batch F1: 0.6818181818181819
Epoch:  958        3 Batch loss: 0.180841 Batch F1: 0.5555555555555556
Epoch:  958        4 Batch loss: 0.152555 Batch F1: 0.7317073170731706
Epoch:  958        5 Batch loss: 0.180239 Batch F1: 0.5945945945945946
Epoch:  958        6 Batch loss: 0.173396 Batch F1: 0.6666666666666666
Epoch:  958        7 Batch loss: 0.197803 Batch F1: 0.5
Epoch:  958        8 Batch loss: 0.146844 Batch F1: 0.8235294117647058
Epoch:  958        9 Batch loss: 0.166928 Batch F1: 0.7346938775510203
Epoch:  958       10 Batch loss: 0.176737 Batch F1: 0.7636363636363638
Epoch:  958       11 Batch loss: 0.166006 Batch F1: 0.7999999999999999
Epoch:  958       12 Batch loss: 0.137688 Batch F1: 0.8000000000000002
Train Avg Loss  958: 0.169130

Train Avg F1  958: 0.702309347728491

Val Avg Loss  958: 0.180347

Val Avg F1  958:  0.6730182926829268

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 959
--------------------------------------------------------------
Epoch:  959        1 Batch loss: 0.183228 Batch F1: 0.6521739130434783
Epoch:  959        2 Batch loss: 0.162820 Batch F1: 0.7142857142857143
Epoch:  959        3 Batch loss: 0.172108 Batch F1: 0.7234042553191491
Epoch:  959        4 Batch loss: 0.169011 Batch F1: 0.7391304347826088
Epoch:  959        5 Batch loss: 0.147219 Batch F1: 0.6857142857142857
Epoch:  959        6 Batch loss: 0.181353 Batch F1: 0.6341463414634146
Epoch:  959        7 Batch loss: 0.163524 Batch F1: 0.7142857142857143
Epoch:  959        8 Batch loss: 0.166518 Batch F1: 0.7391304347826085
Epoch:  959        9 Batch loss: 0.163990 Batch F1: 0.7755102040816326
Epoch:  959       10 Batch loss: 0.151579 Batch F1: 0.7804878048780488
Epoch:  959       11 Batch loss: 0.170452 Batch F1: 0.6976744186046512
Epoch:  959       12 Batch loss: 0.207398 Batch F1: 0.6808510638297872
Train Avg Loss  959: 0.169933

Train Avg F1  959: 0.7113995487559244

Val Avg Loss  959: 0.180880

Val Avg F1  959:  0.6719819819819821

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 960
--------------------------------------------------------------
Epoch:  960        1 Batch loss: 0.179511 Batch F1: 0.6500000000000001
Epoch:  960        2 Batch loss: 0.183352 Batch F1: 0.6818181818181819
Epoch:  960        3 Batch loss: 0.169390 Batch F1: 0.7659574468085107
Epoch:  960        4 Batch loss: 0.196050 Batch F1: 0.5945945945945946
Epoch:  960        5 Batch loss: 0.182457 Batch F1: 0.6363636363636365
Epoch:  960        6 Batch loss: 0.175977 Batch F1: 0.7719298245614034
Epoch:  960        7 Batch loss: 0.153858 Batch F1: 0.7826086956521738
Epoch:  960        8 Batch loss: 0.158092 Batch F1: 0.7000000000000001
Epoch:  960        9 Batch loss: 0.169925 Batch F1: 0.7346938775510204
Epoch:  960       10 Batch loss: 0.174394 Batch F1: 0.6808510638297872
Epoch:  960       11 Batch loss: 0.134468 Batch F1: 0.7500000000000001
Epoch:  960       12 Batch loss: 0.168291 Batch F1: 0.761904761904762
Train Avg Loss  960: 0.170480

Train Avg F1  960: 0.7092268402570059

Val Avg Loss  960: 0.181509

Val Avg F1  960:  0.6764842300556586

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 961
--------------------------------------------------------------
Epoch:  961        1 Batch loss: 0.146251 Batch F1: 0.8205128205128205
Epoch:  961        2 Batch loss: 0.184013 Batch F1: 0.6923076923076923
Epoch:  961        3 Batch loss: 0.209830 Batch F1: 0.5
Epoch:  961        4 Batch loss: 0.153088 Batch F1: 0.7999999999999999
Epoch:  961        5 Batch loss: 0.180234 Batch F1: 0.76
Epoch:  961        6 Batch loss: 0.173102 Batch F1: 0.7083333333333334
Epoch:  961        7 Batch loss: 0.175061 Batch F1: 0.6666666666666666
Epoch:  961        8 Batch loss: 0.147744 Batch F1: 0.8085106382978724
Epoch:  961        9 Batch loss: 0.153450 Batch F1: 0.6470588235294118
Epoch:  961       10 Batch loss: 0.174461 Batch F1: 0.6666666666666666
Epoch:  961       11 Batch loss: 0.164727 Batch F1: 0.7555555555555556
Epoch:  961       12 Batch loss: 0.171817 Batch F1: 0.7222222222222222
Train Avg Loss  961: 0.169481

Train Avg F1  961: 0.7123195349243535

Val Avg Loss  961: 0.181085

Val Avg F1  961:  0.6782704560113197

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 962
--------------------------------------------------------------
Epoch:  962        1 Batch loss: 0.135070 Batch F1: 0.8444444444444444
Epoch:  962        2 Batch loss: 0.154354 Batch F1: 0.8000000000000002
Epoch:  962        3 Batch loss: 0.170902 Batch F1: 0.7555555555555556
Epoch:  962        4 Batch loss: 0.171921 Batch F1: 0.7272727272727273
Epoch:  962        5 Batch loss: 0.190816 Batch F1: 0.6363636363636365
Epoch:  962        6 Batch loss: 0.151650 Batch F1: 0.7027027027027026
Epoch:  962        7 Batch loss: 0.152799 Batch F1: 0.7916666666666667
Epoch:  962        8 Batch loss: 0.203778 Batch F1: 0.5581395348837208
Epoch:  962        9 Batch loss: 0.171926 Batch F1: 0.7
Epoch:  962       10 Batch loss: 0.188333 Batch F1: 0.6341463414634148
Epoch:  962       11 Batch loss: 0.174417 Batch F1: 0.6808510638297872
Epoch:  962       12 Batch loss: 0.171238 Batch F1: 0.6829268292682927
Train Avg Loss  962: 0.169767

Train Avg F1  962: 0.7095057918709125

Val Avg Loss  962: 0.180763

Val Avg F1  962:  0.668266253869969

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 963
--------------------------------------------------------------
Epoch:  963        1 Batch loss: 0.150550 Batch F1: 0.7727272727272727
Epoch:  963        2 Batch loss: 0.186953 Batch F1: 0.6341463414634146
Epoch:  963        3 Batch loss: 0.172224 Batch F1: 0.6956521739130435
Epoch:  963        4 Batch loss: 0.153842 Batch F1: 0.7755102040816326
Epoch:  963        5 Batch loss: 0.199794 Batch F1: 0.6
Epoch:  963        6 Batch loss: 0.150542 Batch F1: 0.8076923076923077
Epoch:  963        7 Batch loss: 0.171459 Batch F1: 0.6666666666666667
Epoch:  963        8 Batch loss: 0.168013 Batch F1: 0.6842105263157895
Epoch:  963        9 Batch loss: 0.157105 Batch F1: 0.7826086956521738
Epoch:  963       10 Batch loss: 0.163939 Batch F1: 0.6486486486486486
Epoch:  963       11 Batch loss: 0.186142 Batch F1: 0.7058823529411765
Epoch:  963       12 Batch loss: 0.167450 Batch F1: 0.7317073170731708
Train Avg Loss  963: 0.169001

Train Avg F1  963: 0.7087877089312747

Val Avg Loss  963: 0.182136

Val Avg F1  963:  0.6702127659574467

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 964
--------------------------------------------------------------
Epoch:  964        1 Batch loss: 0.157732 Batch F1: 0.7924528301886792
Epoch:  964        2 Batch loss: 0.146237 Batch F1: 0.761904761904762
Epoch:  964        3 Batch loss: 0.166075 Batch F1: 0.6486486486486486
Epoch:  964        4 Batch loss: 0.178352 Batch F1: 0.7111111111111111
Epoch:  964        5 Batch loss: 0.146231 Batch F1: 0.75
Epoch:  964        6 Batch loss: 0.176640 Batch F1: 0.6829268292682926
Epoch:  964        7 Batch loss: 0.173803 Batch F1: 0.631578947368421
Epoch:  964        8 Batch loss: 0.174080 Batch F1: 0.6666666666666667
Epoch:  964        9 Batch loss: 0.157451 Batch F1: 0.717948717948718
Epoch:  964       10 Batch loss: 0.185590 Batch F1: 0.7058823529411765
Epoch:  964       11 Batch loss: 0.165426 Batch F1: 0.8214285714285714
Epoch:  964       12 Batch loss: 0.220185 Batch F1: 0.5909090909090909
Train Avg Loss  964: 0.170650

Train Avg F1  964: 0.7067882106986781

Val Avg Loss  964: 0.181750

Val Avg F1  964:  0.6701833848504335

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 965
--------------------------------------------------------------
Epoch:  965        1 Batch loss: 0.182718 Batch F1: 0.6666666666666666
Epoch:  965        2 Batch loss: 0.132189 Batch F1: 0.8695652173913043
Epoch:  965        3 Batch loss: 0.155197 Batch F1: 0.7826086956521738
Epoch:  965        4 Batch loss: 0.180851 Batch F1: 0.6909090909090908
Epoch:  965        5 Batch loss: 0.217542 Batch F1: 0.5714285714285714
Epoch:  965        6 Batch loss: 0.198475 Batch F1: 0.6382978723404256
Epoch:  965        7 Batch loss: 0.156917 Batch F1: 0.717948717948718
Epoch:  965        8 Batch loss: 0.143125 Batch F1: 0.7272727272727272
Epoch:  965        9 Batch loss: 0.185121 Batch F1: 0.6341463414634146
Epoch:  965       10 Batch loss: 0.162928 Batch F1: 0.5714285714285715
Epoch:  965       11 Batch loss: 0.194146 Batch F1: 0.7346938775510203
Epoch:  965       12 Batch loss: 0.187413 Batch F1: 0.6842105263157895
Train Avg Loss  965: 0.174718

Train Avg F1  965: 0.6907647396973728

Val Avg Loss  965: 0.188980

Val Avg F1  965:  0.6750156445556947

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 966
--------------------------------------------------------------
Epoch:  966        1 Batch loss: 0.164034 Batch F1: 0.7894736842105263
Epoch:  966        2 Batch loss: 0.184030 Batch F1: 0.6363636363636364
Epoch:  966        3 Batch loss: 0.139874 Batch F1: 0.8800000000000001
Epoch:  966        4 Batch loss: 0.177208 Batch F1: 0.6486486486486486
Epoch:  966        5 Batch loss: 0.220852 Batch F1: 0.5957446808510638
Epoch:  966        6 Batch loss: 0.199433 Batch F1: 0.5789473684210527
Epoch:  966        7 Batch loss: 0.155071 Batch F1: 0.8235294117647058
Epoch:  966        8 Batch loss: 0.186556 Batch F1: 0.6511627906976744
Epoch:  966        9 Batch loss: 0.152281 Batch F1: 0.8444444444444444
Epoch:  966       10 Batch loss: 0.199356 Batch F1: 0.7586206896551724
Epoch:  966       11 Batch loss: 0.179395 Batch F1: 0.7727272727272727
Epoch:  966       12 Batch loss: 0.175181 Batch F1: 0.7000000000000001
Train Avg Loss  966: 0.177773

Train Avg F1  966: 0.7233052189820164

Val Avg Loss  966: 0.183052

Val Avg F1  966:  0.6769326537490628

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 967
--------------------------------------------------------------
Epoch:  967        1 Batch loss: 0.213596 Batch F1: 0.7169811320754716
Epoch:  967        2 Batch loss: 0.157660 Batch F1: 0.7755102040816326
Epoch:  967        3 Batch loss: 0.160492 Batch F1: 0.7659574468085107
Epoch:  967        4 Batch loss: 0.170724 Batch F1: 0.6511627906976744
Epoch:  967        5 Batch loss: 0.176454 Batch F1: 0.6956521739130435
Epoch:  967        6 Batch loss: 0.194495 Batch F1: 0.7199999999999999
Epoch:  967        7 Batch loss: 0.187550 Batch F1: 0.6808510638297872
Epoch:  967        8 Batch loss: 0.144330 Batch F1: 0.851063829787234
Epoch:  967        9 Batch loss: 0.143391 Batch F1: 0.7096774193548387
Epoch:  967       10 Batch loss: 0.175396 Batch F1: 0.6666666666666666
Epoch:  967       11 Batch loss: 0.175542 Batch F1: 0.5882352941176471
Epoch:  967       12 Batch loss: 0.174061 Batch F1: 0.6666666666666667
Train Avg Loss  967: 0.172807

Train Avg F1  967: 0.7073687239999312

Val Avg Loss  967: 0.182647

Val Avg F1  967:  0.6718073593073594

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 968
--------------------------------------------------------------
Epoch:  968        1 Batch loss: 0.142802 Batch F1: 0.7999999999999999
Epoch:  968        2 Batch loss: 0.178237 Batch F1: 0.6500000000000001
Epoch:  968        3 Batch loss: 0.182829 Batch F1: 0.7450980392156863
Epoch:  968        4 Batch loss: 0.180580 Batch F1: 0.72
Epoch:  968        5 Batch loss: 0.196309 Batch F1: 0.5789473684210527
Epoch:  968        6 Batch loss: 0.167088 Batch F1: 0.7391304347826088
Epoch:  968        7 Batch loss: 0.166507 Batch F1: 0.6285714285714287
Epoch:  968        8 Batch loss: 0.158516 Batch F1: 0.7142857142857143
Epoch:  968        9 Batch loss: 0.172752 Batch F1: 0.7755102040816326
Epoch:  968       10 Batch loss: 0.175276 Batch F1: 0.6511627906976744
Epoch:  968       11 Batch loss: 0.158722 Batch F1: 0.7317073170731707
Epoch:  968       12 Batch loss: 0.163537 Batch F1: 0.7500000000000001
Train Avg Loss  968: 0.170263

Train Avg F1  968: 0.707034441427414

Val Avg Loss  968: 0.182313

Val Avg F1  968:  0.6795254687240749

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 969
--------------------------------------------------------------
Epoch:  969        1 Batch loss: 0.179443 Batch F1: 0.723404255319149
Epoch:  969        2 Batch loss: 0.192304 Batch F1: 0.6
Epoch:  969        3 Batch loss: 0.177654 Batch F1: 0.6341463414634146
Epoch:  969        4 Batch loss: 0.155518 Batch F1: 0.717948717948718
Epoch:  969        5 Batch loss: 0.177262 Batch F1: 0.7857142857142856
Epoch:  969        6 Batch loss: 0.172653 Batch F1: 0.6956521739130435
Epoch:  969        7 Batch loss: 0.150066 Batch F1: 0.8000000000000002
Epoch:  969        8 Batch loss: 0.181856 Batch F1: 0.736842105263158
Epoch:  969        9 Batch loss: 0.153410 Batch F1: 0.8333333333333333
Epoch:  969       10 Batch loss: 0.169287 Batch F1: 0.6666666666666666
Epoch:  969       11 Batch loss: 0.178563 Batch F1: 0.5714285714285714
Epoch:  969       12 Batch loss: 0.156571 Batch F1: 0.7096774193548386
Train Avg Loss  969: 0.170382

Train Avg F1  969: 0.7062344892004315

Val Avg Loss  969: 0.182206

Val Avg F1  969:  0.6744803103498755

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 970
--------------------------------------------------------------
Epoch:  970        1 Batch loss: 0.190608 Batch F1: 0.679245283018868
Epoch:  970        2 Batch loss: 0.152484 Batch F1: 0.761904761904762
Epoch:  970        3 Batch loss: 0.182089 Batch F1: 0.6153846153846154
Epoch:  970        4 Batch loss: 0.160283 Batch F1: 0.761904761904762
Epoch:  970        5 Batch loss: 0.164359 Batch F1: 0.7272727272727272
Epoch:  970        6 Batch loss: 0.184443 Batch F1: 0.7058823529411765
Epoch:  970        7 Batch loss: 0.176318 Batch F1: 0.7307692307692306
Epoch:  970        8 Batch loss: 0.195490 Batch F1: 0.5
Epoch:  970        9 Batch loss: 0.170724 Batch F1: 0.6666666666666666
Epoch:  970       10 Batch loss: 0.166171 Batch F1: 0.8
Epoch:  970       11 Batch loss: 0.143158 Batch F1: 0.7692307692307692
Epoch:  970       12 Batch loss: 0.150529 Batch F1: 0.7647058823529412
Train Avg Loss  970: 0.169721

Train Avg F1  970: 0.7069139209538765

Val Avg Loss  970: 0.181483

Val Avg F1  970:  0.6738862353452019

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 971
--------------------------------------------------------------
Epoch:  971        1 Batch loss: 0.176276 Batch F1: 0.7272727272727273
Epoch:  971        2 Batch loss: 0.180656 Batch F1: 0.7083333333333333
Epoch:  971        3 Batch loss: 0.157995 Batch F1: 0.711111111111111
Epoch:  971        4 Batch loss: 0.177220 Batch F1: 0.5789473684210527
Epoch:  971        5 Batch loss: 0.167654 Batch F1: 0.6666666666666667
Epoch:  971        6 Batch loss: 0.150937 Batch F1: 0.7727272727272727
Epoch:  971        7 Batch loss: 0.174041 Batch F1: 0.6486486486486486
Epoch:  971        8 Batch loss: 0.166468 Batch F1: 0.7346938775510204
Epoch:  971        9 Batch loss: 0.188551 Batch F1: 0.6808510638297872
Epoch:  971       10 Batch loss: 0.159262 Batch F1: 0.75
Epoch:  971       11 Batch loss: 0.206517 Batch F1: 0.6666666666666666
Epoch:  971       12 Batch loss: 0.128013 Batch F1: 0.8780487804878049
Train Avg Loss  971: 0.169466

Train Avg F1  971: 0.7103306263930076

Val Avg Loss  971: 0.181107

Val Avg F1  971:  0.6634814942926324

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 972
--------------------------------------------------------------
Epoch:  972        1 Batch loss: 0.142956 Batch F1: 0.8372093023255814
Epoch:  972        2 Batch loss: 0.188519 Batch F1: 0.6666666666666666
Epoch:  972        3 Batch loss: 0.156658 Batch F1: 0.75
Epoch:  972        4 Batch loss: 0.212584 Batch F1: 0.6296296296296297
Epoch:  972        5 Batch loss: 0.155292 Batch F1: 0.7441860465116279
Epoch:  972        6 Batch loss: 0.169673 Batch F1: 0.6315789473684211
Epoch:  972        7 Batch loss: 0.184104 Batch F1: 0.6666666666666666
Epoch:  972        8 Batch loss: 0.193776 Batch F1: 0.6274509803921569
Epoch:  972        9 Batch loss: 0.132295 Batch F1: 0.8695652173913043
Epoch:  972       10 Batch loss: 0.208446 Batch F1: 0.6666666666666667
Epoch:  972       11 Batch loss: 0.150089 Batch F1: 0.7317073170731708
Epoch:  972       12 Batch loss: 0.151077 Batch F1: 0.8333333333333333
Train Avg Loss  972: 0.170456

Train Avg F1  972: 0.7212217311687689

Val Avg Loss  972: 0.180528

Val Avg F1  972:  0.6689556735445357

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 973
--------------------------------------------------------------
Epoch:  973        1 Batch loss: 0.189529 Batch F1: 0.7058823529411765
Epoch:  973        2 Batch loss: 0.181556 Batch F1: 0.6521739130434783
Epoch:  973        3 Batch loss: 0.147385 Batch F1: 0.7906976744186046
Epoch:  973        4 Batch loss: 0.159946 Batch F1: 0.7500000000000001
Epoch:  973        5 Batch loss: 0.169062 Batch F1: 0.7222222222222222
Epoch:  973        6 Batch loss: 0.177072 Batch F1: 0.6341463414634146
Epoch:  973        7 Batch loss: 0.161436 Batch F1: 0.7441860465116279
Epoch:  973        8 Batch loss: 0.159554 Batch F1: 0.7659574468085107
Epoch:  973        9 Batch loss: 0.179881 Batch F1: 0.6363636363636364
Epoch:  973       10 Batch loss: 0.182219 Batch F1: 0.6956521739130435
Epoch:  973       11 Batch loss: 0.169423 Batch F1: 0.7
Epoch:  973       12 Batch loss: 0.171321 Batch F1: 0.7499999999999999
Train Avg Loss  973: 0.170699

Train Avg F1  973: 0.7122734839738095

Val Avg Loss  973: 0.182547

Val Avg F1  973:  0.6654070519141848

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 974
--------------------------------------------------------------
Epoch:  974        1 Batch loss: 0.202055 Batch F1: 0.5238095238095238
Epoch:  974        2 Batch loss: 0.184749 Batch F1: 0.6363636363636365
Epoch:  974        3 Batch loss: 0.158043 Batch F1: 0.7391304347826089
Epoch:  974        4 Batch loss: 0.156978 Batch F1: 0.7500000000000001
Epoch:  974        5 Batch loss: 0.150803 Batch F1: 0.761904761904762
Epoch:  974        6 Batch loss: 0.199320 Batch F1: 0.75
Epoch:  974        7 Batch loss: 0.168069 Batch F1: 0.7272727272727272
Epoch:  974        8 Batch loss: 0.184926 Batch F1: 0.6666666666666666
Epoch:  974        9 Batch loss: 0.162790 Batch F1: 0.7999999999999999
Epoch:  974       10 Batch loss: 0.157297 Batch F1: 0.7999999999999999
Epoch:  974       11 Batch loss: 0.166009 Batch F1: 0.7142857142857143
Epoch:  974       12 Batch loss: 0.181241 Batch F1: 0.6470588235294118
Train Avg Loss  974: 0.172690

Train Avg F1  974: 0.709707690717921

Val Avg Loss  974: 0.190132

Val Avg F1  974:  0.6783367610610136

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 975
--------------------------------------------------------------
Epoch:  975        1 Batch loss: 0.134512 Batch F1: 0.92
Epoch:  975        2 Batch loss: 0.185936 Batch F1: 0.6341463414634146
Epoch:  975        3 Batch loss: 0.164169 Batch F1: 0.7027027027027027
Epoch:  975        4 Batch loss: 0.184646 Batch F1: 0.6190476190476191
Epoch:  975        5 Batch loss: 0.164463 Batch F1: 0.7272727272727272
Epoch:  975        6 Batch loss: 0.159723 Batch F1: 0.8135593220338982
Epoch:  975        7 Batch loss: 0.156948 Batch F1: 0.5945945945945946
Epoch:  975        8 Batch loss: 0.193021 Batch F1: 0.5777777777777778
Epoch:  975        9 Batch loss: 0.182200 Batch F1: 0.6842105263157895
Epoch:  975       10 Batch loss: 0.148201 Batch F1: 0.8181818181818182
Epoch:  975       11 Batch loss: 0.223823 Batch F1: 0.6037735849056605
Epoch:  975       12 Batch loss: 0.183837 Batch F1: 0.6829268292682926
Train Avg Loss  975: 0.173457

Train Avg F1  975: 0.6981828202970246

Val Avg Loss  975: 0.182627

Val Avg F1  975:  0.6739534883720929

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 976
--------------------------------------------------------------
Epoch:  976        1 Batch loss: 0.196523 Batch F1: 0.6530612244897959
Epoch:  976        2 Batch loss: 0.151579 Batch F1: 0.7692307692307692
Epoch:  976        3 Batch loss: 0.176617 Batch F1: 0.5882352941176471
Epoch:  976        4 Batch loss: 0.161910 Batch F1: 0.6829268292682926
Epoch:  976        5 Batch loss: 0.190340 Batch F1: 0.75
Epoch:  976        6 Batch loss: 0.160459 Batch F1: 0.8
Epoch:  976        7 Batch loss: 0.176970 Batch F1: 0.7547169811320754
Epoch:  976        8 Batch loss: 0.171092 Batch F1: 0.7
Epoch:  976        9 Batch loss: 0.161806 Batch F1: 0.7719298245614035
Epoch:  976       10 Batch loss: 0.205612 Batch F1: 0.6382978723404256
Epoch:  976       11 Batch loss: 0.145573 Batch F1: 0.7272727272727273
Epoch:  976       12 Batch loss: 0.156798 Batch F1: 0.6153846153846153
Train Avg Loss  976: 0.171273

Train Avg F1  976: 0.7042546781498126

Val Avg Loss  976: 0.184513

Val Avg F1  976:  0.6754166666666667

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 977
--------------------------------------------------------------
Epoch:  977        1 Batch loss: 0.177010 Batch F1: 0.8333333333333334
Epoch:  977        2 Batch loss: 0.187504 Batch F1: 0.6909090909090909
Epoch:  977        3 Batch loss: 0.171444 Batch F1: 0.7843137254901961
Epoch:  977        4 Batch loss: 0.164106 Batch F1: 0.7142857142857143
Epoch:  977        5 Batch loss: 0.151391 Batch F1: 0.742857142857143
Epoch:  977        6 Batch loss: 0.174714 Batch F1: 0.6486486486486486
Epoch:  977        7 Batch loss: 0.194072 Batch F1: 0.6341463414634148
Epoch:  977        8 Batch loss: 0.163744 Batch F1: 0.6829268292682927
Epoch:  977        9 Batch loss: 0.171952 Batch F1: 0.7391304347826088
Epoch:  977       10 Batch loss: 0.176396 Batch F1: 0.6956521739130435
Epoch:  977       11 Batch loss: 0.202471 Batch F1: 0.7058823529411764
Epoch:  977       12 Batch loss: 0.184543 Batch F1: 0.6000000000000001
Train Avg Loss  977: 0.176612

Train Avg F1  977: 0.7060071489910551

Val Avg Loss  977: 0.187550

Val Avg F1  977:  0.6481515862158818

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 978
--------------------------------------------------------------
Epoch:  978        1 Batch loss: 0.152369 Batch F1: 0.6666666666666667
Epoch:  978        2 Batch loss: 0.193858 Batch F1: 0.6530612244897959
Epoch:  978        3 Batch loss: 0.181544 Batch F1: 0.5806451612903225
Epoch:  978        4 Batch loss: 0.157032 Batch F1: 0.782608695652174
Epoch:  978        5 Batch loss: 0.153437 Batch F1: 0.8148148148148148
Epoch:  978        6 Batch loss: 0.165149 Batch F1: 0.7142857142857143
Epoch:  978        7 Batch loss: 0.166005 Batch F1: 0.782608695652174
Epoch:  978        8 Batch loss: 0.188052 Batch F1: 0.65
Epoch:  978        9 Batch loss: 0.168387 Batch F1: 0.65
Epoch:  978       10 Batch loss: 0.146699 Batch F1: 0.7804878048780488
Epoch:  978       11 Batch loss: 0.199951 Batch F1: 0.6666666666666666
Epoch:  978       12 Batch loss: 0.194270 Batch F1: 0.6341463414634148
Train Avg Loss  978: 0.172229

Train Avg F1  978: 0.6979993154883161

Val Avg Loss  978: 0.183109

Val Avg F1  978:  0.6660533910533911

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 979
--------------------------------------------------------------
Epoch:  979        1 Batch loss: 0.140501 Batch F1: 0.8666666666666667
Epoch:  979        2 Batch loss: 0.169379 Batch F1: 0.65
Epoch:  979        3 Batch loss: 0.173228 Batch F1: 0.6190476190476191
Epoch:  979        4 Batch loss: 0.190064 Batch F1: 0.6296296296296297
Epoch:  979        5 Batch loss: 0.187142 Batch F1: 0.6808510638297872
Epoch:  979        6 Batch loss: 0.178394 Batch F1: 0.6666666666666667
Epoch:  979        7 Batch loss: 0.158031 Batch F1: 0.6857142857142857
Epoch:  979        8 Batch loss: 0.174093 Batch F1: 0.65
Epoch:  979        9 Batch loss: 0.175273 Batch F1: 0.7843137254901961
Epoch:  979       10 Batch loss: 0.185765 Batch F1: 0.6190476190476191
Epoch:  979       11 Batch loss: 0.172262 Batch F1: 0.7555555555555556
Epoch:  979       12 Batch loss: 0.178021 Batch F1: 0.7368421052631577
Train Avg Loss  979: 0.173513

Train Avg F1  979: 0.6953612447425987

Val Avg Loss  979: 0.185541

Val Avg F1  979:  0.6363652811221201

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 980
--------------------------------------------------------------
Epoch:  980        1 Batch loss: 0.184606 Batch F1: 0.6046511627906976
Epoch:  980        2 Batch loss: 0.198135 Batch F1: 0.5142857142857143
Epoch:  980        3 Batch loss: 0.172502 Batch F1: 0.7391304347826088
Epoch:  980        4 Batch loss: 0.161041 Batch F1: 0.7000000000000001
Epoch:  980        5 Batch loss: 0.172487 Batch F1: 0.7346938775510203
Epoch:  980        6 Batch loss: 0.192218 Batch F1: 0.7058823529411765
Epoch:  980        7 Batch loss: 0.181382 Batch F1: 0.7234042553191491
Epoch:  980        8 Batch loss: 0.179873 Batch F1: 0.7142857142857143
Epoch:  980        9 Batch loss: 0.153162 Batch F1: 0.7317073170731706
Epoch:  980       10 Batch loss: 0.160427 Batch F1: 0.7659574468085107
Epoch:  980       11 Batch loss: 0.149661 Batch F1: 0.8085106382978724
Epoch:  980       12 Batch loss: 0.171045 Batch F1: 0.7368421052631577
Train Avg Loss  980: 0.173045

Train Avg F1  980: 0.7066125849498994

Val Avg Loss  980: 0.186855

Val Avg F1  980:  0.6686427607480239

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 981
--------------------------------------------------------------
Epoch:  981        1 Batch loss: 0.161996 Batch F1: 0.7916666666666666
Epoch:  981        2 Batch loss: 0.181892 Batch F1: 0.7083333333333333
Epoch:  981        3 Batch loss: 0.162681 Batch F1: 0.7450980392156864
Epoch:  981        4 Batch loss: 0.147444 Batch F1: 0.8214285714285715
Epoch:  981        5 Batch loss: 0.172692 Batch F1: 0.7017543859649122
Epoch:  981        6 Batch loss: 0.218806 Batch F1: 0.7346938775510204
Epoch:  981        7 Batch loss: 0.175110 Batch F1: 0.5405405405405405
Epoch:  981        8 Batch loss: 0.158114 Batch F1: 0.7499999999999999
Epoch:  981        9 Batch loss: 0.173192 Batch F1: 0.606060606060606
Epoch:  981       10 Batch loss: 0.225124 Batch F1: 0.4878048780487805
Epoch:  981       11 Batch loss: 0.174954 Batch F1: 0.6976744186046512
Epoch:  981       12 Batch loss: 0.164961 Batch F1: 0.7272727272727272
Train Avg Loss  981: 0.176414

Train Avg F1  981: 0.6926940037239581

Val Avg Loss  981: 0.187277

Val Avg F1  981:  0.678016411737447

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 982
--------------------------------------------------------------
Epoch:  982        1 Batch loss: 0.144951 Batch F1: 0.8372093023255814
Epoch:  982        2 Batch loss: 0.176437 Batch F1: 0.65
Epoch:  982        3 Batch loss: 0.173696 Batch F1: 0.7450980392156864
Epoch:  982        4 Batch loss: 0.200929 Batch F1: 0.6486486486486486
Epoch:  982        5 Batch loss: 0.168419 Batch F1: 0.631578947368421
Epoch:  982        6 Batch loss: 0.182551 Batch F1: 0.68
Epoch:  982        7 Batch loss: 0.183606 Batch F1: 0.6666666666666665
Epoch:  982        8 Batch loss: 0.172625 Batch F1: 0.7391304347826085
Epoch:  982        9 Batch loss: 0.159990 Batch F1: 0.8214285714285715
Epoch:  982       10 Batch loss: 0.162047 Batch F1: 0.8076923076923077
Epoch:  982       11 Batch loss: 0.188031 Batch F1: 0.5945945945945946
Epoch:  982       12 Batch loss: 0.168215 Batch F1: 0.7272727272727273
Train Avg Loss  982: 0.173458

Train Avg F1  982: 0.7124433533329843

Val Avg Loss  982: 0.184362

Val Avg F1  982:  0.6785473542298618

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 983
--------------------------------------------------------------
Epoch:  983        1 Batch loss: 0.181943 Batch F1: 0.6666666666666666
Epoch:  983        2 Batch loss: 0.140661 Batch F1: 0.787878787878788
Epoch:  983        3 Batch loss: 0.168283 Batch F1: 0.7755102040816326
Epoch:  983        4 Batch loss: 0.170663 Batch F1: 0.7843137254901961
Epoch:  983        5 Batch loss: 0.199401 Batch F1: 0.6530612244897959
Epoch:  983        6 Batch loss: 0.172737 Batch F1: 0.7317073170731707
Epoch:  983        7 Batch loss: 0.167089 Batch F1: 0.7
Epoch:  983        8 Batch loss: 0.170916 Batch F1: 0.6976744186046512
Epoch:  983        9 Batch loss: 0.180409 Batch F1: 0.6808510638297872
Epoch:  983       10 Batch loss: 0.151109 Batch F1: 0.7727272727272727
Epoch:  983       11 Batch loss: 0.169947 Batch F1: 0.6666666666666666
Epoch:  983       12 Batch loss: 0.194483 Batch F1: 0.6341463414634146
Train Avg Loss  983: 0.172303

Train Avg F1  983: 0.7126003074143369

Val Avg Loss  983: 0.181469

Val Avg F1  983:  0.6687426500587995

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 984
--------------------------------------------------------------
Epoch:  984        1 Batch loss: 0.164734 Batch F1: 0.606060606060606
Epoch:  984        2 Batch loss: 0.185490 Batch F1: 0.6938775510204083
Epoch:  984        3 Batch loss: 0.128554 Batch F1: 0.8800000000000001
Epoch:  984        4 Batch loss: 0.176513 Batch F1: 0.6956521739130435
Epoch:  984        5 Batch loss: 0.194951 Batch F1: 0.6190476190476191
Epoch:  984        6 Batch loss: 0.145447 Batch F1: 0.8085106382978724
Epoch:  984        7 Batch loss: 0.187829 Batch F1: 0.6666666666666666
Epoch:  984        8 Batch loss: 0.166698 Batch F1: 0.7692307692307693
Epoch:  984        9 Batch loss: 0.187764 Batch F1: 0.6666666666666666
Epoch:  984       10 Batch loss: 0.162669 Batch F1: 0.7222222222222222
Epoch:  984       11 Batch loss: 0.173027 Batch F1: 0.6666666666666666
Epoch:  984       12 Batch loss: 0.175989 Batch F1: 0.6842105263157895
Train Avg Loss  984: 0.170805

Train Avg F1  984: 0.7065676755090277

Val Avg Loss  984: 0.181248

Val Avg F1  984:  0.6784606678431127

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 985
--------------------------------------------------------------
Epoch:  985        1 Batch loss: 0.190969 Batch F1: 0.6956521739130435
Epoch:  985        2 Batch loss: 0.142770 Batch F1: 0.8571428571428572
Epoch:  985        3 Batch loss: 0.207440 Batch F1: 0.5714285714285713
Epoch:  985        4 Batch loss: 0.142122 Batch F1: 0.7804878048780488
Epoch:  985        5 Batch loss: 0.169523 Batch F1: 0.7547169811320754
Epoch:  985        6 Batch loss: 0.178073 Batch F1: 0.72
Epoch:  985        7 Batch loss: 0.186163 Batch F1: 0.5555555555555556
Epoch:  985        8 Batch loss: 0.166700 Batch F1: 0.7500000000000001
Epoch:  985        9 Batch loss: 0.153144 Batch F1: 0.6206896551724138
Epoch:  985       10 Batch loss: 0.158217 Batch F1: 0.7142857142857143
Epoch:  985       11 Batch loss: 0.184397 Batch F1: 0.6938775510204083
Epoch:  985       12 Batch loss: 0.161558 Batch F1: 0.7692307692307692
Train Avg Loss  985: 0.170090

Train Avg F1  985: 0.7069223028132882

Val Avg Loss  985: 0.182191

Val Avg F1  985:  0.676453488372093

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 986
--------------------------------------------------------------
Epoch:  986        1 Batch loss: 0.193535 Batch F1: 0.6808510638297872
Epoch:  986        2 Batch loss: 0.140043 Batch F1: 0.7428571428571428
Epoch:  986        3 Batch loss: 0.154671 Batch F1: 0.7692307692307692
Epoch:  986        4 Batch loss: 0.181045 Batch F1: 0.6976744186046512
Epoch:  986        5 Batch loss: 0.161880 Batch F1: 0.8070175438596492
Epoch:  986        6 Batch loss: 0.141546 Batch F1: 0.7428571428571428
Epoch:  986        7 Batch loss: 0.171944 Batch F1: 0.7547169811320754
Epoch:  986        8 Batch loss: 0.224799 Batch F1: 0.34285714285714286
Epoch:  986        9 Batch loss: 0.164519 Batch F1: 0.7391304347826088
Epoch:  986       10 Batch loss: 0.174699 Batch F1: 0.6938775510204082
Epoch:  986       11 Batch loss: 0.175277 Batch F1: 0.7843137254901961
Epoch:  986       12 Batch loss: 0.151009 Batch F1: 0.7058823529411764
Train Avg Loss  986: 0.169581

Train Avg F1  986: 0.7051055224552291

Val Avg Loss  986: 0.180741

Val Avg F1  986:  0.6785943223443223

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 987
--------------------------------------------------------------
Epoch:  987        1 Batch loss: 0.169512 Batch F1: 0.65
Epoch:  987        2 Batch loss: 0.178277 Batch F1: 0.6190476190476191
Epoch:  987        3 Batch loss: 0.201000 Batch F1: 0.6382978723404256
Epoch:  987        4 Batch loss: 0.184580 Batch F1: 0.7169811320754716
Epoch:  987        5 Batch loss: 0.151685 Batch F1: 0.7727272727272727
Epoch:  987        6 Batch loss: 0.156604 Batch F1: 0.7272727272727273
Epoch:  987        7 Batch loss: 0.175142 Batch F1: 0.76
Epoch:  987        8 Batch loss: 0.189174 Batch F1: 0.7200000000000001
Epoch:  987        9 Batch loss: 0.164251 Batch F1: 0.7368421052631579
Epoch:  987       10 Batch loss: 0.159481 Batch F1: 0.7391304347826088
Epoch:  987       11 Batch loss: 0.127908 Batch F1: 0.8421052631578947
Epoch:  987       12 Batch loss: 0.177079 Batch F1: 0.6060606060606061
Train Avg Loss  987: 0.169558

Train Avg F1  987: 0.7107054193939818

Val Avg Loss  987: 0.181850

Val Avg F1  987:  0.674410734193343

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 988
--------------------------------------------------------------
Epoch:  988        1 Batch loss: 0.170861 Batch F1: 0.7
Epoch:  988        2 Batch loss: 0.149503 Batch F1: 0.7272727272727272
Epoch:  988        3 Batch loss: 0.154933 Batch F1: 0.6666666666666667
Epoch:  988        4 Batch loss: 0.178520 Batch F1: 0.7346938775510203
Epoch:  988        5 Batch loss: 0.165141 Batch F1: 0.76
Epoch:  988        6 Batch loss: 0.176600 Batch F1: 0.6976744186046512
Epoch:  988        7 Batch loss: 0.165187 Batch F1: 0.7272727272727272
Epoch:  988        8 Batch loss: 0.148196 Batch F1: 0.8400000000000001
Epoch:  988        9 Batch loss: 0.206168 Batch F1: 0.6274509803921569
Epoch:  988       10 Batch loss: 0.181953 Batch F1: 0.72
Epoch:  988       11 Batch loss: 0.159483 Batch F1: 0.7755102040816326
Epoch:  988       12 Batch loss: 0.186586 Batch F1: 0.48484848484848486
Train Avg Loss  988: 0.170261

Train Avg F1  988: 0.7051158405575055

Val Avg Loss  988: 0.181131

Val Avg F1  988:  0.6764270925761608

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 989
--------------------------------------------------------------
Epoch:  989        1 Batch loss: 0.172263 Batch F1: 0.7142857142857143
Epoch:  989        2 Batch loss: 0.219970 Batch F1: 0.5416666666666667
Epoch:  989        3 Batch loss: 0.135824 Batch F1: 0.8571428571428571
Epoch:  989        4 Batch loss: 0.164311 Batch F1: 0.6111111111111112
Epoch:  989        5 Batch loss: 0.151295 Batch F1: 0.7804878048780488
Epoch:  989        6 Batch loss: 0.156536 Batch F1: 0.6666666666666667
Epoch:  989        7 Batch loss: 0.172691 Batch F1: 0.6500000000000001
Epoch:  989        8 Batch loss: 0.190046 Batch F1: 0.6382978723404256
Epoch:  989        9 Batch loss: 0.194146 Batch F1: 0.7058823529411765
Epoch:  989       10 Batch loss: 0.166604 Batch F1: 0.7199999999999999
Epoch:  989       11 Batch loss: 0.175402 Batch F1: 0.8571428571428571
Epoch:  989       12 Batch loss: 0.136635 Batch F1: 0.8571428571428572
Train Avg Loss  989: 0.169644

Train Avg F1  989: 0.7166522300265318

Val Avg Loss  989: 0.182093

Val Avg F1  989:  0.6768289275736085

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 990
--------------------------------------------------------------
Epoch:  990        1 Batch loss: 0.167947 Batch F1: 0.7547169811320756
Epoch:  990        2 Batch loss: 0.143200 Batch F1: 0.7368421052631579
Epoch:  990        3 Batch loss: 0.133605 Batch F1: 0.7586206896551724
Epoch:  990        4 Batch loss: 0.210985 Batch F1: 0.5909090909090909
Epoch:  990        5 Batch loss: 0.150970 Batch F1: 0.7906976744186046
Epoch:  990        6 Batch loss: 0.173417 Batch F1: 0.7777777777777777
Epoch:  990        7 Batch loss: 0.150872 Batch F1: 0.7659574468085107
Epoch:  990        8 Batch loss: 0.220264 Batch F1: 0.627450980392157
Epoch:  990        9 Batch loss: 0.226492 Batch F1: 0.5599999999999999
Epoch:  990       10 Batch loss: 0.190189 Batch F1: 0.5405405405405405
Epoch:  990       11 Batch loss: 0.129559 Batch F1: 0.8780487804878048
Epoch:  990       12 Batch loss: 0.157710 Batch F1: 0.7894736842105262
Train Avg Loss  990: 0.171267

Train Avg F1  990: 0.7142529792996181

Val Avg Loss  990: 0.183581

Val Avg F1  990:  0.6773144040224786

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 991
--------------------------------------------------------------
Epoch:  991        1 Batch loss: 0.144293 Batch F1: 0.7894736842105263
Epoch:  991        2 Batch loss: 0.175653 Batch F1: 0.7272727272727272
Epoch:  991        3 Batch loss: 0.156955 Batch F1: 0.7555555555555556
Epoch:  991        4 Batch loss: 0.199867 Batch F1: 0.6363636363636364
Epoch:  991        5 Batch loss: 0.200329 Batch F1: 0.6538461538461539
Epoch:  991        6 Batch loss: 0.150635 Batch F1: 0.7368421052631577
Epoch:  991        7 Batch loss: 0.170954 Batch F1: 0.6976744186046512
Epoch:  991        8 Batch loss: 0.181146 Batch F1: 0.7307692307692308
Epoch:  991        9 Batch loss: 0.132920 Batch F1: 0.8000000000000002
Epoch:  991       10 Batch loss: 0.173588 Batch F1: 0.6829268292682926
Epoch:  991       11 Batch loss: 0.192431 Batch F1: 0.693877551020408
Epoch:  991       12 Batch loss: 0.192299 Batch F1: 0.6666666666666667
Train Avg Loss  991: 0.172589

Train Avg F1  991: 0.7142723799034171

Val Avg Loss  991: 0.183938

Val Avg F1  991:  0.6756372549019609

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 992
--------------------------------------------------------------
Epoch:  992        1 Batch loss: 0.136472 Batch F1: 0.8372093023255814
Epoch:  992        2 Batch loss: 0.176202 Batch F1: 0.7636363636363638
Epoch:  992        3 Batch loss: 0.173457 Batch F1: 0.6666666666666666
Epoch:  992        4 Batch loss: 0.171539 Batch F1: 0.6486486486486486
Epoch:  992        5 Batch loss: 0.177384 Batch F1: 0.711111111111111
Epoch:  992        6 Batch loss: 0.173256 Batch F1: 0.711111111111111
Epoch:  992        7 Batch loss: 0.148805 Batch F1: 0.5384615384615384
Epoch:  992        8 Batch loss: 0.193173 Batch F1: 0.5128205128205129
Epoch:  992        9 Batch loss: 0.146986 Batch F1: 0.8679245283018868
Epoch:  992       10 Batch loss: 0.211599 Batch F1: 0.64
Epoch:  992       11 Batch loss: 0.174422 Batch F1: 0.711111111111111
Epoch:  992       12 Batch loss: 0.164986 Batch F1: 0.7999999999999999
Train Avg Loss  992: 0.170690

Train Avg F1  992: 0.7007250745162109

Val Avg Loss  992: 0.183517

Val Avg F1  992:  0.6776807739747147

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 993
--------------------------------------------------------------
Epoch:  993        1 Batch loss: 0.171419 Batch F1: 0.7441860465116279
Epoch:  993        2 Batch loss: 0.185595 Batch F1: 0.6500000000000001
Epoch:  993        3 Batch loss: 0.177193 Batch F1: 0.76
Epoch:  993        4 Batch loss: 0.163691 Batch F1: 0.7999999999999999
Epoch:  993        5 Batch loss: 0.161516 Batch F1: 0.7555555555555555
Epoch:  993        6 Batch loss: 0.187398 Batch F1: 0.6046511627906976
Epoch:  993        7 Batch loss: 0.158264 Batch F1: 0.7499999999999999
Epoch:  993        8 Batch loss: 0.163813 Batch F1: 0.7450980392156864
Epoch:  993        9 Batch loss: 0.193090 Batch F1: 0.6792452830188679
Epoch:  993       10 Batch loss: 0.155772 Batch F1: 0.7058823529411765
Epoch:  993       11 Batch loss: 0.176540 Batch F1: 0.5517241379310344
Epoch:  993       12 Batch loss: 0.173428 Batch F1: 0.717948717948718
Train Avg Loss  993: 0.172310

Train Avg F1  993: 0.7053576079927804

Val Avg Loss  993: 0.182954

Val Avg F1  993:  0.6782759202971969

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 994
--------------------------------------------------------------
Epoch:  994        1 Batch loss: 0.208145 Batch F1: 0.5
Epoch:  994        2 Batch loss: 0.175769 Batch F1: 0.7083333333333333
Epoch:  994        3 Batch loss: 0.162578 Batch F1: 0.606060606060606
Epoch:  994        4 Batch loss: 0.159447 Batch F1: 0.8852459016393444
Epoch:  994        5 Batch loss: 0.171945 Batch F1: 0.7555555555555555
Epoch:  994        6 Batch loss: 0.169871 Batch F1: 0.6666666666666667
Epoch:  994        7 Batch loss: 0.144731 Batch F1: 0.8333333333333334
Epoch:  994        8 Batch loss: 0.181472 Batch F1: 0.7307692307692306
Epoch:  994        9 Batch loss: 0.153774 Batch F1: 0.7058823529411765
Epoch:  994       10 Batch loss: 0.217279 Batch F1: 0.47619047619047616
Epoch:  994       11 Batch loss: 0.153750 Batch F1: 0.816326530612245
Epoch:  994       12 Batch loss: 0.152453 Batch F1: 0.7058823529411764
Train Avg Loss  994: 0.170935

Train Avg F1  994: 0.6991871950035953

Val Avg Loss  994: 0.182599

Val Avg F1  994:  0.6785503225593702

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 995
--------------------------------------------------------------
Epoch:  995        1 Batch loss: 0.174571 Batch F1: 0.7692307692307692
Epoch:  995        2 Batch loss: 0.170375 Batch F1: 0.5789473684210527
Epoch:  995        3 Batch loss: 0.183217 Batch F1: 0.611111111111111
Epoch:  995        4 Batch loss: 0.177970 Batch F1: 0.723404255319149
Epoch:  995        5 Batch loss: 0.186075 Batch F1: 0.6666666666666666
Epoch:  995        6 Batch loss: 0.148177 Batch F1: 0.6857142857142856
Epoch:  995        7 Batch loss: 0.167646 Batch F1: 0.823529411764706
Epoch:  995        8 Batch loss: 0.152276 Batch F1: 0.6857142857142857
Epoch:  995        9 Batch loss: 0.162326 Batch F1: 0.7804878048780488
Epoch:  995       10 Batch loss: 0.219955 Batch F1: 0.5217391304347826
Epoch:  995       11 Batch loss: 0.170230 Batch F1: 0.7441860465116279
Epoch:  995       12 Batch loss: 0.149481 Batch F1: 0.7272727272727272
Train Avg Loss  995: 0.171858

Train Avg F1  995: 0.6931669885866009

Val Avg Loss  995: 0.181563

Val Avg F1  995:  0.6664285714285714

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 996
--------------------------------------------------------------
Epoch:  996        1 Batch loss: 0.149740 Batch F1: 0.7916666666666667
Epoch:  996        2 Batch loss: 0.172443 Batch F1: 0.6875
Epoch:  996        3 Batch loss: 0.193085 Batch F1: 0.6909090909090909
Epoch:  996        4 Batch loss: 0.174251 Batch F1: 0.7755102040816326
Epoch:  996        5 Batch loss: 0.188291 Batch F1: 0.72
Epoch:  996        6 Batch loss: 0.145334 Batch F1: 0.7916666666666667
Epoch:  996        7 Batch loss: 0.188892 Batch F1: 0.6046511627906977
Epoch:  996        8 Batch loss: 0.168663 Batch F1: 0.7391304347826088
Epoch:  996        9 Batch loss: 0.184727 Batch F1: 0.5555555555555556
Epoch:  996       10 Batch loss: 0.164550 Batch F1: 0.6666666666666666
Epoch:  996       11 Batch loss: 0.193816 Batch F1: 0.5833333333333334
Epoch:  996       12 Batch loss: 0.164597 Batch F1: 0.7777777777777778
Train Avg Loss  996: 0.174032

Train Avg F1  996: 0.6986972966025581

Val Avg Loss  996: 0.183439

Val Avg F1  996:  0.6676406238848027

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 997
--------------------------------------------------------------
Epoch:  997        1 Batch loss: 0.195176 Batch F1: 0.5777777777777778
Epoch:  997        2 Batch loss: 0.160908 Batch F1: 0.8
Epoch:  997        3 Batch loss: 0.141779 Batch F1: 0.8695652173913043
Epoch:  997        4 Batch loss: 0.183653 Batch F1: 0.6500000000000001
Epoch:  997        5 Batch loss: 0.184832 Batch F1: 0.5853658536585366
Epoch:  997        6 Batch loss: 0.175271 Batch F1: 0.7450980392156863
Epoch:  997        7 Batch loss: 0.154202 Batch F1: 0.75
Epoch:  997        8 Batch loss: 0.171893 Batch F1: 0.7500000000000001
Epoch:  997        9 Batch loss: 0.161267 Batch F1: 0.7391304347826089
Epoch:  997       10 Batch loss: 0.145493 Batch F1: 0.7647058823529412
Epoch:  997       11 Batch loss: 0.168581 Batch F1: 0.6829268292682926
Epoch:  997       12 Batch loss: 0.207032 Batch F1: 0.6046511627906977
Train Avg Loss  997: 0.170841

Train Avg F1  997: 0.7099350997698205

Val Avg Loss  997: 0.182053

Val Avg F1  997:  0.6769761494081961

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 998
--------------------------------------------------------------
Epoch:  998        1 Batch loss: 0.189684 Batch F1: 0.68
Epoch:  998        2 Batch loss: 0.148757 Batch F1: 0.7647058823529413
Epoch:  998        3 Batch loss: 0.170629 Batch F1: 0.76
Epoch:  998        4 Batch loss: 0.158905 Batch F1: 0.6857142857142857
Epoch:  998        5 Batch loss: 0.156604 Batch F1: 0.7234042553191489
Epoch:  998        6 Batch loss: 0.182375 Batch F1: 0.6666666666666666
Epoch:  998        7 Batch loss: 0.167911 Batch F1: 0.6818181818181818
Epoch:  998        8 Batch loss: 0.163124 Batch F1: 0.7
Epoch:  998        9 Batch loss: 0.160371 Batch F1: 0.7391304347826089
Epoch:  998       10 Batch loss: 0.174896 Batch F1: 0.6666666666666666
Epoch:  998       11 Batch loss: 0.164224 Batch F1: 0.76
Epoch:  998       12 Batch loss: 0.186721 Batch F1: 0.7142857142857143
Train Avg Loss  998: 0.168684

Train Avg F1  998: 0.711866007300518

Val Avg Loss  998: 0.180982

Val Avg F1  998:  0.6782630721113607

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 999
--------------------------------------------------------------
Epoch:  999        1 Batch loss: 0.152403 Batch F1: 0.5806451612903226
Epoch:  999        2 Batch loss: 0.208226 Batch F1: 0.5714285714285715
Epoch:  999        3 Batch loss: 0.151363 Batch F1: 0.8085106382978724
Epoch:  999        4 Batch loss: 0.168848 Batch F1: 0.7346938775510204
Epoch:  999        5 Batch loss: 0.191299 Batch F1: 0.6521739130434783
Epoch:  999        6 Batch loss: 0.153969 Batch F1: 0.6470588235294118
Epoch:  999        7 Batch loss: 0.166572 Batch F1: 0.8214285714285715
Epoch:  999        8 Batch loss: 0.172980 Batch F1: 0.631578947368421
Epoch:  999        9 Batch loss: 0.187902 Batch F1: 0.6521739130434783
Epoch:  999       10 Batch loss: 0.153652 Batch F1: 0.8135593220338982
Epoch:  999       11 Batch loss: 0.194142 Batch F1: 0.7843137254901961
Epoch:  999       12 Batch loss: 0.169108 Batch F1: 0.761904761904762
Train Avg Loss  999: 0.172539

Train Avg F1  999: 0.7049558522008338

Val Avg Loss  999: 0.182182

Val Avg F1  999:  0.6778748733535968

Optimal Val loss (Epoch 588): 0.1789267472922802

Epoch 1000
--------------------------------------------------------------
Epoch: 1000        1 Batch loss: 0.163752 Batch F1: 0.7391304347826088
Epoch: 1000        2 Batch loss: 0.135341 Batch F1: 0.8695652173913043
Epoch: 1000        3 Batch loss: 0.176416 Batch F1: 0.6956521739130435
Epoch: 1000        4 Batch loss: 0.176476 Batch F1: 0.7234042553191489
Epoch: 1000        5 Batch loss: 0.171946 Batch F1: 0.76
Epoch: 1000        6 Batch loss: 0.181590 Batch F1: 0.6666666666666667
Epoch: 1000        7 Batch loss: 0.178043 Batch F1: 0.7407407407407408
Epoch: 1000        8 Batch loss: 0.183805 Batch F1: 0.7843137254901961
Epoch: 1000        9 Batch loss: 0.177581 Batch F1: 0.6666666666666666
Epoch: 1000       10 Batch loss: 0.182660 Batch F1: 0.6060606060606061
Epoch: 1000       11 Batch loss: 0.171344 Batch F1: 0.7692307692307692
Epoch: 1000       12 Batch loss: 0.198283 Batch F1: 0.7441860465116279
Train Avg Loss 1000: 0.174770

Train Avg F1 1000: 0.7304681085644482

Val Avg Loss 1000: 0.188188

Val Avg F1 1000:  0.8530579349728287

Optimal Val loss (Epoch 588): 0.1789267472922802

Done!
