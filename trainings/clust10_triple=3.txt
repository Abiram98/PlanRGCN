Removed 3 of 595
Removed 0 of 198
Removed 0 of 198
Model with variable positions in join nodes
Loss function: MSELoss
Optimizer: LR [0.01] weight decay [0.0005]
Epoch 1
--------------------------------------------------------------
Epoch:    1        1 Batch loss: 0.256941 Batch F1: 0.43750000000000006
Epoch:    1        2 Batch loss: 0.240131 Batch F1: 0.0
Epoch:    1        3 Batch loss: 0.230780 Batch F1: 0.0
Epoch:    1        4 Batch loss: 0.230455 Batch F1: 0.0
Epoch:    1        5 Batch loss: 0.263858 Batch F1: 0.0
Epoch:    1        6 Batch loss: 0.235692 Batch F1: 0.0
Epoch:    1        7 Batch loss: 0.217183 Batch F1: 0.0
Epoch:    1        8 Batch loss: 0.235635 Batch F1: 0.0
Epoch:    1        9 Batch loss: 0.235600 Batch F1: 0.0
Epoch:    1       10 Batch loss: 0.245229 Batch F1: 0.0
Epoch:    1       11 Batch loss: 0.235614 Batch F1: 0.0
Epoch:    1       12 Batch loss: 0.208449 Batch F1: 0.0
Train Avg Loss    1: 0.236297

Train Avg F1    1: 0.036458333333333336

Val Avg Loss    1: 0.223484

Val Avg F1    1:  0.0

Optimal Val loss (Epoch 1): 0.2234843112528324

Epoch 2
--------------------------------------------------------------
Epoch:    2        1 Batch loss: 0.256076 Batch F1: 0.0
Epoch:    2        2 Batch loss: 0.235556 Batch F1: 0.0
Epoch:    2        3 Batch loss: 0.235692 Batch F1: 0.0
Epoch:    2        4 Batch loss: 0.225260 Batch F1: 0.0
Epoch:    2        5 Batch loss: 0.209313 Batch F1: 0.0
Epoch:    2        6 Batch loss: 0.259625 Batch F1: 0.0
Epoch:    2        7 Batch loss: 0.224426 Batch F1: 0.0
Epoch:    2        8 Batch loss: 0.230566 Batch F1: 0.0
Epoch:    2        9 Batch loss: 0.224375 Batch F1: 0.0
Epoch:    2       10 Batch loss: 0.242482 Batch F1: 0.0
Epoch:    2       11 Batch loss: 0.241908 Batch F1: 0.0
Epoch:    2       12 Batch loss: 0.199585 Batch F1: 0.0
Train Avg Loss    2: 0.232072

Train Avg F1    2: 0.0

Val Avg Loss    2: 0.222625

Val Avg F1    2:  0.0

Optimal Val loss (Epoch 2): 0.22262487187981606

Epoch 3
--------------------------------------------------------------
Epoch:    3        1 Batch loss: 0.235422 Batch F1: 0.0
Epoch:    3        2 Batch loss: 0.261142 Batch F1: 0.0
Epoch:    3        3 Batch loss: 0.252996 Batch F1: 0.0
Epoch:    3        4 Batch loss: 0.221904 Batch F1: 0.0
Epoch:    3        5 Batch loss: 0.231550 Batch F1: 0.0
Epoch:    3        6 Batch loss: 0.243841 Batch F1: 0.0
Epoch:    3        7 Batch loss: 0.219615 Batch F1: 0.0
Epoch:    3        8 Batch loss: 0.220693 Batch F1: 0.0
Epoch:    3        9 Batch loss: 0.241904 Batch F1: 0.0
Epoch:    3       10 Batch loss: 0.249319 Batch F1: 0.0
Epoch:    3       11 Batch loss: 0.211835 Batch F1: 0.0
Epoch:    3       12 Batch loss: 0.199598 Batch F1: 0.0
Train Avg Loss    3: 0.232485

Train Avg F1    3: 0.0

Val Avg Loss    3: 0.222094

Val Avg F1    3:  0.0

Optimal Val loss (Epoch 3): 0.2220938354730606

Epoch 4
--------------------------------------------------------------
Epoch:    4        1 Batch loss: 0.217902 Batch F1: 0.0
Epoch:    4        2 Batch loss: 0.237991 Batch F1: 0.0
Epoch:    4        3 Batch loss: 0.238181 Batch F1: 0.0
Epoch:    4        4 Batch loss: 0.217726 Batch F1: 0.0
Epoch:    4        5 Batch loss: 0.237810 Batch F1: 0.0
Epoch:    4        6 Batch loss: 0.204856 Batch F1: 0.0
Epoch:    4        7 Batch loss: 0.230887 Batch F1: 0.0
Epoch:    4        8 Batch loss: 0.243629 Batch F1: 0.0
Epoch:    4        9 Batch loss: 0.267487 Batch F1: 0.0
Epoch:    4       10 Batch loss: 0.219175 Batch F1: 0.0
Epoch:    4       11 Batch loss: 0.235606 Batch F1: 0.0
Epoch:    4       12 Batch loss: 0.241081 Batch F1: 0.0
Train Avg Loss    4: 0.232694

Train Avg F1    4: 0.0

Val Avg Loss    4: 0.227399

Val Avg F1    4:  0.0

Optimal Val loss (Epoch 3): 0.2220938354730606

Epoch 5
--------------------------------------------------------------
Epoch:    5        1 Batch loss: 0.225050 Batch F1: 0.0
Epoch:    5        2 Batch loss: 0.231122 Batch F1: 0.0
Epoch:    5        3 Batch loss: 0.210344 Batch F1: 0.0
Epoch:    5        4 Batch loss: 0.209663 Batch F1: 0.0
Epoch:    5        5 Batch loss: 0.207040 Batch F1: 0.0
Epoch:    5        6 Batch loss: 0.243143 Batch F1: 0.0
Epoch:    5        7 Batch loss: 0.224458 Batch F1: 0.0
Epoch:    5        8 Batch loss: 0.248170 Batch F1: 0.0
Epoch:    5        9 Batch loss: 0.262054 Batch F1: 0.0
Epoch:    5       10 Batch loss: 0.239991 Batch F1: 0.0
Epoch:    5       11 Batch loss: 0.244036 Batch F1: 0.0
Epoch:    5       12 Batch loss: 0.247554 Batch F1: 0.0
Train Avg Loss    5: 0.232719

Train Avg F1    5: 0.0

Val Avg Loss    5: 0.242252

Val Avg F1    5:  0.0

Optimal Val loss (Epoch 3): 0.2220938354730606

Epoch 6
--------------------------------------------------------------
Epoch:    6        1 Batch loss: 0.248533 Batch F1: 0.0
Epoch:    6        2 Batch loss: 0.241319 Batch F1: 0.0
Epoch:    6        3 Batch loss: 0.243458 Batch F1: 0.0
Epoch:    6        4 Batch loss: 0.221213 Batch F1: 0.0
Epoch:    6        5 Batch loss: 0.195602 Batch F1: 0.0
Epoch:    6        6 Batch loss: 0.217557 Batch F1: 0.0
Epoch:    6        7 Batch loss: 0.267891 Batch F1: 0.0
Epoch:    6        8 Batch loss: 0.218492 Batch F1: 0.0
Epoch:    6        9 Batch loss: 0.268056 Batch F1: 0.0
Epoch:    6       10 Batch loss: 0.249382 Batch F1: 0.0
Epoch:    6       11 Batch loss: 0.253613 Batch F1: 0.0
Epoch:    6       12 Batch loss: 0.207676 Batch F1: 0.0
Train Avg Loss    6: 0.236066

Train Avg F1    6: 0.0

Val Avg Loss    6: 0.222782

Val Avg F1    6:  0.0

Optimal Val loss (Epoch 3): 0.2220938354730606

Epoch 7
--------------------------------------------------------------
Epoch:    7        1 Batch loss: 0.213897 Batch F1: 0.0
Epoch:    7        2 Batch loss: 0.214800 Batch F1: 0.0
Epoch:    7        3 Batch loss: 0.219400 Batch F1: 0.0
Epoch:    7        4 Batch loss: 0.247651 Batch F1: 0.0
Epoch:    7        5 Batch loss: 0.224624 Batch F1: 0.0
Epoch:    7        6 Batch loss: 0.224405 Batch F1: 0.0
Epoch:    7        7 Batch loss: 0.273210 Batch F1: 0.0
Epoch:    7        8 Batch loss: 0.219141 Batch F1: 0.0
Epoch:    7        9 Batch loss: 0.214216 Batch F1: 0.0
Epoch:    7       10 Batch loss: 0.257542 Batch F1: 0.0
Epoch:    7       11 Batch loss: 0.240203 Batch F1: 0.0
Epoch:    7       12 Batch loss: 0.241210 Batch F1: 0.0
Train Avg Loss    7: 0.232525

Train Avg F1    7: 0.0

Val Avg Loss    7: 0.226739

Val Avg F1    7:  0.0

Optimal Val loss (Epoch 3): 0.2220938354730606

Epoch 8
--------------------------------------------------------------
Epoch:    8        1 Batch loss: 0.259221 Batch F1: 0.0
Epoch:    8        2 Batch loss: 0.237430 Batch F1: 0.0
Epoch:    8        3 Batch loss: 0.237751 Batch F1: 0.0
Epoch:    8        4 Batch loss: 0.244187 Batch F1: 0.0
Epoch:    8        5 Batch loss: 0.238246 Batch F1: 0.0
Epoch:    8        6 Batch loss: 0.224369 Batch F1: 0.0
Epoch:    8        7 Batch loss: 0.234969 Batch F1: 0.0
Epoch:    8        8 Batch loss: 0.224841 Batch F1: 0.0
Epoch:    8        9 Batch loss: 0.242214 Batch F1: 0.0
Epoch:    8       10 Batch loss: 0.230581 Batch F1: 0.0
Epoch:    8       11 Batch loss: 0.218206 Batch F1: 0.0
Epoch:    8       12 Batch loss: 0.192015 Batch F1: 0.0
Train Avg Loss    8: 0.232003

Train Avg F1    8: 0.0

Val Avg Loss    8: 0.221923

Val Avg F1    8:  0.0

Optimal Val loss (Epoch 8): 0.22192343324422836

Epoch 9
--------------------------------------------------------------
Epoch:    9        1 Batch loss: 0.224443 Batch F1: 0.0
Epoch:    9        2 Batch loss: 0.238010 Batch F1: 0.0
Epoch:    9        3 Batch loss: 0.251861 Batch F1: 0.0
Epoch:    9        4 Batch loss: 0.244692 Batch F1: 0.0
Epoch:    9        5 Batch loss: 0.211326 Batch F1: 0.0
Epoch:    9        6 Batch loss: 0.218020 Batch F1: 0.0
Epoch:    9        7 Batch loss: 0.224414 Batch F1: 0.0
Epoch:    9        8 Batch loss: 0.243279 Batch F1: 0.0
Epoch:    9        9 Batch loss: 0.212078 Batch F1: 0.0
Epoch:    9       10 Batch loss: 0.224466 Batch F1: 0.0
Epoch:    9       11 Batch loss: 0.236616 Batch F1: 0.0
Epoch:    9       12 Batch loss: 0.272326 Batch F1: 0.0
Train Avg Loss    9: 0.233461

Train Avg F1    9: 0.0

Val Avg Loss    9: 0.222874

Val Avg F1    9:  0.0

Optimal Val loss (Epoch 8): 0.22192343324422836

Epoch 10
--------------------------------------------------------------
Epoch:   10        1 Batch loss: 0.274941 Batch F1: 0.0
Epoch:   10        2 Batch loss: 0.235504 Batch F1: 0.0
Epoch:   10        3 Batch loss: 0.228278 Batch F1: 0.0
Epoch:   10        4 Batch loss: 0.239875 Batch F1: 0.0
Epoch:   10        5 Batch loss: 0.248998 Batch F1: 0.0
Epoch:   10        6 Batch loss: 0.249518 Batch F1: 0.0
Epoch:   10        7 Batch loss: 0.246176 Batch F1: 0.0
Epoch:   10        8 Batch loss: 0.241837 Batch F1: 0.0
Epoch:   10        9 Batch loss: 0.219009 Batch F1: 0.0
Epoch:   10       10 Batch loss: 0.222001 Batch F1: 0.0
Epoch:   10       11 Batch loss: 0.199709 Batch F1: 0.0
Epoch:   10       12 Batch loss: 0.229909 Batch F1: 0.0
Train Avg Loss   10: 0.236313

Train Avg F1   10: 0.0

Val Avg Loss   10: 0.223343

Val Avg F1   10:  0.0

Optimal Val loss (Epoch 8): 0.22192343324422836

Epoch 11
--------------------------------------------------------------
Epoch:   11        1 Batch loss: 0.246297 Batch F1: 0.0
Epoch:   11        2 Batch loss: 0.235722 Batch F1: 0.0
Epoch:   11        3 Batch loss: 0.235398 Batch F1: 0.0
Epoch:   11        4 Batch loss: 0.245838 Batch F1: 0.0
Epoch:   11        5 Batch loss: 0.226259 Batch F1: 0.0
Epoch:   11        6 Batch loss: 0.211973 Batch F1: 0.0
Epoch:   11        7 Batch loss: 0.258131 Batch F1: 0.0
Epoch:   11        8 Batch loss: 0.224643 Batch F1: 0.0
Epoch:   11        9 Batch loss: 0.206123 Batch F1: 0.0
Epoch:   11       10 Batch loss: 0.230796 Batch F1: 0.0
Epoch:   11       11 Batch loss: 0.252050 Batch F1: 0.0
Epoch:   11       12 Batch loss: 0.213385 Batch F1: 0.0
Train Avg Loss   11: 0.232218

Train Avg F1   11: 0.0

Val Avg Loss   11: 0.221489

Val Avg F1   11:  0.0

Optimal Val loss (Epoch 11): 0.2214886173605919

Epoch 12
--------------------------------------------------------------
Epoch:   12        1 Batch loss: 0.229952 Batch F1: 0.0
Epoch:   12        2 Batch loss: 0.263133 Batch F1: 0.0
Epoch:   12        3 Batch loss: 0.210084 Batch F1: 0.0
Epoch:   12        4 Batch loss: 0.224546 Batch F1: 0.0
Epoch:   12        5 Batch loss: 0.233993 Batch F1: 0.0
Epoch:   12        6 Batch loss: 0.275468 Batch F1: 0.0
Epoch:   12        7 Batch loss: 0.224187 Batch F1: 0.0
Epoch:   12        8 Batch loss: 0.225804 Batch F1: 0.0
Epoch:   12        9 Batch loss: 0.218886 Batch F1: 0.0
Epoch:   12       10 Batch loss: 0.243510 Batch F1: 0.0
Epoch:   12       11 Batch loss: 0.207066 Batch F1: 0.0
Epoch:   12       12 Batch loss: 0.247243 Batch F1: 0.0
Train Avg Loss   12: 0.233656

Train Avg F1   12: 0.0

Val Avg Loss   12: 0.222202

Val Avg F1   12:  0.0

Optimal Val loss (Epoch 11): 0.2214886173605919

Epoch 13
--------------------------------------------------------------
Epoch:   13        1 Batch loss: 0.239965 Batch F1: 0.0
Epoch:   13        2 Batch loss: 0.246744 Batch F1: 0.0
Epoch:   13        3 Batch loss: 0.232379 Batch F1: 0.0
Epoch:   13        4 Batch loss: 0.252030 Batch F1: 0.0
Epoch:   13        5 Batch loss: 0.215343 Batch F1: 0.0
Epoch:   13        6 Batch loss: 0.224833 Batch F1: 0.0
Epoch:   13        7 Batch loss: 0.218902 Batch F1: 0.0
Epoch:   13        8 Batch loss: 0.243783 Batch F1: 0.0
Epoch:   13        9 Batch loss: 0.206300 Batch F1: 0.0
Epoch:   13       10 Batch loss: 0.238521 Batch F1: 0.0
Epoch:   13       11 Batch loss: 0.256271 Batch F1: 0.0
Epoch:   13       12 Batch loss: 0.222510 Batch F1: 0.0
Train Avg Loss   13: 0.233132

Train Avg F1   13: 0.0

Val Avg Loss   13: 0.222900

Val Avg F1   13:  0.0

Optimal Val loss (Epoch 11): 0.2214886173605919

Epoch 14
--------------------------------------------------------------
Epoch:   14        1 Batch loss: 0.259149 Batch F1: 0.0
Epoch:   14        2 Batch loss: 0.206829 Batch F1: 0.0
Epoch:   14        3 Batch loss: 0.225934 Batch F1: 0.0
Epoch:   14        4 Batch loss: 0.256174 Batch F1: 0.0
Epoch:   14        5 Batch loss: 0.222011 Batch F1: 0.0
Epoch:   14        6 Batch loss: 0.220625 Batch F1: 0.0
Epoch:   14        7 Batch loss: 0.242336 Batch F1: 0.0
Epoch:   14        8 Batch loss: 0.210324 Batch F1: 0.0
Epoch:   14        9 Batch loss: 0.250062 Batch F1: 0.0
Epoch:   14       10 Batch loss: 0.210348 Batch F1: 0.0
Epoch:   14       11 Batch loss: 0.236532 Batch F1: 0.0
Epoch:   14       12 Batch loss: 0.239660 Batch F1: 0.0
Train Avg Loss   14: 0.231665

Train Avg F1   14: 0.0

Val Avg Loss   14: 0.220711

Val Avg F1   14:  0.0

Optimal Val loss (Epoch 14): 0.22071067616343498

Epoch 15
--------------------------------------------------------------
Epoch:   15        1 Batch loss: 0.219718 Batch F1: 0.0
Epoch:   15        2 Batch loss: 0.223191 Batch F1: 0.0
Epoch:   15        3 Batch loss: 0.233811 Batch F1: 0.0
Epoch:   15        4 Batch loss: 0.204999 Batch F1: 0.0
Epoch:   15        5 Batch loss: 0.224181 Batch F1: 0.0
Epoch:   15        6 Batch loss: 0.229168 Batch F1: 0.0
Epoch:   15        7 Batch loss: 0.230032 Batch F1: 0.0
Epoch:   15        8 Batch loss: 0.266472 Batch F1: 0.0
Epoch:   15        9 Batch loss: 0.240740 Batch F1: 0.0
Epoch:   15       10 Batch loss: 0.235536 Batch F1: 0.0
Epoch:   15       11 Batch loss: 0.235800 Batch F1: 0.0
Epoch:   15       12 Batch loss: 0.229021 Batch F1: 0.0
Train Avg Loss   15: 0.231056

Train Avg F1   15: 0.0

Val Avg Loss   15: 0.227615

Val Avg F1   15:  0.0

Optimal Val loss (Epoch 14): 0.22071067616343498

Epoch 16
--------------------------------------------------------------
Epoch:   16        1 Batch loss: 0.256306 Batch F1: 0.0
Epoch:   16        2 Batch loss: 0.226182 Batch F1: 0.0
Epoch:   16        3 Batch loss: 0.240444 Batch F1: 0.0
Epoch:   16        4 Batch loss: 0.230320 Batch F1: 0.0
Epoch:   16        5 Batch loss: 0.223839 Batch F1: 0.0
Epoch:   16        6 Batch loss: 0.240169 Batch F1: 0.0
Epoch:   16        7 Batch loss: 0.241067 Batch F1: 0.0
Epoch:   16        8 Batch loss: 0.241801 Batch F1: 0.0
Epoch:   16        9 Batch loss: 0.240685 Batch F1: 0.0
Epoch:   16       10 Batch loss: 0.207168 Batch F1: 0.0
Epoch:   16       11 Batch loss: 0.220719 Batch F1: 0.0
Epoch:   16       12 Batch loss: 0.202466 Batch F1: 0.0
Train Avg Loss   16: 0.230930

Train Avg F1   16: 0.0

Val Avg Loss   16: 0.221125

Val Avg F1   16:  0.0

Optimal Val loss (Epoch 14): 0.22071067616343498

Epoch 17
--------------------------------------------------------------
Epoch:   17        1 Batch loss: 0.239071 Batch F1: 0.0
Epoch:   17        2 Batch loss: 0.235060 Batch F1: 0.0
Epoch:   17        3 Batch loss: 0.227986 Batch F1: 0.0
Epoch:   17        4 Batch loss: 0.237109 Batch F1: 0.0
Epoch:   17        5 Batch loss: 0.228324 Batch F1: 0.0
Epoch:   17        6 Batch loss: 0.242261 Batch F1: 0.0
Epoch:   17        7 Batch loss: 0.215824 Batch F1: 0.0
Epoch:   17        8 Batch loss: 0.244664 Batch F1: 0.0
Epoch:   17        9 Batch loss: 0.216799 Batch F1: 0.0
Epoch:   17       10 Batch loss: 0.239497 Batch F1: 0.0
Epoch:   17       11 Batch loss: 0.204899 Batch F1: 0.0
Epoch:   17       12 Batch loss: 0.241801 Batch F1: 0.0
Train Avg Loss   17: 0.231108

Train Avg F1   17: 0.0

Val Avg Loss   17: 0.220397

Val Avg F1   17:  0.0

Optimal Val loss (Epoch 17): 0.22039683535695076

Epoch 18
--------------------------------------------------------------
Epoch:   18        1 Batch loss: 0.227228 Batch F1: 0.0
Epoch:   18        2 Batch loss: 0.241844 Batch F1: 0.0
Epoch:   18        3 Batch loss: 0.202735 Batch F1: 0.0
Epoch:   18        4 Batch loss: 0.246409 Batch F1: 0.0
Epoch:   18        5 Batch loss: 0.229652 Batch F1: 0.0
Epoch:   18        6 Batch loss: 0.240306 Batch F1: 0.0
Epoch:   18        7 Batch loss: 0.253987 Batch F1: 0.0
Epoch:   18        8 Batch loss: 0.228565 Batch F1: 0.31999999999999995
Epoch:   18        9 Batch loss: 0.229887 Batch F1: 0.09523809523809525
Epoch:   18       10 Batch loss: 0.230391 Batch F1: 0.0
Epoch:   18       11 Batch loss: 0.222673 Batch F1: 0.0
Epoch:   18       12 Batch loss: 0.211686 Batch F1: 0.0
Train Avg Loss   18: 0.230447

Train Avg F1   18: 0.0346031746031746

Val Avg Loss   18: 0.219623

Val Avg F1   18:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 19
--------------------------------------------------------------
Epoch:   19        1 Batch loss: 0.232152 Batch F1: 0.0
Epoch:   19        2 Batch loss: 0.226378 Batch F1: 0.0
Epoch:   19        3 Batch loss: 0.233344 Batch F1: 0.0
Epoch:   19        4 Batch loss: 0.209877 Batch F1: 0.0
Epoch:   19        5 Batch loss: 0.280059 Batch F1: 0.0
Epoch:   19        6 Batch loss: 0.239180 Batch F1: 0.0
Epoch:   19        7 Batch loss: 0.210539 Batch F1: 0.0
Epoch:   19        8 Batch loss: 0.229743 Batch F1: 0.0
Epoch:   19        9 Batch loss: 0.241021 Batch F1: 0.0
Epoch:   19       10 Batch loss: 0.221366 Batch F1: 0.0
Epoch:   19       11 Batch loss: 0.239573 Batch F1: 0.0
Epoch:   19       12 Batch loss: 0.240497 Batch F1: 0.0
Train Avg Loss   19: 0.233644

Train Avg F1   19: 0.0

Val Avg Loss   19: 0.225319

Val Avg F1   19:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 20
--------------------------------------------------------------
Epoch:   20        1 Batch loss: 0.247572 Batch F1: 0.0
Epoch:   20        2 Batch loss: 0.251271 Batch F1: 0.0
Epoch:   20        3 Batch loss: 0.234863 Batch F1: 0.0
Epoch:   20        4 Batch loss: 0.243181 Batch F1: 0.0
Epoch:   20        5 Batch loss: 0.224765 Batch F1: 0.0
Epoch:   20        6 Batch loss: 0.224523 Batch F1: 0.0
Epoch:   20        7 Batch loss: 0.229962 Batch F1: 0.0
Epoch:   20        8 Batch loss: 0.229821 Batch F1: 0.0
Epoch:   20        9 Batch loss: 0.224131 Batch F1: 0.0
Epoch:   20       10 Batch loss: 0.217568 Batch F1: 0.0
Epoch:   20       11 Batch loss: 0.244885 Batch F1: 0.0
Epoch:   20       12 Batch loss: 0.222144 Batch F1: 0.0
Train Avg Loss   20: 0.232890

Train Avg F1   20: 0.0

Val Avg Loss   20: 0.222336

Val Avg F1   20:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 21
--------------------------------------------------------------
Epoch:   21        1 Batch loss: 0.210828 Batch F1: 0.0
Epoch:   21        2 Batch loss: 0.231574 Batch F1: 0.0
Epoch:   21        3 Batch loss: 0.287134 Batch F1: 0.0
Epoch:   21        4 Batch loss: 0.251076 Batch F1: 0.0
Epoch:   21        5 Batch loss: 0.205335 Batch F1: 0.0
Epoch:   21        6 Batch loss: 0.224590 Batch F1: 0.0
Epoch:   21        7 Batch loss: 0.230572 Batch F1: 0.0
Epoch:   21        8 Batch loss: 0.252766 Batch F1: 0.0
Epoch:   21        9 Batch loss: 0.219760 Batch F1: 0.0
Epoch:   21       10 Batch loss: 0.225525 Batch F1: 0.0
Epoch:   21       11 Batch loss: 0.235323 Batch F1: 0.0
Epoch:   21       12 Batch loss: 0.224569 Batch F1: 0.0
Train Avg Loss   21: 0.233254

Train Avg F1   21: 0.0

Val Avg Loss   21: 0.223965

Val Avg F1   21:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 22
--------------------------------------------------------------
Epoch:   22        1 Batch loss: 0.225966 Batch F1: 0.0
Epoch:   22        2 Batch loss: 0.206218 Batch F1: 0.0
Epoch:   22        3 Batch loss: 0.250837 Batch F1: 0.0
Epoch:   22        4 Batch loss: 0.251085 Batch F1: 0.0
Epoch:   22        5 Batch loss: 0.240744 Batch F1: 0.0
Epoch:   22        6 Batch loss: 0.235071 Batch F1: 0.0
Epoch:   22        7 Batch loss: 0.235397 Batch F1: 0.0
Epoch:   22        8 Batch loss: 0.230490 Batch F1: 0.0
Epoch:   22        9 Batch loss: 0.211243 Batch F1: 0.0
Epoch:   22       10 Batch loss: 0.230251 Batch F1: 0.0
Epoch:   22       11 Batch loss: 0.240980 Batch F1: 0.0
Epoch:   22       12 Batch loss: 0.230318 Batch F1: 0.0
Train Avg Loss   22: 0.232383

Train Avg F1   22: 0.0

Val Avg Loss   22: 0.223331

Val Avg F1   22:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 23
--------------------------------------------------------------
Epoch:   23        1 Batch loss: 0.229750 Batch F1: 0.0
Epoch:   23        2 Batch loss: 0.219717 Batch F1: 0.0
Epoch:   23        3 Batch loss: 0.202071 Batch F1: 0.0
Epoch:   23        4 Batch loss: 0.218451 Batch F1: 0.0
Epoch:   23        5 Batch loss: 0.249023 Batch F1: 0.0
Epoch:   23        6 Batch loss: 0.230772 Batch F1: 0.0
Epoch:   23        7 Batch loss: 0.243902 Batch F1: 0.0
Epoch:   23        8 Batch loss: 0.263179 Batch F1: 0.0
Epoch:   23        9 Batch loss: 0.261982 Batch F1: 0.0
Epoch:   23       10 Batch loss: 0.201083 Batch F1: 0.0
Epoch:   23       11 Batch loss: 0.241302 Batch F1: 0.0
Epoch:   23       12 Batch loss: 0.235726 Batch F1: 0.0
Train Avg Loss   23: 0.233080

Train Avg F1   23: 0.0

Val Avg Loss   23: 0.223856

Val Avg F1   23:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 24
--------------------------------------------------------------
Epoch:   24        1 Batch loss: 0.214802 Batch F1: 0.0
Epoch:   24        2 Batch loss: 0.260462 Batch F1: 0.0
Epoch:   24        3 Batch loss: 0.217094 Batch F1: 0.0
Epoch:   24        4 Batch loss: 0.221114 Batch F1: 0.0
Epoch:   24        5 Batch loss: 0.221110 Batch F1: 0.0
Epoch:   24        6 Batch loss: 0.255251 Batch F1: 0.0
Epoch:   24        7 Batch loss: 0.220271 Batch F1: 0.0
Epoch:   24        8 Batch loss: 0.274988 Batch F1: 0.0
Epoch:   24        9 Batch loss: 0.211321 Batch F1: 0.0
Epoch:   24       10 Batch loss: 0.239069 Batch F1: 0.0
Epoch:   24       11 Batch loss: 0.207209 Batch F1: 0.0
Epoch:   24       12 Batch loss: 0.247062 Batch F1: 0.0
Train Avg Loss   24: 0.232480

Train Avg F1   24: 0.0

Val Avg Loss   24: 0.223075

Val Avg F1   24:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 25
--------------------------------------------------------------
Epoch:   25        1 Batch loss: 0.260198 Batch F1: 0.0
Epoch:   25        2 Batch loss: 0.202304 Batch F1: 0.0
Epoch:   25        3 Batch loss: 0.239138 Batch F1: 0.0
Epoch:   25        4 Batch loss: 0.215383 Batch F1: 0.0
Epoch:   25        5 Batch loss: 0.239299 Batch F1: 0.0
Epoch:   25        6 Batch loss: 0.229654 Batch F1: 0.0
Epoch:   25        7 Batch loss: 0.228822 Batch F1: 0.0
Epoch:   25        8 Batch loss: 0.250928 Batch F1: 0.0
Epoch:   25        9 Batch loss: 0.254183 Batch F1: 0.0
Epoch:   25       10 Batch loss: 0.223094 Batch F1: 0.0
Epoch:   25       11 Batch loss: 0.222222 Batch F1: 0.0
Epoch:   25       12 Batch loss: 0.213029 Batch F1: 0.0
Train Avg Loss   25: 0.231521

Train Avg F1   25: 0.0

Val Avg Loss   25: 0.222527

Val Avg F1   25:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 26
--------------------------------------------------------------
Epoch:   26        1 Batch loss: 0.226404 Batch F1: 0.0
Epoch:   26        2 Batch loss: 0.240557 Batch F1: 0.0
Epoch:   26        3 Batch loss: 0.227214 Batch F1: 0.0
Epoch:   26        4 Batch loss: 0.227426 Batch F1: 0.0
Epoch:   26        5 Batch loss: 0.239271 Batch F1: 0.0
Epoch:   26        6 Batch loss: 0.225713 Batch F1: 0.0
Epoch:   26        7 Batch loss: 0.210544 Batch F1: 0.0
Epoch:   26        8 Batch loss: 0.240595 Batch F1: 0.0
Epoch:   26        9 Batch loss: 0.244511 Batch F1: 0.0
Epoch:   26       10 Batch loss: 0.231545 Batch F1: 0.0
Epoch:   26       11 Batch loss: 0.208170 Batch F1: 0.0
Epoch:   26       12 Batch loss: 0.246419 Batch F1: 0.0
Train Avg Loss   26: 0.230697

Train Avg F1   26: 0.0

Val Avg Loss   26: 0.221064

Val Avg F1   26:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 27
--------------------------------------------------------------
Epoch:   27        1 Batch loss: 0.208308 Batch F1: 0.0
Epoch:   27        2 Batch loss: 0.286232 Batch F1: 0.0
Epoch:   27        3 Batch loss: 0.221183 Batch F1: 0.0
Epoch:   27        4 Batch loss: 0.218328 Batch F1: 0.0
Epoch:   27        5 Batch loss: 0.246503 Batch F1: 0.0
Epoch:   27        6 Batch loss: 0.226304 Batch F1: 0.0
Epoch:   27        7 Batch loss: 0.241722 Batch F1: 0.0
Epoch:   27        8 Batch loss: 0.225849 Batch F1: 0.0
Epoch:   27        9 Batch loss: 0.208977 Batch F1: 0.0
Epoch:   27       10 Batch loss: 0.211096 Batch F1: 0.0
Epoch:   27       11 Batch loss: 0.227520 Batch F1: 0.0
Epoch:   27       12 Batch loss: 0.281376 Batch F1: 0.0
Train Avg Loss   27: 0.233617

Train Avg F1   27: 0.0

Val Avg Loss   27: 0.220537

Val Avg F1   27:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 28
--------------------------------------------------------------
Epoch:   28        1 Batch loss: 0.224860 Batch F1: 0.0
Epoch:   28        2 Batch loss: 0.216777 Batch F1: 0.0
Epoch:   28        3 Batch loss: 0.225311 Batch F1: 0.0
Epoch:   28        4 Batch loss: 0.224386 Batch F1: 0.0
Epoch:   28        5 Batch loss: 0.237643 Batch F1: 0.0
Epoch:   28        6 Batch loss: 0.233158 Batch F1: 0.0
Epoch:   28        7 Batch loss: 0.240119 Batch F1: 0.0
Epoch:   28        8 Batch loss: 0.205085 Batch F1: 0.0
Epoch:   28        9 Batch loss: 0.232881 Batch F1: 0.0
Epoch:   28       10 Batch loss: 0.242115 Batch F1: 0.0
Epoch:   28       11 Batch loss: 0.244229 Batch F1: 0.0
Epoch:   28       12 Batch loss: 0.234311 Batch F1: 0.0
Train Avg Loss   28: 0.230073

Train Avg F1   28: 0.0

Val Avg Loss   28: 0.226776

Val Avg F1   28:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 29
--------------------------------------------------------------
Epoch:   29        1 Batch loss: 0.232583 Batch F1: 0.0
Epoch:   29        2 Batch loss: 0.241233 Batch F1: 0.0
Epoch:   29        3 Batch loss: 0.235408 Batch F1: 0.0
Epoch:   29        4 Batch loss: 0.238813 Batch F1: 0.0
Epoch:   29        5 Batch loss: 0.239140 Batch F1: 0.0
Epoch:   29        6 Batch loss: 0.225190 Batch F1: 0.0
Epoch:   29        7 Batch loss: 0.262117 Batch F1: 0.0
Epoch:   29        8 Batch loss: 0.201647 Batch F1: 0.0
Epoch:   29        9 Batch loss: 0.223530 Batch F1: 0.0
Epoch:   29       10 Batch loss: 0.202098 Batch F1: 0.0
Epoch:   29       11 Batch loss: 0.243263 Batch F1: 0.0
Epoch:   29       12 Batch loss: 0.217996 Batch F1: 0.0
Train Avg Loss   29: 0.230251

Train Avg F1   29: 0.0

Val Avg Loss   29: 0.220403

Val Avg F1   29:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 30
--------------------------------------------------------------
Epoch:   30        1 Batch loss: 0.197560 Batch F1: 0.0
Epoch:   30        2 Batch loss: 0.224295 Batch F1: 0.0
Epoch:   30        3 Batch loss: 0.182567 Batch F1: 0.0
Epoch:   30        4 Batch loss: 0.243757 Batch F1: 0.0
Epoch:   30        5 Batch loss: 0.181410 Batch F1: 0.0
Epoch:   30        6 Batch loss: 0.263483 Batch F1: 0.0
Epoch:   30        7 Batch loss: 0.246749 Batch F1: 0.0
Epoch:   30        8 Batch loss: 0.245580 Batch F1: 0.0
Epoch:   30        9 Batch loss: 0.248812 Batch F1: 0.411764705882353
Epoch:   30       10 Batch loss: 0.255926 Batch F1: 0.5757575757575757
Epoch:   30       11 Batch loss: 0.258390 Batch F1: 0.5423728813559321
Epoch:   30       12 Batch loss: 0.243879 Batch F1: 0.3846153846153846
Train Avg Loss   30: 0.232701

Train Avg F1   30: 0.15954254563427045

Val Avg Loss   30: 0.227037

Val Avg F1   30:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 31
--------------------------------------------------------------
Epoch:   31        1 Batch loss: 0.223257 Batch F1: 0.0
Epoch:   31        2 Batch loss: 0.228828 Batch F1: 0.0
Epoch:   31        3 Batch loss: 0.266533 Batch F1: 0.0
Epoch:   31        4 Batch loss: 0.199840 Batch F1: 0.0
Epoch:   31        5 Batch loss: 0.225562 Batch F1: 0.0
Epoch:   31        6 Batch loss: 0.245662 Batch F1: 0.0
Epoch:   31        7 Batch loss: 0.224820 Batch F1: 0.0
Epoch:   31        8 Batch loss: 0.259453 Batch F1: 0.0
Epoch:   31        9 Batch loss: 0.234308 Batch F1: 0.0
Epoch:   31       10 Batch loss: 0.244466 Batch F1: 0.0
Epoch:   31       11 Batch loss: 0.200399 Batch F1: 0.0
Epoch:   31       12 Batch loss: 0.235006 Batch F1: 0.0
Train Avg Loss   31: 0.232344

Train Avg F1   31: 0.0

Val Avg Loss   31: 0.221945

Val Avg F1   31:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 32
--------------------------------------------------------------
Epoch:   32        1 Batch loss: 0.210253 Batch F1: 0.0
Epoch:   32        2 Batch loss: 0.241196 Batch F1: 0.0
Epoch:   32        3 Batch loss: 0.256681 Batch F1: 0.0
Epoch:   32        4 Batch loss: 0.220094 Batch F1: 0.0
Epoch:   32        5 Batch loss: 0.252333 Batch F1: 0.0
Epoch:   32        6 Batch loss: 0.238217 Batch F1: 0.0
Epoch:   32        7 Batch loss: 0.223291 Batch F1: 0.0
Epoch:   32        8 Batch loss: 0.222335 Batch F1: 0.0
Epoch:   32        9 Batch loss: 0.232333 Batch F1: 0.0
Epoch:   32       10 Batch loss: 0.224046 Batch F1: 0.0
Epoch:   32       11 Batch loss: 0.210671 Batch F1: 0.0
Epoch:   32       12 Batch loss: 0.239744 Batch F1: 0.0
Train Avg Loss   32: 0.230933

Train Avg F1   32: 0.0

Val Avg Loss   32: 0.220604

Val Avg F1   32:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 33
--------------------------------------------------------------
Epoch:   33        1 Batch loss: 0.231033 Batch F1: 0.0
Epoch:   33        2 Batch loss: 0.214829 Batch F1: 0.0
Epoch:   33        3 Batch loss: 0.239603 Batch F1: 0.0
Epoch:   33        4 Batch loss: 0.206617 Batch F1: 0.0
Epoch:   33        5 Batch loss: 0.223482 Batch F1: 0.0
Epoch:   33        6 Batch loss: 0.246265 Batch F1: 0.0
Epoch:   33        7 Batch loss: 0.203073 Batch F1: 0.0
Epoch:   33        8 Batch loss: 0.243028 Batch F1: 0.0
Epoch:   33        9 Batch loss: 0.208258 Batch F1: 0.0
Epoch:   33       10 Batch loss: 0.265493 Batch F1: 0.0
Epoch:   33       11 Batch loss: 0.230409 Batch F1: 0.0
Epoch:   33       12 Batch loss: 0.255298 Batch F1: 0.0
Train Avg Loss   33: 0.230616

Train Avg F1   33: 0.0

Val Avg Loss   33: 0.223410

Val Avg F1   33:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 34
--------------------------------------------------------------
Epoch:   34        1 Batch loss: 0.210336 Batch F1: 0.0
Epoch:   34        2 Batch loss: 0.240174 Batch F1: 0.0
Epoch:   34        3 Batch loss: 0.219272 Batch F1: 0.0
Epoch:   34        4 Batch loss: 0.218311 Batch F1: 0.0
Epoch:   34        5 Batch loss: 0.245262 Batch F1: 0.0
Epoch:   34        6 Batch loss: 0.215372 Batch F1: 0.0
Epoch:   34        7 Batch loss: 0.229578 Batch F1: 0.0
Epoch:   34        8 Batch loss: 0.285341 Batch F1: 0.0
Epoch:   34        9 Batch loss: 0.231080 Batch F1: 0.0
Epoch:   34       10 Batch loss: 0.221901 Batch F1: 0.0
Epoch:   34       11 Batch loss: 0.225405 Batch F1: 0.0
Epoch:   34       12 Batch loss: 0.224609 Batch F1: 0.0
Train Avg Loss   34: 0.230553

Train Avg F1   34: 0.0

Val Avg Loss   34: 0.221847

Val Avg F1   34:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 35
--------------------------------------------------------------
Epoch:   35        1 Batch loss: 0.194364 Batch F1: 0.0
Epoch:   35        2 Batch loss: 0.234672 Batch F1: 0.0
Epoch:   35        3 Batch loss: 0.247766 Batch F1: 0.0
Epoch:   35        4 Batch loss: 0.248737 Batch F1: 0.0
Epoch:   35        5 Batch loss: 0.256364 Batch F1: 0.0
Epoch:   35        6 Batch loss: 0.209758 Batch F1: 0.0
Epoch:   35        7 Batch loss: 0.221420 Batch F1: 0.0
Epoch:   35        8 Batch loss: 0.228213 Batch F1: 0.0
Epoch:   35        9 Batch loss: 0.235050 Batch F1: 0.0
Epoch:   35       10 Batch loss: 0.252029 Batch F1: 0.0
Epoch:   35       11 Batch loss: 0.222839 Batch F1: 0.0
Epoch:   35       12 Batch loss: 0.233791 Batch F1: 0.0
Train Avg Loss   35: 0.232084

Train Avg F1   35: 0.0

Val Avg Loss   35: 0.224555

Val Avg F1   35:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 36
--------------------------------------------------------------
Epoch:   36        1 Batch loss: 0.243607 Batch F1: 0.0
Epoch:   36        2 Batch loss: 0.231985 Batch F1: 0.0
Epoch:   36        3 Batch loss: 0.235515 Batch F1: 0.0
Epoch:   36        4 Batch loss: 0.214295 Batch F1: 0.0
Epoch:   36        5 Batch loss: 0.222602 Batch F1: 0.0
Epoch:   36        6 Batch loss: 0.236526 Batch F1: 0.0
Epoch:   36        7 Batch loss: 0.221575 Batch F1: 0.0
Epoch:   36        8 Batch loss: 0.231756 Batch F1: 0.0
Epoch:   36        9 Batch loss: 0.243165 Batch F1: 0.0
Epoch:   36       10 Batch loss: 0.215597 Batch F1: 0.0
Epoch:   36       11 Batch loss: 0.241008 Batch F1: 0.0
Epoch:   36       12 Batch loss: 0.225098 Batch F1: 0.0
Train Avg Loss   36: 0.230227

Train Avg F1   36: 0.0

Val Avg Loss   36: 0.220483

Val Avg F1   36:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 37
--------------------------------------------------------------
Epoch:   37        1 Batch loss: 0.259983 Batch F1: 0.0
Epoch:   37        2 Batch loss: 0.213939 Batch F1: 0.0
Epoch:   37        3 Batch loss: 0.229226 Batch F1: 0.0
Epoch:   37        4 Batch loss: 0.233284 Batch F1: 0.0
Epoch:   37        5 Batch loss: 0.228281 Batch F1: 0.0
Epoch:   37        6 Batch loss: 0.228544 Batch F1: 0.0
Epoch:   37        7 Batch loss: 0.242332 Batch F1: 0.0
Epoch:   37        8 Batch loss: 0.202089 Batch F1: 0.0
Epoch:   37        9 Batch loss: 0.238615 Batch F1: 0.0
Epoch:   37       10 Batch loss: 0.218906 Batch F1: 0.0
Epoch:   37       11 Batch loss: 0.249541 Batch F1: 0.0
Epoch:   37       12 Batch loss: 0.227976 Batch F1: 0.0
Train Avg Loss   37: 0.231060

Train Avg F1   37: 0.0

Val Avg Loss   37: 0.221723

Val Avg F1   37:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 38
--------------------------------------------------------------
Epoch:   38        1 Batch loss: 0.214153 Batch F1: 0.0
Epoch:   38        2 Batch loss: 0.216717 Batch F1: 0.0
Epoch:   38        3 Batch loss: 0.236937 Batch F1: 0.0
Epoch:   38        4 Batch loss: 0.215898 Batch F1: 0.0
Epoch:   38        5 Batch loss: 0.226645 Batch F1: 0.0
Epoch:   38        6 Batch loss: 0.239244 Batch F1: 0.0
Epoch:   38        7 Batch loss: 0.194419 Batch F1: 0.0
Epoch:   38        8 Batch loss: 0.254588 Batch F1: 0.0
Epoch:   38        9 Batch loss: 0.277530 Batch F1: 0.0
Epoch:   38       10 Batch loss: 0.224171 Batch F1: 0.0
Epoch:   38       11 Batch loss: 0.248315 Batch F1: 0.0
Epoch:   38       12 Batch loss: 0.205188 Batch F1: 0.0
Train Avg Loss   38: 0.229484

Train Avg F1   38: 0.0

Val Avg Loss   38: 0.221426

Val Avg F1   38:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 39
--------------------------------------------------------------
Epoch:   39        1 Batch loss: 0.231407 Batch F1: 0.0
Epoch:   39        2 Batch loss: 0.238840 Batch F1: 0.0
Epoch:   39        3 Batch loss: 0.225801 Batch F1: 0.0
Epoch:   39        4 Batch loss: 0.235663 Batch F1: 0.0
Epoch:   39        5 Batch loss: 0.214489 Batch F1: 0.0
Epoch:   39        6 Batch loss: 0.227175 Batch F1: 0.0
Epoch:   39        7 Batch loss: 0.209594 Batch F1: 0.0
Epoch:   39        8 Batch loss: 0.216543 Batch F1: 0.0
Epoch:   39        9 Batch loss: 0.231123 Batch F1: 0.0
Epoch:   39       10 Batch loss: 0.283821 Batch F1: 0.0
Epoch:   39       11 Batch loss: 0.231297 Batch F1: 0.0
Epoch:   39       12 Batch loss: 0.221735 Batch F1: 0.0
Train Avg Loss   39: 0.230624

Train Avg F1   39: 0.0

Val Avg Loss   39: 0.221010

Val Avg F1   39:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 40
--------------------------------------------------------------
Epoch:   40        1 Batch loss: 0.228423 Batch F1: 0.0
Epoch:   40        2 Batch loss: 0.204381 Batch F1: 0.0
Epoch:   40        3 Batch loss: 0.205785 Batch F1: 0.0
Epoch:   40        4 Batch loss: 0.251244 Batch F1: 0.0
Epoch:   40        5 Batch loss: 0.204314 Batch F1: 0.0
Epoch:   40        6 Batch loss: 0.221500 Batch F1: 0.0
Epoch:   40        7 Batch loss: 0.270930 Batch F1: 0.0
Epoch:   40        8 Batch loss: 0.232800 Batch F1: 0.0
Epoch:   40        9 Batch loss: 0.213401 Batch F1: 0.0
Epoch:   40       10 Batch loss: 0.257797 Batch F1: 0.0
Epoch:   40       11 Batch loss: 0.245292 Batch F1: 0.0
Epoch:   40       12 Batch loss: 0.226352 Batch F1: 0.0
Train Avg Loss   40: 0.230185

Train Avg F1   40: 0.0

Val Avg Loss   40: 0.225556

Val Avg F1   40:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 41
--------------------------------------------------------------
Epoch:   41        1 Batch loss: 0.254401 Batch F1: 0.0
Epoch:   41        2 Batch loss: 0.241434 Batch F1: 0.0
Epoch:   41        3 Batch loss: 0.233443 Batch F1: 0.19047619047619044
Epoch:   41        4 Batch loss: 0.220230 Batch F1: 0.0
Epoch:   41        5 Batch loss: 0.226962 Batch F1: 0.0
Epoch:   41        6 Batch loss: 0.245529 Batch F1: 0.0
Epoch:   41        7 Batch loss: 0.206804 Batch F1: 0.0
Epoch:   41        8 Batch loss: 0.208283 Batch F1: 0.0
Epoch:   41        9 Batch loss: 0.212887 Batch F1: 0.0
Epoch:   41       10 Batch loss: 0.218550 Batch F1: 0.0
Epoch:   41       11 Batch loss: 0.261427 Batch F1: 0.0
Epoch:   41       12 Batch loss: 0.249140 Batch F1: 0.0
Train Avg Loss   41: 0.231591

Train Avg F1   41: 0.01587301587301587

Val Avg Loss   41: 0.220850

Val Avg F1   41:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 42
--------------------------------------------------------------
Epoch:   42        1 Batch loss: 0.261906 Batch F1: 0.0
Epoch:   42        2 Batch loss: 0.223942 Batch F1: 0.0
Epoch:   42        3 Batch loss: 0.256757 Batch F1: 0.0
Epoch:   42        4 Batch loss: 0.244706 Batch F1: 0.36363636363636365
Epoch:   42        5 Batch loss: 0.245655 Batch F1: 0.13793103448275862
Epoch:   42        6 Batch loss: 0.247534 Batch F1: 0.0
Epoch:   42        7 Batch loss: 0.233652 Batch F1: 0.0
Epoch:   42        8 Batch loss: 0.211834 Batch F1: 0.0
Epoch:   42        9 Batch loss: 0.208427 Batch F1: 0.0
Epoch:   42       10 Batch loss: 0.226144 Batch F1: 0.0
Epoch:   42       11 Batch loss: 0.218132 Batch F1: 0.0
Epoch:   42       12 Batch loss: 0.179357 Batch F1: 0.0
Train Avg Loss   42: 0.229837

Train Avg F1   42: 0.041797283176593515

Val Avg Loss   42: 0.220644

Val Avg F1   42:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 43
--------------------------------------------------------------
Epoch:   43        1 Batch loss: 0.179877 Batch F1: 0.0
Epoch:   43        2 Batch loss: 0.248775 Batch F1: 0.0
Epoch:   43        3 Batch loss: 0.198673 Batch F1: 0.0
Epoch:   43        4 Batch loss: 0.219911 Batch F1: 0.0
Epoch:   43        5 Batch loss: 0.241063 Batch F1: 0.0
Epoch:   43        6 Batch loss: 0.237793 Batch F1: 0.0
Epoch:   43        7 Batch loss: 0.238321 Batch F1: 0.0
Epoch:   43        8 Batch loss: 0.268903 Batch F1: 0.0
Epoch:   43        9 Batch loss: 0.243530 Batch F1: 0.19047619047619047
Epoch:   43       10 Batch loss: 0.244547 Batch F1: 0.27586206896551724
Epoch:   43       11 Batch loss: 0.244733 Batch F1: 0.0
Epoch:   43       12 Batch loss: 0.225861 Batch F1: 0.0
Train Avg Loss   43: 0.232666

Train Avg F1   43: 0.03886152162014231

Val Avg Loss   43: 0.223789

Val Avg F1   43:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 44
--------------------------------------------------------------
Epoch:   44        1 Batch loss: 0.213781 Batch F1: 0.0
Epoch:   44        2 Batch loss: 0.242014 Batch F1: 0.0
Epoch:   44        3 Batch loss: 0.224400 Batch F1: 0.0
Epoch:   44        4 Batch loss: 0.290731 Batch F1: 0.0
Epoch:   44        5 Batch loss: 0.266868 Batch F1: 0.0
Epoch:   44        6 Batch loss: 0.202838 Batch F1: 0.0
Epoch:   44        7 Batch loss: 0.237961 Batch F1: 0.0
Epoch:   44        8 Batch loss: 0.212501 Batch F1: 0.0
Epoch:   44        9 Batch loss: 0.224202 Batch F1: 0.0
Epoch:   44       10 Batch loss: 0.230838 Batch F1: 0.0
Epoch:   44       11 Batch loss: 0.231036 Batch F1: 0.0
Epoch:   44       12 Batch loss: 0.219690 Batch F1: 0.0
Train Avg Loss   44: 0.233072

Train Avg F1   44: 0.0

Val Avg Loss   44: 0.221572

Val Avg F1   44:  0.0

Optimal Val loss (Epoch 18): 0.21962305903434753

Epoch 45
--------------------------------------------------------------
Epoch:   45        1 Batch loss: 0.246458 Batch F1: 0.0
Epoch:   45        2 Batch loss: 0.240440 Batch F1: 0.0
Epoch:   45        3 Batch loss: 0.228305 Batch F1: 0.0
Epoch:   45        4 Batch loss: 0.226603 Batch F1: 0.0
Epoch:   45        5 Batch loss: 0.228481 Batch F1: 0.0
Epoch:   45        6 Batch loss: 0.248881 Batch F1: 0.0
Epoch:   45        7 Batch loss: 0.219867 Batch F1: 0.0
Epoch:   45        8 Batch loss: 0.223794 Batch F1: 0.0
Epoch:   45        9 Batch loss: 0.216823 Batch F1: 0.0
Epoch:   45       10 Batch loss: 0.238688 Batch F1: 0.0
Epoch:   45       11 Batch loss: 0.224592 Batch F1: 0.0
Epoch:   45       12 Batch loss: 0.211628 Batch F1: 0.0
Train Avg Loss   45: 0.229547

Train Avg F1   45: 0.0

Val Avg Loss   45: 0.219533

Val Avg F1   45:  0.0

Optimal Val loss (Epoch 45): 0.21953315660357475

Epoch 46
--------------------------------------------------------------
Epoch:   46        1 Batch loss: 0.225416 Batch F1: 0.0
Epoch:   46        2 Batch loss: 0.221065 Batch F1: 0.0
Epoch:   46        3 Batch loss: 0.235595 Batch F1: 0.0
Epoch:   46        4 Batch loss: 0.272321 Batch F1: 0.0
Epoch:   46        5 Batch loss: 0.208223 Batch F1: 0.0
Epoch:   46        6 Batch loss: 0.239215 Batch F1: 0.0
Epoch:   46        7 Batch loss: 0.239779 Batch F1: 0.0
Epoch:   46        8 Batch loss: 0.234695 Batch F1: 0.0
Epoch:   46        9 Batch loss: 0.212561 Batch F1: 0.0
Epoch:   46       10 Batch loss: 0.221917 Batch F1: 0.0
Epoch:   46       11 Batch loss: 0.230755 Batch F1: 0.0
Epoch:   46       12 Batch loss: 0.237890 Batch F1: 0.0
Train Avg Loss   46: 0.231619

Train Avg F1   46: 0.0

Val Avg Loss   46: 0.221013

Val Avg F1   46:  0.0

Optimal Val loss (Epoch 45): 0.21953315660357475

Epoch 47
--------------------------------------------------------------
Epoch:   47        1 Batch loss: 0.231991 Batch F1: 0.0
Epoch:   47        2 Batch loss: 0.239041 Batch F1: 0.0
Epoch:   47        3 Batch loss: 0.243501 Batch F1: 0.0
Epoch:   47        4 Batch loss: 0.240692 Batch F1: 0.0
Epoch:   47        5 Batch loss: 0.209852 Batch F1: 0.0
Epoch:   47        6 Batch loss: 0.228601 Batch F1: 0.0
Epoch:   47        7 Batch loss: 0.252580 Batch F1: 0.0
Epoch:   47        8 Batch loss: 0.212488 Batch F1: 0.0
Epoch:   47        9 Batch loss: 0.211953 Batch F1: 0.0
Epoch:   47       10 Batch loss: 0.250550 Batch F1: 0.0
Epoch:   47       11 Batch loss: 0.204275 Batch F1: 0.0
Epoch:   47       12 Batch loss: 0.239539 Batch F1: 0.0
Train Avg Loss   47: 0.230422

Train Avg F1   47: 0.0

Val Avg Loss   47: 0.220336

Val Avg F1   47:  0.0

Optimal Val loss (Epoch 45): 0.21953315660357475

Epoch 48
--------------------------------------------------------------
Epoch:   48        1 Batch loss: 0.201713 Batch F1: 0.0
Epoch:   48        2 Batch loss: 0.224735 Batch F1: 0.0
Epoch:   48        3 Batch loss: 0.206372 Batch F1: 0.0
Epoch:   48        4 Batch loss: 0.201642 Batch F1: 0.0
Epoch:   48        5 Batch loss: 0.267954 Batch F1: 0.0
Epoch:   48        6 Batch loss: 0.237304 Batch F1: 0.0
Epoch:   48        7 Batch loss: 0.254383 Batch F1: 0.0
Epoch:   48        8 Batch loss: 0.200110 Batch F1: 0.0
Epoch:   48        9 Batch loss: 0.253062 Batch F1: 0.0
Epoch:   48       10 Batch loss: 0.259785 Batch F1: 0.0
Epoch:   48       11 Batch loss: 0.209690 Batch F1: 0.0
Epoch:   48       12 Batch loss: 0.254181 Batch F1: 0.0
Train Avg Loss   48: 0.230911

Train Avg F1   48: 0.0

Val Avg Loss   48: 0.221060

Val Avg F1   48:  0.0

Optimal Val loss (Epoch 45): 0.21953315660357475

Epoch 49
--------------------------------------------------------------
Epoch:   49        1 Batch loss: 0.236105 Batch F1: 0.0
Epoch:   49        2 Batch loss: 0.221953 Batch F1: 0.0
Epoch:   49        3 Batch loss: 0.253020 Batch F1: 0.0
Epoch:   49        4 Batch loss: 0.220109 Batch F1: 0.0
Epoch:   49        5 Batch loss: 0.232828 Batch F1: 0.0
Epoch:   49        6 Batch loss: 0.233813 Batch F1: 0.0
Epoch:   49        7 Batch loss: 0.235540 Batch F1: 0.0
Epoch:   49        8 Batch loss: 0.218489 Batch F1: 0.0
Epoch:   49        9 Batch loss: 0.205496 Batch F1: 0.0
Epoch:   49       10 Batch loss: 0.238266 Batch F1: 0.0
Epoch:   49       11 Batch loss: 0.240985 Batch F1: 0.0
Epoch:   49       12 Batch loss: 0.220838 Batch F1: 0.0
Train Avg Loss   49: 0.229787

Train Avg F1   49: 0.0

Val Avg Loss   49: 0.219418

Val Avg F1   49:  0.0

Optimal Val loss (Epoch 49): 0.21941844373941422

Epoch 50
--------------------------------------------------------------
Epoch:   50        1 Batch loss: 0.260022 Batch F1: 0.0
Epoch:   50        2 Batch loss: 0.206920 Batch F1: 0.0
Epoch:   50        3 Batch loss: 0.237068 Batch F1: 0.0
Epoch:   50        4 Batch loss: 0.240318 Batch F1: 0.0
Epoch:   50        5 Batch loss: 0.211137 Batch F1: 0.0
Epoch:   50        6 Batch loss: 0.229162 Batch F1: 0.0
Epoch:   50        7 Batch loss: 0.244047 Batch F1: 0.0
Epoch:   50        8 Batch loss: 0.248216 Batch F1: 0.0
Epoch:   50        9 Batch loss: 0.231355 Batch F1: 0.0
Epoch:   50       10 Batch loss: 0.248953 Batch F1: 0.0
Epoch:   50       11 Batch loss: 0.228598 Batch F1: 0.0
Epoch:   50       12 Batch loss: 0.196099 Batch F1: 0.0
Train Avg Loss   50: 0.231824

Train Avg F1   50: 0.0

Val Avg Loss   50: 0.222909

Val Avg F1   50:  0.0

Optimal Val loss (Epoch 49): 0.21941844373941422

Epoch 51
--------------------------------------------------------------
Epoch:   51        1 Batch loss: 0.238455 Batch F1: 0.0
Epoch:   51        2 Batch loss: 0.230904 Batch F1: 0.0
Epoch:   51        3 Batch loss: 0.234665 Batch F1: 0.0
Epoch:   51        4 Batch loss: 0.229583 Batch F1: 0.0
Epoch:   51        5 Batch loss: 0.207419 Batch F1: 0.0
Epoch:   51        6 Batch loss: 0.186714 Batch F1: 0.0
Epoch:   51        7 Batch loss: 0.271533 Batch F1: 0.0
Epoch:   51        8 Batch loss: 0.243365 Batch F1: 0.0
Epoch:   51        9 Batch loss: 0.261774 Batch F1: 0.0
Epoch:   51       10 Batch loss: 0.213380 Batch F1: 0.0
Epoch:   51       11 Batch loss: 0.220056 Batch F1: 0.0
Epoch:   51       12 Batch loss: 0.212663 Batch F1: 0.0
Train Avg Loss   51: 0.229209

Train Avg F1   51: 0.0

Val Avg Loss   51: 0.220650

Val Avg F1   51:  0.0

Optimal Val loss (Epoch 49): 0.21941844373941422

Epoch 52
--------------------------------------------------------------
Epoch:   52        1 Batch loss: 0.245372 Batch F1: 0.0
Epoch:   52        2 Batch loss: 0.203995 Batch F1: 0.0
Epoch:   52        3 Batch loss: 0.234646 Batch F1: 0.0
Epoch:   52        4 Batch loss: 0.237294 Batch F1: 0.0
Epoch:   52        5 Batch loss: 0.233925 Batch F1: 0.0
Epoch:   52        6 Batch loss: 0.223749 Batch F1: 0.0
Epoch:   52        7 Batch loss: 0.227108 Batch F1: 0.0
Epoch:   52        8 Batch loss: 0.217929 Batch F1: 0.0
Epoch:   52        9 Batch loss: 0.233437 Batch F1: 0.0
Epoch:   52       10 Batch loss: 0.212657 Batch F1: 0.0
Epoch:   52       11 Batch loss: 0.236187 Batch F1: 0.0
Epoch:   52       12 Batch loss: 0.255121 Batch F1: 0.0
Train Avg Loss   52: 0.230118

Train Avg F1   52: 0.0

Val Avg Loss   52: 0.218894

Val Avg F1   52:  0.0

Optimal Val loss (Epoch 52): 0.218893650919199

Epoch 53
--------------------------------------------------------------
Epoch:   53        1 Batch loss: 0.227692 Batch F1: 0.0
Epoch:   53        2 Batch loss: 0.207678 Batch F1: 0.0
Epoch:   53        3 Batch loss: 0.264869 Batch F1: 0.0
Epoch:   53        4 Batch loss: 0.231616 Batch F1: 0.0
Epoch:   53        5 Batch loss: 0.230662 Batch F1: 0.0
Epoch:   53        6 Batch loss: 0.206013 Batch F1: 0.0
Epoch:   53        7 Batch loss: 0.246996 Batch F1: 0.0
Epoch:   53        8 Batch loss: 0.228133 Batch F1: 0.0
Epoch:   53        9 Batch loss: 0.211480 Batch F1: 0.0
Epoch:   53       10 Batch loss: 0.221176 Batch F1: 0.0
Epoch:   53       11 Batch loss: 0.227101 Batch F1: 0.0
Epoch:   53       12 Batch loss: 0.252606 Batch F1: 0.0
Train Avg Loss   53: 0.229668

Train Avg F1   53: 0.0

Val Avg Loss   53: 0.219378

Val Avg F1   53:  0.0

Optimal Val loss (Epoch 52): 0.218893650919199

Epoch 54
--------------------------------------------------------------
Epoch:   54        1 Batch loss: 0.233636 Batch F1: 0.0
Epoch:   54        2 Batch loss: 0.228583 Batch F1: 0.0
Epoch:   54        3 Batch loss: 0.183390 Batch F1: 0.0
Epoch:   54        4 Batch loss: 0.217580 Batch F1: 0.0
Epoch:   54        5 Batch loss: 0.303228 Batch F1: 0.0
Epoch:   54        6 Batch loss: 0.258460 Batch F1: 0.0
Epoch:   54        7 Batch loss: 0.225929 Batch F1: 0.0
Epoch:   54        8 Batch loss: 0.211893 Batch F1: 0.0
Epoch:   54        9 Batch loss: 0.229932 Batch F1: 0.0
Epoch:   54       10 Batch loss: 0.234800 Batch F1: 0.0
Epoch:   54       11 Batch loss: 0.227406 Batch F1: 0.0
Epoch:   54       12 Batch loss: 0.203373 Batch F1: 0.0
Train Avg Loss   54: 0.229851

Train Avg F1   54: 0.0

Val Avg Loss   54: 0.218641

Val Avg F1   54:  0.0

Optimal Val loss (Epoch 54): 0.21864120289683342

Epoch 55
--------------------------------------------------------------
Epoch:   55        1 Batch loss: 0.241734 Batch F1: 0.0
Epoch:   55        2 Batch loss: 0.229864 Batch F1: 0.0
Epoch:   55        3 Batch loss: 0.214041 Batch F1: 0.0
Epoch:   55        4 Batch loss: 0.257717 Batch F1: 0.0
Epoch:   55        5 Batch loss: 0.226251 Batch F1: 0.0
Epoch:   55        6 Batch loss: 0.251972 Batch F1: 0.0
Epoch:   55        7 Batch loss: 0.218711 Batch F1: 0.0
Epoch:   55        8 Batch loss: 0.221355 Batch F1: 0.0
Epoch:   55        9 Batch loss: 0.228476 Batch F1: 0.0
Epoch:   55       10 Batch loss: 0.229882 Batch F1: 0.0
Epoch:   55       11 Batch loss: 0.231536 Batch F1: 0.0
Epoch:   55       12 Batch loss: 0.195619 Batch F1: 0.0
Train Avg Loss   55: 0.228930

Train Avg F1   55: 0.0

Val Avg Loss   55: 0.219697

Val Avg F1   55:  0.0

Optimal Val loss (Epoch 54): 0.21864120289683342

Epoch 56
--------------------------------------------------------------
Epoch:   56        1 Batch loss: 0.240632 Batch F1: 0.0
Epoch:   56        2 Batch loss: 0.214184 Batch F1: 0.0
Epoch:   56        3 Batch loss: 0.265310 Batch F1: 0.0
Epoch:   56        4 Batch loss: 0.215985 Batch F1: 0.0
Epoch:   56        5 Batch loss: 0.236345 Batch F1: 0.0
Epoch:   56        6 Batch loss: 0.186060 Batch F1: 0.0
Epoch:   56        7 Batch loss: 0.226325 Batch F1: 0.0
Epoch:   56        8 Batch loss: 0.224295 Batch F1: 0.0
Epoch:   56        9 Batch loss: 0.218647 Batch F1: 0.0
Epoch:   56       10 Batch loss: 0.219704 Batch F1: 0.0
Epoch:   56       11 Batch loss: 0.264699 Batch F1: 0.0
Epoch:   56       12 Batch loss: 0.225864 Batch F1: 0.0
Train Avg Loss   56: 0.228171

Train Avg F1   56: 0.0

Val Avg Loss   56: 0.218274

Val Avg F1   56:  0.0

Optimal Val loss (Epoch 56): 0.21827371791005135

Epoch 57
--------------------------------------------------------------
Epoch:   57        1 Batch loss: 0.231630 Batch F1: 0.0
Epoch:   57        2 Batch loss: 0.216199 Batch F1: 0.0
Epoch:   57        3 Batch loss: 0.221271 Batch F1: 0.0
Epoch:   57        4 Batch loss: 0.234362 Batch F1: 0.0
Epoch:   57        5 Batch loss: 0.237968 Batch F1: 0.0
Epoch:   57        6 Batch loss: 0.226955 Batch F1: 0.17391304347826086
Epoch:   57        7 Batch loss: 0.216644 Batch F1: 0.0
Epoch:   57        8 Batch loss: 0.208058 Batch F1: 0.0
Epoch:   57        9 Batch loss: 0.238171 Batch F1: 0.0
Epoch:   57       10 Batch loss: 0.233832 Batch F1: 0.0
Epoch:   57       11 Batch loss: 0.263145 Batch F1: 0.0
Epoch:   57       12 Batch loss: 0.222051 Batch F1: 0.0
Train Avg Loss   57: 0.229191

Train Avg F1   57: 0.014492753623188406

Val Avg Loss   57: 0.218363

Val Avg F1   57:  0.0

Optimal Val loss (Epoch 56): 0.21827371791005135

Epoch 58
--------------------------------------------------------------
Epoch:   58        1 Batch loss: 0.256937 Batch F1: 0.0
Epoch:   58        2 Batch loss: 0.211029 Batch F1: 0.0
Epoch:   58        3 Batch loss: 0.184905 Batch F1: 0.0
Epoch:   58        4 Batch loss: 0.266720 Batch F1: 0.0
Epoch:   58        5 Batch loss: 0.225417 Batch F1: 0.0
Epoch:   58        6 Batch loss: 0.239296 Batch F1: 0.0
Epoch:   58        7 Batch loss: 0.229626 Batch F1: 0.0
Epoch:   58        8 Batch loss: 0.231222 Batch F1: 0.0
Epoch:   58        9 Batch loss: 0.213247 Batch F1: 0.0
Epoch:   58       10 Batch loss: 0.229901 Batch F1: 0.0
Epoch:   58       11 Batch loss: 0.257533 Batch F1: 0.0
Epoch:   58       12 Batch loss: 0.215250 Batch F1: 0.0
Train Avg Loss   58: 0.230090

Train Avg F1   58: 0.0

Val Avg Loss   58: 0.221847

Val Avg F1   58:  0.0

Optimal Val loss (Epoch 56): 0.21827371791005135

Epoch 59
--------------------------------------------------------------
Epoch:   59        1 Batch loss: 0.231256 Batch F1: 0.0
Epoch:   59        2 Batch loss: 0.212146 Batch F1: 0.0
Epoch:   59        3 Batch loss: 0.229466 Batch F1: 0.0
Epoch:   59        4 Batch loss: 0.236617 Batch F1: 0.0
Epoch:   59        5 Batch loss: 0.203937 Batch F1: 0.0
Epoch:   59        6 Batch loss: 0.220755 Batch F1: 0.0
Epoch:   59        7 Batch loss: 0.234367 Batch F1: 0.0
Epoch:   59        8 Batch loss: 0.248867 Batch F1: 0.0
Epoch:   59        9 Batch loss: 0.223425 Batch F1: 0.0
Epoch:   59       10 Batch loss: 0.236302 Batch F1: 0.0
Epoch:   59       11 Batch loss: 0.240676 Batch F1: 0.0
Epoch:   59       12 Batch loss: 0.240886 Batch F1: 0.0
Train Avg Loss   59: 0.229892

Train Avg F1   59: 0.0

Val Avg Loss   59: 0.220317

Val Avg F1   59:  0.0

Optimal Val loss (Epoch 56): 0.21827371791005135

Epoch 60
--------------------------------------------------------------
Epoch:   60        1 Batch loss: 0.209070 Batch F1: 0.0
Epoch:   60        2 Batch loss: 0.223404 Batch F1: 0.0
Epoch:   60        3 Batch loss: 0.243055 Batch F1: 0.0
Epoch:   60        4 Batch loss: 0.216878 Batch F1: 0.0
Epoch:   60        5 Batch loss: 0.250336 Batch F1: 0.0
Epoch:   60        6 Batch loss: 0.219685 Batch F1: 0.0
Epoch:   60        7 Batch loss: 0.219468 Batch F1: 0.0
Epoch:   60        8 Batch loss: 0.280644 Batch F1: 0.0
Epoch:   60        9 Batch loss: 0.241999 Batch F1: 0.0
Epoch:   60       10 Batch loss: 0.196384 Batch F1: 0.4761904761904762
Epoch:   60       11 Batch loss: 0.242173 Batch F1: 0.0
Epoch:   60       12 Batch loss: 0.201192 Batch F1: 0.0
Train Avg Loss   60: 0.228691

Train Avg F1   60: 0.03968253968253969

Val Avg Loss   60: 0.218824

Val Avg F1   60:  0.0

Optimal Val loss (Epoch 56): 0.21827371791005135

Epoch 61
--------------------------------------------------------------
Epoch:   61        1 Batch loss: 0.219329 Batch F1: 0.0
Epoch:   61        2 Batch loss: 0.236084 Batch F1: 0.0
Epoch:   61        3 Batch loss: 0.234778 Batch F1: 0.0
Epoch:   61        4 Batch loss: 0.193110 Batch F1: 0.0
Epoch:   61        5 Batch loss: 0.259745 Batch F1: 0.0
Epoch:   61        6 Batch loss: 0.257453 Batch F1: 0.0
Epoch:   61        7 Batch loss: 0.227459 Batch F1: 0.0
Epoch:   61        8 Batch loss: 0.217850 Batch F1: 0.0
Epoch:   61        9 Batch loss: 0.209709 Batch F1: 0.0
Epoch:   61       10 Batch loss: 0.199358 Batch F1: 0.0
Epoch:   61       11 Batch loss: 0.247893 Batch F1: 0.0
Epoch:   61       12 Batch loss: 0.266180 Batch F1: 0.0
Train Avg Loss   61: 0.230746

Train Avg F1   61: 0.0

Val Avg Loss   61: 0.220280

Val Avg F1   61:  0.0

Optimal Val loss (Epoch 56): 0.21827371791005135

Epoch 62
--------------------------------------------------------------
Epoch:   62        1 Batch loss: 0.218306 Batch F1: 0.0
Epoch:   62        2 Batch loss: 0.216083 Batch F1: 0.0
Epoch:   62        3 Batch loss: 0.225671 Batch F1: 0.0
Epoch:   62        4 Batch loss: 0.244561 Batch F1: 0.0
Epoch:   62        5 Batch loss: 0.268615 Batch F1: 0.0
Epoch:   62        6 Batch loss: 0.198236 Batch F1: 0.0
Epoch:   62        7 Batch loss: 0.239224 Batch F1: 0.0
Epoch:   62        8 Batch loss: 0.222386 Batch F1: 0.0
Epoch:   62        9 Batch loss: 0.217565 Batch F1: 0.0
Epoch:   62       10 Batch loss: 0.227140 Batch F1: 0.0
Epoch:   62       11 Batch loss: 0.237516 Batch F1: 0.0
Epoch:   62       12 Batch loss: 0.227288 Batch F1: 0.0
Train Avg Loss   62: 0.228549

Train Avg F1   62: 0.0

Val Avg Loss   62: 0.218851

Val Avg F1   62:  0.0

Optimal Val loss (Epoch 56): 0.21827371791005135

Epoch 63
--------------------------------------------------------------
Epoch:   63        1 Batch loss: 0.240314 Batch F1: 0.0
Epoch:   63        2 Batch loss: 0.241145 Batch F1: 0.0
Epoch:   63        3 Batch loss: 0.235154 Batch F1: 0.0
Epoch:   63        4 Batch loss: 0.201977 Batch F1: 0.0
Epoch:   63        5 Batch loss: 0.217541 Batch F1: 0.0
Epoch:   63        6 Batch loss: 0.240534 Batch F1: 0.0
Epoch:   63        7 Batch loss: 0.230144 Batch F1: 0.0
Epoch:   63        8 Batch loss: 0.202023 Batch F1: 0.0
Epoch:   63        9 Batch loss: 0.218013 Batch F1: 0.0
Epoch:   63       10 Batch loss: 0.213657 Batch F1: 0.0
Epoch:   63       11 Batch loss: 0.267993 Batch F1: 0.0
Epoch:   63       12 Batch loss: 0.223548 Batch F1: 0.0
Train Avg Loss   63: 0.227670

Train Avg F1   63: 0.0

Val Avg Loss   63: 0.217715

Val Avg F1   63:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 64
--------------------------------------------------------------
Epoch:   64        1 Batch loss: 0.236930 Batch F1: 0.0
Epoch:   64        2 Batch loss: 0.198742 Batch F1: 0.0
Epoch:   64        3 Batch loss: 0.202133 Batch F1: 0.0
Epoch:   64        4 Batch loss: 0.220873 Batch F1: 0.0
Epoch:   64        5 Batch loss: 0.242222 Batch F1: 0.0
Epoch:   64        6 Batch loss: 0.233268 Batch F1: 0.0
Epoch:   64        7 Batch loss: 0.238995 Batch F1: 0.0
Epoch:   64        8 Batch loss: 0.225734 Batch F1: 0.0
Epoch:   64        9 Batch loss: 0.214969 Batch F1: 0.0
Epoch:   64       10 Batch loss: 0.255209 Batch F1: 0.0
Epoch:   64       11 Batch loss: 0.258764 Batch F1: 0.0
Epoch:   64       12 Batch loss: 0.209375 Batch F1: 0.5714285714285715
Train Avg Loss   64: 0.228101

Train Avg F1   64: 0.04761904761904762

Val Avg Loss   64: 0.228439

Val Avg F1   64:  0.42629082284254693

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 65
--------------------------------------------------------------
Epoch:   65        1 Batch loss: 0.223333 Batch F1: 0.34782608695652173
Epoch:   65        2 Batch loss: 0.229475 Batch F1: 0.0
Epoch:   65        3 Batch loss: 0.239938 Batch F1: 0.0
Epoch:   65        4 Batch loss: 0.244543 Batch F1: 0.0
Epoch:   65        5 Batch loss: 0.220530 Batch F1: 0.0
Epoch:   65        6 Batch loss: 0.222290 Batch F1: 0.0
Epoch:   65        7 Batch loss: 0.244050 Batch F1: 0.0
Epoch:   65        8 Batch loss: 0.206918 Batch F1: 0.0
Epoch:   65        9 Batch loss: 0.225173 Batch F1: 0.0
Epoch:   65       10 Batch loss: 0.236683 Batch F1: 0.0
Epoch:   65       11 Batch loss: 0.214617 Batch F1: 0.0
Epoch:   65       12 Batch loss: 0.242249 Batch F1: 0.0
Train Avg Loss   65: 0.229150

Train Avg F1   65: 0.028985507246376812

Val Avg Loss   65: 0.218532

Val Avg F1   65:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 66
--------------------------------------------------------------
Epoch:   66        1 Batch loss: 0.212835 Batch F1: 0.0
Epoch:   66        2 Batch loss: 0.196959 Batch F1: 0.0
Epoch:   66        3 Batch loss: 0.211721 Batch F1: 0.0
Epoch:   66        4 Batch loss: 0.227081 Batch F1: 0.0
Epoch:   66        5 Batch loss: 0.236620 Batch F1: 0.0
Epoch:   66        6 Batch loss: 0.197984 Batch F1: 0.0
Epoch:   66        7 Batch loss: 0.230746 Batch F1: 0.0
Epoch:   66        8 Batch loss: 0.277315 Batch F1: 0.0
Epoch:   66        9 Batch loss: 0.242031 Batch F1: 0.0
Epoch:   66       10 Batch loss: 0.239030 Batch F1: 0.0
Epoch:   66       11 Batch loss: 0.236933 Batch F1: 0.0
Epoch:   66       12 Batch loss: 0.228913 Batch F1: 0.0
Train Avg Loss   66: 0.228181

Train Avg F1   66: 0.0

Val Avg Loss   66: 0.223139

Val Avg F1   66:  0.3136288998357964

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 67
--------------------------------------------------------------
Epoch:   67        1 Batch loss: 0.242849 Batch F1: 0.08333333333333333
Epoch:   67        2 Batch loss: 0.219333 Batch F1: 0.0
Epoch:   67        3 Batch loss: 0.227982 Batch F1: 0.0
Epoch:   67        4 Batch loss: 0.222375 Batch F1: 0.0
Epoch:   67        5 Batch loss: 0.220589 Batch F1: 0.0
Epoch:   67        6 Batch loss: 0.207964 Batch F1: 0.0
Epoch:   67        7 Batch loss: 0.280513 Batch F1: 0.0
Epoch:   67        8 Batch loss: 0.246897 Batch F1: 0.0
Epoch:   67        9 Batch loss: 0.229837 Batch F1: 0.0
Epoch:   67       10 Batch loss: 0.235594 Batch F1: 0.0
Epoch:   67       11 Batch loss: 0.224822 Batch F1: 0.0
Epoch:   67       12 Batch loss: 0.208290 Batch F1: 0.0
Train Avg Loss   67: 0.230587

Train Avg F1   67: 0.006944444444444444

Val Avg Loss   67: 0.222131

Val Avg F1   67:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 68
--------------------------------------------------------------
Epoch:   68        1 Batch loss: 0.215884 Batch F1: 0.0
Epoch:   68        2 Batch loss: 0.224438 Batch F1: 0.0
Epoch:   68        3 Batch loss: 0.217217 Batch F1: 0.0
Epoch:   68        4 Batch loss: 0.272661 Batch F1: 0.0
Epoch:   68        5 Batch loss: 0.228347 Batch F1: 0.0
Epoch:   68        6 Batch loss: 0.231187 Batch F1: 0.0
Epoch:   68        7 Batch loss: 0.218270 Batch F1: 0.0
Epoch:   68        8 Batch loss: 0.247106 Batch F1: 0.0
Epoch:   68        9 Batch loss: 0.231670 Batch F1: 0.0
Epoch:   68       10 Batch loss: 0.226701 Batch F1: 0.0
Epoch:   68       11 Batch loss: 0.240115 Batch F1: 0.0
Epoch:   68       12 Batch loss: 0.191105 Batch F1: 0.0
Train Avg Loss   68: 0.228725

Train Avg F1   68: 0.0

Val Avg Loss   68: 0.218594

Val Avg F1   68:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 69
--------------------------------------------------------------
Epoch:   69        1 Batch loss: 0.229171 Batch F1: 0.0
Epoch:   69        2 Batch loss: 0.236769 Batch F1: 0.0
Epoch:   69        3 Batch loss: 0.193741 Batch F1: 0.0
Epoch:   69        4 Batch loss: 0.206114 Batch F1: 0.0
Epoch:   69        5 Batch loss: 0.221426 Batch F1: 0.0
Epoch:   69        6 Batch loss: 0.228396 Batch F1: 0.0
Epoch:   69        7 Batch loss: 0.306459 Batch F1: 0.0
Epoch:   69        8 Batch loss: 0.221182 Batch F1: 0.0
Epoch:   69        9 Batch loss: 0.230532 Batch F1: 0.0
Epoch:   69       10 Batch loss: 0.228998 Batch F1: 0.0
Epoch:   69       11 Batch loss: 0.230986 Batch F1: 0.0
Epoch:   69       12 Batch loss: 0.210633 Batch F1: 0.0
Train Avg Loss   69: 0.228701

Train Avg F1   69: 0.0

Val Avg Loss   69: 0.218796

Val Avg F1   69:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 70
--------------------------------------------------------------
Epoch:   70        1 Batch loss: 0.244631 Batch F1: 0.0
Epoch:   70        2 Batch loss: 0.228299 Batch F1: 0.0
Epoch:   70        3 Batch loss: 0.213594 Batch F1: 0.0
Epoch:   70        4 Batch loss: 0.222339 Batch F1: 0.0
Epoch:   70        5 Batch loss: 0.210725 Batch F1: 0.0
Epoch:   70        6 Batch loss: 0.222080 Batch F1: 0.0
Epoch:   70        7 Batch loss: 0.218815 Batch F1: 0.0
Epoch:   70        8 Batch loss: 0.229669 Batch F1: 0.0
Epoch:   70        9 Batch loss: 0.241117 Batch F1: 0.0
Epoch:   70       10 Batch loss: 0.244390 Batch F1: 0.0
Epoch:   70       11 Batch loss: 0.243152 Batch F1: 0.0
Epoch:   70       12 Batch loss: 0.206956 Batch F1: 0.0
Train Avg Loss   70: 0.227147

Train Avg F1   70: 0.0

Val Avg Loss   70: 0.218783

Val Avg F1   70:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 71
--------------------------------------------------------------
Epoch:   71        1 Batch loss: 0.231775 Batch F1: 0.0
Epoch:   71        2 Batch loss: 0.245381 Batch F1: 0.0
Epoch:   71        3 Batch loss: 0.185985 Batch F1: 0.0
Epoch:   71        4 Batch loss: 0.248380 Batch F1: 0.0
Epoch:   71        5 Batch loss: 0.232059 Batch F1: 0.0
Epoch:   71        6 Batch loss: 0.196025 Batch F1: 0.0
Epoch:   71        7 Batch loss: 0.243245 Batch F1: 0.0
Epoch:   71        8 Batch loss: 0.226183 Batch F1: 0.0
Epoch:   71        9 Batch loss: 0.231916 Batch F1: 0.0
Epoch:   71       10 Batch loss: 0.255396 Batch F1: 0.0
Epoch:   71       11 Batch loss: 0.232556 Batch F1: 0.0
Epoch:   71       12 Batch loss: 0.197449 Batch F1: 0.0
Train Avg Loss   71: 0.227196

Train Avg F1   71: 0.0

Val Avg Loss   71: 0.219699

Val Avg F1   71:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 72
--------------------------------------------------------------
Epoch:   72        1 Batch loss: 0.233366 Batch F1: 0.0
Epoch:   72        2 Batch loss: 0.207423 Batch F1: 0.0
Epoch:   72        3 Batch loss: 0.217729 Batch F1: 0.0
Epoch:   72        4 Batch loss: 0.221120 Batch F1: 0.0
Epoch:   72        5 Batch loss: 0.232650 Batch F1: 0.0
Epoch:   72        6 Batch loss: 0.223201 Batch F1: 0.0
Epoch:   72        7 Batch loss: 0.230074 Batch F1: 0.0
Epoch:   72        8 Batch loss: 0.274785 Batch F1: 0.0
Epoch:   72        9 Batch loss: 0.219522 Batch F1: 0.0
Epoch:   72       10 Batch loss: 0.209817 Batch F1: 0.0
Epoch:   72       11 Batch loss: 0.228649 Batch F1: 0.0
Epoch:   72       12 Batch loss: 0.231204 Batch F1: 0.0
Train Avg Loss   72: 0.227462

Train Avg F1   72: 0.0

Val Avg Loss   72: 0.218290

Val Avg F1   72:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 73
--------------------------------------------------------------
Epoch:   73        1 Batch loss: 0.218348 Batch F1: 0.0
Epoch:   73        2 Batch loss: 0.286615 Batch F1: 0.0
Epoch:   73        3 Batch loss: 0.212241 Batch F1: 0.18181818181818182
Epoch:   73        4 Batch loss: 0.254607 Batch F1: 0.19354838709677416
Epoch:   73        5 Batch loss: 0.223850 Batch F1: 0.47058823529411764
Epoch:   73        6 Batch loss: 0.236587 Batch F1: 0.19047619047619047
Epoch:   73        7 Batch loss: 0.239581 Batch F1: 0.0
Epoch:   73        8 Batch loss: 0.185225 Batch F1: 0.0
Epoch:   73        9 Batch loss: 0.241988 Batch F1: 0.0
Epoch:   73       10 Batch loss: 0.207332 Batch F1: 0.0
Epoch:   73       11 Batch loss: 0.217782 Batch F1: 0.0
Epoch:   73       12 Batch loss: 0.232716 Batch F1: 0.0
Train Avg Loss   73: 0.229739

Train Avg F1   73: 0.08636924955710534

Val Avg Loss   73: 0.218384

Val Avg F1   73:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 74
--------------------------------------------------------------
Epoch:   74        1 Batch loss: 0.259315 Batch F1: 0.0
Epoch:   74        2 Batch loss: 0.248999 Batch F1: 0.0
Epoch:   74        3 Batch loss: 0.234909 Batch F1: 0.6470588235294118
Epoch:   74        4 Batch loss: 0.236174 Batch F1: 0.46153846153846156
Epoch:   74        5 Batch loss: 0.230402 Batch F1: 0.0
Epoch:   74        6 Batch loss: 0.222362 Batch F1: 0.0
Epoch:   74        7 Batch loss: 0.250112 Batch F1: 0.0
Epoch:   74        8 Batch loss: 0.252116 Batch F1: 0.0
Epoch:   74        9 Batch loss: 0.215614 Batch F1: 0.0
Epoch:   74       10 Batch loss: 0.199081 Batch F1: 0.0
Epoch:   74       11 Batch loss: 0.217004 Batch F1: 0.0
Epoch:   74       12 Batch loss: 0.204257 Batch F1: 0.0
Train Avg Loss   74: 0.230862

Train Avg F1   74: 0.09238310708898945

Val Avg Loss   74: 0.218549

Val Avg F1   74:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 75
--------------------------------------------------------------
Epoch:   75        1 Batch loss: 0.202899 Batch F1: 0.0
Epoch:   75        2 Batch loss: 0.231876 Batch F1: 0.0
Epoch:   75        3 Batch loss: 0.188959 Batch F1: 0.0
Epoch:   75        4 Batch loss: 0.324774 Batch F1: 0.0
Epoch:   75        5 Batch loss: 0.225669 Batch F1: 0.0
Epoch:   75        6 Batch loss: 0.170494 Batch F1: 0.0
Epoch:   75        7 Batch loss: 0.260997 Batch F1: 0.0
Epoch:   75        8 Batch loss: 0.272297 Batch F1: 0.0
Epoch:   75        9 Batch loss: 0.233510 Batch F1: 0.0
Epoch:   75       10 Batch loss: 0.232210 Batch F1: 0.0
Epoch:   75       11 Batch loss: 0.223255 Batch F1: 0.0
Epoch:   75       12 Batch loss: 0.232660 Batch F1: 0.0
Train Avg Loss   75: 0.233300

Train Avg F1   75: 0.0

Val Avg Loss   75: 0.228673

Val Avg F1   75:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 76
--------------------------------------------------------------
Epoch:   76        1 Batch loss: 0.230001 Batch F1: 0.0
Epoch:   76        2 Batch loss: 0.246981 Batch F1: 0.0
Epoch:   76        3 Batch loss: 0.226486 Batch F1: 0.0
Epoch:   76        4 Batch loss: 0.217109 Batch F1: 0.0
Epoch:   76        5 Batch loss: 0.237779 Batch F1: 0.0
Epoch:   76        6 Batch loss: 0.229938 Batch F1: 0.0
Epoch:   76        7 Batch loss: 0.231939 Batch F1: 0.0
Epoch:   76        8 Batch loss: 0.222699 Batch F1: 0.0
Epoch:   76        9 Batch loss: 0.226349 Batch F1: 0.0
Epoch:   76       10 Batch loss: 0.241525 Batch F1: 0.0
Epoch:   76       11 Batch loss: 0.241776 Batch F1: 0.0
Epoch:   76       12 Batch loss: 0.220412 Batch F1: 0.0
Train Avg Loss   76: 0.231083

Train Avg F1   76: 0.0

Val Avg Loss   76: 0.219581

Val Avg F1   76:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 77
--------------------------------------------------------------
Epoch:   77        1 Batch loss: 0.225931 Batch F1: 0.0
Epoch:   77        2 Batch loss: 0.260722 Batch F1: 0.0
Epoch:   77        3 Batch loss: 0.213605 Batch F1: 0.0
Epoch:   77        4 Batch loss: 0.210126 Batch F1: 0.0
Epoch:   77        5 Batch loss: 0.229107 Batch F1: 0.0
Epoch:   77        6 Batch loss: 0.250858 Batch F1: 0.0
Epoch:   77        7 Batch loss: 0.234912 Batch F1: 0.0
Epoch:   77        8 Batch loss: 0.213178 Batch F1: 0.0
Epoch:   77        9 Batch loss: 0.225399 Batch F1: 0.0
Epoch:   77       10 Batch loss: 0.203930 Batch F1: 0.0
Epoch:   77       11 Batch loss: 0.245983 Batch F1: 0.0
Epoch:   77       12 Batch loss: 0.234221 Batch F1: 0.0
Train Avg Loss   77: 0.228998

Train Avg F1   77: 0.0

Val Avg Loss   77: 0.219054

Val Avg F1   77:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 78
--------------------------------------------------------------
Epoch:   78        1 Batch loss: 0.233910 Batch F1: 0.0
Epoch:   78        2 Batch loss: 0.262171 Batch F1: 0.0
Epoch:   78        3 Batch loss: 0.232366 Batch F1: 0.0
Epoch:   78        4 Batch loss: 0.230901 Batch F1: 0.0
Epoch:   78        5 Batch loss: 0.235727 Batch F1: 0.0
Epoch:   78        6 Batch loss: 0.198372 Batch F1: 0.0
Epoch:   78        7 Batch loss: 0.228235 Batch F1: 0.0
Epoch:   78        8 Batch loss: 0.224536 Batch F1: 0.0
Epoch:   78        9 Batch loss: 0.204330 Batch F1: 0.0
Epoch:   78       10 Batch loss: 0.251083 Batch F1: 0.0
Epoch:   78       11 Batch loss: 0.210365 Batch F1: 0.0
Epoch:   78       12 Batch loss: 0.239929 Batch F1: 0.0
Train Avg Loss   78: 0.229327

Train Avg F1   78: 0.0

Val Avg Loss   78: 0.218020

Val Avg F1   78:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 79
--------------------------------------------------------------
Epoch:   79        1 Batch loss: 0.214840 Batch F1: 0.0
Epoch:   79        2 Batch loss: 0.196513 Batch F1: 0.0
Epoch:   79        3 Batch loss: 0.244361 Batch F1: 0.0
Epoch:   79        4 Batch loss: 0.244977 Batch F1: 0.0
Epoch:   79        5 Batch loss: 0.232134 Batch F1: 0.0
Epoch:   79        6 Batch loss: 0.215085 Batch F1: 0.0
Epoch:   79        7 Batch loss: 0.239475 Batch F1: 0.0
Epoch:   79        8 Batch loss: 0.238983 Batch F1: 0.0
Epoch:   79        9 Batch loss: 0.212688 Batch F1: 0.0
Epoch:   79       10 Batch loss: 0.205909 Batch F1: 0.0
Epoch:   79       11 Batch loss: 0.262209 Batch F1: 0.0
Epoch:   79       12 Batch loss: 0.227760 Batch F1: 0.0
Train Avg Loss   79: 0.227911

Train Avg F1   79: 0.0

Val Avg Loss   79: 0.221058

Val Avg F1   79:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 80
--------------------------------------------------------------
Epoch:   80        1 Batch loss: 0.242388 Batch F1: 0.0
Epoch:   80        2 Batch loss: 0.239867 Batch F1: 0.0
Epoch:   80        3 Batch loss: 0.231797 Batch F1: 0.0
Epoch:   80        4 Batch loss: 0.213388 Batch F1: 0.3478260869565218
Epoch:   80        5 Batch loss: 0.218797 Batch F1: 0.0
Epoch:   80        6 Batch loss: 0.245371 Batch F1: 0.0
Epoch:   80        7 Batch loss: 0.205512 Batch F1: 0.0
Epoch:   80        8 Batch loss: 0.215267 Batch F1: 0.0
Epoch:   80        9 Batch loss: 0.247888 Batch F1: 0.0
Epoch:   80       10 Batch loss: 0.242595 Batch F1: 0.0
Epoch:   80       11 Batch loss: 0.198154 Batch F1: 0.0
Epoch:   80       12 Batch loss: 0.233521 Batch F1: 0.0
Train Avg Loss   80: 0.227879

Train Avg F1   80: 0.028985507246376815

Val Avg Loss   80: 0.217731

Val Avg F1   80:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 81
--------------------------------------------------------------
Epoch:   81        1 Batch loss: 0.194967 Batch F1: 0.0
Epoch:   81        2 Batch loss: 0.214063 Batch F1: 0.0
Epoch:   81        3 Batch loss: 0.238459 Batch F1: 0.0
Epoch:   81        4 Batch loss: 0.235921 Batch F1: 0.0
Epoch:   81        5 Batch loss: 0.238210 Batch F1: 0.0
Epoch:   81        6 Batch loss: 0.213842 Batch F1: 0.0
Epoch:   81        7 Batch loss: 0.250005 Batch F1: 0.0
Epoch:   81        8 Batch loss: 0.272860 Batch F1: 0.0
Epoch:   81        9 Batch loss: 0.204561 Batch F1: 0.0
Epoch:   81       10 Batch loss: 0.212049 Batch F1: 0.0
Epoch:   81       11 Batch loss: 0.223792 Batch F1: 0.0
Epoch:   81       12 Batch loss: 0.237967 Batch F1: 0.0
Train Avg Loss   81: 0.228058

Train Avg F1   81: 0.0

Val Avg Loss   81: 0.220008

Val Avg F1   81:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 82
--------------------------------------------------------------
Epoch:   82        1 Batch loss: 0.224245 Batch F1: 0.0
Epoch:   82        2 Batch loss: 0.231030 Batch F1: 0.0
Epoch:   82        3 Batch loss: 0.247350 Batch F1: 0.0
Epoch:   82        4 Batch loss: 0.202888 Batch F1: 0.0
Epoch:   82        5 Batch loss: 0.227623 Batch F1: 0.23076923076923075
Epoch:   82        6 Batch loss: 0.220678 Batch F1: 0.4
Epoch:   82        7 Batch loss: 0.258986 Batch F1: 0.3888888888888889
Epoch:   82        8 Batch loss: 0.223648 Batch F1: 0.5
Epoch:   82        9 Batch loss: 0.227667 Batch F1: 0.0
Epoch:   82       10 Batch loss: 0.252440 Batch F1: 0.0
Epoch:   82       11 Batch loss: 0.220058 Batch F1: 0.0
Epoch:   82       12 Batch loss: 0.186248 Batch F1: 0.0
Train Avg Loss   82: 0.226905

Train Avg F1   82: 0.12663817663817664

Val Avg Loss   82: 0.219255

Val Avg F1   82:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 83
--------------------------------------------------------------
Epoch:   83        1 Batch loss: 0.186699 Batch F1: 0.0
Epoch:   83        2 Batch loss: 0.242885 Batch F1: 0.0
Epoch:   83        3 Batch loss: 0.226736 Batch F1: 0.0
Epoch:   83        4 Batch loss: 0.285565 Batch F1: 0.0
Epoch:   83        5 Batch loss: 0.245549 Batch F1: 0.0
Epoch:   83        6 Batch loss: 0.208105 Batch F1: 0.0
Epoch:   83        7 Batch loss: 0.267112 Batch F1: 0.0
Epoch:   83        8 Batch loss: 0.218449 Batch F1: 0.0
Epoch:   83        9 Batch loss: 0.236925 Batch F1: 0.0
Epoch:   83       10 Batch loss: 0.233300 Batch F1: 0.0
Epoch:   83       11 Batch loss: 0.231815 Batch F1: 0.0
Epoch:   83       12 Batch loss: 0.205737 Batch F1: 0.0
Train Avg Loss   83: 0.232406

Train Avg F1   83: 0.0

Val Avg Loss   83: 0.221395

Val Avg F1   83:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 84
--------------------------------------------------------------
Epoch:   84        1 Batch loss: 0.243433 Batch F1: 0.0
Epoch:   84        2 Batch loss: 0.215041 Batch F1: 0.0
Epoch:   84        3 Batch loss: 0.227393 Batch F1: 0.0
Epoch:   84        4 Batch loss: 0.203925 Batch F1: 0.0
Epoch:   84        5 Batch loss: 0.207595 Batch F1: 0.0
Epoch:   84        6 Batch loss: 0.251826 Batch F1: 0.0
Epoch:   84        7 Batch loss: 0.258730 Batch F1: 0.0
Epoch:   84        8 Batch loss: 0.210904 Batch F1: 0.0
Epoch:   84        9 Batch loss: 0.224980 Batch F1: 0.0
Epoch:   84       10 Batch loss: 0.243018 Batch F1: 0.0
Epoch:   84       11 Batch loss: 0.250425 Batch F1: 0.0
Epoch:   84       12 Batch loss: 0.203818 Batch F1: 0.0
Train Avg Loss   84: 0.228424

Train Avg F1   84: 0.0

Val Avg Loss   84: 0.221279

Val Avg F1   84:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 85
--------------------------------------------------------------
Epoch:   85        1 Batch loss: 0.259135 Batch F1: 0.0
Epoch:   85        2 Batch loss: 0.225288 Batch F1: 0.0
Epoch:   85        3 Batch loss: 0.201827 Batch F1: 0.0
Epoch:   85        4 Batch loss: 0.248610 Batch F1: 0.0
Epoch:   85        5 Batch loss: 0.204202 Batch F1: 0.0
Epoch:   85        6 Batch loss: 0.241683 Batch F1: 0.0
Epoch:   85        7 Batch loss: 0.215347 Batch F1: 0.0
Epoch:   85        8 Batch loss: 0.243221 Batch F1: 0.0
Epoch:   85        9 Batch loss: 0.244209 Batch F1: 0.0
Epoch:   85       10 Batch loss: 0.219927 Batch F1: 0.0
Epoch:   85       11 Batch loss: 0.223756 Batch F1: 0.0
Epoch:   85       12 Batch loss: 0.217174 Batch F1: 0.0
Train Avg Loss   85: 0.228698

Train Avg F1   85: 0.0

Val Avg Loss   85: 0.218908

Val Avg F1   85:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 86
--------------------------------------------------------------
Epoch:   86        1 Batch loss: 0.213831 Batch F1: 0.0
Epoch:   86        2 Batch loss: 0.234441 Batch F1: 0.0
Epoch:   86        3 Batch loss: 0.227146 Batch F1: 0.0
Epoch:   86        4 Batch loss: 0.250020 Batch F1: 0.0
Epoch:   86        5 Batch loss: 0.214257 Batch F1: 0.0
Epoch:   86        6 Batch loss: 0.250407 Batch F1: 0.0
Epoch:   86        7 Batch loss: 0.228900 Batch F1: 0.0
Epoch:   86        8 Batch loss: 0.201719 Batch F1: 0.0
Epoch:   86        9 Batch loss: 0.229352 Batch F1: 0.0
Epoch:   86       10 Batch loss: 0.215637 Batch F1: 0.0
Epoch:   86       11 Batch loss: 0.235148 Batch F1: 0.0
Epoch:   86       12 Batch loss: 0.232369 Batch F1: 0.0
Train Avg Loss   86: 0.227769

Train Avg F1   86: 0.0

Val Avg Loss   86: 0.218091

Val Avg F1   86:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 87
--------------------------------------------------------------
Epoch:   87        1 Batch loss: 0.239025 Batch F1: 0.0
Epoch:   87        2 Batch loss: 0.220821 Batch F1: 0.0
Epoch:   87        3 Batch loss: 0.207311 Batch F1: 0.0
Epoch:   87        4 Batch loss: 0.252161 Batch F1: 0.0
Epoch:   87        5 Batch loss: 0.206667 Batch F1: 0.0
Epoch:   87        6 Batch loss: 0.251160 Batch F1: 0.0
Epoch:   87        7 Batch loss: 0.220645 Batch F1: 0.0
Epoch:   87        8 Batch loss: 0.222463 Batch F1: 0.0
Epoch:   87        9 Batch loss: 0.250979 Batch F1: 0.0
Epoch:   87       10 Batch loss: 0.205079 Batch F1: 0.0
Epoch:   87       11 Batch loss: 0.216545 Batch F1: 0.0
Epoch:   87       12 Batch loss: 0.228323 Batch F1: 0.0
Train Avg Loss   87: 0.226765

Train Avg F1   87: 0.0

Val Avg Loss   87: 0.218374

Val Avg F1   87:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 88
--------------------------------------------------------------
Epoch:   88        1 Batch loss: 0.219595 Batch F1: 0.0
Epoch:   88        2 Batch loss: 0.217408 Batch F1: 0.0
Epoch:   88        3 Batch loss: 0.212812 Batch F1: 0.0
Epoch:   88        4 Batch loss: 0.230955 Batch F1: 0.0
Epoch:   88        5 Batch loss: 0.201585 Batch F1: 0.0
Epoch:   88        6 Batch loss: 0.256857 Batch F1: 0.0
Epoch:   88        7 Batch loss: 0.192719 Batch F1: 0.0
Epoch:   88        8 Batch loss: 0.252185 Batch F1: 0.0
Epoch:   88        9 Batch loss: 0.226490 Batch F1: 0.0
Epoch:   88       10 Batch loss: 0.243300 Batch F1: 0.0
Epoch:   88       11 Batch loss: 0.248531 Batch F1: 0.0
Epoch:   88       12 Batch loss: 0.229107 Batch F1: 0.0
Train Avg Loss   88: 0.227629

Train Avg F1   88: 0.0

Val Avg Loss   88: 0.221092

Val Avg F1   88:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 89
--------------------------------------------------------------
Epoch:   89        1 Batch loss: 0.223564 Batch F1: 0.0
Epoch:   89        2 Batch loss: 0.208508 Batch F1: 0.0
Epoch:   89        3 Batch loss: 0.240050 Batch F1: 0.0
Epoch:   89        4 Batch loss: 0.248461 Batch F1: 0.0
Epoch:   89        5 Batch loss: 0.223845 Batch F1: 0.0
Epoch:   89        6 Batch loss: 0.229330 Batch F1: 0.0
Epoch:   89        7 Batch loss: 0.231316 Batch F1: 0.0
Epoch:   89        8 Batch loss: 0.217536 Batch F1: 0.0
Epoch:   89        9 Batch loss: 0.228233 Batch F1: 0.0
Epoch:   89       10 Batch loss: 0.240729 Batch F1: 0.0
Epoch:   89       11 Batch loss: 0.203038 Batch F1: 0.0
Epoch:   89       12 Batch loss: 0.229465 Batch F1: 0.0
Train Avg Loss   89: 0.227006

Train Avg F1   89: 0.0

Val Avg Loss   89: 0.217816

Val Avg F1   89:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 90
--------------------------------------------------------------
Epoch:   90        1 Batch loss: 0.240600 Batch F1: 0.0
Epoch:   90        2 Batch loss: 0.252696 Batch F1: 0.0
Epoch:   90        3 Batch loss: 0.224734 Batch F1: 0.3333333333333333
Epoch:   90        4 Batch loss: 0.224200 Batch F1: 0.3333333333333333
Epoch:   90        5 Batch loss: 0.208580 Batch F1: 0.33333333333333337
Epoch:   90        6 Batch loss: 0.211917 Batch F1: 0.0
Epoch:   90        7 Batch loss: 0.231585 Batch F1: 0.0
Epoch:   90        8 Batch loss: 0.216228 Batch F1: 0.0
Epoch:   90        9 Batch loss: 0.230157 Batch F1: 0.0
Epoch:   90       10 Batch loss: 0.228596 Batch F1: 0.0
Epoch:   90       11 Batch loss: 0.228548 Batch F1: 0.0
Epoch:   90       12 Batch loss: 0.252145 Batch F1: 0.0
Train Avg Loss   90: 0.229166

Train Avg F1   90: 0.08333333333333333

Val Avg Loss   90: 0.218979

Val Avg F1   90:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 91
--------------------------------------------------------------
Epoch:   91        1 Batch loss: 0.233605 Batch F1: 0.0
Epoch:   91        2 Batch loss: 0.227728 Batch F1: 0.5517241379310345
Epoch:   91        3 Batch loss: 0.233017 Batch F1: 0.16000000000000003
Epoch:   91        4 Batch loss: 0.234117 Batch F1: 0.16666666666666669
Epoch:   91        5 Batch loss: 0.243240 Batch F1: 0.15384615384615385
Epoch:   91        6 Batch loss: 0.227712 Batch F1: 0.08695652173913043
Epoch:   91        7 Batch loss: 0.219956 Batch F1: 0.0
Epoch:   91        8 Batch loss: 0.245798 Batch F1: 0.0
Epoch:   91        9 Batch loss: 0.224755 Batch F1: 0.0
Epoch:   91       10 Batch loss: 0.226745 Batch F1: 0.0
Epoch:   91       11 Batch loss: 0.199799 Batch F1: 0.0
Epoch:   91       12 Batch loss: 0.203805 Batch F1: 0.0
Train Avg Loss   91: 0.226690

Train Avg F1   91: 0.09326612334858213

Val Avg Loss   91: 0.219870

Val Avg F1   91:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 92
--------------------------------------------------------------
Epoch:   92        1 Batch loss: 0.240164 Batch F1: 0.0
Epoch:   92        2 Batch loss: 0.252725 Batch F1: 0.0
Epoch:   92        3 Batch loss: 0.230387 Batch F1: 0.0
Epoch:   92        4 Batch loss: 0.231749 Batch F1: 0.0
Epoch:   92        5 Batch loss: 0.206336 Batch F1: 0.0
Epoch:   92        6 Batch loss: 0.230662 Batch F1: 0.0
Epoch:   92        7 Batch loss: 0.226854 Batch F1: 0.0
Epoch:   92        8 Batch loss: 0.215180 Batch F1: 0.0
Epoch:   92        9 Batch loss: 0.241193 Batch F1: 0.0
Epoch:   92       10 Batch loss: 0.204002 Batch F1: 0.0
Epoch:   92       11 Batch loss: 0.241251 Batch F1: 0.0
Epoch:   92       12 Batch loss: 0.231606 Batch F1: 0.0
Train Avg Loss   92: 0.229342

Train Avg F1   92: 0.0

Val Avg Loss   92: 0.218002

Val Avg F1   92:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 93
--------------------------------------------------------------
Epoch:   93        1 Batch loss: 0.192203 Batch F1: 0.0
Epoch:   93        2 Batch loss: 0.195835 Batch F1: 0.0
Epoch:   93        3 Batch loss: 0.190696 Batch F1: 0.0
Epoch:   93        4 Batch loss: 0.248226 Batch F1: 0.0
Epoch:   93        5 Batch loss: 0.275051 Batch F1: 0.0
Epoch:   93        6 Batch loss: 0.238845 Batch F1: 0.0
Epoch:   93        7 Batch loss: 0.231067 Batch F1: 0.0
Epoch:   93        8 Batch loss: 0.215803 Batch F1: 0.0
Epoch:   93        9 Batch loss: 0.219324 Batch F1: 0.0
Epoch:   93       10 Batch loss: 0.255046 Batch F1: 0.0
Epoch:   93       11 Batch loss: 0.229395 Batch F1: 0.0
Epoch:   93       12 Batch loss: 0.246492 Batch F1: 0.0
Train Avg Loss   93: 0.228165

Train Avg F1   93: 0.0

Val Avg Loss   93: 0.219371

Val Avg F1   93:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 94
--------------------------------------------------------------
Epoch:   94        1 Batch loss: 0.219173 Batch F1: 0.0
Epoch:   94        2 Batch loss: 0.172616 Batch F1: 0.0
Epoch:   94        3 Batch loss: 0.201193 Batch F1: 0.0
Epoch:   94        4 Batch loss: 0.263683 Batch F1: 0.0
Epoch:   94        5 Batch loss: 0.236713 Batch F1: 0.0
Epoch:   94        6 Batch loss: 0.247538 Batch F1: 0.0
Epoch:   94        7 Batch loss: 0.228491 Batch F1: 0.0
Epoch:   94        8 Batch loss: 0.238766 Batch F1: 0.0
Epoch:   94        9 Batch loss: 0.222765 Batch F1: 0.0
Epoch:   94       10 Batch loss: 0.250659 Batch F1: 0.0
Epoch:   94       11 Batch loss: 0.201867 Batch F1: 0.0
Epoch:   94       12 Batch loss: 0.269224 Batch F1: 0.0
Train Avg Loss   94: 0.229391

Train Avg F1   94: 0.0

Val Avg Loss   94: 0.221628

Val Avg F1   94:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 95
--------------------------------------------------------------
Epoch:   95        1 Batch loss: 0.225149 Batch F1: 0.0
Epoch:   95        2 Batch loss: 0.249632 Batch F1: 0.0
Epoch:   95        3 Batch loss: 0.234455 Batch F1: 0.0
Epoch:   95        4 Batch loss: 0.206685 Batch F1: 0.0
Epoch:   95        5 Batch loss: 0.242176 Batch F1: 0.0
Epoch:   95        6 Batch loss: 0.208976 Batch F1: 0.0
Epoch:   95        7 Batch loss: 0.224437 Batch F1: 0.0
Epoch:   95        8 Batch loss: 0.223405 Batch F1: 0.0
Epoch:   95        9 Batch loss: 0.244675 Batch F1: 0.0
Epoch:   95       10 Batch loss: 0.220005 Batch F1: 0.0
Epoch:   95       11 Batch loss: 0.258384 Batch F1: 0.0
Epoch:   95       12 Batch loss: 0.195115 Batch F1: 0.0
Train Avg Loss   95: 0.227758

Train Avg F1   95: 0.0

Val Avg Loss   95: 0.217747

Val Avg F1   95:  0.0

Optimal Val loss (Epoch 63): 0.21771468967199326

Epoch 96
--------------------------------------------------------------
Epoch:   96        1 Batch loss: 0.214096 Batch F1: 0.0
Epoch:   96        2 Batch loss: 0.262900 Batch F1: 0.0
Epoch:   96        3 Batch loss: 0.231837 Batch F1: 0.0
Epoch:   96        4 Batch loss: 0.238269 Batch F1: 0.0
Epoch:   96        5 Batch loss: 0.226318 Batch F1: 0.0
Epoch:   96        6 Batch loss: 0.224862 Batch F1: 0.0
Epoch:   96        7 Batch loss: 0.233739 Batch F1: 0.0
Epoch:   96        8 Batch loss: 0.214892 Batch F1: 0.0
Epoch:   96        9 Batch loss: 0.238345 Batch F1: 0.0
Epoch:   96       10 Batch loss: 0.237847 Batch F1: 0.0
Epoch:   96       11 Batch loss: 0.207768 Batch F1: 0.0
Epoch:   96       12 Batch loss: 0.193227 Batch F1: 0.0
Train Avg Loss   96: 0.227008

Train Avg F1   96: 0.0

Val Avg Loss   96: 0.216637

Val Avg F1   96:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 97
--------------------------------------------------------------
Epoch:   97        1 Batch loss: 0.249128 Batch F1: 0.0
Epoch:   97        2 Batch loss: 0.224756 Batch F1: 0.0
Epoch:   97        3 Batch loss: 0.243931 Batch F1: 0.0
Epoch:   97        4 Batch loss: 0.194385 Batch F1: 0.0
Epoch:   97        5 Batch loss: 0.229291 Batch F1: 0.0
Epoch:   97        6 Batch loss: 0.182970 Batch F1: 0.0
Epoch:   97        7 Batch loss: 0.218578 Batch F1: 0.0
Epoch:   97        8 Batch loss: 0.200890 Batch F1: 0.0
Epoch:   97        9 Batch loss: 0.247480 Batch F1: 0.0
Epoch:   97       10 Batch loss: 0.235501 Batch F1: 0.0
Epoch:   97       11 Batch loss: 0.205580 Batch F1: 0.0
Epoch:   97       12 Batch loss: 0.291081 Batch F1: 0.0
Train Avg Loss   97: 0.226964

Train Avg F1   97: 0.0

Val Avg Loss   97: 0.220300

Val Avg F1   97:  0.30667249417249415

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 98
--------------------------------------------------------------
Epoch:   98        1 Batch loss: 0.223863 Batch F1: 0.11111111111111112
Epoch:   98        2 Batch loss: 0.222690 Batch F1: 0.0
Epoch:   98        3 Batch loss: 0.196297 Batch F1: 0.125
Epoch:   98        4 Batch loss: 0.222881 Batch F1: 0.0
Epoch:   98        5 Batch loss: 0.208183 Batch F1: 0.0
Epoch:   98        6 Batch loss: 0.213327 Batch F1: 0.0
Epoch:   98        7 Batch loss: 0.249859 Batch F1: 0.0
Epoch:   98        8 Batch loss: 0.263082 Batch F1: 0.0
Epoch:   98        9 Batch loss: 0.239668 Batch F1: 0.0
Epoch:   98       10 Batch loss: 0.236323 Batch F1: 0.0
Epoch:   98       11 Batch loss: 0.215907 Batch F1: 0.0
Epoch:   98       12 Batch loss: 0.257268 Batch F1: 0.1818181818181818
Train Avg Loss   98: 0.229112

Train Avg F1   98: 0.034827441077441075

Val Avg Loss   98: 0.228071

Val Avg F1   98:  0.371985048199882

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 99
--------------------------------------------------------------
Epoch:   99        1 Batch loss: 0.229686 Batch F1: 0.15384615384615385
Epoch:   99        2 Batch loss: 0.238038 Batch F1: 0.16666666666666666
Epoch:   99        3 Batch loss: 0.235630 Batch F1: 0.31999999999999995
Epoch:   99        4 Batch loss: 0.225727 Batch F1: 0.0
Epoch:   99        5 Batch loss: 0.211443 Batch F1: 0.0
Epoch:   99        6 Batch loss: 0.205078 Batch F1: 0.0
Epoch:   99        7 Batch loss: 0.221788 Batch F1: 0.0
Epoch:   99        8 Batch loss: 0.252819 Batch F1: 0.0
Epoch:   99        9 Batch loss: 0.239476 Batch F1: 0.0
Epoch:   99       10 Batch loss: 0.231257 Batch F1: 0.0
Epoch:   99       11 Batch loss: 0.237117 Batch F1: 0.0
Epoch:   99       12 Batch loss: 0.224561 Batch F1: 0.0
Train Avg Loss   99: 0.229385

Train Avg F1   99: 0.05337606837606837

Val Avg Loss   99: 0.223409

Val Avg F1   99:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 100
--------------------------------------------------------------
Epoch:  100        1 Batch loss: 0.218331 Batch F1: 0.0
Epoch:  100        2 Batch loss: 0.228243 Batch F1: 0.0
Epoch:  100        3 Batch loss: 0.213206 Batch F1: 0.0
Epoch:  100        4 Batch loss: 0.262376 Batch F1: 0.0
Epoch:  100        5 Batch loss: 0.200664 Batch F1: 0.0
Epoch:  100        6 Batch loss: 0.225285 Batch F1: 0.0
Epoch:  100        7 Batch loss: 0.206883 Batch F1: 0.0
Epoch:  100        8 Batch loss: 0.277761 Batch F1: 0.0
Epoch:  100        9 Batch loss: 0.254979 Batch F1: 0.0
Epoch:  100       10 Batch loss: 0.227064 Batch F1: 0.0
Epoch:  100       11 Batch loss: 0.241178 Batch F1: 0.0
Epoch:  100       12 Batch loss: 0.205510 Batch F1: 0.0
Train Avg Loss  100: 0.230123

Train Avg F1  100: 0.0

Val Avg Loss  100: 0.220635

Val Avg F1  100:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 101
--------------------------------------------------------------
Epoch:  101        1 Batch loss: 0.222016 Batch F1: 0.0
Epoch:  101        2 Batch loss: 0.214091 Batch F1: 0.0
Epoch:  101        3 Batch loss: 0.241978 Batch F1: 0.0
Epoch:  101        4 Batch loss: 0.230012 Batch F1: 0.0
Epoch:  101        5 Batch loss: 0.236507 Batch F1: 0.0
Epoch:  101        6 Batch loss: 0.227320 Batch F1: 0.0
Epoch:  101        7 Batch loss: 0.216136 Batch F1: 0.0
Epoch:  101        8 Batch loss: 0.236182 Batch F1: 0.0
Epoch:  101        9 Batch loss: 0.258204 Batch F1: 0.0
Epoch:  101       10 Batch loss: 0.199848 Batch F1: 0.0
Epoch:  101       11 Batch loss: 0.235000 Batch F1: 0.0
Epoch:  101       12 Batch loss: 0.231915 Batch F1: 0.0
Train Avg Loss  101: 0.229101

Train Avg F1  101: 0.0

Val Avg Loss  101: 0.219615

Val Avg F1  101:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 102
--------------------------------------------------------------
Epoch:  102        1 Batch loss: 0.217454 Batch F1: 0.0
Epoch:  102        2 Batch loss: 0.224181 Batch F1: 0.0
Epoch:  102        3 Batch loss: 0.242292 Batch F1: 0.0
Epoch:  102        4 Batch loss: 0.237055 Batch F1: 0.0
Epoch:  102        5 Batch loss: 0.236016 Batch F1: 0.0
Epoch:  102        6 Batch loss: 0.217652 Batch F1: 0.3
Epoch:  102        7 Batch loss: 0.220382 Batch F1: 0.2
Epoch:  102        8 Batch loss: 0.249241 Batch F1: 0.0
Epoch:  102        9 Batch loss: 0.226515 Batch F1: 0.0
Epoch:  102       10 Batch loss: 0.210443 Batch F1: 0.0
Epoch:  102       11 Batch loss: 0.214530 Batch F1: 0.0
Epoch:  102       12 Batch loss: 0.240404 Batch F1: 0.0
Train Avg Loss  102: 0.228014

Train Avg F1  102: 0.041666666666666664

Val Avg Loss  102: 0.217132

Val Avg F1  102:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 103
--------------------------------------------------------------
Epoch:  103        1 Batch loss: 0.214293 Batch F1: 0.0
Epoch:  103        2 Batch loss: 0.216186 Batch F1: 0.0
Epoch:  103        3 Batch loss: 0.229887 Batch F1: 0.0
Epoch:  103        4 Batch loss: 0.241333 Batch F1: 0.0
Epoch:  103        5 Batch loss: 0.255279 Batch F1: 0.0
Epoch:  103        6 Batch loss: 0.224137 Batch F1: 0.0
Epoch:  103        7 Batch loss: 0.215460 Batch F1: 0.0
Epoch:  103        8 Batch loss: 0.231804 Batch F1: 0.0
Epoch:  103        9 Batch loss: 0.220330 Batch F1: 0.0
Epoch:  103       10 Batch loss: 0.223949 Batch F1: 0.0
Epoch:  103       11 Batch loss: 0.219514 Batch F1: 0.0
Epoch:  103       12 Batch loss: 0.232031 Batch F1: 0.0
Train Avg Loss  103: 0.227017

Train Avg F1  103: 0.0

Val Avg Loss  103: 0.218739

Val Avg F1  103:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 104
--------------------------------------------------------------
Epoch:  104        1 Batch loss: 0.229023 Batch F1: 0.0
Epoch:  104        2 Batch loss: 0.197662 Batch F1: 0.0
Epoch:  104        3 Batch loss: 0.229859 Batch F1: 0.0
Epoch:  104        4 Batch loss: 0.227066 Batch F1: 0.0
Epoch:  104        5 Batch loss: 0.223856 Batch F1: 0.0
Epoch:  104        6 Batch loss: 0.221302 Batch F1: 0.0
Epoch:  104        7 Batch loss: 0.240952 Batch F1: 0.0
Epoch:  104        8 Batch loss: 0.239173 Batch F1: 0.0
Epoch:  104        9 Batch loss: 0.248876 Batch F1: 0.0
Epoch:  104       10 Batch loss: 0.232473 Batch F1: 0.0
Epoch:  104       11 Batch loss: 0.208722 Batch F1: 0.0
Epoch:  104       12 Batch loss: 0.216879 Batch F1: 0.0
Train Avg Loss  104: 0.226320

Train Avg F1  104: 0.0

Val Avg Loss  104: 0.216714

Val Avg F1  104:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 105
--------------------------------------------------------------
Epoch:  105        1 Batch loss: 0.237765 Batch F1: 0.0
Epoch:  105        2 Batch loss: 0.206361 Batch F1: 0.0
Epoch:  105        3 Batch loss: 0.235423 Batch F1: 0.0
Epoch:  105        4 Batch loss: 0.249098 Batch F1: 0.0
Epoch:  105        5 Batch loss: 0.165078 Batch F1: 0.0
Epoch:  105        6 Batch loss: 0.221149 Batch F1: 0.0
Epoch:  105        7 Batch loss: 0.242289 Batch F1: 0.0
Epoch:  105        8 Batch loss: 0.267306 Batch F1: 0.0
Epoch:  105        9 Batch loss: 0.206764 Batch F1: 0.0
Epoch:  105       10 Batch loss: 0.237220 Batch F1: 0.0
Epoch:  105       11 Batch loss: 0.235170 Batch F1: 0.20689655172413793
Epoch:  105       12 Batch loss: 0.218363 Batch F1: 0.34782608695652173
Train Avg Loss  105: 0.226832

Train Avg F1  105: 0.046226886556721636

Val Avg Loss  105: 0.220062

Val Avg F1  105:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 106
--------------------------------------------------------------
Epoch:  106        1 Batch loss: 0.238495 Batch F1: 0.0
Epoch:  106        2 Batch loss: 0.208237 Batch F1: 0.0
Epoch:  106        3 Batch loss: 0.217595 Batch F1: 0.0
Epoch:  106        4 Batch loss: 0.229149 Batch F1: 0.0
Epoch:  106        5 Batch loss: 0.221608 Batch F1: 0.0
Epoch:  106        6 Batch loss: 0.275458 Batch F1: 0.0
Epoch:  106        7 Batch loss: 0.210033 Batch F1: 0.0
Epoch:  106        8 Batch loss: 0.247654 Batch F1: 0.0
Epoch:  106        9 Batch loss: 0.212821 Batch F1: 0.0
Epoch:  106       10 Batch loss: 0.217070 Batch F1: 0.0
Epoch:  106       11 Batch loss: 0.228231 Batch F1: 0.0
Epoch:  106       12 Batch loss: 0.228990 Batch F1: 0.0
Train Avg Loss  106: 0.227945

Train Avg F1  106: 0.0

Val Avg Loss  106: 0.218732

Val Avg F1  106:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 107
--------------------------------------------------------------
Epoch:  107        1 Batch loss: 0.207156 Batch F1: 0.0
Epoch:  107        2 Batch loss: 0.269635 Batch F1: 0.0
Epoch:  107        3 Batch loss: 0.214387 Batch F1: 0.0
Epoch:  107        4 Batch loss: 0.238042 Batch F1: 0.0
Epoch:  107        5 Batch loss: 0.217086 Batch F1: 0.0
Epoch:  107        6 Batch loss: 0.226442 Batch F1: 0.0
Epoch:  107        7 Batch loss: 0.227859 Batch F1: 0.0
Epoch:  107        8 Batch loss: 0.229749 Batch F1: 0.0
Epoch:  107        9 Batch loss: 0.244290 Batch F1: 0.0
Epoch:  107       10 Batch loss: 0.205169 Batch F1: 0.0
Epoch:  107       11 Batch loss: 0.220914 Batch F1: 0.0
Epoch:  107       12 Batch loss: 0.214866 Batch F1: 0.0
Train Avg Loss  107: 0.226300

Train Avg F1  107: 0.0

Val Avg Loss  107: 0.217271

Val Avg F1  107:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 108
--------------------------------------------------------------
Epoch:  108        1 Batch loss: 0.254121 Batch F1: 0.0
Epoch:  108        2 Batch loss: 0.206780 Batch F1: 0.0
Epoch:  108        3 Batch loss: 0.238645 Batch F1: 0.0
Epoch:  108        4 Batch loss: 0.208433 Batch F1: 0.0
Epoch:  108        5 Batch loss: 0.232830 Batch F1: 0.0
Epoch:  108        6 Batch loss: 0.245360 Batch F1: 0.0
Epoch:  108        7 Batch loss: 0.231192 Batch F1: 0.16666666666666666
Epoch:  108        8 Batch loss: 0.221653 Batch F1: 0.0
Epoch:  108        9 Batch loss: 0.212207 Batch F1: 0.0
Epoch:  108       10 Batch loss: 0.224522 Batch F1: 0.0
Epoch:  108       11 Batch loss: 0.229355 Batch F1: 0.0
Epoch:  108       12 Batch loss: 0.202789 Batch F1: 0.0
Train Avg Loss  108: 0.225657

Train Avg F1  108: 0.013888888888888888

Val Avg Loss  108: 0.217294

Val Avg F1  108:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 109
--------------------------------------------------------------
Epoch:  109        1 Batch loss: 0.239250 Batch F1: 0.0
Epoch:  109        2 Batch loss: 0.246895 Batch F1: 0.0
Epoch:  109        3 Batch loss: 0.207374 Batch F1: 0.0
Epoch:  109        4 Batch loss: 0.231485 Batch F1: 0.0
Epoch:  109        5 Batch loss: 0.192550 Batch F1: 0.0
Epoch:  109        6 Batch loss: 0.222678 Batch F1: 0.0
Epoch:  109        7 Batch loss: 0.200337 Batch F1: 0.0
Epoch:  109        8 Batch loss: 0.272169 Batch F1: 0.0
Epoch:  109        9 Batch loss: 0.265049 Batch F1: 0.0
Epoch:  109       10 Batch loss: 0.216634 Batch F1: 0.0
Epoch:  109       11 Batch loss: 0.225091 Batch F1: 0.38461538461538464
Epoch:  109       12 Batch loss: 0.224703 Batch F1: 0.11111111111111112
Train Avg Loss  109: 0.228685

Train Avg F1  109: 0.041310541310541314

Val Avg Loss  109: 0.221838

Val Avg F1  109:  0.3804347826086957

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 110
--------------------------------------------------------------
Epoch:  110        1 Batch loss: 0.231459 Batch F1: 0.3448275862068966
Epoch:  110        2 Batch loss: 0.221974 Batch F1: 0.0
Epoch:  110        3 Batch loss: 0.201480 Batch F1: 0.0
Epoch:  110        4 Batch loss: 0.256751 Batch F1: 0.0
Epoch:  110        5 Batch loss: 0.225859 Batch F1: 0.0
Epoch:  110        6 Batch loss: 0.196009 Batch F1: 0.5263157894736842
Epoch:  110        7 Batch loss: 0.223331 Batch F1: 0.0
Epoch:  110        8 Batch loss: 0.238952 Batch F1: 0.0
Epoch:  110        9 Batch loss: 0.219402 Batch F1: 0.0
Epoch:  110       10 Batch loss: 0.261768 Batch F1: 0.0
Epoch:  110       11 Batch loss: 0.238719 Batch F1: 0.0
Epoch:  110       12 Batch loss: 0.207595 Batch F1: 0.0
Train Avg Loss  110: 0.226942

Train Avg F1  110: 0.07259528130671507

Val Avg Loss  110: 0.217591

Val Avg F1  110:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 111
--------------------------------------------------------------
Epoch:  111        1 Batch loss: 0.253259 Batch F1: 0.0
Epoch:  111        2 Batch loss: 0.231172 Batch F1: 0.0
Epoch:  111        3 Batch loss: 0.230029 Batch F1: 0.0
Epoch:  111        4 Batch loss: 0.229934 Batch F1: 0.0
Epoch:  111        5 Batch loss: 0.216737 Batch F1: 0.0
Epoch:  111        6 Batch loss: 0.225068 Batch F1: 0.0
Epoch:  111        7 Batch loss: 0.207124 Batch F1: 0.0
Epoch:  111        8 Batch loss: 0.211676 Batch F1: 0.0
Epoch:  111        9 Batch loss: 0.228555 Batch F1: 0.0
Epoch:  111       10 Batch loss: 0.214527 Batch F1: 0.0
Epoch:  111       11 Batch loss: 0.225858 Batch F1: 0.0
Epoch:  111       12 Batch loss: 0.276875 Batch F1: 0.0
Train Avg Loss  111: 0.229235

Train Avg F1  111: 0.0

Val Avg Loss  111: 0.217659

Val Avg F1  111:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 112
--------------------------------------------------------------
Epoch:  112        1 Batch loss: 0.227616 Batch F1: 0.0
Epoch:  112        2 Batch loss: 0.226246 Batch F1: 0.0
Epoch:  112        3 Batch loss: 0.216371 Batch F1: 0.0
Epoch:  112        4 Batch loss: 0.248899 Batch F1: 0.0
Epoch:  112        5 Batch loss: 0.208877 Batch F1: 0.0
Epoch:  112        6 Batch loss: 0.236763 Batch F1: 0.0
Epoch:  112        7 Batch loss: 0.208941 Batch F1: 0.0
Epoch:  112        8 Batch loss: 0.221610 Batch F1: 0.0
Epoch:  112        9 Batch loss: 0.238558 Batch F1: 0.0
Epoch:  112       10 Batch loss: 0.238083 Batch F1: 0.0
Epoch:  112       11 Batch loss: 0.207692 Batch F1: 0.0
Epoch:  112       12 Batch loss: 0.263582 Batch F1: 0.0
Train Avg Loss  112: 0.228603

Train Avg F1  112: 0.0

Val Avg Loss  112: 0.217395

Val Avg F1  112:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 113
--------------------------------------------------------------
Epoch:  113        1 Batch loss: 0.238403 Batch F1: 0.0
Epoch:  113        2 Batch loss: 0.196476 Batch F1: 0.0
Epoch:  113        3 Batch loss: 0.224939 Batch F1: 0.0
Epoch:  113        4 Batch loss: 0.219883 Batch F1: 0.0
Epoch:  113        5 Batch loss: 0.223802 Batch F1: 0.0
Epoch:  113        6 Batch loss: 0.229284 Batch F1: 0.0
Epoch:  113        7 Batch loss: 0.256172 Batch F1: 0.0
Epoch:  113        8 Batch loss: 0.218829 Batch F1: 0.0
Epoch:  113        9 Batch loss: 0.216986 Batch F1: 0.0
Epoch:  113       10 Batch loss: 0.227417 Batch F1: 0.0
Epoch:  113       11 Batch loss: 0.253659 Batch F1: 0.0
Epoch:  113       12 Batch loss: 0.209954 Batch F1: 0.0
Train Avg Loss  113: 0.226317

Train Avg F1  113: 0.0

Val Avg Loss  113: 0.217537

Val Avg F1  113:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 114
--------------------------------------------------------------
Epoch:  114        1 Batch loss: 0.242760 Batch F1: 0.0
Epoch:  114        2 Batch loss: 0.210906 Batch F1: 0.0
Epoch:  114        3 Batch loss: 0.203439 Batch F1: 0.0
Epoch:  114        4 Batch loss: 0.207644 Batch F1: 0.0
Epoch:  114        5 Batch loss: 0.204711 Batch F1: 0.0
Epoch:  114        6 Batch loss: 0.245696 Batch F1: 0.0
Epoch:  114        7 Batch loss: 0.226291 Batch F1: 0.0
Epoch:  114        8 Batch loss: 0.233557 Batch F1: 0.0
Epoch:  114        9 Batch loss: 0.260368 Batch F1: 0.0
Epoch:  114       10 Batch loss: 0.228593 Batch F1: 0.0
Epoch:  114       11 Batch loss: 0.240491 Batch F1: 0.0
Epoch:  114       12 Batch loss: 0.207692 Batch F1: 0.0
Train Avg Loss  114: 0.226012

Train Avg F1  114: 0.0

Val Avg Loss  114: 0.219207

Val Avg F1  114:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 115
--------------------------------------------------------------
Epoch:  115        1 Batch loss: 0.232654 Batch F1: 0.0
Epoch:  115        2 Batch loss: 0.237905 Batch F1: 0.0
Epoch:  115        3 Batch loss: 0.203370 Batch F1: 0.0
Epoch:  115        4 Batch loss: 0.225020 Batch F1: 0.0
Epoch:  115        5 Batch loss: 0.237246 Batch F1: 0.0
Epoch:  115        6 Batch loss: 0.263426 Batch F1: 0.0
Epoch:  115        7 Batch loss: 0.239353 Batch F1: 0.0
Epoch:  115        8 Batch loss: 0.224486 Batch F1: 0.0
Epoch:  115        9 Batch loss: 0.244823 Batch F1: 0.0
Epoch:  115       10 Batch loss: 0.224685 Batch F1: 0.0
Epoch:  115       11 Batch loss: 0.211112 Batch F1: 0.0
Epoch:  115       12 Batch loss: 0.196628 Batch F1: 0.0
Train Avg Loss  115: 0.228392

Train Avg F1  115: 0.0

Val Avg Loss  115: 0.218477

Val Avg F1  115:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 116
--------------------------------------------------------------
Epoch:  116        1 Batch loss: 0.230906 Batch F1: 0.0
Epoch:  116        2 Batch loss: 0.226798 Batch F1: 0.0
Epoch:  116        3 Batch loss: 0.218098 Batch F1: 0.0
Epoch:  116        4 Batch loss: 0.253299 Batch F1: 0.0
Epoch:  116        5 Batch loss: 0.223975 Batch F1: 0.0
Epoch:  116        6 Batch loss: 0.222087 Batch F1: 0.0
Epoch:  116        7 Batch loss: 0.222104 Batch F1: 0.0
Epoch:  116        8 Batch loss: 0.212494 Batch F1: 0.0
Epoch:  116        9 Batch loss: 0.199248 Batch F1: 0.0
Epoch:  116       10 Batch loss: 0.224084 Batch F1: 0.0
Epoch:  116       11 Batch loss: 0.212270 Batch F1: 0.0
Epoch:  116       12 Batch loss: 0.300533 Batch F1: 0.0
Train Avg Loss  116: 0.228825

Train Avg F1  116: 0.0

Val Avg Loss  116: 0.219975

Val Avg F1  116:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 117
--------------------------------------------------------------
Epoch:  117        1 Batch loss: 0.241793 Batch F1: 0.0
Epoch:  117        2 Batch loss: 0.250848 Batch F1: 0.0
Epoch:  117        3 Batch loss: 0.235742 Batch F1: 0.0
Epoch:  117        4 Batch loss: 0.230562 Batch F1: 0.0
Epoch:  117        5 Batch loss: 0.231363 Batch F1: 0.0
Epoch:  117        6 Batch loss: 0.222891 Batch F1: 0.0
Epoch:  117        7 Batch loss: 0.213887 Batch F1: 0.0
Epoch:  117        8 Batch loss: 0.263857 Batch F1: 0.0
Epoch:  117        9 Batch loss: 0.208779 Batch F1: 0.0
Epoch:  117       10 Batch loss: 0.217461 Batch F1: 0.0
Epoch:  117       11 Batch loss: 0.278815 Batch F1: 0.0
Epoch:  117       12 Batch loss: 0.257577 Batch F1: 0.0
Train Avg Loss  117: 0.237798

Train Avg F1  117: 0.0

Val Avg Loss  117: 0.220565

Val Avg F1  117:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 118
--------------------------------------------------------------
Epoch:  118        1 Batch loss: 0.232334 Batch F1: 0.0
Epoch:  118        2 Batch loss: 0.241615 Batch F1: 0.0
Epoch:  118        3 Batch loss: 0.262371 Batch F1: 0.0
Epoch:  118        4 Batch loss: 0.250784 Batch F1: 0.0
Epoch:  118        5 Batch loss: 0.241248 Batch F1: 0.0
Epoch:  118        6 Batch loss: 0.236137 Batch F1: 0.0
Epoch:  118        7 Batch loss: 0.230887 Batch F1: 0.0
Epoch:  118        8 Batch loss: 0.236713 Batch F1: 0.0
Epoch:  118        9 Batch loss: 0.204344 Batch F1: 0.0
Epoch:  118       10 Batch loss: 0.238949 Batch F1: 0.0
Epoch:  118       11 Batch loss: 0.213618 Batch F1: 0.0
Epoch:  118       12 Batch loss: 0.226842 Batch F1: 0.0
Train Avg Loss  118: 0.234654

Train Avg F1  118: 0.0

Val Avg Loss  118: 0.220744

Val Avg F1  118:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 119
--------------------------------------------------------------
Epoch:  119        1 Batch loss: 0.261216 Batch F1: 0.0
Epoch:  119        2 Batch loss: 0.238285 Batch F1: 0.0
Epoch:  119        3 Batch loss: 0.222503 Batch F1: 0.0
Epoch:  119        4 Batch loss: 0.211604 Batch F1: 0.0
Epoch:  119        5 Batch loss: 0.234049 Batch F1: 0.0
Epoch:  119        6 Batch loss: 0.210211 Batch F1: 0.0
Epoch:  119        7 Batch loss: 0.257810 Batch F1: 0.0
Epoch:  119        8 Batch loss: 0.212702 Batch F1: 0.0
Epoch:  119        9 Batch loss: 0.234458 Batch F1: 0.0
Epoch:  119       10 Batch loss: 0.244306 Batch F1: 0.0
Epoch:  119       11 Batch loss: 0.215379 Batch F1: 0.0
Epoch:  119       12 Batch loss: 0.233428 Batch F1: 0.0
Train Avg Loss  119: 0.231329

Train Avg F1  119: 0.0

Val Avg Loss  119: 0.221603

Val Avg F1  119:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 120
--------------------------------------------------------------
Epoch:  120        1 Batch loss: 0.257449 Batch F1: 0.0
Epoch:  120        2 Batch loss: 0.246186 Batch F1: 0.0
Epoch:  120        3 Batch loss: 0.228416 Batch F1: 0.0
Epoch:  120        4 Batch loss: 0.205831 Batch F1: 0.0
Epoch:  120        5 Batch loss: 0.252135 Batch F1: 0.0
Epoch:  120        6 Batch loss: 0.218340 Batch F1: 0.0
Epoch:  120        7 Batch loss: 0.257213 Batch F1: 0.0
Epoch:  120        8 Batch loss: 0.224295 Batch F1: 0.0
Epoch:  120        9 Batch loss: 0.228631 Batch F1: 0.0
Epoch:  120       10 Batch loss: 0.201796 Batch F1: 0.0
Epoch:  120       11 Batch loss: 0.198197 Batch F1: 0.0
Epoch:  120       12 Batch loss: 0.231557 Batch F1: 0.0
Train Avg Loss  120: 0.229170

Train Avg F1  120: 0.0

Val Avg Loss  120: 0.218212

Val Avg F1  120:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 121
--------------------------------------------------------------
Epoch:  121        1 Batch loss: 0.242626 Batch F1: 0.0
Epoch:  121        2 Batch loss: 0.212071 Batch F1: 0.0
Epoch:  121        3 Batch loss: 0.251591 Batch F1: 0.0
Epoch:  121        4 Batch loss: 0.217110 Batch F1: 0.0
Epoch:  121        5 Batch loss: 0.241674 Batch F1: 0.0
Epoch:  121        6 Batch loss: 0.228967 Batch F1: 0.0
Epoch:  121        7 Batch loss: 0.224072 Batch F1: 0.0
Epoch:  121        8 Batch loss: 0.222390 Batch F1: 0.0
Epoch:  121        9 Batch loss: 0.247078 Batch F1: 0.0
Epoch:  121       10 Batch loss: 0.214766 Batch F1: 0.0
Epoch:  121       11 Batch loss: 0.224167 Batch F1: 0.0
Epoch:  121       12 Batch loss: 0.216884 Batch F1: 0.0
Train Avg Loss  121: 0.228616

Train Avg F1  121: 0.0

Val Avg Loss  121: 0.220401

Val Avg F1  121:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 122
--------------------------------------------------------------
Epoch:  122        1 Batch loss: 0.247006 Batch F1: 0.0
Epoch:  122        2 Batch loss: 0.240402 Batch F1: 0.0
Epoch:  122        3 Batch loss: 0.229204 Batch F1: 0.0
Epoch:  122        4 Batch loss: 0.250635 Batch F1: 0.0
Epoch:  122        5 Batch loss: 0.221213 Batch F1: 0.0
Epoch:  122        6 Batch loss: 0.231743 Batch F1: 0.0
Epoch:  122        7 Batch loss: 0.224451 Batch F1: 0.0
Epoch:  122        8 Batch loss: 0.217350 Batch F1: 0.0
Epoch:  122        9 Batch loss: 0.244598 Batch F1: 0.16
Epoch:  122       10 Batch loss: 0.205006 Batch F1: 0.0
Epoch:  122       11 Batch loss: 0.192219 Batch F1: 0.0
Epoch:  122       12 Batch loss: 0.227963 Batch F1: 0.0
Train Avg Loss  122: 0.227649

Train Avg F1  122: 0.013333333333333334

Val Avg Loss  122: 0.217083

Val Avg F1  122:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 123
--------------------------------------------------------------
Epoch:  123        1 Batch loss: 0.212961 Batch F1: 0.0
Epoch:  123        2 Batch loss: 0.221129 Batch F1: 0.0
Epoch:  123        3 Batch loss: 0.249589 Batch F1: 0.0
Epoch:  123        4 Batch loss: 0.227307 Batch F1: 0.0
Epoch:  123        5 Batch loss: 0.212791 Batch F1: 0.0
Epoch:  123        6 Batch loss: 0.232344 Batch F1: 0.0
Epoch:  123        7 Batch loss: 0.230939 Batch F1: 0.0
Epoch:  123        8 Batch loss: 0.235303 Batch F1: 0.0
Epoch:  123        9 Batch loss: 0.222544 Batch F1: 0.0
Epoch:  123       10 Batch loss: 0.249115 Batch F1: 0.0
Epoch:  123       11 Batch loss: 0.223037 Batch F1: 0.0
Epoch:  123       12 Batch loss: 0.224810 Batch F1: 0.0
Train Avg Loss  123: 0.228489

Train Avg F1  123: 0.0

Val Avg Loss  123: 0.220345

Val Avg F1  123:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 124
--------------------------------------------------------------
Epoch:  124        1 Batch loss: 0.229079 Batch F1: 0.0
Epoch:  124        2 Batch loss: 0.213630 Batch F1: 0.2608695652173913
Epoch:  124        3 Batch loss: 0.233152 Batch F1: 0.32
Epoch:  124        4 Batch loss: 0.209875 Batch F1: 0.0
Epoch:  124        5 Batch loss: 0.199062 Batch F1: 0.0
Epoch:  124        6 Batch loss: 0.222406 Batch F1: 0.0
Epoch:  124        7 Batch loss: 0.235731 Batch F1: 0.0
Epoch:  124        8 Batch loss: 0.244795 Batch F1: 0.0
Epoch:  124        9 Batch loss: 0.249053 Batch F1: 0.0
Epoch:  124       10 Batch loss: 0.257311 Batch F1: 0.0
Epoch:  124       11 Batch loss: 0.218378 Batch F1: 0.0
Epoch:  124       12 Batch loss: 0.241886 Batch F1: 0.0
Train Avg Loss  124: 0.229530

Train Avg F1  124: 0.04840579710144927

Val Avg Loss  124: 0.218906

Val Avg F1  124:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 125
--------------------------------------------------------------
Epoch:  125        1 Batch loss: 0.202070 Batch F1: 0.0
Epoch:  125        2 Batch loss: 0.245796 Batch F1: 0.0
Epoch:  125        3 Batch loss: 0.229383 Batch F1: 0.0
Epoch:  125        4 Batch loss: 0.202936 Batch F1: 0.0
Epoch:  125        5 Batch loss: 0.249324 Batch F1: 0.0
Epoch:  125        6 Batch loss: 0.232641 Batch F1: 0.0
Epoch:  125        7 Batch loss: 0.228919 Batch F1: 0.0
Epoch:  125        8 Batch loss: 0.241201 Batch F1: 0.0
Epoch:  125        9 Batch loss: 0.221514 Batch F1: 0.0
Epoch:  125       10 Batch loss: 0.240084 Batch F1: 0.0
Epoch:  125       11 Batch loss: 0.225906 Batch F1: 0.0
Epoch:  125       12 Batch loss: 0.211166 Batch F1: 0.0
Train Avg Loss  125: 0.227578

Train Avg F1  125: 0.0

Val Avg Loss  125: 0.219402

Val Avg F1  125:  0.0

Optimal Val loss (Epoch 96): 0.2166374772787094

Epoch 126
--------------------------------------------------------------
Epoch:  126        1 Batch loss: 0.222234 Batch F1: 0.0
Epoch:  126        2 Batch loss: 0.226779 Batch F1: 0.0
Epoch:  126        3 Batch loss: 0.239604 Batch F1: 0.0
Epoch:  126        4 Batch loss: 0.245514 Batch F1: 0.0
Epoch:  126        5 Batch loss: 0.211808 Batch F1: 0.0
Epoch:  126        6 Batch loss: 0.207240 Batch F1: 0.0
Epoch:  126        7 Batch loss: 0.230321 Batch F1: 0.0
Epoch:  126        8 Batch loss: 0.206953 Batch F1: 0.0
Epoch:  126        9 Batch loss: 0.224478 Batch F1: 0.0
Epoch:  126       10 Batch loss: 0.243343 Batch F1: 0.0
Epoch:  126       11 Batch loss: 0.226474 Batch F1: 0.0
Epoch:  126       12 Batch loss: 0.240537 Batch F1: 0.0
Train Avg Loss  126: 0.227107

Train Avg F1  126: 0.0

Val Avg Loss  126: 0.216555

Val Avg F1  126:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 127
--------------------------------------------------------------
Epoch:  127        1 Batch loss: 0.249066 Batch F1: 0.0
Epoch:  127        2 Batch loss: 0.216321 Batch F1: 0.0
Epoch:  127        3 Batch loss: 0.227175 Batch F1: 0.0
Epoch:  127        4 Batch loss: 0.255564 Batch F1: 0.0
Epoch:  127        5 Batch loss: 0.221805 Batch F1: 0.0
Epoch:  127        6 Batch loss: 0.205518 Batch F1: 0.0
Epoch:  127        7 Batch loss: 0.232497 Batch F1: 0.0
Epoch:  127        8 Batch loss: 0.232351 Batch F1: 0.0
Epoch:  127        9 Batch loss: 0.224554 Batch F1: 0.0
Epoch:  127       10 Batch loss: 0.189670 Batch F1: 0.0
Epoch:  127       11 Batch loss: 0.243726 Batch F1: 0.0
Epoch:  127       12 Batch loss: 0.236083 Batch F1: 0.0
Train Avg Loss  127: 0.227861

Train Avg F1  127: 0.0

Val Avg Loss  127: 0.217322

Val Avg F1  127:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 128
--------------------------------------------------------------
Epoch:  128        1 Batch loss: 0.219809 Batch F1: 0.0
Epoch:  128        2 Batch loss: 0.231425 Batch F1: 0.0
Epoch:  128        3 Batch loss: 0.212056 Batch F1: 0.0
Epoch:  128        4 Batch loss: 0.264326 Batch F1: 0.0
Epoch:  128        5 Batch loss: 0.231167 Batch F1: 0.3225806451612903
Epoch:  128        6 Batch loss: 0.227669 Batch F1: 0.4
Epoch:  128        7 Batch loss: 0.223698 Batch F1: 0.4347826086956522
Epoch:  128        8 Batch loss: 0.214271 Batch F1: 0.0
Epoch:  128        9 Batch loss: 0.216776 Batch F1: 0.0
Epoch:  128       10 Batch loss: 0.257292 Batch F1: 0.0
Epoch:  128       11 Batch loss: 0.224858 Batch F1: 0.0
Epoch:  128       12 Batch loss: 0.207508 Batch F1: 0.0
Train Avg Loss  128: 0.227571

Train Avg F1  128: 0.0964469378214119

Val Avg Loss  128: 0.217824

Val Avg F1  128:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 129
--------------------------------------------------------------
Epoch:  129        1 Batch loss: 0.269205 Batch F1: 0.0
Epoch:  129        2 Batch loss: 0.204727 Batch F1: 0.0
Epoch:  129        3 Batch loss: 0.240361 Batch F1: 0.0
Epoch:  129        4 Batch loss: 0.217815 Batch F1: 0.0
Epoch:  129        5 Batch loss: 0.260224 Batch F1: 0.0
Epoch:  129        6 Batch loss: 0.230463 Batch F1: 0.0
Epoch:  129        7 Batch loss: 0.226164 Batch F1: 0.0
Epoch:  129        8 Batch loss: 0.240608 Batch F1: 0.0
Epoch:  129        9 Batch loss: 0.227236 Batch F1: 0.0
Epoch:  129       10 Batch loss: 0.214279 Batch F1: 0.0
Epoch:  129       11 Batch loss: 0.200110 Batch F1: 0.0
Epoch:  129       12 Batch loss: 0.231406 Batch F1: 0.0
Train Avg Loss  129: 0.230216

Train Avg F1  129: 0.0

Val Avg Loss  129: 0.219216

Val Avg F1  129:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 130
--------------------------------------------------------------
Epoch:  130        1 Batch loss: 0.264872 Batch F1: 0.0
Epoch:  130        2 Batch loss: 0.237753 Batch F1: 0.0
Epoch:  130        3 Batch loss: 0.234349 Batch F1: 0.0
Epoch:  130        4 Batch loss: 0.232425 Batch F1: 0.0
Epoch:  130        5 Batch loss: 0.232283 Batch F1: 0.0
Epoch:  130        6 Batch loss: 0.214439 Batch F1: 0.0
Epoch:  130        7 Batch loss: 0.209819 Batch F1: 0.0
Epoch:  130        8 Batch loss: 0.237879 Batch F1: 0.0
Epoch:  130        9 Batch loss: 0.259858 Batch F1: 0.0
Epoch:  130       10 Batch loss: 0.231530 Batch F1: 0.0
Epoch:  130       11 Batch loss: 0.199938 Batch F1: 0.0
Epoch:  130       12 Batch loss: 0.200092 Batch F1: 0.0
Train Avg Loss  130: 0.229603

Train Avg F1  130: 0.0

Val Avg Loss  130: 0.218330

Val Avg F1  130:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 131
--------------------------------------------------------------
Epoch:  131        1 Batch loss: 0.227906 Batch F1: 0.0
Epoch:  131        2 Batch loss: 0.236363 Batch F1: 0.0
Epoch:  131        3 Batch loss: 0.238563 Batch F1: 0.0
Epoch:  131        4 Batch loss: 0.225851 Batch F1: 0.0
Epoch:  131        5 Batch loss: 0.264907 Batch F1: 0.0
Epoch:  131        6 Batch loss: 0.216855 Batch F1: 0.0
Epoch:  131        7 Batch loss: 0.232111 Batch F1: 0.37037037037037035
Epoch:  131        8 Batch loss: 0.208754 Batch F1: 0.34782608695652173
Epoch:  131        9 Batch loss: 0.230322 Batch F1: 0.0
Epoch:  131       10 Batch loss: 0.244093 Batch F1: 0.0
Epoch:  131       11 Batch loss: 0.215691 Batch F1: 0.0
Epoch:  131       12 Batch loss: 0.213941 Batch F1: 0.0
Train Avg Loss  131: 0.229613

Train Avg F1  131: 0.059849704777241004

Val Avg Loss  131: 0.218473

Val Avg F1  131:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 132
--------------------------------------------------------------
Epoch:  132        1 Batch loss: 0.213249 Batch F1: 0.0
Epoch:  132        2 Batch loss: 0.239463 Batch F1: 0.0
Epoch:  132        3 Batch loss: 0.197962 Batch F1: 0.0
Epoch:  132        4 Batch loss: 0.234426 Batch F1: 0.0
Epoch:  132        5 Batch loss: 0.260859 Batch F1: 0.0
Epoch:  132        6 Batch loss: 0.263858 Batch F1: 0.0
Epoch:  132        7 Batch loss: 0.225302 Batch F1: 0.0
Epoch:  132        8 Batch loss: 0.227720 Batch F1: 0.0
Epoch:  132        9 Batch loss: 0.231620 Batch F1: 0.0
Epoch:  132       10 Batch loss: 0.223218 Batch F1: 0.0
Epoch:  132       11 Batch loss: 0.222455 Batch F1: 0.0
Epoch:  132       12 Batch loss: 0.257771 Batch F1: 0.0
Train Avg Loss  132: 0.233159

Train Avg F1  132: 0.0

Val Avg Loss  132: 0.220035

Val Avg F1  132:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 133
--------------------------------------------------------------
Epoch:  133        1 Batch loss: 0.233412 Batch F1: 0.0
Epoch:  133        2 Batch loss: 0.224532 Batch F1: 0.0
Epoch:  133        3 Batch loss: 0.216885 Batch F1: 0.0
Epoch:  133        4 Batch loss: 0.253281 Batch F1: 0.0
Epoch:  133        5 Batch loss: 0.223078 Batch F1: 0.0
Epoch:  133        6 Batch loss: 0.213037 Batch F1: 0.0
Epoch:  133        7 Batch loss: 0.225089 Batch F1: 0.0
Epoch:  133        8 Batch loss: 0.239770 Batch F1: 0.0
Epoch:  133        9 Batch loss: 0.201715 Batch F1: 0.0
Epoch:  133       10 Batch loss: 0.248431 Batch F1: 0.0
Epoch:  133       11 Batch loss: 0.225885 Batch F1: 0.0
Epoch:  133       12 Batch loss: 0.233180 Batch F1: 0.0
Train Avg Loss  133: 0.228191

Train Avg F1  133: 0.0

Val Avg Loss  133: 0.218995

Val Avg F1  133:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 134
--------------------------------------------------------------
Epoch:  134        1 Batch loss: 0.227941 Batch F1: 0.0
Epoch:  134        2 Batch loss: 0.227542 Batch F1: 0.0
Epoch:  134        3 Batch loss: 0.218940 Batch F1: 0.0
Epoch:  134        4 Batch loss: 0.246287 Batch F1: 0.0
Epoch:  134        5 Batch loss: 0.267421 Batch F1: 0.0
Epoch:  134        6 Batch loss: 0.204234 Batch F1: 0.0
Epoch:  134        7 Batch loss: 0.224636 Batch F1: 0.0
Epoch:  134        8 Batch loss: 0.212730 Batch F1: 0.0
Epoch:  134        9 Batch loss: 0.236484 Batch F1: 0.0
Epoch:  134       10 Batch loss: 0.217284 Batch F1: 0.0
Epoch:  134       11 Batch loss: 0.239465 Batch F1: 0.0
Epoch:  134       12 Batch loss: 0.199469 Batch F1: 0.0
Train Avg Loss  134: 0.226870

Train Avg F1  134: 0.0

Val Avg Loss  134: 0.219311

Val Avg F1  134:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 135
--------------------------------------------------------------
Epoch:  135        1 Batch loss: 0.228592 Batch F1: 0.0
Epoch:  135        2 Batch loss: 0.207607 Batch F1: 0.0
Epoch:  135        3 Batch loss: 0.235219 Batch F1: 0.0
Epoch:  135        4 Batch loss: 0.229612 Batch F1: 0.0
Epoch:  135        5 Batch loss: 0.261512 Batch F1: 0.0
Epoch:  135        6 Batch loss: 0.214588 Batch F1: 0.0
Epoch:  135        7 Batch loss: 0.198574 Batch F1: 0.0
Epoch:  135        8 Batch loss: 0.243023 Batch F1: 0.0
Epoch:  135        9 Batch loss: 0.240384 Batch F1: 0.0
Epoch:  135       10 Batch loss: 0.249341 Batch F1: 0.0
Epoch:  135       11 Batch loss: 0.215094 Batch F1: 0.0
Epoch:  135       12 Batch loss: 0.194293 Batch F1: 0.0
Train Avg Loss  135: 0.226487

Train Avg F1  135: 0.0

Val Avg Loss  135: 0.217646

Val Avg F1  135:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 136
--------------------------------------------------------------
Epoch:  136        1 Batch loss: 0.226046 Batch F1: 0.0
Epoch:  136        2 Batch loss: 0.256212 Batch F1: 0.0
Epoch:  136        3 Batch loss: 0.199674 Batch F1: 0.0
Epoch:  136        4 Batch loss: 0.224129 Batch F1: 0.0
Epoch:  136        5 Batch loss: 0.235105 Batch F1: 0.0
Epoch:  136        6 Batch loss: 0.212812 Batch F1: 0.0
Epoch:  136        7 Batch loss: 0.206512 Batch F1: 0.0
Epoch:  136        8 Batch loss: 0.235976 Batch F1: 0.0
Epoch:  136        9 Batch loss: 0.238385 Batch F1: 0.0
Epoch:  136       10 Batch loss: 0.217351 Batch F1: 0.0
Epoch:  136       11 Batch loss: 0.228951 Batch F1: 0.0
Epoch:  136       12 Batch loss: 0.250138 Batch F1: 0.0
Train Avg Loss  136: 0.227608

Train Avg F1  136: 0.0

Val Avg Loss  136: 0.216926

Val Avg F1  136:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 137
--------------------------------------------------------------
Epoch:  137        1 Batch loss: 0.212578 Batch F1: 0.0
Epoch:  137        2 Batch loss: 0.206179 Batch F1: 0.0
Epoch:  137        3 Batch loss: 0.228954 Batch F1: 0.0
Epoch:  137        4 Batch loss: 0.223006 Batch F1: 0.0
Epoch:  137        5 Batch loss: 0.227491 Batch F1: 0.0
Epoch:  137        6 Batch loss: 0.212565 Batch F1: 0.0
Epoch:  137        7 Batch loss: 0.235270 Batch F1: 0.0
Epoch:  137        8 Batch loss: 0.224165 Batch F1: 0.0
Epoch:  137        9 Batch loss: 0.233960 Batch F1: 0.0
Epoch:  137       10 Batch loss: 0.217238 Batch F1: 0.0
Epoch:  137       11 Batch loss: 0.262664 Batch F1: 0.0
Epoch:  137       12 Batch loss: 0.222297 Batch F1: 0.5
Train Avg Loss  137: 0.225531

Train Avg F1  137: 0.041666666666666664

Val Avg Loss  137: 0.219815

Val Avg F1  137:  0.39389920424403185

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 138
--------------------------------------------------------------
Epoch:  138        1 Batch loss: 0.238909 Batch F1: 0.3448275862068965
Epoch:  138        2 Batch loss: 0.246167 Batch F1: 0.20689655172413793
Epoch:  138        3 Batch loss: 0.230802 Batch F1: 0.588235294117647
Epoch:  138        4 Batch loss: 0.208171 Batch F1: 0.1
Epoch:  138        5 Batch loss: 0.255466 Batch F1: 0.20689655172413793
Epoch:  138        6 Batch loss: 0.193028 Batch F1: 0.4
Epoch:  138        7 Batch loss: 0.213457 Batch F1: 0.0
Epoch:  138        8 Batch loss: 0.216891 Batch F1: 0.0
Epoch:  138        9 Batch loss: 0.255488 Batch F1: 0.0
Epoch:  138       10 Batch loss: 0.199067 Batch F1: 0.0
Epoch:  138       11 Batch loss: 0.219149 Batch F1: 0.0
Epoch:  138       12 Batch loss: 0.247910 Batch F1: 0.0
Train Avg Loss  138: 0.227042

Train Avg F1  138: 0.1539046653144016

Val Avg Loss  138: 0.217274

Val Avg F1  138:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 139
--------------------------------------------------------------
Epoch:  139        1 Batch loss: 0.247847 Batch F1: 0.0
Epoch:  139        2 Batch loss: 0.211650 Batch F1: 0.0
Epoch:  139        3 Batch loss: 0.211932 Batch F1: 0.0
Epoch:  139        4 Batch loss: 0.193578 Batch F1: 0.0
Epoch:  139        5 Batch loss: 0.224880 Batch F1: 0.0
Epoch:  139        6 Batch loss: 0.267047 Batch F1: 0.0
Epoch:  139        7 Batch loss: 0.218721 Batch F1: 0.0
Epoch:  139        8 Batch loss: 0.215845 Batch F1: 0.0
Epoch:  139        9 Batch loss: 0.199314 Batch F1: 0.0
Epoch:  139       10 Batch loss: 0.262088 Batch F1: 0.0
Epoch:  139       11 Batch loss: 0.242843 Batch F1: 0.0
Epoch:  139       12 Batch loss: 0.217725 Batch F1: 0.0
Train Avg Loss  139: 0.226122

Train Avg F1  139: 0.0

Val Avg Loss  139: 0.218039

Val Avg F1  139:  0.0

Optimal Val loss (Epoch 126): 0.2165554128587246

Epoch 140
--------------------------------------------------------------
Epoch:  140        1 Batch loss: 0.236610 Batch F1: 0.0
Epoch:  140        2 Batch loss: 0.219143 Batch F1: 0.0
Epoch:  140        3 Batch loss: 0.224042 Batch F1: 0.0
Epoch:  140        4 Batch loss: 0.220430 Batch F1: 0.0
Epoch:  140        5 Batch loss: 0.227272 Batch F1: 0.0
Epoch:  140        6 Batch loss: 0.229162 Batch F1: 0.0
Epoch:  140        7 Batch loss: 0.207410 Batch F1: 0.0
Epoch:  140        8 Batch loss: 0.233440 Batch F1: 0.0
Epoch:  140        9 Batch loss: 0.197525 Batch F1: 0.0
Epoch:  140       10 Batch loss: 0.206121 Batch F1: 0.0
Epoch:  140       11 Batch loss: 0.283515 Batch F1: 0.0
Epoch:  140       12 Batch loss: 0.229323 Batch F1: 0.0
Train Avg Loss  140: 0.226166

Train Avg F1  140: 0.0

Val Avg Loss  140: 0.216451

Val Avg F1  140:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 141
--------------------------------------------------------------
Epoch:  141        1 Batch loss: 0.258453 Batch F1: 0.0
Epoch:  141        2 Batch loss: 0.218722 Batch F1: 0.0
Epoch:  141        3 Batch loss: 0.263139 Batch F1: 0.0
Epoch:  141        4 Batch loss: 0.214965 Batch F1: 0.0
Epoch:  141        5 Batch loss: 0.200897 Batch F1: 0.0
Epoch:  141        6 Batch loss: 0.246863 Batch F1: 0.0
Epoch:  141        7 Batch loss: 0.237723 Batch F1: 0.0
Epoch:  141        8 Batch loss: 0.216594 Batch F1: 0.0
Epoch:  141        9 Batch loss: 0.214640 Batch F1: 0.0
Epoch:  141       10 Batch loss: 0.240100 Batch F1: 0.0
Epoch:  141       11 Batch loss: 0.196077 Batch F1: 0.0
Epoch:  141       12 Batch loss: 0.207283 Batch F1: 0.0
Train Avg Loss  141: 0.226288

Train Avg F1  141: 0.0

Val Avg Loss  141: 0.217344

Val Avg F1  141:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 142
--------------------------------------------------------------
Epoch:  142        1 Batch loss: 0.211116 Batch F1: 0.0
Epoch:  142        2 Batch loss: 0.199686 Batch F1: 0.0
Epoch:  142        3 Batch loss: 0.170233 Batch F1: 0.0
Epoch:  142        4 Batch loss: 0.277622 Batch F1: 0.0
Epoch:  142        5 Batch loss: 0.228685 Batch F1: 0.0
Epoch:  142        6 Batch loss: 0.245518 Batch F1: 0.0
Epoch:  142        7 Batch loss: 0.234020 Batch F1: 0.0
Epoch:  142        8 Batch loss: 0.223346 Batch F1: 0.0
Epoch:  142        9 Batch loss: 0.243563 Batch F1: 0.0
Epoch:  142       10 Batch loss: 0.235573 Batch F1: 0.0
Epoch:  142       11 Batch loss: 0.249604 Batch F1: 0.0
Epoch:  142       12 Batch loss: 0.230639 Batch F1: 0.0
Train Avg Loss  142: 0.229134

Train Avg F1  142: 0.0

Val Avg Loss  142: 0.225442

Val Avg F1  142:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 143
--------------------------------------------------------------
Epoch:  143        1 Batch loss: 0.241420 Batch F1: 0.0
Epoch:  143        2 Batch loss: 0.216447 Batch F1: 0.0
Epoch:  143        3 Batch loss: 0.250450 Batch F1: 0.0
Epoch:  143        4 Batch loss: 0.244983 Batch F1: 0.0
Epoch:  143        5 Batch loss: 0.230443 Batch F1: 0.0
Epoch:  143        6 Batch loss: 0.227875 Batch F1: 0.0
Epoch:  143        7 Batch loss: 0.218053 Batch F1: 0.0
Epoch:  143        8 Batch loss: 0.226191 Batch F1: 0.0
Epoch:  143        9 Batch loss: 0.189848 Batch F1: 0.0
Epoch:  143       10 Batch loss: 0.258291 Batch F1: 0.0
Epoch:  143       11 Batch loss: 0.231588 Batch F1: 0.0
Epoch:  143       12 Batch loss: 0.214605 Batch F1: 0.0
Train Avg Loss  143: 0.229183

Train Avg F1  143: 0.0

Val Avg Loss  143: 0.219143

Val Avg F1  143:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 144
--------------------------------------------------------------
Epoch:  144        1 Batch loss: 0.215233 Batch F1: 0.0
Epoch:  144        2 Batch loss: 0.213184 Batch F1: 0.0
Epoch:  144        3 Batch loss: 0.247544 Batch F1: 0.0
Epoch:  144        4 Batch loss: 0.203877 Batch F1: 0.0
Epoch:  144        5 Batch loss: 0.241648 Batch F1: 0.0
Epoch:  144        6 Batch loss: 0.238499 Batch F1: 0.0
Epoch:  144        7 Batch loss: 0.227418 Batch F1: 0.0
Epoch:  144        8 Batch loss: 0.244633 Batch F1: 0.0
Epoch:  144        9 Batch loss: 0.245032 Batch F1: 0.07407407407407408
Epoch:  144       10 Batch loss: 0.243359 Batch F1: 0.23076923076923078
Epoch:  144       11 Batch loss: 0.216439 Batch F1: 0.0
Epoch:  144       12 Batch loss: 0.232545 Batch F1: 0.0
Train Avg Loss  144: 0.230784

Train Avg F1  144: 0.02540360873694207

Val Avg Loss  144: 0.221498

Val Avg F1  144:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 145
--------------------------------------------------------------
Epoch:  145        1 Batch loss: 0.237724 Batch F1: 0.0
Epoch:  145        2 Batch loss: 0.209760 Batch F1: 0.0
Epoch:  145        3 Batch loss: 0.219067 Batch F1: 0.0
Epoch:  145        4 Batch loss: 0.261276 Batch F1: 0.0
Epoch:  145        5 Batch loss: 0.266992 Batch F1: 0.0
Epoch:  145        6 Batch loss: 0.232158 Batch F1: 0.0
Epoch:  145        7 Batch loss: 0.200719 Batch F1: 0.0
Epoch:  145        8 Batch loss: 0.234336 Batch F1: 0.0
Epoch:  145        9 Batch loss: 0.229993 Batch F1: 0.0
Epoch:  145       10 Batch loss: 0.207771 Batch F1: 0.0
Epoch:  145       11 Batch loss: 0.217275 Batch F1: 0.0
Epoch:  145       12 Batch loss: 0.225975 Batch F1: 0.0
Train Avg Loss  145: 0.228587

Train Avg F1  145: 0.0

Val Avg Loss  145: 0.218159

Val Avg F1  145:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 146
--------------------------------------------------------------
Epoch:  146        1 Batch loss: 0.225321 Batch F1: 0.0
Epoch:  146        2 Batch loss: 0.224217 Batch F1: 0.0
Epoch:  146        3 Batch loss: 0.192196 Batch F1: 0.0
Epoch:  146        4 Batch loss: 0.234333 Batch F1: 0.0
Epoch:  146        5 Batch loss: 0.193686 Batch F1: 0.0
Epoch:  146        6 Batch loss: 0.207334 Batch F1: 0.0
Epoch:  146        7 Batch loss: 0.244103 Batch F1: 0.0
Epoch:  146        8 Batch loss: 0.246072 Batch F1: 0.0
Epoch:  146        9 Batch loss: 0.253481 Batch F1: 0.0
Epoch:  146       10 Batch loss: 0.264987 Batch F1: 0.0
Epoch:  146       11 Batch loss: 0.200708 Batch F1: 0.0
Epoch:  146       12 Batch loss: 0.271077 Batch F1: 0.0
Train Avg Loss  146: 0.229793

Train Avg F1  146: 0.0

Val Avg Loss  146: 0.222830

Val Avg F1  146:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 147
--------------------------------------------------------------
Epoch:  147        1 Batch loss: 0.243602 Batch F1: 0.0
Epoch:  147        2 Batch loss: 0.217557 Batch F1: 0.25
Epoch:  147        3 Batch loss: 0.213353 Batch F1: 0.5384615384615384
Epoch:  147        4 Batch loss: 0.236753 Batch F1: 0.35714285714285715
Epoch:  147        5 Batch loss: 0.212679 Batch F1: 0.0
Epoch:  147        6 Batch loss: 0.240049 Batch F1: 0.0
Epoch:  147        7 Batch loss: 0.227111 Batch F1: 0.0
Epoch:  147        8 Batch loss: 0.254575 Batch F1: 0.0
Epoch:  147        9 Batch loss: 0.248957 Batch F1: 0.0
Epoch:  147       10 Batch loss: 0.211867 Batch F1: 0.0
Epoch:  147       11 Batch loss: 0.239803 Batch F1: 0.0
Epoch:  147       12 Batch loss: 0.234845 Batch F1: 0.0
Train Avg Loss  147: 0.231763

Train Avg F1  147: 0.09546703296703296

Val Avg Loss  147: 0.219101

Val Avg F1  147:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 148
--------------------------------------------------------------
Epoch:  148        1 Batch loss: 0.212752 Batch F1: 0.0
Epoch:  148        2 Batch loss: 0.234668 Batch F1: 0.0
Epoch:  148        3 Batch loss: 0.237680 Batch F1: 0.0
Epoch:  148        4 Batch loss: 0.229656 Batch F1: 0.0
Epoch:  148        5 Batch loss: 0.228924 Batch F1: 0.0
Epoch:  148        6 Batch loss: 0.223697 Batch F1: 0.0
Epoch:  148        7 Batch loss: 0.225769 Batch F1: 0.0
Epoch:  148        8 Batch loss: 0.234127 Batch F1: 0.0
Epoch:  148        9 Batch loss: 0.204928 Batch F1: 0.0
Epoch:  148       10 Batch loss: 0.231501 Batch F1: 0.0
Epoch:  148       11 Batch loss: 0.228553 Batch F1: 0.0
Epoch:  148       12 Batch loss: 0.237309 Batch F1: 0.0
Train Avg Loss  148: 0.227464

Train Avg F1  148: 0.0

Val Avg Loss  148: 0.217805

Val Avg F1  148:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 149
--------------------------------------------------------------
Epoch:  149        1 Batch loss: 0.211978 Batch F1: 0.0
Epoch:  149        2 Batch loss: 0.250964 Batch F1: 0.0
Epoch:  149        3 Batch loss: 0.249119 Batch F1: 0.0
Epoch:  149        4 Batch loss: 0.198767 Batch F1: 0.0
Epoch:  149        5 Batch loss: 0.238473 Batch F1: 0.0
Epoch:  149        6 Batch loss: 0.221773 Batch F1: 0.0
Epoch:  149        7 Batch loss: 0.196946 Batch F1: 0.0
Epoch:  149        8 Batch loss: 0.230940 Batch F1: 0.0
Epoch:  149        9 Batch loss: 0.249821 Batch F1: 0.0
Epoch:  149       10 Batch loss: 0.235984 Batch F1: 0.0
Epoch:  149       11 Batch loss: 0.246720 Batch F1: 0.0
Epoch:  149       12 Batch loss: 0.201798 Batch F1: 0.0
Train Avg Loss  149: 0.227774

Train Avg F1  149: 0.0

Val Avg Loss  149: 0.217647

Val Avg F1  149:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 150
--------------------------------------------------------------
Epoch:  150        1 Batch loss: 0.231511 Batch F1: 0.0
Epoch:  150        2 Batch loss: 0.221494 Batch F1: 0.0
Epoch:  150        3 Batch loss: 0.231677 Batch F1: 0.0
Epoch:  150        4 Batch loss: 0.240549 Batch F1: 0.0
Epoch:  150        5 Batch loss: 0.239334 Batch F1: 0.0
Epoch:  150        6 Batch loss: 0.218072 Batch F1: 0.0
Epoch:  150        7 Batch loss: 0.209048 Batch F1: 0.0
Epoch:  150        8 Batch loss: 0.232392 Batch F1: 0.09090909090909091
Epoch:  150        9 Batch loss: 0.214582 Batch F1: 0.0
Epoch:  150       10 Batch loss: 0.210201 Batch F1: 0.0
Epoch:  150       11 Batch loss: 0.220666 Batch F1: 0.0
Epoch:  150       12 Batch loss: 0.266472 Batch F1: 0.0
Train Avg Loss  150: 0.228000

Train Avg F1  150: 0.007575757575757576

Val Avg Loss  150: 0.217389

Val Avg F1  150:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 151
--------------------------------------------------------------
Epoch:  151        1 Batch loss: 0.220296 Batch F1: 0.0
Epoch:  151        2 Batch loss: 0.213566 Batch F1: 0.0
Epoch:  151        3 Batch loss: 0.226128 Batch F1: 0.0
Epoch:  151        4 Batch loss: 0.230163 Batch F1: 0.0
Epoch:  151        5 Batch loss: 0.212455 Batch F1: 0.0
Epoch:  151        6 Batch loss: 0.227347 Batch F1: 0.0
Epoch:  151        7 Batch loss: 0.243520 Batch F1: 0.0
Epoch:  151        8 Batch loss: 0.241909 Batch F1: 0.0
Epoch:  151        9 Batch loss: 0.229086 Batch F1: 0.0
Epoch:  151       10 Batch loss: 0.208047 Batch F1: 0.0
Epoch:  151       11 Batch loss: 0.260336 Batch F1: 0.0
Epoch:  151       12 Batch loss: 0.217176 Batch F1: 0.0
Train Avg Loss  151: 0.227502

Train Avg F1  151: 0.0

Val Avg Loss  151: 0.222057

Val Avg F1  151:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 152
--------------------------------------------------------------
Epoch:  152        1 Batch loss: 0.233885 Batch F1: 0.0
Epoch:  152        2 Batch loss: 0.222164 Batch F1: 0.0
Epoch:  152        3 Batch loss: 0.228000 Batch F1: 0.0
Epoch:  152        4 Batch loss: 0.255727 Batch F1: 0.0
Epoch:  152        5 Batch loss: 0.243640 Batch F1: 0.0
Epoch:  152        6 Batch loss: 0.214428 Batch F1: 0.0
Epoch:  152        7 Batch loss: 0.204088 Batch F1: 0.0
Epoch:  152        8 Batch loss: 0.222515 Batch F1: 0.0
Epoch:  152        9 Batch loss: 0.247720 Batch F1: 0.0
Epoch:  152       10 Batch loss: 0.227021 Batch F1: 0.0
Epoch:  152       11 Batch loss: 0.202084 Batch F1: 0.0
Epoch:  152       12 Batch loss: 0.241902 Batch F1: 0.0
Train Avg Loss  152: 0.228598

Train Avg F1  152: 0.0

Val Avg Loss  152: 0.217943

Val Avg F1  152:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 153
--------------------------------------------------------------
Epoch:  153        1 Batch loss: 0.264254 Batch F1: 0.0
Epoch:  153        2 Batch loss: 0.223797 Batch F1: 0.0
Epoch:  153        3 Batch loss: 0.224074 Batch F1: 0.0
Epoch:  153        4 Batch loss: 0.234573 Batch F1: 0.0
Epoch:  153        5 Batch loss: 0.203516 Batch F1: 0.0
Epoch:  153        6 Batch loss: 0.203730 Batch F1: 0.0
Epoch:  153        7 Batch loss: 0.253424 Batch F1: 0.0
Epoch:  153        8 Batch loss: 0.233978 Batch F1: 0.0
Epoch:  153        9 Batch loss: 0.225235 Batch F1: 0.0
Epoch:  153       10 Batch loss: 0.234525 Batch F1: 0.0
Epoch:  153       11 Batch loss: 0.226588 Batch F1: 0.0
Epoch:  153       12 Batch loss: 0.204228 Batch F1: 0.0
Train Avg Loss  153: 0.227660

Train Avg F1  153: 0.0

Val Avg Loss  153: 0.218643

Val Avg F1  153:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 154
--------------------------------------------------------------
Epoch:  154        1 Batch loss: 0.255559 Batch F1: 0.0
Epoch:  154        2 Batch loss: 0.230943 Batch F1: 0.0
Epoch:  154        3 Batch loss: 0.224404 Batch F1: 0.0
Epoch:  154        4 Batch loss: 0.206350 Batch F1: 0.0
Epoch:  154        5 Batch loss: 0.244918 Batch F1: 0.0
Epoch:  154        6 Batch loss: 0.248536 Batch F1: 0.0
Epoch:  154        7 Batch loss: 0.236250 Batch F1: 0.0
Epoch:  154        8 Batch loss: 0.228221 Batch F1: 0.0
Epoch:  154        9 Batch loss: 0.214302 Batch F1: 0.0
Epoch:  154       10 Batch loss: 0.207203 Batch F1: 0.0
Epoch:  154       11 Batch loss: 0.231293 Batch F1: 0.0
Epoch:  154       12 Batch loss: 0.194404 Batch F1: 0.0
Train Avg Loss  154: 0.226865

Train Avg F1  154: 0.0

Val Avg Loss  154: 0.217558

Val Avg F1  154:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 155
--------------------------------------------------------------
Epoch:  155        1 Batch loss: 0.226197 Batch F1: 0.0
Epoch:  155        2 Batch loss: 0.259906 Batch F1: 0.0
Epoch:  155        3 Batch loss: 0.217696 Batch F1: 0.0
Epoch:  155        4 Batch loss: 0.213337 Batch F1: 0.0
Epoch:  155        5 Batch loss: 0.212968 Batch F1: 0.0
Epoch:  155        6 Batch loss: 0.232317 Batch F1: 0.0
Epoch:  155        7 Batch loss: 0.195616 Batch F1: 0.0
Epoch:  155        8 Batch loss: 0.247930 Batch F1: 0.0
Epoch:  155        9 Batch loss: 0.257529 Batch F1: 0.0
Epoch:  155       10 Batch loss: 0.204578 Batch F1: 0.0
Epoch:  155       11 Batch loss: 0.223584 Batch F1: 0.0
Epoch:  155       12 Batch loss: 0.233033 Batch F1: 0.0
Train Avg Loss  155: 0.227058

Train Avg F1  155: 0.0

Val Avg Loss  155: 0.218266

Val Avg F1  155:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 156
--------------------------------------------------------------
Epoch:  156        1 Batch loss: 0.226035 Batch F1: 0.0
Epoch:  156        2 Batch loss: 0.200178 Batch F1: 0.0
Epoch:  156        3 Batch loss: 0.219544 Batch F1: 0.2608695652173913
Epoch:  156        4 Batch loss: 0.234284 Batch F1: 0.0
Epoch:  156        5 Batch loss: 0.214720 Batch F1: 0.0
Epoch:  156        6 Batch loss: 0.222018 Batch F1: 0.0
Epoch:  156        7 Batch loss: 0.241946 Batch F1: 0.0
Epoch:  156        8 Batch loss: 0.205750 Batch F1: 0.0
Epoch:  156        9 Batch loss: 0.227730 Batch F1: 0.0
Epoch:  156       10 Batch loss: 0.232001 Batch F1: 0.0
Epoch:  156       11 Batch loss: 0.252613 Batch F1: 0.0
Epoch:  156       12 Batch loss: 0.248863 Batch F1: 0.0
Train Avg Loss  156: 0.227140

Train Avg F1  156: 0.021739130434782608

Val Avg Loss  156: 0.221747

Val Avg F1  156:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 157
--------------------------------------------------------------
Epoch:  157        1 Batch loss: 0.224395 Batch F1: 0.0
Epoch:  157        2 Batch loss: 0.227324 Batch F1: 0.24000000000000002
Epoch:  157        3 Batch loss: 0.221684 Batch F1: 0.33333333333333337
Epoch:  157        4 Batch loss: 0.232001 Batch F1: 0.46153846153846156
Epoch:  157        5 Batch loss: 0.243267 Batch F1: 0.0
Epoch:  157        6 Batch loss: 0.243132 Batch F1: 0.0
Epoch:  157        7 Batch loss: 0.236660 Batch F1: 0.0
Epoch:  157        8 Batch loss: 0.214202 Batch F1: 0.2222222222222222
Epoch:  157        9 Batch loss: 0.226386 Batch F1: 0.0
Epoch:  157       10 Batch loss: 0.216498 Batch F1: 0.0
Epoch:  157       11 Batch loss: 0.208370 Batch F1: 0.0
Epoch:  157       12 Batch loss: 0.239650 Batch F1: 0.0
Train Avg Loss  157: 0.227797

Train Avg F1  157: 0.10475783475783478

Val Avg Loss  157: 0.216506

Val Avg F1  157:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 158
--------------------------------------------------------------
Epoch:  158        1 Batch loss: 0.249761 Batch F1: 0.0
Epoch:  158        2 Batch loss: 0.251962 Batch F1: 0.0
Epoch:  158        3 Batch loss: 0.215767 Batch F1: 0.0
Epoch:  158        4 Batch loss: 0.275802 Batch F1: 0.0
Epoch:  158        5 Batch loss: 0.203141 Batch F1: 0.0
Epoch:  158        6 Batch loss: 0.220584 Batch F1: 0.0
Epoch:  158        7 Batch loss: 0.222038 Batch F1: 0.0
Epoch:  158        8 Batch loss: 0.210455 Batch F1: 0.0
Epoch:  158        9 Batch loss: 0.201712 Batch F1: 0.0
Epoch:  158       10 Batch loss: 0.211329 Batch F1: 0.0
Epoch:  158       11 Batch loss: 0.235151 Batch F1: 0.0
Epoch:  158       12 Batch loss: 0.255368 Batch F1: 0.0
Train Avg Loss  158: 0.229422

Train Avg F1  158: 0.0

Val Avg Loss  158: 0.217213

Val Avg F1  158:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 159
--------------------------------------------------------------
Epoch:  159        1 Batch loss: 0.242029 Batch F1: 0.0
Epoch:  159        2 Batch loss: 0.225269 Batch F1: 0.0
Epoch:  159        3 Batch loss: 0.248576 Batch F1: 0.0
Epoch:  159        4 Batch loss: 0.234245 Batch F1: 0.0
Epoch:  159        5 Batch loss: 0.221544 Batch F1: 0.0
Epoch:  159        6 Batch loss: 0.219983 Batch F1: 0.0
Epoch:  159        7 Batch loss: 0.208242 Batch F1: 0.0
Epoch:  159        8 Batch loss: 0.215955 Batch F1: 0.0
Epoch:  159        9 Batch loss: 0.242605 Batch F1: 0.0
Epoch:  159       10 Batch loss: 0.209596 Batch F1: 0.0
Epoch:  159       11 Batch loss: 0.225850 Batch F1: 0.0
Epoch:  159       12 Batch loss: 0.248829 Batch F1: 0.0
Train Avg Loss  159: 0.228560

Train Avg F1  159: 0.0

Val Avg Loss  159: 0.217360

Val Avg F1  159:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 160
--------------------------------------------------------------
Epoch:  160        1 Batch loss: 0.229724 Batch F1: 0.0
Epoch:  160        2 Batch loss: 0.226626 Batch F1: 0.0
Epoch:  160        3 Batch loss: 0.231458 Batch F1: 0.0
Epoch:  160        4 Batch loss: 0.235184 Batch F1: 0.0
Epoch:  160        5 Batch loss: 0.221446 Batch F1: 0.0
Epoch:  160        6 Batch loss: 0.199406 Batch F1: 0.0
Epoch:  160        7 Batch loss: 0.235746 Batch F1: 0.0
Epoch:  160        8 Batch loss: 0.196331 Batch F1: 0.0
Epoch:  160        9 Batch loss: 0.213077 Batch F1: 0.0
Epoch:  160       10 Batch loss: 0.263325 Batch F1: 0.0
Epoch:  160       11 Batch loss: 0.253665 Batch F1: 0.0
Epoch:  160       12 Batch loss: 0.213914 Batch F1: 0.0
Train Avg Loss  160: 0.226659

Train Avg F1  160: 0.0

Val Avg Loss  160: 0.218235

Val Avg F1  160:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 161
--------------------------------------------------------------
Epoch:  161        1 Batch loss: 0.223818 Batch F1: 0.0
Epoch:  161        2 Batch loss: 0.230672 Batch F1: 0.0
Epoch:  161        3 Batch loss: 0.218364 Batch F1: 0.0
Epoch:  161        4 Batch loss: 0.248794 Batch F1: 0.0
Epoch:  161        5 Batch loss: 0.236095 Batch F1: 0.0
Epoch:  161        6 Batch loss: 0.186894 Batch F1: 0.0
Epoch:  161        7 Batch loss: 0.207073 Batch F1: 0.0
Epoch:  161        8 Batch loss: 0.209487 Batch F1: 0.0
Epoch:  161        9 Batch loss: 0.210358 Batch F1: 0.0
Epoch:  161       10 Batch loss: 0.241312 Batch F1: 0.0
Epoch:  161       11 Batch loss: 0.255417 Batch F1: 0.0
Epoch:  161       12 Batch loss: 0.254581 Batch F1: 0.0
Train Avg Loss  161: 0.226905

Train Avg F1  161: 0.0

Val Avg Loss  161: 0.218539

Val Avg F1  161:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 162
--------------------------------------------------------------
Epoch:  162        1 Batch loss: 0.221957 Batch F1: 0.0
Epoch:  162        2 Batch loss: 0.199913 Batch F1: 0.0
Epoch:  162        3 Batch loss: 0.231520 Batch F1: 0.0
Epoch:  162        4 Batch loss: 0.260441 Batch F1: 0.0
Epoch:  162        5 Batch loss: 0.257797 Batch F1: 0.0
Epoch:  162        6 Batch loss: 0.234117 Batch F1: 0.0
Epoch:  162        7 Batch loss: 0.235231 Batch F1: 0.0
Epoch:  162        8 Batch loss: 0.203832 Batch F1: 0.0
Epoch:  162        9 Batch loss: 0.229060 Batch F1: 0.0
Epoch:  162       10 Batch loss: 0.239951 Batch F1: 0.0
Epoch:  162       11 Batch loss: 0.220372 Batch F1: 0.0
Epoch:  162       12 Batch loss: 0.189530 Batch F1: 0.0
Train Avg Loss  162: 0.226977

Train Avg F1  162: 0.0

Val Avg Loss  162: 0.217510

Val Avg F1  162:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 163
--------------------------------------------------------------
Epoch:  163        1 Batch loss: 0.215536 Batch F1: 0.0
Epoch:  163        2 Batch loss: 0.219316 Batch F1: 0.0
Epoch:  163        3 Batch loss: 0.228139 Batch F1: 0.0
Epoch:  163        4 Batch loss: 0.217906 Batch F1: 0.0
Epoch:  163        5 Batch loss: 0.243631 Batch F1: 0.0
Epoch:  163        6 Batch loss: 0.248854 Batch F1: 0.0
Epoch:  163        7 Batch loss: 0.244254 Batch F1: 0.0
Epoch:  163        8 Batch loss: 0.213718 Batch F1: 0.0
Epoch:  163        9 Batch loss: 0.214145 Batch F1: 0.0
Epoch:  163       10 Batch loss: 0.218088 Batch F1: 0.0
Epoch:  163       11 Batch loss: 0.253928 Batch F1: 0.0
Epoch:  163       12 Batch loss: 0.217038 Batch F1: 0.0
Train Avg Loss  163: 0.227879

Train Avg F1  163: 0.0

Val Avg Loss  163: 0.217665

Val Avg F1  163:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 164
--------------------------------------------------------------
Epoch:  164        1 Batch loss: 0.220692 Batch F1: 0.0
Epoch:  164        2 Batch loss: 0.228468 Batch F1: 0.0
Epoch:  164        3 Batch loss: 0.215054 Batch F1: 0.0
Epoch:  164        4 Batch loss: 0.264525 Batch F1: 0.0
Epoch:  164        5 Batch loss: 0.232991 Batch F1: 0.0
Epoch:  164        6 Batch loss: 0.218282 Batch F1: 0.0
Epoch:  164        7 Batch loss: 0.207397 Batch F1: 0.0
Epoch:  164        8 Batch loss: 0.228391 Batch F1: 0.0
Epoch:  164        9 Batch loss: 0.231982 Batch F1: 0.0
Epoch:  164       10 Batch loss: 0.218465 Batch F1: 0.0
Epoch:  164       11 Batch loss: 0.214888 Batch F1: 0.0
Epoch:  164       12 Batch loss: 0.252252 Batch F1: 0.0
Train Avg Loss  164: 0.227782

Train Avg F1  164: 0.0

Val Avg Loss  164: 0.217526

Val Avg F1  164:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 165
--------------------------------------------------------------
Epoch:  165        1 Batch loss: 0.218509 Batch F1: 0.0
Epoch:  165        2 Batch loss: 0.236253 Batch F1: 0.0
Epoch:  165        3 Batch loss: 0.253781 Batch F1: 0.0
Epoch:  165        4 Batch loss: 0.211858 Batch F1: 0.0
Epoch:  165        5 Batch loss: 0.193423 Batch F1: 0.0
Epoch:  165        6 Batch loss: 0.211974 Batch F1: 0.0
Epoch:  165        7 Batch loss: 0.250514 Batch F1: 0.0
Epoch:  165        8 Batch loss: 0.254629 Batch F1: 0.0
Epoch:  165        9 Batch loss: 0.219637 Batch F1: 0.0
Epoch:  165       10 Batch loss: 0.215602 Batch F1: 0.0
Epoch:  165       11 Batch loss: 0.218470 Batch F1: 0.0
Epoch:  165       12 Batch loss: 0.247289 Batch F1: 0.0
Train Avg Loss  165: 0.227662

Train Avg F1  165: 0.0

Val Avg Loss  165: 0.217082

Val Avg F1  165:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 166
--------------------------------------------------------------
Epoch:  166        1 Batch loss: 0.216153 Batch F1: 0.0
Epoch:  166        2 Batch loss: 0.237683 Batch F1: 0.0
Epoch:  166        3 Batch loss: 0.240679 Batch F1: 0.0
Epoch:  166        4 Batch loss: 0.207760 Batch F1: 0.0
Epoch:  166        5 Batch loss: 0.222088 Batch F1: 0.0
Epoch:  166        6 Batch loss: 0.198669 Batch F1: 0.0
Epoch:  166        7 Batch loss: 0.238839 Batch F1: 0.0
Epoch:  166        8 Batch loss: 0.231998 Batch F1: 0.0
Epoch:  166        9 Batch loss: 0.265556 Batch F1: 0.0
Epoch:  166       10 Batch loss: 0.246574 Batch F1: 0.0
Epoch:  166       11 Batch loss: 0.199854 Batch F1: 0.0
Epoch:  166       12 Batch loss: 0.215109 Batch F1: 0.0
Train Avg Loss  166: 0.226747

Train Avg F1  166: 0.0

Val Avg Loss  166: 0.216831

Val Avg F1  166:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 167
--------------------------------------------------------------
Epoch:  167        1 Batch loss: 0.211144 Batch F1: 0.0
Epoch:  167        2 Batch loss: 0.220941 Batch F1: 0.0
Epoch:  167        3 Batch loss: 0.242520 Batch F1: 0.0
Epoch:  167        4 Batch loss: 0.182828 Batch F1: 0.0
Epoch:  167        5 Batch loss: 0.239996 Batch F1: 0.0
Epoch:  167        6 Batch loss: 0.231887 Batch F1: 0.0
Epoch:  167        7 Batch loss: 0.181437 Batch F1: 0.0
Epoch:  167        8 Batch loss: 0.225530 Batch F1: 0.0
Epoch:  167        9 Batch loss: 0.253353 Batch F1: 0.0
Epoch:  167       10 Batch loss: 0.261229 Batch F1: 0.0
Epoch:  167       11 Batch loss: 0.223519 Batch F1: 0.0
Epoch:  167       12 Batch loss: 0.253079 Batch F1: 0.0
Train Avg Loss  167: 0.227289

Train Avg F1  167: 0.0

Val Avg Loss  167: 0.220239

Val Avg F1  167:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 168
--------------------------------------------------------------
Epoch:  168        1 Batch loss: 0.231103 Batch F1: 0.0
Epoch:  168        2 Batch loss: 0.208264 Batch F1: 0.39999999999999997
Epoch:  168        3 Batch loss: 0.243042 Batch F1: 0.4
Epoch:  168        4 Batch loss: 0.223898 Batch F1: 0.2608695652173913
Epoch:  168        5 Batch loss: 0.216708 Batch F1: 0.0
Epoch:  168        6 Batch loss: 0.219353 Batch F1: 0.0
Epoch:  168        7 Batch loss: 0.226281 Batch F1: 0.0
Epoch:  168        8 Batch loss: 0.214355 Batch F1: 0.0
Epoch:  168        9 Batch loss: 0.229669 Batch F1: 0.0
Epoch:  168       10 Batch loss: 0.241713 Batch F1: 0.0
Epoch:  168       11 Batch loss: 0.248555 Batch F1: 0.0
Epoch:  168       12 Batch loss: 0.216608 Batch F1: 0.0
Train Avg Loss  168: 0.226629

Train Avg F1  168: 0.08840579710144929

Val Avg Loss  168: 0.216814

Val Avg F1  168:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 169
--------------------------------------------------------------
Epoch:  169        1 Batch loss: 0.195124 Batch F1: 0.0
Epoch:  169        2 Batch loss: 0.229522 Batch F1: 0.0
Epoch:  169        3 Batch loss: 0.223305 Batch F1: 0.0
Epoch:  169        4 Batch loss: 0.229823 Batch F1: 0.0
Epoch:  169        5 Batch loss: 0.221616 Batch F1: 0.0
Epoch:  169        6 Batch loss: 0.247596 Batch F1: 0.0
Epoch:  169        7 Batch loss: 0.226234 Batch F1: 0.0
Epoch:  169        8 Batch loss: 0.220593 Batch F1: 0.0
Epoch:  169        9 Batch loss: 0.252121 Batch F1: 0.0
Epoch:  169       10 Batch loss: 0.196046 Batch F1: 0.0
Epoch:  169       11 Batch loss: 0.247737 Batch F1: 0.0
Epoch:  169       12 Batch loss: 0.223239 Batch F1: 0.0
Train Avg Loss  169: 0.226080

Train Avg F1  169: 0.0

Val Avg Loss  169: 0.219016

Val Avg F1  169:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 170
--------------------------------------------------------------
Epoch:  170        1 Batch loss: 0.247347 Batch F1: 0.0
Epoch:  170        2 Batch loss: 0.221732 Batch F1: 0.0
Epoch:  170        3 Batch loss: 0.242801 Batch F1: 0.18181818181818182
Epoch:  170        4 Batch loss: 0.239305 Batch F1: 0.0
Epoch:  170        5 Batch loss: 0.229118 Batch F1: 0.0
Epoch:  170        6 Batch loss: 0.232248 Batch F1: 0.0
Epoch:  170        7 Batch loss: 0.237351 Batch F1: 0.0
Epoch:  170        8 Batch loss: 0.212680 Batch F1: 0.0
Epoch:  170        9 Batch loss: 0.221263 Batch F1: 0.0
Epoch:  170       10 Batch loss: 0.199675 Batch F1: 0.0
Epoch:  170       11 Batch loss: 0.228800 Batch F1: 0.0
Epoch:  170       12 Batch loss: 0.197257 Batch F1: 0.0
Train Avg Loss  170: 0.225798

Train Avg F1  170: 0.015151515151515152

Val Avg Loss  170: 0.216676

Val Avg F1  170:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 171
--------------------------------------------------------------
Epoch:  171        1 Batch loss: 0.238403 Batch F1: 0.0
Epoch:  171        2 Batch loss: 0.223382 Batch F1: 0.0
Epoch:  171        3 Batch loss: 0.210467 Batch F1: 0.0
Epoch:  171        4 Batch loss: 0.220438 Batch F1: 0.0
Epoch:  171        5 Batch loss: 0.227304 Batch F1: 0.0
Epoch:  171        6 Batch loss: 0.240765 Batch F1: 0.0
Epoch:  171        7 Batch loss: 0.180918 Batch F1: 0.0
Epoch:  171        8 Batch loss: 0.242064 Batch F1: 0.0
Epoch:  171        9 Batch loss: 0.241942 Batch F1: 0.0
Epoch:  171       10 Batch loss: 0.219728 Batch F1: 0.0
Epoch:  171       11 Batch loss: 0.225174 Batch F1: 0.0
Epoch:  171       12 Batch loss: 0.246599 Batch F1: 0.0
Train Avg Loss  171: 0.226432

Train Avg F1  171: 0.0

Val Avg Loss  171: 0.216783

Val Avg F1  171:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 172
--------------------------------------------------------------
Epoch:  172        1 Batch loss: 0.235402 Batch F1: 0.0
Epoch:  172        2 Batch loss: 0.177771 Batch F1: 0.0
Epoch:  172        3 Batch loss: 0.213104 Batch F1: 0.0
Epoch:  172        4 Batch loss: 0.246819 Batch F1: 0.0
Epoch:  172        5 Batch loss: 0.221449 Batch F1: 0.0
Epoch:  172        6 Batch loss: 0.209746 Batch F1: 0.0
Epoch:  172        7 Batch loss: 0.218997 Batch F1: 0.0
Epoch:  172        8 Batch loss: 0.211973 Batch F1: 0.0
Epoch:  172        9 Batch loss: 0.254180 Batch F1: 0.0
Epoch:  172       10 Batch loss: 0.226225 Batch F1: 0.0
Epoch:  172       11 Batch loss: 0.246412 Batch F1: 0.0
Epoch:  172       12 Batch loss: 0.261250 Batch F1: 0.0
Train Avg Loss  172: 0.226944

Train Avg F1  172: 0.0

Val Avg Loss  172: 0.219487

Val Avg F1  172:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 173
--------------------------------------------------------------
Epoch:  173        1 Batch loss: 0.201438 Batch F1: 0.0
Epoch:  173        2 Batch loss: 0.249458 Batch F1: 0.0
Epoch:  173        3 Batch loss: 0.235102 Batch F1: 0.0
Epoch:  173        4 Batch loss: 0.235476 Batch F1: 0.0
Epoch:  173        5 Batch loss: 0.239031 Batch F1: 0.0
Epoch:  173        6 Batch loss: 0.229002 Batch F1: 0.0
Epoch:  173        7 Batch loss: 0.199220 Batch F1: 0.0
Epoch:  173        8 Batch loss: 0.218741 Batch F1: 0.0
Epoch:  173        9 Batch loss: 0.221545 Batch F1: 0.0
Epoch:  173       10 Batch loss: 0.260919 Batch F1: 0.0
Epoch:  173       11 Batch loss: 0.243798 Batch F1: 0.0
Epoch:  173       12 Batch loss: 0.210544 Batch F1: 0.0
Train Avg Loss  173: 0.228689

Train Avg F1  173: 0.0

Val Avg Loss  173: 0.218562

Val Avg F1  173:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 174
--------------------------------------------------------------
Epoch:  174        1 Batch loss: 0.239713 Batch F1: 0.0
Epoch:  174        2 Batch loss: 0.198253 Batch F1: 0.0
Epoch:  174        3 Batch loss: 0.227774 Batch F1: 0.0
Epoch:  174        4 Batch loss: 0.230983 Batch F1: 0.0
Epoch:  174        5 Batch loss: 0.202730 Batch F1: 0.0
Epoch:  174        6 Batch loss: 0.216681 Batch F1: 0.0
Epoch:  174        7 Batch loss: 0.204110 Batch F1: 0.0
Epoch:  174        8 Batch loss: 0.272840 Batch F1: 0.0
Epoch:  174        9 Batch loss: 0.237295 Batch F1: 0.0
Epoch:  174       10 Batch loss: 0.221286 Batch F1: 0.0
Epoch:  174       11 Batch loss: 0.267577 Batch F1: 0.0
Epoch:  174       12 Batch loss: 0.213495 Batch F1: 0.0
Train Avg Loss  174: 0.227728

Train Avg F1  174: 0.0

Val Avg Loss  174: 0.220914

Val Avg F1  174:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 175
--------------------------------------------------------------
Epoch:  175        1 Batch loss: 0.228766 Batch F1: 0.0
Epoch:  175        2 Batch loss: 0.230763 Batch F1: 0.4444444444444444
Epoch:  175        3 Batch loss: 0.211298 Batch F1: 0.11764705882352941
Epoch:  175        4 Batch loss: 0.240978 Batch F1: 0.0
Epoch:  175        5 Batch loss: 0.212430 Batch F1: 0.0
Epoch:  175        6 Batch loss: 0.255812 Batch F1: 0.0
Epoch:  175        7 Batch loss: 0.238179 Batch F1: 0.0
Epoch:  175        8 Batch loss: 0.210124 Batch F1: 0.0
Epoch:  175        9 Batch loss: 0.216678 Batch F1: 0.0
Epoch:  175       10 Batch loss: 0.215125 Batch F1: 0.0
Epoch:  175       11 Batch loss: 0.242890 Batch F1: 0.0
Epoch:  175       12 Batch loss: 0.247307 Batch F1: 0.0
Train Avg Loss  175: 0.229196

Train Avg F1  175: 0.046840958605664486

Val Avg Loss  175: 0.217945

Val Avg F1  175:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 176
--------------------------------------------------------------
Epoch:  176        1 Batch loss: 0.248300 Batch F1: 0.0
Epoch:  176        2 Batch loss: 0.235759 Batch F1: 0.0
Epoch:  176        3 Batch loss: 0.224375 Batch F1: 0.0
Epoch:  176        4 Batch loss: 0.220988 Batch F1: 0.0
Epoch:  176        5 Batch loss: 0.237682 Batch F1: 0.0
Epoch:  176        6 Batch loss: 0.220478 Batch F1: 0.0
Epoch:  176        7 Batch loss: 0.211849 Batch F1: 0.0
Epoch:  176        8 Batch loss: 0.216719 Batch F1: 0.0
Epoch:  176        9 Batch loss: 0.214727 Batch F1: 0.0
Epoch:  176       10 Batch loss: 0.217878 Batch F1: 0.0
Epoch:  176       11 Batch loss: 0.256149 Batch F1: 0.0
Epoch:  176       12 Batch loss: 0.229087 Batch F1: 0.0
Train Avg Loss  176: 0.227833

Train Avg F1  176: 0.0

Val Avg Loss  176: 0.217355

Val Avg F1  176:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 177
--------------------------------------------------------------
Epoch:  177        1 Batch loss: 0.223596 Batch F1: 0.0
Epoch:  177        2 Batch loss: 0.204371 Batch F1: 0.0
Epoch:  177        3 Batch loss: 0.204228 Batch F1: 0.0
Epoch:  177        4 Batch loss: 0.246198 Batch F1: 0.0
Epoch:  177        5 Batch loss: 0.205498 Batch F1: 0.0
Epoch:  177        6 Batch loss: 0.241420 Batch F1: 0.0
Epoch:  177        7 Batch loss: 0.241349 Batch F1: 0.0
Epoch:  177        8 Batch loss: 0.218096 Batch F1: 0.0
Epoch:  177        9 Batch loss: 0.251886 Batch F1: 0.0
Epoch:  177       10 Batch loss: 0.233339 Batch F1: 0.0
Epoch:  177       11 Batch loss: 0.233309 Batch F1: 0.0
Epoch:  177       12 Batch loss: 0.221750 Batch F1: 0.0
Train Avg Loss  177: 0.227087

Train Avg F1  177: 0.0

Val Avg Loss  177: 0.221432

Val Avg F1  177:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 178
--------------------------------------------------------------
Epoch:  178        1 Batch loss: 0.239420 Batch F1: 0.0
Epoch:  178        2 Batch loss: 0.235488 Batch F1: 0.0
Epoch:  178        3 Batch loss: 0.224887 Batch F1: 0.0
Epoch:  178        4 Batch loss: 0.200945 Batch F1: 0.0
Epoch:  178        5 Batch loss: 0.233768 Batch F1: 0.0
Epoch:  178        6 Batch loss: 0.255086 Batch F1: 0.0
Epoch:  178        7 Batch loss: 0.246655 Batch F1: 0.0
Epoch:  178        8 Batch loss: 0.227855 Batch F1: 0.0
Epoch:  178        9 Batch loss: 0.220663 Batch F1: 0.0
Epoch:  178       10 Batch loss: 0.213720 Batch F1: 0.0
Epoch:  178       11 Batch loss: 0.222381 Batch F1: 0.0
Epoch:  178       12 Batch loss: 0.212809 Batch F1: 0.0
Train Avg Loss  178: 0.227806

Train Avg F1  178: 0.0

Val Avg Loss  178: 0.217696

Val Avg F1  178:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 179
--------------------------------------------------------------
Epoch:  179        1 Batch loss: 0.207718 Batch F1: 0.0
Epoch:  179        2 Batch loss: 0.215751 Batch F1: 0.0
Epoch:  179        3 Batch loss: 0.216469 Batch F1: 0.0
Epoch:  179        4 Batch loss: 0.233152 Batch F1: 0.0
Epoch:  179        5 Batch loss: 0.208105 Batch F1: 0.0
Epoch:  179        6 Batch loss: 0.232631 Batch F1: 0.0
Epoch:  179        7 Batch loss: 0.266007 Batch F1: 0.0
Epoch:  179        8 Batch loss: 0.237529 Batch F1: 0.0
Epoch:  179        9 Batch loss: 0.202898 Batch F1: 0.0
Epoch:  179       10 Batch loss: 0.220095 Batch F1: 0.0
Epoch:  179       11 Batch loss: 0.248806 Batch F1: 0.0
Epoch:  179       12 Batch loss: 0.230402 Batch F1: 0.0
Train Avg Loss  179: 0.226630

Train Avg F1  179: 0.0

Val Avg Loss  179: 0.218710

Val Avg F1  179:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 180
--------------------------------------------------------------
Epoch:  180        1 Batch loss: 0.225722 Batch F1: 0.0
Epoch:  180        2 Batch loss: 0.235434 Batch F1: 0.0
Epoch:  180        3 Batch loss: 0.223808 Batch F1: 0.0
Epoch:  180        4 Batch loss: 0.233073 Batch F1: 0.0
Epoch:  180        5 Batch loss: 0.208676 Batch F1: 0.0
Epoch:  180        6 Batch loss: 0.217992 Batch F1: 0.0
Epoch:  180        7 Batch loss: 0.268257 Batch F1: 0.0
Epoch:  180        8 Batch loss: 0.224608 Batch F1: 0.0
Epoch:  180        9 Batch loss: 0.225222 Batch F1: 0.0
Epoch:  180       10 Batch loss: 0.201044 Batch F1: 0.0
Epoch:  180       11 Batch loss: 0.238612 Batch F1: 0.0
Epoch:  180       12 Batch loss: 0.216310 Batch F1: 0.0
Train Avg Loss  180: 0.226563

Train Avg F1  180: 0.0

Val Avg Loss  180: 0.216584

Val Avg F1  180:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 181
--------------------------------------------------------------
Epoch:  181        1 Batch loss: 0.223948 Batch F1: 0.0
Epoch:  181        2 Batch loss: 0.236231 Batch F1: 0.0
Epoch:  181        3 Batch loss: 0.226559 Batch F1: 0.0
Epoch:  181        4 Batch loss: 0.230486 Batch F1: 0.0
Epoch:  181        5 Batch loss: 0.218120 Batch F1: 0.0
Epoch:  181        6 Batch loss: 0.245155 Batch F1: 0.0
Epoch:  181        7 Batch loss: 0.242624 Batch F1: 0.0
Epoch:  181        8 Batch loss: 0.232529 Batch F1: 0.0
Epoch:  181        9 Batch loss: 0.206893 Batch F1: 0.0
Epoch:  181       10 Batch loss: 0.205114 Batch F1: 0.0
Epoch:  181       11 Batch loss: 0.222062 Batch F1: 0.0
Epoch:  181       12 Batch loss: 0.221640 Batch F1: 0.0
Train Avg Loss  181: 0.225947

Train Avg F1  181: 0.0

Val Avg Loss  181: 0.216808

Val Avg F1  181:  0.0

Optimal Val loss (Epoch 140): 0.21645144745707512

Epoch 182
--------------------------------------------------------------
Epoch:  182        1 Batch loss: 0.209457 Batch F1: 0.0
Epoch:  182        2 Batch loss: 0.216697 Batch F1: 0.0
Epoch:  182        3 Batch loss: 0.229911 Batch F1: 0.0
Epoch:  182        4 Batch loss: 0.252344 Batch F1: 0.0
Epoch:  182        5 Batch loss: 0.246613 Batch F1: 0.0
Epoch:  182        6 Batch loss: 0.191036 Batch F1: 0.0
Epoch:  182        7 Batch loss: 0.252965 Batch F1: 0.0
Epoch:  182        8 Batch loss: 0.203182 Batch F1: 0.0
Epoch:  182        9 Batch loss: 0.227877 Batch F1: 0.0
Epoch:  182       10 Batch loss: 0.208892 Batch F1: 0.0
Epoch:  182       11 Batch loss: 0.233283 Batch F1: 0.0
Epoch:  182       12 Batch loss: 0.245648 Batch F1: 0.0
Train Avg Loss  182: 0.226492

Train Avg F1  182: 0.0

Val Avg Loss  182: 0.215907

Val Avg F1  182:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 183
--------------------------------------------------------------
Epoch:  183        1 Batch loss: 0.188501 Batch F1: 0.0
Epoch:  183        2 Batch loss: 0.241700 Batch F1: 0.0
Epoch:  183        3 Batch loss: 0.227729 Batch F1: 0.0
Epoch:  183        4 Batch loss: 0.250775 Batch F1: 0.0
Epoch:  183        5 Batch loss: 0.226126 Batch F1: 0.0
Epoch:  183        6 Batch loss: 0.234119 Batch F1: 0.0
Epoch:  183        7 Batch loss: 0.206058 Batch F1: 0.0
Epoch:  183        8 Batch loss: 0.217254 Batch F1: 0.0
Epoch:  183        9 Batch loss: 0.209999 Batch F1: 0.0
Epoch:  183       10 Batch loss: 0.232059 Batch F1: 0.0
Epoch:  183       11 Batch loss: 0.269616 Batch F1: 0.0
Epoch:  183       12 Batch loss: 0.227186 Batch F1: 0.0
Train Avg Loss  183: 0.227594

Train Avg F1  183: 0.0

Val Avg Loss  183: 0.218318

Val Avg F1  183:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 184
--------------------------------------------------------------
Epoch:  184        1 Batch loss: 0.239032 Batch F1: 0.0
Epoch:  184        2 Batch loss: 0.243176 Batch F1: 0.0
Epoch:  184        3 Batch loss: 0.238596 Batch F1: 0.0
Epoch:  184        4 Batch loss: 0.202937 Batch F1: 0.4
Epoch:  184        5 Batch loss: 0.223344 Batch F1: 0.4137931034482759
Epoch:  184        6 Batch loss: 0.230850 Batch F1: 0.21428571428571427
Epoch:  184        7 Batch loss: 0.219174 Batch F1: 0.5
Epoch:  184        8 Batch loss: 0.217407 Batch F1: 0.17391304347826086
Epoch:  184        9 Batch loss: 0.212123 Batch F1: 0.0
Epoch:  184       10 Batch loss: 0.259891 Batch F1: 0.0
Epoch:  184       11 Batch loss: 0.211326 Batch F1: 0.0
Epoch:  184       12 Batch loss: 0.248461 Batch F1: 0.0
Train Avg Loss  184: 0.228860

Train Avg F1  184: 0.14183265510102092

Val Avg Loss  184: 0.218264

Val Avg F1  184:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 185
--------------------------------------------------------------
Epoch:  185        1 Batch loss: 0.200675 Batch F1: 0.0
Epoch:  185        2 Batch loss: 0.253623 Batch F1: 0.0
Epoch:  185        3 Batch loss: 0.230098 Batch F1: 0.0
Epoch:  185        4 Batch loss: 0.223978 Batch F1: 0.0
Epoch:  185        5 Batch loss: 0.234059 Batch F1: 0.0
Epoch:  185        6 Batch loss: 0.233334 Batch F1: 0.0
Epoch:  185        7 Batch loss: 0.204288 Batch F1: 0.0
Epoch:  185        8 Batch loss: 0.217106 Batch F1: 0.0
Epoch:  185        9 Batch loss: 0.245798 Batch F1: 0.0
Epoch:  185       10 Batch loss: 0.237552 Batch F1: 0.0
Epoch:  185       11 Batch loss: 0.222525 Batch F1: 0.0
Epoch:  185       12 Batch loss: 0.218626 Batch F1: 0.0
Train Avg Loss  185: 0.226805

Train Avg F1  185: 0.0

Val Avg Loss  185: 0.217506

Val Avg F1  185:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 186
--------------------------------------------------------------
Epoch:  186        1 Batch loss: 0.202299 Batch F1: 0.0
Epoch:  186        2 Batch loss: 0.253810 Batch F1: 0.0
Epoch:  186        3 Batch loss: 0.234304 Batch F1: 0.0
Epoch:  186        4 Batch loss: 0.223282 Batch F1: 0.0
Epoch:  186        5 Batch loss: 0.222488 Batch F1: 0.0
Epoch:  186        6 Batch loss: 0.239224 Batch F1: 0.0
Epoch:  186        7 Batch loss: 0.219849 Batch F1: 0.0
Epoch:  186        8 Batch loss: 0.191520 Batch F1: 0.0
Epoch:  186        9 Batch loss: 0.201286 Batch F1: 0.0
Epoch:  186       10 Batch loss: 0.256166 Batch F1: 0.0
Epoch:  186       11 Batch loss: 0.243603 Batch F1: 0.0
Epoch:  186       12 Batch loss: 0.230150 Batch F1: 0.0
Train Avg Loss  186: 0.226498

Train Avg F1  186: 0.0

Val Avg Loss  186: 0.217632

Val Avg F1  186:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 187
--------------------------------------------------------------
Epoch:  187        1 Batch loss: 0.218321 Batch F1: 0.0
Epoch:  187        2 Batch loss: 0.221356 Batch F1: 0.0
Epoch:  187        3 Batch loss: 0.226693 Batch F1: 0.0
Epoch:  187        4 Batch loss: 0.235107 Batch F1: 0.0
Epoch:  187        5 Batch loss: 0.244577 Batch F1: 0.0
Epoch:  187        6 Batch loss: 0.233574 Batch F1: 0.0
Epoch:  187        7 Batch loss: 0.199102 Batch F1: 0.0
Epoch:  187        8 Batch loss: 0.237622 Batch F1: 0.0
Epoch:  187        9 Batch loss: 0.223145 Batch F1: 0.0
Epoch:  187       10 Batch loss: 0.194636 Batch F1: 0.0
Epoch:  187       11 Batch loss: 0.254868 Batch F1: 0.0
Epoch:  187       12 Batch loss: 0.217074 Batch F1: 0.0
Train Avg Loss  187: 0.225506

Train Avg F1  187: 0.0

Val Avg Loss  187: 0.218246

Val Avg F1  187:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 188
--------------------------------------------------------------
Epoch:  188        1 Batch loss: 0.218113 Batch F1: 0.0
Epoch:  188        2 Batch loss: 0.222719 Batch F1: 0.0
Epoch:  188        3 Batch loss: 0.194206 Batch F1: 0.0
Epoch:  188        4 Batch loss: 0.204679 Batch F1: 0.0
Epoch:  188        5 Batch loss: 0.209178 Batch F1: 0.0
Epoch:  188        6 Batch loss: 0.235502 Batch F1: 0.0
Epoch:  188        7 Batch loss: 0.241526 Batch F1: 0.0
Epoch:  188        8 Batch loss: 0.247899 Batch F1: 0.0
Epoch:  188        9 Batch loss: 0.241965 Batch F1: 0.0
Epoch:  188       10 Batch loss: 0.247668 Batch F1: 0.0
Epoch:  188       11 Batch loss: 0.224300 Batch F1: 0.0
Epoch:  188       12 Batch loss: 0.227767 Batch F1: 0.0
Train Avg Loss  188: 0.226293

Train Avg F1  188: 0.0

Val Avg Loss  188: 0.218772

Val Avg F1  188:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 189
--------------------------------------------------------------
Epoch:  189        1 Batch loss: 0.227500 Batch F1: 0.0
Epoch:  189        2 Batch loss: 0.254846 Batch F1: 0.0
Epoch:  189        3 Batch loss: 0.227341 Batch F1: 0.0
Epoch:  189        4 Batch loss: 0.222979 Batch F1: 0.0
Epoch:  189        5 Batch loss: 0.202972 Batch F1: 0.0
Epoch:  189        6 Batch loss: 0.205958 Batch F1: 0.0
Epoch:  189        7 Batch loss: 0.237510 Batch F1: 0.0
Epoch:  189        8 Batch loss: 0.256755 Batch F1: 0.0
Epoch:  189        9 Batch loss: 0.216082 Batch F1: 0.0
Epoch:  189       10 Batch loss: 0.231352 Batch F1: 0.0
Epoch:  189       11 Batch loss: 0.231114 Batch F1: 0.0
Epoch:  189       12 Batch loss: 0.218956 Batch F1: 0.0
Train Avg Loss  189: 0.227780

Train Avg F1  189: 0.0

Val Avg Loss  189: 0.218886

Val Avg F1  189:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 190
--------------------------------------------------------------
Epoch:  190        1 Batch loss: 0.229237 Batch F1: 0.0
Epoch:  190        2 Batch loss: 0.235682 Batch F1: 0.0
Epoch:  190        3 Batch loss: 0.206860 Batch F1: 0.0
Epoch:  190        4 Batch loss: 0.211113 Batch F1: 0.0
Epoch:  190        5 Batch loss: 0.204075 Batch F1: 0.0
Epoch:  190        6 Batch loss: 0.262822 Batch F1: 0.0
Epoch:  190        7 Batch loss: 0.227609 Batch F1: 0.0
Epoch:  190        8 Batch loss: 0.215825 Batch F1: 0.0
Epoch:  190        9 Batch loss: 0.245654 Batch F1: 0.0
Epoch:  190       10 Batch loss: 0.224996 Batch F1: 0.0
Epoch:  190       11 Batch loss: 0.236916 Batch F1: 0.0
Epoch:  190       12 Batch loss: 0.230539 Batch F1: 0.0
Train Avg Loss  190: 0.227611

Train Avg F1  190: 0.0

Val Avg Loss  190: 0.219684

Val Avg F1  190:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 191
--------------------------------------------------------------
Epoch:  191        1 Batch loss: 0.180952 Batch F1: 0.0
Epoch:  191        2 Batch loss: 0.232521 Batch F1: 0.0
Epoch:  191        3 Batch loss: 0.255507 Batch F1: 0.0
Epoch:  191        4 Batch loss: 0.245549 Batch F1: 0.0
Epoch:  191        5 Batch loss: 0.251724 Batch F1: 0.0
Epoch:  191        6 Batch loss: 0.213659 Batch F1: 0.0
Epoch:  191        7 Batch loss: 0.226033 Batch F1: 0.0
Epoch:  191        8 Batch loss: 0.230298 Batch F1: 0.0
Epoch:  191        9 Batch loss: 0.221433 Batch F1: 0.0
Epoch:  191       10 Batch loss: 0.236945 Batch F1: 0.0
Epoch:  191       11 Batch loss: 0.212836 Batch F1: 0.0
Epoch:  191       12 Batch loss: 0.216902 Batch F1: 0.0
Train Avg Loss  191: 0.227030

Train Avg F1  191: 0.0

Val Avg Loss  191: 0.218180

Val Avg F1  191:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 192
--------------------------------------------------------------
Epoch:  192        1 Batch loss: 0.268694 Batch F1: 0.0
Epoch:  192        2 Batch loss: 0.245006 Batch F1: 0.0
Epoch:  192        3 Batch loss: 0.226075 Batch F1: 0.2962962962962963
Epoch:  192        4 Batch loss: 0.222089 Batch F1: 0.31578947368421056
Epoch:  192        5 Batch loss: 0.207248 Batch F1: 0.1111111111111111
Epoch:  192        6 Batch loss: 0.224553 Batch F1: 0.0
Epoch:  192        7 Batch loss: 0.218269 Batch F1: 0.0
Epoch:  192        8 Batch loss: 0.224445 Batch F1: 0.0
Epoch:  192        9 Batch loss: 0.203400 Batch F1: 0.0
Epoch:  192       10 Batch loss: 0.263501 Batch F1: 0.0
Epoch:  192       11 Batch loss: 0.211709 Batch F1: 0.0
Epoch:  192       12 Batch loss: 0.223852 Batch F1: 0.0
Train Avg Loss  192: 0.228237

Train Avg F1  192: 0.06026640675763484

Val Avg Loss  192: 0.219133

Val Avg F1  192:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 193
--------------------------------------------------------------
Epoch:  193        1 Batch loss: 0.227570 Batch F1: 0.0
Epoch:  193        2 Batch loss: 0.235457 Batch F1: 0.0
Epoch:  193        3 Batch loss: 0.255390 Batch F1: 0.0
Epoch:  193        4 Batch loss: 0.253119 Batch F1: 0.24000000000000002
Epoch:  193        5 Batch loss: 0.203523 Batch F1: 0.3333333333333333
Epoch:  193        6 Batch loss: 0.202313 Batch F1: 0.12500000000000003
Epoch:  193        7 Batch loss: 0.206649 Batch F1: 0.0
Epoch:  193        8 Batch loss: 0.227046 Batch F1: 0.0
Epoch:  193        9 Batch loss: 0.239300 Batch F1: 0.0
Epoch:  193       10 Batch loss: 0.202963 Batch F1: 0.0
Epoch:  193       11 Batch loss: 0.225009 Batch F1: 0.0
Epoch:  193       12 Batch loss: 0.281360 Batch F1: 0.0
Train Avg Loss  193: 0.229975

Train Avg F1  193: 0.058194444444444444

Val Avg Loss  193: 0.221166

Val Avg F1  193:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 194
--------------------------------------------------------------
Epoch:  194        1 Batch loss: 0.214389 Batch F1: 0.0
Epoch:  194        2 Batch loss: 0.223595 Batch F1: 0.0
Epoch:  194        3 Batch loss: 0.230675 Batch F1: 0.0
Epoch:  194        4 Batch loss: 0.240310 Batch F1: 0.0
Epoch:  194        5 Batch loss: 0.224871 Batch F1: 0.45161290322580644
Epoch:  194        6 Batch loss: 0.247974 Batch F1: 0.23076923076923075
Epoch:  194        7 Batch loss: 0.250122 Batch F1: 0.4117647058823529
Epoch:  194        8 Batch loss: 0.228996 Batch F1: 0.1
Epoch:  194        9 Batch loss: 0.236204 Batch F1: 0.25
Epoch:  194       10 Batch loss: 0.212343 Batch F1: 0.0
Epoch:  194       11 Batch loss: 0.202301 Batch F1: 0.0
Epoch:  194       12 Batch loss: 0.232997 Batch F1: 0.0
Train Avg Loss  194: 0.228731

Train Avg F1  194: 0.12034556998978252

Val Avg Loss  194: 0.220946

Val Avg F1  194:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 195
--------------------------------------------------------------
Epoch:  195        1 Batch loss: 0.281744 Batch F1: 0.0
Epoch:  195        2 Batch loss: 0.273050 Batch F1: 0.0
Epoch:  195        3 Batch loss: 0.266897 Batch F1: 0.0
Epoch:  195        4 Batch loss: 0.234801 Batch F1: 0.0
Epoch:  195        5 Batch loss: 0.241951 Batch F1: 0.0
Epoch:  195        6 Batch loss: 0.233103 Batch F1: 0.0
Epoch:  195        7 Batch loss: 0.236012 Batch F1: 0.0
Epoch:  195        8 Batch loss: 0.233408 Batch F1: 0.0
Epoch:  195        9 Batch loss: 0.216312 Batch F1: 0.0
Epoch:  195       10 Batch loss: 0.175239 Batch F1: 0.0
Epoch:  195       11 Batch loss: 0.207528 Batch F1: 0.0
Epoch:  195       12 Batch loss: 0.250691 Batch F1: 0.0
Train Avg Loss  195: 0.237561

Train Avg F1  195: 0.0

Val Avg Loss  195: 0.224007

Val Avg F1  195:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 196
--------------------------------------------------------------
Epoch:  196        1 Batch loss: 0.181598 Batch F1: 0.0
Epoch:  196        2 Batch loss: 0.238942 Batch F1: 0.0
Epoch:  196        3 Batch loss: 0.209055 Batch F1: 0.0
Epoch:  196        4 Batch loss: 0.199886 Batch F1: 0.0
Epoch:  196        5 Batch loss: 0.293807 Batch F1: 0.0
Epoch:  196        6 Batch loss: 0.265344 Batch F1: 0.0
Epoch:  196        7 Batch loss: 0.232855 Batch F1: 0.0
Epoch:  196        8 Batch loss: 0.234774 Batch F1: 0.0
Epoch:  196        9 Batch loss: 0.241995 Batch F1: 0.0
Epoch:  196       10 Batch loss: 0.217451 Batch F1: 0.0
Epoch:  196       11 Batch loss: 0.264453 Batch F1: 0.0
Epoch:  196       12 Batch loss: 0.242511 Batch F1: 0.0
Train Avg Loss  196: 0.235223

Train Avg F1  196: 0.0

Val Avg Loss  196: 0.218945

Val Avg F1  196:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 197
--------------------------------------------------------------
Epoch:  197        1 Batch loss: 0.231993 Batch F1: 0.0
Epoch:  197        2 Batch loss: 0.249155 Batch F1: 0.0
Epoch:  197        3 Batch loss: 0.226151 Batch F1: 0.0
Epoch:  197        4 Batch loss: 0.234560 Batch F1: 0.0
Epoch:  197        5 Batch loss: 0.233106 Batch F1: 0.0
Epoch:  197        6 Batch loss: 0.215010 Batch F1: 0.0
Epoch:  197        7 Batch loss: 0.216991 Batch F1: 0.0
Epoch:  197        8 Batch loss: 0.236161 Batch F1: 0.0
Epoch:  197        9 Batch loss: 0.238863 Batch F1: 0.0
Epoch:  197       10 Batch loss: 0.206364 Batch F1: 0.0
Epoch:  197       11 Batch loss: 0.232201 Batch F1: 0.0
Epoch:  197       12 Batch loss: 0.233729 Batch F1: 0.0
Train Avg Loss  197: 0.229524

Train Avg F1  197: 0.0

Val Avg Loss  197: 0.218165

Val Avg F1  197:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 198
--------------------------------------------------------------
Epoch:  198        1 Batch loss: 0.189042 Batch F1: 0.0
Epoch:  198        2 Batch loss: 0.239334 Batch F1: 0.0
Epoch:  198        3 Batch loss: 0.210412 Batch F1: 0.0
Epoch:  198        4 Batch loss: 0.235333 Batch F1: 0.0
Epoch:  198        5 Batch loss: 0.237521 Batch F1: 0.0
Epoch:  198        6 Batch loss: 0.241510 Batch F1: 0.0
Epoch:  198        7 Batch loss: 0.227430 Batch F1: 0.0
Epoch:  198        8 Batch loss: 0.234031 Batch F1: 0.0
Epoch:  198        9 Batch loss: 0.231449 Batch F1: 0.0
Epoch:  198       10 Batch loss: 0.215196 Batch F1: 0.0
Epoch:  198       11 Batch loss: 0.232347 Batch F1: 0.0
Epoch:  198       12 Batch loss: 0.242130 Batch F1: 0.0
Train Avg Loss  198: 0.227978

Train Avg F1  198: 0.0

Val Avg Loss  198: 0.219661

Val Avg F1  198:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 199
--------------------------------------------------------------
Epoch:  199        1 Batch loss: 0.219068 Batch F1: 0.0
Epoch:  199        2 Batch loss: 0.210338 Batch F1: 0.0
Epoch:  199        3 Batch loss: 0.227514 Batch F1: 0.0
Epoch:  199        4 Batch loss: 0.222312 Batch F1: 0.0
Epoch:  199        5 Batch loss: 0.220698 Batch F1: 0.0
Epoch:  199        6 Batch loss: 0.223911 Batch F1: 0.0
Epoch:  199        7 Batch loss: 0.238473 Batch F1: 0.0
Epoch:  199        8 Batch loss: 0.245328 Batch F1: 0.0
Epoch:  199        9 Batch loss: 0.229269 Batch F1: 0.0
Epoch:  199       10 Batch loss: 0.227423 Batch F1: 0.0
Epoch:  199       11 Batch loss: 0.267176 Batch F1: 0.0
Epoch:  199       12 Batch loss: 0.218747 Batch F1: 0.0
Train Avg Loss  199: 0.229188

Train Avg F1  199: 0.0

Val Avg Loss  199: 0.219259

Val Avg F1  199:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 200
--------------------------------------------------------------
Epoch:  200        1 Batch loss: 0.217793 Batch F1: 0.0
Epoch:  200        2 Batch loss: 0.271679 Batch F1: 0.0
Epoch:  200        3 Batch loss: 0.239279 Batch F1: 0.0
Epoch:  200        4 Batch loss: 0.223801 Batch F1: 0.0
Epoch:  200        5 Batch loss: 0.219437 Batch F1: 0.0
Epoch:  200        6 Batch loss: 0.200755 Batch F1: 0.0
Epoch:  200        7 Batch loss: 0.225467 Batch F1: 0.0
Epoch:  200        8 Batch loss: 0.250012 Batch F1: 0.0
Epoch:  200        9 Batch loss: 0.196567 Batch F1: 0.0
Epoch:  200       10 Batch loss: 0.202845 Batch F1: 0.0
Epoch:  200       11 Batch loss: 0.260407 Batch F1: 0.0
Epoch:  200       12 Batch loss: 0.243035 Batch F1: 0.0
Train Avg Loss  200: 0.229256

Train Avg F1  200: 0.0

Val Avg Loss  200: 0.217628

Val Avg F1  200:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 201
--------------------------------------------------------------
Epoch:  201        1 Batch loss: 0.241583 Batch F1: 0.0
Epoch:  201        2 Batch loss: 0.252994 Batch F1: 0.0
Epoch:  201        3 Batch loss: 0.195309 Batch F1: 0.0
Epoch:  201        4 Batch loss: 0.223533 Batch F1: 0.0
Epoch:  201        5 Batch loss: 0.235005 Batch F1: 0.0
Epoch:  201        6 Batch loss: 0.239330 Batch F1: 0.0
Epoch:  201        7 Batch loss: 0.238529 Batch F1: 0.0
Epoch:  201        8 Batch loss: 0.208317 Batch F1: 0.0
Epoch:  201        9 Batch loss: 0.228616 Batch F1: 0.0
Epoch:  201       10 Batch loss: 0.199672 Batch F1: 0.0
Epoch:  201       11 Batch loss: 0.235012 Batch F1: 0.0
Epoch:  201       12 Batch loss: 0.246670 Batch F1: 0.0
Train Avg Loss  201: 0.228714

Train Avg F1  201: 0.0

Val Avg Loss  201: 0.217862

Val Avg F1  201:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 202
--------------------------------------------------------------
Epoch:  202        1 Batch loss: 0.235277 Batch F1: 0.0
Epoch:  202        2 Batch loss: 0.257918 Batch F1: 0.0
Epoch:  202        3 Batch loss: 0.251364 Batch F1: 0.0
Epoch:  202        4 Batch loss: 0.213664 Batch F1: 0.0
Epoch:  202        5 Batch loss: 0.243636 Batch F1: 0.0
Epoch:  202        6 Batch loss: 0.227623 Batch F1: 0.0
Epoch:  202        7 Batch loss: 0.222615 Batch F1: 0.0
Epoch:  202        8 Batch loss: 0.227069 Batch F1: 0.0
Epoch:  202        9 Batch loss: 0.200338 Batch F1: 0.0
Epoch:  202       10 Batch loss: 0.201813 Batch F1: 0.0
Epoch:  202       11 Batch loss: 0.229528 Batch F1: 0.0
Epoch:  202       12 Batch loss: 0.244785 Batch F1: 0.0
Train Avg Loss  202: 0.229636

Train Avg F1  202: 0.0

Val Avg Loss  202: 0.218121

Val Avg F1  202:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 203
--------------------------------------------------------------
Epoch:  203        1 Batch loss: 0.209704 Batch F1: 0.0
Epoch:  203        2 Batch loss: 0.224344 Batch F1: 0.0
Epoch:  203        3 Batch loss: 0.247124 Batch F1: 0.0
Epoch:  203        4 Batch loss: 0.172188 Batch F1: 0.0
Epoch:  203        5 Batch loss: 0.247018 Batch F1: 0.0
Epoch:  203        6 Batch loss: 0.245786 Batch F1: 0.0
Epoch:  203        7 Batch loss: 0.206820 Batch F1: 0.0
Epoch:  203        8 Batch loss: 0.237623 Batch F1: 0.0
Epoch:  203        9 Batch loss: 0.223853 Batch F1: 0.0
Epoch:  203       10 Batch loss: 0.216992 Batch F1: 0.0
Epoch:  203       11 Batch loss: 0.253653 Batch F1: 0.0
Epoch:  203       12 Batch loss: 0.245261 Batch F1: 0.0
Train Avg Loss  203: 0.227531

Train Avg F1  203: 0.0

Val Avg Loss  203: 0.222663

Val Avg F1  203:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 204
--------------------------------------------------------------
Epoch:  204        1 Batch loss: 0.254884 Batch F1: 0.0
Epoch:  204        2 Batch loss: 0.227493 Batch F1: 0.25
Epoch:  204        3 Batch loss: 0.233518 Batch F1: 0.37037037037037035
Epoch:  204        4 Batch loss: 0.239553 Batch F1: 0.2222222222222222
Epoch:  204        5 Batch loss: 0.220601 Batch F1: 0.3
Epoch:  204        6 Batch loss: 0.228752 Batch F1: 0.0
Epoch:  204        7 Batch loss: 0.239255 Batch F1: 0.0
Epoch:  204        8 Batch loss: 0.200685 Batch F1: 0.0
Epoch:  204        9 Batch loss: 0.172976 Batch F1: 0.0
Epoch:  204       10 Batch loss: 0.225158 Batch F1: 0.0
Epoch:  204       11 Batch loss: 0.270221 Batch F1: 0.0
Epoch:  204       12 Batch loss: 0.246677 Batch F1: 0.0
Train Avg Loss  204: 0.229981

Train Avg F1  204: 0.09521604938271605

Val Avg Loss  204: 0.217328

Val Avg F1  204:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 205
--------------------------------------------------------------
Epoch:  205        1 Batch loss: 0.217000 Batch F1: 0.0
Epoch:  205        2 Batch loss: 0.231441 Batch F1: 0.0
Epoch:  205        3 Batch loss: 0.211348 Batch F1: 0.0
Epoch:  205        4 Batch loss: 0.243904 Batch F1: 0.0
Epoch:  205        5 Batch loss: 0.218346 Batch F1: 0.0
Epoch:  205        6 Batch loss: 0.237867 Batch F1: 0.0
Epoch:  205        7 Batch loss: 0.213705 Batch F1: 0.0
Epoch:  205        8 Batch loss: 0.213331 Batch F1: 0.0
Epoch:  205        9 Batch loss: 0.239581 Batch F1: 0.0
Epoch:  205       10 Batch loss: 0.245932 Batch F1: 0.0
Epoch:  205       11 Batch loss: 0.236224 Batch F1: 0.0
Epoch:  205       12 Batch loss: 0.218570 Batch F1: 0.0
Train Avg Loss  205: 0.227271

Train Avg F1  205: 0.0

Val Avg Loss  205: 0.218605

Val Avg F1  205:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 206
--------------------------------------------------------------
Epoch:  206        1 Batch loss: 0.208845 Batch F1: 0.0
Epoch:  206        2 Batch loss: 0.260194 Batch F1: 0.0
Epoch:  206        3 Batch loss: 0.263322 Batch F1: 0.0
Epoch:  206        4 Batch loss: 0.208047 Batch F1: 0.0
Epoch:  206        5 Batch loss: 0.221645 Batch F1: 0.0
Epoch:  206        6 Batch loss: 0.225308 Batch F1: 0.0
Epoch:  206        7 Batch loss: 0.200444 Batch F1: 0.0
Epoch:  206        8 Batch loss: 0.255756 Batch F1: 0.0
Epoch:  206        9 Batch loss: 0.210669 Batch F1: 0.0
Epoch:  206       10 Batch loss: 0.247195 Batch F1: 0.0
Epoch:  206       11 Batch loss: 0.214380 Batch F1: 0.0
Epoch:  206       12 Batch loss: 0.204960 Batch F1: 0.0
Train Avg Loss  206: 0.226730

Train Avg F1  206: 0.0

Val Avg Loss  206: 0.218341

Val Avg F1  206:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 207
--------------------------------------------------------------
Epoch:  207        1 Batch loss: 0.236964 Batch F1: 0.0
Epoch:  207        2 Batch loss: 0.232063 Batch F1: 0.0
Epoch:  207        3 Batch loss: 0.230706 Batch F1: 0.0
Epoch:  207        4 Batch loss: 0.217965 Batch F1: 0.0
Epoch:  207        5 Batch loss: 0.252331 Batch F1: 0.0
Epoch:  207        6 Batch loss: 0.240172 Batch F1: 0.0
Epoch:  207        7 Batch loss: 0.190676 Batch F1: 0.0
Epoch:  207        8 Batch loss: 0.233499 Batch F1: 0.0
Epoch:  207        9 Batch loss: 0.222248 Batch F1: 0.0
Epoch:  207       10 Batch loss: 0.209671 Batch F1: 0.0
Epoch:  207       11 Batch loss: 0.242004 Batch F1: 0.0
Epoch:  207       12 Batch loss: 0.207022 Batch F1: 0.0
Train Avg Loss  207: 0.226277

Train Avg F1  207: 0.0

Val Avg Loss  207: 0.217514

Val Avg F1  207:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 208
--------------------------------------------------------------
Epoch:  208        1 Batch loss: 0.208662 Batch F1: 0.0
Epoch:  208        2 Batch loss: 0.219604 Batch F1: 0.0
Epoch:  208        3 Batch loss: 0.218041 Batch F1: 0.0
Epoch:  208        4 Batch loss: 0.237605 Batch F1: 0.0
Epoch:  208        5 Batch loss: 0.220908 Batch F1: 0.0
Epoch:  208        6 Batch loss: 0.262945 Batch F1: 0.0
Epoch:  208        7 Batch loss: 0.217172 Batch F1: 0.0
Epoch:  208        8 Batch loss: 0.243626 Batch F1: 0.0
Epoch:  208        9 Batch loss: 0.208299 Batch F1: 0.0
Epoch:  208       10 Batch loss: 0.242555 Batch F1: 0.0
Epoch:  208       11 Batch loss: 0.208775 Batch F1: 0.0
Epoch:  208       12 Batch loss: 0.231509 Batch F1: 0.0
Train Avg Loss  208: 0.226642

Train Avg F1  208: 0.0

Val Avg Loss  208: 0.217738

Val Avg F1  208:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 209
--------------------------------------------------------------
Epoch:  209        1 Batch loss: 0.246030 Batch F1: 0.0
Epoch:  209        2 Batch loss: 0.240925 Batch F1: 0.0
Epoch:  209        3 Batch loss: 0.248886 Batch F1: 0.0
Epoch:  209        4 Batch loss: 0.201646 Batch F1: 0.0
Epoch:  209        5 Batch loss: 0.239440 Batch F1: 0.0
Epoch:  209        6 Batch loss: 0.202570 Batch F1: 0.0
Epoch:  209        7 Batch loss: 0.230993 Batch F1: 0.0
Epoch:  209        8 Batch loss: 0.210230 Batch F1: 0.10526315789473685
Epoch:  209        9 Batch loss: 0.251288 Batch F1: 0.0
Epoch:  209       10 Batch loss: 0.225512 Batch F1: 0.0
Epoch:  209       11 Batch loss: 0.199749 Batch F1: 0.0
Epoch:  209       12 Batch loss: 0.223420 Batch F1: 0.0
Train Avg Loss  209: 0.226724

Train Avg F1  209: 0.008771929824561405

Val Avg Loss  209: 0.216565

Val Avg F1  209:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 210
--------------------------------------------------------------
Epoch:  210        1 Batch loss: 0.218088 Batch F1: 0.0
Epoch:  210        2 Batch loss: 0.220490 Batch F1: 0.0
Epoch:  210        3 Batch loss: 0.233129 Batch F1: 0.0
Epoch:  210        4 Batch loss: 0.178759 Batch F1: 0.0
Epoch:  210        5 Batch loss: 0.212320 Batch F1: 0.0
Epoch:  210        6 Batch loss: 0.240060 Batch F1: 0.0
Epoch:  210        7 Batch loss: 0.239184 Batch F1: 0.0
Epoch:  210        8 Batch loss: 0.273088 Batch F1: 0.0
Epoch:  210        9 Batch loss: 0.219902 Batch F1: 0.0
Epoch:  210       10 Batch loss: 0.244771 Batch F1: 0.0
Epoch:  210       11 Batch loss: 0.206071 Batch F1: 0.0
Epoch:  210       12 Batch loss: 0.238399 Batch F1: 0.0
Train Avg Loss  210: 0.227022

Train Avg F1  210: 0.0

Val Avg Loss  210: 0.218996

Val Avg F1  210:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 211
--------------------------------------------------------------
Epoch:  211        1 Batch loss: 0.250196 Batch F1: 0.0
Epoch:  211        2 Batch loss: 0.230897 Batch F1: 0.0
Epoch:  211        3 Batch loss: 0.229548 Batch F1: 0.0
Epoch:  211        4 Batch loss: 0.223008 Batch F1: 0.0
Epoch:  211        5 Batch loss: 0.207081 Batch F1: 0.0
Epoch:  211        6 Batch loss: 0.234734 Batch F1: 0.0
Epoch:  211        7 Batch loss: 0.210057 Batch F1: 0.0
Epoch:  211        8 Batch loss: 0.236862 Batch F1: 0.0
Epoch:  211        9 Batch loss: 0.239563 Batch F1: 0.0
Epoch:  211       10 Batch loss: 0.213385 Batch F1: 0.0
Epoch:  211       11 Batch loss: 0.202522 Batch F1: 0.0
Epoch:  211       12 Batch loss: 0.243187 Batch F1: 0.0
Train Avg Loss  211: 0.226753

Train Avg F1  211: 0.0

Val Avg Loss  211: 0.217181

Val Avg F1  211:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 212
--------------------------------------------------------------
Epoch:  212        1 Batch loss: 0.211584 Batch F1: 0.0
Epoch:  212        2 Batch loss: 0.239824 Batch F1: 0.0
Epoch:  212        3 Batch loss: 0.245772 Batch F1: 0.0
Epoch:  212        4 Batch loss: 0.229942 Batch F1: 0.0
Epoch:  212        5 Batch loss: 0.203385 Batch F1: 0.0
Epoch:  212        6 Batch loss: 0.222742 Batch F1: 0.0
Epoch:  212        7 Batch loss: 0.239032 Batch F1: 0.0
Epoch:  212        8 Batch loss: 0.222502 Batch F1: 0.0
Epoch:  212        9 Batch loss: 0.237798 Batch F1: 0.0
Epoch:  212       10 Batch loss: 0.219219 Batch F1: 0.0
Epoch:  212       11 Batch loss: 0.225055 Batch F1: 0.0
Epoch:  212       12 Batch loss: 0.220115 Batch F1: 0.0
Train Avg Loss  212: 0.226414

Train Avg F1  212: 0.0

Val Avg Loss  212: 0.218200

Val Avg F1  212:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 213
--------------------------------------------------------------
Epoch:  213        1 Batch loss: 0.217184 Batch F1: 0.0
Epoch:  213        2 Batch loss: 0.243418 Batch F1: 0.0
Epoch:  213        3 Batch loss: 0.227101 Batch F1: 0.0
Epoch:  213        4 Batch loss: 0.223605 Batch F1: 0.0
Epoch:  213        5 Batch loss: 0.258622 Batch F1: 0.0
Epoch:  213        6 Batch loss: 0.175549 Batch F1: 0.0
Epoch:  213        7 Batch loss: 0.238068 Batch F1: 0.0
Epoch:  213        8 Batch loss: 0.197789 Batch F1: 0.0
Epoch:  213        9 Batch loss: 0.189473 Batch F1: 0.0
Epoch:  213       10 Batch loss: 0.303063 Batch F1: 0.0
Epoch:  213       11 Batch loss: 0.225348 Batch F1: 0.0
Epoch:  213       12 Batch loss: 0.226134 Batch F1: 0.0
Train Avg Loss  213: 0.227113

Train Avg F1  213: 0.0

Val Avg Loss  213: 0.218580

Val Avg F1  213:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 214
--------------------------------------------------------------
Epoch:  214        1 Batch loss: 0.231494 Batch F1: 0.0
Epoch:  214        2 Batch loss: 0.251101 Batch F1: 0.0
Epoch:  214        3 Batch loss: 0.232051 Batch F1: 0.0
Epoch:  214        4 Batch loss: 0.222737 Batch F1: 0.0
Epoch:  214        5 Batch loss: 0.232414 Batch F1: 0.0
Epoch:  214        6 Batch loss: 0.203896 Batch F1: 0.0
Epoch:  214        7 Batch loss: 0.230282 Batch F1: 0.0
Epoch:  214        8 Batch loss: 0.258708 Batch F1: 0.0
Epoch:  214        9 Batch loss: 0.201952 Batch F1: 0.0
Epoch:  214       10 Batch loss: 0.230842 Batch F1: 0.0
Epoch:  214       11 Batch loss: 0.220179 Batch F1: 0.0
Epoch:  214       12 Batch loss: 0.213048 Batch F1: 0.0
Train Avg Loss  214: 0.227392

Train Avg F1  214: 0.0

Val Avg Loss  214: 0.218770

Val Avg F1  214:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 215
--------------------------------------------------------------
Epoch:  215        1 Batch loss: 0.196773 Batch F1: 0.0
Epoch:  215        2 Batch loss: 0.236332 Batch F1: 0.0
Epoch:  215        3 Batch loss: 0.251388 Batch F1: 0.0
Epoch:  215        4 Batch loss: 0.218202 Batch F1: 0.0
Epoch:  215        5 Batch loss: 0.228386 Batch F1: 0.0
Epoch:  215        6 Batch loss: 0.252313 Batch F1: 0.0
Epoch:  215        7 Batch loss: 0.240434 Batch F1: 0.0
Epoch:  215        8 Batch loss: 0.193224 Batch F1: 0.0
Epoch:  215        9 Batch loss: 0.243979 Batch F1: 0.0
Epoch:  215       10 Batch loss: 0.196282 Batch F1: 0.0
Epoch:  215       11 Batch loss: 0.247915 Batch F1: 0.0
Epoch:  215       12 Batch loss: 0.219220 Batch F1: 0.0
Train Avg Loss  215: 0.227037

Train Avg F1  215: 0.0

Val Avg Loss  215: 0.218357

Val Avg F1  215:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 216
--------------------------------------------------------------
Epoch:  216        1 Batch loss: 0.228594 Batch F1: 0.0
Epoch:  216        2 Batch loss: 0.259394 Batch F1: 0.0
Epoch:  216        3 Batch loss: 0.257601 Batch F1: 0.0
Epoch:  216        4 Batch loss: 0.212771 Batch F1: 0.0
Epoch:  216        5 Batch loss: 0.230837 Batch F1: 0.0
Epoch:  216        6 Batch loss: 0.231281 Batch F1: 0.0
Epoch:  216        7 Batch loss: 0.233805 Batch F1: 0.0
Epoch:  216        8 Batch loss: 0.203093 Batch F1: 0.0
Epoch:  216        9 Batch loss: 0.230328 Batch F1: 0.0
Epoch:  216       10 Batch loss: 0.182620 Batch F1: 0.0
Epoch:  216       11 Batch loss: 0.206625 Batch F1: 0.0
Epoch:  216       12 Batch loss: 0.241666 Batch F1: 0.0
Train Avg Loss  216: 0.226551

Train Avg F1  216: 0.0

Val Avg Loss  216: 0.216830

Val Avg F1  216:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 217
--------------------------------------------------------------
Epoch:  217        1 Batch loss: 0.219655 Batch F1: 0.0
Epoch:  217        2 Batch loss: 0.243527 Batch F1: 0.0
Epoch:  217        3 Batch loss: 0.190166 Batch F1: 0.0
Epoch:  217        4 Batch loss: 0.218094 Batch F1: 0.0
Epoch:  217        5 Batch loss: 0.280830 Batch F1: 0.0
Epoch:  217        6 Batch loss: 0.204910 Batch F1: 0.0
Epoch:  217        7 Batch loss: 0.232798 Batch F1: 0.0
Epoch:  217        8 Batch loss: 0.248727 Batch F1: 0.0
Epoch:  217        9 Batch loss: 0.213564 Batch F1: 0.0
Epoch:  217       10 Batch loss: 0.213766 Batch F1: 0.0
Epoch:  217       11 Batch loss: 0.214242 Batch F1: 0.0
Epoch:  217       12 Batch loss: 0.237844 Batch F1: 0.0
Train Avg Loss  217: 0.226510

Train Avg F1  217: 0.0

Val Avg Loss  217: 0.218071

Val Avg F1  217:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 218
--------------------------------------------------------------
Epoch:  218        1 Batch loss: 0.232075 Batch F1: 0.0
Epoch:  218        2 Batch loss: 0.248432 Batch F1: 0.0
Epoch:  218        3 Batch loss: 0.211117 Batch F1: 0.0
Epoch:  218        4 Batch loss: 0.175857 Batch F1: 0.0
Epoch:  218        5 Batch loss: 0.254796 Batch F1: 0.0
Epoch:  218        6 Batch loss: 0.234624 Batch F1: 0.0
Epoch:  218        7 Batch loss: 0.215167 Batch F1: 0.0
Epoch:  218        8 Batch loss: 0.234350 Batch F1: 0.0
Epoch:  218        9 Batch loss: 0.188586 Batch F1: 0.0
Epoch:  218       10 Batch loss: 0.233811 Batch F1: 0.0
Epoch:  218       11 Batch loss: 0.255826 Batch F1: 0.0
Epoch:  218       12 Batch loss: 0.236788 Batch F1: 0.0
Train Avg Loss  218: 0.226786

Train Avg F1  218: 0.0

Val Avg Loss  218: 0.216821

Val Avg F1  218:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 219
--------------------------------------------------------------
Epoch:  219        1 Batch loss: 0.262051 Batch F1: 0.0
Epoch:  219        2 Batch loss: 0.227828 Batch F1: 0.0
Epoch:  219        3 Batch loss: 0.228519 Batch F1: 0.0
Epoch:  219        4 Batch loss: 0.214834 Batch F1: 0.0
Epoch:  219        5 Batch loss: 0.224063 Batch F1: 0.0
Epoch:  219        6 Batch loss: 0.246365 Batch F1: 0.0
Epoch:  219        7 Batch loss: 0.193053 Batch F1: 0.0
Epoch:  219        8 Batch loss: 0.214627 Batch F1: 0.0
Epoch:  219        9 Batch loss: 0.213701 Batch F1: 0.0
Epoch:  219       10 Batch loss: 0.232103 Batch F1: 0.0
Epoch:  219       11 Batch loss: 0.215526 Batch F1: 0.0
Epoch:  219       12 Batch loss: 0.243848 Batch F1: 0.0
Train Avg Loss  219: 0.226376

Train Avg F1  219: 0.0

Val Avg Loss  219: 0.217072

Val Avg F1  219:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 220
--------------------------------------------------------------
Epoch:  220        1 Batch loss: 0.219744 Batch F1: 0.0
Epoch:  220        2 Batch loss: 0.210485 Batch F1: 0.0
Epoch:  220        3 Batch loss: 0.261482 Batch F1: 0.0
Epoch:  220        4 Batch loss: 0.265604 Batch F1: 0.0
Epoch:  220        5 Batch loss: 0.192644 Batch F1: 0.0
Epoch:  220        6 Batch loss: 0.215997 Batch F1: 0.0
Epoch:  220        7 Batch loss: 0.198158 Batch F1: 0.0
Epoch:  220        8 Batch loss: 0.189501 Batch F1: 0.0
Epoch:  220        9 Batch loss: 0.248379 Batch F1: 0.0
Epoch:  220       10 Batch loss: 0.223183 Batch F1: 0.0
Epoch:  220       11 Batch loss: 0.243700 Batch F1: 0.0
Epoch:  220       12 Batch loss: 0.257532 Batch F1: 0.0
Train Avg Loss  220: 0.227201

Train Avg F1  220: 0.0

Val Avg Loss  220: 0.221566

Val Avg F1  220:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 221
--------------------------------------------------------------
Epoch:  221        1 Batch loss: 0.245063 Batch F1: 0.0
Epoch:  221        2 Batch loss: 0.210900 Batch F1: 0.3157894736842105
Epoch:  221        3 Batch loss: 0.240133 Batch F1: 0.2758620689655173
Epoch:  221        4 Batch loss: 0.225250 Batch F1: 0.26086956521739124
Epoch:  221        5 Batch loss: 0.241987 Batch F1: 0.0
Epoch:  221        6 Batch loss: 0.234808 Batch F1: 0.0
Epoch:  221        7 Batch loss: 0.208204 Batch F1: 0.0
Epoch:  221        8 Batch loss: 0.205324 Batch F1: 0.0
Epoch:  221        9 Batch loss: 0.215549 Batch F1: 0.0
Epoch:  221       10 Batch loss: 0.251107 Batch F1: 0.0
Epoch:  221       11 Batch loss: 0.232467 Batch F1: 0.0
Epoch:  221       12 Batch loss: 0.227908 Batch F1: 0.0
Train Avg Loss  221: 0.228225

Train Avg F1  221: 0.07104342565559325

Val Avg Loss  221: 0.216808

Val Avg F1  221:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 222
--------------------------------------------------------------
Epoch:  222        1 Batch loss: 0.210751 Batch F1: 0.0
Epoch:  222        2 Batch loss: 0.199027 Batch F1: 0.0
Epoch:  222        3 Batch loss: 0.233240 Batch F1: 0.0
Epoch:  222        4 Batch loss: 0.212584 Batch F1: 0.0
Epoch:  222        5 Batch loss: 0.198718 Batch F1: 0.0
Epoch:  222        6 Batch loss: 0.311861 Batch F1: 0.0
Epoch:  222        7 Batch loss: 0.225066 Batch F1: 0.0
Epoch:  222        8 Batch loss: 0.226061 Batch F1: 0.0
Epoch:  222        9 Batch loss: 0.256016 Batch F1: 0.0
Epoch:  222       10 Batch loss: 0.220532 Batch F1: 0.0
Epoch:  222       11 Batch loss: 0.237364 Batch F1: 0.0
Epoch:  222       12 Batch loss: 0.220184 Batch F1: 0.0
Train Avg Loss  222: 0.229284

Train Avg F1  222: 0.0

Val Avg Loss  222: 0.221204

Val Avg F1  222:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 223
--------------------------------------------------------------
Epoch:  223        1 Batch loss: 0.226877 Batch F1: 0.0
Epoch:  223        2 Batch loss: 0.231105 Batch F1: 0.0
Epoch:  223        3 Batch loss: 0.215129 Batch F1: 0.0
Epoch:  223        4 Batch loss: 0.216043 Batch F1: 0.0
Epoch:  223        5 Batch loss: 0.219193 Batch F1: 0.0
Epoch:  223        6 Batch loss: 0.223943 Batch F1: 0.0
Epoch:  223        7 Batch loss: 0.236130 Batch F1: 0.0
Epoch:  223        8 Batch loss: 0.245371 Batch F1: 0.0
Epoch:  223        9 Batch loss: 0.240298 Batch F1: 0.0
Epoch:  223       10 Batch loss: 0.233205 Batch F1: 0.23076923076923075
Epoch:  223       11 Batch loss: 0.223167 Batch F1: 0.0
Epoch:  223       12 Batch loss: 0.236722 Batch F1: 0.0
Train Avg Loss  223: 0.228932

Train Avg F1  223: 0.01923076923076923

Val Avg Loss  223: 0.219560

Val Avg F1  223:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 224
--------------------------------------------------------------
Epoch:  224        1 Batch loss: 0.223929 Batch F1: 0.0
Epoch:  224        2 Batch loss: 0.234061 Batch F1: 0.0
Epoch:  224        3 Batch loss: 0.220913 Batch F1: 0.0
Epoch:  224        4 Batch loss: 0.217209 Batch F1: 0.0
Epoch:  224        5 Batch loss: 0.224600 Batch F1: 0.0
Epoch:  224        6 Batch loss: 0.200846 Batch F1: 0.0
Epoch:  224        7 Batch loss: 0.209149 Batch F1: 0.0
Epoch:  224        8 Batch loss: 0.254897 Batch F1: 0.0
Epoch:  224        9 Batch loss: 0.210143 Batch F1: 0.0
Epoch:  224       10 Batch loss: 0.239410 Batch F1: 0.0
Epoch:  224       11 Batch loss: 0.248308 Batch F1: 0.0
Epoch:  224       12 Batch loss: 0.246521 Batch F1: 0.0
Train Avg Loss  224: 0.227499

Train Avg F1  224: 0.0

Val Avg Loss  224: 0.224689

Val Avg F1  224:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 225
--------------------------------------------------------------
Epoch:  225        1 Batch loss: 0.235826 Batch F1: 0.0
Epoch:  225        2 Batch loss: 0.222092 Batch F1: 0.0
Epoch:  225        3 Batch loss: 0.233806 Batch F1: 0.0
Epoch:  225        4 Batch loss: 0.227851 Batch F1: 0.0
Epoch:  225        5 Batch loss: 0.204755 Batch F1: 0.0
Epoch:  225        6 Batch loss: 0.229453 Batch F1: 0.0
Epoch:  225        7 Batch loss: 0.246112 Batch F1: 0.0
Epoch:  225        8 Batch loss: 0.212239 Batch F1: 0.0
Epoch:  225        9 Batch loss: 0.250164 Batch F1: 0.0
Epoch:  225       10 Batch loss: 0.228626 Batch F1: 0.0
Epoch:  225       11 Batch loss: 0.228548 Batch F1: 0.0
Epoch:  225       12 Batch loss: 0.222689 Batch F1: 0.0
Train Avg Loss  225: 0.228513

Train Avg F1  225: 0.0

Val Avg Loss  225: 0.219506

Val Avg F1  225:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 226
--------------------------------------------------------------
Epoch:  226        1 Batch loss: 0.208851 Batch F1: 0.0
Epoch:  226        2 Batch loss: 0.253258 Batch F1: 0.0
Epoch:  226        3 Batch loss: 0.219443 Batch F1: 0.0
Epoch:  226        4 Batch loss: 0.232356 Batch F1: 0.0
Epoch:  226        5 Batch loss: 0.215007 Batch F1: 0.0
Epoch:  226        6 Batch loss: 0.217492 Batch F1: 0.0
Epoch:  226        7 Batch loss: 0.251473 Batch F1: 0.0
Epoch:  226        8 Batch loss: 0.267878 Batch F1: 0.0
Epoch:  226        9 Batch loss: 0.203976 Batch F1: 0.0
Epoch:  226       10 Batch loss: 0.240134 Batch F1: 0.0
Epoch:  226       11 Batch loss: 0.219116 Batch F1: 0.0
Epoch:  226       12 Batch loss: 0.202424 Batch F1: 0.0
Train Avg Loss  226: 0.227617

Train Avg F1  226: 0.0

Val Avg Loss  226: 0.217854

Val Avg F1  226:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 227
--------------------------------------------------------------
Epoch:  227        1 Batch loss: 0.213063 Batch F1: 0.0
Epoch:  227        2 Batch loss: 0.239457 Batch F1: 0.0
Epoch:  227        3 Batch loss: 0.228761 Batch F1: 0.0
Epoch:  227        4 Batch loss: 0.217918 Batch F1: 0.0
Epoch:  227        5 Batch loss: 0.221499 Batch F1: 0.0
Epoch:  227        6 Batch loss: 0.206069 Batch F1: 0.0
Epoch:  227        7 Batch loss: 0.243383 Batch F1: 0.0
Epoch:  227        8 Batch loss: 0.218031 Batch F1: 0.0
Epoch:  227        9 Batch loss: 0.246956 Batch F1: 0.0
Epoch:  227       10 Batch loss: 0.266611 Batch F1: 0.0
Epoch:  227       11 Batch loss: 0.224917 Batch F1: 0.0
Epoch:  227       12 Batch loss: 0.194518 Batch F1: 0.0
Train Avg Loss  227: 0.226765

Train Avg F1  227: 0.0

Val Avg Loss  227: 0.219601

Val Avg F1  227:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 228
--------------------------------------------------------------
Epoch:  228        1 Batch loss: 0.222371 Batch F1: 0.0
Epoch:  228        2 Batch loss: 0.225950 Batch F1: 0.0
Epoch:  228        3 Batch loss: 0.245008 Batch F1: 0.0
Epoch:  228        4 Batch loss: 0.250138 Batch F1: 0.0
Epoch:  228        5 Batch loss: 0.208071 Batch F1: 0.0
Epoch:  228        6 Batch loss: 0.252470 Batch F1: 0.0
Epoch:  228        7 Batch loss: 0.221430 Batch F1: 0.0
Epoch:  228        8 Batch loss: 0.221685 Batch F1: 0.0
Epoch:  228        9 Batch loss: 0.232659 Batch F1: 0.0
Epoch:  228       10 Batch loss: 0.210631 Batch F1: 0.0
Epoch:  228       11 Batch loss: 0.213031 Batch F1: 0.0
Epoch:  228       12 Batch loss: 0.216904 Batch F1: 0.0
Train Avg Loss  228: 0.226696

Train Avg F1  228: 0.0

Val Avg Loss  228: 0.216969

Val Avg F1  228:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 229
--------------------------------------------------------------
Epoch:  229        1 Batch loss: 0.242660 Batch F1: 0.0
Epoch:  229        2 Batch loss: 0.216693 Batch F1: 0.0
Epoch:  229        3 Batch loss: 0.225093 Batch F1: 0.0
Epoch:  229        4 Batch loss: 0.226095 Batch F1: 0.0
Epoch:  229        5 Batch loss: 0.244914 Batch F1: 0.0
Epoch:  229        6 Batch loss: 0.228449 Batch F1: 0.0
Epoch:  229        7 Batch loss: 0.204256 Batch F1: 0.0
Epoch:  229        8 Batch loss: 0.267405 Batch F1: 0.0
Epoch:  229        9 Batch loss: 0.216139 Batch F1: 0.0
Epoch:  229       10 Batch loss: 0.258729 Batch F1: 0.0
Epoch:  229       11 Batch loss: 0.201944 Batch F1: 0.0
Epoch:  229       12 Batch loss: 0.199483 Batch F1: 0.0
Train Avg Loss  229: 0.227655

Train Avg F1  229: 0.0

Val Avg Loss  229: 0.218254

Val Avg F1  229:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 230
--------------------------------------------------------------
Epoch:  230        1 Batch loss: 0.233080 Batch F1: 0.0
Epoch:  230        2 Batch loss: 0.211243 Batch F1: 0.0
Epoch:  230        3 Batch loss: 0.249111 Batch F1: 0.0
Epoch:  230        4 Batch loss: 0.202630 Batch F1: 0.0
Epoch:  230        5 Batch loss: 0.212212 Batch F1: 0.0
Epoch:  230        6 Batch loss: 0.225755 Batch F1: 0.0
Epoch:  230        7 Batch loss: 0.217558 Batch F1: 0.0
Epoch:  230        8 Batch loss: 0.230959 Batch F1: 0.0
Epoch:  230        9 Batch loss: 0.265278 Batch F1: 0.0
Epoch:  230       10 Batch loss: 0.221030 Batch F1: 0.0
Epoch:  230       11 Batch loss: 0.214832 Batch F1: 0.0
Epoch:  230       12 Batch loss: 0.238110 Batch F1: 0.0
Train Avg Loss  230: 0.226817

Train Avg F1  230: 0.0

Val Avg Loss  230: 0.219314

Val Avg F1  230:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 231
--------------------------------------------------------------
Epoch:  231        1 Batch loss: 0.207714 Batch F1: 0.0
Epoch:  231        2 Batch loss: 0.221245 Batch F1: 0.0
Epoch:  231        3 Batch loss: 0.237345 Batch F1: 0.0
Epoch:  231        4 Batch loss: 0.239255 Batch F1: 0.0
Epoch:  231        5 Batch loss: 0.221269 Batch F1: 0.0
Epoch:  231        6 Batch loss: 0.250375 Batch F1: 0.0
Epoch:  231        7 Batch loss: 0.193836 Batch F1: 0.0
Epoch:  231        8 Batch loss: 0.231761 Batch F1: 0.0
Epoch:  231        9 Batch loss: 0.219401 Batch F1: 0.0
Epoch:  231       10 Batch loss: 0.238977 Batch F1: 0.0
Epoch:  231       11 Batch loss: 0.247734 Batch F1: 0.0
Epoch:  231       12 Batch loss: 0.207054 Batch F1: 0.0
Train Avg Loss  231: 0.226330

Train Avg F1  231: 0.0

Val Avg Loss  231: 0.218380

Val Avg F1  231:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 232
--------------------------------------------------------------
Epoch:  232        1 Batch loss: 0.224527 Batch F1: 0.0
Epoch:  232        2 Batch loss: 0.215208 Batch F1: 0.0
Epoch:  232        3 Batch loss: 0.205103 Batch F1: 0.0
Epoch:  232        4 Batch loss: 0.236470 Batch F1: 0.0
Epoch:  232        5 Batch loss: 0.226973 Batch F1: 0.0
Epoch:  232        6 Batch loss: 0.212080 Batch F1: 0.0
Epoch:  232        7 Batch loss: 0.233612 Batch F1: 0.0
Epoch:  232        8 Batch loss: 0.267562 Batch F1: 0.0
Epoch:  232        9 Batch loss: 0.212492 Batch F1: 0.0
Epoch:  232       10 Batch loss: 0.217892 Batch F1: 0.0
Epoch:  232       11 Batch loss: 0.230618 Batch F1: 0.0
Epoch:  232       12 Batch loss: 0.223991 Batch F1: 0.0
Train Avg Loss  232: 0.225544

Train Avg F1  232: 0.0

Val Avg Loss  232: 0.216866

Val Avg F1  232:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 233
--------------------------------------------------------------
Epoch:  233        1 Batch loss: 0.201911 Batch F1: 0.0
Epoch:  233        2 Batch loss: 0.263951 Batch F1: 0.0
Epoch:  233        3 Batch loss: 0.204505 Batch F1: 0.0
Epoch:  233        4 Batch loss: 0.233390 Batch F1: 0.0
Epoch:  233        5 Batch loss: 0.237056 Batch F1: 0.0
Epoch:  233        6 Batch loss: 0.219181 Batch F1: 0.0
Epoch:  233        7 Batch loss: 0.223743 Batch F1: 0.0
Epoch:  233        8 Batch loss: 0.206760 Batch F1: 0.0
Epoch:  233        9 Batch loss: 0.244847 Batch F1: 0.0
Epoch:  233       10 Batch loss: 0.209458 Batch F1: 0.0
Epoch:  233       11 Batch loss: 0.254872 Batch F1: 0.0
Epoch:  233       12 Batch loss: 0.205901 Batch F1: 0.0
Train Avg Loss  233: 0.225465

Train Avg F1  233: 0.0

Val Avg Loss  233: 0.216794

Val Avg F1  233:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 234
--------------------------------------------------------------
Epoch:  234        1 Batch loss: 0.249566 Batch F1: 0.0
Epoch:  234        2 Batch loss: 0.227063 Batch F1: 0.0
Epoch:  234        3 Batch loss: 0.231596 Batch F1: 0.0
Epoch:  234        4 Batch loss: 0.215188 Batch F1: 0.0
Epoch:  234        5 Batch loss: 0.220900 Batch F1: 0.0
Epoch:  234        6 Batch loss: 0.256281 Batch F1: 0.0
Epoch:  234        7 Batch loss: 0.226547 Batch F1: 0.0
Epoch:  234        8 Batch loss: 0.231642 Batch F1: 0.0
Epoch:  234        9 Batch loss: 0.197514 Batch F1: 0.0
Epoch:  234       10 Batch loss: 0.221462 Batch F1: 0.0
Epoch:  234       11 Batch loss: 0.233220 Batch F1: 0.0
Epoch:  234       12 Batch loss: 0.196123 Batch F1: 0.0
Train Avg Loss  234: 0.225592

Train Avg F1  234: 0.0

Val Avg Loss  234: 0.217398

Val Avg F1  234:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 235
--------------------------------------------------------------
Epoch:  235        1 Batch loss: 0.195640 Batch F1: 0.0
Epoch:  235        2 Batch loss: 0.209251 Batch F1: 0.0
Epoch:  235        3 Batch loss: 0.240639 Batch F1: 0.0
Epoch:  235        4 Batch loss: 0.240583 Batch F1: 0.0
Epoch:  235        5 Batch loss: 0.253989 Batch F1: 0.0
Epoch:  235        6 Batch loss: 0.258424 Batch F1: 0.0
Epoch:  235        7 Batch loss: 0.224826 Batch F1: 0.0
Epoch:  235        8 Batch loss: 0.242084 Batch F1: 0.0
Epoch:  235        9 Batch loss: 0.218927 Batch F1: 0.0
Epoch:  235       10 Batch loss: 0.228800 Batch F1: 0.0
Epoch:  235       11 Batch loss: 0.188569 Batch F1: 0.0
Epoch:  235       12 Batch loss: 0.229979 Batch F1: 0.0
Train Avg Loss  235: 0.227642

Train Avg F1  235: 0.0

Val Avg Loss  235: 0.216989

Val Avg F1  235:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 236
--------------------------------------------------------------
Epoch:  236        1 Batch loss: 0.248546 Batch F1: 0.0
Epoch:  236        2 Batch loss: 0.254209 Batch F1: 0.0
Epoch:  236        3 Batch loss: 0.230052 Batch F1: 0.0
Epoch:  236        4 Batch loss: 0.225312 Batch F1: 0.0
Epoch:  236        5 Batch loss: 0.227629 Batch F1: 0.0
Epoch:  236        6 Batch loss: 0.215294 Batch F1: 0.0
Epoch:  236        7 Batch loss: 0.226502 Batch F1: 0.0
Epoch:  236        8 Batch loss: 0.235063 Batch F1: 0.0
Epoch:  236        9 Batch loss: 0.200054 Batch F1: 0.0
Epoch:  236       10 Batch loss: 0.218256 Batch F1: 0.0
Epoch:  236       11 Batch loss: 0.219626 Batch F1: 0.0
Epoch:  236       12 Batch loss: 0.230082 Batch F1: 0.0
Train Avg Loss  236: 0.227552

Train Avg F1  236: 0.0

Val Avg Loss  236: 0.217480

Val Avg F1  236:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 237
--------------------------------------------------------------
Epoch:  237        1 Batch loss: 0.237166 Batch F1: 0.0
Epoch:  237        2 Batch loss: 0.285994 Batch F1: 0.0
Epoch:  237        3 Batch loss: 0.202171 Batch F1: 0.0
Epoch:  237        4 Batch loss: 0.236746 Batch F1: 0.0
Epoch:  237        5 Batch loss: 0.205209 Batch F1: 0.0
Epoch:  237        6 Batch loss: 0.197314 Batch F1: 0.0
Epoch:  237        7 Batch loss: 0.233438 Batch F1: 0.0
Epoch:  237        8 Batch loss: 0.228569 Batch F1: 0.0
Epoch:  237        9 Batch loss: 0.214201 Batch F1: 0.0
Epoch:  237       10 Batch loss: 0.222079 Batch F1: 0.0
Epoch:  237       11 Batch loss: 0.207196 Batch F1: 0.0
Epoch:  237       12 Batch loss: 0.253547 Batch F1: 0.0
Train Avg Loss  237: 0.226969

Train Avg F1  237: 0.0

Val Avg Loss  237: 0.216809

Val Avg F1  237:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 238
--------------------------------------------------------------
Epoch:  238        1 Batch loss: 0.227081 Batch F1: 0.0
Epoch:  238        2 Batch loss: 0.236712 Batch F1: 0.0
Epoch:  238        3 Batch loss: 0.261349 Batch F1: 0.0
Epoch:  238        4 Batch loss: 0.237007 Batch F1: 0.0
Epoch:  238        5 Batch loss: 0.217095 Batch F1: 0.0
Epoch:  238        6 Batch loss: 0.246354 Batch F1: 0.0
Epoch:  238        7 Batch loss: 0.235562 Batch F1: 0.23076923076923075
Epoch:  238        8 Batch loss: 0.206249 Batch F1: 0.11111111111111112
Epoch:  238        9 Batch loss: 0.232913 Batch F1: 0.0
Epoch:  238       10 Batch loss: 0.204944 Batch F1: 0.0
Epoch:  238       11 Batch loss: 0.217301 Batch F1: 0.0
Epoch:  238       12 Batch loss: 0.192801 Batch F1: 0.0
Train Avg Loss  238: 0.226281

Train Avg F1  238: 0.02849002849002849

Val Avg Loss  238: 0.216881

Val Avg F1  238:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 239
--------------------------------------------------------------
Epoch:  239        1 Batch loss: 0.219175 Batch F1: 0.0
Epoch:  239        2 Batch loss: 0.227961 Batch F1: 0.0
Epoch:  239        3 Batch loss: 0.217834 Batch F1: 0.0
Epoch:  239        4 Batch loss: 0.233312 Batch F1: 0.0
Epoch:  239        5 Batch loss: 0.201508 Batch F1: 0.0
Epoch:  239        6 Batch loss: 0.205694 Batch F1: 0.0
Epoch:  239        7 Batch loss: 0.233837 Batch F1: 0.0
Epoch:  239        8 Batch loss: 0.236365 Batch F1: 0.0
Epoch:  239        9 Batch loss: 0.249608 Batch F1: 0.0
Epoch:  239       10 Batch loss: 0.220734 Batch F1: 0.0
Epoch:  239       11 Batch loss: 0.224427 Batch F1: 0.0
Epoch:  239       12 Batch loss: 0.252295 Batch F1: 0.0
Train Avg Loss  239: 0.226896

Train Avg F1  239: 0.0

Val Avg Loss  239: 0.219695

Val Avg F1  239:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 240
--------------------------------------------------------------
Epoch:  240        1 Batch loss: 0.233619 Batch F1: 0.0
Epoch:  240        2 Batch loss: 0.219387 Batch F1: 0.0
Epoch:  240        3 Batch loss: 0.234897 Batch F1: 0.2580645161290322
Epoch:  240        4 Batch loss: 0.217932 Batch F1: 0.3846153846153846
Epoch:  240        5 Batch loss: 0.241749 Batch F1: 0.0
Epoch:  240        6 Batch loss: 0.240962 Batch F1: 0.0
Epoch:  240        7 Batch loss: 0.235840 Batch F1: 0.0
Epoch:  240        8 Batch loss: 0.244752 Batch F1: 0.0
Epoch:  240        9 Batch loss: 0.201804 Batch F1: 0.0
Epoch:  240       10 Batch loss: 0.218892 Batch F1: 0.0
Epoch:  240       11 Batch loss: 0.203582 Batch F1: 0.0
Epoch:  240       12 Batch loss: 0.230683 Batch F1: 0.0
Train Avg Loss  240: 0.227008

Train Avg F1  240: 0.05355665839536807

Val Avg Loss  240: 0.219187

Val Avg F1  240:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 241
--------------------------------------------------------------
Epoch:  241        1 Batch loss: 0.216060 Batch F1: 0.0
Epoch:  241        2 Batch loss: 0.264874 Batch F1: 0.0
Epoch:  241        3 Batch loss: 0.237160 Batch F1: 0.0
Epoch:  241        4 Batch loss: 0.220010 Batch F1: 0.0
Epoch:  241        5 Batch loss: 0.238895 Batch F1: 0.0
Epoch:  241        6 Batch loss: 0.210271 Batch F1: 0.0
Epoch:  241        7 Batch loss: 0.229308 Batch F1: 0.0
Epoch:  241        8 Batch loss: 0.231206 Batch F1: 0.0
Epoch:  241        9 Batch loss: 0.230370 Batch F1: 0.0
Epoch:  241       10 Batch loss: 0.217852 Batch F1: 0.0
Epoch:  241       11 Batch loss: 0.217287 Batch F1: 0.0
Epoch:  241       12 Batch loss: 0.240000 Batch F1: 0.0
Train Avg Loss  241: 0.229441

Train Avg F1  241: 0.0

Val Avg Loss  241: 0.221031

Val Avg F1  241:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 242
--------------------------------------------------------------
Epoch:  242        1 Batch loss: 0.210602 Batch F1: 0.0
Epoch:  242        2 Batch loss: 0.213237 Batch F1: 0.0
Epoch:  242        3 Batch loss: 0.249056 Batch F1: 0.0
Epoch:  242        4 Batch loss: 0.208805 Batch F1: 0.0
Epoch:  242        5 Batch loss: 0.272313 Batch F1: 0.0
Epoch:  242        6 Batch loss: 0.233237 Batch F1: 0.0
Epoch:  242        7 Batch loss: 0.237695 Batch F1: 0.0
Epoch:  242        8 Batch loss: 0.225696 Batch F1: 0.0
Epoch:  242        9 Batch loss: 0.216013 Batch F1: 0.0
Epoch:  242       10 Batch loss: 0.223802 Batch F1: 0.0
Epoch:  242       11 Batch loss: 0.236920 Batch F1: 0.0
Epoch:  242       12 Batch loss: 0.212940 Batch F1: 0.0
Train Avg Loss  242: 0.228360

Train Avg F1  242: 0.0

Val Avg Loss  242: 0.219505

Val Avg F1  242:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 243
--------------------------------------------------------------
Epoch:  243        1 Batch loss: 0.235871 Batch F1: 0.0
Epoch:  243        2 Batch loss: 0.223671 Batch F1: 0.0
Epoch:  243        3 Batch loss: 0.210792 Batch F1: 0.0
Epoch:  243        4 Batch loss: 0.226631 Batch F1: 0.0
Epoch:  243        5 Batch loss: 0.215587 Batch F1: 0.0
Epoch:  243        6 Batch loss: 0.214205 Batch F1: 0.0
Epoch:  243        7 Batch loss: 0.205971 Batch F1: 0.0
Epoch:  243        8 Batch loss: 0.244715 Batch F1: 0.0
Epoch:  243        9 Batch loss: 0.216398 Batch F1: 0.0
Epoch:  243       10 Batch loss: 0.273294 Batch F1: 0.0
Epoch:  243       11 Batch loss: 0.213166 Batch F1: 0.0
Epoch:  243       12 Batch loss: 0.258980 Batch F1: 0.0
Train Avg Loss  243: 0.228273

Train Avg F1  243: 0.0

Val Avg Loss  243: 0.221374

Val Avg F1  243:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 244
--------------------------------------------------------------
Epoch:  244        1 Batch loss: 0.216673 Batch F1: 0.0
Epoch:  244        2 Batch loss: 0.208131 Batch F1: 0.0
Epoch:  244        3 Batch loss: 0.226838 Batch F1: 0.0
Epoch:  244        4 Batch loss: 0.238448 Batch F1: 0.0
Epoch:  244        5 Batch loss: 0.208842 Batch F1: 0.0
Epoch:  244        6 Batch loss: 0.216320 Batch F1: 0.0
Epoch:  244        7 Batch loss: 0.216833 Batch F1: 0.0
Epoch:  244        8 Batch loss: 0.244098 Batch F1: 0.0
Epoch:  244        9 Batch loss: 0.250569 Batch F1: 0.0
Epoch:  244       10 Batch loss: 0.237624 Batch F1: 0.0
Epoch:  244       11 Batch loss: 0.232126 Batch F1: 0.0
Epoch:  244       12 Batch loss: 0.248801 Batch F1: 0.0
Train Avg Loss  244: 0.228775

Train Avg F1  244: 0.0

Val Avg Loss  244: 0.223391

Val Avg F1  244:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 245
--------------------------------------------------------------
Epoch:  245        1 Batch loss: 0.207421 Batch F1: 0.0
Epoch:  245        2 Batch loss: 0.222623 Batch F1: 0.0
Epoch:  245        3 Batch loss: 0.243939 Batch F1: 0.0
Epoch:  245        4 Batch loss: 0.219319 Batch F1: 0.0
Epoch:  245        5 Batch loss: 0.234265 Batch F1: 0.0
Epoch:  245        6 Batch loss: 0.222982 Batch F1: 0.0
Epoch:  245        7 Batch loss: 0.231678 Batch F1: 0.0
Epoch:  245        8 Batch loss: 0.211303 Batch F1: 0.0
Epoch:  245        9 Batch loss: 0.234815 Batch F1: 0.0
Epoch:  245       10 Batch loss: 0.245605 Batch F1: 0.0
Epoch:  245       11 Batch loss: 0.249840 Batch F1: 0.0
Epoch:  245       12 Batch loss: 0.210220 Batch F1: 0.0
Train Avg Loss  245: 0.227834

Train Avg F1  245: 0.0

Val Avg Loss  245: 0.218538

Val Avg F1  245:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 246
--------------------------------------------------------------
Epoch:  246        1 Batch loss: 0.205198 Batch F1: 0.0
Epoch:  246        2 Batch loss: 0.224883 Batch F1: 0.0
Epoch:  246        3 Batch loss: 0.204727 Batch F1: 0.0
Epoch:  246        4 Batch loss: 0.246301 Batch F1: 0.0
Epoch:  246        5 Batch loss: 0.197137 Batch F1: 0.0
Epoch:  246        6 Batch loss: 0.192303 Batch F1: 0.0
Epoch:  246        7 Batch loss: 0.268901 Batch F1: 0.0
Epoch:  246        8 Batch loss: 0.278998 Batch F1: 0.0
Epoch:  246        9 Batch loss: 0.221819 Batch F1: 0.0
Epoch:  246       10 Batch loss: 0.221642 Batch F1: 0.0
Epoch:  246       11 Batch loss: 0.238032 Batch F1: 0.0
Epoch:  246       12 Batch loss: 0.229879 Batch F1: 0.0
Train Avg Loss  246: 0.227485

Train Avg F1  246: 0.0

Val Avg Loss  246: 0.219640

Val Avg F1  246:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 247
--------------------------------------------------------------
Epoch:  247        1 Batch loss: 0.237480 Batch F1: 0.0
Epoch:  247        2 Batch loss: 0.205366 Batch F1: 0.0
Epoch:  247        3 Batch loss: 0.256594 Batch F1: 0.0
Epoch:  247        4 Batch loss: 0.206204 Batch F1: 0.0
Epoch:  247        5 Batch loss: 0.229308 Batch F1: 0.0
Epoch:  247        6 Batch loss: 0.214414 Batch F1: 0.0
Epoch:  247        7 Batch loss: 0.204385 Batch F1: 0.0
Epoch:  247        8 Batch loss: 0.266724 Batch F1: 0.0
Epoch:  247        9 Batch loss: 0.216139 Batch F1: 0.0
Epoch:  247       10 Batch loss: 0.233864 Batch F1: 0.0
Epoch:  247       11 Batch loss: 0.234541 Batch F1: 0.0
Epoch:  247       12 Batch loss: 0.221581 Batch F1: 0.0
Train Avg Loss  247: 0.227217

Train Avg F1  247: 0.0

Val Avg Loss  247: 0.220285

Val Avg F1  247:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 248
--------------------------------------------------------------
Epoch:  248        1 Batch loss: 0.225917 Batch F1: 0.0
Epoch:  248        2 Batch loss: 0.226192 Batch F1: 0.0
Epoch:  248        3 Batch loss: 0.205382 Batch F1: 0.0
Epoch:  248        4 Batch loss: 0.233530 Batch F1: 0.0
Epoch:  248        5 Batch loss: 0.204427 Batch F1: 0.0
Epoch:  248        6 Batch loss: 0.237287 Batch F1: 0.0
Epoch:  248        7 Batch loss: 0.213967 Batch F1: 0.0
Epoch:  248        8 Batch loss: 0.246190 Batch F1: 0.0
Epoch:  248        9 Batch loss: 0.223638 Batch F1: 0.0
Epoch:  248       10 Batch loss: 0.232946 Batch F1: 0.0
Epoch:  248       11 Batch loss: 0.241638 Batch F1: 0.0
Epoch:  248       12 Batch loss: 0.248090 Batch F1: 0.0
Train Avg Loss  248: 0.228267

Train Avg F1  248: 0.0

Val Avg Loss  248: 0.219577

Val Avg F1  248:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 249
--------------------------------------------------------------
Epoch:  249        1 Batch loss: 0.227102 Batch F1: 0.0
Epoch:  249        2 Batch loss: 0.229007 Batch F1: 0.0
Epoch:  249        3 Batch loss: 0.235361 Batch F1: 0.0
Epoch:  249        4 Batch loss: 0.220443 Batch F1: 0.0
Epoch:  249        5 Batch loss: 0.244712 Batch F1: 0.0
Epoch:  249        6 Batch loss: 0.196098 Batch F1: 0.0
Epoch:  249        7 Batch loss: 0.235093 Batch F1: 0.0
Epoch:  249        8 Batch loss: 0.219338 Batch F1: 0.0
Epoch:  249        9 Batch loss: 0.226238 Batch F1: 0.0
Epoch:  249       10 Batch loss: 0.216574 Batch F1: 0.0
Epoch:  249       11 Batch loss: 0.249915 Batch F1: 0.0
Epoch:  249       12 Batch loss: 0.226219 Batch F1: 0.0
Train Avg Loss  249: 0.227175

Train Avg F1  249: 0.0

Val Avg Loss  249: 0.218296

Val Avg F1  249:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 250
--------------------------------------------------------------
Epoch:  250        1 Batch loss: 0.230989 Batch F1: 0.0
Epoch:  250        2 Batch loss: 0.196239 Batch F1: 0.0
Epoch:  250        3 Batch loss: 0.215688 Batch F1: 0.0
Epoch:  250        4 Batch loss: 0.214076 Batch F1: 0.0
Epoch:  250        5 Batch loss: 0.224035 Batch F1: 0.0
Epoch:  250        6 Batch loss: 0.231483 Batch F1: 0.0
Epoch:  250        7 Batch loss: 0.206609 Batch F1: 0.0
Epoch:  250        8 Batch loss: 0.251652 Batch F1: 0.0
Epoch:  250        9 Batch loss: 0.269077 Batch F1: 0.0
Epoch:  250       10 Batch loss: 0.206178 Batch F1: 0.0
Epoch:  250       11 Batch loss: 0.254968 Batch F1: 0.0
Epoch:  250       12 Batch loss: 0.230002 Batch F1: 0.0
Train Avg Loss  250: 0.227583

Train Avg F1  250: 0.0

Val Avg Loss  250: 0.218758

Val Avg F1  250:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 251
--------------------------------------------------------------
Epoch:  251        1 Batch loss: 0.236303 Batch F1: 0.0
Epoch:  251        2 Batch loss: 0.213938 Batch F1: 0.31999999999999995
Epoch:  251        3 Batch loss: 0.216098 Batch F1: 0.39999999999999997
Epoch:  251        4 Batch loss: 0.249489 Batch F1: 0.33333333333333337
Epoch:  251        5 Batch loss: 0.245083 Batch F1: 0.2857142857142857
Epoch:  251        6 Batch loss: 0.264493 Batch F1: 0.0
Epoch:  251        7 Batch loss: 0.212782 Batch F1: 0.0
Epoch:  251        8 Batch loss: 0.205356 Batch F1: 0.0
Epoch:  251        9 Batch loss: 0.207451 Batch F1: 0.0
Epoch:  251       10 Batch loss: 0.232095 Batch F1: 0.0
Epoch:  251       11 Batch loss: 0.210162 Batch F1: 0.0
Epoch:  251       12 Batch loss: 0.228137 Batch F1: 0.0
Train Avg Loss  251: 0.226782

Train Avg F1  251: 0.11158730158730157

Val Avg Loss  251: 0.220988

Val Avg F1  251:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 252
--------------------------------------------------------------
Epoch:  252        1 Batch loss: 0.250917 Batch F1: 0.0
Epoch:  252        2 Batch loss: 0.239296 Batch F1: 0.0
Epoch:  252        3 Batch loss: 0.259441 Batch F1: 0.0
Epoch:  252        4 Batch loss: 0.231734 Batch F1: 0.0
Epoch:  252        5 Batch loss: 0.216559 Batch F1: 0.0
Epoch:  252        6 Batch loss: 0.240110 Batch F1: 0.0
Epoch:  252        7 Batch loss: 0.227451 Batch F1: 0.0
Epoch:  252        8 Batch loss: 0.234003 Batch F1: 0.0
Epoch:  252        9 Batch loss: 0.223187 Batch F1: 0.0
Epoch:  252       10 Batch loss: 0.208706 Batch F1: 0.0
Epoch:  252       11 Batch loss: 0.211626 Batch F1: 0.0
Epoch:  252       12 Batch loss: 0.246095 Batch F1: 0.0
Train Avg Loss  252: 0.232427

Train Avg F1  252: 0.0

Val Avg Loss  252: 0.218997

Val Avg F1  252:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 253
--------------------------------------------------------------
Epoch:  253        1 Batch loss: 0.195459 Batch F1: 0.0
Epoch:  253        2 Batch loss: 0.259588 Batch F1: 0.0
Epoch:  253        3 Batch loss: 0.222145 Batch F1: 0.0
Epoch:  253        4 Batch loss: 0.230266 Batch F1: 0.0
Epoch:  253        5 Batch loss: 0.227566 Batch F1: 0.0
Epoch:  253        6 Batch loss: 0.217251 Batch F1: 0.0
Epoch:  253        7 Batch loss: 0.194331 Batch F1: 0.0
Epoch:  253        8 Batch loss: 0.221006 Batch F1: 0.0
Epoch:  253        9 Batch loss: 0.256594 Batch F1: 0.0
Epoch:  253       10 Batch loss: 0.234836 Batch F1: 0.0
Epoch:  253       11 Batch loss: 0.219180 Batch F1: 0.0
Epoch:  253       12 Batch loss: 0.270398 Batch F1: 0.0
Train Avg Loss  253: 0.229052

Train Avg F1  253: 0.0

Val Avg Loss  253: 0.219779

Val Avg F1  253:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 254
--------------------------------------------------------------
Epoch:  254        1 Batch loss: 0.226118 Batch F1: 0.0
Epoch:  254        2 Batch loss: 0.228063 Batch F1: 0.0
Epoch:  254        3 Batch loss: 0.223055 Batch F1: 0.0
Epoch:  254        4 Batch loss: 0.200620 Batch F1: 0.0
Epoch:  254        5 Batch loss: 0.245482 Batch F1: 0.0
Epoch:  254        6 Batch loss: 0.247594 Batch F1: 0.0
Epoch:  254        7 Batch loss: 0.216190 Batch F1: 0.0
Epoch:  254        8 Batch loss: 0.230939 Batch F1: 0.0
Epoch:  254        9 Batch loss: 0.246520 Batch F1: 0.0
Epoch:  254       10 Batch loss: 0.237909 Batch F1: 0.0
Epoch:  254       11 Batch loss: 0.238644 Batch F1: 0.0
Epoch:  254       12 Batch loss: 0.203208 Batch F1: 0.0
Train Avg Loss  254: 0.228695

Train Avg F1  254: 0.0

Val Avg Loss  254: 0.221222

Val Avg F1  254:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 255
--------------------------------------------------------------
Epoch:  255        1 Batch loss: 0.228943 Batch F1: 0.0
Epoch:  255        2 Batch loss: 0.230408 Batch F1: 0.0
Epoch:  255        3 Batch loss: 0.245852 Batch F1: 0.0
Epoch:  255        4 Batch loss: 0.236380 Batch F1: 0.0
Epoch:  255        5 Batch loss: 0.237172 Batch F1: 0.0
Epoch:  255        6 Batch loss: 0.234002 Batch F1: 0.0
Epoch:  255        7 Batch loss: 0.178423 Batch F1: 0.0
Epoch:  255        8 Batch loss: 0.239958 Batch F1: 0.0
Epoch:  255        9 Batch loss: 0.228360 Batch F1: 0.0
Epoch:  255       10 Batch loss: 0.242972 Batch F1: 0.0
Epoch:  255       11 Batch loss: 0.228254 Batch F1: 0.0
Epoch:  255       12 Batch loss: 0.200089 Batch F1: 0.0
Train Avg Loss  255: 0.227568

Train Avg F1  255: 0.0

Val Avg Loss  255: 0.217798

Val Avg F1  255:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 256
--------------------------------------------------------------
Epoch:  256        1 Batch loss: 0.241410 Batch F1: 0.0
Epoch:  256        2 Batch loss: 0.213237 Batch F1: 0.0
Epoch:  256        3 Batch loss: 0.227792 Batch F1: 0.0
Epoch:  256        4 Batch loss: 0.195063 Batch F1: 0.0
Epoch:  256        5 Batch loss: 0.229922 Batch F1: 0.0
Epoch:  256        6 Batch loss: 0.239452 Batch F1: 0.0
Epoch:  256        7 Batch loss: 0.198544 Batch F1: 0.0
Epoch:  256        8 Batch loss: 0.227653 Batch F1: 0.0
Epoch:  256        9 Batch loss: 0.215452 Batch F1: 0.09090909090909091
Epoch:  256       10 Batch loss: 0.261597 Batch F1: 0.0
Epoch:  256       11 Batch loss: 0.244122 Batch F1: 0.0
Epoch:  256       12 Batch loss: 0.235719 Batch F1: 0.0
Train Avg Loss  256: 0.227497

Train Avg F1  256: 0.007575757575757576

Val Avg Loss  256: 0.219106

Val Avg F1  256:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 257
--------------------------------------------------------------
Epoch:  257        1 Batch loss: 0.211013 Batch F1: 0.0
Epoch:  257        2 Batch loss: 0.234362 Batch F1: 0.0
Epoch:  257        3 Batch loss: 0.204646 Batch F1: 0.0
Epoch:  257        4 Batch loss: 0.218766 Batch F1: 0.0
Epoch:  257        5 Batch loss: 0.285997 Batch F1: 0.0
Epoch:  257        6 Batch loss: 0.204670 Batch F1: 0.0
Epoch:  257        7 Batch loss: 0.236356 Batch F1: 0.0
Epoch:  257        8 Batch loss: 0.258555 Batch F1: 0.0
Epoch:  257        9 Batch loss: 0.206738 Batch F1: 0.0
Epoch:  257       10 Batch loss: 0.250823 Batch F1: 0.0
Epoch:  257       11 Batch loss: 0.226152 Batch F1: 0.0
Epoch:  257       12 Batch loss: 0.215048 Batch F1: 0.0
Train Avg Loss  257: 0.229427

Train Avg F1  257: 0.0

Val Avg Loss  257: 0.220866

Val Avg F1  257:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 258
--------------------------------------------------------------
Epoch:  258        1 Batch loss: 0.208700 Batch F1: 0.0
Epoch:  258        2 Batch loss: 0.260202 Batch F1: 0.0
Epoch:  258        3 Batch loss: 0.233244 Batch F1: 0.0
Epoch:  258        4 Batch loss: 0.204179 Batch F1: 0.0
Epoch:  258        5 Batch loss: 0.228633 Batch F1: 0.0
Epoch:  258        6 Batch loss: 0.220872 Batch F1: 0.2727272727272727
Epoch:  258        7 Batch loss: 0.209693 Batch F1: 0.38095238095238093
Epoch:  258        8 Batch loss: 0.201378 Batch F1: 0.0
Epoch:  258        9 Batch loss: 0.225951 Batch F1: 0.0
Epoch:  258       10 Batch loss: 0.256135 Batch F1: 0.0
Epoch:  258       11 Batch loss: 0.240684 Batch F1: 0.0
Epoch:  258       12 Batch loss: 0.252249 Batch F1: 0.0
Train Avg Loss  258: 0.228493

Train Avg F1  258: 0.05447330447330447

Val Avg Loss  258: 0.221143

Val Avg F1  258:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 259
--------------------------------------------------------------
Epoch:  259        1 Batch loss: 0.240441 Batch F1: 0.0
Epoch:  259        2 Batch loss: 0.251130 Batch F1: 0.0
Epoch:  259        3 Batch loss: 0.215987 Batch F1: 0.0
Epoch:  259        4 Batch loss: 0.219996 Batch F1: 0.0
Epoch:  259        5 Batch loss: 0.236724 Batch F1: 0.0
Epoch:  259        6 Batch loss: 0.223224 Batch F1: 0.0
Epoch:  259        7 Batch loss: 0.228119 Batch F1: 0.0
Epoch:  259        8 Batch loss: 0.220100 Batch F1: 0.0
Epoch:  259        9 Batch loss: 0.221468 Batch F1: 0.0
Epoch:  259       10 Batch loss: 0.240578 Batch F1: 0.0
Epoch:  259       11 Batch loss: 0.221299 Batch F1: 0.0
Epoch:  259       12 Batch loss: 0.225917 Batch F1: 0.0
Train Avg Loss  259: 0.228749

Train Avg F1  259: 0.0

Val Avg Loss  259: 0.217877

Val Avg F1  259:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 260
--------------------------------------------------------------
Epoch:  260        1 Batch loss: 0.233190 Batch F1: 0.0
Epoch:  260        2 Batch loss: 0.214677 Batch F1: 0.0
Epoch:  260        3 Batch loss: 0.253825 Batch F1: 0.0
Epoch:  260        4 Batch loss: 0.223695 Batch F1: 0.0
Epoch:  260        5 Batch loss: 0.238528 Batch F1: 0.0
Epoch:  260        6 Batch loss: 0.233745 Batch F1: 0.0
Epoch:  260        7 Batch loss: 0.232092 Batch F1: 0.0
Epoch:  260        8 Batch loss: 0.235214 Batch F1: 0.0
Epoch:  260        9 Batch loss: 0.209780 Batch F1: 0.0
Epoch:  260       10 Batch loss: 0.230212 Batch F1: 0.0
Epoch:  260       11 Batch loss: 0.224229 Batch F1: 0.0
Epoch:  260       12 Batch loss: 0.189740 Batch F1: 0.0
Train Avg Loss  260: 0.226577

Train Avg F1  260: 0.0

Val Avg Loss  260: 0.217002

Val Avg F1  260:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 261
--------------------------------------------------------------
Epoch:  261        1 Batch loss: 0.196419 Batch F1: 0.0
Epoch:  261        2 Batch loss: 0.225353 Batch F1: 0.0
Epoch:  261        3 Batch loss: 0.236867 Batch F1: 0.0
Epoch:  261        4 Batch loss: 0.220161 Batch F1: 0.0
Epoch:  261        5 Batch loss: 0.262094 Batch F1: 0.0
Epoch:  261        6 Batch loss: 0.240456 Batch F1: 0.0
Epoch:  261        7 Batch loss: 0.251864 Batch F1: 0.0
Epoch:  261        8 Batch loss: 0.249016 Batch F1: 0.0
Epoch:  261        9 Batch loss: 0.217723 Batch F1: 0.5
Epoch:  261       10 Batch loss: 0.224805 Batch F1: 0.28571428571428575
Epoch:  261       11 Batch loss: 0.235893 Batch F1: 0.0
Epoch:  261       12 Batch loss: 0.218609 Batch F1: 0.0
Train Avg Loss  261: 0.231605

Train Avg F1  261: 0.06547619047619048

Val Avg Loss  261: 0.219499

Val Avg F1  261:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 262
--------------------------------------------------------------
Epoch:  262        1 Batch loss: 0.279818 Batch F1: 0.0
Epoch:  262        2 Batch loss: 0.216343 Batch F1: 0.0
Epoch:  262        3 Batch loss: 0.232768 Batch F1: 0.0
Epoch:  262        4 Batch loss: 0.218172 Batch F1: 0.0
Epoch:  262        5 Batch loss: 0.218986 Batch F1: 0.0
Epoch:  262        6 Batch loss: 0.217855 Batch F1: 0.0
Epoch:  262        7 Batch loss: 0.231231 Batch F1: 0.0
Epoch:  262        8 Batch loss: 0.208130 Batch F1: 0.0
Epoch:  262        9 Batch loss: 0.264247 Batch F1: 0.0
Epoch:  262       10 Batch loss: 0.203663 Batch F1: 0.0
Epoch:  262       11 Batch loss: 0.227163 Batch F1: 0.0
Epoch:  262       12 Batch loss: 0.210784 Batch F1: 0.0
Train Avg Loss  262: 0.227430

Train Avg F1  262: 0.0

Val Avg Loss  262: 0.217461

Val Avg F1  262:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 263
--------------------------------------------------------------
Epoch:  263        1 Batch loss: 0.238465 Batch F1: 0.0
Epoch:  263        2 Batch loss: 0.246848 Batch F1: 0.0
Epoch:  263        3 Batch loss: 0.226303 Batch F1: 0.0
Epoch:  263        4 Batch loss: 0.217818 Batch F1: 0.0
Epoch:  263        5 Batch loss: 0.213221 Batch F1: 0.0
Epoch:  263        6 Batch loss: 0.251101 Batch F1: 0.09090909090909091
Epoch:  263        7 Batch loss: 0.235828 Batch F1: 0.3333333333333333
Epoch:  263        8 Batch loss: 0.217107 Batch F1: 0.18181818181818182
Epoch:  263        9 Batch loss: 0.205522 Batch F1: 0.380952380952381
Epoch:  263       10 Batch loss: 0.222536 Batch F1: 0.0
Epoch:  263       11 Batch loss: 0.227368 Batch F1: 0.0
Epoch:  263       12 Batch loss: 0.232649 Batch F1: 0.0
Train Avg Loss  263: 0.227897

Train Avg F1  263: 0.08225108225108224

Val Avg Loss  263: 0.217076

Val Avg F1  263:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 264
--------------------------------------------------------------
Epoch:  264        1 Batch loss: 0.246760 Batch F1: 0.0
Epoch:  264        2 Batch loss: 0.280409 Batch F1: 0.0
Epoch:  264        3 Batch loss: 0.216400 Batch F1: 0.0
Epoch:  264        4 Batch loss: 0.210715 Batch F1: 0.0
Epoch:  264        5 Batch loss: 0.234103 Batch F1: 0.0
Epoch:  264        6 Batch loss: 0.216321 Batch F1: 0.0
Epoch:  264        7 Batch loss: 0.249702 Batch F1: 0.0
Epoch:  264        8 Batch loss: 0.230237 Batch F1: 0.0
Epoch:  264        9 Batch loss: 0.230481 Batch F1: 0.0
Epoch:  264       10 Batch loss: 0.205637 Batch F1: 0.0
Epoch:  264       11 Batch loss: 0.198617 Batch F1: 0.0
Epoch:  264       12 Batch loss: 0.236329 Batch F1: 0.0
Train Avg Loss  264: 0.229643

Train Avg F1  264: 0.0

Val Avg Loss  264: 0.217460

Val Avg F1  264:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 265
--------------------------------------------------------------
Epoch:  265        1 Batch loss: 0.242109 Batch F1: 0.0
Epoch:  265        2 Batch loss: 0.200471 Batch F1: 0.0
Epoch:  265        3 Batch loss: 0.282579 Batch F1: 0.0
Epoch:  265        4 Batch loss: 0.246859 Batch F1: 0.0
Epoch:  265        5 Batch loss: 0.196540 Batch F1: 0.0
Epoch:  265        6 Batch loss: 0.265253 Batch F1: 0.0
Epoch:  265        7 Batch loss: 0.224952 Batch F1: 0.0
Epoch:  265        8 Batch loss: 0.234464 Batch F1: 0.0
Epoch:  265        9 Batch loss: 0.204394 Batch F1: 0.0
Epoch:  265       10 Batch loss: 0.187668 Batch F1: 0.0
Epoch:  265       11 Batch loss: 0.235328 Batch F1: 0.0
Epoch:  265       12 Batch loss: 0.226609 Batch F1: 0.0
Train Avg Loss  265: 0.228935

Train Avg F1  265: 0.0

Val Avg Loss  265: 0.218026

Val Avg F1  265:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 266
--------------------------------------------------------------
Epoch:  266        1 Batch loss: 0.223163 Batch F1: 0.0
Epoch:  266        2 Batch loss: 0.220234 Batch F1: 0.0
Epoch:  266        3 Batch loss: 0.241942 Batch F1: 0.0
Epoch:  266        4 Batch loss: 0.224568 Batch F1: 0.0
Epoch:  266        5 Batch loss: 0.255897 Batch F1: 0.0
Epoch:  266        6 Batch loss: 0.200220 Batch F1: 0.0
Epoch:  266        7 Batch loss: 0.189117 Batch F1: 0.0
Epoch:  266        8 Batch loss: 0.249713 Batch F1: 0.0
Epoch:  266        9 Batch loss: 0.276679 Batch F1: 0.0
Epoch:  266       10 Batch loss: 0.199564 Batch F1: 0.0
Epoch:  266       11 Batch loss: 0.216188 Batch F1: 0.0
Epoch:  266       12 Batch loss: 0.221399 Batch F1: 0.0
Train Avg Loss  266: 0.226557

Train Avg F1  266: 0.0

Val Avg Loss  266: 0.217560

Val Avg F1  266:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 267
--------------------------------------------------------------
Epoch:  267        1 Batch loss: 0.252264 Batch F1: 0.0
Epoch:  267        2 Batch loss: 0.205014 Batch F1: 0.0
Epoch:  267        3 Batch loss: 0.205915 Batch F1: 0.0
Epoch:  267        4 Batch loss: 0.242425 Batch F1: 0.0
Epoch:  267        5 Batch loss: 0.208860 Batch F1: 0.0
Epoch:  267        6 Batch loss: 0.219391 Batch F1: 0.0
Epoch:  267        7 Batch loss: 0.226984 Batch F1: 0.0
Epoch:  267        8 Batch loss: 0.224260 Batch F1: 0.0
Epoch:  267        9 Batch loss: 0.206538 Batch F1: 0.0
Epoch:  267       10 Batch loss: 0.247142 Batch F1: 0.0
Epoch:  267       11 Batch loss: 0.233070 Batch F1: 0.0
Epoch:  267       12 Batch loss: 0.245523 Batch F1: 0.0
Train Avg Loss  267: 0.226449

Train Avg F1  267: 0.0

Val Avg Loss  267: 0.217425

Val Avg F1  267:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 268
--------------------------------------------------------------
Epoch:  268        1 Batch loss: 0.243422 Batch F1: 0.0
Epoch:  268        2 Batch loss: 0.226334 Batch F1: 0.0
Epoch:  268        3 Batch loss: 0.212772 Batch F1: 0.0
Epoch:  268        4 Batch loss: 0.192282 Batch F1: 0.0
Epoch:  268        5 Batch loss: 0.231482 Batch F1: 0.0
Epoch:  268        6 Batch loss: 0.238095 Batch F1: 0.0
Epoch:  268        7 Batch loss: 0.258586 Batch F1: 0.0
Epoch:  268        8 Batch loss: 0.205225 Batch F1: 0.0
Epoch:  268        9 Batch loss: 0.223620 Batch F1: 0.0
Epoch:  268       10 Batch loss: 0.247058 Batch F1: 0.0
Epoch:  268       11 Batch loss: 0.214289 Batch F1: 0.0
Epoch:  268       12 Batch loss: 0.215930 Batch F1: 0.0
Train Avg Loss  268: 0.225758

Train Avg F1  268: 0.0

Val Avg Loss  268: 0.217721

Val Avg F1  268:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 269
--------------------------------------------------------------
Epoch:  269        1 Batch loss: 0.196349 Batch F1: 0.0
Epoch:  269        2 Batch loss: 0.242806 Batch F1: 0.0
Epoch:  269        3 Batch loss: 0.223654 Batch F1: 0.0
Epoch:  269        4 Batch loss: 0.240770 Batch F1: 0.0
Epoch:  269        5 Batch loss: 0.229078 Batch F1: 0.0
Epoch:  269        6 Batch loss: 0.230698 Batch F1: 0.0
Epoch:  269        7 Batch loss: 0.241253 Batch F1: 0.0
Epoch:  269        8 Batch loss: 0.227141 Batch F1: 0.0
Epoch:  269        9 Batch loss: 0.204919 Batch F1: 0.0
Epoch:  269       10 Batch loss: 0.248414 Batch F1: 0.0
Epoch:  269       11 Batch loss: 0.216637 Batch F1: 0.0
Epoch:  269       12 Batch loss: 0.207076 Batch F1: 0.0
Train Avg Loss  269: 0.225733

Train Avg F1  269: 0.0

Val Avg Loss  269: 0.217541

Val Avg F1  269:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 270
--------------------------------------------------------------
Epoch:  270        1 Batch loss: 0.233460 Batch F1: 0.0
Epoch:  270        2 Batch loss: 0.253662 Batch F1: 0.0
Epoch:  270        3 Batch loss: 0.211496 Batch F1: 0.0
Epoch:  270        4 Batch loss: 0.256875 Batch F1: 0.0
Epoch:  270        5 Batch loss: 0.224732 Batch F1: 0.0
Epoch:  270        6 Batch loss: 0.197464 Batch F1: 0.0
Epoch:  270        7 Batch loss: 0.220601 Batch F1: 0.0
Epoch:  270        8 Batch loss: 0.219640 Batch F1: 0.0
Epoch:  270        9 Batch loss: 0.218712 Batch F1: 0.0
Epoch:  270       10 Batch loss: 0.230015 Batch F1: 0.0
Epoch:  270       11 Batch loss: 0.229681 Batch F1: 0.0
Epoch:  270       12 Batch loss: 0.209846 Batch F1: 0.0
Train Avg Loss  270: 0.225516

Train Avg F1  270: 0.0

Val Avg Loss  270: 0.217302

Val Avg F1  270:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 271
--------------------------------------------------------------
Epoch:  271        1 Batch loss: 0.202795 Batch F1: 0.0
Epoch:  271        2 Batch loss: 0.231024 Batch F1: 0.0
Epoch:  271        3 Batch loss: 0.232900 Batch F1: 0.0
Epoch:  271        4 Batch loss: 0.248675 Batch F1: 0.0
Epoch:  271        5 Batch loss: 0.229712 Batch F1: 0.0
Epoch:  271        6 Batch loss: 0.227312 Batch F1: 0.0
Epoch:  271        7 Batch loss: 0.229295 Batch F1: 0.0
Epoch:  271        8 Batch loss: 0.237450 Batch F1: 0.0
Epoch:  271        9 Batch loss: 0.199951 Batch F1: 0.0
Epoch:  271       10 Batch loss: 0.232244 Batch F1: 0.0
Epoch:  271       11 Batch loss: 0.197058 Batch F1: 0.0
Epoch:  271       12 Batch loss: 0.245562 Batch F1: 0.0
Train Avg Loss  271: 0.226165

Train Avg F1  271: 0.0

Val Avg Loss  271: 0.216308

Val Avg F1  271:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 272
--------------------------------------------------------------
Epoch:  272        1 Batch loss: 0.255205 Batch F1: 0.0
Epoch:  272        2 Batch loss: 0.209448 Batch F1: 0.0
Epoch:  272        3 Batch loss: 0.214115 Batch F1: 0.0
Epoch:  272        4 Batch loss: 0.233478 Batch F1: 0.0
Epoch:  272        5 Batch loss: 0.239369 Batch F1: 0.0
Epoch:  272        6 Batch loss: 0.203548 Batch F1: 0.0
Epoch:  272        7 Batch loss: 0.237586 Batch F1: 0.0
Epoch:  272        8 Batch loss: 0.219946 Batch F1: 0.0
Epoch:  272        9 Batch loss: 0.197435 Batch F1: 0.0
Epoch:  272       10 Batch loss: 0.228635 Batch F1: 0.0
Epoch:  272       11 Batch loss: 0.218289 Batch F1: 0.0
Epoch:  272       12 Batch loss: 0.267085 Batch F1: 0.0
Train Avg Loss  272: 0.227012

Train Avg F1  272: 0.0

Val Avg Loss  272: 0.217094

Val Avg F1  272:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 273
--------------------------------------------------------------
Epoch:  273        1 Batch loss: 0.210861 Batch F1: 0.0
Epoch:  273        2 Batch loss: 0.233108 Batch F1: 0.0
Epoch:  273        3 Batch loss: 0.204660 Batch F1: 0.0
Epoch:  273        4 Batch loss: 0.243001 Batch F1: 0.0
Epoch:  273        5 Batch loss: 0.240302 Batch F1: 0.0
Epoch:  273        6 Batch loss: 0.201799 Batch F1: 0.0
Epoch:  273        7 Batch loss: 0.211710 Batch F1: 0.0
Epoch:  273        8 Batch loss: 0.238240 Batch F1: 0.0
Epoch:  273        9 Batch loss: 0.238301 Batch F1: 0.0
Epoch:  273       10 Batch loss: 0.220374 Batch F1: 0.0
Epoch:  273       11 Batch loss: 0.251139 Batch F1: 0.0
Epoch:  273       12 Batch loss: 0.231621 Batch F1: 0.0
Train Avg Loss  273: 0.227093

Train Avg F1  273: 0.0

Val Avg Loss  273: 0.219786

Val Avg F1  273:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 274
--------------------------------------------------------------
Epoch:  274        1 Batch loss: 0.230014 Batch F1: 0.0
Epoch:  274        2 Batch loss: 0.225363 Batch F1: 0.0
Epoch:  274        3 Batch loss: 0.222995 Batch F1: 0.0
Epoch:  274        4 Batch loss: 0.245936 Batch F1: 0.0
Epoch:  274        5 Batch loss: 0.219013 Batch F1: 0.0
Epoch:  274        6 Batch loss: 0.206444 Batch F1: 0.0
Epoch:  274        7 Batch loss: 0.228417 Batch F1: 0.0
Epoch:  274        8 Batch loss: 0.230862 Batch F1: 0.0
Epoch:  274        9 Batch loss: 0.229616 Batch F1: 0.0
Epoch:  274       10 Batch loss: 0.201660 Batch F1: 0.0
Epoch:  274       11 Batch loss: 0.215009 Batch F1: 0.0
Epoch:  274       12 Batch loss: 0.285331 Batch F1: 0.0
Train Avg Loss  274: 0.228388

Train Avg F1  274: 0.0

Val Avg Loss  274: 0.217115

Val Avg F1  274:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 275
--------------------------------------------------------------
Epoch:  275        1 Batch loss: 0.192167 Batch F1: 0.0
Epoch:  275        2 Batch loss: 0.239991 Batch F1: 0.0
Epoch:  275        3 Batch loss: 0.247640 Batch F1: 0.0
Epoch:  275        4 Batch loss: 0.232668 Batch F1: 0.0
Epoch:  275        5 Batch loss: 0.218596 Batch F1: 0.0
Epoch:  275        6 Batch loss: 0.198802 Batch F1: 0.0
Epoch:  275        7 Batch loss: 0.237291 Batch F1: 0.0
Epoch:  275        8 Batch loss: 0.203362 Batch F1: 0.0
Epoch:  275        9 Batch loss: 0.218474 Batch F1: 0.0
Epoch:  275       10 Batch loss: 0.258587 Batch F1: 0.0
Epoch:  275       11 Batch loss: 0.211989 Batch F1: 0.0
Epoch:  275       12 Batch loss: 0.258404 Batch F1: 0.0
Train Avg Loss  275: 0.226498

Train Avg F1  275: 0.0

Val Avg Loss  275: 0.220090

Val Avg F1  275:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 276
--------------------------------------------------------------
Epoch:  276        1 Batch loss: 0.213516 Batch F1: 0.0
Epoch:  276        2 Batch loss: 0.213430 Batch F1: 0.0
Epoch:  276        3 Batch loss: 0.237997 Batch F1: 0.0
Epoch:  276        4 Batch loss: 0.240018 Batch F1: 0.0
Epoch:  276        5 Batch loss: 0.243650 Batch F1: 0.0
Epoch:  276        6 Batch loss: 0.237131 Batch F1: 0.0
Epoch:  276        7 Batch loss: 0.184832 Batch F1: 0.0
Epoch:  276        8 Batch loss: 0.227527 Batch F1: 0.0
Epoch:  276        9 Batch loss: 0.208614 Batch F1: 0.0
Epoch:  276       10 Batch loss: 0.283031 Batch F1: 0.0
Epoch:  276       11 Batch loss: 0.225241 Batch F1: 0.0
Epoch:  276       12 Batch loss: 0.199389 Batch F1: 0.0
Train Avg Loss  276: 0.226198

Train Avg F1  276: 0.0

Val Avg Loss  276: 0.217486

Val Avg F1  276:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 277
--------------------------------------------------------------
Epoch:  277        1 Batch loss: 0.247797 Batch F1: 0.0
Epoch:  277        2 Batch loss: 0.228690 Batch F1: 0.0
Epoch:  277        3 Batch loss: 0.254558 Batch F1: 0.0
Epoch:  277        4 Batch loss: 0.243034 Batch F1: 0.0
Epoch:  277        5 Batch loss: 0.228641 Batch F1: 0.0
Epoch:  277        6 Batch loss: 0.207970 Batch F1: 0.0
Epoch:  277        7 Batch loss: 0.225449 Batch F1: 0.0
Epoch:  277        8 Batch loss: 0.224039 Batch F1: 0.0
Epoch:  277        9 Batch loss: 0.192562 Batch F1: 0.0
Epoch:  277       10 Batch loss: 0.239494 Batch F1: 0.0
Epoch:  277       11 Batch loss: 0.212662 Batch F1: 0.0
Epoch:  277       12 Batch loss: 0.226033 Batch F1: 0.0
Train Avg Loss  277: 0.227577

Train Avg F1  277: 0.0

Val Avg Loss  277: 0.216987

Val Avg F1  277:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 278
--------------------------------------------------------------
Epoch:  278        1 Batch loss: 0.224963 Batch F1: 0.0
Epoch:  278        2 Batch loss: 0.229269 Batch F1: 0.0
Epoch:  278        3 Batch loss: 0.218146 Batch F1: 0.0
Epoch:  278        4 Batch loss: 0.216493 Batch F1: 0.0
Epoch:  278        5 Batch loss: 0.240042 Batch F1: 0.0
Epoch:  278        6 Batch loss: 0.233738 Batch F1: 0.0
Epoch:  278        7 Batch loss: 0.221731 Batch F1: 0.0
Epoch:  278        8 Batch loss: 0.244168 Batch F1: 0.0
Epoch:  278        9 Batch loss: 0.238986 Batch F1: 0.0
Epoch:  278       10 Batch loss: 0.223838 Batch F1: 0.0
Epoch:  278       11 Batch loss: 0.241847 Batch F1: 0.0
Epoch:  278       12 Batch loss: 0.182047 Batch F1: 0.0
Train Avg Loss  278: 0.226272

Train Avg F1  278: 0.0

Val Avg Loss  278: 0.218431

Val Avg F1  278:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 279
--------------------------------------------------------------
Epoch:  279        1 Batch loss: 0.221261 Batch F1: 0.0
Epoch:  279        2 Batch loss: 0.217996 Batch F1: 0.0
Epoch:  279        3 Batch loss: 0.232804 Batch F1: 0.0
Epoch:  279        4 Batch loss: 0.228564 Batch F1: 0.0
Epoch:  279        5 Batch loss: 0.216971 Batch F1: 0.0
Epoch:  279        6 Batch loss: 0.205540 Batch F1: 0.0
Epoch:  279        7 Batch loss: 0.263840 Batch F1: 0.0
Epoch:  279        8 Batch loss: 0.229869 Batch F1: 0.0
Epoch:  279        9 Batch loss: 0.217278 Batch F1: 0.0
Epoch:  279       10 Batch loss: 0.206333 Batch F1: 0.0
Epoch:  279       11 Batch loss: 0.229482 Batch F1: 0.0
Epoch:  279       12 Batch loss: 0.249787 Batch F1: 0.0
Train Avg Loss  279: 0.226644

Train Avg F1  279: 0.0

Val Avg Loss  279: 0.217065

Val Avg F1  279:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 280
--------------------------------------------------------------
Epoch:  280        1 Batch loss: 0.234769 Batch F1: 0.0
Epoch:  280        2 Batch loss: 0.249837 Batch F1: 0.0
Epoch:  280        3 Batch loss: 0.203555 Batch F1: 0.0
Epoch:  280        4 Batch loss: 0.235874 Batch F1: 0.0
Epoch:  280        5 Batch loss: 0.206885 Batch F1: 0.0
Epoch:  280        6 Batch loss: 0.234991 Batch F1: 0.0
Epoch:  280        7 Batch loss: 0.232278 Batch F1: 0.2608695652173913
Epoch:  280        8 Batch loss: 0.202922 Batch F1: 0.0
Epoch:  280        9 Batch loss: 0.228501 Batch F1: 0.0
Epoch:  280       10 Batch loss: 0.200315 Batch F1: 0.0
Epoch:  280       11 Batch loss: 0.247202 Batch F1: 0.0
Epoch:  280       12 Batch loss: 0.248476 Batch F1: 0.0
Train Avg Loss  280: 0.227134

Train Avg F1  280: 0.021739130434782608

Val Avg Loss  280: 0.217782

Val Avg F1  280:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 281
--------------------------------------------------------------
Epoch:  281        1 Batch loss: 0.229049 Batch F1: 0.0
Epoch:  281        2 Batch loss: 0.185982 Batch F1: 0.0
Epoch:  281        3 Batch loss: 0.232172 Batch F1: 0.0
Epoch:  281        4 Batch loss: 0.201325 Batch F1: 0.0
Epoch:  281        5 Batch loss: 0.252464 Batch F1: 0.0
Epoch:  281        6 Batch loss: 0.221617 Batch F1: 0.0
Epoch:  281        7 Batch loss: 0.261347 Batch F1: 0.0
Epoch:  281        8 Batch loss: 0.235342 Batch F1: 0.0
Epoch:  281        9 Batch loss: 0.212268 Batch F1: 0.0
Epoch:  281       10 Batch loss: 0.241195 Batch F1: 0.0
Epoch:  281       11 Batch loss: 0.217795 Batch F1: 0.0
Epoch:  281       12 Batch loss: 0.251107 Batch F1: 0.0
Train Avg Loss  281: 0.228472

Train Avg F1  281: 0.0

Val Avg Loss  281: 0.222995

Val Avg F1  281:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 282
--------------------------------------------------------------
Epoch:  282        1 Batch loss: 0.263857 Batch F1: 0.0
Epoch:  282        2 Batch loss: 0.237899 Batch F1: 0.0
Epoch:  282        3 Batch loss: 0.225677 Batch F1: 0.33333333333333337
Epoch:  282        4 Batch loss: 0.236071 Batch F1: 0.48484848484848486
Epoch:  282        5 Batch loss: 0.242013 Batch F1: 0.2222222222222222
Epoch:  282        6 Batch loss: 0.223710 Batch F1: 0.16666666666666666
Epoch:  282        7 Batch loss: 0.212025 Batch F1: 0.0
Epoch:  282        8 Batch loss: 0.201674 Batch F1: 0.0
Epoch:  282        9 Batch loss: 0.228264 Batch F1: 0.0
Epoch:  282       10 Batch loss: 0.228844 Batch F1: 0.0
Epoch:  282       11 Batch loss: 0.229907 Batch F1: 0.0
Epoch:  282       12 Batch loss: 0.226368 Batch F1: 0.0
Train Avg Loss  282: 0.229693

Train Avg F1  282: 0.1005892255892256

Val Avg Loss  282: 0.220846

Val Avg F1  282:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 283
--------------------------------------------------------------
Epoch:  283        1 Batch loss: 0.212656 Batch F1: 0.0
Epoch:  283        2 Batch loss: 0.230235 Batch F1: 0.0
Epoch:  283        3 Batch loss: 0.242324 Batch F1: 0.0
Epoch:  283        4 Batch loss: 0.221841 Batch F1: 0.0
Epoch:  283        5 Batch loss: 0.216135 Batch F1: 0.0
Epoch:  283        6 Batch loss: 0.235151 Batch F1: 0.0
Epoch:  283        7 Batch loss: 0.245020 Batch F1: 0.0
Epoch:  283        8 Batch loss: 0.194414 Batch F1: 0.0
Epoch:  283        9 Batch loss: 0.242107 Batch F1: 0.0
Epoch:  283       10 Batch loss: 0.237930 Batch F1: 0.0
Epoch:  283       11 Batch loss: 0.231464 Batch F1: 0.0
Epoch:  283       12 Batch loss: 0.234064 Batch F1: 0.0
Train Avg Loss  283: 0.228612

Train Avg F1  283: 0.0

Val Avg Loss  283: 0.223143

Val Avg F1  283:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 284
--------------------------------------------------------------
Epoch:  284        1 Batch loss: 0.218772 Batch F1: 0.0
Epoch:  284        2 Batch loss: 0.219987 Batch F1: 0.0
Epoch:  284        3 Batch loss: 0.215328 Batch F1: 0.0
Epoch:  284        4 Batch loss: 0.202386 Batch F1: 0.0
Epoch:  284        5 Batch loss: 0.276325 Batch F1: 0.0
Epoch:  284        6 Batch loss: 0.262173 Batch F1: 0.0
Epoch:  284        7 Batch loss: 0.209545 Batch F1: 0.0
Epoch:  284        8 Batch loss: 0.236197 Batch F1: 0.0
Epoch:  284        9 Batch loss: 0.223204 Batch F1: 0.0
Epoch:  284       10 Batch loss: 0.242707 Batch F1: 0.0
Epoch:  284       11 Batch loss: 0.214391 Batch F1: 0.0
Epoch:  284       12 Batch loss: 0.224054 Batch F1: 0.0
Train Avg Loss  284: 0.228756

Train Avg F1  284: 0.0

Val Avg Loss  284: 0.218467

Val Avg F1  284:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 285
--------------------------------------------------------------
Epoch:  285        1 Batch loss: 0.192626 Batch F1: 0.0
Epoch:  285        2 Batch loss: 0.280336 Batch F1: 0.0
Epoch:  285        3 Batch loss: 0.285463 Batch F1: 0.0
Epoch:  285        4 Batch loss: 0.221698 Batch F1: 0.0
Epoch:  285        5 Batch loss: 0.201564 Batch F1: 0.0
Epoch:  285        6 Batch loss: 0.227319 Batch F1: 0.0
Epoch:  285        7 Batch loss: 0.212268 Batch F1: 0.0
Epoch:  285        8 Batch loss: 0.224459 Batch F1: 0.0
Epoch:  285        9 Batch loss: 0.212107 Batch F1: 0.0
Epoch:  285       10 Batch loss: 0.189203 Batch F1: 0.0
Epoch:  285       11 Batch loss: 0.253911 Batch F1: 0.0
Epoch:  285       12 Batch loss: 0.224954 Batch F1: 0.0
Train Avg Loss  285: 0.227159

Train Avg F1  285: 0.0

Val Avg Loss  285: 0.217328

Val Avg F1  285:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 286
--------------------------------------------------------------
Epoch:  286        1 Batch loss: 0.236611 Batch F1: 0.0
Epoch:  286        2 Batch loss: 0.238609 Batch F1: 0.0
Epoch:  286        3 Batch loss: 0.260493 Batch F1: 0.0
Epoch:  286        4 Batch loss: 0.217295 Batch F1: 0.0
Epoch:  286        5 Batch loss: 0.247755 Batch F1: 0.0
Epoch:  286        6 Batch loss: 0.213660 Batch F1: 0.0
Epoch:  286        7 Batch loss: 0.238622 Batch F1: 0.29629629629629634
Epoch:  286        8 Batch loss: 0.211205 Batch F1: 0.2
Epoch:  286        9 Batch loss: 0.245573 Batch F1: 0.23076923076923075
Epoch:  286       10 Batch loss: 0.199138 Batch F1: 0.26666666666666666
Epoch:  286       11 Batch loss: 0.212012 Batch F1: 0.0
Epoch:  286       12 Batch loss: 0.197373 Batch F1: 0.0
Train Avg Loss  286: 0.226529

Train Avg F1  286: 0.08281101614434948

Val Avg Loss  286: 0.216719

Val Avg F1  286:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 287
--------------------------------------------------------------
Epoch:  287        1 Batch loss: 0.233959 Batch F1: 0.0
Epoch:  287        2 Batch loss: 0.208463 Batch F1: 0.0
Epoch:  287        3 Batch loss: 0.197849 Batch F1: 0.0
Epoch:  287        4 Batch loss: 0.229113 Batch F1: 0.0
Epoch:  287        5 Batch loss: 0.225282 Batch F1: 0.0
Epoch:  287        6 Batch loss: 0.189640 Batch F1: 0.0
Epoch:  287        7 Batch loss: 0.249823 Batch F1: 0.0
Epoch:  287        8 Batch loss: 0.253141 Batch F1: 0.0
Epoch:  287        9 Batch loss: 0.238911 Batch F1: 0.0
Epoch:  287       10 Batch loss: 0.234991 Batch F1: 0.0
Epoch:  287       11 Batch loss: 0.233529 Batch F1: 0.0
Epoch:  287       12 Batch loss: 0.231695 Batch F1: 0.0
Train Avg Loss  287: 0.227200

Train Avg F1  287: 0.0

Val Avg Loss  287: 0.217077

Val Avg F1  287:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 288
--------------------------------------------------------------
Epoch:  288        1 Batch loss: 0.263903 Batch F1: 0.0
Epoch:  288        2 Batch loss: 0.217426 Batch F1: 0.0
Epoch:  288        3 Batch loss: 0.220606 Batch F1: 0.0
Epoch:  288        4 Batch loss: 0.221091 Batch F1: 0.0
Epoch:  288        5 Batch loss: 0.238559 Batch F1: 0.0
Epoch:  288        6 Batch loss: 0.232560 Batch F1: 0.0
Epoch:  288        7 Batch loss: 0.209862 Batch F1: 0.0
Epoch:  288        8 Batch loss: 0.217009 Batch F1: 0.0
Epoch:  288        9 Batch loss: 0.229737 Batch F1: 0.0
Epoch:  288       10 Batch loss: 0.246497 Batch F1: 0.0
Epoch:  288       11 Batch loss: 0.194877 Batch F1: 0.0
Epoch:  288       12 Batch loss: 0.233209 Batch F1: 0.0
Train Avg Loss  288: 0.227111

Train Avg F1  288: 0.0

Val Avg Loss  288: 0.217000

Val Avg F1  288:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 289
--------------------------------------------------------------
Epoch:  289        1 Batch loss: 0.227877 Batch F1: 0.0
Epoch:  289        2 Batch loss: 0.234675 Batch F1: 0.0
Epoch:  289        3 Batch loss: 0.230638 Batch F1: 0.0
Epoch:  289        4 Batch loss: 0.251887 Batch F1: 0.0
Epoch:  289        5 Batch loss: 0.216279 Batch F1: 0.0
Epoch:  289        6 Batch loss: 0.244787 Batch F1: 0.0
Epoch:  289        7 Batch loss: 0.216848 Batch F1: 0.0
Epoch:  289        8 Batch loss: 0.240175 Batch F1: 0.0
Epoch:  289        9 Batch loss: 0.199061 Batch F1: 0.0
Epoch:  289       10 Batch loss: 0.247266 Batch F1: 0.0
Epoch:  289       11 Batch loss: 0.192665 Batch F1: 0.0
Epoch:  289       12 Batch loss: 0.211117 Batch F1: 0.0
Train Avg Loss  289: 0.226106

Train Avg F1  289: 0.0

Val Avg Loss  289: 0.217961

Val Avg F1  289:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 290
--------------------------------------------------------------
Epoch:  290        1 Batch loss: 0.242325 Batch F1: 0.0
Epoch:  290        2 Batch loss: 0.235640 Batch F1: 0.0
Epoch:  290        3 Batch loss: 0.223740 Batch F1: 0.0
Epoch:  290        4 Batch loss: 0.255042 Batch F1: 0.0
Epoch:  290        5 Batch loss: 0.223075 Batch F1: 0.38461538461538464
Epoch:  290        6 Batch loss: 0.219939 Batch F1: 0.3846153846153846
Epoch:  290        7 Batch loss: 0.202725 Batch F1: 0.2608695652173913
Epoch:  290        8 Batch loss: 0.225864 Batch F1: 0.0
Epoch:  290        9 Batch loss: 0.224121 Batch F1: 0.0
Epoch:  290       10 Batch loss: 0.223325 Batch F1: 0.0
Epoch:  290       11 Batch loss: 0.204341 Batch F1: 0.0
Epoch:  290       12 Batch loss: 0.243616 Batch F1: 0.0
Train Avg Loss  290: 0.226979

Train Avg F1  290: 0.0858416945373467

Val Avg Loss  290: 0.216491

Val Avg F1  290:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 291
--------------------------------------------------------------
Epoch:  291        1 Batch loss: 0.173072 Batch F1: 0.0
Epoch:  291        2 Batch loss: 0.218278 Batch F1: 0.0
Epoch:  291        3 Batch loss: 0.199766 Batch F1: 0.0
Epoch:  291        4 Batch loss: 0.274522 Batch F1: 0.0
Epoch:  291        5 Batch loss: 0.188363 Batch F1: 0.0
Epoch:  291        6 Batch loss: 0.232863 Batch F1: 0.0
Epoch:  291        7 Batch loss: 0.252537 Batch F1: 0.0
Epoch:  291        8 Batch loss: 0.236355 Batch F1: 0.0
Epoch:  291        9 Batch loss: 0.218444 Batch F1: 0.0
Epoch:  291       10 Batch loss: 0.237461 Batch F1: 0.0
Epoch:  291       11 Batch loss: 0.254933 Batch F1: 0.0
Epoch:  291       12 Batch loss: 0.226379 Batch F1: 0.0
Train Avg Loss  291: 0.226081

Train Avg F1  291: 0.0

Val Avg Loss  291: 0.220310

Val Avg F1  291:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 292
--------------------------------------------------------------
Epoch:  292        1 Batch loss: 0.276551 Batch F1: 0.0
Epoch:  292        2 Batch loss: 0.225068 Batch F1: 0.0
Epoch:  292        3 Batch loss: 0.223448 Batch F1: 0.0
Epoch:  292        4 Batch loss: 0.218704 Batch F1: 0.0
Epoch:  292        5 Batch loss: 0.219628 Batch F1: 0.0
Epoch:  292        6 Batch loss: 0.193304 Batch F1: 0.0
Epoch:  292        7 Batch loss: 0.245621 Batch F1: 0.0
Epoch:  292        8 Batch loss: 0.250994 Batch F1: 0.0
Epoch:  292        9 Batch loss: 0.236267 Batch F1: 0.0
Epoch:  292       10 Batch loss: 0.210792 Batch F1: 0.0
Epoch:  292       11 Batch loss: 0.250966 Batch F1: 0.0
Epoch:  292       12 Batch loss: 0.191525 Batch F1: 0.0
Train Avg Loss  292: 0.228572

Train Avg F1  292: 0.0

Val Avg Loss  292: 0.219688

Val Avg F1  292:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 293
--------------------------------------------------------------
Epoch:  293        1 Batch loss: 0.267697 Batch F1: 0.0
Epoch:  293        2 Batch loss: 0.232957 Batch F1: 0.0
Epoch:  293        3 Batch loss: 0.196013 Batch F1: 0.0
Epoch:  293        4 Batch loss: 0.209816 Batch F1: 0.0
Epoch:  293        5 Batch loss: 0.233090 Batch F1: 0.0
Epoch:  293        6 Batch loss: 0.259229 Batch F1: 0.0
Epoch:  293        7 Batch loss: 0.209036 Batch F1: 0.0
Epoch:  293        8 Batch loss: 0.221255 Batch F1: 0.0
Epoch:  293        9 Batch loss: 0.212048 Batch F1: 0.0
Epoch:  293       10 Batch loss: 0.236378 Batch F1: 0.0
Epoch:  293       11 Batch loss: 0.226538 Batch F1: 0.0
Epoch:  293       12 Batch loss: 0.239625 Batch F1: 0.0
Train Avg Loss  293: 0.228640

Train Avg F1  293: 0.0

Val Avg Loss  293: 0.218483

Val Avg F1  293:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 294
--------------------------------------------------------------
Epoch:  294        1 Batch loss: 0.236276 Batch F1: 0.0
Epoch:  294        2 Batch loss: 0.246672 Batch F1: 0.0
Epoch:  294        3 Batch loss: 0.221209 Batch F1: 0.0
Epoch:  294        4 Batch loss: 0.208695 Batch F1: 0.3846153846153846
Epoch:  294        5 Batch loss: 0.221718 Batch F1: 0.22222222222222224
Epoch:  294        6 Batch loss: 0.219559 Batch F1: 0.0
Epoch:  294        7 Batch loss: 0.206254 Batch F1: 0.0
Epoch:  294        8 Batch loss: 0.207113 Batch F1: 0.0
Epoch:  294        9 Batch loss: 0.254214 Batch F1: 0.0
Epoch:  294       10 Batch loss: 0.216444 Batch F1: 0.0
Epoch:  294       11 Batch loss: 0.275813 Batch F1: 0.0
Epoch:  294       12 Batch loss: 0.228104 Batch F1: 0.0
Train Avg Loss  294: 0.228506

Train Avg F1  294: 0.050569800569800566

Val Avg Loss  294: 0.219095

Val Avg F1  294:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 295
--------------------------------------------------------------
Epoch:  295        1 Batch loss: 0.258001 Batch F1: 0.0
Epoch:  295        2 Batch loss: 0.229019 Batch F1: 0.0
Epoch:  295        3 Batch loss: 0.201700 Batch F1: 0.0
Epoch:  295        4 Batch loss: 0.197814 Batch F1: 0.0
Epoch:  295        5 Batch loss: 0.230768 Batch F1: 0.0
Epoch:  295        6 Batch loss: 0.270378 Batch F1: 0.0
Epoch:  295        7 Batch loss: 0.232722 Batch F1: 0.0
Epoch:  295        8 Batch loss: 0.263203 Batch F1: 0.0
Epoch:  295        9 Batch loss: 0.195156 Batch F1: 0.0
Epoch:  295       10 Batch loss: 0.227455 Batch F1: 0.0
Epoch:  295       11 Batch loss: 0.225286 Batch F1: 0.0
Epoch:  295       12 Batch loss: 0.234305 Batch F1: 0.0
Train Avg Loss  295: 0.230484

Train Avg F1  295: 0.0

Val Avg Loss  295: 0.218710

Val Avg F1  295:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 296
--------------------------------------------------------------
Epoch:  296        1 Batch loss: 0.206574 Batch F1: 0.0
Epoch:  296        2 Batch loss: 0.252624 Batch F1: 0.0
Epoch:  296        3 Batch loss: 0.202277 Batch F1: 0.0
Epoch:  296        4 Batch loss: 0.259214 Batch F1: 0.0
Epoch:  296        5 Batch loss: 0.237379 Batch F1: 0.0
Epoch:  296        6 Batch loss: 0.236062 Batch F1: 0.0
Epoch:  296        7 Batch loss: 0.222240 Batch F1: 0.0
Epoch:  296        8 Batch loss: 0.236545 Batch F1: 0.0
Epoch:  296        9 Batch loss: 0.235994 Batch F1: 0.0
Epoch:  296       10 Batch loss: 0.216725 Batch F1: 0.0
Epoch:  296       11 Batch loss: 0.196416 Batch F1: 0.0
Epoch:  296       12 Batch loss: 0.233848 Batch F1: 0.0
Train Avg Loss  296: 0.227991

Train Avg F1  296: 0.0

Val Avg Loss  296: 0.219215

Val Avg F1  296:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 297
--------------------------------------------------------------
Epoch:  297        1 Batch loss: 0.225612 Batch F1: 0.0
Epoch:  297        2 Batch loss: 0.230419 Batch F1: 0.0
Epoch:  297        3 Batch loss: 0.203339 Batch F1: 0.0
Epoch:  297        4 Batch loss: 0.242942 Batch F1: 0.0
Epoch:  297        5 Batch loss: 0.242726 Batch F1: 0.0
Epoch:  297        6 Batch loss: 0.254256 Batch F1: 0.0
Epoch:  297        7 Batch loss: 0.240644 Batch F1: 0.0
Epoch:  297        8 Batch loss: 0.225393 Batch F1: 0.0
Epoch:  297        9 Batch loss: 0.210542 Batch F1: 0.0
Epoch:  297       10 Batch loss: 0.209613 Batch F1: 0.0
Epoch:  297       11 Batch loss: 0.228013 Batch F1: 0.0
Epoch:  297       12 Batch loss: 0.202100 Batch F1: 0.0
Train Avg Loss  297: 0.226300

Train Avg F1  297: 0.0

Val Avg Loss  297: 0.217604

Val Avg F1  297:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 298
--------------------------------------------------------------
Epoch:  298        1 Batch loss: 0.258224 Batch F1: 0.0
Epoch:  298        2 Batch loss: 0.215616 Batch F1: 0.0
Epoch:  298        3 Batch loss: 0.220107 Batch F1: 0.0
Epoch:  298        4 Batch loss: 0.234048 Batch F1: 0.0
Epoch:  298        5 Batch loss: 0.243118 Batch F1: 0.0
Epoch:  298        6 Batch loss: 0.235567 Batch F1: 0.0
Epoch:  298        7 Batch loss: 0.187889 Batch F1: 0.0
Epoch:  298        8 Batch loss: 0.232795 Batch F1: 0.0
Epoch:  298        9 Batch loss: 0.222351 Batch F1: 0.0
Epoch:  298       10 Batch loss: 0.211266 Batch F1: 0.0
Epoch:  298       11 Batch loss: 0.219525 Batch F1: 0.0
Epoch:  298       12 Batch loss: 0.230121 Batch F1: 0.0
Train Avg Loss  298: 0.225886

Train Avg F1  298: 0.0

Val Avg Loss  298: 0.216900

Val Avg F1  298:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 299
--------------------------------------------------------------
Epoch:  299        1 Batch loss: 0.251418 Batch F1: 0.0
Epoch:  299        2 Batch loss: 0.260268 Batch F1: 0.0
Epoch:  299        3 Batch loss: 0.247153 Batch F1: 0.0
Epoch:  299        4 Batch loss: 0.179391 Batch F1: 0.0
Epoch:  299        5 Batch loss: 0.206816 Batch F1: 0.0
Epoch:  299        6 Batch loss: 0.208986 Batch F1: 0.0
Epoch:  299        7 Batch loss: 0.233368 Batch F1: 0.0
Epoch:  299        8 Batch loss: 0.219665 Batch F1: 0.0
Epoch:  299        9 Batch loss: 0.246749 Batch F1: 0.0
Epoch:  299       10 Batch loss: 0.207964 Batch F1: 0.0
Epoch:  299       11 Batch loss: 0.202852 Batch F1: 0.0
Epoch:  299       12 Batch loss: 0.256985 Batch F1: 0.0
Train Avg Loss  299: 0.226801

Train Avg F1  299: 0.0

Val Avg Loss  299: 0.217081

Val Avg F1  299:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 300
--------------------------------------------------------------
Epoch:  300        1 Batch loss: 0.223036 Batch F1: 0.0
Epoch:  300        2 Batch loss: 0.245121 Batch F1: 0.0
Epoch:  300        3 Batch loss: 0.221066 Batch F1: 0.0
Epoch:  300        4 Batch loss: 0.216056 Batch F1: 0.0
Epoch:  300        5 Batch loss: 0.238240 Batch F1: 0.0
Epoch:  300        6 Batch loss: 0.222920 Batch F1: 0.0
Epoch:  300        7 Batch loss: 0.211949 Batch F1: 0.0
Epoch:  300        8 Batch loss: 0.229381 Batch F1: 0.0
Epoch:  300        9 Batch loss: 0.234800 Batch F1: 0.0
Epoch:  300       10 Batch loss: 0.194178 Batch F1: 0.0
Epoch:  300       11 Batch loss: 0.227731 Batch F1: 0.0
Epoch:  300       12 Batch loss: 0.259161 Batch F1: 0.0
Train Avg Loss  300: 0.226970

Train Avg F1  300: 0.0

Val Avg Loss  300: 0.216836

Val Avg F1  300:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 301
--------------------------------------------------------------
Epoch:  301        1 Batch loss: 0.240471 Batch F1: 0.0
Epoch:  301        2 Batch loss: 0.258299 Batch F1: 0.0
Epoch:  301        3 Batch loss: 0.238870 Batch F1: 0.0
Epoch:  301        4 Batch loss: 0.222734 Batch F1: 0.0
Epoch:  301        5 Batch loss: 0.195020 Batch F1: 0.0
Epoch:  301        6 Batch loss: 0.242388 Batch F1: 0.0
Epoch:  301        7 Batch loss: 0.225299 Batch F1: 0.0
Epoch:  301        8 Batch loss: 0.201402 Batch F1: 0.0
Epoch:  301        9 Batch loss: 0.216889 Batch F1: 0.0
Epoch:  301       10 Batch loss: 0.201594 Batch F1: 0.0
Epoch:  301       11 Batch loss: 0.234465 Batch F1: 0.0
Epoch:  301       12 Batch loss: 0.248743 Batch F1: 0.0
Train Avg Loss  301: 0.227181

Train Avg F1  301: 0.0

Val Avg Loss  301: 0.217441

Val Avg F1  301:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 302
--------------------------------------------------------------
Epoch:  302        1 Batch loss: 0.248833 Batch F1: 0.0
Epoch:  302        2 Batch loss: 0.213484 Batch F1: 0.0
Epoch:  302        3 Batch loss: 0.239650 Batch F1: 0.0
Epoch:  302        4 Batch loss: 0.294627 Batch F1: 0.0
Epoch:  302        5 Batch loss: 0.220521 Batch F1: 0.0
Epoch:  302        6 Batch loss: 0.223884 Batch F1: 0.0
Epoch:  302        7 Batch loss: 0.206923 Batch F1: 0.0
Epoch:  302        8 Batch loss: 0.232107 Batch F1: 0.0
Epoch:  302        9 Batch loss: 0.214138 Batch F1: 0.0
Epoch:  302       10 Batch loss: 0.252229 Batch F1: 0.0
Epoch:  302       11 Batch loss: 0.193320 Batch F1: 0.0
Epoch:  302       12 Batch loss: 0.209600 Batch F1: 0.0
Train Avg Loss  302: 0.229110

Train Avg F1  302: 0.0

Val Avg Loss  302: 0.217626

Val Avg F1  302:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 303
--------------------------------------------------------------
Epoch:  303        1 Batch loss: 0.274439 Batch F1: 0.0
Epoch:  303        2 Batch loss: 0.198859 Batch F1: 0.0
Epoch:  303        3 Batch loss: 0.218756 Batch F1: 0.0
Epoch:  303        4 Batch loss: 0.214810 Batch F1: 0.0
Epoch:  303        5 Batch loss: 0.267982 Batch F1: 0.0
Epoch:  303        6 Batch loss: 0.220222 Batch F1: 0.0
Epoch:  303        7 Batch loss: 0.212807 Batch F1: 0.0
Epoch:  303        8 Batch loss: 0.207211 Batch F1: 0.0
Epoch:  303        9 Batch loss: 0.238259 Batch F1: 0.0
Epoch:  303       10 Batch loss: 0.253005 Batch F1: 0.0
Epoch:  303       11 Batch loss: 0.219279 Batch F1: 0.0
Epoch:  303       12 Batch loss: 0.200928 Batch F1: 0.0
Train Avg Loss  303: 0.227213

Train Avg F1  303: 0.0

Val Avg Loss  303: 0.218468

Val Avg F1  303:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 304
--------------------------------------------------------------
Epoch:  304        1 Batch loss: 0.235956 Batch F1: 0.0
Epoch:  304        2 Batch loss: 0.246074 Batch F1: 0.0
Epoch:  304        3 Batch loss: 0.240898 Batch F1: 0.0
Epoch:  304        4 Batch loss: 0.222095 Batch F1: 0.23076923076923078
Epoch:  304        5 Batch loss: 0.247276 Batch F1: 0.2857142857142857
Epoch:  304        6 Batch loss: 0.241155 Batch F1: 0.15384615384615383
Epoch:  304        7 Batch loss: 0.203485 Batch F1: 0.5833333333333334
Epoch:  304        8 Batch loss: 0.227468 Batch F1: 0.35714285714285715
Epoch:  304        9 Batch loss: 0.207466 Batch F1: 0.2
Epoch:  304       10 Batch loss: 0.207067 Batch F1: 0.0
Epoch:  304       11 Batch loss: 0.205672 Batch F1: 0.0
Epoch:  304       12 Batch loss: 0.253676 Batch F1: 0.0
Train Avg Loss  304: 0.228191

Train Avg F1  304: 0.1509004884004884

Val Avg Loss  304: 0.218085

Val Avg F1  304:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 305
--------------------------------------------------------------
Epoch:  305        1 Batch loss: 0.240216 Batch F1: 0.0
Epoch:  305        2 Batch loss: 0.259148 Batch F1: 0.0
Epoch:  305        3 Batch loss: 0.257832 Batch F1: 0.0
Epoch:  305        4 Batch loss: 0.210908 Batch F1: 0.0
Epoch:  305        5 Batch loss: 0.203514 Batch F1: 0.0
Epoch:  305        6 Batch loss: 0.230462 Batch F1: 0.0
Epoch:  305        7 Batch loss: 0.223817 Batch F1: 0.0
Epoch:  305        8 Batch loss: 0.219162 Batch F1: 0.0
Epoch:  305        9 Batch loss: 0.199931 Batch F1: 0.0
Epoch:  305       10 Batch loss: 0.226800 Batch F1: 0.0
Epoch:  305       11 Batch loss: 0.201297 Batch F1: 0.0
Epoch:  305       12 Batch loss: 0.252506 Batch F1: 0.0
Train Avg Loss  305: 0.227133

Train Avg F1  305: 0.0

Val Avg Loss  305: 0.216278

Val Avg F1  305:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 306
--------------------------------------------------------------
Epoch:  306        1 Batch loss: 0.243929 Batch F1: 0.0
Epoch:  306        2 Batch loss: 0.198521 Batch F1: 0.0
Epoch:  306        3 Batch loss: 0.228904 Batch F1: 0.0
Epoch:  306        4 Batch loss: 0.238149 Batch F1: 0.0
Epoch:  306        5 Batch loss: 0.198477 Batch F1: 0.0
Epoch:  306        6 Batch loss: 0.239164 Batch F1: 0.0
Epoch:  306        7 Batch loss: 0.218488 Batch F1: 0.0
Epoch:  306        8 Batch loss: 0.225037 Batch F1: 0.0
Epoch:  306        9 Batch loss: 0.229006 Batch F1: 0.0
Epoch:  306       10 Batch loss: 0.230075 Batch F1: 0.0
Epoch:  306       11 Batch loss: 0.242072 Batch F1: 0.0
Epoch:  306       12 Batch loss: 0.217366 Batch F1: 0.0
Train Avg Loss  306: 0.225766

Train Avg F1  306: 0.0

Val Avg Loss  306: 0.217691

Val Avg F1  306:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 307
--------------------------------------------------------------
Epoch:  307        1 Batch loss: 0.252872 Batch F1: 0.0
Epoch:  307        2 Batch loss: 0.241574 Batch F1: 0.0
Epoch:  307        3 Batch loss: 0.244695 Batch F1: 0.0
Epoch:  307        4 Batch loss: 0.220839 Batch F1: 0.0
Epoch:  307        5 Batch loss: 0.234486 Batch F1: 0.0
Epoch:  307        6 Batch loss: 0.207780 Batch F1: 0.0
Epoch:  307        7 Batch loss: 0.222741 Batch F1: 0.0
Epoch:  307        8 Batch loss: 0.210061 Batch F1: 0.0
Epoch:  307        9 Batch loss: 0.208846 Batch F1: 0.0
Epoch:  307       10 Batch loss: 0.224577 Batch F1: 0.0
Epoch:  307       11 Batch loss: 0.231812 Batch F1: 0.0
Epoch:  307       12 Batch loss: 0.208937 Batch F1: 0.0
Train Avg Loss  307: 0.225768

Train Avg F1  307: 0.0

Val Avg Loss  307: 0.217624

Val Avg F1  307:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 308
--------------------------------------------------------------
Epoch:  308        1 Batch loss: 0.217973 Batch F1: 0.0
Epoch:  308        2 Batch loss: 0.205211 Batch F1: 0.0
Epoch:  308        3 Batch loss: 0.236316 Batch F1: 0.0
Epoch:  308        4 Batch loss: 0.209018 Batch F1: 0.0
Epoch:  308        5 Batch loss: 0.206601 Batch F1: 0.0
Epoch:  308        6 Batch loss: 0.250863 Batch F1: 0.0
Epoch:  308        7 Batch loss: 0.248291 Batch F1: 0.0
Epoch:  308        8 Batch loss: 0.230800 Batch F1: 0.0
Epoch:  308        9 Batch loss: 0.222718 Batch F1: 0.0
Epoch:  308       10 Batch loss: 0.217004 Batch F1: 0.0
Epoch:  308       11 Batch loss: 0.207957 Batch F1: 0.0
Epoch:  308       12 Batch loss: 0.279247 Batch F1: 0.0
Train Avg Loss  308: 0.227666

Train Avg F1  308: 0.0

Val Avg Loss  308: 0.217399

Val Avg F1  308:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 309
--------------------------------------------------------------
Epoch:  309        1 Batch loss: 0.228062 Batch F1: 0.0
Epoch:  309        2 Batch loss: 0.212212 Batch F1: 0.0
Epoch:  309        3 Batch loss: 0.233325 Batch F1: 0.0
Epoch:  309        4 Batch loss: 0.232741 Batch F1: 0.0
Epoch:  309        5 Batch loss: 0.226922 Batch F1: 0.0
Epoch:  309        6 Batch loss: 0.235413 Batch F1: 0.0
Epoch:  309        7 Batch loss: 0.226894 Batch F1: 0.0
Epoch:  309        8 Batch loss: 0.215421 Batch F1: 0.0
Epoch:  309        9 Batch loss: 0.205067 Batch F1: 0.0
Epoch:  309       10 Batch loss: 0.260198 Batch F1: 0.0
Epoch:  309       11 Batch loss: 0.207269 Batch F1: 0.0
Epoch:  309       12 Batch loss: 0.233177 Batch F1: 0.0
Train Avg Loss  309: 0.226392

Train Avg F1  309: 0.0

Val Avg Loss  309: 0.217866

Val Avg F1  309:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 310
--------------------------------------------------------------
Epoch:  310        1 Batch loss: 0.214382 Batch F1: 0.0
Epoch:  310        2 Batch loss: 0.239100 Batch F1: 0.0
Epoch:  310        3 Batch loss: 0.223366 Batch F1: 0.0
Epoch:  310        4 Batch loss: 0.235513 Batch F1: 0.0
Epoch:  310        5 Batch loss: 0.233248 Batch F1: 0.0
Epoch:  310        6 Batch loss: 0.222908 Batch F1: 0.0
Epoch:  310        7 Batch loss: 0.228619 Batch F1: 0.0
Epoch:  310        8 Batch loss: 0.177395 Batch F1: 0.0
Epoch:  310        9 Batch loss: 0.228512 Batch F1: 0.0
Epoch:  310       10 Batch loss: 0.268883 Batch F1: 0.0
Epoch:  310       11 Batch loss: 0.201478 Batch F1: 0.0
Epoch:  310       12 Batch loss: 0.238370 Batch F1: 0.0
Train Avg Loss  310: 0.225981

Train Avg F1  310: 0.0

Val Avg Loss  310: 0.217147

Val Avg F1  310:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 311
--------------------------------------------------------------
Epoch:  311        1 Batch loss: 0.197856 Batch F1: 0.0
Epoch:  311        2 Batch loss: 0.234838 Batch F1: 0.0
Epoch:  311        3 Batch loss: 0.232660 Batch F1: 0.0
Epoch:  311        4 Batch loss: 0.217502 Batch F1: 0.0
Epoch:  311        5 Batch loss: 0.222564 Batch F1: 0.0
Epoch:  311        6 Batch loss: 0.231508 Batch F1: 0.0
Epoch:  311        7 Batch loss: 0.226448 Batch F1: 0.0
Epoch:  311        8 Batch loss: 0.228163 Batch F1: 0.0
Epoch:  311        9 Batch loss: 0.241198 Batch F1: 0.0
Epoch:  311       10 Batch loss: 0.230082 Batch F1: 0.0
Epoch:  311       11 Batch loss: 0.206951 Batch F1: 0.0
Epoch:  311       12 Batch loss: 0.245210 Batch F1: 0.0
Train Avg Loss  311: 0.226248

Train Avg F1  311: 0.0

Val Avg Loss  311: 0.217461

Val Avg F1  311:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 312
--------------------------------------------------------------
Epoch:  312        1 Batch loss: 0.206511 Batch F1: 0.0
Epoch:  312        2 Batch loss: 0.188512 Batch F1: 0.0
Epoch:  312        3 Batch loss: 0.262999 Batch F1: 0.0
Epoch:  312        4 Batch loss: 0.243534 Batch F1: 0.0
Epoch:  312        5 Batch loss: 0.204788 Batch F1: 0.0
Epoch:  312        6 Batch loss: 0.227076 Batch F1: 0.0
Epoch:  312        7 Batch loss: 0.213884 Batch F1: 0.0
Epoch:  312        8 Batch loss: 0.238020 Batch F1: 0.0
Epoch:  312        9 Batch loss: 0.237577 Batch F1: 0.0
Epoch:  312       10 Batch loss: 0.241833 Batch F1: 0.0
Epoch:  312       11 Batch loss: 0.226711 Batch F1: 0.0
Epoch:  312       12 Batch loss: 0.217832 Batch F1: 0.0
Train Avg Loss  312: 0.225773

Train Avg F1  312: 0.0

Val Avg Loss  312: 0.218135

Val Avg F1  312:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 313
--------------------------------------------------------------
Epoch:  313        1 Batch loss: 0.268117 Batch F1: 0.0
Epoch:  313        2 Batch loss: 0.212800 Batch F1: 0.0
Epoch:  313        3 Batch loss: 0.214067 Batch F1: 0.0
Epoch:  313        4 Batch loss: 0.209576 Batch F1: 0.0
Epoch:  313        5 Batch loss: 0.243976 Batch F1: 0.0
Epoch:  313        6 Batch loss: 0.206422 Batch F1: 0.0
Epoch:  313        7 Batch loss: 0.217631 Batch F1: 0.0
Epoch:  313        8 Batch loss: 0.230454 Batch F1: 0.0
Epoch:  313        9 Batch loss: 0.235768 Batch F1: 0.0
Epoch:  313       10 Batch loss: 0.236878 Batch F1: 0.0
Epoch:  313       11 Batch loss: 0.207948 Batch F1: 0.0
Epoch:  313       12 Batch loss: 0.226968 Batch F1: 0.0
Train Avg Loss  313: 0.225884

Train Avg F1  313: 0.0

Val Avg Loss  313: 0.217479

Val Avg F1  313:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 314
--------------------------------------------------------------
Epoch:  314        1 Batch loss: 0.236791 Batch F1: 0.0
Epoch:  314        2 Batch loss: 0.218481 Batch F1: 0.0
Epoch:  314        3 Batch loss: 0.226503 Batch F1: 0.0
Epoch:  314        4 Batch loss: 0.197699 Batch F1: 0.0
Epoch:  314        5 Batch loss: 0.243005 Batch F1: 0.0
Epoch:  314        6 Batch loss: 0.250805 Batch F1: 0.0
Epoch:  314        7 Batch loss: 0.208925 Batch F1: 0.0
Epoch:  314        8 Batch loss: 0.233084 Batch F1: 0.0
Epoch:  314        9 Batch loss: 0.208043 Batch F1: 0.0
Epoch:  314       10 Batch loss: 0.210658 Batch F1: 0.0
Epoch:  314       11 Batch loss: 0.261847 Batch F1: 0.0
Epoch:  314       12 Batch loss: 0.211425 Batch F1: 0.0
Train Avg Loss  314: 0.225605

Train Avg F1  314: 0.0

Val Avg Loss  314: 0.216646

Val Avg F1  314:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 315
--------------------------------------------------------------
Epoch:  315        1 Batch loss: 0.211748 Batch F1: 0.0
Epoch:  315        2 Batch loss: 0.230941 Batch F1: 0.0
Epoch:  315        3 Batch loss: 0.195043 Batch F1: 0.0
Epoch:  315        4 Batch loss: 0.229241 Batch F1: 0.0
Epoch:  315        5 Batch loss: 0.228884 Batch F1: 0.0
Epoch:  315        6 Batch loss: 0.236486 Batch F1: 0.0
Epoch:  315        7 Batch loss: 0.258030 Batch F1: 0.0
Epoch:  315        8 Batch loss: 0.227316 Batch F1: 0.0
Epoch:  315        9 Batch loss: 0.238402 Batch F1: 0.0
Epoch:  315       10 Batch loss: 0.202790 Batch F1: 0.0
Epoch:  315       11 Batch loss: 0.213461 Batch F1: 0.0
Epoch:  315       12 Batch loss: 0.243164 Batch F1: 0.0
Train Avg Loss  315: 0.226292

Train Avg F1  315: 0.0

Val Avg Loss  315: 0.217809

Val Avg F1  315:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 316
--------------------------------------------------------------
Epoch:  316        1 Batch loss: 0.241360 Batch F1: 0.0
Epoch:  316        2 Batch loss: 0.255630 Batch F1: 0.0
Epoch:  316        3 Batch loss: 0.242521 Batch F1: 0.0
Epoch:  316        4 Batch loss: 0.210629 Batch F1: 0.0
Epoch:  316        5 Batch loss: 0.246792 Batch F1: 0.3076923076923077
Epoch:  316        6 Batch loss: 0.235164 Batch F1: 0.0
Epoch:  316        7 Batch loss: 0.223769 Batch F1: 0.0
Epoch:  316        8 Batch loss: 0.225385 Batch F1: 0.0
Epoch:  316        9 Batch loss: 0.196105 Batch F1: 0.0
Epoch:  316       10 Batch loss: 0.232844 Batch F1: 0.0
Epoch:  316       11 Batch loss: 0.220774 Batch F1: 0.0
Epoch:  316       12 Batch loss: 0.199358 Batch F1: 0.0
Train Avg Loss  316: 0.227528

Train Avg F1  316: 0.025641025641025644

Val Avg Loss  316: 0.218215

Val Avg F1  316:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 317
--------------------------------------------------------------
Epoch:  317        1 Batch loss: 0.242173 Batch F1: 0.0
Epoch:  317        2 Batch loss: 0.254951 Batch F1: 0.0
Epoch:  317        3 Batch loss: 0.260698 Batch F1: 0.0
Epoch:  317        4 Batch loss: 0.211085 Batch F1: 0.0
Epoch:  317        5 Batch loss: 0.256790 Batch F1: 0.0
Epoch:  317        6 Batch loss: 0.219487 Batch F1: 0.0
Epoch:  317        7 Batch loss: 0.214764 Batch F1: 0.0
Epoch:  317        8 Batch loss: 0.223827 Batch F1: 0.0
Epoch:  317        9 Batch loss: 0.193349 Batch F1: 0.0
Epoch:  317       10 Batch loss: 0.209667 Batch F1: 0.0
Epoch:  317       11 Batch loss: 0.250993 Batch F1: 0.0
Epoch:  317       12 Batch loss: 0.249735 Batch F1: 0.0
Train Avg Loss  317: 0.232293

Train Avg F1  317: 0.0

Val Avg Loss  317: 0.218695

Val Avg F1  317:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 318
--------------------------------------------------------------
Epoch:  318        1 Batch loss: 0.243759 Batch F1: 0.0
Epoch:  318        2 Batch loss: 0.216413 Batch F1: 0.0
Epoch:  318        3 Batch loss: 0.249314 Batch F1: 0.0
Epoch:  318        4 Batch loss: 0.244354 Batch F1: 0.0
Epoch:  318        5 Batch loss: 0.242789 Batch F1: 0.0
Epoch:  318        6 Batch loss: 0.242210 Batch F1: 0.0
Epoch:  318        7 Batch loss: 0.243008 Batch F1: 0.0
Epoch:  318        8 Batch loss: 0.237765 Batch F1: 0.0
Epoch:  318        9 Batch loss: 0.218892 Batch F1: 0.0
Epoch:  318       10 Batch loss: 0.221350 Batch F1: 0.0
Epoch:  318       11 Batch loss: 0.224330 Batch F1: 0.0
Epoch:  318       12 Batch loss: 0.207284 Batch F1: 0.0
Train Avg Loss  318: 0.232622

Train Avg F1  318: 0.0

Val Avg Loss  318: 0.218774

Val Avg F1  318:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 319
--------------------------------------------------------------
Epoch:  319        1 Batch loss: 0.223916 Batch F1: 0.0
Epoch:  319        2 Batch loss: 0.262899 Batch F1: 0.0
Epoch:  319        3 Batch loss: 0.198262 Batch F1: 0.0
Epoch:  319        4 Batch loss: 0.245445 Batch F1: 0.0
Epoch:  319        5 Batch loss: 0.225504 Batch F1: 0.0
Epoch:  319        6 Batch loss: 0.235367 Batch F1: 0.0
Epoch:  319        7 Batch loss: 0.224022 Batch F1: 0.0
Epoch:  319        8 Batch loss: 0.221902 Batch F1: 0.0
Epoch:  319        9 Batch loss: 0.204799 Batch F1: 0.0
Epoch:  319       10 Batch loss: 0.202028 Batch F1: 0.0
Epoch:  319       11 Batch loss: 0.301709 Batch F1: 0.0
Epoch:  319       12 Batch loss: 0.238344 Batch F1: 0.0
Train Avg Loss  319: 0.232016

Train Avg F1  319: 0.0

Val Avg Loss  319: 0.217893

Val Avg F1  319:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 320
--------------------------------------------------------------
Epoch:  320        1 Batch loss: 0.229220 Batch F1: 0.0
Epoch:  320        2 Batch loss: 0.239951 Batch F1: 0.0
Epoch:  320        3 Batch loss: 0.225457 Batch F1: 0.0
Epoch:  320        4 Batch loss: 0.222341 Batch F1: 0.0
Epoch:  320        5 Batch loss: 0.221783 Batch F1: 0.0
Epoch:  320        6 Batch loss: 0.249623 Batch F1: 0.0
Epoch:  320        7 Batch loss: 0.231847 Batch F1: 0.0
Epoch:  320        8 Batch loss: 0.228577 Batch F1: 0.0
Epoch:  320        9 Batch loss: 0.232215 Batch F1: 0.0
Epoch:  320       10 Batch loss: 0.209944 Batch F1: 0.0
Epoch:  320       11 Batch loss: 0.214251 Batch F1: 0.0
Epoch:  320       12 Batch loss: 0.241032 Batch F1: 0.0
Train Avg Loss  320: 0.228853

Train Avg F1  320: 0.0

Val Avg Loss  320: 0.219163

Val Avg F1  320:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 321
--------------------------------------------------------------
Epoch:  321        1 Batch loss: 0.217804 Batch F1: 0.0
Epoch:  321        2 Batch loss: 0.219186 Batch F1: 0.0
Epoch:  321        3 Batch loss: 0.220759 Batch F1: 0.0
Epoch:  321        4 Batch loss: 0.230969 Batch F1: 0.0
Epoch:  321        5 Batch loss: 0.237580 Batch F1: 0.0
Epoch:  321        6 Batch loss: 0.208334 Batch F1: 0.0
Epoch:  321        7 Batch loss: 0.224990 Batch F1: 0.0
Epoch:  321        8 Batch loss: 0.224347 Batch F1: 0.0
Epoch:  321        9 Batch loss: 0.240976 Batch F1: 0.0
Epoch:  321       10 Batch loss: 0.225062 Batch F1: 0.0
Epoch:  321       11 Batch loss: 0.246955 Batch F1: 0.0
Epoch:  321       12 Batch loss: 0.238751 Batch F1: 0.0
Train Avg Loss  321: 0.227976

Train Avg F1  321: 0.0

Val Avg Loss  321: 0.219777

Val Avg F1  321:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 322
--------------------------------------------------------------
Epoch:  322        1 Batch loss: 0.244780 Batch F1: 0.0
Epoch:  322        2 Batch loss: 0.253614 Batch F1: 0.0
Epoch:  322        3 Batch loss: 0.246204 Batch F1: 0.2222222222222222
Epoch:  322        4 Batch loss: 0.221544 Batch F1: 0.19047619047619047
Epoch:  322        5 Batch loss: 0.227271 Batch F1: 0.5625
Epoch:  322        6 Batch loss: 0.232815 Batch F1: 0.10526315789473682
Epoch:  322        7 Batch loss: 0.220742 Batch F1: 0.0
Epoch:  322        8 Batch loss: 0.194447 Batch F1: 0.0
Epoch:  322        9 Batch loss: 0.238916 Batch F1: 0.0
Epoch:  322       10 Batch loss: 0.202546 Batch F1: 0.0
Epoch:  322       11 Batch loss: 0.232361 Batch F1: 0.0
Epoch:  322       12 Batch loss: 0.229785 Batch F1: 0.0
Train Avg Loss  322: 0.228752

Train Avg F1  322: 0.09003846421609579

Val Avg Loss  322: 0.217073

Val Avg F1  322:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 323
--------------------------------------------------------------
Epoch:  323        1 Batch loss: 0.237867 Batch F1: 0.0
Epoch:  323        2 Batch loss: 0.224594 Batch F1: 0.0
Epoch:  323        3 Batch loss: 0.192448 Batch F1: 0.0
Epoch:  323        4 Batch loss: 0.259572 Batch F1: 0.0
Epoch:  323        5 Batch loss: 0.255543 Batch F1: 0.0
Epoch:  323        6 Batch loss: 0.246472 Batch F1: 0.42424242424242425
Epoch:  323        7 Batch loss: 0.220486 Batch F1: 0.33333333333333337
Epoch:  323        8 Batch loss: 0.229767 Batch F1: 0.3448275862068966
Epoch:  323        9 Batch loss: 0.215558 Batch F1: 0.0
Epoch:  323       10 Batch loss: 0.220991 Batch F1: 0.0
Epoch:  323       11 Batch loss: 0.223336 Batch F1: 0.0
Epoch:  323       12 Batch loss: 0.243331 Batch F1: 0.0
Train Avg Loss  323: 0.230830

Train Avg F1  323: 0.09186694531522117

Val Avg Loss  323: 0.217142

Val Avg F1  323:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 324
--------------------------------------------------------------
Epoch:  324        1 Batch loss: 0.213755 Batch F1: 0.0
Epoch:  324        2 Batch loss: 0.223751 Batch F1: 0.0
Epoch:  324        3 Batch loss: 0.216760 Batch F1: 0.0
Epoch:  324        4 Batch loss: 0.204145 Batch F1: 0.0
Epoch:  324        5 Batch loss: 0.256151 Batch F1: 0.0
Epoch:  324        6 Batch loss: 0.237843 Batch F1: 0.0
Epoch:  324        7 Batch loss: 0.214974 Batch F1: 0.0
Epoch:  324        8 Batch loss: 0.194052 Batch F1: 0.0
Epoch:  324        9 Batch loss: 0.222807 Batch F1: 0.0
Epoch:  324       10 Batch loss: 0.269278 Batch F1: 0.0
Epoch:  324       11 Batch loss: 0.242488 Batch F1: 0.0
Epoch:  324       12 Batch loss: 0.239510 Batch F1: 0.0
Train Avg Loss  324: 0.227960

Train Avg F1  324: 0.0

Val Avg Loss  324: 0.221390

Val Avg F1  324:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 325
--------------------------------------------------------------
Epoch:  325        1 Batch loss: 0.224442 Batch F1: 0.0
Epoch:  325        2 Batch loss: 0.246566 Batch F1: 0.0
Epoch:  325        3 Batch loss: 0.249139 Batch F1: 0.0
Epoch:  325        4 Batch loss: 0.227226 Batch F1: 0.32
Epoch:  325        5 Batch loss: 0.242763 Batch F1: 0.26666666666666666
Epoch:  325        6 Batch loss: 0.209454 Batch F1: 0.4444444444444445
Epoch:  325        7 Batch loss: 0.228955 Batch F1: 0.0
Epoch:  325        8 Batch loss: 0.201357 Batch F1: 0.0
Epoch:  325        9 Batch loss: 0.233538 Batch F1: 0.0
Epoch:  325       10 Batch loss: 0.270393 Batch F1: 0.0
Epoch:  325       11 Batch loss: 0.227395 Batch F1: 0.0
Epoch:  325       12 Batch loss: 0.214987 Batch F1: 0.0
Train Avg Loss  325: 0.231351

Train Avg F1  325: 0.08592592592592592

Val Avg Loss  325: 0.219701

Val Avg F1  325:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 326
--------------------------------------------------------------
Epoch:  326        1 Batch loss: 0.209787 Batch F1: 0.0
Epoch:  326        2 Batch loss: 0.220220 Batch F1: 0.0
Epoch:  326        3 Batch loss: 0.246237 Batch F1: 0.0
Epoch:  326        4 Batch loss: 0.234493 Batch F1: 0.0
Epoch:  326        5 Batch loss: 0.220264 Batch F1: 0.0
Epoch:  326        6 Batch loss: 0.233850 Batch F1: 0.0
Epoch:  326        7 Batch loss: 0.221330 Batch F1: 0.0
Epoch:  326        8 Batch loss: 0.247417 Batch F1: 0.0
Epoch:  326        9 Batch loss: 0.221266 Batch F1: 0.0
Epoch:  326       10 Batch loss: 0.202562 Batch F1: 0.0
Epoch:  326       11 Batch loss: 0.249830 Batch F1: 0.0
Epoch:  326       12 Batch loss: 0.236568 Batch F1: 0.0
Train Avg Loss  326: 0.228652

Train Avg F1  326: 0.0

Val Avg Loss  326: 0.217926

Val Avg F1  326:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 327
--------------------------------------------------------------
Epoch:  327        1 Batch loss: 0.235540 Batch F1: 0.0
Epoch:  327        2 Batch loss: 0.189399 Batch F1: 0.0
Epoch:  327        3 Batch loss: 0.230750 Batch F1: 0.0
Epoch:  327        4 Batch loss: 0.227261 Batch F1: 0.0
Epoch:  327        5 Batch loss: 0.241268 Batch F1: 0.0
Epoch:  327        6 Batch loss: 0.223990 Batch F1: 0.0
Epoch:  327        7 Batch loss: 0.250093 Batch F1: 0.0
Epoch:  327        8 Batch loss: 0.248604 Batch F1: 0.0
Epoch:  327        9 Batch loss: 0.219505 Batch F1: 0.0
Epoch:  327       10 Batch loss: 0.208725 Batch F1: 0.0
Epoch:  327       11 Batch loss: 0.239483 Batch F1: 0.0
Epoch:  327       12 Batch loss: 0.219376 Batch F1: 0.0
Train Avg Loss  327: 0.227833

Train Avg F1  327: 0.0

Val Avg Loss  327: 0.220770

Val Avg F1  327:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 328
--------------------------------------------------------------
Epoch:  328        1 Batch loss: 0.236768 Batch F1: 0.0
Epoch:  328        2 Batch loss: 0.224927 Batch F1: 0.0
Epoch:  328        3 Batch loss: 0.212980 Batch F1: 0.0
Epoch:  328        4 Batch loss: 0.225614 Batch F1: 0.0
Epoch:  328        5 Batch loss: 0.238817 Batch F1: 0.0
Epoch:  328        6 Batch loss: 0.234995 Batch F1: 0.0
Epoch:  328        7 Batch loss: 0.212948 Batch F1: 0.0
Epoch:  328        8 Batch loss: 0.225510 Batch F1: 0.0
Epoch:  328        9 Batch loss: 0.268584 Batch F1: 0.0
Epoch:  328       10 Batch loss: 0.215487 Batch F1: 0.0
Epoch:  328       11 Batch loss: 0.222528 Batch F1: 0.0
Epoch:  328       12 Batch loss: 0.236359 Batch F1: 0.0
Train Avg Loss  328: 0.229626

Train Avg F1  328: 0.0

Val Avg Loss  328: 0.218311

Val Avg F1  328:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 329
--------------------------------------------------------------
Epoch:  329        1 Batch loss: 0.238049 Batch F1: 0.0
Epoch:  329        2 Batch loss: 0.214044 Batch F1: 0.0
Epoch:  329        3 Batch loss: 0.236969 Batch F1: 0.0
Epoch:  329        4 Batch loss: 0.213155 Batch F1: 0.0
Epoch:  329        5 Batch loss: 0.224230 Batch F1: 0.0
Epoch:  329        6 Batch loss: 0.221829 Batch F1: 0.0
Epoch:  329        7 Batch loss: 0.211575 Batch F1: 0.0
Epoch:  329        8 Batch loss: 0.225796 Batch F1: 0.0
Epoch:  329        9 Batch loss: 0.244632 Batch F1: 0.0
Epoch:  329       10 Batch loss: 0.240378 Batch F1: 0.0
Epoch:  329       11 Batch loss: 0.237039 Batch F1: 0.0
Epoch:  329       12 Batch loss: 0.222681 Batch F1: 0.0
Train Avg Loss  329: 0.227531

Train Avg F1  329: 0.0

Val Avg Loss  329: 0.217785

Val Avg F1  329:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 330
--------------------------------------------------------------
Epoch:  330        1 Batch loss: 0.228643 Batch F1: 0.0
Epoch:  330        2 Batch loss: 0.225966 Batch F1: 0.0
Epoch:  330        3 Batch loss: 0.232567 Batch F1: 0.0
Epoch:  330        4 Batch loss: 0.216081 Batch F1: 0.0
Epoch:  330        5 Batch loss: 0.207093 Batch F1: 0.0
Epoch:  330        6 Batch loss: 0.234714 Batch F1: 0.0
Epoch:  330        7 Batch loss: 0.234408 Batch F1: 0.0
Epoch:  330        8 Batch loss: 0.235501 Batch F1: 0.0
Epoch:  330        9 Batch loss: 0.234761 Batch F1: 0.0
Epoch:  330       10 Batch loss: 0.212935 Batch F1: 0.0
Epoch:  330       11 Batch loss: 0.248932 Batch F1: 0.0
Epoch:  330       12 Batch loss: 0.215795 Batch F1: 0.0
Train Avg Loss  330: 0.227283

Train Avg F1  330: 0.0

Val Avg Loss  330: 0.217868

Val Avg F1  330:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 331
--------------------------------------------------------------
Epoch:  331        1 Batch loss: 0.204941 Batch F1: 0.0
Epoch:  331        2 Batch loss: 0.194909 Batch F1: 0.0
Epoch:  331        3 Batch loss: 0.244363 Batch F1: 0.0
Epoch:  331        4 Batch loss: 0.219462 Batch F1: 0.0
Epoch:  331        5 Batch loss: 0.272776 Batch F1: 0.0
Epoch:  331        6 Batch loss: 0.215077 Batch F1: 0.0
Epoch:  331        7 Batch loss: 0.211242 Batch F1: 0.0
Epoch:  331        8 Batch loss: 0.226604 Batch F1: 0.0
Epoch:  331        9 Batch loss: 0.204192 Batch F1: 0.0
Epoch:  331       10 Batch loss: 0.265541 Batch F1: 0.0
Epoch:  331       11 Batch loss: 0.262266 Batch F1: 0.0
Epoch:  331       12 Batch loss: 0.209463 Batch F1: 0.0
Train Avg Loss  331: 0.227570

Train Avg F1  331: 0.0

Val Avg Loss  331: 0.219734

Val Avg F1  331:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 332
--------------------------------------------------------------
Epoch:  332        1 Batch loss: 0.226173 Batch F1: 0.0
Epoch:  332        2 Batch loss: 0.212289 Batch F1: 0.0
Epoch:  332        3 Batch loss: 0.236614 Batch F1: 0.0
Epoch:  332        4 Batch loss: 0.249995 Batch F1: 0.0
Epoch:  332        5 Batch loss: 0.233105 Batch F1: 0.0
Epoch:  332        6 Batch loss: 0.218829 Batch F1: 0.0
Epoch:  332        7 Batch loss: 0.224803 Batch F1: 0.0
Epoch:  332        8 Batch loss: 0.265537 Batch F1: 0.0
Epoch:  332        9 Batch loss: 0.221000 Batch F1: 0.0
Epoch:  332       10 Batch loss: 0.237435 Batch F1: 0.0
Epoch:  332       11 Batch loss: 0.203263 Batch F1: 0.0
Epoch:  332       12 Batch loss: 0.211543 Batch F1: 0.0
Train Avg Loss  332: 0.228382

Train Avg F1  332: 0.0

Val Avg Loss  332: 0.218297

Val Avg F1  332:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 333
--------------------------------------------------------------
Epoch:  333        1 Batch loss: 0.240029 Batch F1: 0.0
Epoch:  333        2 Batch loss: 0.229321 Batch F1: 0.0
Epoch:  333        3 Batch loss: 0.202498 Batch F1: 0.0
Epoch:  333        4 Batch loss: 0.228888 Batch F1: 0.0
Epoch:  333        5 Batch loss: 0.238467 Batch F1: 0.0
Epoch:  333        6 Batch loss: 0.248090 Batch F1: 0.0
Epoch:  333        7 Batch loss: 0.244575 Batch F1: 0.0
Epoch:  333        8 Batch loss: 0.214251 Batch F1: 0.0
Epoch:  333        9 Batch loss: 0.236021 Batch F1: 0.0
Epoch:  333       10 Batch loss: 0.233273 Batch F1: 0.0
Epoch:  333       11 Batch loss: 0.202172 Batch F1: 0.0
Epoch:  333       12 Batch loss: 0.205809 Batch F1: 0.0
Train Avg Loss  333: 0.226949

Train Avg F1  333: 0.0

Val Avg Loss  333: 0.218331

Val Avg F1  333:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 334
--------------------------------------------------------------
Epoch:  334        1 Batch loss: 0.237789 Batch F1: 0.0
Epoch:  334        2 Batch loss: 0.217523 Batch F1: 0.0
Epoch:  334        3 Batch loss: 0.250319 Batch F1: 0.0
Epoch:  334        4 Batch loss: 0.221441 Batch F1: 0.0
Epoch:  334        5 Batch loss: 0.213196 Batch F1: 0.0
Epoch:  334        6 Batch loss: 0.229342 Batch F1: 0.0
Epoch:  334        7 Batch loss: 0.216925 Batch F1: 0.0
Epoch:  334        8 Batch loss: 0.197298 Batch F1: 0.0
Epoch:  334        9 Batch loss: 0.248511 Batch F1: 0.0
Epoch:  334       10 Batch loss: 0.257556 Batch F1: 0.0
Epoch:  334       11 Batch loss: 0.219548 Batch F1: 0.0
Epoch:  334       12 Batch loss: 0.217012 Batch F1: 0.0
Train Avg Loss  334: 0.227205

Train Avg F1  334: 0.0

Val Avg Loss  334: 0.217637

Val Avg F1  334:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 335
--------------------------------------------------------------
Epoch:  335        1 Batch loss: 0.171173 Batch F1: 0.0
Epoch:  335        2 Batch loss: 0.227068 Batch F1: 0.0
Epoch:  335        3 Batch loss: 0.241356 Batch F1: 0.0
Epoch:  335        4 Batch loss: 0.236118 Batch F1: 0.0
Epoch:  335        5 Batch loss: 0.215689 Batch F1: 0.0
Epoch:  335        6 Batch loss: 0.255654 Batch F1: 0.0
Epoch:  335        7 Batch loss: 0.294339 Batch F1: 0.0
Epoch:  335        8 Batch loss: 0.223877 Batch F1: 0.0
Epoch:  335        9 Batch loss: 0.227071 Batch F1: 0.0
Epoch:  335       10 Batch loss: 0.221728 Batch F1: 0.0
Epoch:  335       11 Batch loss: 0.220966 Batch F1: 0.0
Epoch:  335       12 Batch loss: 0.197956 Batch F1: 0.0
Train Avg Loss  335: 0.227750

Train Avg F1  335: 0.0

Val Avg Loss  335: 0.219970

Val Avg F1  335:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 336
--------------------------------------------------------------
Epoch:  336        1 Batch loss: 0.229876 Batch F1: 0.0
Epoch:  336        2 Batch loss: 0.216955 Batch F1: 0.0
Epoch:  336        3 Batch loss: 0.236176 Batch F1: 0.0
Epoch:  336        4 Batch loss: 0.227885 Batch F1: 0.0
Epoch:  336        5 Batch loss: 0.235073 Batch F1: 0.0
Epoch:  336        6 Batch loss: 0.231786 Batch F1: 0.0
Epoch:  336        7 Batch loss: 0.184397 Batch F1: 0.0
Epoch:  336        8 Batch loss: 0.210162 Batch F1: 0.0
Epoch:  336        9 Batch loss: 0.241396 Batch F1: 0.0
Epoch:  336       10 Batch loss: 0.218376 Batch F1: 0.0
Epoch:  336       11 Batch loss: 0.260810 Batch F1: 0.0
Epoch:  336       12 Batch loss: 0.224565 Batch F1: 0.0
Train Avg Loss  336: 0.226455

Train Avg F1  336: 0.0

Val Avg Loss  336: 0.217094

Val Avg F1  336:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 337
--------------------------------------------------------------
Epoch:  337        1 Batch loss: 0.243308 Batch F1: 0.0
Epoch:  337        2 Batch loss: 0.246275 Batch F1: 0.0
Epoch:  337        3 Batch loss: 0.256614 Batch F1: 0.0
Epoch:  337        4 Batch loss: 0.233711 Batch F1: 0.0
Epoch:  337        5 Batch loss: 0.216008 Batch F1: 0.0
Epoch:  337        6 Batch loss: 0.197146 Batch F1: 0.0
Epoch:  337        7 Batch loss: 0.216800 Batch F1: 0.0
Epoch:  337        8 Batch loss: 0.215406 Batch F1: 0.0
Epoch:  337        9 Batch loss: 0.235892 Batch F1: 0.0
Epoch:  337       10 Batch loss: 0.222268 Batch F1: 0.0
Epoch:  337       11 Batch loss: 0.214777 Batch F1: 0.0
Epoch:  337       12 Batch loss: 0.236286 Batch F1: 0.0
Train Avg Loss  337: 0.227874

Train Avg F1  337: 0.0

Val Avg Loss  337: 0.217565

Val Avg F1  337:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 338
--------------------------------------------------------------
Epoch:  338        1 Batch loss: 0.221129 Batch F1: 0.0
Epoch:  338        2 Batch loss: 0.220849 Batch F1: 0.0
Epoch:  338        3 Batch loss: 0.243783 Batch F1: 0.0
Epoch:  338        4 Batch loss: 0.260818 Batch F1: 0.0
Epoch:  338        5 Batch loss: 0.182636 Batch F1: 0.0
Epoch:  338        6 Batch loss: 0.241123 Batch F1: 0.0
Epoch:  338        7 Batch loss: 0.245824 Batch F1: 0.0
Epoch:  338        8 Batch loss: 0.225699 Batch F1: 0.0
Epoch:  338        9 Batch loss: 0.257060 Batch F1: 0.0
Epoch:  338       10 Batch loss: 0.211824 Batch F1: 0.0
Epoch:  338       11 Batch loss: 0.200595 Batch F1: 0.0
Epoch:  338       12 Batch loss: 0.212536 Batch F1: 0.0
Train Avg Loss  338: 0.226990

Train Avg F1  338: 0.0

Val Avg Loss  338: 0.218395

Val Avg F1  338:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 339
--------------------------------------------------------------
Epoch:  339        1 Batch loss: 0.195941 Batch F1: 0.0
Epoch:  339        2 Batch loss: 0.229143 Batch F1: 0.0
Epoch:  339        3 Batch loss: 0.235427 Batch F1: 0.0
Epoch:  339        4 Batch loss: 0.200294 Batch F1: 0.0
Epoch:  339        5 Batch loss: 0.293163 Batch F1: 0.0
Epoch:  339        6 Batch loss: 0.209762 Batch F1: 0.0
Epoch:  339        7 Batch loss: 0.222193 Batch F1: 0.0
Epoch:  339        8 Batch loss: 0.206268 Batch F1: 0.0
Epoch:  339        9 Batch loss: 0.242102 Batch F1: 0.0
Epoch:  339       10 Batch loss: 0.243525 Batch F1: 0.0
Epoch:  339       11 Batch loss: 0.223790 Batch F1: 0.0
Epoch:  339       12 Batch loss: 0.231456 Batch F1: 0.0
Train Avg Loss  339: 0.227755

Train Avg F1  339: 0.0

Val Avg Loss  339: 0.221600

Val Avg F1  339:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 340
--------------------------------------------------------------
Epoch:  340        1 Batch loss: 0.212093 Batch F1: 0.0
Epoch:  340        2 Batch loss: 0.256874 Batch F1: 0.0
Epoch:  340        3 Batch loss: 0.238970 Batch F1: 0.0
Epoch:  340        4 Batch loss: 0.252348 Batch F1: 0.0
Epoch:  340        5 Batch loss: 0.212363 Batch F1: 0.0
Epoch:  340        6 Batch loss: 0.226294 Batch F1: 0.0
Epoch:  340        7 Batch loss: 0.227359 Batch F1: 0.0
Epoch:  340        8 Batch loss: 0.225157 Batch F1: 0.0
Epoch:  340        9 Batch loss: 0.231969 Batch F1: 0.0
Epoch:  340       10 Batch loss: 0.207240 Batch F1: 0.0
Epoch:  340       11 Batch loss: 0.242190 Batch F1: 0.0
Epoch:  340       12 Batch loss: 0.224600 Batch F1: 0.0
Train Avg Loss  340: 0.229788

Train Avg F1  340: 0.0

Val Avg Loss  340: 0.220502

Val Avg F1  340:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 341
--------------------------------------------------------------
Epoch:  341        1 Batch loss: 0.243234 Batch F1: 0.0
Epoch:  341        2 Batch loss: 0.223062 Batch F1: 0.0
Epoch:  341        3 Batch loss: 0.198138 Batch F1: 0.0
Epoch:  341        4 Batch loss: 0.198755 Batch F1: 0.0
Epoch:  341        5 Batch loss: 0.235493 Batch F1: 0.0
Epoch:  341        6 Batch loss: 0.211127 Batch F1: 0.0
Epoch:  341        7 Batch loss: 0.253170 Batch F1: 0.0
Epoch:  341        8 Batch loss: 0.219980 Batch F1: 0.0
Epoch:  341        9 Batch loss: 0.240382 Batch F1: 0.0
Epoch:  341       10 Batch loss: 0.229354 Batch F1: 0.0
Epoch:  341       11 Batch loss: 0.216357 Batch F1: 0.0
Epoch:  341       12 Batch loss: 0.268456 Batch F1: 0.0
Train Avg Loss  341: 0.228126

Train Avg F1  341: 0.0

Val Avg Loss  341: 0.225655

Val Avg F1  341:  0.38544117647058823

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 342
--------------------------------------------------------------
Epoch:  342        1 Batch loss: 0.220977 Batch F1: 0.30769230769230765
Epoch:  342        2 Batch loss: 0.228955 Batch F1: 0.32
Epoch:  342        3 Batch loss: 0.215250 Batch F1: 0.0
Epoch:  342        4 Batch loss: 0.202673 Batch F1: 0.0
Epoch:  342        5 Batch loss: 0.245687 Batch F1: 0.0
Epoch:  342        6 Batch loss: 0.198654 Batch F1: 0.0
Epoch:  342        7 Batch loss: 0.257994 Batch F1: 0.0
Epoch:  342        8 Batch loss: 0.205173 Batch F1: 0.0
Epoch:  342        9 Batch loss: 0.278811 Batch F1: 0.0
Epoch:  342       10 Batch loss: 0.221180 Batch F1: 0.0
Epoch:  342       11 Batch loss: 0.268418 Batch F1: 0.0
Epoch:  342       12 Batch loss: 0.230472 Batch F1: 0.0
Train Avg Loss  342: 0.231187

Train Avg F1  342: 0.052307692307692305

Val Avg Loss  342: 0.221832

Val Avg F1  342:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 343
--------------------------------------------------------------
Epoch:  343        1 Batch loss: 0.218739 Batch F1: 0.0
Epoch:  343        2 Batch loss: 0.228738 Batch F1: 0.0
Epoch:  343        3 Batch loss: 0.238619 Batch F1: 0.0
Epoch:  343        4 Batch loss: 0.235930 Batch F1: 0.20689655172413793
Epoch:  343        5 Batch loss: 0.214694 Batch F1: 0.2
Epoch:  343        6 Batch loss: 0.219217 Batch F1: 0.0
Epoch:  343        7 Batch loss: 0.245822 Batch F1: 0.0
Epoch:  343        8 Batch loss: 0.239868 Batch F1: 0.0
Epoch:  343        9 Batch loss: 0.276377 Batch F1: 0.0
Epoch:  343       10 Batch loss: 0.224597 Batch F1: 0.0
Epoch:  343       11 Batch loss: 0.209561 Batch F1: 0.0
Epoch:  343       12 Batch loss: 0.189314 Batch F1: 0.0
Train Avg Loss  343: 0.228456

Train Avg F1  343: 0.0339080459770115

Val Avg Loss  343: 0.217352

Val Avg F1  343:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 344
--------------------------------------------------------------
Epoch:  344        1 Batch loss: 0.231444 Batch F1: 0.0
Epoch:  344        2 Batch loss: 0.223478 Batch F1: 0.0
Epoch:  344        3 Batch loss: 0.249084 Batch F1: 0.0
Epoch:  344        4 Batch loss: 0.201646 Batch F1: 0.0
Epoch:  344        5 Batch loss: 0.203545 Batch F1: 0.0
Epoch:  344        6 Batch loss: 0.263937 Batch F1: 0.0
Epoch:  344        7 Batch loss: 0.229998 Batch F1: 0.0
Epoch:  344        8 Batch loss: 0.224616 Batch F1: 0.0
Epoch:  344        9 Batch loss: 0.227397 Batch F1: 0.0
Epoch:  344       10 Batch loss: 0.224926 Batch F1: 0.0
Epoch:  344       11 Batch loss: 0.213127 Batch F1: 0.0
Epoch:  344       12 Batch loss: 0.238749 Batch F1: 0.0
Train Avg Loss  344: 0.227662

Train Avg F1  344: 0.0

Val Avg Loss  344: 0.220682

Val Avg F1  344:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 345
--------------------------------------------------------------
Epoch:  345        1 Batch loss: 0.212307 Batch F1: 0.0
Epoch:  345        2 Batch loss: 0.205168 Batch F1: 0.0
Epoch:  345        3 Batch loss: 0.192408 Batch F1: 0.0
Epoch:  345        4 Batch loss: 0.253883 Batch F1: 0.0
Epoch:  345        5 Batch loss: 0.236341 Batch F1: 0.0
Epoch:  345        6 Batch loss: 0.222960 Batch F1: 0.0
Epoch:  345        7 Batch loss: 0.219127 Batch F1: 0.0
Epoch:  345        8 Batch loss: 0.234997 Batch F1: 0.0
Epoch:  345        9 Batch loss: 0.240876 Batch F1: 0.0
Epoch:  345       10 Batch loss: 0.240589 Batch F1: 0.0
Epoch:  345       11 Batch loss: 0.228449 Batch F1: 0.0
Epoch:  345       12 Batch loss: 0.242573 Batch F1: 0.0
Train Avg Loss  345: 0.227473

Train Avg F1  345: 0.0

Val Avg Loss  345: 0.218627

Val Avg F1  345:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 346
--------------------------------------------------------------
Epoch:  346        1 Batch loss: 0.214311 Batch F1: 0.0
Epoch:  346        2 Batch loss: 0.209138 Batch F1: 0.0
Epoch:  346        3 Batch loss: 0.223617 Batch F1: 0.0
Epoch:  346        4 Batch loss: 0.222353 Batch F1: 0.0
Epoch:  346        5 Batch loss: 0.240189 Batch F1: 0.0
Epoch:  346        6 Batch loss: 0.275888 Batch F1: 0.0
Epoch:  346        7 Batch loss: 0.238626 Batch F1: 0.25
Epoch:  346        8 Batch loss: 0.209388 Batch F1: 0.2962962962962963
Epoch:  346        9 Batch loss: 0.195021 Batch F1: 0.0
Epoch:  346       10 Batch loss: 0.236586 Batch F1: 0.0
Epoch:  346       11 Batch loss: 0.219729 Batch F1: 0.0
Epoch:  346       12 Batch loss: 0.239189 Batch F1: 0.0
Train Avg Loss  346: 0.227003

Train Avg F1  346: 0.04552469135802469

Val Avg Loss  346: 0.218207

Val Avg F1  346:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 347
--------------------------------------------------------------
Epoch:  347        1 Batch loss: 0.224505 Batch F1: 0.0
Epoch:  347        2 Batch loss: 0.201240 Batch F1: 0.0
Epoch:  347        3 Batch loss: 0.245106 Batch F1: 0.0
Epoch:  347        4 Batch loss: 0.201130 Batch F1: 0.0
Epoch:  347        5 Batch loss: 0.238522 Batch F1: 0.0
Epoch:  347        6 Batch loss: 0.229413 Batch F1: 0.0
Epoch:  347        7 Batch loss: 0.240587 Batch F1: 0.0
Epoch:  347        8 Batch loss: 0.245914 Batch F1: 0.0
Epoch:  347        9 Batch loss: 0.230625 Batch F1: 0.0
Epoch:  347       10 Batch loss: 0.215542 Batch F1: 0.0
Epoch:  347       11 Batch loss: 0.229433 Batch F1: 0.0
Epoch:  347       12 Batch loss: 0.236237 Batch F1: 0.0
Train Avg Loss  347: 0.228188

Train Avg F1  347: 0.0

Val Avg Loss  347: 0.219264

Val Avg F1  347:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 348
--------------------------------------------------------------
Epoch:  348        1 Batch loss: 0.219027 Batch F1: 0.0
Epoch:  348        2 Batch loss: 0.238632 Batch F1: 0.0
Epoch:  348        3 Batch loss: 0.234418 Batch F1: 0.0
Epoch:  348        4 Batch loss: 0.228498 Batch F1: 0.0
Epoch:  348        5 Batch loss: 0.209590 Batch F1: 0.0
Epoch:  348        6 Batch loss: 0.219284 Batch F1: 0.0
Epoch:  348        7 Batch loss: 0.237956 Batch F1: 0.0
Epoch:  348        8 Batch loss: 0.220812 Batch F1: 0.0
Epoch:  348        9 Batch loss: 0.228190 Batch F1: 0.0
Epoch:  348       10 Batch loss: 0.230232 Batch F1: 0.0
Epoch:  348       11 Batch loss: 0.239242 Batch F1: 0.0
Epoch:  348       12 Batch loss: 0.216759 Batch F1: 0.0
Train Avg Loss  348: 0.226887

Train Avg F1  348: 0.0

Val Avg Loss  348: 0.217631

Val Avg F1  348:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 349
--------------------------------------------------------------
Epoch:  349        1 Batch loss: 0.226065 Batch F1: 0.0
Epoch:  349        2 Batch loss: 0.220176 Batch F1: 0.0
Epoch:  349        3 Batch loss: 0.241417 Batch F1: 0.0
Epoch:  349        4 Batch loss: 0.240382 Batch F1: 0.0
Epoch:  349        5 Batch loss: 0.249827 Batch F1: 0.0
Epoch:  349        6 Batch loss: 0.235424 Batch F1: 0.0
Epoch:  349        7 Batch loss: 0.236557 Batch F1: 0.0
Epoch:  349        8 Batch loss: 0.219950 Batch F1: 0.0
Epoch:  349        9 Batch loss: 0.211034 Batch F1: 0.0
Epoch:  349       10 Batch loss: 0.217529 Batch F1: 0.0
Epoch:  349       11 Batch loss: 0.245702 Batch F1: 0.0
Epoch:  349       12 Batch loss: 0.186089 Batch F1: 0.0
Train Avg Loss  349: 0.227513

Train Avg F1  349: 0.0

Val Avg Loss  349: 0.218291

Val Avg F1  349:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 350
--------------------------------------------------------------
Epoch:  350        1 Batch loss: 0.233449 Batch F1: 0.0
Epoch:  350        2 Batch loss: 0.220194 Batch F1: 0.0
Epoch:  350        3 Batch loss: 0.222804 Batch F1: 0.0
Epoch:  350        4 Batch loss: 0.239887 Batch F1: 0.0
Epoch:  350        5 Batch loss: 0.253033 Batch F1: 0.0
Epoch:  350        6 Batch loss: 0.179769 Batch F1: 0.0
Epoch:  350        7 Batch loss: 0.207894 Batch F1: 0.0
Epoch:  350        8 Batch loss: 0.271240 Batch F1: 0.0
Epoch:  350        9 Batch loss: 0.229762 Batch F1: 0.0
Epoch:  350       10 Batch loss: 0.222645 Batch F1: 0.0
Epoch:  350       11 Batch loss: 0.219812 Batch F1: 0.0
Epoch:  350       12 Batch loss: 0.222211 Batch F1: 0.0
Train Avg Loss  350: 0.226892

Train Avg F1  350: 0.0

Val Avg Loss  350: 0.216837

Val Avg F1  350:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 351
--------------------------------------------------------------
Epoch:  351        1 Batch loss: 0.259610 Batch F1: 0.0
Epoch:  351        2 Batch loss: 0.225948 Batch F1: 0.0
Epoch:  351        3 Batch loss: 0.215991 Batch F1: 0.0
Epoch:  351        4 Batch loss: 0.247802 Batch F1: 0.0
Epoch:  351        5 Batch loss: 0.223164 Batch F1: 0.0
Epoch:  351        6 Batch loss: 0.222377 Batch F1: 0.0
Epoch:  351        7 Batch loss: 0.226875 Batch F1: 0.0
Epoch:  351        8 Batch loss: 0.223545 Batch F1: 0.0
Epoch:  351        9 Batch loss: 0.195654 Batch F1: 0.0
Epoch:  351       10 Batch loss: 0.219372 Batch F1: 0.0
Epoch:  351       11 Batch loss: 0.229068 Batch F1: 0.0
Epoch:  351       12 Batch loss: 0.232045 Batch F1: 0.0
Train Avg Loss  351: 0.226788

Train Avg F1  351: 0.0

Val Avg Loss  351: 0.217356

Val Avg F1  351:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 352
--------------------------------------------------------------
Epoch:  352        1 Batch loss: 0.212193 Batch F1: 0.0
Epoch:  352        2 Batch loss: 0.213572 Batch F1: 0.0
Epoch:  352        3 Batch loss: 0.238917 Batch F1: 0.0
Epoch:  352        4 Batch loss: 0.194140 Batch F1: 0.0
Epoch:  352        5 Batch loss: 0.206356 Batch F1: 0.0
Epoch:  352        6 Batch loss: 0.234465 Batch F1: 0.0
Epoch:  352        7 Batch loss: 0.256019 Batch F1: 0.0
Epoch:  352        8 Batch loss: 0.222352 Batch F1: 0.0
Epoch:  352        9 Batch loss: 0.236992 Batch F1: 0.0
Epoch:  352       10 Batch loss: 0.254502 Batch F1: 0.0
Epoch:  352       11 Batch loss: 0.229379 Batch F1: 0.0
Epoch:  352       12 Batch loss: 0.206848 Batch F1: 0.0
Train Avg Loss  352: 0.225478

Train Avg F1  352: 0.0

Val Avg Loss  352: 0.217760

Val Avg F1  352:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 353
--------------------------------------------------------------
Epoch:  353        1 Batch loss: 0.218125 Batch F1: 0.0
Epoch:  353        2 Batch loss: 0.193636 Batch F1: 0.0
Epoch:  353        3 Batch loss: 0.240503 Batch F1: 0.0
Epoch:  353        4 Batch loss: 0.210755 Batch F1: 0.0
Epoch:  353        5 Batch loss: 0.252265 Batch F1: 0.0
Epoch:  353        6 Batch loss: 0.232834 Batch F1: 0.0
Epoch:  353        7 Batch loss: 0.225573 Batch F1: 0.0
Epoch:  353        8 Batch loss: 0.229043 Batch F1: 0.0
Epoch:  353        9 Batch loss: 0.239492 Batch F1: 0.0
Epoch:  353       10 Batch loss: 0.212753 Batch F1: 0.26086956521739124
Epoch:  353       11 Batch loss: 0.207081 Batch F1: 0.0
Epoch:  353       12 Batch loss: 0.253808 Batch F1: 0.0
Train Avg Loss  353: 0.226322

Train Avg F1  353: 0.021739130434782605

Val Avg Loss  353: 0.218079

Val Avg F1  353:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 354
--------------------------------------------------------------
Epoch:  354        1 Batch loss: 0.199874 Batch F1: 0.0
Epoch:  354        2 Batch loss: 0.211450 Batch F1: 0.0
Epoch:  354        3 Batch loss: 0.259711 Batch F1: 0.0
Epoch:  354        4 Batch loss: 0.234449 Batch F1: 0.0
Epoch:  354        5 Batch loss: 0.207372 Batch F1: 0.0
Epoch:  354        6 Batch loss: 0.258327 Batch F1: 0.0
Epoch:  354        7 Batch loss: 0.230258 Batch F1: 0.0
Epoch:  354        8 Batch loss: 0.214281 Batch F1: 0.0
Epoch:  354        9 Batch loss: 0.217848 Batch F1: 0.0
Epoch:  354       10 Batch loss: 0.227877 Batch F1: 0.0
Epoch:  354       11 Batch loss: 0.232068 Batch F1: 0.0
Epoch:  354       12 Batch loss: 0.223085 Batch F1: 0.0
Train Avg Loss  354: 0.226383

Train Avg F1  354: 0.0

Val Avg Loss  354: 0.217702

Val Avg F1  354:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 355
--------------------------------------------------------------
Epoch:  355        1 Batch loss: 0.229412 Batch F1: 0.0
Epoch:  355        2 Batch loss: 0.207291 Batch F1: 0.0
Epoch:  355        3 Batch loss: 0.212835 Batch F1: 0.0
Epoch:  355        4 Batch loss: 0.230707 Batch F1: 0.0
Epoch:  355        5 Batch loss: 0.218833 Batch F1: 0.0
Epoch:  355        6 Batch loss: 0.208573 Batch F1: 0.0
Epoch:  355        7 Batch loss: 0.239501 Batch F1: 0.0
Epoch:  355        8 Batch loss: 0.194426 Batch F1: 0.0
Epoch:  355        9 Batch loss: 0.273694 Batch F1: 0.0
Epoch:  355       10 Batch loss: 0.200575 Batch F1: 0.0
Epoch:  355       11 Batch loss: 0.284442 Batch F1: 0.0
Epoch:  355       12 Batch loss: 0.219213 Batch F1: 0.0
Train Avg Loss  355: 0.226625

Train Avg F1  355: 0.0

Val Avg Loss  355: 0.217747

Val Avg F1  355:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 356
--------------------------------------------------------------
Epoch:  356        1 Batch loss: 0.188514 Batch F1: 0.0
Epoch:  356        2 Batch loss: 0.229041 Batch F1: 0.0
Epoch:  356        3 Batch loss: 0.232188 Batch F1: 0.0
Epoch:  356        4 Batch loss: 0.230245 Batch F1: 0.0
Epoch:  356        5 Batch loss: 0.183313 Batch F1: 0.0
Epoch:  356        6 Batch loss: 0.243961 Batch F1: 0.0
Epoch:  356        7 Batch loss: 0.231947 Batch F1: 0.0
Epoch:  356        8 Batch loss: 0.230242 Batch F1: 0.0
Epoch:  356        9 Batch loss: 0.242074 Batch F1: 0.41379310344827586
Epoch:  356       10 Batch loss: 0.243889 Batch F1: 0.3448275862068966
Epoch:  356       11 Batch loss: 0.222717 Batch F1: 0.42857142857142855
Epoch:  356       12 Batch loss: 0.246607 Batch F1: 0.0
Train Avg Loss  356: 0.227061

Train Avg F1  356: 0.09893267651888342

Val Avg Loss  356: 0.219957

Val Avg F1  356:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 357
--------------------------------------------------------------
Epoch:  357        1 Batch loss: 0.225283 Batch F1: 0.0
Epoch:  357        2 Batch loss: 0.245395 Batch F1: 0.0
Epoch:  357        3 Batch loss: 0.254629 Batch F1: 0.0
Epoch:  357        4 Batch loss: 0.253250 Batch F1: 0.0
Epoch:  357        5 Batch loss: 0.218358 Batch F1: 0.0
Epoch:  357        6 Batch loss: 0.236604 Batch F1: 0.0
Epoch:  357        7 Batch loss: 0.204907 Batch F1: 0.0
Epoch:  357        8 Batch loss: 0.210939 Batch F1: 0.0
Epoch:  357        9 Batch loss: 0.237797 Batch F1: 0.0
Epoch:  357       10 Batch loss: 0.242753 Batch F1: 0.0
Epoch:  357       11 Batch loss: 0.193700 Batch F1: 0.0
Epoch:  357       12 Batch loss: 0.183591 Batch F1: 0.0
Train Avg Loss  357: 0.225600

Train Avg F1  357: 0.0

Val Avg Loss  357: 0.216832

Val Avg F1  357:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 358
--------------------------------------------------------------
Epoch:  358        1 Batch loss: 0.226233 Batch F1: 0.0
Epoch:  358        2 Batch loss: 0.212637 Batch F1: 0.0
Epoch:  358        3 Batch loss: 0.270450 Batch F1: 0.0
Epoch:  358        4 Batch loss: 0.233542 Batch F1: 0.0
Epoch:  358        5 Batch loss: 0.212691 Batch F1: 0.0
Epoch:  358        6 Batch loss: 0.243336 Batch F1: 0.4
Epoch:  358        7 Batch loss: 0.243662 Batch F1: 0.28571428571428575
Epoch:  358        8 Batch loss: 0.207483 Batch F1: 0.38095238095238093
Epoch:  358        9 Batch loss: 0.240374 Batch F1: 0.23076923076923078
Epoch:  358       10 Batch loss: 0.213169 Batch F1: 0.2857142857142857
Epoch:  358       11 Batch loss: 0.195027 Batch F1: 0.0
Epoch:  358       12 Batch loss: 0.229544 Batch F1: 0.0
Train Avg Loss  358: 0.227346

Train Avg F1  358: 0.13192918192918193

Val Avg Loss  358: 0.217046

Val Avg F1  358:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 359
--------------------------------------------------------------
Epoch:  359        1 Batch loss: 0.199628 Batch F1: 0.0
Epoch:  359        2 Batch loss: 0.245223 Batch F1: 0.0
Epoch:  359        3 Batch loss: 0.257265 Batch F1: 0.0
Epoch:  359        4 Batch loss: 0.213541 Batch F1: 0.0
Epoch:  359        5 Batch loss: 0.215949 Batch F1: 0.0
Epoch:  359        6 Batch loss: 0.218522 Batch F1: 0.0
Epoch:  359        7 Batch loss: 0.241640 Batch F1: 0.0
Epoch:  359        8 Batch loss: 0.221997 Batch F1: 0.0
Epoch:  359        9 Batch loss: 0.234139 Batch F1: 0.0
Epoch:  359       10 Batch loss: 0.222058 Batch F1: 0.0
Epoch:  359       11 Batch loss: 0.229698 Batch F1: 0.0
Epoch:  359       12 Batch loss: 0.248234 Batch F1: 0.0
Train Avg Loss  359: 0.228991

Train Avg F1  359: 0.0

Val Avg Loss  359: 0.218037

Val Avg F1  359:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 360
--------------------------------------------------------------
Epoch:  360        1 Batch loss: 0.235401 Batch F1: 0.0
Epoch:  360        2 Batch loss: 0.205397 Batch F1: 0.0
Epoch:  360        3 Batch loss: 0.198356 Batch F1: 0.0
Epoch:  360        4 Batch loss: 0.253109 Batch F1: 0.0
Epoch:  360        5 Batch loss: 0.211701 Batch F1: 0.0
Epoch:  360        6 Batch loss: 0.220771 Batch F1: 0.0
Epoch:  360        7 Batch loss: 0.220479 Batch F1: 0.0
Epoch:  360        8 Batch loss: 0.210805 Batch F1: 0.0
Epoch:  360        9 Batch loss: 0.224982 Batch F1: 0.0
Epoch:  360       10 Batch loss: 0.241315 Batch F1: 0.0
Epoch:  360       11 Batch loss: 0.252682 Batch F1: 0.0
Epoch:  360       12 Batch loss: 0.258798 Batch F1: 0.0
Train Avg Loss  360: 0.227816

Train Avg F1  360: 0.0

Val Avg Loss  360: 0.219125

Val Avg F1  360:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 361
--------------------------------------------------------------
Epoch:  361        1 Batch loss: 0.222002 Batch F1: 0.0
Epoch:  361        2 Batch loss: 0.216366 Batch F1: 0.0
Epoch:  361        3 Batch loss: 0.219410 Batch F1: 0.0
Epoch:  361        4 Batch loss: 0.220430 Batch F1: 0.0
Epoch:  361        5 Batch loss: 0.228333 Batch F1: 0.0
Epoch:  361        6 Batch loss: 0.210065 Batch F1: 0.0
Epoch:  361        7 Batch loss: 0.245003 Batch F1: 0.0
Epoch:  361        8 Batch loss: 0.213429 Batch F1: 0.0
Epoch:  361        9 Batch loss: 0.219553 Batch F1: 0.0
Epoch:  361       10 Batch loss: 0.223817 Batch F1: 0.0
Epoch:  361       11 Batch loss: 0.248742 Batch F1: 0.0
Epoch:  361       12 Batch loss: 0.259518 Batch F1: 0.0
Train Avg Loss  361: 0.227222

Train Avg F1  361: 0.0

Val Avg Loss  361: 0.217268

Val Avg F1  361:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 362
--------------------------------------------------------------
Epoch:  362        1 Batch loss: 0.263475 Batch F1: 0.0
Epoch:  362        2 Batch loss: 0.211522 Batch F1: 0.0
Epoch:  362        3 Batch loss: 0.244734 Batch F1: 0.0
Epoch:  362        4 Batch loss: 0.188508 Batch F1: 0.0
Epoch:  362        5 Batch loss: 0.271612 Batch F1: 0.0
Epoch:  362        6 Batch loss: 0.205729 Batch F1: 0.0
Epoch:  362        7 Batch loss: 0.210827 Batch F1: 0.0
Epoch:  362        8 Batch loss: 0.215869 Batch F1: 0.0
Epoch:  362        9 Batch loss: 0.266856 Batch F1: 0.0
Epoch:  362       10 Batch loss: 0.197227 Batch F1: 0.0
Epoch:  362       11 Batch loss: 0.228678 Batch F1: 0.0
Epoch:  362       12 Batch loss: 0.224302 Batch F1: 0.0
Train Avg Loss  362: 0.227445

Train Avg F1  362: 0.0

Val Avg Loss  362: 0.216784

Val Avg F1  362:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 363
--------------------------------------------------------------
Epoch:  363        1 Batch loss: 0.228031 Batch F1: 0.0
Epoch:  363        2 Batch loss: 0.256271 Batch F1: 0.0
Epoch:  363        3 Batch loss: 0.177886 Batch F1: 0.0
Epoch:  363        4 Batch loss: 0.262535 Batch F1: 0.0
Epoch:  363        5 Batch loss: 0.259901 Batch F1: 0.0
Epoch:  363        6 Batch loss: 0.220055 Batch F1: 0.0
Epoch:  363        7 Batch loss: 0.255510 Batch F1: 0.0
Epoch:  363        8 Batch loss: 0.205958 Batch F1: 0.0
Epoch:  363        9 Batch loss: 0.212256 Batch F1: 0.0
Epoch:  363       10 Batch loss: 0.198015 Batch F1: 0.1
Epoch:  363       11 Batch loss: 0.212333 Batch F1: 0.0
Epoch:  363       12 Batch loss: 0.240558 Batch F1: 0.0
Train Avg Loss  363: 0.227442

Train Avg F1  363: 0.008333333333333333

Val Avg Loss  363: 0.217192

Val Avg F1  363:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 364
--------------------------------------------------------------
Epoch:  364        1 Batch loss: 0.269367 Batch F1: 0.0
Epoch:  364        2 Batch loss: 0.225641 Batch F1: 0.0
Epoch:  364        3 Batch loss: 0.194937 Batch F1: 0.0
Epoch:  364        4 Batch loss: 0.216228 Batch F1: 0.0
Epoch:  364        5 Batch loss: 0.235204 Batch F1: 0.0
Epoch:  364        6 Batch loss: 0.195137 Batch F1: 0.0
Epoch:  364        7 Batch loss: 0.226318 Batch F1: 0.0
Epoch:  364        8 Batch loss: 0.242279 Batch F1: 0.0
Epoch:  364        9 Batch loss: 0.226785 Batch F1: 0.0
Epoch:  364       10 Batch loss: 0.218891 Batch F1: 0.0
Epoch:  364       11 Batch loss: 0.248560 Batch F1: 0.0
Epoch:  364       12 Batch loss: 0.230972 Batch F1: 0.0
Train Avg Loss  364: 0.227527

Train Avg F1  364: 0.0

Val Avg Loss  364: 0.219082

Val Avg F1  364:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 365
--------------------------------------------------------------
Epoch:  365        1 Batch loss: 0.234988 Batch F1: 0.0
Epoch:  365        2 Batch loss: 0.212785 Batch F1: 0.0
Epoch:  365        3 Batch loss: 0.211896 Batch F1: 0.0
Epoch:  365        4 Batch loss: 0.231080 Batch F1: 0.0
Epoch:  365        5 Batch loss: 0.220713 Batch F1: 0.0
Epoch:  365        6 Batch loss: 0.226433 Batch F1: 0.0
Epoch:  365        7 Batch loss: 0.248666 Batch F1: 0.0
Epoch:  365        8 Batch loss: 0.221046 Batch F1: 0.0
Epoch:  365        9 Batch loss: 0.204711 Batch F1: 0.0
Epoch:  365       10 Batch loss: 0.233057 Batch F1: 0.0
Epoch:  365       11 Batch loss: 0.236297 Batch F1: 0.0
Epoch:  365       12 Batch loss: 0.259305 Batch F1: 0.0
Train Avg Loss  365: 0.228415

Train Avg F1  365: 0.0

Val Avg Loss  365: 0.218443

Val Avg F1  365:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 366
--------------------------------------------------------------
Epoch:  366        1 Batch loss: 0.199422 Batch F1: 0.0
Epoch:  366        2 Batch loss: 0.221473 Batch F1: 0.0
Epoch:  366        3 Batch loss: 0.203908 Batch F1: 0.0
Epoch:  366        4 Batch loss: 0.218394 Batch F1: 0.0
Epoch:  366        5 Batch loss: 0.210029 Batch F1: 0.0
Epoch:  366        6 Batch loss: 0.223704 Batch F1: 0.0
Epoch:  366        7 Batch loss: 0.248010 Batch F1: 0.0
Epoch:  366        8 Batch loss: 0.270590 Batch F1: 0.0
Epoch:  366        9 Batch loss: 0.213378 Batch F1: 0.0
Epoch:  366       10 Batch loss: 0.253286 Batch F1: 0.0
Epoch:  366       11 Batch loss: 0.238313 Batch F1: 0.0
Epoch:  366       12 Batch loss: 0.226185 Batch F1: 0.0
Train Avg Loss  366: 0.227224

Train Avg F1  366: 0.0

Val Avg Loss  366: 0.220356

Val Avg F1  366:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 367
--------------------------------------------------------------
Epoch:  367        1 Batch loss: 0.207467 Batch F1: 0.0
Epoch:  367        2 Batch loss: 0.225288 Batch F1: 0.0
Epoch:  367        3 Batch loss: 0.227630 Batch F1: 0.0
Epoch:  367        4 Batch loss: 0.212608 Batch F1: 0.0
Epoch:  367        5 Batch loss: 0.218332 Batch F1: 0.0
Epoch:  367        6 Batch loss: 0.253321 Batch F1: 0.0
Epoch:  367        7 Batch loss: 0.229494 Batch F1: 0.0
Epoch:  367        8 Batch loss: 0.227045 Batch F1: 0.21052631578947367
Epoch:  367        9 Batch loss: 0.221655 Batch F1: 0.0
Epoch:  367       10 Batch loss: 0.226517 Batch F1: 0.0
Epoch:  367       11 Batch loss: 0.249074 Batch F1: 0.0
Epoch:  367       12 Batch loss: 0.264842 Batch F1: 0.0
Train Avg Loss  367: 0.230273

Train Avg F1  367: 0.017543859649122806

Val Avg Loss  367: 0.219055

Val Avg F1  367:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 368
--------------------------------------------------------------
Epoch:  368        1 Batch loss: 0.244679 Batch F1: 0.0
Epoch:  368        2 Batch loss: 0.247655 Batch F1: 0.0
Epoch:  368        3 Batch loss: 0.233571 Batch F1: 0.0
Epoch:  368        4 Batch loss: 0.246613 Batch F1: 0.0
Epoch:  368        5 Batch loss: 0.239558 Batch F1: 0.0
Epoch:  368        6 Batch loss: 0.220957 Batch F1: 0.0
Epoch:  368        7 Batch loss: 0.229383 Batch F1: 0.0
Epoch:  368        8 Batch loss: 0.217087 Batch F1: 0.0
Epoch:  368        9 Batch loss: 0.213910 Batch F1: 0.0
Epoch:  368       10 Batch loss: 0.225343 Batch F1: 0.0
Epoch:  368       11 Batch loss: 0.195732 Batch F1: 0.0
Epoch:  368       12 Batch loss: 0.235292 Batch F1: 0.0
Train Avg Loss  368: 0.229148

Train Avg F1  368: 0.0

Val Avg Loss  368: 0.217648

Val Avg F1  368:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 369
--------------------------------------------------------------
Epoch:  369        1 Batch loss: 0.248077 Batch F1: 0.0
Epoch:  369        2 Batch loss: 0.233391 Batch F1: 0.0
Epoch:  369        3 Batch loss: 0.239511 Batch F1: 0.0
Epoch:  369        4 Batch loss: 0.240819 Batch F1: 0.0
Epoch:  369        5 Batch loss: 0.253546 Batch F1: 0.0
Epoch:  369        6 Batch loss: 0.237937 Batch F1: 0.0
Epoch:  369        7 Batch loss: 0.236867 Batch F1: 0.0
Epoch:  369        8 Batch loss: 0.230902 Batch F1: 0.45161290322580644
Epoch:  369        9 Batch loss: 0.231946 Batch F1: 0.27586206896551724
Epoch:  369       10 Batch loss: 0.227121 Batch F1: 0.4166666666666667
Epoch:  369       11 Batch loss: 0.209829 Batch F1: 0.0
Epoch:  369       12 Batch loss: 0.181588 Batch F1: 0.0
Train Avg Loss  369: 0.230961

Train Avg F1  369: 0.09534513657149919

Val Avg Loss  369: 0.217677

Val Avg F1  369:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 370
--------------------------------------------------------------
Epoch:  370        1 Batch loss: 0.262771 Batch F1: 0.0
Epoch:  370        2 Batch loss: 0.272344 Batch F1: 0.0
Epoch:  370        3 Batch loss: 0.217212 Batch F1: 0.0
Epoch:  370        4 Batch loss: 0.245964 Batch F1: 0.0
Epoch:  370        5 Batch loss: 0.214743 Batch F1: 0.0
Epoch:  370        6 Batch loss: 0.219839 Batch F1: 0.0
Epoch:  370        7 Batch loss: 0.236673 Batch F1: 0.0
Epoch:  370        8 Batch loss: 0.232686 Batch F1: 0.0
Epoch:  370        9 Batch loss: 0.217411 Batch F1: 0.1
Epoch:  370       10 Batch loss: 0.207318 Batch F1: 0.0
Epoch:  370       11 Batch loss: 0.211733 Batch F1: 0.0
Epoch:  370       12 Batch loss: 0.249953 Batch F1: 0.0
Train Avg Loss  370: 0.232387

Train Avg F1  370: 0.008333333333333333

Val Avg Loss  370: 0.218045

Val Avg F1  370:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 371
--------------------------------------------------------------
Epoch:  371        1 Batch loss: 0.239331 Batch F1: 0.0
Epoch:  371        2 Batch loss: 0.219119 Batch F1: 0.0
Epoch:  371        3 Batch loss: 0.216924 Batch F1: 0.0
Epoch:  371        4 Batch loss: 0.249985 Batch F1: 0.0
Epoch:  371        5 Batch loss: 0.234294 Batch F1: 0.0
Epoch:  371        6 Batch loss: 0.219766 Batch F1: 0.0
Epoch:  371        7 Batch loss: 0.236895 Batch F1: 0.0
Epoch:  371        8 Batch loss: 0.207914 Batch F1: 0.0
Epoch:  371        9 Batch loss: 0.235202 Batch F1: 0.0
Epoch:  371       10 Batch loss: 0.226195 Batch F1: 0.0
Epoch:  371       11 Batch loss: 0.250498 Batch F1: 0.0
Epoch:  371       12 Batch loss: 0.207002 Batch F1: 0.0
Train Avg Loss  371: 0.228594

Train Avg F1  371: 0.0

Val Avg Loss  371: 0.218744

Val Avg F1  371:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 372
--------------------------------------------------------------
Epoch:  372        1 Batch loss: 0.231679 Batch F1: 0.0
Epoch:  372        2 Batch loss: 0.241579 Batch F1: 0.0
Epoch:  372        3 Batch loss: 0.210901 Batch F1: 0.0
Epoch:  372        4 Batch loss: 0.230399 Batch F1: 0.0
Epoch:  372        5 Batch loss: 0.222512 Batch F1: 0.0
Epoch:  372        6 Batch loss: 0.269011 Batch F1: 0.0
Epoch:  372        7 Batch loss: 0.223620 Batch F1: 0.0
Epoch:  372        8 Batch loss: 0.210907 Batch F1: 0.0
Epoch:  372        9 Batch loss: 0.212864 Batch F1: 0.0
Epoch:  372       10 Batch loss: 0.226967 Batch F1: 0.0
Epoch:  372       11 Batch loss: 0.231075 Batch F1: 0.0
Epoch:  372       12 Batch loss: 0.220074 Batch F1: 0.0
Train Avg Loss  372: 0.227632

Train Avg F1  372: 0.0

Val Avg Loss  372: 0.218142

Val Avg F1  372:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 373
--------------------------------------------------------------
Epoch:  373        1 Batch loss: 0.232115 Batch F1: 0.0
Epoch:  373        2 Batch loss: 0.226867 Batch F1: 0.0
Epoch:  373        3 Batch loss: 0.232145 Batch F1: 0.0
Epoch:  373        4 Batch loss: 0.227896 Batch F1: 0.0
Epoch:  373        5 Batch loss: 0.213203 Batch F1: 0.0
Epoch:  373        6 Batch loss: 0.235901 Batch F1: 0.0
Epoch:  373        7 Batch loss: 0.242914 Batch F1: 0.0
Epoch:  373        8 Batch loss: 0.242466 Batch F1: 0.0
Epoch:  373        9 Batch loss: 0.238669 Batch F1: 0.0
Epoch:  373       10 Batch loss: 0.226322 Batch F1: 0.0
Epoch:  373       11 Batch loss: 0.212178 Batch F1: 0.0
Epoch:  373       12 Batch loss: 0.192057 Batch F1: 0.0
Train Avg Loss  373: 0.226894

Train Avg F1  373: 0.0

Val Avg Loss  373: 0.217693

Val Avg F1  373:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 374
--------------------------------------------------------------
Epoch:  374        1 Batch loss: 0.237475 Batch F1: 0.0
Epoch:  374        2 Batch loss: 0.204666 Batch F1: 0.0
Epoch:  374        3 Batch loss: 0.200775 Batch F1: 0.0
Epoch:  374        4 Batch loss: 0.254733 Batch F1: 0.0
Epoch:  374        5 Batch loss: 0.234018 Batch F1: 0.0
Epoch:  374        6 Batch loss: 0.246500 Batch F1: 0.0
Epoch:  374        7 Batch loss: 0.205018 Batch F1: 0.0
Epoch:  374        8 Batch loss: 0.257755 Batch F1: 0.0
Epoch:  374        9 Batch loss: 0.228638 Batch F1: 0.0
Epoch:  374       10 Batch loss: 0.243811 Batch F1: 0.0
Epoch:  374       11 Batch loss: 0.195736 Batch F1: 0.0
Epoch:  374       12 Batch loss: 0.228257 Batch F1: 0.0
Train Avg Loss  374: 0.228115

Train Avg F1  374: 0.0

Val Avg Loss  374: 0.217349

Val Avg F1  374:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 375
--------------------------------------------------------------
Epoch:  375        1 Batch loss: 0.271205 Batch F1: 0.0
Epoch:  375        2 Batch loss: 0.200192 Batch F1: 0.0
Epoch:  375        3 Batch loss: 0.237562 Batch F1: 0.0
Epoch:  375        4 Batch loss: 0.228440 Batch F1: 0.0
Epoch:  375        5 Batch loss: 0.263227 Batch F1: 0.0
Epoch:  375        6 Batch loss: 0.220357 Batch F1: 0.0
Epoch:  375        7 Batch loss: 0.219311 Batch F1: 0.16666666666666666
Epoch:  375        8 Batch loss: 0.214278 Batch F1: 0.45161290322580644
Epoch:  375        9 Batch loss: 0.225692 Batch F1: 0.6000000000000001
Epoch:  375       10 Batch loss: 0.216402 Batch F1: 0.39999999999999997
Epoch:  375       11 Batch loss: 0.220129 Batch F1: 0.0
Epoch:  375       12 Batch loss: 0.216582 Batch F1: 0.0
Train Avg Loss  375: 0.227781

Train Avg F1  375: 0.13485663082437274

Val Avg Loss  375: 0.217043

Val Avg F1  375:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 376
--------------------------------------------------------------
Epoch:  376        1 Batch loss: 0.241870 Batch F1: 0.0
Epoch:  376        2 Batch loss: 0.193194 Batch F1: 0.0
Epoch:  376        3 Batch loss: 0.192392 Batch F1: 0.0
Epoch:  376        4 Batch loss: 0.205434 Batch F1: 0.0
Epoch:  376        5 Batch loss: 0.238442 Batch F1: 0.0
Epoch:  376        6 Batch loss: 0.247200 Batch F1: 0.0
Epoch:  376        7 Batch loss: 0.225131 Batch F1: 0.0
Epoch:  376        8 Batch loss: 0.254642 Batch F1: 0.0
Epoch:  376        9 Batch loss: 0.249202 Batch F1: 0.0
Epoch:  376       10 Batch loss: 0.204324 Batch F1: 0.0
Epoch:  376       11 Batch loss: 0.238770 Batch F1: 0.0
Epoch:  376       12 Batch loss: 0.242701 Batch F1: 0.0
Train Avg Loss  376: 0.227775

Train Avg F1  376: 0.0

Val Avg Loss  376: 0.219470

Val Avg F1  376:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 377
--------------------------------------------------------------
Epoch:  377        1 Batch loss: 0.218708 Batch F1: 0.0
Epoch:  377        2 Batch loss: 0.216982 Batch F1: 0.0
Epoch:  377        3 Batch loss: 0.224453 Batch F1: 0.0
Epoch:  377        4 Batch loss: 0.212453 Batch F1: 0.0
Epoch:  377        5 Batch loss: 0.249495 Batch F1: 0.0
Epoch:  377        6 Batch loss: 0.219326 Batch F1: 0.0
Epoch:  377        7 Batch loss: 0.199235 Batch F1: 0.0
Epoch:  377        8 Batch loss: 0.235883 Batch F1: 0.0
Epoch:  377        9 Batch loss: 0.224025 Batch F1: 0.0
Epoch:  377       10 Batch loss: 0.244953 Batch F1: 0.0
Epoch:  377       11 Batch loss: 0.275759 Batch F1: 0.0
Epoch:  377       12 Batch loss: 0.218218 Batch F1: 0.0
Train Avg Loss  377: 0.228291

Train Avg F1  377: 0.0

Val Avg Loss  377: 0.220535

Val Avg F1  377:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 378
--------------------------------------------------------------
Epoch:  378        1 Batch loss: 0.237417 Batch F1: 0.0
Epoch:  378        2 Batch loss: 0.220256 Batch F1: 0.0
Epoch:  378        3 Batch loss: 0.218294 Batch F1: 0.0
Epoch:  378        4 Batch loss: 0.213579 Batch F1: 0.0
Epoch:  378        5 Batch loss: 0.237928 Batch F1: 0.0
Epoch:  378        6 Batch loss: 0.202206 Batch F1: 0.0
Epoch:  378        7 Batch loss: 0.261462 Batch F1: 0.0
Epoch:  378        8 Batch loss: 0.242076 Batch F1: 0.0
Epoch:  378        9 Batch loss: 0.219963 Batch F1: 0.0
Epoch:  378       10 Batch loss: 0.231391 Batch F1: 0.0
Epoch:  378       11 Batch loss: 0.231918 Batch F1: 0.0
Epoch:  378       12 Batch loss: 0.223901 Batch F1: 0.0
Train Avg Loss  378: 0.228366

Train Avg F1  378: 0.0

Val Avg Loss  378: 0.218972

Val Avg F1  378:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 379
--------------------------------------------------------------
Epoch:  379        1 Batch loss: 0.258129 Batch F1: 0.0
Epoch:  379        2 Batch loss: 0.232971 Batch F1: 0.0
Epoch:  379        3 Batch loss: 0.234935 Batch F1: 0.0
Epoch:  379        4 Batch loss: 0.243286 Batch F1: 0.0
Epoch:  379        5 Batch loss: 0.241863 Batch F1: 0.0
Epoch:  379        6 Batch loss: 0.223848 Batch F1: 0.0
Epoch:  379        7 Batch loss: 0.234713 Batch F1: 0.0
Epoch:  379        8 Batch loss: 0.211991 Batch F1: 0.0
Epoch:  379        9 Batch loss: 0.198527 Batch F1: 0.0
Epoch:  379       10 Batch loss: 0.208662 Batch F1: 0.0
Epoch:  379       11 Batch loss: 0.226522 Batch F1: 0.0
Epoch:  379       12 Batch loss: 0.216233 Batch F1: 0.0
Train Avg Loss  379: 0.227640

Train Avg F1  379: 0.0

Val Avg Loss  379: 0.217228

Val Avg F1  379:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 380
--------------------------------------------------------------
Epoch:  380        1 Batch loss: 0.234026 Batch F1: 0.0
Epoch:  380        2 Batch loss: 0.239859 Batch F1: 0.0
Epoch:  380        3 Batch loss: 0.244018 Batch F1: 0.0
Epoch:  380        4 Batch loss: 0.249341 Batch F1: 0.0
Epoch:  380        5 Batch loss: 0.255324 Batch F1: 0.0
Epoch:  380        6 Batch loss: 0.227784 Batch F1: 0.0
Epoch:  380        7 Batch loss: 0.221880 Batch F1: 0.0
Epoch:  380        8 Batch loss: 0.218359 Batch F1: 0.0
Epoch:  380        9 Batch loss: 0.220565 Batch F1: 0.0
Epoch:  380       10 Batch loss: 0.209406 Batch F1: 0.0
Epoch:  380       11 Batch loss: 0.238903 Batch F1: 0.0
Epoch:  380       12 Batch loss: 0.187692 Batch F1: 0.0
Train Avg Loss  380: 0.228930

Train Avg F1  380: 0.0

Val Avg Loss  380: 0.216932

Val Avg F1  380:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 381
--------------------------------------------------------------
Epoch:  381        1 Batch loss: 0.213116 Batch F1: 0.0
Epoch:  381        2 Batch loss: 0.229418 Batch F1: 0.0
Epoch:  381        3 Batch loss: 0.198737 Batch F1: 0.0
Epoch:  381        4 Batch loss: 0.223756 Batch F1: 0.0
Epoch:  381        5 Batch loss: 0.230079 Batch F1: 0.0
Epoch:  381        6 Batch loss: 0.219437 Batch F1: 0.0
Epoch:  381        7 Batch loss: 0.259643 Batch F1: 0.0
Epoch:  381        8 Batch loss: 0.196327 Batch F1: 0.0
Epoch:  381        9 Batch loss: 0.275156 Batch F1: 0.0
Epoch:  381       10 Batch loss: 0.228554 Batch F1: 0.0
Epoch:  381       11 Batch loss: 0.223620 Batch F1: 0.0
Epoch:  381       12 Batch loss: 0.229289 Batch F1: 0.0
Train Avg Loss  381: 0.227261

Train Avg F1  381: 0.0

Val Avg Loss  381: 0.220454

Val Avg F1  381:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 382
--------------------------------------------------------------
Epoch:  382        1 Batch loss: 0.218982 Batch F1: 0.0
Epoch:  382        2 Batch loss: 0.223499 Batch F1: 0.0
Epoch:  382        3 Batch loss: 0.210102 Batch F1: 0.0
Epoch:  382        4 Batch loss: 0.236154 Batch F1: 0.0
Epoch:  382        5 Batch loss: 0.246730 Batch F1: 0.0
Epoch:  382        6 Batch loss: 0.211041 Batch F1: 0.0
Epoch:  382        7 Batch loss: 0.205509 Batch F1: 0.0
Epoch:  382        8 Batch loss: 0.263570 Batch F1: 0.0
Epoch:  382        9 Batch loss: 0.216612 Batch F1: 0.0
Epoch:  382       10 Batch loss: 0.248205 Batch F1: 0.0
Epoch:  382       11 Batch loss: 0.200120 Batch F1: 0.0
Epoch:  382       12 Batch loss: 0.246967 Batch F1: 0.0
Train Avg Loss  382: 0.227291

Train Avg F1  382: 0.0

Val Avg Loss  382: 0.218193

Val Avg F1  382:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 383
--------------------------------------------------------------
Epoch:  383        1 Batch loss: 0.250353 Batch F1: 0.0
Epoch:  383        2 Batch loss: 0.254392 Batch F1: 0.0
Epoch:  383        3 Batch loss: 0.226221 Batch F1: 0.0
Epoch:  383        4 Batch loss: 0.223443 Batch F1: 0.0
Epoch:  383        5 Batch loss: 0.232079 Batch F1: 0.0
Epoch:  383        6 Batch loss: 0.228852 Batch F1: 0.0
Epoch:  383        7 Batch loss: 0.203103 Batch F1: 0.0
Epoch:  383        8 Batch loss: 0.232379 Batch F1: 0.0
Epoch:  383        9 Batch loss: 0.230704 Batch F1: 0.0
Epoch:  383       10 Batch loss: 0.223366 Batch F1: 0.0
Epoch:  383       11 Batch loss: 0.188850 Batch F1: 0.0
Epoch:  383       12 Batch loss: 0.222726 Batch F1: 0.0
Train Avg Loss  383: 0.226372

Train Avg F1  383: 0.0

Val Avg Loss  383: 0.217628

Val Avg F1  383:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 384
--------------------------------------------------------------
Epoch:  384        1 Batch loss: 0.207984 Batch F1: 0.0
Epoch:  384        2 Batch loss: 0.209886 Batch F1: 0.0
Epoch:  384        3 Batch loss: 0.237519 Batch F1: 0.0
Epoch:  384        4 Batch loss: 0.212133 Batch F1: 0.0
Epoch:  384        5 Batch loss: 0.219888 Batch F1: 0.0
Epoch:  384        6 Batch loss: 0.235659 Batch F1: 0.0
Epoch:  384        7 Batch loss: 0.239056 Batch F1: 0.0
Epoch:  384        8 Batch loss: 0.256873 Batch F1: 0.0
Epoch:  384        9 Batch loss: 0.242823 Batch F1: 0.0
Epoch:  384       10 Batch loss: 0.234938 Batch F1: 0.0
Epoch:  384       11 Batch loss: 0.221553 Batch F1: 0.0
Epoch:  384       12 Batch loss: 0.195296 Batch F1: 0.0
Train Avg Loss  384: 0.226134

Train Avg F1  384: 0.0

Val Avg Loss  384: 0.218159

Val Avg F1  384:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 385
--------------------------------------------------------------
Epoch:  385        1 Batch loss: 0.227314 Batch F1: 0.0
Epoch:  385        2 Batch loss: 0.245674 Batch F1: 0.0
Epoch:  385        3 Batch loss: 0.237173 Batch F1: 0.0
Epoch:  385        4 Batch loss: 0.225509 Batch F1: 0.0
Epoch:  385        5 Batch loss: 0.255545 Batch F1: 0.0
Epoch:  385        6 Batch loss: 0.197273 Batch F1: 0.0
Epoch:  385        7 Batch loss: 0.231196 Batch F1: 0.0
Epoch:  385        8 Batch loss: 0.233402 Batch F1: 0.0
Epoch:  385        9 Batch loss: 0.207974 Batch F1: 0.0
Epoch:  385       10 Batch loss: 0.219268 Batch F1: 0.0
Epoch:  385       11 Batch loss: 0.211821 Batch F1: 0.0
Epoch:  385       12 Batch loss: 0.216882 Batch F1: 0.0
Train Avg Loss  385: 0.225753

Train Avg F1  385: 0.0

Val Avg Loss  385: 0.216735

Val Avg F1  385:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 386
--------------------------------------------------------------
Epoch:  386        1 Batch loss: 0.216302 Batch F1: 0.0
Epoch:  386        2 Batch loss: 0.256612 Batch F1: 0.0
Epoch:  386        3 Batch loss: 0.222294 Batch F1: 0.0
Epoch:  386        4 Batch loss: 0.244886 Batch F1: 0.0
Epoch:  386        5 Batch loss: 0.247430 Batch F1: 0.0
Epoch:  386        6 Batch loss: 0.228985 Batch F1: 0.0
Epoch:  386        7 Batch loss: 0.192180 Batch F1: 0.0
Epoch:  386        8 Batch loss: 0.260117 Batch F1: 0.0
Epoch:  386        9 Batch loss: 0.182243 Batch F1: 0.0
Epoch:  386       10 Batch loss: 0.226337 Batch F1: 0.0
Epoch:  386       11 Batch loss: 0.197050 Batch F1: 0.0
Epoch:  386       12 Batch loss: 0.250022 Batch F1: 0.0
Train Avg Loss  386: 0.227038

Train Avg F1  386: 0.0

Val Avg Loss  386: 0.217015

Val Avg F1  386:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 387
--------------------------------------------------------------
Epoch:  387        1 Batch loss: 0.221872 Batch F1: 0.0
Epoch:  387        2 Batch loss: 0.197552 Batch F1: 0.0
Epoch:  387        3 Batch loss: 0.225862 Batch F1: 0.0
Epoch:  387        4 Batch loss: 0.245913 Batch F1: 0.0
Epoch:  387        5 Batch loss: 0.212079 Batch F1: 0.0
Epoch:  387        6 Batch loss: 0.238269 Batch F1: 0.0
Epoch:  387        7 Batch loss: 0.256772 Batch F1: 0.0
Epoch:  387        8 Batch loss: 0.192943 Batch F1: 0.0
Epoch:  387        9 Batch loss: 0.229759 Batch F1: 0.0
Epoch:  387       10 Batch loss: 0.227184 Batch F1: 0.0
Epoch:  387       11 Batch loss: 0.223788 Batch F1: 0.0
Epoch:  387       12 Batch loss: 0.242236 Batch F1: 0.0
Train Avg Loss  387: 0.226186

Train Avg F1  387: 0.0

Val Avg Loss  387: 0.217255

Val Avg F1  387:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 388
--------------------------------------------------------------
Epoch:  388        1 Batch loss: 0.220263 Batch F1: 0.0
Epoch:  388        2 Batch loss: 0.225016 Batch F1: 0.0
Epoch:  388        3 Batch loss: 0.237788 Batch F1: 0.0
Epoch:  388        4 Batch loss: 0.231683 Batch F1: 0.0
Epoch:  388        5 Batch loss: 0.229283 Batch F1: 0.0
Epoch:  388        6 Batch loss: 0.213320 Batch F1: 0.0
Epoch:  388        7 Batch loss: 0.254401 Batch F1: 0.0
Epoch:  388        8 Batch loss: 0.235052 Batch F1: 0.0
Epoch:  388        9 Batch loss: 0.190150 Batch F1: 0.0
Epoch:  388       10 Batch loss: 0.232945 Batch F1: 0.0
Epoch:  388       11 Batch loss: 0.207201 Batch F1: 0.0
Epoch:  388       12 Batch loss: 0.238039 Batch F1: 0.0
Train Avg Loss  388: 0.226262

Train Avg F1  388: 0.0

Val Avg Loss  388: 0.217150

Val Avg F1  388:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 389
--------------------------------------------------------------
Epoch:  389        1 Batch loss: 0.237423 Batch F1: 0.0
Epoch:  389        2 Batch loss: 0.202274 Batch F1: 0.0
Epoch:  389        3 Batch loss: 0.234546 Batch F1: 0.0
Epoch:  389        4 Batch loss: 0.274802 Batch F1: 0.0
Epoch:  389        5 Batch loss: 0.249695 Batch F1: 0.0
Epoch:  389        6 Batch loss: 0.218126 Batch F1: 0.0
Epoch:  389        7 Batch loss: 0.207772 Batch F1: 0.0
Epoch:  389        8 Batch loss: 0.217279 Batch F1: 0.0
Epoch:  389        9 Batch loss: 0.218100 Batch F1: 0.0
Epoch:  389       10 Batch loss: 0.227099 Batch F1: 0.0
Epoch:  389       11 Batch loss: 0.205159 Batch F1: 0.0
Epoch:  389       12 Batch loss: 0.217352 Batch F1: 0.0
Train Avg Loss  389: 0.225802

Train Avg F1  389: 0.0

Val Avg Loss  389: 0.217391

Val Avg F1  389:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 390
--------------------------------------------------------------
Epoch:  390        1 Batch loss: 0.196027 Batch F1: 0.0
Epoch:  390        2 Batch loss: 0.256175 Batch F1: 0.0
Epoch:  390        3 Batch loss: 0.229450 Batch F1: 0.0
Epoch:  390        4 Batch loss: 0.212267 Batch F1: 0.0
Epoch:  390        5 Batch loss: 0.255584 Batch F1: 0.0
Epoch:  390        6 Batch loss: 0.264580 Batch F1: 0.0
Epoch:  390        7 Batch loss: 0.199875 Batch F1: 0.0
Epoch:  390        8 Batch loss: 0.207492 Batch F1: 0.0
Epoch:  390        9 Batch loss: 0.215040 Batch F1: 0.0
Epoch:  390       10 Batch loss: 0.220380 Batch F1: 0.0
Epoch:  390       11 Batch loss: 0.224069 Batch F1: 0.0
Epoch:  390       12 Batch loss: 0.230515 Batch F1: 0.0
Train Avg Loss  390: 0.225954

Train Avg F1  390: 0.0

Val Avg Loss  390: 0.216689

Val Avg F1  390:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 391
--------------------------------------------------------------
Epoch:  391        1 Batch loss: 0.218717 Batch F1: 0.0
Epoch:  391        2 Batch loss: 0.213434 Batch F1: 0.0
Epoch:  391        3 Batch loss: 0.230568 Batch F1: 0.0
Epoch:  391        4 Batch loss: 0.264416 Batch F1: 0.0
Epoch:  391        5 Batch loss: 0.215571 Batch F1: 0.0
Epoch:  391        6 Batch loss: 0.225836 Batch F1: 0.0
Epoch:  391        7 Batch loss: 0.203975 Batch F1: 0.0
Epoch:  391        8 Batch loss: 0.187193 Batch F1: 0.0
Epoch:  391        9 Batch loss: 0.251525 Batch F1: 0.0
Epoch:  391       10 Batch loss: 0.192391 Batch F1: 0.0
Epoch:  391       11 Batch loss: 0.283896 Batch F1: 0.0
Epoch:  391       12 Batch loss: 0.238827 Batch F1: 0.0
Train Avg Loss  391: 0.227196

Train Avg F1  391: 0.0

Val Avg Loss  391: 0.218511

Val Avg F1  391:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 392
--------------------------------------------------------------
Epoch:  392        1 Batch loss: 0.237444 Batch F1: 0.0
Epoch:  392        2 Batch loss: 0.203307 Batch F1: 0.0
Epoch:  392        3 Batch loss: 0.237345 Batch F1: 0.0
Epoch:  392        4 Batch loss: 0.215145 Batch F1: 0.0
Epoch:  392        5 Batch loss: 0.227269 Batch F1: 0.0
Epoch:  392        6 Batch loss: 0.205381 Batch F1: 0.0
Epoch:  392        7 Batch loss: 0.218564 Batch F1: 0.0
Epoch:  392        8 Batch loss: 0.197777 Batch F1: 0.0
Epoch:  392        9 Batch loss: 0.205346 Batch F1: 0.0
Epoch:  392       10 Batch loss: 0.298014 Batch F1: 0.0
Epoch:  392       11 Batch loss: 0.264798 Batch F1: 0.0
Epoch:  392       12 Batch loss: 0.246218 Batch F1: 0.0
Train Avg Loss  392: 0.229717

Train Avg F1  392: 0.0

Val Avg Loss  392: 0.219797

Val Avg F1  392:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 393
--------------------------------------------------------------
Epoch:  393        1 Batch loss: 0.221111 Batch F1: 0.0
Epoch:  393        2 Batch loss: 0.204171 Batch F1: 0.0
Epoch:  393        3 Batch loss: 0.224817 Batch F1: 0.0
Epoch:  393        4 Batch loss: 0.218562 Batch F1: 0.0
Epoch:  393        5 Batch loss: 0.237710 Batch F1: 0.0
Epoch:  393        6 Batch loss: 0.246631 Batch F1: 0.0
Epoch:  393        7 Batch loss: 0.231699 Batch F1: 0.0
Epoch:  393        8 Batch loss: 0.215835 Batch F1: 0.0
Epoch:  393        9 Batch loss: 0.233981 Batch F1: 0.0
Epoch:  393       10 Batch loss: 0.239383 Batch F1: 0.0
Epoch:  393       11 Batch loss: 0.245786 Batch F1: 0.0
Epoch:  393       12 Batch loss: 0.201259 Batch F1: 0.0
Train Avg Loss  393: 0.226745

Train Avg F1  393: 0.0

Val Avg Loss  393: 0.219026

Val Avg F1  393:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 394
--------------------------------------------------------------
Epoch:  394        1 Batch loss: 0.208030 Batch F1: 0.0
Epoch:  394        2 Batch loss: 0.192656 Batch F1: 0.0
Epoch:  394        3 Batch loss: 0.220471 Batch F1: 0.0
Epoch:  394        4 Batch loss: 0.241324 Batch F1: 0.0
Epoch:  394        5 Batch loss: 0.230932 Batch F1: 0.0
Epoch:  394        6 Batch loss: 0.262095 Batch F1: 0.0
Epoch:  394        7 Batch loss: 0.232203 Batch F1: 0.0
Epoch:  394        8 Batch loss: 0.224147 Batch F1: 0.0
Epoch:  394        9 Batch loss: 0.225304 Batch F1: 0.0
Epoch:  394       10 Batch loss: 0.218187 Batch F1: 0.0
Epoch:  394       11 Batch loss: 0.210106 Batch F1: 0.0
Epoch:  394       12 Batch loss: 0.267376 Batch F1: 0.0
Train Avg Loss  394: 0.227736

Train Avg F1  394: 0.0

Val Avg Loss  394: 0.218462

Val Avg F1  394:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 395
--------------------------------------------------------------
Epoch:  395        1 Batch loss: 0.224869 Batch F1: 0.0
Epoch:  395        2 Batch loss: 0.232895 Batch F1: 0.0
Epoch:  395        3 Batch loss: 0.206956 Batch F1: 0.0
Epoch:  395        4 Batch loss: 0.222648 Batch F1: 0.0
Epoch:  395        5 Batch loss: 0.232997 Batch F1: 0.0
Epoch:  395        6 Batch loss: 0.225911 Batch F1: 0.0
Epoch:  395        7 Batch loss: 0.208258 Batch F1: 0.0
Epoch:  395        8 Batch loss: 0.235786 Batch F1: 0.0
Epoch:  395        9 Batch loss: 0.216463 Batch F1: 0.0
Epoch:  395       10 Batch loss: 0.257350 Batch F1: 0.0
Epoch:  395       11 Batch loss: 0.194360 Batch F1: 0.0
Epoch:  395       12 Batch loss: 0.265825 Batch F1: 0.0
Train Avg Loss  395: 0.227026

Train Avg F1  395: 0.0

Val Avg Loss  395: 0.217473

Val Avg F1  395:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 396
--------------------------------------------------------------
Epoch:  396        1 Batch loss: 0.244295 Batch F1: 0.0
Epoch:  396        2 Batch loss: 0.242749 Batch F1: 0.0
Epoch:  396        3 Batch loss: 0.219549 Batch F1: 0.0
Epoch:  396        4 Batch loss: 0.214518 Batch F1: 0.0
Epoch:  396        5 Batch loss: 0.216801 Batch F1: 0.0
Epoch:  396        6 Batch loss: 0.243776 Batch F1: 0.0
Epoch:  396        7 Batch loss: 0.231746 Batch F1: 0.0
Epoch:  396        8 Batch loss: 0.240292 Batch F1: 0.0
Epoch:  396        9 Batch loss: 0.211440 Batch F1: 0.0
Epoch:  396       10 Batch loss: 0.207786 Batch F1: 0.125
Epoch:  396       11 Batch loss: 0.215395 Batch F1: 0.0
Epoch:  396       12 Batch loss: 0.226899 Batch F1: 0.0
Train Avg Loss  396: 0.226271

Train Avg F1  396: 0.010416666666666666

Val Avg Loss  396: 0.217874

Val Avg F1  396:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 397
--------------------------------------------------------------
Epoch:  397        1 Batch loss: 0.223269 Batch F1: 0.0
Epoch:  397        2 Batch loss: 0.261745 Batch F1: 0.0
Epoch:  397        3 Batch loss: 0.217676 Batch F1: 0.0
Epoch:  397        4 Batch loss: 0.228448 Batch F1: 0.0
Epoch:  397        5 Batch loss: 0.217607 Batch F1: 0.0
Epoch:  397        6 Batch loss: 0.244779 Batch F1: 0.0
Epoch:  397        7 Batch loss: 0.231117 Batch F1: 0.0
Epoch:  397        8 Batch loss: 0.203476 Batch F1: 0.0
Epoch:  397        9 Batch loss: 0.229924 Batch F1: 0.0
Epoch:  397       10 Batch loss: 0.225145 Batch F1: 0.0
Epoch:  397       11 Batch loss: 0.267517 Batch F1: 0.0
Epoch:  397       12 Batch loss: 0.185407 Batch F1: 0.0
Train Avg Loss  397: 0.228009

Train Avg F1  397: 0.0

Val Avg Loss  397: 0.219840

Val Avg F1  397:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 398
--------------------------------------------------------------
Epoch:  398        1 Batch loss: 0.226914 Batch F1: 0.0
Epoch:  398        2 Batch loss: 0.255416 Batch F1: 0.0
Epoch:  398        3 Batch loss: 0.222441 Batch F1: 0.0
Epoch:  398        4 Batch loss: 0.212577 Batch F1: 0.0
Epoch:  398        5 Batch loss: 0.222890 Batch F1: 0.0
Epoch:  398        6 Batch loss: 0.229261 Batch F1: 0.0
Epoch:  398        7 Batch loss: 0.233687 Batch F1: 0.0
Epoch:  398        8 Batch loss: 0.213645 Batch F1: 0.0
Epoch:  398        9 Batch loss: 0.193274 Batch F1: 0.0
Epoch:  398       10 Batch loss: 0.211656 Batch F1: 0.0
Epoch:  398       11 Batch loss: 0.244899 Batch F1: 0.0
Epoch:  398       12 Batch loss: 0.261204 Batch F1: 0.0
Train Avg Loss  398: 0.227322

Train Avg F1  398: 0.0

Val Avg Loss  398: 0.218363

Val Avg F1  398:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 399
--------------------------------------------------------------
Epoch:  399        1 Batch loss: 0.222801 Batch F1: 0.0
Epoch:  399        2 Batch loss: 0.227722 Batch F1: 0.0
Epoch:  399        3 Batch loss: 0.241738 Batch F1: 0.0
Epoch:  399        4 Batch loss: 0.240290 Batch F1: 0.16
Epoch:  399        5 Batch loss: 0.233886 Batch F1: 0.32
Epoch:  399        6 Batch loss: 0.224880 Batch F1: 0.37037037037037035
Epoch:  399        7 Batch loss: 0.211444 Batch F1: 0.0
Epoch:  399        8 Batch loss: 0.209538 Batch F1: 0.0
Epoch:  399        9 Batch loss: 0.230556 Batch F1: 0.0
Epoch:  399       10 Batch loss: 0.234711 Batch F1: 0.0
Epoch:  399       11 Batch loss: 0.207220 Batch F1: 0.0
Epoch:  399       12 Batch loss: 0.237803 Batch F1: 0.0
Train Avg Loss  399: 0.226882

Train Avg F1  399: 0.07086419753086419

Val Avg Loss  399: 0.217405

Val Avg F1  399:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 400
--------------------------------------------------------------
Epoch:  400        1 Batch loss: 0.220233 Batch F1: 0.0
Epoch:  400        2 Batch loss: 0.213768 Batch F1: 0.0
Epoch:  400        3 Batch loss: 0.248153 Batch F1: 0.0
Epoch:  400        4 Batch loss: 0.196919 Batch F1: 0.0
Epoch:  400        5 Batch loss: 0.202127 Batch F1: 0.0
Epoch:  400        6 Batch loss: 0.217051 Batch F1: 0.0
Epoch:  400        7 Batch loss: 0.284312 Batch F1: 0.0
Epoch:  400        8 Batch loss: 0.235416 Batch F1: 0.0
Epoch:  400        9 Batch loss: 0.243993 Batch F1: 0.0
Epoch:  400       10 Batch loss: 0.222890 Batch F1: 0.0
Epoch:  400       11 Batch loss: 0.226383 Batch F1: 0.0
Epoch:  400       12 Batch loss: 0.211400 Batch F1: 0.0
Train Avg Loss  400: 0.226887

Train Avg F1  400: 0.0

Val Avg Loss  400: 0.218590

Val Avg F1  400:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 401
--------------------------------------------------------------
Epoch:  401        1 Batch loss: 0.234646 Batch F1: 0.0
Epoch:  401        2 Batch loss: 0.206211 Batch F1: 0.0
Epoch:  401        3 Batch loss: 0.237710 Batch F1: 0.0
Epoch:  401        4 Batch loss: 0.214141 Batch F1: 0.0
Epoch:  401        5 Batch loss: 0.233250 Batch F1: 0.0
Epoch:  401        6 Batch loss: 0.226552 Batch F1: 0.0
Epoch:  401        7 Batch loss: 0.224826 Batch F1: 0.0
Epoch:  401        8 Batch loss: 0.237256 Batch F1: 0.0
Epoch:  401        9 Batch loss: 0.206340 Batch F1: 0.0
Epoch:  401       10 Batch loss: 0.238815 Batch F1: 0.0
Epoch:  401       11 Batch loss: 0.261180 Batch F1: 0.0
Epoch:  401       12 Batch loss: 0.188458 Batch F1: 0.0
Train Avg Loss  401: 0.225782

Train Avg F1  401: 0.0

Val Avg Loss  401: 0.219647

Val Avg F1  401:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 402
--------------------------------------------------------------
Epoch:  402        1 Batch loss: 0.249158 Batch F1: 0.0
Epoch:  402        2 Batch loss: 0.208581 Batch F1: 0.0
Epoch:  402        3 Batch loss: 0.225185 Batch F1: 0.0
Epoch:  402        4 Batch loss: 0.237757 Batch F1: 0.0
Epoch:  402        5 Batch loss: 0.244292 Batch F1: 0.0
Epoch:  402        6 Batch loss: 0.221056 Batch F1: 0.0
Epoch:  402        7 Batch loss: 0.242693 Batch F1: 0.0
Epoch:  402        8 Batch loss: 0.214496 Batch F1: 0.0
Epoch:  402        9 Batch loss: 0.238547 Batch F1: 0.0
Epoch:  402       10 Batch loss: 0.202999 Batch F1: 0.0
Epoch:  402       11 Batch loss: 0.201986 Batch F1: 0.0
Epoch:  402       12 Batch loss: 0.229611 Batch F1: 0.0
Train Avg Loss  402: 0.226364

Train Avg F1  402: 0.0

Val Avg Loss  402: 0.217329

Val Avg F1  402:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 403
--------------------------------------------------------------
Epoch:  403        1 Batch loss: 0.251050 Batch F1: 0.0
Epoch:  403        2 Batch loss: 0.238362 Batch F1: 0.0
Epoch:  403        3 Batch loss: 0.224998 Batch F1: 0.0
Epoch:  403        4 Batch loss: 0.234168 Batch F1: 0.0
Epoch:  403        5 Batch loss: 0.211706 Batch F1: 0.0
Epoch:  403        6 Batch loss: 0.195147 Batch F1: 0.0
Epoch:  403        7 Batch loss: 0.236214 Batch F1: 0.0
Epoch:  403        8 Batch loss: 0.211256 Batch F1: 0.0
Epoch:  403        9 Batch loss: 0.240551 Batch F1: 0.0
Epoch:  403       10 Batch loss: 0.226148 Batch F1: 0.0
Epoch:  403       11 Batch loss: 0.250657 Batch F1: 0.0
Epoch:  403       12 Batch loss: 0.191854 Batch F1: 0.0
Train Avg Loss  403: 0.226009

Train Avg F1  403: 0.0

Val Avg Loss  403: 0.216589

Val Avg F1  403:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 404
--------------------------------------------------------------
Epoch:  404        1 Batch loss: 0.203479 Batch F1: 0.0
Epoch:  404        2 Batch loss: 0.233187 Batch F1: 0.0
Epoch:  404        3 Batch loss: 0.212344 Batch F1: 0.0
Epoch:  404        4 Batch loss: 0.232610 Batch F1: 0.0
Epoch:  404        5 Batch loss: 0.235133 Batch F1: 0.0
Epoch:  404        6 Batch loss: 0.251001 Batch F1: 0.0
Epoch:  404        7 Batch loss: 0.232087 Batch F1: 0.0
Epoch:  404        8 Batch loss: 0.213661 Batch F1: 0.0
Epoch:  404        9 Batch loss: 0.243457 Batch F1: 0.0
Epoch:  404       10 Batch loss: 0.200646 Batch F1: 0.0
Epoch:  404       11 Batch loss: 0.231371 Batch F1: 0.0
Epoch:  404       12 Batch loss: 0.251655 Batch F1: 0.0
Train Avg Loss  404: 0.228386

Train Avg F1  404: 0.0

Val Avg Loss  404: 0.220909

Val Avg F1  404:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 405
--------------------------------------------------------------
Epoch:  405        1 Batch loss: 0.226515 Batch F1: 0.0
Epoch:  405        2 Batch loss: 0.206455 Batch F1: 0.0
Epoch:  405        3 Batch loss: 0.239360 Batch F1: 0.0
Epoch:  405        4 Batch loss: 0.242730 Batch F1: 0.0
Epoch:  405        5 Batch loss: 0.234158 Batch F1: 0.0
Epoch:  405        6 Batch loss: 0.211298 Batch F1: 0.0
Epoch:  405        7 Batch loss: 0.239691 Batch F1: 0.0
Epoch:  405        8 Batch loss: 0.215028 Batch F1: 0.0
Epoch:  405        9 Batch loss: 0.233704 Batch F1: 0.0
Epoch:  405       10 Batch loss: 0.242955 Batch F1: 0.0
Epoch:  405       11 Batch loss: 0.211138 Batch F1: 0.0
Epoch:  405       12 Batch loss: 0.240725 Batch F1: 0.0
Train Avg Loss  405: 0.228646

Train Avg F1  405: 0.0

Val Avg Loss  405: 0.219915

Val Avg F1  405:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 406
--------------------------------------------------------------
Epoch:  406        1 Batch loss: 0.199379 Batch F1: 0.0
Epoch:  406        2 Batch loss: 0.226904 Batch F1: 0.0
Epoch:  406        3 Batch loss: 0.222952 Batch F1: 0.0
Epoch:  406        4 Batch loss: 0.265666 Batch F1: 0.0
Epoch:  406        5 Batch loss: 0.250160 Batch F1: 0.0
Epoch:  406        6 Batch loss: 0.230150 Batch F1: 0.0
Epoch:  406        7 Batch loss: 0.226778 Batch F1: 0.0
Epoch:  406        8 Batch loss: 0.222347 Batch F1: 0.0
Epoch:  406        9 Batch loss: 0.210951 Batch F1: 0.0
Epoch:  406       10 Batch loss: 0.203908 Batch F1: 0.0
Epoch:  406       11 Batch loss: 0.255301 Batch F1: 0.0
Epoch:  406       12 Batch loss: 0.260060 Batch F1: 0.0
Train Avg Loss  406: 0.231213

Train Avg F1  406: 0.0

Val Avg Loss  406: 0.217934

Val Avg F1  406:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 407
--------------------------------------------------------------
Epoch:  407        1 Batch loss: 0.213920 Batch F1: 0.0
Epoch:  407        2 Batch loss: 0.258773 Batch F1: 0.0
Epoch:  407        3 Batch loss: 0.224880 Batch F1: 0.0
Epoch:  407        4 Batch loss: 0.231358 Batch F1: 0.0
Epoch:  407        5 Batch loss: 0.208671 Batch F1: 0.0
Epoch:  407        6 Batch loss: 0.212632 Batch F1: 0.0
Epoch:  407        7 Batch loss: 0.214587 Batch F1: 0.0
Epoch:  407        8 Batch loss: 0.247261 Batch F1: 0.0
Epoch:  407        9 Batch loss: 0.206508 Batch F1: 0.0
Epoch:  407       10 Batch loss: 0.282599 Batch F1: 0.0
Epoch:  407       11 Batch loss: 0.227327 Batch F1: 0.0
Epoch:  407       12 Batch loss: 0.228259 Batch F1: 0.0
Train Avg Loss  407: 0.229731

Train Avg F1  407: 0.0

Val Avg Loss  407: 0.220183

Val Avg F1  407:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 408
--------------------------------------------------------------
Epoch:  408        1 Batch loss: 0.220585 Batch F1: 0.0
Epoch:  408        2 Batch loss: 0.204635 Batch F1: 0.0
Epoch:  408        3 Batch loss: 0.227376 Batch F1: 0.0
Epoch:  408        4 Batch loss: 0.236151 Batch F1: 0.0
Epoch:  408        5 Batch loss: 0.223092 Batch F1: 0.0
Epoch:  408        6 Batch loss: 0.223147 Batch F1: 0.0
Epoch:  408        7 Batch loss: 0.234482 Batch F1: 0.0
Epoch:  408        8 Batch loss: 0.220473 Batch F1: 0.0
Epoch:  408        9 Batch loss: 0.247415 Batch F1: 0.0
Epoch:  408       10 Batch loss: 0.261819 Batch F1: 0.0
Epoch:  408       11 Batch loss: 0.231516 Batch F1: 0.0
Epoch:  408       12 Batch loss: 0.192672 Batch F1: 0.0
Train Avg Loss  408: 0.226947

Train Avg F1  408: 0.0

Val Avg Loss  408: 0.218066

Val Avg F1  408:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 409
--------------------------------------------------------------
Epoch:  409        1 Batch loss: 0.210883 Batch F1: 0.0
Epoch:  409        2 Batch loss: 0.224789 Batch F1: 0.0
Epoch:  409        3 Batch loss: 0.220792 Batch F1: 0.0
Epoch:  409        4 Batch loss: 0.238771 Batch F1: 0.0
Epoch:  409        5 Batch loss: 0.271256 Batch F1: 0.0
Epoch:  409        6 Batch loss: 0.218193 Batch F1: 0.0
Epoch:  409        7 Batch loss: 0.217103 Batch F1: 0.0
Epoch:  409        8 Batch loss: 0.231726 Batch F1: 0.0
Epoch:  409        9 Batch loss: 0.198553 Batch F1: 0.0
Epoch:  409       10 Batch loss: 0.242325 Batch F1: 0.0
Epoch:  409       11 Batch loss: 0.210536 Batch F1: 0.0
Epoch:  409       12 Batch loss: 0.239627 Batch F1: 0.0
Train Avg Loss  409: 0.227046

Train Avg F1  409: 0.0

Val Avg Loss  409: 0.217802

Val Avg F1  409:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 410
--------------------------------------------------------------
Epoch:  410        1 Batch loss: 0.238182 Batch F1: 0.0
Epoch:  410        2 Batch loss: 0.230493 Batch F1: 0.0
Epoch:  410        3 Batch loss: 0.195537 Batch F1: 0.0
Epoch:  410        4 Batch loss: 0.217072 Batch F1: 0.0
Epoch:  410        5 Batch loss: 0.241330 Batch F1: 0.0
Epoch:  410        6 Batch loss: 0.223024 Batch F1: 0.0
Epoch:  410        7 Batch loss: 0.209457 Batch F1: 0.0
Epoch:  410        8 Batch loss: 0.263555 Batch F1: 0.0
Epoch:  410        9 Batch loss: 0.226083 Batch F1: 0.0
Epoch:  410       10 Batch loss: 0.224514 Batch F1: 0.0
Epoch:  410       11 Batch loss: 0.213103 Batch F1: 0.0
Epoch:  410       12 Batch loss: 0.240836 Batch F1: 0.0
Train Avg Loss  410: 0.226932

Train Avg F1  410: 0.0

Val Avg Loss  410: 0.218658

Val Avg F1  410:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 411
--------------------------------------------------------------
Epoch:  411        1 Batch loss: 0.219818 Batch F1: 0.0
Epoch:  411        2 Batch loss: 0.234980 Batch F1: 0.0
Epoch:  411        3 Batch loss: 0.237274 Batch F1: 0.0
Epoch:  411        4 Batch loss: 0.207069 Batch F1: 0.0
Epoch:  411        5 Batch loss: 0.250796 Batch F1: 0.0
Epoch:  411        6 Batch loss: 0.230737 Batch F1: 0.0
Epoch:  411        7 Batch loss: 0.245636 Batch F1: 0.0
Epoch:  411        8 Batch loss: 0.229717 Batch F1: 0.0
Epoch:  411        9 Batch loss: 0.210387 Batch F1: 0.0
Epoch:  411       10 Batch loss: 0.206154 Batch F1: 0.0
Epoch:  411       11 Batch loss: 0.262969 Batch F1: 0.0
Epoch:  411       12 Batch loss: 0.181970 Batch F1: 0.0
Train Avg Loss  411: 0.226459

Train Avg F1  411: 0.0

Val Avg Loss  411: 0.217361

Val Avg F1  411:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 412
--------------------------------------------------------------
Epoch:  412        1 Batch loss: 0.219063 Batch F1: 0.0
Epoch:  412        2 Batch loss: 0.247010 Batch F1: 0.0
Epoch:  412        3 Batch loss: 0.252202 Batch F1: 0.0
Epoch:  412        4 Batch loss: 0.261697 Batch F1: 0.0
Epoch:  412        5 Batch loss: 0.211043 Batch F1: 0.0
Epoch:  412        6 Batch loss: 0.227563 Batch F1: 0.0
Epoch:  412        7 Batch loss: 0.222652 Batch F1: 0.0
Epoch:  412        8 Batch loss: 0.227095 Batch F1: 0.0
Epoch:  412        9 Batch loss: 0.230396 Batch F1: 0.0
Epoch:  412       10 Batch loss: 0.220230 Batch F1: 0.0
Epoch:  412       11 Batch loss: 0.211113 Batch F1: 0.0
Epoch:  412       12 Batch loss: 0.207264 Batch F1: 0.0
Train Avg Loss  412: 0.228111

Train Avg F1  412: 0.0

Val Avg Loss  412: 0.217060

Val Avg F1  412:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 413
--------------------------------------------------------------
Epoch:  413        1 Batch loss: 0.198941 Batch F1: 0.0
Epoch:  413        2 Batch loss: 0.250093 Batch F1: 0.0
Epoch:  413        3 Batch loss: 0.235863 Batch F1: 0.0
Epoch:  413        4 Batch loss: 0.240221 Batch F1: 0.0
Epoch:  413        5 Batch loss: 0.198889 Batch F1: 0.0
Epoch:  413        6 Batch loss: 0.227277 Batch F1: 0.0
Epoch:  413        7 Batch loss: 0.235244 Batch F1: 0.0
Epoch:  413        8 Batch loss: 0.241941 Batch F1: 0.0
Epoch:  413        9 Batch loss: 0.266714 Batch F1: 0.0
Epoch:  413       10 Batch loss: 0.215295 Batch F1: 0.2857142857142857
Epoch:  413       11 Batch loss: 0.217301 Batch F1: 0.28571428571428575
Epoch:  413       12 Batch loss: 0.209101 Batch F1: 0.3
Train Avg Loss  413: 0.228073

Train Avg F1  413: 0.07261904761904762

Val Avg Loss  413: 0.217535

Val Avg F1  413:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 414
--------------------------------------------------------------
Epoch:  414        1 Batch loss: 0.237366 Batch F1: 0.0
Epoch:  414        2 Batch loss: 0.242261 Batch F1: 0.0
Epoch:  414        3 Batch loss: 0.194538 Batch F1: 0.0
Epoch:  414        4 Batch loss: 0.245144 Batch F1: 0.0
Epoch:  414        5 Batch loss: 0.232164 Batch F1: 0.0
Epoch:  414        6 Batch loss: 0.176607 Batch F1: 0.0
Epoch:  414        7 Batch loss: 0.266992 Batch F1: 0.0
Epoch:  414        8 Batch loss: 0.211807 Batch F1: 0.0
Epoch:  414        9 Batch loss: 0.217413 Batch F1: 0.0
Epoch:  414       10 Batch loss: 0.264259 Batch F1: 0.0
Epoch:  414       11 Batch loss: 0.238987 Batch F1: 0.0
Epoch:  414       12 Batch loss: 0.190017 Batch F1: 0.0
Train Avg Loss  414: 0.226463

Train Avg F1  414: 0.0

Val Avg Loss  414: 0.218383

Val Avg F1  414:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 415
--------------------------------------------------------------
Epoch:  415        1 Batch loss: 0.225000 Batch F1: 0.0
Epoch:  415        2 Batch loss: 0.238035 Batch F1: 0.0
Epoch:  415        3 Batch loss: 0.226433 Batch F1: 0.0
Epoch:  415        4 Batch loss: 0.209933 Batch F1: 0.0
Epoch:  415        5 Batch loss: 0.214574 Batch F1: 0.0
Epoch:  415        6 Batch loss: 0.229705 Batch F1: 0.0
Epoch:  415        7 Batch loss: 0.224432 Batch F1: 0.0
Epoch:  415        8 Batch loss: 0.207898 Batch F1: 0.0
Epoch:  415        9 Batch loss: 0.227054 Batch F1: 0.0
Epoch:  415       10 Batch loss: 0.216672 Batch F1: 0.0
Epoch:  415       11 Batch loss: 0.276211 Batch F1: 0.0
Epoch:  415       12 Batch loss: 0.219338 Batch F1: 0.0
Train Avg Loss  415: 0.226274

Train Avg F1  415: 0.0

Val Avg Loss  415: 0.216861

Val Avg F1  415:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 416
--------------------------------------------------------------
Epoch:  416        1 Batch loss: 0.238247 Batch F1: 0.0
Epoch:  416        2 Batch loss: 0.227026 Batch F1: 0.0
Epoch:  416        3 Batch loss: 0.215376 Batch F1: 0.0
Epoch:  416        4 Batch loss: 0.224459 Batch F1: 0.0
Epoch:  416        5 Batch loss: 0.225916 Batch F1: 0.0
Epoch:  416        6 Batch loss: 0.225533 Batch F1: 0.0
Epoch:  416        7 Batch loss: 0.263530 Batch F1: 0.0
Epoch:  416        8 Batch loss: 0.237146 Batch F1: 0.08695652173913043
Epoch:  416        9 Batch loss: 0.244687 Batch F1: 0.3529411764705882
Epoch:  416       10 Batch loss: 0.224330 Batch F1: 0.26086956521739124
Epoch:  416       11 Batch loss: 0.185448 Batch F1: 0.0
Epoch:  416       12 Batch loss: 0.206584 Batch F1: 0.0
Train Avg Loss  416: 0.226523

Train Avg F1  416: 0.058397271952259154

Val Avg Loss  416: 0.217638

Val Avg F1  416:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 417
--------------------------------------------------------------
Epoch:  417        1 Batch loss: 0.189260 Batch F1: 0.0
Epoch:  417        2 Batch loss: 0.237872 Batch F1: 0.0
Epoch:  417        3 Batch loss: 0.241108 Batch F1: 0.0
Epoch:  417        4 Batch loss: 0.216057 Batch F1: 0.0
Epoch:  417        5 Batch loss: 0.234366 Batch F1: 0.0
Epoch:  417        6 Batch loss: 0.223165 Batch F1: 0.0
Epoch:  417        7 Batch loss: 0.259127 Batch F1: 0.0
Epoch:  417        8 Batch loss: 0.243668 Batch F1: 0.0
Epoch:  417        9 Batch loss: 0.237872 Batch F1: 0.0
Epoch:  417       10 Batch loss: 0.242040 Batch F1: 0.0
Epoch:  417       11 Batch loss: 0.231363 Batch F1: 0.0
Epoch:  417       12 Batch loss: 0.224471 Batch F1: 0.0
Train Avg Loss  417: 0.231697

Train Avg F1  417: 0.0

Val Avg Loss  417: 0.221530

Val Avg F1  417:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 418
--------------------------------------------------------------
Epoch:  418        1 Batch loss: 0.210461 Batch F1: 0.0
Epoch:  418        2 Batch loss: 0.201448 Batch F1: 0.0
Epoch:  418        3 Batch loss: 0.272569 Batch F1: 0.0
Epoch:  418        4 Batch loss: 0.267285 Batch F1: 0.0
Epoch:  418        5 Batch loss: 0.228315 Batch F1: 0.0
Epoch:  418        6 Batch loss: 0.192494 Batch F1: 0.0
Epoch:  418        7 Batch loss: 0.216759 Batch F1: 0.0
Epoch:  418        8 Batch loss: 0.232141 Batch F1: 0.0
Epoch:  418        9 Batch loss: 0.259939 Batch F1: 0.0
Epoch:  418       10 Batch loss: 0.241485 Batch F1: 0.0
Epoch:  418       11 Batch loss: 0.243378 Batch F1: 0.0
Epoch:  418       12 Batch loss: 0.216958 Batch F1: 0.0
Train Avg Loss  418: 0.231936

Train Avg F1  418: 0.0

Val Avg Loss  418: 0.223560

Val Avg F1  418:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 419
--------------------------------------------------------------
Epoch:  419        1 Batch loss: 0.240668 Batch F1: 0.0
Epoch:  419        2 Batch loss: 0.231908 Batch F1: 0.0
Epoch:  419        3 Batch loss: 0.212515 Batch F1: 0.0
Epoch:  419        4 Batch loss: 0.225550 Batch F1: 0.0
Epoch:  419        5 Batch loss: 0.240743 Batch F1: 0.0
Epoch:  419        6 Batch loss: 0.231956 Batch F1: 0.0
Epoch:  419        7 Batch loss: 0.258008 Batch F1: 0.0
Epoch:  419        8 Batch loss: 0.283797 Batch F1: 0.0
Epoch:  419        9 Batch loss: 0.213703 Batch F1: 0.0
Epoch:  419       10 Batch loss: 0.201586 Batch F1: 0.0
Epoch:  419       11 Batch loss: 0.218104 Batch F1: 0.0
Epoch:  419       12 Batch loss: 0.226858 Batch F1: 0.0
Train Avg Loss  419: 0.232116

Train Avg F1  419: 0.0

Val Avg Loss  419: 0.217959

Val Avg F1  419:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 420
--------------------------------------------------------------
Epoch:  420        1 Batch loss: 0.266535 Batch F1: 0.0
Epoch:  420        2 Batch loss: 0.212714 Batch F1: 0.0
Epoch:  420        3 Batch loss: 0.241306 Batch F1: 0.0
Epoch:  420        4 Batch loss: 0.213424 Batch F1: 0.0
Epoch:  420        5 Batch loss: 0.261585 Batch F1: 0.0
Epoch:  420        6 Batch loss: 0.263315 Batch F1: 0.0
Epoch:  420        7 Batch loss: 0.205916 Batch F1: 0.0
Epoch:  420        8 Batch loss: 0.216643 Batch F1: 0.0
Epoch:  420        9 Batch loss: 0.233113 Batch F1: 0.0
Epoch:  420       10 Batch loss: 0.235132 Batch F1: 0.0
Epoch:  420       11 Batch loss: 0.212968 Batch F1: 0.0
Epoch:  420       12 Batch loss: 0.223553 Batch F1: 0.0
Train Avg Loss  420: 0.232184

Train Avg F1  420: 0.0

Val Avg Loss  420: 0.222317

Val Avg F1  420:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 421
--------------------------------------------------------------
Epoch:  421        1 Batch loss: 0.225954 Batch F1: 0.0
Epoch:  421        2 Batch loss: 0.197066 Batch F1: 0.0
Epoch:  421        3 Batch loss: 0.209329 Batch F1: 0.0
Epoch:  421        4 Batch loss: 0.217382 Batch F1: 0.0
Epoch:  421        5 Batch loss: 0.231294 Batch F1: 0.0
Epoch:  421        6 Batch loss: 0.243940 Batch F1: 0.0
Epoch:  421        7 Batch loss: 0.206775 Batch F1: 0.0
Epoch:  421        8 Batch loss: 0.250653 Batch F1: 0.0
Epoch:  421        9 Batch loss: 0.244485 Batch F1: 0.0
Epoch:  421       10 Batch loss: 0.258775 Batch F1: 0.0
Epoch:  421       11 Batch loss: 0.224566 Batch F1: 0.0
Epoch:  421       12 Batch loss: 0.238176 Batch F1: 0.0
Train Avg Loss  421: 0.229033

Train Avg F1  421: 0.0

Val Avg Loss  421: 0.219215

Val Avg F1  421:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 422
--------------------------------------------------------------
Epoch:  422        1 Batch loss: 0.231180 Batch F1: 0.0
Epoch:  422        2 Batch loss: 0.225384 Batch F1: 0.0
Epoch:  422        3 Batch loss: 0.199561 Batch F1: 0.0
Epoch:  422        4 Batch loss: 0.264094 Batch F1: 0.0
Epoch:  422        5 Batch loss: 0.231393 Batch F1: 0.0
Epoch:  422        6 Batch loss: 0.223747 Batch F1: 0.0
Epoch:  422        7 Batch loss: 0.256812 Batch F1: 0.0
Epoch:  422        8 Batch loss: 0.199682 Batch F1: 0.0
Epoch:  422        9 Batch loss: 0.205726 Batch F1: 0.0
Epoch:  422       10 Batch loss: 0.218243 Batch F1: 0.0
Epoch:  422       11 Batch loss: 0.247272 Batch F1: 0.0
Epoch:  422       12 Batch loss: 0.227991 Batch F1: 0.0
Train Avg Loss  422: 0.227590

Train Avg F1  422: 0.0

Val Avg Loss  422: 0.218268

Val Avg F1  422:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 423
--------------------------------------------------------------
Epoch:  423        1 Batch loss: 0.246100 Batch F1: 0.0
Epoch:  423        2 Batch loss: 0.242257 Batch F1: 0.0
Epoch:  423        3 Batch loss: 0.235200 Batch F1: 0.0
Epoch:  423        4 Batch loss: 0.220239 Batch F1: 0.0
Epoch:  423        5 Batch loss: 0.242380 Batch F1: 0.23999999999999996
Epoch:  423        6 Batch loss: 0.245328 Batch F1: 0.33333333333333326
Epoch:  423        7 Batch loss: 0.218812 Batch F1: 0.2727272727272727
Epoch:  423        8 Batch loss: 0.212184 Batch F1: 0.0
Epoch:  423        9 Batch loss: 0.203964 Batch F1: 0.0
Epoch:  423       10 Batch loss: 0.223618 Batch F1: 0.0
Epoch:  423       11 Batch loss: 0.227056 Batch F1: 0.0
Epoch:  423       12 Batch loss: 0.216353 Batch F1: 0.0
Train Avg Loss  423: 0.227791

Train Avg F1  423: 0.0705050505050505

Val Avg Loss  423: 0.216895

Val Avg F1  423:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 424
--------------------------------------------------------------
Epoch:  424        1 Batch loss: 0.250833 Batch F1: 0.0
Epoch:  424        2 Batch loss: 0.191987 Batch F1: 0.0
Epoch:  424        3 Batch loss: 0.202441 Batch F1: 0.0
Epoch:  424        4 Batch loss: 0.218896 Batch F1: 0.0
Epoch:  424        5 Batch loss: 0.272384 Batch F1: 0.0
Epoch:  424        6 Batch loss: 0.221573 Batch F1: 0.0
Epoch:  424        7 Batch loss: 0.251733 Batch F1: 0.0
Epoch:  424        8 Batch loss: 0.212864 Batch F1: 0.0
Epoch:  424        9 Batch loss: 0.208158 Batch F1: 0.0
Epoch:  424       10 Batch loss: 0.198884 Batch F1: 0.0
Epoch:  424       11 Batch loss: 0.267110 Batch F1: 0.0
Epoch:  424       12 Batch loss: 0.235771 Batch F1: 0.0
Train Avg Loss  424: 0.227720

Train Avg F1  424: 0.0

Val Avg Loss  424: 0.218074

Val Avg F1  424:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 425
--------------------------------------------------------------
Epoch:  425        1 Batch loss: 0.233987 Batch F1: 0.0
Epoch:  425        2 Batch loss: 0.226800 Batch F1: 0.0
Epoch:  425        3 Batch loss: 0.229322 Batch F1: 0.0
Epoch:  425        4 Batch loss: 0.231100 Batch F1: 0.27586206896551724
Epoch:  425        5 Batch loss: 0.245377 Batch F1: 0.2
Epoch:  425        6 Batch loss: 0.234171 Batch F1: 0.15384615384615383
Epoch:  425        7 Batch loss: 0.197558 Batch F1: 0.0
Epoch:  425        8 Batch loss: 0.227427 Batch F1: 0.0
Epoch:  425        9 Batch loss: 0.235137 Batch F1: 0.0
Epoch:  425       10 Batch loss: 0.204198 Batch F1: 0.0
Epoch:  425       11 Batch loss: 0.247648 Batch F1: 0.0
Epoch:  425       12 Batch loss: 0.227245 Batch F1: 0.0
Train Avg Loss  425: 0.228331

Train Avg F1  425: 0.05247568523430592

Val Avg Loss  425: 0.216753

Val Avg F1  425:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 426
--------------------------------------------------------------
Epoch:  426        1 Batch loss: 0.210898 Batch F1: 0.0
Epoch:  426        2 Batch loss: 0.225129 Batch F1: 0.0
Epoch:  426        3 Batch loss: 0.241597 Batch F1: 0.0
Epoch:  426        4 Batch loss: 0.193180 Batch F1: 0.0
Epoch:  426        5 Batch loss: 0.214421 Batch F1: 0.0
Epoch:  426        6 Batch loss: 0.255005 Batch F1: 0.0
Epoch:  426        7 Batch loss: 0.235190 Batch F1: 0.0
Epoch:  426        8 Batch loss: 0.244989 Batch F1: 0.0
Epoch:  426        9 Batch loss: 0.227933 Batch F1: 0.0
Epoch:  426       10 Batch loss: 0.229225 Batch F1: 0.3703703703703704
Epoch:  426       11 Batch loss: 0.247182 Batch F1: 0.0
Epoch:  426       12 Batch loss: 0.192653 Batch F1: 0.0
Train Avg Loss  426: 0.226450

Train Avg F1  426: 0.0308641975308642

Val Avg Loss  426: 0.218975

Val Avg F1  426:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 427
--------------------------------------------------------------
Epoch:  427        1 Batch loss: 0.249280 Batch F1: 0.0
Epoch:  427        2 Batch loss: 0.218945 Batch F1: 0.0
Epoch:  427        3 Batch loss: 0.231557 Batch F1: 0.0
Epoch:  427        4 Batch loss: 0.190125 Batch F1: 0.0
Epoch:  427        5 Batch loss: 0.232278 Batch F1: 0.0
Epoch:  427        6 Batch loss: 0.247530 Batch F1: 0.0
Epoch:  427        7 Batch loss: 0.225780 Batch F1: 0.0
Epoch:  427        8 Batch loss: 0.219385 Batch F1: 0.0
Epoch:  427        9 Batch loss: 0.232414 Batch F1: 0.0
Epoch:  427       10 Batch loss: 0.215437 Batch F1: 0.0
Epoch:  427       11 Batch loss: 0.227018 Batch F1: 0.0
Epoch:  427       12 Batch loss: 0.233589 Batch F1: 0.0
Train Avg Loss  427: 0.226945

Train Avg F1  427: 0.0

Val Avg Loss  427: 0.218572

Val Avg F1  427:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 428
--------------------------------------------------------------
Epoch:  428        1 Batch loss: 0.229217 Batch F1: 0.0
Epoch:  428        2 Batch loss: 0.211623 Batch F1: 0.0
Epoch:  428        3 Batch loss: 0.231395 Batch F1: 0.0
Epoch:  428        4 Batch loss: 0.242207 Batch F1: 0.0
Epoch:  428        5 Batch loss: 0.241926 Batch F1: 0.0
Epoch:  428        6 Batch loss: 0.202950 Batch F1: 0.0
Epoch:  428        7 Batch loss: 0.226543 Batch F1: 0.0
Epoch:  428        8 Batch loss: 0.242806 Batch F1: 0.0
Epoch:  428        9 Batch loss: 0.191474 Batch F1: 0.0
Epoch:  428       10 Batch loss: 0.201790 Batch F1: 0.0
Epoch:  428       11 Batch loss: 0.244564 Batch F1: 0.0
Epoch:  428       12 Batch loss: 0.253663 Batch F1: 0.0
Train Avg Loss  428: 0.226680

Train Avg F1  428: 0.0

Val Avg Loss  428: 0.217221

Val Avg F1  428:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 429
--------------------------------------------------------------
Epoch:  429        1 Batch loss: 0.219393 Batch F1: 0.0
Epoch:  429        2 Batch loss: 0.256879 Batch F1: 0.0
Epoch:  429        3 Batch loss: 0.203049 Batch F1: 0.0
Epoch:  429        4 Batch loss: 0.199190 Batch F1: 0.0
Epoch:  429        5 Batch loss: 0.232602 Batch F1: 0.0
Epoch:  429        6 Batch loss: 0.222443 Batch F1: 0.0
Epoch:  429        7 Batch loss: 0.218157 Batch F1: 0.0
Epoch:  429        8 Batch loss: 0.236263 Batch F1: 0.0
Epoch:  429        9 Batch loss: 0.234850 Batch F1: 0.0
Epoch:  429       10 Batch loss: 0.249656 Batch F1: 0.0
Epoch:  429       11 Batch loss: 0.212148 Batch F1: 0.0
Epoch:  429       12 Batch loss: 0.225970 Batch F1: 0.0
Train Avg Loss  429: 0.225883

Train Avg F1  429: 0.0

Val Avg Loss  429: 0.217365

Val Avg F1  429:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 430
--------------------------------------------------------------
Epoch:  430        1 Batch loss: 0.222797 Batch F1: 0.0
Epoch:  430        2 Batch loss: 0.236356 Batch F1: 0.0
Epoch:  430        3 Batch loss: 0.207526 Batch F1: 0.0
Epoch:  430        4 Batch loss: 0.221520 Batch F1: 0.0
Epoch:  430        5 Batch loss: 0.240791 Batch F1: 0.0
Epoch:  430        6 Batch loss: 0.230693 Batch F1: 0.0
Epoch:  430        7 Batch loss: 0.246455 Batch F1: 0.0
Epoch:  430        8 Batch loss: 0.221310 Batch F1: 0.0
Epoch:  430        9 Batch loss: 0.210809 Batch F1: 0.0
Epoch:  430       10 Batch loss: 0.216121 Batch F1: 0.0
Epoch:  430       11 Batch loss: 0.224634 Batch F1: 0.0
Epoch:  430       12 Batch loss: 0.228107 Batch F1: 0.0
Train Avg Loss  430: 0.225593

Train Avg F1  430: 0.0

Val Avg Loss  430: 0.217931

Val Avg F1  430:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 431
--------------------------------------------------------------
Epoch:  431        1 Batch loss: 0.237467 Batch F1: 0.0
Epoch:  431        2 Batch loss: 0.220118 Batch F1: 0.0
Epoch:  431        3 Batch loss: 0.262767 Batch F1: 0.0
Epoch:  431        4 Batch loss: 0.264373 Batch F1: 0.0
Epoch:  431        5 Batch loss: 0.209832 Batch F1: 0.0
Epoch:  431        6 Batch loss: 0.224664 Batch F1: 0.0
Epoch:  431        7 Batch loss: 0.215904 Batch F1: 0.0
Epoch:  431        8 Batch loss: 0.201462 Batch F1: 0.0
Epoch:  431        9 Batch loss: 0.214791 Batch F1: 0.0
Epoch:  431       10 Batch loss: 0.231004 Batch F1: 0.0
Epoch:  431       11 Batch loss: 0.220957 Batch F1: 0.0
Epoch:  431       12 Batch loss: 0.210480 Batch F1: 0.0
Train Avg Loss  431: 0.226152

Train Avg F1  431: 0.0

Val Avg Loss  431: 0.217272

Val Avg F1  431:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 432
--------------------------------------------------------------
Epoch:  432        1 Batch loss: 0.196132 Batch F1: 0.0
Epoch:  432        2 Batch loss: 0.210811 Batch F1: 0.0
Epoch:  432        3 Batch loss: 0.226959 Batch F1: 0.0
Epoch:  432        4 Batch loss: 0.233832 Batch F1: 0.0
Epoch:  432        5 Batch loss: 0.192190 Batch F1: 0.0
Epoch:  432        6 Batch loss: 0.265131 Batch F1: 0.0
Epoch:  432        7 Batch loss: 0.209709 Batch F1: 0.0
Epoch:  432        8 Batch loss: 0.251059 Batch F1: 0.0
Epoch:  432        9 Batch loss: 0.224061 Batch F1: 0.0
Epoch:  432       10 Batch loss: 0.226052 Batch F1: 0.0
Epoch:  432       11 Batch loss: 0.231965 Batch F1: 0.0
Epoch:  432       12 Batch loss: 0.247169 Batch F1: 0.0
Train Avg Loss  432: 0.226256

Train Avg F1  432: 0.0

Val Avg Loss  432: 0.218918

Val Avg F1  432:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 433
--------------------------------------------------------------
Epoch:  433        1 Batch loss: 0.244956 Batch F1: 0.0
Epoch:  433        2 Batch loss: 0.205409 Batch F1: 0.0
Epoch:  433        3 Batch loss: 0.218539 Batch F1: 0.0
Epoch:  433        4 Batch loss: 0.215173 Batch F1: 0.0
Epoch:  433        5 Batch loss: 0.240279 Batch F1: 0.0
Epoch:  433        6 Batch loss: 0.223908 Batch F1: 0.0
Epoch:  433        7 Batch loss: 0.268739 Batch F1: 0.0
Epoch:  433        8 Batch loss: 0.198943 Batch F1: 0.0
Epoch:  433        9 Batch loss: 0.224699 Batch F1: 0.0
Epoch:  433       10 Batch loss: 0.229207 Batch F1: 0.0
Epoch:  433       11 Batch loss: 0.227707 Batch F1: 0.0
Epoch:  433       12 Batch loss: 0.210903 Batch F1: 0.0
Train Avg Loss  433: 0.225705

Train Avg F1  433: 0.0

Val Avg Loss  433: 0.216250

Val Avg F1  433:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 434
--------------------------------------------------------------
Epoch:  434        1 Batch loss: 0.251140 Batch F1: 0.0
Epoch:  434        2 Batch loss: 0.225147 Batch F1: 0.0
Epoch:  434        3 Batch loss: 0.183163 Batch F1: 0.0
Epoch:  434        4 Batch loss: 0.221075 Batch F1: 0.0
Epoch:  434        5 Batch loss: 0.212905 Batch F1: 0.0
Epoch:  434        6 Batch loss: 0.256285 Batch F1: 0.0
Epoch:  434        7 Batch loss: 0.259025 Batch F1: 0.0
Epoch:  434        8 Batch loss: 0.231463 Batch F1: 0.0
Epoch:  434        9 Batch loss: 0.229513 Batch F1: 0.0
Epoch:  434       10 Batch loss: 0.182709 Batch F1: 0.0
Epoch:  434       11 Batch loss: 0.230586 Batch F1: 0.0
Epoch:  434       12 Batch loss: 0.225314 Batch F1: 0.0
Train Avg Loss  434: 0.225694

Train Avg F1  434: 0.0

Val Avg Loss  434: 0.216983

Val Avg F1  434:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 435
--------------------------------------------------------------
Epoch:  435        1 Batch loss: 0.250559 Batch F1: 0.0
Epoch:  435        2 Batch loss: 0.235925 Batch F1: 0.0
Epoch:  435        3 Batch loss: 0.229277 Batch F1: 0.0
Epoch:  435        4 Batch loss: 0.234293 Batch F1: 0.0
Epoch:  435        5 Batch loss: 0.247632 Batch F1: 0.0
Epoch:  435        6 Batch loss: 0.195619 Batch F1: 0.0
Epoch:  435        7 Batch loss: 0.217846 Batch F1: 0.0
Epoch:  435        8 Batch loss: 0.200508 Batch F1: 0.0
Epoch:  435        9 Batch loss: 0.251675 Batch F1: 0.0
Epoch:  435       10 Batch loss: 0.218658 Batch F1: 0.0
Epoch:  435       11 Batch loss: 0.211003 Batch F1: 0.0
Epoch:  435       12 Batch loss: 0.212411 Batch F1: 0.0
Train Avg Loss  435: 0.225450

Train Avg F1  435: 0.0

Val Avg Loss  435: 0.217362

Val Avg F1  435:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 436
--------------------------------------------------------------
Epoch:  436        1 Batch loss: 0.235118 Batch F1: 0.0
Epoch:  436        2 Batch loss: 0.227867 Batch F1: 0.0
Epoch:  436        3 Batch loss: 0.201708 Batch F1: 0.0
Epoch:  436        4 Batch loss: 0.226453 Batch F1: 0.0
Epoch:  436        5 Batch loss: 0.182484 Batch F1: 0.0
Epoch:  436        6 Batch loss: 0.261833 Batch F1: 0.0
Epoch:  436        7 Batch loss: 0.248552 Batch F1: 0.0
Epoch:  436        8 Batch loss: 0.232610 Batch F1: 0.0
Epoch:  436        9 Batch loss: 0.222016 Batch F1: 0.0
Epoch:  436       10 Batch loss: 0.223082 Batch F1: 0.0
Epoch:  436       11 Batch loss: 0.230450 Batch F1: 0.0
Epoch:  436       12 Batch loss: 0.210553 Batch F1: 0.0
Train Avg Loss  436: 0.225227

Train Avg F1  436: 0.0

Val Avg Loss  436: 0.217459

Val Avg F1  436:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 437
--------------------------------------------------------------
Epoch:  437        1 Batch loss: 0.250206 Batch F1: 0.0
Epoch:  437        2 Batch loss: 0.214707 Batch F1: 0.0
Epoch:  437        3 Batch loss: 0.192292 Batch F1: 0.0
Epoch:  437        4 Batch loss: 0.244885 Batch F1: 0.0
Epoch:  437        5 Batch loss: 0.272666 Batch F1: 0.0
Epoch:  437        6 Batch loss: 0.202161 Batch F1: 0.0
Epoch:  437        7 Batch loss: 0.196134 Batch F1: 0.0
Epoch:  437        8 Batch loss: 0.225607 Batch F1: 0.0
Epoch:  437        9 Batch loss: 0.216819 Batch F1: 0.0
Epoch:  437       10 Batch loss: 0.256555 Batch F1: 0.0
Epoch:  437       11 Batch loss: 0.205663 Batch F1: 0.0
Epoch:  437       12 Batch loss: 0.231808 Batch F1: 0.0
Train Avg Loss  437: 0.225792

Train Avg F1  437: 0.0

Val Avg Loss  437: 0.217096

Val Avg F1  437:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 438
--------------------------------------------------------------
Epoch:  438        1 Batch loss: 0.236805 Batch F1: 0.0
Epoch:  438        2 Batch loss: 0.229363 Batch F1: 0.0
Epoch:  438        3 Batch loss: 0.256726 Batch F1: 0.0
Epoch:  438        4 Batch loss: 0.217512 Batch F1: 0.0
Epoch:  438        5 Batch loss: 0.227752 Batch F1: 0.0
Epoch:  438        6 Batch loss: 0.198548 Batch F1: 0.0
Epoch:  438        7 Batch loss: 0.218136 Batch F1: 0.0
Epoch:  438        8 Batch loss: 0.222660 Batch F1: 0.0
Epoch:  438        9 Batch loss: 0.236192 Batch F1: 0.0
Epoch:  438       10 Batch loss: 0.246407 Batch F1: 0.0
Epoch:  438       11 Batch loss: 0.214796 Batch F1: 0.0
Epoch:  438       12 Batch loss: 0.205346 Batch F1: 0.0
Train Avg Loss  438: 0.225854

Train Avg F1  438: 0.0

Val Avg Loss  438: 0.217743

Val Avg F1  438:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 439
--------------------------------------------------------------
Epoch:  439        1 Batch loss: 0.200553 Batch F1: 0.0
Epoch:  439        2 Batch loss: 0.240828 Batch F1: 0.0
Epoch:  439        3 Batch loss: 0.201011 Batch F1: 0.0
Epoch:  439        4 Batch loss: 0.265002 Batch F1: 0.0
Epoch:  439        5 Batch loss: 0.238142 Batch F1: 0.0
Epoch:  439        6 Batch loss: 0.213544 Batch F1: 0.0
Epoch:  439        7 Batch loss: 0.241211 Batch F1: 0.0
Epoch:  439        8 Batch loss: 0.191781 Batch F1: 0.0
Epoch:  439        9 Batch loss: 0.247636 Batch F1: 0.0
Epoch:  439       10 Batch loss: 0.241137 Batch F1: 0.0
Epoch:  439       11 Batch loss: 0.190757 Batch F1: 0.0
Epoch:  439       12 Batch loss: 0.240458 Batch F1: 0.0
Train Avg Loss  439: 0.226005

Train Avg F1  439: 0.0

Val Avg Loss  439: 0.217115

Val Avg F1  439:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 440
--------------------------------------------------------------
Epoch:  440        1 Batch loss: 0.245339 Batch F1: 0.0
Epoch:  440        2 Batch loss: 0.211790 Batch F1: 0.0
Epoch:  440        3 Batch loss: 0.238937 Batch F1: 0.0
Epoch:  440        4 Batch loss: 0.210823 Batch F1: 0.0
Epoch:  440        5 Batch loss: 0.225868 Batch F1: 0.0
Epoch:  440        6 Batch loss: 0.236976 Batch F1: 0.0
Epoch:  440        7 Batch loss: 0.214226 Batch F1: 0.0
Epoch:  440        8 Batch loss: 0.218741 Batch F1: 0.0
Epoch:  440        9 Batch loss: 0.215749 Batch F1: 0.0
Epoch:  440       10 Batch loss: 0.237948 Batch F1: 0.0
Epoch:  440       11 Batch loss: 0.218742 Batch F1: 0.0
Epoch:  440       12 Batch loss: 0.255138 Batch F1: 0.0
Train Avg Loss  440: 0.227523

Train Avg F1  440: 0.0

Val Avg Loss  440: 0.218276

Val Avg F1  440:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 441
--------------------------------------------------------------
Epoch:  441        1 Batch loss: 0.202434 Batch F1: 0.0
Epoch:  441        2 Batch loss: 0.232339 Batch F1: 0.0
Epoch:  441        3 Batch loss: 0.217448 Batch F1: 0.0
Epoch:  441        4 Batch loss: 0.257591 Batch F1: 0.0
Epoch:  441        5 Batch loss: 0.214890 Batch F1: 0.0
Epoch:  441        6 Batch loss: 0.227942 Batch F1: 0.0
Epoch:  441        7 Batch loss: 0.266499 Batch F1: 0.0
Epoch:  441        8 Batch loss: 0.208384 Batch F1: 0.0
Epoch:  441        9 Batch loss: 0.215708 Batch F1: 0.0
Epoch:  441       10 Batch loss: 0.200850 Batch F1: 0.0
Epoch:  441       11 Batch loss: 0.254459 Batch F1: 0.0
Epoch:  441       12 Batch loss: 0.223568 Batch F1: 0.0
Train Avg Loss  441: 0.226843

Train Avg F1  441: 0.0

Val Avg Loss  441: 0.217491

Val Avg F1  441:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 442
--------------------------------------------------------------
Epoch:  442        1 Batch loss: 0.227590 Batch F1: 0.0
Epoch:  442        2 Batch loss: 0.259308 Batch F1: 0.0
Epoch:  442        3 Batch loss: 0.205345 Batch F1: 0.0
Epoch:  442        4 Batch loss: 0.226212 Batch F1: 0.0
Epoch:  442        5 Batch loss: 0.231065 Batch F1: 0.0
Epoch:  442        6 Batch loss: 0.248047 Batch F1: 0.0
Epoch:  442        7 Batch loss: 0.245528 Batch F1: 0.0
Epoch:  442        8 Batch loss: 0.228175 Batch F1: 0.0
Epoch:  442        9 Batch loss: 0.237276 Batch F1: 0.0
Epoch:  442       10 Batch loss: 0.228696 Batch F1: 0.0
Epoch:  442       11 Batch loss: 0.212031 Batch F1: 0.0
Epoch:  442       12 Batch loss: 0.181075 Batch F1: 0.0
Train Avg Loss  442: 0.227529

Train Avg F1  442: 0.0

Val Avg Loss  442: 0.218624

Val Avg F1  442:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 443
--------------------------------------------------------------
Epoch:  443        1 Batch loss: 0.230403 Batch F1: 0.0
Epoch:  443        2 Batch loss: 0.253160 Batch F1: 0.0
Epoch:  443        3 Batch loss: 0.270641 Batch F1: 0.0
Epoch:  443        4 Batch loss: 0.226924 Batch F1: 0.0
Epoch:  443        5 Batch loss: 0.242940 Batch F1: 0.0
Epoch:  443        6 Batch loss: 0.215173 Batch F1: 0.0
Epoch:  443        7 Batch loss: 0.236089 Batch F1: 0.0
Epoch:  443        8 Batch loss: 0.231619 Batch F1: 0.0
Epoch:  443        9 Batch loss: 0.235038 Batch F1: 0.0
Epoch:  443       10 Batch loss: 0.241074 Batch F1: 0.0
Epoch:  443       11 Batch loss: 0.176166 Batch F1: 0.0
Epoch:  443       12 Batch loss: 0.228079 Batch F1: 0.0
Train Avg Loss  443: 0.232275

Train Avg F1  443: 0.0

Val Avg Loss  443: 0.218955

Val Avg F1  443:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 444
--------------------------------------------------------------
Epoch:  444        1 Batch loss: 0.207436 Batch F1: 0.0
Epoch:  444        2 Batch loss: 0.231483 Batch F1: 0.0
Epoch:  444        3 Batch loss: 0.220500 Batch F1: 0.0
Epoch:  444        4 Batch loss: 0.237927 Batch F1: 0.0
Epoch:  444        5 Batch loss: 0.244888 Batch F1: 0.0
Epoch:  444        6 Batch loss: 0.193421 Batch F1: 0.0
Epoch:  444        7 Batch loss: 0.241813 Batch F1: 0.0
Epoch:  444        8 Batch loss: 0.243503 Batch F1: 0.0
Epoch:  444        9 Batch loss: 0.262278 Batch F1: 0.0
Epoch:  444       10 Batch loss: 0.239576 Batch F1: 0.0
Epoch:  444       11 Batch loss: 0.221339 Batch F1: 0.0
Epoch:  444       12 Batch loss: 0.218335 Batch F1: 0.0
Train Avg Loss  444: 0.230208

Train Avg F1  444: 0.0

Val Avg Loss  444: 0.223345

Val Avg F1  444:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 445
--------------------------------------------------------------
Epoch:  445        1 Batch loss: 0.225212 Batch F1: 0.0
Epoch:  445        2 Batch loss: 0.203702 Batch F1: 0.0
Epoch:  445        3 Batch loss: 0.233414 Batch F1: 0.0
Epoch:  445        4 Batch loss: 0.231094 Batch F1: 0.0
Epoch:  445        5 Batch loss: 0.231233 Batch F1: 0.0
Epoch:  445        6 Batch loss: 0.229055 Batch F1: 0.0
Epoch:  445        7 Batch loss: 0.249833 Batch F1: 0.0
Epoch:  445        8 Batch loss: 0.237528 Batch F1: 0.0
Epoch:  445        9 Batch loss: 0.233917 Batch F1: 0.0
Epoch:  445       10 Batch loss: 0.198992 Batch F1: 0.0
Epoch:  445       11 Batch loss: 0.234713 Batch F1: 0.0
Epoch:  445       12 Batch loss: 0.228002 Batch F1: 0.0
Train Avg Loss  445: 0.228058

Train Avg F1  445: 0.0

Val Avg Loss  445: 0.218868

Val Avg F1  445:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 446
--------------------------------------------------------------
Epoch:  446        1 Batch loss: 0.264021 Batch F1: 0.0
Epoch:  446        2 Batch loss: 0.226962 Batch F1: 0.0
Epoch:  446        3 Batch loss: 0.209490 Batch F1: 0.0
Epoch:  446        4 Batch loss: 0.224805 Batch F1: 0.0
Epoch:  446        5 Batch loss: 0.236129 Batch F1: 0.0
Epoch:  446        6 Batch loss: 0.216531 Batch F1: 0.0
Epoch:  446        7 Batch loss: 0.209221 Batch F1: 0.0
Epoch:  446        8 Batch loss: 0.215827 Batch F1: 0.0
Epoch:  446        9 Batch loss: 0.216004 Batch F1: 0.0
Epoch:  446       10 Batch loss: 0.209198 Batch F1: 0.0
Epoch:  446       11 Batch loss: 0.253173 Batch F1: 0.0
Epoch:  446       12 Batch loss: 0.256567 Batch F1: 0.0
Train Avg Loss  446: 0.228161

Train Avg F1  446: 0.0

Val Avg Loss  446: 0.218058

Val Avg F1  446:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 447
--------------------------------------------------------------
Epoch:  447        1 Batch loss: 0.229045 Batch F1: 0.0
Epoch:  447        2 Batch loss: 0.237683 Batch F1: 0.0
Epoch:  447        3 Batch loss: 0.215833 Batch F1: 0.18181818181818182
Epoch:  447        4 Batch loss: 0.230025 Batch F1: 0.23076923076923078
Epoch:  447        5 Batch loss: 0.261697 Batch F1: 0.0
Epoch:  447        6 Batch loss: 0.225816 Batch F1: 0.0
Epoch:  447        7 Batch loss: 0.244269 Batch F1: 0.0
Epoch:  447        8 Batch loss: 0.213075 Batch F1: 0.0
Epoch:  447        9 Batch loss: 0.241156 Batch F1: 0.0
Epoch:  447       10 Batch loss: 0.203564 Batch F1: 0.0
Epoch:  447       11 Batch loss: 0.195338 Batch F1: 0.0
Epoch:  447       12 Batch loss: 0.228647 Batch F1: 0.0
Train Avg Loss  447: 0.227179

Train Avg F1  447: 0.034382284382284384

Val Avg Loss  447: 0.217302

Val Avg F1  447:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 448
--------------------------------------------------------------
Epoch:  448        1 Batch loss: 0.242105 Batch F1: 0.0
Epoch:  448        2 Batch loss: 0.215662 Batch F1: 0.0
Epoch:  448        3 Batch loss: 0.191407 Batch F1: 0.0
Epoch:  448        4 Batch loss: 0.221769 Batch F1: 0.0
Epoch:  448        5 Batch loss: 0.218610 Batch F1: 0.0
Epoch:  448        6 Batch loss: 0.250874 Batch F1: 0.0
Epoch:  448        7 Batch loss: 0.215114 Batch F1: 0.0
Epoch:  448        8 Batch loss: 0.243901 Batch F1: 0.0
Epoch:  448        9 Batch loss: 0.219549 Batch F1: 0.0
Epoch:  448       10 Batch loss: 0.258223 Batch F1: 0.0
Epoch:  448       11 Batch loss: 0.205042 Batch F1: 0.0
Epoch:  448       12 Batch loss: 0.251886 Batch F1: 0.0
Train Avg Loss  448: 0.227845

Train Avg F1  448: 0.0

Val Avg Loss  448: 0.218149

Val Avg F1  448:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 449
--------------------------------------------------------------
Epoch:  449        1 Batch loss: 0.237468 Batch F1: 0.0
Epoch:  449        2 Batch loss: 0.256638 Batch F1: 0.0
Epoch:  449        3 Batch loss: 0.187282 Batch F1: 0.0
Epoch:  449        4 Batch loss: 0.234044 Batch F1: 0.2962962962962963
Epoch:  449        5 Batch loss: 0.210039 Batch F1: 0.0
Epoch:  449        6 Batch loss: 0.229236 Batch F1: 0.0
Epoch:  449        7 Batch loss: 0.242379 Batch F1: 0.0
Epoch:  449        8 Batch loss: 0.227581 Batch F1: 0.0
Epoch:  449        9 Batch loss: 0.230550 Batch F1: 0.0
Epoch:  449       10 Batch loss: 0.209953 Batch F1: 0.0
Epoch:  449       11 Batch loss: 0.253888 Batch F1: 0.0
Epoch:  449       12 Batch loss: 0.236947 Batch F1: 0.0
Train Avg Loss  449: 0.229667

Train Avg F1  449: 0.024691358024691357

Val Avg Loss  449: 0.217963

Val Avg F1  449:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 450
--------------------------------------------------------------
Epoch:  450        1 Batch loss: 0.240539 Batch F1: 0.0
Epoch:  450        2 Batch loss: 0.213683 Batch F1: 0.0
Epoch:  450        3 Batch loss: 0.232026 Batch F1: 0.0
Epoch:  450        4 Batch loss: 0.217828 Batch F1: 0.0
Epoch:  450        5 Batch loss: 0.222956 Batch F1: 0.0
Epoch:  450        6 Batch loss: 0.241279 Batch F1: 0.0
Epoch:  450        7 Batch loss: 0.243791 Batch F1: 0.0
Epoch:  450        8 Batch loss: 0.229189 Batch F1: 0.0
Epoch:  450        9 Batch loss: 0.224426 Batch F1: 0.0
Epoch:  450       10 Batch loss: 0.192295 Batch F1: 0.0
Epoch:  450       11 Batch loss: 0.238942 Batch F1: 0.0
Epoch:  450       12 Batch loss: 0.240039 Batch F1: 0.0
Train Avg Loss  450: 0.228083

Train Avg F1  450: 0.0

Val Avg Loss  450: 0.218252

Val Avg F1  450:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 451
--------------------------------------------------------------
Epoch:  451        1 Batch loss: 0.196728 Batch F1: 0.0
Epoch:  451        2 Batch loss: 0.230135 Batch F1: 0.0
Epoch:  451        3 Batch loss: 0.251143 Batch F1: 0.0
Epoch:  451        4 Batch loss: 0.233031 Batch F1: 0.0
Epoch:  451        5 Batch loss: 0.200012 Batch F1: 0.0
Epoch:  451        6 Batch loss: 0.239583 Batch F1: 0.0
Epoch:  451        7 Batch loss: 0.219850 Batch F1: 0.0
Epoch:  451        8 Batch loss: 0.224405 Batch F1: 0.0
Epoch:  451        9 Batch loss: 0.256636 Batch F1: 0.0
Epoch:  451       10 Batch loss: 0.234427 Batch F1: 0.0
Epoch:  451       11 Batch loss: 0.224388 Batch F1: 0.0
Epoch:  451       12 Batch loss: 0.216604 Batch F1: 0.0
Train Avg Loss  451: 0.227245

Train Avg F1  451: 0.0

Val Avg Loss  451: 0.218060

Val Avg F1  451:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 452
--------------------------------------------------------------
Epoch:  452        1 Batch loss: 0.195531 Batch F1: 0.0
Epoch:  452        2 Batch loss: 0.219665 Batch F1: 0.0
Epoch:  452        3 Batch loss: 0.252766 Batch F1: 0.0
Epoch:  452        4 Batch loss: 0.257703 Batch F1: 0.0
Epoch:  452        5 Batch loss: 0.222844 Batch F1: 0.0
Epoch:  452        6 Batch loss: 0.215205 Batch F1: 0.0
Epoch:  452        7 Batch loss: 0.201299 Batch F1: 0.0
Epoch:  452        8 Batch loss: 0.232519 Batch F1: 0.0
Epoch:  452        9 Batch loss: 0.251623 Batch F1: 0.0
Epoch:  452       10 Batch loss: 0.204231 Batch F1: 0.0
Epoch:  452       11 Batch loss: 0.225413 Batch F1: 0.0
Epoch:  452       12 Batch loss: 0.249619 Batch F1: 0.0
Train Avg Loss  452: 0.227368

Train Avg F1  452: 0.0

Val Avg Loss  452: 0.219633

Val Avg F1  452:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 453
--------------------------------------------------------------
Epoch:  453        1 Batch loss: 0.215773 Batch F1: 0.0
Epoch:  453        2 Batch loss: 0.210046 Batch F1: 0.0
Epoch:  453        3 Batch loss: 0.256745 Batch F1: 0.0
Epoch:  453        4 Batch loss: 0.246632 Batch F1: 0.0
Epoch:  453        5 Batch loss: 0.244026 Batch F1: 0.0
Epoch:  453        6 Batch loss: 0.230475 Batch F1: 0.0
Epoch:  453        7 Batch loss: 0.232332 Batch F1: 0.24
Epoch:  453        8 Batch loss: 0.224407 Batch F1: 0.16666666666666669
Epoch:  453        9 Batch loss: 0.219799 Batch F1: 0.38461538461538464
Epoch:  453       10 Batch loss: 0.220244 Batch F1: 0.0
Epoch:  453       11 Batch loss: 0.216987 Batch F1: 0.0
Epoch:  453       12 Batch loss: 0.210538 Batch F1: 0.0
Train Avg Loss  453: 0.227334

Train Avg F1  453: 0.06594017094017095

Val Avg Loss  453: 0.217632

Val Avg F1  453:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 454
--------------------------------------------------------------
Epoch:  454        1 Batch loss: 0.215853 Batch F1: 0.0
Epoch:  454        2 Batch loss: 0.227159 Batch F1: 0.0
Epoch:  454        3 Batch loss: 0.264503 Batch F1: 0.0
Epoch:  454        4 Batch loss: 0.200125 Batch F1: 0.0
Epoch:  454        5 Batch loss: 0.260212 Batch F1: 0.0
Epoch:  454        6 Batch loss: 0.234862 Batch F1: 0.0
Epoch:  454        7 Batch loss: 0.200724 Batch F1: 0.0
Epoch:  454        8 Batch loss: 0.229266 Batch F1: 0.0
Epoch:  454        9 Batch loss: 0.224139 Batch F1: 0.0
Epoch:  454       10 Batch loss: 0.214826 Batch F1: 0.0
Epoch:  454       11 Batch loss: 0.205354 Batch F1: 0.0
Epoch:  454       12 Batch loss: 0.253764 Batch F1: 0.0
Train Avg Loss  454: 0.227566

Train Avg F1  454: 0.0

Val Avg Loss  454: 0.217756

Val Avg F1  454:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 455
--------------------------------------------------------------
Epoch:  455        1 Batch loss: 0.225842 Batch F1: 0.0
Epoch:  455        2 Batch loss: 0.257580 Batch F1: 0.0
Epoch:  455        3 Batch loss: 0.225515 Batch F1: 0.0
Epoch:  455        4 Batch loss: 0.226379 Batch F1: 0.0
Epoch:  455        5 Batch loss: 0.226272 Batch F1: 0.0
Epoch:  455        6 Batch loss: 0.234033 Batch F1: 0.0
Epoch:  455        7 Batch loss: 0.227339 Batch F1: 0.0
Epoch:  455        8 Batch loss: 0.215556 Batch F1: 0.0
Epoch:  455        9 Batch loss: 0.210070 Batch F1: 0.0
Epoch:  455       10 Batch loss: 0.249525 Batch F1: 0.0
Epoch:  455       11 Batch loss: 0.176351 Batch F1: 0.0
Epoch:  455       12 Batch loss: 0.261791 Batch F1: 0.0
Train Avg Loss  455: 0.228021

Train Avg F1  455: 0.0

Val Avg Loss  455: 0.217471

Val Avg F1  455:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 456
--------------------------------------------------------------
Epoch:  456        1 Batch loss: 0.195630 Batch F1: 0.0
Epoch:  456        2 Batch loss: 0.201499 Batch F1: 0.0
Epoch:  456        3 Batch loss: 0.205629 Batch F1: 0.0
Epoch:  456        4 Batch loss: 0.236949 Batch F1: 0.0
Epoch:  456        5 Batch loss: 0.258351 Batch F1: 0.0
Epoch:  456        6 Batch loss: 0.233378 Batch F1: 0.0
Epoch:  456        7 Batch loss: 0.209823 Batch F1: 0.0
Epoch:  456        8 Batch loss: 0.221396 Batch F1: 0.0
Epoch:  456        9 Batch loss: 0.230740 Batch F1: 0.0
Epoch:  456       10 Batch loss: 0.251555 Batch F1: 0.0
Epoch:  456       11 Batch loss: 0.230227 Batch F1: 0.4
Epoch:  456       12 Batch loss: 0.243118 Batch F1: 0.2727272727272727
Train Avg Loss  456: 0.226525

Train Avg F1  456: 0.05606060606060606

Val Avg Loss  456: 0.224346

Val Avg F1  456:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 457
--------------------------------------------------------------
Epoch:  457        1 Batch loss: 0.241022 Batch F1: 0.0
Epoch:  457        2 Batch loss: 0.232140 Batch F1: 0.0
Epoch:  457        3 Batch loss: 0.221235 Batch F1: 0.0
Epoch:  457        4 Batch loss: 0.223235 Batch F1: 0.0
Epoch:  457        5 Batch loss: 0.247761 Batch F1: 0.0
Epoch:  457        6 Batch loss: 0.224561 Batch F1: 0.0
Epoch:  457        7 Batch loss: 0.219534 Batch F1: 0.0
Epoch:  457        8 Batch loss: 0.234731 Batch F1: 0.0
Epoch:  457        9 Batch loss: 0.213151 Batch F1: 0.0
Epoch:  457       10 Batch loss: 0.235936 Batch F1: 0.0
Epoch:  457       11 Batch loss: 0.225141 Batch F1: 0.0
Epoch:  457       12 Batch loss: 0.195445 Batch F1: 0.0
Train Avg Loss  457: 0.226158

Train Avg F1  457: 0.0

Val Avg Loss  457: 0.217339

Val Avg F1  457:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 458
--------------------------------------------------------------
Epoch:  458        1 Batch loss: 0.219423 Batch F1: 0.0
Epoch:  458        2 Batch loss: 0.201257 Batch F1: 0.0
Epoch:  458        3 Batch loss: 0.217596 Batch F1: 0.0
Epoch:  458        4 Batch loss: 0.199430 Batch F1: 0.0
Epoch:  458        5 Batch loss: 0.227875 Batch F1: 0.0
Epoch:  458        6 Batch loss: 0.221955 Batch F1: 0.0
Epoch:  458        7 Batch loss: 0.259788 Batch F1: 0.0
Epoch:  458        8 Batch loss: 0.227524 Batch F1: 0.4848484848484849
Epoch:  458        9 Batch loss: 0.245754 Batch F1: 0.15384615384615385
Epoch:  458       10 Batch loss: 0.236688 Batch F1: 0.26666666666666666
Epoch:  458       11 Batch loss: 0.243512 Batch F1: 0.21428571428571427
Epoch:  458       12 Batch loss: 0.229400 Batch F1: 0.4799999999999999
Train Avg Loss  458: 0.227517

Train Avg F1  458: 0.1333039183039183

Val Avg Loss  458: 0.225094

Val Avg F1  458:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 459
--------------------------------------------------------------
Epoch:  459        1 Batch loss: 0.217927 Batch F1: 0.0
Epoch:  459        2 Batch loss: 0.230054 Batch F1: 0.0
Epoch:  459        3 Batch loss: 0.250426 Batch F1: 0.0
Epoch:  459        4 Batch loss: 0.210893 Batch F1: 0.0
Epoch:  459        5 Batch loss: 0.228446 Batch F1: 0.0
Epoch:  459        6 Batch loss: 0.202432 Batch F1: 0.0
Epoch:  459        7 Batch loss: 0.233254 Batch F1: 0.0
Epoch:  459        8 Batch loss: 0.247803 Batch F1: 0.0
Epoch:  459        9 Batch loss: 0.225977 Batch F1: 0.0
Epoch:  459       10 Batch loss: 0.268163 Batch F1: 0.0
Epoch:  459       11 Batch loss: 0.207121 Batch F1: 0.0
Epoch:  459       12 Batch loss: 0.224402 Batch F1: 0.0
Train Avg Loss  459: 0.228908

Train Avg F1  459: 0.0

Val Avg Loss  459: 0.221557

Val Avg F1  459:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 460
--------------------------------------------------------------
Epoch:  460        1 Batch loss: 0.240543 Batch F1: 0.0
Epoch:  460        2 Batch loss: 0.212759 Batch F1: 0.09523809523809523
Epoch:  460        3 Batch loss: 0.237612 Batch F1: 0.2857142857142857
Epoch:  460        4 Batch loss: 0.228815 Batch F1: 0.19047619047619047
Epoch:  460        5 Batch loss: 0.233295 Batch F1: 0.0
Epoch:  460        6 Batch loss: 0.206039 Batch F1: 0.0
Epoch:  460        7 Batch loss: 0.222671 Batch F1: 0.0
Epoch:  460        8 Batch loss: 0.218013 Batch F1: 0.0
Epoch:  460        9 Batch loss: 0.220469 Batch F1: 0.0
Epoch:  460       10 Batch loss: 0.221441 Batch F1: 0.0
Epoch:  460       11 Batch loss: 0.290381 Batch F1: 0.0
Epoch:  460       12 Batch loss: 0.200694 Batch F1: 0.0
Train Avg Loss  460: 0.227728

Train Avg F1  460: 0.047619047619047616

Val Avg Loss  460: 0.217373

Val Avg F1  460:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 461
--------------------------------------------------------------
Epoch:  461        1 Batch loss: 0.223683 Batch F1: 0.0
Epoch:  461        2 Batch loss: 0.195704 Batch F1: 0.0
Epoch:  461        3 Batch loss: 0.230561 Batch F1: 0.0
Epoch:  461        4 Batch loss: 0.245612 Batch F1: 0.0
Epoch:  461        5 Batch loss: 0.249429 Batch F1: 0.0
Epoch:  461        6 Batch loss: 0.251140 Batch F1: 0.0
Epoch:  461        7 Batch loss: 0.232572 Batch F1: 0.3846153846153846
Epoch:  461        8 Batch loss: 0.237568 Batch F1: 0.2
Epoch:  461        9 Batch loss: 0.235344 Batch F1: 0.09523809523809522
Epoch:  461       10 Batch loss: 0.228777 Batch F1: 0.0
Epoch:  461       11 Batch loss: 0.190705 Batch F1: 0.0
Epoch:  461       12 Batch loss: 0.207594 Batch F1: 0.0
Train Avg Loss  461: 0.227391

Train Avg F1  461: 0.05665445665445665

Val Avg Loss  461: 0.218633

Val Avg F1  461:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 462
--------------------------------------------------------------
Epoch:  462        1 Batch loss: 0.234911 Batch F1: 0.0
Epoch:  462        2 Batch loss: 0.267047 Batch F1: 0.0
Epoch:  462        3 Batch loss: 0.189186 Batch F1: 0.0
Epoch:  462        4 Batch loss: 0.215117 Batch F1: 0.0
Epoch:  462        5 Batch loss: 0.276412 Batch F1: 0.0
Epoch:  462        6 Batch loss: 0.237444 Batch F1: 0.0
Epoch:  462        7 Batch loss: 0.239550 Batch F1: 0.0
Epoch:  462        8 Batch loss: 0.256577 Batch F1: 0.0
Epoch:  462        9 Batch loss: 0.217281 Batch F1: 0.0
Epoch:  462       10 Batch loss: 0.224670 Batch F1: 0.0
Epoch:  462       11 Batch loss: 0.206211 Batch F1: 0.0
Epoch:  462       12 Batch loss: 0.233976 Batch F1: 0.0
Train Avg Loss  462: 0.233199

Train Avg F1  462: 0.0

Val Avg Loss  462: 0.219393

Val Avg F1  462:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 463
--------------------------------------------------------------
Epoch:  463        1 Batch loss: 0.226204 Batch F1: 0.0
Epoch:  463        2 Batch loss: 0.217090 Batch F1: 0.0
Epoch:  463        3 Batch loss: 0.225170 Batch F1: 0.0
Epoch:  463        4 Batch loss: 0.233903 Batch F1: 0.0
Epoch:  463        5 Batch loss: 0.239410 Batch F1: 0.0
Epoch:  463        6 Batch loss: 0.218003 Batch F1: 0.0
Epoch:  463        7 Batch loss: 0.251960 Batch F1: 0.0
Epoch:  463        8 Batch loss: 0.203400 Batch F1: 0.0
Epoch:  463        9 Batch loss: 0.208648 Batch F1: 0.0
Epoch:  463       10 Batch loss: 0.266318 Batch F1: 0.0
Epoch:  463       11 Batch loss: 0.213450 Batch F1: 0.0
Epoch:  463       12 Batch loss: 0.241424 Batch F1: 0.0
Train Avg Loss  463: 0.228749

Train Avg F1  463: 0.0

Val Avg Loss  463: 0.218876

Val Avg F1  463:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 464
--------------------------------------------------------------
Epoch:  464        1 Batch loss: 0.212658 Batch F1: 0.0
Epoch:  464        2 Batch loss: 0.230867 Batch F1: 0.0
Epoch:  464        3 Batch loss: 0.223391 Batch F1: 0.0
Epoch:  464        4 Batch loss: 0.238000 Batch F1: 0.0
Epoch:  464        5 Batch loss: 0.240111 Batch F1: 0.0
Epoch:  464        6 Batch loss: 0.215513 Batch F1: 0.0
Epoch:  464        7 Batch loss: 0.238025 Batch F1: 0.0
Epoch:  464        8 Batch loss: 0.180892 Batch F1: 0.0
Epoch:  464        9 Batch loss: 0.220626 Batch F1: 0.0
Epoch:  464       10 Batch loss: 0.222597 Batch F1: 0.0
Epoch:  464       11 Batch loss: 0.267248 Batch F1: 0.0
Epoch:  464       12 Batch loss: 0.256262 Batch F1: 0.0
Train Avg Loss  464: 0.228849

Train Avg F1  464: 0.0

Val Avg Loss  464: 0.217481

Val Avg F1  464:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 465
--------------------------------------------------------------
Epoch:  465        1 Batch loss: 0.216645 Batch F1: 0.0
Epoch:  465        2 Batch loss: 0.238328 Batch F1: 0.0
Epoch:  465        3 Batch loss: 0.234309 Batch F1: 0.0
Epoch:  465        4 Batch loss: 0.240645 Batch F1: 0.23076923076923078
Epoch:  465        5 Batch loss: 0.242632 Batch F1: 0.24999999999999997
Epoch:  465        6 Batch loss: 0.211694 Batch F1: 0.4800000000000001
Epoch:  465        7 Batch loss: 0.227678 Batch F1: 0.0
Epoch:  465        8 Batch loss: 0.194554 Batch F1: 0.0
Epoch:  465        9 Batch loss: 0.207588 Batch F1: 0.0
Epoch:  465       10 Batch loss: 0.247021 Batch F1: 0.0
Epoch:  465       11 Batch loss: 0.241215 Batch F1: 0.0
Epoch:  465       12 Batch loss: 0.246099 Batch F1: 0.0
Train Avg Loss  465: 0.229034

Train Avg F1  465: 0.08006410256410257

Val Avg Loss  465: 0.218678

Val Avg F1  465:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 466
--------------------------------------------------------------
Epoch:  466        1 Batch loss: 0.222717 Batch F1: 0.0
Epoch:  466        2 Batch loss: 0.206320 Batch F1: 0.0
Epoch:  466        3 Batch loss: 0.201289 Batch F1: 0.0
Epoch:  466        4 Batch loss: 0.207954 Batch F1: 0.0
Epoch:  466        5 Batch loss: 0.270729 Batch F1: 0.0
Epoch:  466        6 Batch loss: 0.228927 Batch F1: 0.0
Epoch:  466        7 Batch loss: 0.221479 Batch F1: 0.0
Epoch:  466        8 Batch loss: 0.218508 Batch F1: 0.0
Epoch:  466        9 Batch loss: 0.249638 Batch F1: 0.0
Epoch:  466       10 Batch loss: 0.236531 Batch F1: 0.0
Epoch:  466       11 Batch loss: 0.237897 Batch F1: 0.0
Epoch:  466       12 Batch loss: 0.244020 Batch F1: 0.0
Train Avg Loss  466: 0.228834

Train Avg F1  466: 0.0

Val Avg Loss  466: 0.220103

Val Avg F1  466:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 467
--------------------------------------------------------------
Epoch:  467        1 Batch loss: 0.242541 Batch F1: 0.0
Epoch:  467        2 Batch loss: 0.228727 Batch F1: 0.0
Epoch:  467        3 Batch loss: 0.215001 Batch F1: 0.2857142857142857
Epoch:  467        4 Batch loss: 0.221317 Batch F1: 0.3846153846153846
Epoch:  467        5 Batch loss: 0.226494 Batch F1: 0.2727272727272727
Epoch:  467        6 Batch loss: 0.214062 Batch F1: 0.0
Epoch:  467        7 Batch loss: 0.217762 Batch F1: 0.0
Epoch:  467        8 Batch loss: 0.248730 Batch F1: 0.0
Epoch:  467        9 Batch loss: 0.246286 Batch F1: 0.0
Epoch:  467       10 Batch loss: 0.198118 Batch F1: 0.0
Epoch:  467       11 Batch loss: 0.226286 Batch F1: 0.0
Epoch:  467       12 Batch loss: 0.257511 Batch F1: 0.0
Train Avg Loss  467: 0.228570

Train Avg F1  467: 0.07858807858807858

Val Avg Loss  467: 0.217713

Val Avg F1  467:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 468
--------------------------------------------------------------
Epoch:  468        1 Batch loss: 0.224812 Batch F1: 0.0
Epoch:  468        2 Batch loss: 0.240821 Batch F1: 0.0
Epoch:  468        3 Batch loss: 0.230837 Batch F1: 0.0
Epoch:  468        4 Batch loss: 0.212723 Batch F1: 0.0
Epoch:  468        5 Batch loss: 0.198938 Batch F1: 0.0
Epoch:  468        6 Batch loss: 0.223444 Batch F1: 0.0
Epoch:  468        7 Batch loss: 0.275013 Batch F1: 0.0
Epoch:  468        8 Batch loss: 0.201035 Batch F1: 0.0
Epoch:  468        9 Batch loss: 0.239958 Batch F1: 0.0
Epoch:  468       10 Batch loss: 0.231653 Batch F1: 0.0
Epoch:  468       11 Batch loss: 0.229963 Batch F1: 0.0
Epoch:  468       12 Batch loss: 0.208606 Batch F1: 0.0
Train Avg Loss  468: 0.226484

Train Avg F1  468: 0.0

Val Avg Loss  468: 0.218313

Val Avg F1  468:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 469
--------------------------------------------------------------
Epoch:  469        1 Batch loss: 0.248608 Batch F1: 0.0
Epoch:  469        2 Batch loss: 0.184288 Batch F1: 0.0
Epoch:  469        3 Batch loss: 0.223647 Batch F1: 0.0
Epoch:  469        4 Batch loss: 0.217384 Batch F1: 0.0
Epoch:  469        5 Batch loss: 0.234909 Batch F1: 0.0
Epoch:  469        6 Batch loss: 0.210110 Batch F1: 0.0
Epoch:  469        7 Batch loss: 0.265991 Batch F1: 0.0
Epoch:  469        8 Batch loss: 0.244970 Batch F1: 0.0
Epoch:  469        9 Batch loss: 0.243120 Batch F1: 0.0
Epoch:  469       10 Batch loss: 0.214850 Batch F1: 0.0
Epoch:  469       11 Batch loss: 0.237178 Batch F1: 0.0
Epoch:  469       12 Batch loss: 0.185941 Batch F1: 0.0
Train Avg Loss  469: 0.225916

Train Avg F1  469: 0.0

Val Avg Loss  469: 0.217150

Val Avg F1  469:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 470
--------------------------------------------------------------
Epoch:  470        1 Batch loss: 0.192579 Batch F1: 0.0
Epoch:  470        2 Batch loss: 0.248562 Batch F1: 0.0
Epoch:  470        3 Batch loss: 0.224697 Batch F1: 0.0
Epoch:  470        4 Batch loss: 0.240238 Batch F1: 0.0
Epoch:  470        5 Batch loss: 0.199634 Batch F1: 0.0
Epoch:  470        6 Batch loss: 0.230468 Batch F1: 0.0
Epoch:  470        7 Batch loss: 0.245010 Batch F1: 0.0
Epoch:  470        8 Batch loss: 0.238373 Batch F1: 0.0
Epoch:  470        9 Batch loss: 0.226480 Batch F1: 0.0
Epoch:  470       10 Batch loss: 0.228896 Batch F1: 0.0
Epoch:  470       11 Batch loss: 0.240573 Batch F1: 0.0
Epoch:  470       12 Batch loss: 0.222546 Batch F1: 0.0
Train Avg Loss  470: 0.228171

Train Avg F1  470: 0.0

Val Avg Loss  470: 0.220485

Val Avg F1  470:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 471
--------------------------------------------------------------
Epoch:  471        1 Batch loss: 0.212185 Batch F1: 0.0
Epoch:  471        2 Batch loss: 0.222317 Batch F1: 0.0
Epoch:  471        3 Batch loss: 0.224289 Batch F1: 0.0
Epoch:  471        4 Batch loss: 0.210595 Batch F1: 0.0
Epoch:  471        5 Batch loss: 0.229600 Batch F1: 0.0
Epoch:  471        6 Batch loss: 0.273454 Batch F1: 0.0
Epoch:  471        7 Batch loss: 0.224072 Batch F1: 0.0
Epoch:  471        8 Batch loss: 0.222960 Batch F1: 0.0
Epoch:  471        9 Batch loss: 0.244817 Batch F1: 0.0
Epoch:  471       10 Batch loss: 0.201046 Batch F1: 0.0
Epoch:  471       11 Batch loss: 0.237484 Batch F1: 0.0
Epoch:  471       12 Batch loss: 0.227102 Batch F1: 0.0
Train Avg Loss  471: 0.227493

Train Avg F1  471: 0.0

Val Avg Loss  471: 0.219271

Val Avg F1  471:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 472
--------------------------------------------------------------
Epoch:  472        1 Batch loss: 0.231233 Batch F1: 0.0
Epoch:  472        2 Batch loss: 0.235308 Batch F1: 0.0
Epoch:  472        3 Batch loss: 0.215178 Batch F1: 0.0
Epoch:  472        4 Batch loss: 0.254191 Batch F1: 0.0
Epoch:  472        5 Batch loss: 0.215336 Batch F1: 0.0
Epoch:  472        6 Batch loss: 0.249983 Batch F1: 0.0
Epoch:  472        7 Batch loss: 0.217412 Batch F1: 0.0
Epoch:  472        8 Batch loss: 0.211622 Batch F1: 0.0
Epoch:  472        9 Batch loss: 0.192069 Batch F1: 0.0
Epoch:  472       10 Batch loss: 0.240215 Batch F1: 0.0
Epoch:  472       11 Batch loss: 0.223581 Batch F1: 0.0
Epoch:  472       12 Batch loss: 0.236478 Batch F1: 0.0
Train Avg Loss  472: 0.226884

Train Avg F1  472: 0.0

Val Avg Loss  472: 0.217330

Val Avg F1  472:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 473
--------------------------------------------------------------
Epoch:  473        1 Batch loss: 0.227515 Batch F1: 0.0
Epoch:  473        2 Batch loss: 0.201039 Batch F1: 0.0
Epoch:  473        3 Batch loss: 0.215902 Batch F1: 0.0
Epoch:  473        4 Batch loss: 0.229255 Batch F1: 0.0
Epoch:  473        5 Batch loss: 0.209812 Batch F1: 0.0
Epoch:  473        6 Batch loss: 0.253000 Batch F1: 0.0
Epoch:  473        7 Batch loss: 0.250909 Batch F1: 0.0
Epoch:  473        8 Batch loss: 0.196681 Batch F1: 0.0
Epoch:  473        9 Batch loss: 0.225699 Batch F1: 0.0
Epoch:  473       10 Batch loss: 0.221214 Batch F1: 0.0
Epoch:  473       11 Batch loss: 0.213646 Batch F1: 0.0
Epoch:  473       12 Batch loss: 0.277535 Batch F1: 0.0
Train Avg Loss  473: 0.226851

Train Avg F1  473: 0.0

Val Avg Loss  473: 0.217347

Val Avg F1  473:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 474
--------------------------------------------------------------
Epoch:  474        1 Batch loss: 0.201982 Batch F1: 0.0
Epoch:  474        2 Batch loss: 0.200680 Batch F1: 0.0
Epoch:  474        3 Batch loss: 0.259296 Batch F1: 0.0
Epoch:  474        4 Batch loss: 0.233646 Batch F1: 0.0
Epoch:  474        5 Batch loss: 0.242592 Batch F1: 0.0
Epoch:  474        6 Batch loss: 0.238170 Batch F1: 0.29629629629629634
Epoch:  474        7 Batch loss: 0.211199 Batch F1: 0.10526315789473684
Epoch:  474        8 Batch loss: 0.234878 Batch F1: 0.37037037037037035
Epoch:  474        9 Batch loss: 0.220411 Batch F1: 0.0
Epoch:  474       10 Batch loss: 0.232575 Batch F1: 0.0
Epoch:  474       11 Batch loss: 0.238876 Batch F1: 0.0
Epoch:  474       12 Batch loss: 0.190249 Batch F1: 0.0
Train Avg Loss  474: 0.225380

Train Avg F1  474: 0.06432748538011696

Val Avg Loss  474: 0.216826

Val Avg F1  474:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 475
--------------------------------------------------------------
Epoch:  475        1 Batch loss: 0.175712 Batch F1: 0.0
Epoch:  475        2 Batch loss: 0.203992 Batch F1: 0.0
Epoch:  475        3 Batch loss: 0.222392 Batch F1: 0.0
Epoch:  475        4 Batch loss: 0.220075 Batch F1: 0.0
Epoch:  475        5 Batch loss: 0.235982 Batch F1: 0.0
Epoch:  475        6 Batch loss: 0.237266 Batch F1: 0.0
Epoch:  475        7 Batch loss: 0.230749 Batch F1: 0.0
Epoch:  475        8 Batch loss: 0.230895 Batch F1: 0.0
Epoch:  475        9 Batch loss: 0.258212 Batch F1: 0.0
Epoch:  475       10 Batch loss: 0.241582 Batch F1: 0.0
Epoch:  475       11 Batch loss: 0.230334 Batch F1: 0.0
Epoch:  475       12 Batch loss: 0.240036 Batch F1: 0.0
Train Avg Loss  475: 0.227269

Train Avg F1  475: 0.0

Val Avg Loss  475: 0.227026

Val Avg F1  475:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 476
--------------------------------------------------------------
Epoch:  476        1 Batch loss: 0.226701 Batch F1: 0.0
Epoch:  476        2 Batch loss: 0.234267 Batch F1: 0.0
Epoch:  476        3 Batch loss: 0.220619 Batch F1: 0.0
Epoch:  476        4 Batch loss: 0.248103 Batch F1: 0.0
Epoch:  476        5 Batch loss: 0.172610 Batch F1: 0.0
Epoch:  476        6 Batch loss: 0.233307 Batch F1: 0.0
Epoch:  476        7 Batch loss: 0.238614 Batch F1: 0.0
Epoch:  476        8 Batch loss: 0.260441 Batch F1: 0.0
Epoch:  476        9 Batch loss: 0.234524 Batch F1: 0.0
Epoch:  476       10 Batch loss: 0.250326 Batch F1: 0.0
Epoch:  476       11 Batch loss: 0.231261 Batch F1: 0.0
Epoch:  476       12 Batch loss: 0.219280 Batch F1: 0.0
Train Avg Loss  476: 0.230838

Train Avg F1  476: 0.0

Val Avg Loss  476: 0.223311

Val Avg F1  476:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 477
--------------------------------------------------------------
Epoch:  477        1 Batch loss: 0.238524 Batch F1: 0.0
Epoch:  477        2 Batch loss: 0.231627 Batch F1: 0.0
Epoch:  477        3 Batch loss: 0.221659 Batch F1: 0.0
Epoch:  477        4 Batch loss: 0.254526 Batch F1: 0.0
Epoch:  477        5 Batch loss: 0.235484 Batch F1: 0.0
Epoch:  477        6 Batch loss: 0.231716 Batch F1: 0.0
Epoch:  477        7 Batch loss: 0.214208 Batch F1: 0.0
Epoch:  477        8 Batch loss: 0.241490 Batch F1: 0.0
Epoch:  477        9 Batch loss: 0.221633 Batch F1: 0.0
Epoch:  477       10 Batch loss: 0.217136 Batch F1: 0.0
Epoch:  477       11 Batch loss: 0.228669 Batch F1: 0.0
Epoch:  477       12 Batch loss: 0.219334 Batch F1: 0.0
Train Avg Loss  477: 0.229667

Train Avg F1  477: 0.0

Val Avg Loss  477: 0.218821

Val Avg F1  477:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 478
--------------------------------------------------------------
Epoch:  478        1 Batch loss: 0.221591 Batch F1: 0.0
Epoch:  478        2 Batch loss: 0.218460 Batch F1: 0.0
Epoch:  478        3 Batch loss: 0.256920 Batch F1: 0.0
Epoch:  478        4 Batch loss: 0.226770 Batch F1: 0.0
Epoch:  478        5 Batch loss: 0.233402 Batch F1: 0.3448275862068966
Epoch:  478        6 Batch loss: 0.226236 Batch F1: 0.0
Epoch:  478        7 Batch loss: 0.211420 Batch F1: 0.0
Epoch:  478        8 Batch loss: 0.200056 Batch F1: 0.0
Epoch:  478        9 Batch loss: 0.240389 Batch F1: 0.0
Epoch:  478       10 Batch loss: 0.240182 Batch F1: 0.0
Epoch:  478       11 Batch loss: 0.219411 Batch F1: 0.0
Epoch:  478       12 Batch loss: 0.238108 Batch F1: 0.0
Train Avg Loss  478: 0.227745

Train Avg F1  478: 0.02873563218390805

Val Avg Loss  478: 0.217717

Val Avg F1  478:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 479
--------------------------------------------------------------
Epoch:  479        1 Batch loss: 0.223301 Batch F1: 0.0
Epoch:  479        2 Batch loss: 0.229965 Batch F1: 0.0
Epoch:  479        3 Batch loss: 0.223667 Batch F1: 0.0
Epoch:  479        4 Batch loss: 0.200442 Batch F1: 0.0
Epoch:  479        5 Batch loss: 0.180711 Batch F1: 0.0
Epoch:  479        6 Batch loss: 0.213050 Batch F1: 0.0
Epoch:  479        7 Batch loss: 0.259976 Batch F1: 0.0
Epoch:  479        8 Batch loss: 0.237795 Batch F1: 0.0
Epoch:  479        9 Batch loss: 0.250007 Batch F1: 0.0
Epoch:  479       10 Batch loss: 0.234962 Batch F1: 0.0
Epoch:  479       11 Batch loss: 0.257300 Batch F1: 0.0
Epoch:  479       12 Batch loss: 0.246067 Batch F1: 0.0
Train Avg Loss  479: 0.229770

Train Avg F1  479: 0.0

Val Avg Loss  479: 0.236592

Val Avg F1  479:  0.3828540552678483

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 480
--------------------------------------------------------------
Epoch:  480        1 Batch loss: 0.236391 Batch F1: 0.23999999999999996
Epoch:  480        2 Batch loss: 0.248105 Batch F1: 0.47368421052631576
Epoch:  480        3 Batch loss: 0.243303 Batch F1: 0.39999999999999997
Epoch:  480        4 Batch loss: 0.247259 Batch F1: 0.3636363636363637
Epoch:  480        5 Batch loss: 0.231959 Batch F1: 0.1818181818181818
Epoch:  480        6 Batch loss: 0.232243 Batch F1: 0.0
Epoch:  480        7 Batch loss: 0.228681 Batch F1: 0.0
Epoch:  480        8 Batch loss: 0.189431 Batch F1: 0.0
Epoch:  480        9 Batch loss: 0.285210 Batch F1: 0.0
Epoch:  480       10 Batch loss: 0.235732 Batch F1: 0.0
Epoch:  480       11 Batch loss: 0.173288 Batch F1: 0.0
Epoch:  480       12 Batch loss: 0.227906 Batch F1: 0.0
Train Avg Loss  480: 0.231626

Train Avg F1  480: 0.1382615629984051

Val Avg Loss  480: 0.218501

Val Avg F1  480:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 481
--------------------------------------------------------------
Epoch:  481        1 Batch loss: 0.241603 Batch F1: 0.0
Epoch:  481        2 Batch loss: 0.241776 Batch F1: 0.0
Epoch:  481        3 Batch loss: 0.216500 Batch F1: 0.0
Epoch:  481        4 Batch loss: 0.187837 Batch F1: 0.0
Epoch:  481        5 Batch loss: 0.217630 Batch F1: 0.0
Epoch:  481        6 Batch loss: 0.285606 Batch F1: 0.0
Epoch:  481        7 Batch loss: 0.193444 Batch F1: 0.0
Epoch:  481        8 Batch loss: 0.234508 Batch F1: 0.0
Epoch:  481        9 Batch loss: 0.245294 Batch F1: 0.0
Epoch:  481       10 Batch loss: 0.250928 Batch F1: 0.0
Epoch:  481       11 Batch loss: 0.227895 Batch F1: 0.19047619047619044
Epoch:  481       12 Batch loss: 0.217019 Batch F1: 0.0
Train Avg Loss  481: 0.230003

Train Avg F1  481: 0.01587301587301587

Val Avg Loss  481: 0.217408

Val Avg F1  481:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 482
--------------------------------------------------------------
Epoch:  482        1 Batch loss: 0.190941 Batch F1: 0.0
Epoch:  482        2 Batch loss: 0.236747 Batch F1: 0.0
Epoch:  482        3 Batch loss: 0.180472 Batch F1: 0.0
Epoch:  482        4 Batch loss: 0.215696 Batch F1: 0.0
Epoch:  482        5 Batch loss: 0.282265 Batch F1: 0.0
Epoch:  482        6 Batch loss: 0.254938 Batch F1: 0.0
Epoch:  482        7 Batch loss: 0.219090 Batch F1: 0.0
Epoch:  482        8 Batch loss: 0.247991 Batch F1: 0.0
Epoch:  482        9 Batch loss: 0.256286 Batch F1: 0.0
Epoch:  482       10 Batch loss: 0.212996 Batch F1: 0.0
Epoch:  482       11 Batch loss: 0.232075 Batch F1: 0.0
Epoch:  482       12 Batch loss: 0.241408 Batch F1: 0.0
Train Avg Loss  482: 0.230909

Train Avg F1  482: 0.0

Val Avg Loss  482: 0.224449

Val Avg F1  482:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 483
--------------------------------------------------------------
Epoch:  483        1 Batch loss: 0.219502 Batch F1: 0.0
Epoch:  483        2 Batch loss: 0.233226 Batch F1: 0.0
Epoch:  483        3 Batch loss: 0.238753 Batch F1: 0.0
Epoch:  483        4 Batch loss: 0.247236 Batch F1: 0.0
Epoch:  483        5 Batch loss: 0.222508 Batch F1: 0.0
Epoch:  483        6 Batch loss: 0.227946 Batch F1: 0.0
Epoch:  483        7 Batch loss: 0.214602 Batch F1: 0.0
Epoch:  483        8 Batch loss: 0.241555 Batch F1: 0.0
Epoch:  483        9 Batch loss: 0.215049 Batch F1: 0.0
Epoch:  483       10 Batch loss: 0.240794 Batch F1: 0.0
Epoch:  483       11 Batch loss: 0.217775 Batch F1: 0.0
Epoch:  483       12 Batch loss: 0.221357 Batch F1: 0.0
Train Avg Loss  483: 0.228359

Train Avg F1  483: 0.0

Val Avg Loss  483: 0.217575

Val Avg F1  483:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 484
--------------------------------------------------------------
Epoch:  484        1 Batch loss: 0.225583 Batch F1: 0.0
Epoch:  484        2 Batch loss: 0.191724 Batch F1: 0.0
Epoch:  484        3 Batch loss: 0.209324 Batch F1: 0.0
Epoch:  484        4 Batch loss: 0.226411 Batch F1: 0.0
Epoch:  484        5 Batch loss: 0.231442 Batch F1: 0.0
Epoch:  484        6 Batch loss: 0.266526 Batch F1: 0.0
Epoch:  484        7 Batch loss: 0.240602 Batch F1: 0.0
Epoch:  484        8 Batch loss: 0.259249 Batch F1: 0.0
Epoch:  484        9 Batch loss: 0.209362 Batch F1: 0.1
Epoch:  484       10 Batch loss: 0.238442 Batch F1: 0.10526315789473684
Epoch:  484       11 Batch loss: 0.221100 Batch F1: 0.1
Epoch:  484       12 Batch loss: 0.239901 Batch F1: 0.0
Train Avg Loss  484: 0.229972

Train Avg F1  484: 0.02543859649122807

Val Avg Loss  484: 0.219484

Val Avg F1  484:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 485
--------------------------------------------------------------
Epoch:  485        1 Batch loss: 0.207877 Batch F1: 0.0
Epoch:  485        2 Batch loss: 0.214013 Batch F1: 0.0
Epoch:  485        3 Batch loss: 0.268212 Batch F1: 0.0
Epoch:  485        4 Batch loss: 0.228809 Batch F1: 0.0
Epoch:  485        5 Batch loss: 0.221181 Batch F1: 0.0
Epoch:  485        6 Batch loss: 0.217823 Batch F1: 0.0
Epoch:  485        7 Batch loss: 0.220063 Batch F1: 0.0
Epoch:  485        8 Batch loss: 0.230991 Batch F1: 0.0
Epoch:  485        9 Batch loss: 0.230138 Batch F1: 0.0
Epoch:  485       10 Batch loss: 0.250548 Batch F1: 0.0
Epoch:  485       11 Batch loss: 0.209593 Batch F1: 0.0
Epoch:  485       12 Batch loss: 0.240442 Batch F1: 0.0
Train Avg Loss  485: 0.228307

Train Avg F1  485: 0.0

Val Avg Loss  485: 0.219691

Val Avg F1  485:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 486
--------------------------------------------------------------
Epoch:  486        1 Batch loss: 0.239301 Batch F1: 0.0
Epoch:  486        2 Batch loss: 0.218290 Batch F1: 0.0
Epoch:  486        3 Batch loss: 0.212508 Batch F1: 0.0
Epoch:  486        4 Batch loss: 0.243597 Batch F1: 0.0
Epoch:  486        5 Batch loss: 0.204813 Batch F1: 0.0
Epoch:  486        6 Batch loss: 0.208869 Batch F1: 0.0
Epoch:  486        7 Batch loss: 0.208506 Batch F1: 0.0
Epoch:  486        8 Batch loss: 0.251905 Batch F1: 0.0
Epoch:  486        9 Batch loss: 0.237624 Batch F1: 0.0
Epoch:  486       10 Batch loss: 0.263424 Batch F1: 0.0
Epoch:  486       11 Batch loss: 0.227629 Batch F1: 0.0
Epoch:  486       12 Batch loss: 0.228841 Batch F1: 0.0
Train Avg Loss  486: 0.228775

Train Avg F1  486: 0.0

Val Avg Loss  486: 0.217791

Val Avg F1  486:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 487
--------------------------------------------------------------
Epoch:  487        1 Batch loss: 0.205750 Batch F1: 0.0
Epoch:  487        2 Batch loss: 0.230868 Batch F1: 0.0
Epoch:  487        3 Batch loss: 0.223749 Batch F1: 0.0
Epoch:  487        4 Batch loss: 0.262049 Batch F1: 0.0
Epoch:  487        5 Batch loss: 0.225507 Batch F1: 0.0
Epoch:  487        6 Batch loss: 0.250011 Batch F1: 0.0
Epoch:  487        7 Batch loss: 0.234223 Batch F1: 0.09090909090909091
Epoch:  487        8 Batch loss: 0.241797 Batch F1: 0.27586206896551724
Epoch:  487        9 Batch loss: 0.226572 Batch F1: 0.25
Epoch:  487       10 Batch loss: 0.197540 Batch F1: 0.13333333333333333
Epoch:  487       11 Batch loss: 0.193432 Batch F1: 0.0
Epoch:  487       12 Batch loss: 0.239491 Batch F1: 0.0
Train Avg Loss  487: 0.227582

Train Avg F1  487: 0.06250870776732846

Val Avg Loss  487: 0.217903

Val Avg F1  487:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 488
--------------------------------------------------------------
Epoch:  488        1 Batch loss: 0.213313 Batch F1: 0.0
Epoch:  488        2 Batch loss: 0.217628 Batch F1: 0.0
Epoch:  488        3 Batch loss: 0.252338 Batch F1: 0.0
Epoch:  488        4 Batch loss: 0.221967 Batch F1: 0.0
Epoch:  488        5 Batch loss: 0.206321 Batch F1: 0.0
Epoch:  488        6 Batch loss: 0.268368 Batch F1: 0.0
Epoch:  488        7 Batch loss: 0.233317 Batch F1: 0.0
Epoch:  488        8 Batch loss: 0.190814 Batch F1: 0.0
Epoch:  488        9 Batch loss: 0.248189 Batch F1: 0.0
Epoch:  488       10 Batch loss: 0.225134 Batch F1: 0.0
Epoch:  488       11 Batch loss: 0.225707 Batch F1: 0.0
Epoch:  488       12 Batch loss: 0.225543 Batch F1: 0.0
Train Avg Loss  488: 0.227387

Train Avg F1  488: 0.0

Val Avg Loss  488: 0.219489

Val Avg F1  488:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 489
--------------------------------------------------------------
Epoch:  489        1 Batch loss: 0.228037 Batch F1: 0.0
Epoch:  489        2 Batch loss: 0.227050 Batch F1: 0.0
Epoch:  489        3 Batch loss: 0.223440 Batch F1: 0.0
Epoch:  489        4 Batch loss: 0.211093 Batch F1: 0.0
Epoch:  489        5 Batch loss: 0.229288 Batch F1: 0.0
Epoch:  489        6 Batch loss: 0.238535 Batch F1: 0.0
Epoch:  489        7 Batch loss: 0.243192 Batch F1: 0.0
Epoch:  489        8 Batch loss: 0.236524 Batch F1: 0.0
Epoch:  489        9 Batch loss: 0.230940 Batch F1: 0.0
Epoch:  489       10 Batch loss: 0.223670 Batch F1: 0.0
Epoch:  489       11 Batch loss: 0.206140 Batch F1: 0.0
Epoch:  489       12 Batch loss: 0.223872 Batch F1: 0.0
Train Avg Loss  489: 0.226815

Train Avg F1  489: 0.0

Val Avg Loss  489: 0.219265

Val Avg F1  489:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 490
--------------------------------------------------------------
Epoch:  490        1 Batch loss: 0.222898 Batch F1: 0.0
Epoch:  490        2 Batch loss: 0.208264 Batch F1: 0.39999999999999997
Epoch:  490        3 Batch loss: 0.246676 Batch F1: 0.36363636363636365
Epoch:  490        4 Batch loss: 0.228244 Batch F1: 0.25
Epoch:  490        5 Batch loss: 0.250340 Batch F1: 0.3636363636363636
Epoch:  490        6 Batch loss: 0.246035 Batch F1: 0.0
Epoch:  490        7 Batch loss: 0.193693 Batch F1: 0.0
Epoch:  490        8 Batch loss: 0.227483 Batch F1: 0.0
Epoch:  490        9 Batch loss: 0.236766 Batch F1: 0.0
Epoch:  490       10 Batch loss: 0.219645 Batch F1: 0.0
Epoch:  490       11 Batch loss: 0.224584 Batch F1: 0.0
Epoch:  490       12 Batch loss: 0.215898 Batch F1: 0.0
Train Avg Loss  490: 0.226710

Train Avg F1  490: 0.11477272727272726

Val Avg Loss  490: 0.217174

Val Avg F1  490:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 491
--------------------------------------------------------------
Epoch:  491        1 Batch loss: 0.227863 Batch F1: 0.0
Epoch:  491        2 Batch loss: 0.221542 Batch F1: 0.0
Epoch:  491        3 Batch loss: 0.232309 Batch F1: 0.0
Epoch:  491        4 Batch loss: 0.237470 Batch F1: 0.0
Epoch:  491        5 Batch loss: 0.222528 Batch F1: 0.0
Epoch:  491        6 Batch loss: 0.217681 Batch F1: 0.0
Epoch:  491        7 Batch loss: 0.234600 Batch F1: 0.0
Epoch:  491        8 Batch loss: 0.219127 Batch F1: 0.0
Epoch:  491        9 Batch loss: 0.228141 Batch F1: 0.0
Epoch:  491       10 Batch loss: 0.206408 Batch F1: 0.0
Epoch:  491       11 Batch loss: 0.234410 Batch F1: 0.0
Epoch:  491       12 Batch loss: 0.232968 Batch F1: 0.0
Train Avg Loss  491: 0.226254

Train Avg F1  491: 0.0

Val Avg Loss  491: 0.217558

Val Avg F1  491:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 492
--------------------------------------------------------------
Epoch:  492        1 Batch loss: 0.176975 Batch F1: 0.0
Epoch:  492        2 Batch loss: 0.227376 Batch F1: 0.0
Epoch:  492        3 Batch loss: 0.249817 Batch F1: 0.0
Epoch:  492        4 Batch loss: 0.245555 Batch F1: 0.0
Epoch:  492        5 Batch loss: 0.183843 Batch F1: 0.0
Epoch:  492        6 Batch loss: 0.232055 Batch F1: 0.0
Epoch:  492        7 Batch loss: 0.247411 Batch F1: 0.0
Epoch:  492        8 Batch loss: 0.206456 Batch F1: 0.0
Epoch:  492        9 Batch loss: 0.230774 Batch F1: 0.0
Epoch:  492       10 Batch loss: 0.237871 Batch F1: 0.0
Epoch:  492       11 Batch loss: 0.238449 Batch F1: 0.0
Epoch:  492       12 Batch loss: 0.242924 Batch F1: 0.0
Train Avg Loss  492: 0.226625

Train Avg F1  492: 0.0

Val Avg Loss  492: 0.219376

Val Avg F1  492:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 493
--------------------------------------------------------------
Epoch:  493        1 Batch loss: 0.201040 Batch F1: 0.0
Epoch:  493        2 Batch loss: 0.223956 Batch F1: 0.0
Epoch:  493        3 Batch loss: 0.197349 Batch F1: 0.0
Epoch:  493        4 Batch loss: 0.223151 Batch F1: 0.0
Epoch:  493        5 Batch loss: 0.230705 Batch F1: 0.0
Epoch:  493        6 Batch loss: 0.232288 Batch F1: 0.0
Epoch:  493        7 Batch loss: 0.245545 Batch F1: 0.0
Epoch:  493        8 Batch loss: 0.229898 Batch F1: 0.0
Epoch:  493        9 Batch loss: 0.268252 Batch F1: 0.0
Epoch:  493       10 Batch loss: 0.237599 Batch F1: 0.0
Epoch:  493       11 Batch loss: 0.230858 Batch F1: 0.18181818181818182
Epoch:  493       12 Batch loss: 0.211291 Batch F1: 0.0
Train Avg Loss  493: 0.227661

Train Avg F1  493: 0.015151515151515152

Val Avg Loss  493: 0.224071

Val Avg F1  493:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 494
--------------------------------------------------------------
Epoch:  494        1 Batch loss: 0.232965 Batch F1: 0.0
Epoch:  494        2 Batch loss: 0.236260 Batch F1: 0.30769230769230765
Epoch:  494        3 Batch loss: 0.247254 Batch F1: 0.0
Epoch:  494        4 Batch loss: 0.206338 Batch F1: 0.2727272727272727
Epoch:  494        5 Batch loss: 0.216120 Batch F1: 0.0
Epoch:  494        6 Batch loss: 0.199221 Batch F1: 0.0
Epoch:  494        7 Batch loss: 0.208845 Batch F1: 0.0
Epoch:  494        8 Batch loss: 0.252936 Batch F1: 0.0
Epoch:  494        9 Batch loss: 0.201954 Batch F1: 0.0
Epoch:  494       10 Batch loss: 0.242821 Batch F1: 0.0
Epoch:  494       11 Batch loss: 0.240809 Batch F1: 0.0
Epoch:  494       12 Batch loss: 0.236159 Batch F1: 0.0
Train Avg Loss  494: 0.226807

Train Avg F1  494: 0.04836829836829837

Val Avg Loss  494: 0.217395

Val Avg F1  494:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 495
--------------------------------------------------------------
Epoch:  495        1 Batch loss: 0.246620 Batch F1: 0.0
Epoch:  495        2 Batch loss: 0.208617 Batch F1: 0.0
Epoch:  495        3 Batch loss: 0.221423 Batch F1: 0.0
Epoch:  495        4 Batch loss: 0.263543 Batch F1: 0.0
Epoch:  495        5 Batch loss: 0.241470 Batch F1: 0.0
Epoch:  495        6 Batch loss: 0.212079 Batch F1: 0.0
Epoch:  495        7 Batch loss: 0.238337 Batch F1: 0.0
Epoch:  495        8 Batch loss: 0.222012 Batch F1: 0.0
Epoch:  495        9 Batch loss: 0.216481 Batch F1: 0.0
Epoch:  495       10 Batch loss: 0.199378 Batch F1: 0.0
Epoch:  495       11 Batch loss: 0.223862 Batch F1: 0.0
Epoch:  495       12 Batch loss: 0.249420 Batch F1: 0.0
Train Avg Loss  495: 0.228604

Train Avg F1  495: 0.0

Val Avg Loss  495: 0.218311

Val Avg F1  495:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 496
--------------------------------------------------------------
Epoch:  496        1 Batch loss: 0.277119 Batch F1: 0.0
Epoch:  496        2 Batch loss: 0.225995 Batch F1: 0.0
Epoch:  496        3 Batch loss: 0.212552 Batch F1: 0.0
Epoch:  496        4 Batch loss: 0.237009 Batch F1: 0.0
Epoch:  496        5 Batch loss: 0.239285 Batch F1: 0.0
Epoch:  496        6 Batch loss: 0.239997 Batch F1: 0.3448275862068965
Epoch:  496        7 Batch loss: 0.220767 Batch F1: 0.27272727272727276
Epoch:  496        8 Batch loss: 0.238599 Batch F1: 0.0
Epoch:  496        9 Batch loss: 0.233024 Batch F1: 0.0
Epoch:  496       10 Batch loss: 0.208269 Batch F1: 0.0
Epoch:  496       11 Batch loss: 0.193784 Batch F1: 0.0
Epoch:  496       12 Batch loss: 0.220749 Batch F1: 0.0
Train Avg Loss  496: 0.228929

Train Avg F1  496: 0.051462904911180773

Val Avg Loss  496: 0.222943

Val Avg F1  496:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 497
--------------------------------------------------------------
Epoch:  497        1 Batch loss: 0.226840 Batch F1: 0.0
Epoch:  497        2 Batch loss: 0.247482 Batch F1: 0.0
Epoch:  497        3 Batch loss: 0.265680 Batch F1: 0.0
Epoch:  497        4 Batch loss: 0.243799 Batch F1: 0.0
Epoch:  497        5 Batch loss: 0.224439 Batch F1: 0.0
Epoch:  497        6 Batch loss: 0.234427 Batch F1: 0.0
Epoch:  497        7 Batch loss: 0.233384 Batch F1: 0.0
Epoch:  497        8 Batch loss: 0.210255 Batch F1: 0.0
Epoch:  497        9 Batch loss: 0.194009 Batch F1: 0.0
Epoch:  497       10 Batch loss: 0.228311 Batch F1: 0.0
Epoch:  497       11 Batch loss: 0.252177 Batch F1: 0.0
Epoch:  497       12 Batch loss: 0.254231 Batch F1: 0.0
Train Avg Loss  497: 0.234586

Train Avg F1  497: 0.0

Val Avg Loss  497: 0.221819

Val Avg F1  497:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 498
--------------------------------------------------------------
Epoch:  498        1 Batch loss: 0.198454 Batch F1: 0.0
Epoch:  498        2 Batch loss: 0.226275 Batch F1: 0.0
Epoch:  498        3 Batch loss: 0.264547 Batch F1: 0.0
Epoch:  498        4 Batch loss: 0.213944 Batch F1: 0.0
Epoch:  498        5 Batch loss: 0.237819 Batch F1: 0.0
Epoch:  498        6 Batch loss: 0.205847 Batch F1: 0.0
Epoch:  498        7 Batch loss: 0.248846 Batch F1: 0.0
Epoch:  498        8 Batch loss: 0.232956 Batch F1: 0.0
Epoch:  498        9 Batch loss: 0.198014 Batch F1: 0.0
Epoch:  498       10 Batch loss: 0.241679 Batch F1: 0.0
Epoch:  498       11 Batch loss: 0.264399 Batch F1: 0.0
Epoch:  498       12 Batch loss: 0.218077 Batch F1: 0.0
Train Avg Loss  498: 0.229238

Train Avg F1  498: 0.0

Val Avg Loss  498: 0.219988

Val Avg F1  498:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 499
--------------------------------------------------------------
Epoch:  499        1 Batch loss: 0.234951 Batch F1: 0.0
Epoch:  499        2 Batch loss: 0.230916 Batch F1: 0.0
Epoch:  499        3 Batch loss: 0.235088 Batch F1: 0.0
Epoch:  499        4 Batch loss: 0.218776 Batch F1: 0.0
Epoch:  499        5 Batch loss: 0.235235 Batch F1: 0.0
Epoch:  499        6 Batch loss: 0.247544 Batch F1: 0.0
Epoch:  499        7 Batch loss: 0.232795 Batch F1: 0.5333333333333333
Epoch:  499        8 Batch loss: 0.223272 Batch F1: 0.3333333333333333
Epoch:  499        9 Batch loss: 0.211925 Batch F1: 0.0
Epoch:  499       10 Batch loss: 0.230812 Batch F1: 0.0
Epoch:  499       11 Batch loss: 0.208239 Batch F1: 0.0
Epoch:  499       12 Batch loss: 0.231199 Batch F1: 0.0
Train Avg Loss  499: 0.228396

Train Avg F1  499: 0.07222222222222223

Val Avg Loss  499: 0.220848

Val Avg F1  499:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 500
--------------------------------------------------------------
Epoch:  500        1 Batch loss: 0.191821 Batch F1: 0.0
Epoch:  500        2 Batch loss: 0.235130 Batch F1: 0.0
Epoch:  500        3 Batch loss: 0.205047 Batch F1: 0.0
Epoch:  500        4 Batch loss: 0.239223 Batch F1: 0.0
Epoch:  500        5 Batch loss: 0.206449 Batch F1: 0.0
Epoch:  500        6 Batch loss: 0.206498 Batch F1: 0.0
Epoch:  500        7 Batch loss: 0.258398 Batch F1: 0.0
Epoch:  500        8 Batch loss: 0.242274 Batch F1: 0.0
Epoch:  500        9 Batch loss: 0.244046 Batch F1: 0.0
Epoch:  500       10 Batch loss: 0.244856 Batch F1: 0.0
Epoch:  500       11 Batch loss: 0.234533 Batch F1: 0.0
Epoch:  500       12 Batch loss: 0.232657 Batch F1: 0.10526315789473682
Train Avg Loss  500: 0.228411

Train Avg F1  500: 0.008771929824561401

Val Avg Loss  500: 0.232045

Val Avg F1  500:  0.3873376623376623

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 501
--------------------------------------------------------------
Epoch:  501        1 Batch loss: 0.231776 Batch F1: 0.32
Epoch:  501        2 Batch loss: 0.231633 Batch F1: 0.42857142857142855
Epoch:  501        3 Batch loss: 0.240868 Batch F1: 0.0
Epoch:  501        4 Batch loss: 0.250425 Batch F1: 0.0
Epoch:  501        5 Batch loss: 0.251125 Batch F1: 0.0
Epoch:  501        6 Batch loss: 0.227397 Batch F1: 0.0
Epoch:  501        7 Batch loss: 0.204869 Batch F1: 0.0
Epoch:  501        8 Batch loss: 0.233766 Batch F1: 0.0
Epoch:  501        9 Batch loss: 0.216749 Batch F1: 0.0
Epoch:  501       10 Batch loss: 0.222074 Batch F1: 0.0
Epoch:  501       11 Batch loss: 0.200983 Batch F1: 0.0
Epoch:  501       12 Batch loss: 0.228510 Batch F1: 0.0
Train Avg Loss  501: 0.228348

Train Avg F1  501: 0.06238095238095238

Val Avg Loss  501: 0.217583

Val Avg F1  501:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 502
--------------------------------------------------------------
Epoch:  502        1 Batch loss: 0.204190 Batch F1: 0.0
Epoch:  502        2 Batch loss: 0.232487 Batch F1: 0.0
Epoch:  502        3 Batch loss: 0.224232 Batch F1: 0.0
Epoch:  502        4 Batch loss: 0.223493 Batch F1: 0.0
Epoch:  502        5 Batch loss: 0.223688 Batch F1: 0.0
Epoch:  502        6 Batch loss: 0.230153 Batch F1: 0.0
Epoch:  502        7 Batch loss: 0.246422 Batch F1: 0.0
Epoch:  502        8 Batch loss: 0.226540 Batch F1: 0.0
Epoch:  502        9 Batch loss: 0.223728 Batch F1: 0.0
Epoch:  502       10 Batch loss: 0.225980 Batch F1: 0.0
Epoch:  502       11 Batch loss: 0.227073 Batch F1: 0.0
Epoch:  502       12 Batch loss: 0.245708 Batch F1: 0.0
Train Avg Loss  502: 0.227808

Train Avg F1  502: 0.0

Val Avg Loss  502: 0.218891

Val Avg F1  502:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 503
--------------------------------------------------------------
Epoch:  503        1 Batch loss: 0.238073 Batch F1: 0.0
Epoch:  503        2 Batch loss: 0.222791 Batch F1: 0.0
Epoch:  503        3 Batch loss: 0.229125 Batch F1: 0.0
Epoch:  503        4 Batch loss: 0.224729 Batch F1: 0.0
Epoch:  503        5 Batch loss: 0.203118 Batch F1: 0.0
Epoch:  503        6 Batch loss: 0.224113 Batch F1: 0.0
Epoch:  503        7 Batch loss: 0.213144 Batch F1: 0.0
Epoch:  503        8 Batch loss: 0.202386 Batch F1: 0.0
Epoch:  503        9 Batch loss: 0.253854 Batch F1: 0.0
Epoch:  503       10 Batch loss: 0.242721 Batch F1: 0.0
Epoch:  503       11 Batch loss: 0.253060 Batch F1: 0.0
Epoch:  503       12 Batch loss: 0.216091 Batch F1: 0.0
Train Avg Loss  503: 0.226934

Train Avg F1  503: 0.0

Val Avg Loss  503: 0.220412

Val Avg F1  503:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 504
--------------------------------------------------------------
Epoch:  504        1 Batch loss: 0.216399 Batch F1: 0.0
Epoch:  504        2 Batch loss: 0.222206 Batch F1: 0.0
Epoch:  504        3 Batch loss: 0.226186 Batch F1: 0.0
Epoch:  504        4 Batch loss: 0.226369 Batch F1: 0.0
Epoch:  504        5 Batch loss: 0.203303 Batch F1: 0.0
Epoch:  504        6 Batch loss: 0.244024 Batch F1: 0.0
Epoch:  504        7 Batch loss: 0.233616 Batch F1: 0.0
Epoch:  504        8 Batch loss: 0.253989 Batch F1: 0.0
Epoch:  504        9 Batch loss: 0.209714 Batch F1: 0.0
Epoch:  504       10 Batch loss: 0.219212 Batch F1: 0.0
Epoch:  504       11 Batch loss: 0.247308 Batch F1: 0.0
Epoch:  504       12 Batch loss: 0.223279 Batch F1: 0.0
Train Avg Loss  504: 0.227134

Train Avg F1  504: 0.0

Val Avg Loss  504: 0.219190

Val Avg F1  504:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 505
--------------------------------------------------------------
Epoch:  505        1 Batch loss: 0.241110 Batch F1: 0.0
Epoch:  505        2 Batch loss: 0.236126 Batch F1: 0.0
Epoch:  505        3 Batch loss: 0.226150 Batch F1: 0.0
Epoch:  505        4 Batch loss: 0.228884 Batch F1: 0.0
Epoch:  505        5 Batch loss: 0.232665 Batch F1: 0.0
Epoch:  505        6 Batch loss: 0.224092 Batch F1: 0.0
Epoch:  505        7 Batch loss: 0.208074 Batch F1: 0.0
Epoch:  505        8 Batch loss: 0.226687 Batch F1: 0.0
Epoch:  505        9 Batch loss: 0.238576 Batch F1: 0.0
Epoch:  505       10 Batch loss: 0.244790 Batch F1: 0.0
Epoch:  505       11 Batch loss: 0.181400 Batch F1: 0.26666666666666666
Epoch:  505       12 Batch loss: 0.238225 Batch F1: 0.0
Train Avg Loss  505: 0.227232

Train Avg F1  505: 0.022222222222222223

Val Avg Loss  505: 0.218695

Val Avg F1  505:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 506
--------------------------------------------------------------
Epoch:  506        1 Batch loss: 0.206036 Batch F1: 0.0
Epoch:  506        2 Batch loss: 0.231675 Batch F1: 0.0
Epoch:  506        3 Batch loss: 0.197996 Batch F1: 0.0
Epoch:  506        4 Batch loss: 0.236052 Batch F1: 0.0
Epoch:  506        5 Batch loss: 0.216254 Batch F1: 0.0
Epoch:  506        6 Batch loss: 0.239663 Batch F1: 0.0
Epoch:  506        7 Batch loss: 0.224488 Batch F1: 0.0
Epoch:  506        8 Batch loss: 0.224791 Batch F1: 0.0
Epoch:  506        9 Batch loss: 0.251325 Batch F1: 0.0
Epoch:  506       10 Batch loss: 0.232679 Batch F1: 0.0
Epoch:  506       11 Batch loss: 0.207509 Batch F1: 0.0
Epoch:  506       12 Batch loss: 0.265196 Batch F1: 0.0
Train Avg Loss  506: 0.227805

Train Avg F1  506: 0.0

Val Avg Loss  506: 0.220537

Val Avg F1  506:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 507
--------------------------------------------------------------
Epoch:  507        1 Batch loss: 0.242894 Batch F1: 0.0
Epoch:  507        2 Batch loss: 0.222024 Batch F1: 0.25
Epoch:  507        3 Batch loss: 0.238478 Batch F1: 0.4848484848484849
Epoch:  507        4 Batch loss: 0.227256 Batch F1: 0.3846153846153846
Epoch:  507        5 Batch loss: 0.230820 Batch F1: 0.3448275862068965
Epoch:  507        6 Batch loss: 0.202655 Batch F1: 0.5384615384615384
Epoch:  507        7 Batch loss: 0.225130 Batch F1: 0.0
Epoch:  507        8 Batch loss: 0.236400 Batch F1: 0.0
Epoch:  507        9 Batch loss: 0.253874 Batch F1: 0.0
Epoch:  507       10 Batch loss: 0.216181 Batch F1: 0.0
Epoch:  507       11 Batch loss: 0.218274 Batch F1: 0.0
Epoch:  507       12 Batch loss: 0.250173 Batch F1: 0.0
Train Avg Loss  507: 0.230346

Train Avg F1  507: 0.16689608284435872

Val Avg Loss  507: 0.221002

Val Avg F1  507:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 508
--------------------------------------------------------------
Epoch:  508        1 Batch loss: 0.192313 Batch F1: 0.0
Epoch:  508        2 Batch loss: 0.224009 Batch F1: 0.0
Epoch:  508        3 Batch loss: 0.230196 Batch F1: 0.0
Epoch:  508        4 Batch loss: 0.252780 Batch F1: 0.0
Epoch:  508        5 Batch loss: 0.223676 Batch F1: 0.0
Epoch:  508        6 Batch loss: 0.229364 Batch F1: 0.0
Epoch:  508        7 Batch loss: 0.246228 Batch F1: 0.0
Epoch:  508        8 Batch loss: 0.215785 Batch F1: 0.0
Epoch:  508        9 Batch loss: 0.241844 Batch F1: 0.0
Epoch:  508       10 Batch loss: 0.222256 Batch F1: 0.0
Epoch:  508       11 Batch loss: 0.238727 Batch F1: 0.0
Epoch:  508       12 Batch loss: 0.240768 Batch F1: 0.0
Train Avg Loss  508: 0.229829

Train Avg F1  508: 0.0

Val Avg Loss  508: 0.220845

Val Avg F1  508:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 509
--------------------------------------------------------------
Epoch:  509        1 Batch loss: 0.220273 Batch F1: 0.0
Epoch:  509        2 Batch loss: 0.220358 Batch F1: 0.0
Epoch:  509        3 Batch loss: 0.235671 Batch F1: 0.0
Epoch:  509        4 Batch loss: 0.222239 Batch F1: 0.0
Epoch:  509        5 Batch loss: 0.188101 Batch F1: 0.0
Epoch:  509        6 Batch loss: 0.242268 Batch F1: 0.0
Epoch:  509        7 Batch loss: 0.204522 Batch F1: 0.0
Epoch:  509        8 Batch loss: 0.230344 Batch F1: 0.0
Epoch:  509        9 Batch loss: 0.244889 Batch F1: 0.0
Epoch:  509       10 Batch loss: 0.275224 Batch F1: 0.0
Epoch:  509       11 Batch loss: 0.247282 Batch F1: 0.0
Epoch:  509       12 Batch loss: 0.247555 Batch F1: 0.0
Train Avg Loss  509: 0.231560

Train Avg F1  509: 0.0

Val Avg Loss  509: 0.223950

Val Avg F1  509:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 510
--------------------------------------------------------------
Epoch:  510        1 Batch loss: 0.233367 Batch F1: 0.0
Epoch:  510        2 Batch loss: 0.229606 Batch F1: 0.0
Epoch:  510        3 Batch loss: 0.215953 Batch F1: 0.0
Epoch:  510        4 Batch loss: 0.243116 Batch F1: 0.0
Epoch:  510        5 Batch loss: 0.223926 Batch F1: 0.0
Epoch:  510        6 Batch loss: 0.220800 Batch F1: 0.0
Epoch:  510        7 Batch loss: 0.245134 Batch F1: 0.0
Epoch:  510        8 Batch loss: 0.220890 Batch F1: 0.0
Epoch:  510        9 Batch loss: 0.256127 Batch F1: 0.0
Epoch:  510       10 Batch loss: 0.218188 Batch F1: 0.0
Epoch:  510       11 Batch loss: 0.229323 Batch F1: 0.0
Epoch:  510       12 Batch loss: 0.224837 Batch F1: 0.0
Train Avg Loss  510: 0.230105

Train Avg F1  510: 0.0

Val Avg Loss  510: 0.220791

Val Avg F1  510:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 511
--------------------------------------------------------------
Epoch:  511        1 Batch loss: 0.225150 Batch F1: 0.0
Epoch:  511        2 Batch loss: 0.192298 Batch F1: 0.0
Epoch:  511        3 Batch loss: 0.210297 Batch F1: 0.0
Epoch:  511        4 Batch loss: 0.235701 Batch F1: 0.0
Epoch:  511        5 Batch loss: 0.233979 Batch F1: 0.0
Epoch:  511        6 Batch loss: 0.252397 Batch F1: 0.0
Epoch:  511        7 Batch loss: 0.238216 Batch F1: 0.0
Epoch:  511        8 Batch loss: 0.245623 Batch F1: 0.0
Epoch:  511        9 Batch loss: 0.187100 Batch F1: 0.0
Epoch:  511       10 Batch loss: 0.268511 Batch F1: 0.0
Epoch:  511       11 Batch loss: 0.233052 Batch F1: 0.0
Epoch:  511       12 Batch loss: 0.245022 Batch F1: 0.0
Train Avg Loss  511: 0.230612

Train Avg F1  511: 0.0

Val Avg Loss  511: 0.226894

Val Avg F1  511:  0.30599033816425125

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 512
--------------------------------------------------------------
Epoch:  512        1 Batch loss: 0.252367 Batch F1: 0.15384615384615385
Epoch:  512        2 Batch loss: 0.231959 Batch F1: 0.3225806451612903
Epoch:  512        3 Batch loss: 0.232720 Batch F1: 0.5
Epoch:  512        4 Batch loss: 0.248732 Batch F1: 0.4827586206896552
Epoch:  512        5 Batch loss: 0.211328 Batch F1: 0.5217391304347826
Epoch:  512        6 Batch loss: 0.238883 Batch F1: 0.0
Epoch:  512        7 Batch loss: 0.221456 Batch F1: 0.0
Epoch:  512        8 Batch loss: 0.235975 Batch F1: 0.0
Epoch:  512        9 Batch loss: 0.242480 Batch F1: 0.0
Epoch:  512       10 Batch loss: 0.213391 Batch F1: 0.0
Epoch:  512       11 Batch loss: 0.230254 Batch F1: 0.0
Epoch:  512       12 Batch loss: 0.229977 Batch F1: 0.0
Train Avg Loss  512: 0.232460

Train Avg F1  512: 0.1650770458443235

Val Avg Loss  512: 0.219131

Val Avg F1  512:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 513
--------------------------------------------------------------
Epoch:  513        1 Batch loss: 0.210681 Batch F1: 0.0
Epoch:  513        2 Batch loss: 0.232333 Batch F1: 0.0
Epoch:  513        3 Batch loss: 0.249487 Batch F1: 0.0
Epoch:  513        4 Batch loss: 0.236120 Batch F1: 0.0
Epoch:  513        5 Batch loss: 0.229781 Batch F1: 0.0
Epoch:  513        6 Batch loss: 0.244881 Batch F1: 0.0
Epoch:  513        7 Batch loss: 0.210495 Batch F1: 0.0
Epoch:  513        8 Batch loss: 0.204650 Batch F1: 0.0
Epoch:  513        9 Batch loss: 0.269753 Batch F1: 0.0
Epoch:  513       10 Batch loss: 0.196528 Batch F1: 0.0
Epoch:  513       11 Batch loss: 0.232028 Batch F1: 0.0
Epoch:  513       12 Batch loss: 0.238586 Batch F1: 0.0
Train Avg Loss  513: 0.229610

Train Avg F1  513: 0.0

Val Avg Loss  513: 0.218361

Val Avg F1  513:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 514
--------------------------------------------------------------
Epoch:  514        1 Batch loss: 0.215482 Batch F1: 0.0
Epoch:  514        2 Batch loss: 0.231481 Batch F1: 0.0
Epoch:  514        3 Batch loss: 0.207573 Batch F1: 0.0
Epoch:  514        4 Batch loss: 0.201039 Batch F1: 0.0
Epoch:  514        5 Batch loss: 0.225097 Batch F1: 0.0
Epoch:  514        6 Batch loss: 0.253530 Batch F1: 0.0
Epoch:  514        7 Batch loss: 0.224983 Batch F1: 0.0
Epoch:  514        8 Batch loss: 0.253161 Batch F1: 0.0
Epoch:  514        9 Batch loss: 0.231824 Batch F1: 0.0
Epoch:  514       10 Batch loss: 0.231030 Batch F1: 0.0
Epoch:  514       11 Batch loss: 0.245367 Batch F1: 0.0
Epoch:  514       12 Batch loss: 0.207912 Batch F1: 0.0
Train Avg Loss  514: 0.227373

Train Avg F1  514: 0.0

Val Avg Loss  514: 0.219302

Val Avg F1  514:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 515
--------------------------------------------------------------
Epoch:  515        1 Batch loss: 0.210355 Batch F1: 0.0
Epoch:  515        2 Batch loss: 0.199212 Batch F1: 0.0
Epoch:  515        3 Batch loss: 0.228647 Batch F1: 0.0
Epoch:  515        4 Batch loss: 0.197590 Batch F1: 0.0
Epoch:  515        5 Batch loss: 0.234748 Batch F1: 0.0
Epoch:  515        6 Batch loss: 0.254674 Batch F1: 0.0
Epoch:  515        7 Batch loss: 0.236221 Batch F1: 0.0
Epoch:  515        8 Batch loss: 0.255591 Batch F1: 0.0
Epoch:  515        9 Batch loss: 0.210296 Batch F1: 0.0
Epoch:  515       10 Batch loss: 0.219543 Batch F1: 0.0
Epoch:  515       11 Batch loss: 0.260439 Batch F1: 0.0
Epoch:  515       12 Batch loss: 0.221978 Batch F1: 0.0
Train Avg Loss  515: 0.227441

Train Avg F1  515: 0.0

Val Avg Loss  515: 0.218127

Val Avg F1  515:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 516
--------------------------------------------------------------
Epoch:  516        1 Batch loss: 0.197319 Batch F1: 0.0
Epoch:  516        2 Batch loss: 0.238904 Batch F1: 0.0
Epoch:  516        3 Batch loss: 0.249319 Batch F1: 0.0
Epoch:  516        4 Batch loss: 0.230745 Batch F1: 0.0
Epoch:  516        5 Batch loss: 0.210087 Batch F1: 0.0
Epoch:  516        6 Batch loss: 0.216109 Batch F1: 0.0
Epoch:  516        7 Batch loss: 0.240167 Batch F1: 0.0
Epoch:  516        8 Batch loss: 0.225523 Batch F1: 0.0
Epoch:  516        9 Batch loss: 0.201357 Batch F1: 0.0
Epoch:  516       10 Batch loss: 0.241393 Batch F1: 0.0
Epoch:  516       11 Batch loss: 0.219904 Batch F1: 0.0
Epoch:  516       12 Batch loss: 0.254088 Batch F1: 0.0
Train Avg Loss  516: 0.227076

Train Avg F1  516: 0.0

Val Avg Loss  516: 0.218020

Val Avg F1  516:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 517
--------------------------------------------------------------
Epoch:  517        1 Batch loss: 0.221058 Batch F1: 0.0
Epoch:  517        2 Batch loss: 0.235186 Batch F1: 0.0
Epoch:  517        3 Batch loss: 0.215482 Batch F1: 0.0
Epoch:  517        4 Batch loss: 0.226580 Batch F1: 0.0
Epoch:  517        5 Batch loss: 0.240107 Batch F1: 0.0
Epoch:  517        6 Batch loss: 0.199066 Batch F1: 0.0
Epoch:  517        7 Batch loss: 0.230339 Batch F1: 0.0
Epoch:  517        8 Batch loss: 0.212245 Batch F1: 0.0
Epoch:  517        9 Batch loss: 0.238093 Batch F1: 0.0
Epoch:  517       10 Batch loss: 0.222179 Batch F1: 0.0
Epoch:  517       11 Batch loss: 0.238605 Batch F1: 0.0
Epoch:  517       12 Batch loss: 0.238477 Batch F1: 0.0
Train Avg Loss  517: 0.226451

Train Avg F1  517: 0.0

Val Avg Loss  517: 0.218212

Val Avg F1  517:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 518
--------------------------------------------------------------
Epoch:  518        1 Batch loss: 0.229580 Batch F1: 0.0
Epoch:  518        2 Batch loss: 0.244539 Batch F1: 0.0
Epoch:  518        3 Batch loss: 0.209007 Batch F1: 0.0
Epoch:  518        4 Batch loss: 0.226469 Batch F1: 0.0
Epoch:  518        5 Batch loss: 0.222437 Batch F1: 0.0
Epoch:  518        6 Batch loss: 0.210098 Batch F1: 0.0
Epoch:  518        7 Batch loss: 0.256701 Batch F1: 0.0
Epoch:  518        8 Batch loss: 0.223800 Batch F1: 0.0
Epoch:  518        9 Batch loss: 0.238247 Batch F1: 0.0
Epoch:  518       10 Batch loss: 0.217658 Batch F1: 0.48
Epoch:  518       11 Batch loss: 0.228759 Batch F1: 0.0
Epoch:  518       12 Batch loss: 0.211261 Batch F1: 0.0
Train Avg Loss  518: 0.226546

Train Avg F1  518: 0.04

Val Avg Loss  518: 0.218004

Val Avg F1  518:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 519
--------------------------------------------------------------
Epoch:  519        1 Batch loss: 0.218280 Batch F1: 0.0
Epoch:  519        2 Batch loss: 0.246829 Batch F1: 0.0
Epoch:  519        3 Batch loss: 0.242677 Batch F1: 0.0
Epoch:  519        4 Batch loss: 0.220582 Batch F1: 0.0
Epoch:  519        5 Batch loss: 0.242144 Batch F1: 0.0
Epoch:  519        6 Batch loss: 0.218321 Batch F1: 0.0
Epoch:  519        7 Batch loss: 0.196977 Batch F1: 0.0
Epoch:  519        8 Batch loss: 0.259868 Batch F1: 0.0
Epoch:  519        9 Batch loss: 0.213696 Batch F1: 0.0
Epoch:  519       10 Batch loss: 0.225071 Batch F1: 0.0
Epoch:  519       11 Batch loss: 0.213864 Batch F1: 0.0
Epoch:  519       12 Batch loss: 0.219663 Batch F1: 0.0
Train Avg Loss  519: 0.226498

Train Avg F1  519: 0.0

Val Avg Loss  519: 0.217047

Val Avg F1  519:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 520
--------------------------------------------------------------
Epoch:  520        1 Batch loss: 0.235553 Batch F1: 0.0
Epoch:  520        2 Batch loss: 0.222250 Batch F1: 0.0
Epoch:  520        3 Batch loss: 0.207319 Batch F1: 0.0
Epoch:  520        4 Batch loss: 0.213358 Batch F1: 0.0
Epoch:  520        5 Batch loss: 0.225140 Batch F1: 0.0
Epoch:  520        6 Batch loss: 0.212781 Batch F1: 0.0
Epoch:  520        7 Batch loss: 0.209521 Batch F1: 0.0
Epoch:  520        8 Batch loss: 0.237628 Batch F1: 0.0
Epoch:  520        9 Batch loss: 0.249000 Batch F1: 0.0
Epoch:  520       10 Batch loss: 0.212215 Batch F1: 0.0
Epoch:  520       11 Batch loss: 0.232065 Batch F1: 0.0
Epoch:  520       12 Batch loss: 0.262467 Batch F1: 0.0
Train Avg Loss  520: 0.226608

Train Avg F1  520: 0.0

Val Avg Loss  520: 0.217870

Val Avg F1  520:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 521
--------------------------------------------------------------
Epoch:  521        1 Batch loss: 0.231760 Batch F1: 0.0
Epoch:  521        2 Batch loss: 0.234631 Batch F1: 0.0
Epoch:  521        3 Batch loss: 0.258970 Batch F1: 0.0
Epoch:  521        4 Batch loss: 0.222499 Batch F1: 0.0
Epoch:  521        5 Batch loss: 0.193002 Batch F1: 0.0
Epoch:  521        6 Batch loss: 0.213875 Batch F1: 0.0
Epoch:  521        7 Batch loss: 0.208115 Batch F1: 0.0
Epoch:  521        8 Batch loss: 0.223807 Batch F1: 0.0
Epoch:  521        9 Batch loss: 0.219507 Batch F1: 0.0
Epoch:  521       10 Batch loss: 0.241414 Batch F1: 0.0
Epoch:  521       11 Batch loss: 0.213896 Batch F1: 0.0
Epoch:  521       12 Batch loss: 0.261629 Batch F1: 0.0
Train Avg Loss  521: 0.226925

Train Avg F1  521: 0.0

Val Avg Loss  521: 0.217541

Val Avg F1  521:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 522
--------------------------------------------------------------
Epoch:  522        1 Batch loss: 0.214272 Batch F1: 0.0
Epoch:  522        2 Batch loss: 0.226336 Batch F1: 0.0
Epoch:  522        3 Batch loss: 0.238248 Batch F1: 0.0
Epoch:  522        4 Batch loss: 0.248142 Batch F1: 0.0
Epoch:  522        5 Batch loss: 0.233484 Batch F1: 0.24
Epoch:  522        6 Batch loss: 0.224705 Batch F1: 0.41379310344827586
Epoch:  522        7 Batch loss: 0.207521 Batch F1: 0.0
Epoch:  522        8 Batch loss: 0.216380 Batch F1: 0.0
Epoch:  522        9 Batch loss: 0.225124 Batch F1: 0.0
Epoch:  522       10 Batch loss: 0.250646 Batch F1: 0.0
Epoch:  522       11 Batch loss: 0.217657 Batch F1: 0.0
Epoch:  522       12 Batch loss: 0.212297 Batch F1: 0.0
Train Avg Loss  522: 0.226234

Train Avg F1  522: 0.05448275862068965

Val Avg Loss  522: 0.217734

Val Avg F1  522:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 523
--------------------------------------------------------------
Epoch:  523        1 Batch loss: 0.202001 Batch F1: 0.0
Epoch:  523        2 Batch loss: 0.212670 Batch F1: 0.0
Epoch:  523        3 Batch loss: 0.209784 Batch F1: 0.0
Epoch:  523        4 Batch loss: 0.268819 Batch F1: 0.0
Epoch:  523        5 Batch loss: 0.255309 Batch F1: 0.0
Epoch:  523        6 Batch loss: 0.227432 Batch F1: 0.0
Epoch:  523        7 Batch loss: 0.213102 Batch F1: 0.0
Epoch:  523        8 Batch loss: 0.229553 Batch F1: 0.0
Epoch:  523        9 Batch loss: 0.224334 Batch F1: 0.0
Epoch:  523       10 Batch loss: 0.241715 Batch F1: 0.0
Epoch:  523       11 Batch loss: 0.242756 Batch F1: 0.0
Epoch:  523       12 Batch loss: 0.227004 Batch F1: 0.0
Train Avg Loss  523: 0.229540

Train Avg F1  523: 0.0

Val Avg Loss  523: 0.222930

Val Avg F1  523:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 524
--------------------------------------------------------------
Epoch:  524        1 Batch loss: 0.247694 Batch F1: 0.0
Epoch:  524        2 Batch loss: 0.235871 Batch F1: 0.0
Epoch:  524        3 Batch loss: 0.223481 Batch F1: 0.0
Epoch:  524        4 Batch loss: 0.206342 Batch F1: 0.0
Epoch:  524        5 Batch loss: 0.252710 Batch F1: 0.0
Epoch:  524        6 Batch loss: 0.211511 Batch F1: 0.0
Epoch:  524        7 Batch loss: 0.274592 Batch F1: 0.0
Epoch:  524        8 Batch loss: 0.225899 Batch F1: 0.0
Epoch:  524        9 Batch loss: 0.208043 Batch F1: 0.0
Epoch:  524       10 Batch loss: 0.218382 Batch F1: 0.0
Epoch:  524       11 Batch loss: 0.208981 Batch F1: 0.0
Epoch:  524       12 Batch loss: 0.205942 Batch F1: 0.0
Train Avg Loss  524: 0.226621

Train Avg F1  524: 0.0

Val Avg Loss  524: 0.216865

Val Avg F1  524:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 525
--------------------------------------------------------------
Epoch:  525        1 Batch loss: 0.217802 Batch F1: 0.0
Epoch:  525        2 Batch loss: 0.221470 Batch F1: 0.0
Epoch:  525        3 Batch loss: 0.255631 Batch F1: 0.0
Epoch:  525        4 Batch loss: 0.201407 Batch F1: 0.0
Epoch:  525        5 Batch loss: 0.219000 Batch F1: 0.0
Epoch:  525        6 Batch loss: 0.264905 Batch F1: 0.0
Epoch:  525        7 Batch loss: 0.204264 Batch F1: 0.0
Epoch:  525        8 Batch loss: 0.215841 Batch F1: 0.0
Epoch:  525        9 Batch loss: 0.229342 Batch F1: 0.0
Epoch:  525       10 Batch loss: 0.244226 Batch F1: 0.0
Epoch:  525       11 Batch loss: 0.231797 Batch F1: 0.0
Epoch:  525       12 Batch loss: 0.214880 Batch F1: 0.0
Train Avg Loss  525: 0.226714

Train Avg F1  525: 0.0

Val Avg Loss  525: 0.217239

Val Avg F1  525:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 526
--------------------------------------------------------------
Epoch:  526        1 Batch loss: 0.222710 Batch F1: 0.0
Epoch:  526        2 Batch loss: 0.222189 Batch F1: 0.0
Epoch:  526        3 Batch loss: 0.236686 Batch F1: 0.0
Epoch:  526        4 Batch loss: 0.236506 Batch F1: 0.0
Epoch:  526        5 Batch loss: 0.227703 Batch F1: 0.0
Epoch:  526        6 Batch loss: 0.251779 Batch F1: 0.0
Epoch:  526        7 Batch loss: 0.205393 Batch F1: 0.0
Epoch:  526        8 Batch loss: 0.201948 Batch F1: 0.0
Epoch:  526        9 Batch loss: 0.246624 Batch F1: 0.0
Epoch:  526       10 Batch loss: 0.226743 Batch F1: 0.0
Epoch:  526       11 Batch loss: 0.228633 Batch F1: 0.09523809523809523
Epoch:  526       12 Batch loss: 0.200387 Batch F1: 0.35294117647058826
Train Avg Loss  526: 0.225608

Train Avg F1  526: 0.03734827264239029

Val Avg Loss  526: 0.218752

Val Avg F1  526:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 527
--------------------------------------------------------------
Epoch:  527        1 Batch loss: 0.219746 Batch F1: 0.0
Epoch:  527        2 Batch loss: 0.241190 Batch F1: 0.0
Epoch:  527        3 Batch loss: 0.206524 Batch F1: 0.0
Epoch:  527        4 Batch loss: 0.227256 Batch F1: 0.0
Epoch:  527        5 Batch loss: 0.211131 Batch F1: 0.0
Epoch:  527        6 Batch loss: 0.198533 Batch F1: 0.0
Epoch:  527        7 Batch loss: 0.263115 Batch F1: 0.0
Epoch:  527        8 Batch loss: 0.248371 Batch F1: 0.0
Epoch:  527        9 Batch loss: 0.225047 Batch F1: 0.0
Epoch:  527       10 Batch loss: 0.244889 Batch F1: 0.0
Epoch:  527       11 Batch loss: 0.243299 Batch F1: 0.0
Epoch:  527       12 Batch loss: 0.188746 Batch F1: 0.0
Train Avg Loss  527: 0.226487

Train Avg F1  527: 0.0

Val Avg Loss  527: 0.219216

Val Avg F1  527:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 528
--------------------------------------------------------------
Epoch:  528        1 Batch loss: 0.191463 Batch F1: 0.0
Epoch:  528        2 Batch loss: 0.233598 Batch F1: 0.0
Epoch:  528        3 Batch loss: 0.254792 Batch F1: 0.0
Epoch:  528        4 Batch loss: 0.204389 Batch F1: 0.0
Epoch:  528        5 Batch loss: 0.274987 Batch F1: 0.0
Epoch:  528        6 Batch loss: 0.248915 Batch F1: 0.0
Epoch:  528        7 Batch loss: 0.235976 Batch F1: 0.0
Epoch:  528        8 Batch loss: 0.235657 Batch F1: 0.0
Epoch:  528        9 Batch loss: 0.213722 Batch F1: 0.0
Epoch:  528       10 Batch loss: 0.221480 Batch F1: 0.0
Epoch:  528       11 Batch loss: 0.204476 Batch F1: 0.0
Epoch:  528       12 Batch loss: 0.221819 Batch F1: 0.0
Train Avg Loss  528: 0.228439

Train Avg F1  528: 0.0

Val Avg Loss  528: 0.218540

Val Avg F1  528:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 529
--------------------------------------------------------------
Epoch:  529        1 Batch loss: 0.244068 Batch F1: 0.0
Epoch:  529        2 Batch loss: 0.238063 Batch F1: 0.0
Epoch:  529        3 Batch loss: 0.253597 Batch F1: 0.0
Epoch:  529        4 Batch loss: 0.241212 Batch F1: 0.0
Epoch:  529        5 Batch loss: 0.241497 Batch F1: 0.0
Epoch:  529        6 Batch loss: 0.206671 Batch F1: 0.0
Epoch:  529        7 Batch loss: 0.219101 Batch F1: 0.0
Epoch:  529        8 Batch loss: 0.187660 Batch F1: 0.0
Epoch:  529        9 Batch loss: 0.212097 Batch F1: 0.0
Epoch:  529       10 Batch loss: 0.221910 Batch F1: 0.0
Epoch:  529       11 Batch loss: 0.252732 Batch F1: 0.0
Epoch:  529       12 Batch loss: 0.208893 Batch F1: 0.0
Train Avg Loss  529: 0.227292

Train Avg F1  529: 0.0

Val Avg Loss  529: 0.216885

Val Avg F1  529:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 530
--------------------------------------------------------------
Epoch:  530        1 Batch loss: 0.221124 Batch F1: 0.0
Epoch:  530        2 Batch loss: 0.256113 Batch F1: 0.0
Epoch:  530        3 Batch loss: 0.221149 Batch F1: 0.0
Epoch:  530        4 Batch loss: 0.221884 Batch F1: 0.0
Epoch:  530        5 Batch loss: 0.217371 Batch F1: 0.0
Epoch:  530        6 Batch loss: 0.197277 Batch F1: 0.0
Epoch:  530        7 Batch loss: 0.203548 Batch F1: 0.0
Epoch:  530        8 Batch loss: 0.224223 Batch F1: 0.0
Epoch:  530        9 Batch loss: 0.258045 Batch F1: 0.0
Epoch:  530       10 Batch loss: 0.272969 Batch F1: 0.0
Epoch:  530       11 Batch loss: 0.205559 Batch F1: 0.0
Epoch:  530       12 Batch loss: 0.242242 Batch F1: 0.0
Train Avg Loss  530: 0.228459

Train Avg F1  530: 0.0

Val Avg Loss  530: 0.220607

Val Avg F1  530:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 531
--------------------------------------------------------------
Epoch:  531        1 Batch loss: 0.212432 Batch F1: 0.0
Epoch:  531        2 Batch loss: 0.214813 Batch F1: 0.0
Epoch:  531        3 Batch loss: 0.246676 Batch F1: 0.0
Epoch:  531        4 Batch loss: 0.236834 Batch F1: 0.0
Epoch:  531        5 Batch loss: 0.234527 Batch F1: 0.0
Epoch:  531        6 Batch loss: 0.252481 Batch F1: 0.0
Epoch:  531        7 Batch loss: 0.218596 Batch F1: 0.19047619047619047
Epoch:  531        8 Batch loss: 0.204685 Batch F1: 0.0
Epoch:  531        9 Batch loss: 0.257557 Batch F1: 0.0
Epoch:  531       10 Batch loss: 0.229145 Batch F1: 0.0
Epoch:  531       11 Batch loss: 0.215007 Batch F1: 0.0
Epoch:  531       12 Batch loss: 0.203278 Batch F1: 0.0
Train Avg Loss  531: 0.227169

Train Avg F1  531: 0.015873015873015872

Val Avg Loss  531: 0.217097

Val Avg F1  531:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 532
--------------------------------------------------------------
Epoch:  532        1 Batch loss: 0.244132 Batch F1: 0.0
Epoch:  532        2 Batch loss: 0.216929 Batch F1: 0.0
Epoch:  532        3 Batch loss: 0.250747 Batch F1: 0.0
Epoch:  532        4 Batch loss: 0.227248 Batch F1: 0.0
Epoch:  532        5 Batch loss: 0.233819 Batch F1: 0.0
Epoch:  532        6 Batch loss: 0.224672 Batch F1: 0.0
Epoch:  532        7 Batch loss: 0.224028 Batch F1: 0.0
Epoch:  532        8 Batch loss: 0.227774 Batch F1: 0.0
Epoch:  532        9 Batch loss: 0.210361 Batch F1: 0.0
Epoch:  532       10 Batch loss: 0.220521 Batch F1: 0.0
Epoch:  532       11 Batch loss: 0.223476 Batch F1: 0.0
Epoch:  532       12 Batch loss: 0.230583 Batch F1: 0.0
Train Avg Loss  532: 0.227858

Train Avg F1  532: 0.0

Val Avg Loss  532: 0.217278

Val Avg F1  532:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 533
--------------------------------------------------------------
Epoch:  533        1 Batch loss: 0.274489 Batch F1: 0.0
Epoch:  533        2 Batch loss: 0.220342 Batch F1: 0.0
Epoch:  533        3 Batch loss: 0.220344 Batch F1: 0.0
Epoch:  533        4 Batch loss: 0.195180 Batch F1: 0.0
Epoch:  533        5 Batch loss: 0.201395 Batch F1: 0.0
Epoch:  533        6 Batch loss: 0.243022 Batch F1: 0.0
Epoch:  533        7 Batch loss: 0.220121 Batch F1: 0.0
Epoch:  533        8 Batch loss: 0.202686 Batch F1: 0.0
Epoch:  533        9 Batch loss: 0.219059 Batch F1: 0.0
Epoch:  533       10 Batch loss: 0.242990 Batch F1: 0.0
Epoch:  533       11 Batch loss: 0.250003 Batch F1: 0.0
Epoch:  533       12 Batch loss: 0.229466 Batch F1: 0.0
Train Avg Loss  533: 0.226591

Train Avg F1  533: 0.0

Val Avg Loss  533: 0.218794

Val Avg F1  533:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 534
--------------------------------------------------------------
Epoch:  534        1 Batch loss: 0.235032 Batch F1: 0.0
Epoch:  534        2 Batch loss: 0.211889 Batch F1: 0.1111111111111111
Epoch:  534        3 Batch loss: 0.227258 Batch F1: 0.3478260869565218
Epoch:  534        4 Batch loss: 0.224381 Batch F1: 0.17391304347826086
Epoch:  534        5 Batch loss: 0.254153 Batch F1: 0.0
Epoch:  534        6 Batch loss: 0.211026 Batch F1: 0.0
Epoch:  534        7 Batch loss: 0.229290 Batch F1: 0.0
Epoch:  534        8 Batch loss: 0.235325 Batch F1: 0.0
Epoch:  534        9 Batch loss: 0.222414 Batch F1: 0.0
Epoch:  534       10 Batch loss: 0.199508 Batch F1: 0.0
Epoch:  534       11 Batch loss: 0.220802 Batch F1: 0.0
Epoch:  534       12 Batch loss: 0.258328 Batch F1: 0.0
Train Avg Loss  534: 0.227450

Train Avg F1  534: 0.05273752012882448

Val Avg Loss  534: 0.216422

Val Avg F1  534:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 535
--------------------------------------------------------------
Epoch:  535        1 Batch loss: 0.221058 Batch F1: 0.0
Epoch:  535        2 Batch loss: 0.222876 Batch F1: 0.0
Epoch:  535        3 Batch loss: 0.251440 Batch F1: 0.0
Epoch:  535        4 Batch loss: 0.179832 Batch F1: 0.0
Epoch:  535        5 Batch loss: 0.243895 Batch F1: 0.0
Epoch:  535        6 Batch loss: 0.256657 Batch F1: 0.0
Epoch:  535        7 Batch loss: 0.224765 Batch F1: 0.0
Epoch:  535        8 Batch loss: 0.200667 Batch F1: 0.0
Epoch:  535        9 Batch loss: 0.227849 Batch F1: 0.0
Epoch:  535       10 Batch loss: 0.227435 Batch F1: 0.0
Epoch:  535       11 Batch loss: 0.245695 Batch F1: 0.0
Epoch:  535       12 Batch loss: 0.216044 Batch F1: 0.0
Train Avg Loss  535: 0.226518

Train Avg F1  535: 0.0

Val Avg Loss  535: 0.217584

Val Avg F1  535:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 536
--------------------------------------------------------------
Epoch:  536        1 Batch loss: 0.216641 Batch F1: 0.0
Epoch:  536        2 Batch loss: 0.205616 Batch F1: 0.0
Epoch:  536        3 Batch loss: 0.242944 Batch F1: 0.0
Epoch:  536        4 Batch loss: 0.196494 Batch F1: 0.0
Epoch:  536        5 Batch loss: 0.236024 Batch F1: 0.0
Epoch:  536        6 Batch loss: 0.229954 Batch F1: 0.0
Epoch:  536        7 Batch loss: 0.207508 Batch F1: 0.0
Epoch:  536        8 Batch loss: 0.274715 Batch F1: 0.0
Epoch:  536        9 Batch loss: 0.232744 Batch F1: 0.0
Epoch:  536       10 Batch loss: 0.250623 Batch F1: 0.0
Epoch:  536       11 Batch loss: 0.230644 Batch F1: 0.0
Epoch:  536       12 Batch loss: 0.200854 Batch F1: 0.0
Train Avg Loss  536: 0.227063

Train Avg F1  536: 0.0

Val Avg Loss  536: 0.222053

Val Avg F1  536:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 537
--------------------------------------------------------------
Epoch:  537        1 Batch loss: 0.233143 Batch F1: 0.0
Epoch:  537        2 Batch loss: 0.232798 Batch F1: 0.0
Epoch:  537        3 Batch loss: 0.213400 Batch F1: 0.0
Epoch:  537        4 Batch loss: 0.242737 Batch F1: 0.0
Epoch:  537        5 Batch loss: 0.269231 Batch F1: 0.0
Epoch:  537        6 Batch loss: 0.228748 Batch F1: 0.0
Epoch:  537        7 Batch loss: 0.203367 Batch F1: 0.0
Epoch:  537        8 Batch loss: 0.210749 Batch F1: 0.0
Epoch:  537        9 Batch loss: 0.215474 Batch F1: 0.0
Epoch:  537       10 Batch loss: 0.211579 Batch F1: 0.0
Epoch:  537       11 Batch loss: 0.222748 Batch F1: 0.0
Epoch:  537       12 Batch loss: 0.239775 Batch F1: 0.0
Train Avg Loss  537: 0.226979

Train Avg F1  537: 0.0

Val Avg Loss  537: 0.217420

Val Avg F1  537:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 538
--------------------------------------------------------------
Epoch:  538        1 Batch loss: 0.218505 Batch F1: 0.0
Epoch:  538        2 Batch loss: 0.244730 Batch F1: 0.0
Epoch:  538        3 Batch loss: 0.225848 Batch F1: 0.0
Epoch:  538        4 Batch loss: 0.218412 Batch F1: 0.0
Epoch:  538        5 Batch loss: 0.219966 Batch F1: 0.3333333333333333
Epoch:  538        6 Batch loss: 0.232662 Batch F1: 0.0
Epoch:  538        7 Batch loss: 0.252998 Batch F1: 0.0
Epoch:  538        8 Batch loss: 0.217068 Batch F1: 0.0
Epoch:  538        9 Batch loss: 0.210532 Batch F1: 0.0
Epoch:  538       10 Batch loss: 0.219278 Batch F1: 0.0
Epoch:  538       11 Batch loss: 0.206211 Batch F1: 0.0
Epoch:  538       12 Batch loss: 0.258999 Batch F1: 0.0
Train Avg Loss  538: 0.227101

Train Avg F1  538: 0.027777777777777776

Val Avg Loss  538: 0.217359

Val Avg F1  538:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 539
--------------------------------------------------------------
Epoch:  539        1 Batch loss: 0.208136 Batch F1: 0.0
Epoch:  539        2 Batch loss: 0.219277 Batch F1: 0.0
Epoch:  539        3 Batch loss: 0.217858 Batch F1: 0.0
Epoch:  539        4 Batch loss: 0.232274 Batch F1: 0.0
Epoch:  539        5 Batch loss: 0.199655 Batch F1: 0.0
Epoch:  539        6 Batch loss: 0.237515 Batch F1: 0.0
Epoch:  539        7 Batch loss: 0.240322 Batch F1: 0.0
Epoch:  539        8 Batch loss: 0.233344 Batch F1: 0.0
Epoch:  539        9 Batch loss: 0.233416 Batch F1: 0.0
Epoch:  539       10 Batch loss: 0.214259 Batch F1: 0.0
Epoch:  539       11 Batch loss: 0.226818 Batch F1: 0.0
Epoch:  539       12 Batch loss: 0.262234 Batch F1: 0.0
Train Avg Loss  539: 0.227092

Train Avg F1  539: 0.0

Val Avg Loss  539: 0.217984

Val Avg F1  539:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 540
--------------------------------------------------------------
Epoch:  540        1 Batch loss: 0.234981 Batch F1: 0.0
Epoch:  540        2 Batch loss: 0.224844 Batch F1: 0.0
Epoch:  540        3 Batch loss: 0.222687 Batch F1: 0.0
Epoch:  540        4 Batch loss: 0.228423 Batch F1: 0.2608695652173913
Epoch:  540        5 Batch loss: 0.235020 Batch F1: 0.3333333333333333
Epoch:  540        6 Batch loss: 0.199863 Batch F1: 0.3636363636363636
Epoch:  540        7 Batch loss: 0.219591 Batch F1: 0.0
Epoch:  540        8 Batch loss: 0.225994 Batch F1: 0.0
Epoch:  540        9 Batch loss: 0.224039 Batch F1: 0.0
Epoch:  540       10 Batch loss: 0.245446 Batch F1: 0.0
Epoch:  540       11 Batch loss: 0.251906 Batch F1: 0.0
Epoch:  540       12 Batch loss: 0.222535 Batch F1: 0.0
Train Avg Loss  540: 0.227944

Train Avg F1  540: 0.07981993851559067

Val Avg Loss  540: 0.219889

Val Avg F1  540:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 541
--------------------------------------------------------------
Epoch:  541        1 Batch loss: 0.216792 Batch F1: 0.0
Epoch:  541        2 Batch loss: 0.231249 Batch F1: 0.0
Epoch:  541        3 Batch loss: 0.221081 Batch F1: 0.0
Epoch:  541        4 Batch loss: 0.216233 Batch F1: 0.0
Epoch:  541        5 Batch loss: 0.242229 Batch F1: 0.0
Epoch:  541        6 Batch loss: 0.226342 Batch F1: 0.0
Epoch:  541        7 Batch loss: 0.224836 Batch F1: 0.0
Epoch:  541        8 Batch loss: 0.238830 Batch F1: 0.0
Epoch:  541        9 Batch loss: 0.234548 Batch F1: 0.0
Epoch:  541       10 Batch loss: 0.238658 Batch F1: 0.0
Epoch:  541       11 Batch loss: 0.197268 Batch F1: 0.0
Epoch:  541       12 Batch loss: 0.248757 Batch F1: 0.0
Train Avg Loss  541: 0.228068

Train Avg F1  541: 0.0

Val Avg Loss  541: 0.218010

Val Avg F1  541:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 542
--------------------------------------------------------------
Epoch:  542        1 Batch loss: 0.209158 Batch F1: 0.0
Epoch:  542        2 Batch loss: 0.234417 Batch F1: 0.0
Epoch:  542        3 Batch loss: 0.246655 Batch F1: 0.0
Epoch:  542        4 Batch loss: 0.201478 Batch F1: 0.0
Epoch:  542        5 Batch loss: 0.235011 Batch F1: 0.0
Epoch:  542        6 Batch loss: 0.214276 Batch F1: 0.0
Epoch:  542        7 Batch loss: 0.232630 Batch F1: 0.0
Epoch:  542        8 Batch loss: 0.242505 Batch F1: 0.0
Epoch:  542        9 Batch loss: 0.222765 Batch F1: 0.0
Epoch:  542       10 Batch loss: 0.235823 Batch F1: 0.0
Epoch:  542       11 Batch loss: 0.210548 Batch F1: 0.0
Epoch:  542       12 Batch loss: 0.247034 Batch F1: 0.0
Train Avg Loss  542: 0.227691

Train Avg F1  542: 0.0

Val Avg Loss  542: 0.219655

Val Avg F1  542:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 543
--------------------------------------------------------------
Epoch:  543        1 Batch loss: 0.231112 Batch F1: 0.0
Epoch:  543        2 Batch loss: 0.213002 Batch F1: 0.0
Epoch:  543        3 Batch loss: 0.217298 Batch F1: 0.0
Epoch:  543        4 Batch loss: 0.223678 Batch F1: 0.0
Epoch:  543        5 Batch loss: 0.241130 Batch F1: 0.0
Epoch:  543        6 Batch loss: 0.224439 Batch F1: 0.0
Epoch:  543        7 Batch loss: 0.257038 Batch F1: 0.0
Epoch:  543        8 Batch loss: 0.198948 Batch F1: 0.0
Epoch:  543        9 Batch loss: 0.245649 Batch F1: 0.0
Epoch:  543       10 Batch loss: 0.230862 Batch F1: 0.0
Epoch:  543       11 Batch loss: 0.225512 Batch F1: 0.0
Epoch:  543       12 Batch loss: 0.212282 Batch F1: 0.0
Train Avg Loss  543: 0.226746

Train Avg F1  543: 0.0

Val Avg Loss  543: 0.219032

Val Avg F1  543:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 544
--------------------------------------------------------------
Epoch:  544        1 Batch loss: 0.212543 Batch F1: 0.0
Epoch:  544        2 Batch loss: 0.247391 Batch F1: 0.0
Epoch:  544        3 Batch loss: 0.205850 Batch F1: 0.0
Epoch:  544        4 Batch loss: 0.220871 Batch F1: 0.0
Epoch:  544        5 Batch loss: 0.241214 Batch F1: 0.0
Epoch:  544        6 Batch loss: 0.259995 Batch F1: 0.0
Epoch:  544        7 Batch loss: 0.202098 Batch F1: 0.0
Epoch:  544        8 Batch loss: 0.222552 Batch F1: 0.0
Epoch:  544        9 Batch loss: 0.249497 Batch F1: 0.0
Epoch:  544       10 Batch loss: 0.211074 Batch F1: 0.0
Epoch:  544       11 Batch loss: 0.199528 Batch F1: 0.0
Epoch:  544       12 Batch loss: 0.248200 Batch F1: 0.0
Train Avg Loss  544: 0.226734

Train Avg F1  544: 0.0

Val Avg Loss  544: 0.217514

Val Avg F1  544:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 545
--------------------------------------------------------------
Epoch:  545        1 Batch loss: 0.208882 Batch F1: 0.0
Epoch:  545        2 Batch loss: 0.264948 Batch F1: 0.0
Epoch:  545        3 Batch loss: 0.223181 Batch F1: 0.0
Epoch:  545        4 Batch loss: 0.231214 Batch F1: 0.0
Epoch:  545        5 Batch loss: 0.249785 Batch F1: 0.0
Epoch:  545        6 Batch loss: 0.213747 Batch F1: 0.41379310344827586
Epoch:  545        7 Batch loss: 0.213537 Batch F1: 0.0
Epoch:  545        8 Batch loss: 0.230587 Batch F1: 0.0
Epoch:  545        9 Batch loss: 0.233772 Batch F1: 0.0
Epoch:  545       10 Batch loss: 0.191648 Batch F1: 0.0
Epoch:  545       11 Batch loss: 0.233055 Batch F1: 0.0
Epoch:  545       12 Batch loss: 0.218085 Batch F1: 0.0
Train Avg Loss  545: 0.226037

Train Avg F1  545: 0.034482758620689655

Val Avg Loss  545: 0.217142

Val Avg F1  545:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 546
--------------------------------------------------------------
Epoch:  546        1 Batch loss: 0.202249 Batch F1: 0.0
Epoch:  546        2 Batch loss: 0.243950 Batch F1: 0.0
Epoch:  546        3 Batch loss: 0.208434 Batch F1: 0.0
Epoch:  546        4 Batch loss: 0.227045 Batch F1: 0.0
Epoch:  546        5 Batch loss: 0.247066 Batch F1: 0.0
Epoch:  546        6 Batch loss: 0.218083 Batch F1: 0.0
Epoch:  546        7 Batch loss: 0.265758 Batch F1: 0.0
Epoch:  546        8 Batch loss: 0.238603 Batch F1: 0.0
Epoch:  546        9 Batch loss: 0.215841 Batch F1: 0.0
Epoch:  546       10 Batch loss: 0.230415 Batch F1: 0.0
Epoch:  546       11 Batch loss: 0.202787 Batch F1: 0.0
Epoch:  546       12 Batch loss: 0.217773 Batch F1: 0.0
Train Avg Loss  546: 0.226500

Train Avg F1  546: 0.0

Val Avg Loss  546: 0.217595

Val Avg F1  546:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 547
--------------------------------------------------------------
Epoch:  547        1 Batch loss: 0.227146 Batch F1: 0.0
Epoch:  547        2 Batch loss: 0.221591 Batch F1: 0.0
Epoch:  547        3 Batch loss: 0.222289 Batch F1: 0.0
Epoch:  547        4 Batch loss: 0.268099 Batch F1: 0.0
Epoch:  547        5 Batch loss: 0.267904 Batch F1: 0.0
Epoch:  547        6 Batch loss: 0.205852 Batch F1: 0.0
Epoch:  547        7 Batch loss: 0.214900 Batch F1: 0.0
Epoch:  547        8 Batch loss: 0.218858 Batch F1: 0.0
Epoch:  547        9 Batch loss: 0.239457 Batch F1: 0.0
Epoch:  547       10 Batch loss: 0.219901 Batch F1: 0.0
Epoch:  547       11 Batch loss: 0.220966 Batch F1: 0.37037037037037035
Epoch:  547       12 Batch loss: 0.239939 Batch F1: 0.3157894736842105
Train Avg Loss  547: 0.230575

Train Avg F1  547: 0.057179987004548405

Val Avg Loss  547: 0.221805

Val Avg F1  547:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 548
--------------------------------------------------------------
Epoch:  548        1 Batch loss: 0.229759 Batch F1: 0.0
Epoch:  548        2 Batch loss: 0.246580 Batch F1: 0.0
Epoch:  548        3 Batch loss: 0.220443 Batch F1: 0.0
Epoch:  548        4 Batch loss: 0.266639 Batch F1: 0.0
Epoch:  548        5 Batch loss: 0.225188 Batch F1: 0.0
Epoch:  548        6 Batch loss: 0.236875 Batch F1: 0.0
Epoch:  548        7 Batch loss: 0.235151 Batch F1: 0.0
Epoch:  548        8 Batch loss: 0.223909 Batch F1: 0.0
Epoch:  548        9 Batch loss: 0.221394 Batch F1: 0.0
Epoch:  548       10 Batch loss: 0.218370 Batch F1: 0.0
Epoch:  548       11 Batch loss: 0.231387 Batch F1: 0.0
Epoch:  548       12 Batch loss: 0.200913 Batch F1: 0.0
Train Avg Loss  548: 0.229717

Train Avg F1  548: 0.0

Val Avg Loss  548: 0.218519

Val Avg F1  548:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 549
--------------------------------------------------------------
Epoch:  549        1 Batch loss: 0.239364 Batch F1: 0.0
Epoch:  549        2 Batch loss: 0.229965 Batch F1: 0.0
Epoch:  549        3 Batch loss: 0.232489 Batch F1: 0.0
Epoch:  549        4 Batch loss: 0.206749 Batch F1: 0.0
Epoch:  549        5 Batch loss: 0.240661 Batch F1: 0.0
Epoch:  549        6 Batch loss: 0.223961 Batch F1: 0.0
Epoch:  549        7 Batch loss: 0.234332 Batch F1: 0.0
Epoch:  549        8 Batch loss: 0.216149 Batch F1: 0.0
Epoch:  549        9 Batch loss: 0.233896 Batch F1: 0.0
Epoch:  549       10 Batch loss: 0.244911 Batch F1: 0.0
Epoch:  549       11 Batch loss: 0.202675 Batch F1: 0.0
Epoch:  549       12 Batch loss: 0.220071 Batch F1: 0.0
Train Avg Loss  549: 0.227102

Train Avg F1  549: 0.0

Val Avg Loss  549: 0.218284

Val Avg F1  549:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 550
--------------------------------------------------------------
Epoch:  550        1 Batch loss: 0.257424 Batch F1: 0.0
Epoch:  550        2 Batch loss: 0.262684 Batch F1: 0.0
Epoch:  550        3 Batch loss: 0.218381 Batch F1: 0.0
Epoch:  550        4 Batch loss: 0.226656 Batch F1: 0.0
Epoch:  550        5 Batch loss: 0.222583 Batch F1: 0.0
Epoch:  550        6 Batch loss: 0.225498 Batch F1: 0.0
Epoch:  550        7 Batch loss: 0.235508 Batch F1: 0.0
Epoch:  550        8 Batch loss: 0.241953 Batch F1: 0.0
Epoch:  550        9 Batch loss: 0.196163 Batch F1: 0.0
Epoch:  550       10 Batch loss: 0.236808 Batch F1: 0.0
Epoch:  550       11 Batch loss: 0.214361 Batch F1: 0.0
Epoch:  550       12 Batch loss: 0.221740 Batch F1: 0.0
Train Avg Loss  550: 0.229980

Train Avg F1  550: 0.0

Val Avg Loss  550: 0.217983

Val Avg F1  550:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 551
--------------------------------------------------------------
Epoch:  551        1 Batch loss: 0.244136 Batch F1: 0.0
Epoch:  551        2 Batch loss: 0.192170 Batch F1: 0.0
Epoch:  551        3 Batch loss: 0.202059 Batch F1: 0.0
Epoch:  551        4 Batch loss: 0.220883 Batch F1: 0.0
Epoch:  551        5 Batch loss: 0.262912 Batch F1: 0.0
Epoch:  551        6 Batch loss: 0.219172 Batch F1: 0.0
Epoch:  551        7 Batch loss: 0.198680 Batch F1: 0.0
Epoch:  551        8 Batch loss: 0.220241 Batch F1: 0.0
Epoch:  551        9 Batch loss: 0.253936 Batch F1: 0.0
Epoch:  551       10 Batch loss: 0.262614 Batch F1: 0.0
Epoch:  551       11 Batch loss: 0.228237 Batch F1: 0.0
Epoch:  551       12 Batch loss: 0.223756 Batch F1: 0.23529411764705882
Train Avg Loss  551: 0.227400

Train Avg F1  551: 0.0196078431372549

Val Avg Loss  551: 0.224130

Val Avg F1  551:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 552
--------------------------------------------------------------
Epoch:  552        1 Batch loss: 0.228221 Batch F1: 0.0
Epoch:  552        2 Batch loss: 0.207024 Batch F1: 0.0
Epoch:  552        3 Batch loss: 0.229845 Batch F1: 0.0
Epoch:  552        4 Batch loss: 0.246708 Batch F1: 0.0
Epoch:  552        5 Batch loss: 0.209630 Batch F1: 0.0
Epoch:  552        6 Batch loss: 0.250872 Batch F1: 0.0
Epoch:  552        7 Batch loss: 0.198464 Batch F1: 0.0
Epoch:  552        8 Batch loss: 0.242012 Batch F1: 0.0
Epoch:  552        9 Batch loss: 0.217634 Batch F1: 0.0
Epoch:  552       10 Batch loss: 0.245249 Batch F1: 0.0
Epoch:  552       11 Batch loss: 0.219238 Batch F1: 0.0
Epoch:  552       12 Batch loss: 0.237304 Batch F1: 0.0
Train Avg Loss  552: 0.227683

Train Avg F1  552: 0.0

Val Avg Loss  552: 0.216966

Val Avg F1  552:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 553
--------------------------------------------------------------
Epoch:  553        1 Batch loss: 0.219894 Batch F1: 0.0
Epoch:  553        2 Batch loss: 0.236528 Batch F1: 0.0
Epoch:  553        3 Batch loss: 0.233407 Batch F1: 0.0
Epoch:  553        4 Batch loss: 0.236105 Batch F1: 0.0
Epoch:  553        5 Batch loss: 0.200813 Batch F1: 0.0
Epoch:  553        6 Batch loss: 0.227186 Batch F1: 0.0
Epoch:  553        7 Batch loss: 0.219180 Batch F1: 0.0
Epoch:  553        8 Batch loss: 0.238524 Batch F1: 0.0
Epoch:  553        9 Batch loss: 0.221453 Batch F1: 0.0
Epoch:  553       10 Batch loss: 0.254861 Batch F1: 0.0
Epoch:  553       11 Batch loss: 0.216791 Batch F1: 0.0
Epoch:  553       12 Batch loss: 0.209490 Batch F1: 0.0
Train Avg Loss  553: 0.226186

Train Avg F1  553: 0.0

Val Avg Loss  553: 0.218178

Val Avg F1  553:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 554
--------------------------------------------------------------
Epoch:  554        1 Batch loss: 0.201464 Batch F1: 0.0
Epoch:  554        2 Batch loss: 0.236662 Batch F1: 0.0
Epoch:  554        3 Batch loss: 0.259164 Batch F1: 0.0
Epoch:  554        4 Batch loss: 0.250478 Batch F1: 0.0
Epoch:  554        5 Batch loss: 0.184467 Batch F1: 0.0
Epoch:  554        6 Batch loss: 0.230693 Batch F1: 0.0
Epoch:  554        7 Batch loss: 0.232974 Batch F1: 0.0
Epoch:  554        8 Batch loss: 0.192393 Batch F1: 0.0
Epoch:  554        9 Batch loss: 0.247183 Batch F1: 0.0
Epoch:  554       10 Batch loss: 0.204786 Batch F1: 0.0
Epoch:  554       11 Batch loss: 0.231582 Batch F1: 0.0
Epoch:  554       12 Batch loss: 0.244632 Batch F1: 0.0
Train Avg Loss  554: 0.226373

Train Avg F1  554: 0.0

Val Avg Loss  554: 0.217360

Val Avg F1  554:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 555
--------------------------------------------------------------
Epoch:  555        1 Batch loss: 0.225024 Batch F1: 0.0
Epoch:  555        2 Batch loss: 0.242615 Batch F1: 0.0
Epoch:  555        3 Batch loss: 0.212258 Batch F1: 0.0
Epoch:  555        4 Batch loss: 0.216635 Batch F1: 0.0
Epoch:  555        5 Batch loss: 0.265829 Batch F1: 0.0
Epoch:  555        6 Batch loss: 0.203196 Batch F1: 0.0
Epoch:  555        7 Batch loss: 0.233782 Batch F1: 0.0
Epoch:  555        8 Batch loss: 0.219675 Batch F1: 0.0
Epoch:  555        9 Batch loss: 0.212452 Batch F1: 0.0
Epoch:  555       10 Batch loss: 0.250597 Batch F1: 0.0
Epoch:  555       11 Batch loss: 0.219815 Batch F1: 0.2105263157894737
Epoch:  555       12 Batch loss: 0.205533 Batch F1: 0.0
Train Avg Loss  555: 0.225618

Train Avg F1  555: 0.01754385964912281

Val Avg Loss  555: 0.218181

Val Avg F1  555:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 556
--------------------------------------------------------------
Epoch:  556        1 Batch loss: 0.225643 Batch F1: 0.0
Epoch:  556        2 Batch loss: 0.238480 Batch F1: 0.0
Epoch:  556        3 Batch loss: 0.227567 Batch F1: 0.0
Epoch:  556        4 Batch loss: 0.187881 Batch F1: 0.0
Epoch:  556        5 Batch loss: 0.216867 Batch F1: 0.0
Epoch:  556        6 Batch loss: 0.236210 Batch F1: 0.0
Epoch:  556        7 Batch loss: 0.267511 Batch F1: 0.0
Epoch:  556        8 Batch loss: 0.230605 Batch F1: 0.0
Epoch:  556        9 Batch loss: 0.217247 Batch F1: 0.0
Epoch:  556       10 Batch loss: 0.229248 Batch F1: 0.0
Epoch:  556       11 Batch loss: 0.213932 Batch F1: 0.0
Epoch:  556       12 Batch loss: 0.250948 Batch F1: 0.0
Train Avg Loss  556: 0.228512

Train Avg F1  556: 0.0

Val Avg Loss  556: 0.220693

Val Avg F1  556:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 557
--------------------------------------------------------------
Epoch:  557        1 Batch loss: 0.244671 Batch F1: 0.0
Epoch:  557        2 Batch loss: 0.231612 Batch F1: 0.0
Epoch:  557        3 Batch loss: 0.207973 Batch F1: 0.0
Epoch:  557        4 Batch loss: 0.211057 Batch F1: 0.0
Epoch:  557        5 Batch loss: 0.233335 Batch F1: 0.0
Epoch:  557        6 Batch loss: 0.223161 Batch F1: 0.0
Epoch:  557        7 Batch loss: 0.219974 Batch F1: 0.0
Epoch:  557        8 Batch loss: 0.224759 Batch F1: 0.0
Epoch:  557        9 Batch loss: 0.217180 Batch F1: 0.0
Epoch:  557       10 Batch loss: 0.250473 Batch F1: 0.0
Epoch:  557       11 Batch loss: 0.252884 Batch F1: 0.0
Epoch:  557       12 Batch loss: 0.219657 Batch F1: 0.0
Train Avg Loss  557: 0.228061

Train Avg F1  557: 0.0

Val Avg Loss  557: 0.218415

Val Avg F1  557:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 558
--------------------------------------------------------------
Epoch:  558        1 Batch loss: 0.217048 Batch F1: 0.0
Epoch:  558        2 Batch loss: 0.180679 Batch F1: 0.0
Epoch:  558        3 Batch loss: 0.234188 Batch F1: 0.0
Epoch:  558        4 Batch loss: 0.245246 Batch F1: 0.0
Epoch:  558        5 Batch loss: 0.243328 Batch F1: 0.0
Epoch:  558        6 Batch loss: 0.224362 Batch F1: 0.0
Epoch:  558        7 Batch loss: 0.213809 Batch F1: 0.0
Epoch:  558        8 Batch loss: 0.226455 Batch F1: 0.0
Epoch:  558        9 Batch loss: 0.233252 Batch F1: 0.0
Epoch:  558       10 Batch loss: 0.245423 Batch F1: 0.0
Epoch:  558       11 Batch loss: 0.253763 Batch F1: 0.0
Epoch:  558       12 Batch loss: 0.206511 Batch F1: 0.0
Train Avg Loss  558: 0.227005

Train Avg F1  558: 0.0

Val Avg Loss  558: 0.218000

Val Avg F1  558:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 559
--------------------------------------------------------------
Epoch:  559        1 Batch loss: 0.243645 Batch F1: 0.0
Epoch:  559        2 Batch loss: 0.223622 Batch F1: 0.0
Epoch:  559        3 Batch loss: 0.250946 Batch F1: 0.0
Epoch:  559        4 Batch loss: 0.187847 Batch F1: 0.0
Epoch:  559        5 Batch loss: 0.232718 Batch F1: 0.0
Epoch:  559        6 Batch loss: 0.226562 Batch F1: 0.0
Epoch:  559        7 Batch loss: 0.228126 Batch F1: 0.0
Epoch:  559        8 Batch loss: 0.246430 Batch F1: 0.0
Epoch:  559        9 Batch loss: 0.196736 Batch F1: 0.0
Epoch:  559       10 Batch loss: 0.223000 Batch F1: 0.0
Epoch:  559       11 Batch loss: 0.222444 Batch F1: 0.0
Epoch:  559       12 Batch loss: 0.236750 Batch F1: 0.0
Train Avg Loss  559: 0.226569

Train Avg F1  559: 0.0

Val Avg Loss  559: 0.218359

Val Avg F1  559:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 560
--------------------------------------------------------------
Epoch:  560        1 Batch loss: 0.236829 Batch F1: 0.0
Epoch:  560        2 Batch loss: 0.219640 Batch F1: 0.0
Epoch:  560        3 Batch loss: 0.251500 Batch F1: 0.0
Epoch:  560        4 Batch loss: 0.191772 Batch F1: 0.0
Epoch:  560        5 Batch loss: 0.218614 Batch F1: 0.0
Epoch:  560        6 Batch loss: 0.234915 Batch F1: 0.0
Epoch:  560        7 Batch loss: 0.227552 Batch F1: 0.0
Epoch:  560        8 Batch loss: 0.231308 Batch F1: 0.0
Epoch:  560        9 Batch loss: 0.187041 Batch F1: 0.0
Epoch:  560       10 Batch loss: 0.232193 Batch F1: 0.0
Epoch:  560       11 Batch loss: 0.267063 Batch F1: 0.0
Epoch:  560       12 Batch loss: 0.233228 Batch F1: 0.0
Train Avg Loss  560: 0.227638

Train Avg F1  560: 0.0

Val Avg Loss  560: 0.217186

Val Avg F1  560:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 561
--------------------------------------------------------------
Epoch:  561        1 Batch loss: 0.236424 Batch F1: 0.0
Epoch:  561        2 Batch loss: 0.221542 Batch F1: 0.0
Epoch:  561        3 Batch loss: 0.239360 Batch F1: 0.0
Epoch:  561        4 Batch loss: 0.235284 Batch F1: 0.0
Epoch:  561        5 Batch loss: 0.220969 Batch F1: 0.0
Epoch:  561        6 Batch loss: 0.227782 Batch F1: 0.0
Epoch:  561        7 Batch loss: 0.235627 Batch F1: 0.0
Epoch:  561        8 Batch loss: 0.248628 Batch F1: 0.0
Epoch:  561        9 Batch loss: 0.210017 Batch F1: 0.09999999999999999
Epoch:  561       10 Batch loss: 0.204253 Batch F1: 0.2222222222222222
Epoch:  561       11 Batch loss: 0.203389 Batch F1: 0.0
Epoch:  561       12 Batch loss: 0.231852 Batch F1: 0.0
Train Avg Loss  561: 0.226261

Train Avg F1  561: 0.02685185185185185

Val Avg Loss  561: 0.217074

Val Avg F1  561:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 562
--------------------------------------------------------------
Epoch:  562        1 Batch loss: 0.242100 Batch F1: 0.0
Epoch:  562        2 Batch loss: 0.233476 Batch F1: 0.0
Epoch:  562        3 Batch loss: 0.230683 Batch F1: 0.0
Epoch:  562        4 Batch loss: 0.221088 Batch F1: 0.0
Epoch:  562        5 Batch loss: 0.231385 Batch F1: 0.0
Epoch:  562        6 Batch loss: 0.198182 Batch F1: 0.0
Epoch:  562        7 Batch loss: 0.231649 Batch F1: 0.0
Epoch:  562        8 Batch loss: 0.201473 Batch F1: 0.0
Epoch:  562        9 Batch loss: 0.266837 Batch F1: 0.0
Epoch:  562       10 Batch loss: 0.240607 Batch F1: 0.0
Epoch:  562       11 Batch loss: 0.195942 Batch F1: 0.0
Epoch:  562       12 Batch loss: 0.222478 Batch F1: 0.0
Train Avg Loss  562: 0.226325

Train Avg F1  562: 0.0

Val Avg Loss  562: 0.218611

Val Avg F1  562:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 563
--------------------------------------------------------------
Epoch:  563        1 Batch loss: 0.251976 Batch F1: 0.0
Epoch:  563        2 Batch loss: 0.212803 Batch F1: 0.0
Epoch:  563        3 Batch loss: 0.234834 Batch F1: 0.0
Epoch:  563        4 Batch loss: 0.206864 Batch F1: 0.0
Epoch:  563        5 Batch loss: 0.195318 Batch F1: 0.0
Epoch:  563        6 Batch loss: 0.218162 Batch F1: 0.0
Epoch:  563        7 Batch loss: 0.229404 Batch F1: 0.0
Epoch:  563        8 Batch loss: 0.252595 Batch F1: 0.0
Epoch:  563        9 Batch loss: 0.206331 Batch F1: 0.0
Epoch:  563       10 Batch loss: 0.238655 Batch F1: 0.0
Epoch:  563       11 Batch loss: 0.232999 Batch F1: 0.0
Epoch:  563       12 Batch loss: 0.233722 Batch F1: 0.0
Train Avg Loss  563: 0.226138

Train Avg F1  563: 0.0

Val Avg Loss  563: 0.220745

Val Avg F1  563:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 564
--------------------------------------------------------------
Epoch:  564        1 Batch loss: 0.248450 Batch F1: 0.0
Epoch:  564        2 Batch loss: 0.223080 Batch F1: 0.0
Epoch:  564        3 Batch loss: 0.209357 Batch F1: 0.0
Epoch:  564        4 Batch loss: 0.234104 Batch F1: 0.0
Epoch:  564        5 Batch loss: 0.237720 Batch F1: 0.0
Epoch:  564        6 Batch loss: 0.238554 Batch F1: 0.0
Epoch:  564        7 Batch loss: 0.238104 Batch F1: 0.0
Epoch:  564        8 Batch loss: 0.209555 Batch F1: 0.0
Epoch:  564        9 Batch loss: 0.214219 Batch F1: 0.0
Epoch:  564       10 Batch loss: 0.217428 Batch F1: 0.0
Epoch:  564       11 Batch loss: 0.226489 Batch F1: 0.0
Epoch:  564       12 Batch loss: 0.251980 Batch F1: 0.0
Train Avg Loss  564: 0.229087

Train Avg F1  564: 0.0

Val Avg Loss  564: 0.216483

Val Avg F1  564:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 565
--------------------------------------------------------------
Epoch:  565        1 Batch loss: 0.250005 Batch F1: 0.0
Epoch:  565        2 Batch loss: 0.223817 Batch F1: 0.0
Epoch:  565        3 Batch loss: 0.211125 Batch F1: 0.0
Epoch:  565        4 Batch loss: 0.243745 Batch F1: 0.0
Epoch:  565        5 Batch loss: 0.187787 Batch F1: 0.0
Epoch:  565        6 Batch loss: 0.198684 Batch F1: 0.0
Epoch:  565        7 Batch loss: 0.247405 Batch F1: 0.0
Epoch:  565        8 Batch loss: 0.226185 Batch F1: 0.0
Epoch:  565        9 Batch loss: 0.226216 Batch F1: 0.0
Epoch:  565       10 Batch loss: 0.261341 Batch F1: 0.0
Epoch:  565       11 Batch loss: 0.243083 Batch F1: 0.0
Epoch:  565       12 Batch loss: 0.223741 Batch F1: 0.0
Train Avg Loss  565: 0.228595

Train Avg F1  565: 0.0

Val Avg Loss  565: 0.220895

Val Avg F1  565:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 566
--------------------------------------------------------------
Epoch:  566        1 Batch loss: 0.221075 Batch F1: 0.0
Epoch:  566        2 Batch loss: 0.217342 Batch F1: 0.0
Epoch:  566        3 Batch loss: 0.218912 Batch F1: 0.0
Epoch:  566        4 Batch loss: 0.244233 Batch F1: 0.0
Epoch:  566        5 Batch loss: 0.197527 Batch F1: 0.0
Epoch:  566        6 Batch loss: 0.225457 Batch F1: 0.0
Epoch:  566        7 Batch loss: 0.230305 Batch F1: 0.0
Epoch:  566        8 Batch loss: 0.206926 Batch F1: 0.0
Epoch:  566        9 Batch loss: 0.272973 Batch F1: 0.0
Epoch:  566       10 Batch loss: 0.231406 Batch F1: 0.0
Epoch:  566       11 Batch loss: 0.235439 Batch F1: 0.0
Epoch:  566       12 Batch loss: 0.234481 Batch F1: 0.0
Train Avg Loss  566: 0.228006

Train Avg F1  566: 0.0

Val Avg Loss  566: 0.227501

Val Avg F1  566:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 567
--------------------------------------------------------------
Epoch:  567        1 Batch loss: 0.231875 Batch F1: 0.0
Epoch:  567        2 Batch loss: 0.248395 Batch F1: 0.0
Epoch:  567        3 Batch loss: 0.227493 Batch F1: 0.0
Epoch:  567        4 Batch loss: 0.236796 Batch F1: 0.0
Epoch:  567        5 Batch loss: 0.228777 Batch F1: 0.0
Epoch:  567        6 Batch loss: 0.253213 Batch F1: 0.0
Epoch:  567        7 Batch loss: 0.239328 Batch F1: 0.0
Epoch:  567        8 Batch loss: 0.211609 Batch F1: 0.0
Epoch:  567        9 Batch loss: 0.217786 Batch F1: 0.0
Epoch:  567       10 Batch loss: 0.240969 Batch F1: 0.0
Epoch:  567       11 Batch loss: 0.207551 Batch F1: 0.0
Epoch:  567       12 Batch loss: 0.189722 Batch F1: 0.0
Train Avg Loss  567: 0.227793

Train Avg F1  567: 0.0

Val Avg Loss  567: 0.217212

Val Avg F1  567:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 568
--------------------------------------------------------------
Epoch:  568        1 Batch loss: 0.234709 Batch F1: 0.0
Epoch:  568        2 Batch loss: 0.216572 Batch F1: 0.0
Epoch:  568        3 Batch loss: 0.251684 Batch F1: 0.0
Epoch:  568        4 Batch loss: 0.188755 Batch F1: 0.0
Epoch:  568        5 Batch loss: 0.220861 Batch F1: 0.0
Epoch:  568        6 Batch loss: 0.244604 Batch F1: 0.0
Epoch:  568        7 Batch loss: 0.204049 Batch F1: 0.0
Epoch:  568        8 Batch loss: 0.204455 Batch F1: 0.0
Epoch:  568        9 Batch loss: 0.225704 Batch F1: 0.0
Epoch:  568       10 Batch loss: 0.238152 Batch F1: 0.0
Epoch:  568       11 Batch loss: 0.285507 Batch F1: 0.0
Epoch:  568       12 Batch loss: 0.213928 Batch F1: 0.0
Train Avg Loss  568: 0.227415

Train Avg F1  568: 0.0

Val Avg Loss  568: 0.223540

Val Avg F1  568:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 569
--------------------------------------------------------------
Epoch:  569        1 Batch loss: 0.233221 Batch F1: 0.0
Epoch:  569        2 Batch loss: 0.223499 Batch F1: 0.3478260869565218
Epoch:  569        3 Batch loss: 0.209368 Batch F1: 0.0
Epoch:  569        4 Batch loss: 0.217973 Batch F1: 0.0
Epoch:  569        5 Batch loss: 0.220576 Batch F1: 0.0
Epoch:  569        6 Batch loss: 0.225331 Batch F1: 0.0
Epoch:  569        7 Batch loss: 0.201510 Batch F1: 0.0
Epoch:  569        8 Batch loss: 0.259818 Batch F1: 0.0
Epoch:  569        9 Batch loss: 0.273474 Batch F1: 0.0
Epoch:  569       10 Batch loss: 0.244256 Batch F1: 0.0
Epoch:  569       11 Batch loss: 0.224637 Batch F1: 0.0
Epoch:  569       12 Batch loss: 0.249434 Batch F1: 0.0
Train Avg Loss  569: 0.231925

Train Avg F1  569: 0.028985507246376815

Val Avg Loss  569: 0.217794

Val Avg F1  569:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 570
--------------------------------------------------------------
Epoch:  570        1 Batch loss: 0.219708 Batch F1: 0.0
Epoch:  570        2 Batch loss: 0.239908 Batch F1: 0.0
Epoch:  570        3 Batch loss: 0.242775 Batch F1: 0.0
Epoch:  570        4 Batch loss: 0.210745 Batch F1: 0.0
Epoch:  570        5 Batch loss: 0.219335 Batch F1: 0.0
Epoch:  570        6 Batch loss: 0.244892 Batch F1: 0.0
Epoch:  570        7 Batch loss: 0.219229 Batch F1: 0.0
Epoch:  570        8 Batch loss: 0.234402 Batch F1: 0.0
Epoch:  570        9 Batch loss: 0.239880 Batch F1: 0.0
Epoch:  570       10 Batch loss: 0.186867 Batch F1: 0.0
Epoch:  570       11 Batch loss: 0.253669 Batch F1: 0.0
Epoch:  570       12 Batch loss: 0.215238 Batch F1: 0.0
Train Avg Loss  570: 0.227221

Train Avg F1  570: 0.0

Val Avg Loss  570: 0.217600

Val Avg F1  570:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 571
--------------------------------------------------------------
Epoch:  571        1 Batch loss: 0.203131 Batch F1: 0.0
Epoch:  571        2 Batch loss: 0.246168 Batch F1: 0.0
Epoch:  571        3 Batch loss: 0.230339 Batch F1: 0.0
Epoch:  571        4 Batch loss: 0.281628 Batch F1: 0.0
Epoch:  571        5 Batch loss: 0.207346 Batch F1: 0.0
Epoch:  571        6 Batch loss: 0.212812 Batch F1: 0.0
Epoch:  571        7 Batch loss: 0.212926 Batch F1: 0.0
Epoch:  571        8 Batch loss: 0.252040 Batch F1: 0.0
Epoch:  571        9 Batch loss: 0.205394 Batch F1: 0.0
Epoch:  571       10 Batch loss: 0.205939 Batch F1: 0.0
Epoch:  571       11 Batch loss: 0.272155 Batch F1: 0.0
Epoch:  571       12 Batch loss: 0.194139 Batch F1: 0.0
Train Avg Loss  571: 0.227001

Train Avg F1  571: 0.0

Val Avg Loss  571: 0.218613

Val Avg F1  571:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 572
--------------------------------------------------------------
Epoch:  572        1 Batch loss: 0.238296 Batch F1: 0.0
Epoch:  572        2 Batch loss: 0.250755 Batch F1: 0.0
Epoch:  572        3 Batch loss: 0.234888 Batch F1: 0.0
Epoch:  572        4 Batch loss: 0.247267 Batch F1: 0.0
Epoch:  572        5 Batch loss: 0.175480 Batch F1: 0.0
Epoch:  572        6 Batch loss: 0.187956 Batch F1: 0.0
Epoch:  572        7 Batch loss: 0.227807 Batch F1: 0.0
Epoch:  572        8 Batch loss: 0.217485 Batch F1: 0.0
Epoch:  572        9 Batch loss: 0.222817 Batch F1: 0.0
Epoch:  572       10 Batch loss: 0.219749 Batch F1: 0.0
Epoch:  572       11 Batch loss: 0.245046 Batch F1: 0.0
Epoch:  572       12 Batch loss: 0.261526 Batch F1: 0.0
Train Avg Loss  572: 0.227423

Train Avg F1  572: 0.0

Val Avg Loss  572: 0.217924

Val Avg F1  572:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 573
--------------------------------------------------------------
Epoch:  573        1 Batch loss: 0.216098 Batch F1: 0.0
Epoch:  573        2 Batch loss: 0.213689 Batch F1: 0.0
Epoch:  573        3 Batch loss: 0.253347 Batch F1: 0.0
Epoch:  573        4 Batch loss: 0.222916 Batch F1: 0.48275862068965514
Epoch:  573        5 Batch loss: 0.219938 Batch F1: 0.38095238095238093
Epoch:  573        6 Batch loss: 0.234396 Batch F1: 0.0
Epoch:  573        7 Batch loss: 0.225971 Batch F1: 0.0
Epoch:  573        8 Batch loss: 0.227859 Batch F1: 0.0
Epoch:  573        9 Batch loss: 0.240815 Batch F1: 0.0
Epoch:  573       10 Batch loss: 0.261290 Batch F1: 0.0
Epoch:  573       11 Batch loss: 0.199578 Batch F1: 0.0
Epoch:  573       12 Batch loss: 0.196675 Batch F1: 0.0
Train Avg Loss  573: 0.226048

Train Avg F1  573: 0.071975916803503

Val Avg Loss  573: 0.217260

Val Avg F1  573:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 574
--------------------------------------------------------------
Epoch:  574        1 Batch loss: 0.244122 Batch F1: 0.0
Epoch:  574        2 Batch loss: 0.256893 Batch F1: 0.0
Epoch:  574        3 Batch loss: 0.212809 Batch F1: 0.0
Epoch:  574        4 Batch loss: 0.217834 Batch F1: 0.0
Epoch:  574        5 Batch loss: 0.259476 Batch F1: 0.0
Epoch:  574        6 Batch loss: 0.203637 Batch F1: 0.0
Epoch:  574        7 Batch loss: 0.189536 Batch F1: 0.0
Epoch:  574        8 Batch loss: 0.245775 Batch F1: 0.0
Epoch:  574        9 Batch loss: 0.249288 Batch F1: 0.0
Epoch:  574       10 Batch loss: 0.228646 Batch F1: 0.0
Epoch:  574       11 Batch loss: 0.186109 Batch F1: 0.0
Epoch:  574       12 Batch loss: 0.224306 Batch F1: 0.0
Train Avg Loss  574: 0.226536

Train Avg F1  574: 0.0

Val Avg Loss  574: 0.217486

Val Avg F1  574:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 575
--------------------------------------------------------------
Epoch:  575        1 Batch loss: 0.276354 Batch F1: 0.0
Epoch:  575        2 Batch loss: 0.220560 Batch F1: 0.0
Epoch:  575        3 Batch loss: 0.210464 Batch F1: 0.0
Epoch:  575        4 Batch loss: 0.236193 Batch F1: 0.0
Epoch:  575        5 Batch loss: 0.202312 Batch F1: 0.0
Epoch:  575        6 Batch loss: 0.217413 Batch F1: 0.0
Epoch:  575        7 Batch loss: 0.224307 Batch F1: 0.0
Epoch:  575        8 Batch loss: 0.230863 Batch F1: 0.0
Epoch:  575        9 Batch loss: 0.218234 Batch F1: 0.0
Epoch:  575       10 Batch loss: 0.190625 Batch F1: 0.0
Epoch:  575       11 Batch loss: 0.247291 Batch F1: 0.0
Epoch:  575       12 Batch loss: 0.233869 Batch F1: 0.0
Train Avg Loss  575: 0.225707

Train Avg F1  575: 0.0

Val Avg Loss  575: 0.217397

Val Avg F1  575:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 576
--------------------------------------------------------------
Epoch:  576        1 Batch loss: 0.231377 Batch F1: 0.0
Epoch:  576        2 Batch loss: 0.227165 Batch F1: 0.0
Epoch:  576        3 Batch loss: 0.247436 Batch F1: 0.0
Epoch:  576        4 Batch loss: 0.242556 Batch F1: 0.0
Epoch:  576        5 Batch loss: 0.213286 Batch F1: 0.0
Epoch:  576        6 Batch loss: 0.205700 Batch F1: 0.0
Epoch:  576        7 Batch loss: 0.274834 Batch F1: 0.0
Epoch:  576        8 Batch loss: 0.215026 Batch F1: 0.0
Epoch:  576        9 Batch loss: 0.211697 Batch F1: 0.0
Epoch:  576       10 Batch loss: 0.241865 Batch F1: 0.0
Epoch:  576       11 Batch loss: 0.177918 Batch F1: 0.0
Epoch:  576       12 Batch loss: 0.219074 Batch F1: 0.0
Train Avg Loss  576: 0.225661

Train Avg F1  576: 0.0

Val Avg Loss  576: 0.217751

Val Avg F1  576:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 577
--------------------------------------------------------------
Epoch:  577        1 Batch loss: 0.219840 Batch F1: 0.0
Epoch:  577        2 Batch loss: 0.252950 Batch F1: 0.0
Epoch:  577        3 Batch loss: 0.197800 Batch F1: 0.0
Epoch:  577        4 Batch loss: 0.203035 Batch F1: 0.0
Epoch:  577        5 Batch loss: 0.220681 Batch F1: 0.0
Epoch:  577        6 Batch loss: 0.272081 Batch F1: 0.0
Epoch:  577        7 Batch loss: 0.224974 Batch F1: 0.0
Epoch:  577        8 Batch loss: 0.196030 Batch F1: 0.0
Epoch:  577        9 Batch loss: 0.251640 Batch F1: 0.0
Epoch:  577       10 Batch loss: 0.194650 Batch F1: 0.0
Epoch:  577       11 Batch loss: 0.245403 Batch F1: 0.0
Epoch:  577       12 Batch loss: 0.230311 Batch F1: 0.0
Train Avg Loss  577: 0.225783

Train Avg F1  577: 0.0

Val Avg Loss  577: 0.217013

Val Avg F1  577:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 578
--------------------------------------------------------------
Epoch:  578        1 Batch loss: 0.208690 Batch F1: 0.0
Epoch:  578        2 Batch loss: 0.211255 Batch F1: 0.0
Epoch:  578        3 Batch loss: 0.251251 Batch F1: 0.0
Epoch:  578        4 Batch loss: 0.217924 Batch F1: 0.0
Epoch:  578        5 Batch loss: 0.228310 Batch F1: 0.0
Epoch:  578        6 Batch loss: 0.245631 Batch F1: 0.0
Epoch:  578        7 Batch loss: 0.205548 Batch F1: 0.0
Epoch:  578        8 Batch loss: 0.219763 Batch F1: 0.0
Epoch:  578        9 Batch loss: 0.263558 Batch F1: 0.0
Epoch:  578       10 Batch loss: 0.188973 Batch F1: 0.0
Epoch:  578       11 Batch loss: 0.233787 Batch F1: 0.0
Epoch:  578       12 Batch loss: 0.233096 Batch F1: 0.0
Train Avg Loss  578: 0.225649

Train Avg F1  578: 0.0

Val Avg Loss  578: 0.218061

Val Avg F1  578:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 579
--------------------------------------------------------------
Epoch:  579        1 Batch loss: 0.214139 Batch F1: 0.0
Epoch:  579        2 Batch loss: 0.255511 Batch F1: 0.0
Epoch:  579        3 Batch loss: 0.225160 Batch F1: 0.0
Epoch:  579        4 Batch loss: 0.229607 Batch F1: 0.0
Epoch:  579        5 Batch loss: 0.244817 Batch F1: 0.0
Epoch:  579        6 Batch loss: 0.233380 Batch F1: 0.3846153846153846
Epoch:  579        7 Batch loss: 0.223026 Batch F1: 0.2608695652173913
Epoch:  579        8 Batch loss: 0.213872 Batch F1: 0.2857142857142857
Epoch:  579        9 Batch loss: 0.222236 Batch F1: 0.3478260869565218
Epoch:  579       10 Batch loss: 0.232146 Batch F1: 0.0
Epoch:  579       11 Batch loss: 0.195087 Batch F1: 0.0
Epoch:  579       12 Batch loss: 0.221937 Batch F1: 0.0
Train Avg Loss  579: 0.225910

Train Avg F1  579: 0.1065854435419653

Val Avg Loss  579: 0.217765

Val Avg F1  579:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 580
--------------------------------------------------------------
Epoch:  580        1 Batch loss: 0.207678 Batch F1: 0.0
Epoch:  580        2 Batch loss: 0.194605 Batch F1: 0.0
Epoch:  580        3 Batch loss: 0.197071 Batch F1: 0.0
Epoch:  580        4 Batch loss: 0.238067 Batch F1: 0.0
Epoch:  580        5 Batch loss: 0.227625 Batch F1: 0.0
Epoch:  580        6 Batch loss: 0.230046 Batch F1: 0.0
Epoch:  580        7 Batch loss: 0.226453 Batch F1: 0.0
Epoch:  580        8 Batch loss: 0.227627 Batch F1: 0.0
Epoch:  580        9 Batch loss: 0.249692 Batch F1: 0.0
Epoch:  580       10 Batch loss: 0.264855 Batch F1: 0.0
Epoch:  580       11 Batch loss: 0.221118 Batch F1: 0.0
Epoch:  580       12 Batch loss: 0.238366 Batch F1: 0.0
Train Avg Loss  580: 0.226933

Train Avg F1  580: 0.0

Val Avg Loss  580: 0.230380

Val Avg F1  580:  0.3818403818403818

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 581
--------------------------------------------------------------
Epoch:  581        1 Batch loss: 0.225829 Batch F1: 0.4761904761904762
Epoch:  581        2 Batch loss: 0.216495 Batch F1: 0.5185185185185185
Epoch:  581        3 Batch loss: 0.214084 Batch F1: 0.11111111111111112
Epoch:  581        4 Batch loss: 0.253258 Batch F1: 0.0
Epoch:  581        5 Batch loss: 0.229655 Batch F1: 0.0
Epoch:  581        6 Batch loss: 0.204664 Batch F1: 0.0
Epoch:  581        7 Batch loss: 0.204422 Batch F1: 0.0
Epoch:  581        8 Batch loss: 0.211589 Batch F1: 0.0
Epoch:  581        9 Batch loss: 0.281019 Batch F1: 0.0
Epoch:  581       10 Batch loss: 0.268673 Batch F1: 0.0
Epoch:  581       11 Batch loss: 0.231959 Batch F1: 0.0
Epoch:  581       12 Batch loss: 0.254221 Batch F1: 0.0
Train Avg Loss  581: 0.232989

Train Avg F1  581: 0.09215167548500881

Val Avg Loss  581: 0.221445

Val Avg F1  581:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 582
--------------------------------------------------------------
Epoch:  582        1 Batch loss: 0.258158 Batch F1: 0.0
Epoch:  582        2 Batch loss: 0.241702 Batch F1: 0.0
Epoch:  582        3 Batch loss: 0.220779 Batch F1: 0.23529411764705882
Epoch:  582        4 Batch loss: 0.245111 Batch F1: 0.0
Epoch:  582        5 Batch loss: 0.243947 Batch F1: 0.0
Epoch:  582        6 Batch loss: 0.237847 Batch F1: 0.0
Epoch:  582        7 Batch loss: 0.210930 Batch F1: 0.0
Epoch:  582        8 Batch loss: 0.229600 Batch F1: 0.0
Epoch:  582        9 Batch loss: 0.234219 Batch F1: 0.0
Epoch:  582       10 Batch loss: 0.201790 Batch F1: 0.0
Epoch:  582       11 Batch loss: 0.235830 Batch F1: 0.0
Epoch:  582       12 Batch loss: 0.200426 Batch F1: 0.0
Train Avg Loss  582: 0.230028

Train Avg F1  582: 0.0196078431372549

Val Avg Loss  582: 0.217487

Val Avg F1  582:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 583
--------------------------------------------------------------
Epoch:  583        1 Batch loss: 0.230184 Batch F1: 0.0
Epoch:  583        2 Batch loss: 0.230488 Batch F1: 0.0
Epoch:  583        3 Batch loss: 0.214343 Batch F1: 0.0
Epoch:  583        4 Batch loss: 0.242676 Batch F1: 0.0
Epoch:  583        5 Batch loss: 0.256324 Batch F1: 0.0
Epoch:  583        6 Batch loss: 0.221376 Batch F1: 0.0
Epoch:  583        7 Batch loss: 0.230717 Batch F1: 0.0
Epoch:  583        8 Batch loss: 0.205045 Batch F1: 0.0
Epoch:  583        9 Batch loss: 0.231034 Batch F1: 0.0
Epoch:  583       10 Batch loss: 0.244338 Batch F1: 0.0
Epoch:  583       11 Batch loss: 0.211736 Batch F1: 0.0
Epoch:  583       12 Batch loss: 0.237272 Batch F1: 0.0
Train Avg Loss  583: 0.229628

Train Avg F1  583: 0.0

Val Avg Loss  583: 0.217666

Val Avg F1  583:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 584
--------------------------------------------------------------
Epoch:  584        1 Batch loss: 0.230093 Batch F1: 0.0
Epoch:  584        2 Batch loss: 0.266272 Batch F1: 0.0
Epoch:  584        3 Batch loss: 0.240566 Batch F1: 0.0
Epoch:  584        4 Batch loss: 0.219513 Batch F1: 0.0
Epoch:  584        5 Batch loss: 0.233867 Batch F1: 0.0
Epoch:  584        6 Batch loss: 0.200369 Batch F1: 0.0
Epoch:  584        7 Batch loss: 0.220716 Batch F1: 0.0
Epoch:  584        8 Batch loss: 0.216799 Batch F1: 0.0
Epoch:  584        9 Batch loss: 0.226077 Batch F1: 0.0
Epoch:  584       10 Batch loss: 0.198999 Batch F1: 0.0
Epoch:  584       11 Batch loss: 0.231294 Batch F1: 0.0
Epoch:  584       12 Batch loss: 0.267975 Batch F1: 0.0
Train Avg Loss  584: 0.229378

Train Avg F1  584: 0.0

Val Avg Loss  584: 0.217154

Val Avg F1  584:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 585
--------------------------------------------------------------
Epoch:  585        1 Batch loss: 0.233948 Batch F1: 0.0
Epoch:  585        2 Batch loss: 0.220339 Batch F1: 0.0
Epoch:  585        3 Batch loss: 0.236833 Batch F1: 0.0
Epoch:  585        4 Batch loss: 0.226734 Batch F1: 0.0
Epoch:  585        5 Batch loss: 0.243232 Batch F1: 0.0
Epoch:  585        6 Batch loss: 0.206815 Batch F1: 0.0
Epoch:  585        7 Batch loss: 0.222810 Batch F1: 0.0
Epoch:  585        8 Batch loss: 0.213177 Batch F1: 0.0
Epoch:  585        9 Batch loss: 0.221120 Batch F1: 0.0
Epoch:  585       10 Batch loss: 0.272199 Batch F1: 0.0
Epoch:  585       11 Batch loss: 0.209323 Batch F1: 0.0
Epoch:  585       12 Batch loss: 0.224718 Batch F1: 0.0
Train Avg Loss  585: 0.227604

Train Avg F1  585: 0.0

Val Avg Loss  585: 0.217610

Val Avg F1  585:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 586
--------------------------------------------------------------
Epoch:  586        1 Batch loss: 0.220152 Batch F1: 0.0
Epoch:  586        2 Batch loss: 0.199811 Batch F1: 0.0
Epoch:  586        3 Batch loss: 0.218958 Batch F1: 0.0
Epoch:  586        4 Batch loss: 0.238231 Batch F1: 0.0
Epoch:  586        5 Batch loss: 0.236628 Batch F1: 0.0
Epoch:  586        6 Batch loss: 0.205744 Batch F1: 0.0
Epoch:  586        7 Batch loss: 0.204065 Batch F1: 0.0
Epoch:  586        8 Batch loss: 0.222768 Batch F1: 0.0
Epoch:  586        9 Batch loss: 0.252035 Batch F1: 0.0
Epoch:  586       10 Batch loss: 0.255121 Batch F1: 0.0
Epoch:  586       11 Batch loss: 0.223532 Batch F1: 0.0
Epoch:  586       12 Batch loss: 0.258462 Batch F1: 0.0
Train Avg Loss  586: 0.227959

Train Avg F1  586: 0.0

Val Avg Loss  586: 0.217895

Val Avg F1  586:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 587
--------------------------------------------------------------
Epoch:  587        1 Batch loss: 0.195356 Batch F1: 0.0
Epoch:  587        2 Batch loss: 0.237420 Batch F1: 0.0
Epoch:  587        3 Batch loss: 0.238629 Batch F1: 0.0
Epoch:  587        4 Batch loss: 0.212545 Batch F1: 0.0
Epoch:  587        5 Batch loss: 0.243320 Batch F1: 0.0
Epoch:  587        6 Batch loss: 0.215835 Batch F1: 0.0
Epoch:  587        7 Batch loss: 0.229912 Batch F1: 0.0
Epoch:  587        8 Batch loss: 0.229752 Batch F1: 0.0
Epoch:  587        9 Batch loss: 0.227915 Batch F1: 0.0
Epoch:  587       10 Batch loss: 0.242043 Batch F1: 0.0
Epoch:  587       11 Batch loss: 0.246340 Batch F1: 0.0
Epoch:  587       12 Batch loss: 0.195385 Batch F1: 0.0
Train Avg Loss  587: 0.226204

Train Avg F1  587: 0.0

Val Avg Loss  587: 0.219122

Val Avg F1  587:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 588
--------------------------------------------------------------
Epoch:  588        1 Batch loss: 0.201812 Batch F1: 0.0
Epoch:  588        2 Batch loss: 0.234353 Batch F1: 0.0
Epoch:  588        3 Batch loss: 0.261614 Batch F1: 0.0
Epoch:  588        4 Batch loss: 0.251980 Batch F1: 0.0
Epoch:  588        5 Batch loss: 0.237539 Batch F1: 0.0
Epoch:  588        6 Batch loss: 0.198356 Batch F1: 0.0
Epoch:  588        7 Batch loss: 0.227498 Batch F1: 0.0
Epoch:  588        8 Batch loss: 0.226524 Batch F1: 0.0
Epoch:  588        9 Batch loss: 0.227741 Batch F1: 0.0
Epoch:  588       10 Batch loss: 0.194121 Batch F1: 0.0
Epoch:  588       11 Batch loss: 0.236044 Batch F1: 0.0
Epoch:  588       12 Batch loss: 0.228978 Batch F1: 0.0
Train Avg Loss  588: 0.227213

Train Avg F1  588: 0.0

Val Avg Loss  588: 0.218613

Val Avg F1  588:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 589
--------------------------------------------------------------
Epoch:  589        1 Batch loss: 0.221174 Batch F1: 0.0
Epoch:  589        2 Batch loss: 0.236063 Batch F1: 0.0
Epoch:  589        3 Batch loss: 0.235156 Batch F1: 0.0
Epoch:  589        4 Batch loss: 0.229736 Batch F1: 0.32000000000000006
Epoch:  589        5 Batch loss: 0.229519 Batch F1: 0.2857142857142857
Epoch:  589        6 Batch loss: 0.213416 Batch F1: 0.3703703703703704
Epoch:  589        7 Batch loss: 0.224342 Batch F1: 0.42857142857142855
Epoch:  589        8 Batch loss: 0.203974 Batch F1: 0.2222222222222222
Epoch:  589        9 Batch loss: 0.225754 Batch F1: 0.0
Epoch:  589       10 Batch loss: 0.279369 Batch F1: 0.0
Epoch:  589       11 Batch loss: 0.204773 Batch F1: 0.0
Epoch:  589       12 Batch loss: 0.213668 Batch F1: 0.0
Train Avg Loss  589: 0.226412

Train Avg F1  589: 0.1355731922398589

Val Avg Loss  589: 0.217053

Val Avg F1  589:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 590
--------------------------------------------------------------
Epoch:  590        1 Batch loss: 0.203127 Batch F1: 0.0
Epoch:  590        2 Batch loss: 0.234460 Batch F1: 0.0
Epoch:  590        3 Batch loss: 0.243670 Batch F1: 0.0
Epoch:  590        4 Batch loss: 0.213954 Batch F1: 0.0
Epoch:  590        5 Batch loss: 0.237360 Batch F1: 0.0
Epoch:  590        6 Batch loss: 0.215168 Batch F1: 0.0
Epoch:  590        7 Batch loss: 0.218264 Batch F1: 0.0
Epoch:  590        8 Batch loss: 0.262271 Batch F1: 0.0
Epoch:  590        9 Batch loss: 0.213295 Batch F1: 0.0
Epoch:  590       10 Batch loss: 0.207985 Batch F1: 0.0
Epoch:  590       11 Batch loss: 0.218147 Batch F1: 0.0
Epoch:  590       12 Batch loss: 0.265242 Batch F1: 0.0
Train Avg Loss  590: 0.227745

Train Avg F1  590: 0.0

Val Avg Loss  590: 0.218214

Val Avg F1  590:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 591
--------------------------------------------------------------
Epoch:  591        1 Batch loss: 0.232354 Batch F1: 0.0
Epoch:  591        2 Batch loss: 0.234051 Batch F1: 0.0
Epoch:  591        3 Batch loss: 0.215269 Batch F1: 0.0
Epoch:  591        4 Batch loss: 0.233092 Batch F1: 0.0
Epoch:  591        5 Batch loss: 0.216029 Batch F1: 0.0
Epoch:  591        6 Batch loss: 0.198517 Batch F1: 0.0
Epoch:  591        7 Batch loss: 0.243743 Batch F1: 0.0
Epoch:  591        8 Batch loss: 0.239368 Batch F1: 0.0
Epoch:  591        9 Batch loss: 0.241461 Batch F1: 0.0
Epoch:  591       10 Batch loss: 0.221876 Batch F1: 0.0
Epoch:  591       11 Batch loss: 0.220238 Batch F1: 0.0
Epoch:  591       12 Batch loss: 0.232779 Batch F1: 0.0
Train Avg Loss  591: 0.227398

Train Avg F1  591: 0.0

Val Avg Loss  591: 0.220632

Val Avg F1  591:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 592
--------------------------------------------------------------
Epoch:  592        1 Batch loss: 0.216341 Batch F1: 0.0
Epoch:  592        2 Batch loss: 0.220730 Batch F1: 0.0
Epoch:  592        3 Batch loss: 0.272026 Batch F1: 0.0
Epoch:  592        4 Batch loss: 0.212424 Batch F1: 0.0
Epoch:  592        5 Batch loss: 0.227182 Batch F1: 0.0
Epoch:  592        6 Batch loss: 0.226779 Batch F1: 0.0
Epoch:  592        7 Batch loss: 0.243951 Batch F1: 0.0
Epoch:  592        8 Batch loss: 0.212339 Batch F1: 0.0
Epoch:  592        9 Batch loss: 0.226423 Batch F1: 0.0
Epoch:  592       10 Batch loss: 0.223451 Batch F1: 0.0
Epoch:  592       11 Batch loss: 0.208253 Batch F1: 0.0
Epoch:  592       12 Batch loss: 0.234784 Batch F1: 0.0
Train Avg Loss  592: 0.227057

Train Avg F1  592: 0.0

Val Avg Loss  592: 0.218058

Val Avg F1  592:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 593
--------------------------------------------------------------
Epoch:  593        1 Batch loss: 0.236213 Batch F1: 0.0
Epoch:  593        2 Batch loss: 0.243707 Batch F1: 0.0
Epoch:  593        3 Batch loss: 0.245526 Batch F1: 0.0
Epoch:  593        4 Batch loss: 0.227915 Batch F1: 0.0
Epoch:  593        5 Batch loss: 0.244769 Batch F1: 0.0
Epoch:  593        6 Batch loss: 0.213362 Batch F1: 0.0
Epoch:  593        7 Batch loss: 0.228107 Batch F1: 0.0
Epoch:  593        8 Batch loss: 0.222963 Batch F1: 0.0
Epoch:  593        9 Batch loss: 0.211272 Batch F1: 0.0
Epoch:  593       10 Batch loss: 0.213866 Batch F1: 0.0
Epoch:  593       11 Batch loss: 0.209846 Batch F1: 0.0
Epoch:  593       12 Batch loss: 0.224189 Batch F1: 0.0
Train Avg Loss  593: 0.226811

Train Avg F1  593: 0.0

Val Avg Loss  593: 0.216559

Val Avg F1  593:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 594
--------------------------------------------------------------
Epoch:  594        1 Batch loss: 0.255516 Batch F1: 0.0
Epoch:  594        2 Batch loss: 0.245028 Batch F1: 0.0
Epoch:  594        3 Batch loss: 0.237811 Batch F1: 0.0
Epoch:  594        4 Batch loss: 0.212234 Batch F1: 0.0
Epoch:  594        5 Batch loss: 0.244946 Batch F1: 0.0
Epoch:  594        6 Batch loss: 0.200568 Batch F1: 0.0
Epoch:  594        7 Batch loss: 0.227664 Batch F1: 0.0
Epoch:  594        8 Batch loss: 0.213245 Batch F1: 0.0
Epoch:  594        9 Batch loss: 0.238724 Batch F1: 0.0
Epoch:  594       10 Batch loss: 0.203206 Batch F1: 0.0
Epoch:  594       11 Batch loss: 0.220440 Batch F1: 0.0
Epoch:  594       12 Batch loss: 0.224568 Batch F1: 0.0
Train Avg Loss  594: 0.226996

Train Avg F1  594: 0.0

Val Avg Loss  594: 0.217075

Val Avg F1  594:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 595
--------------------------------------------------------------
Epoch:  595        1 Batch loss: 0.234486 Batch F1: 0.0
Epoch:  595        2 Batch loss: 0.229357 Batch F1: 0.0
Epoch:  595        3 Batch loss: 0.213661 Batch F1: 0.0
Epoch:  595        4 Batch loss: 0.224173 Batch F1: 0.0
Epoch:  595        5 Batch loss: 0.235773 Batch F1: 0.0
Epoch:  595        6 Batch loss: 0.237341 Batch F1: 0.0
Epoch:  595        7 Batch loss: 0.232087 Batch F1: 0.0
Epoch:  595        8 Batch loss: 0.218842 Batch F1: 0.0
Epoch:  595        9 Batch loss: 0.216248 Batch F1: 0.0
Epoch:  595       10 Batch loss: 0.258203 Batch F1: 0.0
Epoch:  595       11 Batch loss: 0.204749 Batch F1: 0.0
Epoch:  595       12 Batch loss: 0.200573 Batch F1: 0.0
Train Avg Loss  595: 0.225458

Train Avg F1  595: 0.0

Val Avg Loss  595: 0.217256

Val Avg F1  595:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 596
--------------------------------------------------------------
Epoch:  596        1 Batch loss: 0.221279 Batch F1: 0.0
Epoch:  596        2 Batch loss: 0.225964 Batch F1: 0.0
Epoch:  596        3 Batch loss: 0.192018 Batch F1: 0.0
Epoch:  596        4 Batch loss: 0.211443 Batch F1: 0.0
Epoch:  596        5 Batch loss: 0.207937 Batch F1: 0.0
Epoch:  596        6 Batch loss: 0.260370 Batch F1: 0.0
Epoch:  596        7 Batch loss: 0.215482 Batch F1: 0.0
Epoch:  596        8 Batch loss: 0.251679 Batch F1: 0.0
Epoch:  596        9 Batch loss: 0.262561 Batch F1: 0.0
Epoch:  596       10 Batch loss: 0.210008 Batch F1: 0.0
Epoch:  596       11 Batch loss: 0.220870 Batch F1: 0.0
Epoch:  596       12 Batch loss: 0.231663 Batch F1: 0.0
Train Avg Loss  596: 0.225940

Train Avg F1  596: 0.0

Val Avg Loss  596: 0.217502

Val Avg F1  596:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 597
--------------------------------------------------------------
Epoch:  597        1 Batch loss: 0.191733 Batch F1: 0.0
Epoch:  597        2 Batch loss: 0.243175 Batch F1: 0.0
Epoch:  597        3 Batch loss: 0.266847 Batch F1: 0.0
Epoch:  597        4 Batch loss: 0.215099 Batch F1: 0.0
Epoch:  597        5 Batch loss: 0.222310 Batch F1: 0.0
Epoch:  597        6 Batch loss: 0.190273 Batch F1: 0.0
Epoch:  597        7 Batch loss: 0.250589 Batch F1: 0.0
Epoch:  597        8 Batch loss: 0.228834 Batch F1: 0.0
Epoch:  597        9 Batch loss: 0.198924 Batch F1: 0.0
Epoch:  597       10 Batch loss: 0.256359 Batch F1: 0.0
Epoch:  597       11 Batch loss: 0.192130 Batch F1: 0.0
Epoch:  597       12 Batch loss: 0.262586 Batch F1: 0.0
Train Avg Loss  597: 0.226572

Train Avg F1  597: 0.0

Val Avg Loss  597: 0.217171

Val Avg F1  597:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 598
--------------------------------------------------------------
Epoch:  598        1 Batch loss: 0.237599 Batch F1: 0.0
Epoch:  598        2 Batch loss: 0.220134 Batch F1: 0.0
Epoch:  598        3 Batch loss: 0.275557 Batch F1: 0.0
Epoch:  598        4 Batch loss: 0.207882 Batch F1: 0.0
Epoch:  598        5 Batch loss: 0.212074 Batch F1: 0.0
Epoch:  598        6 Batch loss: 0.217613 Batch F1: 0.0
Epoch:  598        7 Batch loss: 0.205047 Batch F1: 0.0
Epoch:  598        8 Batch loss: 0.221964 Batch F1: 0.0
Epoch:  598        9 Batch loss: 0.232985 Batch F1: 0.0
Epoch:  598       10 Batch loss: 0.218708 Batch F1: 0.0
Epoch:  598       11 Batch loss: 0.245089 Batch F1: 0.0
Epoch:  598       12 Batch loss: 0.219208 Batch F1: 0.0
Train Avg Loss  598: 0.226155

Train Avg F1  598: 0.0

Val Avg Loss  598: 0.216858

Val Avg F1  598:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 599
--------------------------------------------------------------
Epoch:  599        1 Batch loss: 0.227528 Batch F1: 0.0
Epoch:  599        2 Batch loss: 0.228372 Batch F1: 0.0
Epoch:  599        3 Batch loss: 0.194977 Batch F1: 0.0
Epoch:  599        4 Batch loss: 0.247775 Batch F1: 0.0
Epoch:  599        5 Batch loss: 0.282943 Batch F1: 0.0
Epoch:  599        6 Batch loss: 0.228932 Batch F1: 0.0
Epoch:  599        7 Batch loss: 0.184244 Batch F1: 0.0
Epoch:  599        8 Batch loss: 0.235380 Batch F1: 0.0
Epoch:  599        9 Batch loss: 0.232464 Batch F1: 0.0
Epoch:  599       10 Batch loss: 0.181457 Batch F1: 0.0
Epoch:  599       11 Batch loss: 0.224869 Batch F1: 0.0
Epoch:  599       12 Batch loss: 0.250192 Batch F1: 0.0
Train Avg Loss  599: 0.226595

Train Avg F1  599: 0.0

Val Avg Loss  599: 0.217174

Val Avg F1  599:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 600
--------------------------------------------------------------
Epoch:  600        1 Batch loss: 0.232835 Batch F1: 0.0
Epoch:  600        2 Batch loss: 0.229633 Batch F1: 0.0
Epoch:  600        3 Batch loss: 0.218448 Batch F1: 0.0
Epoch:  600        4 Batch loss: 0.216250 Batch F1: 0.0
Epoch:  600        5 Batch loss: 0.236599 Batch F1: 0.0
Epoch:  600        6 Batch loss: 0.218912 Batch F1: 0.0
Epoch:  600        7 Batch loss: 0.225105 Batch F1: 0.0
Epoch:  600        8 Batch loss: 0.247023 Batch F1: 0.0
Epoch:  600        9 Batch loss: 0.214355 Batch F1: 0.0
Epoch:  600       10 Batch loss: 0.205632 Batch F1: 0.0
Epoch:  600       11 Batch loss: 0.230096 Batch F1: 0.0
Epoch:  600       12 Batch loss: 0.237612 Batch F1: 0.0
Train Avg Loss  600: 0.226042

Train Avg F1  600: 0.0

Val Avg Loss  600: 0.217121

Val Avg F1  600:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 601
--------------------------------------------------------------
Epoch:  601        1 Batch loss: 0.233412 Batch F1: 0.0
Epoch:  601        2 Batch loss: 0.231756 Batch F1: 0.0
Epoch:  601        3 Batch loss: 0.215534 Batch F1: 0.0
Epoch:  601        4 Batch loss: 0.204331 Batch F1: 0.0
Epoch:  601        5 Batch loss: 0.228365 Batch F1: 0.0
Epoch:  601        6 Batch loss: 0.211014 Batch F1: 0.0
Epoch:  601        7 Batch loss: 0.210720 Batch F1: 0.0
Epoch:  601        8 Batch loss: 0.246523 Batch F1: 0.0
Epoch:  601        9 Batch loss: 0.212967 Batch F1: 0.0
Epoch:  601       10 Batch loss: 0.237639 Batch F1: 0.0
Epoch:  601       11 Batch loss: 0.223639 Batch F1: 0.0
Epoch:  601       12 Batch loss: 0.261298 Batch F1: 0.0
Train Avg Loss  601: 0.226433

Train Avg F1  601: 0.0

Val Avg Loss  601: 0.217676

Val Avg F1  601:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 602
--------------------------------------------------------------
Epoch:  602        1 Batch loss: 0.184261 Batch F1: 0.0
Epoch:  602        2 Batch loss: 0.197676 Batch F1: 0.0
Epoch:  602        3 Batch loss: 0.225874 Batch F1: 0.0
Epoch:  602        4 Batch loss: 0.215148 Batch F1: 0.0
Epoch:  602        5 Batch loss: 0.232527 Batch F1: 0.0
Epoch:  602        6 Batch loss: 0.229256 Batch F1: 0.0
Epoch:  602        7 Batch loss: 0.232513 Batch F1: 0.0
Epoch:  602        8 Batch loss: 0.221312 Batch F1: 0.0
Epoch:  602        9 Batch loss: 0.243735 Batch F1: 0.0
Epoch:  602       10 Batch loss: 0.261885 Batch F1: 0.0
Epoch:  602       11 Batch loss: 0.207985 Batch F1: 0.0
Epoch:  602       12 Batch loss: 0.262258 Batch F1: 0.0
Train Avg Loss  602: 0.226202

Train Avg F1  602: 0.0

Val Avg Loss  602: 0.221930

Val Avg F1  602:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 603
--------------------------------------------------------------
Epoch:  603        1 Batch loss: 0.215075 Batch F1: 0.0
Epoch:  603        2 Batch loss: 0.257711 Batch F1: 0.0
Epoch:  603        3 Batch loss: 0.222613 Batch F1: 0.1739130434782609
Epoch:  603        4 Batch loss: 0.250318 Batch F1: 0.23999999999999996
Epoch:  603        5 Batch loss: 0.216477 Batch F1: 0.39999999999999997
Epoch:  603        6 Batch loss: 0.209448 Batch F1: 0.46153846153846156
Epoch:  603        7 Batch loss: 0.226226 Batch F1: 0.0
Epoch:  603        8 Batch loss: 0.207706 Batch F1: 0.0
Epoch:  603        9 Batch loss: 0.217227 Batch F1: 0.0
Epoch:  603       10 Batch loss: 0.268551 Batch F1: 0.0
Epoch:  603       11 Batch loss: 0.210915 Batch F1: 0.0
Epoch:  603       12 Batch loss: 0.228597 Batch F1: 0.0
Train Avg Loss  603: 0.227572

Train Avg F1  603: 0.10628762541806021

Val Avg Loss  603: 0.219352

Val Avg F1  603:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 604
--------------------------------------------------------------
Epoch:  604        1 Batch loss: 0.234398 Batch F1: 0.0
Epoch:  604        2 Batch loss: 0.196045 Batch F1: 0.0
Epoch:  604        3 Batch loss: 0.238626 Batch F1: 0.0
Epoch:  604        4 Batch loss: 0.221706 Batch F1: 0.0
Epoch:  604        5 Batch loss: 0.209336 Batch F1: 0.0
Epoch:  604        6 Batch loss: 0.236389 Batch F1: 0.0
Epoch:  604        7 Batch loss: 0.254464 Batch F1: 0.0
Epoch:  604        8 Batch loss: 0.234775 Batch F1: 0.0
Epoch:  604        9 Batch loss: 0.261053 Batch F1: 0.0
Epoch:  604       10 Batch loss: 0.198655 Batch F1: 0.0
Epoch:  604       11 Batch loss: 0.201388 Batch F1: 0.0
Epoch:  604       12 Batch loss: 0.242265 Batch F1: 0.0
Train Avg Loss  604: 0.227425

Train Avg F1  604: 0.0

Val Avg Loss  604: 0.216675

Val Avg F1  604:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 605
--------------------------------------------------------------
Epoch:  605        1 Batch loss: 0.247129 Batch F1: 0.0
Epoch:  605        2 Batch loss: 0.209825 Batch F1: 0.0
Epoch:  605        3 Batch loss: 0.221033 Batch F1: 0.0
Epoch:  605        4 Batch loss: 0.239203 Batch F1: 0.0
Epoch:  605        5 Batch loss: 0.187328 Batch F1: 0.0
Epoch:  605        6 Batch loss: 0.210791 Batch F1: 0.0
Epoch:  605        7 Batch loss: 0.208771 Batch F1: 0.0
Epoch:  605        8 Batch loss: 0.212931 Batch F1: 0.0
Epoch:  605        9 Batch loss: 0.256503 Batch F1: 0.0
Epoch:  605       10 Batch loss: 0.249405 Batch F1: 0.0
Epoch:  605       11 Batch loss: 0.272434 Batch F1: 0.0
Epoch:  605       12 Batch loss: 0.205058 Batch F1: 0.0
Train Avg Loss  605: 0.226701

Train Avg F1  605: 0.0

Val Avg Loss  605: 0.222182

Val Avg F1  605:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 606
--------------------------------------------------------------
Epoch:  606        1 Batch loss: 0.257999 Batch F1: 0.0
Epoch:  606        2 Batch loss: 0.218871 Batch F1: 0.4444444444444445
Epoch:  606        3 Batch loss: 0.215135 Batch F1: 0.45161290322580644
Epoch:  606        4 Batch loss: 0.236294 Batch F1: 0.35714285714285715
Epoch:  606        5 Batch loss: 0.241020 Batch F1: 0.0
Epoch:  606        6 Batch loss: 0.228781 Batch F1: 0.0
Epoch:  606        7 Batch loss: 0.205397 Batch F1: 0.0
Epoch:  606        8 Batch loss: 0.214030 Batch F1: 0.0
Epoch:  606        9 Batch loss: 0.225567 Batch F1: 0.0
Epoch:  606       10 Batch loss: 0.268004 Batch F1: 0.0
Epoch:  606       11 Batch loss: 0.211509 Batch F1: 0.0
Epoch:  606       12 Batch loss: 0.221073 Batch F1: 0.0
Train Avg Loss  606: 0.228640

Train Avg F1  606: 0.10443335040109235

Val Avg Loss  606: 0.218209

Val Avg F1  606:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 607
--------------------------------------------------------------
Epoch:  607        1 Batch loss: 0.216929 Batch F1: 0.0
Epoch:  607        2 Batch loss: 0.206649 Batch F1: 0.0
Epoch:  607        3 Batch loss: 0.233231 Batch F1: 0.0
Epoch:  607        4 Batch loss: 0.235938 Batch F1: 0.0
Epoch:  607        5 Batch loss: 0.239400 Batch F1: 0.0
Epoch:  607        6 Batch loss: 0.244781 Batch F1: 0.0
Epoch:  607        7 Batch loss: 0.221025 Batch F1: 0.0
Epoch:  607        8 Batch loss: 0.233431 Batch F1: 0.0
Epoch:  607        9 Batch loss: 0.229330 Batch F1: 0.0
Epoch:  607       10 Batch loss: 0.203938 Batch F1: 0.0
Epoch:  607       11 Batch loss: 0.251790 Batch F1: 0.0
Epoch:  607       12 Batch loss: 0.206471 Batch F1: 0.0
Train Avg Loss  607: 0.226909

Train Avg F1  607: 0.0

Val Avg Loss  607: 0.218217

Val Avg F1  607:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 608
--------------------------------------------------------------
Epoch:  608        1 Batch loss: 0.242391 Batch F1: 0.0
Epoch:  608        2 Batch loss: 0.185845 Batch F1: 0.0
Epoch:  608        3 Batch loss: 0.232521 Batch F1: 0.0
Epoch:  608        4 Batch loss: 0.208594 Batch F1: 0.0
Epoch:  608        5 Batch loss: 0.206171 Batch F1: 0.0
Epoch:  608        6 Batch loss: 0.224379 Batch F1: 0.0
Epoch:  608        7 Batch loss: 0.255004 Batch F1: 0.0
Epoch:  608        8 Batch loss: 0.258594 Batch F1: 0.0
Epoch:  608        9 Batch loss: 0.202409 Batch F1: 0.0
Epoch:  608       10 Batch loss: 0.223519 Batch F1: 0.0
Epoch:  608       11 Batch loss: 0.247070 Batch F1: 0.0
Epoch:  608       12 Batch loss: 0.245901 Batch F1: 0.0
Train Avg Loss  608: 0.227700

Train Avg F1  608: 0.0

Val Avg Loss  608: 0.219242

Val Avg F1  608:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 609
--------------------------------------------------------------
Epoch:  609        1 Batch loss: 0.210702 Batch F1: 0.0
Epoch:  609        2 Batch loss: 0.238506 Batch F1: 0.0
Epoch:  609        3 Batch loss: 0.256092 Batch F1: 0.0
Epoch:  609        4 Batch loss: 0.217593 Batch F1: 0.0
Epoch:  609        5 Batch loss: 0.216072 Batch F1: 0.0
Epoch:  609        6 Batch loss: 0.228658 Batch F1: 0.0
Epoch:  609        7 Batch loss: 0.219731 Batch F1: 0.0
Epoch:  609        8 Batch loss: 0.212800 Batch F1: 0.0
Epoch:  609        9 Batch loss: 0.217150 Batch F1: 0.0
Epoch:  609       10 Batch loss: 0.222521 Batch F1: 0.0
Epoch:  609       11 Batch loss: 0.256357 Batch F1: 0.0
Epoch:  609       12 Batch loss: 0.227996 Batch F1: 0.0
Train Avg Loss  609: 0.227015

Train Avg F1  609: 0.0

Val Avg Loss  609: 0.220132

Val Avg F1  609:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 610
--------------------------------------------------------------
Epoch:  610        1 Batch loss: 0.246363 Batch F1: 0.0
Epoch:  610        2 Batch loss: 0.216014 Batch F1: 0.0
Epoch:  610        3 Batch loss: 0.233088 Batch F1: 0.0
Epoch:  610        4 Batch loss: 0.250796 Batch F1: 0.0
Epoch:  610        5 Batch loss: 0.245772 Batch F1: 0.3529411764705882
Epoch:  610        6 Batch loss: 0.208117 Batch F1: 0.4545454545454545
Epoch:  610        7 Batch loss: 0.231837 Batch F1: 0.19047619047619047
Epoch:  610        8 Batch loss: 0.228652 Batch F1: 0.0
Epoch:  610        9 Batch loss: 0.200892 Batch F1: 0.0
Epoch:  610       10 Batch loss: 0.216724 Batch F1: 0.0
Epoch:  610       11 Batch loss: 0.251762 Batch F1: 0.0
Epoch:  610       12 Batch loss: 0.221309 Batch F1: 0.0
Train Avg Loss  610: 0.229277

Train Avg F1  610: 0.08316356845768609

Val Avg Loss  610: 0.219256

Val Avg F1  610:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 611
--------------------------------------------------------------
Epoch:  611        1 Batch loss: 0.203041 Batch F1: 0.0
Epoch:  611        2 Batch loss: 0.244949 Batch F1: 0.0
Epoch:  611        3 Batch loss: 0.239999 Batch F1: 0.0
Epoch:  611        4 Batch loss: 0.230363 Batch F1: 0.0
Epoch:  611        5 Batch loss: 0.202101 Batch F1: 0.0
Epoch:  611        6 Batch loss: 0.212251 Batch F1: 0.0
Epoch:  611        7 Batch loss: 0.208577 Batch F1: 0.0
Epoch:  611        8 Batch loss: 0.246341 Batch F1: 0.0
Epoch:  611        9 Batch loss: 0.250004 Batch F1: 0.0
Epoch:  611       10 Batch loss: 0.241174 Batch F1: 0.0
Epoch:  611       11 Batch loss: 0.222430 Batch F1: 0.0
Epoch:  611       12 Batch loss: 0.266365 Batch F1: 0.0
Train Avg Loss  611: 0.230633

Train Avg F1  611: 0.0

Val Avg Loss  611: 0.220591

Val Avg F1  611:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 612
--------------------------------------------------------------
Epoch:  612        1 Batch loss: 0.223633 Batch F1: 0.0
Epoch:  612        2 Batch loss: 0.224475 Batch F1: 0.0
Epoch:  612        3 Batch loss: 0.220702 Batch F1: 0.0
Epoch:  612        4 Batch loss: 0.223646 Batch F1: 0.0
Epoch:  612        5 Batch loss: 0.223822 Batch F1: 0.0
Epoch:  612        6 Batch loss: 0.244601 Batch F1: 0.0
Epoch:  612        7 Batch loss: 0.242106 Batch F1: 0.0
Epoch:  612        8 Batch loss: 0.218661 Batch F1: 0.0
Epoch:  612        9 Batch loss: 0.236266 Batch F1: 0.0
Epoch:  612       10 Batch loss: 0.217432 Batch F1: 0.0
Epoch:  612       11 Batch loss: 0.211053 Batch F1: 0.0
Epoch:  612       12 Batch loss: 0.264109 Batch F1: 0.0
Train Avg Loss  612: 0.229209

Train Avg F1  612: 0.0

Val Avg Loss  612: 0.218329

Val Avg F1  612:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 613
--------------------------------------------------------------
Epoch:  613        1 Batch loss: 0.224261 Batch F1: 0.0
Epoch:  613        2 Batch loss: 0.221220 Batch F1: 0.0
Epoch:  613        3 Batch loss: 0.257722 Batch F1: 0.0
Epoch:  613        4 Batch loss: 0.212715 Batch F1: 0.0
Epoch:  613        5 Batch loss: 0.240458 Batch F1: 0.0
Epoch:  613        6 Batch loss: 0.194139 Batch F1: 0.0
Epoch:  613        7 Batch loss: 0.226177 Batch F1: 0.0
Epoch:  613        8 Batch loss: 0.231131 Batch F1: 0.0
Epoch:  613        9 Batch loss: 0.236834 Batch F1: 0.0
Epoch:  613       10 Batch loss: 0.229766 Batch F1: 0.0
Epoch:  613       11 Batch loss: 0.226153 Batch F1: 0.0
Epoch:  613       12 Batch loss: 0.226301 Batch F1: 0.0
Train Avg Loss  613: 0.227240

Train Avg F1  613: 0.0

Val Avg Loss  613: 0.217942

Val Avg F1  613:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 614
--------------------------------------------------------------
Epoch:  614        1 Batch loss: 0.237309 Batch F1: 0.0
Epoch:  614        2 Batch loss: 0.208382 Batch F1: 0.0
Epoch:  614        3 Batch loss: 0.229738 Batch F1: 0.0
Epoch:  614        4 Batch loss: 0.220734 Batch F1: 0.0
Epoch:  614        5 Batch loss: 0.227186 Batch F1: 0.0
Epoch:  614        6 Batch loss: 0.199710 Batch F1: 0.0
Epoch:  614        7 Batch loss: 0.216331 Batch F1: 0.0
Epoch:  614        8 Batch loss: 0.249080 Batch F1: 0.0
Epoch:  614        9 Batch loss: 0.221351 Batch F1: 0.0
Epoch:  614       10 Batch loss: 0.247573 Batch F1: 0.0
Epoch:  614       11 Batch loss: 0.232812 Batch F1: 0.0
Epoch:  614       12 Batch loss: 0.227022 Batch F1: 0.0
Train Avg Loss  614: 0.226436

Train Avg F1  614: 0.0

Val Avg Loss  614: 0.217830

Val Avg F1  614:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 615
--------------------------------------------------------------
Epoch:  615        1 Batch loss: 0.230336 Batch F1: 0.0
Epoch:  615        2 Batch loss: 0.257489 Batch F1: 0.0
Epoch:  615        3 Batch loss: 0.214744 Batch F1: 0.0
Epoch:  615        4 Batch loss: 0.223404 Batch F1: 0.0
Epoch:  615        5 Batch loss: 0.212829 Batch F1: 0.0
Epoch:  615        6 Batch loss: 0.251183 Batch F1: 0.0
Epoch:  615        7 Batch loss: 0.227360 Batch F1: 0.0
Epoch:  615        8 Batch loss: 0.223477 Batch F1: 0.0
Epoch:  615        9 Batch loss: 0.239431 Batch F1: 0.0
Epoch:  615       10 Batch loss: 0.216174 Batch F1: 0.0
Epoch:  615       11 Batch loss: 0.183817 Batch F1: 0.0
Epoch:  615       12 Batch loss: 0.231025 Batch F1: 0.0
Train Avg Loss  615: 0.225939

Train Avg F1  615: 0.0

Val Avg Loss  615: 0.216566

Val Avg F1  615:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 616
--------------------------------------------------------------
Epoch:  616        1 Batch loss: 0.240692 Batch F1: 0.0
Epoch:  616        2 Batch loss: 0.200546 Batch F1: 0.0
Epoch:  616        3 Batch loss: 0.243491 Batch F1: 0.0
Epoch:  616        4 Batch loss: 0.240139 Batch F1: 0.0
Epoch:  616        5 Batch loss: 0.211659 Batch F1: 0.0
Epoch:  616        6 Batch loss: 0.213315 Batch F1: 0.0
Epoch:  616        7 Batch loss: 0.216092 Batch F1: 0.0
Epoch:  616        8 Batch loss: 0.260411 Batch F1: 0.0
Epoch:  616        9 Batch loss: 0.209477 Batch F1: 0.0
Epoch:  616       10 Batch loss: 0.233617 Batch F1: 0.0
Epoch:  616       11 Batch loss: 0.220878 Batch F1: 0.0
Epoch:  616       12 Batch loss: 0.221706 Batch F1: 0.0
Train Avg Loss  616: 0.226002

Train Avg F1  616: 0.0

Val Avg Loss  616: 0.216947

Val Avg F1  616:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 617
--------------------------------------------------------------
Epoch:  617        1 Batch loss: 0.266462 Batch F1: 0.0
Epoch:  617        2 Batch loss: 0.213744 Batch F1: 0.0
Epoch:  617        3 Batch loss: 0.228769 Batch F1: 0.0
Epoch:  617        4 Batch loss: 0.214367 Batch F1: 0.0
Epoch:  617        5 Batch loss: 0.229981 Batch F1: 0.0
Epoch:  617        6 Batch loss: 0.219247 Batch F1: 0.0
Epoch:  617        7 Batch loss: 0.206733 Batch F1: 0.0
Epoch:  617        8 Batch loss: 0.227855 Batch F1: 0.0
Epoch:  617        9 Batch loss: 0.177072 Batch F1: 0.0
Epoch:  617       10 Batch loss: 0.219031 Batch F1: 0.0
Epoch:  617       11 Batch loss: 0.251512 Batch F1: 0.0
Epoch:  617       12 Batch loss: 0.268921 Batch F1: 0.0
Train Avg Loss  617: 0.226974

Train Avg F1  617: 0.0

Val Avg Loss  617: 0.217027

Val Avg F1  617:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 618
--------------------------------------------------------------
Epoch:  618        1 Batch loss: 0.206860 Batch F1: 0.0
Epoch:  618        2 Batch loss: 0.220576 Batch F1: 0.0
Epoch:  618        3 Batch loss: 0.200035 Batch F1: 0.0
Epoch:  618        4 Batch loss: 0.277347 Batch F1: 0.0
Epoch:  618        5 Batch loss: 0.204648 Batch F1: 0.0
Epoch:  618        6 Batch loss: 0.204446 Batch F1: 0.0
Epoch:  618        7 Batch loss: 0.213557 Batch F1: 0.0
Epoch:  618        8 Batch loss: 0.208783 Batch F1: 0.0
Epoch:  618        9 Batch loss: 0.288841 Batch F1: 0.0
Epoch:  618       10 Batch loss: 0.204343 Batch F1: 0.0
Epoch:  618       11 Batch loss: 0.249813 Batch F1: 0.0
Epoch:  618       12 Batch loss: 0.245070 Batch F1: 0.0
Train Avg Loss  618: 0.227026

Train Avg F1  618: 0.0

Val Avg Loss  618: 0.218187

Val Avg F1  618:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 619
--------------------------------------------------------------
Epoch:  619        1 Batch loss: 0.230577 Batch F1: 0.0
Epoch:  619        2 Batch loss: 0.236601 Batch F1: 0.0
Epoch:  619        3 Batch loss: 0.211901 Batch F1: 0.0
Epoch:  619        4 Batch loss: 0.213816 Batch F1: 0.0
Epoch:  619        5 Batch loss: 0.225914 Batch F1: 0.0
Epoch:  619        6 Batch loss: 0.224404 Batch F1: 0.0
Epoch:  619        7 Batch loss: 0.187242 Batch F1: 0.0
Epoch:  619        8 Batch loss: 0.222383 Batch F1: 0.0
Epoch:  619        9 Batch loss: 0.235024 Batch F1: 0.0
Epoch:  619       10 Batch loss: 0.259582 Batch F1: 0.0
Epoch:  619       11 Batch loss: 0.237835 Batch F1: 0.0
Epoch:  619       12 Batch loss: 0.248655 Batch F1: 0.0
Train Avg Loss  619: 0.227828

Train Avg F1  619: 0.0

Val Avg Loss  619: 0.219871

Val Avg F1  619:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 620
--------------------------------------------------------------
Epoch:  620        1 Batch loss: 0.238777 Batch F1: 0.0
Epoch:  620        2 Batch loss: 0.234006 Batch F1: 0.3846153846153846
Epoch:  620        3 Batch loss: 0.211788 Batch F1: 0.2857142857142857
Epoch:  620        4 Batch loss: 0.215058 Batch F1: 0.0
Epoch:  620        5 Batch loss: 0.239504 Batch F1: 0.0
Epoch:  620        6 Batch loss: 0.223972 Batch F1: 0.0
Epoch:  620        7 Batch loss: 0.230816 Batch F1: 0.0
Epoch:  620        8 Batch loss: 0.219241 Batch F1: 0.0
Epoch:  620        9 Batch loss: 0.270331 Batch F1: 0.0
Epoch:  620       10 Batch loss: 0.212503 Batch F1: 0.0
Epoch:  620       11 Batch loss: 0.189901 Batch F1: 0.0
Epoch:  620       12 Batch loss: 0.248444 Batch F1: 0.0
Train Avg Loss  620: 0.227862

Train Avg F1  620: 0.05586080586080586

Val Avg Loss  620: 0.217928

Val Avg F1  620:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 621
--------------------------------------------------------------
Epoch:  621        1 Batch loss: 0.228136 Batch F1: 0.0
Epoch:  621        2 Batch loss: 0.250305 Batch F1: 0.0
Epoch:  621        3 Batch loss: 0.248458 Batch F1: 0.0
Epoch:  621        4 Batch loss: 0.206981 Batch F1: 0.0
Epoch:  621        5 Batch loss: 0.202557 Batch F1: 0.0
Epoch:  621        6 Batch loss: 0.237264 Batch F1: 0.0
Epoch:  621        7 Batch loss: 0.228483 Batch F1: 0.0
Epoch:  621        8 Batch loss: 0.267937 Batch F1: 0.0
Epoch:  621        9 Batch loss: 0.198568 Batch F1: 0.0
Epoch:  621       10 Batch loss: 0.219879 Batch F1: 0.0
Epoch:  621       11 Batch loss: 0.227004 Batch F1: 0.0
Epoch:  621       12 Batch loss: 0.221992 Batch F1: 0.0
Train Avg Loss  621: 0.228130

Train Avg F1  621: 0.0

Val Avg Loss  621: 0.217905

Val Avg F1  621:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 622
--------------------------------------------------------------
Epoch:  622        1 Batch loss: 0.216859 Batch F1: 0.0
Epoch:  622        2 Batch loss: 0.217687 Batch F1: 0.0
Epoch:  622        3 Batch loss: 0.229370 Batch F1: 0.0
Epoch:  622        4 Batch loss: 0.214083 Batch F1: 0.0
Epoch:  622        5 Batch loss: 0.242525 Batch F1: 0.0
Epoch:  622        6 Batch loss: 0.226307 Batch F1: 0.0
Epoch:  622        7 Batch loss: 0.256184 Batch F1: 0.0
Epoch:  622        8 Batch loss: 0.231167 Batch F1: 0.0
Epoch:  622        9 Batch loss: 0.211353 Batch F1: 0.0
Epoch:  622       10 Batch loss: 0.191137 Batch F1: 0.0
Epoch:  622       11 Batch loss: 0.246124 Batch F1: 0.0
Epoch:  622       12 Batch loss: 0.241548 Batch F1: 0.0
Train Avg Loss  622: 0.227029

Train Avg F1  622: 0.0

Val Avg Loss  622: 0.217603

Val Avg F1  622:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 623
--------------------------------------------------------------
Epoch:  623        1 Batch loss: 0.257538 Batch F1: 0.0
Epoch:  623        2 Batch loss: 0.209883 Batch F1: 0.0
Epoch:  623        3 Batch loss: 0.217577 Batch F1: 0.0
Epoch:  623        4 Batch loss: 0.189391 Batch F1: 0.0
Epoch:  623        5 Batch loss: 0.220780 Batch F1: 0.0
Epoch:  623        6 Batch loss: 0.235304 Batch F1: 0.0
Epoch:  623        7 Batch loss: 0.206865 Batch F1: 0.0
Epoch:  623        8 Batch loss: 0.242701 Batch F1: 0.0
Epoch:  623        9 Batch loss: 0.229301 Batch F1: 0.0
Epoch:  623       10 Batch loss: 0.238188 Batch F1: 0.0
Epoch:  623       11 Batch loss: 0.239291 Batch F1: 0.0
Epoch:  623       12 Batch loss: 0.239019 Batch F1: 0.0
Train Avg Loss  623: 0.227153

Train Avg F1  623: 0.0

Val Avg Loss  623: 0.223808

Val Avg F1  623:  0.30666666666666664

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 624
--------------------------------------------------------------
Epoch:  624        1 Batch loss: 0.228845 Batch F1: 0.3870967741935484
Epoch:  624        2 Batch loss: 0.235044 Batch F1: 0.39999999999999997
Epoch:  624        3 Batch loss: 0.226833 Batch F1: 0.42857142857142855
Epoch:  624        4 Batch loss: 0.212812 Batch F1: 0.0
Epoch:  624        5 Batch loss: 0.218192 Batch F1: 0.0
Epoch:  624        6 Batch loss: 0.257031 Batch F1: 0.0
Epoch:  624        7 Batch loss: 0.221754 Batch F1: 0.0
Epoch:  624        8 Batch loss: 0.226596 Batch F1: 0.0
Epoch:  624        9 Batch loss: 0.214592 Batch F1: 0.0
Epoch:  624       10 Batch loss: 0.214072 Batch F1: 0.0
Epoch:  624       11 Batch loss: 0.214325 Batch F1: 0.0
Epoch:  624       12 Batch loss: 0.267072 Batch F1: 0.0
Train Avg Loss  624: 0.228097

Train Avg F1  624: 0.10130568356374808

Val Avg Loss  624: 0.219839

Val Avg F1  624:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 625
--------------------------------------------------------------
Epoch:  625        1 Batch loss: 0.244365 Batch F1: 0.0
Epoch:  625        2 Batch loss: 0.241137 Batch F1: 0.0
Epoch:  625        3 Batch loss: 0.237542 Batch F1: 0.0
Epoch:  625        4 Batch loss: 0.206765 Batch F1: 0.0
Epoch:  625        5 Batch loss: 0.248390 Batch F1: 0.0
Epoch:  625        6 Batch loss: 0.224538 Batch F1: 0.0
Epoch:  625        7 Batch loss: 0.228965 Batch F1: 0.0
Epoch:  625        8 Batch loss: 0.233335 Batch F1: 0.0
Epoch:  625        9 Batch loss: 0.204537 Batch F1: 0.0
Epoch:  625       10 Batch loss: 0.196561 Batch F1: 0.0
Epoch:  625       11 Batch loss: 0.215665 Batch F1: 0.0
Epoch:  625       12 Batch loss: 0.306177 Batch F1: 0.0
Train Avg Loss  625: 0.232331

Train Avg F1  625: 0.0

Val Avg Loss  625: 0.219605

Val Avg F1  625:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 626
--------------------------------------------------------------
Epoch:  626        1 Batch loss: 0.212882 Batch F1: 0.0
Epoch:  626        2 Batch loss: 0.210300 Batch F1: 0.0
Epoch:  626        3 Batch loss: 0.226271 Batch F1: 0.0
Epoch:  626        4 Batch loss: 0.251037 Batch F1: 0.0
Epoch:  626        5 Batch loss: 0.197665 Batch F1: 0.0
Epoch:  626        6 Batch loss: 0.216907 Batch F1: 0.0
Epoch:  626        7 Batch loss: 0.232668 Batch F1: 0.0
Epoch:  626        8 Batch loss: 0.247066 Batch F1: 0.0
Epoch:  626        9 Batch loss: 0.241164 Batch F1: 0.0
Epoch:  626       10 Batch loss: 0.224684 Batch F1: 0.0
Epoch:  626       11 Batch loss: 0.228424 Batch F1: 0.0
Epoch:  626       12 Batch loss: 0.243311 Batch F1: 0.0
Train Avg Loss  626: 0.227698

Train Avg F1  626: 0.0

Val Avg Loss  626: 0.222660

Val Avg F1  626:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 627
--------------------------------------------------------------
Epoch:  627        1 Batch loss: 0.267490 Batch F1: 0.0
Epoch:  627        2 Batch loss: 0.233947 Batch F1: 0.0
Epoch:  627        3 Batch loss: 0.218686 Batch F1: 0.0
Epoch:  627        4 Batch loss: 0.213150 Batch F1: 0.0
Epoch:  627        5 Batch loss: 0.204765 Batch F1: 0.0
Epoch:  627        6 Batch loss: 0.218162 Batch F1: 0.0
Epoch:  627        7 Batch loss: 0.244491 Batch F1: 0.0
Epoch:  627        8 Batch loss: 0.212917 Batch F1: 0.0
Epoch:  627        9 Batch loss: 0.251756 Batch F1: 0.0
Epoch:  627       10 Batch loss: 0.241338 Batch F1: 0.0
Epoch:  627       11 Batch loss: 0.240696 Batch F1: 0.0
Epoch:  627       12 Batch loss: 0.220535 Batch F1: 0.0
Train Avg Loss  627: 0.230661

Train Avg F1  627: 0.0

Val Avg Loss  627: 0.220478

Val Avg F1  627:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 628
--------------------------------------------------------------
Epoch:  628        1 Batch loss: 0.245373 Batch F1: 0.0
Epoch:  628        2 Batch loss: 0.216153 Batch F1: 0.0
Epoch:  628        3 Batch loss: 0.204111 Batch F1: 0.0
Epoch:  628        4 Batch loss: 0.217542 Batch F1: 0.0
Epoch:  628        5 Batch loss: 0.213504 Batch F1: 0.0
Epoch:  628        6 Batch loss: 0.259769 Batch F1: 0.0
Epoch:  628        7 Batch loss: 0.208753 Batch F1: 0.0
Epoch:  628        8 Batch loss: 0.232061 Batch F1: 0.0
Epoch:  628        9 Batch loss: 0.265605 Batch F1: 0.0
Epoch:  628       10 Batch loss: 0.250020 Batch F1: 0.0
Epoch:  628       11 Batch loss: 0.218111 Batch F1: 0.0
Epoch:  628       12 Batch loss: 0.236407 Batch F1: 0.0
Train Avg Loss  628: 0.230617

Train Avg F1  628: 0.0

Val Avg Loss  628: 0.222489

Val Avg F1  628:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 629
--------------------------------------------------------------
Epoch:  629        1 Batch loss: 0.223134 Batch F1: 0.0
Epoch:  629        2 Batch loss: 0.234960 Batch F1: 0.0
Epoch:  629        3 Batch loss: 0.216210 Batch F1: 0.0
Epoch:  629        4 Batch loss: 0.251958 Batch F1: 0.0
Epoch:  629        5 Batch loss: 0.233382 Batch F1: 0.0
Epoch:  629        6 Batch loss: 0.221051 Batch F1: 0.0
Epoch:  629        7 Batch loss: 0.242546 Batch F1: 0.0
Epoch:  629        8 Batch loss: 0.207309 Batch F1: 0.0
Epoch:  629        9 Batch loss: 0.206910 Batch F1: 0.0
Epoch:  629       10 Batch loss: 0.234542 Batch F1: 0.0
Epoch:  629       11 Batch loss: 0.232563 Batch F1: 0.0
Epoch:  629       12 Batch loss: 0.229938 Batch F1: 0.0
Train Avg Loss  629: 0.227875

Train Avg F1  629: 0.0

Val Avg Loss  629: 0.218814

Val Avg F1  629:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 630
--------------------------------------------------------------
Epoch:  630        1 Batch loss: 0.224501 Batch F1: 0.0
Epoch:  630        2 Batch loss: 0.216333 Batch F1: 0.0
Epoch:  630        3 Batch loss: 0.245236 Batch F1: 0.0
Epoch:  630        4 Batch loss: 0.203077 Batch F1: 0.0
Epoch:  630        5 Batch loss: 0.238323 Batch F1: 0.0
Epoch:  630        6 Batch loss: 0.253277 Batch F1: 0.0
Epoch:  630        7 Batch loss: 0.229270 Batch F1: 0.0
Epoch:  630        8 Batch loss: 0.206709 Batch F1: 0.0
Epoch:  630        9 Batch loss: 0.218327 Batch F1: 0.0
Epoch:  630       10 Batch loss: 0.224954 Batch F1: 0.0
Epoch:  630       11 Batch loss: 0.211382 Batch F1: 0.0
Epoch:  630       12 Batch loss: 0.250524 Batch F1: 0.0
Train Avg Loss  630: 0.226826

Train Avg F1  630: 0.0

Val Avg Loss  630: 0.217693

Val Avg F1  630:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 631
--------------------------------------------------------------
Epoch:  631        1 Batch loss: 0.214981 Batch F1: 0.0
Epoch:  631        2 Batch loss: 0.258615 Batch F1: 0.0
Epoch:  631        3 Batch loss: 0.219632 Batch F1: 0.0
Epoch:  631        4 Batch loss: 0.222446 Batch F1: 0.0
Epoch:  631        5 Batch loss: 0.226667 Batch F1: 0.0
Epoch:  631        6 Batch loss: 0.241122 Batch F1: 0.0
Epoch:  631        7 Batch loss: 0.238177 Batch F1: 0.0
Epoch:  631        8 Batch loss: 0.199771 Batch F1: 0.0
Epoch:  631        9 Batch loss: 0.239771 Batch F1: 0.0
Epoch:  631       10 Batch loss: 0.248692 Batch F1: 0.0
Epoch:  631       11 Batch loss: 0.193466 Batch F1: 0.0
Epoch:  631       12 Batch loss: 0.206584 Batch F1: 0.0
Train Avg Loss  631: 0.225827

Train Avg F1  631: 0.0

Val Avg Loss  631: 0.217443

Val Avg F1  631:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 632
--------------------------------------------------------------
Epoch:  632        1 Batch loss: 0.216853 Batch F1: 0.0
Epoch:  632        2 Batch loss: 0.229154 Batch F1: 0.0
Epoch:  632        3 Batch loss: 0.243164 Batch F1: 0.0
Epoch:  632        4 Batch loss: 0.224986 Batch F1: 0.0
Epoch:  632        5 Batch loss: 0.231887 Batch F1: 0.0
Epoch:  632        6 Batch loss: 0.202802 Batch F1: 0.0
Epoch:  632        7 Batch loss: 0.225471 Batch F1: 0.0
Epoch:  632        8 Batch loss: 0.222038 Batch F1: 0.0
Epoch:  632        9 Batch loss: 0.215805 Batch F1: 0.0
Epoch:  632       10 Batch loss: 0.204395 Batch F1: 0.0
Epoch:  632       11 Batch loss: 0.223916 Batch F1: 0.0
Epoch:  632       12 Batch loss: 0.281366 Batch F1: 0.0
Train Avg Loss  632: 0.226820

Train Avg F1  632: 0.0

Val Avg Loss  632: 0.217597

Val Avg F1  632:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 633
--------------------------------------------------------------
Epoch:  633        1 Batch loss: 0.226126 Batch F1: 0.0
Epoch:  633        2 Batch loss: 0.224870 Batch F1: 0.0
Epoch:  633        3 Batch loss: 0.216104 Batch F1: 0.0
Epoch:  633        4 Batch loss: 0.255582 Batch F1: 0.0
Epoch:  633        5 Batch loss: 0.241339 Batch F1: 0.0
Epoch:  633        6 Batch loss: 0.218344 Batch F1: 0.0
Epoch:  633        7 Batch loss: 0.191560 Batch F1: 0.0
Epoch:  633        8 Batch loss: 0.245492 Batch F1: 0.0
Epoch:  633        9 Batch loss: 0.215384 Batch F1: 0.0
Epoch:  633       10 Batch loss: 0.213746 Batch F1: 0.0
Epoch:  633       11 Batch loss: 0.236422 Batch F1: 0.0
Epoch:  633       12 Batch loss: 0.228878 Batch F1: 0.0
Train Avg Loss  633: 0.226154

Train Avg F1  633: 0.0

Val Avg Loss  633: 0.217102

Val Avg F1  633:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 634
--------------------------------------------------------------
Epoch:  634        1 Batch loss: 0.182494 Batch F1: 0.0
Epoch:  634        2 Batch loss: 0.218277 Batch F1: 0.0
Epoch:  634        3 Batch loss: 0.224021 Batch F1: 0.0
Epoch:  634        4 Batch loss: 0.243763 Batch F1: 0.0
Epoch:  634        5 Batch loss: 0.211104 Batch F1: 0.0
Epoch:  634        6 Batch loss: 0.249852 Batch F1: 0.0
Epoch:  634        7 Batch loss: 0.233487 Batch F1: 0.0
Epoch:  634        8 Batch loss: 0.242385 Batch F1: 0.0
Epoch:  634        9 Batch loss: 0.238654 Batch F1: 0.0
Epoch:  634       10 Batch loss: 0.236300 Batch F1: 0.0
Epoch:  634       11 Batch loss: 0.182265 Batch F1: 0.0
Epoch:  634       12 Batch loss: 0.250928 Batch F1: 0.0
Train Avg Loss  634: 0.226127

Train Avg F1  634: 0.0

Val Avg Loss  634: 0.218046

Val Avg F1  634:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 635
--------------------------------------------------------------
Epoch:  635        1 Batch loss: 0.208483 Batch F1: 0.0
Epoch:  635        2 Batch loss: 0.237406 Batch F1: 0.0
Epoch:  635        3 Batch loss: 0.224912 Batch F1: 0.0
Epoch:  635        4 Batch loss: 0.236318 Batch F1: 0.0
Epoch:  635        5 Batch loss: 0.210049 Batch F1: 0.0
Epoch:  635        6 Batch loss: 0.232521 Batch F1: 0.0
Epoch:  635        7 Batch loss: 0.228099 Batch F1: 0.0
Epoch:  635        8 Batch loss: 0.231906 Batch F1: 0.0
Epoch:  635        9 Batch loss: 0.230259 Batch F1: 0.0
Epoch:  635       10 Batch loss: 0.228069 Batch F1: 0.0
Epoch:  635       11 Batch loss: 0.222998 Batch F1: 0.0
Epoch:  635       12 Batch loss: 0.213386 Batch F1: 0.0
Train Avg Loss  635: 0.225367

Train Avg F1  635: 0.0

Val Avg Loss  635: 0.217510

Val Avg F1  635:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 636
--------------------------------------------------------------
Epoch:  636        1 Batch loss: 0.248452 Batch F1: 0.0
Epoch:  636        2 Batch loss: 0.244619 Batch F1: 0.0
Epoch:  636        3 Batch loss: 0.209767 Batch F1: 0.0
Epoch:  636        4 Batch loss: 0.213368 Batch F1: 0.0
Epoch:  636        5 Batch loss: 0.212600 Batch F1: 0.0
Epoch:  636        6 Batch loss: 0.233776 Batch F1: 0.0
Epoch:  636        7 Batch loss: 0.217085 Batch F1: 0.0
Epoch:  636        8 Batch loss: 0.207221 Batch F1: 0.0
Epoch:  636        9 Batch loss: 0.213046 Batch F1: 0.0
Epoch:  636       10 Batch loss: 0.219607 Batch F1: 0.0
Epoch:  636       11 Batch loss: 0.280962 Batch F1: 0.0
Epoch:  636       12 Batch loss: 0.213645 Batch F1: 0.0
Train Avg Loss  636: 0.226179

Train Avg F1  636: 0.0

Val Avg Loss  636: 0.218659

Val Avg F1  636:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 637
--------------------------------------------------------------
Epoch:  637        1 Batch loss: 0.227055 Batch F1: 0.0
Epoch:  637        2 Batch loss: 0.249638 Batch F1: 0.0
Epoch:  637        3 Batch loss: 0.222175 Batch F1: 0.0
Epoch:  637        4 Batch loss: 0.254754 Batch F1: 0.0
Epoch:  637        5 Batch loss: 0.214261 Batch F1: 0.0
Epoch:  637        6 Batch loss: 0.263932 Batch F1: 0.0
Epoch:  637        7 Batch loss: 0.218554 Batch F1: 0.0
Epoch:  637        8 Batch loss: 0.214921 Batch F1: 0.0
Epoch:  637        9 Batch loss: 0.212969 Batch F1: 0.0
Epoch:  637       10 Batch loss: 0.219294 Batch F1: 0.0
Epoch:  637       11 Batch loss: 0.218096 Batch F1: 0.0
Epoch:  637       12 Batch loss: 0.217974 Batch F1: 0.0
Train Avg Loss  637: 0.227802

Train Avg F1  637: 0.0

Val Avg Loss  637: 0.216764

Val Avg F1  637:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 638
--------------------------------------------------------------
Epoch:  638        1 Batch loss: 0.234794 Batch F1: 0.0
Epoch:  638        2 Batch loss: 0.272809 Batch F1: 0.0
Epoch:  638        3 Batch loss: 0.218653 Batch F1: 0.0
Epoch:  638        4 Batch loss: 0.229572 Batch F1: 0.0
Epoch:  638        5 Batch loss: 0.234041 Batch F1: 0.0
Epoch:  638        6 Batch loss: 0.192090 Batch F1: 0.0
Epoch:  638        7 Batch loss: 0.230205 Batch F1: 0.0
Epoch:  638        8 Batch loss: 0.224658 Batch F1: 0.0
Epoch:  638        9 Batch loss: 0.199758 Batch F1: 0.0
Epoch:  638       10 Batch loss: 0.236073 Batch F1: 0.0
Epoch:  638       11 Batch loss: 0.257716 Batch F1: 0.0
Epoch:  638       12 Batch loss: 0.201391 Batch F1: 0.0
Train Avg Loss  638: 0.227647

Train Avg F1  638: 0.0

Val Avg Loss  638: 0.217307

Val Avg F1  638:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 639
--------------------------------------------------------------
Epoch:  639        1 Batch loss: 0.225946 Batch F1: 0.0
Epoch:  639        2 Batch loss: 0.229179 Batch F1: 0.0
Epoch:  639        3 Batch loss: 0.239821 Batch F1: 0.0
Epoch:  639        4 Batch loss: 0.237815 Batch F1: 0.0
Epoch:  639        5 Batch loss: 0.231263 Batch F1: 0.0
Epoch:  639        6 Batch loss: 0.204785 Batch F1: 0.0
Epoch:  639        7 Batch loss: 0.222967 Batch F1: 0.0
Epoch:  639        8 Batch loss: 0.212199 Batch F1: 0.0
Epoch:  639        9 Batch loss: 0.214329 Batch F1: 0.0
Epoch:  639       10 Batch loss: 0.244098 Batch F1: 0.0
Epoch:  639       11 Batch loss: 0.212382 Batch F1: 0.0
Epoch:  639       12 Batch loss: 0.249738 Batch F1: 0.0
Train Avg Loss  639: 0.227044

Train Avg F1  639: 0.0

Val Avg Loss  639: 0.219072

Val Avg F1  639:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 640
--------------------------------------------------------------
Epoch:  640        1 Batch loss: 0.233897 Batch F1: 0.0
Epoch:  640        2 Batch loss: 0.251743 Batch F1: 0.0
Epoch:  640        3 Batch loss: 0.227933 Batch F1: 0.09523809523809525
Epoch:  640        4 Batch loss: 0.251893 Batch F1: 0.0
Epoch:  640        5 Batch loss: 0.232998 Batch F1: 0.0
Epoch:  640        6 Batch loss: 0.230857 Batch F1: 0.0
Epoch:  640        7 Batch loss: 0.234049 Batch F1: 0.0
Epoch:  640        8 Batch loss: 0.236708 Batch F1: 0.0
Epoch:  640        9 Batch loss: 0.220937 Batch F1: 0.0
Epoch:  640       10 Batch loss: 0.193236 Batch F1: 0.0
Epoch:  640       11 Batch loss: 0.201058 Batch F1: 0.0
Epoch:  640       12 Batch loss: 0.215795 Batch F1: 0.0
Train Avg Loss  640: 0.227592

Train Avg F1  640: 0.007936507936507938

Val Avg Loss  640: 0.217358

Val Avg F1  640:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 641
--------------------------------------------------------------
Epoch:  641        1 Batch loss: 0.225391 Batch F1: 0.0
Epoch:  641        2 Batch loss: 0.234623 Batch F1: 0.0
Epoch:  641        3 Batch loss: 0.250295 Batch F1: 0.0
Epoch:  641        4 Batch loss: 0.216137 Batch F1: 0.0
Epoch:  641        5 Batch loss: 0.223146 Batch F1: 0.0
Epoch:  641        6 Batch loss: 0.219657 Batch F1: 0.0
Epoch:  641        7 Batch loss: 0.237916 Batch F1: 0.0
Epoch:  641        8 Batch loss: 0.238766 Batch F1: 0.0
Epoch:  641        9 Batch loss: 0.234541 Batch F1: 0.0
Epoch:  641       10 Batch loss: 0.224851 Batch F1: 0.0
Epoch:  641       11 Batch loss: 0.186163 Batch F1: 0.0
Epoch:  641       12 Batch loss: 0.232289 Batch F1: 0.0
Train Avg Loss  641: 0.226981

Train Avg F1  641: 0.0

Val Avg Loss  641: 0.216584

Val Avg F1  641:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 642
--------------------------------------------------------------
Epoch:  642        1 Batch loss: 0.216515 Batch F1: 0.0
Epoch:  642        2 Batch loss: 0.191673 Batch F1: 0.0
Epoch:  642        3 Batch loss: 0.246608 Batch F1: 0.0
Epoch:  642        4 Batch loss: 0.227658 Batch F1: 0.0
Epoch:  642        5 Batch loss: 0.213164 Batch F1: 0.0
Epoch:  642        6 Batch loss: 0.232363 Batch F1: 0.0
Epoch:  642        7 Batch loss: 0.242812 Batch F1: 0.0
Epoch:  642        8 Batch loss: 0.237208 Batch F1: 0.0
Epoch:  642        9 Batch loss: 0.222225 Batch F1: 0.0
Epoch:  642       10 Batch loss: 0.234277 Batch F1: 0.0
Epoch:  642       11 Batch loss: 0.244042 Batch F1: 0.0
Epoch:  642       12 Batch loss: 0.229195 Batch F1: 0.0
Train Avg Loss  642: 0.228145

Train Avg F1  642: 0.0

Val Avg Loss  642: 0.219319

Val Avg F1  642:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 643
--------------------------------------------------------------
Epoch:  643        1 Batch loss: 0.224432 Batch F1: 0.0
Epoch:  643        2 Batch loss: 0.238574 Batch F1: 0.0
Epoch:  643        3 Batch loss: 0.217313 Batch F1: 0.0
Epoch:  643        4 Batch loss: 0.228347 Batch F1: 0.0
Epoch:  643        5 Batch loss: 0.219290 Batch F1: 0.0
Epoch:  643        6 Batch loss: 0.189958 Batch F1: 0.0
Epoch:  643        7 Batch loss: 0.240384 Batch F1: 0.0
Epoch:  643        8 Batch loss: 0.244579 Batch F1: 0.0
Epoch:  643        9 Batch loss: 0.248050 Batch F1: 0.0
Epoch:  643       10 Batch loss: 0.229356 Batch F1: 0.0
Epoch:  643       11 Batch loss: 0.209036 Batch F1: 0.0
Epoch:  643       12 Batch loss: 0.250599 Batch F1: 0.0
Train Avg Loss  643: 0.228327

Train Avg F1  643: 0.0

Val Avg Loss  643: 0.217331

Val Avg F1  643:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 644
--------------------------------------------------------------
Epoch:  644        1 Batch loss: 0.235187 Batch F1: 0.0
Epoch:  644        2 Batch loss: 0.215208 Batch F1: 0.0
Epoch:  644        3 Batch loss: 0.247780 Batch F1: 0.0
Epoch:  644        4 Batch loss: 0.209095 Batch F1: 0.0
Epoch:  644        5 Batch loss: 0.207545 Batch F1: 0.0
Epoch:  644        6 Batch loss: 0.246185 Batch F1: 0.0
Epoch:  644        7 Batch loss: 0.193911 Batch F1: 0.0
Epoch:  644        8 Batch loss: 0.266948 Batch F1: 0.0
Epoch:  644        9 Batch loss: 0.251453 Batch F1: 0.0
Epoch:  644       10 Batch loss: 0.222218 Batch F1: 0.0
Epoch:  644       11 Batch loss: 0.224686 Batch F1: 0.0
Epoch:  644       12 Batch loss: 0.208318 Batch F1: 0.0
Train Avg Loss  644: 0.227378

Train Avg F1  644: 0.0

Val Avg Loss  644: 0.218828

Val Avg F1  644:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 645
--------------------------------------------------------------
Epoch:  645        1 Batch loss: 0.223595 Batch F1: 0.0
Epoch:  645        2 Batch loss: 0.223286 Batch F1: 0.0
Epoch:  645        3 Batch loss: 0.204370 Batch F1: 0.0
Epoch:  645        4 Batch loss: 0.218822 Batch F1: 0.0
Epoch:  645        5 Batch loss: 0.226857 Batch F1: 0.0
Epoch:  645        6 Batch loss: 0.260142 Batch F1: 0.0
Epoch:  645        7 Batch loss: 0.255102 Batch F1: 0.0
Epoch:  645        8 Batch loss: 0.236290 Batch F1: 0.0
Epoch:  645        9 Batch loss: 0.206524 Batch F1: 0.0
Epoch:  645       10 Batch loss: 0.223456 Batch F1: 0.0
Epoch:  645       11 Batch loss: 0.236446 Batch F1: 0.0
Epoch:  645       12 Batch loss: 0.199375 Batch F1: 0.0
Train Avg Loss  645: 0.226189

Train Avg F1  645: 0.0

Val Avg Loss  645: 0.218643

Val Avg F1  645:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 646
--------------------------------------------------------------
Epoch:  646        1 Batch loss: 0.227981 Batch F1: 0.0
Epoch:  646        2 Batch loss: 0.244294 Batch F1: 0.0
Epoch:  646        3 Batch loss: 0.226375 Batch F1: 0.0
Epoch:  646        4 Batch loss: 0.247859 Batch F1: 0.0
Epoch:  646        5 Batch loss: 0.197363 Batch F1: 0.0
Epoch:  646        6 Batch loss: 0.236478 Batch F1: 0.0
Epoch:  646        7 Batch loss: 0.225514 Batch F1: 0.0
Epoch:  646        8 Batch loss: 0.216906 Batch F1: 0.0
Epoch:  646        9 Batch loss: 0.242746 Batch F1: 0.0
Epoch:  646       10 Batch loss: 0.217098 Batch F1: 0.0
Epoch:  646       11 Batch loss: 0.202681 Batch F1: 0.0
Epoch:  646       12 Batch loss: 0.219351 Batch F1: 0.0
Train Avg Loss  646: 0.225387

Train Avg F1  646: 0.0

Val Avg Loss  646: 0.216342

Val Avg F1  646:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 647
--------------------------------------------------------------
Epoch:  647        1 Batch loss: 0.214630 Batch F1: 0.0
Epoch:  647        2 Batch loss: 0.187795 Batch F1: 0.0
Epoch:  647        3 Batch loss: 0.209790 Batch F1: 0.0
Epoch:  647        4 Batch loss: 0.229649 Batch F1: 0.0
Epoch:  647        5 Batch loss: 0.216329 Batch F1: 0.0
Epoch:  647        6 Batch loss: 0.230493 Batch F1: 0.0
Epoch:  647        7 Batch loss: 0.236931 Batch F1: 0.0
Epoch:  647        8 Batch loss: 0.235347 Batch F1: 0.0
Epoch:  647        9 Batch loss: 0.253320 Batch F1: 0.0
Epoch:  647       10 Batch loss: 0.219218 Batch F1: 0.0
Epoch:  647       11 Batch loss: 0.226939 Batch F1: 0.0
Epoch:  647       12 Batch loss: 0.258066 Batch F1: 0.0
Train Avg Loss  647: 0.226542

Train Avg F1  647: 0.0

Val Avg Loss  647: 0.217286

Val Avg F1  647:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 648
--------------------------------------------------------------
Epoch:  648        1 Batch loss: 0.216247 Batch F1: 0.0
Epoch:  648        2 Batch loss: 0.231327 Batch F1: 0.0
Epoch:  648        3 Batch loss: 0.240088 Batch F1: 0.0
Epoch:  648        4 Batch loss: 0.233821 Batch F1: 0.0
Epoch:  648        5 Batch loss: 0.196829 Batch F1: 0.0
Epoch:  648        6 Batch loss: 0.239918 Batch F1: 0.0
Epoch:  648        7 Batch loss: 0.217837 Batch F1: 0.0
Epoch:  648        8 Batch loss: 0.242608 Batch F1: 0.0
Epoch:  648        9 Batch loss: 0.210437 Batch F1: 0.0
Epoch:  648       10 Batch loss: 0.210567 Batch F1: 0.0
Epoch:  648       11 Batch loss: 0.233282 Batch F1: 0.0
Epoch:  648       12 Batch loss: 0.241353 Batch F1: 0.0
Train Avg Loss  648: 0.226193

Train Avg F1  648: 0.0

Val Avg Loss  648: 0.220836

Val Avg F1  648:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 649
--------------------------------------------------------------
Epoch:  649        1 Batch loss: 0.243428 Batch F1: 0.0
Epoch:  649        2 Batch loss: 0.239251 Batch F1: 0.0
Epoch:  649        3 Batch loss: 0.243586 Batch F1: 0.21428571428571425
Epoch:  649        4 Batch loss: 0.191940 Batch F1: 0.33333333333333326
Epoch:  649        5 Batch loss: 0.239349 Batch F1: 0.0
Epoch:  649        6 Batch loss: 0.219272 Batch F1: 0.0
Epoch:  649        7 Batch loss: 0.219128 Batch F1: 0.0
Epoch:  649        8 Batch loss: 0.228211 Batch F1: 0.0
Epoch:  649        9 Batch loss: 0.239229 Batch F1: 0.0
Epoch:  649       10 Batch loss: 0.217629 Batch F1: 0.0
Epoch:  649       11 Batch loss: 0.218427 Batch F1: 0.0
Epoch:  649       12 Batch loss: 0.223410 Batch F1: 0.0
Train Avg Loss  649: 0.226905

Train Avg F1  649: 0.04563492063492062

Val Avg Loss  649: 0.217221

Val Avg F1  649:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 650
--------------------------------------------------------------
Epoch:  650        1 Batch loss: 0.224975 Batch F1: 0.0
Epoch:  650        2 Batch loss: 0.255188 Batch F1: 0.0
Epoch:  650        3 Batch loss: 0.229189 Batch F1: 0.0
Epoch:  650        4 Batch loss: 0.240513 Batch F1: 0.0
Epoch:  650        5 Batch loss: 0.236010 Batch F1: 0.0
Epoch:  650        6 Batch loss: 0.233246 Batch F1: 0.16666666666666666
Epoch:  650        7 Batch loss: 0.232922 Batch F1: 0.2857142857142857
Epoch:  650        8 Batch loss: 0.225934 Batch F1: 0.19047619047619047
Epoch:  650        9 Batch loss: 0.215268 Batch F1: 0.0
Epoch:  650       10 Batch loss: 0.224352 Batch F1: 0.0
Epoch:  650       11 Batch loss: 0.201476 Batch F1: 0.0
Epoch:  650       12 Batch loss: 0.193012 Batch F1: 0.0
Train Avg Loss  650: 0.226007

Train Avg F1  650: 0.05357142857142857

Val Avg Loss  650: 0.216775

Val Avg F1  650:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 651
--------------------------------------------------------------
Epoch:  651        1 Batch loss: 0.209055 Batch F1: 0.0
Epoch:  651        2 Batch loss: 0.271843 Batch F1: 0.0
Epoch:  651        3 Batch loss: 0.222962 Batch F1: 0.0
Epoch:  651        4 Batch loss: 0.206824 Batch F1: 0.0
Epoch:  651        5 Batch loss: 0.218016 Batch F1: 0.0
Epoch:  651        6 Batch loss: 0.247232 Batch F1: 0.0
Epoch:  651        7 Batch loss: 0.229116 Batch F1: 0.0
Epoch:  651        8 Batch loss: 0.261160 Batch F1: 0.0
Epoch:  651        9 Batch loss: 0.219870 Batch F1: 0.0
Epoch:  651       10 Batch loss: 0.212742 Batch F1: 0.0
Epoch:  651       11 Batch loss: 0.233685 Batch F1: 0.0
Epoch:  651       12 Batch loss: 0.204475 Batch F1: 0.0
Train Avg Loss  651: 0.228082

Train Avg F1  651: 0.0

Val Avg Loss  651: 0.217467

Val Avg F1  651:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 652
--------------------------------------------------------------
Epoch:  652        1 Batch loss: 0.213965 Batch F1: 0.0
Epoch:  652        2 Batch loss: 0.244594 Batch F1: 0.0
Epoch:  652        3 Batch loss: 0.241360 Batch F1: 0.0
Epoch:  652        4 Batch loss: 0.246229 Batch F1: 0.0
Epoch:  652        5 Batch loss: 0.232832 Batch F1: 0.0
Epoch:  652        6 Batch loss: 0.219405 Batch F1: 0.0
Epoch:  652        7 Batch loss: 0.218641 Batch F1: 0.0
Epoch:  652        8 Batch loss: 0.211654 Batch F1: 0.0
Epoch:  652        9 Batch loss: 0.215292 Batch F1: 0.0
Epoch:  652       10 Batch loss: 0.235061 Batch F1: 0.0
Epoch:  652       11 Batch loss: 0.234452 Batch F1: 0.0
Epoch:  652       12 Batch loss: 0.233673 Batch F1: 0.0
Train Avg Loss  652: 0.228930

Train Avg F1  652: 0.0

Val Avg Loss  652: 0.218501

Val Avg F1  652:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 653
--------------------------------------------------------------
Epoch:  653        1 Batch loss: 0.263657 Batch F1: 0.0
Epoch:  653        2 Batch loss: 0.237368 Batch F1: 0.0
Epoch:  653        3 Batch loss: 0.234375 Batch F1: 0.0
Epoch:  653        4 Batch loss: 0.225553 Batch F1: 0.37499999999999994
Epoch:  653        5 Batch loss: 0.256944 Batch F1: 0.1935483870967742
Epoch:  653        6 Batch loss: 0.229963 Batch F1: 0.5517241379310345
Epoch:  653        7 Batch loss: 0.205958 Batch F1: 0.35294117647058826
Epoch:  653        8 Batch loss: 0.192019 Batch F1: 0.0
Epoch:  653        9 Batch loss: 0.218826 Batch F1: 0.0
Epoch:  653       10 Batch loss: 0.237909 Batch F1: 0.0
Epoch:  653       11 Batch loss: 0.212449 Batch F1: 0.0
Epoch:  653       12 Batch loss: 0.245157 Batch F1: 0.0
Train Avg Loss  653: 0.230015

Train Avg F1  653: 0.12276780845819975

Val Avg Loss  653: 0.217397

Val Avg F1  653:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 654
--------------------------------------------------------------
Epoch:  654        1 Batch loss: 0.203923 Batch F1: 0.0
Epoch:  654        2 Batch loss: 0.184692 Batch F1: 0.0
Epoch:  654        3 Batch loss: 0.259086 Batch F1: 0.0
Epoch:  654        4 Batch loss: 0.238449 Batch F1: 0.0
Epoch:  654        5 Batch loss: 0.236472 Batch F1: 0.0
Epoch:  654        6 Batch loss: 0.259904 Batch F1: 0.0
Epoch:  654        7 Batch loss: 0.217403 Batch F1: 0.56
Epoch:  654        8 Batch loss: 0.222345 Batch F1: 0.3
Epoch:  654        9 Batch loss: 0.225678 Batch F1: 0.0
Epoch:  654       10 Batch loss: 0.225592 Batch F1: 0.0
Epoch:  654       11 Batch loss: 0.231028 Batch F1: 0.0
Epoch:  654       12 Batch loss: 0.259948 Batch F1: 0.0
Train Avg Loss  654: 0.230377

Train Avg F1  654: 0.07166666666666667

Val Avg Loss  654: 0.217266

Val Avg F1  654:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 655
--------------------------------------------------------------
Epoch:  655        1 Batch loss: 0.272013 Batch F1: 0.0
Epoch:  655        2 Batch loss: 0.220220 Batch F1: 0.0
Epoch:  655        3 Batch loss: 0.215186 Batch F1: 0.0
Epoch:  655        4 Batch loss: 0.204805 Batch F1: 0.0
Epoch:  655        5 Batch loss: 0.230625 Batch F1: 0.0
Epoch:  655        6 Batch loss: 0.221074 Batch F1: 0.0
Epoch:  655        7 Batch loss: 0.238247 Batch F1: 0.0
Epoch:  655        8 Batch loss: 0.217816 Batch F1: 0.0
Epoch:  655        9 Batch loss: 0.190455 Batch F1: 0.0
Epoch:  655       10 Batch loss: 0.248518 Batch F1: 0.0
Epoch:  655       11 Batch loss: 0.243966 Batch F1: 0.0
Epoch:  655       12 Batch loss: 0.274523 Batch F1: 0.0
Train Avg Loss  655: 0.231454

Train Avg F1  655: 0.0

Val Avg Loss  655: 0.217800

Val Avg F1  655:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 656
--------------------------------------------------------------
Epoch:  656        1 Batch loss: 0.231816 Batch F1: 0.0
Epoch:  656        2 Batch loss: 0.202794 Batch F1: 0.0
Epoch:  656        3 Batch loss: 0.238633 Batch F1: 0.0
Epoch:  656        4 Batch loss: 0.250390 Batch F1: 0.0
Epoch:  656        5 Batch loss: 0.241596 Batch F1: 0.0
Epoch:  656        6 Batch loss: 0.219843 Batch F1: 0.0
Epoch:  656        7 Batch loss: 0.236893 Batch F1: 0.0
Epoch:  656        8 Batch loss: 0.233954 Batch F1: 0.0
Epoch:  656        9 Batch loss: 0.213562 Batch F1: 0.0
Epoch:  656       10 Batch loss: 0.228589 Batch F1: 0.0
Epoch:  656       11 Batch loss: 0.193861 Batch F1: 0.0
Epoch:  656       12 Batch loss: 0.255690 Batch F1: 0.0
Train Avg Loss  656: 0.228968

Train Avg F1  656: 0.0

Val Avg Loss  656: 0.218998

Val Avg F1  656:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 657
--------------------------------------------------------------
Epoch:  657        1 Batch loss: 0.252382 Batch F1: 0.0
Epoch:  657        2 Batch loss: 0.219899 Batch F1: 0.0
Epoch:  657        3 Batch loss: 0.231681 Batch F1: 0.0
Epoch:  657        4 Batch loss: 0.203464 Batch F1: 0.0
Epoch:  657        5 Batch loss: 0.249931 Batch F1: 0.0
Epoch:  657        6 Batch loss: 0.214644 Batch F1: 0.0
Epoch:  657        7 Batch loss: 0.243173 Batch F1: 0.0
Epoch:  657        8 Batch loss: 0.237196 Batch F1: 0.0
Epoch:  657        9 Batch loss: 0.230678 Batch F1: 0.0
Epoch:  657       10 Batch loss: 0.216452 Batch F1: 0.0
Epoch:  657       11 Batch loss: 0.222371 Batch F1: 0.0
Epoch:  657       12 Batch loss: 0.234449 Batch F1: 0.0
Train Avg Loss  657: 0.229693

Train Avg F1  657: 0.0

Val Avg Loss  657: 0.219226

Val Avg F1  657:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 658
--------------------------------------------------------------
Epoch:  658        1 Batch loss: 0.199099 Batch F1: 0.0
Epoch:  658        2 Batch loss: 0.206720 Batch F1: 0.0
Epoch:  658        3 Batch loss: 0.192263 Batch F1: 0.0
Epoch:  658        4 Batch loss: 0.267996 Batch F1: 0.0
Epoch:  658        5 Batch loss: 0.209429 Batch F1: 0.0
Epoch:  658        6 Batch loss: 0.222282 Batch F1: 0.0
Epoch:  658        7 Batch loss: 0.231164 Batch F1: 0.0
Epoch:  658        8 Batch loss: 0.229427 Batch F1: 0.0
Epoch:  658        9 Batch loss: 0.246058 Batch F1: 0.0
Epoch:  658       10 Batch loss: 0.205375 Batch F1: 0.0
Epoch:  658       11 Batch loss: 0.272455 Batch F1: 0.0
Epoch:  658       12 Batch loss: 0.262361 Batch F1: 0.0
Train Avg Loss  658: 0.228719

Train Avg F1  658: 0.0

Val Avg Loss  658: 0.219992

Val Avg F1  658:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 659
--------------------------------------------------------------
Epoch:  659        1 Batch loss: 0.231589 Batch F1: 0.0
Epoch:  659        2 Batch loss: 0.241592 Batch F1: 0.0
Epoch:  659        3 Batch loss: 0.230469 Batch F1: 0.0
Epoch:  659        4 Batch loss: 0.226634 Batch F1: 0.0
Epoch:  659        5 Batch loss: 0.223572 Batch F1: 0.0
Epoch:  659        6 Batch loss: 0.218551 Batch F1: 0.0
Epoch:  659        7 Batch loss: 0.218153 Batch F1: 0.0
Epoch:  659        8 Batch loss: 0.239803 Batch F1: 0.0
Epoch:  659        9 Batch loss: 0.203309 Batch F1: 0.0
Epoch:  659       10 Batch loss: 0.235250 Batch F1: 0.0
Epoch:  659       11 Batch loss: 0.234692 Batch F1: 0.0
Epoch:  659       12 Batch loss: 0.233714 Batch F1: 0.0
Train Avg Loss  659: 0.228111

Train Avg F1  659: 0.0

Val Avg Loss  659: 0.218741

Val Avg F1  659:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 660
--------------------------------------------------------------
Epoch:  660        1 Batch loss: 0.244072 Batch F1: 0.0
Epoch:  660        2 Batch loss: 0.206348 Batch F1: 0.0
Epoch:  660        3 Batch loss: 0.208666 Batch F1: 0.0
Epoch:  660        4 Batch loss: 0.268606 Batch F1: 0.0
Epoch:  660        5 Batch loss: 0.208220 Batch F1: 0.0
Epoch:  660        6 Batch loss: 0.233264 Batch F1: 0.0
Epoch:  660        7 Batch loss: 0.233426 Batch F1: 0.0
Epoch:  660        8 Batch loss: 0.231063 Batch F1: 0.0
Epoch:  660        9 Batch loss: 0.216606 Batch F1: 0.0
Epoch:  660       10 Batch loss: 0.216788 Batch F1: 0.0
Epoch:  660       11 Batch loss: 0.226669 Batch F1: 0.0
Epoch:  660       12 Batch loss: 0.228644 Batch F1: 0.0
Train Avg Loss  660: 0.226864

Train Avg F1  660: 0.0

Val Avg Loss  660: 0.217642

Val Avg F1  660:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 661
--------------------------------------------------------------
Epoch:  661        1 Batch loss: 0.215071 Batch F1: 0.0
Epoch:  661        2 Batch loss: 0.219128 Batch F1: 0.0
Epoch:  661        3 Batch loss: 0.277448 Batch F1: 0.0
Epoch:  661        4 Batch loss: 0.218398 Batch F1: 0.0
Epoch:  661        5 Batch loss: 0.222721 Batch F1: 0.0
Epoch:  661        6 Batch loss: 0.222823 Batch F1: 0.0
Epoch:  661        7 Batch loss: 0.202160 Batch F1: 0.0
Epoch:  661        8 Batch loss: 0.232780 Batch F1: 0.0
Epoch:  661        9 Batch loss: 0.214659 Batch F1: 0.0
Epoch:  661       10 Batch loss: 0.223669 Batch F1: 0.0
Epoch:  661       11 Batch loss: 0.243535 Batch F1: 0.0
Epoch:  661       12 Batch loss: 0.230798 Batch F1: 0.0
Train Avg Loss  661: 0.226932

Train Avg F1  661: 0.0

Val Avg Loss  661: 0.217722

Val Avg F1  661:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 662
--------------------------------------------------------------
Epoch:  662        1 Batch loss: 0.252316 Batch F1: 0.0
Epoch:  662        2 Batch loss: 0.222593 Batch F1: 0.0
Epoch:  662        3 Batch loss: 0.240322 Batch F1: 0.0
Epoch:  662        4 Batch loss: 0.242431 Batch F1: 0.0
Epoch:  662        5 Batch loss: 0.235459 Batch F1: 0.0
Epoch:  662        6 Batch loss: 0.232340 Batch F1: 0.0
Epoch:  662        7 Batch loss: 0.227635 Batch F1: 0.1111111111111111
Epoch:  662        8 Batch loss: 0.227046 Batch F1: 0.0
Epoch:  662        9 Batch loss: 0.235160 Batch F1: 0.0
Epoch:  662       10 Batch loss: 0.208161 Batch F1: 0.0
Epoch:  662       11 Batch loss: 0.203480 Batch F1: 0.0
Epoch:  662       12 Batch loss: 0.194730 Batch F1: 0.0
Train Avg Loss  662: 0.226806

Train Avg F1  662: 0.009259259259259259

Val Avg Loss  662: 0.217121

Val Avg F1  662:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 663
--------------------------------------------------------------
Epoch:  663        1 Batch loss: 0.256383 Batch F1: 0.0
Epoch:  663        2 Batch loss: 0.198786 Batch F1: 0.0
Epoch:  663        3 Batch loss: 0.227560 Batch F1: 0.0
Epoch:  663        4 Batch loss: 0.212246 Batch F1: 0.0
Epoch:  663        5 Batch loss: 0.235815 Batch F1: 0.0
Epoch:  663        6 Batch loss: 0.256355 Batch F1: 0.0
Epoch:  663        7 Batch loss: 0.246382 Batch F1: 0.0
Epoch:  663        8 Batch loss: 0.218373 Batch F1: 0.0
Epoch:  663        9 Batch loss: 0.204410 Batch F1: 0.0
Epoch:  663       10 Batch loss: 0.230134 Batch F1: 0.0
Epoch:  663       11 Batch loss: 0.204022 Batch F1: 0.0
Epoch:  663       12 Batch loss: 0.253668 Batch F1: 0.0
Train Avg Loss  663: 0.228678

Train Avg F1  663: 0.0

Val Avg Loss  663: 0.217037

Val Avg F1  663:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 664
--------------------------------------------------------------
Epoch:  664        1 Batch loss: 0.262437 Batch F1: 0.0
Epoch:  664        2 Batch loss: 0.193645 Batch F1: 0.0
Epoch:  664        3 Batch loss: 0.198183 Batch F1: 0.0
Epoch:  664        4 Batch loss: 0.234361 Batch F1: 0.0
Epoch:  664        5 Batch loss: 0.248712 Batch F1: 0.0
Epoch:  664        6 Batch loss: 0.213399 Batch F1: 0.0
Epoch:  664        7 Batch loss: 0.212043 Batch F1: 0.0
Epoch:  664        8 Batch loss: 0.232562 Batch F1: 0.0
Epoch:  664        9 Batch loss: 0.233351 Batch F1: 0.0
Epoch:  664       10 Batch loss: 0.242179 Batch F1: 0.0
Epoch:  664       11 Batch loss: 0.219251 Batch F1: 0.0
Epoch:  664       12 Batch loss: 0.226684 Batch F1: 0.0
Train Avg Loss  664: 0.226401

Train Avg F1  664: 0.0

Val Avg Loss  664: 0.218835

Val Avg F1  664:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 665
--------------------------------------------------------------
Epoch:  665        1 Batch loss: 0.276644 Batch F1: 0.0
Epoch:  665        2 Batch loss: 0.229786 Batch F1: 0.0
Epoch:  665        3 Batch loss: 0.228302 Batch F1: 0.3478260869565218
Epoch:  665        4 Batch loss: 0.209276 Batch F1: 0.34782608695652173
Epoch:  665        5 Batch loss: 0.224298 Batch F1: 0.5161290322580644
Epoch:  665        6 Batch loss: 0.227240 Batch F1: 0.0
Epoch:  665        7 Batch loss: 0.215402 Batch F1: 0.0
Epoch:  665        8 Batch loss: 0.279604 Batch F1: 0.0
Epoch:  665        9 Batch loss: 0.208495 Batch F1: 0.0
Epoch:  665       10 Batch loss: 0.195719 Batch F1: 0.0
Epoch:  665       11 Batch loss: 0.218975 Batch F1: 0.0
Epoch:  665       12 Batch loss: 0.203636 Batch F1: 0.0
Train Avg Loss  665: 0.226448

Train Avg F1  665: 0.10098176718092566

Val Avg Loss  665: 0.217996

Val Avg F1  665:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 666
--------------------------------------------------------------
Epoch:  666        1 Batch loss: 0.215804 Batch F1: 0.0
Epoch:  666        2 Batch loss: 0.232768 Batch F1: 0.0
Epoch:  666        3 Batch loss: 0.200090 Batch F1: 0.0
Epoch:  666        4 Batch loss: 0.229881 Batch F1: 0.0
Epoch:  666        5 Batch loss: 0.252247 Batch F1: 0.0
Epoch:  666        6 Batch loss: 0.239053 Batch F1: 0.0
Epoch:  666        7 Batch loss: 0.200893 Batch F1: 0.0
Epoch:  666        8 Batch loss: 0.235120 Batch F1: 0.0
Epoch:  666        9 Batch loss: 0.241247 Batch F1: 0.0
Epoch:  666       10 Batch loss: 0.217787 Batch F1: 0.0
Epoch:  666       11 Batch loss: 0.245306 Batch F1: 0.0
Epoch:  666       12 Batch loss: 0.211788 Batch F1: 0.0
Train Avg Loss  666: 0.226832

Train Avg F1  666: 0.0

Val Avg Loss  666: 0.220394

Val Avg F1  666:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 667
--------------------------------------------------------------
Epoch:  667        1 Batch loss: 0.215285 Batch F1: 0.0
Epoch:  667        2 Batch loss: 0.210444 Batch F1: 0.0
Epoch:  667        3 Batch loss: 0.234512 Batch F1: 0.0
Epoch:  667        4 Batch loss: 0.210346 Batch F1: 0.0
Epoch:  667        5 Batch loss: 0.218067 Batch F1: 0.0
Epoch:  667        6 Batch loss: 0.255654 Batch F1: 0.0
Epoch:  667        7 Batch loss: 0.222100 Batch F1: 0.0
Epoch:  667        8 Batch loss: 0.233313 Batch F1: 0.0
Epoch:  667        9 Batch loss: 0.225613 Batch F1: 0.0
Epoch:  667       10 Batch loss: 0.234748 Batch F1: 0.0
Epoch:  667       11 Batch loss: 0.235370 Batch F1: 0.0
Epoch:  667       12 Batch loss: 0.224510 Batch F1: 0.0
Train Avg Loss  667: 0.226664

Train Avg F1  667: 0.0

Val Avg Loss  667: 0.217918

Val Avg F1  667:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 668
--------------------------------------------------------------
Epoch:  668        1 Batch loss: 0.227700 Batch F1: 0.0
Epoch:  668        2 Batch loss: 0.230111 Batch F1: 0.0
Epoch:  668        3 Batch loss: 0.233747 Batch F1: 0.0
Epoch:  668        4 Batch loss: 0.248515 Batch F1: 0.0
Epoch:  668        5 Batch loss: 0.243220 Batch F1: 0.24
Epoch:  668        6 Batch loss: 0.198908 Batch F1: 0.11764705882352941
Epoch:  668        7 Batch loss: 0.211998 Batch F1: 0.0
Epoch:  668        8 Batch loss: 0.241554 Batch F1: 0.0
Epoch:  668        9 Batch loss: 0.197365 Batch F1: 0.0
Epoch:  668       10 Batch loss: 0.204601 Batch F1: 0.0
Epoch:  668       11 Batch loss: 0.231354 Batch F1: 0.0
Epoch:  668       12 Batch loss: 0.255473 Batch F1: 0.0
Train Avg Loss  668: 0.227046

Train Avg F1  668: 0.02980392156862745

Val Avg Loss  668: 0.216969

Val Avg F1  668:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 669
--------------------------------------------------------------
Epoch:  669        1 Batch loss: 0.248031 Batch F1: 0.0
Epoch:  669        2 Batch loss: 0.222790 Batch F1: 0.0
Epoch:  669        3 Batch loss: 0.192175 Batch F1: 0.0
Epoch:  669        4 Batch loss: 0.204636 Batch F1: 0.0
Epoch:  669        5 Batch loss: 0.212088 Batch F1: 0.0
Epoch:  669        6 Batch loss: 0.201775 Batch F1: 0.0
Epoch:  669        7 Batch loss: 0.273329 Batch F1: 0.0
Epoch:  669        8 Batch loss: 0.244083 Batch F1: 0.0
Epoch:  669        9 Batch loss: 0.218317 Batch F1: 0.0
Epoch:  669       10 Batch loss: 0.222452 Batch F1: 0.0
Epoch:  669       11 Batch loss: 0.224156 Batch F1: 0.0
Epoch:  669       12 Batch loss: 0.272416 Batch F1: 0.0
Train Avg Loss  669: 0.228021

Train Avg F1  669: 0.0

Val Avg Loss  669: 0.217937

Val Avg F1  669:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 670
--------------------------------------------------------------
Epoch:  670        1 Batch loss: 0.239295 Batch F1: 0.0
Epoch:  670        2 Batch loss: 0.255445 Batch F1: 0.0
Epoch:  670        3 Batch loss: 0.211929 Batch F1: 0.0
Epoch:  670        4 Batch loss: 0.215622 Batch F1: 0.0
Epoch:  670        5 Batch loss: 0.257483 Batch F1: 0.0
Epoch:  670        6 Batch loss: 0.211880 Batch F1: 0.0
Epoch:  670        7 Batch loss: 0.232347 Batch F1: 0.0
Epoch:  670        8 Batch loss: 0.224383 Batch F1: 0.34782608695652173
Epoch:  670        9 Batch loss: 0.197870 Batch F1: 0.2222222222222222
Epoch:  670       10 Batch loss: 0.218921 Batch F1: 0.0
Epoch:  670       11 Batch loss: 0.246877 Batch F1: 0.0
Epoch:  670       12 Batch loss: 0.207080 Batch F1: 0.0
Train Avg Loss  670: 0.226594

Train Avg F1  670: 0.047504025764895326

Val Avg Loss  670: 0.216525

Val Avg F1  670:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 671
--------------------------------------------------------------
Epoch:  671        1 Batch loss: 0.221394 Batch F1: 0.0
Epoch:  671        2 Batch loss: 0.249061 Batch F1: 0.0
Epoch:  671        3 Batch loss: 0.240901 Batch F1: 0.0
Epoch:  671        4 Batch loss: 0.242723 Batch F1: 0.0
Epoch:  671        5 Batch loss: 0.235550 Batch F1: 0.0
Epoch:  671        6 Batch loss: 0.205333 Batch F1: 0.0
Epoch:  671        7 Batch loss: 0.230947 Batch F1: 0.0
Epoch:  671        8 Batch loss: 0.207132 Batch F1: 0.0
Epoch:  671        9 Batch loss: 0.203869 Batch F1: 0.0
Epoch:  671       10 Batch loss: 0.226158 Batch F1: 0.0
Epoch:  671       11 Batch loss: 0.215598 Batch F1: 0.0
Epoch:  671       12 Batch loss: 0.252353 Batch F1: 0.0
Train Avg Loss  671: 0.227585

Train Avg F1  671: 0.0

Val Avg Loss  671: 0.216945

Val Avg F1  671:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 672
--------------------------------------------------------------
Epoch:  672        1 Batch loss: 0.231034 Batch F1: 0.0
Epoch:  672        2 Batch loss: 0.219843 Batch F1: 0.0
Epoch:  672        3 Batch loss: 0.234319 Batch F1: 0.0
Epoch:  672        4 Batch loss: 0.232261 Batch F1: 0.0
Epoch:  672        5 Batch loss: 0.254818 Batch F1: 0.0
Epoch:  672        6 Batch loss: 0.241410 Batch F1: 0.0
Epoch:  672        7 Batch loss: 0.223824 Batch F1: 0.0
Epoch:  672        8 Batch loss: 0.236215 Batch F1: 0.0
Epoch:  672        9 Batch loss: 0.224624 Batch F1: 0.0
Epoch:  672       10 Batch loss: 0.199798 Batch F1: 0.0
Epoch:  672       11 Batch loss: 0.207403 Batch F1: 0.0
Epoch:  672       12 Batch loss: 0.208328 Batch F1: 0.0
Train Avg Loss  672: 0.226156

Train Avg F1  672: 0.0

Val Avg Loss  672: 0.218272

Val Avg F1  672:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 673
--------------------------------------------------------------
Epoch:  673        1 Batch loss: 0.226240 Batch F1: 0.0
Epoch:  673        2 Batch loss: 0.222767 Batch F1: 0.0
Epoch:  673        3 Batch loss: 0.245431 Batch F1: 0.0
Epoch:  673        4 Batch loss: 0.239374 Batch F1: 0.0
Epoch:  673        5 Batch loss: 0.232585 Batch F1: 0.15384615384615385
Epoch:  673        6 Batch loss: 0.207887 Batch F1: 0.5517241379310345
Epoch:  673        7 Batch loss: 0.264085 Batch F1: 0.0
Epoch:  673        8 Batch loss: 0.201576 Batch F1: 0.0
Epoch:  673        9 Batch loss: 0.196491 Batch F1: 0.0
Epoch:  673       10 Batch loss: 0.258458 Batch F1: 0.0
Epoch:  673       11 Batch loss: 0.182117 Batch F1: 0.0
Epoch:  673       12 Batch loss: 0.237898 Batch F1: 0.0
Train Avg Loss  673: 0.226242

Train Avg F1  673: 0.058797524314765696

Val Avg Loss  673: 0.216718

Val Avg F1  673:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 674
--------------------------------------------------------------
Epoch:  674        1 Batch loss: 0.230155 Batch F1: 0.0
Epoch:  674        2 Batch loss: 0.228051 Batch F1: 0.0
Epoch:  674        3 Batch loss: 0.204594 Batch F1: 0.0
Epoch:  674        4 Batch loss: 0.214616 Batch F1: 0.0
Epoch:  674        5 Batch loss: 0.240959 Batch F1: 0.0
Epoch:  674        6 Batch loss: 0.216927 Batch F1: 0.0
Epoch:  674        7 Batch loss: 0.241074 Batch F1: 0.0
Epoch:  674        8 Batch loss: 0.191449 Batch F1: 0.0
Epoch:  674        9 Batch loss: 0.223659 Batch F1: 0.0
Epoch:  674       10 Batch loss: 0.254169 Batch F1: 0.0
Epoch:  674       11 Batch loss: 0.244908 Batch F1: 0.0
Epoch:  674       12 Batch loss: 0.230850 Batch F1: 0.0
Train Avg Loss  674: 0.226784

Train Avg F1  674: 0.0

Val Avg Loss  674: 0.217317

Val Avg F1  674:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 675
--------------------------------------------------------------
Epoch:  675        1 Batch loss: 0.215469 Batch F1: 0.0
Epoch:  675        2 Batch loss: 0.231600 Batch F1: 0.0
Epoch:  675        3 Batch loss: 0.240999 Batch F1: 0.0
Epoch:  675        4 Batch loss: 0.201970 Batch F1: 0.0
Epoch:  675        5 Batch loss: 0.209407 Batch F1: 0.0
Epoch:  675        6 Batch loss: 0.214097 Batch F1: 0.0
Epoch:  675        7 Batch loss: 0.256769 Batch F1: 0.0
Epoch:  675        8 Batch loss: 0.243213 Batch F1: 0.0
Epoch:  675        9 Batch loss: 0.208428 Batch F1: 0.0
Epoch:  675       10 Batch loss: 0.230064 Batch F1: 0.0
Epoch:  675       11 Batch loss: 0.208556 Batch F1: 0.0
Epoch:  675       12 Batch loss: 0.268382 Batch F1: 0.0
Train Avg Loss  675: 0.227413

Train Avg F1  675: 0.0

Val Avg Loss  675: 0.218007

Val Avg F1  675:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 676
--------------------------------------------------------------
Epoch:  676        1 Batch loss: 0.199736 Batch F1: 0.0
Epoch:  676        2 Batch loss: 0.226511 Batch F1: 0.0
Epoch:  676        3 Batch loss: 0.265360 Batch F1: 0.0
Epoch:  676        4 Batch loss: 0.241798 Batch F1: 0.0
Epoch:  676        5 Batch loss: 0.211220 Batch F1: 0.0
Epoch:  676        6 Batch loss: 0.256730 Batch F1: 0.0
Epoch:  676        7 Batch loss: 0.218606 Batch F1: 0.0
Epoch:  676        8 Batch loss: 0.233867 Batch F1: 0.0
Epoch:  676        9 Batch loss: 0.227272 Batch F1: 0.0
Epoch:  676       10 Batch loss: 0.214934 Batch F1: 0.0
Epoch:  676       11 Batch loss: 0.235497 Batch F1: 0.0
Epoch:  676       12 Batch loss: 0.200883 Batch F1: 0.0
Train Avg Loss  676: 0.227701

Train Avg F1  676: 0.0

Val Avg Loss  676: 0.218256

Val Avg F1  676:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 677
--------------------------------------------------------------
Epoch:  677        1 Batch loss: 0.216961 Batch F1: 0.0
Epoch:  677        2 Batch loss: 0.230282 Batch F1: 0.0
Epoch:  677        3 Batch loss: 0.232093 Batch F1: 0.0
Epoch:  677        4 Batch loss: 0.208046 Batch F1: 0.0
Epoch:  677        5 Batch loss: 0.237145 Batch F1: 0.0
Epoch:  677        6 Batch loss: 0.192676 Batch F1: 0.0
Epoch:  677        7 Batch loss: 0.230381 Batch F1: 0.0
Epoch:  677        8 Batch loss: 0.261227 Batch F1: 0.0
Epoch:  677        9 Batch loss: 0.219277 Batch F1: 0.0
Epoch:  677       10 Batch loss: 0.227827 Batch F1: 0.0
Epoch:  677       11 Batch loss: 0.220221 Batch F1: 0.0
Epoch:  677       12 Batch loss: 0.251570 Batch F1: 0.0
Train Avg Loss  677: 0.227309

Train Avg F1  677: 0.0

Val Avg Loss  677: 0.216926

Val Avg F1  677:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 678
--------------------------------------------------------------
Epoch:  678        1 Batch loss: 0.233149 Batch F1: 0.0
Epoch:  678        2 Batch loss: 0.222118 Batch F1: 0.0
Epoch:  678        3 Batch loss: 0.227984 Batch F1: 0.0
Epoch:  678        4 Batch loss: 0.256904 Batch F1: 0.0
Epoch:  678        5 Batch loss: 0.206185 Batch F1: 0.0
Epoch:  678        6 Batch loss: 0.217658 Batch F1: 0.0
Epoch:  678        7 Batch loss: 0.202174 Batch F1: 0.0
Epoch:  678        8 Batch loss: 0.204971 Batch F1: 0.0
Epoch:  678        9 Batch loss: 0.256395 Batch F1: 0.0
Epoch:  678       10 Batch loss: 0.227943 Batch F1: 0.0
Epoch:  678       11 Batch loss: 0.217485 Batch F1: 0.0
Epoch:  678       12 Batch loss: 0.251414 Batch F1: 0.0
Train Avg Loss  678: 0.227032

Train Avg F1  678: 0.0

Val Avg Loss  678: 0.219311

Val Avg F1  678:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 679
--------------------------------------------------------------
Epoch:  679        1 Batch loss: 0.201018 Batch F1: 0.0
Epoch:  679        2 Batch loss: 0.216260 Batch F1: 0.2
Epoch:  679        3 Batch loss: 0.218700 Batch F1: 0.0
Epoch:  679        4 Batch loss: 0.206803 Batch F1: 0.0
Epoch:  679        5 Batch loss: 0.215254 Batch F1: 0.0
Epoch:  679        6 Batch loss: 0.231724 Batch F1: 0.0
Epoch:  679        7 Batch loss: 0.263578 Batch F1: 0.0
Epoch:  679        8 Batch loss: 0.230130 Batch F1: 0.0
Epoch:  679        9 Batch loss: 0.240168 Batch F1: 0.0
Epoch:  679       10 Batch loss: 0.225247 Batch F1: 0.0
Epoch:  679       11 Batch loss: 0.243799 Batch F1: 0.0
Epoch:  679       12 Batch loss: 0.245570 Batch F1: 0.0
Train Avg Loss  679: 0.228187

Train Avg F1  679: 0.016666666666666666

Val Avg Loss  679: 0.225283

Val Avg F1  679:  0.3905374235958944

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 680
--------------------------------------------------------------
Epoch:  680        1 Batch loss: 0.211601 Batch F1: 0.43478260869565216
Epoch:  680        2 Batch loss: 0.226100 Batch F1: 0.0
Epoch:  680        3 Batch loss: 0.223233 Batch F1: 0.0
Epoch:  680        4 Batch loss: 0.246321 Batch F1: 0.0
Epoch:  680        5 Batch loss: 0.244736 Batch F1: 0.0
Epoch:  680        6 Batch loss: 0.251336 Batch F1: 0.0
Epoch:  680        7 Batch loss: 0.199826 Batch F1: 0.0
Epoch:  680        8 Batch loss: 0.209903 Batch F1: 0.0
Epoch:  680        9 Batch loss: 0.233107 Batch F1: 0.0
Epoch:  680       10 Batch loss: 0.228785 Batch F1: 0.0
Epoch:  680       11 Batch loss: 0.236404 Batch F1: 0.0
Epoch:  680       12 Batch loss: 0.225200 Batch F1: 0.0
Train Avg Loss  680: 0.228046

Train Avg F1  680: 0.036231884057971016

Val Avg Loss  680: 0.218341

Val Avg F1  680:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 681
--------------------------------------------------------------
Epoch:  681        1 Batch loss: 0.197720 Batch F1: 0.0
Epoch:  681        2 Batch loss: 0.229011 Batch F1: 0.0
Epoch:  681        3 Batch loss: 0.239315 Batch F1: 0.0
Epoch:  681        4 Batch loss: 0.243075 Batch F1: 0.0
Epoch:  681        5 Batch loss: 0.219160 Batch F1: 0.0
Epoch:  681        6 Batch loss: 0.234445 Batch F1: 0.0
Epoch:  681        7 Batch loss: 0.199799 Batch F1: 0.0
Epoch:  681        8 Batch loss: 0.229642 Batch F1: 0.24
Epoch:  681        9 Batch loss: 0.238654 Batch F1: 0.2962962962962963
Epoch:  681       10 Batch loss: 0.241039 Batch F1: 0.0
Epoch:  681       11 Batch loss: 0.222122 Batch F1: 0.0
Epoch:  681       12 Batch loss: 0.220831 Batch F1: 0.0
Train Avg Loss  681: 0.226235

Train Avg F1  681: 0.044691358024691354

Val Avg Loss  681: 0.216858

Val Avg F1  681:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 682
--------------------------------------------------------------
Epoch:  682        1 Batch loss: 0.201348 Batch F1: 0.0
Epoch:  682        2 Batch loss: 0.255846 Batch F1: 0.0
Epoch:  682        3 Batch loss: 0.222055 Batch F1: 0.0
Epoch:  682        4 Batch loss: 0.203609 Batch F1: 0.0
Epoch:  682        5 Batch loss: 0.228913 Batch F1: 0.0
Epoch:  682        6 Batch loss: 0.234972 Batch F1: 0.0
Epoch:  682        7 Batch loss: 0.206770 Batch F1: 0.0
Epoch:  682        8 Batch loss: 0.263588 Batch F1: 0.0
Epoch:  682        9 Batch loss: 0.223600 Batch F1: 0.0
Epoch:  682       10 Batch loss: 0.222483 Batch F1: 0.0
Epoch:  682       11 Batch loss: 0.232531 Batch F1: 0.14814814814814814
Epoch:  682       12 Batch loss: 0.225022 Batch F1: 0.0
Train Avg Loss  682: 0.226728

Train Avg F1  682: 0.012345679012345678

Val Avg Loss  682: 0.219088

Val Avg F1  682:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 683
--------------------------------------------------------------
Epoch:  683        1 Batch loss: 0.229280 Batch F1: 0.0
Epoch:  683        2 Batch loss: 0.234543 Batch F1: 0.0
Epoch:  683        3 Batch loss: 0.229400 Batch F1: 0.0
Epoch:  683        4 Batch loss: 0.265246 Batch F1: 0.0
Epoch:  683        5 Batch loss: 0.219548 Batch F1: 0.0
Epoch:  683        6 Batch loss: 0.230350 Batch F1: 0.0
Epoch:  683        7 Batch loss: 0.237326 Batch F1: 0.0
Epoch:  683        8 Batch loss: 0.229571 Batch F1: 0.0
Epoch:  683        9 Batch loss: 0.215032 Batch F1: 0.0
Epoch:  683       10 Batch loss: 0.232101 Batch F1: 0.0
Epoch:  683       11 Batch loss: 0.206693 Batch F1: 0.0
Epoch:  683       12 Batch loss: 0.194455 Batch F1: 0.0
Train Avg Loss  683: 0.226962

Train Avg F1  683: 0.0

Val Avg Loss  683: 0.217369

Val Avg F1  683:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 684
--------------------------------------------------------------
Epoch:  684        1 Batch loss: 0.212321 Batch F1: 0.0
Epoch:  684        2 Batch loss: 0.239918 Batch F1: 0.0
Epoch:  684        3 Batch loss: 0.237923 Batch F1: 0.0
Epoch:  684        4 Batch loss: 0.188890 Batch F1: 0.0
Epoch:  684        5 Batch loss: 0.218796 Batch F1: 0.0
Epoch:  684        6 Batch loss: 0.248465 Batch F1: 0.0
Epoch:  684        7 Batch loss: 0.255507 Batch F1: 0.0
Epoch:  684        8 Batch loss: 0.224262 Batch F1: 0.0
Epoch:  684        9 Batch loss: 0.235276 Batch F1: 0.0
Epoch:  684       10 Batch loss: 0.237403 Batch F1: 0.0
Epoch:  684       11 Batch loss: 0.214036 Batch F1: 0.0
Epoch:  684       12 Batch loss: 0.219701 Batch F1: 0.0
Train Avg Loss  684: 0.227708

Train Avg F1  684: 0.0

Val Avg Loss  684: 0.218843

Val Avg F1  684:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 685
--------------------------------------------------------------
Epoch:  685        1 Batch loss: 0.213100 Batch F1: 0.0
Epoch:  685        2 Batch loss: 0.194198 Batch F1: 0.0
Epoch:  685        3 Batch loss: 0.252975 Batch F1: 0.0
Epoch:  685        4 Batch loss: 0.219690 Batch F1: 0.0
Epoch:  685        5 Batch loss: 0.226516 Batch F1: 0.0
Epoch:  685        6 Batch loss: 0.223547 Batch F1: 0.0
Epoch:  685        7 Batch loss: 0.203337 Batch F1: 0.0
Epoch:  685        8 Batch loss: 0.254198 Batch F1: 0.0
Epoch:  685        9 Batch loss: 0.218351 Batch F1: 0.0
Epoch:  685       10 Batch loss: 0.262583 Batch F1: 0.0
Epoch:  685       11 Batch loss: 0.199536 Batch F1: 0.0
Epoch:  685       12 Batch loss: 0.252494 Batch F1: 0.0
Train Avg Loss  685: 0.226710

Train Avg F1  685: 0.0

Val Avg Loss  685: 0.221960

Val Avg F1  685:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 686
--------------------------------------------------------------
Epoch:  686        1 Batch loss: 0.226763 Batch F1: 0.0
Epoch:  686        2 Batch loss: 0.229555 Batch F1: 0.24
Epoch:  686        3 Batch loss: 0.235434 Batch F1: 0.23076923076923078
Epoch:  686        4 Batch loss: 0.214380 Batch F1: 0.0
Epoch:  686        5 Batch loss: 0.239026 Batch F1: 0.0
Epoch:  686        6 Batch loss: 0.234609 Batch F1: 0.0
Epoch:  686        7 Batch loss: 0.215572 Batch F1: 0.0
Epoch:  686        8 Batch loss: 0.217436 Batch F1: 0.0
Epoch:  686        9 Batch loss: 0.205521 Batch F1: 0.0
Epoch:  686       10 Batch loss: 0.242546 Batch F1: 0.0
Epoch:  686       11 Batch loss: 0.231861 Batch F1: 0.0
Epoch:  686       12 Batch loss: 0.252549 Batch F1: 0.0
Train Avg Loss  686: 0.228771

Train Avg F1  686: 0.03923076923076923

Val Avg Loss  686: 0.217275

Val Avg F1  686:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 687
--------------------------------------------------------------
Epoch:  687        1 Batch loss: 0.181045 Batch F1: 0.0
Epoch:  687        2 Batch loss: 0.208269 Batch F1: 0.0
Epoch:  687        3 Batch loss: 0.224600 Batch F1: 0.0
Epoch:  687        4 Batch loss: 0.233915 Batch F1: 0.0
Epoch:  687        5 Batch loss: 0.253249 Batch F1: 0.0
Epoch:  687        6 Batch loss: 0.232983 Batch F1: 0.0
Epoch:  687        7 Batch loss: 0.230791 Batch F1: 0.0
Epoch:  687        8 Batch loss: 0.221827 Batch F1: 0.0
Epoch:  687        9 Batch loss: 0.228912 Batch F1: 0.0
Epoch:  687       10 Batch loss: 0.237387 Batch F1: 0.0
Epoch:  687       11 Batch loss: 0.254683 Batch F1: 0.0
Epoch:  687       12 Batch loss: 0.199535 Batch F1: 0.5217391304347827
Train Avg Loss  687: 0.225600

Train Avg F1  687: 0.04347826086956522

Val Avg Loss  687: 0.220355

Val Avg F1  687:  0.2906142167011732

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 688
--------------------------------------------------------------
Epoch:  688        1 Batch loss: 0.225846 Batch F1: 0.3448275862068966
Epoch:  688        2 Batch loss: 0.227759 Batch F1: 0.0
Epoch:  688        3 Batch loss: 0.235356 Batch F1: 0.0
Epoch:  688        4 Batch loss: 0.231717 Batch F1: 0.0
Epoch:  688        5 Batch loss: 0.233983 Batch F1: 0.0
Epoch:  688        6 Batch loss: 0.244806 Batch F1: 0.0
Epoch:  688        7 Batch loss: 0.226695 Batch F1: 0.38461538461538464
Epoch:  688        8 Batch loss: 0.208980 Batch F1: 0.28571428571428575
Epoch:  688        9 Batch loss: 0.204769 Batch F1: 0.0
Epoch:  688       10 Batch loss: 0.191351 Batch F1: 0.0
Epoch:  688       11 Batch loss: 0.284956 Batch F1: 0.0
Epoch:  688       12 Batch loss: 0.247327 Batch F1: 0.0
Train Avg Loss  688: 0.230295

Train Avg F1  688: 0.08459643804471391

Val Avg Loss  688: 0.217280

Val Avg F1  688:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 689
--------------------------------------------------------------
Epoch:  689        1 Batch loss: 0.252334 Batch F1: 0.0
Epoch:  689        2 Batch loss: 0.201763 Batch F1: 0.0
Epoch:  689        3 Batch loss: 0.226691 Batch F1: 0.0
Epoch:  689        4 Batch loss: 0.242318 Batch F1: 0.0
Epoch:  689        5 Batch loss: 0.227994 Batch F1: 0.0
Epoch:  689        6 Batch loss: 0.221074 Batch F1: 0.0
Epoch:  689        7 Batch loss: 0.223022 Batch F1: 0.0
Epoch:  689        8 Batch loss: 0.228987 Batch F1: 0.0
Epoch:  689        9 Batch loss: 0.231991 Batch F1: 0.0
Epoch:  689       10 Batch loss: 0.223854 Batch F1: 0.0
Epoch:  689       11 Batch loss: 0.225787 Batch F1: 0.0
Epoch:  689       12 Batch loss: 0.234340 Batch F1: 0.0
Train Avg Loss  689: 0.228346

Train Avg F1  689: 0.0

Val Avg Loss  689: 0.217498

Val Avg F1  689:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 690
--------------------------------------------------------------
Epoch:  690        1 Batch loss: 0.217464 Batch F1: 0.0
Epoch:  690        2 Batch loss: 0.218449 Batch F1: 0.0
Epoch:  690        3 Batch loss: 0.235603 Batch F1: 0.0
Epoch:  690        4 Batch loss: 0.214758 Batch F1: 0.0
Epoch:  690        5 Batch loss: 0.220027 Batch F1: 0.0
Epoch:  690        6 Batch loss: 0.215655 Batch F1: 0.0
Epoch:  690        7 Batch loss: 0.266451 Batch F1: 0.0
Epoch:  690        8 Batch loss: 0.223554 Batch F1: 0.0
Epoch:  690        9 Batch loss: 0.244073 Batch F1: 0.0
Epoch:  690       10 Batch loss: 0.232950 Batch F1: 0.0
Epoch:  690       11 Batch loss: 0.259577 Batch F1: 0.0
Epoch:  690       12 Batch loss: 0.179452 Batch F1: 0.0
Train Avg Loss  690: 0.227335

Train Avg F1  690: 0.0

Val Avg Loss  690: 0.218175

Val Avg F1  690:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 691
--------------------------------------------------------------
Epoch:  691        1 Batch loss: 0.243451 Batch F1: 0.0
Epoch:  691        2 Batch loss: 0.209131 Batch F1: 0.0
Epoch:  691        3 Batch loss: 0.232621 Batch F1: 0.0
Epoch:  691        4 Batch loss: 0.223853 Batch F1: 0.0
Epoch:  691        5 Batch loss: 0.243946 Batch F1: 0.0
Epoch:  691        6 Batch loss: 0.249312 Batch F1: 0.0
Epoch:  691        7 Batch loss: 0.211439 Batch F1: 0.0
Epoch:  691        8 Batch loss: 0.243390 Batch F1: 0.0
Epoch:  691        9 Batch loss: 0.193620 Batch F1: 0.0
Epoch:  691       10 Batch loss: 0.206182 Batch F1: 0.0
Epoch:  691       11 Batch loss: 0.231143 Batch F1: 0.0
Epoch:  691       12 Batch loss: 0.230002 Batch F1: 0.0
Train Avg Loss  691: 0.226507

Train Avg F1  691: 0.0

Val Avg Loss  691: 0.217476

Val Avg F1  691:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 692
--------------------------------------------------------------
Epoch:  692        1 Batch loss: 0.240230 Batch F1: 0.0
Epoch:  692        2 Batch loss: 0.217434 Batch F1: 0.0
Epoch:  692        3 Batch loss: 0.202029 Batch F1: 0.0
Epoch:  692        4 Batch loss: 0.239051 Batch F1: 0.0
Epoch:  692        5 Batch loss: 0.250853 Batch F1: 0.0
Epoch:  692        6 Batch loss: 0.224622 Batch F1: 0.0
Epoch:  692        7 Batch loss: 0.269155 Batch F1: 0.0
Epoch:  692        8 Batch loss: 0.209828 Batch F1: 0.56
Epoch:  692        9 Batch loss: 0.212219 Batch F1: 0.5384615384615384
Epoch:  692       10 Batch loss: 0.203470 Batch F1: 0.4210526315789474
Epoch:  692       11 Batch loss: 0.227952 Batch F1: 0.25
Epoch:  692       12 Batch loss: 0.247836 Batch F1: 0.0
Train Avg Loss  692: 0.228723

Train Avg F1  692: 0.14745951417004047

Val Avg Loss  692: 0.217955

Val Avg F1  692:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 693
--------------------------------------------------------------
Epoch:  693        1 Batch loss: 0.214950 Batch F1: 0.0
Epoch:  693        2 Batch loss: 0.191740 Batch F1: 0.0
Epoch:  693        3 Batch loss: 0.254554 Batch F1: 0.0
Epoch:  693        4 Batch loss: 0.223319 Batch F1: 0.0
Epoch:  693        5 Batch loss: 0.224682 Batch F1: 0.0
Epoch:  693        6 Batch loss: 0.205727 Batch F1: 0.0
Epoch:  693        7 Batch loss: 0.201910 Batch F1: 0.0
Epoch:  693        8 Batch loss: 0.279153 Batch F1: 0.0
Epoch:  693        9 Batch loss: 0.234652 Batch F1: 0.0
Epoch:  693       10 Batch loss: 0.241651 Batch F1: 0.0
Epoch:  693       11 Batch loss: 0.224623 Batch F1: 0.4166666666666667
Epoch:  693       12 Batch loss: 0.236132 Batch F1: 0.3846153846153846
Train Avg Loss  693: 0.227758

Train Avg F1  693: 0.06677350427350427

Val Avg Loss  693: 0.227904

Val Avg F1  693:  0.4286343800804313

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 694
--------------------------------------------------------------
Epoch:  694        1 Batch loss: 0.241911 Batch F1: 0.2758620689655173
Epoch:  694        2 Batch loss: 0.232208 Batch F1: 0.35714285714285715
Epoch:  694        3 Batch loss: 0.233457 Batch F1: 0.30769230769230765
Epoch:  694        4 Batch loss: 0.223349 Batch F1: 0.0
Epoch:  694        5 Batch loss: 0.212862 Batch F1: 0.0
Epoch:  694        6 Batch loss: 0.236025 Batch F1: 0.0
Epoch:  694        7 Batch loss: 0.224448 Batch F1: 0.0
Epoch:  694        8 Batch loss: 0.211902 Batch F1: 0.0
Epoch:  694        9 Batch loss: 0.211399 Batch F1: 0.0
Epoch:  694       10 Batch loss: 0.221365 Batch F1: 0.0
Epoch:  694       11 Batch loss: 0.283463 Batch F1: 0.0
Epoch:  694       12 Batch loss: 0.203677 Batch F1: 0.0
Train Avg Loss  694: 0.228005

Train Avg F1  694: 0.07839143615005684

Val Avg Loss  694: 0.218400

Val Avg F1  694:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 695
--------------------------------------------------------------
Epoch:  695        1 Batch loss: 0.220282 Batch F1: 0.0
Epoch:  695        2 Batch loss: 0.232008 Batch F1: 0.0
Epoch:  695        3 Batch loss: 0.230769 Batch F1: 0.0
Epoch:  695        4 Batch loss: 0.240183 Batch F1: 0.0
Epoch:  695        5 Batch loss: 0.202356 Batch F1: 0.0
Epoch:  695        6 Batch loss: 0.215638 Batch F1: 0.0
Epoch:  695        7 Batch loss: 0.261351 Batch F1: 0.0
Epoch:  695        8 Batch loss: 0.205544 Batch F1: 0.0
Epoch:  695        9 Batch loss: 0.256268 Batch F1: 0.0
Epoch:  695       10 Batch loss: 0.239216 Batch F1: 0.0
Epoch:  695       11 Batch loss: 0.213697 Batch F1: 0.0
Epoch:  695       12 Batch loss: 0.208577 Batch F1: 0.0
Train Avg Loss  695: 0.227157

Train Avg F1  695: 0.0

Val Avg Loss  695: 0.217150

Val Avg F1  695:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 696
--------------------------------------------------------------
Epoch:  696        1 Batch loss: 0.208396 Batch F1: 0.0
Epoch:  696        2 Batch loss: 0.241449 Batch F1: 0.0
Epoch:  696        3 Batch loss: 0.236597 Batch F1: 0.0
Epoch:  696        4 Batch loss: 0.263134 Batch F1: 0.0
Epoch:  696        5 Batch loss: 0.242631 Batch F1: 0.0
Epoch:  696        6 Batch loss: 0.234278 Batch F1: 0.0
Epoch:  696        7 Batch loss: 0.214617 Batch F1: 0.3333333333333333
Epoch:  696        8 Batch loss: 0.240976 Batch F1: 0.25
Epoch:  696        9 Batch loss: 0.207326 Batch F1: 0.3157894736842105
Epoch:  696       10 Batch loss: 0.220093 Batch F1: 0.0
Epoch:  696       11 Batch loss: 0.211131 Batch F1: 0.0
Epoch:  696       12 Batch loss: 0.206439 Batch F1: 0.0
Train Avg Loss  696: 0.227256

Train Avg F1  696: 0.07492690058479531

Val Avg Loss  696: 0.217190

Val Avg F1  696:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 697
--------------------------------------------------------------
Epoch:  697        1 Batch loss: 0.218163 Batch F1: 0.0
Epoch:  697        2 Batch loss: 0.205389 Batch F1: 0.0
Epoch:  697        3 Batch loss: 0.233851 Batch F1: 0.0
Epoch:  697        4 Batch loss: 0.182974 Batch F1: 0.0
Epoch:  697        5 Batch loss: 0.257636 Batch F1: 0.0
Epoch:  697        6 Batch loss: 0.204650 Batch F1: 0.0
Epoch:  697        7 Batch loss: 0.265417 Batch F1: 0.0
Epoch:  697        8 Batch loss: 0.240109 Batch F1: 0.0
Epoch:  697        9 Batch loss: 0.213603 Batch F1: 0.0
Epoch:  697       10 Batch loss: 0.235465 Batch F1: 0.0
Epoch:  697       11 Batch loss: 0.223706 Batch F1: 0.0
Epoch:  697       12 Batch loss: 0.263672 Batch F1: 0.0
Train Avg Loss  697: 0.228720

Train Avg F1  697: 0.0

Val Avg Loss  697: 0.226170

Val Avg F1  697:  0.383963258963259

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 698
--------------------------------------------------------------
Epoch:  698        1 Batch loss: 0.209432 Batch F1: 0.4
Epoch:  698        2 Batch loss: 0.234476 Batch F1: 0.0
Epoch:  698        3 Batch loss: 0.246300 Batch F1: 0.0
Epoch:  698        4 Batch loss: 0.225180 Batch F1: 0.0
Epoch:  698        5 Batch loss: 0.233146 Batch F1: 0.0
Epoch:  698        6 Batch loss: 0.211572 Batch F1: 0.0
Epoch:  698        7 Batch loss: 0.251984 Batch F1: 0.0
Epoch:  698        8 Batch loss: 0.219247 Batch F1: 0.0
Epoch:  698        9 Batch loss: 0.264301 Batch F1: 0.0
Epoch:  698       10 Batch loss: 0.214468 Batch F1: 0.0
Epoch:  698       11 Batch loss: 0.205869 Batch F1: 0.0
Epoch:  698       12 Batch loss: 0.220979 Batch F1: 0.0
Train Avg Loss  698: 0.228079

Train Avg F1  698: 0.03333333333333333

Val Avg Loss  698: 0.216763

Val Avg F1  698:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 699
--------------------------------------------------------------
Epoch:  699        1 Batch loss: 0.213373 Batch F1: 0.0
Epoch:  699        2 Batch loss: 0.231255 Batch F1: 0.0
Epoch:  699        3 Batch loss: 0.213058 Batch F1: 0.0
Epoch:  699        4 Batch loss: 0.275755 Batch F1: 0.0
Epoch:  699        5 Batch loss: 0.243653 Batch F1: 0.0
Epoch:  699        6 Batch loss: 0.217574 Batch F1: 0.0
Epoch:  699        7 Batch loss: 0.240865 Batch F1: 0.0
Epoch:  699        8 Batch loss: 0.215749 Batch F1: 0.0
Epoch:  699        9 Batch loss: 0.217881 Batch F1: 0.0
Epoch:  699       10 Batch loss: 0.254974 Batch F1: 0.0
Epoch:  699       11 Batch loss: 0.220242 Batch F1: 0.0
Epoch:  699       12 Batch loss: 0.205372 Batch F1: 0.0
Train Avg Loss  699: 0.229146

Train Avg F1  699: 0.0

Val Avg Loss  699: 0.222878

Val Avg F1  699:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 700
--------------------------------------------------------------
Epoch:  700        1 Batch loss: 0.203492 Batch F1: 0.0
Epoch:  700        2 Batch loss: 0.217009 Batch F1: 0.0
Epoch:  700        3 Batch loss: 0.214590 Batch F1: 0.0
Epoch:  700        4 Batch loss: 0.217753 Batch F1: 0.0
Epoch:  700        5 Batch loss: 0.248168 Batch F1: 0.0
Epoch:  700        6 Batch loss: 0.247931 Batch F1: 0.0
Epoch:  700        7 Batch loss: 0.238867 Batch F1: 0.0
Epoch:  700        8 Batch loss: 0.219482 Batch F1: 0.0
Epoch:  700        9 Batch loss: 0.223134 Batch F1: 0.0
Epoch:  700       10 Batch loss: 0.227783 Batch F1: 0.0
Epoch:  700       11 Batch loss: 0.257329 Batch F1: 0.0
Epoch:  700       12 Batch loss: 0.228343 Batch F1: 0.0
Train Avg Loss  700: 0.228657

Train Avg F1  700: 0.0

Val Avg Loss  700: 0.222203

Val Avg F1  700:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 701
--------------------------------------------------------------
Epoch:  701        1 Batch loss: 0.223173 Batch F1: 0.0
Epoch:  701        2 Batch loss: 0.219124 Batch F1: 0.0
Epoch:  701        3 Batch loss: 0.245097 Batch F1: 0.0
Epoch:  701        4 Batch loss: 0.228541 Batch F1: 0.0
Epoch:  701        5 Batch loss: 0.214924 Batch F1: 0.0
Epoch:  701        6 Batch loss: 0.233780 Batch F1: 0.0
Epoch:  701        7 Batch loss: 0.236546 Batch F1: 0.0
Epoch:  701        8 Batch loss: 0.223591 Batch F1: 0.0
Epoch:  701        9 Batch loss: 0.249352 Batch F1: 0.0
Epoch:  701       10 Batch loss: 0.229067 Batch F1: 0.0
Epoch:  701       11 Batch loss: 0.214940 Batch F1: 0.0
Epoch:  701       12 Batch loss: 0.207454 Batch F1: 0.0
Train Avg Loss  701: 0.227132

Train Avg F1  701: 0.0

Val Avg Loss  701: 0.217901

Val Avg F1  701:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 702
--------------------------------------------------------------
Epoch:  702        1 Batch loss: 0.217400 Batch F1: 0.0
Epoch:  702        2 Batch loss: 0.228105 Batch F1: 0.0
Epoch:  702        3 Batch loss: 0.206345 Batch F1: 0.0
Epoch:  702        4 Batch loss: 0.226290 Batch F1: 0.0
Epoch:  702        5 Batch loss: 0.240785 Batch F1: 0.0
Epoch:  702        6 Batch loss: 0.226514 Batch F1: 0.0
Epoch:  702        7 Batch loss: 0.208080 Batch F1: 0.0
Epoch:  702        8 Batch loss: 0.219221 Batch F1: 0.0
Epoch:  702        9 Batch loss: 0.225645 Batch F1: 0.0
Epoch:  702       10 Batch loss: 0.211829 Batch F1: 0.0
Epoch:  702       11 Batch loss: 0.274385 Batch F1: 0.0
Epoch:  702       12 Batch loss: 0.238370 Batch F1: 0.0
Train Avg Loss  702: 0.226914

Train Avg F1  702: 0.0

Val Avg Loss  702: 0.217622

Val Avg F1  702:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 703
--------------------------------------------------------------
Epoch:  703        1 Batch loss: 0.223212 Batch F1: 0.0
Epoch:  703        2 Batch loss: 0.203316 Batch F1: 0.0
Epoch:  703        3 Batch loss: 0.224451 Batch F1: 0.0
Epoch:  703        4 Batch loss: 0.194278 Batch F1: 0.0
Epoch:  703        5 Batch loss: 0.210040 Batch F1: 0.0
Epoch:  703        6 Batch loss: 0.281707 Batch F1: 0.0
Epoch:  703        7 Batch loss: 0.217887 Batch F1: 0.0
Epoch:  703        8 Batch loss: 0.238496 Batch F1: 0.0
Epoch:  703        9 Batch loss: 0.240637 Batch F1: 0.0
Epoch:  703       10 Batch loss: 0.229436 Batch F1: 0.0
Epoch:  703       11 Batch loss: 0.236133 Batch F1: 0.0
Epoch:  703       12 Batch loss: 0.210160 Batch F1: 0.0
Train Avg Loss  703: 0.225813

Train Avg F1  703: 0.0

Val Avg Loss  703: 0.218337

Val Avg F1  703:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 704
--------------------------------------------------------------
Epoch:  704        1 Batch loss: 0.250319 Batch F1: 0.0
Epoch:  704        2 Batch loss: 0.235771 Batch F1: 0.0
Epoch:  704        3 Batch loss: 0.236310 Batch F1: 0.0
Epoch:  704        4 Batch loss: 0.215459 Batch F1: 0.0
Epoch:  704        5 Batch loss: 0.214029 Batch F1: 0.0
Epoch:  704        6 Batch loss: 0.223239 Batch F1: 0.0
Epoch:  704        7 Batch loss: 0.244805 Batch F1: 0.0
Epoch:  704        8 Batch loss: 0.207861 Batch F1: 0.0
Epoch:  704        9 Batch loss: 0.258236 Batch F1: 0.0
Epoch:  704       10 Batch loss: 0.216749 Batch F1: 0.0
Epoch:  704       11 Batch loss: 0.216325 Batch F1: 0.0
Epoch:  704       12 Batch loss: 0.187546 Batch F1: 0.0
Train Avg Loss  704: 0.225554

Train Avg F1  704: 0.0

Val Avg Loss  704: 0.218623

Val Avg F1  704:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 705
--------------------------------------------------------------
Epoch:  705        1 Batch loss: 0.192571 Batch F1: 0.0
Epoch:  705        2 Batch loss: 0.228222 Batch F1: 0.0
Epoch:  705        3 Batch loss: 0.215671 Batch F1: 0.0
Epoch:  705        4 Batch loss: 0.272602 Batch F1: 0.0
Epoch:  705        5 Batch loss: 0.220404 Batch F1: 0.0
Epoch:  705        6 Batch loss: 0.212949 Batch F1: 0.0
Epoch:  705        7 Batch loss: 0.214529 Batch F1: 0.0
Epoch:  705        8 Batch loss: 0.217852 Batch F1: 0.0
Epoch:  705        9 Batch loss: 0.239591 Batch F1: 0.0
Epoch:  705       10 Batch loss: 0.224608 Batch F1: 0.0
Epoch:  705       11 Batch loss: 0.260307 Batch F1: 0.0
Epoch:  705       12 Batch loss: 0.217351 Batch F1: 0.0
Train Avg Loss  705: 0.226388

Train Avg F1  705: 0.0

Val Avg Loss  705: 0.217417

Val Avg F1  705:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 706
--------------------------------------------------------------
Epoch:  706        1 Batch loss: 0.224909 Batch F1: 0.0
Epoch:  706        2 Batch loss: 0.198203 Batch F1: 0.0
Epoch:  706        3 Batch loss: 0.195425 Batch F1: 0.0
Epoch:  706        4 Batch loss: 0.210495 Batch F1: 0.0
Epoch:  706        5 Batch loss: 0.243982 Batch F1: 0.0
Epoch:  706        6 Batch loss: 0.225364 Batch F1: 0.0
Epoch:  706        7 Batch loss: 0.208935 Batch F1: 0.0
Epoch:  706        8 Batch loss: 0.230943 Batch F1: 0.0
Epoch:  706        9 Batch loss: 0.245997 Batch F1: 0.0
Epoch:  706       10 Batch loss: 0.255262 Batch F1: 0.0
Epoch:  706       11 Batch loss: 0.240576 Batch F1: 0.0
Epoch:  706       12 Batch loss: 0.229762 Batch F1: 0.0
Train Avg Loss  706: 0.225821

Train Avg F1  706: 0.0

Val Avg Loss  706: 0.217964

Val Avg F1  706:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 707
--------------------------------------------------------------
Epoch:  707        1 Batch loss: 0.215833 Batch F1: 0.0
Epoch:  707        2 Batch loss: 0.240079 Batch F1: 0.0
Epoch:  707        3 Batch loss: 0.231024 Batch F1: 0.0
Epoch:  707        4 Batch loss: 0.218656 Batch F1: 0.0
Epoch:  707        5 Batch loss: 0.214588 Batch F1: 0.0
Epoch:  707        6 Batch loss: 0.237649 Batch F1: 0.0
Epoch:  707        7 Batch loss: 0.217430 Batch F1: 0.0
Epoch:  707        8 Batch loss: 0.236377 Batch F1: 0.0
Epoch:  707        9 Batch loss: 0.216901 Batch F1: 0.0
Epoch:  707       10 Batch loss: 0.228708 Batch F1: 0.0
Epoch:  707       11 Batch loss: 0.214396 Batch F1: 0.0
Epoch:  707       12 Batch loss: 0.235714 Batch F1: 0.0
Train Avg Loss  707: 0.225613

Train Avg F1  707: 0.0

Val Avg Loss  707: 0.217512

Val Avg F1  707:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 708
--------------------------------------------------------------
Epoch:  708        1 Batch loss: 0.254870 Batch F1: 0.0
Epoch:  708        2 Batch loss: 0.187873 Batch F1: 0.0
Epoch:  708        3 Batch loss: 0.213343 Batch F1: 0.0
Epoch:  708        4 Batch loss: 0.250477 Batch F1: 0.0
Epoch:  708        5 Batch loss: 0.236645 Batch F1: 0.0
Epoch:  708        6 Batch loss: 0.202489 Batch F1: 0.0
Epoch:  708        7 Batch loss: 0.197749 Batch F1: 0.0
Epoch:  708        8 Batch loss: 0.226302 Batch F1: 0.0
Epoch:  708        9 Batch loss: 0.222320 Batch F1: 0.0
Epoch:  708       10 Batch loss: 0.256547 Batch F1: 0.0
Epoch:  708       11 Batch loss: 0.233020 Batch F1: 0.0
Epoch:  708       12 Batch loss: 0.227168 Batch F1: 0.0
Train Avg Loss  708: 0.225734

Train Avg F1  708: 0.0

Val Avg Loss  708: 0.217561

Val Avg F1  708:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 709
--------------------------------------------------------------
Epoch:  709        1 Batch loss: 0.183275 Batch F1: 0.0
Epoch:  709        2 Batch loss: 0.236281 Batch F1: 0.0
Epoch:  709        3 Batch loss: 0.235862 Batch F1: 0.0
Epoch:  709        4 Batch loss: 0.201012 Batch F1: 0.0
Epoch:  709        5 Batch loss: 0.249761 Batch F1: 0.0
Epoch:  709        6 Batch loss: 0.234515 Batch F1: 0.0
Epoch:  709        7 Batch loss: 0.251810 Batch F1: 0.0
Epoch:  709        8 Batch loss: 0.202110 Batch F1: 0.5714285714285714
Epoch:  709        9 Batch loss: 0.244958 Batch F1: 0.4
Epoch:  709       10 Batch loss: 0.229259 Batch F1: 0.1739130434782609
Epoch:  709       11 Batch loss: 0.215121 Batch F1: 0.0
Epoch:  709       12 Batch loss: 0.225698 Batch F1: 0.0
Train Avg Loss  709: 0.225805

Train Avg F1  709: 0.09544513457556936

Val Avg Loss  709: 0.217401

Val Avg F1  709:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 710
--------------------------------------------------------------
Epoch:  710        1 Batch loss: 0.240366 Batch F1: 0.0
Epoch:  710        2 Batch loss: 0.207276 Batch F1: 0.0
Epoch:  710        3 Batch loss: 0.253819 Batch F1: 0.0
Epoch:  710        4 Batch loss: 0.231984 Batch F1: 0.0
Epoch:  710        5 Batch loss: 0.267638 Batch F1: 0.0
Epoch:  710        6 Batch loss: 0.207355 Batch F1: 0.0
Epoch:  710        7 Batch loss: 0.201840 Batch F1: 0.0
Epoch:  710        8 Batch loss: 0.240364 Batch F1: 0.0
Epoch:  710        9 Batch loss: 0.183229 Batch F1: 0.0
Epoch:  710       10 Batch loss: 0.248085 Batch F1: 0.0
Epoch:  710       11 Batch loss: 0.232591 Batch F1: 0.0
Epoch:  710       12 Batch loss: 0.243032 Batch F1: 0.0
Train Avg Loss  710: 0.229798

Train Avg F1  710: 0.0

Val Avg Loss  710: 0.217963

Val Avg F1  710:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 711
--------------------------------------------------------------
Epoch:  711        1 Batch loss: 0.233953 Batch F1: 0.0
Epoch:  711        2 Batch loss: 0.240512 Batch F1: 0.0
Epoch:  711        3 Batch loss: 0.208187 Batch F1: 0.0
Epoch:  711        4 Batch loss: 0.222071 Batch F1: 0.0
Epoch:  711        5 Batch loss: 0.254993 Batch F1: 0.0
Epoch:  711        6 Batch loss: 0.230273 Batch F1: 0.0
Epoch:  711        7 Batch loss: 0.233688 Batch F1: 0.0
Epoch:  711        8 Batch loss: 0.211936 Batch F1: 0.0
Epoch:  711        9 Batch loss: 0.220936 Batch F1: 0.0
Epoch:  711       10 Batch loss: 0.226367 Batch F1: 0.0
Epoch:  711       11 Batch loss: 0.220954 Batch F1: 0.0
Epoch:  711       12 Batch loss: 0.216375 Batch F1: 0.0
Train Avg Loss  711: 0.226687

Train Avg F1  711: 0.0

Val Avg Loss  711: 0.217515

Val Avg F1  711:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 712
--------------------------------------------------------------
Epoch:  712        1 Batch loss: 0.253042 Batch F1: 0.0
Epoch:  712        2 Batch loss: 0.207240 Batch F1: 0.0
Epoch:  712        3 Batch loss: 0.223894 Batch F1: 0.0
Epoch:  712        4 Batch loss: 0.241009 Batch F1: 0.0
Epoch:  712        5 Batch loss: 0.208291 Batch F1: 0.0
Epoch:  712        6 Batch loss: 0.245119 Batch F1: 0.0
Epoch:  712        7 Batch loss: 0.209211 Batch F1: 0.0
Epoch:  712        8 Batch loss: 0.228550 Batch F1: 0.0
Epoch:  712        9 Batch loss: 0.209964 Batch F1: 0.0
Epoch:  712       10 Batch loss: 0.252162 Batch F1: 0.0
Epoch:  712       11 Batch loss: 0.222998 Batch F1: 0.0
Epoch:  712       12 Batch loss: 0.210669 Batch F1: 0.0
Train Avg Loss  712: 0.226013

Train Avg F1  712: 0.0

Val Avg Loss  712: 0.217250

Val Avg F1  712:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 713
--------------------------------------------------------------
Epoch:  713        1 Batch loss: 0.222780 Batch F1: 0.0
Epoch:  713        2 Batch loss: 0.215097 Batch F1: 0.0
Epoch:  713        3 Batch loss: 0.245754 Batch F1: 0.0
Epoch:  713        4 Batch loss: 0.230180 Batch F1: 0.0
Epoch:  713        5 Batch loss: 0.180251 Batch F1: 0.0
Epoch:  713        6 Batch loss: 0.260125 Batch F1: 0.0
Epoch:  713        7 Batch loss: 0.208906 Batch F1: 0.0
Epoch:  713        8 Batch loss: 0.200877 Batch F1: 0.0
Epoch:  713        9 Batch loss: 0.206076 Batch F1: 0.0
Epoch:  713       10 Batch loss: 0.278790 Batch F1: 0.0
Epoch:  713       11 Batch loss: 0.217978 Batch F1: 0.0
Epoch:  713       12 Batch loss: 0.244584 Batch F1: 0.0
Train Avg Loss  713: 0.225950

Train Avg F1  713: 0.0

Val Avg Loss  713: 0.218004

Val Avg F1  713:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 714
--------------------------------------------------------------
Epoch:  714        1 Batch loss: 0.245505 Batch F1: 0.0
Epoch:  714        2 Batch loss: 0.267506 Batch F1: 0.0
Epoch:  714        3 Batch loss: 0.230291 Batch F1: 0.29629629629629634
Epoch:  714        4 Batch loss: 0.213900 Batch F1: 0.18181818181818182
Epoch:  714        5 Batch loss: 0.242963 Batch F1: 0.0
Epoch:  714        6 Batch loss: 0.192248 Batch F1: 0.2105263157894737
Epoch:  714        7 Batch loss: 0.204955 Batch F1: 0.380952380952381
Epoch:  714        8 Batch loss: 0.223895 Batch F1: 0.0
Epoch:  714        9 Batch loss: 0.217368 Batch F1: 0.0
Epoch:  714       10 Batch loss: 0.221064 Batch F1: 0.0
Epoch:  714       11 Batch loss: 0.258522 Batch F1: 0.0
Epoch:  714       12 Batch loss: 0.201894 Batch F1: 0.0
Train Avg Loss  714: 0.226676

Train Avg F1  714: 0.08913276457136106

Val Avg Loss  714: 0.217704

Val Avg F1  714:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 715
--------------------------------------------------------------
Epoch:  715        1 Batch loss: 0.251142 Batch F1: 0.0
Epoch:  715        2 Batch loss: 0.214810 Batch F1: 0.0
Epoch:  715        3 Batch loss: 0.218076 Batch F1: 0.0
Epoch:  715        4 Batch loss: 0.212618 Batch F1: 0.0
Epoch:  715        5 Batch loss: 0.255174 Batch F1: 0.0
Epoch:  715        6 Batch loss: 0.226962 Batch F1: 0.0
Epoch:  715        7 Batch loss: 0.203019 Batch F1: 0.0
Epoch:  715        8 Batch loss: 0.228964 Batch F1: 0.0
Epoch:  715        9 Batch loss: 0.206710 Batch F1: 0.0
Epoch:  715       10 Batch loss: 0.239013 Batch F1: 0.0
Epoch:  715       11 Batch loss: 0.221327 Batch F1: 0.0
Epoch:  715       12 Batch loss: 0.246436 Batch F1: 0.0
Train Avg Loss  715: 0.227021

Train Avg F1  715: 0.0

Val Avg Loss  715: 0.216522

Val Avg F1  715:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 716
--------------------------------------------------------------
Epoch:  716        1 Batch loss: 0.237597 Batch F1: 0.0
Epoch:  716        2 Batch loss: 0.250655 Batch F1: 0.0
Epoch:  716        3 Batch loss: 0.232858 Batch F1: 0.0
Epoch:  716        4 Batch loss: 0.187350 Batch F1: 0.0
Epoch:  716        5 Batch loss: 0.200710 Batch F1: 0.0
Epoch:  716        6 Batch loss: 0.252781 Batch F1: 0.0
Epoch:  716        7 Batch loss: 0.236907 Batch F1: 0.0
Epoch:  716        8 Batch loss: 0.234371 Batch F1: 0.0
Epoch:  716        9 Batch loss: 0.243679 Batch F1: 0.0
Epoch:  716       10 Batch loss: 0.238233 Batch F1: 0.0
Epoch:  716       11 Batch loss: 0.210217 Batch F1: 0.0
Epoch:  716       12 Batch loss: 0.218300 Batch F1: 0.0
Train Avg Loss  716: 0.228638

Train Avg F1  716: 0.0

Val Avg Loss  716: 0.219236

Val Avg F1  716:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 717
--------------------------------------------------------------
Epoch:  717        1 Batch loss: 0.193279 Batch F1: 0.0
Epoch:  717        2 Batch loss: 0.237022 Batch F1: 0.0
Epoch:  717        3 Batch loss: 0.240497 Batch F1: 0.0
Epoch:  717        4 Batch loss: 0.224816 Batch F1: 0.0
Epoch:  717        5 Batch loss: 0.204489 Batch F1: 0.0
Epoch:  717        6 Batch loss: 0.244423 Batch F1: 0.0
Epoch:  717        7 Batch loss: 0.249433 Batch F1: 0.0
Epoch:  717        8 Batch loss: 0.226831 Batch F1: 0.0
Epoch:  717        9 Batch loss: 0.205338 Batch F1: 0.0
Epoch:  717       10 Batch loss: 0.237293 Batch F1: 0.0
Epoch:  717       11 Batch loss: 0.264450 Batch F1: 0.0
Epoch:  717       12 Batch loss: 0.208874 Batch F1: 0.0
Train Avg Loss  717: 0.228062

Train Avg F1  717: 0.0

Val Avg Loss  717: 0.221995

Val Avg F1  717:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 718
--------------------------------------------------------------
Epoch:  718        1 Batch loss: 0.250819 Batch F1: 0.0
Epoch:  718        2 Batch loss: 0.237800 Batch F1: 0.0
Epoch:  718        3 Batch loss: 0.245256 Batch F1: 0.0
Epoch:  718        4 Batch loss: 0.244912 Batch F1: 0.0
Epoch:  718        5 Batch loss: 0.236879 Batch F1: 0.2962962962962963
Epoch:  718        6 Batch loss: 0.216623 Batch F1: 0.0
Epoch:  718        7 Batch loss: 0.200406 Batch F1: 0.0
Epoch:  718        8 Batch loss: 0.206768 Batch F1: 0.0
Epoch:  718        9 Batch loss: 0.231224 Batch F1: 0.0
Epoch:  718       10 Batch loss: 0.230023 Batch F1: 0.0
Epoch:  718       11 Batch loss: 0.236198 Batch F1: 0.0
Epoch:  718       12 Batch loss: 0.223826 Batch F1: 0.0
Train Avg Loss  718: 0.230061

Train Avg F1  718: 0.024691358024691357

Val Avg Loss  718: 0.218599

Val Avg F1  718:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 719
--------------------------------------------------------------
Epoch:  719        1 Batch loss: 0.189970 Batch F1: 0.0
Epoch:  719        2 Batch loss: 0.240268 Batch F1: 0.0
Epoch:  719        3 Batch loss: 0.212762 Batch F1: 0.0
Epoch:  719        4 Batch loss: 0.262989 Batch F1: 0.08
Epoch:  719        5 Batch loss: 0.257601 Batch F1: 0.3
Epoch:  719        6 Batch loss: 0.222953 Batch F1: 0.5384615384615384
Epoch:  719        7 Batch loss: 0.236138 Batch F1: 0.27586206896551724
Epoch:  719        8 Batch loss: 0.238841 Batch F1: 0.08
Epoch:  719        9 Batch loss: 0.234418 Batch F1: 0.0
Epoch:  719       10 Batch loss: 0.211291 Batch F1: 0.0
Epoch:  719       11 Batch loss: 0.205732 Batch F1: 0.0
Epoch:  719       12 Batch loss: 0.235202 Batch F1: 0.0
Train Avg Loss  719: 0.229014

Train Avg F1  719: 0.10619363395225463

Val Avg Loss  719: 0.221694

Val Avg F1  719:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 720
--------------------------------------------------------------
Epoch:  720        1 Batch loss: 0.236635 Batch F1: 0.0
Epoch:  720        2 Batch loss: 0.248918 Batch F1: 0.0
Epoch:  720        3 Batch loss: 0.238289 Batch F1: 0.0
Epoch:  720        4 Batch loss: 0.261613 Batch F1: 0.0
Epoch:  720        5 Batch loss: 0.245787 Batch F1: 0.0
Epoch:  720        6 Batch loss: 0.249959 Batch F1: 0.0
Epoch:  720        7 Batch loss: 0.219162 Batch F1: 0.0
Epoch:  720        8 Batch loss: 0.232311 Batch F1: 0.0
Epoch:  720        9 Batch loss: 0.222181 Batch F1: 0.0
Epoch:  720       10 Batch loss: 0.216395 Batch F1: 0.0
Epoch:  720       11 Batch loss: 0.192411 Batch F1: 0.0
Epoch:  720       12 Batch loss: 0.255539 Batch F1: 0.0
Train Avg Loss  720: 0.234933

Train Avg F1  720: 0.0

Val Avg Loss  720: 0.222347

Val Avg F1  720:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 721
--------------------------------------------------------------
Epoch:  721        1 Batch loss: 0.203860 Batch F1: 0.0
Epoch:  721        2 Batch loss: 0.262495 Batch F1: 0.0
Epoch:  721        3 Batch loss: 0.197529 Batch F1: 0.0
Epoch:  721        4 Batch loss: 0.222908 Batch F1: 0.0
Epoch:  721        5 Batch loss: 0.238433 Batch F1: 0.0
Epoch:  721        6 Batch loss: 0.256263 Batch F1: 0.0
Epoch:  721        7 Batch loss: 0.233691 Batch F1: 0.0
Epoch:  721        8 Batch loss: 0.243148 Batch F1: 0.0
Epoch:  721        9 Batch loss: 0.226771 Batch F1: 0.0
Epoch:  721       10 Batch loss: 0.223985 Batch F1: 0.0
Epoch:  721       11 Batch loss: 0.233386 Batch F1: 0.0
Epoch:  721       12 Batch loss: 0.232268 Batch F1: 0.0
Train Avg Loss  721: 0.231228

Train Avg F1  721: 0.0

Val Avg Loss  721: 0.219998

Val Avg F1  721:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 722
--------------------------------------------------------------
Epoch:  722        1 Batch loss: 0.233102 Batch F1: 0.0
Epoch:  722        2 Batch loss: 0.254115 Batch F1: 0.0
Epoch:  722        3 Batch loss: 0.228457 Batch F1: 0.0
Epoch:  722        4 Batch loss: 0.268698 Batch F1: 0.0
Epoch:  722        5 Batch loss: 0.218265 Batch F1: 0.0
Epoch:  722        6 Batch loss: 0.222172 Batch F1: 0.0
Epoch:  722        7 Batch loss: 0.238866 Batch F1: 0.0
Epoch:  722        8 Batch loss: 0.224154 Batch F1: 0.0
Epoch:  722        9 Batch loss: 0.201353 Batch F1: 0.0
Epoch:  722       10 Batch loss: 0.199996 Batch F1: 0.0
Epoch:  722       11 Batch loss: 0.243357 Batch F1: 0.0
Epoch:  722       12 Batch loss: 0.227196 Batch F1: 0.0
Train Avg Loss  722: 0.229978

Train Avg F1  722: 0.0

Val Avg Loss  722: 0.218312

Val Avg F1  722:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 723
--------------------------------------------------------------
Epoch:  723        1 Batch loss: 0.200959 Batch F1: 0.0
Epoch:  723        2 Batch loss: 0.215269 Batch F1: 0.0
Epoch:  723        3 Batch loss: 0.250385 Batch F1: 0.0
Epoch:  723        4 Batch loss: 0.238160 Batch F1: 0.0
Epoch:  723        5 Batch loss: 0.191129 Batch F1: 0.0
Epoch:  723        6 Batch loss: 0.232077 Batch F1: 0.0
Epoch:  723        7 Batch loss: 0.253637 Batch F1: 0.0
Epoch:  723        8 Batch loss: 0.210854 Batch F1: 0.0
Epoch:  723        9 Batch loss: 0.231551 Batch F1: 0.0
Epoch:  723       10 Batch loss: 0.234615 Batch F1: 0.0
Epoch:  723       11 Batch loss: 0.227832 Batch F1: 0.0
Epoch:  723       12 Batch loss: 0.255563 Batch F1: 0.0
Train Avg Loss  723: 0.228503

Train Avg F1  723: 0.0

Val Avg Loss  723: 0.222461

Val Avg F1  723:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 724
--------------------------------------------------------------
Epoch:  724        1 Batch loss: 0.224351 Batch F1: 0.0
Epoch:  724        2 Batch loss: 0.243882 Batch F1: 0.0
Epoch:  724        3 Batch loss: 0.227751 Batch F1: 0.0
Epoch:  724        4 Batch loss: 0.247236 Batch F1: 0.0
Epoch:  724        5 Batch loss: 0.195677 Batch F1: 0.0
Epoch:  724        6 Batch loss: 0.227849 Batch F1: 0.0
Epoch:  724        7 Batch loss: 0.238770 Batch F1: 0.0
Epoch:  724        8 Batch loss: 0.251059 Batch F1: 0.0
Epoch:  724        9 Batch loss: 0.230306 Batch F1: 0.0
Epoch:  724       10 Batch loss: 0.213030 Batch F1: 0.0
Epoch:  724       11 Batch loss: 0.226379 Batch F1: 0.0
Epoch:  724       12 Batch loss: 0.223846 Batch F1: 0.0
Train Avg Loss  724: 0.229178

Train Avg F1  724: 0.0

Val Avg Loss  724: 0.217825

Val Avg F1  724:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 725
--------------------------------------------------------------
Epoch:  725        1 Batch loss: 0.250519 Batch F1: 0.0
Epoch:  725        2 Batch loss: 0.219452 Batch F1: 0.0
Epoch:  725        3 Batch loss: 0.204638 Batch F1: 0.0
Epoch:  725        4 Batch loss: 0.248781 Batch F1: 0.0
Epoch:  725        5 Batch loss: 0.218947 Batch F1: 0.0
Epoch:  725        6 Batch loss: 0.242910 Batch F1: 0.0
Epoch:  725        7 Batch loss: 0.223723 Batch F1: 0.0
Epoch:  725        8 Batch loss: 0.201813 Batch F1: 0.0
Epoch:  725        9 Batch loss: 0.240088 Batch F1: 0.0
Epoch:  725       10 Batch loss: 0.227128 Batch F1: 0.0
Epoch:  725       11 Batch loss: 0.237956 Batch F1: 0.0
Epoch:  725       12 Batch loss: 0.203052 Batch F1: 0.0
Train Avg Loss  725: 0.226584

Train Avg F1  725: 0.0

Val Avg Loss  725: 0.218004

Val Avg F1  725:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 726
--------------------------------------------------------------
Epoch:  726        1 Batch loss: 0.242771 Batch F1: 0.0
Epoch:  726        2 Batch loss: 0.225949 Batch F1: 0.0
Epoch:  726        3 Batch loss: 0.232379 Batch F1: 0.0
Epoch:  726        4 Batch loss: 0.257355 Batch F1: 0.0
Epoch:  726        5 Batch loss: 0.182673 Batch F1: 0.0
Epoch:  726        6 Batch loss: 0.245512 Batch F1: 0.0
Epoch:  726        7 Batch loss: 0.270763 Batch F1: 0.0
Epoch:  726        8 Batch loss: 0.241277 Batch F1: 0.0
Epoch:  726        9 Batch loss: 0.180212 Batch F1: 0.0
Epoch:  726       10 Batch loss: 0.223992 Batch F1: 0.0
Epoch:  726       11 Batch loss: 0.203395 Batch F1: 0.0
Epoch:  726       12 Batch loss: 0.212739 Batch F1: 0.0
Train Avg Loss  726: 0.226585

Train Avg F1  726: 0.0

Val Avg Loss  726: 0.218042

Val Avg F1  726:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 727
--------------------------------------------------------------
Epoch:  727        1 Batch loss: 0.232765 Batch F1: 0.0
Epoch:  727        2 Batch loss: 0.240086 Batch F1: 0.0
Epoch:  727        3 Batch loss: 0.262063 Batch F1: 0.0
Epoch:  727        4 Batch loss: 0.203820 Batch F1: 0.0
Epoch:  727        5 Batch loss: 0.231850 Batch F1: 0.0
Epoch:  727        6 Batch loss: 0.251238 Batch F1: 0.0
Epoch:  727        7 Batch loss: 0.260648 Batch F1: 0.0
Epoch:  727        8 Batch loss: 0.217505 Batch F1: 0.0
Epoch:  727        9 Batch loss: 0.195557 Batch F1: 0.0
Epoch:  727       10 Batch loss: 0.213717 Batch F1: 0.0
Epoch:  727       11 Batch loss: 0.193696 Batch F1: 0.0
Epoch:  727       12 Batch loss: 0.212403 Batch F1: 0.0
Train Avg Loss  727: 0.226279

Train Avg F1  727: 0.0

Val Avg Loss  727: 0.217915

Val Avg F1  727:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 728
--------------------------------------------------------------
Epoch:  728        1 Batch loss: 0.270529 Batch F1: 0.0
Epoch:  728        2 Batch loss: 0.225888 Batch F1: 0.0
Epoch:  728        3 Batch loss: 0.251053 Batch F1: 0.0
Epoch:  728        4 Batch loss: 0.207865 Batch F1: 0.0
Epoch:  728        5 Batch loss: 0.234408 Batch F1: 0.0
Epoch:  728        6 Batch loss: 0.208736 Batch F1: 0.0
Epoch:  728        7 Batch loss: 0.205501 Batch F1: 0.0
Epoch:  728        8 Batch loss: 0.236983 Batch F1: 0.0
Epoch:  728        9 Batch loss: 0.201960 Batch F1: 0.0
Epoch:  728       10 Batch loss: 0.242910 Batch F1: 0.0
Epoch:  728       11 Batch loss: 0.205962 Batch F1: 0.0
Epoch:  728       12 Batch loss: 0.223110 Batch F1: 0.0
Train Avg Loss  728: 0.226242

Train Avg F1  728: 0.0

Val Avg Loss  728: 0.217055

Val Avg F1  728:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 729
--------------------------------------------------------------
Epoch:  729        1 Batch loss: 0.226194 Batch F1: 0.0
Epoch:  729        2 Batch loss: 0.254089 Batch F1: 0.0
Epoch:  729        3 Batch loss: 0.202161 Batch F1: 0.0
Epoch:  729        4 Batch loss: 0.201736 Batch F1: 0.0
Epoch:  729        5 Batch loss: 0.217698 Batch F1: 0.0
Epoch:  729        6 Batch loss: 0.226129 Batch F1: 0.0
Epoch:  729        7 Batch loss: 0.234823 Batch F1: 0.0
Epoch:  729        8 Batch loss: 0.222288 Batch F1: 0.0
Epoch:  729        9 Batch loss: 0.252220 Batch F1: 0.0
Epoch:  729       10 Batch loss: 0.250980 Batch F1: 0.0
Epoch:  729       11 Batch loss: 0.203623 Batch F1: 0.0
Epoch:  729       12 Batch loss: 0.227636 Batch F1: 0.0
Train Avg Loss  729: 0.226632

Train Avg F1  729: 0.0

Val Avg Loss  729: 0.217346

Val Avg F1  729:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 730
--------------------------------------------------------------
Epoch:  730        1 Batch loss: 0.235208 Batch F1: 0.0
Epoch:  730        2 Batch loss: 0.248427 Batch F1: 0.0
Epoch:  730        3 Batch loss: 0.234355 Batch F1: 0.0
Epoch:  730        4 Batch loss: 0.210161 Batch F1: 0.0
Epoch:  730        5 Batch loss: 0.248157 Batch F1: 0.0
Epoch:  730        6 Batch loss: 0.201232 Batch F1: 0.0
Epoch:  730        7 Batch loss: 0.217317 Batch F1: 0.0
Epoch:  730        8 Batch loss: 0.230202 Batch F1: 0.0
Epoch:  730        9 Batch loss: 0.225162 Batch F1: 0.0
Epoch:  730       10 Batch loss: 0.246106 Batch F1: 0.0
Epoch:  730       11 Batch loss: 0.234549 Batch F1: 0.26666666666666666
Epoch:  730       12 Batch loss: 0.179721 Batch F1: 0.0
Train Avg Loss  730: 0.225883

Train Avg F1  730: 0.022222222222222223

Val Avg Loss  730: 0.216936

Val Avg F1  730:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 731
--------------------------------------------------------------
Epoch:  731        1 Batch loss: 0.218450 Batch F1: 0.0
Epoch:  731        2 Batch loss: 0.219720 Batch F1: 0.0
Epoch:  731        3 Batch loss: 0.202271 Batch F1: 0.0
Epoch:  731        4 Batch loss: 0.225408 Batch F1: 0.0
Epoch:  731        5 Batch loss: 0.218390 Batch F1: 0.0
Epoch:  731        6 Batch loss: 0.263482 Batch F1: 0.0
Epoch:  731        7 Batch loss: 0.222498 Batch F1: 0.0
Epoch:  731        8 Batch loss: 0.225235 Batch F1: 0.0
Epoch:  731        9 Batch loss: 0.231316 Batch F1: 0.0
Epoch:  731       10 Batch loss: 0.230970 Batch F1: 0.0
Epoch:  731       11 Batch loss: 0.234498 Batch F1: 0.0
Epoch:  731       12 Batch loss: 0.239461 Batch F1: 0.0
Train Avg Loss  731: 0.227642

Train Avg F1  731: 0.0

Val Avg Loss  731: 0.220142

Val Avg F1  731:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 732
--------------------------------------------------------------
Epoch:  732        1 Batch loss: 0.230818 Batch F1: 0.0
Epoch:  732        2 Batch loss: 0.222069 Batch F1: 0.0
Epoch:  732        3 Batch loss: 0.213781 Batch F1: 0.0
Epoch:  732        4 Batch loss: 0.214277 Batch F1: 0.0
Epoch:  732        5 Batch loss: 0.234778 Batch F1: 0.0
Epoch:  732        6 Batch loss: 0.240093 Batch F1: 0.0
Epoch:  732        7 Batch loss: 0.207373 Batch F1: 0.0
Epoch:  732        8 Batch loss: 0.229109 Batch F1: 0.0
Epoch:  732        9 Batch loss: 0.217016 Batch F1: 0.0
Epoch:  732       10 Batch loss: 0.246021 Batch F1: 0.0
Epoch:  732       11 Batch loss: 0.236907 Batch F1: 0.0
Epoch:  732       12 Batch loss: 0.245309 Batch F1: 0.0
Train Avg Loss  732: 0.228129

Train Avg F1  732: 0.0

Val Avg Loss  732: 0.218300

Val Avg F1  732:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 733
--------------------------------------------------------------
Epoch:  733        1 Batch loss: 0.239964 Batch F1: 0.0
Epoch:  733        2 Batch loss: 0.224883 Batch F1: 0.0
Epoch:  733        3 Batch loss: 0.242438 Batch F1: 0.0
Epoch:  733        4 Batch loss: 0.259158 Batch F1: 0.0
Epoch:  733        5 Batch loss: 0.229825 Batch F1: 0.23076923076923075
Epoch:  733        6 Batch loss: 0.219878 Batch F1: 0.5333333333333333
Epoch:  733        7 Batch loss: 0.229226 Batch F1: 0.32
Epoch:  733        8 Batch loss: 0.208639 Batch F1: 0.0
Epoch:  733        9 Batch loss: 0.232811 Batch F1: 0.0
Epoch:  733       10 Batch loss: 0.211147 Batch F1: 0.0
Epoch:  733       11 Batch loss: 0.220266 Batch F1: 0.0
Epoch:  733       12 Batch loss: 0.226057 Batch F1: 0.0
Train Avg Loss  733: 0.228691

Train Avg F1  733: 0.09034188034188034

Val Avg Loss  733: 0.218091

Val Avg F1  733:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 734
--------------------------------------------------------------
Epoch:  734        1 Batch loss: 0.232599 Batch F1: 0.0
Epoch:  734        2 Batch loss: 0.205770 Batch F1: 0.0
Epoch:  734        3 Batch loss: 0.222787 Batch F1: 0.0
Epoch:  734        4 Batch loss: 0.241713 Batch F1: 0.0
Epoch:  734        5 Batch loss: 0.237258 Batch F1: 0.0
Epoch:  734        6 Batch loss: 0.268596 Batch F1: 0.0
Epoch:  734        7 Batch loss: 0.203431 Batch F1: 0.0
Epoch:  734        8 Batch loss: 0.232367 Batch F1: 0.1818181818181818
Epoch:  734        9 Batch loss: 0.235429 Batch F1: 0.0
Epoch:  734       10 Batch loss: 0.232749 Batch F1: 0.0
Epoch:  734       11 Batch loss: 0.212945 Batch F1: 0.0
Epoch:  734       12 Batch loss: 0.228749 Batch F1: 0.0
Train Avg Loss  734: 0.229533

Train Avg F1  734: 0.01515151515151515

Val Avg Loss  734: 0.218423

Val Avg F1  734:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 735
--------------------------------------------------------------
Epoch:  735        1 Batch loss: 0.249691 Batch F1: 0.0
Epoch:  735        2 Batch loss: 0.203248 Batch F1: 0.0
Epoch:  735        3 Batch loss: 0.259011 Batch F1: 0.0
Epoch:  735        4 Batch loss: 0.191759 Batch F1: 0.0
Epoch:  735        5 Batch loss: 0.196276 Batch F1: 0.0
Epoch:  735        6 Batch loss: 0.238496 Batch F1: 0.0
Epoch:  735        7 Batch loss: 0.250628 Batch F1: 0.0
Epoch:  735        8 Batch loss: 0.204163 Batch F1: 0.0
Epoch:  735        9 Batch loss: 0.240770 Batch F1: 0.0
Epoch:  735       10 Batch loss: 0.202571 Batch F1: 0.0
Epoch:  735       11 Batch loss: 0.200337 Batch F1: 0.0
Epoch:  735       12 Batch loss: 0.305089 Batch F1: 0.0
Train Avg Loss  735: 0.228503

Train Avg F1  735: 0.0

Val Avg Loss  735: 0.217652

Val Avg F1  735:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 736
--------------------------------------------------------------
Epoch:  736        1 Batch loss: 0.204025 Batch F1: 0.0
Epoch:  736        2 Batch loss: 0.267579 Batch F1: 0.0
Epoch:  736        3 Batch loss: 0.259179 Batch F1: 0.0
Epoch:  736        4 Batch loss: 0.215122 Batch F1: 0.0
Epoch:  736        5 Batch loss: 0.246329 Batch F1: 0.0
Epoch:  736        6 Batch loss: 0.200970 Batch F1: 0.0
Epoch:  736        7 Batch loss: 0.248119 Batch F1: 0.0
Epoch:  736        8 Batch loss: 0.248692 Batch F1: 0.0
Epoch:  736        9 Batch loss: 0.217966 Batch F1: 0.0
Epoch:  736       10 Batch loss: 0.214733 Batch F1: 0.0
Epoch:  736       11 Batch loss: 0.201936 Batch F1: 0.0
Epoch:  736       12 Batch loss: 0.196570 Batch F1: 0.0
Train Avg Loss  736: 0.226768

Train Avg F1  736: 0.0

Val Avg Loss  736: 0.216871

Val Avg F1  736:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 737
--------------------------------------------------------------
Epoch:  737        1 Batch loss: 0.177560 Batch F1: 0.0
Epoch:  737        2 Batch loss: 0.208606 Batch F1: 0.0
Epoch:  737        3 Batch loss: 0.192438 Batch F1: 0.0
Epoch:  737        4 Batch loss: 0.249043 Batch F1: 0.0
Epoch:  737        5 Batch loss: 0.191806 Batch F1: 0.0
Epoch:  737        6 Batch loss: 0.267494 Batch F1: 0.0
Epoch:  737        7 Batch loss: 0.225914 Batch F1: 0.0
Epoch:  737        8 Batch loss: 0.258496 Batch F1: 0.0
Epoch:  737        9 Batch loss: 0.234233 Batch F1: 0.2727272727272727
Epoch:  737       10 Batch loss: 0.245387 Batch F1: 0.21428571428571427
Epoch:  737       11 Batch loss: 0.241223 Batch F1: 0.4242424242424242
Epoch:  737       12 Batch loss: 0.236081 Batch F1: 0.10526315789473685
Train Avg Loss  737: 0.227357

Train Avg F1  737: 0.08470988076251235

Val Avg Loss  737: 0.228513

Val Avg F1  737:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 738
--------------------------------------------------------------
Epoch:  738        1 Batch loss: 0.230248 Batch F1: 0.0
Epoch:  738        2 Batch loss: 0.233373 Batch F1: 0.0
Epoch:  738        3 Batch loss: 0.221257 Batch F1: 0.0
Epoch:  738        4 Batch loss: 0.222850 Batch F1: 0.0
Epoch:  738        5 Batch loss: 0.209724 Batch F1: 0.0
Epoch:  738        6 Batch loss: 0.259494 Batch F1: 0.0
Epoch:  738        7 Batch loss: 0.220405 Batch F1: 0.0
Epoch:  738        8 Batch loss: 0.240774 Batch F1: 0.0
Epoch:  738        9 Batch loss: 0.219377 Batch F1: 0.0
Epoch:  738       10 Batch loss: 0.217569 Batch F1: 0.0
Epoch:  738       11 Batch loss: 0.256247 Batch F1: 0.0
Epoch:  738       12 Batch loss: 0.218823 Batch F1: 0.0
Train Avg Loss  738: 0.229179

Train Avg F1  738: 0.0

Val Avg Loss  738: 0.219724

Val Avg F1  738:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 739
--------------------------------------------------------------
Epoch:  739        1 Batch loss: 0.258530 Batch F1: 0.0
Epoch:  739        2 Batch loss: 0.215705 Batch F1: 0.0
Epoch:  739        3 Batch loss: 0.226406 Batch F1: 0.3333333333333333
Epoch:  739        4 Batch loss: 0.243734 Batch F1: 0.20689655172413793
Epoch:  739        5 Batch loss: 0.238033 Batch F1: 0.4444444444444444
Epoch:  739        6 Batch loss: 0.217864 Batch F1: 0.4000000000000001
Epoch:  739        7 Batch loss: 0.225082 Batch F1: 0.0
Epoch:  739        8 Batch loss: 0.221151 Batch F1: 0.0
Epoch:  739        9 Batch loss: 0.226023 Batch F1: 0.0
Epoch:  739       10 Batch loss: 0.250322 Batch F1: 0.0
Epoch:  739       11 Batch loss: 0.217637 Batch F1: 0.0
Epoch:  739       12 Batch loss: 0.203079 Batch F1: 0.0
Train Avg Loss  739: 0.228631

Train Avg F1  739: 0.11538952745849297

Val Avg Loss  739: 0.217076

Val Avg F1  739:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 740
--------------------------------------------------------------
Epoch:  740        1 Batch loss: 0.196708 Batch F1: 0.0
Epoch:  740        2 Batch loss: 0.204927 Batch F1: 0.0
Epoch:  740        3 Batch loss: 0.188234 Batch F1: 0.0
Epoch:  740        4 Batch loss: 0.247794 Batch F1: 0.0
Epoch:  740        5 Batch loss: 0.264526 Batch F1: 0.0
Epoch:  740        6 Batch loss: 0.229753 Batch F1: 0.0
Epoch:  740        7 Batch loss: 0.235951 Batch F1: 0.0
Epoch:  740        8 Batch loss: 0.220686 Batch F1: 0.0
Epoch:  740        9 Batch loss: 0.238062 Batch F1: 0.0
Epoch:  740       10 Batch loss: 0.236587 Batch F1: 0.0
Epoch:  740       11 Batch loss: 0.236973 Batch F1: 0.0
Epoch:  740       12 Batch loss: 0.233756 Batch F1: 0.0
Train Avg Loss  740: 0.227830

Train Avg F1  740: 0.0

Val Avg Loss  740: 0.225818

Val Avg F1  740:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 741
--------------------------------------------------------------
Epoch:  741        1 Batch loss: 0.230284 Batch F1: 0.0
Epoch:  741        2 Batch loss: 0.238829 Batch F1: 0.0
Epoch:  741        3 Batch loss: 0.235306 Batch F1: 0.30303030303030304
Epoch:  741        4 Batch loss: 0.212247 Batch F1: 0.38095238095238093
Epoch:  741        5 Batch loss: 0.213899 Batch F1: 0.0
Epoch:  741        6 Batch loss: 0.224015 Batch F1: 0.0
Epoch:  741        7 Batch loss: 0.236552 Batch F1: 0.0
Epoch:  741        8 Batch loss: 0.212428 Batch F1: 0.0
Epoch:  741        9 Batch loss: 0.225916 Batch F1: 0.0
Epoch:  741       10 Batch loss: 0.250683 Batch F1: 0.0
Epoch:  741       11 Batch loss: 0.231350 Batch F1: 0.0
Epoch:  741       12 Batch loss: 0.229288 Batch F1: 0.0
Train Avg Loss  741: 0.228400

Train Avg F1  741: 0.05699855699855699

Val Avg Loss  741: 0.218854

Val Avg F1  741:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 742
--------------------------------------------------------------
Epoch:  742        1 Batch loss: 0.199901 Batch F1: 0.0
Epoch:  742        2 Batch loss: 0.196094 Batch F1: 0.0
Epoch:  742        3 Batch loss: 0.228470 Batch F1: 0.0
Epoch:  742        4 Batch loss: 0.260696 Batch F1: 0.0
Epoch:  742        5 Batch loss: 0.238073 Batch F1: 0.0
Epoch:  742        6 Batch loss: 0.210308 Batch F1: 0.0
Epoch:  742        7 Batch loss: 0.212993 Batch F1: 0.0
Epoch:  742        8 Batch loss: 0.223146 Batch F1: 0.0
Epoch:  742        9 Batch loss: 0.248884 Batch F1: 0.0
Epoch:  742       10 Batch loss: 0.214765 Batch F1: 0.0
Epoch:  742       11 Batch loss: 0.228615 Batch F1: 0.0
Epoch:  742       12 Batch loss: 0.276850 Batch F1: 0.0
Train Avg Loss  742: 0.228233

Train Avg F1  742: 0.0

Val Avg Loss  742: 0.219753

Val Avg F1  742:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 743
--------------------------------------------------------------
Epoch:  743        1 Batch loss: 0.251115 Batch F1: 0.0
Epoch:  743        2 Batch loss: 0.207075 Batch F1: 0.0
Epoch:  743        3 Batch loss: 0.227398 Batch F1: 0.1818181818181818
Epoch:  743        4 Batch loss: 0.226938 Batch F1: 0.31999999999999995
Epoch:  743        5 Batch loss: 0.234412 Batch F1: 0.42857142857142855
Epoch:  743        6 Batch loss: 0.219897 Batch F1: 0.46153846153846156
Epoch:  743        7 Batch loss: 0.248149 Batch F1: 0.41379310344827586
Epoch:  743        8 Batch loss: 0.210137 Batch F1: 0.3
Epoch:  743        9 Batch loss: 0.229320 Batch F1: 0.0
Epoch:  743       10 Batch loss: 0.201393 Batch F1: 0.0
Epoch:  743       11 Batch loss: 0.248101 Batch F1: 0.0
Epoch:  743       12 Batch loss: 0.218570 Batch F1: 0.0
Train Avg Loss  743: 0.226875

Train Avg F1  743: 0.17547676461469564

Val Avg Loss  743: 0.217248

Val Avg F1  743:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 744
--------------------------------------------------------------
Epoch:  744        1 Batch loss: 0.265142 Batch F1: 0.0
Epoch:  744        2 Batch loss: 0.246531 Batch F1: 0.0
Epoch:  744        3 Batch loss: 0.225200 Batch F1: 0.0
Epoch:  744        4 Batch loss: 0.245490 Batch F1: 0.0
Epoch:  744        5 Batch loss: 0.248944 Batch F1: 0.0
Epoch:  744        6 Batch loss: 0.238397 Batch F1: 0.0
Epoch:  744        7 Batch loss: 0.248206 Batch F1: 0.0
Epoch:  744        8 Batch loss: 0.220985 Batch F1: 0.33333333333333337
Epoch:  744        9 Batch loss: 0.217910 Batch F1: 0.2857142857142857
Epoch:  744       10 Batch loss: 0.211934 Batch F1: 0.0
Epoch:  744       11 Batch loss: 0.205307 Batch F1: 0.0
Epoch:  744       12 Batch loss: 0.181461 Batch F1: 0.0
Train Avg Loss  744: 0.229626

Train Avg F1  744: 0.05158730158730159

Val Avg Loss  744: 0.216886

Val Avg F1  744:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 745
--------------------------------------------------------------
Epoch:  745        1 Batch loss: 0.208187 Batch F1: 0.0
Epoch:  745        2 Batch loss: 0.240433 Batch F1: 0.0
Epoch:  745        3 Batch loss: 0.286384 Batch F1: 0.0
Epoch:  745        4 Batch loss: 0.252188 Batch F1: 0.0
Epoch:  745        5 Batch loss: 0.243917 Batch F1: 0.0
Epoch:  745        6 Batch loss: 0.234799 Batch F1: 0.0
Epoch:  745        7 Batch loss: 0.232007 Batch F1: 0.28571428571428575
Epoch:  745        8 Batch loss: 0.222043 Batch F1: 0.0
Epoch:  745        9 Batch loss: 0.222380 Batch F1: 0.0
Epoch:  745       10 Batch loss: 0.247410 Batch F1: 0.0
Epoch:  745       11 Batch loss: 0.231741 Batch F1: 0.0
Epoch:  745       12 Batch loss: 0.185739 Batch F1: 0.0
Train Avg Loss  745: 0.233936

Train Avg F1  745: 0.02380952380952381

Val Avg Loss  745: 0.218668

Val Avg F1  745:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 746
--------------------------------------------------------------
Epoch:  746        1 Batch loss: 0.215385 Batch F1: 0.0
Epoch:  746        2 Batch loss: 0.230303 Batch F1: 0.0
Epoch:  746        3 Batch loss: 0.227543 Batch F1: 0.0
Epoch:  746        4 Batch loss: 0.216286 Batch F1: 0.0
Epoch:  746        5 Batch loss: 0.252238 Batch F1: 0.0
Epoch:  746        6 Batch loss: 0.244676 Batch F1: 0.0
Epoch:  746        7 Batch loss: 0.246958 Batch F1: 0.0
Epoch:  746        8 Batch loss: 0.219726 Batch F1: 0.0
Epoch:  746        9 Batch loss: 0.244454 Batch F1: 0.0
Epoch:  746       10 Batch loss: 0.214722 Batch F1: 0.0
Epoch:  746       11 Batch loss: 0.232277 Batch F1: 0.0
Epoch:  746       12 Batch loss: 0.215036 Batch F1: 0.0
Train Avg Loss  746: 0.229967

Train Avg F1  746: 0.0

Val Avg Loss  746: 0.221009

Val Avg F1  746:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 747
--------------------------------------------------------------
Epoch:  747        1 Batch loss: 0.227657 Batch F1: 0.0
Epoch:  747        2 Batch loss: 0.254457 Batch F1: 0.0
Epoch:  747        3 Batch loss: 0.242433 Batch F1: 0.0
Epoch:  747        4 Batch loss: 0.238333 Batch F1: 0.0
Epoch:  747        5 Batch loss: 0.251997 Batch F1: 0.0
Epoch:  747        6 Batch loss: 0.228763 Batch F1: 0.0
Epoch:  747        7 Batch loss: 0.203414 Batch F1: 0.0
Epoch:  747        8 Batch loss: 0.196307 Batch F1: 0.0
Epoch:  747        9 Batch loss: 0.224983 Batch F1: 0.0
Epoch:  747       10 Batch loss: 0.233687 Batch F1: 0.0
Epoch:  747       11 Batch loss: 0.231797 Batch F1: 0.0
Epoch:  747       12 Batch loss: 0.209066 Batch F1: 0.0
Train Avg Loss  747: 0.228575

Train Avg F1  747: 0.0

Val Avg Loss  747: 0.217257

Val Avg F1  747:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 748
--------------------------------------------------------------
Epoch:  748        1 Batch loss: 0.237627 Batch F1: 0.0
Epoch:  748        2 Batch loss: 0.198754 Batch F1: 0.0
Epoch:  748        3 Batch loss: 0.209841 Batch F1: 0.0
Epoch:  748        4 Batch loss: 0.193188 Batch F1: 0.0
Epoch:  748        5 Batch loss: 0.213182 Batch F1: 0.0
Epoch:  748        6 Batch loss: 0.239427 Batch F1: 0.0
Epoch:  748        7 Batch loss: 0.292628 Batch F1: 0.0
Epoch:  748        8 Batch loss: 0.243415 Batch F1: 0.0
Epoch:  748        9 Batch loss: 0.238802 Batch F1: 0.0
Epoch:  748       10 Batch loss: 0.202442 Batch F1: 0.0
Epoch:  748       11 Batch loss: 0.244982 Batch F1: 0.0
Epoch:  748       12 Batch loss: 0.217382 Batch F1: 0.0
Train Avg Loss  748: 0.227639

Train Avg F1  748: 0.0

Val Avg Loss  748: 0.220841

Val Avg F1  748:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 749
--------------------------------------------------------------
Epoch:  749        1 Batch loss: 0.214321 Batch F1: 0.0
Epoch:  749        2 Batch loss: 0.258357 Batch F1: 0.0
Epoch:  749        3 Batch loss: 0.211170 Batch F1: 0.0
Epoch:  749        4 Batch loss: 0.247526 Batch F1: 0.0
Epoch:  749        5 Batch loss: 0.223638 Batch F1: 0.0
Epoch:  749        6 Batch loss: 0.243348 Batch F1: 0.0
Epoch:  749        7 Batch loss: 0.249183 Batch F1: 0.0
Epoch:  749        8 Batch loss: 0.216331 Batch F1: 0.0
Epoch:  749        9 Batch loss: 0.217167 Batch F1: 0.0
Epoch:  749       10 Batch loss: 0.247070 Batch F1: 0.0
Epoch:  749       11 Batch loss: 0.192481 Batch F1: 0.0
Epoch:  749       12 Batch loss: 0.197170 Batch F1: 0.0
Train Avg Loss  749: 0.226480

Train Avg F1  749: 0.0

Val Avg Loss  749: 0.217143

Val Avg F1  749:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 750
--------------------------------------------------------------
Epoch:  750        1 Batch loss: 0.239172 Batch F1: 0.0
Epoch:  750        2 Batch loss: 0.205076 Batch F1: 0.0
Epoch:  750        3 Batch loss: 0.224695 Batch F1: 0.0
Epoch:  750        4 Batch loss: 0.273085 Batch F1: 0.0
Epoch:  750        5 Batch loss: 0.234516 Batch F1: 0.0
Epoch:  750        6 Batch loss: 0.228167 Batch F1: 0.0
Epoch:  750        7 Batch loss: 0.238072 Batch F1: 0.0
Epoch:  750        8 Batch loss: 0.217367 Batch F1: 0.0
Epoch:  750        9 Batch loss: 0.243995 Batch F1: 0.0
Epoch:  750       10 Batch loss: 0.198341 Batch F1: 0.0
Epoch:  750       11 Batch loss: 0.242966 Batch F1: 0.0
Epoch:  750       12 Batch loss: 0.201280 Batch F1: 0.0
Train Avg Loss  750: 0.228894

Train Avg F1  750: 0.0

Val Avg Loss  750: 0.219773

Val Avg F1  750:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 751
--------------------------------------------------------------
Epoch:  751        1 Batch loss: 0.234004 Batch F1: 0.0
Epoch:  751        2 Batch loss: 0.220868 Batch F1: 0.0
Epoch:  751        3 Batch loss: 0.213416 Batch F1: 0.0
Epoch:  751        4 Batch loss: 0.214460 Batch F1: 0.0
Epoch:  751        5 Batch loss: 0.237902 Batch F1: 0.0
Epoch:  751        6 Batch loss: 0.280569 Batch F1: 0.0
Epoch:  751        7 Batch loss: 0.223764 Batch F1: 0.0
Epoch:  751        8 Batch loss: 0.216759 Batch F1: 0.0
Epoch:  751        9 Batch loss: 0.218088 Batch F1: 0.0
Epoch:  751       10 Batch loss: 0.236641 Batch F1: 0.0
Epoch:  751       11 Batch loss: 0.222392 Batch F1: 0.0
Epoch:  751       12 Batch loss: 0.246242 Batch F1: 0.0
Train Avg Loss  751: 0.230425

Train Avg F1  751: 0.0

Val Avg Loss  751: 0.218268

Val Avg F1  751:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 752
--------------------------------------------------------------
Epoch:  752        1 Batch loss: 0.208029 Batch F1: 0.0
Epoch:  752        2 Batch loss: 0.238507 Batch F1: 0.0
Epoch:  752        3 Batch loss: 0.224571 Batch F1: 0.0
Epoch:  752        4 Batch loss: 0.230654 Batch F1: 0.0
Epoch:  752        5 Batch loss: 0.226252 Batch F1: 0.0
Epoch:  752        6 Batch loss: 0.181280 Batch F1: 0.0
Epoch:  752        7 Batch loss: 0.250223 Batch F1: 0.0
Epoch:  752        8 Batch loss: 0.231880 Batch F1: 0.0
Epoch:  752        9 Batch loss: 0.215763 Batch F1: 0.0
Epoch:  752       10 Batch loss: 0.243249 Batch F1: 0.0
Epoch:  752       11 Batch loss: 0.232653 Batch F1: 0.0
Epoch:  752       12 Batch loss: 0.244122 Batch F1: 0.0
Train Avg Loss  752: 0.227265

Train Avg F1  752: 0.0

Val Avg Loss  752: 0.221307

Val Avg F1  752:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 753
--------------------------------------------------------------
Epoch:  753        1 Batch loss: 0.243783 Batch F1: 0.0
Epoch:  753        2 Batch loss: 0.236408 Batch F1: 0.16
Epoch:  753        3 Batch loss: 0.221144 Batch F1: 0.2857142857142857
Epoch:  753        4 Batch loss: 0.241246 Batch F1: 0.0
Epoch:  753        5 Batch loss: 0.218190 Batch F1: 0.0
Epoch:  753        6 Batch loss: 0.244923 Batch F1: 0.0
Epoch:  753        7 Batch loss: 0.227973 Batch F1: 0.0
Epoch:  753        8 Batch loss: 0.236726 Batch F1: 0.0
Epoch:  753        9 Batch loss: 0.200425 Batch F1: 0.0
Epoch:  753       10 Batch loss: 0.205679 Batch F1: 0.0
Epoch:  753       11 Batch loss: 0.232011 Batch F1: 0.0
Epoch:  753       12 Batch loss: 0.221695 Batch F1: 0.0
Train Avg Loss  753: 0.227517

Train Avg F1  753: 0.037142857142857144

Val Avg Loss  753: 0.217983

Val Avg F1  753:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 754
--------------------------------------------------------------
Epoch:  754        1 Batch loss: 0.201987 Batch F1: 0.0
Epoch:  754        2 Batch loss: 0.272920 Batch F1: 0.0
Epoch:  754        3 Batch loss: 0.221695 Batch F1: 0.0
Epoch:  754        4 Batch loss: 0.207650 Batch F1: 0.0
Epoch:  754        5 Batch loss: 0.234921 Batch F1: 0.0
Epoch:  754        6 Batch loss: 0.223950 Batch F1: 0.0
Epoch:  754        7 Batch loss: 0.215736 Batch F1: 0.0
Epoch:  754        8 Batch loss: 0.229278 Batch F1: 0.0
Epoch:  754        9 Batch loss: 0.223182 Batch F1: 0.0
Epoch:  754       10 Batch loss: 0.225648 Batch F1: 0.0
Epoch:  754       11 Batch loss: 0.227007 Batch F1: 0.0
Epoch:  754       12 Batch loss: 0.238622 Batch F1: 0.0
Train Avg Loss  754: 0.226883

Train Avg F1  754: 0.0

Val Avg Loss  754: 0.217369

Val Avg F1  754:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 755
--------------------------------------------------------------
Epoch:  755        1 Batch loss: 0.257262 Batch F1: 0.0
Epoch:  755        2 Batch loss: 0.202659 Batch F1: 0.0
Epoch:  755        3 Batch loss: 0.213878 Batch F1: 0.0
Epoch:  755        4 Batch loss: 0.251662 Batch F1: 0.0
Epoch:  755        5 Batch loss: 0.229730 Batch F1: 0.0
Epoch:  755        6 Batch loss: 0.192531 Batch F1: 0.0
Epoch:  755        7 Batch loss: 0.249244 Batch F1: 0.0
Epoch:  755        8 Batch loss: 0.225879 Batch F1: 0.0
Epoch:  755        9 Batch loss: 0.225433 Batch F1: 0.0
Epoch:  755       10 Batch loss: 0.228545 Batch F1: 0.0
Epoch:  755       11 Batch loss: 0.222157 Batch F1: 0.0
Epoch:  755       12 Batch loss: 0.218176 Batch F1: 0.0
Train Avg Loss  755: 0.226430

Train Avg F1  755: 0.0

Val Avg Loss  755: 0.217444

Val Avg F1  755:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 756
--------------------------------------------------------------
Epoch:  756        1 Batch loss: 0.213059 Batch F1: 0.0
Epoch:  756        2 Batch loss: 0.275970 Batch F1: 0.0
Epoch:  756        3 Batch loss: 0.202587 Batch F1: 0.0
Epoch:  756        4 Batch loss: 0.222227 Batch F1: 0.0
Epoch:  756        5 Batch loss: 0.232423 Batch F1: 0.0
Epoch:  756        6 Batch loss: 0.204523 Batch F1: 0.0
Epoch:  756        7 Batch loss: 0.274532 Batch F1: 0.0
Epoch:  756        8 Batch loss: 0.188292 Batch F1: 0.0
Epoch:  756        9 Batch loss: 0.202518 Batch F1: 0.0
Epoch:  756       10 Batch loss: 0.240820 Batch F1: 0.0
Epoch:  756       11 Batch loss: 0.218251 Batch F1: 0.0
Epoch:  756       12 Batch loss: 0.241511 Batch F1: 0.0
Train Avg Loss  756: 0.226393

Train Avg F1  756: 0.0

Val Avg Loss  756: 0.217266

Val Avg F1  756:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 757
--------------------------------------------------------------
Epoch:  757        1 Batch loss: 0.230043 Batch F1: 0.0
Epoch:  757        2 Batch loss: 0.238290 Batch F1: 0.0
Epoch:  757        3 Batch loss: 0.243477 Batch F1: 0.0
Epoch:  757        4 Batch loss: 0.234721 Batch F1: 0.0
Epoch:  757        5 Batch loss: 0.219050 Batch F1: 0.25
Epoch:  757        6 Batch loss: 0.209175 Batch F1: 0.0
Epoch:  757        7 Batch loss: 0.219585 Batch F1: 0.0
Epoch:  757        8 Batch loss: 0.240282 Batch F1: 0.0
Epoch:  757        9 Batch loss: 0.196137 Batch F1: 0.0
Epoch:  757       10 Batch loss: 0.229374 Batch F1: 0.0
Epoch:  757       11 Batch loss: 0.239474 Batch F1: 0.0
Epoch:  757       12 Batch loss: 0.225096 Batch F1: 0.0
Train Avg Loss  757: 0.227059

Train Avg F1  757: 0.020833333333333332

Val Avg Loss  757: 0.217153

Val Avg F1  757:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 758
--------------------------------------------------------------
Epoch:  758        1 Batch loss: 0.215293 Batch F1: 0.0
Epoch:  758        2 Batch loss: 0.246271 Batch F1: 0.0
Epoch:  758        3 Batch loss: 0.249781 Batch F1: 0.0
Epoch:  758        4 Batch loss: 0.208802 Batch F1: 0.0
Epoch:  758        5 Batch loss: 0.225588 Batch F1: 0.0
Epoch:  758        6 Batch loss: 0.227141 Batch F1: 0.0
Epoch:  758        7 Batch loss: 0.232732 Batch F1: 0.0
Epoch:  758        8 Batch loss: 0.185119 Batch F1: 0.0
Epoch:  758        9 Batch loss: 0.262929 Batch F1: 0.0
Epoch:  758       10 Batch loss: 0.212688 Batch F1: 0.0
Epoch:  758       11 Batch loss: 0.241165 Batch F1: 0.0
Epoch:  758       12 Batch loss: 0.222510 Batch F1: 0.0
Train Avg Loss  758: 0.227502

Train Avg F1  758: 0.0

Val Avg Loss  758: 0.218387

Val Avg F1  758:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 759
--------------------------------------------------------------
Epoch:  759        1 Batch loss: 0.256516 Batch F1: 0.0
Epoch:  759        2 Batch loss: 0.221710 Batch F1: 0.0
Epoch:  759        3 Batch loss: 0.198434 Batch F1: 0.0
Epoch:  759        4 Batch loss: 0.225169 Batch F1: 0.0
Epoch:  759        5 Batch loss: 0.220977 Batch F1: 0.0
Epoch:  759        6 Batch loss: 0.236841 Batch F1: 0.0
Epoch:  759        7 Batch loss: 0.230990 Batch F1: 0.0
Epoch:  759        8 Batch loss: 0.234579 Batch F1: 0.0
Epoch:  759        9 Batch loss: 0.214167 Batch F1: 0.0
Epoch:  759       10 Batch loss: 0.234537 Batch F1: 0.0
Epoch:  759       11 Batch loss: 0.262398 Batch F1: 0.0
Epoch:  759       12 Batch loss: 0.182495 Batch F1: 0.0
Train Avg Loss  759: 0.226568

Train Avg F1  759: 0.0

Val Avg Loss  759: 0.218637

Val Avg F1  759:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 760
--------------------------------------------------------------
Epoch:  760        1 Batch loss: 0.216248 Batch F1: 0.0
Epoch:  760        2 Batch loss: 0.224066 Batch F1: 0.0
Epoch:  760        3 Batch loss: 0.199946 Batch F1: 0.0
Epoch:  760        4 Batch loss: 0.210546 Batch F1: 0.0
Epoch:  760        5 Batch loss: 0.226171 Batch F1: 0.0
Epoch:  760        6 Batch loss: 0.219060 Batch F1: 0.0
Epoch:  760        7 Batch loss: 0.235074 Batch F1: 0.0
Epoch:  760        8 Batch loss: 0.226562 Batch F1: 0.0
Epoch:  760        9 Batch loss: 0.225304 Batch F1: 0.0
Epoch:  760       10 Batch loss: 0.234242 Batch F1: 0.0
Epoch:  760       11 Batch loss: 0.276684 Batch F1: 0.0
Epoch:  760       12 Batch loss: 0.228440 Batch F1: 0.0
Train Avg Loss  760: 0.226862

Train Avg F1  760: 0.0

Val Avg Loss  760: 0.218876

Val Avg F1  760:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 761
--------------------------------------------------------------
Epoch:  761        1 Batch loss: 0.251444 Batch F1: 0.0
Epoch:  761        2 Batch loss: 0.226542 Batch F1: 0.0
Epoch:  761        3 Batch loss: 0.209257 Batch F1: 0.0
Epoch:  761        4 Batch loss: 0.228940 Batch F1: 0.0
Epoch:  761        5 Batch loss: 0.228480 Batch F1: 0.0
Epoch:  761        6 Batch loss: 0.188096 Batch F1: 0.0
Epoch:  761        7 Batch loss: 0.267023 Batch F1: 0.0
Epoch:  761        8 Batch loss: 0.186635 Batch F1: 0.0
Epoch:  761        9 Batch loss: 0.245489 Batch F1: 0.0
Epoch:  761       10 Batch loss: 0.257151 Batch F1: 0.0
Epoch:  761       11 Batch loss: 0.233901 Batch F1: 0.0
Epoch:  761       12 Batch loss: 0.217200 Batch F1: 0.0
Train Avg Loss  761: 0.228346

Train Avg F1  761: 0.0

Val Avg Loss  761: 0.219959

Val Avg F1  761:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 762
--------------------------------------------------------------
Epoch:  762        1 Batch loss: 0.260777 Batch F1: 0.0
Epoch:  762        2 Batch loss: 0.212272 Batch F1: 0.0
Epoch:  762        3 Batch loss: 0.237952 Batch F1: 0.3333333333333333
Epoch:  762        4 Batch loss: 0.242176 Batch F1: 0.31249999999999994
Epoch:  762        5 Batch loss: 0.227991 Batch F1: 0.0
Epoch:  762        6 Batch loss: 0.225710 Batch F1: 0.0
Epoch:  762        7 Batch loss: 0.194147 Batch F1: 0.0
Epoch:  762        8 Batch loss: 0.283781 Batch F1: 0.0
Epoch:  762        9 Batch loss: 0.208313 Batch F1: 0.0
Epoch:  762       10 Batch loss: 0.221212 Batch F1: 0.0
Epoch:  762       11 Batch loss: 0.210437 Batch F1: 0.0
Epoch:  762       12 Batch loss: 0.189209 Batch F1: 0.0
Train Avg Loss  762: 0.226165

Train Avg F1  762: 0.05381944444444444

Val Avg Loss  762: 0.217241

Val Avg F1  762:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 763
--------------------------------------------------------------
Epoch:  763        1 Batch loss: 0.218235 Batch F1: 0.0
Epoch:  763        2 Batch loss: 0.242819 Batch F1: 0.0
Epoch:  763        3 Batch loss: 0.228894 Batch F1: 0.0
Epoch:  763        4 Batch loss: 0.202347 Batch F1: 0.0
Epoch:  763        5 Batch loss: 0.242510 Batch F1: 0.0
Epoch:  763        6 Batch loss: 0.213395 Batch F1: 0.0
Epoch:  763        7 Batch loss: 0.234736 Batch F1: 0.0
Epoch:  763        8 Batch loss: 0.227833 Batch F1: 0.0
Epoch:  763        9 Batch loss: 0.236551 Batch F1: 0.0
Epoch:  763       10 Batch loss: 0.223469 Batch F1: 0.1
Epoch:  763       11 Batch loss: 0.217532 Batch F1: 0.0
Epoch:  763       12 Batch loss: 0.233904 Batch F1: 0.0
Train Avg Loss  763: 0.226852

Train Avg F1  763: 0.008333333333333333

Val Avg Loss  763: 0.217190

Val Avg F1  763:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 764
--------------------------------------------------------------
Epoch:  764        1 Batch loss: 0.225902 Batch F1: 0.0
Epoch:  764        2 Batch loss: 0.244710 Batch F1: 0.0
Epoch:  764        3 Batch loss: 0.201278 Batch F1: 0.0
Epoch:  764        4 Batch loss: 0.233876 Batch F1: 0.0
Epoch:  764        5 Batch loss: 0.238486 Batch F1: 0.0
Epoch:  764        6 Batch loss: 0.239521 Batch F1: 0.0
Epoch:  764        7 Batch loss: 0.199328 Batch F1: 0.0
Epoch:  764        8 Batch loss: 0.232311 Batch F1: 0.0
Epoch:  764        9 Batch loss: 0.224934 Batch F1: 0.0
Epoch:  764       10 Batch loss: 0.233933 Batch F1: 0.0
Epoch:  764       11 Batch loss: 0.214924 Batch F1: 0.0
Epoch:  764       12 Batch loss: 0.227464 Batch F1: 0.0
Train Avg Loss  764: 0.226389

Train Avg F1  764: 0.0

Val Avg Loss  764: 0.218962

Val Avg F1  764:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 765
--------------------------------------------------------------
Epoch:  765        1 Batch loss: 0.215194 Batch F1: 0.0
Epoch:  765        2 Batch loss: 0.205506 Batch F1: 0.0
Epoch:  765        3 Batch loss: 0.250592 Batch F1: 0.0
Epoch:  765        4 Batch loss: 0.244099 Batch F1: 0.0
Epoch:  765        5 Batch loss: 0.213738 Batch F1: 0.0
Epoch:  765        6 Batch loss: 0.181832 Batch F1: 0.0
Epoch:  765        7 Batch loss: 0.271315 Batch F1: 0.0
Epoch:  765        8 Batch loss: 0.204047 Batch F1: 0.0
Epoch:  765        9 Batch loss: 0.219372 Batch F1: 0.0
Epoch:  765       10 Batch loss: 0.245977 Batch F1: 0.0
Epoch:  765       11 Batch loss: 0.226933 Batch F1: 0.0
Epoch:  765       12 Batch loss: 0.236658 Batch F1: 0.0
Train Avg Loss  765: 0.226272

Train Avg F1  765: 0.0

Val Avg Loss  765: 0.216891

Val Avg F1  765:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 766
--------------------------------------------------------------
Epoch:  766        1 Batch loss: 0.230883 Batch F1: 0.0
Epoch:  766        2 Batch loss: 0.230785 Batch F1: 0.0
Epoch:  766        3 Batch loss: 0.238489 Batch F1: 0.0
Epoch:  766        4 Batch loss: 0.241302 Batch F1: 0.0
Epoch:  766        5 Batch loss: 0.240097 Batch F1: 0.0
Epoch:  766        6 Batch loss: 0.196298 Batch F1: 0.0
Epoch:  766        7 Batch loss: 0.223066 Batch F1: 0.0
Epoch:  766        8 Batch loss: 0.196448 Batch F1: 0.0
Epoch:  766        9 Batch loss: 0.232810 Batch F1: 0.0
Epoch:  766       10 Batch loss: 0.223471 Batch F1: 0.0
Epoch:  766       11 Batch loss: 0.249500 Batch F1: 0.0
Epoch:  766       12 Batch loss: 0.216108 Batch F1: 0.0
Train Avg Loss  766: 0.226605

Train Avg F1  766: 0.0

Val Avg Loss  766: 0.217816

Val Avg F1  766:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 767
--------------------------------------------------------------
Epoch:  767        1 Batch loss: 0.256813 Batch F1: 0.0
Epoch:  767        2 Batch loss: 0.230255 Batch F1: 0.0
Epoch:  767        3 Batch loss: 0.231204 Batch F1: 0.0
Epoch:  767        4 Batch loss: 0.227753 Batch F1: 0.0
Epoch:  767        5 Batch loss: 0.224372 Batch F1: 0.0
Epoch:  767        6 Batch loss: 0.216493 Batch F1: 0.0
Epoch:  767        7 Batch loss: 0.222903 Batch F1: 0.0
Epoch:  767        8 Batch loss: 0.233639 Batch F1: 0.0
Epoch:  767        9 Batch loss: 0.191004 Batch F1: 0.0
Epoch:  767       10 Batch loss: 0.256870 Batch F1: 0.0
Epoch:  767       11 Batch loss: 0.251777 Batch F1: 0.0
Epoch:  767       12 Batch loss: 0.196803 Batch F1: 0.0
Train Avg Loss  767: 0.228324

Train Avg F1  767: 0.0

Val Avg Loss  767: 0.217810

Val Avg F1  767:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 768
--------------------------------------------------------------
Epoch:  768        1 Batch loss: 0.234468 Batch F1: 0.0
Epoch:  768        2 Batch loss: 0.207602 Batch F1: 0.0
Epoch:  768        3 Batch loss: 0.239505 Batch F1: 0.0
Epoch:  768        4 Batch loss: 0.218934 Batch F1: 0.0
Epoch:  768        5 Batch loss: 0.230859 Batch F1: 0.0
Epoch:  768        6 Batch loss: 0.236324 Batch F1: 0.0
Epoch:  768        7 Batch loss: 0.212037 Batch F1: 0.0
Epoch:  768        8 Batch loss: 0.238908 Batch F1: 0.0
Epoch:  768        9 Batch loss: 0.243364 Batch F1: 0.0
Epoch:  768       10 Batch loss: 0.206650 Batch F1: 0.0
Epoch:  768       11 Batch loss: 0.229363 Batch F1: 0.0
Epoch:  768       12 Batch loss: 0.225944 Batch F1: 0.0
Train Avg Loss  768: 0.226996

Train Avg F1  768: 0.0

Val Avg Loss  768: 0.218222

Val Avg F1  768:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 769
--------------------------------------------------------------
Epoch:  769        1 Batch loss: 0.232784 Batch F1: 0.0
Epoch:  769        2 Batch loss: 0.239306 Batch F1: 0.0
Epoch:  769        3 Batch loss: 0.237985 Batch F1: 0.0
Epoch:  769        4 Batch loss: 0.245568 Batch F1: 0.0
Epoch:  769        5 Batch loss: 0.203390 Batch F1: 0.2
Epoch:  769        6 Batch loss: 0.232465 Batch F1: 0.0
Epoch:  769        7 Batch loss: 0.236241 Batch F1: 0.0
Epoch:  769        8 Batch loss: 0.204700 Batch F1: 0.0
Epoch:  769        9 Batch loss: 0.230255 Batch F1: 0.0
Epoch:  769       10 Batch loss: 0.207031 Batch F1: 0.0
Epoch:  769       11 Batch loss: 0.232998 Batch F1: 0.0
Epoch:  769       12 Batch loss: 0.227638 Batch F1: 0.0
Train Avg Loss  769: 0.227530

Train Avg F1  769: 0.016666666666666666

Val Avg Loss  769: 0.218158

Val Avg F1  769:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 770
--------------------------------------------------------------
Epoch:  770        1 Batch loss: 0.228722 Batch F1: 0.0
Epoch:  770        2 Batch loss: 0.221652 Batch F1: 0.0
Epoch:  770        3 Batch loss: 0.224029 Batch F1: 0.0
Epoch:  770        4 Batch loss: 0.203050 Batch F1: 0.0
Epoch:  770        5 Batch loss: 0.245612 Batch F1: 0.0
Epoch:  770        6 Batch loss: 0.202060 Batch F1: 0.0
Epoch:  770        7 Batch loss: 0.203070 Batch F1: 0.0
Epoch:  770        8 Batch loss: 0.248655 Batch F1: 0.0
Epoch:  770        9 Batch loss: 0.256670 Batch F1: 0.0
Epoch:  770       10 Batch loss: 0.225140 Batch F1: 0.0
Epoch:  770       11 Batch loss: 0.219917 Batch F1: 0.0
Epoch:  770       12 Batch loss: 0.238747 Batch F1: 0.0
Train Avg Loss  770: 0.226444

Train Avg F1  770: 0.0

Val Avg Loss  770: 0.217437

Val Avg F1  770:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 771
--------------------------------------------------------------
Epoch:  771        1 Batch loss: 0.221131 Batch F1: 0.0
Epoch:  771        2 Batch loss: 0.218559 Batch F1: 0.0
Epoch:  771        3 Batch loss: 0.243060 Batch F1: 0.0
Epoch:  771        4 Batch loss: 0.194584 Batch F1: 0.0
Epoch:  771        5 Batch loss: 0.227130 Batch F1: 0.0
Epoch:  771        6 Batch loss: 0.218354 Batch F1: 0.0
Epoch:  771        7 Batch loss: 0.242617 Batch F1: 0.0
Epoch:  771        8 Batch loss: 0.244915 Batch F1: 0.0
Epoch:  771        9 Batch loss: 0.228459 Batch F1: 0.0
Epoch:  771       10 Batch loss: 0.231193 Batch F1: 0.0
Epoch:  771       11 Batch loss: 0.217326 Batch F1: 0.0
Epoch:  771       12 Batch loss: 0.229191 Batch F1: 0.0
Train Avg Loss  771: 0.226377

Train Avg F1  771: 0.0

Val Avg Loss  771: 0.218155

Val Avg F1  771:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 772
--------------------------------------------------------------
Epoch:  772        1 Batch loss: 0.205201 Batch F1: 0.0
Epoch:  772        2 Batch loss: 0.204778 Batch F1: 0.0
Epoch:  772        3 Batch loss: 0.210797 Batch F1: 0.0
Epoch:  772        4 Batch loss: 0.229352 Batch F1: 0.0
Epoch:  772        5 Batch loss: 0.226504 Batch F1: 0.0
Epoch:  772        6 Batch loss: 0.214064 Batch F1: 0.0
Epoch:  772        7 Batch loss: 0.247326 Batch F1: 0.0
Epoch:  772        8 Batch loss: 0.238719 Batch F1: 0.0
Epoch:  772        9 Batch loss: 0.282426 Batch F1: 0.0
Epoch:  772       10 Batch loss: 0.195304 Batch F1: 0.0
Epoch:  772       11 Batch loss: 0.237087 Batch F1: 0.0
Epoch:  772       12 Batch loss: 0.228596 Batch F1: 0.0
Train Avg Loss  772: 0.226679

Train Avg F1  772: 0.0

Val Avg Loss  772: 0.222575

Val Avg F1  772:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 773
--------------------------------------------------------------
Epoch:  773        1 Batch loss: 0.222145 Batch F1: 0.0
Epoch:  773        2 Batch loss: 0.229450 Batch F1: 0.0
Epoch:  773        3 Batch loss: 0.235035 Batch F1: 0.0
Epoch:  773        4 Batch loss: 0.243331 Batch F1: 0.0
Epoch:  773        5 Batch loss: 0.218324 Batch F1: 0.0
Epoch:  773        6 Batch loss: 0.222506 Batch F1: 0.0
Epoch:  773        7 Batch loss: 0.239435 Batch F1: 0.0
Epoch:  773        8 Batch loss: 0.230321 Batch F1: 0.0
Epoch:  773        9 Batch loss: 0.243402 Batch F1: 0.0
Epoch:  773       10 Batch loss: 0.183194 Batch F1: 0.0
Epoch:  773       11 Batch loss: 0.256408 Batch F1: 0.0
Epoch:  773       12 Batch loss: 0.220389 Batch F1: 0.0
Train Avg Loss  773: 0.228662

Train Avg F1  773: 0.0

Val Avg Loss  773: 0.218413

Val Avg F1  773:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 774
--------------------------------------------------------------
Epoch:  774        1 Batch loss: 0.243838 Batch F1: 0.0
Epoch:  774        2 Batch loss: 0.217962 Batch F1: 0.0
Epoch:  774        3 Batch loss: 0.224711 Batch F1: 0.0
Epoch:  774        4 Batch loss: 0.229044 Batch F1: 0.0
Epoch:  774        5 Batch loss: 0.236421 Batch F1: 0.0
Epoch:  774        6 Batch loss: 0.208820 Batch F1: 0.0
Epoch:  774        7 Batch loss: 0.238552 Batch F1: 0.0
Epoch:  774        8 Batch loss: 0.228977 Batch F1: 0.0
Epoch:  774        9 Batch loss: 0.244711 Batch F1: 0.0
Epoch:  774       10 Batch loss: 0.241471 Batch F1: 0.0
Epoch:  774       11 Batch loss: 0.191064 Batch F1: 0.0
Epoch:  774       12 Batch loss: 0.216380 Batch F1: 0.0
Train Avg Loss  774: 0.226829

Train Avg F1  774: 0.0

Val Avg Loss  774: 0.217996

Val Avg F1  774:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 775
--------------------------------------------------------------
Epoch:  775        1 Batch loss: 0.215388 Batch F1: 0.0
Epoch:  775        2 Batch loss: 0.189531 Batch F1: 0.0
Epoch:  775        3 Batch loss: 0.226054 Batch F1: 0.0
Epoch:  775        4 Batch loss: 0.248460 Batch F1: 0.0
Epoch:  775        5 Batch loss: 0.220836 Batch F1: 0.0
Epoch:  775        6 Batch loss: 0.242783 Batch F1: 0.0
Epoch:  775        7 Batch loss: 0.216418 Batch F1: 0.0
Epoch:  775        8 Batch loss: 0.206208 Batch F1: 0.0
Epoch:  775        9 Batch loss: 0.266896 Batch F1: 0.0
Epoch:  775       10 Batch loss: 0.243384 Batch F1: 0.0
Epoch:  775       11 Batch loss: 0.202550 Batch F1: 0.0
Epoch:  775       12 Batch loss: 0.236058 Batch F1: 0.0
Train Avg Loss  775: 0.226214

Train Avg F1  775: 0.0

Val Avg Loss  775: 0.219036

Val Avg F1  775:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 776
--------------------------------------------------------------
Epoch:  776        1 Batch loss: 0.236718 Batch F1: 0.0
Epoch:  776        2 Batch loss: 0.247158 Batch F1: 0.0
Epoch:  776        3 Batch loss: 0.221494 Batch F1: 0.19047619047619044
Epoch:  776        4 Batch loss: 0.222404 Batch F1: 0.3333333333333333
Epoch:  776        5 Batch loss: 0.205576 Batch F1: 0.2727272727272727
Epoch:  776        6 Batch loss: 0.233056 Batch F1: 0.4666666666666667
Epoch:  776        7 Batch loss: 0.246391 Batch F1: 0.27586206896551724
Epoch:  776        8 Batch loss: 0.219550 Batch F1: 0.0
Epoch:  776        9 Batch loss: 0.214729 Batch F1: 0.0
Epoch:  776       10 Batch loss: 0.237697 Batch F1: 0.0
Epoch:  776       11 Batch loss: 0.249416 Batch F1: 0.0
Epoch:  776       12 Batch loss: 0.178668 Batch F1: 0.0
Train Avg Loss  776: 0.226071

Train Avg F1  776: 0.1282554610140817

Val Avg Loss  776: 0.219066

Val Avg F1  776:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 777
--------------------------------------------------------------
Epoch:  777        1 Batch loss: 0.236476 Batch F1: 0.0
Epoch:  777        2 Batch loss: 0.210113 Batch F1: 0.0
Epoch:  777        3 Batch loss: 0.230500 Batch F1: 0.0
Epoch:  777        4 Batch loss: 0.229534 Batch F1: 0.0
Epoch:  777        5 Batch loss: 0.239946 Batch F1: 0.0
Epoch:  777        6 Batch loss: 0.256536 Batch F1: 0.0
Epoch:  777        7 Batch loss: 0.228352 Batch F1: 0.0
Epoch:  777        8 Batch loss: 0.209866 Batch F1: 0.0
Epoch:  777        9 Batch loss: 0.215965 Batch F1: 0.0
Epoch:  777       10 Batch loss: 0.238634 Batch F1: 0.0
Epoch:  777       11 Batch loss: 0.243682 Batch F1: 0.0
Epoch:  777       12 Batch loss: 0.224848 Batch F1: 0.0
Train Avg Loss  777: 0.230371

Train Avg F1  777: 0.0

Val Avg Loss  777: 0.220347

Val Avg F1  777:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 778
--------------------------------------------------------------
Epoch:  778        1 Batch loss: 0.243947 Batch F1: 0.0
Epoch:  778        2 Batch loss: 0.220959 Batch F1: 0.0
Epoch:  778        3 Batch loss: 0.204946 Batch F1: 0.0
Epoch:  778        4 Batch loss: 0.224946 Batch F1: 0.0
Epoch:  778        5 Batch loss: 0.248905 Batch F1: 0.0
Epoch:  778        6 Batch loss: 0.205103 Batch F1: 0.0
Epoch:  778        7 Batch loss: 0.225497 Batch F1: 0.0
Epoch:  778        8 Batch loss: 0.233529 Batch F1: 0.0
Epoch:  778        9 Batch loss: 0.224028 Batch F1: 0.0
Epoch:  778       10 Batch loss: 0.231301 Batch F1: 0.0
Epoch:  778       11 Batch loss: 0.263167 Batch F1: 0.0
Epoch:  778       12 Batch loss: 0.214615 Batch F1: 0.0
Train Avg Loss  778: 0.228412

Train Avg F1  778: 0.0

Val Avg Loss  778: 0.217571

Val Avg F1  778:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 779
--------------------------------------------------------------
Epoch:  779        1 Batch loss: 0.187044 Batch F1: 0.0
Epoch:  779        2 Batch loss: 0.204241 Batch F1: 0.0
Epoch:  779        3 Batch loss: 0.259682 Batch F1: 0.0
Epoch:  779        4 Batch loss: 0.209506 Batch F1: 0.0
Epoch:  779        5 Batch loss: 0.218848 Batch F1: 0.0
Epoch:  779        6 Batch loss: 0.198826 Batch F1: 0.0
Epoch:  779        7 Batch loss: 0.247742 Batch F1: 0.0
Epoch:  779        8 Batch loss: 0.242165 Batch F1: 0.0
Epoch:  779        9 Batch loss: 0.226274 Batch F1: 0.0
Epoch:  779       10 Batch loss: 0.222043 Batch F1: 0.0
Epoch:  779       11 Batch loss: 0.255466 Batch F1: 0.0
Epoch:  779       12 Batch loss: 0.250454 Batch F1: 0.0
Train Avg Loss  779: 0.226858

Train Avg F1  779: 0.0

Val Avg Loss  779: 0.218662

Val Avg F1  779:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 780
--------------------------------------------------------------
Epoch:  780        1 Batch loss: 0.209732 Batch F1: 0.0
Epoch:  780        2 Batch loss: 0.225185 Batch F1: 0.0
Epoch:  780        3 Batch loss: 0.207391 Batch F1: 0.0
Epoch:  780        4 Batch loss: 0.227771 Batch F1: 0.0
Epoch:  780        5 Batch loss: 0.224332 Batch F1: 0.0
Epoch:  780        6 Batch loss: 0.212836 Batch F1: 0.0
Epoch:  780        7 Batch loss: 0.200522 Batch F1: 0.0
Epoch:  780        8 Batch loss: 0.285935 Batch F1: 0.0
Epoch:  780        9 Batch loss: 0.236486 Batch F1: 0.0
Epoch:  780       10 Batch loss: 0.227185 Batch F1: 0.0
Epoch:  780       11 Batch loss: 0.253020 Batch F1: 0.0
Epoch:  780       12 Batch loss: 0.217816 Batch F1: 0.23529411764705882
Train Avg Loss  780: 0.227351

Train Avg F1  780: 0.0196078431372549

Val Avg Loss  780: 0.221199

Val Avg F1  780:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 781
--------------------------------------------------------------
Epoch:  781        1 Batch loss: 0.224903 Batch F1: 0.0
Epoch:  781        2 Batch loss: 0.211605 Batch F1: 0.0
Epoch:  781        3 Batch loss: 0.202964 Batch F1: 0.0
Epoch:  781        4 Batch loss: 0.215102 Batch F1: 0.0
Epoch:  781        5 Batch loss: 0.228307 Batch F1: 0.0
Epoch:  781        6 Batch loss: 0.264997 Batch F1: 0.0
Epoch:  781        7 Batch loss: 0.211306 Batch F1: 0.0
Epoch:  781        8 Batch loss: 0.258143 Batch F1: 0.0
Epoch:  781        9 Batch loss: 0.238742 Batch F1: 0.0
Epoch:  781       10 Batch loss: 0.223659 Batch F1: 0.0
Epoch:  781       11 Batch loss: 0.238988 Batch F1: 0.0
Epoch:  781       12 Batch loss: 0.233233 Batch F1: 0.0
Train Avg Loss  781: 0.229329

Train Avg F1  781: 0.0

Val Avg Loss  781: 0.219100

Val Avg F1  781:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 782
--------------------------------------------------------------
Epoch:  782        1 Batch loss: 0.214198 Batch F1: 0.0
Epoch:  782        2 Batch loss: 0.258063 Batch F1: 0.0
Epoch:  782        3 Batch loss: 0.216381 Batch F1: 0.0
Epoch:  782        4 Batch loss: 0.237282 Batch F1: 0.0
Epoch:  782        5 Batch loss: 0.240760 Batch F1: 0.0
Epoch:  782        6 Batch loss: 0.251375 Batch F1: 0.0
Epoch:  782        7 Batch loss: 0.228653 Batch F1: 0.0
Epoch:  782        8 Batch loss: 0.216624 Batch F1: 0.0
Epoch:  782        9 Batch loss: 0.225173 Batch F1: 0.0
Epoch:  782       10 Batch loss: 0.198391 Batch F1: 0.0
Epoch:  782       11 Batch loss: 0.226764 Batch F1: 0.0
Epoch:  782       12 Batch loss: 0.238727 Batch F1: 0.0
Train Avg Loss  782: 0.229366

Train Avg F1  782: 0.0

Val Avg Loss  782: 0.217666

Val Avg F1  782:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 783
--------------------------------------------------------------
Epoch:  783        1 Batch loss: 0.238599 Batch F1: 0.0
Epoch:  783        2 Batch loss: 0.198019 Batch F1: 0.0
Epoch:  783        3 Batch loss: 0.189995 Batch F1: 0.0
Epoch:  783        4 Batch loss: 0.243093 Batch F1: 0.0
Epoch:  783        5 Batch loss: 0.251055 Batch F1: 0.0
Epoch:  783        6 Batch loss: 0.225413 Batch F1: 0.0
Epoch:  783        7 Batch loss: 0.271576 Batch F1: 0.0
Epoch:  783        8 Batch loss: 0.230026 Batch F1: 0.0
Epoch:  783        9 Batch loss: 0.202180 Batch F1: 0.0
Epoch:  783       10 Batch loss: 0.215118 Batch F1: 0.0
Epoch:  783       11 Batch loss: 0.227593 Batch F1: 0.0
Epoch:  783       12 Batch loss: 0.242766 Batch F1: 0.0
Train Avg Loss  783: 0.227953

Train Avg F1  783: 0.0

Val Avg Loss  783: 0.219261

Val Avg F1  783:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 784
--------------------------------------------------------------
Epoch:  784        1 Batch loss: 0.202270 Batch F1: 0.0
Epoch:  784        2 Batch loss: 0.222049 Batch F1: 0.0
Epoch:  784        3 Batch loss: 0.253745 Batch F1: 0.0
Epoch:  784        4 Batch loss: 0.205042 Batch F1: 0.0
Epoch:  784        5 Batch loss: 0.214549 Batch F1: 0.0
Epoch:  784        6 Batch loss: 0.227028 Batch F1: 0.0
Epoch:  784        7 Batch loss: 0.237754 Batch F1: 0.0
Epoch:  784        8 Batch loss: 0.246610 Batch F1: 0.0
Epoch:  784        9 Batch loss: 0.221904 Batch F1: 0.0
Epoch:  784       10 Batch loss: 0.239057 Batch F1: 0.0
Epoch:  784       11 Batch loss: 0.244416 Batch F1: 0.0
Epoch:  784       12 Batch loss: 0.210913 Batch F1: 0.0
Train Avg Loss  784: 0.227111

Train Avg F1  784: 0.0

Val Avg Loss  784: 0.219429

Val Avg F1  784:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 785
--------------------------------------------------------------
Epoch:  785        1 Batch loss: 0.214428 Batch F1: 0.0
Epoch:  785        2 Batch loss: 0.220614 Batch F1: 0.0
Epoch:  785        3 Batch loss: 0.243471 Batch F1: 0.0
Epoch:  785        4 Batch loss: 0.240611 Batch F1: 0.0
Epoch:  785        5 Batch loss: 0.219969 Batch F1: 0.0
Epoch:  785        6 Batch loss: 0.243213 Batch F1: 0.0
Epoch:  785        7 Batch loss: 0.234373 Batch F1: 0.0
Epoch:  785        8 Batch loss: 0.198880 Batch F1: 0.0
Epoch:  785        9 Batch loss: 0.248196 Batch F1: 0.0
Epoch:  785       10 Batch loss: 0.194955 Batch F1: 0.0
Epoch:  785       11 Batch loss: 0.203367 Batch F1: 0.0
Epoch:  785       12 Batch loss: 0.262256 Batch F1: 0.0
Train Avg Loss  785: 0.227028

Train Avg F1  785: 0.0

Val Avg Loss  785: 0.218492

Val Avg F1  785:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 786
--------------------------------------------------------------
Epoch:  786        1 Batch loss: 0.222032 Batch F1: 0.0
Epoch:  786        2 Batch loss: 0.207662 Batch F1: 0.0
Epoch:  786        3 Batch loss: 0.236000 Batch F1: 0.0
Epoch:  786        4 Batch loss: 0.212512 Batch F1: 0.0
Epoch:  786        5 Batch loss: 0.242001 Batch F1: 0.0
Epoch:  786        6 Batch loss: 0.254568 Batch F1: 0.0
Epoch:  786        7 Batch loss: 0.192482 Batch F1: 0.0
Epoch:  786        8 Batch loss: 0.195991 Batch F1: 0.0
Epoch:  786        9 Batch loss: 0.239320 Batch F1: 0.0
Epoch:  786       10 Batch loss: 0.230820 Batch F1: 0.0
Epoch:  786       11 Batch loss: 0.224209 Batch F1: 0.0
Epoch:  786       12 Batch loss: 0.262266 Batch F1: 0.0
Train Avg Loss  786: 0.226655

Train Avg F1  786: 0.0

Val Avg Loss  786: 0.217606

Val Avg F1  786:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 787
--------------------------------------------------------------
Epoch:  787        1 Batch loss: 0.232561 Batch F1: 0.0
Epoch:  787        2 Batch loss: 0.201464 Batch F1: 0.0
Epoch:  787        3 Batch loss: 0.222092 Batch F1: 0.0
Epoch:  787        4 Batch loss: 0.200366 Batch F1: 0.0
Epoch:  787        5 Batch loss: 0.252298 Batch F1: 0.0
Epoch:  787        6 Batch loss: 0.218942 Batch F1: 0.0
Epoch:  787        7 Batch loss: 0.234926 Batch F1: 0.0
Epoch:  787        8 Batch loss: 0.197827 Batch F1: 0.0
Epoch:  787        9 Batch loss: 0.252928 Batch F1: 0.0
Epoch:  787       10 Batch loss: 0.227601 Batch F1: 0.0
Epoch:  787       11 Batch loss: 0.213520 Batch F1: 0.0
Epoch:  787       12 Batch loss: 0.262678 Batch F1: 0.0
Train Avg Loss  787: 0.226434

Train Avg F1  787: 0.0

Val Avg Loss  787: 0.217879

Val Avg F1  787:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 788
--------------------------------------------------------------
Epoch:  788        1 Batch loss: 0.221376 Batch F1: 0.0
Epoch:  788        2 Batch loss: 0.235049 Batch F1: 0.0
Epoch:  788        3 Batch loss: 0.212432 Batch F1: 0.0
Epoch:  788        4 Batch loss: 0.226685 Batch F1: 0.0
Epoch:  788        5 Batch loss: 0.204839 Batch F1: 0.0
Epoch:  788        6 Batch loss: 0.234968 Batch F1: 0.0
Epoch:  788        7 Batch loss: 0.220557 Batch F1: 0.0
Epoch:  788        8 Batch loss: 0.263934 Batch F1: 0.0
Epoch:  788        9 Batch loss: 0.230865 Batch F1: 0.0
Epoch:  788       10 Batch loss: 0.208755 Batch F1: 0.0
Epoch:  788       11 Batch loss: 0.228637 Batch F1: 0.0
Epoch:  788       12 Batch loss: 0.227855 Batch F1: 0.0
Train Avg Loss  788: 0.226329

Train Avg F1  788: 0.0

Val Avg Loss  788: 0.218151

Val Avg F1  788:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 789
--------------------------------------------------------------
Epoch:  789        1 Batch loss: 0.226220 Batch F1: 0.0
Epoch:  789        2 Batch loss: 0.238406 Batch F1: 0.0
Epoch:  789        3 Batch loss: 0.230366 Batch F1: 0.0
Epoch:  789        4 Batch loss: 0.222444 Batch F1: 0.0
Epoch:  789        5 Batch loss: 0.244677 Batch F1: 0.0
Epoch:  789        6 Batch loss: 0.225837 Batch F1: 0.0
Epoch:  789        7 Batch loss: 0.224416 Batch F1: 0.0
Epoch:  789        8 Batch loss: 0.231310 Batch F1: 0.0
Epoch:  789        9 Batch loss: 0.202444 Batch F1: 0.0
Epoch:  789       10 Batch loss: 0.237387 Batch F1: 0.0
Epoch:  789       11 Batch loss: 0.239694 Batch F1: 0.0
Epoch:  789       12 Batch loss: 0.209354 Batch F1: 0.0
Train Avg Loss  789: 0.227713

Train Avg F1  789: 0.0

Val Avg Loss  789: 0.218285

Val Avg F1  789:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 790
--------------------------------------------------------------
Epoch:  790        1 Batch loss: 0.232672 Batch F1: 0.0
Epoch:  790        2 Batch loss: 0.239142 Batch F1: 0.0
Epoch:  790        3 Batch loss: 0.213042 Batch F1: 0.0
Epoch:  790        4 Batch loss: 0.226241 Batch F1: 0.0
Epoch:  790        5 Batch loss: 0.232246 Batch F1: 0.0
Epoch:  790        6 Batch loss: 0.209406 Batch F1: 0.0
Epoch:  790        7 Batch loss: 0.247465 Batch F1: 0.0
Epoch:  790        8 Batch loss: 0.191171 Batch F1: 0.0
Epoch:  790        9 Batch loss: 0.227870 Batch F1: 0.0
Epoch:  790       10 Batch loss: 0.223326 Batch F1: 0.0
Epoch:  790       11 Batch loss: 0.247605 Batch F1: 0.0
Epoch:  790       12 Batch loss: 0.217633 Batch F1: 0.0
Train Avg Loss  790: 0.225652

Train Avg F1  790: 0.0

Val Avg Loss  790: 0.217036

Val Avg F1  790:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 791
--------------------------------------------------------------
Epoch:  791        1 Batch loss: 0.237083 Batch F1: 0.0
Epoch:  791        2 Batch loss: 0.239833 Batch F1: 0.0
Epoch:  791        3 Batch loss: 0.207210 Batch F1: 0.0
Epoch:  791        4 Batch loss: 0.213679 Batch F1: 0.0
Epoch:  791        5 Batch loss: 0.237462 Batch F1: 0.0
Epoch:  791        6 Batch loss: 0.188950 Batch F1: 0.0
Epoch:  791        7 Batch loss: 0.230052 Batch F1: 0.0
Epoch:  791        8 Batch loss: 0.208241 Batch F1: 0.0
Epoch:  791        9 Batch loss: 0.220942 Batch F1: 0.0
Epoch:  791       10 Batch loss: 0.243911 Batch F1: 0.0
Epoch:  791       11 Batch loss: 0.258015 Batch F1: 0.0
Epoch:  791       12 Batch loss: 0.228793 Batch F1: 0.0
Train Avg Loss  791: 0.226181

Train Avg F1  791: 0.0

Val Avg Loss  791: 0.216836

Val Avg F1  791:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 792
--------------------------------------------------------------
Epoch:  792        1 Batch loss: 0.208718 Batch F1: 0.0
Epoch:  792        2 Batch loss: 0.212621 Batch F1: 0.0
Epoch:  792        3 Batch loss: 0.214148 Batch F1: 0.0
Epoch:  792        4 Batch loss: 0.235139 Batch F1: 0.0
Epoch:  792        5 Batch loss: 0.251682 Batch F1: 0.0
Epoch:  792        6 Batch loss: 0.220595 Batch F1: 0.0
Epoch:  792        7 Batch loss: 0.248641 Batch F1: 0.0
Epoch:  792        8 Batch loss: 0.216707 Batch F1: 0.0
Epoch:  792        9 Batch loss: 0.223274 Batch F1: 0.0
Epoch:  792       10 Batch loss: 0.218859 Batch F1: 0.0
Epoch:  792       11 Batch loss: 0.239101 Batch F1: 0.0
Epoch:  792       12 Batch loss: 0.237562 Batch F1: 0.0
Train Avg Loss  792: 0.227254

Train Avg F1  792: 0.0

Val Avg Loss  792: 0.218649

Val Avg F1  792:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 793
--------------------------------------------------------------
Epoch:  793        1 Batch loss: 0.218767 Batch F1: 0.0
Epoch:  793        2 Batch loss: 0.223094 Batch F1: 0.0
Epoch:  793        3 Batch loss: 0.225639 Batch F1: 0.0
Epoch:  793        4 Batch loss: 0.251992 Batch F1: 0.0
Epoch:  793        5 Batch loss: 0.242128 Batch F1: 0.0
Epoch:  793        6 Batch loss: 0.228653 Batch F1: 0.0
Epoch:  793        7 Batch loss: 0.223274 Batch F1: 0.0
Epoch:  793        8 Batch loss: 0.243113 Batch F1: 0.0
Epoch:  793        9 Batch loss: 0.219626 Batch F1: 0.0
Epoch:  793       10 Batch loss: 0.228367 Batch F1: 0.0
Epoch:  793       11 Batch loss: 0.205599 Batch F1: 0.0
Epoch:  793       12 Batch loss: 0.220679 Batch F1: 0.1111111111111111
Train Avg Loss  793: 0.227578

Train Avg F1  793: 0.009259259259259259

Val Avg Loss  793: 0.218580

Val Avg F1  793:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 794
--------------------------------------------------------------
Epoch:  794        1 Batch loss: 0.247269 Batch F1: 0.0
Epoch:  794        2 Batch loss: 0.217576 Batch F1: 0.0
Epoch:  794        3 Batch loss: 0.178116 Batch F1: 0.0
Epoch:  794        4 Batch loss: 0.215436 Batch F1: 0.0
Epoch:  794        5 Batch loss: 0.239472 Batch F1: 0.0
Epoch:  794        6 Batch loss: 0.212223 Batch F1: 0.0
Epoch:  794        7 Batch loss: 0.254931 Batch F1: 0.0
Epoch:  794        8 Batch loss: 0.214708 Batch F1: 0.0
Epoch:  794        9 Batch loss: 0.248717 Batch F1: 0.0
Epoch:  794       10 Batch loss: 0.245456 Batch F1: 0.0
Epoch:  794       11 Batch loss: 0.245226 Batch F1: 0.33333333333333326
Epoch:  794       12 Batch loss: 0.227995 Batch F1: 0.18181818181818185
Train Avg Loss  794: 0.228927

Train Avg F1  794: 0.04292929292929293

Val Avg Loss  794: 0.226741

Val Avg F1  794:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 795
--------------------------------------------------------------
Epoch:  795        1 Batch loss: 0.237742 Batch F1: 0.0
Epoch:  795        2 Batch loss: 0.225223 Batch F1: 0.0
Epoch:  795        3 Batch loss: 0.218096 Batch F1: 0.0
Epoch:  795        4 Batch loss: 0.213745 Batch F1: 0.0
Epoch:  795        5 Batch loss: 0.211321 Batch F1: 0.0
Epoch:  795        6 Batch loss: 0.231314 Batch F1: 0.0
Epoch:  795        7 Batch loss: 0.227011 Batch F1: 0.0
Epoch:  795        8 Batch loss: 0.235255 Batch F1: 0.0
Epoch:  795        9 Batch loss: 0.262271 Batch F1: 0.0
Epoch:  795       10 Batch loss: 0.232005 Batch F1: 0.6250000000000001
Epoch:  795       11 Batch loss: 0.235969 Batch F1: 0.4999999999999999
Epoch:  795       12 Batch loss: 0.249932 Batch F1: 0.0
Train Avg Loss  795: 0.231657

Train Avg F1  795: 0.09375

Val Avg Loss  795: 0.223629

Val Avg F1  795:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 796
--------------------------------------------------------------
Epoch:  796        1 Batch loss: 0.224886 Batch F1: 0.0
Epoch:  796        2 Batch loss: 0.237100 Batch F1: 0.0
Epoch:  796        3 Batch loss: 0.220335 Batch F1: 0.0
Epoch:  796        4 Batch loss: 0.209950 Batch F1: 0.0
Epoch:  796        5 Batch loss: 0.205796 Batch F1: 0.0
Epoch:  796        6 Batch loss: 0.226650 Batch F1: 0.0
Epoch:  796        7 Batch loss: 0.248268 Batch F1: 0.0
Epoch:  796        8 Batch loss: 0.228532 Batch F1: 0.0
Epoch:  796        9 Batch loss: 0.238329 Batch F1: 0.0
Epoch:  796       10 Batch loss: 0.241361 Batch F1: 0.0
Epoch:  796       11 Batch loss: 0.230703 Batch F1: 0.0
Epoch:  796       12 Batch loss: 0.226341 Batch F1: 0.0
Train Avg Loss  796: 0.228188

Train Avg F1  796: 0.0

Val Avg Loss  796: 0.220302

Val Avg F1  796:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 797
--------------------------------------------------------------
Epoch:  797        1 Batch loss: 0.203816 Batch F1: 0.0
Epoch:  797        2 Batch loss: 0.234794 Batch F1: 0.0
Epoch:  797        3 Batch loss: 0.219620 Batch F1: 0.0
Epoch:  797        4 Batch loss: 0.270897 Batch F1: 0.0
Epoch:  797        5 Batch loss: 0.246280 Batch F1: 0.0
Epoch:  797        6 Batch loss: 0.221569 Batch F1: 0.0
Epoch:  797        7 Batch loss: 0.232641 Batch F1: 0.0
Epoch:  797        8 Batch loss: 0.210001 Batch F1: 0.0
Epoch:  797        9 Batch loss: 0.225970 Batch F1: 0.0
Epoch:  797       10 Batch loss: 0.250912 Batch F1: 0.0
Epoch:  797       11 Batch loss: 0.225231 Batch F1: 0.0
Epoch:  797       12 Batch loss: 0.194008 Batch F1: 0.0
Train Avg Loss  797: 0.227978

Train Avg F1  797: 0.0

Val Avg Loss  797: 0.218928

Val Avg F1  797:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 798
--------------------------------------------------------------
Epoch:  798        1 Batch loss: 0.229293 Batch F1: 0.0
Epoch:  798        2 Batch loss: 0.251395 Batch F1: 0.0
Epoch:  798        3 Batch loss: 0.254465 Batch F1: 0.0
Epoch:  798        4 Batch loss: 0.238968 Batch F1: 0.0
Epoch:  798        5 Batch loss: 0.232198 Batch F1: 0.0
Epoch:  798        6 Batch loss: 0.231069 Batch F1: 0.0
Epoch:  798        7 Batch loss: 0.228022 Batch F1: 0.0
Epoch:  798        8 Batch loss: 0.201310 Batch F1: 0.0
Epoch:  798        9 Batch loss: 0.207329 Batch F1: 0.0
Epoch:  798       10 Batch loss: 0.208860 Batch F1: 0.0
Epoch:  798       11 Batch loss: 0.241930 Batch F1: 0.0
Epoch:  798       12 Batch loss: 0.202197 Batch F1: 0.0
Train Avg Loss  798: 0.227253

Train Avg F1  798: 0.0

Val Avg Loss  798: 0.217563

Val Avg F1  798:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 799
--------------------------------------------------------------
Epoch:  799        1 Batch loss: 0.263375 Batch F1: 0.0
Epoch:  799        2 Batch loss: 0.234915 Batch F1: 0.0
Epoch:  799        3 Batch loss: 0.235444 Batch F1: 0.0
Epoch:  799        4 Batch loss: 0.224384 Batch F1: 0.0
Epoch:  799        5 Batch loss: 0.221667 Batch F1: 0.0
Epoch:  799        6 Batch loss: 0.224695 Batch F1: 0.0
Epoch:  799        7 Batch loss: 0.244112 Batch F1: 0.0
Epoch:  799        8 Batch loss: 0.198737 Batch F1: 0.0
Epoch:  799        9 Batch loss: 0.208071 Batch F1: 0.0
Epoch:  799       10 Batch loss: 0.213567 Batch F1: 0.0
Epoch:  799       11 Batch loss: 0.252198 Batch F1: 0.0
Epoch:  799       12 Batch loss: 0.215900 Batch F1: 0.0
Train Avg Loss  799: 0.228089

Train Avg F1  799: 0.0

Val Avg Loss  799: 0.217807

Val Avg F1  799:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 800
--------------------------------------------------------------
Epoch:  800        1 Batch loss: 0.239700 Batch F1: 0.0
Epoch:  800        2 Batch loss: 0.255820 Batch F1: 0.0
Epoch:  800        3 Batch loss: 0.230983 Batch F1: 0.0
Epoch:  800        4 Batch loss: 0.230347 Batch F1: 0.0
Epoch:  800        5 Batch loss: 0.235411 Batch F1: 0.0
Epoch:  800        6 Batch loss: 0.223724 Batch F1: 0.0
Epoch:  800        7 Batch loss: 0.249162 Batch F1: 0.0
Epoch:  800        8 Batch loss: 0.206783 Batch F1: 0.0
Epoch:  800        9 Batch loss: 0.209617 Batch F1: 0.0
Epoch:  800       10 Batch loss: 0.213388 Batch F1: 0.0
Epoch:  800       11 Batch loss: 0.220429 Batch F1: 0.0
Epoch:  800       12 Batch loss: 0.220889 Batch F1: 0.0
Train Avg Loss  800: 0.228021

Train Avg F1  800: 0.0

Val Avg Loss  800: 0.219308

Val Avg F1  800:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 801
--------------------------------------------------------------
Epoch:  801        1 Batch loss: 0.247199 Batch F1: 0.0
Epoch:  801        2 Batch loss: 0.229611 Batch F1: 0.0
Epoch:  801        3 Batch loss: 0.233256 Batch F1: 0.0
Epoch:  801        4 Batch loss: 0.223189 Batch F1: 0.0
Epoch:  801        5 Batch loss: 0.206829 Batch F1: 0.0
Epoch:  801        6 Batch loss: 0.241331 Batch F1: 0.0
Epoch:  801        7 Batch loss: 0.245434 Batch F1: 0.0
Epoch:  801        8 Batch loss: 0.240431 Batch F1: 0.0
Epoch:  801        9 Batch loss: 0.216851 Batch F1: 0.09523809523809525
Epoch:  801       10 Batch loss: 0.226327 Batch F1: 0.0
Epoch:  801       11 Batch loss: 0.225077 Batch F1: 0.0
Epoch:  801       12 Batch loss: 0.217610 Batch F1: 0.0
Train Avg Loss  801: 0.229429

Train Avg F1  801: 0.007936507936507938

Val Avg Loss  801: 0.219846

Val Avg F1  801:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 802
--------------------------------------------------------------
Epoch:  802        1 Batch loss: 0.224592 Batch F1: 0.0
Epoch:  802        2 Batch loss: 0.242240 Batch F1: 0.0
Epoch:  802        3 Batch loss: 0.317961 Batch F1: 0.0
Epoch:  802        4 Batch loss: 0.233954 Batch F1: 0.0
Epoch:  802        5 Batch loss: 0.219337 Batch F1: 0.0
Epoch:  802        6 Batch loss: 0.250691 Batch F1: 0.0
Epoch:  802        7 Batch loss: 0.227859 Batch F1: 0.0
Epoch:  802        8 Batch loss: 0.229155 Batch F1: 0.0
Epoch:  802        9 Batch loss: 0.224923 Batch F1: 0.0
Epoch:  802       10 Batch loss: 0.224378 Batch F1: 0.0
Epoch:  802       11 Batch loss: 0.201862 Batch F1: 0.0
Epoch:  802       12 Batch loss: 0.225335 Batch F1: 0.0
Train Avg Loss  802: 0.235191

Train Avg F1  802: 0.0

Val Avg Loss  802: 0.219927

Val Avg F1  802:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 803
--------------------------------------------------------------
Epoch:  803        1 Batch loss: 0.207791 Batch F1: 0.0
Epoch:  803        2 Batch loss: 0.235179 Batch F1: 0.0
Epoch:  803        3 Batch loss: 0.234446 Batch F1: 0.0
Epoch:  803        4 Batch loss: 0.190444 Batch F1: 0.0
Epoch:  803        5 Batch loss: 0.243810 Batch F1: 0.0
Epoch:  803        6 Batch loss: 0.231838 Batch F1: 0.0
Epoch:  803        7 Batch loss: 0.229019 Batch F1: 0.0
Epoch:  803        8 Batch loss: 0.238177 Batch F1: 0.0
Epoch:  803        9 Batch loss: 0.251044 Batch F1: 0.0
Epoch:  803       10 Batch loss: 0.244095 Batch F1: 0.0
Epoch:  803       11 Batch loss: 0.214234 Batch F1: 0.0
Epoch:  803       12 Batch loss: 0.246556 Batch F1: 0.0
Train Avg Loss  803: 0.230553

Train Avg F1  803: 0.0

Val Avg Loss  803: 0.223248

Val Avg F1  803:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 804
--------------------------------------------------------------
Epoch:  804        1 Batch loss: 0.226979 Batch F1: 0.0
Epoch:  804        2 Batch loss: 0.232205 Batch F1: 0.0
Epoch:  804        3 Batch loss: 0.234475 Batch F1: 0.0
Epoch:  804        4 Batch loss: 0.231705 Batch F1: 0.0
Epoch:  804        5 Batch loss: 0.191887 Batch F1: 0.0
Epoch:  804        6 Batch loss: 0.233632 Batch F1: 0.0
Epoch:  804        7 Batch loss: 0.240010 Batch F1: 0.0
Epoch:  804        8 Batch loss: 0.250697 Batch F1: 0.0
Epoch:  804        9 Batch loss: 0.249640 Batch F1: 0.0
Epoch:  804       10 Batch loss: 0.208651 Batch F1: 0.0
Epoch:  804       11 Batch loss: 0.231746 Batch F1: 0.0
Epoch:  804       12 Batch loss: 0.232112 Batch F1: 0.0
Train Avg Loss  804: 0.230312

Train Avg F1  804: 0.0

Val Avg Loss  804: 0.221292

Val Avg F1  804:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 805
--------------------------------------------------------------
Epoch:  805        1 Batch loss: 0.219039 Batch F1: 0.0
Epoch:  805        2 Batch loss: 0.217008 Batch F1: 0.0
Epoch:  805        3 Batch loss: 0.189640 Batch F1: 0.0
Epoch:  805        4 Batch loss: 0.228835 Batch F1: 0.0
Epoch:  805        5 Batch loss: 0.229700 Batch F1: 0.0
Epoch:  805        6 Batch loss: 0.213194 Batch F1: 0.0
Epoch:  805        7 Batch loss: 0.240828 Batch F1: 0.0
Epoch:  805        8 Batch loss: 0.247178 Batch F1: 0.0
Epoch:  805        9 Batch loss: 0.260038 Batch F1: 0.0
Epoch:  805       10 Batch loss: 0.232958 Batch F1: 0.0
Epoch:  805       11 Batch loss: 0.221825 Batch F1: 0.0
Epoch:  805       12 Batch loss: 0.265657 Batch F1: 0.0
Train Avg Loss  805: 0.230492

Train Avg F1  805: 0.0

Val Avg Loss  805: 0.221013

Val Avg F1  805:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 806
--------------------------------------------------------------
Epoch:  806        1 Batch loss: 0.238035 Batch F1: 0.0
Epoch:  806        2 Batch loss: 0.224008 Batch F1: 0.0
Epoch:  806        3 Batch loss: 0.218411 Batch F1: 0.0
Epoch:  806        4 Batch loss: 0.221999 Batch F1: 0.0
Epoch:  806        5 Batch loss: 0.214654 Batch F1: 0.0
Epoch:  806        6 Batch loss: 0.241748 Batch F1: 0.0
Epoch:  806        7 Batch loss: 0.226499 Batch F1: 0.0
Epoch:  806        8 Batch loss: 0.223147 Batch F1: 0.0
Epoch:  806        9 Batch loss: 0.225099 Batch F1: 0.0
Epoch:  806       10 Batch loss: 0.254202 Batch F1: 0.0
Epoch:  806       11 Batch loss: 0.227654 Batch F1: 0.0
Epoch:  806       12 Batch loss: 0.258631 Batch F1: 0.0
Train Avg Loss  806: 0.231174

Train Avg F1  806: 0.0

Val Avg Loss  806: 0.219091

Val Avg F1  806:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 807
--------------------------------------------------------------
Epoch:  807        1 Batch loss: 0.206433 Batch F1: 0.0
Epoch:  807        2 Batch loss: 0.229060 Batch F1: 0.0
Epoch:  807        3 Batch loss: 0.230638 Batch F1: 0.0
Epoch:  807        4 Batch loss: 0.221572 Batch F1: 0.0
Epoch:  807        5 Batch loss: 0.235726 Batch F1: 0.0
Epoch:  807        6 Batch loss: 0.254406 Batch F1: 0.0
Epoch:  807        7 Batch loss: 0.215342 Batch F1: 0.0
Epoch:  807        8 Batch loss: 0.224648 Batch F1: 0.0
Epoch:  807        9 Batch loss: 0.247144 Batch F1: 0.0
Epoch:  807       10 Batch loss: 0.224922 Batch F1: 0.0
Epoch:  807       11 Batch loss: 0.238323 Batch F1: 0.0
Epoch:  807       12 Batch loss: 0.199210 Batch F1: 0.0
Train Avg Loss  807: 0.227285

Train Avg F1  807: 0.0

Val Avg Loss  807: 0.219043

Val Avg F1  807:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 808
--------------------------------------------------------------
Epoch:  808        1 Batch loss: 0.211462 Batch F1: 0.0
Epoch:  808        2 Batch loss: 0.204666 Batch F1: 0.0
Epoch:  808        3 Batch loss: 0.241496 Batch F1: 0.0
Epoch:  808        4 Batch loss: 0.224958 Batch F1: 0.0
Epoch:  808        5 Batch loss: 0.248291 Batch F1: 0.0
Epoch:  808        6 Batch loss: 0.206282 Batch F1: 0.0
Epoch:  808        7 Batch loss: 0.238969 Batch F1: 0.0
Epoch:  808        8 Batch loss: 0.237297 Batch F1: 0.0
Epoch:  808        9 Batch loss: 0.254479 Batch F1: 0.0
Epoch:  808       10 Batch loss: 0.210865 Batch F1: 0.0
Epoch:  808       11 Batch loss: 0.227354 Batch F1: 0.0
Epoch:  808       12 Batch loss: 0.224570 Batch F1: 0.0
Train Avg Loss  808: 0.227557

Train Avg F1  808: 0.0

Val Avg Loss  808: 0.218605

Val Avg F1  808:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 809
--------------------------------------------------------------
Epoch:  809        1 Batch loss: 0.235101 Batch F1: 0.0
Epoch:  809        2 Batch loss: 0.221970 Batch F1: 0.0
Epoch:  809        3 Batch loss: 0.204848 Batch F1: 0.0
Epoch:  809        4 Batch loss: 0.245919 Batch F1: 0.0
Epoch:  809        5 Batch loss: 0.196661 Batch F1: 0.0
Epoch:  809        6 Batch loss: 0.253284 Batch F1: 0.0
Epoch:  809        7 Batch loss: 0.238904 Batch F1: 0.0
Epoch:  809        8 Batch loss: 0.239744 Batch F1: 0.0
Epoch:  809        9 Batch loss: 0.201529 Batch F1: 0.0
Epoch:  809       10 Batch loss: 0.250955 Batch F1: 0.0
Epoch:  809       11 Batch loss: 0.202689 Batch F1: 0.0
Epoch:  809       12 Batch loss: 0.228427 Batch F1: 0.0
Train Avg Loss  809: 0.226669

Train Avg F1  809: 0.0

Val Avg Loss  809: 0.218037

Val Avg F1  809:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 810
--------------------------------------------------------------
Epoch:  810        1 Batch loss: 0.235997 Batch F1: 0.0
Epoch:  810        2 Batch loss: 0.239452 Batch F1: 0.0
Epoch:  810        3 Batch loss: 0.217923 Batch F1: 0.0
Epoch:  810        4 Batch loss: 0.216470 Batch F1: 0.0
Epoch:  810        5 Batch loss: 0.247882 Batch F1: 0.0
Epoch:  810        6 Batch loss: 0.205433 Batch F1: 0.0
Epoch:  810        7 Batch loss: 0.224711 Batch F1: 0.0
Epoch:  810        8 Batch loss: 0.236024 Batch F1: 0.0
Epoch:  810        9 Batch loss: 0.216709 Batch F1: 0.0
Epoch:  810       10 Batch loss: 0.217281 Batch F1: 0.0
Epoch:  810       11 Batch loss: 0.228974 Batch F1: 0.0
Epoch:  810       12 Batch loss: 0.228732 Batch F1: 0.0
Train Avg Loss  810: 0.226299

Train Avg F1  810: 0.0

Val Avg Loss  810: 0.217560

Val Avg F1  810:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 811
--------------------------------------------------------------
Epoch:  811        1 Batch loss: 0.241930 Batch F1: 0.0
Epoch:  811        2 Batch loss: 0.230244 Batch F1: 0.0
Epoch:  811        3 Batch loss: 0.202297 Batch F1: 0.0
Epoch:  811        4 Batch loss: 0.221261 Batch F1: 0.0
Epoch:  811        5 Batch loss: 0.220380 Batch F1: 0.0
Epoch:  811        6 Batch loss: 0.255571 Batch F1: 0.0
Epoch:  811        7 Batch loss: 0.224786 Batch F1: 0.0
Epoch:  811        8 Batch loss: 0.203295 Batch F1: 0.0
Epoch:  811        9 Batch loss: 0.214739 Batch F1: 0.0
Epoch:  811       10 Batch loss: 0.237241 Batch F1: 0.0
Epoch:  811       11 Batch loss: 0.228049 Batch F1: 0.0
Epoch:  811       12 Batch loss: 0.236947 Batch F1: 0.0
Train Avg Loss  811: 0.226395

Train Avg F1  811: 0.0

Val Avg Loss  811: 0.217918

Val Avg F1  811:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 812
--------------------------------------------------------------
Epoch:  812        1 Batch loss: 0.187831 Batch F1: 0.0
Epoch:  812        2 Batch loss: 0.199597 Batch F1: 0.0
Epoch:  812        3 Batch loss: 0.225242 Batch F1: 0.0
Epoch:  812        4 Batch loss: 0.232585 Batch F1: 0.0
Epoch:  812        5 Batch loss: 0.252059 Batch F1: 0.0
Epoch:  812        6 Batch loss: 0.267683 Batch F1: 0.0
Epoch:  812        7 Batch loss: 0.243333 Batch F1: 0.0
Epoch:  812        8 Batch loss: 0.260383 Batch F1: 0.0
Epoch:  812        9 Batch loss: 0.234918 Batch F1: 0.20689655172413793
Epoch:  812       10 Batch loss: 0.230191 Batch F1: 0.41379310344827586
Epoch:  812       11 Batch loss: 0.199306 Batch F1: 0.3
Epoch:  812       12 Batch loss: 0.200310 Batch F1: 0.0
Train Avg Loss  812: 0.227786

Train Avg F1  812: 0.07672413793103448

Val Avg Loss  812: 0.218657

Val Avg F1  812:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 813
--------------------------------------------------------------
Epoch:  813        1 Batch loss: 0.251689 Batch F1: 0.0
Epoch:  813        2 Batch loss: 0.225765 Batch F1: 0.0
Epoch:  813        3 Batch loss: 0.212621 Batch F1: 0.0
Epoch:  813        4 Batch loss: 0.252596 Batch F1: 0.0
Epoch:  813        5 Batch loss: 0.251680 Batch F1: 0.0
Epoch:  813        6 Batch loss: 0.249695 Batch F1: 0.0
Epoch:  813        7 Batch loss: 0.221452 Batch F1: 0.0
Epoch:  813        8 Batch loss: 0.221771 Batch F1: 0.0
Epoch:  813        9 Batch loss: 0.222954 Batch F1: 0.0
Epoch:  813       10 Batch loss: 0.231118 Batch F1: 0.0
Epoch:  813       11 Batch loss: 0.207422 Batch F1: 0.0
Epoch:  813       12 Batch loss: 0.207246 Batch F1: 0.0
Train Avg Loss  813: 0.229667

Train Avg F1  813: 0.0

Val Avg Loss  813: 0.218907

Val Avg F1  813:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 814
--------------------------------------------------------------
Epoch:  814        1 Batch loss: 0.249439 Batch F1: 0.0
Epoch:  814        2 Batch loss: 0.228653 Batch F1: 0.0
Epoch:  814        3 Batch loss: 0.207096 Batch F1: 0.0
Epoch:  814        4 Batch loss: 0.251593 Batch F1: 0.0
Epoch:  814        5 Batch loss: 0.218547 Batch F1: 0.0
Epoch:  814        6 Batch loss: 0.252033 Batch F1: 0.0
Epoch:  814        7 Batch loss: 0.202598 Batch F1: 0.0
Epoch:  814        8 Batch loss: 0.219317 Batch F1: 0.0
Epoch:  814        9 Batch loss: 0.209602 Batch F1: 0.0
Epoch:  814       10 Batch loss: 0.225096 Batch F1: 0.0
Epoch:  814       11 Batch loss: 0.235207 Batch F1: 0.0
Epoch:  814       12 Batch loss: 0.222882 Batch F1: 0.0
Train Avg Loss  814: 0.226839

Train Avg F1  814: 0.0

Val Avg Loss  814: 0.217358

Val Avg F1  814:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 815
--------------------------------------------------------------
Epoch:  815        1 Batch loss: 0.227299 Batch F1: 0.0
Epoch:  815        2 Batch loss: 0.212573 Batch F1: 0.0
Epoch:  815        3 Batch loss: 0.250936 Batch F1: 0.0
Epoch:  815        4 Batch loss: 0.220755 Batch F1: 0.0
Epoch:  815        5 Batch loss: 0.197549 Batch F1: 0.0
Epoch:  815        6 Batch loss: 0.223390 Batch F1: 0.0
Epoch:  815        7 Batch loss: 0.201950 Batch F1: 0.0
Epoch:  815        8 Batch loss: 0.213220 Batch F1: 0.0
Epoch:  815        9 Batch loss: 0.260583 Batch F1: 0.0
Epoch:  815       10 Batch loss: 0.235653 Batch F1: 0.0
Epoch:  815       11 Batch loss: 0.236568 Batch F1: 0.0
Epoch:  815       12 Batch loss: 0.246900 Batch F1: 0.0
Train Avg Loss  815: 0.227281

Train Avg F1  815: 0.0

Val Avg Loss  815: 0.219009

Val Avg F1  815:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 816
--------------------------------------------------------------
Epoch:  816        1 Batch loss: 0.231951 Batch F1: 0.0
Epoch:  816        2 Batch loss: 0.226767 Batch F1: 0.0
Epoch:  816        3 Batch loss: 0.230900 Batch F1: 0.0
Epoch:  816        4 Batch loss: 0.233183 Batch F1: 0.0
Epoch:  816        5 Batch loss: 0.240235 Batch F1: 0.0
Epoch:  816        6 Batch loss: 0.232270 Batch F1: 0.0
Epoch:  816        7 Batch loss: 0.229292 Batch F1: 0.0
Epoch:  816        8 Batch loss: 0.235082 Batch F1: 0.0
Epoch:  816        9 Batch loss: 0.192109 Batch F1: 0.0
Epoch:  816       10 Batch loss: 0.211321 Batch F1: 0.0
Epoch:  816       11 Batch loss: 0.260714 Batch F1: 0.0
Epoch:  816       12 Batch loss: 0.203653 Batch F1: 0.0
Train Avg Loss  816: 0.227290

Train Avg F1  816: 0.0

Val Avg Loss  816: 0.217318

Val Avg F1  816:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 817
--------------------------------------------------------------
Epoch:  817        1 Batch loss: 0.242949 Batch F1: 0.0
Epoch:  817        2 Batch loss: 0.226567 Batch F1: 0.0
Epoch:  817        3 Batch loss: 0.235576 Batch F1: 0.0
Epoch:  817        4 Batch loss: 0.219305 Batch F1: 0.0
Epoch:  817        5 Batch loss: 0.222829 Batch F1: 0.0
Epoch:  817        6 Batch loss: 0.246394 Batch F1: 0.0
Epoch:  817        7 Batch loss: 0.235725 Batch F1: 0.0
Epoch:  817        8 Batch loss: 0.249336 Batch F1: 0.0
Epoch:  817        9 Batch loss: 0.188579 Batch F1: 0.5217391304347826
Epoch:  817       10 Batch loss: 0.246790 Batch F1: 0.2962962962962963
Epoch:  817       11 Batch loss: 0.215891 Batch F1: 0.5
Epoch:  817       12 Batch loss: 0.194924 Batch F1: 0.0
Train Avg Loss  817: 0.227072

Train Avg F1  817: 0.10983628556092324

Val Avg Loss  817: 0.217971

Val Avg F1  817:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 818
--------------------------------------------------------------
Epoch:  818        1 Batch loss: 0.201356 Batch F1: 0.0
Epoch:  818        2 Batch loss: 0.226542 Batch F1: 0.0
Epoch:  818        3 Batch loss: 0.244586 Batch F1: 0.0
Epoch:  818        4 Batch loss: 0.211683 Batch F1: 0.0
Epoch:  818        5 Batch loss: 0.263080 Batch F1: 0.0
Epoch:  818        6 Batch loss: 0.230383 Batch F1: 0.0
Epoch:  818        7 Batch loss: 0.252763 Batch F1: 0.0
Epoch:  818        8 Batch loss: 0.213471 Batch F1: 0.0
Epoch:  818        9 Batch loss: 0.197273 Batch F1: 0.0
Epoch:  818       10 Batch loss: 0.265717 Batch F1: 0.0
Epoch:  818       11 Batch loss: 0.234529 Batch F1: 0.0
Epoch:  818       12 Batch loss: 0.221207 Batch F1: 0.0
Train Avg Loss  818: 0.230216

Train Avg F1  818: 0.0

Val Avg Loss  818: 0.222945

Val Avg F1  818:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 819
--------------------------------------------------------------
Epoch:  819        1 Batch loss: 0.229279 Batch F1: 0.0
Epoch:  819        2 Batch loss: 0.222276 Batch F1: 0.0
Epoch:  819        3 Batch loss: 0.188276 Batch F1: 0.0
Epoch:  819        4 Batch loss: 0.221969 Batch F1: 0.0
Epoch:  819        5 Batch loss: 0.259636 Batch F1: 0.0
Epoch:  819        6 Batch loss: 0.228938 Batch F1: 0.0
Epoch:  819        7 Batch loss: 0.222780 Batch F1: 0.0
Epoch:  819        8 Batch loss: 0.225317 Batch F1: 0.0
Epoch:  819        9 Batch loss: 0.264207 Batch F1: 0.0
Epoch:  819       10 Batch loss: 0.218228 Batch F1: 0.0
Epoch:  819       11 Batch loss: 0.214882 Batch F1: 0.0
Epoch:  819       12 Batch loss: 0.254598 Batch F1: 0.0
Train Avg Loss  819: 0.229199

Train Avg F1  819: 0.0

Val Avg Loss  819: 0.220599

Val Avg F1  819:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 820
--------------------------------------------------------------
Epoch:  820        1 Batch loss: 0.238593 Batch F1: 0.0
Epoch:  820        2 Batch loss: 0.233964 Batch F1: 0.0
Epoch:  820        3 Batch loss: 0.235627 Batch F1: 0.0
Epoch:  820        4 Batch loss: 0.220913 Batch F1: 0.0
Epoch:  820        5 Batch loss: 0.225695 Batch F1: 0.0
Epoch:  820        6 Batch loss: 0.222830 Batch F1: 0.0
Epoch:  820        7 Batch loss: 0.220854 Batch F1: 0.0
Epoch:  820        8 Batch loss: 0.200003 Batch F1: 0.0
Epoch:  820        9 Batch loss: 0.202556 Batch F1: 0.0
Epoch:  820       10 Batch loss: 0.262594 Batch F1: 0.0
Epoch:  820       11 Batch loss: 0.244838 Batch F1: 0.0
Epoch:  820       12 Batch loss: 0.248110 Batch F1: 0.0
Train Avg Loss  820: 0.229715

Train Avg F1  820: 0.0

Val Avg Loss  820: 0.223157

Val Avg F1  820:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 821
--------------------------------------------------------------
Epoch:  821        1 Batch loss: 0.229121 Batch F1: 0.0
Epoch:  821        2 Batch loss: 0.238180 Batch F1: 0.0
Epoch:  821        3 Batch loss: 0.250523 Batch F1: 0.0
Epoch:  821        4 Batch loss: 0.239360 Batch F1: 0.0
Epoch:  821        5 Batch loss: 0.213012 Batch F1: 0.0
Epoch:  821        6 Batch loss: 0.226950 Batch F1: 0.0
Epoch:  821        7 Batch loss: 0.212592 Batch F1: 0.0
Epoch:  821        8 Batch loss: 0.262961 Batch F1: 0.0
Epoch:  821        9 Batch loss: 0.230280 Batch F1: 0.0
Epoch:  821       10 Batch loss: 0.219757 Batch F1: 0.0
Epoch:  821       11 Batch loss: 0.238201 Batch F1: 0.0
Epoch:  821       12 Batch loss: 0.220985 Batch F1: 0.0
Train Avg Loss  821: 0.231827

Train Avg F1  821: 0.0

Val Avg Loss  821: 0.222275

Val Avg F1  821:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 822
--------------------------------------------------------------
Epoch:  822        1 Batch loss: 0.231824 Batch F1: 0.0
Epoch:  822        2 Batch loss: 0.247313 Batch F1: 0.0
Epoch:  822        3 Batch loss: 0.203260 Batch F1: 0.0
Epoch:  822        4 Batch loss: 0.217474 Batch F1: 0.0
Epoch:  822        5 Batch loss: 0.229989 Batch F1: 0.0
Epoch:  822        6 Batch loss: 0.224374 Batch F1: 0.0
Epoch:  822        7 Batch loss: 0.211288 Batch F1: 0.0
Epoch:  822        8 Batch loss: 0.300891 Batch F1: 0.0
Epoch:  822        9 Batch loss: 0.239318 Batch F1: 0.0
Epoch:  822       10 Batch loss: 0.229204 Batch F1: 0.0
Epoch:  822       11 Batch loss: 0.234473 Batch F1: 0.08333333333333333
Epoch:  822       12 Batch loss: 0.211909 Batch F1: 0.28571428571428575
Train Avg Loss  822: 0.231776

Train Avg F1  822: 0.030753968253968256

Val Avg Loss  822: 0.221861

Val Avg F1  822:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 823
--------------------------------------------------------------
Epoch:  823        1 Batch loss: 0.228999 Batch F1: 0.0
Epoch:  823        2 Batch loss: 0.212384 Batch F1: 0.0
Epoch:  823        3 Batch loss: 0.250345 Batch F1: 0.0
Epoch:  823        4 Batch loss: 0.204418 Batch F1: 0.0
Epoch:  823        5 Batch loss: 0.251790 Batch F1: 0.0
Epoch:  823        6 Batch loss: 0.261990 Batch F1: 0.0
Epoch:  823        7 Batch loss: 0.232413 Batch F1: 0.0
Epoch:  823        8 Batch loss: 0.254169 Batch F1: 0.0
Epoch:  823        9 Batch loss: 0.201162 Batch F1: 0.0
Epoch:  823       10 Batch loss: 0.206610 Batch F1: 0.0
Epoch:  823       11 Batch loss: 0.239724 Batch F1: 0.0
Epoch:  823       12 Batch loss: 0.189099 Batch F1: 0.0
Train Avg Loss  823: 0.227759

Train Avg F1  823: 0.0

Val Avg Loss  823: 0.218592

Val Avg F1  823:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 824
--------------------------------------------------------------
Epoch:  824        1 Batch loss: 0.203082 Batch F1: 0.0
Epoch:  824        2 Batch loss: 0.251467 Batch F1: 0.0
Epoch:  824        3 Batch loss: 0.208068 Batch F1: 0.0
Epoch:  824        4 Batch loss: 0.249463 Batch F1: 0.0
Epoch:  824        5 Batch loss: 0.248158 Batch F1: 0.0
Epoch:  824        6 Batch loss: 0.239694 Batch F1: 0.0
Epoch:  824        7 Batch loss: 0.234859 Batch F1: 0.0
Epoch:  824        8 Batch loss: 0.221887 Batch F1: 0.0
Epoch:  824        9 Batch loss: 0.217599 Batch F1: 0.0
Epoch:  824       10 Batch loss: 0.231614 Batch F1: 0.0
Epoch:  824       11 Batch loss: 0.231154 Batch F1: 0.0
Epoch:  824       12 Batch loss: 0.218296 Batch F1: 0.0
Train Avg Loss  824: 0.229612

Train Avg F1  824: 0.0

Val Avg Loss  824: 0.220915

Val Avg F1  824:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 825
--------------------------------------------------------------
Epoch:  825        1 Batch loss: 0.217030 Batch F1: 0.0
Epoch:  825        2 Batch loss: 0.216315 Batch F1: 0.0
Epoch:  825        3 Batch loss: 0.236366 Batch F1: 0.0
Epoch:  825        4 Batch loss: 0.233682 Batch F1: 0.0
Epoch:  825        5 Batch loss: 0.194252 Batch F1: 0.0
Epoch:  825        6 Batch loss: 0.226553 Batch F1: 0.0
Epoch:  825        7 Batch loss: 0.228846 Batch F1: 0.0
Epoch:  825        8 Batch loss: 0.229337 Batch F1: 0.0
Epoch:  825        9 Batch loss: 0.275778 Batch F1: 0.0
Epoch:  825       10 Batch loss: 0.223523 Batch F1: 0.0
Epoch:  825       11 Batch loss: 0.236073 Batch F1: 0.0
Epoch:  825       12 Batch loss: 0.218798 Batch F1: 0.0
Train Avg Loss  825: 0.228046

Train Avg F1  825: 0.0

Val Avg Loss  825: 0.219083

Val Avg F1  825:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 826
--------------------------------------------------------------
Epoch:  826        1 Batch loss: 0.239978 Batch F1: 0.0
Epoch:  826        2 Batch loss: 0.209621 Batch F1: 0.0
Epoch:  826        3 Batch loss: 0.221867 Batch F1: 0.0
Epoch:  826        4 Batch loss: 0.209372 Batch F1: 0.0
Epoch:  826        5 Batch loss: 0.264958 Batch F1: 0.0
Epoch:  826        6 Batch loss: 0.230664 Batch F1: 0.0
Epoch:  826        7 Batch loss: 0.188525 Batch F1: 0.0
Epoch:  826        8 Batch loss: 0.245784 Batch F1: 0.0
Epoch:  826        9 Batch loss: 0.225723 Batch F1: 0.0
Epoch:  826       10 Batch loss: 0.255256 Batch F1: 0.0
Epoch:  826       11 Batch loss: 0.220207 Batch F1: 0.0
Epoch:  826       12 Batch loss: 0.210271 Batch F1: 0.0
Train Avg Loss  826: 0.226852

Train Avg F1  826: 0.0

Val Avg Loss  826: 0.218244

Val Avg F1  826:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 827
--------------------------------------------------------------
Epoch:  827        1 Batch loss: 0.252852 Batch F1: 0.0
Epoch:  827        2 Batch loss: 0.232674 Batch F1: 0.5
Epoch:  827        3 Batch loss: 0.205329 Batch F1: 0.34782608695652173
Epoch:  827        4 Batch loss: 0.234956 Batch F1: 0.26666666666666666
Epoch:  827        5 Batch loss: 0.244811 Batch F1: 0.2758620689655173
Epoch:  827        6 Batch loss: 0.220811 Batch F1: 0.25
Epoch:  827        7 Batch loss: 0.230088 Batch F1: 0.0
Epoch:  827        8 Batch loss: 0.253795 Batch F1: 0.0
Epoch:  827        9 Batch loss: 0.217446 Batch F1: 0.0
Epoch:  827       10 Batch loss: 0.210369 Batch F1: 0.0
Epoch:  827       11 Batch loss: 0.195541 Batch F1: 0.0
Epoch:  827       12 Batch loss: 0.212087 Batch F1: 0.0
Train Avg Loss  827: 0.225897

Train Avg F1  827: 0.13669623521572546

Val Avg Loss  827: 0.218555

Val Avg F1  827:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 828
--------------------------------------------------------------
Epoch:  828        1 Batch loss: 0.204170 Batch F1: 0.0
Epoch:  828        2 Batch loss: 0.238321 Batch F1: 0.0
Epoch:  828        3 Batch loss: 0.231325 Batch F1: 0.0
Epoch:  828        4 Batch loss: 0.240633 Batch F1: 0.0
Epoch:  828        5 Batch loss: 0.222151 Batch F1: 0.0
Epoch:  828        6 Batch loss: 0.220470 Batch F1: 0.0
Epoch:  828        7 Batch loss: 0.234646 Batch F1: 0.0
Epoch:  828        8 Batch loss: 0.213786 Batch F1: 0.1
Epoch:  828        9 Batch loss: 0.212435 Batch F1: 0.0
Epoch:  828       10 Batch loss: 0.235606 Batch F1: 0.0
Epoch:  828       11 Batch loss: 0.259914 Batch F1: 0.0
Epoch:  828       12 Batch loss: 0.252669 Batch F1: 0.0
Train Avg Loss  828: 0.230511

Train Avg F1  828: 0.008333333333333333

Val Avg Loss  828: 0.218105

Val Avg F1  828:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 829
--------------------------------------------------------------
Epoch:  829        1 Batch loss: 0.206454 Batch F1: 0.0
Epoch:  829        2 Batch loss: 0.227772 Batch F1: 0.0
Epoch:  829        3 Batch loss: 0.240365 Batch F1: 0.0
Epoch:  829        4 Batch loss: 0.241980 Batch F1: 0.0
Epoch:  829        5 Batch loss: 0.230822 Batch F1: 0.0
Epoch:  829        6 Batch loss: 0.217595 Batch F1: 0.0
Epoch:  829        7 Batch loss: 0.237797 Batch F1: 0.0
Epoch:  829        8 Batch loss: 0.239383 Batch F1: 0.0
Epoch:  829        9 Batch loss: 0.235371 Batch F1: 0.0
Epoch:  829       10 Batch loss: 0.239871 Batch F1: 0.0
Epoch:  829       11 Batch loss: 0.206925 Batch F1: 0.0
Epoch:  829       12 Batch loss: 0.226205 Batch F1: 0.0
Train Avg Loss  829: 0.229212

Train Avg F1  829: 0.0

Val Avg Loss  829: 0.220050

Val Avg F1  829:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 830
--------------------------------------------------------------
Epoch:  830        1 Batch loss: 0.261297 Batch F1: 0.0
Epoch:  830        2 Batch loss: 0.200954 Batch F1: 0.0
Epoch:  830        3 Batch loss: 0.229458 Batch F1: 0.0
Epoch:  830        4 Batch loss: 0.243325 Batch F1: 0.0
Epoch:  830        5 Batch loss: 0.206631 Batch F1: 0.0
Epoch:  830        6 Batch loss: 0.243965 Batch F1: 0.0
Epoch:  830        7 Batch loss: 0.187825 Batch F1: 0.0
Epoch:  830        8 Batch loss: 0.235246 Batch F1: 0.0
Epoch:  830        9 Batch loss: 0.227894 Batch F1: 0.0
Epoch:  830       10 Batch loss: 0.217212 Batch F1: 0.0
Epoch:  830       11 Batch loss: 0.262529 Batch F1: 0.0
Epoch:  830       12 Batch loss: 0.202512 Batch F1: 0.0
Train Avg Loss  830: 0.226571

Train Avg F1  830: 0.0

Val Avg Loss  830: 0.218219

Val Avg F1  830:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 831
--------------------------------------------------------------
Epoch:  831        1 Batch loss: 0.201978 Batch F1: 0.0
Epoch:  831        2 Batch loss: 0.225587 Batch F1: 0.0
Epoch:  831        3 Batch loss: 0.198689 Batch F1: 0.0
Epoch:  831        4 Batch loss: 0.224058 Batch F1: 0.0
Epoch:  831        5 Batch loss: 0.218798 Batch F1: 0.0
Epoch:  831        6 Batch loss: 0.210672 Batch F1: 0.0
Epoch:  831        7 Batch loss: 0.177628 Batch F1: 0.0
Epoch:  831        8 Batch loss: 0.283454 Batch F1: 0.0
Epoch:  831        9 Batch loss: 0.269610 Batch F1: 0.0
Epoch:  831       10 Batch loss: 0.270654 Batch F1: 0.0
Epoch:  831       11 Batch loss: 0.225344 Batch F1: 0.0
Epoch:  831       12 Batch loss: 0.241350 Batch F1: 0.0
Train Avg Loss  831: 0.228985

Train Avg F1  831: 0.0

Val Avg Loss  831: 0.220992

Val Avg F1  831:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 832
--------------------------------------------------------------
Epoch:  832        1 Batch loss: 0.245665 Batch F1: 0.0
Epoch:  832        2 Batch loss: 0.198880 Batch F1: 0.0
Epoch:  832        3 Batch loss: 0.230509 Batch F1: 0.0
Epoch:  832        4 Batch loss: 0.209851 Batch F1: 0.0
Epoch:  832        5 Batch loss: 0.202166 Batch F1: 0.0
Epoch:  832        6 Batch loss: 0.209973 Batch F1: 0.0
Epoch:  832        7 Batch loss: 0.203531 Batch F1: 0.0
Epoch:  832        8 Batch loss: 0.270818 Batch F1: 0.0
Epoch:  832        9 Batch loss: 0.278811 Batch F1: 0.0
Epoch:  832       10 Batch loss: 0.254086 Batch F1: 0.0
Epoch:  832       11 Batch loss: 0.222278 Batch F1: 0.0
Epoch:  832       12 Batch loss: 0.243409 Batch F1: 0.16666666666666666
Train Avg Loss  832: 0.230831

Train Avg F1  832: 0.013888888888888888

Val Avg Loss  832: 0.225491

Val Avg F1  832:  0.3674660685530251

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 833
--------------------------------------------------------------
Epoch:  833        1 Batch loss: 0.220606 Batch F1: 0.3478260869565218
Epoch:  833        2 Batch loss: 0.225499 Batch F1: 0.0
Epoch:  833        3 Batch loss: 0.229929 Batch F1: 0.0
Epoch:  833        4 Batch loss: 0.213309 Batch F1: 0.0
Epoch:  833        5 Batch loss: 0.226357 Batch F1: 0.0
Epoch:  833        6 Batch loss: 0.227685 Batch F1: 0.0
Epoch:  833        7 Batch loss: 0.264101 Batch F1: 0.0
Epoch:  833        8 Batch loss: 0.253063 Batch F1: 0.0
Epoch:  833        9 Batch loss: 0.197580 Batch F1: 0.0
Epoch:  833       10 Batch loss: 0.225508 Batch F1: 0.0
Epoch:  833       11 Batch loss: 0.234533 Batch F1: 0.0
Epoch:  833       12 Batch loss: 0.219363 Batch F1: 0.0
Train Avg Loss  833: 0.228128

Train Avg F1  833: 0.028985507246376815

Val Avg Loss  833: 0.218307

Val Avg F1  833:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 834
--------------------------------------------------------------
Epoch:  834        1 Batch loss: 0.211307 Batch F1: 0.0
Epoch:  834        2 Batch loss: 0.249492 Batch F1: 0.0
Epoch:  834        3 Batch loss: 0.239618 Batch F1: 0.0
Epoch:  834        4 Batch loss: 0.224148 Batch F1: 0.0
Epoch:  834        5 Batch loss: 0.221412 Batch F1: 0.0
Epoch:  834        6 Batch loss: 0.218184 Batch F1: 0.0
Epoch:  834        7 Batch loss: 0.233772 Batch F1: 0.0
Epoch:  834        8 Batch loss: 0.238983 Batch F1: 0.0
Epoch:  834        9 Batch loss: 0.251842 Batch F1: 0.0
Epoch:  834       10 Batch loss: 0.247170 Batch F1: 0.0
Epoch:  834       11 Batch loss: 0.195207 Batch F1: 0.0
Epoch:  834       12 Batch loss: 0.201025 Batch F1: 0.0
Train Avg Loss  834: 0.227680

Train Avg F1  834: 0.0

Val Avg Loss  834: 0.219076

Val Avg F1  834:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 835
--------------------------------------------------------------
Epoch:  835        1 Batch loss: 0.195724 Batch F1: 0.0
Epoch:  835        2 Batch loss: 0.211774 Batch F1: 0.0
Epoch:  835        3 Batch loss: 0.196627 Batch F1: 0.0
Epoch:  835        4 Batch loss: 0.209532 Batch F1: 0.0
Epoch:  835        5 Batch loss: 0.212716 Batch F1: 0.0
Epoch:  835        6 Batch loss: 0.233887 Batch F1: 0.0
Epoch:  835        7 Batch loss: 0.223304 Batch F1: 0.0
Epoch:  835        8 Batch loss: 0.247013 Batch F1: 0.0
Epoch:  835        9 Batch loss: 0.258666 Batch F1: 0.0
Epoch:  835       10 Batch loss: 0.235408 Batch F1: 0.0
Epoch:  835       11 Batch loss: 0.247636 Batch F1: 0.0
Epoch:  835       12 Batch loss: 0.246847 Batch F1: 0.0
Train Avg Loss  835: 0.226595

Train Avg F1  835: 0.0

Val Avg Loss  835: 0.226702

Val Avg F1  835:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 836
--------------------------------------------------------------
Epoch:  836        1 Batch loss: 0.229448 Batch F1: 0.0
Epoch:  836        2 Batch loss: 0.256099 Batch F1: 0.3333333333333333
Epoch:  836        3 Batch loss: 0.229054 Batch F1: 0.5333333333333333
Epoch:  836        4 Batch loss: 0.232725 Batch F1: 0.33333333333333337
Epoch:  836        5 Batch loss: 0.223802 Batch F1: 0.0
Epoch:  836        6 Batch loss: 0.218048 Batch F1: 0.0
Epoch:  836        7 Batch loss: 0.249664 Batch F1: 0.0
Epoch:  836        8 Batch loss: 0.240388 Batch F1: 0.0
Epoch:  836        9 Batch loss: 0.228505 Batch F1: 0.0
Epoch:  836       10 Batch loss: 0.237780 Batch F1: 0.0
Epoch:  836       11 Batch loss: 0.203855 Batch F1: 0.0
Epoch:  836       12 Batch loss: 0.220981 Batch F1: 0.0
Train Avg Loss  836: 0.230862

Train Avg F1  836: 0.10000000000000002

Val Avg Loss  836: 0.217418

Val Avg F1  836:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 837
--------------------------------------------------------------
Epoch:  837        1 Batch loss: 0.220083 Batch F1: 0.0
Epoch:  837        2 Batch loss: 0.235792 Batch F1: 0.0
Epoch:  837        3 Batch loss: 0.215914 Batch F1: 0.0
Epoch:  837        4 Batch loss: 0.226519 Batch F1: 0.0
Epoch:  837        5 Batch loss: 0.217291 Batch F1: 0.0
Epoch:  837        6 Batch loss: 0.238736 Batch F1: 0.0
Epoch:  837        7 Batch loss: 0.201421 Batch F1: 0.0
Epoch:  837        8 Batch loss: 0.226587 Batch F1: 0.0
Epoch:  837        9 Batch loss: 0.234275 Batch F1: 0.0
Epoch:  837       10 Batch loss: 0.239721 Batch F1: 0.0
Epoch:  837       11 Batch loss: 0.240897 Batch F1: 0.4
Epoch:  837       12 Batch loss: 0.230828 Batch F1: 0.2857142857142857
Train Avg Loss  837: 0.227339

Train Avg F1  837: 0.05714285714285714

Val Avg Loss  837: 0.225429

Val Avg F1  837:  0.43935973189875654

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 838
--------------------------------------------------------------
Epoch:  838        1 Batch loss: 0.237447 Batch F1: 0.5365853658536585
Epoch:  838        2 Batch loss: 0.201761 Batch F1: 0.4545454545454546
Epoch:  838        3 Batch loss: 0.213490 Batch F1: 0.4166666666666667
Epoch:  838        4 Batch loss: 0.235267 Batch F1: 0.0
Epoch:  838        5 Batch loss: 0.226253 Batch F1: 0.0
Epoch:  838        6 Batch loss: 0.303654 Batch F1: 0.0
Epoch:  838        7 Batch loss: 0.203944 Batch F1: 0.0
Epoch:  838        8 Batch loss: 0.225553 Batch F1: 0.0
Epoch:  838        9 Batch loss: 0.191819 Batch F1: 0.0
Epoch:  838       10 Batch loss: 0.201769 Batch F1: 0.0
Epoch:  838       11 Batch loss: 0.232972 Batch F1: 0.0
Epoch:  838       12 Batch loss: 0.252603 Batch F1: 0.0
Train Avg Loss  838: 0.227211

Train Avg F1  838: 0.11731645725548163

Val Avg Loss  838: 0.217651

Val Avg F1  838:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 839
--------------------------------------------------------------
Epoch:  839        1 Batch loss: 0.196181 Batch F1: 0.0
Epoch:  839        2 Batch loss: 0.237260 Batch F1: 0.0
Epoch:  839        3 Batch loss: 0.211687 Batch F1: 0.0
Epoch:  839        4 Batch loss: 0.254170 Batch F1: 0.0
Epoch:  839        5 Batch loss: 0.204542 Batch F1: 0.0
Epoch:  839        6 Batch loss: 0.222603 Batch F1: 0.0
Epoch:  839        7 Batch loss: 0.228259 Batch F1: 0.0
Epoch:  839        8 Batch loss: 0.248812 Batch F1: 0.0
Epoch:  839        9 Batch loss: 0.239590 Batch F1: 0.0
Epoch:  839       10 Batch loss: 0.234005 Batch F1: 0.0
Epoch:  839       11 Batch loss: 0.219417 Batch F1: 0.0
Epoch:  839       12 Batch loss: 0.227760 Batch F1: 0.0
Train Avg Loss  839: 0.227024

Train Avg F1  839: 0.0

Val Avg Loss  839: 0.218358

Val Avg F1  839:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 840
--------------------------------------------------------------
Epoch:  840        1 Batch loss: 0.214336 Batch F1: 0.0
Epoch:  840        2 Batch loss: 0.217098 Batch F1: 0.0
Epoch:  840        3 Batch loss: 0.208288 Batch F1: 0.0
Epoch:  840        4 Batch loss: 0.215219 Batch F1: 0.0
Epoch:  840        5 Batch loss: 0.255502 Batch F1: 0.0
Epoch:  840        6 Batch loss: 0.241174 Batch F1: 0.0
Epoch:  840        7 Batch loss: 0.234190 Batch F1: 0.0
Epoch:  840        8 Batch loss: 0.210571 Batch F1: 0.0
Epoch:  840        9 Batch loss: 0.233703 Batch F1: 0.0
Epoch:  840       10 Batch loss: 0.197765 Batch F1: 0.0
Epoch:  840       11 Batch loss: 0.239489 Batch F1: 0.0
Epoch:  840       12 Batch loss: 0.256496 Batch F1: 0.0
Train Avg Loss  840: 0.226986

Train Avg F1  840: 0.0

Val Avg Loss  840: 0.217997

Val Avg F1  840:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 841
--------------------------------------------------------------
Epoch:  841        1 Batch loss: 0.235193 Batch F1: 0.0
Epoch:  841        2 Batch loss: 0.178720 Batch F1: 0.0
Epoch:  841        3 Batch loss: 0.243635 Batch F1: 0.0
Epoch:  841        4 Batch loss: 0.211299 Batch F1: 0.0
Epoch:  841        5 Batch loss: 0.253532 Batch F1: 0.0
Epoch:  841        6 Batch loss: 0.198739 Batch F1: 0.0
Epoch:  841        7 Batch loss: 0.254151 Batch F1: 0.0
Epoch:  841        8 Batch loss: 0.264822 Batch F1: 0.0
Epoch:  841        9 Batch loss: 0.208088 Batch F1: 0.0
Epoch:  841       10 Batch loss: 0.224668 Batch F1: 0.0
Epoch:  841       11 Batch loss: 0.209934 Batch F1: 0.0
Epoch:  841       12 Batch loss: 0.233547 Batch F1: 0.0
Train Avg Loss  841: 0.226361

Train Avg F1  841: 0.0

Val Avg Loss  841: 0.217993

Val Avg F1  841:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 842
--------------------------------------------------------------
Epoch:  842        1 Batch loss: 0.243866 Batch F1: 0.0
Epoch:  842        2 Batch loss: 0.215268 Batch F1: 0.0
Epoch:  842        3 Batch loss: 0.202110 Batch F1: 0.0
Epoch:  842        4 Batch loss: 0.238164 Batch F1: 0.0
Epoch:  842        5 Batch loss: 0.249178 Batch F1: 0.0
Epoch:  842        6 Batch loss: 0.202079 Batch F1: 0.0
Epoch:  842        7 Batch loss: 0.220356 Batch F1: 0.0
Epoch:  842        8 Batch loss: 0.192349 Batch F1: 0.0
Epoch:  842        9 Batch loss: 0.270202 Batch F1: 0.0
Epoch:  842       10 Batch loss: 0.233365 Batch F1: 0.0
Epoch:  842       11 Batch loss: 0.206924 Batch F1: 0.0
Epoch:  842       12 Batch loss: 0.238795 Batch F1: 0.0
Train Avg Loss  842: 0.226055

Train Avg F1  842: 0.0

Val Avg Loss  842: 0.217633

Val Avg F1  842:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 843
--------------------------------------------------------------
Epoch:  843        1 Batch loss: 0.268713 Batch F1: 0.0
Epoch:  843        2 Batch loss: 0.200148 Batch F1: 0.0
Epoch:  843        3 Batch loss: 0.214939 Batch F1: 0.0
Epoch:  843        4 Batch loss: 0.223337 Batch F1: 0.0
Epoch:  843        5 Batch loss: 0.226800 Batch F1: 0.0
Epoch:  843        6 Batch loss: 0.204790 Batch F1: 0.0
Epoch:  843        7 Batch loss: 0.233698 Batch F1: 0.0
Epoch:  843        8 Batch loss: 0.211402 Batch F1: 0.0
Epoch:  843        9 Batch loss: 0.198527 Batch F1: 0.0
Epoch:  843       10 Batch loss: 0.245844 Batch F1: 0.0
Epoch:  843       11 Batch loss: 0.243773 Batch F1: 0.0
Epoch:  843       12 Batch loss: 0.248342 Batch F1: 0.0
Train Avg Loss  843: 0.226693

Train Avg F1  843: 0.0

Val Avg Loss  843: 0.217986

Val Avg F1  843:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 844
--------------------------------------------------------------
Epoch:  844        1 Batch loss: 0.224418 Batch F1: 0.0
Epoch:  844        2 Batch loss: 0.225328 Batch F1: 0.0
Epoch:  844        3 Batch loss: 0.223701 Batch F1: 0.0
Epoch:  844        4 Batch loss: 0.234246 Batch F1: 0.0
Epoch:  844        5 Batch loss: 0.229196 Batch F1: 0.0
Epoch:  844        6 Batch loss: 0.210309 Batch F1: 0.3478260869565218
Epoch:  844        7 Batch loss: 0.234628 Batch F1: 0.36363636363636365
Epoch:  844        8 Batch loss: 0.270671 Batch F1: 0.25000000000000006
Epoch:  844        9 Batch loss: 0.197705 Batch F1: 0.25
Epoch:  844       10 Batch loss: 0.235787 Batch F1: 0.0
Epoch:  844       11 Batch loss: 0.226336 Batch F1: 0.0
Epoch:  844       12 Batch loss: 0.194402 Batch F1: 0.0
Train Avg Loss  844: 0.225561

Train Avg F1  844: 0.10095520421607379

Val Avg Loss  844: 0.217075

Val Avg F1  844:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 845
--------------------------------------------------------------
Epoch:  845        1 Batch loss: 0.236171 Batch F1: 0.0
Epoch:  845        2 Batch loss: 0.220832 Batch F1: 0.0
Epoch:  845        3 Batch loss: 0.256480 Batch F1: 0.0
Epoch:  845        4 Batch loss: 0.206895 Batch F1: 0.0
Epoch:  845        5 Batch loss: 0.267282 Batch F1: 0.0
Epoch:  845        6 Batch loss: 0.215815 Batch F1: 0.0
Epoch:  845        7 Batch loss: 0.245676 Batch F1: 0.0
Epoch:  845        8 Batch loss: 0.226202 Batch F1: 0.0
Epoch:  845        9 Batch loss: 0.213063 Batch F1: 0.0
Epoch:  845       10 Batch loss: 0.193419 Batch F1: 0.0
Epoch:  845       11 Batch loss: 0.240656 Batch F1: 0.0
Epoch:  845       12 Batch loss: 0.207996 Batch F1: 0.0
Train Avg Loss  845: 0.227541

Train Avg F1  845: 0.0

Val Avg Loss  845: 0.217574

Val Avg F1  845:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 846
--------------------------------------------------------------
Epoch:  846        1 Batch loss: 0.238362 Batch F1: 0.0
Epoch:  846        2 Batch loss: 0.244868 Batch F1: 0.0
Epoch:  846        3 Batch loss: 0.237390 Batch F1: 0.0
Epoch:  846        4 Batch loss: 0.229995 Batch F1: 0.0
Epoch:  846        5 Batch loss: 0.217432 Batch F1: 0.0
Epoch:  846        6 Batch loss: 0.240071 Batch F1: 0.0
Epoch:  846        7 Batch loss: 0.221799 Batch F1: 0.41379310344827586
Epoch:  846        8 Batch loss: 0.235158 Batch F1: 0.24
Epoch:  846        9 Batch loss: 0.223610 Batch F1: 0.0
Epoch:  846       10 Batch loss: 0.216249 Batch F1: 0.0
Epoch:  846       11 Batch loss: 0.221640 Batch F1: 0.0
Epoch:  846       12 Batch loss: 0.186017 Batch F1: 0.0
Train Avg Loss  846: 0.226049

Train Avg F1  846: 0.05448275862068965

Val Avg Loss  846: 0.217534

Val Avg F1  846:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 847
--------------------------------------------------------------
Epoch:  847        1 Batch loss: 0.208768 Batch F1: 0.0
Epoch:  847        2 Batch loss: 0.177489 Batch F1: 0.0
Epoch:  847        3 Batch loss: 0.245379 Batch F1: 0.0
Epoch:  847        4 Batch loss: 0.177175 Batch F1: 0.0
Epoch:  847        5 Batch loss: 0.300192 Batch F1: 0.0
Epoch:  847        6 Batch loss: 0.206235 Batch F1: 0.0
Epoch:  847        7 Batch loss: 0.227948 Batch F1: 0.0
Epoch:  847        8 Batch loss: 0.226239 Batch F1: 0.0
Epoch:  847        9 Batch loss: 0.234280 Batch F1: 0.0
Epoch:  847       10 Batch loss: 0.228349 Batch F1: 0.0
Epoch:  847       11 Batch loss: 0.258674 Batch F1: 0.0
Epoch:  847       12 Batch loss: 0.254640 Batch F1: 0.0
Train Avg Loss  847: 0.228781

Train Avg F1  847: 0.0

Val Avg Loss  847: 0.233393

Val Avg F1  847:  0.34112318840579714

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 848
--------------------------------------------------------------
Epoch:  848        1 Batch loss: 0.243497 Batch F1: 0.17391304347826086
Epoch:  848        2 Batch loss: 0.243391 Batch F1: 0.4375
Epoch:  848        3 Batch loss: 0.240687 Batch F1: 0.5142857142857143
Epoch:  848        4 Batch loss: 0.241602 Batch F1: 0.0
Epoch:  848        5 Batch loss: 0.225232 Batch F1: 0.0
Epoch:  848        6 Batch loss: 0.249821 Batch F1: 0.0
Epoch:  848        7 Batch loss: 0.231260 Batch F1: 0.0
Epoch:  848        8 Batch loss: 0.252345 Batch F1: 0.0
Epoch:  848        9 Batch loss: 0.188569 Batch F1: 0.0
Epoch:  848       10 Batch loss: 0.211866 Batch F1: 0.0
Epoch:  848       11 Batch loss: 0.250283 Batch F1: 0.0
Epoch:  848       12 Batch loss: 0.217857 Batch F1: 0.0
Train Avg Loss  848: 0.233034

Train Avg F1  848: 0.0938082298136646

Val Avg Loss  848: 0.218303

Val Avg F1  848:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 849
--------------------------------------------------------------
Epoch:  849        1 Batch loss: 0.242716 Batch F1: 0.0
Epoch:  849        2 Batch loss: 0.190425 Batch F1: 0.0
Epoch:  849        3 Batch loss: 0.252796 Batch F1: 0.0
Epoch:  849        4 Batch loss: 0.230025 Batch F1: 0.0
Epoch:  849        5 Batch loss: 0.213465 Batch F1: 0.0
Epoch:  849        6 Batch loss: 0.221116 Batch F1: 0.0
Epoch:  849        7 Batch loss: 0.232570 Batch F1: 0.0
Epoch:  849        8 Batch loss: 0.247162 Batch F1: 0.0
Epoch:  849        9 Batch loss: 0.213586 Batch F1: 0.0
Epoch:  849       10 Batch loss: 0.231026 Batch F1: 0.0
Epoch:  849       11 Batch loss: 0.238207 Batch F1: 0.0
Epoch:  849       12 Batch loss: 0.228969 Batch F1: 0.0
Train Avg Loss  849: 0.228505

Train Avg F1  849: 0.0

Val Avg Loss  849: 0.220905

Val Avg F1  849:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 850
--------------------------------------------------------------
Epoch:  850        1 Batch loss: 0.238572 Batch F1: 0.0
Epoch:  850        2 Batch loss: 0.230800 Batch F1: 0.0
Epoch:  850        3 Batch loss: 0.247686 Batch F1: 0.0
Epoch:  850        4 Batch loss: 0.233757 Batch F1: 0.35714285714285715
Epoch:  850        5 Batch loss: 0.227875 Batch F1: 0.2857142857142857
Epoch:  850        6 Batch loss: 0.233752 Batch F1: 0.35714285714285715
Epoch:  850        7 Batch loss: 0.212463 Batch F1: 0.0
Epoch:  850        8 Batch loss: 0.226568 Batch F1: 0.0
Epoch:  850        9 Batch loss: 0.248203 Batch F1: 0.0
Epoch:  850       10 Batch loss: 0.212600 Batch F1: 0.0
Epoch:  850       11 Batch loss: 0.227177 Batch F1: 0.0
Epoch:  850       12 Batch loss: 0.211115 Batch F1: 0.0
Train Avg Loss  850: 0.229214

Train Avg F1  850: 0.08333333333333333

Val Avg Loss  850: 0.219306

Val Avg F1  850:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 851
--------------------------------------------------------------
Epoch:  851        1 Batch loss: 0.203171 Batch F1: 0.0
Epoch:  851        2 Batch loss: 0.226450 Batch F1: 0.0
Epoch:  851        3 Batch loss: 0.254886 Batch F1: 0.0
Epoch:  851        4 Batch loss: 0.217522 Batch F1: 0.0
Epoch:  851        5 Batch loss: 0.251021 Batch F1: 0.0
Epoch:  851        6 Batch loss: 0.248620 Batch F1: 0.0
Epoch:  851        7 Batch loss: 0.226458 Batch F1: 0.0
Epoch:  851        8 Batch loss: 0.221494 Batch F1: 0.0
Epoch:  851        9 Batch loss: 0.228517 Batch F1: 0.0
Epoch:  851       10 Batch loss: 0.227534 Batch F1: 0.0
Epoch:  851       11 Batch loss: 0.231479 Batch F1: 0.0
Epoch:  851       12 Batch loss: 0.232998 Batch F1: 0.0
Train Avg Loss  851: 0.230846

Train Avg F1  851: 0.0

Val Avg Loss  851: 0.218068

Val Avg F1  851:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 852
--------------------------------------------------------------
Epoch:  852        1 Batch loss: 0.222379 Batch F1: 0.0
Epoch:  852        2 Batch loss: 0.230873 Batch F1: 0.0
Epoch:  852        3 Batch loss: 0.220688 Batch F1: 0.0
Epoch:  852        4 Batch loss: 0.202139 Batch F1: 0.0
Epoch:  852        5 Batch loss: 0.237240 Batch F1: 0.0
Epoch:  852        6 Batch loss: 0.215725 Batch F1: 0.0
Epoch:  852        7 Batch loss: 0.216101 Batch F1: 0.0
Epoch:  852        8 Batch loss: 0.298136 Batch F1: 0.0
Epoch:  852        9 Batch loss: 0.221619 Batch F1: 0.0
Epoch:  852       10 Batch loss: 0.247668 Batch F1: 0.0
Epoch:  852       11 Batch loss: 0.233958 Batch F1: 0.0
Epoch:  852       12 Batch loss: 0.209625 Batch F1: 0.30769230769230765
Train Avg Loss  852: 0.229679

Train Avg F1  852: 0.025641025641025637

Val Avg Loss  852: 0.224551

Val Avg F1  852:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 853
--------------------------------------------------------------
Epoch:  853        1 Batch loss: 0.224505 Batch F1: 0.0
Epoch:  853        2 Batch loss: 0.250583 Batch F1: 0.0
Epoch:  853        3 Batch loss: 0.216366 Batch F1: 0.0
Epoch:  853        4 Batch loss: 0.224323 Batch F1: 0.0
Epoch:  853        5 Batch loss: 0.248631 Batch F1: 0.0
Epoch:  853        6 Batch loss: 0.225597 Batch F1: 0.0
Epoch:  853        7 Batch loss: 0.235306 Batch F1: 0.0
Epoch:  853        8 Batch loss: 0.237442 Batch F1: 0.0
Epoch:  853        9 Batch loss: 0.182009 Batch F1: 0.0
Epoch:  853       10 Batch loss: 0.198648 Batch F1: 0.0
Epoch:  853       11 Batch loss: 0.237532 Batch F1: 0.0
Epoch:  853       12 Batch loss: 0.287201 Batch F1: 0.0
Train Avg Loss  853: 0.230679

Train Avg F1  853: 0.0

Val Avg Loss  853: 0.217136

Val Avg F1  853:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 854
--------------------------------------------------------------
Epoch:  854        1 Batch loss: 0.220665 Batch F1: 0.0
Epoch:  854        2 Batch loss: 0.220507 Batch F1: 0.0
Epoch:  854        3 Batch loss: 0.211094 Batch F1: 0.0
Epoch:  854        4 Batch loss: 0.222940 Batch F1: 0.0
Epoch:  854        5 Batch loss: 0.241810 Batch F1: 0.0
Epoch:  854        6 Batch loss: 0.229309 Batch F1: 0.0
Epoch:  854        7 Batch loss: 0.207136 Batch F1: 0.0
Epoch:  854        8 Batch loss: 0.233991 Batch F1: 0.0
Epoch:  854        9 Batch loss: 0.215311 Batch F1: 0.0
Epoch:  854       10 Batch loss: 0.246870 Batch F1: 0.0
Epoch:  854       11 Batch loss: 0.251210 Batch F1: 0.0
Epoch:  854       12 Batch loss: 0.235964 Batch F1: 0.0
Train Avg Loss  854: 0.228067

Train Avg F1  854: 0.0

Val Avg Loss  854: 0.217992

Val Avg F1  854:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 855
--------------------------------------------------------------
Epoch:  855        1 Batch loss: 0.211537 Batch F1: 0.0
Epoch:  855        2 Batch loss: 0.239502 Batch F1: 0.0
Epoch:  855        3 Batch loss: 0.195096 Batch F1: 0.0
Epoch:  855        4 Batch loss: 0.282936 Batch F1: 0.0
Epoch:  855        5 Batch loss: 0.195730 Batch F1: 0.0
Epoch:  855        6 Batch loss: 0.240637 Batch F1: 0.0
Epoch:  855        7 Batch loss: 0.219485 Batch F1: 0.0
Epoch:  855        8 Batch loss: 0.215601 Batch F1: 0.0
Epoch:  855        9 Batch loss: 0.223182 Batch F1: 0.0
Epoch:  855       10 Batch loss: 0.227657 Batch F1: 0.0
Epoch:  855       11 Batch loss: 0.257197 Batch F1: 0.0
Epoch:  855       12 Batch loss: 0.209366 Batch F1: 0.0
Train Avg Loss  855: 0.226494

Train Avg F1  855: 0.0

Val Avg Loss  855: 0.217984

Val Avg F1  855:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 856
--------------------------------------------------------------
Epoch:  856        1 Batch loss: 0.238473 Batch F1: 0.0
Epoch:  856        2 Batch loss: 0.229811 Batch F1: 0.0
Epoch:  856        3 Batch loss: 0.228060 Batch F1: 0.0
Epoch:  856        4 Batch loss: 0.225113 Batch F1: 0.0
Epoch:  856        5 Batch loss: 0.216492 Batch F1: 0.0
Epoch:  856        6 Batch loss: 0.234002 Batch F1: 0.0
Epoch:  856        7 Batch loss: 0.213863 Batch F1: 0.0
Epoch:  856        8 Batch loss: 0.202317 Batch F1: 0.0
Epoch:  856        9 Batch loss: 0.223384 Batch F1: 0.0
Epoch:  856       10 Batch loss: 0.223391 Batch F1: 0.0
Epoch:  856       11 Batch loss: 0.227732 Batch F1: 0.0
Epoch:  856       12 Batch loss: 0.267326 Batch F1: 0.0
Train Avg Loss  856: 0.227497

Train Avg F1  856: 0.0

Val Avg Loss  856: 0.217345

Val Avg F1  856:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 857
--------------------------------------------------------------
Epoch:  857        1 Batch loss: 0.244208 Batch F1: 0.0
Epoch:  857        2 Batch loss: 0.202262 Batch F1: 0.0
Epoch:  857        3 Batch loss: 0.234587 Batch F1: 0.0
Epoch:  857        4 Batch loss: 0.236929 Batch F1: 0.0
Epoch:  857        5 Batch loss: 0.210252 Batch F1: 0.0
Epoch:  857        6 Batch loss: 0.206941 Batch F1: 0.0
Epoch:  857        7 Batch loss: 0.264839 Batch F1: 0.0
Epoch:  857        8 Batch loss: 0.231463 Batch F1: 0.0
Epoch:  857        9 Batch loss: 0.221105 Batch F1: 0.0
Epoch:  857       10 Batch loss: 0.231575 Batch F1: 0.0
Epoch:  857       11 Batch loss: 0.229310 Batch F1: 0.0
Epoch:  857       12 Batch loss: 0.210086 Batch F1: 0.0
Train Avg Loss  857: 0.226963

Train Avg F1  857: 0.0

Val Avg Loss  857: 0.217602

Val Avg F1  857:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 858
--------------------------------------------------------------
Epoch:  858        1 Batch loss: 0.203736 Batch F1: 0.0
Epoch:  858        2 Batch loss: 0.230076 Batch F1: 0.0
Epoch:  858        3 Batch loss: 0.198017 Batch F1: 0.0
Epoch:  858        4 Batch loss: 0.237558 Batch F1: 0.0
Epoch:  858        5 Batch loss: 0.203210 Batch F1: 0.0
Epoch:  858        6 Batch loss: 0.212780 Batch F1: 0.0
Epoch:  858        7 Batch loss: 0.223217 Batch F1: 0.0
Epoch:  858        8 Batch loss: 0.213988 Batch F1: 0.0
Epoch:  858        9 Batch loss: 0.252912 Batch F1: 0.0
Epoch:  858       10 Batch loss: 0.253431 Batch F1: 0.0
Epoch:  858       11 Batch loss: 0.232725 Batch F1: 0.0
Epoch:  858       12 Batch loss: 0.257434 Batch F1: 0.0
Train Avg Loss  858: 0.226590

Train Avg F1  858: 0.0

Val Avg Loss  858: 0.225630

Val Avg F1  858:  0.35782969951974164

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 859
--------------------------------------------------------------
Epoch:  859        1 Batch loss: 0.225536 Batch F1: 0.375
Epoch:  859        2 Batch loss: 0.216916 Batch F1: 0.6206896551724137
Epoch:  859        3 Batch loss: 0.225866 Batch F1: 0.0
Epoch:  859        4 Batch loss: 0.239645 Batch F1: 0.0
Epoch:  859        5 Batch loss: 0.206215 Batch F1: 0.0
Epoch:  859        6 Batch loss: 0.258646 Batch F1: 0.0
Epoch:  859        7 Batch loss: 0.236729 Batch F1: 0.0
Epoch:  859        8 Batch loss: 0.233291 Batch F1: 0.0
Epoch:  859        9 Batch loss: 0.228013 Batch F1: 0.38461538461538464
Epoch:  859       10 Batch loss: 0.243898 Batch F1: 0.0
Epoch:  859       11 Batch loss: 0.208934 Batch F1: 0.0
Epoch:  859       12 Batch loss: 0.232273 Batch F1: 0.0
Train Avg Loss  859: 0.229664

Train Avg F1  859: 0.11502541998231652

Val Avg Loss  859: 0.219082

Val Avg F1  859:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 860
--------------------------------------------------------------
Epoch:  860        1 Batch loss: 0.219339 Batch F1: 0.0
Epoch:  860        2 Batch loss: 0.225743 Batch F1: 0.0
Epoch:  860        3 Batch loss: 0.218370 Batch F1: 0.0
Epoch:  860        4 Batch loss: 0.231439 Batch F1: 0.0
Epoch:  860        5 Batch loss: 0.198916 Batch F1: 0.0
Epoch:  860        6 Batch loss: 0.249457 Batch F1: 0.0
Epoch:  860        7 Batch loss: 0.204296 Batch F1: 0.0
Epoch:  860        8 Batch loss: 0.214280 Batch F1: 0.0
Epoch:  860        9 Batch loss: 0.243067 Batch F1: 0.0
Epoch:  860       10 Batch loss: 0.245722 Batch F1: 0.0
Epoch:  860       11 Batch loss: 0.237087 Batch F1: 0.0
Epoch:  860       12 Batch loss: 0.242176 Batch F1: 0.0
Train Avg Loss  860: 0.227491

Train Avg F1  860: 0.0

Val Avg Loss  860: 0.218259

Val Avg F1  860:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 861
--------------------------------------------------------------
Epoch:  861        1 Batch loss: 0.218246 Batch F1: 0.0
Epoch:  861        2 Batch loss: 0.221791 Batch F1: 0.0
Epoch:  861        3 Batch loss: 0.234721 Batch F1: 0.0
Epoch:  861        4 Batch loss: 0.250414 Batch F1: 0.0
Epoch:  861        5 Batch loss: 0.225785 Batch F1: 0.0
Epoch:  861        6 Batch loss: 0.238474 Batch F1: 0.16666666666666666
Epoch:  861        7 Batch loss: 0.216431 Batch F1: 0.2727272727272727
Epoch:  861        8 Batch loss: 0.226878 Batch F1: 0.0
Epoch:  861        9 Batch loss: 0.233540 Batch F1: 0.0
Epoch:  861       10 Batch loss: 0.248442 Batch F1: 0.0
Epoch:  861       11 Batch loss: 0.225462 Batch F1: 0.0
Epoch:  861       12 Batch loss: 0.183291 Batch F1: 0.0
Train Avg Loss  861: 0.226956

Train Avg F1  861: 0.03661616161616161

Val Avg Loss  861: 0.217856

Val Avg F1  861:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 862
--------------------------------------------------------------
Epoch:  862        1 Batch loss: 0.242888 Batch F1: 0.0
Epoch:  862        2 Batch loss: 0.219088 Batch F1: 0.0
Epoch:  862        3 Batch loss: 0.213034 Batch F1: 0.0
Epoch:  862        4 Batch loss: 0.234150 Batch F1: 0.0
Epoch:  862        5 Batch loss: 0.216539 Batch F1: 0.0
Epoch:  862        6 Batch loss: 0.238254 Batch F1: 0.0
Epoch:  862        7 Batch loss: 0.228306 Batch F1: 0.0
Epoch:  862        8 Batch loss: 0.213220 Batch F1: 0.0
Epoch:  862        9 Batch loss: 0.194331 Batch F1: 0.0
Epoch:  862       10 Batch loss: 0.205985 Batch F1: 0.0
Epoch:  862       11 Batch loss: 0.255976 Batch F1: 0.0
Epoch:  862       12 Batch loss: 0.262300 Batch F1: 0.0
Train Avg Loss  862: 0.227006

Train Avg F1  862: 0.0

Val Avg Loss  862: 0.217504

Val Avg F1  862:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 863
--------------------------------------------------------------
Epoch:  863        1 Batch loss: 0.220453 Batch F1: 0.0
Epoch:  863        2 Batch loss: 0.238659 Batch F1: 0.0
Epoch:  863        3 Batch loss: 0.214138 Batch F1: 0.0
Epoch:  863        4 Batch loss: 0.223074 Batch F1: 0.0
Epoch:  863        5 Batch loss: 0.219420 Batch F1: 0.0
Epoch:  863        6 Batch loss: 0.239999 Batch F1: 0.0
Epoch:  863        7 Batch loss: 0.198525 Batch F1: 0.0
Epoch:  863        8 Batch loss: 0.188400 Batch F1: 0.0
Epoch:  863        9 Batch loss: 0.239660 Batch F1: 0.0
Epoch:  863       10 Batch loss: 0.270174 Batch F1: 0.0
Epoch:  863       11 Batch loss: 0.234801 Batch F1: 0.0
Epoch:  863       12 Batch loss: 0.245459 Batch F1: 0.0
Train Avg Loss  863: 0.227730

Train Avg F1  863: 0.0

Val Avg Loss  863: 0.218479

Val Avg F1  863:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 864
--------------------------------------------------------------
Epoch:  864        1 Batch loss: 0.201041 Batch F1: 0.0
Epoch:  864        2 Batch loss: 0.234561 Batch F1: 0.0
Epoch:  864        3 Batch loss: 0.218283 Batch F1: 0.0
Epoch:  864        4 Batch loss: 0.209700 Batch F1: 0.0
Epoch:  864        5 Batch loss: 0.256072 Batch F1: 0.0
Epoch:  864        6 Batch loss: 0.211857 Batch F1: 0.23529411764705882
Epoch:  864        7 Batch loss: 0.225338 Batch F1: 0.0
Epoch:  864        8 Batch loss: 0.215705 Batch F1: 0.0
Epoch:  864        9 Batch loss: 0.260402 Batch F1: 0.0
Epoch:  864       10 Batch loss: 0.210596 Batch F1: 0.0
Epoch:  864       11 Batch loss: 0.217667 Batch F1: 0.0
Epoch:  864       12 Batch loss: 0.268410 Batch F1: 0.0
Train Avg Loss  864: 0.227469

Train Avg F1  864: 0.0196078431372549

Val Avg Loss  864: 0.217500

Val Avg F1  864:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 865
--------------------------------------------------------------
Epoch:  865        1 Batch loss: 0.210119 Batch F1: 0.0
Epoch:  865        2 Batch loss: 0.223991 Batch F1: 0.0
Epoch:  865        3 Batch loss: 0.206671 Batch F1: 0.0
Epoch:  865        4 Batch loss: 0.219310 Batch F1: 0.0
Epoch:  865        5 Batch loss: 0.237228 Batch F1: 0.0
Epoch:  865        6 Batch loss: 0.209137 Batch F1: 0.0
Epoch:  865        7 Batch loss: 0.269806 Batch F1: 0.0
Epoch:  865        8 Batch loss: 0.217910 Batch F1: 0.0
Epoch:  865        9 Batch loss: 0.246864 Batch F1: 0.0
Epoch:  865       10 Batch loss: 0.258586 Batch F1: 0.0
Epoch:  865       11 Batch loss: 0.198582 Batch F1: 0.0
Epoch:  865       12 Batch loss: 0.217651 Batch F1: 0.0
Train Avg Loss  865: 0.226321

Train Avg F1  865: 0.0

Val Avg Loss  865: 0.218682

Val Avg F1  865:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 866
--------------------------------------------------------------
Epoch:  866        1 Batch loss: 0.211728 Batch F1: 0.0
Epoch:  866        2 Batch loss: 0.207896 Batch F1: 0.0
Epoch:  866        3 Batch loss: 0.252967 Batch F1: 0.0
Epoch:  866        4 Batch loss: 0.224131 Batch F1: 0.0
Epoch:  866        5 Batch loss: 0.244428 Batch F1: 0.0
Epoch:  866        6 Batch loss: 0.222053 Batch F1: 0.0
Epoch:  866        7 Batch loss: 0.211623 Batch F1: 0.0
Epoch:  866        8 Batch loss: 0.238600 Batch F1: 0.0
Epoch:  866        9 Batch loss: 0.186663 Batch F1: 0.0
Epoch:  866       10 Batch loss: 0.227290 Batch F1: 0.0
Epoch:  866       11 Batch loss: 0.264607 Batch F1: 0.0
Epoch:  866       12 Batch loss: 0.218837 Batch F1: 0.0
Train Avg Loss  866: 0.225902

Train Avg F1  866: 0.0

Val Avg Loss  866: 0.217150

Val Avg F1  866:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 867
--------------------------------------------------------------
Epoch:  867        1 Batch loss: 0.254023 Batch F1: 0.0
Epoch:  867        2 Batch loss: 0.212256 Batch F1: 0.0
Epoch:  867        3 Batch loss: 0.208691 Batch F1: 0.0
Epoch:  867        4 Batch loss: 0.259323 Batch F1: 0.0
Epoch:  867        5 Batch loss: 0.224859 Batch F1: 0.0
Epoch:  867        6 Batch loss: 0.204606 Batch F1: 0.0
Epoch:  867        7 Batch loss: 0.228084 Batch F1: 0.0
Epoch:  867        8 Batch loss: 0.227778 Batch F1: 0.0
Epoch:  867        9 Batch loss: 0.222017 Batch F1: 0.0
Epoch:  867       10 Batch loss: 0.203315 Batch F1: 0.0
Epoch:  867       11 Batch loss: 0.230374 Batch F1: 0.0
Epoch:  867       12 Batch loss: 0.235003 Batch F1: 0.0
Train Avg Loss  867: 0.225861

Train Avg F1  867: 0.0

Val Avg Loss  867: 0.216946

Val Avg F1  867:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 868
--------------------------------------------------------------
Epoch:  868        1 Batch loss: 0.229120 Batch F1: 0.0
Epoch:  868        2 Batch loss: 0.223442 Batch F1: 0.0
Epoch:  868        3 Batch loss: 0.197206 Batch F1: 0.0
Epoch:  868        4 Batch loss: 0.215001 Batch F1: 0.0
Epoch:  868        5 Batch loss: 0.237094 Batch F1: 0.0
Epoch:  868        6 Batch loss: 0.242229 Batch F1: 0.0
Epoch:  868        7 Batch loss: 0.205887 Batch F1: 0.0
Epoch:  868        8 Batch loss: 0.229951 Batch F1: 0.0
Epoch:  868        9 Batch loss: 0.269522 Batch F1: 0.0
Epoch:  868       10 Batch loss: 0.192509 Batch F1: 0.0
Epoch:  868       11 Batch loss: 0.215637 Batch F1: 0.0
Epoch:  868       12 Batch loss: 0.258339 Batch F1: 0.0
Train Avg Loss  868: 0.226328

Train Avg F1  868: 0.0

Val Avg Loss  868: 0.218785

Val Avg F1  868:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 869
--------------------------------------------------------------
Epoch:  869        1 Batch loss: 0.209357 Batch F1: 0.0
Epoch:  869        2 Batch loss: 0.222994 Batch F1: 0.0
Epoch:  869        3 Batch loss: 0.228995 Batch F1: 0.0
Epoch:  869        4 Batch loss: 0.216234 Batch F1: 0.0
Epoch:  869        5 Batch loss: 0.251891 Batch F1: 0.0
Epoch:  869        6 Batch loss: 0.228885 Batch F1: 0.0
Epoch:  869        7 Batch loss: 0.254277 Batch F1: 0.0
Epoch:  869        8 Batch loss: 0.220970 Batch F1: 0.0
Epoch:  869        9 Batch loss: 0.194239 Batch F1: 0.1111111111111111
Epoch:  869       10 Batch loss: 0.223725 Batch F1: 0.0
Epoch:  869       11 Batch loss: 0.210858 Batch F1: 0.0
Epoch:  869       12 Batch loss: 0.261611 Batch F1: 0.0
Train Avg Loss  869: 0.227003

Train Avg F1  869: 0.009259259259259259

Val Avg Loss  869: 0.217927

Val Avg F1  869:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 870
--------------------------------------------------------------
Epoch:  870        1 Batch loss: 0.245180 Batch F1: 0.0
Epoch:  870        2 Batch loss: 0.229070 Batch F1: 0.0
Epoch:  870        3 Batch loss: 0.226981 Batch F1: 0.0
Epoch:  870        4 Batch loss: 0.207062 Batch F1: 0.0
Epoch:  870        5 Batch loss: 0.228888 Batch F1: 0.0
Epoch:  870        6 Batch loss: 0.210314 Batch F1: 0.0
Epoch:  870        7 Batch loss: 0.223668 Batch F1: 0.0
Epoch:  870        8 Batch loss: 0.225778 Batch F1: 0.0
Epoch:  870        9 Batch loss: 0.236888 Batch F1: 0.0
Epoch:  870       10 Batch loss: 0.209671 Batch F1: 0.0
Epoch:  870       11 Batch loss: 0.252485 Batch F1: 0.0
Epoch:  870       12 Batch loss: 0.226586 Batch F1: 0.0
Train Avg Loss  870: 0.226881

Train Avg F1  870: 0.0

Val Avg Loss  870: 0.218694

Val Avg F1  870:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 871
--------------------------------------------------------------
Epoch:  871        1 Batch loss: 0.218255 Batch F1: 0.0
Epoch:  871        2 Batch loss: 0.235049 Batch F1: 0.0
Epoch:  871        3 Batch loss: 0.250212 Batch F1: 0.0
Epoch:  871        4 Batch loss: 0.223505 Batch F1: 0.0
Epoch:  871        5 Batch loss: 0.231861 Batch F1: 0.0
Epoch:  871        6 Batch loss: 0.221290 Batch F1: 0.0
Epoch:  871        7 Batch loss: 0.229077 Batch F1: 0.0
Epoch:  871        8 Batch loss: 0.226732 Batch F1: 0.0
Epoch:  871        9 Batch loss: 0.213526 Batch F1: 0.0
Epoch:  871       10 Batch loss: 0.253573 Batch F1: 0.0
Epoch:  871       11 Batch loss: 0.236980 Batch F1: 0.0
Epoch:  871       12 Batch loss: 0.187053 Batch F1: 0.0
Train Avg Loss  871: 0.227259

Train Avg F1  871: 0.0

Val Avg Loss  871: 0.217705

Val Avg F1  871:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 872
--------------------------------------------------------------
Epoch:  872        1 Batch loss: 0.200575 Batch F1: 0.0
Epoch:  872        2 Batch loss: 0.210381 Batch F1: 0.0
Epoch:  872        3 Batch loss: 0.283501 Batch F1: 0.0
Epoch:  872        4 Batch loss: 0.205841 Batch F1: 0.0
Epoch:  872        5 Batch loss: 0.294684 Batch F1: 0.0
Epoch:  872        6 Batch loss: 0.235589 Batch F1: 0.0
Epoch:  872        7 Batch loss: 0.206066 Batch F1: 0.0
Epoch:  872        8 Batch loss: 0.257056 Batch F1: 0.0
Epoch:  872        9 Batch loss: 0.253345 Batch F1: 0.0
Epoch:  872       10 Batch loss: 0.204917 Batch F1: 0.0
Epoch:  872       11 Batch loss: 0.196251 Batch F1: 0.0
Epoch:  872       12 Batch loss: 0.207079 Batch F1: 0.0
Train Avg Loss  872: 0.229607

Train Avg F1  872: 0.0

Val Avg Loss  872: 0.219480

Val Avg F1  872:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 873
--------------------------------------------------------------
Epoch:  873        1 Batch loss: 0.210600 Batch F1: 0.0
Epoch:  873        2 Batch loss: 0.185226 Batch F1: 0.0
Epoch:  873        3 Batch loss: 0.249916 Batch F1: 0.0
Epoch:  873        4 Batch loss: 0.262099 Batch F1: 0.0
Epoch:  873        5 Batch loss: 0.253658 Batch F1: 0.0
Epoch:  873        6 Batch loss: 0.197009 Batch F1: 0.0
Epoch:  873        7 Batch loss: 0.227586 Batch F1: 0.0
Epoch:  873        8 Batch loss: 0.247460 Batch F1: 0.0
Epoch:  873        9 Batch loss: 0.240321 Batch F1: 0.0
Epoch:  873       10 Batch loss: 0.200692 Batch F1: 0.0
Epoch:  873       11 Batch loss: 0.248748 Batch F1: 0.0
Epoch:  873       12 Batch loss: 0.259249 Batch F1: 0.0
Train Avg Loss  873: 0.231880

Train Avg F1  873: 0.0

Val Avg Loss  873: 0.222026

Val Avg F1  873:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 874
--------------------------------------------------------------
Epoch:  874        1 Batch loss: 0.239446 Batch F1: 0.0
Epoch:  874        2 Batch loss: 0.222671 Batch F1: 0.0
Epoch:  874        3 Batch loss: 0.214505 Batch F1: 0.0
Epoch:  874        4 Batch loss: 0.239852 Batch F1: 0.0
Epoch:  874        5 Batch loss: 0.229172 Batch F1: 0.0
Epoch:  874        6 Batch loss: 0.187648 Batch F1: 0.0
Epoch:  874        7 Batch loss: 0.261727 Batch F1: 0.0
Epoch:  874        8 Batch loss: 0.239547 Batch F1: 0.0
Epoch:  874        9 Batch loss: 0.230893 Batch F1: 0.0
Epoch:  874       10 Batch loss: 0.246429 Batch F1: 0.0
Epoch:  874       11 Batch loss: 0.216401 Batch F1: 0.0
Epoch:  874       12 Batch loss: 0.223411 Batch F1: 0.0
Train Avg Loss  874: 0.229308

Train Avg F1  874: 0.0

Val Avg Loss  874: 0.223853

Val Avg F1  874:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 875
--------------------------------------------------------------
Epoch:  875        1 Batch loss: 0.229879 Batch F1: 0.0
Epoch:  875        2 Batch loss: 0.225356 Batch F1: 0.0
Epoch:  875        3 Batch loss: 0.220545 Batch F1: 0.0
Epoch:  875        4 Batch loss: 0.251891 Batch F1: 0.0
Epoch:  875        5 Batch loss: 0.185448 Batch F1: 0.0
Epoch:  875        6 Batch loss: 0.215701 Batch F1: 0.0
Epoch:  875        7 Batch loss: 0.236068 Batch F1: 0.0
Epoch:  875        8 Batch loss: 0.233566 Batch F1: 0.0
Epoch:  875        9 Batch loss: 0.240512 Batch F1: 0.0
Epoch:  875       10 Batch loss: 0.213437 Batch F1: 0.0
Epoch:  875       11 Batch loss: 0.236616 Batch F1: 0.0
Epoch:  875       12 Batch loss: 0.242864 Batch F1: 0.0
Train Avg Loss  875: 0.227657

Train Avg F1  875: 0.0

Val Avg Loss  875: 0.218270

Val Avg F1  875:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 876
--------------------------------------------------------------
Epoch:  876        1 Batch loss: 0.214576 Batch F1: 0.0
Epoch:  876        2 Batch loss: 0.242648 Batch F1: 0.0
Epoch:  876        3 Batch loss: 0.223681 Batch F1: 0.0
Epoch:  876        4 Batch loss: 0.216653 Batch F1: 0.0
Epoch:  876        5 Batch loss: 0.220144 Batch F1: 0.0
Epoch:  876        6 Batch loss: 0.226629 Batch F1: 0.0
Epoch:  876        7 Batch loss: 0.228609 Batch F1: 0.0
Epoch:  876        8 Batch loss: 0.209627 Batch F1: 0.0
Epoch:  876        9 Batch loss: 0.265767 Batch F1: 0.0
Epoch:  876       10 Batch loss: 0.225804 Batch F1: 0.0
Epoch:  876       11 Batch loss: 0.241351 Batch F1: 0.0
Epoch:  876       12 Batch loss: 0.199033 Batch F1: 0.0
Train Avg Loss  876: 0.226210

Train Avg F1  876: 0.0

Val Avg Loss  876: 0.217580

Val Avg F1  876:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 877
--------------------------------------------------------------
Epoch:  877        1 Batch loss: 0.228253 Batch F1: 0.0
Epoch:  877        2 Batch loss: 0.221853 Batch F1: 0.0
Epoch:  877        3 Batch loss: 0.223206 Batch F1: 0.0
Epoch:  877        4 Batch loss: 0.220718 Batch F1: 0.0
Epoch:  877        5 Batch loss: 0.216056 Batch F1: 0.0
Epoch:  877        6 Batch loss: 0.200540 Batch F1: 0.0
Epoch:  877        7 Batch loss: 0.231704 Batch F1: 0.0
Epoch:  877        8 Batch loss: 0.226491 Batch F1: 0.0
Epoch:  877        9 Batch loss: 0.231331 Batch F1: 0.0
Epoch:  877       10 Batch loss: 0.218043 Batch F1: 0.0
Epoch:  877       11 Batch loss: 0.244581 Batch F1: 0.0
Epoch:  877       12 Batch loss: 0.252934 Batch F1: 0.0
Train Avg Loss  877: 0.226309

Train Avg F1  877: 0.0

Val Avg Loss  877: 0.217096

Val Avg F1  877:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 878
--------------------------------------------------------------
Epoch:  878        1 Batch loss: 0.226026 Batch F1: 0.0
Epoch:  878        2 Batch loss: 0.218329 Batch F1: 0.0
Epoch:  878        3 Batch loss: 0.242659 Batch F1: 0.0
Epoch:  878        4 Batch loss: 0.244744 Batch F1: 0.37499999999999994
Epoch:  878        5 Batch loss: 0.230497 Batch F1: 0.0
Epoch:  878        6 Batch loss: 0.203040 Batch F1: 0.0
Epoch:  878        7 Batch loss: 0.217111 Batch F1: 0.0
Epoch:  878        8 Batch loss: 0.210173 Batch F1: 0.0
Epoch:  878        9 Batch loss: 0.207843 Batch F1: 0.0
Epoch:  878       10 Batch loss: 0.245960 Batch F1: 0.0
Epoch:  878       11 Batch loss: 0.254178 Batch F1: 0.0
Epoch:  878       12 Batch loss: 0.237963 Batch F1: 0.0
Train Avg Loss  878: 0.228210

Train Avg F1  878: 0.031249999999999997

Val Avg Loss  878: 0.217719

Val Avg F1  878:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 879
--------------------------------------------------------------
Epoch:  879        1 Batch loss: 0.219009 Batch F1: 0.0
Epoch:  879        2 Batch loss: 0.238062 Batch F1: 0.0
Epoch:  879        3 Batch loss: 0.234168 Batch F1: 0.0
Epoch:  879        4 Batch loss: 0.211638 Batch F1: 0.2222222222222222
Epoch:  879        5 Batch loss: 0.241432 Batch F1: 0.22222222222222224
Epoch:  879        6 Batch loss: 0.225249 Batch F1: 0.29629629629629634
Epoch:  879        7 Batch loss: 0.205353 Batch F1: 0.0
Epoch:  879        8 Batch loss: 0.247520 Batch F1: 0.0
Epoch:  879        9 Batch loss: 0.227211 Batch F1: 0.0
Epoch:  879       10 Batch loss: 0.249671 Batch F1: 0.0
Epoch:  879       11 Batch loss: 0.219069 Batch F1: 0.0
Epoch:  879       12 Batch loss: 0.212793 Batch F1: 0.0
Train Avg Loss  879: 0.227598

Train Avg F1  879: 0.06172839506172839

Val Avg Loss  879: 0.220641

Val Avg F1  879:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 880
--------------------------------------------------------------
Epoch:  880        1 Batch loss: 0.206338 Batch F1: 0.0
Epoch:  880        2 Batch loss: 0.225116 Batch F1: 0.0
Epoch:  880        3 Batch loss: 0.227811 Batch F1: 0.0
Epoch:  880        4 Batch loss: 0.192688 Batch F1: 0.0
Epoch:  880        5 Batch loss: 0.300253 Batch F1: 0.0
Epoch:  880        6 Batch loss: 0.247554 Batch F1: 0.0
Epoch:  880        7 Batch loss: 0.245002 Batch F1: 0.0
Epoch:  880        8 Batch loss: 0.213833 Batch F1: 0.0
Epoch:  880        9 Batch loss: 0.237735 Batch F1: 0.0
Epoch:  880       10 Batch loss: 0.213742 Batch F1: 0.0
Epoch:  880       11 Batch loss: 0.213764 Batch F1: 0.0
Epoch:  880       12 Batch loss: 0.236851 Batch F1: 0.0
Train Avg Loss  880: 0.230057

Train Avg F1  880: 0.0

Val Avg Loss  880: 0.220645

Val Avg F1  880:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 881
--------------------------------------------------------------
Epoch:  881        1 Batch loss: 0.217888 Batch F1: 0.0
Epoch:  881        2 Batch loss: 0.248240 Batch F1: 0.0
Epoch:  881        3 Batch loss: 0.213070 Batch F1: 0.0
Epoch:  881        4 Batch loss: 0.215073 Batch F1: 0.0
Epoch:  881        5 Batch loss: 0.212651 Batch F1: 0.0
Epoch:  881        6 Batch loss: 0.228183 Batch F1: 0.0
Epoch:  881        7 Batch loss: 0.187966 Batch F1: 0.0
Epoch:  881        8 Batch loss: 0.262722 Batch F1: 0.0
Epoch:  881        9 Batch loss: 0.245221 Batch F1: 0.0
Epoch:  881       10 Batch loss: 0.219478 Batch F1: 0.0
Epoch:  881       11 Batch loss: 0.234605 Batch F1: 0.0
Epoch:  881       12 Batch loss: 0.244788 Batch F1: 0.0
Train Avg Loss  881: 0.227491

Train Avg F1  881: 0.0

Val Avg Loss  881: 0.217823

Val Avg F1  881:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 882
--------------------------------------------------------------
Epoch:  882        1 Batch loss: 0.222936 Batch F1: 0.0
Epoch:  882        2 Batch loss: 0.226640 Batch F1: 0.0
Epoch:  882        3 Batch loss: 0.230773 Batch F1: 0.0
Epoch:  882        4 Batch loss: 0.273047 Batch F1: 0.0
Epoch:  882        5 Batch loss: 0.213742 Batch F1: 0.0
Epoch:  882        6 Batch loss: 0.224833 Batch F1: 0.0
Epoch:  882        7 Batch loss: 0.217416 Batch F1: 0.0
Epoch:  882        8 Batch loss: 0.230825 Batch F1: 0.0
Epoch:  882        9 Batch loss: 0.208430 Batch F1: 0.0
Epoch:  882       10 Batch loss: 0.232363 Batch F1: 0.0
Epoch:  882       11 Batch loss: 0.206729 Batch F1: 0.0
Epoch:  882       12 Batch loss: 0.236929 Batch F1: 0.0
Train Avg Loss  882: 0.227055

Train Avg F1  882: 0.0

Val Avg Loss  882: 0.217417

Val Avg F1  882:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 883
--------------------------------------------------------------
Epoch:  883        1 Batch loss: 0.199175 Batch F1: 0.0
Epoch:  883        2 Batch loss: 0.240193 Batch F1: 0.0
Epoch:  883        3 Batch loss: 0.230482 Batch F1: 0.0
Epoch:  883        4 Batch loss: 0.230313 Batch F1: 0.0
Epoch:  883        5 Batch loss: 0.271973 Batch F1: 0.0
Epoch:  883        6 Batch loss: 0.212647 Batch F1: 0.0
Epoch:  883        7 Batch loss: 0.262680 Batch F1: 0.0
Epoch:  883        8 Batch loss: 0.224768 Batch F1: 0.0
Epoch:  883        9 Batch loss: 0.233471 Batch F1: 0.0
Epoch:  883       10 Batch loss: 0.196280 Batch F1: 0.0
Epoch:  883       11 Batch loss: 0.209128 Batch F1: 0.0
Epoch:  883       12 Batch loss: 0.231901 Batch F1: 0.0
Train Avg Loss  883: 0.228584

Train Avg F1  883: 0.0

Val Avg Loss  883: 0.217019

Val Avg F1  883:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 884
--------------------------------------------------------------
Epoch:  884        1 Batch loss: 0.228066 Batch F1: 0.0
Epoch:  884        2 Batch loss: 0.210406 Batch F1: 0.0
Epoch:  884        3 Batch loss: 0.225441 Batch F1: 0.0
Epoch:  884        4 Batch loss: 0.269712 Batch F1: 0.0
Epoch:  884        5 Batch loss: 0.211988 Batch F1: 0.0
Epoch:  884        6 Batch loss: 0.245229 Batch F1: 0.0
Epoch:  884        7 Batch loss: 0.225398 Batch F1: 0.0
Epoch:  884        8 Batch loss: 0.232664 Batch F1: 0.0
Epoch:  884        9 Batch loss: 0.246301 Batch F1: 0.0
Epoch:  884       10 Batch loss: 0.206174 Batch F1: 0.6
Epoch:  884       11 Batch loss: 0.209515 Batch F1: 0.0
Epoch:  884       12 Batch loss: 0.247365 Batch F1: 0.0
Train Avg Loss  884: 0.229855

Train Avg F1  884: 0.049999999999999996

Val Avg Loss  884: 0.218103

Val Avg F1  884:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 885
--------------------------------------------------------------
Epoch:  885        1 Batch loss: 0.226786 Batch F1: 0.0
Epoch:  885        2 Batch loss: 0.229047 Batch F1: 0.0
Epoch:  885        3 Batch loss: 0.230996 Batch F1: 0.0
Epoch:  885        4 Batch loss: 0.206464 Batch F1: 0.0
Epoch:  885        5 Batch loss: 0.198879 Batch F1: 0.0
Epoch:  885        6 Batch loss: 0.197976 Batch F1: 0.0
Epoch:  885        7 Batch loss: 0.260173 Batch F1: 0.0
Epoch:  885        8 Batch loss: 0.281196 Batch F1: 0.0
Epoch:  885        9 Batch loss: 0.247984 Batch F1: 0.0
Epoch:  885       10 Batch loss: 0.230432 Batch F1: 0.0
Epoch:  885       11 Batch loss: 0.226669 Batch F1: 0.0
Epoch:  885       12 Batch loss: 0.216145 Batch F1: 0.0
Train Avg Loss  885: 0.229396

Train Avg F1  885: 0.0

Val Avg Loss  885: 0.224696

Val Avg F1  885:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 886
--------------------------------------------------------------
Epoch:  886        1 Batch loss: 0.230750 Batch F1: 0.0
Epoch:  886        2 Batch loss: 0.224947 Batch F1: 0.0
Epoch:  886        3 Batch loss: 0.201424 Batch F1: 0.0
Epoch:  886        4 Batch loss: 0.227165 Batch F1: 0.0
Epoch:  886        5 Batch loss: 0.219545 Batch F1: 0.0
Epoch:  886        6 Batch loss: 0.238367 Batch F1: 0.0
Epoch:  886        7 Batch loss: 0.216208 Batch F1: 0.0
Epoch:  886        8 Batch loss: 0.218758 Batch F1: 0.0
Epoch:  886        9 Batch loss: 0.234587 Batch F1: 0.0
Epoch:  886       10 Batch loss: 0.239084 Batch F1: 0.0
Epoch:  886       11 Batch loss: 0.273145 Batch F1: 0.0
Epoch:  886       12 Batch loss: 0.210364 Batch F1: 0.0
Train Avg Loss  886: 0.227862

Train Avg F1  886: 0.0

Val Avg Loss  886: 0.217410

Val Avg F1  886:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 887
--------------------------------------------------------------
Epoch:  887        1 Batch loss: 0.203197 Batch F1: 0.0
Epoch:  887        2 Batch loss: 0.207417 Batch F1: 0.0
Epoch:  887        3 Batch loss: 0.214384 Batch F1: 0.0
Epoch:  887        4 Batch loss: 0.243462 Batch F1: 0.0
Epoch:  887        5 Batch loss: 0.212369 Batch F1: 0.0
Epoch:  887        6 Batch loss: 0.208145 Batch F1: 0.0
Epoch:  887        7 Batch loss: 0.244598 Batch F1: 0.0
Epoch:  887        8 Batch loss: 0.242519 Batch F1: 0.0
Epoch:  887        9 Batch loss: 0.269291 Batch F1: 0.0
Epoch:  887       10 Batch loss: 0.243079 Batch F1: 0.0
Epoch:  887       11 Batch loss: 0.192945 Batch F1: 0.0
Epoch:  887       12 Batch loss: 0.237387 Batch F1: 0.0
Train Avg Loss  887: 0.226566

Train Avg F1  887: 0.0

Val Avg Loss  887: 0.218713

Val Avg F1  887:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 888
--------------------------------------------------------------
Epoch:  888        1 Batch loss: 0.256033 Batch F1: 0.0
Epoch:  888        2 Batch loss: 0.230582 Batch F1: 0.0
Epoch:  888        3 Batch loss: 0.223847 Batch F1: 0.0
Epoch:  888        4 Batch loss: 0.214735 Batch F1: 0.0
Epoch:  888        5 Batch loss: 0.212953 Batch F1: 0.0
Epoch:  888        6 Batch loss: 0.220053 Batch F1: 0.0
Epoch:  888        7 Batch loss: 0.235038 Batch F1: 0.0
Epoch:  888        8 Batch loss: 0.220151 Batch F1: 0.0
Epoch:  888        9 Batch loss: 0.234197 Batch F1: 0.0
Epoch:  888       10 Batch loss: 0.254261 Batch F1: 0.0
Epoch:  888       11 Batch loss: 0.215907 Batch F1: 0.0
Epoch:  888       12 Batch loss: 0.195194 Batch F1: 0.0
Train Avg Loss  888: 0.226079

Train Avg F1  888: 0.0

Val Avg Loss  888: 0.217212

Val Avg F1  888:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 889
--------------------------------------------------------------
Epoch:  889        1 Batch loss: 0.245996 Batch F1: 0.0
Epoch:  889        2 Batch loss: 0.200479 Batch F1: 0.0
Epoch:  889        3 Batch loss: 0.196392 Batch F1: 0.0
Epoch:  889        4 Batch loss: 0.230835 Batch F1: 0.0
Epoch:  889        5 Batch loss: 0.261147 Batch F1: 0.0
Epoch:  889        6 Batch loss: 0.212561 Batch F1: 0.0
Epoch:  889        7 Batch loss: 0.212166 Batch F1: 0.0
Epoch:  889        8 Batch loss: 0.224264 Batch F1: 0.0
Epoch:  889        9 Batch loss: 0.228716 Batch F1: 0.0
Epoch:  889       10 Batch loss: 0.211196 Batch F1: 0.0
Epoch:  889       11 Batch loss: 0.238714 Batch F1: 0.0
Epoch:  889       12 Batch loss: 0.258079 Batch F1: 0.0
Train Avg Loss  889: 0.226712

Train Avg F1  889: 0.0

Val Avg Loss  889: 0.217490

Val Avg F1  889:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 890
--------------------------------------------------------------
Epoch:  890        1 Batch loss: 0.241370 Batch F1: 0.0
Epoch:  890        2 Batch loss: 0.199597 Batch F1: 0.0
Epoch:  890        3 Batch loss: 0.236390 Batch F1: 0.0
Epoch:  890        4 Batch loss: 0.241335 Batch F1: 0.0
Epoch:  890        5 Batch loss: 0.198578 Batch F1: 0.0
Epoch:  890        6 Batch loss: 0.209452 Batch F1: 0.0
Epoch:  890        7 Batch loss: 0.230876 Batch F1: 0.0
Epoch:  890        8 Batch loss: 0.188556 Batch F1: 0.0
Epoch:  890        9 Batch loss: 0.252592 Batch F1: 0.0
Epoch:  890       10 Batch loss: 0.248384 Batch F1: 0.0
Epoch:  890       11 Batch loss: 0.221709 Batch F1: 0.0
Epoch:  890       12 Batch loss: 0.249693 Batch F1: 0.0
Train Avg Loss  890: 0.226544

Train Avg F1  890: 0.0

Val Avg Loss  890: 0.217337

Val Avg F1  890:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 891
--------------------------------------------------------------
Epoch:  891        1 Batch loss: 0.227739 Batch F1: 0.0
Epoch:  891        2 Batch loss: 0.207738 Batch F1: 0.0
Epoch:  891        3 Batch loss: 0.245626 Batch F1: 0.0
Epoch:  891        4 Batch loss: 0.273786 Batch F1: 0.0
Epoch:  891        5 Batch loss: 0.215489 Batch F1: 0.0
Epoch:  891        6 Batch loss: 0.254032 Batch F1: 0.0
Epoch:  891        7 Batch loss: 0.219569 Batch F1: 0.3846153846153846
Epoch:  891        8 Batch loss: 0.210591 Batch F1: 0.38095238095238093
Epoch:  891        9 Batch loss: 0.226127 Batch F1: 0.3703703703703704
Epoch:  891       10 Batch loss: 0.218644 Batch F1: 0.3478260869565218
Epoch:  891       11 Batch loss: 0.222904 Batch F1: 0.2
Epoch:  891       12 Batch loss: 0.202396 Batch F1: 0.0
Train Avg Loss  891: 0.227053

Train Avg F1  891: 0.14031368524122148

Val Avg Loss  891: 0.217780

Val Avg F1  891:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 892
--------------------------------------------------------------
Epoch:  892        1 Batch loss: 0.221485 Batch F1: 0.0
Epoch:  892        2 Batch loss: 0.238835 Batch F1: 0.0
Epoch:  892        3 Batch loss: 0.197889 Batch F1: 0.0
Epoch:  892        4 Batch loss: 0.217784 Batch F1: 0.0
Epoch:  892        5 Batch loss: 0.223958 Batch F1: 0.0
Epoch:  892        6 Batch loss: 0.226473 Batch F1: 0.0
Epoch:  892        7 Batch loss: 0.269602 Batch F1: 0.0
Epoch:  892        8 Batch loss: 0.232750 Batch F1: 0.0
Epoch:  892        9 Batch loss: 0.206582 Batch F1: 0.0
Epoch:  892       10 Batch loss: 0.220630 Batch F1: 0.0
Epoch:  892       11 Batch loss: 0.260257 Batch F1: 0.0
Epoch:  892       12 Batch loss: 0.237754 Batch F1: 0.0
Train Avg Loss  892: 0.229500

Train Avg F1  892: 0.0

Val Avg Loss  892: 0.222920

Val Avg F1  892:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 893
--------------------------------------------------------------
Epoch:  893        1 Batch loss: 0.213241 Batch F1: 0.0
Epoch:  893        2 Batch loss: 0.225279 Batch F1: 0.0
Epoch:  893        3 Batch loss: 0.241493 Batch F1: 0.0
Epoch:  893        4 Batch loss: 0.224695 Batch F1: 0.0
Epoch:  893        5 Batch loss: 0.251714 Batch F1: 0.0
Epoch:  893        6 Batch loss: 0.223081 Batch F1: 0.0
Epoch:  893        7 Batch loss: 0.249551 Batch F1: 0.0
Epoch:  893        8 Batch loss: 0.186112 Batch F1: 0.0
Epoch:  893        9 Batch loss: 0.217335 Batch F1: 0.0
Epoch:  893       10 Batch loss: 0.246264 Batch F1: 0.0
Epoch:  893       11 Batch loss: 0.219542 Batch F1: 0.0
Epoch:  893       12 Batch loss: 0.245633 Batch F1: 0.0
Train Avg Loss  893: 0.228662

Train Avg F1  893: 0.0

Val Avg Loss  893: 0.217088

Val Avg F1  893:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 894
--------------------------------------------------------------
Epoch:  894        1 Batch loss: 0.198674 Batch F1: 0.0
Epoch:  894        2 Batch loss: 0.242063 Batch F1: 0.0
Epoch:  894        3 Batch loss: 0.211081 Batch F1: 0.0
Epoch:  894        4 Batch loss: 0.231898 Batch F1: 0.0
Epoch:  894        5 Batch loss: 0.249065 Batch F1: 0.0
Epoch:  894        6 Batch loss: 0.237736 Batch F1: 0.0
Epoch:  894        7 Batch loss: 0.216209 Batch F1: 0.0
Epoch:  894        8 Batch loss: 0.213231 Batch F1: 0.0
Epoch:  894        9 Batch loss: 0.215931 Batch F1: 0.0
Epoch:  894       10 Batch loss: 0.252726 Batch F1: 0.0
Epoch:  894       11 Batch loss: 0.219883 Batch F1: 0.0
Epoch:  894       12 Batch loss: 0.238847 Batch F1: 0.0
Train Avg Loss  894: 0.227279

Train Avg F1  894: 0.0

Val Avg Loss  894: 0.218521

Val Avg F1  894:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 895
--------------------------------------------------------------
Epoch:  895        1 Batch loss: 0.220231 Batch F1: 0.0
Epoch:  895        2 Batch loss: 0.208794 Batch F1: 0.0
Epoch:  895        3 Batch loss: 0.226367 Batch F1: 0.0
Epoch:  895        4 Batch loss: 0.228274 Batch F1: 0.0
Epoch:  895        5 Batch loss: 0.190875 Batch F1: 0.0
Epoch:  895        6 Batch loss: 0.230035 Batch F1: 0.0
Epoch:  895        7 Batch loss: 0.272182 Batch F1: 0.0
Epoch:  895        8 Batch loss: 0.243459 Batch F1: 0.0
Epoch:  895        9 Batch loss: 0.228521 Batch F1: 0.0
Epoch:  895       10 Batch loss: 0.200239 Batch F1: 0.0
Epoch:  895       11 Batch loss: 0.210704 Batch F1: 0.0
Epoch:  895       12 Batch loss: 0.259955 Batch F1: 0.0
Train Avg Loss  895: 0.226636

Train Avg F1  895: 0.0

Val Avg Loss  895: 0.217382

Val Avg F1  895:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 896
--------------------------------------------------------------
Epoch:  896        1 Batch loss: 0.232146 Batch F1: 0.0
Epoch:  896        2 Batch loss: 0.208587 Batch F1: 0.0
Epoch:  896        3 Batch loss: 0.230558 Batch F1: 0.0
Epoch:  896        4 Batch loss: 0.242649 Batch F1: 0.0
Epoch:  896        5 Batch loss: 0.211052 Batch F1: 0.0
Epoch:  896        6 Batch loss: 0.221967 Batch F1: 0.0
Epoch:  896        7 Batch loss: 0.219430 Batch F1: 0.0
Epoch:  896        8 Batch loss: 0.190798 Batch F1: 0.0
Epoch:  896        9 Batch loss: 0.242192 Batch F1: 0.0
Epoch:  896       10 Batch loss: 0.280167 Batch F1: 0.0
Epoch:  896       11 Batch loss: 0.200705 Batch F1: 0.0
Epoch:  896       12 Batch loss: 0.235086 Batch F1: 0.0
Train Avg Loss  896: 0.226278

Train Avg F1  896: 0.0

Val Avg Loss  896: 0.217775

Val Avg F1  896:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 897
--------------------------------------------------------------
Epoch:  897        1 Batch loss: 0.242942 Batch F1: 0.0
Epoch:  897        2 Batch loss: 0.244522 Batch F1: 0.0
Epoch:  897        3 Batch loss: 0.223452 Batch F1: 0.0
Epoch:  897        4 Batch loss: 0.228475 Batch F1: 0.0
Epoch:  897        5 Batch loss: 0.212975 Batch F1: 0.0
Epoch:  897        6 Batch loss: 0.217687 Batch F1: 0.0
Epoch:  897        7 Batch loss: 0.252001 Batch F1: 0.0
Epoch:  897        8 Batch loss: 0.241927 Batch F1: 0.0
Epoch:  897        9 Batch loss: 0.184370 Batch F1: 0.0
Epoch:  897       10 Batch loss: 0.194947 Batch F1: 0.0
Epoch:  897       11 Batch loss: 0.221908 Batch F1: 0.0
Epoch:  897       12 Batch loss: 0.258231 Batch F1: 0.0
Train Avg Loss  897: 0.226953

Train Avg F1  897: 0.0

Val Avg Loss  897: 0.217056

Val Avg F1  897:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 898
--------------------------------------------------------------
Epoch:  898        1 Batch loss: 0.222246 Batch F1: 0.0
Epoch:  898        2 Batch loss: 0.221197 Batch F1: 0.0
Epoch:  898        3 Batch loss: 0.241604 Batch F1: 0.0
Epoch:  898        4 Batch loss: 0.218550 Batch F1: 0.0
Epoch:  898        5 Batch loss: 0.205748 Batch F1: 0.0
Epoch:  898        6 Batch loss: 0.198178 Batch F1: 0.0
Epoch:  898        7 Batch loss: 0.287207 Batch F1: 0.0
Epoch:  898        8 Batch loss: 0.214166 Batch F1: 0.0
Epoch:  898        9 Batch loss: 0.239537 Batch F1: 0.0
Epoch:  898       10 Batch loss: 0.235205 Batch F1: 0.0
Epoch:  898       11 Batch loss: 0.222735 Batch F1: 0.0
Epoch:  898       12 Batch loss: 0.209808 Batch F1: 0.0
Train Avg Loss  898: 0.226348

Train Avg F1  898: 0.0

Val Avg Loss  898: 0.217651

Val Avg F1  898:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 899
--------------------------------------------------------------
Epoch:  899        1 Batch loss: 0.186321 Batch F1: 0.0
Epoch:  899        2 Batch loss: 0.235796 Batch F1: 0.0
Epoch:  899        3 Batch loss: 0.243441 Batch F1: 0.0
Epoch:  899        4 Batch loss: 0.218074 Batch F1: 0.0
Epoch:  899        5 Batch loss: 0.239611 Batch F1: 0.0
Epoch:  899        6 Batch loss: 0.257728 Batch F1: 0.0
Epoch:  899        7 Batch loss: 0.248155 Batch F1: 0.0
Epoch:  899        8 Batch loss: 0.214828 Batch F1: 0.0
Epoch:  899        9 Batch loss: 0.248675 Batch F1: 0.0
Epoch:  899       10 Batch loss: 0.231133 Batch F1: 0.0
Epoch:  899       11 Batch loss: 0.233255 Batch F1: 0.14814814814814817
Epoch:  899       12 Batch loss: 0.207442 Batch F1: 0.0
Train Avg Loss  899: 0.230371

Train Avg F1  899: 0.01234567901234568

Val Avg Loss  899: 0.219604

Val Avg F1  899:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 900
--------------------------------------------------------------
Epoch:  900        1 Batch loss: 0.226077 Batch F1: 0.0
Epoch:  900        2 Batch loss: 0.205345 Batch F1: 0.0
Epoch:  900        3 Batch loss: 0.251027 Batch F1: 0.0
Epoch:  900        4 Batch loss: 0.224451 Batch F1: 0.0
Epoch:  900        5 Batch loss: 0.234793 Batch F1: 0.0
Epoch:  900        6 Batch loss: 0.210125 Batch F1: 0.0
Epoch:  900        7 Batch loss: 0.220956 Batch F1: 0.0
Epoch:  900        8 Batch loss: 0.244797 Batch F1: 0.0
Epoch:  900        9 Batch loss: 0.230759 Batch F1: 0.0
Epoch:  900       10 Batch loss: 0.240949 Batch F1: 0.0
Epoch:  900       11 Batch loss: 0.230116 Batch F1: 0.0
Epoch:  900       12 Batch loss: 0.222210 Batch F1: 0.0
Train Avg Loss  900: 0.228467

Train Avg F1  900: 0.0

Val Avg Loss  900: 0.220592

Val Avg F1  900:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 901
--------------------------------------------------------------
Epoch:  901        1 Batch loss: 0.258640 Batch F1: 0.0
Epoch:  901        2 Batch loss: 0.222554 Batch F1: 0.0
Epoch:  901        3 Batch loss: 0.237228 Batch F1: 0.0
Epoch:  901        4 Batch loss: 0.241595 Batch F1: 0.0
Epoch:  901        5 Batch loss: 0.232297 Batch F1: 0.0
Epoch:  901        6 Batch loss: 0.224912 Batch F1: 0.0
Epoch:  901        7 Batch loss: 0.207851 Batch F1: 0.0
Epoch:  901        8 Batch loss: 0.211186 Batch F1: 0.0
Epoch:  901        9 Batch loss: 0.222372 Batch F1: 0.0
Epoch:  901       10 Batch loss: 0.217402 Batch F1: 0.0
Epoch:  901       11 Batch loss: 0.222048 Batch F1: 0.0
Epoch:  901       12 Batch loss: 0.241998 Batch F1: 0.0
Train Avg Loss  901: 0.228340

Train Avg F1  901: 0.0

Val Avg Loss  901: 0.217120

Val Avg F1  901:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 902
--------------------------------------------------------------
Epoch:  902        1 Batch loss: 0.208102 Batch F1: 0.0
Epoch:  902        2 Batch loss: 0.228962 Batch F1: 0.0
Epoch:  902        3 Batch loss: 0.201933 Batch F1: 0.0
Epoch:  902        4 Batch loss: 0.296579 Batch F1: 0.0
Epoch:  902        5 Batch loss: 0.210851 Batch F1: 0.0
Epoch:  902        6 Batch loss: 0.221448 Batch F1: 0.0
Epoch:  902        7 Batch loss: 0.224553 Batch F1: 0.0
Epoch:  902        8 Batch loss: 0.241565 Batch F1: 0.0
Epoch:  902        9 Batch loss: 0.233753 Batch F1: 0.0
Epoch:  902       10 Batch loss: 0.236910 Batch F1: 0.0
Epoch:  902       11 Batch loss: 0.189805 Batch F1: 0.0
Epoch:  902       12 Batch loss: 0.236541 Batch F1: 0.0
Train Avg Loss  902: 0.227584

Train Avg F1  902: 0.0

Val Avg Loss  902: 0.217494

Val Avg F1  902:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 903
--------------------------------------------------------------
Epoch:  903        1 Batch loss: 0.272538 Batch F1: 0.0
Epoch:  903        2 Batch loss: 0.205159 Batch F1: 0.0
Epoch:  903        3 Batch loss: 0.231031 Batch F1: 0.0
Epoch:  903        4 Batch loss: 0.257097 Batch F1: 0.0
Epoch:  903        5 Batch loss: 0.209425 Batch F1: 0.0
Epoch:  903        6 Batch loss: 0.201250 Batch F1: 0.0
Epoch:  903        7 Batch loss: 0.239280 Batch F1: 0.0
Epoch:  903        8 Batch loss: 0.210696 Batch F1: 0.0
Epoch:  903        9 Batch loss: 0.204640 Batch F1: 0.0
Epoch:  903       10 Batch loss: 0.224412 Batch F1: 0.0
Epoch:  903       11 Batch loss: 0.241943 Batch F1: 0.0
Epoch:  903       12 Batch loss: 0.212950 Batch F1: 0.0
Train Avg Loss  903: 0.225868

Train Avg F1  903: 0.0

Val Avg Loss  903: 0.217310

Val Avg F1  903:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 904
--------------------------------------------------------------
Epoch:  904        1 Batch loss: 0.224009 Batch F1: 0.0
Epoch:  904        2 Batch loss: 0.239667 Batch F1: 0.0
Epoch:  904        3 Batch loss: 0.184401 Batch F1: 0.0
Epoch:  904        4 Batch loss: 0.258435 Batch F1: 0.0
Epoch:  904        5 Batch loss: 0.236631 Batch F1: 0.0
Epoch:  904        6 Batch loss: 0.237514 Batch F1: 0.0
Epoch:  904        7 Batch loss: 0.230674 Batch F1: 0.0
Epoch:  904        8 Batch loss: 0.229441 Batch F1: 0.0
Epoch:  904        9 Batch loss: 0.211347 Batch F1: 0.0
Epoch:  904       10 Batch loss: 0.227198 Batch F1: 0.0
Epoch:  904       11 Batch loss: 0.202884 Batch F1: 0.0
Epoch:  904       12 Batch loss: 0.262895 Batch F1: 0.0
Train Avg Loss  904: 0.228758

Train Avg F1  904: 0.0

Val Avg Loss  904: 0.219129

Val Avg F1  904:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 905
--------------------------------------------------------------
Epoch:  905        1 Batch loss: 0.226909 Batch F1: 0.0
Epoch:  905        2 Batch loss: 0.208664 Batch F1: 0.0
Epoch:  905        3 Batch loss: 0.237461 Batch F1: 0.0
Epoch:  905        4 Batch loss: 0.230158 Batch F1: 0.0
Epoch:  905        5 Batch loss: 0.198958 Batch F1: 0.0
Epoch:  905        6 Batch loss: 0.237546 Batch F1: 0.0
Epoch:  905        7 Batch loss: 0.212858 Batch F1: 0.34782608695652173
Epoch:  905        8 Batch loss: 0.201634 Batch F1: 0.0
Epoch:  905        9 Batch loss: 0.241920 Batch F1: 0.0
Epoch:  905       10 Batch loss: 0.250998 Batch F1: 0.0
Epoch:  905       11 Batch loss: 0.255728 Batch F1: 0.0
Epoch:  905       12 Batch loss: 0.223929 Batch F1: 0.0
Train Avg Loss  905: 0.227230

Train Avg F1  905: 0.028985507246376812

Val Avg Loss  905: 0.217838

Val Avg F1  905:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 906
--------------------------------------------------------------
Epoch:  906        1 Batch loss: 0.241995 Batch F1: 0.0
Epoch:  906        2 Batch loss: 0.234029 Batch F1: 0.0
Epoch:  906        3 Batch loss: 0.215136 Batch F1: 0.10526315789473685
Epoch:  906        4 Batch loss: 0.240828 Batch F1: 0.0
Epoch:  906        5 Batch loss: 0.221013 Batch F1: 0.0
Epoch:  906        6 Batch loss: 0.212136 Batch F1: 0.0
Epoch:  906        7 Batch loss: 0.236336 Batch F1: 0.0
Epoch:  906        8 Batch loss: 0.207176 Batch F1: 0.0
Epoch:  906        9 Batch loss: 0.238169 Batch F1: 0.0
Epoch:  906       10 Batch loss: 0.235741 Batch F1: 0.0
Epoch:  906       11 Batch loss: 0.218962 Batch F1: 0.0
Epoch:  906       12 Batch loss: 0.224848 Batch F1: 0.0
Train Avg Loss  906: 0.227197

Train Avg F1  906: 0.008771929824561405

Val Avg Loss  906: 0.218073

Val Avg F1  906:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 907
--------------------------------------------------------------
Epoch:  907        1 Batch loss: 0.234050 Batch F1: 0.0
Epoch:  907        2 Batch loss: 0.237054 Batch F1: 0.0
Epoch:  907        3 Batch loss: 0.207803 Batch F1: 0.0
Epoch:  907        4 Batch loss: 0.211074 Batch F1: 0.0
Epoch:  907        5 Batch loss: 0.217089 Batch F1: 0.0
Epoch:  907        6 Batch loss: 0.231731 Batch F1: 0.0
Epoch:  907        7 Batch loss: 0.245223 Batch F1: 0.0
Epoch:  907        8 Batch loss: 0.255482 Batch F1: 0.0
Epoch:  907        9 Batch loss: 0.225000 Batch F1: 0.0
Epoch:  907       10 Batch loss: 0.226335 Batch F1: 0.0
Epoch:  907       11 Batch loss: 0.244506 Batch F1: 0.0
Epoch:  907       12 Batch loss: 0.198777 Batch F1: 0.0
Train Avg Loss  907: 0.227844

Train Avg F1  907: 0.0

Val Avg Loss  907: 0.219486

Val Avg F1  907:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 908
--------------------------------------------------------------
Epoch:  908        1 Batch loss: 0.248971 Batch F1: 0.0
Epoch:  908        2 Batch loss: 0.226153 Batch F1: 0.0
Epoch:  908        3 Batch loss: 0.243074 Batch F1: 0.0
Epoch:  908        4 Batch loss: 0.275986 Batch F1: 0.0
Epoch:  908        5 Batch loss: 0.217437 Batch F1: 0.0
Epoch:  908        6 Batch loss: 0.224271 Batch F1: 0.0
Epoch:  908        7 Batch loss: 0.202714 Batch F1: 0.0
Epoch:  908        8 Batch loss: 0.219377 Batch F1: 0.0
Epoch:  908        9 Batch loss: 0.196629 Batch F1: 0.0
Epoch:  908       10 Batch loss: 0.241342 Batch F1: 0.0
Epoch:  908       11 Batch loss: 0.207948 Batch F1: 0.0
Epoch:  908       12 Batch loss: 0.223768 Batch F1: 0.0
Train Avg Loss  908: 0.227306

Train Avg F1  908: 0.0

Val Avg Loss  908: 0.217659

Val Avg F1  908:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 909
--------------------------------------------------------------
Epoch:  909        1 Batch loss: 0.230444 Batch F1: 0.0
Epoch:  909        2 Batch loss: 0.222589 Batch F1: 0.0
Epoch:  909        3 Batch loss: 0.225949 Batch F1: 0.0
Epoch:  909        4 Batch loss: 0.215389 Batch F1: 0.2
Epoch:  909        5 Batch loss: 0.272518 Batch F1: 0.0
Epoch:  909        6 Batch loss: 0.208531 Batch F1: 0.0
Epoch:  909        7 Batch loss: 0.250769 Batch F1: 0.0
Epoch:  909        8 Batch loss: 0.211082 Batch F1: 0.0
Epoch:  909        9 Batch loss: 0.244045 Batch F1: 0.0
Epoch:  909       10 Batch loss: 0.214715 Batch F1: 0.0
Epoch:  909       11 Batch loss: 0.216873 Batch F1: 0.0
Epoch:  909       12 Batch loss: 0.203529 Batch F1: 0.0
Train Avg Loss  909: 0.226369

Train Avg F1  909: 0.016666666666666666

Val Avg Loss  909: 0.217250

Val Avg F1  909:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 910
--------------------------------------------------------------
Epoch:  910        1 Batch loss: 0.245413 Batch F1: 0.0
Epoch:  910        2 Batch loss: 0.207893 Batch F1: 0.0
Epoch:  910        3 Batch loss: 0.224148 Batch F1: 0.0
Epoch:  910        4 Batch loss: 0.223708 Batch F1: 0.10526315789473685
Epoch:  910        5 Batch loss: 0.219345 Batch F1: 0.24
Epoch:  910        6 Batch loss: 0.184563 Batch F1: 0.0
Epoch:  910        7 Batch loss: 0.212852 Batch F1: 0.0
Epoch:  910        8 Batch loss: 0.226878 Batch F1: 0.0
Epoch:  910        9 Batch loss: 0.246051 Batch F1: 0.0
Epoch:  910       10 Batch loss: 0.243322 Batch F1: 0.0
Epoch:  910       11 Batch loss: 0.270529 Batch F1: 0.0
Epoch:  910       12 Batch loss: 0.248378 Batch F1: 0.0
Train Avg Loss  910: 0.229423

Train Avg F1  910: 0.028771929824561403

Val Avg Loss  910: 0.219457

Val Avg F1  910:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 911
--------------------------------------------------------------
Epoch:  911        1 Batch loss: 0.206851 Batch F1: 0.0
Epoch:  911        2 Batch loss: 0.217865 Batch F1: 0.0
Epoch:  911        3 Batch loss: 0.219437 Batch F1: 0.0
Epoch:  911        4 Batch loss: 0.241974 Batch F1: 0.0
Epoch:  911        5 Batch loss: 0.272728 Batch F1: 0.0
Epoch:  911        6 Batch loss: 0.211162 Batch F1: 0.0
Epoch:  911        7 Batch loss: 0.223565 Batch F1: 0.0
Epoch:  911        8 Batch loss: 0.198698 Batch F1: 0.0
Epoch:  911        9 Batch loss: 0.221536 Batch F1: 0.0
Epoch:  911       10 Batch loss: 0.192838 Batch F1: 0.0
Epoch:  911       11 Batch loss: 0.274735 Batch F1: 0.0
Epoch:  911       12 Batch loss: 0.285668 Batch F1: 0.0
Train Avg Loss  911: 0.230588

Train Avg F1  911: 0.0

Val Avg Loss  911: 0.217883

Val Avg F1  911:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 912
--------------------------------------------------------------
Epoch:  912        1 Batch loss: 0.197806 Batch F1: 0.0
Epoch:  912        2 Batch loss: 0.231358 Batch F1: 0.0
Epoch:  912        3 Batch loss: 0.226437 Batch F1: 0.0
Epoch:  912        4 Batch loss: 0.215038 Batch F1: 0.0
Epoch:  912        5 Batch loss: 0.241903 Batch F1: 0.0
Epoch:  912        6 Batch loss: 0.211959 Batch F1: 0.0
Epoch:  912        7 Batch loss: 0.219024 Batch F1: 0.0
Epoch:  912        8 Batch loss: 0.263141 Batch F1: 0.0
Epoch:  912        9 Batch loss: 0.200646 Batch F1: 0.0
Epoch:  912       10 Batch loss: 0.242760 Batch F1: 0.0
Epoch:  912       11 Batch loss: 0.238599 Batch F1: 0.0
Epoch:  912       12 Batch loss: 0.229450 Batch F1: 0.0
Train Avg Loss  912: 0.226510

Train Avg F1  912: 0.0

Val Avg Loss  912: 0.218430

Val Avg F1  912:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 913
--------------------------------------------------------------
Epoch:  913        1 Batch loss: 0.237078 Batch F1: 0.0
Epoch:  913        2 Batch loss: 0.221442 Batch F1: 0.0
Epoch:  913        3 Batch loss: 0.247242 Batch F1: 0.0
Epoch:  913        4 Batch loss: 0.242797 Batch F1: 0.3448275862068966
Epoch:  913        5 Batch loss: 0.233865 Batch F1: 0.3076923076923077
Epoch:  913        6 Batch loss: 0.219013 Batch F1: 0.0
Epoch:  913        7 Batch loss: 0.249764 Batch F1: 0.0
Epoch:  913        8 Batch loss: 0.182151 Batch F1: 0.0
Epoch:  913        9 Batch loss: 0.225897 Batch F1: 0.0
Epoch:  913       10 Batch loss: 0.236973 Batch F1: 0.0
Epoch:  913       11 Batch loss: 0.202838 Batch F1: 0.0
Epoch:  913       12 Batch loss: 0.240688 Batch F1: 0.0
Train Avg Loss  913: 0.228312

Train Avg F1  913: 0.05437665782493369

Val Avg Loss  913: 0.216814

Val Avg F1  913:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 914
--------------------------------------------------------------
Epoch:  914        1 Batch loss: 0.163626 Batch F1: 0.0
Epoch:  914        2 Batch loss: 0.239764 Batch F1: 0.0
Epoch:  914        3 Batch loss: 0.228221 Batch F1: 0.0
Epoch:  914        4 Batch loss: 0.252180 Batch F1: 0.0
Epoch:  914        5 Batch loss: 0.197772 Batch F1: 0.0
Epoch:  914        6 Batch loss: 0.229703 Batch F1: 0.0
Epoch:  914        7 Batch loss: 0.241794 Batch F1: 0.0
Epoch:  914        8 Batch loss: 0.237420 Batch F1: 0.0
Epoch:  914        9 Batch loss: 0.229340 Batch F1: 0.0
Epoch:  914       10 Batch loss: 0.201485 Batch F1: 0.21052631578947367
Epoch:  914       11 Batch loss: 0.256813 Batch F1: 0.0
Epoch:  914       12 Batch loss: 0.254452 Batch F1: 0.0
Train Avg Loss  914: 0.227714

Train Avg F1  914: 0.017543859649122806

Val Avg Loss  914: 0.219200

Val Avg F1  914:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 915
--------------------------------------------------------------
Epoch:  915        1 Batch loss: 0.228324 Batch F1: 0.0
Epoch:  915        2 Batch loss: 0.245691 Batch F1: 0.0
Epoch:  915        3 Batch loss: 0.226904 Batch F1: 0.0
Epoch:  915        4 Batch loss: 0.188263 Batch F1: 0.0
Epoch:  915        5 Batch loss: 0.226392 Batch F1: 0.0
Epoch:  915        6 Batch loss: 0.197649 Batch F1: 0.0
Epoch:  915        7 Batch loss: 0.259145 Batch F1: 0.0
Epoch:  915        8 Batch loss: 0.215380 Batch F1: 0.0
Epoch:  915        9 Batch loss: 0.253376 Batch F1: 0.0
Epoch:  915       10 Batch loss: 0.232765 Batch F1: 0.0
Epoch:  915       11 Batch loss: 0.219597 Batch F1: 0.0
Epoch:  915       12 Batch loss: 0.235745 Batch F1: 0.0
Train Avg Loss  915: 0.227436

Train Avg F1  915: 0.0

Val Avg Loss  915: 0.218545

Val Avg F1  915:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 916
--------------------------------------------------------------
Epoch:  916        1 Batch loss: 0.202425 Batch F1: 0.0
Epoch:  916        2 Batch loss: 0.204110 Batch F1: 0.0
Epoch:  916        3 Batch loss: 0.229650 Batch F1: 0.0
Epoch:  916        4 Batch loss: 0.210368 Batch F1: 0.0
Epoch:  916        5 Batch loss: 0.223650 Batch F1: 0.0
Epoch:  916        6 Batch loss: 0.205056 Batch F1: 0.0
Epoch:  916        7 Batch loss: 0.242872 Batch F1: 0.0
Epoch:  916        8 Batch loss: 0.238845 Batch F1: 0.0
Epoch:  916        9 Batch loss: 0.257779 Batch F1: 0.0
Epoch:  916       10 Batch loss: 0.236800 Batch F1: 0.0
Epoch:  916       11 Batch loss: 0.241977 Batch F1: 0.0
Epoch:  916       12 Batch loss: 0.217919 Batch F1: 0.0
Train Avg Loss  916: 0.225954

Train Avg F1  916: 0.0

Val Avg Loss  916: 0.218074

Val Avg F1  916:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 917
--------------------------------------------------------------
Epoch:  917        1 Batch loss: 0.235539 Batch F1: 0.0
Epoch:  917        2 Batch loss: 0.224882 Batch F1: 0.0
Epoch:  917        3 Batch loss: 0.220681 Batch F1: 0.0
Epoch:  917        4 Batch loss: 0.216776 Batch F1: 0.0
Epoch:  917        5 Batch loss: 0.211688 Batch F1: 0.0
Epoch:  917        6 Batch loss: 0.230086 Batch F1: 0.0
Epoch:  917        7 Batch loss: 0.204396 Batch F1: 0.0
Epoch:  917        8 Batch loss: 0.222916 Batch F1: 0.0
Epoch:  917        9 Batch loss: 0.243942 Batch F1: 0.0
Epoch:  917       10 Batch loss: 0.215663 Batch F1: 0.0
Epoch:  917       11 Batch loss: 0.251203 Batch F1: 0.0
Epoch:  917       12 Batch loss: 0.234940 Batch F1: 0.0
Train Avg Loss  917: 0.226059

Train Avg F1  917: 0.0

Val Avg Loss  917: 0.219037

Val Avg F1  917:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 918
--------------------------------------------------------------
Epoch:  918        1 Batch loss: 0.217501 Batch F1: 0.0
Epoch:  918        2 Batch loss: 0.246464 Batch F1: 0.0
Epoch:  918        3 Batch loss: 0.237944 Batch F1: 0.0
Epoch:  918        4 Batch loss: 0.217509 Batch F1: 0.0
Epoch:  918        5 Batch loss: 0.207427 Batch F1: 0.0
Epoch:  918        6 Batch loss: 0.236736 Batch F1: 0.0
Epoch:  918        7 Batch loss: 0.211506 Batch F1: 0.0
Epoch:  918        8 Batch loss: 0.221858 Batch F1: 0.0
Epoch:  918        9 Batch loss: 0.210203 Batch F1: 0.0
Epoch:  918       10 Batch loss: 0.217403 Batch F1: 0.0
Epoch:  918       11 Batch loss: 0.248827 Batch F1: 0.0
Epoch:  918       12 Batch loss: 0.238214 Batch F1: 0.0
Train Avg Loss  918: 0.225966

Train Avg F1  918: 0.0

Val Avg Loss  918: 0.217593

Val Avg F1  918:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 919
--------------------------------------------------------------
Epoch:  919        1 Batch loss: 0.235580 Batch F1: 0.0
Epoch:  919        2 Batch loss: 0.203222 Batch F1: 0.0
Epoch:  919        3 Batch loss: 0.243207 Batch F1: 0.0
Epoch:  919        4 Batch loss: 0.229359 Batch F1: 0.0
Epoch:  919        5 Batch loss: 0.232898 Batch F1: 0.23076923076923078
Epoch:  919        6 Batch loss: 0.226490 Batch F1: 0.27272727272727276
Epoch:  919        7 Batch loss: 0.226451 Batch F1: 0.17391304347826086
Epoch:  919        8 Batch loss: 0.233620 Batch F1: 0.0
Epoch:  919        9 Batch loss: 0.241484 Batch F1: 0.0
Epoch:  919       10 Batch loss: 0.176542 Batch F1: 0.0
Epoch:  919       11 Batch loss: 0.242531 Batch F1: 0.0
Epoch:  919       12 Batch loss: 0.221816 Batch F1: 0.0
Train Avg Loss  919: 0.226100

Train Avg F1  919: 0.05645079558123037

Val Avg Loss  919: 0.216713

Val Avg F1  919:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 920
--------------------------------------------------------------
Epoch:  920        1 Batch loss: 0.190969 Batch F1: 0.0
Epoch:  920        2 Batch loss: 0.207921 Batch F1: 0.0
Epoch:  920        3 Batch loss: 0.222669 Batch F1: 0.0
Epoch:  920        4 Batch loss: 0.281008 Batch F1: 0.0
Epoch:  920        5 Batch loss: 0.255013 Batch F1: 0.0
Epoch:  920        6 Batch loss: 0.229645 Batch F1: 0.0
Epoch:  920        7 Batch loss: 0.212693 Batch F1: 0.0
Epoch:  920        8 Batch loss: 0.199150 Batch F1: 0.0
Epoch:  920        9 Batch loss: 0.201806 Batch F1: 0.0
Epoch:  920       10 Batch loss: 0.237874 Batch F1: 0.0
Epoch:  920       11 Batch loss: 0.255383 Batch F1: 0.0
Epoch:  920       12 Batch loss: 0.230659 Batch F1: 0.0
Train Avg Loss  920: 0.227066

Train Avg F1  920: 0.0

Val Avg Loss  920: 0.216281

Val Avg F1  920:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 921
--------------------------------------------------------------
Epoch:  921        1 Batch loss: 0.219911 Batch F1: 0.0
Epoch:  921        2 Batch loss: 0.226946 Batch F1: 0.0
Epoch:  921        3 Batch loss: 0.222359 Batch F1: 0.0
Epoch:  921        4 Batch loss: 0.220059 Batch F1: 0.0
Epoch:  921        5 Batch loss: 0.201294 Batch F1: 0.0
Epoch:  921        6 Batch loss: 0.243277 Batch F1: 0.0
Epoch:  921        7 Batch loss: 0.247977 Batch F1: 0.0
Epoch:  921        8 Batch loss: 0.252871 Batch F1: 0.0
Epoch:  921        9 Batch loss: 0.207878 Batch F1: 0.0
Epoch:  921       10 Batch loss: 0.241400 Batch F1: 0.0
Epoch:  921       11 Batch loss: 0.191697 Batch F1: 0.0
Epoch:  921       12 Batch loss: 0.236459 Batch F1: 0.0
Train Avg Loss  921: 0.226011

Train Avg F1  921: 0.0

Val Avg Loss  921: 0.218235

Val Avg F1  921:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 922
--------------------------------------------------------------
Epoch:  922        1 Batch loss: 0.185804 Batch F1: 0.0
Epoch:  922        2 Batch loss: 0.238299 Batch F1: 0.0
Epoch:  922        3 Batch loss: 0.215256 Batch F1: 0.0
Epoch:  922        4 Batch loss: 0.216033 Batch F1: 0.0
Epoch:  922        5 Batch loss: 0.251686 Batch F1: 0.0
Epoch:  922        6 Batch loss: 0.264123 Batch F1: 0.0
Epoch:  922        7 Batch loss: 0.229031 Batch F1: 0.0
Epoch:  922        8 Batch loss: 0.209965 Batch F1: 0.0
Epoch:  922        9 Batch loss: 0.233098 Batch F1: 0.0
Epoch:  922       10 Batch loss: 0.230912 Batch F1: 0.0
Epoch:  922       11 Batch loss: 0.215254 Batch F1: 0.0
Epoch:  922       12 Batch loss: 0.236132 Batch F1: 0.0
Train Avg Loss  922: 0.227133

Train Avg F1  922: 0.0

Val Avg Loss  922: 0.217834

Val Avg F1  922:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 923
--------------------------------------------------------------
Epoch:  923        1 Batch loss: 0.200117 Batch F1: 0.0
Epoch:  923        2 Batch loss: 0.221131 Batch F1: 0.0
Epoch:  923        3 Batch loss: 0.270852 Batch F1: 0.0
Epoch:  923        4 Batch loss: 0.203130 Batch F1: 0.0
Epoch:  923        5 Batch loss: 0.256761 Batch F1: 0.0
Epoch:  923        6 Batch loss: 0.202687 Batch F1: 0.0
Epoch:  923        7 Batch loss: 0.217699 Batch F1: 0.0
Epoch:  923        8 Batch loss: 0.219642 Batch F1: 0.0
Epoch:  923        9 Batch loss: 0.252104 Batch F1: 0.0
Epoch:  923       10 Batch loss: 0.223110 Batch F1: 0.0
Epoch:  923       11 Batch loss: 0.223650 Batch F1: 0.0
Epoch:  923       12 Batch loss: 0.229984 Batch F1: 0.0
Train Avg Loss  923: 0.226739

Train Avg F1  923: 0.0

Val Avg Loss  923: 0.219760

Val Avg F1  923:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 924
--------------------------------------------------------------
Epoch:  924        1 Batch loss: 0.248669 Batch F1: 0.0
Epoch:  924        2 Batch loss: 0.232408 Batch F1: 0.0
Epoch:  924        3 Batch loss: 0.202078 Batch F1: 0.0
Epoch:  924        4 Batch loss: 0.216037 Batch F1: 0.0
Epoch:  924        5 Batch loss: 0.246460 Batch F1: 0.0
Epoch:  924        6 Batch loss: 0.234694 Batch F1: 0.0
Epoch:  924        7 Batch loss: 0.217907 Batch F1: 0.0
Epoch:  924        8 Batch loss: 0.231035 Batch F1: 0.0
Epoch:  924        9 Batch loss: 0.241513 Batch F1: 0.0
Epoch:  924       10 Batch loss: 0.225316 Batch F1: 0.0
Epoch:  924       11 Batch loss: 0.224632 Batch F1: 0.0
Epoch:  924       12 Batch loss: 0.216328 Batch F1: 0.0
Train Avg Loss  924: 0.228090

Train Avg F1  924: 0.0

Val Avg Loss  924: 0.218648

Val Avg F1  924:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 925
--------------------------------------------------------------
Epoch:  925        1 Batch loss: 0.221982 Batch F1: 0.0
Epoch:  925        2 Batch loss: 0.221059 Batch F1: 0.0
Epoch:  925        3 Batch loss: 0.219014 Batch F1: 0.0
Epoch:  925        4 Batch loss: 0.205574 Batch F1: 0.0
Epoch:  925        5 Batch loss: 0.231981 Batch F1: 0.0
Epoch:  925        6 Batch loss: 0.238300 Batch F1: 0.0
Epoch:  925        7 Batch loss: 0.279181 Batch F1: 0.0
Epoch:  925        8 Batch loss: 0.246252 Batch F1: 0.0
Epoch:  925        9 Batch loss: 0.227422 Batch F1: 0.0
Epoch:  925       10 Batch loss: 0.206000 Batch F1: 0.0
Epoch:  925       11 Batch loss: 0.216741 Batch F1: 0.0
Epoch:  925       12 Batch loss: 0.232859 Batch F1: 0.0
Train Avg Loss  925: 0.228864

Train Avg F1  925: 0.0

Val Avg Loss  925: 0.218170

Val Avg F1  925:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 926
--------------------------------------------------------------
Epoch:  926        1 Batch loss: 0.233047 Batch F1: 0.0
Epoch:  926        2 Batch loss: 0.218348 Batch F1: 0.0
Epoch:  926        3 Batch loss: 0.243508 Batch F1: 0.0
Epoch:  926        4 Batch loss: 0.213091 Batch F1: 0.0
Epoch:  926        5 Batch loss: 0.203451 Batch F1: 0.0
Epoch:  926        6 Batch loss: 0.221227 Batch F1: 0.0
Epoch:  926        7 Batch loss: 0.237629 Batch F1: 0.0
Epoch:  926        8 Batch loss: 0.237623 Batch F1: 0.0
Epoch:  926        9 Batch loss: 0.246594 Batch F1: 0.0
Epoch:  926       10 Batch loss: 0.241648 Batch F1: 0.0
Epoch:  926       11 Batch loss: 0.213824 Batch F1: 0.0
Epoch:  926       12 Batch loss: 0.201610 Batch F1: 0.0
Train Avg Loss  926: 0.225967

Train Avg F1  926: 0.0

Val Avg Loss  926: 0.218023

Val Avg F1  926:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 927
--------------------------------------------------------------
Epoch:  927        1 Batch loss: 0.245205 Batch F1: 0.0
Epoch:  927        2 Batch loss: 0.239112 Batch F1: 0.0
Epoch:  927        3 Batch loss: 0.243648 Batch F1: 0.0
Epoch:  927        4 Batch loss: 0.185991 Batch F1: 0.0
Epoch:  927        5 Batch loss: 0.214471 Batch F1: 0.0
Epoch:  927        6 Batch loss: 0.241349 Batch F1: 0.0
Epoch:  927        7 Batch loss: 0.248457 Batch F1: 0.0
Epoch:  927        8 Batch loss: 0.216143 Batch F1: 0.0
Epoch:  927        9 Batch loss: 0.239660 Batch F1: 0.0
Epoch:  927       10 Batch loss: 0.228314 Batch F1: 0.0
Epoch:  927       11 Batch loss: 0.185166 Batch F1: 0.0
Epoch:  927       12 Batch loss: 0.239557 Batch F1: 0.0
Train Avg Loss  927: 0.227256

Train Avg F1  927: 0.0

Val Avg Loss  927: 0.217285

Val Avg F1  927:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 928
--------------------------------------------------------------
Epoch:  928        1 Batch loss: 0.241374 Batch F1: 0.0
Epoch:  928        2 Batch loss: 0.240186 Batch F1: 0.0
Epoch:  928        3 Batch loss: 0.206490 Batch F1: 0.0
Epoch:  928        4 Batch loss: 0.225468 Batch F1: 0.0
Epoch:  928        5 Batch loss: 0.194235 Batch F1: 0.0
Epoch:  928        6 Batch loss: 0.269172 Batch F1: 0.0
Epoch:  928        7 Batch loss: 0.205743 Batch F1: 0.0
Epoch:  928        8 Batch loss: 0.247436 Batch F1: 0.0
Epoch:  928        9 Batch loss: 0.215229 Batch F1: 0.0
Epoch:  928       10 Batch loss: 0.223473 Batch F1: 0.0
Epoch:  928       11 Batch loss: 0.229419 Batch F1: 0.0
Epoch:  928       12 Batch loss: 0.221319 Batch F1: 0.0
Train Avg Loss  928: 0.226629

Train Avg F1  928: 0.0

Val Avg Loss  928: 0.219421

Val Avg F1  928:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 929
--------------------------------------------------------------
Epoch:  929        1 Batch loss: 0.244931 Batch F1: 0.0
Epoch:  929        2 Batch loss: 0.224260 Batch F1: 0.0
Epoch:  929        3 Batch loss: 0.228581 Batch F1: 0.0
Epoch:  929        4 Batch loss: 0.193150 Batch F1: 0.0
Epoch:  929        5 Batch loss: 0.255723 Batch F1: 0.0
Epoch:  929        6 Batch loss: 0.250954 Batch F1: 0.0
Epoch:  929        7 Batch loss: 0.202408 Batch F1: 0.0
Epoch:  929        8 Batch loss: 0.225969 Batch F1: 0.0
Epoch:  929        9 Batch loss: 0.243621 Batch F1: 0.0
Epoch:  929       10 Batch loss: 0.218453 Batch F1: 0.4666666666666667
Epoch:  929       11 Batch loss: 0.242226 Batch F1: 0.0
Epoch:  929       12 Batch loss: 0.220719 Batch F1: 0.0
Train Avg Loss  929: 0.229250

Train Avg F1  929: 0.03888888888888889

Val Avg Loss  929: 0.217851

Val Avg F1  929:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 930
--------------------------------------------------------------
Epoch:  930        1 Batch loss: 0.177984 Batch F1: 0.0
Epoch:  930        2 Batch loss: 0.242078 Batch F1: 0.0
Epoch:  930        3 Batch loss: 0.243986 Batch F1: 0.0
Epoch:  930        4 Batch loss: 0.227846 Batch F1: 0.0
Epoch:  930        5 Batch loss: 0.276855 Batch F1: 0.0
Epoch:  930        6 Batch loss: 0.209954 Batch F1: 0.0
Epoch:  930        7 Batch loss: 0.250814 Batch F1: 0.0
Epoch:  930        8 Batch loss: 0.204210 Batch F1: 0.0
Epoch:  930        9 Batch loss: 0.201093 Batch F1: 0.0
Epoch:  930       10 Batch loss: 0.228557 Batch F1: 0.0
Epoch:  930       11 Batch loss: 0.226477 Batch F1: 0.0
Epoch:  930       12 Batch loss: 0.270031 Batch F1: 0.0
Train Avg Loss  930: 0.229990

Train Avg F1  930: 0.0

Val Avg Loss  930: 0.218867

Val Avg F1  930:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 931
--------------------------------------------------------------
Epoch:  931        1 Batch loss: 0.225384 Batch F1: 0.0
Epoch:  931        2 Batch loss: 0.248060 Batch F1: 0.0
Epoch:  931        3 Batch loss: 0.224513 Batch F1: 0.0
Epoch:  931        4 Batch loss: 0.225411 Batch F1: 0.0
Epoch:  931        5 Batch loss: 0.244345 Batch F1: 0.19047619047619047
Epoch:  931        6 Batch loss: 0.247195 Batch F1: 0.16
Epoch:  931        7 Batch loss: 0.215242 Batch F1: 0.0
Epoch:  931        8 Batch loss: 0.199734 Batch F1: 0.0
Epoch:  931        9 Batch loss: 0.208334 Batch F1: 0.0
Epoch:  931       10 Batch loss: 0.235863 Batch F1: 0.0
Epoch:  931       11 Batch loss: 0.245326 Batch F1: 0.0
Epoch:  931       12 Batch loss: 0.206709 Batch F1: 0.0
Train Avg Loss  931: 0.227176

Train Avg F1  931: 0.029206349206349208

Val Avg Loss  931: 0.217501

Val Avg F1  931:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 932
--------------------------------------------------------------
Epoch:  932        1 Batch loss: 0.236260 Batch F1: 0.0
Epoch:  932        2 Batch loss: 0.279937 Batch F1: 0.0
Epoch:  932        3 Batch loss: 0.212940 Batch F1: 0.1
Epoch:  932        4 Batch loss: 0.215461 Batch F1: 0.0
Epoch:  932        5 Batch loss: 0.275257 Batch F1: 0.0
Epoch:  932        6 Batch loss: 0.206854 Batch F1: 0.0
Epoch:  932        7 Batch loss: 0.206822 Batch F1: 0.0
Epoch:  932        8 Batch loss: 0.203710 Batch F1: 0.0
Epoch:  932        9 Batch loss: 0.220582 Batch F1: 0.0
Epoch:  932       10 Batch loss: 0.224206 Batch F1: 0.0
Epoch:  932       11 Batch loss: 0.208310 Batch F1: 0.0
Epoch:  932       12 Batch loss: 0.239904 Batch F1: 0.0
Train Avg Loss  932: 0.227520

Train Avg F1  932: 0.008333333333333333

Val Avg Loss  932: 0.217034

Val Avg F1  932:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 933
--------------------------------------------------------------
Epoch:  933        1 Batch loss: 0.239710 Batch F1: 0.0
Epoch:  933        2 Batch loss: 0.209980 Batch F1: 0.0
Epoch:  933        3 Batch loss: 0.229606 Batch F1: 0.0
Epoch:  933        4 Batch loss: 0.227325 Batch F1: 0.0
Epoch:  933        5 Batch loss: 0.216282 Batch F1: 0.0
Epoch:  933        6 Batch loss: 0.274879 Batch F1: 0.0
Epoch:  933        7 Batch loss: 0.249189 Batch F1: 0.0
Epoch:  933        8 Batch loss: 0.187218 Batch F1: 0.0
Epoch:  933        9 Batch loss: 0.229252 Batch F1: 0.0
Epoch:  933       10 Batch loss: 0.203569 Batch F1: 0.0
Epoch:  933       11 Batch loss: 0.220523 Batch F1: 0.0
Epoch:  933       12 Batch loss: 0.234173 Batch F1: 0.0
Train Avg Loss  933: 0.226809

Train Avg F1  933: 0.0

Val Avg Loss  933: 0.217451

Val Avg F1  933:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 934
--------------------------------------------------------------
Epoch:  934        1 Batch loss: 0.194943 Batch F1: 0.0
Epoch:  934        2 Batch loss: 0.232197 Batch F1: 0.0
Epoch:  934        3 Batch loss: 0.232717 Batch F1: 0.0
Epoch:  934        4 Batch loss: 0.249625 Batch F1: 0.0
Epoch:  934        5 Batch loss: 0.231059 Batch F1: 0.0
Epoch:  934        6 Batch loss: 0.224885 Batch F1: 0.0
Epoch:  934        7 Batch loss: 0.249004 Batch F1: 0.3333333333333333
Epoch:  934        8 Batch loss: 0.248147 Batch F1: 0.0
Epoch:  934        9 Batch loss: 0.197059 Batch F1: 0.0
Epoch:  934       10 Batch loss: 0.249585 Batch F1: 0.0
Epoch:  934       11 Batch loss: 0.216367 Batch F1: 0.0
Epoch:  934       12 Batch loss: 0.195520 Batch F1: 0.0
Train Avg Loss  934: 0.226759

Train Avg F1  934: 0.027777777777777776

Val Avg Loss  934: 0.217012

Val Avg F1  934:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 935
--------------------------------------------------------------
Epoch:  935        1 Batch loss: 0.229033 Batch F1: 0.0
Epoch:  935        2 Batch loss: 0.230652 Batch F1: 0.0
Epoch:  935        3 Batch loss: 0.270495 Batch F1: 0.0
Epoch:  935        4 Batch loss: 0.208168 Batch F1: 0.0
Epoch:  935        5 Batch loss: 0.254471 Batch F1: 0.0
Epoch:  935        6 Batch loss: 0.208081 Batch F1: 0.0
Epoch:  935        7 Batch loss: 0.233521 Batch F1: 0.0
Epoch:  935        8 Batch loss: 0.209433 Batch F1: 0.0
Epoch:  935        9 Batch loss: 0.202492 Batch F1: 0.0
Epoch:  935       10 Batch loss: 0.218690 Batch F1: 0.0
Epoch:  935       11 Batch loss: 0.250149 Batch F1: 0.0
Epoch:  935       12 Batch loss: 0.232515 Batch F1: 0.0
Train Avg Loss  935: 0.228975

Train Avg F1  935: 0.0

Val Avg Loss  935: 0.218507

Val Avg F1  935:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 936
--------------------------------------------------------------
Epoch:  936        1 Batch loss: 0.268823 Batch F1: 0.0
Epoch:  936        2 Batch loss: 0.215254 Batch F1: 0.0
Epoch:  936        3 Batch loss: 0.212152 Batch F1: 0.3809523809523809
Epoch:  936        4 Batch loss: 0.231789 Batch F1: 0.41379310344827586
Epoch:  936        5 Batch loss: 0.223588 Batch F1: 0.0
Epoch:  936        6 Batch loss: 0.245806 Batch F1: 0.0
Epoch:  936        7 Batch loss: 0.272450 Batch F1: 0.0
Epoch:  936        8 Batch loss: 0.203452 Batch F1: 0.0
Epoch:  936        9 Batch loss: 0.237061 Batch F1: 0.0
Epoch:  936       10 Batch loss: 0.256545 Batch F1: 0.0
Epoch:  936       11 Batch loss: 0.204216 Batch F1: 0.0
Epoch:  936       12 Batch loss: 0.179379 Batch F1: 0.0
Train Avg Loss  936: 0.229210

Train Avg F1  936: 0.0662287903667214

Val Avg Loss  936: 0.218490

Val Avg F1  936:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 937
--------------------------------------------------------------
Epoch:  937        1 Batch loss: 0.271537 Batch F1: 0.0
Epoch:  937        2 Batch loss: 0.228865 Batch F1: 0.0
Epoch:  937        3 Batch loss: 0.222750 Batch F1: 0.0
Epoch:  937        4 Batch loss: 0.238462 Batch F1: 0.0
Epoch:  937        5 Batch loss: 0.193112 Batch F1: 0.0
Epoch:  937        6 Batch loss: 0.218963 Batch F1: 0.0
Epoch:  937        7 Batch loss: 0.240941 Batch F1: 0.0
Epoch:  937        8 Batch loss: 0.216641 Batch F1: 0.0
Epoch:  937        9 Batch loss: 0.223552 Batch F1: 0.0
Epoch:  937       10 Batch loss: 0.233454 Batch F1: 0.0
Epoch:  937       11 Batch loss: 0.223333 Batch F1: 0.0
Epoch:  937       12 Batch loss: 0.232768 Batch F1: 0.0
Train Avg Loss  937: 0.228698

Train Avg F1  937: 0.0

Val Avg Loss  937: 0.217475

Val Avg F1  937:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 938
--------------------------------------------------------------
Epoch:  938        1 Batch loss: 0.218916 Batch F1: 0.0
Epoch:  938        2 Batch loss: 0.231629 Batch F1: 0.0
Epoch:  938        3 Batch loss: 0.206828 Batch F1: 0.0
Epoch:  938        4 Batch loss: 0.192085 Batch F1: 0.0
Epoch:  938        5 Batch loss: 0.209284 Batch F1: 0.0
Epoch:  938        6 Batch loss: 0.239065 Batch F1: 0.0
Epoch:  938        7 Batch loss: 0.280051 Batch F1: 0.0
Epoch:  938        8 Batch loss: 0.233954 Batch F1: 0.0
Epoch:  938        9 Batch loss: 0.222379 Batch F1: 0.0
Epoch:  938       10 Batch loss: 0.238576 Batch F1: 0.0
Epoch:  938       11 Batch loss: 0.223636 Batch F1: 0.0
Epoch:  938       12 Batch loss: 0.222818 Batch F1: 0.0
Train Avg Loss  938: 0.226602

Train Avg F1  938: 0.0

Val Avg Loss  938: 0.217653

Val Avg F1  938:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 939
--------------------------------------------------------------
Epoch:  939        1 Batch loss: 0.217873 Batch F1: 0.0
Epoch:  939        2 Batch loss: 0.239617 Batch F1: 0.0
Epoch:  939        3 Batch loss: 0.244289 Batch F1: 0.0
Epoch:  939        4 Batch loss: 0.208625 Batch F1: 0.0
Epoch:  939        5 Batch loss: 0.207992 Batch F1: 0.0
Epoch:  939        6 Batch loss: 0.210794 Batch F1: 0.0
Epoch:  939        7 Batch loss: 0.225050 Batch F1: 0.0
Epoch:  939        8 Batch loss: 0.223336 Batch F1: 0.0
Epoch:  939        9 Batch loss: 0.260074 Batch F1: 0.0
Epoch:  939       10 Batch loss: 0.263844 Batch F1: 0.0
Epoch:  939       11 Batch loss: 0.206976 Batch F1: 0.0
Epoch:  939       12 Batch loss: 0.199064 Batch F1: 0.0
Train Avg Loss  939: 0.225628

Train Avg F1  939: 0.0

Val Avg Loss  939: 0.217572

Val Avg F1  939:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 940
--------------------------------------------------------------
Epoch:  940        1 Batch loss: 0.230904 Batch F1: 0.0
Epoch:  940        2 Batch loss: 0.221948 Batch F1: 0.0
Epoch:  940        3 Batch loss: 0.218000 Batch F1: 0.0
Epoch:  940        4 Batch loss: 0.207082 Batch F1: 0.0
Epoch:  940        5 Batch loss: 0.202334 Batch F1: 0.0
Epoch:  940        6 Batch loss: 0.245156 Batch F1: 0.0
Epoch:  940        7 Batch loss: 0.238311 Batch F1: 0.0
Epoch:  940        8 Batch loss: 0.228902 Batch F1: 0.0
Epoch:  940        9 Batch loss: 0.240472 Batch F1: 0.0
Epoch:  940       10 Batch loss: 0.234255 Batch F1: 0.0
Epoch:  940       11 Batch loss: 0.191124 Batch F1: 0.0
Epoch:  940       12 Batch loss: 0.259657 Batch F1: 0.0
Train Avg Loss  940: 0.226512

Train Avg F1  940: 0.0

Val Avg Loss  940: 0.217151

Val Avg F1  940:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 941
--------------------------------------------------------------
Epoch:  941        1 Batch loss: 0.256452 Batch F1: 0.0
Epoch:  941        2 Batch loss: 0.215455 Batch F1: 0.0
Epoch:  941        3 Batch loss: 0.220912 Batch F1: 0.0
Epoch:  941        4 Batch loss: 0.259109 Batch F1: 0.0
Epoch:  941        5 Batch loss: 0.241220 Batch F1: 0.2580645161290323
Epoch:  941        6 Batch loss: 0.230785 Batch F1: 0.2962962962962963
Epoch:  941        7 Batch loss: 0.228370 Batch F1: 0.4166666666666667
Epoch:  941        8 Batch loss: 0.235477 Batch F1: 0.0
Epoch:  941        9 Batch loss: 0.223708 Batch F1: 0.0
Epoch:  941       10 Batch loss: 0.204413 Batch F1: 0.0
Epoch:  941       11 Batch loss: 0.228216 Batch F1: 0.0
Epoch:  941       12 Batch loss: 0.182314 Batch F1: 0.0
Train Avg Loss  941: 0.227203

Train Avg F1  941: 0.08091895659099961

Val Avg Loss  941: 0.217435

Val Avg F1  941:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 942
--------------------------------------------------------------
Epoch:  942        1 Batch loss: 0.241955 Batch F1: 0.0
Epoch:  942        2 Batch loss: 0.254554 Batch F1: 0.0
Epoch:  942        3 Batch loss: 0.219414 Batch F1: 0.0
Epoch:  942        4 Batch loss: 0.203248 Batch F1: 0.0
Epoch:  942        5 Batch loss: 0.253676 Batch F1: 0.0
Epoch:  942        6 Batch loss: 0.217661 Batch F1: 0.0
Epoch:  942        7 Batch loss: 0.226728 Batch F1: 0.0
Epoch:  942        8 Batch loss: 0.205527 Batch F1: 0.0
Epoch:  942        9 Batch loss: 0.203504 Batch F1: 0.0
Epoch:  942       10 Batch loss: 0.240945 Batch F1: 0.0
Epoch:  942       11 Batch loss: 0.250674 Batch F1: 0.0
Epoch:  942       12 Batch loss: 0.217707 Batch F1: 0.0
Train Avg Loss  942: 0.227966

Train Avg F1  942: 0.0

Val Avg Loss  942: 0.217312

Val Avg F1  942:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 943
--------------------------------------------------------------
Epoch:  943        1 Batch loss: 0.238835 Batch F1: 0.0
Epoch:  943        2 Batch loss: 0.222306 Batch F1: 0.0
Epoch:  943        3 Batch loss: 0.248642 Batch F1: 0.0
Epoch:  943        4 Batch loss: 0.215951 Batch F1: 0.0
Epoch:  943        5 Batch loss: 0.261180 Batch F1: 0.0
Epoch:  943        6 Batch loss: 0.202028 Batch F1: 0.0
Epoch:  943        7 Batch loss: 0.213210 Batch F1: 0.0
Epoch:  943        8 Batch loss: 0.244316 Batch F1: 0.0
Epoch:  943        9 Batch loss: 0.242275 Batch F1: 0.0
Epoch:  943       10 Batch loss: 0.213644 Batch F1: 0.0
Epoch:  943       11 Batch loss: 0.203319 Batch F1: 0.0
Epoch:  943       12 Batch loss: 0.222591 Batch F1: 0.0
Train Avg Loss  943: 0.227358

Train Avg F1  943: 0.0

Val Avg Loss  943: 0.216948

Val Avg F1  943:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 944
--------------------------------------------------------------
Epoch:  944        1 Batch loss: 0.180817 Batch F1: 0.0
Epoch:  944        2 Batch loss: 0.237233 Batch F1: 0.0
Epoch:  944        3 Batch loss: 0.244461 Batch F1: 0.0
Epoch:  944        4 Batch loss: 0.252699 Batch F1: 0.0
Epoch:  944        5 Batch loss: 0.230376 Batch F1: 0.0
Epoch:  944        6 Batch loss: 0.224236 Batch F1: 0.0
Epoch:  944        7 Batch loss: 0.216106 Batch F1: 0.0
Epoch:  944        8 Batch loss: 0.237153 Batch F1: 0.0
Epoch:  944        9 Batch loss: 0.239893 Batch F1: 0.0
Epoch:  944       10 Batch loss: 0.206275 Batch F1: 0.0
Epoch:  944       11 Batch loss: 0.237275 Batch F1: 0.0
Epoch:  944       12 Batch loss: 0.210163 Batch F1: 0.0
Train Avg Loss  944: 0.226391

Train Avg F1  944: 0.0

Val Avg Loss  944: 0.217944

Val Avg F1  944:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 945
--------------------------------------------------------------
Epoch:  945        1 Batch loss: 0.246351 Batch F1: 0.0
Epoch:  945        2 Batch loss: 0.214800 Batch F1: 0.0
Epoch:  945        3 Batch loss: 0.254759 Batch F1: 0.0
Epoch:  945        4 Batch loss: 0.211052 Batch F1: 0.0
Epoch:  945        5 Batch loss: 0.260475 Batch F1: 0.0
Epoch:  945        6 Batch loss: 0.235735 Batch F1: 0.0
Epoch:  945        7 Batch loss: 0.191518 Batch F1: 0.0
Epoch:  945        8 Batch loss: 0.217209 Batch F1: 0.0
Epoch:  945        9 Batch loss: 0.222568 Batch F1: 0.0
Epoch:  945       10 Batch loss: 0.218829 Batch F1: 0.0
Epoch:  945       11 Batch loss: 0.217892 Batch F1: 0.0
Epoch:  945       12 Batch loss: 0.224624 Batch F1: 0.0
Train Avg Loss  945: 0.226318

Train Avg F1  945: 0.0

Val Avg Loss  945: 0.217802

Val Avg F1  945:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 946
--------------------------------------------------------------
Epoch:  946        1 Batch loss: 0.187422 Batch F1: 0.0
Epoch:  946        2 Batch loss: 0.226199 Batch F1: 0.0
Epoch:  946        3 Batch loss: 0.184102 Batch F1: 0.0
Epoch:  946        4 Batch loss: 0.226655 Batch F1: 0.0
Epoch:  946        5 Batch loss: 0.214223 Batch F1: 0.0
Epoch:  946        6 Batch loss: 0.256293 Batch F1: 0.0
Epoch:  946        7 Batch loss: 0.190600 Batch F1: 0.0
Epoch:  946        8 Batch loss: 0.232549 Batch F1: 0.0
Epoch:  946        9 Batch loss: 0.249096 Batch F1: 0.0
Epoch:  946       10 Batch loss: 0.221982 Batch F1: 0.0
Epoch:  946       11 Batch loss: 0.264159 Batch F1: 0.0
Epoch:  946       12 Batch loss: 0.259456 Batch F1: 0.0
Train Avg Loss  946: 0.226061

Train Avg F1  946: 0.0

Val Avg Loss  946: 0.228573

Val Avg F1  946:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 947
--------------------------------------------------------------
Epoch:  947        1 Batch loss: 0.229578 Batch F1: 0.0
Epoch:  947        2 Batch loss: 0.253376 Batch F1: 0.0
Epoch:  947        3 Batch loss: 0.241577 Batch F1: 0.0
Epoch:  947        4 Batch loss: 0.249046 Batch F1: 0.0
Epoch:  947        5 Batch loss: 0.226200 Batch F1: 0.0
Epoch:  947        6 Batch loss: 0.227473 Batch F1: 0.0
Epoch:  947        7 Batch loss: 0.222321 Batch F1: 0.0
Epoch:  947        8 Batch loss: 0.226086 Batch F1: 0.0
Epoch:  947        9 Batch loss: 0.215861 Batch F1: 0.0
Epoch:  947       10 Batch loss: 0.227082 Batch F1: 0.0
Epoch:  947       11 Batch loss: 0.215975 Batch F1: 0.0
Epoch:  947       12 Batch loss: 0.226493 Batch F1: 0.0
Train Avg Loss  947: 0.230089

Train Avg F1  947: 0.0

Val Avg Loss  947: 0.218019

Val Avg F1  947:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 948
--------------------------------------------------------------
Epoch:  948        1 Batch loss: 0.225867 Batch F1: 0.0
Epoch:  948        2 Batch loss: 0.250333 Batch F1: 0.0
Epoch:  948        3 Batch loss: 0.207192 Batch F1: 0.0
Epoch:  948        4 Batch loss: 0.232588 Batch F1: 0.0
Epoch:  948        5 Batch loss: 0.228080 Batch F1: 0.0
Epoch:  948        6 Batch loss: 0.217074 Batch F1: 0.0
Epoch:  948        7 Batch loss: 0.235856 Batch F1: 0.0
Epoch:  948        8 Batch loss: 0.217453 Batch F1: 0.0
Epoch:  948        9 Batch loss: 0.218107 Batch F1: 0.0
Epoch:  948       10 Batch loss: 0.214505 Batch F1: 0.0
Epoch:  948       11 Batch loss: 0.265075 Batch F1: 0.0
Epoch:  948       12 Batch loss: 0.233908 Batch F1: 0.0
Train Avg Loss  948: 0.228836

Train Avg F1  948: 0.0

Val Avg Loss  948: 0.218614

Val Avg F1  948:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 949
--------------------------------------------------------------
Epoch:  949        1 Batch loss: 0.238308 Batch F1: 0.0
Epoch:  949        2 Batch loss: 0.237221 Batch F1: 0.0
Epoch:  949        3 Batch loss: 0.212453 Batch F1: 0.0
Epoch:  949        4 Batch loss: 0.222120 Batch F1: 0.0
Epoch:  949        5 Batch loss: 0.215236 Batch F1: 0.0
Epoch:  949        6 Batch loss: 0.214330 Batch F1: 0.0
Epoch:  949        7 Batch loss: 0.286300 Batch F1: 0.0
Epoch:  949        8 Batch loss: 0.223399 Batch F1: 0.0
Epoch:  949        9 Batch loss: 0.222064 Batch F1: 0.0
Epoch:  949       10 Batch loss: 0.206735 Batch F1: 0.0
Epoch:  949       11 Batch loss: 0.254094 Batch F1: 0.0
Epoch:  949       12 Batch loss: 0.203993 Batch F1: 0.0
Train Avg Loss  949: 0.228021

Train Avg F1  949: 0.0

Val Avg Loss  949: 0.219318

Val Avg F1  949:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 950
--------------------------------------------------------------
Epoch:  950        1 Batch loss: 0.206695 Batch F1: 0.0
Epoch:  950        2 Batch loss: 0.240211 Batch F1: 0.0
Epoch:  950        3 Batch loss: 0.214426 Batch F1: 0.0
Epoch:  950        4 Batch loss: 0.254160 Batch F1: 0.0
Epoch:  950        5 Batch loss: 0.236031 Batch F1: 0.0
Epoch:  950        6 Batch loss: 0.240767 Batch F1: 0.0
Epoch:  950        7 Batch loss: 0.222334 Batch F1: 0.23076923076923075
Epoch:  950        8 Batch loss: 0.228145 Batch F1: 0.1818181818181818
Epoch:  950        9 Batch loss: 0.217449 Batch F1: 0.0
Epoch:  950       10 Batch loss: 0.242920 Batch F1: 0.0
Epoch:  950       11 Batch loss: 0.216861 Batch F1: 0.0
Epoch:  950       12 Batch loss: 0.200083 Batch F1: 0.0
Train Avg Loss  950: 0.226673

Train Avg F1  950: 0.03438228438228438

Val Avg Loss  950: 0.216586

Val Avg F1  950:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 951
--------------------------------------------------------------
Epoch:  951        1 Batch loss: 0.221260 Batch F1: 0.0
Epoch:  951        2 Batch loss: 0.212121 Batch F1: 0.0
Epoch:  951        3 Batch loss: 0.230434 Batch F1: 0.0
Epoch:  951        4 Batch loss: 0.226167 Batch F1: 0.0
Epoch:  951        5 Batch loss: 0.180988 Batch F1: 0.0
Epoch:  951        6 Batch loss: 0.245111 Batch F1: 0.0
Epoch:  951        7 Batch loss: 0.231567 Batch F1: 0.0
Epoch:  951        8 Batch loss: 0.195874 Batch F1: 0.0
Epoch:  951        9 Batch loss: 0.252905 Batch F1: 0.0
Epoch:  951       10 Batch loss: 0.231518 Batch F1: 0.0
Epoch:  951       11 Batch loss: 0.258535 Batch F1: 0.0
Epoch:  951       12 Batch loss: 0.237107 Batch F1: 0.0
Train Avg Loss  951: 0.226966

Train Avg F1  951: 0.0

Val Avg Loss  951: 0.219340

Val Avg F1  951:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 952
--------------------------------------------------------------
Epoch:  952        1 Batch loss: 0.240166 Batch F1: 0.0
Epoch:  952        2 Batch loss: 0.227997 Batch F1: 0.0
Epoch:  952        3 Batch loss: 0.211864 Batch F1: 0.0
Epoch:  952        4 Batch loss: 0.235049 Batch F1: 0.0
Epoch:  952        5 Batch loss: 0.229904 Batch F1: 0.0
Epoch:  952        6 Batch loss: 0.204343 Batch F1: 0.0
Epoch:  952        7 Batch loss: 0.247669 Batch F1: 0.0
Epoch:  952        8 Batch loss: 0.251444 Batch F1: 0.0
Epoch:  952        9 Batch loss: 0.261762 Batch F1: 0.0
Epoch:  952       10 Batch loss: 0.224955 Batch F1: 0.0
Epoch:  952       11 Batch loss: 0.207733 Batch F1: 0.1111111111111111
Epoch:  952       12 Batch loss: 0.193220 Batch F1: 0.0
Train Avg Loss  952: 0.228009

Train Avg F1  952: 0.009259259259259259

Val Avg Loss  952: 0.218373

Val Avg F1  952:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 953
--------------------------------------------------------------
Epoch:  953        1 Batch loss: 0.254660 Batch F1: 0.0
Epoch:  953        2 Batch loss: 0.206408 Batch F1: 0.0
Epoch:  953        3 Batch loss: 0.202988 Batch F1: 0.0
Epoch:  953        4 Batch loss: 0.217449 Batch F1: 0.0
Epoch:  953        5 Batch loss: 0.179715 Batch F1: 0.0
Epoch:  953        6 Batch loss: 0.259026 Batch F1: 0.0
Epoch:  953        7 Batch loss: 0.222872 Batch F1: 0.0
Epoch:  953        8 Batch loss: 0.247795 Batch F1: 0.0
Epoch:  953        9 Batch loss: 0.260906 Batch F1: 0.0
Epoch:  953       10 Batch loss: 0.226777 Batch F1: 0.0
Epoch:  953       11 Batch loss: 0.229589 Batch F1: 0.0
Epoch:  953       12 Batch loss: 0.216003 Batch F1: 0.0
Train Avg Loss  953: 0.227016

Train Avg F1  953: 0.0

Val Avg Loss  953: 0.220374

Val Avg F1  953:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 954
--------------------------------------------------------------
Epoch:  954        1 Batch loss: 0.218444 Batch F1: 0.0
Epoch:  954        2 Batch loss: 0.210778 Batch F1: 0.0
Epoch:  954        3 Batch loss: 0.229249 Batch F1: 0.0
Epoch:  954        4 Batch loss: 0.262462 Batch F1: 0.0
Epoch:  954        5 Batch loss: 0.239142 Batch F1: 0.0
Epoch:  954        6 Batch loss: 0.214291 Batch F1: 0.0
Epoch:  954        7 Batch loss: 0.232845 Batch F1: 0.0
Epoch:  954        8 Batch loss: 0.206005 Batch F1: 0.0
Epoch:  954        9 Batch loss: 0.225729 Batch F1: 0.0
Epoch:  954       10 Batch loss: 0.212661 Batch F1: 0.0
Epoch:  954       11 Batch loss: 0.227238 Batch F1: 0.0
Epoch:  954       12 Batch loss: 0.261978 Batch F1: 0.0
Train Avg Loss  954: 0.228402

Train Avg F1  954: 0.0

Val Avg Loss  954: 0.217656

Val Avg F1  954:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 955
--------------------------------------------------------------
Epoch:  955        1 Batch loss: 0.231458 Batch F1: 0.0
Epoch:  955        2 Batch loss: 0.220675 Batch F1: 0.0
Epoch:  955        3 Batch loss: 0.223699 Batch F1: 0.0
Epoch:  955        4 Batch loss: 0.242670 Batch F1: 0.0
Epoch:  955        5 Batch loss: 0.224832 Batch F1: 0.0
Epoch:  955        6 Batch loss: 0.224697 Batch F1: 0.0
Epoch:  955        7 Batch loss: 0.226991 Batch F1: 0.0
Epoch:  955        8 Batch loss: 0.231345 Batch F1: 0.0
Epoch:  955        9 Batch loss: 0.195979 Batch F1: 0.0
Epoch:  955       10 Batch loss: 0.237261 Batch F1: 0.0
Epoch:  955       11 Batch loss: 0.244984 Batch F1: 0.0
Epoch:  955       12 Batch loss: 0.212484 Batch F1: 0.0
Train Avg Loss  955: 0.226423

Train Avg F1  955: 0.0

Val Avg Loss  955: 0.216961

Val Avg F1  955:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 956
--------------------------------------------------------------
Epoch:  956        1 Batch loss: 0.208107 Batch F1: 0.0
Epoch:  956        2 Batch loss: 0.214526 Batch F1: 0.0
Epoch:  956        3 Batch loss: 0.248560 Batch F1: 0.0
Epoch:  956        4 Batch loss: 0.222872 Batch F1: 0.0
Epoch:  956        5 Batch loss: 0.203165 Batch F1: 0.0
Epoch:  956        6 Batch loss: 0.235909 Batch F1: 0.0
Epoch:  956        7 Batch loss: 0.236353 Batch F1: 0.0
Epoch:  956        8 Batch loss: 0.234988 Batch F1: 0.0
Epoch:  956        9 Batch loss: 0.224854 Batch F1: 0.0
Epoch:  956       10 Batch loss: 0.229049 Batch F1: 0.0
Epoch:  956       11 Batch loss: 0.234719 Batch F1: 0.0
Epoch:  956       12 Batch loss: 0.216892 Batch F1: 0.0
Train Avg Loss  956: 0.225833

Train Avg F1  956: 0.0

Val Avg Loss  956: 0.219329

Val Avg F1  956:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 957
--------------------------------------------------------------
Epoch:  957        1 Batch loss: 0.230486 Batch F1: 0.0
Epoch:  957        2 Batch loss: 0.225294 Batch F1: 0.0
Epoch:  957        3 Batch loss: 0.216332 Batch F1: 0.0
Epoch:  957        4 Batch loss: 0.233198 Batch F1: 0.0
Epoch:  957        5 Batch loss: 0.210701 Batch F1: 0.0
Epoch:  957        6 Batch loss: 0.215643 Batch F1: 0.0
Epoch:  957        7 Batch loss: 0.223578 Batch F1: 0.0
Epoch:  957        8 Batch loss: 0.277940 Batch F1: 0.0
Epoch:  957        9 Batch loss: 0.216715 Batch F1: 0.0
Epoch:  957       10 Batch loss: 0.222767 Batch F1: 0.0
Epoch:  957       11 Batch loss: 0.212102 Batch F1: 0.0
Epoch:  957       12 Batch loss: 0.243707 Batch F1: 0.0
Train Avg Loss  957: 0.227372

Train Avg F1  957: 0.0

Val Avg Loss  957: 0.216928

Val Avg F1  957:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 958
--------------------------------------------------------------
Epoch:  958        1 Batch loss: 0.223224 Batch F1: 0.0
Epoch:  958        2 Batch loss: 0.241361 Batch F1: 0.0
Epoch:  958        3 Batch loss: 0.225533 Batch F1: 0.0
Epoch:  958        4 Batch loss: 0.209259 Batch F1: 0.0
Epoch:  958        5 Batch loss: 0.231987 Batch F1: 0.0
Epoch:  958        6 Batch loss: 0.227212 Batch F1: 0.0
Epoch:  958        7 Batch loss: 0.264620 Batch F1: 0.0
Epoch:  958        8 Batch loss: 0.193290 Batch F1: 0.0
Epoch:  958        9 Batch loss: 0.216175 Batch F1: 0.0
Epoch:  958       10 Batch loss: 0.230598 Batch F1: 0.0
Epoch:  958       11 Batch loss: 0.220992 Batch F1: 0.0
Epoch:  958       12 Batch loss: 0.235087 Batch F1: 0.0
Train Avg Loss  958: 0.226612

Train Avg F1  958: 0.0

Val Avg Loss  958: 0.217383

Val Avg F1  958:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 959
--------------------------------------------------------------
Epoch:  959        1 Batch loss: 0.221107 Batch F1: 0.0
Epoch:  959        2 Batch loss: 0.216794 Batch F1: 0.0
Epoch:  959        3 Batch loss: 0.233064 Batch F1: 0.0
Epoch:  959        4 Batch loss: 0.211425 Batch F1: 0.0
Epoch:  959        5 Batch loss: 0.206115 Batch F1: 0.0
Epoch:  959        6 Batch loss: 0.242093 Batch F1: 0.0
Epoch:  959        7 Batch loss: 0.223404 Batch F1: 0.0
Epoch:  959        8 Batch loss: 0.218387 Batch F1: 0.0
Epoch:  959        9 Batch loss: 0.232189 Batch F1: 0.0
Epoch:  959       10 Batch loss: 0.228054 Batch F1: 0.0
Epoch:  959       11 Batch loss: 0.237116 Batch F1: 0.0
Epoch:  959       12 Batch loss: 0.237243 Batch F1: 0.0
Train Avg Loss  959: 0.225583

Train Avg F1  959: 0.0

Val Avg Loss  959: 0.217962

Val Avg F1  959:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 960
--------------------------------------------------------------
Epoch:  960        1 Batch loss: 0.253814 Batch F1: 0.0
Epoch:  960        2 Batch loss: 0.236139 Batch F1: 0.0
Epoch:  960        3 Batch loss: 0.237177 Batch F1: 0.07142857142857144
Epoch:  960        4 Batch loss: 0.278410 Batch F1: 0.0
Epoch:  960        5 Batch loss: 0.220137 Batch F1: 0.0
Epoch:  960        6 Batch loss: 0.212838 Batch F1: 0.0
Epoch:  960        7 Batch loss: 0.213761 Batch F1: 0.0
Epoch:  960        8 Batch loss: 0.221946 Batch F1: 0.0
Epoch:  960        9 Batch loss: 0.201621 Batch F1: 0.0
Epoch:  960       10 Batch loss: 0.199990 Batch F1: 0.0
Epoch:  960       11 Batch loss: 0.230173 Batch F1: 0.0
Epoch:  960       12 Batch loss: 0.220947 Batch F1: 0.0
Train Avg Loss  960: 0.227246

Train Avg F1  960: 0.005952380952380953

Val Avg Loss  960: 0.216937

Val Avg F1  960:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 961
--------------------------------------------------------------
Epoch:  961        1 Batch loss: 0.290503 Batch F1: 0.0
Epoch:  961        2 Batch loss: 0.196063 Batch F1: 0.0
Epoch:  961        3 Batch loss: 0.201058 Batch F1: 0.0
Epoch:  961        4 Batch loss: 0.227959 Batch F1: 0.0
Epoch:  961        5 Batch loss: 0.251702 Batch F1: 0.0
Epoch:  961        6 Batch loss: 0.194368 Batch F1: 0.0
Epoch:  961        7 Batch loss: 0.236620 Batch F1: 0.0
Epoch:  961        8 Batch loss: 0.206228 Batch F1: 0.0
Epoch:  961        9 Batch loss: 0.225076 Batch F1: 0.0
Epoch:  961       10 Batch loss: 0.238043 Batch F1: 0.0
Epoch:  961       11 Batch loss: 0.224319 Batch F1: 0.0
Epoch:  961       12 Batch loss: 0.258130 Batch F1: 0.0
Train Avg Loss  961: 0.229172

Train Avg F1  961: 0.0

Val Avg Loss  961: 0.216448

Val Avg F1  961:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 962
--------------------------------------------------------------
Epoch:  962        1 Batch loss: 0.216446 Batch F1: 0.0
Epoch:  962        2 Batch loss: 0.204075 Batch F1: 0.0
Epoch:  962        3 Batch loss: 0.226368 Batch F1: 0.0
Epoch:  962        4 Batch loss: 0.245155 Batch F1: 0.0
Epoch:  962        5 Batch loss: 0.246419 Batch F1: 0.0
Epoch:  962        6 Batch loss: 0.226420 Batch F1: 0.0
Epoch:  962        7 Batch loss: 0.217759 Batch F1: 0.0
Epoch:  962        8 Batch loss: 0.230017 Batch F1: 0.0
Epoch:  962        9 Batch loss: 0.242356 Batch F1: 0.0
Epoch:  962       10 Batch loss: 0.253041 Batch F1: 0.0
Epoch:  962       11 Batch loss: 0.216846 Batch F1: 0.28571428571428575
Epoch:  962       12 Batch loss: 0.195277 Batch F1: 0.16666666666666666
Train Avg Loss  962: 0.226682

Train Avg F1  962: 0.0376984126984127

Val Avg Loss  962: 0.218804

Val Avg F1  962:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 963
--------------------------------------------------------------
Epoch:  963        1 Batch loss: 0.222971 Batch F1: 0.0
Epoch:  963        2 Batch loss: 0.256342 Batch F1: 0.0
Epoch:  963        3 Batch loss: 0.226714 Batch F1: 0.0
Epoch:  963        4 Batch loss: 0.201056 Batch F1: 0.0
Epoch:  963        5 Batch loss: 0.273226 Batch F1: 0.0
Epoch:  963        6 Batch loss: 0.198046 Batch F1: 0.0
Epoch:  963        7 Batch loss: 0.250571 Batch F1: 0.0
Epoch:  963        8 Batch loss: 0.258141 Batch F1: 0.0
Epoch:  963        9 Batch loss: 0.214008 Batch F1: 0.0
Epoch:  963       10 Batch loss: 0.228205 Batch F1: 0.0
Epoch:  963       11 Batch loss: 0.215268 Batch F1: 0.0
Epoch:  963       12 Batch loss: 0.209591 Batch F1: 0.0
Train Avg Loss  963: 0.229512

Train Avg F1  963: 0.0

Val Avg Loss  963: 0.219477

Val Avg F1  963:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 964
--------------------------------------------------------------
Epoch:  964        1 Batch loss: 0.196288 Batch F1: 0.0
Epoch:  964        2 Batch loss: 0.210707 Batch F1: 0.0
Epoch:  964        3 Batch loss: 0.244282 Batch F1: 0.0
Epoch:  964        4 Batch loss: 0.235119 Batch F1: 0.0
Epoch:  964        5 Batch loss: 0.209116 Batch F1: 0.0
Epoch:  964        6 Batch loss: 0.268300 Batch F1: 0.0
Epoch:  964        7 Batch loss: 0.225431 Batch F1: 0.0
Epoch:  964        8 Batch loss: 0.260531 Batch F1: 0.0
Epoch:  964        9 Batch loss: 0.230040 Batch F1: 0.0
Epoch:  964       10 Batch loss: 0.221363 Batch F1: 0.0
Epoch:  964       11 Batch loss: 0.217656 Batch F1: 0.0
Epoch:  964       12 Batch loss: 0.222436 Batch F1: 0.0
Train Avg Loss  964: 0.228439

Train Avg F1  964: 0.0

Val Avg Loss  964: 0.219496

Val Avg F1  964:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 965
--------------------------------------------------------------
Epoch:  965        1 Batch loss: 0.227751 Batch F1: 0.0
Epoch:  965        2 Batch loss: 0.213632 Batch F1: 0.0
Epoch:  965        3 Batch loss: 0.202522 Batch F1: 0.0
Epoch:  965        4 Batch loss: 0.189234 Batch F1: 0.0
Epoch:  965        5 Batch loss: 0.273919 Batch F1: 0.0
Epoch:  965        6 Batch loss: 0.246288 Batch F1: 0.0
Epoch:  965        7 Batch loss: 0.224551 Batch F1: 0.0
Epoch:  965        8 Batch loss: 0.234431 Batch F1: 0.0
Epoch:  965        9 Batch loss: 0.245893 Batch F1: 0.0
Epoch:  965       10 Batch loss: 0.231512 Batch F1: 0.0
Epoch:  965       11 Batch loss: 0.229454 Batch F1: 0.0
Epoch:  965       12 Batch loss: 0.215244 Batch F1: 0.0
Train Avg Loss  965: 0.227869

Train Avg F1  965: 0.0

Val Avg Loss  965: 0.219537

Val Avg F1  965:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 966
--------------------------------------------------------------
Epoch:  966        1 Batch loss: 0.247848 Batch F1: 0.0
Epoch:  966        2 Batch loss: 0.228851 Batch F1: 0.0
Epoch:  966        3 Batch loss: 0.205550 Batch F1: 0.0
Epoch:  966        4 Batch loss: 0.239900 Batch F1: 0.0
Epoch:  966        5 Batch loss: 0.255031 Batch F1: 0.0
Epoch:  966        6 Batch loss: 0.243256 Batch F1: 0.0
Epoch:  966        7 Batch loss: 0.197083 Batch F1: 0.0
Epoch:  966        8 Batch loss: 0.223982 Batch F1: 0.0
Epoch:  966        9 Batch loss: 0.230057 Batch F1: 0.0
Epoch:  966       10 Batch loss: 0.210492 Batch F1: 0.0
Epoch:  966       11 Batch loss: 0.232884 Batch F1: 0.0
Epoch:  966       12 Batch loss: 0.198299 Batch F1: 0.0
Train Avg Loss  966: 0.226103

Train Avg F1  966: 0.0

Val Avg Loss  966: 0.217082

Val Avg F1  966:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 967
--------------------------------------------------------------
Epoch:  967        1 Batch loss: 0.251955 Batch F1: 0.0
Epoch:  967        2 Batch loss: 0.198780 Batch F1: 0.0
Epoch:  967        3 Batch loss: 0.216520 Batch F1: 0.0
Epoch:  967        4 Batch loss: 0.197411 Batch F1: 0.0
Epoch:  967        5 Batch loss: 0.220847 Batch F1: 0.0
Epoch:  967        6 Batch loss: 0.222218 Batch F1: 0.0
Epoch:  967        7 Batch loss: 0.253047 Batch F1: 0.0
Epoch:  967        8 Batch loss: 0.223427 Batch F1: 0.0
Epoch:  967        9 Batch loss: 0.237787 Batch F1: 0.0
Epoch:  967       10 Batch loss: 0.240537 Batch F1: 0.0
Epoch:  967       11 Batch loss: 0.249533 Batch F1: 0.0
Epoch:  967       12 Batch loss: 0.217186 Batch F1: 0.0
Train Avg Loss  967: 0.227437

Train Avg F1  967: 0.0

Val Avg Loss  967: 0.219921

Val Avg F1  967:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 968
--------------------------------------------------------------
Epoch:  968        1 Batch loss: 0.172985 Batch F1: 0.0
Epoch:  968        2 Batch loss: 0.222198 Batch F1: 0.0
Epoch:  968        3 Batch loss: 0.249702 Batch F1: 0.0
Epoch:  968        4 Batch loss: 0.236001 Batch F1: 0.0
Epoch:  968        5 Batch loss: 0.271070 Batch F1: 0.0
Epoch:  968        6 Batch loss: 0.216821 Batch F1: 0.0
Epoch:  968        7 Batch loss: 0.253571 Batch F1: 0.0
Epoch:  968        8 Batch loss: 0.192933 Batch F1: 0.0
Epoch:  968        9 Batch loss: 0.244232 Batch F1: 0.0
Epoch:  968       10 Batch loss: 0.230175 Batch F1: 0.0
Epoch:  968       11 Batch loss: 0.223878 Batch F1: 0.0
Epoch:  968       12 Batch loss: 0.217213 Batch F1: 0.0
Train Avg Loss  968: 0.227565

Train Avg F1  968: 0.0

Val Avg Loss  968: 0.217951

Val Avg F1  968:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 969
--------------------------------------------------------------
Epoch:  969        1 Batch loss: 0.241050 Batch F1: 0.0
Epoch:  969        2 Batch loss: 0.245022 Batch F1: 0.0
Epoch:  969        3 Batch loss: 0.237274 Batch F1: 0.3448275862068965
Epoch:  969        4 Batch loss: 0.232223 Batch F1: 0.23076923076923078
Epoch:  969        5 Batch loss: 0.211185 Batch F1: 0.4799999999999999
Epoch:  969        6 Batch loss: 0.214915 Batch F1: 0.5714285714285714
Epoch:  969        7 Batch loss: 0.216946 Batch F1: 0.1739130434782609
Epoch:  969        8 Batch loss: 0.196178 Batch F1: 0.5263157894736842
Epoch:  969        9 Batch loss: 0.251721 Batch F1: 0.0
Epoch:  969       10 Batch loss: 0.194299 Batch F1: 0.0
Epoch:  969       11 Batch loss: 0.239935 Batch F1: 0.0
Epoch:  969       12 Batch loss: 0.250152 Batch F1: 0.0
Train Avg Loss  969: 0.227575

Train Avg F1  969: 0.1939378517797203

Val Avg Loss  969: 0.217441

Val Avg F1  969:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 970
--------------------------------------------------------------
Epoch:  970        1 Batch loss: 0.215163 Batch F1: 0.0
Epoch:  970        2 Batch loss: 0.210099 Batch F1: 0.0
Epoch:  970        3 Batch loss: 0.257100 Batch F1: 0.0
Epoch:  970        4 Batch loss: 0.221001 Batch F1: 0.0
Epoch:  970        5 Batch loss: 0.224103 Batch F1: 0.0
Epoch:  970        6 Batch loss: 0.238507 Batch F1: 0.0
Epoch:  970        7 Batch loss: 0.215867 Batch F1: 0.0
Epoch:  970        8 Batch loss: 0.274923 Batch F1: 0.0
Epoch:  970        9 Batch loss: 0.221949 Batch F1: 0.0
Epoch:  970       10 Batch loss: 0.211580 Batch F1: 0.0
Epoch:  970       11 Batch loss: 0.218029 Batch F1: 0.0
Epoch:  970       12 Batch loss: 0.226392 Batch F1: 0.0
Train Avg Loss  970: 0.227893

Train Avg F1  970: 0.0

Val Avg Loss  970: 0.218287

Val Avg F1  970:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 971
--------------------------------------------------------------
Epoch:  971        1 Batch loss: 0.248712 Batch F1: 0.0
Epoch:  971        2 Batch loss: 0.241088 Batch F1: 0.0
Epoch:  971        3 Batch loss: 0.191711 Batch F1: 0.0
Epoch:  971        4 Batch loss: 0.219989 Batch F1: 0.0
Epoch:  971        5 Batch loss: 0.256961 Batch F1: 0.0
Epoch:  971        6 Batch loss: 0.198008 Batch F1: 0.0
Epoch:  971        7 Batch loss: 0.235053 Batch F1: 0.0
Epoch:  971        8 Batch loss: 0.202509 Batch F1: 0.0
Epoch:  971        9 Batch loss: 0.239517 Batch F1: 0.0
Epoch:  971       10 Batch loss: 0.210387 Batch F1: 0.0
Epoch:  971       11 Batch loss: 0.274487 Batch F1: 0.0
Epoch:  971       12 Batch loss: 0.196245 Batch F1: 0.0
Train Avg Loss  971: 0.226222

Train Avg F1  971: 0.0

Val Avg Loss  971: 0.218242

Val Avg F1  971:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 972
--------------------------------------------------------------
Epoch:  972        1 Batch loss: 0.242369 Batch F1: 0.0
Epoch:  972        2 Batch loss: 0.235009 Batch F1: 0.0
Epoch:  972        3 Batch loss: 0.211951 Batch F1: 0.0
Epoch:  972        4 Batch loss: 0.202563 Batch F1: 0.0
Epoch:  972        5 Batch loss: 0.217386 Batch F1: 0.0
Epoch:  972        6 Batch loss: 0.217730 Batch F1: 0.0
Epoch:  972        7 Batch loss: 0.238740 Batch F1: 0.0
Epoch:  972        8 Batch loss: 0.210331 Batch F1: 0.0
Epoch:  972        9 Batch loss: 0.224766 Batch F1: 0.0
Epoch:  972       10 Batch loss: 0.285231 Batch F1: 0.0
Epoch:  972       11 Batch loss: 0.207980 Batch F1: 0.0
Epoch:  972       12 Batch loss: 0.249049 Batch F1: 0.0
Train Avg Loss  972: 0.228592

Train Avg F1  972: 0.0

Val Avg Loss  972: 0.219217

Val Avg F1  972:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 973
--------------------------------------------------------------
Epoch:  973        1 Batch loss: 0.226313 Batch F1: 0.0
Epoch:  973        2 Batch loss: 0.221510 Batch F1: 0.0
Epoch:  973        3 Batch loss: 0.218104 Batch F1: 0.0
Epoch:  973        4 Batch loss: 0.219135 Batch F1: 0.0
Epoch:  973        5 Batch loss: 0.294867 Batch F1: 0.0
Epoch:  973        6 Batch loss: 0.221912 Batch F1: 0.0
Epoch:  973        7 Batch loss: 0.232451 Batch F1: 0.0
Epoch:  973        8 Batch loss: 0.216046 Batch F1: 0.0
Epoch:  973        9 Batch loss: 0.202729 Batch F1: 0.0
Epoch:  973       10 Batch loss: 0.206194 Batch F1: 0.0
Epoch:  973       11 Batch loss: 0.244121 Batch F1: 0.0
Epoch:  973       12 Batch loss: 0.230128 Batch F1: 0.0
Train Avg Loss  973: 0.227792

Train Avg F1  973: 0.0

Val Avg Loss  973: 0.218790

Val Avg F1  973:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 974
--------------------------------------------------------------
Epoch:  974        1 Batch loss: 0.231053 Batch F1: 0.0
Epoch:  974        2 Batch loss: 0.224418 Batch F1: 0.0
Epoch:  974        3 Batch loss: 0.208190 Batch F1: 0.19047619047619044
Epoch:  974        4 Batch loss: 0.226567 Batch F1: 0.5161290322580645
Epoch:  974        5 Batch loss: 0.215939 Batch F1: 0.3846153846153846
Epoch:  974        6 Batch loss: 0.217404 Batch F1: 0.0
Epoch:  974        7 Batch loss: 0.233271 Batch F1: 0.0
Epoch:  974        8 Batch loss: 0.230287 Batch F1: 0.0
Epoch:  974        9 Batch loss: 0.202492 Batch F1: 0.0
Epoch:  974       10 Batch loss: 0.270816 Batch F1: 0.0
Epoch:  974       11 Batch loss: 0.212867 Batch F1: 0.0
Epoch:  974       12 Batch loss: 0.247585 Batch F1: 0.0
Train Avg Loss  974: 0.226741

Train Avg F1  974: 0.09093505061246997

Val Avg Loss  974: 0.217697

Val Avg F1  974:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 975
--------------------------------------------------------------
Epoch:  975        1 Batch loss: 0.201104 Batch F1: 0.0
Epoch:  975        2 Batch loss: 0.230580 Batch F1: 0.0
Epoch:  975        3 Batch loss: 0.258182 Batch F1: 0.0
Epoch:  975        4 Batch loss: 0.235123 Batch F1: 0.0
Epoch:  975        5 Batch loss: 0.233513 Batch F1: 0.0
Epoch:  975        6 Batch loss: 0.190541 Batch F1: 0.0
Epoch:  975        7 Batch loss: 0.198649 Batch F1: 0.0
Epoch:  975        8 Batch loss: 0.245659 Batch F1: 0.0
Epoch:  975        9 Batch loss: 0.265200 Batch F1: 0.0
Epoch:  975       10 Batch loss: 0.227562 Batch F1: 0.0
Epoch:  975       11 Batch loss: 0.214618 Batch F1: 0.0
Epoch:  975       12 Batch loss: 0.213251 Batch F1: 0.0
Train Avg Loss  975: 0.226165

Train Avg F1  975: 0.0

Val Avg Loss  975: 0.216894

Val Avg F1  975:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 976
--------------------------------------------------------------
Epoch:  976        1 Batch loss: 0.207663 Batch F1: 0.0
Epoch:  976        2 Batch loss: 0.239146 Batch F1: 0.0
Epoch:  976        3 Batch loss: 0.260005 Batch F1: 0.0
Epoch:  976        4 Batch loss: 0.193529 Batch F1: 0.0
Epoch:  976        5 Batch loss: 0.202122 Batch F1: 0.0
Epoch:  976        6 Batch loss: 0.226262 Batch F1: 0.0
Epoch:  976        7 Batch loss: 0.224401 Batch F1: 0.0
Epoch:  976        8 Batch loss: 0.254126 Batch F1: 0.0
Epoch:  976        9 Batch loss: 0.176822 Batch F1: 0.0
Epoch:  976       10 Batch loss: 0.260853 Batch F1: 0.0
Epoch:  976       11 Batch loss: 0.231469 Batch F1: 0.0
Epoch:  976       12 Batch loss: 0.238132 Batch F1: 0.0
Train Avg Loss  976: 0.226211

Train Avg F1  976: 0.0

Val Avg Loss  976: 0.217408

Val Avg F1  976:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 977
--------------------------------------------------------------
Epoch:  977        1 Batch loss: 0.212046 Batch F1: 0.0
Epoch:  977        2 Batch loss: 0.191641 Batch F1: 0.0
Epoch:  977        3 Batch loss: 0.222362 Batch F1: 0.0
Epoch:  977        4 Batch loss: 0.214040 Batch F1: 0.0
Epoch:  977        5 Batch loss: 0.238113 Batch F1: 0.0
Epoch:  977        6 Batch loss: 0.212066 Batch F1: 0.0
Epoch:  977        7 Batch loss: 0.254093 Batch F1: 0.0
Epoch:  977        8 Batch loss: 0.220017 Batch F1: 0.0
Epoch:  977        9 Batch loss: 0.242199 Batch F1: 0.0
Epoch:  977       10 Batch loss: 0.210685 Batch F1: 0.0
Epoch:  977       11 Batch loss: 0.252822 Batch F1: 0.0
Epoch:  977       12 Batch loss: 0.240328 Batch F1: 0.0
Train Avg Loss  977: 0.225868

Train Avg F1  977: 0.0

Val Avg Loss  977: 0.218868

Val Avg F1  977:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 978
--------------------------------------------------------------
Epoch:  978        1 Batch loss: 0.209907 Batch F1: 0.0
Epoch:  978        2 Batch loss: 0.233845 Batch F1: 0.0
Epoch:  978        3 Batch loss: 0.267864 Batch F1: 0.0
Epoch:  978        4 Batch loss: 0.231246 Batch F1: 0.4
Epoch:  978        5 Batch loss: 0.183425 Batch F1: 0.14285714285714285
Epoch:  978        6 Batch loss: 0.229136 Batch F1: 0.0
Epoch:  978        7 Batch loss: 0.222923 Batch F1: 0.0
Epoch:  978        8 Batch loss: 0.250820 Batch F1: 0.0
Epoch:  978        9 Batch loss: 0.220492 Batch F1: 0.0
Epoch:  978       10 Batch loss: 0.211494 Batch F1: 0.0
Epoch:  978       11 Batch loss: 0.236726 Batch F1: 0.0
Epoch:  978       12 Batch loss: 0.215100 Batch F1: 0.0
Train Avg Loss  978: 0.226082

Train Avg F1  978: 0.045238095238095244

Val Avg Loss  978: 0.217666

Val Avg F1  978:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 979
--------------------------------------------------------------
Epoch:  979        1 Batch loss: 0.172078 Batch F1: 0.0
Epoch:  979        2 Batch loss: 0.223417 Batch F1: 0.0
Epoch:  979        3 Batch loss: 0.215659 Batch F1: 0.0
Epoch:  979        4 Batch loss: 0.224981 Batch F1: 0.0
Epoch:  979        5 Batch loss: 0.225942 Batch F1: 0.0
Epoch:  979        6 Batch loss: 0.262868 Batch F1: 0.0
Epoch:  979        7 Batch loss: 0.268211 Batch F1: 0.0
Epoch:  979        8 Batch loss: 0.238596 Batch F1: 0.0
Epoch:  979        9 Batch loss: 0.201448 Batch F1: 0.0
Epoch:  979       10 Batch loss: 0.207239 Batch F1: 0.0
Epoch:  979       11 Batch loss: 0.237258 Batch F1: 0.0
Epoch:  979       12 Batch loss: 0.240054 Batch F1: 0.0
Train Avg Loss  979: 0.226479

Train Avg F1  979: 0.0

Val Avg Loss  979: 0.217157

Val Avg F1  979:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 980
--------------------------------------------------------------
Epoch:  980        1 Batch loss: 0.220061 Batch F1: 0.0
Epoch:  980        2 Batch loss: 0.261672 Batch F1: 0.0
Epoch:  980        3 Batch loss: 0.231397 Batch F1: 0.0
Epoch:  980        4 Batch loss: 0.224839 Batch F1: 0.18181818181818182
Epoch:  980        5 Batch loss: 0.214843 Batch F1: 0.0
Epoch:  980        6 Batch loss: 0.221089 Batch F1: 0.0
Epoch:  980        7 Batch loss: 0.243357 Batch F1: 0.0
Epoch:  980        8 Batch loss: 0.271753 Batch F1: 0.0
Epoch:  980        9 Batch loss: 0.199258 Batch F1: 0.0
Epoch:  980       10 Batch loss: 0.204040 Batch F1: 0.0
Epoch:  980       11 Batch loss: 0.214078 Batch F1: 0.0
Epoch:  980       12 Batch loss: 0.208173 Batch F1: 0.0
Train Avg Loss  980: 0.226213

Train Avg F1  980: 0.015151515151515152

Val Avg Loss  980: 0.216928

Val Avg F1  980:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 981
--------------------------------------------------------------
Epoch:  981        1 Batch loss: 0.241712 Batch F1: 0.0
Epoch:  981        2 Batch loss: 0.183062 Batch F1: 0.0
Epoch:  981        3 Batch loss: 0.250581 Batch F1: 0.0
Epoch:  981        4 Batch loss: 0.193872 Batch F1: 0.0
Epoch:  981        5 Batch loss: 0.175305 Batch F1: 0.0
Epoch:  981        6 Batch loss: 0.246264 Batch F1: 0.0
Epoch:  981        7 Batch loss: 0.261762 Batch F1: 0.0
Epoch:  981        8 Batch loss: 0.187123 Batch F1: 0.0
Epoch:  981        9 Batch loss: 0.252784 Batch F1: 0.0
Epoch:  981       10 Batch loss: 0.267933 Batch F1: 0.0
Epoch:  981       11 Batch loss: 0.230789 Batch F1: 0.0
Epoch:  981       12 Batch loss: 0.235029 Batch F1: 0.0
Train Avg Loss  981: 0.227185

Train Avg F1  981: 0.0

Val Avg Loss  981: 0.219193

Val Avg F1  981:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 982
--------------------------------------------------------------
Epoch:  982        1 Batch loss: 0.212706 Batch F1: 0.0
Epoch:  982        2 Batch loss: 0.237960 Batch F1: 0.0
Epoch:  982        3 Batch loss: 0.212797 Batch F1: 0.0
Epoch:  982        4 Batch loss: 0.232508 Batch F1: 0.0
Epoch:  982        5 Batch loss: 0.221220 Batch F1: 0.0
Epoch:  982        6 Batch loss: 0.206286 Batch F1: 0.0
Epoch:  982        7 Batch loss: 0.229049 Batch F1: 0.0
Epoch:  982        8 Batch loss: 0.233344 Batch F1: 0.0
Epoch:  982        9 Batch loss: 0.216511 Batch F1: 0.0
Epoch:  982       10 Batch loss: 0.218831 Batch F1: 0.0
Epoch:  982       11 Batch loss: 0.260781 Batch F1: 0.0
Epoch:  982       12 Batch loss: 0.234725 Batch F1: 0.0
Train Avg Loss  982: 0.226393

Train Avg F1  982: 0.0

Val Avg Loss  982: 0.217384

Val Avg F1  982:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 983
--------------------------------------------------------------
Epoch:  983        1 Batch loss: 0.221843 Batch F1: 0.0
Epoch:  983        2 Batch loss: 0.250485 Batch F1: 0.0
Epoch:  983        3 Batch loss: 0.217174 Batch F1: 0.0
Epoch:  983        4 Batch loss: 0.223632 Batch F1: 0.0
Epoch:  983        5 Batch loss: 0.234841 Batch F1: 0.0
Epoch:  983        6 Batch loss: 0.252976 Batch F1: 0.0
Epoch:  983        7 Batch loss: 0.219342 Batch F1: 0.0
Epoch:  983        8 Batch loss: 0.220877 Batch F1: 0.0
Epoch:  983        9 Batch loss: 0.217625 Batch F1: 0.0
Epoch:  983       10 Batch loss: 0.218352 Batch F1: 0.0
Epoch:  983       11 Batch loss: 0.210334 Batch F1: 0.0
Epoch:  983       12 Batch loss: 0.222169 Batch F1: 0.0
Train Avg Loss  983: 0.225804

Train Avg F1  983: 0.0

Val Avg Loss  983: 0.216671

Val Avg F1  983:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 984
--------------------------------------------------------------
Epoch:  984        1 Batch loss: 0.232499 Batch F1: 0.0
Epoch:  984        2 Batch loss: 0.247721 Batch F1: 0.0
Epoch:  984        3 Batch loss: 0.200213 Batch F1: 0.0
Epoch:  984        4 Batch loss: 0.237170 Batch F1: 0.0
Epoch:  984        5 Batch loss: 0.251535 Batch F1: 0.0
Epoch:  984        6 Batch loss: 0.214181 Batch F1: 0.0
Epoch:  984        7 Batch loss: 0.245938 Batch F1: 0.0
Epoch:  984        8 Batch loss: 0.204268 Batch F1: 0.0
Epoch:  984        9 Batch loss: 0.237266 Batch F1: 0.0
Epoch:  984       10 Batch loss: 0.255932 Batch F1: 0.0
Epoch:  984       11 Batch loss: 0.217831 Batch F1: 0.0
Epoch:  984       12 Batch loss: 0.222590 Batch F1: 0.0
Train Avg Loss  984: 0.230595

Train Avg F1  984: 0.0

Val Avg Loss  984: 0.219619

Val Avg F1  984:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 985
--------------------------------------------------------------
Epoch:  985        1 Batch loss: 0.259035 Batch F1: 0.0
Epoch:  985        2 Batch loss: 0.206657 Batch F1: 0.0
Epoch:  985        3 Batch loss: 0.262528 Batch F1: 0.0
Epoch:  985        4 Batch loss: 0.207991 Batch F1: 0.3809523809523809
Epoch:  985        5 Batch loss: 0.206513 Batch F1: 0.4615384615384615
Epoch:  985        6 Batch loss: 0.205992 Batch F1: 0.0
Epoch:  985        7 Batch loss: 0.262447 Batch F1: 0.0
Epoch:  985        8 Batch loss: 0.218791 Batch F1: 0.0
Epoch:  985        9 Batch loss: 0.251119 Batch F1: 0.0
Epoch:  985       10 Batch loss: 0.213588 Batch F1: 0.0
Epoch:  985       11 Batch loss: 0.224136 Batch F1: 0.0
Epoch:  985       12 Batch loss: 0.229183 Batch F1: 0.0
Train Avg Loss  985: 0.228998

Train Avg F1  985: 0.0702075702075702

Val Avg Loss  985: 0.218720

Val Avg F1  985:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 986
--------------------------------------------------------------
Epoch:  986        1 Batch loss: 0.241993 Batch F1: 0.0
Epoch:  986        2 Batch loss: 0.210516 Batch F1: 0.0
Epoch:  986        3 Batch loss: 0.254903 Batch F1: 0.0
Epoch:  986        4 Batch loss: 0.255818 Batch F1: 0.0
Epoch:  986        5 Batch loss: 0.205785 Batch F1: 0.0
Epoch:  986        6 Batch loss: 0.237393 Batch F1: 0.0
Epoch:  986        7 Batch loss: 0.211801 Batch F1: 0.0
Epoch:  986        8 Batch loss: 0.254278 Batch F1: 0.0
Epoch:  986        9 Batch loss: 0.220317 Batch F1: 0.0
Epoch:  986       10 Batch loss: 0.196345 Batch F1: 0.0
Epoch:  986       11 Batch loss: 0.234964 Batch F1: 0.0
Epoch:  986       12 Batch loss: 0.215368 Batch F1: 0.0
Train Avg Loss  986: 0.228290

Train Avg F1  986: 0.0

Val Avg Loss  986: 0.217277

Val Avg F1  986:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 987
--------------------------------------------------------------
Epoch:  987        1 Batch loss: 0.225390 Batch F1: 0.0
Epoch:  987        2 Batch loss: 0.214719 Batch F1: 0.0
Epoch:  987        3 Batch loss: 0.232858 Batch F1: 0.0
Epoch:  987        4 Batch loss: 0.215502 Batch F1: 0.0
Epoch:  987        5 Batch loss: 0.222470 Batch F1: 0.0
Epoch:  987        6 Batch loss: 0.188123 Batch F1: 0.0
Epoch:  987        7 Batch loss: 0.233992 Batch F1: 0.0
Epoch:  987        8 Batch loss: 0.247339 Batch F1: 0.0
Epoch:  987        9 Batch loss: 0.250257 Batch F1: 0.0
Epoch:  987       10 Batch loss: 0.225086 Batch F1: 0.25
Epoch:  987       11 Batch loss: 0.252896 Batch F1: 0.08695652173913045
Epoch:  987       12 Batch loss: 0.227869 Batch F1: 0.0
Train Avg Loss  987: 0.228042

Train Avg F1  987: 0.028079710144927536

Val Avg Loss  987: 0.221973

Val Avg F1  987:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 988
--------------------------------------------------------------
Epoch:  988        1 Batch loss: 0.255606 Batch F1: 0.0
Epoch:  988        2 Batch loss: 0.254990 Batch F1: 0.0
Epoch:  988        3 Batch loss: 0.239969 Batch F1: 0.0
Epoch:  988        4 Batch loss: 0.225437 Batch F1: 0.0
Epoch:  988        5 Batch loss: 0.216732 Batch F1: 0.0
Epoch:  988        6 Batch loss: 0.218309 Batch F1: 0.0
Epoch:  988        7 Batch loss: 0.242668 Batch F1: 0.0
Epoch:  988        8 Batch loss: 0.216616 Batch F1: 0.0
Epoch:  988        9 Batch loss: 0.229310 Batch F1: 0.0
Epoch:  988       10 Batch loss: 0.242434 Batch F1: 0.0
Epoch:  988       11 Batch loss: 0.209804 Batch F1: 0.0
Epoch:  988       12 Batch loss: 0.184706 Batch F1: 0.0
Train Avg Loss  988: 0.228048

Train Avg F1  988: 0.0

Val Avg Loss  988: 0.217423

Val Avg F1  988:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 989
--------------------------------------------------------------
Epoch:  989        1 Batch loss: 0.239212 Batch F1: 0.0
Epoch:  989        2 Batch loss: 0.246537 Batch F1: 0.0
Epoch:  989        3 Batch loss: 0.222099 Batch F1: 0.0
Epoch:  989        4 Batch loss: 0.221129 Batch F1: 0.0
Epoch:  989        5 Batch loss: 0.237976 Batch F1: 0.0
Epoch:  989        6 Batch loss: 0.246081 Batch F1: 0.0
Epoch:  989        7 Batch loss: 0.236664 Batch F1: 0.19047619047619047
Epoch:  989        8 Batch loss: 0.226446 Batch F1: 0.0
Epoch:  989        9 Batch loss: 0.241352 Batch F1: 0.0
Epoch:  989       10 Batch loss: 0.194517 Batch F1: 0.0
Epoch:  989       11 Batch loss: 0.226544 Batch F1: 0.0
Epoch:  989       12 Batch loss: 0.192560 Batch F1: 0.0
Train Avg Loss  989: 0.227593

Train Avg F1  989: 0.015873015873015872

Val Avg Loss  989: 0.219362

Val Avg F1  989:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 990
--------------------------------------------------------------
Epoch:  990        1 Batch loss: 0.200053 Batch F1: 0.0
Epoch:  990        2 Batch loss: 0.201930 Batch F1: 0.0
Epoch:  990        3 Batch loss: 0.266630 Batch F1: 0.0
Epoch:  990        4 Batch loss: 0.304162 Batch F1: 0.0
Epoch:  990        5 Batch loss: 0.241428 Batch F1: 0.0
Epoch:  990        6 Batch loss: 0.214834 Batch F1: 0.0
Epoch:  990        7 Batch loss: 0.203244 Batch F1: 0.0
Epoch:  990        8 Batch loss: 0.215259 Batch F1: 0.0
Epoch:  990        9 Batch loss: 0.238612 Batch F1: 0.0
Epoch:  990       10 Batch loss: 0.233343 Batch F1: 0.0
Epoch:  990       11 Batch loss: 0.239897 Batch F1: 0.0
Epoch:  990       12 Batch loss: 0.219352 Batch F1: 0.0
Train Avg Loss  990: 0.231562

Train Avg F1  990: 0.0

Val Avg Loss  990: 0.218480

Val Avg F1  990:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 991
--------------------------------------------------------------
Epoch:  991        1 Batch loss: 0.235385 Batch F1: 0.0
Epoch:  991        2 Batch loss: 0.235456 Batch F1: 0.0
Epoch:  991        3 Batch loss: 0.216923 Batch F1: 0.0
Epoch:  991        4 Batch loss: 0.240650 Batch F1: 0.0
Epoch:  991        5 Batch loss: 0.220028 Batch F1: 0.0
Epoch:  991        6 Batch loss: 0.226888 Batch F1: 0.0
Epoch:  991        7 Batch loss: 0.224729 Batch F1: 0.0
Epoch:  991        8 Batch loss: 0.222333 Batch F1: 0.0
Epoch:  991        9 Batch loss: 0.193488 Batch F1: 0.0
Epoch:  991       10 Batch loss: 0.234576 Batch F1: 0.0
Epoch:  991       11 Batch loss: 0.237669 Batch F1: 0.0
Epoch:  991       12 Batch loss: 0.250211 Batch F1: 0.0
Train Avg Loss  991: 0.228195

Train Avg F1  991: 0.0

Val Avg Loss  991: 0.217240

Val Avg F1  991:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 992
--------------------------------------------------------------
Epoch:  992        1 Batch loss: 0.214018 Batch F1: 0.0
Epoch:  992        2 Batch loss: 0.205585 Batch F1: 0.0
Epoch:  992        3 Batch loss: 0.243693 Batch F1: 0.0
Epoch:  992        4 Batch loss: 0.255121 Batch F1: 0.0
Epoch:  992        5 Batch loss: 0.224825 Batch F1: 0.0
Epoch:  992        6 Batch loss: 0.237988 Batch F1: 0.0
Epoch:  992        7 Batch loss: 0.245983 Batch F1: 0.0
Epoch:  992        8 Batch loss: 0.227888 Batch F1: 0.0
Epoch:  992        9 Batch loss: 0.207865 Batch F1: 0.0
Epoch:  992       10 Batch loss: 0.241033 Batch F1: 0.0
Epoch:  992       11 Batch loss: 0.231108 Batch F1: 0.0
Epoch:  992       12 Batch loss: 0.192915 Batch F1: 0.0
Train Avg Loss  992: 0.227335

Train Avg F1  992: 0.0

Val Avg Loss  992: 0.217647

Val Avg F1  992:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 993
--------------------------------------------------------------
Epoch:  993        1 Batch loss: 0.231917 Batch F1: 0.0
Epoch:  993        2 Batch loss: 0.246185 Batch F1: 0.0
Epoch:  993        3 Batch loss: 0.240684 Batch F1: 0.0
Epoch:  993        4 Batch loss: 0.224274 Batch F1: 0.0
Epoch:  993        5 Batch loss: 0.240313 Batch F1: 0.0
Epoch:  993        6 Batch loss: 0.225641 Batch F1: 0.0
Epoch:  993        7 Batch loss: 0.190683 Batch F1: 0.0
Epoch:  993        8 Batch loss: 0.199612 Batch F1: 0.0
Epoch:  993        9 Batch loss: 0.222754 Batch F1: 0.0
Epoch:  993       10 Batch loss: 0.243208 Batch F1: 0.0
Epoch:  993       11 Batch loss: 0.250314 Batch F1: 0.0
Epoch:  993       12 Batch loss: 0.229799 Batch F1: 0.0
Train Avg Loss  993: 0.228782

Train Avg F1  993: 0.0

Val Avg Loss  993: 0.219240

Val Avg F1  993:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 994
--------------------------------------------------------------
Epoch:  994        1 Batch loss: 0.268496 Batch F1: 0.0
Epoch:  994        2 Batch loss: 0.205787 Batch F1: 0.0
Epoch:  994        3 Batch loss: 0.240001 Batch F1: 0.0
Epoch:  994        4 Batch loss: 0.213473 Batch F1: 0.1818181818181818
Epoch:  994        5 Batch loss: 0.239096 Batch F1: 0.08695652173913043
Epoch:  994        6 Batch loss: 0.238988 Batch F1: 0.0
Epoch:  994        7 Batch loss: 0.232229 Batch F1: 0.0
Epoch:  994        8 Batch loss: 0.224068 Batch F1: 0.0
Epoch:  994        9 Batch loss: 0.240659 Batch F1: 0.0
Epoch:  994       10 Batch loss: 0.237647 Batch F1: 0.0
Epoch:  994       11 Batch loss: 0.211666 Batch F1: 0.0
Epoch:  994       12 Batch loss: 0.192883 Batch F1: 0.0
Train Avg Loss  994: 0.228749

Train Avg F1  994: 0.022397891963109356

Val Avg Loss  994: 0.218345

Val Avg F1  994:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 995
--------------------------------------------------------------
Epoch:  995        1 Batch loss: 0.228816 Batch F1: 0.0
Epoch:  995        2 Batch loss: 0.231219 Batch F1: 0.0
Epoch:  995        3 Batch loss: 0.221076 Batch F1: 0.0
Epoch:  995        4 Batch loss: 0.218556 Batch F1: 0.0
Epoch:  995        5 Batch loss: 0.245078 Batch F1: 0.37500000000000006
Epoch:  995        6 Batch loss: 0.237392 Batch F1: 0.27586206896551724
Epoch:  995        7 Batch loss: 0.214504 Batch F1: 0.2608695652173913
Epoch:  995        8 Batch loss: 0.233570 Batch F1: 0.0
Epoch:  995        9 Batch loss: 0.214939 Batch F1: 0.0
Epoch:  995       10 Batch loss: 0.230113 Batch F1: 0.0
Epoch:  995       11 Batch loss: 0.250217 Batch F1: 0.0
Epoch:  995       12 Batch loss: 0.217870 Batch F1: 0.0
Train Avg Loss  995: 0.228612

Train Avg F1  995: 0.07597763618190906

Val Avg Loss  995: 0.216970

Val Avg F1  995:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 996
--------------------------------------------------------------
Epoch:  996        1 Batch loss: 0.196532 Batch F1: 0.0
Epoch:  996        2 Batch loss: 0.263434 Batch F1: 0.0
Epoch:  996        3 Batch loss: 0.221566 Batch F1: 0.0
Epoch:  996        4 Batch loss: 0.242806 Batch F1: 0.0
Epoch:  996        5 Batch loss: 0.221788 Batch F1: 0.0
Epoch:  996        6 Batch loss: 0.193837 Batch F1: 0.0
Epoch:  996        7 Batch loss: 0.223026 Batch F1: 0.0
Epoch:  996        8 Batch loss: 0.224705 Batch F1: 0.0
Epoch:  996        9 Batch loss: 0.233913 Batch F1: 0.0
Epoch:  996       10 Batch loss: 0.215302 Batch F1: 0.0
Epoch:  996       11 Batch loss: 0.241564 Batch F1: 0.0
Epoch:  996       12 Batch loss: 0.249330 Batch F1: 0.0
Train Avg Loss  996: 0.227317

Train Avg F1  996: 0.0

Val Avg Loss  996: 0.217380

Val Avg F1  996:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 997
--------------------------------------------------------------
Epoch:  997        1 Batch loss: 0.207837 Batch F1: 0.0
Epoch:  997        2 Batch loss: 0.223095 Batch F1: 0.0
Epoch:  997        3 Batch loss: 0.234714 Batch F1: 0.0
Epoch:  997        4 Batch loss: 0.272941 Batch F1: 0.0
Epoch:  997        5 Batch loss: 0.216039 Batch F1: 0.0
Epoch:  997        6 Batch loss: 0.218955 Batch F1: 0.0
Epoch:  997        7 Batch loss: 0.219676 Batch F1: 0.0
Epoch:  997        8 Batch loss: 0.234230 Batch F1: 0.0
Epoch:  997        9 Batch loss: 0.204881 Batch F1: 0.0
Epoch:  997       10 Batch loss: 0.247216 Batch F1: 0.0
Epoch:  997       11 Batch loss: 0.228672 Batch F1: 0.0
Epoch:  997       12 Batch loss: 0.205544 Batch F1: 0.0
Train Avg Loss  997: 0.226150

Train Avg F1  997: 0.0

Val Avg Loss  997: 0.218535

Val Avg F1  997:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 998
--------------------------------------------------------------
Epoch:  998        1 Batch loss: 0.210009 Batch F1: 0.0
Epoch:  998        2 Batch loss: 0.275626 Batch F1: 0.0
Epoch:  998        3 Batch loss: 0.195815 Batch F1: 0.0
Epoch:  998        4 Batch loss: 0.254415 Batch F1: 0.0
Epoch:  998        5 Batch loss: 0.204631 Batch F1: 0.0
Epoch:  998        6 Batch loss: 0.232358 Batch F1: 0.0
Epoch:  998        7 Batch loss: 0.216326 Batch F1: 0.0
Epoch:  998        8 Batch loss: 0.228846 Batch F1: 0.0
Epoch:  998        9 Batch loss: 0.215108 Batch F1: 0.0
Epoch:  998       10 Batch loss: 0.236547 Batch F1: 0.0
Epoch:  998       11 Batch loss: 0.210676 Batch F1: 0.0
Epoch:  998       12 Batch loss: 0.233184 Batch F1: 0.0
Train Avg Loss  998: 0.226128

Train Avg F1  998: 0.0

Val Avg Loss  998: 0.216681

Val Avg F1  998:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 999
--------------------------------------------------------------
Epoch:  999        1 Batch loss: 0.205635 Batch F1: 0.0
Epoch:  999        2 Batch loss: 0.244586 Batch F1: 0.0
Epoch:  999        3 Batch loss: 0.226177 Batch F1: 0.0
Epoch:  999        4 Batch loss: 0.214470 Batch F1: 0.0
Epoch:  999        5 Batch loss: 0.224876 Batch F1: 0.0
Epoch:  999        6 Batch loss: 0.235171 Batch F1: 0.0
Epoch:  999        7 Batch loss: 0.203261 Batch F1: 0.0
Epoch:  999        8 Batch loss: 0.243010 Batch F1: 0.0
Epoch:  999        9 Batch loss: 0.216432 Batch F1: 0.0
Epoch:  999       10 Batch loss: 0.223228 Batch F1: 0.0
Epoch:  999       11 Batch loss: 0.228858 Batch F1: 0.0
Epoch:  999       12 Batch loss: 0.245415 Batch F1: 0.0
Train Avg Loss  999: 0.225927

Train Avg F1  999: 0.0

Val Avg Loss  999: 0.217394

Val Avg F1  999:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Epoch 1000
--------------------------------------------------------------
Epoch: 1000        1 Batch loss: 0.196140 Batch F1: 0.0
Epoch: 1000        2 Batch loss: 0.215102 Batch F1: 0.0
Epoch: 1000        3 Batch loss: 0.223490 Batch F1: 0.0
Epoch: 1000        4 Batch loss: 0.243964 Batch F1: 0.0
Epoch: 1000        5 Batch loss: 0.217895 Batch F1: 0.0
Epoch: 1000        6 Batch loss: 0.241947 Batch F1: 0.0
Epoch: 1000        7 Batch loss: 0.218689 Batch F1: 0.0
Epoch: 1000        8 Batch loss: 0.206846 Batch F1: 0.0
Epoch: 1000        9 Batch loss: 0.260557 Batch F1: 0.0
Epoch: 1000       10 Batch loss: 0.268320 Batch F1: 0.0
Epoch: 1000       11 Batch loss: 0.201633 Batch F1: 0.0
Epoch: 1000       12 Batch loss: 0.210347 Batch F1: 0.0
Train Avg Loss 1000: 0.225411

Train Avg F1 1000: 0.0

Val Avg Loss 1000: 0.217543

Val Avg F1 1000:  0.0

Optimal Val loss (Epoch 182): 0.2159072905778885

Done!
