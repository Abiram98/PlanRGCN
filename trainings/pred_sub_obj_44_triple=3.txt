Removed 3 of 595
Removed 0 of 198
Removed 0 of 198
Model with variable positions in join nodes
Loss function: MSELoss
Optimizer: LR [0.01] weight decay [0.0005]
Epoch 1
--------------------------------------------------------------
Epoch:    1        1 Batch loss: 0.248646 Batch F1: 0.0
Epoch:    1        2 Batch loss: 0.260789 Batch F1: 0.0
Epoch:    1        3 Batch loss: 0.222508 Batch F1: 0.0
Epoch:    1        4 Batch loss: 0.208406 Batch F1: 0.0
Epoch:    1        5 Batch loss: 0.204003 Batch F1: 0.0
Epoch:    1        6 Batch loss: 0.236907 Batch F1: 0.0
Epoch:    1        7 Batch loss: 0.190546 Batch F1: 0.0
Epoch:    1        8 Batch loss: 0.262211 Batch F1: 0.0
Epoch:    1        9 Batch loss: 0.277685 Batch F1: 0.0
Epoch:    1       10 Batch loss: 0.217653 Batch F1: 0.0
Epoch:    1       11 Batch loss: 0.231034 Batch F1: 0.0
Epoch:    1       12 Batch loss: 0.260886 Batch F1: 0.0
Train Avg Loss    1: 0.235106

Train Avg F1    1: 0.0

Val Avg Loss    1: 0.229910

Val Avg F1    1:  0.0

Optimal Val loss (Epoch 1): 0.2299100160598755

Epoch 2
--------------------------------------------------------------
Epoch:    2        1 Batch loss: 0.255631 Batch F1: 0.0
Epoch:    2        2 Batch loss: 0.251669 Batch F1: 0.5245901639344263
Epoch:    2        3 Batch loss: 0.248823 Batch F1: 0.3870967741935484
Epoch:    2        4 Batch loss: 0.241561 Batch F1: 0.0
Epoch:    2        5 Batch loss: 0.216127 Batch F1: 0.0
Epoch:    2        6 Batch loss: 0.225717 Batch F1: 0.0
Epoch:    2        7 Batch loss: 0.230354 Batch F1: 0.0
Epoch:    2        8 Batch loss: 0.244104 Batch F1: 0.0
Epoch:    2        9 Batch loss: 0.251636 Batch F1: 0.0
Epoch:    2       10 Batch loss: 0.211042 Batch F1: 0.0
Epoch:    2       11 Batch loss: 0.184633 Batch F1: 0.0
Epoch:    2       12 Batch loss: 0.302558 Batch F1: 0.0
Train Avg Loss    2: 0.238655

Train Avg F1    2: 0.07597391151066456

Val Avg Loss    2: 0.222129

Val Avg F1    2:  0.0

Optimal Val loss (Epoch 2): 0.22212932258844376

Epoch 3
--------------------------------------------------------------
Epoch:    3        1 Batch loss: 0.249949 Batch F1: 0.0
Epoch:    3        2 Batch loss: 0.218763 Batch F1: 0.0
Epoch:    3        3 Batch loss: 0.257457 Batch F1: 0.0
Epoch:    3        4 Batch loss: 0.235685 Batch F1: 0.0
Epoch:    3        5 Batch loss: 0.227928 Batch F1: 0.0
Epoch:    3        6 Batch loss: 0.229056 Batch F1: 0.0
Epoch:    3        7 Batch loss: 0.206944 Batch F1: 0.0
Epoch:    3        8 Batch loss: 0.213586 Batch F1: 0.0
Epoch:    3        9 Batch loss: 0.214050 Batch F1: 0.0
Epoch:    3       10 Batch loss: 0.293536 Batch F1: 0.0
Epoch:    3       11 Batch loss: 0.237445 Batch F1: 0.0
Epoch:    3       12 Batch loss: 0.245512 Batch F1: 0.0
Train Avg Loss    3: 0.235826

Train Avg F1    3: 0.0

Val Avg Loss    3: 0.222181

Val Avg F1    3:  0.0

Optimal Val loss (Epoch 2): 0.22212932258844376

Epoch 4
--------------------------------------------------------------
Epoch:    4        1 Batch loss: 0.237283 Batch F1: 0.0
Epoch:    4        2 Batch loss: 0.211707 Batch F1: 0.0
Epoch:    4        3 Batch loss: 0.236862 Batch F1: 0.0
Epoch:    4        4 Batch loss: 0.242599 Batch F1: 0.0
Epoch:    4        5 Batch loss: 0.218711 Batch F1: 0.0
Epoch:    4        6 Batch loss: 0.224771 Batch F1: 0.0
Epoch:    4        7 Batch loss: 0.247131 Batch F1: 0.0
Epoch:    4        8 Batch loss: 0.241089 Batch F1: 0.0
Epoch:    4        9 Batch loss: 0.204946 Batch F1: 0.0
Epoch:    4       10 Batch loss: 0.250846 Batch F1: 0.0
Epoch:    4       11 Batch loss: 0.250416 Batch F1: 0.0
Epoch:    4       12 Batch loss: 0.219190 Batch F1: 0.0
Train Avg Loss    4: 0.232129

Train Avg F1    4: 0.0

Val Avg Loss    4: 0.224650

Val Avg F1    4:  0.0

Optimal Val loss (Epoch 2): 0.22212932258844376

Epoch 5
--------------------------------------------------------------
Epoch:    5        1 Batch loss: 0.222053 Batch F1: 0.0
Epoch:    5        2 Batch loss: 0.216736 Batch F1: 0.0
Epoch:    5        3 Batch loss: 0.235599 Batch F1: 0.0
Epoch:    5        4 Batch loss: 0.224967 Batch F1: 0.0
Epoch:    5        5 Batch loss: 0.258599 Batch F1: 0.0
Epoch:    5        6 Batch loss: 0.298336 Batch F1: 0.0
Epoch:    5        7 Batch loss: 0.235771 Batch F1: 0.0
Epoch:    5        8 Batch loss: 0.196373 Batch F1: 0.0
Epoch:    5        9 Batch loss: 0.225777 Batch F1: 0.0
Epoch:    5       10 Batch loss: 0.220862 Batch F1: 0.0
Epoch:    5       11 Batch loss: 0.230641 Batch F1: 0.0
Epoch:    5       12 Batch loss: 0.235790 Batch F1: 0.0
Train Avg Loss    5: 0.233459

Train Avg F1    5: 0.0

Val Avg Loss    5: 0.223341

Val Avg F1    5:  0.0

Optimal Val loss (Epoch 2): 0.22212932258844376

Epoch 6
--------------------------------------------------------------
Epoch:    6        1 Batch loss: 0.220120 Batch F1: 0.0
Epoch:    6        2 Batch loss: 0.235744 Batch F1: 0.0
Epoch:    6        3 Batch loss: 0.235802 Batch F1: 0.0
Epoch:    6        4 Batch loss: 0.208820 Batch F1: 0.0
Epoch:    6        5 Batch loss: 0.230408 Batch F1: 0.0
Epoch:    6        6 Batch loss: 0.230407 Batch F1: 0.0
Epoch:    6        7 Batch loss: 0.253633 Batch F1: 0.0
Epoch:    6        8 Batch loss: 0.213103 Batch F1: 0.0
Epoch:    6        9 Batch loss: 0.236294 Batch F1: 0.0
Epoch:    6       10 Batch loss: 0.230441 Batch F1: 0.0
Epoch:    6       11 Batch loss: 0.236292 Batch F1: 0.0
Epoch:    6       12 Batch loss: 0.264189 Batch F1: 0.0
Train Avg Loss    6: 0.232938

Train Avg F1    6: 0.0

Val Avg Loss    6: 0.223154

Val Avg F1    6:  0.0

Optimal Val loss (Epoch 2): 0.22212932258844376

Epoch 7
--------------------------------------------------------------
Epoch:    7        1 Batch loss: 0.208486 Batch F1: 0.0
Epoch:    7        2 Batch loss: 0.219320 Batch F1: 0.0
Epoch:    7        3 Batch loss: 0.257854 Batch F1: 0.0
Epoch:    7        4 Batch loss: 0.251704 Batch F1: 0.0
Epoch:    7        5 Batch loss: 0.220702 Batch F1: 0.0
Epoch:    7        6 Batch loss: 0.212337 Batch F1: 0.0
Epoch:    7        7 Batch loss: 0.240582 Batch F1: 0.0
Epoch:    7        8 Batch loss: 0.225455 Batch F1: 0.0
Epoch:    7        9 Batch loss: 0.251425 Batch F1: 0.0
Epoch:    7       10 Batch loss: 0.256351 Batch F1: 0.0
Epoch:    7       11 Batch loss: 0.230231 Batch F1: 0.0
Epoch:    7       12 Batch loss: 0.212854 Batch F1: 0.0
Train Avg Loss    7: 0.232275

Train Avg F1    7: 0.0

Val Avg Loss    7: 0.223967

Val Avg F1    7:  0.0

Optimal Val loss (Epoch 2): 0.22212932258844376

Epoch 8
--------------------------------------------------------------
Epoch:    8        1 Batch loss: 0.230657 Batch F1: 0.0
Epoch:    8        2 Batch loss: 0.245277 Batch F1: 0.0
Epoch:    8        3 Batch loss: 0.259809 Batch F1: 0.0
Epoch:    8        4 Batch loss: 0.212127 Batch F1: 0.0
Epoch:    8        5 Batch loss: 0.216761 Batch F1: 0.0
Epoch:    8        6 Batch loss: 0.216455 Batch F1: 0.0
Epoch:    8        7 Batch loss: 0.235574 Batch F1: 0.0
Epoch:    8        8 Batch loss: 0.219872 Batch F1: 0.0
Epoch:    8        9 Batch loss: 0.262637 Batch F1: 0.0
Epoch:    8       10 Batch loss: 0.246721 Batch F1: 0.0
Epoch:    8       11 Batch loss: 0.214346 Batch F1: 0.0
Epoch:    8       12 Batch loss: 0.229298 Batch F1: 0.0
Train Avg Loss    8: 0.232461

Train Avg F1    8: 0.0

Val Avg Loss    8: 0.223145

Val Avg F1    8:  0.0

Optimal Val loss (Epoch 2): 0.22212932258844376

Epoch 9
--------------------------------------------------------------
Epoch:    9        1 Batch loss: 0.230212 Batch F1: 0.0
Epoch:    9        2 Batch loss: 0.235734 Batch F1: 0.0
Epoch:    9        3 Batch loss: 0.209143 Batch F1: 0.0
Epoch:    9        4 Batch loss: 0.235749 Batch F1: 0.0
Epoch:    9        5 Batch loss: 0.241565 Batch F1: 0.0
Epoch:    9        6 Batch loss: 0.223951 Batch F1: 0.0
Epoch:    9        7 Batch loss: 0.225165 Batch F1: 0.0
Epoch:    9        8 Batch loss: 0.234601 Batch F1: 0.0
Epoch:    9        9 Batch loss: 0.249601 Batch F1: 0.0
Epoch:    9       10 Batch loss: 0.223064 Batch F1: 0.0
Epoch:    9       11 Batch loss: 0.233627 Batch F1: 0.0
Epoch:    9       12 Batch loss: 0.235322 Batch F1: 0.0
Train Avg Loss    9: 0.231478

Train Avg F1    9: 0.0

Val Avg Loss    9: 0.221617

Val Avg F1    9:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 10
--------------------------------------------------------------
Epoch:   10        1 Batch loss: 0.250896 Batch F1: 0.0
Epoch:   10        2 Batch loss: 0.212641 Batch F1: 0.0
Epoch:   10        3 Batch loss: 0.241755 Batch F1: 0.0
Epoch:   10        4 Batch loss: 0.200032 Batch F1: 0.0
Epoch:   10        5 Batch loss: 0.237187 Batch F1: 0.0
Epoch:   10        6 Batch loss: 0.246969 Batch F1: 0.0
Epoch:   10        7 Batch loss: 0.226266 Batch F1: 0.0
Epoch:   10        8 Batch loss: 0.183389 Batch F1: 0.0
Epoch:   10        9 Batch loss: 0.248042 Batch F1: 0.0
Epoch:   10       10 Batch loss: 0.234863 Batch F1: 0.0
Epoch:   10       11 Batch loss: 0.254787 Batch F1: 0.0
Epoch:   10       12 Batch loss: 0.240186 Batch F1: 0.0
Train Avg Loss   10: 0.231418

Train Avg F1   10: 0.0

Val Avg Loss   10: 0.221660

Val Avg F1   10:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 11
--------------------------------------------------------------
Epoch:   11        1 Batch loss: 0.234225 Batch F1: 0.0
Epoch:   11        2 Batch loss: 0.213158 Batch F1: 0.0
Epoch:   11        3 Batch loss: 0.265091 Batch F1: 0.0
Epoch:   11        4 Batch loss: 0.224440 Batch F1: 0.0
Epoch:   11        5 Batch loss: 0.211502 Batch F1: 0.0
Epoch:   11        6 Batch loss: 0.235623 Batch F1: 0.0
Epoch:   11        7 Batch loss: 0.212963 Batch F1: 0.0
Epoch:   11        8 Batch loss: 0.229561 Batch F1: 0.0
Epoch:   11        9 Batch loss: 0.252378 Batch F1: 0.0
Epoch:   11       10 Batch loss: 0.270209 Batch F1: 0.0
Epoch:   11       11 Batch loss: 0.206636 Batch F1: 0.0
Epoch:   11       12 Batch loss: 0.224730 Batch F1: 0.0
Train Avg Loss   11: 0.231710

Train Avg F1   11: 0.0

Val Avg Loss   11: 0.221686

Val Avg F1   11:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 12
--------------------------------------------------------------
Epoch:   12        1 Batch loss: 0.233454 Batch F1: 0.0
Epoch:   12        2 Batch loss: 0.231195 Batch F1: 0.0
Epoch:   12        3 Batch loss: 0.189431 Batch F1: 0.0
Epoch:   12        4 Batch loss: 0.238439 Batch F1: 0.0
Epoch:   12        5 Batch loss: 0.247016 Batch F1: 0.0
Epoch:   12        6 Batch loss: 0.242538 Batch F1: 0.0
Epoch:   12        7 Batch loss: 0.256847 Batch F1: 0.0
Epoch:   12        8 Batch loss: 0.242883 Batch F1: 0.0
Epoch:   12        9 Batch loss: 0.240943 Batch F1: 0.0
Epoch:   12       10 Batch loss: 0.205634 Batch F1: 0.0
Epoch:   12       11 Batch loss: 0.225551 Batch F1: 0.0
Epoch:   12       12 Batch loss: 0.216855 Batch F1: 0.0
Train Avg Loss   12: 0.230899

Train Avg F1   12: 0.0

Val Avg Loss   12: 0.222474

Val Avg F1   12:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 13
--------------------------------------------------------------
Epoch:   13        1 Batch loss: 0.205833 Batch F1: 0.0
Epoch:   13        2 Batch loss: 0.258595 Batch F1: 0.0
Epoch:   13        3 Batch loss: 0.217599 Batch F1: 0.0
Epoch:   13        4 Batch loss: 0.241657 Batch F1: 0.0
Epoch:   13        5 Batch loss: 0.239099 Batch F1: 0.0
Epoch:   13        6 Batch loss: 0.269739 Batch F1: 0.0
Epoch:   13        7 Batch loss: 0.232216 Batch F1: 0.0
Epoch:   13        8 Batch loss: 0.229146 Batch F1: 0.0
Epoch:   13        9 Batch loss: 0.232925 Batch F1: 0.0
Epoch:   13       10 Batch loss: 0.230630 Batch F1: 0.0
Epoch:   13       11 Batch loss: 0.207776 Batch F1: 0.0
Epoch:   13       12 Batch loss: 0.228469 Batch F1: 0.0
Train Avg Loss   13: 0.232807

Train Avg F1   13: 0.0

Val Avg Loss   13: 0.221942

Val Avg F1   13:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 14
--------------------------------------------------------------
Epoch:   14        1 Batch loss: 0.235200 Batch F1: 0.0
Epoch:   14        2 Batch loss: 0.217438 Batch F1: 0.0
Epoch:   14        3 Batch loss: 0.215387 Batch F1: 0.0
Epoch:   14        4 Batch loss: 0.231490 Batch F1: 0.0
Epoch:   14        5 Batch loss: 0.212386 Batch F1: 0.0
Epoch:   14        6 Batch loss: 0.232315 Batch F1: 0.0
Epoch:   14        7 Batch loss: 0.227665 Batch F1: 0.0
Epoch:   14        8 Batch loss: 0.202845 Batch F1: 0.0
Epoch:   14        9 Batch loss: 0.252517 Batch F1: 0.0
Epoch:   14       10 Batch loss: 0.263788 Batch F1: 0.0
Epoch:   14       11 Batch loss: 0.252861 Batch F1: 0.0
Epoch:   14       12 Batch loss: 0.236387 Batch F1: 0.0
Train Avg Loss   14: 0.231690

Train Avg F1   14: 0.0

Val Avg Loss   14: 0.227022

Val Avg F1   14:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 15
--------------------------------------------------------------
Epoch:   15        1 Batch loss: 0.226916 Batch F1: 0.0
Epoch:   15        2 Batch loss: 0.244071 Batch F1: 0.0
Epoch:   15        3 Batch loss: 0.259071 Batch F1: 0.0
Epoch:   15        4 Batch loss: 0.222285 Batch F1: 0.0
Epoch:   15        5 Batch loss: 0.235332 Batch F1: 0.0
Epoch:   15        6 Batch loss: 0.233045 Batch F1: 0.0
Epoch:   15        7 Batch loss: 0.229664 Batch F1: 0.0
Epoch:   15        8 Batch loss: 0.212990 Batch F1: 0.0
Epoch:   15        9 Batch loss: 0.231292 Batch F1: 0.0
Epoch:   15       10 Batch loss: 0.203150 Batch F1: 0.0
Epoch:   15       11 Batch loss: 0.258179 Batch F1: 0.0
Epoch:   15       12 Batch loss: 0.229476 Batch F1: 0.0
Train Avg Loss   15: 0.232123

Train Avg F1   15: 0.0

Val Avg Loss   15: 0.222108

Val Avg F1   15:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 16
--------------------------------------------------------------
Epoch:   16        1 Batch loss: 0.205229 Batch F1: 0.0
Epoch:   16        2 Batch loss: 0.256281 Batch F1: 0.0
Epoch:   16        3 Batch loss: 0.254178 Batch F1: 0.0
Epoch:   16        4 Batch loss: 0.230864 Batch F1: 0.0
Epoch:   16        5 Batch loss: 0.216300 Batch F1: 0.0
Epoch:   16        6 Batch loss: 0.247731 Batch F1: 0.0
Epoch:   16        7 Batch loss: 0.244544 Batch F1: 0.0
Epoch:   16        8 Batch loss: 0.246595 Batch F1: 0.0
Epoch:   16        9 Batch loss: 0.230069 Batch F1: 0.0
Epoch:   16       10 Batch loss: 0.227463 Batch F1: 0.0
Epoch:   16       11 Batch loss: 0.230128 Batch F1: 0.0
Epoch:   16       12 Batch loss: 0.192221 Batch F1: 0.0
Train Avg Loss   16: 0.231800

Train Avg F1   16: 0.0

Val Avg Loss   16: 0.221884

Val Avg F1   16:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 17
--------------------------------------------------------------
Epoch:   17        1 Batch loss: 0.237533 Batch F1: 0.0
Epoch:   17        2 Batch loss: 0.258243 Batch F1: 0.0
Epoch:   17        3 Batch loss: 0.275859 Batch F1: 0.0
Epoch:   17        4 Batch loss: 0.213220 Batch F1: 0.0
Epoch:   17        5 Batch loss: 0.215335 Batch F1: 0.0
Epoch:   17        6 Batch loss: 0.220423 Batch F1: 0.0
Epoch:   17        7 Batch loss: 0.209087 Batch F1: 0.0
Epoch:   17        8 Batch loss: 0.223779 Batch F1: 0.0
Epoch:   17        9 Batch loss: 0.230437 Batch F1: 0.0
Epoch:   17       10 Batch loss: 0.257912 Batch F1: 0.0
Epoch:   17       11 Batch loss: 0.224218 Batch F1: 0.0
Epoch:   17       12 Batch loss: 0.245894 Batch F1: 0.0
Train Avg Loss   17: 0.234328

Train Avg F1   17: 0.0

Val Avg Loss   17: 0.222191

Val Avg F1   17:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 18
--------------------------------------------------------------
Epoch:   18        1 Batch loss: 0.243785 Batch F1: 0.0
Epoch:   18        2 Batch loss: 0.205539 Batch F1: 0.0
Epoch:   18        3 Batch loss: 0.259776 Batch F1: 0.0
Epoch:   18        4 Batch loss: 0.257604 Batch F1: 0.0
Epoch:   18        5 Batch loss: 0.215748 Batch F1: 0.0
Epoch:   18        6 Batch loss: 0.196486 Batch F1: 0.0
Epoch:   18        7 Batch loss: 0.250507 Batch F1: 0.0
Epoch:   18        8 Batch loss: 0.230267 Batch F1: 0.0
Epoch:   18        9 Batch loss: 0.220513 Batch F1: 0.0
Epoch:   18       10 Batch loss: 0.251284 Batch F1: 0.0
Epoch:   18       11 Batch loss: 0.225243 Batch F1: 0.0
Epoch:   18       12 Batch loss: 0.242315 Batch F1: 0.0
Train Avg Loss   18: 0.233256

Train Avg F1   18: 0.0

Val Avg Loss   18: 0.222892

Val Avg F1   18:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 19
--------------------------------------------------------------
Epoch:   19        1 Batch loss: 0.268157 Batch F1: 0.0
Epoch:   19        2 Batch loss: 0.215456 Batch F1: 0.0
Epoch:   19        3 Batch loss: 0.240115 Batch F1: 0.0
Epoch:   19        4 Batch loss: 0.230891 Batch F1: 0.0
Epoch:   19        5 Batch loss: 0.216550 Batch F1: 0.0
Epoch:   19        6 Batch loss: 0.216451 Batch F1: 0.0
Epoch:   19        7 Batch loss: 0.250259 Batch F1: 0.0
Epoch:   19        8 Batch loss: 0.250633 Batch F1: 0.0
Epoch:   19        9 Batch loss: 0.190709 Batch F1: 0.0
Epoch:   19       10 Batch loss: 0.230383 Batch F1: 0.0
Epoch:   19       11 Batch loss: 0.235741 Batch F1: 0.0
Epoch:   19       12 Batch loss: 0.249706 Batch F1: 0.0
Train Avg Loss   19: 0.232921

Train Avg F1   19: 0.0

Val Avg Loss   19: 0.222646

Val Avg F1   19:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 20
--------------------------------------------------------------
Epoch:   20        1 Batch loss: 0.219103 Batch F1: 0.0
Epoch:   20        2 Batch loss: 0.241676 Batch F1: 0.0
Epoch:   20        3 Batch loss: 0.201411 Batch F1: 0.0
Epoch:   20        4 Batch loss: 0.260101 Batch F1: 0.0
Epoch:   20        5 Batch loss: 0.200895 Batch F1: 0.0
Epoch:   20        6 Batch loss: 0.260379 Batch F1: 0.0
Epoch:   20        7 Batch loss: 0.230536 Batch F1: 0.0
Epoch:   20        8 Batch loss: 0.265357 Batch F1: 0.0
Epoch:   20        9 Batch loss: 0.207897 Batch F1: 0.0
Epoch:   20       10 Batch loss: 0.202794 Batch F1: 0.0
Epoch:   20       11 Batch loss: 0.268524 Batch F1: 0.0
Epoch:   20       12 Batch loss: 0.229537 Batch F1: 0.0
Train Avg Loss   20: 0.232351

Train Avg F1   20: 0.0

Val Avg Loss   20: 0.223181

Val Avg F1   20:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 21
--------------------------------------------------------------
Epoch:   21        1 Batch loss: 0.250869 Batch F1: 0.0
Epoch:   21        2 Batch loss: 0.229502 Batch F1: 0.0
Epoch:   21        3 Batch loss: 0.235455 Batch F1: 0.0
Epoch:   21        4 Batch loss: 0.234972 Batch F1: 0.0
Epoch:   21        5 Batch loss: 0.234087 Batch F1: 0.0
Epoch:   21        6 Batch loss: 0.228462 Batch F1: 0.0
Epoch:   21        7 Batch loss: 0.215514 Batch F1: 0.0
Epoch:   21        8 Batch loss: 0.250792 Batch F1: 0.0
Epoch:   21        9 Batch loss: 0.220625 Batch F1: 0.0
Epoch:   21       10 Batch loss: 0.244748 Batch F1: 0.0
Epoch:   21       11 Batch loss: 0.239960 Batch F1: 0.0
Epoch:   21       12 Batch loss: 0.198436 Batch F1: 0.0
Train Avg Loss   21: 0.231952

Train Avg F1   21: 0.0

Val Avg Loss   21: 0.222724

Val Avg F1   21:  0.0

Optimal Val loss (Epoch 9): 0.22161738947033882

Epoch 22
--------------------------------------------------------------
Epoch:   22        1 Batch loss: 0.229250 Batch F1: 0.0
Epoch:   22        2 Batch loss: 0.252364 Batch F1: 0.0
Epoch:   22        3 Batch loss: 0.213718 Batch F1: 0.0
Epoch:   22        4 Batch loss: 0.228771 Batch F1: 0.0
Epoch:   22        5 Batch loss: 0.247779 Batch F1: 0.0
Epoch:   22        6 Batch loss: 0.222681 Batch F1: 0.0
Epoch:   22        7 Batch loss: 0.215621 Batch F1: 0.0
Epoch:   22        8 Batch loss: 0.235405 Batch F1: 0.0
Epoch:   22        9 Batch loss: 0.237902 Batch F1: 0.0
Epoch:   22       10 Batch loss: 0.212093 Batch F1: 0.0
Epoch:   22       11 Batch loss: 0.245335 Batch F1: 0.0
Epoch:   22       12 Batch loss: 0.234829 Batch F1: 0.0
Train Avg Loss   22: 0.231312

Train Avg F1   22: 0.0

Val Avg Loss   22: 0.221196

Val Avg F1   22:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 23
--------------------------------------------------------------
Epoch:   23        1 Batch loss: 0.226674 Batch F1: 0.0
Epoch:   23        2 Batch loss: 0.223309 Batch F1: 0.0
Epoch:   23        3 Batch loss: 0.254380 Batch F1: 0.0
Epoch:   23        4 Batch loss: 0.216130 Batch F1: 0.0
Epoch:   23        5 Batch loss: 0.220461 Batch F1: 0.0
Epoch:   23        6 Batch loss: 0.193521 Batch F1: 0.0
Epoch:   23        7 Batch loss: 0.211471 Batch F1: 0.0
Epoch:   23        8 Batch loss: 0.224698 Batch F1: 0.0
Epoch:   23        9 Batch loss: 0.244866 Batch F1: 0.0
Epoch:   23       10 Batch loss: 0.269871 Batch F1: 0.0
Epoch:   23       11 Batch loss: 0.263577 Batch F1: 0.0
Epoch:   23       12 Batch loss: 0.237803 Batch F1: 0.0
Train Avg Loss   23: 0.232230

Train Avg F1   23: 0.0

Val Avg Loss   23: 0.234789

Val Avg F1   23:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 24
--------------------------------------------------------------
Epoch:   24        1 Batch loss: 0.237210 Batch F1: 0.0
Epoch:   24        2 Batch loss: 0.239929 Batch F1: 0.0
Epoch:   24        3 Batch loss: 0.231695 Batch F1: 0.0
Epoch:   24        4 Batch loss: 0.242362 Batch F1: 0.0
Epoch:   24        5 Batch loss: 0.258987 Batch F1: 0.0
Epoch:   24        6 Batch loss: 0.215281 Batch F1: 0.0
Epoch:   24        7 Batch loss: 0.208694 Batch F1: 0.0
Epoch:   24        8 Batch loss: 0.234910 Batch F1: 0.0
Epoch:   24        9 Batch loss: 0.248861 Batch F1: 0.0
Epoch:   24       10 Batch loss: 0.230668 Batch F1: 0.0
Epoch:   24       11 Batch loss: 0.217950 Batch F1: 0.0
Epoch:   24       12 Batch loss: 0.229778 Batch F1: 0.0
Train Avg Loss   24: 0.233027

Train Avg F1   24: 0.0

Val Avg Loss   24: 0.221839

Val Avg F1   24:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 25
--------------------------------------------------------------
Epoch:   25        1 Batch loss: 0.267465 Batch F1: 0.0
Epoch:   25        2 Batch loss: 0.200601 Batch F1: 0.0
Epoch:   25        3 Batch loss: 0.217048 Batch F1: 0.0
Epoch:   25        4 Batch loss: 0.211799 Batch F1: 0.0
Epoch:   25        5 Batch loss: 0.249114 Batch F1: 0.0
Epoch:   25        6 Batch loss: 0.226047 Batch F1: 0.0
Epoch:   25        7 Batch loss: 0.252035 Batch F1: 0.0
Epoch:   25        8 Batch loss: 0.239950 Batch F1: 0.0
Epoch:   25        9 Batch loss: 0.216488 Batch F1: 0.0
Epoch:   25       10 Batch loss: 0.243276 Batch F1: 0.0
Epoch:   25       11 Batch loss: 0.241840 Batch F1: 0.0
Epoch:   25       12 Batch loss: 0.218370 Batch F1: 0.0
Train Avg Loss   25: 0.232003

Train Avg F1   25: 0.0

Val Avg Loss   25: 0.224333

Val Avg F1   25:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 26
--------------------------------------------------------------
Epoch:   26        1 Batch loss: 0.241911 Batch F1: 0.0
Epoch:   26        2 Batch loss: 0.190404 Batch F1: 0.0
Epoch:   26        3 Batch loss: 0.249876 Batch F1: 0.0
Epoch:   26        4 Batch loss: 0.218128 Batch F1: 0.0
Epoch:   26        5 Batch loss: 0.217125 Batch F1: 0.0
Epoch:   26        6 Batch loss: 0.221941 Batch F1: 0.0
Epoch:   26        7 Batch loss: 0.217439 Batch F1: 0.0
Epoch:   26        8 Batch loss: 0.280097 Batch F1: 0.0
Epoch:   26        9 Batch loss: 0.217610 Batch F1: 0.0
Epoch:   26       10 Batch loss: 0.230126 Batch F1: 0.0
Epoch:   26       11 Batch loss: 0.242757 Batch F1: 0.0
Epoch:   26       12 Batch loss: 0.252811 Batch F1: 0.0
Train Avg Loss   26: 0.231685

Train Avg F1   26: 0.0

Val Avg Loss   26: 0.225822

Val Avg F1   26:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 27
--------------------------------------------------------------
Epoch:   27        1 Batch loss: 0.237634 Batch F1: 0.0
Epoch:   27        2 Batch loss: 0.246827 Batch F1: 0.0
Epoch:   27        3 Batch loss: 0.241993 Batch F1: 0.0
Epoch:   27        4 Batch loss: 0.226311 Batch F1: 0.0
Epoch:   27        5 Batch loss: 0.232364 Batch F1: 0.0
Epoch:   27        6 Batch loss: 0.241569 Batch F1: 0.0
Epoch:   27        7 Batch loss: 0.208586 Batch F1: 0.0
Epoch:   27        8 Batch loss: 0.204613 Batch F1: 0.0
Epoch:   27        9 Batch loss: 0.224113 Batch F1: 0.0
Epoch:   27       10 Batch loss: 0.224747 Batch F1: 0.0
Epoch:   27       11 Batch loss: 0.259957 Batch F1: 0.0
Epoch:   27       12 Batch loss: 0.246550 Batch F1: 0.0
Train Avg Loss   27: 0.232939

Train Avg F1   27: 0.0

Val Avg Loss   27: 0.221837

Val Avg F1   27:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 28
--------------------------------------------------------------
Epoch:   28        1 Batch loss: 0.198297 Batch F1: 0.0
Epoch:   28        2 Batch loss: 0.246349 Batch F1: 0.0
Epoch:   28        3 Batch loss: 0.182750 Batch F1: 0.0
Epoch:   28        4 Batch loss: 0.230678 Batch F1: 0.0
Epoch:   28        5 Batch loss: 0.261130 Batch F1: 0.0
Epoch:   28        6 Batch loss: 0.269241 Batch F1: 0.0
Epoch:   28        7 Batch loss: 0.217938 Batch F1: 0.0
Epoch:   28        8 Batch loss: 0.201128 Batch F1: 0.0
Epoch:   28        9 Batch loss: 0.237634 Batch F1: 0.0
Epoch:   28       10 Batch loss: 0.232618 Batch F1: 0.0
Epoch:   28       11 Batch loss: 0.262157 Batch F1: 0.0
Epoch:   28       12 Batch loss: 0.243433 Batch F1: 0.0
Train Avg Loss   28: 0.231946

Train Avg F1   28: 0.0

Val Avg Loss   28: 0.225577

Val Avg F1   28:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 29
--------------------------------------------------------------
Epoch:   29        1 Batch loss: 0.216190 Batch F1: 0.0
Epoch:   29        2 Batch loss: 0.227944 Batch F1: 0.0
Epoch:   29        3 Batch loss: 0.219458 Batch F1: 0.0
Epoch:   29        4 Batch loss: 0.263310 Batch F1: 0.0
Epoch:   29        5 Batch loss: 0.255924 Batch F1: 0.0
Epoch:   29        6 Batch loss: 0.272489 Batch F1: 0.0
Epoch:   29        7 Batch loss: 0.226452 Batch F1: 0.0
Epoch:   29        8 Batch loss: 0.233025 Batch F1: 0.0
Epoch:   29        9 Batch loss: 0.246587 Batch F1: 0.0
Epoch:   29       10 Batch loss: 0.217058 Batch F1: 0.0
Epoch:   29       11 Batch loss: 0.228924 Batch F1: 0.0
Epoch:   29       12 Batch loss: 0.199413 Batch F1: 0.0
Train Avg Loss   29: 0.233898

Train Avg F1   29: 0.0

Val Avg Loss   29: 0.221726

Val Avg F1   29:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 30
--------------------------------------------------------------
Epoch:   30        1 Batch loss: 0.234939 Batch F1: 0.0
Epoch:   30        2 Batch loss: 0.250502 Batch F1: 0.0
Epoch:   30        3 Batch loss: 0.225111 Batch F1: 0.0
Epoch:   30        4 Batch loss: 0.238163 Batch F1: 0.0
Epoch:   30        5 Batch loss: 0.237060 Batch F1: 0.0
Epoch:   30        6 Batch loss: 0.217871 Batch F1: 0.0
Epoch:   30        7 Batch loss: 0.188795 Batch F1: 0.0
Epoch:   30        8 Batch loss: 0.236849 Batch F1: 0.0
Epoch:   30        9 Batch loss: 0.248665 Batch F1: 0.0
Epoch:   30       10 Batch loss: 0.246469 Batch F1: 0.0
Epoch:   30       11 Batch loss: 0.246861 Batch F1: 0.0
Epoch:   30       12 Batch loss: 0.224005 Batch F1: 0.0
Train Avg Loss   30: 0.232941

Train Avg F1   30: 0.0

Val Avg Loss   30: 0.224162

Val Avg F1   30:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 31
--------------------------------------------------------------
Epoch:   31        1 Batch loss: 0.268516 Batch F1: 0.0
Epoch:   31        2 Batch loss: 0.243480 Batch F1: 0.0
Epoch:   31        3 Batch loss: 0.239644 Batch F1: 0.0
Epoch:   31        4 Batch loss: 0.248633 Batch F1: 0.0
Epoch:   31        5 Batch loss: 0.232992 Batch F1: 0.0
Epoch:   31        6 Batch loss: 0.231672 Batch F1: 0.0
Epoch:   31        7 Batch loss: 0.200576 Batch F1: 0.0
Epoch:   31        8 Batch loss: 0.263047 Batch F1: 0.0
Epoch:   31        9 Batch loss: 0.238523 Batch F1: 0.0
Epoch:   31       10 Batch loss: 0.217702 Batch F1: 0.0
Epoch:   31       11 Batch loss: 0.169301 Batch F1: 0.0
Epoch:   31       12 Batch loss: 0.238938 Batch F1: 0.0
Train Avg Loss   31: 0.232752

Train Avg F1   31: 0.0

Val Avg Loss   31: 0.222209

Val Avg F1   31:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 32
--------------------------------------------------------------
Epoch:   32        1 Batch loss: 0.246355 Batch F1: 0.0
Epoch:   32        2 Batch loss: 0.224745 Batch F1: 0.0
Epoch:   32        3 Batch loss: 0.224308 Batch F1: 0.0
Epoch:   32        4 Batch loss: 0.244765 Batch F1: 0.0
Epoch:   32        5 Batch loss: 0.244542 Batch F1: 0.0
Epoch:   32        6 Batch loss: 0.247707 Batch F1: 0.0
Epoch:   32        7 Batch loss: 0.245076 Batch F1: 0.0
Epoch:   32        8 Batch loss: 0.218370 Batch F1: 0.0
Epoch:   32        9 Batch loss: 0.221032 Batch F1: 0.0
Epoch:   32       10 Batch loss: 0.248403 Batch F1: 0.0
Epoch:   32       11 Batch loss: 0.210267 Batch F1: 0.0
Epoch:   32       12 Batch loss: 0.234620 Batch F1: 0.0
Train Avg Loss   32: 0.234183

Train Avg F1   32: 0.0

Val Avg Loss   32: 0.221858

Val Avg F1   32:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 33
--------------------------------------------------------------
Epoch:   33        1 Batch loss: 0.253711 Batch F1: 0.0
Epoch:   33        2 Batch loss: 0.218644 Batch F1: 0.0
Epoch:   33        3 Batch loss: 0.260499 Batch F1: 0.0
Epoch:   33        4 Batch loss: 0.218407 Batch F1: 0.0
Epoch:   33        5 Batch loss: 0.258357 Batch F1: 0.0
Epoch:   33        6 Batch loss: 0.223830 Batch F1: 0.0
Epoch:   33        7 Batch loss: 0.249566 Batch F1: 0.0
Epoch:   33        8 Batch loss: 0.222118 Batch F1: 0.0
Epoch:   33        9 Batch loss: 0.212752 Batch F1: 0.0
Epoch:   33       10 Batch loss: 0.223526 Batch F1: 0.0
Epoch:   33       11 Batch loss: 0.234023 Batch F1: 0.0
Epoch:   33       12 Batch loss: 0.211926 Batch F1: 0.0
Train Avg Loss   33: 0.232280

Train Avg F1   33: 0.0

Val Avg Loss   33: 0.222134

Val Avg F1   33:  0.0

Optimal Val loss (Epoch 22): 0.22119560465216637

Epoch 34
--------------------------------------------------------------
Epoch:   34        1 Batch loss: 0.261358 Batch F1: 0.0
Epoch:   34        2 Batch loss: 0.201846 Batch F1: 0.0
Epoch:   34        3 Batch loss: 0.221125 Batch F1: 0.0
Epoch:   34        4 Batch loss: 0.243327 Batch F1: 0.0
Epoch:   34        5 Batch loss: 0.241861 Batch F1: 0.0
Epoch:   34        6 Batch loss: 0.217620 Batch F1: 0.0
Epoch:   34        7 Batch loss: 0.205395 Batch F1: 0.0
Epoch:   34        8 Batch loss: 0.271221 Batch F1: 0.0
Epoch:   34        9 Batch loss: 0.229224 Batch F1: 0.0
Epoch:   34       10 Batch loss: 0.222526 Batch F1: 0.0
Epoch:   34       11 Batch loss: 0.238105 Batch F1: 0.0
Epoch:   34       12 Batch loss: 0.219054 Batch F1: 0.0
Train Avg Loss   34: 0.231055

Train Avg F1   34: 0.0

Val Avg Loss   34: 0.221192

Val Avg F1   34:  0.0

Optimal Val loss (Epoch 34): 0.2211919240653515

Epoch 35
--------------------------------------------------------------
Epoch:   35        1 Batch loss: 0.203800 Batch F1: 0.0
Epoch:   35        2 Batch loss: 0.239184 Batch F1: 0.0
Epoch:   35        3 Batch loss: 0.236539 Batch F1: 0.0
Epoch:   35        4 Batch loss: 0.231947 Batch F1: 0.0
Epoch:   35        5 Batch loss: 0.201447 Batch F1: 0.0
Epoch:   35        6 Batch loss: 0.222671 Batch F1: 0.0
Epoch:   35        7 Batch loss: 0.233171 Batch F1: 0.0
Epoch:   35        8 Batch loss: 0.266346 Batch F1: 0.0
Epoch:   35        9 Batch loss: 0.226161 Batch F1: 0.0
Epoch:   35       10 Batch loss: 0.261875 Batch F1: 0.0
Epoch:   35       11 Batch loss: 0.233948 Batch F1: 0.0
Epoch:   35       12 Batch loss: 0.221895 Batch F1: 0.0
Train Avg Loss   35: 0.231582

Train Avg F1   35: 0.0

Val Avg Loss   35: 0.225879

Val Avg F1   35:  0.0

Optimal Val loss (Epoch 34): 0.2211919240653515

Epoch 36
--------------------------------------------------------------
Epoch:   36        1 Batch loss: 0.246027 Batch F1: 0.0
Epoch:   36        2 Batch loss: 0.207588 Batch F1: 0.0
Epoch:   36        3 Batch loss: 0.229498 Batch F1: 0.0
Epoch:   36        4 Batch loss: 0.248652 Batch F1: 0.0
Epoch:   36        5 Batch loss: 0.193745 Batch F1: 0.0
Epoch:   36        6 Batch loss: 0.236789 Batch F1: 0.0
Epoch:   36        7 Batch loss: 0.250901 Batch F1: 0.0
Epoch:   36        8 Batch loss: 0.231499 Batch F1: 0.0
Epoch:   36        9 Batch loss: 0.210022 Batch F1: 0.0
Epoch:   36       10 Batch loss: 0.217258 Batch F1: 0.0
Epoch:   36       11 Batch loss: 0.292929 Batch F1: 0.0
Epoch:   36       12 Batch loss: 0.215994 Batch F1: 0.0
Train Avg Loss   36: 0.231742

Train Avg F1   36: 0.0

Val Avg Loss   36: 0.221808

Val Avg F1   36:  0.0

Optimal Val loss (Epoch 34): 0.2211919240653515

Epoch 37
--------------------------------------------------------------
Epoch:   37        1 Batch loss: 0.228815 Batch F1: 0.0
Epoch:   37        2 Batch loss: 0.223324 Batch F1: 0.0
Epoch:   37        3 Batch loss: 0.240967 Batch F1: 0.0
Epoch:   37        4 Batch loss: 0.230052 Batch F1: 0.0
Epoch:   37        5 Batch loss: 0.207210 Batch F1: 0.0
Epoch:   37        6 Batch loss: 0.248456 Batch F1: 0.0
Epoch:   37        7 Batch loss: 0.234175 Batch F1: 0.0
Epoch:   37        8 Batch loss: 0.245950 Batch F1: 0.0
Epoch:   37        9 Batch loss: 0.233493 Batch F1: 0.0
Epoch:   37       10 Batch loss: 0.218315 Batch F1: 0.0
Epoch:   37       11 Batch loss: 0.244870 Batch F1: 0.0
Epoch:   37       12 Batch loss: 0.209469 Batch F1: 0.0
Train Avg Loss   37: 0.230425

Train Avg F1   37: 0.0

Val Avg Loss   37: 0.221772

Val Avg F1   37:  0.0

Optimal Val loss (Epoch 34): 0.2211919240653515

Epoch 38
--------------------------------------------------------------
Epoch:   38        1 Batch loss: 0.231023 Batch F1: 0.0
Epoch:   38        2 Batch loss: 0.233370 Batch F1: 0.0
Epoch:   38        3 Batch loss: 0.205122 Batch F1: 0.0
Epoch:   38        4 Batch loss: 0.241496 Batch F1: 0.0
Epoch:   38        5 Batch loss: 0.218573 Batch F1: 0.0
Epoch:   38        6 Batch loss: 0.231327 Batch F1: 0.0
Epoch:   38        7 Batch loss: 0.250783 Batch F1: 0.0
Epoch:   38        8 Batch loss: 0.221523 Batch F1: 0.0
Epoch:   38        9 Batch loss: 0.215001 Batch F1: 0.0
Epoch:   38       10 Batch loss: 0.262820 Batch F1: 0.0
Epoch:   38       11 Batch loss: 0.208106 Batch F1: 0.0
Epoch:   38       12 Batch loss: 0.247134 Batch F1: 0.0
Train Avg Loss   38: 0.230523

Train Avg F1   38: 0.0

Val Avg Loss   38: 0.221381

Val Avg F1   38:  0.0

Optimal Val loss (Epoch 34): 0.2211919240653515

Epoch 39
--------------------------------------------------------------
Epoch:   39        1 Batch loss: 0.236960 Batch F1: 0.0
Epoch:   39        2 Batch loss: 0.207711 Batch F1: 0.0
Epoch:   39        3 Batch loss: 0.231786 Batch F1: 0.0
Epoch:   39        4 Batch loss: 0.237235 Batch F1: 0.0
Epoch:   39        5 Batch loss: 0.217691 Batch F1: 0.0
Epoch:   39        6 Batch loss: 0.228379 Batch F1: 0.0
Epoch:   39        7 Batch loss: 0.257634 Batch F1: 0.0
Epoch:   39        8 Batch loss: 0.219261 Batch F1: 0.0
Epoch:   39        9 Batch loss: 0.255221 Batch F1: 0.0
Epoch:   39       10 Batch loss: 0.235279 Batch F1: 0.0
Epoch:   39       11 Batch loss: 0.216872 Batch F1: 0.0
Epoch:   39       12 Batch loss: 0.227201 Batch F1: 0.0
Train Avg Loss   39: 0.230936

Train Avg F1   39: 0.0

Val Avg Loss   39: 0.221378

Val Avg F1   39:  0.0

Optimal Val loss (Epoch 34): 0.2211919240653515

Epoch 40
--------------------------------------------------------------
Epoch:   40        1 Batch loss: 0.239839 Batch F1: 0.0
Epoch:   40        2 Batch loss: 0.203964 Batch F1: 0.0
Epoch:   40        3 Batch loss: 0.222737 Batch F1: 0.0
Epoch:   40        4 Batch loss: 0.272034 Batch F1: 0.0
Epoch:   40        5 Batch loss: 0.224616 Batch F1: 0.0
Epoch:   40        6 Batch loss: 0.211280 Batch F1: 0.0
Epoch:   40        7 Batch loss: 0.211228 Batch F1: 0.0
Epoch:   40        8 Batch loss: 0.243111 Batch F1: 0.0
Epoch:   40        9 Batch loss: 0.205305 Batch F1: 0.0
Epoch:   40       10 Batch loss: 0.262428 Batch F1: 0.0
Epoch:   40       11 Batch loss: 0.255622 Batch F1: 0.0
Epoch:   40       12 Batch loss: 0.241387 Batch F1: 0.0
Train Avg Loss   40: 0.232796

Train Avg F1   40: 0.0

Val Avg Loss   40: 0.223797

Val Avg F1   40:  0.0

Optimal Val loss (Epoch 34): 0.2211919240653515

Epoch 41
--------------------------------------------------------------
Epoch:   41        1 Batch loss: 0.205742 Batch F1: 0.0
Epoch:   41        2 Batch loss: 0.263394 Batch F1: 0.0
Epoch:   41        3 Batch loss: 0.234171 Batch F1: 0.0
Epoch:   41        4 Batch loss: 0.231429 Batch F1: 0.0
Epoch:   41        5 Batch loss: 0.218265 Batch F1: 0.0
Epoch:   41        6 Batch loss: 0.243212 Batch F1: 0.0
Epoch:   41        7 Batch loss: 0.248953 Batch F1: 0.0
Epoch:   41        8 Batch loss: 0.214656 Batch F1: 0.0
Epoch:   41        9 Batch loss: 0.230226 Batch F1: 0.0
Epoch:   41       10 Batch loss: 0.214143 Batch F1: 0.0
Epoch:   41       11 Batch loss: 0.240177 Batch F1: 0.0
Epoch:   41       12 Batch loss: 0.242619 Batch F1: 0.0
Train Avg Loss   41: 0.232249

Train Avg F1   41: 0.0

Val Avg Loss   41: 0.221672

Val Avg F1   41:  0.0

Optimal Val loss (Epoch 34): 0.2211919240653515

Epoch 42
--------------------------------------------------------------
Epoch:   42        1 Batch loss: 0.221773 Batch F1: 0.0
Epoch:   42        2 Batch loss: 0.216858 Batch F1: 0.0
Epoch:   42        3 Batch loss: 0.225308 Batch F1: 0.0
Epoch:   42        4 Batch loss: 0.265850 Batch F1: 0.0
Epoch:   42        5 Batch loss: 0.275331 Batch F1: 0.0
Epoch:   42        6 Batch loss: 0.227432 Batch F1: 0.0
Epoch:   42        7 Batch loss: 0.236676 Batch F1: 0.0
Epoch:   42        8 Batch loss: 0.211138 Batch F1: 0.0
Epoch:   42        9 Batch loss: 0.238418 Batch F1: 0.0
Epoch:   42       10 Batch loss: 0.229739 Batch F1: 0.0
Epoch:   42       11 Batch loss: 0.231511 Batch F1: 0.0
Epoch:   42       12 Batch loss: 0.199488 Batch F1: 0.0
Train Avg Loss   42: 0.231627

Train Avg F1   42: 0.0

Val Avg Loss   42: 0.221862

Val Avg F1   42:  0.0

Optimal Val loss (Epoch 34): 0.2211919240653515

Epoch 43
--------------------------------------------------------------
Epoch:   43        1 Batch loss: 0.233333 Batch F1: 0.0
Epoch:   43        2 Batch loss: 0.250713 Batch F1: 0.0
Epoch:   43        3 Batch loss: 0.215103 Batch F1: 0.0
Epoch:   43        4 Batch loss: 0.229290 Batch F1: 0.0
Epoch:   43        5 Batch loss: 0.220383 Batch F1: 0.0
Epoch:   43        6 Batch loss: 0.230930 Batch F1: 0.0
Epoch:   43        7 Batch loss: 0.208441 Batch F1: 0.0
Epoch:   43        8 Batch loss: 0.215575 Batch F1: 0.0
Epoch:   43        9 Batch loss: 0.243974 Batch F1: 0.0
Epoch:   43       10 Batch loss: 0.248289 Batch F1: 0.0
Epoch:   43       11 Batch loss: 0.244612 Batch F1: 0.0
Epoch:   43       12 Batch loss: 0.225637 Batch F1: 0.0
Train Avg Loss   43: 0.230523

Train Avg F1   43: 0.0

Val Avg Loss   43: 0.226652

Val Avg F1   43:  0.0

Optimal Val loss (Epoch 34): 0.2211919240653515

Epoch 44
--------------------------------------------------------------
Epoch:   44        1 Batch loss: 0.235246 Batch F1: 0.0
Epoch:   44        2 Batch loss: 0.238808 Batch F1: 0.0
Epoch:   44        3 Batch loss: 0.229939 Batch F1: 0.0
Epoch:   44        4 Batch loss: 0.225255 Batch F1: 0.0
Epoch:   44        5 Batch loss: 0.212838 Batch F1: 0.0
Epoch:   44        6 Batch loss: 0.246285 Batch F1: 0.0
Epoch:   44        7 Batch loss: 0.198503 Batch F1: 0.0
Epoch:   44        8 Batch loss: 0.228936 Batch F1: 0.0
Epoch:   44        9 Batch loss: 0.251923 Batch F1: 0.0
Epoch:   44       10 Batch loss: 0.221550 Batch F1: 0.0
Epoch:   44       11 Batch loss: 0.216688 Batch F1: 0.0
Epoch:   44       12 Batch loss: 0.257361 Batch F1: 0.0
Train Avg Loss   44: 0.230278

Train Avg F1   44: 0.0

Val Avg Loss   44: 0.220018

Val Avg F1   44:  0.0

Optimal Val loss (Epoch 44): 0.22001799196004868

Epoch 45
--------------------------------------------------------------
Epoch:   45        1 Batch loss: 0.235773 Batch F1: 0.0
Epoch:   45        2 Batch loss: 0.232383 Batch F1: 0.0
Epoch:   45        3 Batch loss: 0.255380 Batch F1: 0.0
Epoch:   45        4 Batch loss: 0.231169 Batch F1: 0.25
Epoch:   45        5 Batch loss: 0.225528 Batch F1: 0.2
Epoch:   45        6 Batch loss: 0.228228 Batch F1: 0.0
Epoch:   45        7 Batch loss: 0.219103 Batch F1: 0.0
Epoch:   45        8 Batch loss: 0.241678 Batch F1: 0.0
Epoch:   45        9 Batch loss: 0.228409 Batch F1: 0.0
Epoch:   45       10 Batch loss: 0.240615 Batch F1: 0.0
Epoch:   45       11 Batch loss: 0.210932 Batch F1: 0.0
Epoch:   45       12 Batch loss: 0.201748 Batch F1: 0.0
Train Avg Loss   45: 0.229245

Train Avg F1   45: 0.0375

Val Avg Loss   45: 0.219769

Val Avg F1   45:  0.0

Optimal Val loss (Epoch 45): 0.21976915374398232

Epoch 46
--------------------------------------------------------------
Epoch:   46        1 Batch loss: 0.227853 Batch F1: 0.0
Epoch:   46        2 Batch loss: 0.239061 Batch F1: 0.0
Epoch:   46        3 Batch loss: 0.248114 Batch F1: 0.0
Epoch:   46        4 Batch loss: 0.233713 Batch F1: 0.0
Epoch:   46        5 Batch loss: 0.222549 Batch F1: 0.0
Epoch:   46        6 Batch loss: 0.198968 Batch F1: 0.0
Epoch:   46        7 Batch loss: 0.212498 Batch F1: 0.0
Epoch:   46        8 Batch loss: 0.245667 Batch F1: 0.0
Epoch:   46        9 Batch loss: 0.239234 Batch F1: 0.0
Epoch:   46       10 Batch loss: 0.241936 Batch F1: 0.0
Epoch:   46       11 Batch loss: 0.244104 Batch F1: 0.0
Epoch:   46       12 Batch loss: 0.206838 Batch F1: 0.0
Train Avg Loss   46: 0.230045

Train Avg F1   46: 0.0

Val Avg Loss   46: 0.219759

Val Avg F1   46:  0.0

Optimal Val loss (Epoch 46): 0.21975944563746452

Epoch 47
--------------------------------------------------------------
Epoch:   47        1 Batch loss: 0.239913 Batch F1: 0.0
Epoch:   47        2 Batch loss: 0.225201 Batch F1: 0.0
Epoch:   47        3 Batch loss: 0.236344 Batch F1: 0.0
Epoch:   47        4 Batch loss: 0.206145 Batch F1: 0.0
Epoch:   47        5 Batch loss: 0.208810 Batch F1: 0.0
Epoch:   47        6 Batch loss: 0.244009 Batch F1: 0.0
Epoch:   47        7 Batch loss: 0.217809 Batch F1: 0.0
Epoch:   47        8 Batch loss: 0.203812 Batch F1: 0.0
Epoch:   47        9 Batch loss: 0.215766 Batch F1: 0.0
Epoch:   47       10 Batch loss: 0.248208 Batch F1: 0.0
Epoch:   47       11 Batch loss: 0.245510 Batch F1: 0.0
Epoch:   47       12 Batch loss: 0.262675 Batch F1: 0.0
Train Avg Loss   47: 0.229517

Train Avg F1   47: 0.0

Val Avg Loss   47: 0.221156

Val Avg F1   47:  0.0

Optimal Val loss (Epoch 46): 0.21975944563746452

Epoch 48
--------------------------------------------------------------
Epoch:   48        1 Batch loss: 0.244920 Batch F1: 0.0
Epoch:   48        2 Batch loss: 0.236468 Batch F1: 0.1739130434782609
Epoch:   48        3 Batch loss: 0.232212 Batch F1: 0.29629629629629634
Epoch:   48        4 Batch loss: 0.251170 Batch F1: 0.14285714285714285
Epoch:   48        5 Batch loss: 0.242098 Batch F1: 0.2758620689655173
Epoch:   48        6 Batch loss: 0.207571 Batch F1: 0.3076923076923077
Epoch:   48        7 Batch loss: 0.230206 Batch F1: 0.0
Epoch:   48        8 Batch loss: 0.197550 Batch F1: 0.0
Epoch:   48        9 Batch loss: 0.241818 Batch F1: 0.0
Epoch:   48       10 Batch loss: 0.237571 Batch F1: 0.0
Epoch:   48       11 Batch loss: 0.233923 Batch F1: 0.0
Epoch:   48       12 Batch loss: 0.205327 Batch F1: 0.0
Train Avg Loss   48: 0.230070

Train Avg F1   48: 0.09971840494079376

Val Avg Loss   48: 0.219599

Val Avg F1   48:  0.0

Optimal Val loss (Epoch 48): 0.21959871426224709

Epoch 49
--------------------------------------------------------------
Epoch:   49        1 Batch loss: 0.221485 Batch F1: 0.0
Epoch:   49        2 Batch loss: 0.229820 Batch F1: 0.0
Epoch:   49        3 Batch loss: 0.231409 Batch F1: 0.0
Epoch:   49        4 Batch loss: 0.249356 Batch F1: 0.0
Epoch:   49        5 Batch loss: 0.175599 Batch F1: 0.0
Epoch:   49        6 Batch loss: 0.213147 Batch F1: 0.0
Epoch:   49        7 Batch loss: 0.228245 Batch F1: 0.0
Epoch:   49        8 Batch loss: 0.254369 Batch F1: 0.0
Epoch:   49        9 Batch loss: 0.217332 Batch F1: 0.0
Epoch:   49       10 Batch loss: 0.234917 Batch F1: 0.0
Epoch:   49       11 Batch loss: 0.275392 Batch F1: 0.0
Epoch:   49       12 Batch loss: 0.246315 Batch F1: 0.0
Train Avg Loss   49: 0.231449

Train Avg F1   49: 0.0

Val Avg Loss   49: 0.223610

Val Avg F1   49:  0.0

Optimal Val loss (Epoch 48): 0.21959871426224709

Epoch 50
--------------------------------------------------------------
Epoch:   50        1 Batch loss: 0.230203 Batch F1: 0.0
Epoch:   50        2 Batch loss: 0.234433 Batch F1: 0.0
Epoch:   50        3 Batch loss: 0.240753 Batch F1: 0.0909090909090909
Epoch:   50        4 Batch loss: 0.233773 Batch F1: 0.0
Epoch:   50        5 Batch loss: 0.232106 Batch F1: 0.0
Epoch:   50        6 Batch loss: 0.222024 Batch F1: 0.0
Epoch:   50        7 Batch loss: 0.234988 Batch F1: 0.0
Epoch:   50        8 Batch loss: 0.193479 Batch F1: 0.0
Epoch:   50        9 Batch loss: 0.264381 Batch F1: 0.0
Epoch:   50       10 Batch loss: 0.233197 Batch F1: 0.0
Epoch:   50       11 Batch loss: 0.206693 Batch F1: 0.0
Epoch:   50       12 Batch loss: 0.246060 Batch F1: 0.0
Train Avg Loss   50: 0.231007

Train Avg F1   50: 0.007575757575757575

Val Avg Loss   50: 0.221452

Val Avg F1   50:  0.0

Optimal Val loss (Epoch 48): 0.21959871426224709

Epoch 51
--------------------------------------------------------------
Epoch:   51        1 Batch loss: 0.236464 Batch F1: 0.0
Epoch:   51        2 Batch loss: 0.251400 Batch F1: 0.0
Epoch:   51        3 Batch loss: 0.217031 Batch F1: 0.0
Epoch:   51        4 Batch loss: 0.223200 Batch F1: 0.0
Epoch:   51        5 Batch loss: 0.250245 Batch F1: 0.0
Epoch:   51        6 Batch loss: 0.243580 Batch F1: 0.0
Epoch:   51        7 Batch loss: 0.231479 Batch F1: 0.0
Epoch:   51        8 Batch loss: 0.222586 Batch F1: 0.0
Epoch:   51        9 Batch loss: 0.219821 Batch F1: 0.0
Epoch:   51       10 Batch loss: 0.219500 Batch F1: 0.0
Epoch:   51       11 Batch loss: 0.200746 Batch F1: 0.0
Epoch:   51       12 Batch loss: 0.227646 Batch F1: 0.0
Train Avg Loss   51: 0.228642

Train Avg F1   51: 0.0

Val Avg Loss   51: 0.218719

Val Avg F1   51:  0.0

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 52
--------------------------------------------------------------
Epoch:   52        1 Batch loss: 0.194421 Batch F1: 0.0
Epoch:   52        2 Batch loss: 0.200460 Batch F1: 0.0
Epoch:   52        3 Batch loss: 0.263098 Batch F1: 0.0
Epoch:   52        4 Batch loss: 0.252343 Batch F1: 0.0
Epoch:   52        5 Batch loss: 0.228035 Batch F1: 0.0
Epoch:   52        6 Batch loss: 0.230746 Batch F1: 0.0
Epoch:   52        7 Batch loss: 0.210875 Batch F1: 0.0
Epoch:   52        8 Batch loss: 0.243351 Batch F1: 0.0
Epoch:   52        9 Batch loss: 0.255533 Batch F1: 0.0
Epoch:   52       10 Batch loss: 0.231550 Batch F1: 0.0
Epoch:   52       11 Batch loss: 0.222542 Batch F1: 0.0
Epoch:   52       12 Batch loss: 0.233947 Batch F1: 0.0
Train Avg Loss   52: 0.230575

Train Avg F1   52: 0.0

Val Avg Loss   52: 0.222835

Val Avg F1   52:  0.0

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 53
--------------------------------------------------------------
Epoch:   53        1 Batch loss: 0.228463 Batch F1: 0.0
Epoch:   53        2 Batch loss: 0.210588 Batch F1: 0.0
Epoch:   53        3 Batch loss: 0.259784 Batch F1: 0.0
Epoch:   53        4 Batch loss: 0.207909 Batch F1: 0.0
Epoch:   53        5 Batch loss: 0.203669 Batch F1: 0.0
Epoch:   53        6 Batch loss: 0.260691 Batch F1: 0.0
Epoch:   53        7 Batch loss: 0.246831 Batch F1: 0.0
Epoch:   53        8 Batch loss: 0.211171 Batch F1: 0.0
Epoch:   53        9 Batch loss: 0.230100 Batch F1: 0.0
Epoch:   53       10 Batch loss: 0.194347 Batch F1: 0.0
Epoch:   53       11 Batch loss: 0.259811 Batch F1: 0.0
Epoch:   53       12 Batch loss: 0.245012 Batch F1: 0.0
Train Avg Loss   53: 0.229865

Train Avg F1   53: 0.0

Val Avg Loss   53: 0.219736

Val Avg F1   53:  0.0

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 54
--------------------------------------------------------------
Epoch:   54        1 Batch loss: 0.216878 Batch F1: 0.0
Epoch:   54        2 Batch loss: 0.212340 Batch F1: 0.0
Epoch:   54        3 Batch loss: 0.254965 Batch F1: 0.0
Epoch:   54        4 Batch loss: 0.234652 Batch F1: 0.0
Epoch:   54        5 Batch loss: 0.228641 Batch F1: 0.0
Epoch:   54        6 Batch loss: 0.239991 Batch F1: 0.0
Epoch:   54        7 Batch loss: 0.200978 Batch F1: 0.0
Epoch:   54        8 Batch loss: 0.233300 Batch F1: 0.0
Epoch:   54        9 Batch loss: 0.221954 Batch F1: 0.0
Epoch:   54       10 Batch loss: 0.233217 Batch F1: 0.0
Epoch:   54       11 Batch loss: 0.225551 Batch F1: 0.0
Epoch:   54       12 Batch loss: 0.246548 Batch F1: 0.0
Train Avg Loss   54: 0.229085

Train Avg F1   54: 0.0

Val Avg Loss   54: 0.221782

Val Avg F1   54:  0.0

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 55
--------------------------------------------------------------
Epoch:   55        1 Batch loss: 0.230697 Batch F1: 0.0
Epoch:   55        2 Batch loss: 0.248969 Batch F1: 0.0
Epoch:   55        3 Batch loss: 0.225996 Batch F1: 0.32
Epoch:   55        4 Batch loss: 0.225949 Batch F1: 0.48275862068965514
Epoch:   55        5 Batch loss: 0.226089 Batch F1: 0.23999999999999996
Epoch:   55        6 Batch loss: 0.224697 Batch F1: 0.2105263157894737
Epoch:   55        7 Batch loss: 0.211853 Batch F1: 0.0
Epoch:   55        8 Batch loss: 0.225634 Batch F1: 0.0
Epoch:   55        9 Batch loss: 0.239853 Batch F1: 0.0
Epoch:   55       10 Batch loss: 0.237777 Batch F1: 0.0
Epoch:   55       11 Batch loss: 0.281097 Batch F1: 0.0
Epoch:   55       12 Batch loss: 0.200976 Batch F1: 0.0
Train Avg Loss   55: 0.231632

Train Avg F1   55: 0.10444041137326072

Val Avg Loss   55: 0.219952

Val Avg F1   55:  0.0

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 56
--------------------------------------------------------------
Epoch:   56        1 Batch loss: 0.213499 Batch F1: 0.0
Epoch:   56        2 Batch loss: 0.211246 Batch F1: 0.0
Epoch:   56        3 Batch loss: 0.256478 Batch F1: 0.0
Epoch:   56        4 Batch loss: 0.211315 Batch F1: 0.0
Epoch:   56        5 Batch loss: 0.258095 Batch F1: 0.0
Epoch:   56        6 Batch loss: 0.201526 Batch F1: 0.0
Epoch:   56        7 Batch loss: 0.244877 Batch F1: 0.0
Epoch:   56        8 Batch loss: 0.237550 Batch F1: 0.0
Epoch:   56        9 Batch loss: 0.228353 Batch F1: 0.0
Epoch:   56       10 Batch loss: 0.211897 Batch F1: 0.0
Epoch:   56       11 Batch loss: 0.225398 Batch F1: 0.0
Epoch:   56       12 Batch loss: 0.254466 Batch F1: 0.0
Train Avg Loss   56: 0.229558

Train Avg F1   56: 0.0

Val Avg Loss   56: 0.221359

Val Avg F1   56:  0.0

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 57
--------------------------------------------------------------
Epoch:   57        1 Batch loss: 0.231348 Batch F1: 0.0
Epoch:   57        2 Batch loss: 0.219476 Batch F1: 0.0
Epoch:   57        3 Batch loss: 0.262532 Batch F1: 0.0
Epoch:   57        4 Batch loss: 0.216129 Batch F1: 0.0
Epoch:   57        5 Batch loss: 0.221173 Batch F1: 0.0
Epoch:   57        6 Batch loss: 0.270284 Batch F1: 0.0
Epoch:   57        7 Batch loss: 0.228524 Batch F1: 0.0
Epoch:   57        8 Batch loss: 0.212570 Batch F1: 0.0
Epoch:   57        9 Batch loss: 0.228361 Batch F1: 0.0
Epoch:   57       10 Batch loss: 0.192432 Batch F1: 0.0
Epoch:   57       11 Batch loss: 0.232744 Batch F1: 0.0
Epoch:   57       12 Batch loss: 0.230456 Batch F1: 0.0
Train Avg Loss   57: 0.228836

Train Avg F1   57: 0.0

Val Avg Loss   57: 0.218846

Val Avg F1   57:  0.0

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 58
--------------------------------------------------------------
Epoch:   58        1 Batch loss: 0.249732 Batch F1: 0.0
Epoch:   58        2 Batch loss: 0.239725 Batch F1: 0.0
Epoch:   58        3 Batch loss: 0.215410 Batch F1: 0.0
Epoch:   58        4 Batch loss: 0.244069 Batch F1: 0.0
Epoch:   58        5 Batch loss: 0.182077 Batch F1: 0.0
Epoch:   58        6 Batch loss: 0.204091 Batch F1: 0.0
Epoch:   58        7 Batch loss: 0.261783 Batch F1: 0.0
Epoch:   58        8 Batch loss: 0.221508 Batch F1: 0.0
Epoch:   58        9 Batch loss: 0.270627 Batch F1: 0.0
Epoch:   58       10 Batch loss: 0.223053 Batch F1: 0.0
Epoch:   58       11 Batch loss: 0.210468 Batch F1: 0.2222222222222222
Epoch:   58       12 Batch loss: 0.222515 Batch F1: 0.23529411764705882
Train Avg Loss   58: 0.228755

Train Avg F1   58: 0.03812636165577342

Val Avg Loss   58: 0.220506

Val Avg F1   58:  0.0

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 59
--------------------------------------------------------------
Epoch:   59        1 Batch loss: 0.214028 Batch F1: 0.0
Epoch:   59        2 Batch loss: 0.230251 Batch F1: 0.0
Epoch:   59        3 Batch loss: 0.199852 Batch F1: 0.0
Epoch:   59        4 Batch loss: 0.225907 Batch F1: 0.0
Epoch:   59        5 Batch loss: 0.247452 Batch F1: 0.0
Epoch:   59        6 Batch loss: 0.211769 Batch F1: 0.0
Epoch:   59        7 Batch loss: 0.212339 Batch F1: 0.0
Epoch:   59        8 Batch loss: 0.234254 Batch F1: 0.0
Epoch:   59        9 Batch loss: 0.247835 Batch F1: 0.0
Epoch:   59       10 Batch loss: 0.227580 Batch F1: 0.0
Epoch:   59       11 Batch loss: 0.255105 Batch F1: 0.08
Epoch:   59       12 Batch loss: 0.225880 Batch F1: 0.23529411764705882
Train Avg Loss   59: 0.227688

Train Avg F1   59: 0.02627450980392157

Val Avg Loss   59: 0.222881

Val Avg F1   59:  0.25903381642512074

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 60
--------------------------------------------------------------
Epoch:   60        1 Batch loss: 0.229791 Batch F1: 0.4444444444444444
Epoch:   60        2 Batch loss: 0.235292 Batch F1: 0.0
Epoch:   60        3 Batch loss: 0.230413 Batch F1: 0.0
Epoch:   60        4 Batch loss: 0.211371 Batch F1: 0.0
Epoch:   60        5 Batch loss: 0.181654 Batch F1: 0.0
Epoch:   60        6 Batch loss: 0.210627 Batch F1: 0.0
Epoch:   60        7 Batch loss: 0.208517 Batch F1: 0.0
Epoch:   60        8 Batch loss: 0.301476 Batch F1: 0.0
Epoch:   60        9 Batch loss: 0.250198 Batch F1: 0.0
Epoch:   60       10 Batch loss: 0.240322 Batch F1: 0.0
Epoch:   60       11 Batch loss: 0.217364 Batch F1: 0.0
Epoch:   60       12 Batch loss: 0.263175 Batch F1: 0.0
Train Avg Loss   60: 0.231683

Train Avg F1   60: 0.037037037037037035

Val Avg Loss   60: 0.221485

Val Avg F1   60:  0.0

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 61
--------------------------------------------------------------
Epoch:   61        1 Batch loss: 0.228633 Batch F1: 0.0
Epoch:   61        2 Batch loss: 0.226318 Batch F1: 0.0
Epoch:   61        3 Batch loss: 0.237214 Batch F1: 0.0
Epoch:   61        4 Batch loss: 0.259036 Batch F1: 0.0
Epoch:   61        5 Batch loss: 0.222106 Batch F1: 0.0
Epoch:   61        6 Batch loss: 0.205273 Batch F1: 0.0
Epoch:   61        7 Batch loss: 0.217755 Batch F1: 0.0
Epoch:   61        8 Batch loss: 0.224042 Batch F1: 0.0
Epoch:   61        9 Batch loss: 0.229971 Batch F1: 0.0
Epoch:   61       10 Batch loss: 0.232148 Batch F1: 0.0
Epoch:   61       11 Batch loss: 0.216445 Batch F1: 0.0
Epoch:   61       12 Batch loss: 0.253944 Batch F1: 0.0
Train Avg Loss   61: 0.229407

Train Avg F1   61: 0.0

Val Avg Loss   61: 0.220567

Val Avg F1   61:  0.0

Optimal Val loss (Epoch 51): 0.21871937066316605

Epoch 62
--------------------------------------------------------------
Epoch:   62        1 Batch loss: 0.236340 Batch F1: 0.0
Epoch:   62        2 Batch loss: 0.234354 Batch F1: 0.0
Epoch:   62        3 Batch loss: 0.223695 Batch F1: 0.0
Epoch:   62        4 Batch loss: 0.233420 Batch F1: 0.4137931034482759
Epoch:   62        5 Batch loss: 0.233554 Batch F1: 0.08695652173913043
Epoch:   62        6 Batch loss: 0.215277 Batch F1: 0.3636363636363636
Epoch:   62        7 Batch loss: 0.252227 Batch F1: 0.24999999999999997
Epoch:   62        8 Batch loss: 0.234456 Batch F1: 0.0
Epoch:   62        9 Batch loss: 0.205305 Batch F1: 0.0
Epoch:   62       10 Batch loss: 0.237641 Batch F1: 0.0
Epoch:   62       11 Batch loss: 0.207105 Batch F1: 0.0
Epoch:   62       12 Batch loss: 0.206961 Batch F1: 0.0
Train Avg Loss   62: 0.226695

Train Avg F1   62: 0.0928654990686475

Val Avg Loss   62: 0.218025

Val Avg F1   62:  0.0

Optimal Val loss (Epoch 62): 0.21802495792508125

Epoch 63
--------------------------------------------------------------
Epoch:   63        1 Batch loss: 0.265244 Batch F1: 0.0
Epoch:   63        2 Batch loss: 0.193101 Batch F1: 0.0
Epoch:   63        3 Batch loss: 0.220450 Batch F1: 0.0
Epoch:   63        4 Batch loss: 0.208487 Batch F1: 0.0
Epoch:   63        5 Batch loss: 0.216475 Batch F1: 0.0
Epoch:   63        6 Batch loss: 0.199873 Batch F1: 0.0
Epoch:   63        7 Batch loss: 0.208419 Batch F1: 0.0
Epoch:   63        8 Batch loss: 0.225104 Batch F1: 0.0
Epoch:   63        9 Batch loss: 0.251729 Batch F1: 0.0
Epoch:   63       10 Batch loss: 0.271430 Batch F1: 0.0
Epoch:   63       11 Batch loss: 0.257745 Batch F1: 0.0
Epoch:   63       12 Batch loss: 0.230233 Batch F1: 0.0
Train Avg Loss   63: 0.229024

Train Avg F1   63: 0.0

Val Avg Loss   63: 0.221588

Val Avg F1   63:  0.0

Optimal Val loss (Epoch 62): 0.21802495792508125

Epoch 64
--------------------------------------------------------------
Epoch:   64        1 Batch loss: 0.240034 Batch F1: 0.0
Epoch:   64        2 Batch loss: 0.215911 Batch F1: 0.23529411764705882
Epoch:   64        3 Batch loss: 0.229845 Batch F1: 0.37037037037037035
Epoch:   64        4 Batch loss: 0.230081 Batch F1: 0.2857142857142857
Epoch:   64        5 Batch loss: 0.222327 Batch F1: 0.11111111111111112
Epoch:   64        6 Batch loss: 0.229180 Batch F1: 0.0
Epoch:   64        7 Batch loss: 0.240026 Batch F1: 0.0
Epoch:   64        8 Batch loss: 0.222828 Batch F1: 0.0
Epoch:   64        9 Batch loss: 0.210431 Batch F1: 0.0
Epoch:   64       10 Batch loss: 0.223839 Batch F1: 0.0
Epoch:   64       11 Batch loss: 0.224595 Batch F1: 0.0
Epoch:   64       12 Batch loss: 0.259466 Batch F1: 0.0
Train Avg Loss   64: 0.229047

Train Avg F1   64: 0.08354082373690215

Val Avg Loss   64: 0.218226

Val Avg F1   64:  0.0

Optimal Val loss (Epoch 62): 0.21802495792508125

Epoch 65
--------------------------------------------------------------
Epoch:   65        1 Batch loss: 0.210914 Batch F1: 0.0
Epoch:   65        2 Batch loss: 0.232856 Batch F1: 0.0
Epoch:   65        3 Batch loss: 0.235169 Batch F1: 0.0
Epoch:   65        4 Batch loss: 0.220190 Batch F1: 0.0
Epoch:   65        5 Batch loss: 0.267486 Batch F1: 0.0
Epoch:   65        6 Batch loss: 0.202835 Batch F1: 0.0
Epoch:   65        7 Batch loss: 0.213578 Batch F1: 0.0
Epoch:   65        8 Batch loss: 0.244079 Batch F1: 0.0
Epoch:   65        9 Batch loss: 0.222103 Batch F1: 0.0
Epoch:   65       10 Batch loss: 0.230731 Batch F1: 0.0
Epoch:   65       11 Batch loss: 0.215847 Batch F1: 0.0
Epoch:   65       12 Batch loss: 0.230422 Batch F1: 0.0
Train Avg Loss   65: 0.227184

Train Avg F1   65: 0.0

Val Avg Loss   65: 0.220233

Val Avg F1   65:  0.0

Optimal Val loss (Epoch 62): 0.21802495792508125

Epoch 66
--------------------------------------------------------------
Epoch:   66        1 Batch loss: 0.261757 Batch F1: 0.0
Epoch:   66        2 Batch loss: 0.214961 Batch F1: 0.0
Epoch:   66        3 Batch loss: 0.201439 Batch F1: 0.0
Epoch:   66        4 Batch loss: 0.211487 Batch F1: 0.0
Epoch:   66        5 Batch loss: 0.240076 Batch F1: 0.0
Epoch:   66        6 Batch loss: 0.231124 Batch F1: 0.0
Epoch:   66        7 Batch loss: 0.211272 Batch F1: 0.0
Epoch:   66        8 Batch loss: 0.235976 Batch F1: 0.0
Epoch:   66        9 Batch loss: 0.227450 Batch F1: 0.0
Epoch:   66       10 Batch loss: 0.236200 Batch F1: 0.0
Epoch:   66       11 Batch loss: 0.221565 Batch F1: 0.0
Epoch:   66       12 Batch loss: 0.221674 Batch F1: 0.0
Train Avg Loss   66: 0.226248

Train Avg F1   66: 0.0

Val Avg Loss   66: 0.218850

Val Avg F1   66:  0.0

Optimal Val loss (Epoch 62): 0.21802495792508125

Epoch 67
--------------------------------------------------------------
Epoch:   67        1 Batch loss: 0.205670 Batch F1: 0.0
Epoch:   67        2 Batch loss: 0.220074 Batch F1: 0.0
Epoch:   67        3 Batch loss: 0.224557 Batch F1: 0.0
Epoch:   67        4 Batch loss: 0.230758 Batch F1: 0.0
Epoch:   67        5 Batch loss: 0.213791 Batch F1: 0.0
Epoch:   67        6 Batch loss: 0.243957 Batch F1: 0.0
Epoch:   67        7 Batch loss: 0.237445 Batch F1: 0.0
Epoch:   67        8 Batch loss: 0.196256 Batch F1: 0.0
Epoch:   67        9 Batch loss: 0.239557 Batch F1: 0.3333333333333333
Epoch:   67       10 Batch loss: 0.230616 Batch F1: 0.30769230769230765
Epoch:   67       11 Batch loss: 0.229774 Batch F1: 0.0
Epoch:   67       12 Batch loss: 0.257588 Batch F1: 0.0
Train Avg Loss   67: 0.227504

Train Avg F1   67: 0.053418803418803416

Val Avg Loss   67: 0.219614

Val Avg F1   67:  0.0

Optimal Val loss (Epoch 62): 0.21802495792508125

Epoch 68
--------------------------------------------------------------
Epoch:   68        1 Batch loss: 0.228765 Batch F1: 0.0
Epoch:   68        2 Batch loss: 0.228823 Batch F1: 0.0
Epoch:   68        3 Batch loss: 0.231036 Batch F1: 0.0
Epoch:   68        4 Batch loss: 0.219857 Batch F1: 0.0
Epoch:   68        5 Batch loss: 0.220711 Batch F1: 0.0
Epoch:   68        6 Batch loss: 0.248177 Batch F1: 0.0
Epoch:   68        7 Batch loss: 0.229479 Batch F1: 0.0
Epoch:   68        8 Batch loss: 0.230781 Batch F1: 0.18181818181818182
Epoch:   68        9 Batch loss: 0.214821 Batch F1: 0.0
Epoch:   68       10 Batch loss: 0.211725 Batch F1: 0.0
Epoch:   68       11 Batch loss: 0.246565 Batch F1: 0.0
Epoch:   68       12 Batch loss: 0.206227 Batch F1: 0.0
Train Avg Loss   68: 0.226414

Train Avg F1   68: 0.015151515151515152

Val Avg Loss   68: 0.217658

Val Avg F1   68:  0.0

Optimal Val loss (Epoch 68): 0.21765847876667976

Epoch 69
--------------------------------------------------------------
Epoch:   69        1 Batch loss: 0.245067 Batch F1: 0.0
Epoch:   69        2 Batch loss: 0.216945 Batch F1: 0.0
Epoch:   69        3 Batch loss: 0.204037 Batch F1: 0.0
Epoch:   69        4 Batch loss: 0.266343 Batch F1: 0.0
Epoch:   69        5 Batch loss: 0.229284 Batch F1: 0.0
Epoch:   69        6 Batch loss: 0.224060 Batch F1: 0.0
Epoch:   69        7 Batch loss: 0.232024 Batch F1: 0.0
Epoch:   69        8 Batch loss: 0.219028 Batch F1: 0.0
Epoch:   69        9 Batch loss: 0.193283 Batch F1: 0.0
Epoch:   69       10 Batch loss: 0.205693 Batch F1: 0.0
Epoch:   69       11 Batch loss: 0.266847 Batch F1: 0.0
Epoch:   69       12 Batch loss: 0.216244 Batch F1: 0.0
Train Avg Loss   69: 0.226571

Train Avg F1   69: 0.0

Val Avg Loss   69: 0.217470

Val Avg F1   69:  0.0

Optimal Val loss (Epoch 69): 0.2174699828028679

Epoch 70
--------------------------------------------------------------
Epoch:   70        1 Batch loss: 0.217600 Batch F1: 0.0
Epoch:   70        2 Batch loss: 0.206361 Batch F1: 0.0
Epoch:   70        3 Batch loss: 0.216077 Batch F1: 0.0
Epoch:   70        4 Batch loss: 0.205065 Batch F1: 0.2222222222222222
Epoch:   70        5 Batch loss: 0.245693 Batch F1: 0.0
Epoch:   70        6 Batch loss: 0.215232 Batch F1: 0.42105263157894735
Epoch:   70        7 Batch loss: 0.228362 Batch F1: 0.35714285714285715
Epoch:   70        8 Batch loss: 0.242353 Batch F1: 0.0
Epoch:   70        9 Batch loss: 0.265294 Batch F1: 0.0
Epoch:   70       10 Batch loss: 0.236919 Batch F1: 0.16666666666666666
Epoch:   70       11 Batch loss: 0.220008 Batch F1: 0.3636363636363636
Epoch:   70       12 Batch loss: 0.217030 Batch F1: 0.25
Train Avg Loss   70: 0.226333

Train Avg F1   70: 0.1483933951039214

Val Avg Loss   70: 0.219296

Val Avg F1   70:  0.0

Optimal Val loss (Epoch 69): 0.2174699828028679

Epoch 71
--------------------------------------------------------------
Epoch:   71        1 Batch loss: 0.224434 Batch F1: 0.0
Epoch:   71        2 Batch loss: 0.212318 Batch F1: 0.0
Epoch:   71        3 Batch loss: 0.238290 Batch F1: 0.0
Epoch:   71        4 Batch loss: 0.189282 Batch F1: 0.0
Epoch:   71        5 Batch loss: 0.217351 Batch F1: 0.0
Epoch:   71        6 Batch loss: 0.213813 Batch F1: 0.0
Epoch:   71        7 Batch loss: 0.305643 Batch F1: 0.0
Epoch:   71        8 Batch loss: 0.246260 Batch F1: 0.0
Epoch:   71        9 Batch loss: 0.228069 Batch F1: 0.0
Epoch:   71       10 Batch loss: 0.238984 Batch F1: 0.0
Epoch:   71       11 Batch loss: 0.212784 Batch F1: 0.0
Epoch:   71       12 Batch loss: 0.225291 Batch F1: 0.0
Train Avg Loss   71: 0.229377

Train Avg F1   71: 0.0

Val Avg Loss   71: 0.223875

Val Avg F1   71:  0.26619433198380565

Optimal Val loss (Epoch 69): 0.2174699828028679

Epoch 72
--------------------------------------------------------------
Epoch:   72        1 Batch loss: 0.256923 Batch F1: 0.1935483870967742
Epoch:   72        2 Batch loss: 0.214733 Batch F1: 0.5384615384615384
Epoch:   72        3 Batch loss: 0.227390 Batch F1: 0.3076923076923077
Epoch:   72        4 Batch loss: 0.208950 Batch F1: 0.19999999999999998
Epoch:   72        5 Batch loss: 0.244373 Batch F1: 0.2962962962962963
Epoch:   72        6 Batch loss: 0.262080 Batch F1: 0.16666666666666666
Epoch:   72        7 Batch loss: 0.210924 Batch F1: 0.0
Epoch:   72        8 Batch loss: 0.216625 Batch F1: 0.0
Epoch:   72        9 Batch loss: 0.197262 Batch F1: 0.0
Epoch:   72       10 Batch loss: 0.219219 Batch F1: 0.0
Epoch:   72       11 Batch loss: 0.239286 Batch F1: 0.0
Epoch:   72       12 Batch loss: 0.233411 Batch F1: 0.0
Train Avg Loss   72: 0.227598

Train Avg F1   72: 0.14188876635113193

Val Avg Loss   72: 0.218546

Val Avg F1   72:  0.0

Optimal Val loss (Epoch 69): 0.2174699828028679

Epoch 73
--------------------------------------------------------------
Epoch:   73        1 Batch loss: 0.262483 Batch F1: 0.0
Epoch:   73        2 Batch loss: 0.219164 Batch F1: 0.0
Epoch:   73        3 Batch loss: 0.214832 Batch F1: 0.0
Epoch:   73        4 Batch loss: 0.220252 Batch F1: 0.0
Epoch:   73        5 Batch loss: 0.206244 Batch F1: 0.0
Epoch:   73        6 Batch loss: 0.229840 Batch F1: 0.0
Epoch:   73        7 Batch loss: 0.221434 Batch F1: 0.0
Epoch:   73        8 Batch loss: 0.198497 Batch F1: 0.0
Epoch:   73        9 Batch loss: 0.302266 Batch F1: 0.0
Epoch:   73       10 Batch loss: 0.240918 Batch F1: 0.0
Epoch:   73       11 Batch loss: 0.232770 Batch F1: 0.0
Epoch:   73       12 Batch loss: 0.204270 Batch F1: 0.0
Train Avg Loss   73: 0.229414

Train Avg F1   73: 0.0

Val Avg Loss   73: 0.219910

Val Avg F1   73:  0.0

Optimal Val loss (Epoch 69): 0.2174699828028679

Epoch 74
--------------------------------------------------------------
Epoch:   74        1 Batch loss: 0.236249 Batch F1: 0.0
Epoch:   74        2 Batch loss: 0.230701 Batch F1: 0.0
Epoch:   74        3 Batch loss: 0.244785 Batch F1: 0.0
Epoch:   74        4 Batch loss: 0.225737 Batch F1: 0.0
Epoch:   74        5 Batch loss: 0.218623 Batch F1: 0.0
Epoch:   74        6 Batch loss: 0.245558 Batch F1: 0.3448275862068965
Epoch:   74        7 Batch loss: 0.221720 Batch F1: 0.2608695652173913
Epoch:   74        8 Batch loss: 0.236752 Batch F1: 0.1111111111111111
Epoch:   74        9 Batch loss: 0.210985 Batch F1: 0.0
Epoch:   74       10 Batch loss: 0.203576 Batch F1: 0.0
Epoch:   74       11 Batch loss: 0.216407 Batch F1: 0.0
Epoch:   74       12 Batch loss: 0.240749 Batch F1: 0.0
Train Avg Loss   74: 0.227653

Train Avg F1   74: 0.059734021877949905

Val Avg Loss   74: 0.218005

Val Avg F1   74:  0.0

Optimal Val loss (Epoch 69): 0.2174699828028679

Epoch 75
--------------------------------------------------------------
Epoch:   75        1 Batch loss: 0.230553 Batch F1: 0.0
Epoch:   75        2 Batch loss: 0.227553 Batch F1: 0.0
Epoch:   75        3 Batch loss: 0.240526 Batch F1: 0.0
Epoch:   75        4 Batch loss: 0.232638 Batch F1: 0.0
Epoch:   75        5 Batch loss: 0.242363 Batch F1: 0.0
Epoch:   75        6 Batch loss: 0.190484 Batch F1: 0.0
Epoch:   75        7 Batch loss: 0.208973 Batch F1: 0.0
Epoch:   75        8 Batch loss: 0.240863 Batch F1: 0.0
Epoch:   75        9 Batch loss: 0.244697 Batch F1: 0.0
Epoch:   75       10 Batch loss: 0.200204 Batch F1: 0.0
Epoch:   75       11 Batch loss: 0.229015 Batch F1: 0.0
Epoch:   75       12 Batch loss: 0.230950 Batch F1: 0.0
Train Avg Loss   75: 0.226568

Train Avg F1   75: 0.0

Val Avg Loss   75: 0.218452

Val Avg F1   75:  0.0

Optimal Val loss (Epoch 69): 0.2174699828028679

Epoch 76
--------------------------------------------------------------
Epoch:   76        1 Batch loss: 0.255116 Batch F1: 0.0
Epoch:   76        2 Batch loss: 0.245979 Batch F1: 0.0
Epoch:   76        3 Batch loss: 0.211267 Batch F1: 0.47619047619047616
Epoch:   76        4 Batch loss: 0.225207 Batch F1: 0.1818181818181818
Epoch:   76        5 Batch loss: 0.224309 Batch F1: 0.1
Epoch:   76        6 Batch loss: 0.194522 Batch F1: 0.3333333333333333
Epoch:   76        7 Batch loss: 0.227662 Batch F1: 0.0
Epoch:   76        8 Batch loss: 0.226250 Batch F1: 0.0
Epoch:   76        9 Batch loss: 0.224501 Batch F1: 0.0
Epoch:   76       10 Batch loss: 0.208210 Batch F1: 0.0
Epoch:   76       11 Batch loss: 0.234689 Batch F1: 0.0
Epoch:   76       12 Batch loss: 0.235002 Batch F1: 0.0
Train Avg Loss   76: 0.226059

Train Avg F1   76: 0.09094516594516594

Val Avg Loss   76: 0.217798

Val Avg F1   76:  0.0

Optimal Val loss (Epoch 69): 0.2174699828028679

Epoch 77
--------------------------------------------------------------
Epoch:   77        1 Batch loss: 0.216362 Batch F1: 0.0
Epoch:   77        2 Batch loss: 0.243797 Batch F1: 0.0
Epoch:   77        3 Batch loss: 0.221097 Batch F1: 0.0
Epoch:   77        4 Batch loss: 0.243942 Batch F1: 0.0
Epoch:   77        5 Batch loss: 0.254896 Batch F1: 0.0
Epoch:   77        6 Batch loss: 0.256320 Batch F1: 0.0
Epoch:   77        7 Batch loss: 0.199544 Batch F1: 0.0
Epoch:   77        8 Batch loss: 0.205129 Batch F1: 0.3333333333333333
Epoch:   77        9 Batch loss: 0.211962 Batch F1: 0.5454545454545454
Epoch:   77       10 Batch loss: 0.239344 Batch F1: 0.28571428571428575
Epoch:   77       11 Batch loss: 0.187739 Batch F1: 0.0
Epoch:   77       12 Batch loss: 0.249234 Batch F1: 0.0
Train Avg Loss   77: 0.227447

Train Avg F1   77: 0.09704184704184704

Val Avg Loss   77: 0.218172

Val Avg F1   77:  0.0

Optimal Val loss (Epoch 69): 0.2174699828028679

Epoch 78
--------------------------------------------------------------
Epoch:   78        1 Batch loss: 0.230882 Batch F1: 0.0
Epoch:   78        2 Batch loss: 0.210960 Batch F1: 0.0
Epoch:   78        3 Batch loss: 0.229951 Batch F1: 0.0
Epoch:   78        4 Batch loss: 0.226079 Batch F1: 0.0
Epoch:   78        5 Batch loss: 0.230255 Batch F1: 0.0
Epoch:   78        6 Batch loss: 0.241141 Batch F1: 0.0
Epoch:   78        7 Batch loss: 0.219458 Batch F1: 0.0
Epoch:   78        8 Batch loss: 0.237341 Batch F1: 0.0
Epoch:   78        9 Batch loss: 0.198952 Batch F1: 0.0
Epoch:   78       10 Batch loss: 0.228999 Batch F1: 0.0
Epoch:   78       11 Batch loss: 0.210117 Batch F1: 0.0
Epoch:   78       12 Batch loss: 0.249714 Batch F1: 0.0
Train Avg Loss   78: 0.226154

Train Avg F1   78: 0.0

Val Avg Loss   78: 0.217809

Val Avg F1   78:  0.0

Optimal Val loss (Epoch 69): 0.2174699828028679

Epoch 79
--------------------------------------------------------------
Epoch:   79        1 Batch loss: 0.244425 Batch F1: 0.0
Epoch:   79        2 Batch loss: 0.246854 Batch F1: 0.0
Epoch:   79        3 Batch loss: 0.221830 Batch F1: 0.4444444444444444
Epoch:   79        4 Batch loss: 0.238096 Batch F1: 0.2962962962962963
Epoch:   79        5 Batch loss: 0.192686 Batch F1: 0.5
Epoch:   79        6 Batch loss: 0.255579 Batch F1: 0.42424242424242425
Epoch:   79        7 Batch loss: 0.213948 Batch F1: 0.0
Epoch:   79        8 Batch loss: 0.231153 Batch F1: 0.0
Epoch:   79        9 Batch loss: 0.243592 Batch F1: 0.0
Epoch:   79       10 Batch loss: 0.213578 Batch F1: 0.0
Epoch:   79       11 Batch loss: 0.208168 Batch F1: 0.0
Epoch:   79       12 Batch loss: 0.202818 Batch F1: 0.0
Train Avg Loss   79: 0.226060

Train Avg F1   79: 0.1387485970819304

Val Avg Loss   79: 0.217063

Val Avg F1   79:  0.0

Optimal Val loss (Epoch 79): 0.21706270053982735

Epoch 80
--------------------------------------------------------------
Epoch:   80        1 Batch loss: 0.231709 Batch F1: 0.0
Epoch:   80        2 Batch loss: 0.217956 Batch F1: 0.0
Epoch:   80        3 Batch loss: 0.192808 Batch F1: 0.0
Epoch:   80        4 Batch loss: 0.239671 Batch F1: 0.0
Epoch:   80        5 Batch loss: 0.279578 Batch F1: 0.0
Epoch:   80        6 Batch loss: 0.224817 Batch F1: 0.0
Epoch:   80        7 Batch loss: 0.221257 Batch F1: 0.0
Epoch:   80        8 Batch loss: 0.190108 Batch F1: 0.0
Epoch:   80        9 Batch loss: 0.222978 Batch F1: 0.0
Epoch:   80       10 Batch loss: 0.238352 Batch F1: 0.0
Epoch:   80       11 Batch loss: 0.231358 Batch F1: 0.25
Epoch:   80       12 Batch loss: 0.217263 Batch F1: 0.36363636363636365
Train Avg Loss   80: 0.225654

Train Avg F1   80: 0.05113636363636364

Val Avg Loss   80: 0.220510

Val Avg F1   80:  0.27937710437710433

Optimal Val loss (Epoch 79): 0.21706270053982735

Epoch 81
--------------------------------------------------------------
Epoch:   81        1 Batch loss: 0.197142 Batch F1: 0.14285714285714288
Epoch:   81        2 Batch loss: 0.248333 Batch F1: 0.41379310344827586
Epoch:   81        3 Batch loss: 0.195369 Batch F1: 0.23529411764705882
Epoch:   81        4 Batch loss: 0.241190 Batch F1: 0.2580645161290322
Epoch:   81        5 Batch loss: 0.238248 Batch F1: 0.24000000000000002
Epoch:   81        6 Batch loss: 0.237868 Batch F1: 0.23999999999999996
Epoch:   81        7 Batch loss: 0.220651 Batch F1: 0.32
Epoch:   81        8 Batch loss: 0.221129 Batch F1: 0.3478260869565218
Epoch:   81        9 Batch loss: 0.202490 Batch F1: 0.0
Epoch:   81       10 Batch loss: 0.216619 Batch F1: 0.0
Epoch:   81       11 Batch loss: 0.233406 Batch F1: 0.0
Epoch:   81       12 Batch loss: 0.249913 Batch F1: 0.0
Train Avg Loss   81: 0.225196

Train Avg F1   81: 0.18315291391983599

Val Avg Loss   81: 0.217017

Val Avg F1   81:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 82
--------------------------------------------------------------
Epoch:   82        1 Batch loss: 0.234549 Batch F1: 0.0
Epoch:   82        2 Batch loss: 0.240080 Batch F1: 0.0
Epoch:   82        3 Batch loss: 0.205769 Batch F1: 0.3157894736842105
Epoch:   82        4 Batch loss: 0.204172 Batch F1: 0.6206896551724138
Epoch:   82        5 Batch loss: 0.223225 Batch F1: 0.16
Epoch:   82        6 Batch loss: 0.243965 Batch F1: 0.21428571428571427
Epoch:   82        7 Batch loss: 0.223221 Batch F1: 0.18181818181818182
Epoch:   82        8 Batch loss: 0.208632 Batch F1: 0.11764705882352941
Epoch:   82        9 Batch loss: 0.221828 Batch F1: 0.0
Epoch:   82       10 Batch loss: 0.227936 Batch F1: 0.0
Epoch:   82       11 Batch loss: 0.258243 Batch F1: 0.0
Epoch:   82       12 Batch loss: 0.227400 Batch F1: 0.0
Train Avg Loss   82: 0.226585

Train Avg F1   82: 0.13418584031533748

Val Avg Loss   82: 0.218394

Val Avg F1   82:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 83
--------------------------------------------------------------
Epoch:   83        1 Batch loss: 0.238245 Batch F1: 0.0
Epoch:   83        2 Batch loss: 0.232263 Batch F1: 0.0
Epoch:   83        3 Batch loss: 0.238805 Batch F1: 0.0
Epoch:   83        4 Batch loss: 0.228810 Batch F1: 0.0
Epoch:   83        5 Batch loss: 0.240999 Batch F1: 0.0
Epoch:   83        6 Batch loss: 0.211858 Batch F1: 0.0
Epoch:   83        7 Batch loss: 0.242166 Batch F1: 0.0
Epoch:   83        8 Batch loss: 0.241323 Batch F1: 0.0
Epoch:   83        9 Batch loss: 0.219808 Batch F1: 0.0
Epoch:   83       10 Batch loss: 0.228580 Batch F1: 0.0
Epoch:   83       11 Batch loss: 0.208635 Batch F1: 0.0
Epoch:   83       12 Batch loss: 0.194766 Batch F1: 0.0
Train Avg Loss   83: 0.227188

Train Avg F1   83: 0.0

Val Avg Loss   83: 0.218105

Val Avg F1   83:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 84
--------------------------------------------------------------
Epoch:   84        1 Batch loss: 0.216359 Batch F1: 0.0
Epoch:   84        2 Batch loss: 0.224266 Batch F1: 0.0
Epoch:   84        3 Batch loss: 0.250590 Batch F1: 0.0
Epoch:   84        4 Batch loss: 0.248235 Batch F1: 0.0
Epoch:   84        5 Batch loss: 0.194793 Batch F1: 0.0
Epoch:   84        6 Batch loss: 0.250361 Batch F1: 0.0
Epoch:   84        7 Batch loss: 0.207259 Batch F1: 0.47619047619047616
Epoch:   84        8 Batch loss: 0.245653 Batch F1: 0.16666666666666669
Epoch:   84        9 Batch loss: 0.230805 Batch F1: 0.24
Epoch:   84       10 Batch loss: 0.200480 Batch F1: 0.23529411764705882
Epoch:   84       11 Batch loss: 0.231082 Batch F1: 0.0
Epoch:   84       12 Batch loss: 0.213233 Batch F1: 0.0
Train Avg Loss   84: 0.226093

Train Avg F1   84: 0.09317927170868347

Val Avg Loss   84: 0.217841

Val Avg F1   84:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 85
--------------------------------------------------------------
Epoch:   85        1 Batch loss: 0.228384 Batch F1: 0.0
Epoch:   85        2 Batch loss: 0.239994 Batch F1: 0.0
Epoch:   85        3 Batch loss: 0.242618 Batch F1: 0.0
Epoch:   85        4 Batch loss: 0.200014 Batch F1: 0.31578947368421056
Epoch:   85        5 Batch loss: 0.201927 Batch F1: 0.3333333333333333
Epoch:   85        6 Batch loss: 0.223581 Batch F1: 0.0
Epoch:   85        7 Batch loss: 0.222132 Batch F1: 0.27272727272727276
Epoch:   85        8 Batch loss: 0.229638 Batch F1: 0.1818181818181818
Epoch:   85        9 Batch loss: 0.216430 Batch F1: 0.3478260869565218
Epoch:   85       10 Batch loss: 0.222536 Batch F1: 0.3
Epoch:   85       11 Batch loss: 0.240649 Batch F1: 0.0
Epoch:   85       12 Batch loss: 0.243856 Batch F1: 0.0
Train Avg Loss   85: 0.225980

Train Avg F1   85: 0.1459578623766267

Val Avg Loss   85: 0.217517

Val Avg F1   85:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 86
--------------------------------------------------------------
Epoch:   86        1 Batch loss: 0.248586 Batch F1: 0.0
Epoch:   86        2 Batch loss: 0.200978 Batch F1: 0.0
Epoch:   86        3 Batch loss: 0.220159 Batch F1: 0.0
Epoch:   86        4 Batch loss: 0.217971 Batch F1: 0.0
Epoch:   86        5 Batch loss: 0.220880 Batch F1: 0.0
Epoch:   86        6 Batch loss: 0.173796 Batch F1: 0.0
Epoch:   86        7 Batch loss: 0.275635 Batch F1: 0.0
Epoch:   86        8 Batch loss: 0.246688 Batch F1: 0.0
Epoch:   86        9 Batch loss: 0.228756 Batch F1: 0.0
Epoch:   86       10 Batch loss: 0.251478 Batch F1: 0.0
Epoch:   86       11 Batch loss: 0.211908 Batch F1: 0.3478260869565218
Epoch:   86       12 Batch loss: 0.233208 Batch F1: 0.18181818181818182
Train Avg Loss   86: 0.227504

Train Avg F1   86: 0.04413702239789197

Val Avg Loss   86: 0.224675

Val Avg F1   86:  0.33821733821733824

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 87
--------------------------------------------------------------
Epoch:   87        1 Batch loss: 0.219858 Batch F1: 0.3333333333333333
Epoch:   87        2 Batch loss: 0.243671 Batch F1: 0.23076923076923078
Epoch:   87        3 Batch loss: 0.216115 Batch F1: 0.26086956521739124
Epoch:   87        4 Batch loss: 0.211359 Batch F1: 0.5185185185185185
Epoch:   87        5 Batch loss: 0.208014 Batch F1: 0.2222222222222222
Epoch:   87        6 Batch loss: 0.254917 Batch F1: 0.0
Epoch:   87        7 Batch loss: 0.230028 Batch F1: 0.0
Epoch:   87        8 Batch loss: 0.173802 Batch F1: 0.15384615384615383
Epoch:   87        9 Batch loss: 0.217187 Batch F1: 0.34782608695652173
Epoch:   87       10 Batch loss: 0.233435 Batch F1: 0.0
Epoch:   87       11 Batch loss: 0.264284 Batch F1: 0.0
Epoch:   87       12 Batch loss: 0.250568 Batch F1: 0.0
Train Avg Loss   87: 0.226936

Train Avg F1   87: 0.17228209257194763

Val Avg Loss   87: 0.218211

Val Avg F1   87:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 88
--------------------------------------------------------------
Epoch:   88        1 Batch loss: 0.200370 Batch F1: 0.0
Epoch:   88        2 Batch loss: 0.212845 Batch F1: 0.0
Epoch:   88        3 Batch loss: 0.238987 Batch F1: 0.0
Epoch:   88        4 Batch loss: 0.202521 Batch F1: 0.0
Epoch:   88        5 Batch loss: 0.230201 Batch F1: 0.0
Epoch:   88        6 Batch loss: 0.210394 Batch F1: 0.0
Epoch:   88        7 Batch loss: 0.232239 Batch F1: 0.0
Epoch:   88        8 Batch loss: 0.252615 Batch F1: 0.0
Epoch:   88        9 Batch loss: 0.242872 Batch F1: 0.3846153846153846
Epoch:   88       10 Batch loss: 0.227268 Batch F1: 0.0
Epoch:   88       11 Batch loss: 0.222819 Batch F1: 0.2608695652173913
Epoch:   88       12 Batch loss: 0.221873 Batch F1: 0.3478260869565218
Train Avg Loss   88: 0.224583

Train Avg F1   88: 0.08277591973244147

Val Avg Loss   88: 0.221098

Val Avg F1   88:  0.2547778308647874

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 89
--------------------------------------------------------------
Epoch:   89        1 Batch loss: 0.206645 Batch F1: 0.5
Epoch:   89        2 Batch loss: 0.213166 Batch F1: 0.3333333333333333
Epoch:   89        3 Batch loss: 0.208869 Batch F1: 0.3
Epoch:   89        4 Batch loss: 0.204092 Batch F1: 0.13333333333333336
Epoch:   89        5 Batch loss: 0.236334 Batch F1: 0.0909090909090909
Epoch:   89        6 Batch loss: 0.222168 Batch F1: 0.0
Epoch:   89        7 Batch loss: 0.253004 Batch F1: 0.0
Epoch:   89        8 Batch loss: 0.215317 Batch F1: 0.0
Epoch:   89        9 Batch loss: 0.233905 Batch F1: 0.0
Epoch:   89       10 Batch loss: 0.290711 Batch F1: 0.0
Epoch:   89       11 Batch loss: 0.189806 Batch F1: 0.0
Epoch:   89       12 Batch loss: 0.259155 Batch F1: 0.0
Train Avg Loss   89: 0.227764

Train Avg F1   89: 0.11313131313131312

Val Avg Loss   89: 0.221923

Val Avg F1   89:  0.2436868686868687

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 90
--------------------------------------------------------------
Epoch:   90        1 Batch loss: 0.225230 Batch F1: 0.3478260869565218
Epoch:   90        2 Batch loss: 0.253559 Batch F1: 0.24
Epoch:   90        3 Batch loss: 0.265938 Batch F1: 0.06896551724137931
Epoch:   90        4 Batch loss: 0.226951 Batch F1: 0.17391304347826086
Epoch:   90        5 Batch loss: 0.225698 Batch F1: 0.35714285714285715
Epoch:   90        6 Batch loss: 0.233696 Batch F1: 0.3846153846153846
Epoch:   90        7 Batch loss: 0.213206 Batch F1: 0.0
Epoch:   90        8 Batch loss: 0.203779 Batch F1: 0.0
Epoch:   90        9 Batch loss: 0.212623 Batch F1: 0.0
Epoch:   90       10 Batch loss: 0.218878 Batch F1: 0.0
Epoch:   90       11 Batch loss: 0.218198 Batch F1: 0.0
Epoch:   90       12 Batch loss: 0.249873 Batch F1: 0.0
Train Avg Loss   90: 0.228969

Train Avg F1   90: 0.13103857411953365

Val Avg Loss   90: 0.220661

Val Avg F1   90:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 91
--------------------------------------------------------------
Epoch:   91        1 Batch loss: 0.275010 Batch F1: 0.0
Epoch:   91        2 Batch loss: 0.244096 Batch F1: 0.5263157894736842
Epoch:   91        3 Batch loss: 0.250133 Batch F1: 0.4489795918367347
Epoch:   91        4 Batch loss: 0.247044 Batch F1: 0.56
Epoch:   91        5 Batch loss: 0.243527 Batch F1: 0.4878048780487805
Epoch:   91        6 Batch loss: 0.219040 Batch F1: 0.4
Epoch:   91        7 Batch loss: 0.213408 Batch F1: 0.0
Epoch:   91        8 Batch loss: 0.261078 Batch F1: 0.0
Epoch:   91        9 Batch loss: 0.188822 Batch F1: 0.0
Epoch:   91       10 Batch loss: 0.220497 Batch F1: 0.0
Epoch:   91       11 Batch loss: 0.209866 Batch F1: 0.0
Epoch:   91       12 Batch loss: 0.175977 Batch F1: 0.0
Train Avg Loss   91: 0.229041

Train Avg F1   91: 0.20192502161326661

Val Avg Loss   91: 0.219829

Val Avg F1   91:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 92
--------------------------------------------------------------
Epoch:   92        1 Batch loss: 0.249358 Batch F1: 0.0
Epoch:   92        2 Batch loss: 0.221365 Batch F1: 0.0
Epoch:   92        3 Batch loss: 0.235273 Batch F1: 0.0
Epoch:   92        4 Batch loss: 0.239703 Batch F1: 0.0
Epoch:   92        5 Batch loss: 0.226169 Batch F1: 0.0
Epoch:   92        6 Batch loss: 0.200686 Batch F1: 0.0
Epoch:   92        7 Batch loss: 0.250428 Batch F1: 0.0
Epoch:   92        8 Batch loss: 0.234092 Batch F1: 0.0
Epoch:   92        9 Batch loss: 0.240748 Batch F1: 0.0
Epoch:   92       10 Batch loss: 0.225708 Batch F1: 0.0
Epoch:   92       11 Batch loss: 0.208369 Batch F1: 0.0
Epoch:   92       12 Batch loss: 0.224041 Batch F1: 0.0
Train Avg Loss   92: 0.229662

Train Avg F1   92: 0.0

Val Avg Loss   92: 0.217809

Val Avg F1   92:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 93
--------------------------------------------------------------
Epoch:   93        1 Batch loss: 0.209662 Batch F1: 0.0
Epoch:   93        2 Batch loss: 0.240620 Batch F1: 0.0
Epoch:   93        3 Batch loss: 0.183900 Batch F1: 0.0
Epoch:   93        4 Batch loss: 0.262290 Batch F1: 0.0
Epoch:   93        5 Batch loss: 0.245469 Batch F1: 0.0
Epoch:   93        6 Batch loss: 0.237608 Batch F1: 0.0
Epoch:   93        7 Batch loss: 0.211927 Batch F1: 0.0
Epoch:   93        8 Batch loss: 0.238758 Batch F1: 0.0
Epoch:   93        9 Batch loss: 0.267432 Batch F1: 0.0
Epoch:   93       10 Batch loss: 0.227751 Batch F1: 0.0
Epoch:   93       11 Batch loss: 0.208307 Batch F1: 0.3478260869565218
Epoch:   93       12 Batch loss: 0.208280 Batch F1: 0.3157894736842105
Train Avg Loss   93: 0.228501

Train Avg F1   93: 0.05530129672006103

Val Avg Loss   93: 0.223885

Val Avg F1   93:  0.26705465587044536

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 94
--------------------------------------------------------------
Epoch:   94        1 Batch loss: 0.219752 Batch F1: 0.2222222222222222
Epoch:   94        2 Batch loss: 0.240282 Batch F1: 0.0
Epoch:   94        3 Batch loss: 0.211843 Batch F1: 0.0
Epoch:   94        4 Batch loss: 0.243052 Batch F1: 0.0
Epoch:   94        5 Batch loss: 0.230842 Batch F1: 0.0
Epoch:   94        6 Batch loss: 0.234417 Batch F1: 0.0
Epoch:   94        7 Batch loss: 0.220192 Batch F1: 0.0
Epoch:   94        8 Batch loss: 0.215455 Batch F1: 0.0
Epoch:   94        9 Batch loss: 0.224917 Batch F1: 0.0
Epoch:   94       10 Batch loss: 0.194108 Batch F1: 0.0
Epoch:   94       11 Batch loss: 0.216989 Batch F1: 0.0
Epoch:   94       12 Batch loss: 0.280656 Batch F1: 0.0
Train Avg Loss   94: 0.227709

Train Avg F1   94: 0.018518518518518517

Val Avg Loss   94: 0.218757

Val Avg F1   94:  0.24683666570076307

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 95
--------------------------------------------------------------
Epoch:   95        1 Batch loss: 0.237735 Batch F1: 0.09090909090909091
Epoch:   95        2 Batch loss: 0.228535 Batch F1: 0.19999999999999998
Epoch:   95        3 Batch loss: 0.238530 Batch F1: 0.3448275862068966
Epoch:   95        4 Batch loss: 0.213504 Batch F1: 0.10526315789473682
Epoch:   95        5 Batch loss: 0.190796 Batch F1: 0.28571428571428575
Epoch:   95        6 Batch loss: 0.230607 Batch F1: 0.0
Epoch:   95        7 Batch loss: 0.253912 Batch F1: 0.0
Epoch:   95        8 Batch loss: 0.232041 Batch F1: 0.0
Epoch:   95        9 Batch loss: 0.257745 Batch F1: 0.0
Epoch:   95       10 Batch loss: 0.223210 Batch F1: 0.0
Epoch:   95       11 Batch loss: 0.215143 Batch F1: 0.0
Epoch:   95       12 Batch loss: 0.212250 Batch F1: 0.0
Train Avg Loss   95: 0.227834

Train Avg F1   95: 0.08555951006041751

Val Avg Loss   95: 0.218361

Val Avg F1   95:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 96
--------------------------------------------------------------
Epoch:   96        1 Batch loss: 0.206192 Batch F1: 0.0
Epoch:   96        2 Batch loss: 0.229612 Batch F1: 0.0
Epoch:   96        3 Batch loss: 0.211715 Batch F1: 0.3
Epoch:   96        4 Batch loss: 0.243452 Batch F1: 0.2608695652173913
Epoch:   96        5 Batch loss: 0.227025 Batch F1: 0.23076923076923078
Epoch:   96        6 Batch loss: 0.261074 Batch F1: 0.08333333333333334
Epoch:   96        7 Batch loss: 0.222311 Batch F1: 0.4
Epoch:   96        8 Batch loss: 0.219346 Batch F1: 0.10526315789473682
Epoch:   96        9 Batch loss: 0.244498 Batch F1: 0.3333333333333333
Epoch:   96       10 Batch loss: 0.193773 Batch F1: 0.5217391304347826
Epoch:   96       11 Batch loss: 0.226369 Batch F1: 0.0
Epoch:   96       12 Batch loss: 0.219060 Batch F1: 0.0
Train Avg Loss   96: 0.225369

Train Avg F1   96: 0.18627564591523402

Val Avg Loss   96: 0.217523

Val Avg F1   96:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 97
--------------------------------------------------------------
Epoch:   97        1 Batch loss: 0.227454 Batch F1: 0.0
Epoch:   97        2 Batch loss: 0.234384 Batch F1: 0.0
Epoch:   97        3 Batch loss: 0.214451 Batch F1: 0.0
Epoch:   97        4 Batch loss: 0.214068 Batch F1: 0.0
Epoch:   97        5 Batch loss: 0.212037 Batch F1: 0.0
Epoch:   97        6 Batch loss: 0.242322 Batch F1: 0.0
Epoch:   97        7 Batch loss: 0.227938 Batch F1: 0.0
Epoch:   97        8 Batch loss: 0.256423 Batch F1: 0.0
Epoch:   97        9 Batch loss: 0.189873 Batch F1: 0.0
Epoch:   97       10 Batch loss: 0.233141 Batch F1: 0.0
Epoch:   97       11 Batch loss: 0.224470 Batch F1: 0.0
Epoch:   97       12 Batch loss: 0.215036 Batch F1: 0.0
Train Avg Loss   97: 0.224300

Train Avg F1   97: 0.0

Val Avg Loss   97: 0.218678

Val Avg F1   97:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 98
--------------------------------------------------------------
Epoch:   98        1 Batch loss: 0.220817 Batch F1: 0.0
Epoch:   98        2 Batch loss: 0.236538 Batch F1: 0.0
Epoch:   98        3 Batch loss: 0.196214 Batch F1: 0.0
Epoch:   98        4 Batch loss: 0.220853 Batch F1: 0.0
Epoch:   98        5 Batch loss: 0.229627 Batch F1: 0.0
Epoch:   98        6 Batch loss: 0.226471 Batch F1: 0.0
Epoch:   98        7 Batch loss: 0.213491 Batch F1: 0.10526315789473684
Epoch:   98        8 Batch loss: 0.209979 Batch F1: 0.11764705882352941
Epoch:   98        9 Batch loss: 0.215305 Batch F1: 0.0
Epoch:   98       10 Batch loss: 0.247209 Batch F1: 0.0
Epoch:   98       11 Batch loss: 0.232187 Batch F1: 0.0
Epoch:   98       12 Batch loss: 0.244934 Batch F1: 0.0
Train Avg Loss   98: 0.224469

Train Avg F1   98: 0.018575851393188854

Val Avg Loss   98: 0.217825

Val Avg F1   98:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 99
--------------------------------------------------------------
Epoch:   99        1 Batch loss: 0.217621 Batch F1: 0.0
Epoch:   99        2 Batch loss: 0.214193 Batch F1: 0.0
Epoch:   99        3 Batch loss: 0.241431 Batch F1: 0.0
Epoch:   99        4 Batch loss: 0.229183 Batch F1: 0.2222222222222222
Epoch:   99        5 Batch loss: 0.219692 Batch F1: 0.42857142857142855
Epoch:   99        6 Batch loss: 0.215555 Batch F1: 0.3
Epoch:   99        7 Batch loss: 0.263779 Batch F1: 0.20689655172413793
Epoch:   99        8 Batch loss: 0.255029 Batch F1: 0.3243243243243243
Epoch:   99        9 Batch loss: 0.196405 Batch F1: 0.3333333333333333
Epoch:   99       10 Batch loss: 0.210151 Batch F1: 0.1818181818181818
Epoch:   99       11 Batch loss: 0.227025 Batch F1: 0.32
Epoch:   99       12 Batch loss: 0.204456 Batch F1: 0.18181818181818182
Train Avg Loss   99: 0.224543

Train Avg F1   99: 0.2082486853176508

Val Avg Loss   99: 0.217860

Val Avg F1   99:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 100
--------------------------------------------------------------
Epoch:  100        1 Batch loss: 0.229718 Batch F1: 0.0
Epoch:  100        2 Batch loss: 0.211281 Batch F1: 0.0
Epoch:  100        3 Batch loss: 0.256109 Batch F1: 0.0
Epoch:  100        4 Batch loss: 0.215096 Batch F1: 0.0
Epoch:  100        5 Batch loss: 0.186629 Batch F1: 0.0
Epoch:  100        6 Batch loss: 0.232656 Batch F1: 0.0
Epoch:  100        7 Batch loss: 0.229990 Batch F1: 0.0
Epoch:  100        8 Batch loss: 0.213104 Batch F1: 0.0
Epoch:  100        9 Batch loss: 0.251427 Batch F1: 0.0
Epoch:  100       10 Batch loss: 0.272700 Batch F1: 0.25
Epoch:  100       11 Batch loss: 0.214276 Batch F1: 0.42857142857142855
Epoch:  100       12 Batch loss: 0.203926 Batch F1: 0.0
Train Avg Loss  100: 0.226409

Train Avg F1  100: 0.05654761904761905

Val Avg Loss  100: 0.220711

Val Avg F1  100:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 101
--------------------------------------------------------------
Epoch:  101        1 Batch loss: 0.234516 Batch F1: 0.18181818181818182
Epoch:  101        2 Batch loss: 0.231901 Batch F1: 0.0
Epoch:  101        3 Batch loss: 0.280592 Batch F1: 0.0
Epoch:  101        4 Batch loss: 0.224456 Batch F1: 0.0
Epoch:  101        5 Batch loss: 0.200918 Batch F1: 0.0
Epoch:  101        6 Batch loss: 0.245280 Batch F1: 0.0
Epoch:  101        7 Batch loss: 0.235537 Batch F1: 0.29629629629629634
Epoch:  101        8 Batch loss: 0.209437 Batch F1: 0.23529411764705882
Epoch:  101        9 Batch loss: 0.219337 Batch F1: 0.1818181818181818
Epoch:  101       10 Batch loss: 0.174049 Batch F1: 0.42857142857142855
Epoch:  101       11 Batch loss: 0.229307 Batch F1: 0.0
Epoch:  101       12 Batch loss: 0.212128 Batch F1: 0.0
Train Avg Loss  101: 0.224788

Train Avg F1  101: 0.11031651717926227

Val Avg Loss  101: 0.217243

Val Avg F1  101:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 102
--------------------------------------------------------------
Epoch:  102        1 Batch loss: 0.256666 Batch F1: 0.0
Epoch:  102        2 Batch loss: 0.198364 Batch F1: 0.0
Epoch:  102        3 Batch loss: 0.223814 Batch F1: 0.0
Epoch:  102        4 Batch loss: 0.201338 Batch F1: 0.0
Epoch:  102        5 Batch loss: 0.265280 Batch F1: 0.0
Epoch:  102        6 Batch loss: 0.230360 Batch F1: 0.0
Epoch:  102        7 Batch loss: 0.204998 Batch F1: 0.0
Epoch:  102        8 Batch loss: 0.198116 Batch F1: 0.0
Epoch:  102        9 Batch loss: 0.237736 Batch F1: 0.0
Epoch:  102       10 Batch loss: 0.242097 Batch F1: 0.0
Epoch:  102       11 Batch loss: 0.229414 Batch F1: 0.23999999999999996
Epoch:  102       12 Batch loss: 0.218419 Batch F1: 0.3478260869565218
Train Avg Loss  102: 0.225550

Train Avg F1  102: 0.04898550724637681

Val Avg Loss  102: 0.222305

Val Avg F1  102:  0.2667300434995535

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 103
--------------------------------------------------------------
Epoch:  103        1 Batch loss: 0.236192 Batch F1: 0.08
Epoch:  103        2 Batch loss: 0.234481 Batch F1: 0.3870967741935483
Epoch:  103        3 Batch loss: 0.229643 Batch F1: 0.39999999999999997
Epoch:  103        4 Batch loss: 0.224367 Batch F1: 0.4666666666666667
Epoch:  103        5 Batch loss: 0.201920 Batch F1: 0.4166666666666667
Epoch:  103        6 Batch loss: 0.260327 Batch F1: 0.27586206896551724
Epoch:  103        7 Batch loss: 0.220805 Batch F1: 0.32
Epoch:  103        8 Batch loss: 0.249536 Batch F1: 0.0
Epoch:  103        9 Batch loss: 0.182540 Batch F1: 0.0
Epoch:  103       10 Batch loss: 0.243760 Batch F1: 0.0
Epoch:  103       11 Batch loss: 0.213757 Batch F1: 0.0
Epoch:  103       12 Batch loss: 0.188990 Batch F1: 0.0
Train Avg Loss  103: 0.223860

Train Avg F1  103: 0.19552434804103322

Val Avg Loss  103: 0.217287

Val Avg F1  103:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 104
--------------------------------------------------------------
Epoch:  104        1 Batch loss: 0.230949 Batch F1: 0.0
Epoch:  104        2 Batch loss: 0.240595 Batch F1: 0.0
Epoch:  104        3 Batch loss: 0.189448 Batch F1: 0.0
Epoch:  104        4 Batch loss: 0.221985 Batch F1: 0.0
Epoch:  104        5 Batch loss: 0.217714 Batch F1: 0.0
Epoch:  104        6 Batch loss: 0.254616 Batch F1: 0.16
Epoch:  104        7 Batch loss: 0.225306 Batch F1: 0.35714285714285715
Epoch:  104        8 Batch loss: 0.260087 Batch F1: 0.28571428571428564
Epoch:  104        9 Batch loss: 0.242654 Batch F1: 0.24
Epoch:  104       10 Batch loss: 0.234997 Batch F1: 0.0
Epoch:  104       11 Batch loss: 0.188682 Batch F1: 0.0
Epoch:  104       12 Batch loss: 0.223767 Batch F1: 0.0
Train Avg Loss  104: 0.227567

Train Avg F1  104: 0.08690476190476189

Val Avg Loss  104: 0.217483

Val Avg F1  104:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 105
--------------------------------------------------------------
Epoch:  105        1 Batch loss: 0.211927 Batch F1: 0.0
Epoch:  105        2 Batch loss: 0.215647 Batch F1: 0.0
Epoch:  105        3 Batch loss: 0.230615 Batch F1: 0.0
Epoch:  105        4 Batch loss: 0.213538 Batch F1: 0.0
Epoch:  105        5 Batch loss: 0.231874 Batch F1: 0.0
Epoch:  105        6 Batch loss: 0.208812 Batch F1: 0.0
Epoch:  105        7 Batch loss: 0.220096 Batch F1: 0.0
Epoch:  105        8 Batch loss: 0.214301 Batch F1: 0.0
Epoch:  105        9 Batch loss: 0.253286 Batch F1: 0.0
Epoch:  105       10 Batch loss: 0.242918 Batch F1: 0.0
Epoch:  105       11 Batch loss: 0.223513 Batch F1: 0.3333333333333333
Epoch:  105       12 Batch loss: 0.246446 Batch F1: 0.3333333333333333
Train Avg Loss  105: 0.226081

Train Avg F1  105: 0.05555555555555555

Val Avg Loss  105: 0.236145

Val Avg F1  105:  0.44857364857364856

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 106
--------------------------------------------------------------
Epoch:  106        1 Batch loss: 0.232719 Batch F1: 0.55
Epoch:  106        2 Batch loss: 0.225338 Batch F1: 0.4827586206896552
Epoch:  106        3 Batch loss: 0.245559 Batch F1: 0.0
Epoch:  106        4 Batch loss: 0.217917 Batch F1: 0.0
Epoch:  106        5 Batch loss: 0.216249 Batch F1: 0.0
Epoch:  106        6 Batch loss: 0.267043 Batch F1: 0.0
Epoch:  106        7 Batch loss: 0.269523 Batch F1: 0.0
Epoch:  106        8 Batch loss: 0.224236 Batch F1: 0.0
Epoch:  106        9 Batch loss: 0.210164 Batch F1: 0.0
Epoch:  106       10 Batch loss: 0.236520 Batch F1: 0.0
Epoch:  106       11 Batch loss: 0.195816 Batch F1: 0.0
Epoch:  106       12 Batch loss: 0.210687 Batch F1: 0.0
Train Avg Loss  106: 0.229314

Train Avg F1  106: 0.08606321839080461

Val Avg Loss  106: 0.219097

Val Avg F1  106:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 107
--------------------------------------------------------------
Epoch:  107        1 Batch loss: 0.235024 Batch F1: 0.0
Epoch:  107        2 Batch loss: 0.245372 Batch F1: 0.0
Epoch:  107        3 Batch loss: 0.242655 Batch F1: 0.0
Epoch:  107        4 Batch loss: 0.218960 Batch F1: 0.0
Epoch:  107        5 Batch loss: 0.222332 Batch F1: 0.0
Epoch:  107        6 Batch loss: 0.215174 Batch F1: 0.0
Epoch:  107        7 Batch loss: 0.210167 Batch F1: 0.0
Epoch:  107        8 Batch loss: 0.234660 Batch F1: 0.0
Epoch:  107        9 Batch loss: 0.233173 Batch F1: 0.0
Epoch:  107       10 Batch loss: 0.223730 Batch F1: 0.21052631578947367
Epoch:  107       11 Batch loss: 0.201893 Batch F1: 0.4
Epoch:  107       12 Batch loss: 0.216624 Batch F1: 0.0
Train Avg Loss  107: 0.224980

Train Avg F1  107: 0.05087719298245614

Val Avg Loss  107: 0.217204

Val Avg F1  107:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 108
--------------------------------------------------------------
Epoch:  108        1 Batch loss: 0.241420 Batch F1: 0.0
Epoch:  108        2 Batch loss: 0.205835 Batch F1: 0.0
Epoch:  108        3 Batch loss: 0.250186 Batch F1: 0.0
Epoch:  108        4 Batch loss: 0.213049 Batch F1: 0.0
Epoch:  108        5 Batch loss: 0.224661 Batch F1: 0.0
Epoch:  108        6 Batch loss: 0.211635 Batch F1: 0.0
Epoch:  108        7 Batch loss: 0.246493 Batch F1: 0.2
Epoch:  108        8 Batch loss: 0.230318 Batch F1: 0.23076923076923075
Epoch:  108        9 Batch loss: 0.204995 Batch F1: 0.2
Epoch:  108       10 Batch loss: 0.215104 Batch F1: 0.1
Epoch:  108       11 Batch loss: 0.240970 Batch F1: 0.0
Epoch:  108       12 Batch loss: 0.214004 Batch F1: 0.0
Train Avg Loss  108: 0.224889

Train Avg F1  108: 0.060897435897435896

Val Avg Loss  108: 0.219159

Val Avg F1  108:  0.0664488017429194

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 109
--------------------------------------------------------------
Epoch:  109        1 Batch loss: 0.235832 Batch F1: 0.0
Epoch:  109        2 Batch loss: 0.227005 Batch F1: 0.0
Epoch:  109        3 Batch loss: 0.203654 Batch F1: 0.0
Epoch:  109        4 Batch loss: 0.220267 Batch F1: 0.5
Epoch:  109        5 Batch loss: 0.234745 Batch F1: 0.0
Epoch:  109        6 Batch loss: 0.221234 Batch F1: 0.0
Epoch:  109        7 Batch loss: 0.225878 Batch F1: 0.0
Epoch:  109        8 Batch loss: 0.222753 Batch F1: 0.0
Epoch:  109        9 Batch loss: 0.218243 Batch F1: 0.0
Epoch:  109       10 Batch loss: 0.237342 Batch F1: 0.0
Epoch:  109       11 Batch loss: 0.180644 Batch F1: 0.0
Epoch:  109       12 Batch loss: 0.267231 Batch F1: 0.0
Train Avg Loss  109: 0.224569

Train Avg F1  109: 0.041666666666666664

Val Avg Loss  109: 0.218227

Val Avg F1  109:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 110
--------------------------------------------------------------
Epoch:  110        1 Batch loss: 0.195842 Batch F1: 0.0
Epoch:  110        2 Batch loss: 0.216551 Batch F1: 0.0
Epoch:  110        3 Batch loss: 0.209468 Batch F1: 0.0
Epoch:  110        4 Batch loss: 0.193711 Batch F1: 0.0
Epoch:  110        5 Batch loss: 0.249515 Batch F1: 0.0
Epoch:  110        6 Batch loss: 0.212491 Batch F1: 0.0
Epoch:  110        7 Batch loss: 0.223784 Batch F1: 0.0
Epoch:  110        8 Batch loss: 0.242973 Batch F1: 0.0
Epoch:  110        9 Batch loss: 0.225734 Batch F1: 0.09523809523809525
Epoch:  110       10 Batch loss: 0.248394 Batch F1: 0.25
Epoch:  110       11 Batch loss: 0.227052 Batch F1: 0.1904761904761905
Epoch:  110       12 Batch loss: 0.240712 Batch F1: 0.32000000000000006
Train Avg Loss  110: 0.223852

Train Avg F1  110: 0.07130952380952381

Val Avg Loss  110: 0.219119

Val Avg F1  110:  0.2600250626566416

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 111
--------------------------------------------------------------
Epoch:  111        1 Batch loss: 0.241522 Batch F1: 0.35714285714285715
Epoch:  111        2 Batch loss: 0.226652 Batch F1: 0.32
Epoch:  111        3 Batch loss: 0.239730 Batch F1: 0.21428571428571425
Epoch:  111        4 Batch loss: 0.247338 Batch F1: 0.08
Epoch:  111        5 Batch loss: 0.218872 Batch F1: 0.35714285714285715
Epoch:  111        6 Batch loss: 0.209175 Batch F1: 0.5454545454545455
Epoch:  111        7 Batch loss: 0.225917 Batch F1: 0.10526315789473682
Epoch:  111        8 Batch loss: 0.238254 Batch F1: 0.30769230769230765
Epoch:  111        9 Batch loss: 0.208798 Batch F1: 0.0
Epoch:  111       10 Batch loss: 0.188604 Batch F1: 0.0
Epoch:  111       11 Batch loss: 0.224382 Batch F1: 0.0
Epoch:  111       12 Batch loss: 0.242656 Batch F1: 0.0
Train Avg Loss  111: 0.225992

Train Avg F1  111: 0.1905817866344182

Val Avg Loss  111: 0.217327

Val Avg F1  111:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 112
--------------------------------------------------------------
Epoch:  112        1 Batch loss: 0.220456 Batch F1: 0.0
Epoch:  112        2 Batch loss: 0.236440 Batch F1: 0.0
Epoch:  112        3 Batch loss: 0.195029 Batch F1: 0.0
Epoch:  112        4 Batch loss: 0.231978 Batch F1: 0.0
Epoch:  112        5 Batch loss: 0.264420 Batch F1: 0.0
Epoch:  112        6 Batch loss: 0.249439 Batch F1: 0.0
Epoch:  112        7 Batch loss: 0.192920 Batch F1: 0.0
Epoch:  112        8 Batch loss: 0.222565 Batch F1: 0.0
Epoch:  112        9 Batch loss: 0.217919 Batch F1: 0.0
Epoch:  112       10 Batch loss: 0.220304 Batch F1: 0.0
Epoch:  112       11 Batch loss: 0.230029 Batch F1: 0.0
Epoch:  112       12 Batch loss: 0.219551 Batch F1: 0.0
Train Avg Loss  112: 0.225088

Train Avg F1  112: 0.0

Val Avg Loss  112: 0.218268

Val Avg F1  112:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 113
--------------------------------------------------------------
Epoch:  113        1 Batch loss: 0.231135 Batch F1: 0.09090909090909091
Epoch:  113        2 Batch loss: 0.210670 Batch F1: 0.38095238095238093
Epoch:  113        3 Batch loss: 0.203966 Batch F1: 0.3478260869565218
Epoch:  113        4 Batch loss: 0.252769 Batch F1: 0.2727272727272727
Epoch:  113        5 Batch loss: 0.228193 Batch F1: 0.0
Epoch:  113        6 Batch loss: 0.247285 Batch F1: 0.0
Epoch:  113        7 Batch loss: 0.194603 Batch F1: 0.0
Epoch:  113        8 Batch loss: 0.221145 Batch F1: 0.0
Epoch:  113        9 Batch loss: 0.216444 Batch F1: 0.37500000000000006
Epoch:  113       10 Batch loss: 0.242716 Batch F1: 0.43902439024390244
Epoch:  113       11 Batch loss: 0.215151 Batch F1: 0.4242424242424242
Epoch:  113       12 Batch loss: 0.260508 Batch F1: 0.3478260869565218
Train Avg Loss  113: 0.227049

Train Avg F1  113: 0.22320897774900958

Val Avg Loss  113: 0.217583

Val Avg F1  113:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 114
--------------------------------------------------------------
Epoch:  114        1 Batch loss: 0.238257 Batch F1: 0.0
Epoch:  114        2 Batch loss: 0.177859 Batch F1: 0.0
Epoch:  114        3 Batch loss: 0.248817 Batch F1: 0.0
Epoch:  114        4 Batch loss: 0.255840 Batch F1: 0.0
Epoch:  114        5 Batch loss: 0.244399 Batch F1: 0.0
Epoch:  114        6 Batch loss: 0.214945 Batch F1: 0.0
Epoch:  114        7 Batch loss: 0.169058 Batch F1: 0.0
Epoch:  114        8 Batch loss: 0.227596 Batch F1: 0.0
Epoch:  114        9 Batch loss: 0.226462 Batch F1: 0.0
Epoch:  114       10 Batch loss: 0.237467 Batch F1: 0.0
Epoch:  114       11 Batch loss: 0.253663 Batch F1: 0.0
Epoch:  114       12 Batch loss: 0.230864 Batch F1: 0.0
Train Avg Loss  114: 0.227102

Train Avg F1  114: 0.0

Val Avg Loss  114: 0.219329

Val Avg F1  114:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 115
--------------------------------------------------------------
Epoch:  115        1 Batch loss: 0.203910 Batch F1: 0.0
Epoch:  115        2 Batch loss: 0.212895 Batch F1: 0.0
Epoch:  115        3 Batch loss: 0.229511 Batch F1: 0.0
Epoch:  115        4 Batch loss: 0.209571 Batch F1: 0.0
Epoch:  115        5 Batch loss: 0.256456 Batch F1: 0.0
Epoch:  115        6 Batch loss: 0.237262 Batch F1: 0.0
Epoch:  115        7 Batch loss: 0.244293 Batch F1: 0.0
Epoch:  115        8 Batch loss: 0.204808 Batch F1: 0.0
Epoch:  115        9 Batch loss: 0.232762 Batch F1: 0.24
Epoch:  115       10 Batch loss: 0.225282 Batch F1: 0.33333333333333337
Epoch:  115       11 Batch loss: 0.227262 Batch F1: 0.4285714285714285
Epoch:  115       12 Batch loss: 0.219663 Batch F1: 0.25
Train Avg Loss  115: 0.225306

Train Avg F1  115: 0.10432539682539682

Val Avg Loss  115: 0.220016

Val Avg F1  115:  0.25877495671546014

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 116
--------------------------------------------------------------
Epoch:  116        1 Batch loss: 0.242563 Batch F1: 0.3076923076923077
Epoch:  116        2 Batch loss: 0.195781 Batch F1: 0.31578947368421056
Epoch:  116        3 Batch loss: 0.231836 Batch F1: 0.3333333333333333
Epoch:  116        4 Batch loss: 0.195602 Batch F1: 0.27272727272727276
Epoch:  116        5 Batch loss: 0.233314 Batch F1: 0.2608695652173913
Epoch:  116        6 Batch loss: 0.249845 Batch F1: 0.37500000000000006
Epoch:  116        7 Batch loss: 0.217981 Batch F1: 0.45454545454545453
Epoch:  116        8 Batch loss: 0.192604 Batch F1: 0.48
Epoch:  116        9 Batch loss: 0.246129 Batch F1: 0.23999999999999996
Epoch:  116       10 Batch loss: 0.242827 Batch F1: 0.17391304347826086
Epoch:  116       11 Batch loss: 0.204783 Batch F1: 0.11764705882352941
Epoch:  116       12 Batch loss: 0.238579 Batch F1: 0.0
Train Avg Loss  116: 0.224320

Train Avg F1  116: 0.27762645912514666

Val Avg Loss  116: 0.217519

Val Avg F1  116:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 117
--------------------------------------------------------------
Epoch:  117        1 Batch loss: 0.226515 Batch F1: 0.0
Epoch:  117        2 Batch loss: 0.218208 Batch F1: 0.0
Epoch:  117        3 Batch loss: 0.223709 Batch F1: 0.08695652173913043
Epoch:  117        4 Batch loss: 0.212083 Batch F1: 0.1111111111111111
Epoch:  117        5 Batch loss: 0.253037 Batch F1: 0.2962962962962963
Epoch:  117        6 Batch loss: 0.205564 Batch F1: 0.5217391304347826
Epoch:  117        7 Batch loss: 0.203989 Batch F1: 0.10526315789473682
Epoch:  117        8 Batch loss: 0.225081 Batch F1: 0.0
Epoch:  117        9 Batch loss: 0.230137 Batch F1: 0.0
Epoch:  117       10 Batch loss: 0.221219 Batch F1: 0.0
Epoch:  117       11 Batch loss: 0.238638 Batch F1: 0.0
Epoch:  117       12 Batch loss: 0.232660 Batch F1: 0.0
Train Avg Loss  117: 0.224237

Train Avg F1  117: 0.09344718478967144

Val Avg Loss  117: 0.218437

Val Avg F1  117:  0.2678806700545831

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 118
--------------------------------------------------------------
Epoch:  118        1 Batch loss: 0.215597 Batch F1: 0.25
Epoch:  118        2 Batch loss: 0.233148 Batch F1: 0.2857142857142857
Epoch:  118        3 Batch loss: 0.204246 Batch F1: 0.34782608695652173
Epoch:  118        4 Batch loss: 0.242661 Batch F1: 0.14814814814814817
Epoch:  118        5 Batch loss: 0.234012 Batch F1: 0.16666666666666666
Epoch:  118        6 Batch loss: 0.218067 Batch F1: 0.2105263157894737
Epoch:  118        7 Batch loss: 0.233854 Batch F1: 0.5161290322580645
Epoch:  118        8 Batch loss: 0.224963 Batch F1: 0.0
Epoch:  118        9 Batch loss: 0.178383 Batch F1: 0.0
Epoch:  118       10 Batch loss: 0.270753 Batch F1: 0.0
Epoch:  118       11 Batch loss: 0.231415 Batch F1: 0.4137931034482759
Epoch:  118       12 Batch loss: 0.205910 Batch F1: 0.18181818181818182
Train Avg Loss  118: 0.224417

Train Avg F1  118: 0.2100518183999682

Val Avg Loss  118: 0.219310

Val Avg F1  118:  0.23955026455026454

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 119
--------------------------------------------------------------
Epoch:  119        1 Batch loss: 0.212524 Batch F1: 0.2727272727272727
Epoch:  119        2 Batch loss: 0.193229 Batch F1: 0.5833333333333334
Epoch:  119        3 Batch loss: 0.237146 Batch F1: 0.1818181818181818
Epoch:  119        4 Batch loss: 0.235089 Batch F1: 0.0
Epoch:  119        5 Batch loss: 0.210729 Batch F1: 0.0
Epoch:  119        6 Batch loss: 0.208217 Batch F1: 0.0
Epoch:  119        7 Batch loss: 0.210883 Batch F1: 0.0
Epoch:  119        8 Batch loss: 0.275089 Batch F1: 0.0
Epoch:  119        9 Batch loss: 0.239984 Batch F1: 0.0
Epoch:  119       10 Batch loss: 0.218926 Batch F1: 0.0
Epoch:  119       11 Batch loss: 0.205374 Batch F1: 0.0
Epoch:  119       12 Batch loss: 0.245566 Batch F1: 0.0
Train Avg Loss  119: 0.224396

Train Avg F1  119: 0.08648989898989899

Val Avg Loss  119: 0.219510

Val Avg F1  119:  0.2748251748251748

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 120
--------------------------------------------------------------
Epoch:  120        1 Batch loss: 0.262530 Batch F1: 0.2857142857142857
Epoch:  120        2 Batch loss: 0.239832 Batch F1: 0.08333333333333333
Epoch:  120        3 Batch loss: 0.220550 Batch F1: 0.4516129032258065
Epoch:  120        4 Batch loss: 0.228533 Batch F1: 0.5
Epoch:  120        5 Batch loss: 0.249659 Batch F1: 0.5263157894736842
Epoch:  120        6 Batch loss: 0.198569 Batch F1: 0.7096774193548386
Epoch:  120        7 Batch loss: 0.219088 Batch F1: 0.38461538461538464
Epoch:  120        8 Batch loss: 0.215446 Batch F1: 0.0
Epoch:  120        9 Batch loss: 0.196085 Batch F1: 0.0
Epoch:  120       10 Batch loss: 0.239345 Batch F1: 0.0
Epoch:  120       11 Batch loss: 0.239500 Batch F1: 0.0
Epoch:  120       12 Batch loss: 0.186176 Batch F1: 0.0
Train Avg Loss  120: 0.224609

Train Avg F1  120: 0.24510575964311107

Val Avg Loss  120: 0.219522

Val Avg F1  120:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 121
--------------------------------------------------------------
Epoch:  121        1 Batch loss: 0.220983 Batch F1: 0.0
Epoch:  121        2 Batch loss: 0.267777 Batch F1: 0.0
Epoch:  121        3 Batch loss: 0.231120 Batch F1: 0.0
Epoch:  121        4 Batch loss: 0.217036 Batch F1: 0.0
Epoch:  121        5 Batch loss: 0.219940 Batch F1: 0.0
Epoch:  121        6 Batch loss: 0.209204 Batch F1: 0.0
Epoch:  121        7 Batch loss: 0.237972 Batch F1: 0.0
Epoch:  121        8 Batch loss: 0.212675 Batch F1: 0.0
Epoch:  121        9 Batch loss: 0.257052 Batch F1: 0.0
Epoch:  121       10 Batch loss: 0.222223 Batch F1: 0.0
Epoch:  121       11 Batch loss: 0.234263 Batch F1: 0.0
Epoch:  121       12 Batch loss: 0.200039 Batch F1: 0.0
Train Avg Loss  121: 0.227523

Train Avg F1  121: 0.0

Val Avg Loss  121: 0.217877

Val Avg F1  121:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 122
--------------------------------------------------------------
Epoch:  122        1 Batch loss: 0.222778 Batch F1: 0.0
Epoch:  122        2 Batch loss: 0.226030 Batch F1: 0.0
Epoch:  122        3 Batch loss: 0.211093 Batch F1: 0.0
Epoch:  122        4 Batch loss: 0.247565 Batch F1: 0.0
Epoch:  122        5 Batch loss: 0.208742 Batch F1: 0.0
Epoch:  122        6 Batch loss: 0.223971 Batch F1: 0.0
Epoch:  122        7 Batch loss: 0.219808 Batch F1: 0.0
Epoch:  122        8 Batch loss: 0.232075 Batch F1: 0.0
Epoch:  122        9 Batch loss: 0.181236 Batch F1: 0.0
Epoch:  122       10 Batch loss: 0.254018 Batch F1: 0.0
Epoch:  122       11 Batch loss: 0.212889 Batch F1: 0.0
Epoch:  122       12 Batch loss: 0.259489 Batch F1: 0.0
Train Avg Loss  122: 0.224975

Train Avg F1  122: 0.0

Val Avg Loss  122: 0.219785

Val Avg F1  122:  0.24871794871794872

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 123
--------------------------------------------------------------
Epoch:  123        1 Batch loss: 0.216947 Batch F1: 0.31578947368421056
Epoch:  123        2 Batch loss: 0.252402 Batch F1: 0.19999999999999998
Epoch:  123        3 Batch loss: 0.242570 Batch F1: 0.3448275862068966
Epoch:  123        4 Batch loss: 0.223871 Batch F1: 0.5806451612903225
Epoch:  123        5 Batch loss: 0.246535 Batch F1: 0.35714285714285715
Epoch:  123        6 Batch loss: 0.255816 Batch F1: 0.13333333333333333
Epoch:  123        7 Batch loss: 0.205137 Batch F1: 0.5
Epoch:  123        8 Batch loss: 0.215387 Batch F1: 0.5185185185185185
Epoch:  123        9 Batch loss: 0.228444 Batch F1: 0.17391304347826086
Epoch:  123       10 Batch loss: 0.204746 Batch F1: 0.0
Epoch:  123       11 Batch loss: 0.236976 Batch F1: 0.0
Epoch:  123       12 Batch loss: 0.182844 Batch F1: 0.0
Train Avg Loss  123: 0.225973

Train Avg F1  123: 0.2603474978045333

Val Avg Loss  123: 0.217398

Val Avg F1  123:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 124
--------------------------------------------------------------
Epoch:  124        1 Batch loss: 0.209129 Batch F1: 0.0
Epoch:  124        2 Batch loss: 0.238665 Batch F1: 0.0
Epoch:  124        3 Batch loss: 0.237425 Batch F1: 0.0
Epoch:  124        4 Batch loss: 0.210555 Batch F1: 0.0
Epoch:  124        5 Batch loss: 0.247184 Batch F1: 0.0
Epoch:  124        6 Batch loss: 0.220030 Batch F1: 0.0
Epoch:  124        7 Batch loss: 0.215279 Batch F1: 0.0
Epoch:  124        8 Batch loss: 0.248803 Batch F1: 0.0
Epoch:  124        9 Batch loss: 0.187459 Batch F1: 0.0
Epoch:  124       10 Batch loss: 0.215532 Batch F1: 0.0
Epoch:  124       11 Batch loss: 0.242106 Batch F1: 0.0
Epoch:  124       12 Batch loss: 0.222606 Batch F1: 0.0
Train Avg Loss  124: 0.224564

Train Avg F1  124: 0.0

Val Avg Loss  124: 0.218900

Val Avg F1  124:  0.26749942489072925

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 125
--------------------------------------------------------------
Epoch:  125        1 Batch loss: 0.260721 Batch F1: 0.3870967741935483
Epoch:  125        2 Batch loss: 0.219353 Batch F1: 0.48275862068965514
Epoch:  125        3 Batch loss: 0.216313 Batch F1: 0.16666666666666666
Epoch:  125        4 Batch loss: 0.228822 Batch F1: 0.4516129032258065
Epoch:  125        5 Batch loss: 0.198697 Batch F1: 0.5263157894736842
Epoch:  125        6 Batch loss: 0.223622 Batch F1: 0.2
Epoch:  125        7 Batch loss: 0.254098 Batch F1: 0.0
Epoch:  125        8 Batch loss: 0.246893 Batch F1: 0.0
Epoch:  125        9 Batch loss: 0.237054 Batch F1: 0.0
Epoch:  125       10 Batch loss: 0.221896 Batch F1: 0.0
Epoch:  125       11 Batch loss: 0.215970 Batch F1: 0.0
Epoch:  125       12 Batch loss: 0.192383 Batch F1: 0.0
Train Avg Loss  125: 0.226319

Train Avg F1  125: 0.1845375628541134

Val Avg Loss  125: 0.218905

Val Avg F1  125:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 126
--------------------------------------------------------------
Epoch:  126        1 Batch loss: 0.274972 Batch F1: 0.0
Epoch:  126        2 Batch loss: 0.218817 Batch F1: 0.0
Epoch:  126        3 Batch loss: 0.203495 Batch F1: 0.0
Epoch:  126        4 Batch loss: 0.214446 Batch F1: 0.0
Epoch:  126        5 Batch loss: 0.225293 Batch F1: 0.0
Epoch:  126        6 Batch loss: 0.220902 Batch F1: 0.0
Epoch:  126        7 Batch loss: 0.235839 Batch F1: 0.0
Epoch:  126        8 Batch loss: 0.190528 Batch F1: 0.0
Epoch:  126        9 Batch loss: 0.248820 Batch F1: 0.0
Epoch:  126       10 Batch loss: 0.208593 Batch F1: 0.0
Epoch:  126       11 Batch loss: 0.230547 Batch F1: 0.08333333333333334
Epoch:  126       12 Batch loss: 0.235925 Batch F1: 0.21052631578947367
Train Avg Loss  126: 0.225681

Train Avg F1  126: 0.024488304093567254

Val Avg Loss  126: 0.221366

Val Avg F1  126:  0.2669565217391304

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 127
--------------------------------------------------------------
Epoch:  127        1 Batch loss: 0.219443 Batch F1: 0.37037037037037035
Epoch:  127        2 Batch loss: 0.266843 Batch F1: 0.12903225806451613
Epoch:  127        3 Batch loss: 0.230372 Batch F1: 0.23999999999999996
Epoch:  127        4 Batch loss: 0.236949 Batch F1: 0.28571428571428575
Epoch:  127        5 Batch loss: 0.237266 Batch F1: 0.24
Epoch:  127        6 Batch loss: 0.217710 Batch F1: 0.0
Epoch:  127        7 Batch loss: 0.221914 Batch F1: 0.0
Epoch:  127        8 Batch loss: 0.216135 Batch F1: 0.0
Epoch:  127        9 Batch loss: 0.197681 Batch F1: 0.0
Epoch:  127       10 Batch loss: 0.243351 Batch F1: 0.0
Epoch:  127       11 Batch loss: 0.222369 Batch F1: 0.0
Epoch:  127       12 Batch loss: 0.223054 Batch F1: 0.0
Train Avg Loss  127: 0.227757

Train Avg F1  127: 0.10542640951243103

Val Avg Loss  127: 0.218785

Val Avg F1  127:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 128
--------------------------------------------------------------
Epoch:  128        1 Batch loss: 0.269952 Batch F1: 0.0
Epoch:  128        2 Batch loss: 0.244189 Batch F1: 0.0
Epoch:  128        3 Batch loss: 0.258471 Batch F1: 0.0
Epoch:  128        4 Batch loss: 0.224321 Batch F1: 0.32
Epoch:  128        5 Batch loss: 0.233763 Batch F1: 0.32
Epoch:  128        6 Batch loss: 0.218870 Batch F1: 0.19047619047619044
Epoch:  128        7 Batch loss: 0.231787 Batch F1: 0.09090909090909091
Epoch:  128        8 Batch loss: 0.223754 Batch F1: 0.0
Epoch:  128        9 Batch loss: 0.194441 Batch F1: 0.0
Epoch:  128       10 Batch loss: 0.216575 Batch F1: 0.0
Epoch:  128       11 Batch loss: 0.218158 Batch F1: 0.0
Epoch:  128       12 Batch loss: 0.205184 Batch F1: 0.0
Train Avg Loss  128: 0.228289

Train Avg F1  128: 0.07678210678210678

Val Avg Loss  128: 0.217085

Val Avg F1  128:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 129
--------------------------------------------------------------
Epoch:  129        1 Batch loss: 0.224968 Batch F1: 0.0
Epoch:  129        2 Batch loss: 0.236601 Batch F1: 0.0
Epoch:  129        3 Batch loss: 0.211628 Batch F1: 0.0
Epoch:  129        4 Batch loss: 0.239018 Batch F1: 0.0
Epoch:  129        5 Batch loss: 0.233107 Batch F1: 0.09523809523809525
Epoch:  129        6 Batch loss: 0.217829 Batch F1: 0.2222222222222222
Epoch:  129        7 Batch loss: 0.210890 Batch F1: 0.2727272727272727
Epoch:  129        8 Batch loss: 0.239167 Batch F1: 0.0
Epoch:  129        9 Batch loss: 0.224859 Batch F1: 0.0
Epoch:  129       10 Batch loss: 0.237960 Batch F1: 0.0
Epoch:  129       11 Batch loss: 0.217485 Batch F1: 0.0
Epoch:  129       12 Batch loss: 0.213078 Batch F1: 0.0
Train Avg Loss  129: 0.225549

Train Avg F1  129: 0.04918229918229918

Val Avg Loss  129: 0.217029

Val Avg F1  129:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 130
--------------------------------------------------------------
Epoch:  130        1 Batch loss: 0.224789 Batch F1: 0.0
Epoch:  130        2 Batch loss: 0.232941 Batch F1: 0.0
Epoch:  130        3 Batch loss: 0.183322 Batch F1: 0.0
Epoch:  130        4 Batch loss: 0.223274 Batch F1: 0.0
Epoch:  130        5 Batch loss: 0.240804 Batch F1: 0.0
Epoch:  130        6 Batch loss: 0.250464 Batch F1: 0.0
Epoch:  130        7 Batch loss: 0.238034 Batch F1: 0.2962962962962963
Epoch:  130        8 Batch loss: 0.208300 Batch F1: 0.36363636363636365
Epoch:  130        9 Batch loss: 0.223088 Batch F1: 0.37037037037037035
Epoch:  130       10 Batch loss: 0.260830 Batch F1: 0.09090909090909091
Epoch:  130       11 Batch loss: 0.221320 Batch F1: 0.32000000000000006
Epoch:  130       12 Batch loss: 0.199173 Batch F1: 0.13333333333333336
Train Avg Loss  130: 0.225528

Train Avg F1  130: 0.1312121212121212

Val Avg Loss  130: 0.218796

Val Avg F1  130:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 131
--------------------------------------------------------------
Epoch:  131        1 Batch loss: 0.198515 Batch F1: 0.0
Epoch:  131        2 Batch loss: 0.231174 Batch F1: 0.0
Epoch:  131        3 Batch loss: 0.200564 Batch F1: 0.0
Epoch:  131        4 Batch loss: 0.166551 Batch F1: 0.0
Epoch:  131        5 Batch loss: 0.235287 Batch F1: 0.0
Epoch:  131        6 Batch loss: 0.249716 Batch F1: 0.0
Epoch:  131        7 Batch loss: 0.234989 Batch F1: 0.0
Epoch:  131        8 Batch loss: 0.255238 Batch F1: 0.0
Epoch:  131        9 Batch loss: 0.217198 Batch F1: 0.0
Epoch:  131       10 Batch loss: 0.218350 Batch F1: 0.0
Epoch:  131       11 Batch loss: 0.261026 Batch F1: 0.08333333333333334
Epoch:  131       12 Batch loss: 0.237010 Batch F1: 0.25
Train Avg Loss  131: 0.225468

Train Avg F1  131: 0.02777777777777778

Val Avg Loss  131: 0.233925

Val Avg F1  131:  0.36311389759665624

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 132
--------------------------------------------------------------
Epoch:  132        1 Batch loss: 0.238244 Batch F1: 0.22222222222222224
Epoch:  132        2 Batch loss: 0.240096 Batch F1: 0.30303030303030304
Epoch:  132        3 Batch loss: 0.243932 Batch F1: 0.3703703703703704
Epoch:  132        4 Batch loss: 0.250662 Batch F1: 0.0
Epoch:  132        5 Batch loss: 0.214299 Batch F1: 0.0
Epoch:  132        6 Batch loss: 0.218166 Batch F1: 0.0
Epoch:  132        7 Batch loss: 0.236478 Batch F1: 0.0
Epoch:  132        8 Batch loss: 0.189633 Batch F1: 0.0
Epoch:  132        9 Batch loss: 0.233985 Batch F1: 0.0
Epoch:  132       10 Batch loss: 0.212280 Batch F1: 0.0
Epoch:  132       11 Batch loss: 0.245610 Batch F1: 0.0
Epoch:  132       12 Batch loss: 0.197945 Batch F1: 0.0
Train Avg Loss  132: 0.226777

Train Avg F1  132: 0.07463524130190798

Val Avg Loss  132: 0.217580

Val Avg F1  132:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 133
--------------------------------------------------------------
Epoch:  133        1 Batch loss: 0.192717 Batch F1: 0.0
Epoch:  133        2 Batch loss: 0.262870 Batch F1: 0.0
Epoch:  133        3 Batch loss: 0.215146 Batch F1: 0.0
Epoch:  133        4 Batch loss: 0.227997 Batch F1: 0.0
Epoch:  133        5 Batch loss: 0.210982 Batch F1: 0.3333333333333333
Epoch:  133        6 Batch loss: 0.205254 Batch F1: 0.11764705882352941
Epoch:  133        7 Batch loss: 0.221897 Batch F1: 0.09090909090909091
Epoch:  133        8 Batch loss: 0.222929 Batch F1: 0.42857142857142855
Epoch:  133        9 Batch loss: 0.216667 Batch F1: 0.3846153846153846
Epoch:  133       10 Batch loss: 0.241124 Batch F1: 0.16
Epoch:  133       11 Batch loss: 0.224354 Batch F1: 0.30769230769230765
Epoch:  133       12 Batch loss: 0.255321 Batch F1: 0.38095238095238093
Train Avg Loss  133: 0.224772

Train Avg F1  133: 0.18364341540812126

Val Avg Loss  133: 0.218462

Val Avg F1  133:  0.25166666666666665

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 134
--------------------------------------------------------------
Epoch:  134        1 Batch loss: 0.206058 Batch F1: 0.2105263157894737
Epoch:  134        2 Batch loss: 0.251297 Batch F1: 0.0
Epoch:  134        3 Batch loss: 0.203714 Batch F1: 0.0
Epoch:  134        4 Batch loss: 0.230537 Batch F1: 0.0
Epoch:  134        5 Batch loss: 0.261475 Batch F1: 0.0
Epoch:  134        6 Batch loss: 0.210586 Batch F1: 0.0
Epoch:  134        7 Batch loss: 0.205127 Batch F1: 0.0
Epoch:  134        8 Batch loss: 0.207606 Batch F1: 0.0
Epoch:  134        9 Batch loss: 0.239554 Batch F1: 0.0
Epoch:  134       10 Batch loss: 0.221041 Batch F1: 0.0
Epoch:  134       11 Batch loss: 0.234279 Batch F1: 0.0
Epoch:  134       12 Batch loss: 0.220851 Batch F1: 0.21052631578947367
Train Avg Loss  134: 0.224344

Train Avg F1  134: 0.03508771929824561

Val Avg Loss  134: 0.220610

Val Avg F1  134:  0.25624303232998885

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 135
--------------------------------------------------------------
Epoch:  135        1 Batch loss: 0.204909 Batch F1: 0.3478260869565218
Epoch:  135        2 Batch loss: 0.209495 Batch F1: 0.2962962962962963
Epoch:  135        3 Batch loss: 0.215321 Batch F1: 0.3846153846153846
Epoch:  135        4 Batch loss: 0.227869 Batch F1: 0.23076923076923078
Epoch:  135        5 Batch loss: 0.191027 Batch F1: 0.25
Epoch:  135        6 Batch loss: 0.239671 Batch F1: 0.4
Epoch:  135        7 Batch loss: 0.228122 Batch F1: 0.4285714285714285
Epoch:  135        8 Batch loss: 0.235648 Batch F1: 0.21052631578947367
Epoch:  135        9 Batch loss: 0.230669 Batch F1: 0.0
Epoch:  135       10 Batch loss: 0.256537 Batch F1: 0.0
Epoch:  135       11 Batch loss: 0.249093 Batch F1: 0.0
Epoch:  135       12 Batch loss: 0.209848 Batch F1: 0.0
Train Avg Loss  135: 0.224851

Train Avg F1  135: 0.21238372858319465

Val Avg Loss  135: 0.218992

Val Avg F1  135:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 136
--------------------------------------------------------------
Epoch:  136        1 Batch loss: 0.253130 Batch F1: 0.0
Epoch:  136        2 Batch loss: 0.212400 Batch F1: 0.11764705882352941
Epoch:  136        3 Batch loss: 0.211743 Batch F1: 0.10526315789473684
Epoch:  136        4 Batch loss: 0.215232 Batch F1: 0.0
Epoch:  136        5 Batch loss: 0.213268 Batch F1: 0.0
Epoch:  136        6 Batch loss: 0.254031 Batch F1: 0.0
Epoch:  136        7 Batch loss: 0.217815 Batch F1: 0.0
Epoch:  136        8 Batch loss: 0.256852 Batch F1: 0.0
Epoch:  136        9 Batch loss: 0.196089 Batch F1: 0.2222222222222222
Epoch:  136       10 Batch loss: 0.218658 Batch F1: 0.0
Epoch:  136       11 Batch loss: 0.208743 Batch F1: 0.0
Epoch:  136       12 Batch loss: 0.233512 Batch F1: 0.4347826086956522
Train Avg Loss  136: 0.224289

Train Avg F1  136: 0.07332625396967839

Val Avg Loss  136: 0.219569

Val Avg F1  136:  0.23681318681318683

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 137
--------------------------------------------------------------
Epoch:  137        1 Batch loss: 0.259957 Batch F1: 0.16
Epoch:  137        2 Batch loss: 0.218779 Batch F1: 0.18181818181818182
Epoch:  137        3 Batch loss: 0.212752 Batch F1: 0.4516129032258065
Epoch:  137        4 Batch loss: 0.235482 Batch F1: 0.21052631578947364
Epoch:  137        5 Batch loss: 0.223675 Batch F1: 0.24
Epoch:  137        6 Batch loss: 0.212101 Batch F1: 0.2727272727272727
Epoch:  137        7 Batch loss: 0.237202 Batch F1: 0.08333333333333334
Epoch:  137        8 Batch loss: 0.208596 Batch F1: 0.0
Epoch:  137        9 Batch loss: 0.222536 Batch F1: 0.0
Epoch:  137       10 Batch loss: 0.199327 Batch F1: 0.5217391304347825
Epoch:  137       11 Batch loss: 0.238211 Batch F1: 0.2608695652173913
Epoch:  137       12 Batch loss: 0.212788 Batch F1: 0.4
Train Avg Loss  137: 0.223451

Train Avg F1  137: 0.2318855585455201

Val Avg Loss  137: 0.218873

Val Avg F1  137:  0.2660119047619047

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 138
--------------------------------------------------------------
Epoch:  138        1 Batch loss: 0.185385 Batch F1: 0.39999999999999997
Epoch:  138        2 Batch loss: 0.244367 Batch F1: 0.3448275862068966
Epoch:  138        3 Batch loss: 0.206796 Batch F1: 0.4210526315789474
Epoch:  138        4 Batch loss: 0.240785 Batch F1: 0.0
Epoch:  138        5 Batch loss: 0.254400 Batch F1: 0.08333333333333333
Epoch:  138        6 Batch loss: 0.218794 Batch F1: 0.2727272727272727
Epoch:  138        7 Batch loss: 0.224720 Batch F1: 0.0
Epoch:  138        8 Batch loss: 0.240033 Batch F1: 0.41379310344827586
Epoch:  138        9 Batch loss: 0.221998 Batch F1: 0.21052631578947367
Epoch:  138       10 Batch loss: 0.210164 Batch F1: 0.28571428571428575
Epoch:  138       11 Batch loss: 0.219023 Batch F1: 0.48275862068965514
Epoch:  138       12 Batch loss: 0.223403 Batch F1: 0.2857142857142857
Train Avg Loss  138: 0.224156

Train Avg F1  138: 0.2667039529335355

Val Avg Loss  138: 0.218748

Val Avg F1  138:  0.2588605351763246

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 139
--------------------------------------------------------------
Epoch:  139        1 Batch loss: 0.231544 Batch F1: 0.23999999999999996
Epoch:  139        2 Batch loss: 0.220413 Batch F1: 0.2857142857142857
Epoch:  139        3 Batch loss: 0.262060 Batch F1: 0.21428571428571427
Epoch:  139        4 Batch loss: 0.231797 Batch F1: 0.37037037037037035
Epoch:  139        5 Batch loss: 0.215690 Batch F1: 0.31999999999999995
Epoch:  139        6 Batch loss: 0.188713 Batch F1: 0.6153846153846154
Epoch:  139        7 Batch loss: 0.253235 Batch F1: 0.29411764705882354
Epoch:  139        8 Batch loss: 0.210472 Batch F1: 0.1818181818181818
Epoch:  139        9 Batch loss: 0.213038 Batch F1: 0.11764705882352941
Epoch:  139       10 Batch loss: 0.253380 Batch F1: 0.15384615384615383
Epoch:  139       11 Batch loss: 0.213472 Batch F1: 0.0
Epoch:  139       12 Batch loss: 0.191187 Batch F1: 0.0
Train Avg Loss  139: 0.223750

Train Avg F1  139: 0.23276533560847282

Val Avg Loss  139: 0.217901

Val Avg F1  139:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 140
--------------------------------------------------------------
Epoch:  140        1 Batch loss: 0.214650 Batch F1: 0.0
Epoch:  140        2 Batch loss: 0.209713 Batch F1: 0.0
Epoch:  140        3 Batch loss: 0.235397 Batch F1: 0.0
Epoch:  140        4 Batch loss: 0.241786 Batch F1: 0.0
Epoch:  140        5 Batch loss: 0.230331 Batch F1: 0.0
Epoch:  140        6 Batch loss: 0.198187 Batch F1: 0.11764705882352942
Epoch:  140        7 Batch loss: 0.234104 Batch F1: 0.08333333333333334
Epoch:  140        8 Batch loss: 0.208584 Batch F1: 0.10526315789473684
Epoch:  140        9 Batch loss: 0.195223 Batch F1: 0.0
Epoch:  140       10 Batch loss: 0.248134 Batch F1: 0.0
Epoch:  140       11 Batch loss: 0.257164 Batch F1: 0.0909090909090909
Epoch:  140       12 Batch loss: 0.217099 Batch F1: 0.0
Train Avg Loss  140: 0.224198

Train Avg F1  140: 0.03309605341339087

Val Avg Loss  140: 0.217532

Val Avg F1  140:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 141
--------------------------------------------------------------
Epoch:  141        1 Batch loss: 0.205301 Batch F1: 0.0
Epoch:  141        2 Batch loss: 0.198756 Batch F1: 0.0
Epoch:  141        3 Batch loss: 0.225966 Batch F1: 0.08333333333333333
Epoch:  141        4 Batch loss: 0.242788 Batch F1: 0.0
Epoch:  141        5 Batch loss: 0.223607 Batch F1: 0.09090909090909091
Epoch:  141        6 Batch loss: 0.189141 Batch F1: 0.0
Epoch:  141        7 Batch loss: 0.255389 Batch F1: 0.0
Epoch:  141        8 Batch loss: 0.246539 Batch F1: 0.23076923076923075
Epoch:  141        9 Batch loss: 0.216036 Batch F1: 0.3333333333333333
Epoch:  141       10 Batch loss: 0.224564 Batch F1: 0.5806451612903226
Epoch:  141       11 Batch loss: 0.192805 Batch F1: 0.3157894736842105
Epoch:  141       12 Batch loss: 0.252860 Batch F1: 0.16
Train Avg Loss  141: 0.222813

Train Avg F1  141: 0.14956496860996013

Val Avg Loss  141: 0.220451

Val Avg F1  141:  0.2437265037593985

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 142
--------------------------------------------------------------
Epoch:  142        1 Batch loss: 0.205931 Batch F1: 0.1818181818181818
Epoch:  142        2 Batch loss: 0.217522 Batch F1: 0.27272727272727276
Epoch:  142        3 Batch loss: 0.242485 Batch F1: 0.30303030303030304
Epoch:  142        4 Batch loss: 0.256832 Batch F1: 0.4
Epoch:  142        5 Batch loss: 0.243352 Batch F1: 0.27586206896551724
Epoch:  142        6 Batch loss: 0.191832 Batch F1: 0.6666666666666667
Epoch:  142        7 Batch loss: 0.205989 Batch F1: 0.4444444444444445
Epoch:  142        8 Batch loss: 0.226675 Batch F1: 0.0
Epoch:  142        9 Batch loss: 0.224945 Batch F1: 0.0
Epoch:  142       10 Batch loss: 0.244714 Batch F1: 0.0
Epoch:  142       11 Batch loss: 0.220005 Batch F1: 0.0
Epoch:  142       12 Batch loss: 0.227091 Batch F1: 0.0
Train Avg Loss  142: 0.225614

Train Avg F1  142: 0.21204574480436555

Val Avg Loss  142: 0.218254

Val Avg F1  142:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 143
--------------------------------------------------------------
Epoch:  143        1 Batch loss: 0.205588 Batch F1: 0.0
Epoch:  143        2 Batch loss: 0.219322 Batch F1: 0.0
Epoch:  143        3 Batch loss: 0.215454 Batch F1: 0.33333333333333337
Epoch:  143        4 Batch loss: 0.228012 Batch F1: 0.31999999999999995
Epoch:  143        5 Batch loss: 0.208884 Batch F1: 0.5384615384615384
Epoch:  143        6 Batch loss: 0.253031 Batch F1: 0.27586206896551724
Epoch:  143        7 Batch loss: 0.218771 Batch F1: 0.48
Epoch:  143        8 Batch loss: 0.217538 Batch F1: 0.32
Epoch:  143        9 Batch loss: 0.231434 Batch F1: 0.39999999999999997
Epoch:  143       10 Batch loss: 0.238410 Batch F1: 0.24
Epoch:  143       11 Batch loss: 0.229897 Batch F1: 0.4
Epoch:  143       12 Batch loss: 0.213880 Batch F1: 0.0
Train Avg Loss  143: 0.223352

Train Avg F1  143: 0.27563807839669907

Val Avg Loss  143: 0.217034

Val Avg F1  143:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 144
--------------------------------------------------------------
Epoch:  144        1 Batch loss: 0.239602 Batch F1: 0.0
Epoch:  144        2 Batch loss: 0.200470 Batch F1: 0.0
Epoch:  144        3 Batch loss: 0.218327 Batch F1: 0.1111111111111111
Epoch:  144        4 Batch loss: 0.219057 Batch F1: 0.0
Epoch:  144        5 Batch loss: 0.245555 Batch F1: 0.0
Epoch:  144        6 Batch loss: 0.202229 Batch F1: 0.24
Epoch:  144        7 Batch loss: 0.178016 Batch F1: 0.37499999999999994
Epoch:  144        8 Batch loss: 0.223532 Batch F1: 0.0
Epoch:  144        9 Batch loss: 0.245935 Batch F1: 0.0
Epoch:  144       10 Batch loss: 0.252337 Batch F1: 0.0
Epoch:  144       11 Batch loss: 0.209992 Batch F1: 0.0
Epoch:  144       12 Batch loss: 0.266151 Batch F1: 0.0
Train Avg Loss  144: 0.225100

Train Avg F1  144: 0.060509259259259256

Val Avg Loss  144: 0.218431

Val Avg F1  144:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 145
--------------------------------------------------------------
Epoch:  145        1 Batch loss: 0.235412 Batch F1: 0.0
Epoch:  145        2 Batch loss: 0.224685 Batch F1: 0.0
Epoch:  145        3 Batch loss: 0.249952 Batch F1: 0.0
Epoch:  145        4 Batch loss: 0.214118 Batch F1: 0.46153846153846156
Epoch:  145        5 Batch loss: 0.229188 Batch F1: 0.0
Epoch:  145        6 Batch loss: 0.233052 Batch F1: 0.09523809523809523
Epoch:  145        7 Batch loss: 0.236680 Batch F1: 0.0
Epoch:  145        8 Batch loss: 0.244848 Batch F1: 0.0
Epoch:  145        9 Batch loss: 0.202116 Batch F1: 0.0
Epoch:  145       10 Batch loss: 0.245823 Batch F1: 0.0
Epoch:  145       11 Batch loss: 0.187145 Batch F1: 0.0
Epoch:  145       12 Batch loss: 0.204585 Batch F1: 0.0
Train Avg Loss  145: 0.225634

Train Avg F1  145: 0.0463980463980464

Val Avg Loss  145: 0.217614

Val Avg F1  145:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 146
--------------------------------------------------------------
Epoch:  146        1 Batch loss: 0.216936 Batch F1: 0.0
Epoch:  146        2 Batch loss: 0.227041 Batch F1: 0.0
Epoch:  146        3 Batch loss: 0.238853 Batch F1: 0.0
Epoch:  146        4 Batch loss: 0.212218 Batch F1: 0.0
Epoch:  146        5 Batch loss: 0.196004 Batch F1: 0.0
Epoch:  146        6 Batch loss: 0.226350 Batch F1: 0.0
Epoch:  146        7 Batch loss: 0.277555 Batch F1: 0.0
Epoch:  146        8 Batch loss: 0.234356 Batch F1: 0.0
Epoch:  146        9 Batch loss: 0.199673 Batch F1: 0.0
Epoch:  146       10 Batch loss: 0.229227 Batch F1: 0.2
Epoch:  146       11 Batch loss: 0.224664 Batch F1: 0.3448275862068965
Epoch:  146       12 Batch loss: 0.219453 Batch F1: 0.5217391304347825
Train Avg Loss  146: 0.225194

Train Avg F1  146: 0.08888055972013992

Val Avg Loss  146: 0.220356

Val Avg F1  146:  0.24125874125874125

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 147
--------------------------------------------------------------
Epoch:  147        1 Batch loss: 0.238049 Batch F1: 0.375
Epoch:  147        2 Batch loss: 0.237835 Batch F1: 0.16000000000000003
Epoch:  147        3 Batch loss: 0.248985 Batch F1: 0.36363636363636365
Epoch:  147        4 Batch loss: 0.203945 Batch F1: 0.606060606060606
Epoch:  147        5 Batch loss: 0.196223 Batch F1: 0.6363636363636364
Epoch:  147        6 Batch loss: 0.226625 Batch F1: 0.30769230769230765
Epoch:  147        7 Batch loss: 0.237832 Batch F1: 0.0
Epoch:  147        8 Batch loss: 0.209357 Batch F1: 0.0
Epoch:  147        9 Batch loss: 0.238025 Batch F1: 0.0
Epoch:  147       10 Batch loss: 0.241449 Batch F1: 0.0
Epoch:  147       11 Batch loss: 0.234778 Batch F1: 0.0
Epoch:  147       12 Batch loss: 0.185350 Batch F1: 0.0
Train Avg Loss  147: 0.224871

Train Avg F1  147: 0.2040627428127428

Val Avg Loss  147: 0.218704

Val Avg F1  147:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 148
--------------------------------------------------------------
Epoch:  148        1 Batch loss: 0.238539 Batch F1: 0.09523809523809523
Epoch:  148        2 Batch loss: 0.224581 Batch F1: 0.0
Epoch:  148        3 Batch loss: 0.237400 Batch F1: 0.0
Epoch:  148        4 Batch loss: 0.224275 Batch F1: 0.0
Epoch:  148        5 Batch loss: 0.221959 Batch F1: 0.0
Epoch:  148        6 Batch loss: 0.210152 Batch F1: 0.0
Epoch:  148        7 Batch loss: 0.255281 Batch F1: 0.0
Epoch:  148        8 Batch loss: 0.231424 Batch F1: 0.0
Epoch:  148        9 Batch loss: 0.217838 Batch F1: 0.0
Epoch:  148       10 Batch loss: 0.211572 Batch F1: 0.09999999999999999
Epoch:  148       11 Batch loss: 0.225302 Batch F1: 0.0
Epoch:  148       12 Batch loss: 0.202951 Batch F1: 0.0
Train Avg Loss  148: 0.225106

Train Avg F1  148: 0.016269841269841268

Val Avg Loss  148: 0.218170

Val Avg F1  148:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 149
--------------------------------------------------------------
Epoch:  149        1 Batch loss: 0.202906 Batch F1: 0.0
Epoch:  149        2 Batch loss: 0.218924 Batch F1: 0.0
Epoch:  149        3 Batch loss: 0.213474 Batch F1: 0.0
Epoch:  149        4 Batch loss: 0.264767 Batch F1: 0.0
Epoch:  149        5 Batch loss: 0.237740 Batch F1: 0.0
Epoch:  149        6 Batch loss: 0.249071 Batch F1: 0.0
Epoch:  149        7 Batch loss: 0.221798 Batch F1: 0.0
Epoch:  149        8 Batch loss: 0.219445 Batch F1: 0.2
Epoch:  149        9 Batch loss: 0.201256 Batch F1: 0.3333333333333333
Epoch:  149       10 Batch loss: 0.215116 Batch F1: 0.34782608695652173
Epoch:  149       11 Batch loss: 0.220325 Batch F1: 0.32
Epoch:  149       12 Batch loss: 0.235022 Batch F1: 0.27272727272727276
Train Avg Loss  149: 0.224987

Train Avg F1  149: 0.12282389108476065

Val Avg Loss  149: 0.219564

Val Avg F1  149:  0.25527201842991315

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 150
--------------------------------------------------------------
Epoch:  150        1 Batch loss: 0.212845 Batch F1: 0.3333333333333333
Epoch:  150        2 Batch loss: 0.200400 Batch F1: 0.3636363636363636
Epoch:  150        3 Batch loss: 0.214155 Batch F1: 0.2857142857142857
Epoch:  150        4 Batch loss: 0.230071 Batch F1: 0.0
Epoch:  150        5 Batch loss: 0.239848 Batch F1: 0.0
Epoch:  150        6 Batch loss: 0.244293 Batch F1: 0.0
Epoch:  150        7 Batch loss: 0.219451 Batch F1: 0.0
Epoch:  150        8 Batch loss: 0.241846 Batch F1: 0.24000000000000002
Epoch:  150        9 Batch loss: 0.223346 Batch F1: 0.21052631578947364
Epoch:  150       10 Batch loss: 0.202252 Batch F1: 0.36363636363636365
Epoch:  150       11 Batch loss: 0.228282 Batch F1: 0.44444444444444436
Epoch:  150       12 Batch loss: 0.245252 Batch F1: 0.32
Train Avg Loss  150: 0.225170

Train Avg F1  150: 0.21344092554618865

Val Avg Loss  150: 0.219585

Val Avg F1  150:  0.26044795783926217

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 151
--------------------------------------------------------------
Epoch:  151        1 Batch loss: 0.206924 Batch F1: 0.1
Epoch:  151        2 Batch loss: 0.231434 Batch F1: 0.3846153846153846
Epoch:  151        3 Batch loss: 0.230583 Batch F1: 0.5000000000000001
Epoch:  151        4 Batch loss: 0.232026 Batch F1: 0.30769230769230765
Epoch:  151        5 Batch loss: 0.244855 Batch F1: 0.08695652173913045
Epoch:  151        6 Batch loss: 0.198211 Batch F1: 0.5263157894736842
Epoch:  151        7 Batch loss: 0.224825 Batch F1: 0.3076923076923077
Epoch:  151        8 Batch loss: 0.229241 Batch F1: 0.33333333333333337
Epoch:  151        9 Batch loss: 0.205150 Batch F1: 0.19047619047619047
Epoch:  151       10 Batch loss: 0.250692 Batch F1: 0.2962962962962963
Epoch:  151       11 Batch loss: 0.198646 Batch F1: 0.0
Epoch:  151       12 Batch loss: 0.239613 Batch F1: 0.0
Train Avg Loss  151: 0.224350

Train Avg F1  151: 0.25278151094321955

Val Avg Loss  151: 0.217472

Val Avg F1  151:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 152
--------------------------------------------------------------
Epoch:  152        1 Batch loss: 0.196009 Batch F1: 0.0
Epoch:  152        2 Batch loss: 0.221672 Batch F1: 0.0
Epoch:  152        3 Batch loss: 0.178141 Batch F1: 0.14285714285714288
Epoch:  152        4 Batch loss: 0.225600 Batch F1: 0.0
Epoch:  152        5 Batch loss: 0.246132 Batch F1: 0.27586206896551724
Epoch:  152        6 Batch loss: 0.235457 Batch F1: 0.4444444444444444
Epoch:  152        7 Batch loss: 0.229362 Batch F1: 0.24
Epoch:  152        8 Batch loss: 0.227310 Batch F1: 0.17391304347826086
Epoch:  152        9 Batch loss: 0.239568 Batch F1: 0.32000000000000006
Epoch:  152       10 Batch loss: 0.231701 Batch F1: 0.25
Epoch:  152       11 Batch loss: 0.205065 Batch F1: 0.4615384615384615
Epoch:  152       12 Batch loss: 0.251445 Batch F1: 0.25
Train Avg Loss  152: 0.223955

Train Avg F1  152: 0.21321793010698556

Val Avg Loss  152: 0.219474

Val Avg F1  152:  0.2569798434116275

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 153
--------------------------------------------------------------
Epoch:  153        1 Batch loss: 0.263407 Batch F1: 0.2962962962962963
Epoch:  153        2 Batch loss: 0.206806 Batch F1: 0.23529411764705882
Epoch:  153        3 Batch loss: 0.237103 Batch F1: 0.0
Epoch:  153        4 Batch loss: 0.216339 Batch F1: 0.0
Epoch:  153        5 Batch loss: 0.207942 Batch F1: 0.0
Epoch:  153        6 Batch loss: 0.230991 Batch F1: 0.0
Epoch:  153        7 Batch loss: 0.208260 Batch F1: 0.0
Epoch:  153        8 Batch loss: 0.232668 Batch F1: 0.09523809523809523
Epoch:  153        9 Batch loss: 0.229608 Batch F1: 0.0
Epoch:  153       10 Batch loss: 0.211074 Batch F1: 0.0
Epoch:  153       11 Batch loss: 0.230263 Batch F1: 0.0909090909090909
Epoch:  153       12 Batch loss: 0.209416 Batch F1: 0.0
Train Avg Loss  153: 0.223656

Train Avg F1  153: 0.05981146667421178

Val Avg Loss  153: 0.218682

Val Avg F1  153:  0.023809523809523808

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 154
--------------------------------------------------------------
Epoch:  154        1 Batch loss: 0.230247 Batch F1: 0.09523809523809523
Epoch:  154        2 Batch loss: 0.204180 Batch F1: 0.2222222222222222
Epoch:  154        3 Batch loss: 0.239366 Batch F1: 0.37037037037037035
Epoch:  154        4 Batch loss: 0.236356 Batch F1: 0.2608695652173913
Epoch:  154        5 Batch loss: 0.244822 Batch F1: 0.3846153846153846
Epoch:  154        6 Batch loss: 0.207979 Batch F1: 0.34782608695652173
Epoch:  154        7 Batch loss: 0.252069 Batch F1: 0.3529411764705882
Epoch:  154        8 Batch loss: 0.210180 Batch F1: 0.09090909090909091
Epoch:  154        9 Batch loss: 0.202781 Batch F1: 0.3
Epoch:  154       10 Batch loss: 0.223490 Batch F1: 0.3076923076923077
Epoch:  154       11 Batch loss: 0.203134 Batch F1: 0.2727272727272727
Epoch:  154       12 Batch loss: 0.218061 Batch F1: 0.4799999999999999
Train Avg Loss  154: 0.222722

Train Avg F1  154: 0.29045096436827034

Val Avg Loss  154: 0.219751

Val Avg F1  154:  0.22142225590501452

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 155
--------------------------------------------------------------
Epoch:  155        1 Batch loss: 0.197000 Batch F1: 0.36363636363636365
Epoch:  155        2 Batch loss: 0.231934 Batch F1: 0.25
Epoch:  155        3 Batch loss: 0.198175 Batch F1: 0.1739130434782609
Epoch:  155        4 Batch loss: 0.215830 Batch F1: 0.3333333333333333
Epoch:  155        5 Batch loss: 0.226779 Batch F1: 0.25
Epoch:  155        6 Batch loss: 0.273263 Batch F1: 0.19999999999999998
Epoch:  155        7 Batch loss: 0.237899 Batch F1: 0.4
Epoch:  155        8 Batch loss: 0.213601 Batch F1: 0.3448275862068966
Epoch:  155        9 Batch loss: 0.226600 Batch F1: 0.3703703703703704
Epoch:  155       10 Batch loss: 0.233168 Batch F1: 0.5000000000000001
Epoch:  155       11 Batch loss: 0.207334 Batch F1: 0.3
Epoch:  155       12 Batch loss: 0.202931 Batch F1: 0.23529411764705882
Train Avg Loss  155: 0.222043

Train Avg F1  155: 0.31011456788935693

Val Avg Loss  155: 0.218210

Val Avg F1  155:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 156
--------------------------------------------------------------
Epoch:  156        1 Batch loss: 0.199153 Batch F1: 0.0
Epoch:  156        2 Batch loss: 0.247401 Batch F1: 0.0
Epoch:  156        3 Batch loss: 0.197365 Batch F1: 0.0
Epoch:  156        4 Batch loss: 0.242285 Batch F1: 0.0
Epoch:  156        5 Batch loss: 0.255133 Batch F1: 0.0
Epoch:  156        6 Batch loss: 0.255582 Batch F1: 0.15384615384615385
Epoch:  156        7 Batch loss: 0.194568 Batch F1: 0.2222222222222222
Epoch:  156        8 Batch loss: 0.191676 Batch F1: 0.56
Epoch:  156        9 Batch loss: 0.204399 Batch F1: 0.19047619047619047
Epoch:  156       10 Batch loss: 0.221713 Batch F1: 0.46153846153846156
Epoch:  156       11 Batch loss: 0.247816 Batch F1: 0.16
Epoch:  156       12 Batch loss: 0.229392 Batch F1: 0.18181818181818182
Train Avg Loss  156: 0.223874

Train Avg F1  156: 0.16082510082510082

Val Avg Loss  156: 0.219144

Val Avg F1  156:  0.25757575757575757

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 157
--------------------------------------------------------------
Epoch:  157        1 Batch loss: 0.240640 Batch F1: 0.3529411764705882
Epoch:  157        2 Batch loss: 0.237421 Batch F1: 0.3076923076923077
Epoch:  157        3 Batch loss: 0.231778 Batch F1: 0.41379310344827586
Epoch:  157        4 Batch loss: 0.248368 Batch F1: 0.24242424242424243
Epoch:  157        5 Batch loss: 0.180009 Batch F1: 0.4
Epoch:  157        6 Batch loss: 0.214889 Batch F1: 0.0
Epoch:  157        7 Batch loss: 0.245367 Batch F1: 0.0
Epoch:  157        8 Batch loss: 0.206665 Batch F1: 0.1
Epoch:  157        9 Batch loss: 0.228603 Batch F1: 0.08695652173913042
Epoch:  157       10 Batch loss: 0.226134 Batch F1: 0.4166666666666667
Epoch:  157       11 Batch loss: 0.235522 Batch F1: 0.25
Epoch:  157       12 Batch loss: 0.204000 Batch F1: 0.25
Train Avg Loss  157: 0.224950

Train Avg F1  157: 0.2350395015367676

Val Avg Loss  157: 0.218564

Val Avg F1  157:  0.267259056732741

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 158
--------------------------------------------------------------
Epoch:  158        1 Batch loss: 0.230908 Batch F1: 0.23076923076923075
Epoch:  158        2 Batch loss: 0.245401 Batch F1: 0.35714285714285715
Epoch:  158        3 Batch loss: 0.229696 Batch F1: 0.08695652173913045
Epoch:  158        4 Batch loss: 0.206955 Batch F1: 0.10526315789473684
Epoch:  158        5 Batch loss: 0.226051 Batch F1: 0.0
Epoch:  158        6 Batch loss: 0.206289 Batch F1: 0.1
Epoch:  158        7 Batch loss: 0.232030 Batch F1: 0.0
Epoch:  158        8 Batch loss: 0.191824 Batch F1: 0.0
Epoch:  158        9 Batch loss: 0.206514 Batch F1: 0.0
Epoch:  158       10 Batch loss: 0.233125 Batch F1: 0.0
Epoch:  158       11 Batch loss: 0.254481 Batch F1: 0.0
Epoch:  158       12 Batch loss: 0.224437 Batch F1: 0.0
Train Avg Loss  158: 0.223976

Train Avg F1  158: 0.07334431396216294

Val Avg Loss  158: 0.218180

Val Avg F1  158:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 159
--------------------------------------------------------------
Epoch:  159        1 Batch loss: 0.204294 Batch F1: 0.1
Epoch:  159        2 Batch loss: 0.204476 Batch F1: 0.0
Epoch:  159        3 Batch loss: 0.218010 Batch F1: 0.3333333333333333
Epoch:  159        4 Batch loss: 0.235935 Batch F1: 0.18181818181818182
Epoch:  159        5 Batch loss: 0.155756 Batch F1: 0.5333333333333333
Epoch:  159        6 Batch loss: 0.220760 Batch F1: 0.30769230769230765
Epoch:  159        7 Batch loss: 0.208286 Batch F1: 0.0
Epoch:  159        8 Batch loss: 0.272150 Batch F1: 0.0
Epoch:  159        9 Batch loss: 0.253080 Batch F1: 0.0
Epoch:  159       10 Batch loss: 0.248223 Batch F1: 0.22222222222222218
Epoch:  159       11 Batch loss: 0.231653 Batch F1: 0.2962962962962963
Epoch:  159       12 Batch loss: 0.237004 Batch F1: 0.2857142857142857
Train Avg Loss  159: 0.224136

Train Avg F1  159: 0.18836749670083

Val Avg Loss  159: 0.222820

Val Avg F1  159:  0.34282051282051285

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 160
--------------------------------------------------------------
Epoch:  160        1 Batch loss: 0.232248 Batch F1: 0.35714285714285715
Epoch:  160        2 Batch loss: 0.229275 Batch F1: 0.41379310344827586
Epoch:  160        3 Batch loss: 0.231702 Batch F1: 0.2857142857142857
Epoch:  160        4 Batch loss: 0.229796 Batch F1: 0.32
Epoch:  160        5 Batch loss: 0.204629 Batch F1: 0.3809523809523809
Epoch:  160        6 Batch loss: 0.227219 Batch F1: 0.0
Epoch:  160        7 Batch loss: 0.242572 Batch F1: 0.0
Epoch:  160        8 Batch loss: 0.212326 Batch F1: 0.09999999999999999
Epoch:  160        9 Batch loss: 0.222610 Batch F1: 0.0
Epoch:  160       10 Batch loss: 0.249296 Batch F1: 0.0
Epoch:  160       11 Batch loss: 0.178411 Batch F1: 0.0
Epoch:  160       12 Batch loss: 0.228350 Batch F1: 0.28571428571428575
Train Avg Loss  160: 0.224036

Train Avg F1  160: 0.1786097427476738

Val Avg Loss  160: 0.218698

Val Avg F1  160:  0.22523809523809524

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 161
--------------------------------------------------------------
Epoch:  161        1 Batch loss: 0.202733 Batch F1: 0.125
Epoch:  161        2 Batch loss: 0.233179 Batch F1: 0.0
Epoch:  161        3 Batch loss: 0.190583 Batch F1: 0.0
Epoch:  161        4 Batch loss: 0.239062 Batch F1: 0.0
Epoch:  161        5 Batch loss: 0.241457 Batch F1: 0.0
Epoch:  161        6 Batch loss: 0.235598 Batch F1: 0.0
Epoch:  161        7 Batch loss: 0.195381 Batch F1: 0.0
Epoch:  161        8 Batch loss: 0.233720 Batch F1: 0.0
Epoch:  161        9 Batch loss: 0.213011 Batch F1: 0.5185185185185185
Epoch:  161       10 Batch loss: 0.227462 Batch F1: 0.2
Epoch:  161       11 Batch loss: 0.232557 Batch F1: 0.4444444444444445
Epoch:  161       12 Batch loss: 0.242877 Batch F1: 0.2727272727272727
Train Avg Loss  161: 0.223968

Train Avg F1  161: 0.13005751964085296

Val Avg Loss  161: 0.219206

Val Avg F1  161:  0.2295204795204795

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 162
--------------------------------------------------------------
Epoch:  162        1 Batch loss: 0.245052 Batch F1: 0.16666666666666669
Epoch:  162        2 Batch loss: 0.211945 Batch F1: 0.36363636363636365
Epoch:  162        3 Batch loss: 0.224434 Batch F1: 0.48484848484848486
Epoch:  162        4 Batch loss: 0.192267 Batch F1: 0.1111111111111111
Epoch:  162        5 Batch loss: 0.216734 Batch F1: 0.0
Epoch:  162        6 Batch loss: 0.276415 Batch F1: 0.20689655172413793
Epoch:  162        7 Batch loss: 0.232978 Batch F1: 0.21428571428571427
Epoch:  162        8 Batch loss: 0.210728 Batch F1: 0.31999999999999995
Epoch:  162        9 Batch loss: 0.216457 Batch F1: 0.3333333333333333
Epoch:  162       10 Batch loss: 0.216463 Batch F1: 0.3636363636363636
Epoch:  162       11 Batch loss: 0.238120 Batch F1: 0.0
Epoch:  162       12 Batch loss: 0.217054 Batch F1: 0.0
Train Avg Loss  162: 0.224887

Train Avg F1  162: 0.2137012157701813

Val Avg Loss  162: 0.218013

Val Avg F1  162:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 163
--------------------------------------------------------------
Epoch:  163        1 Batch loss: 0.234563 Batch F1: 0.0
Epoch:  163        2 Batch loss: 0.220037 Batch F1: 0.0
Epoch:  163        3 Batch loss: 0.234196 Batch F1: 0.0
Epoch:  163        4 Batch loss: 0.201941 Batch F1: 0.0
Epoch:  163        5 Batch loss: 0.218914 Batch F1: 0.0
Epoch:  163        6 Batch loss: 0.238786 Batch F1: 0.0
Epoch:  163        7 Batch loss: 0.217359 Batch F1: 0.0
Epoch:  163        8 Batch loss: 0.239162 Batch F1: 0.1
Epoch:  163        9 Batch loss: 0.193057 Batch F1: 0.0
Epoch:  163       10 Batch loss: 0.243371 Batch F1: 0.0
Epoch:  163       11 Batch loss: 0.248909 Batch F1: 0.0
Epoch:  163       12 Batch loss: 0.194379 Batch F1: 0.0
Train Avg Loss  163: 0.223723

Train Avg F1  163: 0.008333333333333333

Val Avg Loss  163: 0.218690

Val Avg F1  163:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 164
--------------------------------------------------------------
Epoch:  164        1 Batch loss: 0.237079 Batch F1: 0.0
Epoch:  164        2 Batch loss: 0.232643 Batch F1: 0.16666666666666669
Epoch:  164        3 Batch loss: 0.224306 Batch F1: 0.44444444444444436
Epoch:  164        4 Batch loss: 0.250498 Batch F1: 0.4
Epoch:  164        5 Batch loss: 0.213051 Batch F1: 0.6875
Epoch:  164        6 Batch loss: 0.199669 Batch F1: 0.41666666666666663
Epoch:  164        7 Batch loss: 0.206701 Batch F1: 0.22222222222222224
Epoch:  164        8 Batch loss: 0.228567 Batch F1: 0.0
Epoch:  164        9 Batch loss: 0.206117 Batch F1: 0.0
Epoch:  164       10 Batch loss: 0.207589 Batch F1: 0.0
Epoch:  164       11 Batch loss: 0.280116 Batch F1: 0.0
Epoch:  164       12 Batch loss: 0.210162 Batch F1: 0.25000000000000006
Train Avg Loss  164: 0.224708

Train Avg F1  164: 0.21562499999999998

Val Avg Loss  164: 0.218424

Val Avg F1  164:  0.2543879731379731

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 165
--------------------------------------------------------------
Epoch:  165        1 Batch loss: 0.238744 Batch F1: 0.4137931034482759
Epoch:  165        2 Batch loss: 0.198472 Batch F1: 0.3157894736842105
Epoch:  165        3 Batch loss: 0.220677 Batch F1: 0.2608695652173913
Epoch:  165        4 Batch loss: 0.231286 Batch F1: 0.0
Epoch:  165        5 Batch loss: 0.187406 Batch F1: 0.38095238095238093
Epoch:  165        6 Batch loss: 0.219097 Batch F1: 0.1904761904761905
Epoch:  165        7 Batch loss: 0.230230 Batch F1: 0.25
Epoch:  165        8 Batch loss: 0.253094 Batch F1: 0.0
Epoch:  165        9 Batch loss: 0.220961 Batch F1: 0.10526315789473684
Epoch:  165       10 Batch loss: 0.208246 Batch F1: 0.22222222222222224
Epoch:  165       11 Batch loss: 0.211608 Batch F1: 0.09090909090909091
Epoch:  165       12 Batch loss: 0.273176 Batch F1: 0.0
Train Avg Loss  165: 0.224416

Train Avg F1  165: 0.18585626540037492

Val Avg Loss  165: 0.217736

Val Avg F1  165:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 166
--------------------------------------------------------------
Epoch:  166        1 Batch loss: 0.204208 Batch F1: 0.0
Epoch:  166        2 Batch loss: 0.234086 Batch F1: 0.10526315789473684
Epoch:  166        3 Batch loss: 0.200615 Batch F1: 0.2
Epoch:  166        4 Batch loss: 0.263778 Batch F1: 0.3125
Epoch:  166        5 Batch loss: 0.225991 Batch F1: 0.08695652173913043
Epoch:  166        6 Batch loss: 0.250776 Batch F1: 0.25
Epoch:  166        7 Batch loss: 0.201539 Batch F1: 0.5185185185185185
Epoch:  166        8 Batch loss: 0.227156 Batch F1: 0.5454545454545454
Epoch:  166        9 Batch loss: 0.233462 Batch F1: 0.4285714285714285
Epoch:  166       10 Batch loss: 0.197961 Batch F1: 0.56
Epoch:  166       11 Batch loss: 0.218016 Batch F1: 0.4
Epoch:  166       12 Batch loss: 0.222035 Batch F1: 0.3
Train Avg Loss  166: 0.223302

Train Avg F1  166: 0.30893868101486327

Val Avg Loss  166: 0.217534

Val Avg F1  166:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 167
--------------------------------------------------------------
Epoch:  167        1 Batch loss: 0.206872 Batch F1: 0.0
Epoch:  167        2 Batch loss: 0.238368 Batch F1: 0.0
Epoch:  167        3 Batch loss: 0.231036 Batch F1: 0.0
Epoch:  167        4 Batch loss: 0.259106 Batch F1: 0.0
Epoch:  167        5 Batch loss: 0.240778 Batch F1: 0.0
Epoch:  167        6 Batch loss: 0.205575 Batch F1: 0.0
Epoch:  167        7 Batch loss: 0.214777 Batch F1: 0.0
Epoch:  167        8 Batch loss: 0.225939 Batch F1: 0.0
Epoch:  167        9 Batch loss: 0.229322 Batch F1: 0.0
Epoch:  167       10 Batch loss: 0.220813 Batch F1: 0.0
Epoch:  167       11 Batch loss: 0.208637 Batch F1: 0.0
Epoch:  167       12 Batch loss: 0.235360 Batch F1: 0.0
Train Avg Loss  167: 0.226382

Train Avg F1  167: 0.0

Val Avg Loss  167: 0.217598

Val Avg F1  167:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 168
--------------------------------------------------------------
Epoch:  168        1 Batch loss: 0.227159 Batch F1: 0.0
Epoch:  168        2 Batch loss: 0.237921 Batch F1: 0.0
Epoch:  168        3 Batch loss: 0.232521 Batch F1: 0.1111111111111111
Epoch:  168        4 Batch loss: 0.209614 Batch F1: 0.2608695652173913
Epoch:  168        5 Batch loss: 0.233825 Batch F1: 0.22222222222222224
Epoch:  168        6 Batch loss: 0.195171 Batch F1: 0.56
Epoch:  168        7 Batch loss: 0.200459 Batch F1: 0.4166666666666667
Epoch:  168        8 Batch loss: 0.261424 Batch F1: 0.08333333333333334
Epoch:  168        9 Batch loss: 0.227469 Batch F1: 0.0
Epoch:  168       10 Batch loss: 0.233028 Batch F1: 0.0
Epoch:  168       11 Batch loss: 0.247926 Batch F1: 0.0
Epoch:  168       12 Batch loss: 0.190375 Batch F1: 0.0
Train Avg Loss  168: 0.224741

Train Avg F1  168: 0.13785024154589373

Val Avg Loss  168: 0.217635

Val Avg F1  168:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 169
--------------------------------------------------------------
Epoch:  169        1 Batch loss: 0.212568 Batch F1: 0.0
Epoch:  169        2 Batch loss: 0.203311 Batch F1: 0.11764705882352941
Epoch:  169        3 Batch loss: 0.202659 Batch F1: 0.0
Epoch:  169        4 Batch loss: 0.230994 Batch F1: 0.0
Epoch:  169        5 Batch loss: 0.270677 Batch F1: 0.0
Epoch:  169        6 Batch loss: 0.183563 Batch F1: 0.0
Epoch:  169        7 Batch loss: 0.229629 Batch F1: 0.0
Epoch:  169        8 Batch loss: 0.251269 Batch F1: 0.0
Epoch:  169        9 Batch loss: 0.236168 Batch F1: 0.1904761904761905
Epoch:  169       10 Batch loss: 0.218185 Batch F1: 0.09523809523809523
Epoch:  169       11 Batch loss: 0.203965 Batch F1: 0.5333333333333333
Epoch:  169       12 Batch loss: 0.246952 Batch F1: 0.16666666666666666
Train Avg Loss  169: 0.224162

Train Avg F1  169: 0.0919467787114846

Val Avg Loss  169: 0.220877

Val Avg F1  169:  0.2631828316610925

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 170
--------------------------------------------------------------
Epoch:  170        1 Batch loss: 0.228114 Batch F1: 0.4
Epoch:  170        2 Batch loss: 0.250122 Batch F1: 0.1818181818181818
Epoch:  170        3 Batch loss: 0.218247 Batch F1: 0.41379310344827586
Epoch:  170        4 Batch loss: 0.230230 Batch F1: 0.39999999999999997
Epoch:  170        5 Batch loss: 0.203185 Batch F1: 0.2
Epoch:  170        6 Batch loss: 0.214312 Batch F1: 0.32
Epoch:  170        7 Batch loss: 0.245017 Batch F1: 0.23076923076923078
Epoch:  170        8 Batch loss: 0.223395 Batch F1: 0.4
Epoch:  170        9 Batch loss: 0.184817 Batch F1: 0.47058823529411764
Epoch:  170       10 Batch loss: 0.242689 Batch F1: 0.32000000000000006
Epoch:  170       11 Batch loss: 0.235800 Batch F1: 0.35714285714285715
Epoch:  170       12 Batch loss: 0.194724 Batch F1: 0.0
Train Avg Loss  170: 0.222554

Train Avg F1  170: 0.3078426340393886

Val Avg Loss  170: 0.218368

Val Avg F1  170:  0.26592617908407384

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 171
--------------------------------------------------------------
Epoch:  171        1 Batch loss: 0.242955 Batch F1: 0.2962962962962963
Epoch:  171        2 Batch loss: 0.246369 Batch F1: 0.30769230769230765
Epoch:  171        3 Batch loss: 0.218451 Batch F1: 0.4
Epoch:  171        4 Batch loss: 0.215872 Batch F1: 0.09999999999999999
Epoch:  171        5 Batch loss: 0.238330 Batch F1: 0.35714285714285715
Epoch:  171        6 Batch loss: 0.238392 Batch F1: 0.17391304347826084
Epoch:  171        7 Batch loss: 0.220176 Batch F1: 0.19999999999999998
Epoch:  171        8 Batch loss: 0.204948 Batch F1: 0.4
Epoch:  171        9 Batch loss: 0.198556 Batch F1: 0.2
Epoch:  171       10 Batch loss: 0.222023 Batch F1: 0.2727272727272727
Epoch:  171       11 Batch loss: 0.209088 Batch F1: 0.4
Epoch:  171       12 Batch loss: 0.223430 Batch F1: 0.3
Train Avg Loss  171: 0.223216

Train Avg F1  171: 0.28398098144474954

Val Avg Loss  171: 0.217748

Val Avg F1  171:  0.1222222222222222

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 172
--------------------------------------------------------------
Epoch:  172        1 Batch loss: 0.166132 Batch F1: 0.13333333333333333
Epoch:  172        2 Batch loss: 0.226214 Batch F1: 0.0
Epoch:  172        3 Batch loss: 0.237592 Batch F1: 0.0
Epoch:  172        4 Batch loss: 0.237394 Batch F1: 0.0
Epoch:  172        5 Batch loss: 0.231616 Batch F1: 0.08695652173913045
Epoch:  172        6 Batch loss: 0.239415 Batch F1: 0.09523809523809525
Epoch:  172        7 Batch loss: 0.216042 Batch F1: 0.2
Epoch:  172        8 Batch loss: 0.241204 Batch F1: 0.19047619047619047
Epoch:  172        9 Batch loss: 0.212677 Batch F1: 0.24999999999999997
Epoch:  172       10 Batch loss: 0.239201 Batch F1: 0.33333333333333326
Epoch:  172       11 Batch loss: 0.229006 Batch F1: 0.4666666666666667
Epoch:  172       12 Batch loss: 0.211104 Batch F1: 0.2
Train Avg Loss  172: 0.223966

Train Avg F1  172: 0.16300034506556244

Val Avg Loss  172: 0.221039

Val Avg F1  172:  0.25734913234913237

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 173
--------------------------------------------------------------
Epoch:  173        1 Batch loss: 0.209644 Batch F1: 0.42857142857142855
Epoch:  173        2 Batch loss: 0.232816 Batch F1: 0.1
Epoch:  173        3 Batch loss: 0.182020 Batch F1: 0.125
Epoch:  173        4 Batch loss: 0.237154 Batch F1: 0.0
Epoch:  173        5 Batch loss: 0.219889 Batch F1: 0.0
Epoch:  173        6 Batch loss: 0.209805 Batch F1: 0.0
Epoch:  173        7 Batch loss: 0.207402 Batch F1: 0.0
Epoch:  173        8 Batch loss: 0.236070 Batch F1: 0.0
Epoch:  173        9 Batch loss: 0.232603 Batch F1: 0.0
Epoch:  173       10 Batch loss: 0.258008 Batch F1: 0.30303030303030304
Epoch:  173       11 Batch loss: 0.223048 Batch F1: 0.42857142857142855
Epoch:  173       12 Batch loss: 0.248855 Batch F1: 0.41379310344827586
Train Avg Loss  173: 0.224776

Train Avg F1  173: 0.14991385530178633

Val Avg Loss  173: 0.221217

Val Avg F1  173:  0.2770680406549972

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 174
--------------------------------------------------------------
Epoch:  174        1 Batch loss: 0.221223 Batch F1: 0.1818181818181818
Epoch:  174        2 Batch loss: 0.223652 Batch F1: 0.0
Epoch:  174        3 Batch loss: 0.247733 Batch F1: 0.0
Epoch:  174        4 Batch loss: 0.214519 Batch F1: 0.0
Epoch:  174        5 Batch loss: 0.194672 Batch F1: 0.13333333333333336
Epoch:  174        6 Batch loss: 0.220736 Batch F1: 0.0
Epoch:  174        7 Batch loss: 0.206663 Batch F1: 0.0
Epoch:  174        8 Batch loss: 0.211329 Batch F1: 0.0
Epoch:  174        9 Batch loss: 0.256271 Batch F1: 0.0
Epoch:  174       10 Batch loss: 0.272823 Batch F1: 0.0
Epoch:  174       11 Batch loss: 0.222867 Batch F1: 0.0
Epoch:  174       12 Batch loss: 0.223735 Batch F1: 0.0
Train Avg Loss  174: 0.226352

Train Avg F1  174: 0.026262626262626265

Val Avg Loss  174: 0.219232

Val Avg F1  174:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 175
--------------------------------------------------------------
Epoch:  175        1 Batch loss: 0.230420 Batch F1: 0.0
Epoch:  175        2 Batch loss: 0.193283 Batch F1: 0.3333333333333333
Epoch:  175        3 Batch loss: 0.243804 Batch F1: 0.4137931034482759
Epoch:  175        4 Batch loss: 0.211405 Batch F1: 0.0
Epoch:  175        5 Batch loss: 0.231894 Batch F1: 0.2
Epoch:  175        6 Batch loss: 0.267105 Batch F1: 0.07407407407407407
Epoch:  175        7 Batch loss: 0.216631 Batch F1: 0.0
Epoch:  175        8 Batch loss: 0.231821 Batch F1: 0.0
Epoch:  175        9 Batch loss: 0.211182 Batch F1: 0.09090909090909091
Epoch:  175       10 Batch loss: 0.228995 Batch F1: 0.19047619047619047
Epoch:  175       11 Batch loss: 0.200364 Batch F1: 0.3
Epoch:  175       12 Batch loss: 0.223765 Batch F1: 0.3
Train Avg Loss  175: 0.224222

Train Avg F1  175: 0.1585488160200804

Val Avg Loss  175: 0.218911

Val Avg F1  175:  0.2595163457232422

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 176
--------------------------------------------------------------
Epoch:  176        1 Batch loss: 0.217969 Batch F1: 0.5806451612903226
Epoch:  176        2 Batch loss: 0.235258 Batch F1: 0.16666666666666666
Epoch:  176        3 Batch loss: 0.233457 Batch F1: 0.16666666666666669
Epoch:  176        4 Batch loss: 0.244392 Batch F1: 0.30769230769230765
Epoch:  176        5 Batch loss: 0.223659 Batch F1: 0.3636363636363636
Epoch:  176        6 Batch loss: 0.223027 Batch F1: 0.4444444444444445
Epoch:  176        7 Batch loss: 0.268318 Batch F1: 0.25
Epoch:  176        8 Batch loss: 0.226281 Batch F1: 0.3333333333333333
Epoch:  176        9 Batch loss: 0.194750 Batch F1: 0.3
Epoch:  176       10 Batch loss: 0.218278 Batch F1: 0.30769230769230765
Epoch:  176       11 Batch loss: 0.200174 Batch F1: 0.0
Epoch:  176       12 Batch loss: 0.175623 Batch F1: 0.0
Train Avg Loss  176: 0.221766

Train Avg F1  176: 0.26839810428520106

Val Avg Loss  176: 0.217287

Val Avg F1  176:  0.0

Optimal Val loss (Epoch 81): 0.21701717004179955

Epoch 177
--------------------------------------------------------------
Epoch:  177        1 Batch loss: 0.206414 Batch F1: 0.0
Epoch:  177        2 Batch loss: 0.219251 Batch F1: 0.0
Epoch:  177        3 Batch loss: 0.241753 Batch F1: 0.0
Epoch:  177        4 Batch loss: 0.244984 Batch F1: 0.0
Epoch:  177        5 Batch loss: 0.223469 Batch F1: 0.0
Epoch:  177        6 Batch loss: 0.220877 Batch F1: 0.0
Epoch:  177        7 Batch loss: 0.218823 Batch F1: 0.0
Epoch:  177        8 Batch loss: 0.224600 Batch F1: 0.5161290322580645
Epoch:  177        9 Batch loss: 0.257648 Batch F1: 0.14814814814814814
Epoch:  177       10 Batch loss: 0.184298 Batch F1: 0.6363636363636364
Epoch:  177       11 Batch loss: 0.239383 Batch F1: 0.43749999999999994
Epoch:  177       12 Batch loss: 0.237700 Batch F1: 0.0
Train Avg Loss  177: 0.226600

Train Avg F1  177: 0.1448450680641541

Val Avg Loss  177: 0.216254

Val Avg F1  177:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 178
--------------------------------------------------------------
Epoch:  178        1 Batch loss: 0.215879 Batch F1: 0.0
Epoch:  178        2 Batch loss: 0.215375 Batch F1: 0.0
Epoch:  178        3 Batch loss: 0.204060 Batch F1: 0.2857142857142857
Epoch:  178        4 Batch loss: 0.239098 Batch F1: 0.2608695652173913
Epoch:  178        5 Batch loss: 0.208493 Batch F1: 0.2727272727272727
Epoch:  178        6 Batch loss: 0.222674 Batch F1: 0.1
Epoch:  178        7 Batch loss: 0.219813 Batch F1: 0.0
Epoch:  178        8 Batch loss: 0.210519 Batch F1: 0.0
Epoch:  178        9 Batch loss: 0.229266 Batch F1: 0.0
Epoch:  178       10 Batch loss: 0.241766 Batch F1: 0.0
Epoch:  178       11 Batch loss: 0.196224 Batch F1: 0.380952380952381
Epoch:  178       12 Batch loss: 0.297849 Batch F1: 0.07407407407407407
Train Avg Loss  178: 0.225085

Train Avg F1  178: 0.11452813155711705

Val Avg Loss  178: 0.218619

Val Avg F1  178:  0.251375864355404

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 179
--------------------------------------------------------------
Epoch:  179        1 Batch loss: 0.205637 Batch F1: 0.2727272727272727
Epoch:  179        2 Batch loss: 0.234116 Batch F1: 0.35714285714285715
Epoch:  179        3 Batch loss: 0.249116 Batch F1: 0.2758620689655173
Epoch:  179        4 Batch loss: 0.235764 Batch F1: 0.27586206896551724
Epoch:  179        5 Batch loss: 0.239371 Batch F1: 0.3333333333333333
Epoch:  179        6 Batch loss: 0.234712 Batch F1: 0.3870967741935483
Epoch:  179        7 Batch loss: 0.184138 Batch F1: 0.4705882352941177
Epoch:  179        8 Batch loss: 0.199522 Batch F1: 0.2857142857142857
Epoch:  179        9 Batch loss: 0.250912 Batch F1: 0.0
Epoch:  179       10 Batch loss: 0.180528 Batch F1: 0.0
Epoch:  179       11 Batch loss: 0.261899 Batch F1: 0.0
Epoch:  179       12 Batch loss: 0.210677 Batch F1: 0.0
Train Avg Loss  179: 0.223866

Train Avg F1  179: 0.22152724136137078

Val Avg Loss  179: 0.217104

Val Avg F1  179:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 180
--------------------------------------------------------------
Epoch:  180        1 Batch loss: 0.226864 Batch F1: 0.0
Epoch:  180        2 Batch loss: 0.235038 Batch F1: 0.0
Epoch:  180        3 Batch loss: 0.232262 Batch F1: 0.0
Epoch:  180        4 Batch loss: 0.196657 Batch F1: 0.0
Epoch:  180        5 Batch loss: 0.232560 Batch F1: 0.08695652173913045
Epoch:  180        6 Batch loss: 0.204021 Batch F1: 0.26086956521739124
Epoch:  180        7 Batch loss: 0.222722 Batch F1: 0.18181818181818182
Epoch:  180        8 Batch loss: 0.218477 Batch F1: 0.27272727272727276
Epoch:  180        9 Batch loss: 0.217985 Batch F1: 0.0
Epoch:  180       10 Batch loss: 0.258416 Batch F1: 0.0
Epoch:  180       11 Batch loss: 0.233382 Batch F1: 0.10526315789473684
Epoch:  180       12 Batch loss: 0.199913 Batch F1: 0.5
Train Avg Loss  180: 0.223191

Train Avg F1  180: 0.11730289161639278

Val Avg Loss  180: 0.218742

Val Avg F1  180:  0.2648351648351648

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 181
--------------------------------------------------------------
Epoch:  181        1 Batch loss: 0.245918 Batch F1: 0.14285714285714288
Epoch:  181        2 Batch loss: 0.198213 Batch F1: 0.11764705882352941
Epoch:  181        3 Batch loss: 0.188109 Batch F1: 0.2666666666666667
Epoch:  181        4 Batch loss: 0.205076 Batch F1: 0.3809523809523809
Epoch:  181        5 Batch loss: 0.205588 Batch F1: 0.0
Epoch:  181        6 Batch loss: 0.222233 Batch F1: 0.0
Epoch:  181        7 Batch loss: 0.208554 Batch F1: 0.0
Epoch:  181        8 Batch loss: 0.288058 Batch F1: 0.06666666666666667
Epoch:  181        9 Batch loss: 0.236005 Batch F1: 0.08695652173913042
Epoch:  181       10 Batch loss: 0.230731 Batch F1: 0.18181818181818182
Epoch:  181       11 Batch loss: 0.219072 Batch F1: 0.46153846153846156
Epoch:  181       12 Batch loss: 0.245403 Batch F1: 0.33333333333333337
Train Avg Loss  181: 0.224413

Train Avg F1  181: 0.1698697011996245

Val Avg Loss  181: 0.219219

Val Avg F1  181:  0.277972027972028

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 182
--------------------------------------------------------------
Epoch:  182        1 Batch loss: 0.255369 Batch F1: 0.20689655172413793
Epoch:  182        2 Batch loss: 0.236164 Batch F1: 0.3333333333333333
Epoch:  182        3 Batch loss: 0.205218 Batch F1: 0.2
Epoch:  182        4 Batch loss: 0.229558 Batch F1: 0.09523809523809523
Epoch:  182        5 Batch loss: 0.202801 Batch F1: 0.0
Epoch:  182        6 Batch loss: 0.189614 Batch F1: 0.0
Epoch:  182        7 Batch loss: 0.230381 Batch F1: 0.0
Epoch:  182        8 Batch loss: 0.325681 Batch F1: 0.0
Epoch:  182        9 Batch loss: 0.220967 Batch F1: 0.0
Epoch:  182       10 Batch loss: 0.218558 Batch F1: 0.2608695652173913
Epoch:  182       11 Batch loss: 0.201736 Batch F1: 0.25
Epoch:  182       12 Batch loss: 0.224549 Batch F1: 0.4166666666666667
Train Avg Loss  182: 0.228383

Train Avg F1  182: 0.14691701768163537

Val Avg Loss  182: 0.218158

Val Avg F1  182:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 183
--------------------------------------------------------------
Epoch:  183        1 Batch loss: 0.207811 Batch F1: 0.0
Epoch:  183        2 Batch loss: 0.250073 Batch F1: 0.0
Epoch:  183        3 Batch loss: 0.208952 Batch F1: 0.0
Epoch:  183        4 Batch loss: 0.228462 Batch F1: 0.0
Epoch:  183        5 Batch loss: 0.222979 Batch F1: 0.1
Epoch:  183        6 Batch loss: 0.238419 Batch F1: 0.0
Epoch:  183        7 Batch loss: 0.232541 Batch F1: 0.09523809523809523
Epoch:  183        8 Batch loss: 0.221789 Batch F1: 0.3
Epoch:  183        9 Batch loss: 0.201996 Batch F1: 0.11764705882352941
Epoch:  183       10 Batch loss: 0.220526 Batch F1: 0.0
Epoch:  183       11 Batch loss: 0.218737 Batch F1: 0.0
Epoch:  183       12 Batch loss: 0.253975 Batch F1: 0.0
Train Avg Loss  183: 0.225522

Train Avg F1  183: 0.05107376283846873

Val Avg Loss  183: 0.217664

Val Avg F1  183:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 184
--------------------------------------------------------------
Epoch:  184        1 Batch loss: 0.239427 Batch F1: 0.0
Epoch:  184        2 Batch loss: 0.209339 Batch F1: 0.0
Epoch:  184        3 Batch loss: 0.200083 Batch F1: 0.0
Epoch:  184        4 Batch loss: 0.196434 Batch F1: 0.0
Epoch:  184        5 Batch loss: 0.237008 Batch F1: 0.0
Epoch:  184        6 Batch loss: 0.211682 Batch F1: 0.0
Epoch:  184        7 Batch loss: 0.263097 Batch F1: 0.0
Epoch:  184        8 Batch loss: 0.232730 Batch F1: 0.0
Epoch:  184        9 Batch loss: 0.207286 Batch F1: 0.0
Epoch:  184       10 Batch loss: 0.237467 Batch F1: 0.08333333333333334
Epoch:  184       11 Batch loss: 0.221178 Batch F1: 0.30769230769230765
Epoch:  184       12 Batch loss: 0.242890 Batch F1: 0.3076923076923077
Train Avg Loss  184: 0.224885

Train Avg F1  184: 0.05822649572649572

Val Avg Loss  184: 0.223737

Val Avg F1  184:  0.31445868945868943

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 185
--------------------------------------------------------------
Epoch:  185        1 Batch loss: 0.224354 Batch F1: 0.28571428571428575
Epoch:  185        2 Batch loss: 0.255644 Batch F1: 0.0
Epoch:  185        3 Batch loss: 0.236362 Batch F1: 0.0
Epoch:  185        4 Batch loss: 0.240724 Batch F1: 0.0
Epoch:  185        5 Batch loss: 0.244399 Batch F1: 0.0
Epoch:  185        6 Batch loss: 0.234751 Batch F1: 0.0
Epoch:  185        7 Batch loss: 0.201681 Batch F1: 0.0
Epoch:  185        8 Batch loss: 0.227678 Batch F1: 0.0
Epoch:  185        9 Batch loss: 0.213870 Batch F1: 0.1111111111111111
Epoch:  185       10 Batch loss: 0.203181 Batch F1: 0.2
Epoch:  185       11 Batch loss: 0.192930 Batch F1: 0.13333333333333333
Epoch:  185       12 Batch loss: 0.237492 Batch F1: 0.0
Train Avg Loss  185: 0.226089

Train Avg F1  185: 0.06084656084656085

Val Avg Loss  185: 0.218215

Val Avg F1  185:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 186
--------------------------------------------------------------
Epoch:  186        1 Batch loss: 0.205137 Batch F1: 0.10526315789473684
Epoch:  186        2 Batch loss: 0.211187 Batch F1: 0.0
Epoch:  186        3 Batch loss: 0.225284 Batch F1: 0.2608695652173913
Epoch:  186        4 Batch loss: 0.273074 Batch F1: 0.19999999999999998
Epoch:  186        5 Batch loss: 0.222739 Batch F1: 0.27272727272727276
Epoch:  186        6 Batch loss: 0.209141 Batch F1: 0.4799999999999999
Epoch:  186        7 Batch loss: 0.187855 Batch F1: 0.3
Epoch:  186        8 Batch loss: 0.223247 Batch F1: 0.19047619047619047
Epoch:  186        9 Batch loss: 0.238219 Batch F1: 0.16
Epoch:  186       10 Batch loss: 0.225854 Batch F1: 0.2
Epoch:  186       11 Batch loss: 0.232511 Batch F1: 0.0
Epoch:  186       12 Batch loss: 0.236321 Batch F1: 0.0
Train Avg Loss  186: 0.224214

Train Avg F1  186: 0.18077801552629927

Val Avg Loss  186: 0.217135

Val Avg F1  186:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 187
--------------------------------------------------------------
Epoch:  187        1 Batch loss: 0.221814 Batch F1: 0.125
Epoch:  187        2 Batch loss: 0.234217 Batch F1: 0.0
Epoch:  187        3 Batch loss: 0.215403 Batch F1: 0.0
Epoch:  187        4 Batch loss: 0.236009 Batch F1: 0.0
Epoch:  187        5 Batch loss: 0.216561 Batch F1: 0.0
Epoch:  187        6 Batch loss: 0.234095 Batch F1: 0.0
Epoch:  187        7 Batch loss: 0.235871 Batch F1: 0.0909090909090909
Epoch:  187        8 Batch loss: 0.228425 Batch F1: 0.14814814814814814
Epoch:  187        9 Batch loss: 0.215770 Batch F1: 0.1111111111111111
Epoch:  187       10 Batch loss: 0.215641 Batch F1: 0.1818181818181818
Epoch:  187       11 Batch loss: 0.217527 Batch F1: 0.27272727272727276
Epoch:  187       12 Batch loss: 0.199395 Batch F1: 0.4615384615384615
Train Avg Loss  187: 0.222561

Train Avg F1  187: 0.11593768885435551

Val Avg Loss  187: 0.220595

Val Avg F1  187:  0.24207373271889399

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 188
--------------------------------------------------------------
Epoch:  188        1 Batch loss: 0.243149 Batch F1: 0.07692307692307693
Epoch:  188        2 Batch loss: 0.200192 Batch F1: 0.4
Epoch:  188        3 Batch loss: 0.247677 Batch F1: 0.39999999999999997
Epoch:  188        4 Batch loss: 0.218452 Batch F1: 0.4
Epoch:  188        5 Batch loss: 0.217007 Batch F1: 0.2727272727272727
Epoch:  188        6 Batch loss: 0.245454 Batch F1: 0.08333333333333333
Epoch:  188        7 Batch loss: 0.216008 Batch F1: 0.19047619047619044
Epoch:  188        8 Batch loss: 0.200932 Batch F1: 0.23529411764705882
Epoch:  188        9 Batch loss: 0.231566 Batch F1: 0.0
Epoch:  188       10 Batch loss: 0.223838 Batch F1: 0.0
Epoch:  188       11 Batch loss: 0.214695 Batch F1: 0.0
Epoch:  188       12 Batch loss: 0.225393 Batch F1: 0.0
Train Avg Loss  188: 0.223697

Train Avg F1  188: 0.17156283259224434

Val Avg Loss  188: 0.217694

Val Avg F1  188:  0.2460076473234368

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 189
--------------------------------------------------------------
Epoch:  189        1 Batch loss: 0.218877 Batch F1: 0.0
Epoch:  189        2 Batch loss: 0.251490 Batch F1: 0.2962962962962963
Epoch:  189        3 Batch loss: 0.197107 Batch F1: 0.6666666666666667
Epoch:  189        4 Batch loss: 0.221757 Batch F1: 0.1739130434782609
Epoch:  189        5 Batch loss: 0.239023 Batch F1: 0.32000000000000006
Epoch:  189        6 Batch loss: 0.236201 Batch F1: 0.0
Epoch:  189        7 Batch loss: 0.236433 Batch F1: 0.4137931034482759
Epoch:  189        8 Batch loss: 0.219422 Batch F1: 0.3333333333333333
Epoch:  189        9 Batch loss: 0.234552 Batch F1: 0.3333333333333333
Epoch:  189       10 Batch loss: 0.182095 Batch F1: 0.4999999999999999
Epoch:  189       11 Batch loss: 0.202199 Batch F1: 0.34782608695652173
Epoch:  189       12 Batch loss: 0.242784 Batch F1: 0.1111111111111111
Train Avg Loss  189: 0.223495

Train Avg F1  189: 0.29135608121865003

Val Avg Loss  189: 0.217900

Val Avg F1  189:  0.1854066985645933

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 190
--------------------------------------------------------------
Epoch:  190        1 Batch loss: 0.241900 Batch F1: 0.43750000000000006
Epoch:  190        2 Batch loss: 0.255614 Batch F1: 0.17391304347826086
Epoch:  190        3 Batch loss: 0.194604 Batch F1: 0.0
Epoch:  190        4 Batch loss: 0.197447 Batch F1: 0.0
Epoch:  190        5 Batch loss: 0.216781 Batch F1: 0.0
Epoch:  190        6 Batch loss: 0.187777 Batch F1: 0.0
Epoch:  190        7 Batch loss: 0.222815 Batch F1: 0.0
Epoch:  190        8 Batch loss: 0.220850 Batch F1: 0.0
Epoch:  190        9 Batch loss: 0.248856 Batch F1: 0.0
Epoch:  190       10 Batch loss: 0.261144 Batch F1: 0.16000000000000003
Epoch:  190       11 Batch loss: 0.238294 Batch F1: 0.2962962962962963
Epoch:  190       12 Batch loss: 0.202796 Batch F1: 0.3
Train Avg Loss  190: 0.224073

Train Avg F1  190: 0.11397577831454643

Val Avg Loss  190: 0.219157

Val Avg F1  190:  0.2677083333333333

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 191
--------------------------------------------------------------
Epoch:  191        1 Batch loss: 0.221727 Batch F1: 0.25
Epoch:  191        2 Batch loss: 0.250639 Batch F1: 0.23076923076923075
Epoch:  191        3 Batch loss: 0.225870 Batch F1: 0.3448275862068966
Epoch:  191        4 Batch loss: 0.231498 Batch F1: 0.3571428571428571
Epoch:  191        5 Batch loss: 0.206218 Batch F1: 0.3478260869565218
Epoch:  191        6 Batch loss: 0.217078 Batch F1: 0.4666666666666666
Epoch:  191        7 Batch loss: 0.235343 Batch F1: 0.3703703703703704
Epoch:  191        8 Batch loss: 0.232764 Batch F1: 0.4242424242424242
Epoch:  191        9 Batch loss: 0.187981 Batch F1: 0.4166666666666667
Epoch:  191       10 Batch loss: 0.226180 Batch F1: 0.27272727272727276
Epoch:  191       11 Batch loss: 0.254123 Batch F1: 0.0
Epoch:  191       12 Batch loss: 0.193403 Batch F1: 0.0
Train Avg Loss  191: 0.223569

Train Avg F1  191: 0.29010326347907556

Val Avg Loss  191: 0.217033

Val Avg F1  191:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 192
--------------------------------------------------------------
Epoch:  192        1 Batch loss: 0.215866 Batch F1: 0.0
Epoch:  192        2 Batch loss: 0.269095 Batch F1: 0.0
Epoch:  192        3 Batch loss: 0.249338 Batch F1: 0.0
Epoch:  192        4 Batch loss: 0.207800 Batch F1: 0.21052631578947367
Epoch:  192        5 Batch loss: 0.198264 Batch F1: 0.36363636363636365
Epoch:  192        6 Batch loss: 0.206843 Batch F1: 0.27272727272727276
Epoch:  192        7 Batch loss: 0.213903 Batch F1: 0.45161290322580644
Epoch:  192        8 Batch loss: 0.265513 Batch F1: 0.3333333333333333
Epoch:  192        9 Batch loss: 0.216689 Batch F1: 0.25
Epoch:  192       10 Batch loss: 0.209728 Batch F1: 0.1
Epoch:  192       11 Batch loss: 0.225106 Batch F1: 0.27272727272727276
Epoch:  192       12 Batch loss: 0.209430 Batch F1: 0.3809523809523809
Train Avg Loss  192: 0.223965

Train Avg F1  192: 0.2196263201993253

Val Avg Loss  192: 0.217833

Val Avg F1  192:  0.2562770562770563

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 193
--------------------------------------------------------------
Epoch:  193        1 Batch loss: 0.241878 Batch F1: 0.23076923076923078
Epoch:  193        2 Batch loss: 0.253684 Batch F1: 0.07142857142857142
Epoch:  193        3 Batch loss: 0.228407 Batch F1: 0.0
Epoch:  193        4 Batch loss: 0.200080 Batch F1: 0.0
Epoch:  193        5 Batch loss: 0.226689 Batch F1: 0.0
Epoch:  193        6 Batch loss: 0.209789 Batch F1: 0.10526315789473684
Epoch:  193        7 Batch loss: 0.216954 Batch F1: 0.0
Epoch:  193        8 Batch loss: 0.235599 Batch F1: 0.0
Epoch:  193        9 Batch loss: 0.249649 Batch F1: 0.27586206896551724
Epoch:  193       10 Batch loss: 0.186266 Batch F1: 0.3157894736842105
Epoch:  193       11 Batch loss: 0.222052 Batch F1: 0.4
Epoch:  193       12 Batch loss: 0.201418 Batch F1: 0.14285714285714288
Train Avg Loss  193: 0.222705

Train Avg F1  193: 0.12849747046661747

Val Avg Loss  193: 0.218752

Val Avg F1  193:  0.2661472148541114

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 194
--------------------------------------------------------------
Epoch:  194        1 Batch loss: 0.237136 Batch F1: 0.3125
Epoch:  194        2 Batch loss: 0.227185 Batch F1: 0.24
Epoch:  194        3 Batch loss: 0.197056 Batch F1: 0.3809523809523809
Epoch:  194        4 Batch loss: 0.246026 Batch F1: 0.0
Epoch:  194        5 Batch loss: 0.212232 Batch F1: 0.2608695652173913
Epoch:  194        6 Batch loss: 0.250052 Batch F1: 0.23076923076923078
Epoch:  194        7 Batch loss: 0.253625 Batch F1: 0.3225806451612903
Epoch:  194        8 Batch loss: 0.242226 Batch F1: 0.39999999999999997
Epoch:  194        9 Batch loss: 0.211460 Batch F1: 0.3636363636363636
Epoch:  194       10 Batch loss: 0.173992 Batch F1: 0.19999999999999998
Epoch:  194       11 Batch loss: 0.212570 Batch F1: 0.37037037037037035
Epoch:  194       12 Batch loss: 0.215062 Batch F1: 0.3529411764705882
Train Avg Loss  194: 0.223219

Train Avg F1  194: 0.28621831104813467

Val Avg Loss  194: 0.217123

Val Avg F1  194:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 195
--------------------------------------------------------------
Epoch:  195        1 Batch loss: 0.185434 Batch F1: 0.14285714285714288
Epoch:  195        2 Batch loss: 0.243605 Batch F1: 0.0
Epoch:  195        3 Batch loss: 0.232464 Batch F1: 0.0
Epoch:  195        4 Batch loss: 0.235219 Batch F1: 0.23076923076923075
Epoch:  195        5 Batch loss: 0.201946 Batch F1: 0.35294117647058826
Epoch:  195        6 Batch loss: 0.198982 Batch F1: 0.3
Epoch:  195        7 Batch loss: 0.268630 Batch F1: 0.07142857142857142
Epoch:  195        8 Batch loss: 0.216548 Batch F1: 0.08695652173913042
Epoch:  195        9 Batch loss: 0.205523 Batch F1: 0.4
Epoch:  195       10 Batch loss: 0.252004 Batch F1: 0.0
Epoch:  195       11 Batch loss: 0.214154 Batch F1: 0.0
Epoch:  195       12 Batch loss: 0.236473 Batch F1: 0.19999999999999998
Train Avg Loss  195: 0.224248

Train Avg F1  195: 0.14874605360538865

Val Avg Loss  195: 0.218568

Val Avg F1  195:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 196
--------------------------------------------------------------
Epoch:  196        1 Batch loss: 0.211888 Batch F1: 0.19999999999999998
Epoch:  196        2 Batch loss: 0.205841 Batch F1: 0.2222222222222222
Epoch:  196        3 Batch loss: 0.235522 Batch F1: 0.09523809523809525
Epoch:  196        4 Batch loss: 0.251003 Batch F1: 0.15384615384615385
Epoch:  196        5 Batch loss: 0.243575 Batch F1: 0.16
Epoch:  196        6 Batch loss: 0.220386 Batch F1: 0.3
Epoch:  196        7 Batch loss: 0.196512 Batch F1: 0.48
Epoch:  196        8 Batch loss: 0.206274 Batch F1: 0.5625
Epoch:  196        9 Batch loss: 0.223638 Batch F1: 0.2857142857142857
Epoch:  196       10 Batch loss: 0.257756 Batch F1: 0.25806451612903225
Epoch:  196       11 Batch loss: 0.218732 Batch F1: 0.1818181818181818
Epoch:  196       12 Batch loss: 0.195036 Batch F1: 0.13333333333333336
Train Avg Loss  196: 0.222180

Train Avg F1  196: 0.2527280656917753

Val Avg Loss  196: 0.217705

Val Avg F1  196:  0.05

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 197
--------------------------------------------------------------
Epoch:  197        1 Batch loss: 0.235615 Batch F1: 0.08695652173913045
Epoch:  197        2 Batch loss: 0.200989 Batch F1: 0.19047619047619047
Epoch:  197        3 Batch loss: 0.184125 Batch F1: 0.4
Epoch:  197        4 Batch loss: 0.214765 Batch F1: 0.09523809523809523
Epoch:  197        5 Batch loss: 0.228558 Batch F1: 0.3478260869565218
Epoch:  197        6 Batch loss: 0.217636 Batch F1: 0.0
Epoch:  197        7 Batch loss: 0.237094 Batch F1: 0.0
Epoch:  197        8 Batch loss: 0.212305 Batch F1: 0.32
Epoch:  197        9 Batch loss: 0.250937 Batch F1: 0.16666666666666666
Epoch:  197       10 Batch loss: 0.205927 Batch F1: 0.4
Epoch:  197       11 Batch loss: 0.244059 Batch F1: 0.26666666666666666
Epoch:  197       12 Batch loss: 0.237949 Batch F1: 0.3
Train Avg Loss  197: 0.222497

Train Avg F1  197: 0.21448585231193928

Val Avg Loss  197: 0.219753

Val Avg F1  197:  0.3202564102564102

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 198
--------------------------------------------------------------
Epoch:  198        1 Batch loss: 0.223019 Batch F1: 0.5
Epoch:  198        2 Batch loss: 0.209170 Batch F1: 0.3478260869565218
Epoch:  198        3 Batch loss: 0.222605 Batch F1: 0.4705882352941177
Epoch:  198        4 Batch loss: 0.241821 Batch F1: 0.4516129032258065
Epoch:  198        5 Batch loss: 0.218987 Batch F1: 0.3333333333333333
Epoch:  198        6 Batch loss: 0.203646 Batch F1: 0.2222222222222222
Epoch:  198        7 Batch loss: 0.240023 Batch F1: 0.21428571428571427
Epoch:  198        8 Batch loss: 0.224026 Batch F1: 0.4
Epoch:  198        9 Batch loss: 0.226197 Batch F1: 0.10526315789473682
Epoch:  198       10 Batch loss: 0.222916 Batch F1: 0.1904761904761905
Epoch:  198       11 Batch loss: 0.239157 Batch F1: 0.08333333333333333
Epoch:  198       12 Batch loss: 0.201569 Batch F1: 0.25
Train Avg Loss  198: 0.222761

Train Avg F1  198: 0.2974117647518314

Val Avg Loss  198: 0.217409

Val Avg F1  198:  0.1538095238095238

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 199
--------------------------------------------------------------
Epoch:  199        1 Batch loss: 0.238063 Batch F1: 0.2608695652173913
Epoch:  199        2 Batch loss: 0.205592 Batch F1: 0.3
Epoch:  199        3 Batch loss: 0.178139 Batch F1: 0.3157894736842105
Epoch:  199        4 Batch loss: 0.213629 Batch F1: 0.1111111111111111
Epoch:  199        5 Batch loss: 0.231640 Batch F1: 0.0
Epoch:  199        6 Batch loss: 0.180329 Batch F1: 0.13333333333333333
Epoch:  199        7 Batch loss: 0.228409 Batch F1: 0.0
Epoch:  199        8 Batch loss: 0.206091 Batch F1: 0.0
Epoch:  199        9 Batch loss: 0.276814 Batch F1: 0.20689655172413793
Epoch:  199       10 Batch loss: 0.227679 Batch F1: 0.25
Epoch:  199       11 Batch loss: 0.257552 Batch F1: 0.19999999999999998
Epoch:  199       12 Batch loss: 0.227500 Batch F1: 0.5925925925925927
Train Avg Loss  199: 0.222620

Train Avg F1  199: 0.19754938563856472

Val Avg Loss  199: 0.220345

Val Avg F1  199:  0.3302898550724638

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 200
--------------------------------------------------------------
Epoch:  200        1 Batch loss: 0.249611 Batch F1: 0.3125
Epoch:  200        2 Batch loss: 0.237761 Batch F1: 0.4
Epoch:  200        3 Batch loss: 0.218016 Batch F1: 0.5789473684210527
Epoch:  200        4 Batch loss: 0.231778 Batch F1: 0.35714285714285715
Epoch:  200        5 Batch loss: 0.221682 Batch F1: 0.38461538461538464
Epoch:  200        6 Batch loss: 0.221550 Batch F1: 0.3478260869565218
Epoch:  200        7 Batch loss: 0.200675 Batch F1: 0.0
Epoch:  200        8 Batch loss: 0.213956 Batch F1: 0.0
Epoch:  200        9 Batch loss: 0.193736 Batch F1: 0.0
Epoch:  200       10 Batch loss: 0.239978 Batch F1: 0.0
Epoch:  200       11 Batch loss: 0.255461 Batch F1: 0.0
Epoch:  200       12 Batch loss: 0.226394 Batch F1: 0.0
Train Avg Loss  200: 0.225883

Train Avg F1  200: 0.19841930809465136

Val Avg Loss  200: 0.216628

Val Avg F1  200:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 201
--------------------------------------------------------------
Epoch:  201        1 Batch loss: 0.230561 Batch F1: 0.0
Epoch:  201        2 Batch loss: 0.208013 Batch F1: 0.0
Epoch:  201        3 Batch loss: 0.210448 Batch F1: 0.1111111111111111
Epoch:  201        4 Batch loss: 0.193760 Batch F1: 0.5384615384615384
Epoch:  201        5 Batch loss: 0.217951 Batch F1: 0.25
Epoch:  201        6 Batch loss: 0.197867 Batch F1: 0.11111111111111112
Epoch:  201        7 Batch loss: 0.221492 Batch F1: 0.0
Epoch:  201        8 Batch loss: 0.281507 Batch F1: 0.0
Epoch:  201        9 Batch loss: 0.251463 Batch F1: 0.0
Epoch:  201       10 Batch loss: 0.247981 Batch F1: 0.0
Epoch:  201       11 Batch loss: 0.220195 Batch F1: 0.0
Epoch:  201       12 Batch loss: 0.245489 Batch F1: 0.09523809523809525
Train Avg Loss  201: 0.227227

Train Avg F1  201: 0.09216015466015466

Val Avg Loss  201: 0.229229

Val Avg F1  201:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 202
--------------------------------------------------------------
Epoch:  202        1 Batch loss: 0.245748 Batch F1: 0.0
Epoch:  202        2 Batch loss: 0.231916 Batch F1: 0.0
Epoch:  202        3 Batch loss: 0.225418 Batch F1: 0.1
Epoch:  202        4 Batch loss: 0.215366 Batch F1: 0.0
Epoch:  202        5 Batch loss: 0.218368 Batch F1: 0.0
Epoch:  202        6 Batch loss: 0.246691 Batch F1: 0.0
Epoch:  202        7 Batch loss: 0.209465 Batch F1: 0.0
Epoch:  202        8 Batch loss: 0.235593 Batch F1: 0.1818181818181818
Epoch:  202        9 Batch loss: 0.209918 Batch F1: 0.34782608695652173
Epoch:  202       10 Batch loss: 0.227576 Batch F1: 0.4
Epoch:  202       11 Batch loss: 0.213867 Batch F1: 0.2727272727272727
Epoch:  202       12 Batch loss: 0.234545 Batch F1: 0.11764705882352941
Train Avg Loss  202: 0.226206

Train Avg F1  202: 0.11833488336045882

Val Avg Loss  202: 0.217224

Val Avg F1  202:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 203
--------------------------------------------------------------
Epoch:  203        1 Batch loss: 0.240614 Batch F1: 0.0
Epoch:  203        2 Batch loss: 0.222420 Batch F1: 0.0
Epoch:  203        3 Batch loss: 0.190694 Batch F1: 0.0
Epoch:  203        4 Batch loss: 0.238655 Batch F1: 0.0
Epoch:  203        5 Batch loss: 0.187135 Batch F1: 0.0
Epoch:  203        6 Batch loss: 0.271198 Batch F1: 0.0
Epoch:  203        7 Batch loss: 0.233572 Batch F1: 0.07999999999999999
Epoch:  203        8 Batch loss: 0.212065 Batch F1: 0.2105263157894737
Epoch:  203        9 Batch loss: 0.269815 Batch F1: 0.3428571428571428
Epoch:  203       10 Batch loss: 0.220546 Batch F1: 0.48275862068965514
Epoch:  203       11 Batch loss: 0.207609 Batch F1: 0.5161290322580646
Epoch:  203       12 Batch loss: 0.228586 Batch F1: 0.11764705882352942
Train Avg Loss  203: 0.226909

Train Avg F1  203: 0.14582651420148882

Val Avg Loss  203: 0.217876

Val Avg F1  203:  0.12283549783549783

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 204
--------------------------------------------------------------
Epoch:  204        1 Batch loss: 0.222719 Batch F1: 0.0
Epoch:  204        2 Batch loss: 0.172856 Batch F1: 0.0
Epoch:  204        3 Batch loss: 0.244644 Batch F1: 0.0
Epoch:  204        4 Batch loss: 0.214827 Batch F1: 0.0
Epoch:  204        5 Batch loss: 0.256217 Batch F1: 0.0
Epoch:  204        6 Batch loss: 0.244818 Batch F1: 0.0
Epoch:  204        7 Batch loss: 0.241203 Batch F1: 0.0
Epoch:  204        8 Batch loss: 0.237025 Batch F1: 0.0
Epoch:  204        9 Batch loss: 0.219478 Batch F1: 0.1111111111111111
Epoch:  204       10 Batch loss: 0.244439 Batch F1: 0.3448275862068965
Epoch:  204       11 Batch loss: 0.249910 Batch F1: 0.1739130434782609
Epoch:  204       12 Batch loss: 0.209266 Batch F1: 0.2222222222222222
Train Avg Loss  204: 0.229783

Train Avg F1  204: 0.07100616358487423

Val Avg Loss  204: 0.220911

Val Avg F1  204:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 205
--------------------------------------------------------------
Epoch:  205        1 Batch loss: 0.217301 Batch F1: 0.0
Epoch:  205        2 Batch loss: 0.250739 Batch F1: 0.0
Epoch:  205        3 Batch loss: 0.248331 Batch F1: 0.0
Epoch:  205        4 Batch loss: 0.217069 Batch F1: 0.0
Epoch:  205        5 Batch loss: 0.214563 Batch F1: 0.0
Epoch:  205        6 Batch loss: 0.229818 Batch F1: 0.0
Epoch:  205        7 Batch loss: 0.264440 Batch F1: 0.0
Epoch:  205        8 Batch loss: 0.203698 Batch F1: 0.0
Epoch:  205        9 Batch loss: 0.215960 Batch F1: 0.0
Epoch:  205       10 Batch loss: 0.202787 Batch F1: 0.0
Epoch:  205       11 Batch loss: 0.203540 Batch F1: 0.0
Epoch:  205       12 Batch loss: 0.234874 Batch F1: 0.1111111111111111
Train Avg Loss  205: 0.225260

Train Avg F1  205: 0.009259259259259259

Val Avg Loss  205: 0.217532

Val Avg F1  205:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 206
--------------------------------------------------------------
Epoch:  206        1 Batch loss: 0.214229 Batch F1: 0.11764705882352941
Epoch:  206        2 Batch loss: 0.264176 Batch F1: 0.0
Epoch:  206        3 Batch loss: 0.208081 Batch F1: 0.0
Epoch:  206        4 Batch loss: 0.220445 Batch F1: 0.0
Epoch:  206        5 Batch loss: 0.196106 Batch F1: 0.125
Epoch:  206        6 Batch loss: 0.213893 Batch F1: 0.11764705882352941
Epoch:  206        7 Batch loss: 0.248248 Batch F1: 0.0
Epoch:  206        8 Batch loss: 0.220010 Batch F1: 0.0
Epoch:  206        9 Batch loss: 0.233789 Batch F1: 0.0
Epoch:  206       10 Batch loss: 0.223555 Batch F1: 0.0
Epoch:  206       11 Batch loss: 0.231729 Batch F1: 0.0
Epoch:  206       12 Batch loss: 0.205486 Batch F1: 0.5
Train Avg Loss  206: 0.223312

Train Avg F1  206: 0.07169117647058824

Val Avg Loss  206: 0.218190

Val Avg F1  206:  0.24105072463768112

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 207
--------------------------------------------------------------
Epoch:  207        1 Batch loss: 0.210473 Batch F1: 0.2857142857142857
Epoch:  207        2 Batch loss: 0.221777 Batch F1: 0.21052631578947367
Epoch:  207        3 Batch loss: 0.218418 Batch F1: 0.3846153846153846
Epoch:  207        4 Batch loss: 0.203863 Batch F1: 0.4347826086956522
Epoch:  207        5 Batch loss: 0.230674 Batch F1: 0.42857142857142855
Epoch:  207        6 Batch loss: 0.205723 Batch F1: 0.25
Epoch:  207        7 Batch loss: 0.231125 Batch F1: 0.3333333333333333
Epoch:  207        8 Batch loss: 0.230506 Batch F1: 0.2608695652173913
Epoch:  207        9 Batch loss: 0.217590 Batch F1: 0.27272727272727276
Epoch:  207       10 Batch loss: 0.219858 Batch F1: 0.3333333333333333
Epoch:  207       11 Batch loss: 0.236779 Batch F1: 0.36363636363636365
Epoch:  207       12 Batch loss: 0.247184 Batch F1: 0.10526315789473684
Train Avg Loss  207: 0.222831

Train Avg F1  207: 0.30528108746072136

Val Avg Loss  207: 0.217542

Val Avg F1  207:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 208
--------------------------------------------------------------
Epoch:  208        1 Batch loss: 0.232070 Batch F1: 0.0
Epoch:  208        2 Batch loss: 0.224296 Batch F1: 0.0
Epoch:  208        3 Batch loss: 0.243228 Batch F1: 0.08695652173913045
Epoch:  208        4 Batch loss: 0.216730 Batch F1: 0.39999999999999997
Epoch:  208        5 Batch loss: 0.242849 Batch F1: 0.14285714285714288
Epoch:  208        6 Batch loss: 0.229539 Batch F1: 0.1904761904761905
Epoch:  208        7 Batch loss: 0.215021 Batch F1: 0.4166666666666667
Epoch:  208        8 Batch loss: 0.227400 Batch F1: 0.38461538461538464
Epoch:  208        9 Batch loss: 0.203397 Batch F1: 0.5
Epoch:  208       10 Batch loss: 0.227387 Batch F1: 0.37037037037037035
Epoch:  208       11 Batch loss: 0.212895 Batch F1: 0.10526315789473684
Epoch:  208       12 Batch loss: 0.199609 Batch F1: 0.0
Train Avg Loss  208: 0.222869

Train Avg F1  208: 0.21643378621830187

Val Avg Loss  208: 0.217364

Val Avg F1  208:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 209
--------------------------------------------------------------
Epoch:  209        1 Batch loss: 0.218479 Batch F1: 0.0
Epoch:  209        2 Batch loss: 0.220290 Batch F1: 0.0
Epoch:  209        3 Batch loss: 0.213652 Batch F1: 0.0
Epoch:  209        4 Batch loss: 0.257816 Batch F1: 0.0
Epoch:  209        5 Batch loss: 0.201294 Batch F1: 0.0
Epoch:  209        6 Batch loss: 0.275071 Batch F1: 0.07142857142857142
Epoch:  209        7 Batch loss: 0.256784 Batch F1: 0.0
Epoch:  209        8 Batch loss: 0.208849 Batch F1: 0.25000000000000006
Epoch:  209        9 Batch loss: 0.216467 Batch F1: 0.5217391304347826
Epoch:  209       10 Batch loss: 0.214034 Batch F1: 0.09523809523809525
Epoch:  209       11 Batch loss: 0.220555 Batch F1: 0.0
Epoch:  209       12 Batch loss: 0.207133 Batch F1: 0.0
Train Avg Loss  209: 0.225869

Train Avg F1  209: 0.07820048309178744

Val Avg Loss  209: 0.218740

Val Avg F1  209:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 210
--------------------------------------------------------------
Epoch:  210        1 Batch loss: 0.224041 Batch F1: 0.0
Epoch:  210        2 Batch loss: 0.205717 Batch F1: 0.0
Epoch:  210        3 Batch loss: 0.235249 Batch F1: 0.0
Epoch:  210        4 Batch loss: 0.216981 Batch F1: 0.1
Epoch:  210        5 Batch loss: 0.237732 Batch F1: 0.08333333333333334
Epoch:  210        6 Batch loss: 0.248931 Batch F1: 0.24
Epoch:  210        7 Batch loss: 0.191922 Batch F1: 0.0
Epoch:  210        8 Batch loss: 0.244320 Batch F1: 0.23999999999999996
Epoch:  210        9 Batch loss: 0.234050 Batch F1: 0.15384615384615383
Epoch:  210       10 Batch loss: 0.221374 Batch F1: 0.08695652173913042
Epoch:  210       11 Batch loss: 0.215316 Batch F1: 0.5217391304347825
Epoch:  210       12 Batch loss: 0.208492 Batch F1: 0.5
Train Avg Loss  210: 0.223677

Train Avg F1  210: 0.16048959494611667

Val Avg Loss  210: 0.216942

Val Avg F1  210:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 211
--------------------------------------------------------------
Epoch:  211        1 Batch loss: 0.238531 Batch F1: 0.0
Epoch:  211        2 Batch loss: 0.204824 Batch F1: 0.0
Epoch:  211        3 Batch loss: 0.245822 Batch F1: 0.1
Epoch:  211        4 Batch loss: 0.251466 Batch F1: 0.0
Epoch:  211        5 Batch loss: 0.193883 Batch F1: 0.0
Epoch:  211        6 Batch loss: 0.185961 Batch F1: 0.0
Epoch:  211        7 Batch loss: 0.302428 Batch F1: 0.24242424242424243
Epoch:  211        8 Batch loss: 0.222890 Batch F1: 0.23999999999999996
Epoch:  211        9 Batch loss: 0.223593 Batch F1: 0.3
Epoch:  211       10 Batch loss: 0.222100 Batch F1: 0.24
Epoch:  211       11 Batch loss: 0.196732 Batch F1: 0.5
Epoch:  211       12 Batch loss: 0.206878 Batch F1: 0.2222222222222222
Train Avg Loss  211: 0.224592

Train Avg F1  211: 0.1537205387205387

Val Avg Loss  211: 0.217361

Val Avg F1  211:  0.11734143049932523

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 212
--------------------------------------------------------------
Epoch:  212        1 Batch loss: 0.207612 Batch F1: 0.39999999999999997
Epoch:  212        2 Batch loss: 0.193490 Batch F1: 0.2857142857142857
Epoch:  212        3 Batch loss: 0.201353 Batch F1: 0.11764705882352941
Epoch:  212        4 Batch loss: 0.235377 Batch F1: 0.16666666666666666
Epoch:  212        5 Batch loss: 0.240518 Batch F1: 0.08695652173913045
Epoch:  212        6 Batch loss: 0.219787 Batch F1: 0.1818181818181818
Epoch:  212        7 Batch loss: 0.204748 Batch F1: 0.2222222222222222
Epoch:  212        8 Batch loss: 0.235268 Batch F1: 0.24
Epoch:  212        9 Batch loss: 0.252403 Batch F1: 0.15384615384615385
Epoch:  212       10 Batch loss: 0.232532 Batch F1: 0.37037037037037035
Epoch:  212       11 Batch loss: 0.230107 Batch F1: 0.19047619047619047
Epoch:  212       12 Batch loss: 0.222434 Batch F1: 0.33333333333333337
Train Avg Loss  212: 0.222969

Train Avg F1  212: 0.22908758208417204

Val Avg Loss  212: 0.218022

Val Avg F1  212:  0.10841759571342148

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 213
--------------------------------------------------------------
Epoch:  213        1 Batch loss: 0.217192 Batch F1: 0.2857142857142857
Epoch:  213        2 Batch loss: 0.220632 Batch F1: 0.0
Epoch:  213        3 Batch loss: 0.214384 Batch F1: 0.1111111111111111
Epoch:  213        4 Batch loss: 0.221736 Batch F1: 0.0
Epoch:  213        5 Batch loss: 0.208169 Batch F1: 0.0
Epoch:  213        6 Batch loss: 0.236704 Batch F1: 0.0
Epoch:  213        7 Batch loss: 0.227639 Batch F1: 0.0
Epoch:  213        8 Batch loss: 0.259198 Batch F1: 0.0
Epoch:  213        9 Batch loss: 0.229789 Batch F1: 0.39999999999999997
Epoch:  213       10 Batch loss: 0.237662 Batch F1: 0.26666666666666666
Epoch:  213       11 Batch loss: 0.233327 Batch F1: 0.39999999999999997
Epoch:  213       12 Batch loss: 0.207544 Batch F1: 0.15384615384615385
Train Avg Loss  213: 0.226165

Train Avg F1  213: 0.1347781847781848

Val Avg Loss  213: 0.220136

Val Avg F1  213:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 214
--------------------------------------------------------------
Epoch:  214        1 Batch loss: 0.235295 Batch F1: 0.0
Epoch:  214        2 Batch loss: 0.207975 Batch F1: 0.0
Epoch:  214        3 Batch loss: 0.271046 Batch F1: 0.0
Epoch:  214        4 Batch loss: 0.234646 Batch F1: 0.0
Epoch:  214        5 Batch loss: 0.185739 Batch F1: 0.0
Epoch:  214        6 Batch loss: 0.221087 Batch F1: 0.0
Epoch:  214        7 Batch loss: 0.243098 Batch F1: 0.0
Epoch:  214        8 Batch loss: 0.220493 Batch F1: 0.0
Epoch:  214        9 Batch loss: 0.213827 Batch F1: 0.0
Epoch:  214       10 Batch loss: 0.221376 Batch F1: 0.37037037037037035
Epoch:  214       11 Batch loss: 0.224074 Batch F1: 0.3478260869565218
Epoch:  214       12 Batch loss: 0.250699 Batch F1: 0.1739130434782609
Train Avg Loss  214: 0.227446

Train Avg F1  214: 0.07434245840042943

Val Avg Loss  214: 0.217243

Val Avg F1  214:  0.16474120082815732

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 215
--------------------------------------------------------------
Epoch:  215        1 Batch loss: 0.222563 Batch F1: 0.18181818181818182
Epoch:  215        2 Batch loss: 0.209040 Batch F1: 0.0
Epoch:  215        3 Batch loss: 0.258382 Batch F1: 0.0
Epoch:  215        4 Batch loss: 0.232921 Batch F1: 0.0
Epoch:  215        5 Batch loss: 0.205419 Batch F1: 0.0
Epoch:  215        6 Batch loss: 0.211787 Batch F1: 0.4
Epoch:  215        7 Batch loss: 0.232435 Batch F1: 0.27586206896551724
Epoch:  215        8 Batch loss: 0.216248 Batch F1: 0.3703703703703704
Epoch:  215        9 Batch loss: 0.241771 Batch F1: 0.15384615384615385
Epoch:  215       10 Batch loss: 0.224376 Batch F1: 0.2608695652173913
Epoch:  215       11 Batch loss: 0.228345 Batch F1: 0.23999999999999996
Epoch:  215       12 Batch loss: 0.213985 Batch F1: 0.23529411764705882
Train Avg Loss  215: 0.224773

Train Avg F1  215: 0.17650503815538945

Val Avg Loss  215: 0.220420

Val Avg F1  215:  0.26097361575622446

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 216
--------------------------------------------------------------
Epoch:  216        1 Batch loss: 0.229424 Batch F1: 0.30769230769230765
Epoch:  216        2 Batch loss: 0.156644 Batch F1: 0.5714285714285714
Epoch:  216        3 Batch loss: 0.198791 Batch F1: 0.0
Epoch:  216        4 Batch loss: 0.249869 Batch F1: 0.0
Epoch:  216        5 Batch loss: 0.246929 Batch F1: 0.0
Epoch:  216        6 Batch loss: 0.287011 Batch F1: 0.0
Epoch:  216        7 Batch loss: 0.227693 Batch F1: 0.0
Epoch:  216        8 Batch loss: 0.220798 Batch F1: 0.2
Epoch:  216        9 Batch loss: 0.244413 Batch F1: 0.3225806451612903
Epoch:  216       10 Batch loss: 0.220871 Batch F1: 0.32
Epoch:  216       11 Batch loss: 0.210405 Batch F1: 0.3333333333333333
Epoch:  216       12 Batch loss: 0.208499 Batch F1: 0.2222222222222222
Train Avg Loss  216: 0.225112

Train Avg F1  216: 0.18977142331981042

Val Avg Loss  216: 0.219367

Val Avg F1  216:  0.2616341991341991

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 217
--------------------------------------------------------------
Epoch:  217        1 Batch loss: 0.192513 Batch F1: 0.3478260869565218
Epoch:  217        2 Batch loss: 0.217972 Batch F1: 0.18181818181818182
Epoch:  217        3 Batch loss: 0.222435 Batch F1: 0.39999999999999997
Epoch:  217        4 Batch loss: 0.226996 Batch F1: 0.19047619047619047
Epoch:  217        5 Batch loss: 0.238462 Batch F1: 0.0
Epoch:  217        6 Batch loss: 0.220056 Batch F1: 0.0
Epoch:  217        7 Batch loss: 0.205838 Batch F1: 0.0
Epoch:  217        8 Batch loss: 0.195323 Batch F1: 0.0
Epoch:  217        9 Batch loss: 0.245463 Batch F1: 0.0
Epoch:  217       10 Batch loss: 0.241407 Batch F1: 0.0
Epoch:  217       11 Batch loss: 0.238729 Batch F1: 0.0
Epoch:  217       12 Batch loss: 0.238918 Batch F1: 0.0
Train Avg Loss  217: 0.223676

Train Avg F1  217: 0.09334337160424117

Val Avg Loss  217: 0.218989

Val Avg F1  217:  0.2840985101854667

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 218
--------------------------------------------------------------
Epoch:  218        1 Batch loss: 0.199449 Batch F1: 0.46153846153846156
Epoch:  218        2 Batch loss: 0.219301 Batch F1: 0.35714285714285715
Epoch:  218        3 Batch loss: 0.220490 Batch F1: 0.42857142857142855
Epoch:  218        4 Batch loss: 0.223170 Batch F1: 0.28571428571428575
Epoch:  218        5 Batch loss: 0.232650 Batch F1: 0.5
Epoch:  218        6 Batch loss: 0.241822 Batch F1: 0.3870967741935483
Epoch:  218        7 Batch loss: 0.217508 Batch F1: 0.37037037037037035
Epoch:  218        8 Batch loss: 0.242244 Batch F1: 0.08695652173913043
Epoch:  218        9 Batch loss: 0.217201 Batch F1: 0.4347826086956522
Epoch:  218       10 Batch loss: 0.234614 Batch F1: 0.09523809523809523
Epoch:  218       11 Batch loss: 0.202428 Batch F1: 0.4166666666666667
Epoch:  218       12 Batch loss: 0.224097 Batch F1: 0.0
Train Avg Loss  218: 0.222914

Train Avg F1  218: 0.318673172489208

Val Avg Loss  218: 0.216475

Val Avg F1  218:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 219
--------------------------------------------------------------
Epoch:  219        1 Batch loss: 0.225695 Batch F1: 0.0
Epoch:  219        2 Batch loss: 0.226530 Batch F1: 0.0
Epoch:  219        3 Batch loss: 0.229151 Batch F1: 0.0
Epoch:  219        4 Batch loss: 0.228468 Batch F1: 0.0
Epoch:  219        5 Batch loss: 0.181746 Batch F1: 0.0
Epoch:  219        6 Batch loss: 0.243846 Batch F1: 0.0
Epoch:  219        7 Batch loss: 0.252772 Batch F1: 0.0
Epoch:  219        8 Batch loss: 0.276596 Batch F1: 0.06666666666666667
Epoch:  219        9 Batch loss: 0.198322 Batch F1: 0.5217391304347826
Epoch:  219       10 Batch loss: 0.194164 Batch F1: 0.45454545454545453
Epoch:  219       11 Batch loss: 0.227506 Batch F1: 0.0
Epoch:  219       12 Batch loss: 0.226358 Batch F1: 0.0
Train Avg Loss  219: 0.225929

Train Avg F1  219: 0.08691260430390864

Val Avg Loss  219: 0.217521

Val Avg F1  219:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 220
--------------------------------------------------------------
Epoch:  220        1 Batch loss: 0.228894 Batch F1: 0.0
Epoch:  220        2 Batch loss: 0.248033 Batch F1: 0.0
Epoch:  220        3 Batch loss: 0.241317 Batch F1: 0.3448275862068966
Epoch:  220        4 Batch loss: 0.227590 Batch F1: 0.3448275862068966
Epoch:  220        5 Batch loss: 0.244931 Batch F1: 0.5217391304347826
Epoch:  220        6 Batch loss: 0.228723 Batch F1: 0.4242424242424242
Epoch:  220        7 Batch loss: 0.216524 Batch F1: 0.28571428571428575
Epoch:  220        8 Batch loss: 0.198704 Batch F1: 0.125
Epoch:  220        9 Batch loss: 0.234909 Batch F1: 0.0
Epoch:  220       10 Batch loss: 0.202691 Batch F1: 0.0
Epoch:  220       11 Batch loss: 0.212871 Batch F1: 0.0
Epoch:  220       12 Batch loss: 0.240309 Batch F1: 0.0
Train Avg Loss  220: 0.227125

Train Avg F1  220: 0.17052925106710717

Val Avg Loss  220: 0.217876

Val Avg F1  220:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 221
--------------------------------------------------------------
Epoch:  221        1 Batch loss: 0.217376 Batch F1: 0.0
Epoch:  221        2 Batch loss: 0.210170 Batch F1: 0.0
Epoch:  221        3 Batch loss: 0.220705 Batch F1: 0.0
Epoch:  221        4 Batch loss: 0.238068 Batch F1: 0.1739130434782609
Epoch:  221        5 Batch loss: 0.253962 Batch F1: 0.07407407407407407
Epoch:  221        6 Batch loss: 0.231626 Batch F1: 0.5789473684210527
Epoch:  221        7 Batch loss: 0.235717 Batch F1: 0.35714285714285715
Epoch:  221        8 Batch loss: 0.223877 Batch F1: 0.09523809523809523
Epoch:  221        9 Batch loss: 0.244383 Batch F1: 0.0
Epoch:  221       10 Batch loss: 0.210182 Batch F1: 0.0
Epoch:  221       11 Batch loss: 0.217460 Batch F1: 0.0
Epoch:  221       12 Batch loss: 0.233334 Batch F1: 0.0
Train Avg Loss  221: 0.228072

Train Avg F1  221: 0.10660961986286166

Val Avg Loss  221: 0.217350

Val Avg F1  221:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 222
--------------------------------------------------------------
Epoch:  222        1 Batch loss: 0.242630 Batch F1: 0.0
Epoch:  222        2 Batch loss: 0.249783 Batch F1: 0.08695652173913045
Epoch:  222        3 Batch loss: 0.207415 Batch F1: 0.0
Epoch:  222        4 Batch loss: 0.227103 Batch F1: 0.2727272727272727
Epoch:  222        5 Batch loss: 0.198694 Batch F1: 0.0
Epoch:  222        6 Batch loss: 0.251892 Batch F1: 0.0
Epoch:  222        7 Batch loss: 0.191838 Batch F1: 0.0
Epoch:  222        8 Batch loss: 0.205587 Batch F1: 0.0
Epoch:  222        9 Batch loss: 0.242345 Batch F1: 0.0
Epoch:  222       10 Batch loss: 0.224733 Batch F1: 0.0
Epoch:  222       11 Batch loss: 0.262523 Batch F1: 0.0
Epoch:  222       12 Batch loss: 0.194666 Batch F1: 0.0
Train Avg Loss  222: 0.224934

Train Avg F1  222: 0.02997364953886693

Val Avg Loss  222: 0.219214

Val Avg F1  222:  0.2405945604048071

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 223
--------------------------------------------------------------
Epoch:  223        1 Batch loss: 0.276708 Batch F1: 0.22857142857142856
Epoch:  223        2 Batch loss: 0.251140 Batch F1: 0.08
Epoch:  223        3 Batch loss: 0.226051 Batch F1: 0.5625
Epoch:  223        4 Batch loss: 0.225404 Batch F1: 0.4166666666666667
Epoch:  223        5 Batch loss: 0.197659 Batch F1: 0.6923076923076923
Epoch:  223        6 Batch loss: 0.209546 Batch F1: 0.3
Epoch:  223        7 Batch loss: 0.232169 Batch F1: 0.18181818181818182
Epoch:  223        8 Batch loss: 0.195098 Batch F1: 0.0
Epoch:  223        9 Batch loss: 0.232524 Batch F1: 0.0
Epoch:  223       10 Batch loss: 0.237846 Batch F1: 0.0
Epoch:  223       11 Batch loss: 0.228726 Batch F1: 0.0
Epoch:  223       12 Batch loss: 0.215709 Batch F1: 0.14285714285714285
Train Avg Loss  223: 0.227382

Train Avg F1  223: 0.21706009268509266

Val Avg Loss  223: 0.218940

Val Avg F1  223:  0.2404624893435635

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 224
--------------------------------------------------------------
Epoch:  224        1 Batch loss: 0.239278 Batch F1: 0.2962962962962963
Epoch:  224        2 Batch loss: 0.203740 Batch F1: 0.11764705882352941
Epoch:  224        3 Batch loss: 0.199890 Batch F1: 0.3478260869565218
Epoch:  224        4 Batch loss: 0.247559 Batch F1: 0.22222222222222218
Epoch:  224        5 Batch loss: 0.225972 Batch F1: 0.25
Epoch:  224        6 Batch loss: 0.167038 Batch F1: 0.3529411764705882
Epoch:  224        7 Batch loss: 0.193905 Batch F1: 0.21052631578947367
Epoch:  224        8 Batch loss: 0.289793 Batch F1: 0.07407407407407408
Epoch:  224        9 Batch loss: 0.222868 Batch F1: 0.3636363636363636
Epoch:  224       10 Batch loss: 0.235775 Batch F1: 0.3703703703703704
Epoch:  224       11 Batch loss: 0.222094 Batch F1: 0.24
Epoch:  224       12 Batch loss: 0.235193 Batch F1: 0.1111111111111111
Train Avg Loss  224: 0.223592

Train Avg F1  224: 0.24638758964587926

Val Avg Loss  224: 0.217582

Val Avg F1  224:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 225
--------------------------------------------------------------
Epoch:  225        1 Batch loss: 0.174803 Batch F1: 0.0
Epoch:  225        2 Batch loss: 0.264363 Batch F1: 0.0
Epoch:  225        3 Batch loss: 0.209827 Batch F1: 0.1111111111111111
Epoch:  225        4 Batch loss: 0.218363 Batch F1: 0.2962962962962963
Epoch:  225        5 Batch loss: 0.247702 Batch F1: 0.35714285714285715
Epoch:  225        6 Batch loss: 0.216359 Batch F1: 0.4166666666666667
Epoch:  225        7 Batch loss: 0.213033 Batch F1: 0.34782608695652173
Epoch:  225        8 Batch loss: 0.246828 Batch F1: 0.16666666666666666
Epoch:  225        9 Batch loss: 0.216659 Batch F1: 0.33333333333333337
Epoch:  225       10 Batch loss: 0.213593 Batch F1: 0.1
Epoch:  225       11 Batch loss: 0.285508 Batch F1: 0.0
Epoch:  225       12 Batch loss: 0.192295 Batch F1: 0.0
Train Avg Loss  225: 0.224944

Train Avg F1  225: 0.17742025151445442

Val Avg Loss  225: 0.217077

Val Avg F1  225:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 226
--------------------------------------------------------------
Epoch:  226        1 Batch loss: 0.198146 Batch F1: 0.11764705882352941
Epoch:  226        2 Batch loss: 0.212872 Batch F1: 0.0
Epoch:  226        3 Batch loss: 0.209357 Batch F1: 0.0
Epoch:  226        4 Batch loss: 0.225602 Batch F1: 0.0
Epoch:  226        5 Batch loss: 0.231034 Batch F1: 0.0
Epoch:  226        6 Batch loss: 0.250523 Batch F1: 0.1739130434782609
Epoch:  226        7 Batch loss: 0.233733 Batch F1: 0.32000000000000006
Epoch:  226        8 Batch loss: 0.232756 Batch F1: 0.3846153846153846
Epoch:  226        9 Batch loss: 0.260954 Batch F1: 0.07407407407407407
Epoch:  226       10 Batch loss: 0.201647 Batch F1: 0.34782608695652173
Epoch:  226       11 Batch loss: 0.192388 Batch F1: 0.43478260869565216
Epoch:  226       12 Batch loss: 0.226793 Batch F1: 0.4615384615384615
Train Avg Loss  226: 0.222984

Train Avg F1  226: 0.19286639318182372

Val Avg Loss  226: 0.220076

Val Avg F1  226:  0.23741441020852788

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 227
--------------------------------------------------------------
Epoch:  227        1 Batch loss: 0.200539 Batch F1: 0.2105263157894737
Epoch:  227        2 Batch loss: 0.222575 Batch F1: 0.24
Epoch:  227        3 Batch loss: 0.213042 Batch F1: 0.28571428571428575
Epoch:  227        4 Batch loss: 0.246645 Batch F1: 0.15384615384615385
Epoch:  227        5 Batch loss: 0.225553 Batch F1: 0.09090909090909091
Epoch:  227        6 Batch loss: 0.232338 Batch F1: 0.0
Epoch:  227        7 Batch loss: 0.237004 Batch F1: 0.0
Epoch:  227        8 Batch loss: 0.220766 Batch F1: 0.24
Epoch:  227        9 Batch loss: 0.206542 Batch F1: 0.56
Epoch:  227       10 Batch loss: 0.225824 Batch F1: 0.09523809523809525
Epoch:  227       11 Batch loss: 0.215677 Batch F1: 0.10526315789473682
Epoch:  227       12 Batch loss: 0.237880 Batch F1: 0.0
Train Avg Loss  227: 0.223699

Train Avg F1  227: 0.16512475828265302

Val Avg Loss  227: 0.216617

Val Avg F1  227:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 228
--------------------------------------------------------------
Epoch:  228        1 Batch loss: 0.286137 Batch F1: 0.0
Epoch:  228        2 Batch loss: 0.253220 Batch F1: 0.26666666666666666
Epoch:  228        3 Batch loss: 0.237177 Batch F1: 0.4
Epoch:  228        4 Batch loss: 0.218063 Batch F1: 0.25
Epoch:  228        5 Batch loss: 0.210700 Batch F1: 0.48000000000000004
Epoch:  228        6 Batch loss: 0.212344 Batch F1: 0.4800000000000001
Epoch:  228        7 Batch loss: 0.234301 Batch F1: 0.41379310344827586
Epoch:  228        8 Batch loss: 0.224235 Batch F1: 0.0
Epoch:  228        9 Batch loss: 0.221264 Batch F1: 0.0
Epoch:  228       10 Batch loss: 0.220846 Batch F1: 0.0
Epoch:  228       11 Batch loss: 0.215563 Batch F1: 0.0
Epoch:  228       12 Batch loss: 0.191786 Batch F1: 0.0
Train Avg Loss  228: 0.227136

Train Avg F1  228: 0.19087164750957855

Val Avg Loss  228: 0.217388

Val Avg F1  228:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 229
--------------------------------------------------------------
Epoch:  229        1 Batch loss: 0.243566 Batch F1: 0.08695652173913045
Epoch:  229        2 Batch loss: 0.226087 Batch F1: 0.08333333333333333
Epoch:  229        3 Batch loss: 0.180853 Batch F1: 0.35294117647058826
Epoch:  229        4 Batch loss: 0.222759 Batch F1: 0.09090909090909091
Epoch:  229        5 Batch loss: 0.216981 Batch F1: 0.2105263157894737
Epoch:  229        6 Batch loss: 0.193593 Batch F1: 0.0
Epoch:  229        7 Batch loss: 0.272467 Batch F1: 0.0
Epoch:  229        8 Batch loss: 0.195116 Batch F1: 0.0
Epoch:  229        9 Batch loss: 0.228486 Batch F1: 0.0
Epoch:  229       10 Batch loss: 0.241038 Batch F1: 0.0
Epoch:  229       11 Batch loss: 0.245983 Batch F1: 0.0
Epoch:  229       12 Batch loss: 0.237695 Batch F1: 0.21052631578947367
Train Avg Loss  229: 0.225385

Train Avg F1  229: 0.0862660628359242

Val Avg Loss  229: 0.219648

Val Avg F1  229:  0.24216524216524216

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 230
--------------------------------------------------------------
Epoch:  230        1 Batch loss: 0.236815 Batch F1: 0.4
Epoch:  230        2 Batch loss: 0.240480 Batch F1: 0.14814814814814817
Epoch:  230        3 Batch loss: 0.227749 Batch F1: 0.29629629629629634
Epoch:  230        4 Batch loss: 0.220997 Batch F1: 0.5789473684210525
Epoch:  230        5 Batch loss: 0.241274 Batch F1: 0.40909090909090917
Epoch:  230        6 Batch loss: 0.222034 Batch F1: 0.47058823529411764
Epoch:  230        7 Batch loss: 0.229776 Batch F1: 0.34782608695652173
Epoch:  230        8 Batch loss: 0.210731 Batch F1: 0.21052631578947367
Epoch:  230        9 Batch loss: 0.221732 Batch F1: 0.0
Epoch:  230       10 Batch loss: 0.228692 Batch F1: 0.0
Epoch:  230       11 Batch loss: 0.181151 Batch F1: 0.0
Epoch:  230       12 Batch loss: 0.241085 Batch F1: 0.0
Train Avg Loss  230: 0.225210

Train Avg F1  230: 0.2384519466663766

Val Avg Loss  230: 0.218525

Val Avg F1  230:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 231
--------------------------------------------------------------
Epoch:  231        1 Batch loss: 0.246716 Batch F1: 0.0
Epoch:  231        2 Batch loss: 0.218762 Batch F1: 0.0
Epoch:  231        3 Batch loss: 0.241175 Batch F1: 0.0
Epoch:  231        4 Batch loss: 0.221076 Batch F1: 0.0
Epoch:  231        5 Batch loss: 0.200017 Batch F1: 0.0
Epoch:  231        6 Batch loss: 0.221578 Batch F1: 0.0
Epoch:  231        7 Batch loss: 0.270211 Batch F1: 0.0
Epoch:  231        8 Batch loss: 0.215025 Batch F1: 0.0
Epoch:  231        9 Batch loss: 0.217509 Batch F1: 0.0
Epoch:  231       10 Batch loss: 0.204869 Batch F1: 0.23529411764705882
Epoch:  231       11 Batch loss: 0.214731 Batch F1: 0.2105263157894737
Epoch:  231       12 Batch loss: 0.253633 Batch F1: 0.0
Train Avg Loss  231: 0.227108

Train Avg F1  231: 0.037151702786377715

Val Avg Loss  231: 0.217817

Val Avg F1  231:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 232
--------------------------------------------------------------
Epoch:  232        1 Batch loss: 0.242062 Batch F1: 0.0
Epoch:  232        2 Batch loss: 0.206138 Batch F1: 0.0
Epoch:  232        3 Batch loss: 0.225242 Batch F1: 0.0
Epoch:  232        4 Batch loss: 0.217519 Batch F1: 0.0
Epoch:  232        5 Batch loss: 0.223057 Batch F1: 0.0
Epoch:  232        6 Batch loss: 0.224152 Batch F1: 0.0
Epoch:  232        7 Batch loss: 0.210284 Batch F1: 0.0
Epoch:  232        8 Batch loss: 0.222389 Batch F1: 0.0
Epoch:  232        9 Batch loss: 0.243283 Batch F1: 0.0
Epoch:  232       10 Batch loss: 0.240524 Batch F1: 0.08000000000000002
Epoch:  232       11 Batch loss: 0.249331 Batch F1: 0.42857142857142855
Epoch:  232       12 Batch loss: 0.169914 Batch F1: 0.3076923076923077
Train Avg Loss  232: 0.222825

Train Avg F1  232: 0.06802197802197803

Val Avg Loss  232: 0.218993

Val Avg F1  232:  0.2640409207161125

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 233
--------------------------------------------------------------
Epoch:  233        1 Batch loss: 0.184622 Batch F1: 0.4166666666666667
Epoch:  233        2 Batch loss: 0.199185 Batch F1: 0.25
Epoch:  233        3 Batch loss: 0.233769 Batch F1: 0.14285714285714285
Epoch:  233        4 Batch loss: 0.209332 Batch F1: 0.18181818181818182
Epoch:  233        5 Batch loss: 0.228968 Batch F1: 0.22222222222222218
Epoch:  233        6 Batch loss: 0.217001 Batch F1: 0.35714285714285715
Epoch:  233        7 Batch loss: 0.270373 Batch F1: 0.2666666666666667
Epoch:  233        8 Batch loss: 0.245769 Batch F1: 0.37499999999999994
Epoch:  233        9 Batch loss: 0.182859 Batch F1: 0.4761904761904762
Epoch:  233       10 Batch loss: 0.241144 Batch F1: 0.3333333333333333
Epoch:  233       11 Batch loss: 0.198503 Batch F1: 0.43478260869565216
Epoch:  233       12 Batch loss: 0.265540 Batch F1: 0.1
Train Avg Loss  233: 0.223089

Train Avg F1  233: 0.29639001296609996

Val Avg Loss  233: 0.219446

Val Avg F1  233:  0.23980676328502412

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 234
--------------------------------------------------------------
Epoch:  234        1 Batch loss: 0.232096 Batch F1: 0.4285714285714285
Epoch:  234        2 Batch loss: 0.202040 Batch F1: 0.3
Epoch:  234        3 Batch loss: 0.194826 Batch F1: 0.23529411764705882
Epoch:  234        4 Batch loss: 0.237152 Batch F1: 0.37037037037037035
Epoch:  234        5 Batch loss: 0.187121 Batch F1: 0.22222222222222224
Epoch:  234        6 Batch loss: 0.230829 Batch F1: 0.08333333333333334
Epoch:  234        7 Batch loss: 0.205288 Batch F1: 0.3478260869565218
Epoch:  234        8 Batch loss: 0.224257 Batch F1: 0.19047619047619047
Epoch:  234        9 Batch loss: 0.226840 Batch F1: 0.37037037037037035
Epoch:  234       10 Batch loss: 0.269802 Batch F1: 0.27586206896551724
Epoch:  234       11 Batch loss: 0.215983 Batch F1: 0.2727272727272727
Epoch:  234       12 Batch loss: 0.246458 Batch F1: 0.2962962962962963
Train Avg Loss  234: 0.222724

Train Avg F1  234: 0.2827791464947152

Val Avg Loss  234: 0.218367

Val Avg F1  234:  0.25022727272727274

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 235
--------------------------------------------------------------
Epoch:  235        1 Batch loss: 0.213019 Batch F1: 0.25
Epoch:  235        2 Batch loss: 0.246555 Batch F1: 0.16
Epoch:  235        3 Batch loss: 0.246658 Batch F1: 0.15384615384615385
Epoch:  235        4 Batch loss: 0.233128 Batch F1: 0.37037037037037035
Epoch:  235        5 Batch loss: 0.206825 Batch F1: 0.36363636363636365
Epoch:  235        6 Batch loss: 0.248761 Batch F1: 0.26666666666666666
Epoch:  235        7 Batch loss: 0.181380 Batch F1: 0.4210526315789474
Epoch:  235        8 Batch loss: 0.210039 Batch F1: 0.2222222222222222
Epoch:  235        9 Batch loss: 0.224511 Batch F1: 0.1818181818181818
Epoch:  235       10 Batch loss: 0.222279 Batch F1: 0.2727272727272727
Epoch:  235       11 Batch loss: 0.226927 Batch F1: 0.48275862068965514
Epoch:  235       12 Batch loss: 0.207462 Batch F1: 0.3636363636363636
Train Avg Loss  235: 0.222295

Train Avg F1  235: 0.2923945705993498

Val Avg Loss  235: 0.218366

Val Avg F1  235:  0.24824016563147

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 236
--------------------------------------------------------------
Epoch:  236        1 Batch loss: 0.231238 Batch F1: 0.19047619047619047
Epoch:  236        2 Batch loss: 0.191670 Batch F1: 0.2857142857142857
Epoch:  236        3 Batch loss: 0.210406 Batch F1: 0.2857142857142857
Epoch:  236        4 Batch loss: 0.193920 Batch F1: 0.45454545454545453
Epoch:  236        5 Batch loss: 0.268343 Batch F1: 0.06896551724137931
Epoch:  236        6 Batch loss: 0.231060 Batch F1: 0.16000000000000003
Epoch:  236        7 Batch loss: 0.203161 Batch F1: 0.3529411764705882
Epoch:  236        8 Batch loss: 0.277362 Batch F1: 0.1875
Epoch:  236        9 Batch loss: 0.229198 Batch F1: 0.32
Epoch:  236       10 Batch loss: 0.225575 Batch F1: 0.3846153846153846
Epoch:  236       11 Batch loss: 0.207658 Batch F1: 0.2857142857142857
Epoch:  236       12 Batch loss: 0.198383 Batch F1: 0.4
Train Avg Loss  236: 0.222331

Train Avg F1  236: 0.2813488817076545

Val Avg Loss  236: 0.217898

Val Avg F1  236:  0.2185045948203843

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 237
--------------------------------------------------------------
Epoch:  237        1 Batch loss: 0.193654 Batch F1: 0.4
Epoch:  237        2 Batch loss: 0.217137 Batch F1: 0.2857142857142857
Epoch:  237        3 Batch loss: 0.173786 Batch F1: 0.5
Epoch:  237        4 Batch loss: 0.216978 Batch F1: 0.0
Epoch:  237        5 Batch loss: 0.221183 Batch F1: 0.0
Epoch:  237        6 Batch loss: 0.279006 Batch F1: 0.0
Epoch:  237        7 Batch loss: 0.224303 Batch F1: 0.0
Epoch:  237        8 Batch loss: 0.221058 Batch F1: 0.0
Epoch:  237        9 Batch loss: 0.224862 Batch F1: 0.2608695652173913
Epoch:  237       10 Batch loss: 0.242638 Batch F1: 0.375
Epoch:  237       11 Batch loss: 0.231195 Batch F1: 0.30769230769230765
Epoch:  237       12 Batch loss: 0.228819 Batch F1: 0.3478260869565218
Train Avg Loss  237: 0.222885

Train Avg F1  237: 0.20642518713170888

Val Avg Loss  237: 0.226008

Val Avg F1  237:  0.3328184443966686

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 238
--------------------------------------------------------------
Epoch:  238        1 Batch loss: 0.216848 Batch F1: 0.36363636363636365
Epoch:  238        2 Batch loss: 0.243358 Batch F1: 0.6046511627906976
Epoch:  238        3 Batch loss: 0.225423 Batch F1: 0.37037037037037035
Epoch:  238        4 Batch loss: 0.229299 Batch F1: 0.43750000000000006
Epoch:  238        5 Batch loss: 0.227324 Batch F1: 0.4137931034482759
Epoch:  238        6 Batch loss: 0.220454 Batch F1: 0.3333333333333333
Epoch:  238        7 Batch loss: 0.213260 Batch F1: 0.10526315789473685
Epoch:  238        8 Batch loss: 0.217355 Batch F1: 0.37037037037037035
Epoch:  238        9 Batch loss: 0.250308 Batch F1: 0.35714285714285715
Epoch:  238       10 Batch loss: 0.214185 Batch F1: 0.1818181818181818
Epoch:  238       11 Batch loss: 0.216646 Batch F1: 0.1904761904761905
Epoch:  238       12 Batch loss: 0.205309 Batch F1: 0.0
Train Avg Loss  238: 0.223314

Train Avg F1  238: 0.3106962576067815

Val Avg Loss  238: 0.217986

Val Avg F1  238:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 239
--------------------------------------------------------------
Epoch:  239        1 Batch loss: 0.245956 Batch F1: 0.0
Epoch:  239        2 Batch loss: 0.230135 Batch F1: 0.0
Epoch:  239        3 Batch loss: 0.231304 Batch F1: 0.0
Epoch:  239        4 Batch loss: 0.248075 Batch F1: 0.0
Epoch:  239        5 Batch loss: 0.223116 Batch F1: 0.0
Epoch:  239        6 Batch loss: 0.252155 Batch F1: 0.0
Epoch:  239        7 Batch loss: 0.228889 Batch F1: 0.0
Epoch:  239        8 Batch loss: 0.207026 Batch F1: 0.0
Epoch:  239        9 Batch loss: 0.229044 Batch F1: 0.0
Epoch:  239       10 Batch loss: 0.218927 Batch F1: 0.0
Epoch:  239       11 Batch loss: 0.233878 Batch F1: 0.0
Epoch:  239       12 Batch loss: 0.208614 Batch F1: 0.0
Train Avg Loss  239: 0.229760

Train Avg F1  239: 0.0

Val Avg Loss  239: 0.217562

Val Avg F1  239:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 240
--------------------------------------------------------------
Epoch:  240        1 Batch loss: 0.180597 Batch F1: 0.0
Epoch:  240        2 Batch loss: 0.238483 Batch F1: 0.0
Epoch:  240        3 Batch loss: 0.199148 Batch F1: 0.0
Epoch:  240        4 Batch loss: 0.214052 Batch F1: 0.0
Epoch:  240        5 Batch loss: 0.216406 Batch F1: 0.0
Epoch:  240        6 Batch loss: 0.238576 Batch F1: 0.0
Epoch:  240        7 Batch loss: 0.214349 Batch F1: 0.0
Epoch:  240        8 Batch loss: 0.252988 Batch F1: 0.0
Epoch:  240        9 Batch loss: 0.242602 Batch F1: 0.0
Epoch:  240       10 Batch loss: 0.269733 Batch F1: 0.0
Epoch:  240       11 Batch loss: 0.236281 Batch F1: 0.0
Epoch:  240       12 Batch loss: 0.223495 Batch F1: 0.5454545454545455
Train Avg Loss  240: 0.227226

Train Avg F1  240: 0.04545454545454546

Val Avg Loss  240: 0.232242

Val Avg F1  240:  0.42969348659003825

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 241
--------------------------------------------------------------
Epoch:  241        1 Batch loss: 0.253356 Batch F1: 0.43902439024390244
Epoch:  241        2 Batch loss: 0.245043 Batch F1: 0.4210526315789474
Epoch:  241        3 Batch loss: 0.222135 Batch F1: 0.43478260869565216
Epoch:  241        4 Batch loss: 0.231709 Batch F1: 0.0
Epoch:  241        5 Batch loss: 0.230492 Batch F1: 0.0
Epoch:  241        6 Batch loss: 0.189604 Batch F1: 0.0
Epoch:  241        7 Batch loss: 0.192841 Batch F1: 0.0
Epoch:  241        8 Batch loss: 0.228155 Batch F1: 0.0
Epoch:  241        9 Batch loss: 0.260645 Batch F1: 0.0
Epoch:  241       10 Batch loss: 0.219167 Batch F1: 0.0
Epoch:  241       11 Batch loss: 0.221079 Batch F1: 0.0
Epoch:  241       12 Batch loss: 0.246979 Batch F1: 0.09999999999999999
Train Avg Loss  241: 0.228434

Train Avg F1  241: 0.11623830254320851

Val Avg Loss  241: 0.221717

Val Avg F1  241:  0.32741060025542784

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 242
--------------------------------------------------------------
Epoch:  242        1 Batch loss: 0.272703 Batch F1: 0.33333333333333337
Epoch:  242        2 Batch loss: 0.223071 Batch F1: 0.3448275862068966
Epoch:  242        3 Batch loss: 0.228132 Batch F1: 0.31999999999999995
Epoch:  242        4 Batch loss: 0.232150 Batch F1: 0.5
Epoch:  242        5 Batch loss: 0.200932 Batch F1: 0.47619047619047616
Epoch:  242        6 Batch loss: 0.209519 Batch F1: 0.4166666666666667
Epoch:  242        7 Batch loss: 0.211572 Batch F1: 0.0
Epoch:  242        8 Batch loss: 0.227663 Batch F1: 0.0
Epoch:  242        9 Batch loss: 0.256836 Batch F1: 0.0
Epoch:  242       10 Batch loss: 0.217237 Batch F1: 0.0
Epoch:  242       11 Batch loss: 0.217045 Batch F1: 0.0
Epoch:  242       12 Batch loss: 0.226550 Batch F1: 0.0
Train Avg Loss  242: 0.226951

Train Avg F1  242: 0.19925150519978105

Val Avg Loss  242: 0.217725

Val Avg F1  242:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 243
--------------------------------------------------------------
Epoch:  243        1 Batch loss: 0.210604 Batch F1: 0.0
Epoch:  243        2 Batch loss: 0.230292 Batch F1: 0.0
Epoch:  243        3 Batch loss: 0.193750 Batch F1: 0.0
Epoch:  243        4 Batch loss: 0.226569 Batch F1: 0.0
Epoch:  243        5 Batch loss: 0.175789 Batch F1: 0.0
Epoch:  243        6 Batch loss: 0.241080 Batch F1: 0.0
Epoch:  243        7 Batch loss: 0.262317 Batch F1: 0.0
Epoch:  243        8 Batch loss: 0.231582 Batch F1: 0.0
Epoch:  243        9 Batch loss: 0.278768 Batch F1: 0.0
Epoch:  243       10 Batch loss: 0.233505 Batch F1: 0.3333333333333333
Epoch:  243       11 Batch loss: 0.222270 Batch F1: 0.2727272727272727
Epoch:  243       12 Batch loss: 0.186925 Batch F1: 0.5555555555555556
Train Avg Loss  243: 0.224454

Train Avg F1  243: 0.09680134680134679

Val Avg Loss  243: 0.222946

Val Avg F1  243:  0.312276554030677

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 244
--------------------------------------------------------------
Epoch:  244        1 Batch loss: 0.229979 Batch F1: 0.5294117647058824
Epoch:  244        2 Batch loss: 0.217137 Batch F1: 0.5
Epoch:  244        3 Batch loss: 0.222296 Batch F1: 0.36363636363636365
Epoch:  244        4 Batch loss: 0.234563 Batch F1: 0.2608695652173913
Epoch:  244        5 Batch loss: 0.210935 Batch F1: 0.1111111111111111
Epoch:  244        6 Batch loss: 0.230800 Batch F1: 0.0
Epoch:  244        7 Batch loss: 0.211957 Batch F1: 0.0
Epoch:  244        8 Batch loss: 0.241264 Batch F1: 0.0
Epoch:  244        9 Batch loss: 0.211337 Batch F1: 0.0
Epoch:  244       10 Batch loss: 0.230958 Batch F1: 0.0
Epoch:  244       11 Batch loss: 0.213059 Batch F1: 0.0
Epoch:  244       12 Batch loss: 0.250065 Batch F1: 0.0
Train Avg Loss  244: 0.225362

Train Avg F1  244: 0.14708573372256237

Val Avg Loss  244: 0.222258

Val Avg F1  244:  0.2554347826086957

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 245
--------------------------------------------------------------
Epoch:  245        1 Batch loss: 0.231340 Batch F1: 0.37037037037037035
Epoch:  245        2 Batch loss: 0.238684 Batch F1: 0.3076923076923077
Epoch:  245        3 Batch loss: 0.235951 Batch F1: 0.2857142857142857
Epoch:  245        4 Batch loss: 0.206546 Batch F1: 0.0
Epoch:  245        5 Batch loss: 0.244102 Batch F1: 0.0
Epoch:  245        6 Batch loss: 0.250857 Batch F1: 0.0
Epoch:  245        7 Batch loss: 0.194926 Batch F1: 0.0
Epoch:  245        8 Batch loss: 0.226159 Batch F1: 0.0
Epoch:  245        9 Batch loss: 0.262407 Batch F1: 0.07692307692307693
Epoch:  245       10 Batch loss: 0.208479 Batch F1: 0.0
Epoch:  245       11 Batch loss: 0.207108 Batch F1: 0.4347826086956522
Epoch:  245       12 Batch loss: 0.201493 Batch F1: 0.31578947368421056
Train Avg Loss  245: 0.225671

Train Avg F1  245: 0.14927267692332527

Val Avg Loss  245: 0.219527

Val Avg F1  245:  0.2696969696969697

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 246
--------------------------------------------------------------
Epoch:  246        1 Batch loss: 0.214526 Batch F1: 0.3333333333333333
Epoch:  246        2 Batch loss: 0.236362 Batch F1: 0.31249999999999994
Epoch:  246        3 Batch loss: 0.240379 Batch F1: 0.21428571428571427
Epoch:  246        4 Batch loss: 0.191484 Batch F1: 0.45454545454545453
Epoch:  246        5 Batch loss: 0.237744 Batch F1: 0.3846153846153846
Epoch:  246        6 Batch loss: 0.222396 Batch F1: 0.48275862068965514
Epoch:  246        7 Batch loss: 0.236063 Batch F1: 0.35714285714285715
Epoch:  246        8 Batch loss: 0.217078 Batch F1: 0.23999999999999996
Epoch:  246        9 Batch loss: 0.190886 Batch F1: 0.23529411764705882
Epoch:  246       10 Batch loss: 0.185261 Batch F1: 0.0
Epoch:  246       11 Batch loss: 0.228049 Batch F1: 0.0
Epoch:  246       12 Batch loss: 0.286885 Batch F1: 0.0
Train Avg Loss  246: 0.223926

Train Avg F1  246: 0.25120629018828816

Val Avg Loss  246: 0.219588

Val Avg F1  246:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 247
--------------------------------------------------------------
Epoch:  247        1 Batch loss: 0.165254 Batch F1: 0.0
Epoch:  247        2 Batch loss: 0.235611 Batch F1: 0.0
Epoch:  247        3 Batch loss: 0.192076 Batch F1: 0.0
Epoch:  247        4 Batch loss: 0.200442 Batch F1: 0.0
Epoch:  247        5 Batch loss: 0.268261 Batch F1: 0.07692307692307691
Epoch:  247        6 Batch loss: 0.247073 Batch F1: 0.3870967741935483
Epoch:  247        7 Batch loss: 0.233522 Batch F1: 0.3703703703703704
Epoch:  247        8 Batch loss: 0.238567 Batch F1: 0.2962962962962963
Epoch:  247        9 Batch loss: 0.233724 Batch F1: 0.4666666666666667
Epoch:  247       10 Batch loss: 0.215788 Batch F1: 0.30769230769230765
Epoch:  247       11 Batch loss: 0.232073 Batch F1: 0.43750000000000006
Epoch:  247       12 Batch loss: 0.215993 Batch F1: 0.13333333333333333
Train Avg Loss  247: 0.223199

Train Avg F1  247: 0.20632323545629996

Val Avg Loss  247: 0.222475

Val Avg F1  247:  0.2484903381642512

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 248
--------------------------------------------------------------
Epoch:  248        1 Batch loss: 0.233803 Batch F1: 0.2962962962962963
Epoch:  248        2 Batch loss: 0.231615 Batch F1: 0.35714285714285715
Epoch:  248        3 Batch loss: 0.236885 Batch F1: 0.43750000000000006
Epoch:  248        4 Batch loss: 0.228302 Batch F1: 0.3809523809523809
Epoch:  248        5 Batch loss: 0.204115 Batch F1: 0.4166666666666667
Epoch:  248        6 Batch loss: 0.221379 Batch F1: 0.0
Epoch:  248        7 Batch loss: 0.254508 Batch F1: 0.0
Epoch:  248        8 Batch loss: 0.185817 Batch F1: 0.0
Epoch:  248        9 Batch loss: 0.222097 Batch F1: 0.09523809523809525
Epoch:  248       10 Batch loss: 0.235486 Batch F1: 0.0
Epoch:  248       11 Batch loss: 0.183161 Batch F1: 0.0
Epoch:  248       12 Batch loss: 0.240486 Batch F1: 0.0
Train Avg Loss  248: 0.223138

Train Avg F1  248: 0.16531635802469138

Val Avg Loss  248: 0.217368

Val Avg F1  248:  0.02173913043478261

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 249
--------------------------------------------------------------
Epoch:  249        1 Batch loss: 0.209192 Batch F1: 0.1111111111111111
Epoch:  249        2 Batch loss: 0.224559 Batch F1: 0.4137931034482759
Epoch:  249        3 Batch loss: 0.184668 Batch F1: 0.0
Epoch:  249        4 Batch loss: 0.203908 Batch F1: 0.2857142857142857
Epoch:  249        5 Batch loss: 0.220449 Batch F1: 0.3
Epoch:  249        6 Batch loss: 0.184925 Batch F1: 0.4
Epoch:  249        7 Batch loss: 0.263584 Batch F1: 0.0
Epoch:  249        8 Batch loss: 0.270692 Batch F1: 0.0
Epoch:  249        9 Batch loss: 0.212995 Batch F1: 0.37037037037037035
Epoch:  249       10 Batch loss: 0.248822 Batch F1: 0.16
Epoch:  249       11 Batch loss: 0.241143 Batch F1: 0.17391304347826086
Epoch:  249       12 Batch loss: 0.222776 Batch F1: 0.34782608695652173
Train Avg Loss  249: 0.223976

Train Avg F1  249: 0.21356066675656882

Val Avg Loss  249: 0.222501

Val Avg F1  249:  0.3389945652173913

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 250
--------------------------------------------------------------
Epoch:  250        1 Batch loss: 0.236863 Batch F1: 0.5625
Epoch:  250        2 Batch loss: 0.181170 Batch F1: 0.5599999999999999
Epoch:  250        3 Batch loss: 0.213332 Batch F1: 0.4444444444444444
Epoch:  250        4 Batch loss: 0.261137 Batch F1: 0.26666666666666666
Epoch:  250        5 Batch loss: 0.200104 Batch F1: 0.2
Epoch:  250        6 Batch loss: 0.209576 Batch F1: 0.11764705882352941
Epoch:  250        7 Batch loss: 0.232050 Batch F1: 0.1
Epoch:  250        8 Batch loss: 0.230903 Batch F1: 0.0
Epoch:  250        9 Batch loss: 0.250789 Batch F1: 0.0
Epoch:  250       10 Batch loss: 0.246740 Batch F1: 0.0
Epoch:  250       11 Batch loss: 0.187227 Batch F1: 0.0
Epoch:  250       12 Batch loss: 0.244444 Batch F1: 0.19999999999999998
Train Avg Loss  250: 0.224528

Train Avg F1  250: 0.20427151416122005

Val Avg Loss  250: 0.220180

Val Avg F1  250:  0.2586455689903966

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 251
--------------------------------------------------------------
Epoch:  251        1 Batch loss: 0.215451 Batch F1: 0.2727272727272727
Epoch:  251        2 Batch loss: 0.233124 Batch F1: 0.43749999999999994
Epoch:  251        3 Batch loss: 0.265436 Batch F1: 0.41025641025641024
Epoch:  251        4 Batch loss: 0.225891 Batch F1: 0.25
Epoch:  251        5 Batch loss: 0.227287 Batch F1: 0.38461538461538464
Epoch:  251        6 Batch loss: 0.221255 Batch F1: 0.3809523809523809
Epoch:  251        7 Batch loss: 0.226599 Batch F1: 0.2
Epoch:  251        8 Batch loss: 0.220936 Batch F1: 0.37037037037037035
Epoch:  251        9 Batch loss: 0.211179 Batch F1: 0.27272727272727276
Epoch:  251       10 Batch loss: 0.217710 Batch F1: 0.0
Epoch:  251       11 Batch loss: 0.255491 Batch F1: 0.0
Epoch:  251       12 Batch loss: 0.161369 Batch F1: 0.0
Train Avg Loss  251: 0.223477

Train Avg F1  251: 0.24826242430409098

Val Avg Loss  251: 0.218114

Val Avg F1  251:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 252
--------------------------------------------------------------
Epoch:  252        1 Batch loss: 0.248364 Batch F1: 0.0
Epoch:  252        2 Batch loss: 0.237661 Batch F1: 0.14814814814814814
Epoch:  252        3 Batch loss: 0.219646 Batch F1: 0.10526315789473684
Epoch:  252        4 Batch loss: 0.217853 Batch F1: 0.28571428571428575
Epoch:  252        5 Batch loss: 0.250144 Batch F1: 0.3428571428571428
Epoch:  252        6 Batch loss: 0.222891 Batch F1: 0.3478260869565218
Epoch:  252        7 Batch loss: 0.212382 Batch F1: 0.5
Epoch:  252        8 Batch loss: 0.230300 Batch F1: 0.0
Epoch:  252        9 Batch loss: 0.204780 Batch F1: 0.41379310344827586
Epoch:  252       10 Batch loss: 0.201690 Batch F1: 0.2105263157894737
Epoch:  252       11 Batch loss: 0.216614 Batch F1: 0.2857142857142857
Epoch:  252       12 Batch loss: 0.209074 Batch F1: 0.0
Train Avg Loss  252: 0.222616

Train Avg F1  252: 0.2199868772102392

Val Avg Loss  252: 0.217236

Val Avg F1  252:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 253
--------------------------------------------------------------
Epoch:  253        1 Batch loss: 0.223217 Batch F1: 0.0
Epoch:  253        2 Batch loss: 0.270846 Batch F1: 0.0
Epoch:  253        3 Batch loss: 0.196045 Batch F1: 0.2222222222222222
Epoch:  253        4 Batch loss: 0.234121 Batch F1: 0.1
Epoch:  253        5 Batch loss: 0.226368 Batch F1: 0.1
Epoch:  253        6 Batch loss: 0.240909 Batch F1: 0.09090909090909091
Epoch:  253        7 Batch loss: 0.216029 Batch F1: 0.10526315789473684
Epoch:  253        8 Batch loss: 0.192198 Batch F1: 0.3809523809523809
Epoch:  253        9 Batch loss: 0.215825 Batch F1: 0.3636363636363636
Epoch:  253       10 Batch loss: 0.217698 Batch F1: 0.3333333333333333
Epoch:  253       11 Batch loss: 0.231277 Batch F1: 0.3448275862068966
Epoch:  253       12 Batch loss: 0.204662 Batch F1: 0.45454545454545453
Train Avg Loss  253: 0.222433

Train Avg F1  253: 0.2079741324750399

Val Avg Loss  253: 0.218279

Val Avg F1  253:  0.25367892976588624

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 254
--------------------------------------------------------------
Epoch:  254        1 Batch loss: 0.236653 Batch F1: 0.32000000000000006
Epoch:  254        2 Batch loss: 0.221160 Batch F1: 0.3636363636363636
Epoch:  254        3 Batch loss: 0.228155 Batch F1: 0.35714285714285715
Epoch:  254        4 Batch loss: 0.218860 Batch F1: 0.0909090909090909
Epoch:  254        5 Batch loss: 0.234243 Batch F1: 0.25
Epoch:  254        6 Batch loss: 0.203909 Batch F1: 0.28571428571428575
Epoch:  254        7 Batch loss: 0.205985 Batch F1: 0.48275862068965514
Epoch:  254        8 Batch loss: 0.204938 Batch F1: 0.2
Epoch:  254        9 Batch loss: 0.233385 Batch F1: 0.3870967741935484
Epoch:  254       10 Batch loss: 0.208225 Batch F1: 0.5
Epoch:  254       11 Batch loss: 0.232351 Batch F1: 0.14814814814814814
Epoch:  254       12 Batch loss: 0.237600 Batch F1: 0.1111111111111111
Train Avg Loss  254: 0.222122

Train Avg F1  254: 0.29137643762875504

Val Avg Loss  254: 0.218520

Val Avg F1  254:  0.2222222222222222

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 255
--------------------------------------------------------------
Epoch:  255        1 Batch loss: 0.211747 Batch F1: 0.22222222222222224
Epoch:  255        2 Batch loss: 0.235114 Batch F1: 0.08695652173913045
Epoch:  255        3 Batch loss: 0.188481 Batch F1: 0.0
Epoch:  255        4 Batch loss: 0.228474 Batch F1: 0.0
Epoch:  255        5 Batch loss: 0.250815 Batch F1: 0.0909090909090909
Epoch:  255        6 Batch loss: 0.246418 Batch F1: 0.0
Epoch:  255        7 Batch loss: 0.216162 Batch F1: 0.0
Epoch:  255        8 Batch loss: 0.199369 Batch F1: 0.0
Epoch:  255        9 Batch loss: 0.260956 Batch F1: 0.0
Epoch:  255       10 Batch loss: 0.205845 Batch F1: 0.2727272727272727
Epoch:  255       11 Batch loss: 0.225099 Batch F1: 0.36363636363636365
Epoch:  255       12 Batch loss: 0.203917 Batch F1: 0.37499999999999994
Train Avg Loss  255: 0.222700

Train Avg F1  255: 0.11762095593617332

Val Avg Loss  255: 0.220689

Val Avg F1  255:  0.2945271574303832

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 256
--------------------------------------------------------------
Epoch:  256        1 Batch loss: 0.232254 Batch F1: 0.4
Epoch:  256        2 Batch loss: 0.214346 Batch F1: 0.2608695652173913
Epoch:  256        3 Batch loss: 0.196885 Batch F1: 0.2
Epoch:  256        4 Batch loss: 0.234031 Batch F1: 0.0
Epoch:  256        5 Batch loss: 0.199650 Batch F1: 0.2222222222222222
Epoch:  256        6 Batch loss: 0.196774 Batch F1: 0.0
Epoch:  256        7 Batch loss: 0.273276 Batch F1: 0.0
Epoch:  256        8 Batch loss: 0.241090 Batch F1: 0.0
Epoch:  256        9 Batch loss: 0.200829 Batch F1: 0.3478260869565218
Epoch:  256       10 Batch loss: 0.249643 Batch F1: 0.2962962962962963
Epoch:  256       11 Batch loss: 0.240996 Batch F1: 0.21428571428571427
Epoch:  256       12 Batch loss: 0.203448 Batch F1: 0.3333333333333333
Train Avg Loss  256: 0.223602

Train Avg F1  256: 0.18956943485928993

Val Avg Loss  256: 0.220629

Val Avg F1  256:  0.26964170692431566

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 257
--------------------------------------------------------------
Epoch:  257        1 Batch loss: 0.220919 Batch F1: 0.25
Epoch:  257        2 Batch loss: 0.250552 Batch F1: 0.25806451612903225
Epoch:  257        3 Batch loss: 0.216484 Batch F1: 0.5142857142857142
Epoch:  257        4 Batch loss: 0.233193 Batch F1: 0.42424242424242425
Epoch:  257        5 Batch loss: 0.227849 Batch F1: 0.4571428571428572
Epoch:  257        6 Batch loss: 0.230960 Batch F1: 0.35714285714285715
Epoch:  257        7 Batch loss: 0.214477 Batch F1: 0.4761904761904762
Epoch:  257        8 Batch loss: 0.237314 Batch F1: 0.3448275862068966
Epoch:  257        9 Batch loss: 0.213715 Batch F1: 0.09523809523809523
Epoch:  257       10 Batch loss: 0.208240 Batch F1: 0.36363636363636365
Epoch:  257       11 Batch loss: 0.208579 Batch F1: 0.19999999999999998
Epoch:  257       12 Batch loss: 0.204915 Batch F1: 0.0
Train Avg Loss  257: 0.222266

Train Avg F1  257: 0.3117309075178931

Val Avg Loss  257: 0.217768

Val Avg F1  257:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 258
--------------------------------------------------------------
Epoch:  258        1 Batch loss: 0.209892 Batch F1: 0.0
Epoch:  258        2 Batch loss: 0.250880 Batch F1: 0.0
Epoch:  258        3 Batch loss: 0.182357 Batch F1: 0.0
Epoch:  258        4 Batch loss: 0.230190 Batch F1: 0.0
Epoch:  258        5 Batch loss: 0.182543 Batch F1: 0.0
Epoch:  258        6 Batch loss: 0.250037 Batch F1: 0.0
Epoch:  258        7 Batch loss: 0.187020 Batch F1: 0.25
Epoch:  258        8 Batch loss: 0.225663 Batch F1: 0.32000000000000006
Epoch:  258        9 Batch loss: 0.225303 Batch F1: 0.19047619047619047
Epoch:  258       10 Batch loss: 0.233363 Batch F1: 0.1904761904761905
Epoch:  258       11 Batch loss: 0.244015 Batch F1: 0.15384615384615383
Epoch:  258       12 Batch loss: 0.256106 Batch F1: 0.42857142857142855
Train Avg Loss  258: 0.223114

Train Avg F1  258: 0.1277808302808303

Val Avg Loss  258: 0.218433

Val Avg F1  258:  0.24107142857142855

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 259
--------------------------------------------------------------
Epoch:  259        1 Batch loss: 0.231483 Batch F1: 0.3076923076923077
Epoch:  259        2 Batch loss: 0.211798 Batch F1: 0.3478260869565218
Epoch:  259        3 Batch loss: 0.211292 Batch F1: 0.4666666666666666
Epoch:  259        4 Batch loss: 0.214701 Batch F1: 0.2962962962962963
Epoch:  259        5 Batch loss: 0.215548 Batch F1: 0.19047619047619047
Epoch:  259        6 Batch loss: 0.263833 Batch F1: 0.2857142857142857
Epoch:  259        7 Batch loss: 0.206667 Batch F1: 0.38095238095238093
Epoch:  259        8 Batch loss: 0.233265 Batch F1: 0.09090909090909091
Epoch:  259        9 Batch loss: 0.220249 Batch F1: 0.32000000000000006
Epoch:  259       10 Batch loss: 0.212138 Batch F1: 0.3846153846153846
Epoch:  259       11 Batch loss: 0.226726 Batch F1: 0.25
Epoch:  259       12 Batch loss: 0.224484 Batch F1: 0.1
Train Avg Loss  259: 0.222682

Train Avg F1  259: 0.28509572418992707

Val Avg Loss  259: 0.219347

Val Avg F1  259:  0.24305555555555555

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 260
--------------------------------------------------------------
Epoch:  260        1 Batch loss: 0.240034 Batch F1: 0.14814814814814814
Epoch:  260        2 Batch loss: 0.223148 Batch F1: 0.25
Epoch:  260        3 Batch loss: 0.232417 Batch F1: 0.33333333333333337
Epoch:  260        4 Batch loss: 0.204092 Batch F1: 0.45454545454545453
Epoch:  260        5 Batch loss: 0.249181 Batch F1: 0.4444444444444444
Epoch:  260        6 Batch loss: 0.205984 Batch F1: 0.48
Epoch:  260        7 Batch loss: 0.224158 Batch F1: 0.18181818181818182
Epoch:  260        8 Batch loss: 0.223918 Batch F1: 0.0
Epoch:  260        9 Batch loss: 0.207078 Batch F1: 0.0
Epoch:  260       10 Batch loss: 0.197789 Batch F1: 0.0
Epoch:  260       11 Batch loss: 0.230947 Batch F1: 0.0
Epoch:  260       12 Batch loss: 0.236444 Batch F1: 0.2
Train Avg Loss  260: 0.222932

Train Avg F1  260: 0.2076907968574635

Val Avg Loss  260: 0.219096

Val Avg F1  260:  0.2526190476190476

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 261
--------------------------------------------------------------
Epoch:  261        1 Batch loss: 0.268574 Batch F1: 0.29411764705882354
Epoch:  261        2 Batch loss: 0.201514 Batch F1: 0.6153846153846153
Epoch:  261        3 Batch loss: 0.228087 Batch F1: 0.4
Epoch:  261        4 Batch loss: 0.192851 Batch F1: 0.5384615384615384
Epoch:  261        5 Batch loss: 0.207652 Batch F1: 0.5185185185185185
Epoch:  261        6 Batch loss: 0.212070 Batch F1: 0.3
Epoch:  261        7 Batch loss: 0.255246 Batch F1: 0.0
Epoch:  261        8 Batch loss: 0.240832 Batch F1: 0.16
Epoch:  261        9 Batch loss: 0.238204 Batch F1: 0.0
Epoch:  261       10 Batch loss: 0.234512 Batch F1: 0.08695652173913045
Epoch:  261       11 Batch loss: 0.182836 Batch F1: 0.0
Epoch:  261       12 Batch loss: 0.223081 Batch F1: 0.0
Train Avg Loss  261: 0.223788

Train Avg F1  261: 0.2427865700968855

Val Avg Loss  261: 0.218012

Val Avg F1  261:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 262
--------------------------------------------------------------
Epoch:  262        1 Batch loss: 0.198622 Batch F1: 0.10526315789473684
Epoch:  262        2 Batch loss: 0.268825 Batch F1: 0.0
Epoch:  262        3 Batch loss: 0.200054 Batch F1: 0.0
Epoch:  262        4 Batch loss: 0.196891 Batch F1: 0.0
Epoch:  262        5 Batch loss: 0.217348 Batch F1: 0.10526315789473684
Epoch:  262        6 Batch loss: 0.252938 Batch F1: 0.07692307692307693
Epoch:  262        7 Batch loss: 0.233825 Batch F1: 0.0
Epoch:  262        8 Batch loss: 0.225108 Batch F1: 0.25
Epoch:  262        9 Batch loss: 0.242844 Batch F1: 0.2222222222222222
Epoch:  262       10 Batch loss: 0.210383 Batch F1: 0.10526315789473684
Epoch:  262       11 Batch loss: 0.212829 Batch F1: 0.5454545454545455
Epoch:  262       12 Batch loss: 0.214545 Batch F1: 0.3
Train Avg Loss  262: 0.222851

Train Avg F1  262: 0.14253244319033792

Val Avg Loss  262: 0.219677

Val Avg F1  262:  0.20918023960156143

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 263
--------------------------------------------------------------
Epoch:  263        1 Batch loss: 0.218581 Batch F1: 0.4827586206896552
Epoch:  263        2 Batch loss: 0.239654 Batch F1: 0.25
Epoch:  263        3 Batch loss: 0.213728 Batch F1: 0.3478260869565218
Epoch:  263        4 Batch loss: 0.198642 Batch F1: 0.26086956521739124
Epoch:  263        5 Batch loss: 0.233628 Batch F1: 0.30769230769230765
Epoch:  263        6 Batch loss: 0.223412 Batch F1: 0.0
Epoch:  263        7 Batch loss: 0.214959 Batch F1: 0.33333333333333337
Epoch:  263        8 Batch loss: 0.227761 Batch F1: 0.27272727272727276
Epoch:  263        9 Batch loss: 0.233139 Batch F1: 0.24999999999999997
Epoch:  263       10 Batch loss: 0.255950 Batch F1: 0.0
Epoch:  263       11 Batch loss: 0.205448 Batch F1: 0.5185185185185185
Epoch:  263       12 Batch loss: 0.206317 Batch F1: 0.3636363636363636
Train Avg Loss  263: 0.222602

Train Avg F1  263: 0.2822801723976137

Val Avg Loss  263: 0.218972

Val Avg F1  263:  0.259047619047619

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 264
--------------------------------------------------------------
Epoch:  264        1 Batch loss: 0.209128 Batch F1: 0.5517241379310345
Epoch:  264        2 Batch loss: 0.246950 Batch F1: 0.3333333333333333
Epoch:  264        3 Batch loss: 0.205731 Batch F1: 0.13333333333333333
Epoch:  264        4 Batch loss: 0.230837 Batch F1: 0.23076923076923078
Epoch:  264        5 Batch loss: 0.205775 Batch F1: 0.0
Epoch:  264        6 Batch loss: 0.227463 Batch F1: 0.0
Epoch:  264        7 Batch loss: 0.228954 Batch F1: 0.0
Epoch:  264        8 Batch loss: 0.207952 Batch F1: 0.0
Epoch:  264        9 Batch loss: 0.244201 Batch F1: 0.0
Epoch:  264       10 Batch loss: 0.203531 Batch F1: 0.1111111111111111
Epoch:  264       11 Batch loss: 0.215664 Batch F1: 0.0
Epoch:  264       12 Batch loss: 0.243625 Batch F1: 0.1904761904761905
Train Avg Loss  264: 0.222484

Train Avg F1  264: 0.12922894474618613

Val Avg Loss  264: 0.218712

Val Avg F1  264:  0.25111111111111106

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 265
--------------------------------------------------------------
Epoch:  265        1 Batch loss: 0.224213 Batch F1: 0.25
Epoch:  265        2 Batch loss: 0.253321 Batch F1: 0.24
Epoch:  265        3 Batch loss: 0.239584 Batch F1: 0.2222222222222222
Epoch:  265        4 Batch loss: 0.201443 Batch F1: 0.2857142857142857
Epoch:  265        5 Batch loss: 0.219200 Batch F1: 0.31999999999999995
Epoch:  265        6 Batch loss: 0.222762 Batch F1: 0.3636363636363636
Epoch:  265        7 Batch loss: 0.215596 Batch F1: 0.39999999999999997
Epoch:  265        8 Batch loss: 0.258834 Batch F1: 0.14814814814814814
Epoch:  265        9 Batch loss: 0.213120 Batch F1: 0.4166666666666667
Epoch:  265       10 Batch loss: 0.207105 Batch F1: 0.4
Epoch:  265       11 Batch loss: 0.205929 Batch F1: 0.2857142857142857
Epoch:  265       12 Batch loss: 0.206686 Batch F1: 0.31578947368421056
Train Avg Loss  265: 0.222316

Train Avg F1  265: 0.3039909538155152

Val Avg Loss  265: 0.218373

Val Avg F1  265:  0.25673254281949937

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 266
--------------------------------------------------------------
Epoch:  266        1 Batch loss: 0.196005 Batch F1: 0.3333333333333333
Epoch:  266        2 Batch loss: 0.236284 Batch F1: 0.32
Epoch:  266        3 Batch loss: 0.203996 Batch F1: 0.28571428571428575
Epoch:  266        4 Batch loss: 0.201962 Batch F1: 0.23529411764705885
Epoch:  266        5 Batch loss: 0.201743 Batch F1: 0.1818181818181818
Epoch:  266        6 Batch loss: 0.229338 Batch F1: 0.32
Epoch:  266        7 Batch loss: 0.229711 Batch F1: 0.0
Epoch:  266        8 Batch loss: 0.247280 Batch F1: 0.0
Epoch:  266        9 Batch loss: 0.238297 Batch F1: 0.21428571428571427
Epoch:  266       10 Batch loss: 0.219439 Batch F1: 0.3
Epoch:  266       11 Batch loss: 0.227572 Batch F1: 0.3333333333333333
Epoch:  266       12 Batch loss: 0.251119 Batch F1: 0.25
Train Avg Loss  266: 0.223562

Train Avg F1  266: 0.23114824717765894

Val Avg Loss  266: 0.220956

Val Avg F1  266:  0.32743621321207533

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 267
--------------------------------------------------------------
Epoch:  267        1 Batch loss: 0.203267 Batch F1: 0.3
Epoch:  267        2 Batch loss: 0.224858 Batch F1: 0.10526315789473684
Epoch:  267        3 Batch loss: 0.213284 Batch F1: 0.2608695652173913
Epoch:  267        4 Batch loss: 0.225371 Batch F1: 0.18181818181818182
Epoch:  267        5 Batch loss: 0.229421 Batch F1: 0.18181818181818182
Epoch:  267        6 Batch loss: 0.231718 Batch F1: 0.0
Epoch:  267        7 Batch loss: 0.231182 Batch F1: 0.08333333333333334
Epoch:  267        8 Batch loss: 0.244435 Batch F1: 0.14814814814814814
Epoch:  267        9 Batch loss: 0.235017 Batch F1: 0.25
Epoch:  267       10 Batch loss: 0.226625 Batch F1: 0.4666666666666666
Epoch:  267       11 Batch loss: 0.197917 Batch F1: 0.5
Epoch:  267       12 Batch loss: 0.234371 Batch F1: 0.43478260869565216
Train Avg Loss  267: 0.224789

Train Avg F1  267: 0.24272498696602432

Val Avg Loss  267: 0.217553

Val Avg F1  267:  0.0

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 268
--------------------------------------------------------------
Epoch:  268        1 Batch loss: 0.215625 Batch F1: 0.0
Epoch:  268        2 Batch loss: 0.226065 Batch F1: 0.0
Epoch:  268        3 Batch loss: 0.231289 Batch F1: 0.0
Epoch:  268        4 Batch loss: 0.206305 Batch F1: 0.0
Epoch:  268        5 Batch loss: 0.224251 Batch F1: 0.1
Epoch:  268        6 Batch loss: 0.209004 Batch F1: 0.2
Epoch:  268        7 Batch loss: 0.246486 Batch F1: 0.28571428571428575
Epoch:  268        8 Batch loss: 0.230696 Batch F1: 0.17391304347826086
Epoch:  268        9 Batch loss: 0.226604 Batch F1: 0.24
Epoch:  268       10 Batch loss: 0.227271 Batch F1: 0.0
Epoch:  268       11 Batch loss: 0.204182 Batch F1: 0.45454545454545453
Epoch:  268       12 Batch loss: 0.243718 Batch F1: 0.3636363636363636
Train Avg Loss  268: 0.224291

Train Avg F1  268: 0.15148409561453038

Val Avg Loss  268: 0.218441

Val Avg F1  268:  0.2759083022240917

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 269
--------------------------------------------------------------
Epoch:  269        1 Batch loss: 0.203721 Batch F1: 0.2857142857142857
Epoch:  269        2 Batch loss: 0.218980 Batch F1: 0.23999999999999996
Epoch:  269        3 Batch loss: 0.207494 Batch F1: 0.34782608695652173
Epoch:  269        4 Batch loss: 0.237633 Batch F1: 0.4
Epoch:  269        5 Batch loss: 0.197276 Batch F1: 0.37037037037037035
Epoch:  269        6 Batch loss: 0.228253 Batch F1: 0.3478260869565218
Epoch:  269        7 Batch loss: 0.227564 Batch F1: 0.46153846153846156
Epoch:  269        8 Batch loss: 0.224736 Batch F1: 0.1739130434782609
Epoch:  269        9 Batch loss: 0.212519 Batch F1: 0.3809523809523809
Epoch:  269       10 Batch loss: 0.255527 Batch F1: 0.16000000000000003
Epoch:  269       11 Batch loss: 0.253584 Batch F1: 0.0
Epoch:  269       12 Batch loss: 0.199753 Batch F1: 0.31578947368421056
Train Avg Loss  269: 0.222253

Train Avg F1  269: 0.29032751580425115

Val Avg Loss  269: 0.217655

Val Avg F1  269:  0.24199134199134195

Optimal Val loss (Epoch 177): 0.21625445038080215

Epoch 270
--------------------------------------------------------------
Epoch:  270        1 Batch loss: 0.230680 Batch F1: 0.3076923076923077
Epoch:  270        2 Batch loss: 0.207937 Batch F1: 0.4166666666666667
Epoch:  270        3 Batch loss: 0.240954 Batch F1: 0.48484848484848486
Epoch:  270        4 Batch loss: 0.231759 Batch F1: 0.32
Epoch:  270        5 Batch loss: 0.230259 Batch F1: 0.08000000000000002
Epoch:  270        6 Batch loss: 0.238484 Batch F1: 0.0909090909090909
Epoch:  270        7 Batch loss: 0.242228 Batch F1: 0.0
Epoch:  270        8 Batch loss: 0.237547 Batch F1: 0.0
Epoch:  270        9 Batch loss: 0.202195 Batch F1: 0.0
Epoch:  270       10 Batch loss: 0.215270 Batch F1: 0.0
Epoch:  270       11 Batch loss: 0.212632 Batch F1: 0.0
Epoch:  270       12 Batch loss: 0.208908 Batch F1: 0.0
Train Avg Loss  270: 0.224904

Train Avg F1  270: 0.14167637917637918

Val Avg Loss  270: 0.216056

Val Avg F1  270:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 271
--------------------------------------------------------------
Epoch:  271        1 Batch loss: 0.257001 Batch F1: 0.0
Epoch:  271        2 Batch loss: 0.247194 Batch F1: 0.08000000000000002
Epoch:  271        3 Batch loss: 0.231803 Batch F1: 0.27586206896551724
Epoch:  271        4 Batch loss: 0.196862 Batch F1: 0.31578947368421056
Epoch:  271        5 Batch loss: 0.248923 Batch F1: 0.1739130434782609
Epoch:  271        6 Batch loss: 0.214437 Batch F1: 0.3478260869565218
Epoch:  271        7 Batch loss: 0.215321 Batch F1: 0.0
Epoch:  271        8 Batch loss: 0.235329 Batch F1: 0.0
Epoch:  271        9 Batch loss: 0.235804 Batch F1: 0.0
Epoch:  271       10 Batch loss: 0.157354 Batch F1: 0.0
Epoch:  271       11 Batch loss: 0.203876 Batch F1: 0.1
Epoch:  271       12 Batch loss: 0.264759 Batch F1: 0.0
Train Avg Loss  271: 0.225722

Train Avg F1  271: 0.10778255609037589

Val Avg Loss  271: 0.217533

Val Avg F1  271:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 272
--------------------------------------------------------------
Epoch:  272        1 Batch loss: 0.224401 Batch F1: 0.1904761904761905
Epoch:  272        2 Batch loss: 0.245423 Batch F1: 0.3125
Epoch:  272        3 Batch loss: 0.208883 Batch F1: 0.21052631578947367
Epoch:  272        4 Batch loss: 0.254326 Batch F1: 0.35294117647058826
Epoch:  272        5 Batch loss: 0.219581 Batch F1: 0.32
Epoch:  272        6 Batch loss: 0.188382 Batch F1: 0.47058823529411764
Epoch:  272        7 Batch loss: 0.197198 Batch F1: 0.3157894736842105
Epoch:  272        8 Batch loss: 0.252006 Batch F1: 0.26666666666666666
Epoch:  272        9 Batch loss: 0.217334 Batch F1: 0.2608695652173913
Epoch:  272       10 Batch loss: 0.200036 Batch F1: 0.2
Epoch:  272       11 Batch loss: 0.245917 Batch F1: 0.21052631578947367
Epoch:  272       12 Batch loss: 0.233349 Batch F1: 0.0
Train Avg Loss  272: 0.223903

Train Avg F1  272: 0.2592403282823427

Val Avg Loss  272: 0.217538

Val Avg F1  272:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 273
--------------------------------------------------------------
Epoch:  273        1 Batch loss: 0.215497 Batch F1: 0.0
Epoch:  273        2 Batch loss: 0.266346 Batch F1: 0.08333333333333333
Epoch:  273        3 Batch loss: 0.211793 Batch F1: 0.2857142857142857
Epoch:  273        4 Batch loss: 0.191067 Batch F1: 0.0
Epoch:  273        5 Batch loss: 0.236513 Batch F1: 0.0
Epoch:  273        6 Batch loss: 0.184979 Batch F1: 0.0
Epoch:  273        7 Batch loss: 0.230788 Batch F1: 0.0
Epoch:  273        8 Batch loss: 0.213675 Batch F1: 0.0
Epoch:  273        9 Batch loss: 0.219010 Batch F1: 0.0
Epoch:  273       10 Batch loss: 0.205284 Batch F1: 0.0
Epoch:  273       11 Batch loss: 0.273027 Batch F1: 0.0
Epoch:  273       12 Batch loss: 0.280597 Batch F1: 0.0
Train Avg Loss  273: 0.227381

Train Avg F1  273: 0.030753968253968252

Val Avg Loss  273: 0.218130

Val Avg F1  273:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 274
--------------------------------------------------------------
Epoch:  274        1 Batch loss: 0.206146 Batch F1: 0.0
Epoch:  274        2 Batch loss: 0.229027 Batch F1: 0.08333333333333334
Epoch:  274        3 Batch loss: 0.243453 Batch F1: 0.41379310344827586
Epoch:  274        4 Batch loss: 0.228259 Batch F1: 0.3846153846153846
Epoch:  274        5 Batch loss: 0.240753 Batch F1: 0.08695652173913045
Epoch:  274        6 Batch loss: 0.193926 Batch F1: 0.10526315789473685
Epoch:  274        7 Batch loss: 0.212217 Batch F1: 0.10526315789473684
Epoch:  274        8 Batch loss: 0.212213 Batch F1: 0.0
Epoch:  274        9 Batch loss: 0.224960 Batch F1: 0.0
Epoch:  274       10 Batch loss: 0.251364 Batch F1: 0.0
Epoch:  274       11 Batch loss: 0.232696 Batch F1: 0.0
Epoch:  274       12 Batch loss: 0.234022 Batch F1: 0.0
Train Avg Loss  274: 0.225753

Train Avg F1  274: 0.09826872157713318

Val Avg Loss  274: 0.217780

Val Avg F1  274:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 275
--------------------------------------------------------------
Epoch:  275        1 Batch loss: 0.222325 Batch F1: 0.0
Epoch:  275        2 Batch loss: 0.199316 Batch F1: 0.0
Epoch:  275        3 Batch loss: 0.216021 Batch F1: 0.3
Epoch:  275        4 Batch loss: 0.228052 Batch F1: 0.0
Epoch:  275        5 Batch loss: 0.234697 Batch F1: 0.0
Epoch:  275        6 Batch loss: 0.238789 Batch F1: 0.0
Epoch:  275        7 Batch loss: 0.240982 Batch F1: 0.0
Epoch:  275        8 Batch loss: 0.240847 Batch F1: 0.0
Epoch:  275        9 Batch loss: 0.213236 Batch F1: 0.0
Epoch:  275       10 Batch loss: 0.184444 Batch F1: 0.0
Epoch:  275       11 Batch loss: 0.252927 Batch F1: 0.07407407407407407
Epoch:  275       12 Batch loss: 0.232828 Batch F1: 0.3333333333333333
Train Avg Loss  275: 0.225372

Train Avg F1  275: 0.05895061728395062

Val Avg Loss  275: 0.226845

Val Avg F1  275:  0.34305555555555556

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 276
--------------------------------------------------------------
Epoch:  276        1 Batch loss: 0.222265 Batch F1: 0.4347826086956522
Epoch:  276        2 Batch loss: 0.255168 Batch F1: 0.4444444444444444
Epoch:  276        3 Batch loss: 0.184523 Batch F1: 0.6153846153846154
Epoch:  276        4 Batch loss: 0.259990 Batch F1: 0.27586206896551724
Epoch:  276        5 Batch loss: 0.176702 Batch F1: 0.37499999999999994
Epoch:  276        6 Batch loss: 0.237033 Batch F1: 0.0
Epoch:  276        7 Batch loss: 0.217395 Batch F1: 0.0
Epoch:  276        8 Batch loss: 0.241154 Batch F1: 0.0
Epoch:  276        9 Batch loss: 0.209151 Batch F1: 0.25
Epoch:  276       10 Batch loss: 0.224157 Batch F1: 0.08333333333333334
Epoch:  276       11 Batch loss: 0.234384 Batch F1: 0.2608695652173913
Epoch:  276       12 Batch loss: 0.248354 Batch F1: 0.1818181818181818
Train Avg Loss  276: 0.225856

Train Avg F1  276: 0.2434579014882613

Val Avg Loss  276: 0.220737

Val Avg F1  276:  0.2670264518090605

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 277
--------------------------------------------------------------
Epoch:  277        1 Batch loss: 0.231042 Batch F1: 0.3448275862068966
Epoch:  277        2 Batch loss: 0.217931 Batch F1: 0.32
Epoch:  277        3 Batch loss: 0.281386 Batch F1: 0.1935483870967742
Epoch:  277        4 Batch loss: 0.218545 Batch F1: 0.4444444444444445
Epoch:  277        5 Batch loss: 0.236225 Batch F1: 0.27586206896551724
Epoch:  277        6 Batch loss: 0.211664 Batch F1: 0.34782608695652173
Epoch:  277        7 Batch loss: 0.205604 Batch F1: 0.3333333333333333
Epoch:  277        8 Batch loss: 0.193407 Batch F1: 0.64
Epoch:  277        9 Batch loss: 0.240393 Batch F1: 0.2608695652173913
Epoch:  277       10 Batch loss: 0.227721 Batch F1: 0.0909090909090909
Epoch:  277       11 Batch loss: 0.185918 Batch F1: 0.23529411764705882
Epoch:  277       12 Batch loss: 0.235941 Batch F1: 0.0
Train Avg Loss  277: 0.223815

Train Avg F1  277: 0.2905762233980857

Val Avg Loss  277: 0.217425

Val Avg F1  277:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 278
--------------------------------------------------------------
Epoch:  278        1 Batch loss: 0.189456 Batch F1: 0.0
Epoch:  278        2 Batch loss: 0.242991 Batch F1: 0.0
Epoch:  278        3 Batch loss: 0.193680 Batch F1: 0.0
Epoch:  278        4 Batch loss: 0.216595 Batch F1: 0.0
Epoch:  278        5 Batch loss: 0.209977 Batch F1: 0.0
Epoch:  278        6 Batch loss: 0.224153 Batch F1: 0.3448275862068966
Epoch:  278        7 Batch loss: 0.275248 Batch F1: 0.25000000000000006
Epoch:  278        8 Batch loss: 0.209548 Batch F1: 0.6666666666666667
Epoch:  278        9 Batch loss: 0.242721 Batch F1: 0.3448275862068965
Epoch:  278       10 Batch loss: 0.231949 Batch F1: 0.2962962962962963
Epoch:  278       11 Batch loss: 0.202906 Batch F1: 0.0
Epoch:  278       12 Batch loss: 0.283928 Batch F1: 0.0
Train Avg Loss  278: 0.226929

Train Avg F1  278: 0.15855151128139636

Val Avg Loss  278: 0.217638

Val Avg F1  278:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 279
--------------------------------------------------------------
Epoch:  279        1 Batch loss: 0.231355 Batch F1: 0.0
Epoch:  279        2 Batch loss: 0.276585 Batch F1: 0.0
Epoch:  279        3 Batch loss: 0.221992 Batch F1: 0.0
Epoch:  279        4 Batch loss: 0.229987 Batch F1: 0.0
Epoch:  279        5 Batch loss: 0.225093 Batch F1: 0.0
Epoch:  279        6 Batch loss: 0.225874 Batch F1: 0.18181818181818182
Epoch:  279        7 Batch loss: 0.224123 Batch F1: 0.0
Epoch:  279        8 Batch loss: 0.224861 Batch F1: 0.0
Epoch:  279        9 Batch loss: 0.237519 Batch F1: 0.0
Epoch:  279       10 Batch loss: 0.241793 Batch F1: 0.0
Epoch:  279       11 Batch loss: 0.178588 Batch F1: 0.0
Epoch:  279       12 Batch loss: 0.223512 Batch F1: 0.0
Train Avg Loss  279: 0.228440

Train Avg F1  279: 0.015151515151515152

Val Avg Loss  279: 0.217177

Val Avg F1  279:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 280
--------------------------------------------------------------
Epoch:  280        1 Batch loss: 0.224172 Batch F1: 0.0
Epoch:  280        2 Batch loss: 0.180277 Batch F1: 0.0
Epoch:  280        3 Batch loss: 0.225949 Batch F1: 0.0
Epoch:  280        4 Batch loss: 0.247482 Batch F1: 0.0
Epoch:  280        5 Batch loss: 0.284188 Batch F1: 0.0
Epoch:  280        6 Batch loss: 0.228992 Batch F1: 0.0
Epoch:  280        7 Batch loss: 0.222317 Batch F1: 0.25
Epoch:  280        8 Batch loss: 0.224100 Batch F1: 0.16666666666666666
Epoch:  280        9 Batch loss: 0.219170 Batch F1: 0.37037037037037035
Epoch:  280       10 Batch loss: 0.225794 Batch F1: 0.25
Epoch:  280       11 Batch loss: 0.217986 Batch F1: 0.10526315789473685
Epoch:  280       12 Batch loss: 0.234493 Batch F1: 0.3333333333333333
Train Avg Loss  280: 0.227910

Train Avg F1  280: 0.12296946068875893

Val Avg Loss  280: 0.219155

Val Avg F1  280:  0.02777777777777778

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 281
--------------------------------------------------------------
Epoch:  281        1 Batch loss: 0.217433 Batch F1: 0.1818181818181818
Epoch:  281        2 Batch loss: 0.188715 Batch F1: 0.0
Epoch:  281        3 Batch loss: 0.248769 Batch F1: 0.08695652173913045
Epoch:  281        4 Batch loss: 0.196732 Batch F1: 0.0
Epoch:  281        5 Batch loss: 0.239036 Batch F1: 0.0
Epoch:  281        6 Batch loss: 0.232379 Batch F1: 0.0
Epoch:  281        7 Batch loss: 0.215338 Batch F1: 0.0
Epoch:  281        8 Batch loss: 0.253734 Batch F1: 0.0
Epoch:  281        9 Batch loss: 0.231597 Batch F1: 0.0
Epoch:  281       10 Batch loss: 0.213859 Batch F1: 0.0
Epoch:  281       11 Batch loss: 0.239404 Batch F1: 0.35714285714285715
Epoch:  281       12 Batch loss: 0.212409 Batch F1: 0.23529411764705882
Train Avg Loss  281: 0.224117

Train Avg F1  281: 0.07176763986226903

Val Avg Loss  281: 0.220948

Val Avg F1  281:  0.23214285714285715

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 282
--------------------------------------------------------------
Epoch:  282        1 Batch loss: 0.211942 Batch F1: 0.3333333333333333
Epoch:  282        2 Batch loss: 0.248206 Batch F1: 0.23076923076923075
Epoch:  282        3 Batch loss: 0.227696 Batch F1: 0.2727272727272727
Epoch:  282        4 Batch loss: 0.256096 Batch F1: 0.21428571428571427
Epoch:  282        5 Batch loss: 0.192376 Batch F1: 0.47619047619047616
Epoch:  282        6 Batch loss: 0.222535 Batch F1: 0.24999999999999997
Epoch:  282        7 Batch loss: 0.210499 Batch F1: 0.2222222222222222
Epoch:  282        8 Batch loss: 0.213671 Batch F1: 0.09523809523809523
Epoch:  282        9 Batch loss: 0.255506 Batch F1: 0.0
Epoch:  282       10 Batch loss: 0.204438 Batch F1: 0.0
Epoch:  282       11 Batch loss: 0.206838 Batch F1: 0.0
Epoch:  282       12 Batch loss: 0.230613 Batch F1: 0.0
Train Avg Loss  282: 0.223368

Train Avg F1  282: 0.17456386206386207

Val Avg Loss  282: 0.217661

Val Avg F1  282:  0.17163461538461539

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 283
--------------------------------------------------------------
Epoch:  283        1 Batch loss: 0.247119 Batch F1: 0.2857142857142857
Epoch:  283        2 Batch loss: 0.204383 Batch F1: 0.4444444444444444
Epoch:  283        3 Batch loss: 0.186020 Batch F1: 0.5
Epoch:  283        4 Batch loss: 0.212219 Batch F1: 0.21052631578947364
Epoch:  283        5 Batch loss: 0.228264 Batch F1: 0.3846153846153846
Epoch:  283        6 Batch loss: 0.221060 Batch F1: 0.21052631578947367
Epoch:  283        7 Batch loss: 0.220321 Batch F1: 0.16666666666666669
Epoch:  283        8 Batch loss: 0.237927 Batch F1: 0.28571428571428575
Epoch:  283        9 Batch loss: 0.197691 Batch F1: 0.21052631578947367
Epoch:  283       10 Batch loss: 0.241108 Batch F1: 0.0
Epoch:  283       11 Batch loss: 0.253861 Batch F1: 0.13793103448275865
Epoch:  283       12 Batch loss: 0.234281 Batch F1: 0.31578947368421056
Train Avg Loss  283: 0.223688

Train Avg F1  283: 0.2627045435575381

Val Avg Loss  283: 0.220658

Val Avg F1  283:  0.30940506637437587

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 284
--------------------------------------------------------------
Epoch:  284        1 Batch loss: 0.236039 Batch F1: 0.5333333333333333
Epoch:  284        2 Batch loss: 0.216108 Batch F1: 0.4444444444444444
Epoch:  284        3 Batch loss: 0.218669 Batch F1: 0.2
Epoch:  284        4 Batch loss: 0.212593 Batch F1: 0.2608695652173913
Epoch:  284        5 Batch loss: 0.223633 Batch F1: 0.2608695652173913
Epoch:  284        6 Batch loss: 0.218431 Batch F1: 0.25
Epoch:  284        7 Batch loss: 0.252724 Batch F1: 0.08333333333333334
Epoch:  284        8 Batch loss: 0.265506 Batch F1: 0.3125
Epoch:  284        9 Batch loss: 0.192933 Batch F1: 0.5
Epoch:  284       10 Batch loss: 0.229725 Batch F1: 0.35714285714285715
Epoch:  284       11 Batch loss: 0.207535 Batch F1: 0.3636363636363636
Epoch:  284       12 Batch loss: 0.194314 Batch F1: 0.35294117647058826
Train Avg Loss  284: 0.222351

Train Avg F1  284: 0.3265892198996419

Val Avg Loss  284: 0.218845

Val Avg F1  284:  0.2614827201783723

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 285
--------------------------------------------------------------
Epoch:  285        1 Batch loss: 0.213500 Batch F1: 0.37037037037037035
Epoch:  285        2 Batch loss: 0.246180 Batch F1: 0.4
Epoch:  285        3 Batch loss: 0.209106 Batch F1: 0.0
Epoch:  285        4 Batch loss: 0.215674 Batch F1: 0.25
Epoch:  285        5 Batch loss: 0.229195 Batch F1: 0.3448275862068966
Epoch:  285        6 Batch loss: 0.238011 Batch F1: 0.25
Epoch:  285        7 Batch loss: 0.181739 Batch F1: 0.5454545454545454
Epoch:  285        8 Batch loss: 0.201196 Batch F1: 0.34782608695652173
Epoch:  285        9 Batch loss: 0.223573 Batch F1: 0.3
Epoch:  285       10 Batch loss: 0.262510 Batch F1: 0.07692307692307691
Epoch:  285       11 Batch loss: 0.221117 Batch F1: 0.18181818181818182
Epoch:  285       12 Batch loss: 0.225290 Batch F1: 0.0
Train Avg Loss  285: 0.222258

Train Avg F1  285: 0.25560165397746604

Val Avg Loss  285: 0.217538

Val Avg F1  285:  0.025

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 286
--------------------------------------------------------------
Epoch:  286        1 Batch loss: 0.245299 Batch F1: 0.0
Epoch:  286        2 Batch loss: 0.250092 Batch F1: 0.41379310344827586
Epoch:  286        3 Batch loss: 0.235622 Batch F1: 0.23076923076923075
Epoch:  286        4 Batch loss: 0.212446 Batch F1: 0.37037037037037035
Epoch:  286        5 Batch loss: 0.218574 Batch F1: 0.1818181818181818
Epoch:  286        6 Batch loss: 0.190671 Batch F1: 0.5217391304347825
Epoch:  286        7 Batch loss: 0.238465 Batch F1: 0.37037037037037035
Epoch:  286        8 Batch loss: 0.208494 Batch F1: 0.3703703703703704
Epoch:  286        9 Batch loss: 0.210889 Batch F1: 0.3333333333333333
Epoch:  286       10 Batch loss: 0.202586 Batch F1: 0.36363636363636365
Epoch:  286       11 Batch loss: 0.247707 Batch F1: 0.08000000000000002
Epoch:  286       12 Batch loss: 0.201538 Batch F1: 0.23529411764705882
Train Avg Loss  286: 0.221865

Train Avg F1  286: 0.2892912143498615

Val Avg Loss  286: 0.218518

Val Avg F1  286:  0.2703722002635046

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 287
--------------------------------------------------------------
Epoch:  287        1 Batch loss: 0.199685 Batch F1: 0.5
Epoch:  287        2 Batch loss: 0.231525 Batch F1: 0.1739130434782609
Epoch:  287        3 Batch loss: 0.262518 Batch F1: 0.0
Epoch:  287        4 Batch loss: 0.221663 Batch F1: 0.0
Epoch:  287        5 Batch loss: 0.199306 Batch F1: 0.3333333333333333
Epoch:  287        6 Batch loss: 0.240186 Batch F1: 0.16666666666666666
Epoch:  287        7 Batch loss: 0.223149 Batch F1: 0.25
Epoch:  287        8 Batch loss: 0.227200 Batch F1: 0.3846153846153846
Epoch:  287        9 Batch loss: 0.236004 Batch F1: 0.2962962962962963
Epoch:  287       10 Batch loss: 0.202822 Batch F1: 0.4
Epoch:  287       11 Batch loss: 0.223361 Batch F1: 0.2962962962962963
Epoch:  287       12 Batch loss: 0.201636 Batch F1: 0.3333333333333333
Train Avg Loss  287: 0.222421

Train Avg F1  287: 0.2612045295016309

Val Avg Loss  287: 0.218920

Val Avg F1  287:  0.23273910582908883

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 288
--------------------------------------------------------------
Epoch:  288        1 Batch loss: 0.233047 Batch F1: 0.2222222222222222
Epoch:  288        2 Batch loss: 0.192412 Batch F1: 0.5
Epoch:  288        3 Batch loss: 0.213350 Batch F1: 0.3846153846153846
Epoch:  288        4 Batch loss: 0.261979 Batch F1: 0.16666666666666666
Epoch:  288        5 Batch loss: 0.214851 Batch F1: 0.28571428571428575
Epoch:  288        6 Batch loss: 0.257388 Batch F1: 0.15384615384615383
Epoch:  288        7 Batch loss: 0.185962 Batch F1: 0.35294117647058826
Epoch:  288        8 Batch loss: 0.236361 Batch F1: 0.2608695652173913
Epoch:  288        9 Batch loss: 0.235956 Batch F1: 0.0
Epoch:  288       10 Batch loss: 0.219408 Batch F1: 0.3846153846153846
Epoch:  288       11 Batch loss: 0.222939 Batch F1: 0.2727272727272727
Epoch:  288       12 Batch loss: 0.188142 Batch F1: 0.5263157894736842
Train Avg Loss  288: 0.221816

Train Avg F1  288: 0.29254449179741954

Val Avg Loss  288: 0.219289

Val Avg F1  288:  0.24647416551464527

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 289
--------------------------------------------------------------
Epoch:  289        1 Batch loss: 0.239544 Batch F1: 0.3846153846153846
Epoch:  289        2 Batch loss: 0.213720 Batch F1: 0.23076923076923078
Epoch:  289        3 Batch loss: 0.220565 Batch F1: 0.42857142857142855
Epoch:  289        4 Batch loss: 0.232778 Batch F1: 0.45161290322580644
Epoch:  289        5 Batch loss: 0.231290 Batch F1: 0.17391304347826086
Epoch:  289        6 Batch loss: 0.173983 Batch F1: 0.23529411764705882
Epoch:  289        7 Batch loss: 0.225464 Batch F1: 0.2608695652173913
Epoch:  289        8 Batch loss: 0.223710 Batch F1: 0.1904761904761905
Epoch:  289        9 Batch loss: 0.237667 Batch F1: 0.09090909090909091
Epoch:  289       10 Batch loss: 0.217684 Batch F1: 0.3703703703703704
Epoch:  289       11 Batch loss: 0.198858 Batch F1: 0.18181818181818182
Epoch:  289       12 Batch loss: 0.259125 Batch F1: 0.1739130434782609
Train Avg Loss  289: 0.222866

Train Avg F1  289: 0.26442771254805464

Val Avg Loss  289: 0.217132

Val Avg F1  289:  0.2578703703703704

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 290
--------------------------------------------------------------
Epoch:  290        1 Batch loss: 0.185323 Batch F1: 0.23529411764705882
Epoch:  290        2 Batch loss: 0.202111 Batch F1: 0.4
Epoch:  290        3 Batch loss: 0.195782 Batch F1: 0.32
Epoch:  290        4 Batch loss: 0.259960 Batch F1: 0.375
Epoch:  290        5 Batch loss: 0.223489 Batch F1: 0.17391304347826086
Epoch:  290        6 Batch loss: 0.244958 Batch F1: 0.20689655172413793
Epoch:  290        7 Batch loss: 0.233617 Batch F1: 0.26666666666666666
Epoch:  290        8 Batch loss: 0.220542 Batch F1: 0.4444444444444445
Epoch:  290        9 Batch loss: 0.198123 Batch F1: 0.5217391304347826
Epoch:  290       10 Batch loss: 0.252112 Batch F1: 0.37037037037037035
Epoch:  290       11 Batch loss: 0.230403 Batch F1: 0.0
Epoch:  290       12 Batch loss: 0.227996 Batch F1: 0.0
Train Avg Loss  290: 0.222868

Train Avg F1  290: 0.2761936937304768

Val Avg Loss  290: 0.219221

Val Avg F1  290:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 291
--------------------------------------------------------------
Epoch:  291        1 Batch loss: 0.250758 Batch F1: 0.0
Epoch:  291        2 Batch loss: 0.222888 Batch F1: 0.0
Epoch:  291        3 Batch loss: 0.194072 Batch F1: 0.0
Epoch:  291        4 Batch loss: 0.206832 Batch F1: 0.0
Epoch:  291        5 Batch loss: 0.246039 Batch F1: 0.0
Epoch:  291        6 Batch loss: 0.219176 Batch F1: 0.0
Epoch:  291        7 Batch loss: 0.228905 Batch F1: 0.0
Epoch:  291        8 Batch loss: 0.231207 Batch F1: 0.0
Epoch:  291        9 Batch loss: 0.225477 Batch F1: 0.0
Epoch:  291       10 Batch loss: 0.228490 Batch F1: 0.0
Epoch:  291       11 Batch loss: 0.239921 Batch F1: 0.0
Epoch:  291       12 Batch loss: 0.238381 Batch F1: 0.0
Train Avg Loss  291: 0.227679

Train Avg F1  291: 0.0

Val Avg Loss  291: 0.222048

Val Avg F1  291:  0.23854978354978357

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 292
--------------------------------------------------------------
Epoch:  292        1 Batch loss: 0.231948 Batch F1: 0.23076923076923078
Epoch:  292        2 Batch loss: 0.215558 Batch F1: 0.4444444444444445
Epoch:  292        3 Batch loss: 0.230921 Batch F1: 0.3448275862068965
Epoch:  292        4 Batch loss: 0.234873 Batch F1: 0.26086956521739135
Epoch:  292        5 Batch loss: 0.224789 Batch F1: 0.3333333333333333
Epoch:  292        6 Batch loss: 0.228327 Batch F1: 0.0
Epoch:  292        7 Batch loss: 0.222603 Batch F1: 0.0
Epoch:  292        8 Batch loss: 0.229337 Batch F1: 0.0
Epoch:  292        9 Batch loss: 0.220857 Batch F1: 0.0
Epoch:  292       10 Batch loss: 0.215033 Batch F1: 0.0
Epoch:  292       11 Batch loss: 0.232314 Batch F1: 0.0
Epoch:  292       12 Batch loss: 0.221716 Batch F1: 0.0
Train Avg Loss  292: 0.225690

Train Avg F1  292: 0.1345203466642747

Val Avg Loss  292: 0.219243

Val Avg F1  292:  0.19123459660544062

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 293
--------------------------------------------------------------
Epoch:  293        1 Batch loss: 0.214745 Batch F1: 0.16
Epoch:  293        2 Batch loss: 0.223889 Batch F1: 0.3870967741935483
Epoch:  293        3 Batch loss: 0.224503 Batch F1: 0.380952380952381
Epoch:  293        4 Batch loss: 0.223481 Batch F1: 0.37037037037037035
Epoch:  293        5 Batch loss: 0.195954 Batch F1: 0.4166666666666667
Epoch:  293        6 Batch loss: 0.206095 Batch F1: 0.2222222222222222
Epoch:  293        7 Batch loss: 0.243202 Batch F1: 0.0
Epoch:  293        8 Batch loss: 0.229697 Batch F1: 0.0
Epoch:  293        9 Batch loss: 0.235841 Batch F1: 0.0
Epoch:  293       10 Batch loss: 0.228314 Batch F1: 0.11764705882352941
Epoch:  293       11 Batch loss: 0.237149 Batch F1: 0.25
Epoch:  293       12 Batch loss: 0.229411 Batch F1: 0.5
Train Avg Loss  293: 0.224357

Train Avg F1  293: 0.2337462894357265

Val Avg Loss  293: 0.220484

Val Avg F1  293:  0.25212121212121213

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 294
--------------------------------------------------------------
Epoch:  294        1 Batch loss: 0.226570 Batch F1: 0.23999999999999996
Epoch:  294        2 Batch loss: 0.194131 Batch F1: 0.2727272727272727
Epoch:  294        3 Batch loss: 0.208193 Batch F1: 0.3
Epoch:  294        4 Batch loss: 0.254759 Batch F1: 0.0
Epoch:  294        5 Batch loss: 0.231526 Batch F1: 0.0
Epoch:  294        6 Batch loss: 0.213640 Batch F1: 0.0
Epoch:  294        7 Batch loss: 0.252066 Batch F1: 0.0
Epoch:  294        8 Batch loss: 0.213759 Batch F1: 0.3478260869565218
Epoch:  294        9 Batch loss: 0.212982 Batch F1: 0.10526315789473684
Epoch:  294       10 Batch loss: 0.244204 Batch F1: 0.2222222222222222
Epoch:  294       11 Batch loss: 0.244864 Batch F1: 0.16
Epoch:  294       12 Batch loss: 0.191178 Batch F1: 0.37499999999999994
Train Avg Loss  294: 0.223989

Train Avg F1  294: 0.16858656165006278

Val Avg Loss  294: 0.219236

Val Avg F1  294:  0.24676434676434678

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 295
--------------------------------------------------------------
Epoch:  295        1 Batch loss: 0.228863 Batch F1: 0.35714285714285715
Epoch:  295        2 Batch loss: 0.213167 Batch F1: 0.2727272727272727
Epoch:  295        3 Batch loss: 0.193792 Batch F1: 0.5
Epoch:  295        4 Batch loss: 0.196905 Batch F1: 0.23529411764705882
Epoch:  295        5 Batch loss: 0.219357 Batch F1: 0.3636363636363636
Epoch:  295        6 Batch loss: 0.252525 Batch F1: 0.0
Epoch:  295        7 Batch loss: 0.278054 Batch F1: 0.0
Epoch:  295        8 Batch loss: 0.241903 Batch F1: 0.4736842105263157
Epoch:  295        9 Batch loss: 0.207431 Batch F1: 0.3333333333333333
Epoch:  295       10 Batch loss: 0.200207 Batch F1: 0.10526315789473682
Epoch:  295       11 Batch loss: 0.230049 Batch F1: 0.29629629629629634
Epoch:  295       12 Batch loss: 0.230171 Batch F1: 0.33333333333333337
Train Avg Loss  295: 0.224369

Train Avg F1  295: 0.272559245211464

Val Avg Loss  295: 0.218201

Val Avg F1  295:  0.024999999999999998

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 296
--------------------------------------------------------------
Epoch:  296        1 Batch loss: 0.193826 Batch F1: 0.0
Epoch:  296        2 Batch loss: 0.224950 Batch F1: 0.0
Epoch:  296        3 Batch loss: 0.238192 Batch F1: 0.0
Epoch:  296        4 Batch loss: 0.230404 Batch F1: 0.0
Epoch:  296        5 Batch loss: 0.219530 Batch F1: 0.0
Epoch:  296        6 Batch loss: 0.208465 Batch F1: 0.0
Epoch:  296        7 Batch loss: 0.244612 Batch F1: 0.08333333333333333
Epoch:  296        8 Batch loss: 0.214591 Batch F1: 0.1904761904761905
Epoch:  296        9 Batch loss: 0.256004 Batch F1: 0.20689655172413796
Epoch:  296       10 Batch loss: 0.214777 Batch F1: 0.2608695652173913
Epoch:  296       11 Batch loss: 0.228823 Batch F1: 0.20689655172413796
Epoch:  296       12 Batch loss: 0.219585 Batch F1: 0.22222222222222224
Train Avg Loss  296: 0.224480

Train Avg F1  296: 0.09755786789145111

Val Avg Loss  296: 0.219977

Val Avg F1  296:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 297
--------------------------------------------------------------
Epoch:  297        1 Batch loss: 0.214091 Batch F1: 0.0
Epoch:  297        2 Batch loss: 0.199924 Batch F1: 0.0
Epoch:  297        3 Batch loss: 0.266002 Batch F1: 0.0
Epoch:  297        4 Batch loss: 0.212929 Batch F1: 0.0
Epoch:  297        5 Batch loss: 0.210672 Batch F1: 0.0
Epoch:  297        6 Batch loss: 0.233897 Batch F1: 0.0
Epoch:  297        7 Batch loss: 0.236828 Batch F1: 0.0
Epoch:  297        8 Batch loss: 0.211170 Batch F1: 0.0
Epoch:  297        9 Batch loss: 0.238676 Batch F1: 0.42424242424242425
Epoch:  297       10 Batch loss: 0.245427 Batch F1: 0.23076923076923078
Epoch:  297       11 Batch loss: 0.204290 Batch F1: 0.4999999999999999
Epoch:  297       12 Batch loss: 0.252997 Batch F1: 0.10526315789473684
Train Avg Loss  297: 0.227242

Train Avg F1  297: 0.10502290107553265

Val Avg Loss  297: 0.218150

Val Avg F1  297:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 298
--------------------------------------------------------------
Epoch:  298        1 Batch loss: 0.227337 Batch F1: 0.0
Epoch:  298        2 Batch loss: 0.228218 Batch F1: 0.0
Epoch:  298        3 Batch loss: 0.236750 Batch F1: 0.0
Epoch:  298        4 Batch loss: 0.212832 Batch F1: 0.0
Epoch:  298        5 Batch loss: 0.204359 Batch F1: 0.0
Epoch:  298        6 Batch loss: 0.211226 Batch F1: 0.0
Epoch:  298        7 Batch loss: 0.255001 Batch F1: 0.0
Epoch:  298        8 Batch loss: 0.210504 Batch F1: 0.0
Epoch:  298        9 Batch loss: 0.243603 Batch F1: 0.07999999999999999
Epoch:  298       10 Batch loss: 0.230946 Batch F1: 0.09523809523809523
Epoch:  298       11 Batch loss: 0.215324 Batch F1: 0.48275862068965514
Epoch:  298       12 Batch loss: 0.202600 Batch F1: 0.45454545454545453
Train Avg Loss  298: 0.223225

Train Avg F1  298: 0.09271184753943373

Val Avg Loss  298: 0.219354

Val Avg F1  298:  0.2544230769230769

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 299
--------------------------------------------------------------
Epoch:  299        1 Batch loss: 0.222328 Batch F1: 0.4444444444444444
Epoch:  299        2 Batch loss: 0.251838 Batch F1: 0.3225806451612903
Epoch:  299        3 Batch loss: 0.190661 Batch F1: 0.3157894736842105
Epoch:  299        4 Batch loss: 0.239530 Batch F1: 0.26086956521739124
Epoch:  299        5 Batch loss: 0.207192 Batch F1: 0.1
Epoch:  299        6 Batch loss: 0.219907 Batch F1: 0.08695652173913045
Epoch:  299        7 Batch loss: 0.227182 Batch F1: 0.0
Epoch:  299        8 Batch loss: 0.228029 Batch F1: 0.1818181818181818
Epoch:  299        9 Batch loss: 0.259925 Batch F1: 0.22222222222222218
Epoch:  299       10 Batch loss: 0.193495 Batch F1: 0.5217391304347825
Epoch:  299       11 Batch loss: 0.251006 Batch F1: 0.3333333333333333
Epoch:  299       12 Batch loss: 0.196327 Batch F1: 0.42857142857142855
Train Avg Loss  299: 0.223952

Train Avg F1  299: 0.26819374555220127

Val Avg Loss  299: 0.218764

Val Avg F1  299:  0.26271645021645024

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 300
--------------------------------------------------------------
Epoch:  300        1 Batch loss: 0.209394 Batch F1: 0.4
Epoch:  300        2 Batch loss: 0.208969 Batch F1: 0.19047619047619047
Epoch:  300        3 Batch loss: 0.241957 Batch F1: 0.3448275862068965
Epoch:  300        4 Batch loss: 0.270853 Batch F1: 0.14814814814814814
Epoch:  300        5 Batch loss: 0.194124 Batch F1: 0.6086956521739131
Epoch:  300        6 Batch loss: 0.223302 Batch F1: 0.30769230769230765
Epoch:  300        7 Batch loss: 0.186879 Batch F1: 0.3636363636363636
Epoch:  300        8 Batch loss: 0.221783 Batch F1: 0.2857142857142857
Epoch:  300        9 Batch loss: 0.225848 Batch F1: 0.37037037037037035
Epoch:  300       10 Batch loss: 0.233652 Batch F1: 0.2608695652173913
Epoch:  300       11 Batch loss: 0.214740 Batch F1: 0.0909090909090909
Epoch:  300       12 Batch loss: 0.232144 Batch F1: 0.17391304347826086
Train Avg Loss  300: 0.221970

Train Avg F1  300: 0.29543771700193483

Val Avg Loss  300: 0.218255

Val Avg F1  300:  0.20192307692307693

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 301
--------------------------------------------------------------
Epoch:  301        1 Batch loss: 0.220350 Batch F1: 0.1739130434782609
Epoch:  301        2 Batch loss: 0.226461 Batch F1: 0.37037037037037035
Epoch:  301        3 Batch loss: 0.245043 Batch F1: 0.16
Epoch:  301        4 Batch loss: 0.215437 Batch F1: 0.1818181818181818
Epoch:  301        5 Batch loss: 0.223945 Batch F1: 0.1
Epoch:  301        6 Batch loss: 0.215175 Batch F1: 0.33333333333333337
Epoch:  301        7 Batch loss: 0.226411 Batch F1: 0.3076923076923077
Epoch:  301        8 Batch loss: 0.262332 Batch F1: 0.4
Epoch:  301        9 Batch loss: 0.210527 Batch F1: 0.4
Epoch:  301       10 Batch loss: 0.204503 Batch F1: 0.2857142857142857
Epoch:  301       11 Batch loss: 0.211145 Batch F1: 0.48275862068965514
Epoch:  301       12 Batch loss: 0.199891 Batch F1: 0.23529411764705882
Train Avg Loss  301: 0.221768

Train Avg F1  301: 0.2859078550619545

Val Avg Loss  301: 0.219218

Val Avg F1  301:  0.23904682274247493

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 302
--------------------------------------------------------------
Epoch:  302        1 Batch loss: 0.211816 Batch F1: 0.3846153846153846
Epoch:  302        2 Batch loss: 0.185997 Batch F1: 0.3
Epoch:  302        3 Batch loss: 0.201615 Batch F1: 0.28571428571428575
Epoch:  302        4 Batch loss: 0.300050 Batch F1: 0.13793103448275862
Epoch:  302        5 Batch loss: 0.213073 Batch F1: 0.1818181818181818
Epoch:  302        6 Batch loss: 0.209464 Batch F1: 0.0
Epoch:  302        7 Batch loss: 0.231769 Batch F1: 0.18181818181818182
Epoch:  302        8 Batch loss: 0.240970 Batch F1: 0.0
Epoch:  302        9 Batch loss: 0.205824 Batch F1: 0.2105263157894737
Epoch:  302       10 Batch loss: 0.211847 Batch F1: 0.4166666666666667
Epoch:  302       11 Batch loss: 0.225808 Batch F1: 0.41379310344827586
Epoch:  302       12 Batch loss: 0.232979 Batch F1: 0.0
Train Avg Loss  302: 0.222601

Train Avg F1  302: 0.20940692952943407

Val Avg Loss  302: 0.219318

Val Avg F1  302:  0.25573551608034367

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 303
--------------------------------------------------------------
Epoch:  303        1 Batch loss: 0.243104 Batch F1: 0.14814814814814814
Epoch:  303        2 Batch loss: 0.212423 Batch F1: 0.42857142857142855
Epoch:  303        3 Batch loss: 0.214303 Batch F1: 0.48
Epoch:  303        4 Batch loss: 0.249812 Batch F1: 0.2857142857142857
Epoch:  303        5 Batch loss: 0.221401 Batch F1: 0.3333333333333333
Epoch:  303        6 Batch loss: 0.232199 Batch F1: 0.45
Epoch:  303        7 Batch loss: 0.235360 Batch F1: 0.38095238095238093
Epoch:  303        8 Batch loss: 0.210400 Batch F1: 0.32000000000000006
Epoch:  303        9 Batch loss: 0.223608 Batch F1: 0.42857142857142855
Epoch:  303       10 Batch loss: 0.198025 Batch F1: 0.2
Epoch:  303       11 Batch loss: 0.208265 Batch F1: 0.2857142857142857
Epoch:  303       12 Batch loss: 0.218298 Batch F1: 0.1111111111111111
Train Avg Loss  303: 0.222266

Train Avg F1  303: 0.3210097001763668

Val Avg Loss  303: 0.218250

Val Avg F1  303:  0.24564870674710493

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 304
--------------------------------------------------------------
Epoch:  304        1 Batch loss: 0.245543 Batch F1: 0.22222222222222218
Epoch:  304        2 Batch loss: 0.198250 Batch F1: 0.21052631578947367
Epoch:  304        3 Batch loss: 0.215180 Batch F1: 0.43478260869565216
Epoch:  304        4 Batch loss: 0.238880 Batch F1: 0.42857142857142855
Epoch:  304        5 Batch loss: 0.211730 Batch F1: 0.1
Epoch:  304        6 Batch loss: 0.231154 Batch F1: 0.1818181818181818
Epoch:  304        7 Batch loss: 0.247715 Batch F1: 0.07692307692307693
Epoch:  304        8 Batch loss: 0.202852 Batch F1: 0.4615384615384615
Epoch:  304        9 Batch loss: 0.215973 Batch F1: 0.1818181818181818
Epoch:  304       10 Batch loss: 0.240434 Batch F1: 0.16
Epoch:  304       11 Batch loss: 0.222825 Batch F1: 0.29629629629629634
Epoch:  304       12 Batch loss: 0.198827 Batch F1: 0.0
Train Avg Loss  304: 0.222447

Train Avg F1  304: 0.22954139780608127

Val Avg Loss  304: 0.219382

Val Avg F1  304:  0.2601998171607679

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 305
--------------------------------------------------------------
Epoch:  305        1 Batch loss: 0.184669 Batch F1: 0.15384615384615383
Epoch:  305        2 Batch loss: 0.220876 Batch F1: 0.23076923076923073
Epoch:  305        3 Batch loss: 0.228531 Batch F1: 0.0
Epoch:  305        4 Batch loss: 0.235800 Batch F1: 0.0
Epoch:  305        5 Batch loss: 0.187702 Batch F1: 0.13333333333333333
Epoch:  305        6 Batch loss: 0.262822 Batch F1: 0.0
Epoch:  305        7 Batch loss: 0.275596 Batch F1: 0.13793103448275862
Epoch:  305        8 Batch loss: 0.205049 Batch F1: 0.3333333333333333
Epoch:  305        9 Batch loss: 0.254714 Batch F1: 0.3125
Epoch:  305       10 Batch loss: 0.199274 Batch F1: 0.11764705882352941
Epoch:  305       11 Batch loss: 0.220296 Batch F1: 0.2608695652173913
Epoch:  305       12 Batch loss: 0.193303 Batch F1: 0.5833333333333334
Train Avg Loss  305: 0.222386

Train Avg F1  305: 0.188630253594922

Val Avg Loss  305: 0.219537

Val Avg F1  305:  0.250045747328356

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 306
--------------------------------------------------------------
Epoch:  306        1 Batch loss: 0.213713 Batch F1: 0.3846153846153846
Epoch:  306        2 Batch loss: 0.225378 Batch F1: 0.18181818181818182
Epoch:  306        3 Batch loss: 0.240328 Batch F1: 0.3870967741935483
Epoch:  306        4 Batch loss: 0.207282 Batch F1: 0.18181818181818182
Epoch:  306        5 Batch loss: 0.206484 Batch F1: 0.11111111111111112
Epoch:  306        6 Batch loss: 0.257783 Batch F1: 0.07407407407407407
Epoch:  306        7 Batch loss: 0.224244 Batch F1: 0.0
Epoch:  306        8 Batch loss: 0.238504 Batch F1: 0.0
Epoch:  306        9 Batch loss: 0.233826 Batch F1: 0.08695652173913045
Epoch:  306       10 Batch loss: 0.217417 Batch F1: 0.0
Epoch:  306       11 Batch loss: 0.195591 Batch F1: 0.21052631578947367
Epoch:  306       12 Batch loss: 0.211143 Batch F1: 0.2666666666666667
Train Avg Loss  306: 0.222641

Train Avg F1  306: 0.15705693431881274

Val Avg Loss  306: 0.219728

Val Avg F1  306:  0.2743741765480896

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 307
--------------------------------------------------------------
Epoch:  307        1 Batch loss: 0.227063 Batch F1: 0.3846153846153846
Epoch:  307        2 Batch loss: 0.226844 Batch F1: 0.32
Epoch:  307        3 Batch loss: 0.246360 Batch F1: 0.48648648648648646
Epoch:  307        4 Batch loss: 0.239269 Batch F1: 0.5142857142857143
Epoch:  307        5 Batch loss: 0.183743 Batch F1: 0.41666666666666663
Epoch:  307        6 Batch loss: 0.227585 Batch F1: 0.42857142857142855
Epoch:  307        7 Batch loss: 0.175365 Batch F1: 0.36363636363636365
Epoch:  307        8 Batch loss: 0.241197 Batch F1: 0.14814814814814817
Epoch:  307        9 Batch loss: 0.222129 Batch F1: 0.0
Epoch:  307       10 Batch loss: 0.220292 Batch F1: 0.0
Epoch:  307       11 Batch loss: 0.225808 Batch F1: 0.0
Epoch:  307       12 Batch loss: 0.242441 Batch F1: 0.0
Train Avg Loss  307: 0.223175

Train Avg F1  307: 0.255200849367516

Val Avg Loss  307: 0.218078

Val Avg F1  307:  0.2263425925925926

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 308
--------------------------------------------------------------
Epoch:  308        1 Batch loss: 0.198323 Batch F1: 0.2
Epoch:  308        2 Batch loss: 0.232402 Batch F1: 0.1739130434782609
Epoch:  308        3 Batch loss: 0.220609 Batch F1: 0.09523809523809523
Epoch:  308        4 Batch loss: 0.167712 Batch F1: 0.0
Epoch:  308        5 Batch loss: 0.254730 Batch F1: 0.0
Epoch:  308        6 Batch loss: 0.233264 Batch F1: 0.0
Epoch:  308        7 Batch loss: 0.239286 Batch F1: 0.18181818181818182
Epoch:  308        8 Batch loss: 0.226485 Batch F1: 0.32000000000000006
Epoch:  308        9 Batch loss: 0.207838 Batch F1: 0.2
Epoch:  308       10 Batch loss: 0.221128 Batch F1: 0.3333333333333333
Epoch:  308       11 Batch loss: 0.227015 Batch F1: 0.3448275862068965
Epoch:  308       12 Batch loss: 0.247230 Batch F1: 0.37037037037037035
Train Avg Loss  308: 0.223002

Train Avg F1  308: 0.1849583842037615

Val Avg Loss  308: 0.223826

Val Avg F1  308:  0.3557239057239057

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 309
--------------------------------------------------------------
Epoch:  309        1 Batch loss: 0.204857 Batch F1: 0.5517241379310344
Epoch:  309        2 Batch loss: 0.221901 Batch F1: 0.4375
Epoch:  309        3 Batch loss: 0.235548 Batch F1: 0.4242424242424242
Epoch:  309        4 Batch loss: 0.235992 Batch F1: 0.3846153846153846
Epoch:  309        5 Batch loss: 0.230355 Batch F1: 0.30769230769230765
Epoch:  309        6 Batch loss: 0.218351 Batch F1: 0.4166666666666667
Epoch:  309        7 Batch loss: 0.248811 Batch F1: 0.3333333333333333
Epoch:  309        8 Batch loss: 0.203515 Batch F1: 0.23529411764705882
Epoch:  309        9 Batch loss: 0.230161 Batch F1: 0.0
Epoch:  309       10 Batch loss: 0.190375 Batch F1: 0.0
Epoch:  309       11 Batch loss: 0.238734 Batch F1: 0.0
Epoch:  309       12 Batch loss: 0.237642 Batch F1: 0.0
Train Avg Loss  309: 0.224687

Train Avg F1  309: 0.25758903101068414

Val Avg Loss  309: 0.217512

Val Avg F1  309:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 310
--------------------------------------------------------------
Epoch:  310        1 Batch loss: 0.228455 Batch F1: 0.0
Epoch:  310        2 Batch loss: 0.208714 Batch F1: 0.0
Epoch:  310        3 Batch loss: 0.223858 Batch F1: 0.0
Epoch:  310        4 Batch loss: 0.243502 Batch F1: 0.0
Epoch:  310        5 Batch loss: 0.190910 Batch F1: 0.0
Epoch:  310        6 Batch loss: 0.236660 Batch F1: 0.0
Epoch:  310        7 Batch loss: 0.221731 Batch F1: 0.09090909090909091
Epoch:  310        8 Batch loss: 0.249034 Batch F1: 0.3529411764705882
Epoch:  310        9 Batch loss: 0.254486 Batch F1: 0.43750000000000006
Epoch:  310       10 Batch loss: 0.180527 Batch F1: 0.5263157894736842
Epoch:  310       11 Batch loss: 0.234265 Batch F1: 0.2857142857142857
Epoch:  310       12 Batch loss: 0.212254 Batch F1: 0.4166666666666667
Train Avg Loss  310: 0.223700

Train Avg F1  310: 0.17583725076952628

Val Avg Loss  310: 0.218544

Val Avg F1  310:  0.2642650103519669

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 311
--------------------------------------------------------------
Epoch:  311        1 Batch loss: 0.223970 Batch F1: 0.48275862068965514
Epoch:  311        2 Batch loss: 0.207344 Batch F1: 0.09999999999999999
Epoch:  311        3 Batch loss: 0.252154 Batch F1: 0.3333333333333333
Epoch:  311        4 Batch loss: 0.206379 Batch F1: 0.19047619047619047
Epoch:  311        5 Batch loss: 0.226153 Batch F1: 0.32
Epoch:  311        6 Batch loss: 0.226291 Batch F1: 0.24
Epoch:  311        7 Batch loss: 0.204784 Batch F1: 0.3
Epoch:  311        8 Batch loss: 0.214532 Batch F1: 0.23076923076923078
Epoch:  311        9 Batch loss: 0.225662 Batch F1: 0.25
Epoch:  311       10 Batch loss: 0.253276 Batch F1: 0.2962962962962963
Epoch:  311       11 Batch loss: 0.214430 Batch F1: 0.3333333333333333
Epoch:  311       12 Batch loss: 0.211284 Batch F1: 0.13333333333333333
Train Avg Loss  311: 0.222188

Train Avg F1  311: 0.26752502818594776

Val Avg Loss  311: 0.218069

Val Avg F1  311:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 312
--------------------------------------------------------------
Epoch:  312        1 Batch loss: 0.201181 Batch F1: 0.0
Epoch:  312        2 Batch loss: 0.240709 Batch F1: 0.0
Epoch:  312        3 Batch loss: 0.192455 Batch F1: 0.0
Epoch:  312        4 Batch loss: 0.246343 Batch F1: 0.0
Epoch:  312        5 Batch loss: 0.232915 Batch F1: 0.0
Epoch:  312        6 Batch loss: 0.185166 Batch F1: 0.0
Epoch:  312        7 Batch loss: 0.190251 Batch F1: 0.0
Epoch:  312        8 Batch loss: 0.251193 Batch F1: 0.0
Epoch:  312        9 Batch loss: 0.238196 Batch F1: 0.0
Epoch:  312       10 Batch loss: 0.219256 Batch F1: 0.0
Epoch:  312       11 Batch loss: 0.239762 Batch F1: 0.2962962962962963
Epoch:  312       12 Batch loss: 0.260579 Batch F1: 0.16666666666666666
Train Avg Loss  312: 0.224834

Train Avg F1  312: 0.038580246913580245

Val Avg Loss  312: 0.220604

Val Avg F1  312:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 313
--------------------------------------------------------------
Epoch:  313        1 Batch loss: 0.217808 Batch F1: 0.125
Epoch:  313        2 Batch loss: 0.206647 Batch F1: 0.0
Epoch:  313        3 Batch loss: 0.268557 Batch F1: 0.0
Epoch:  313        4 Batch loss: 0.186562 Batch F1: 0.0
Epoch:  313        5 Batch loss: 0.243939 Batch F1: 0.0
Epoch:  313        6 Batch loss: 0.223681 Batch F1: 0.0
Epoch:  313        7 Batch loss: 0.226820 Batch F1: 0.0
Epoch:  313        8 Batch loss: 0.233342 Batch F1: 0.0
Epoch:  313        9 Batch loss: 0.232974 Batch F1: 0.0
Epoch:  313       10 Batch loss: 0.220137 Batch F1: 0.0
Epoch:  313       11 Batch loss: 0.230744 Batch F1: 0.17391304347826084
Epoch:  313       12 Batch loss: 0.235162 Batch F1: 0.5625
Train Avg Loss  313: 0.227198

Train Avg F1  313: 0.07178442028985507

Val Avg Loss  313: 0.230178

Val Avg F1  313:  0.43943255233577816

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 314
--------------------------------------------------------------
Epoch:  314        1 Batch loss: 0.203630 Batch F1: 0.7500000000000001
Epoch:  314        2 Batch loss: 0.237124 Batch F1: 0.42857142857142855
Epoch:  314        3 Batch loss: 0.237259 Batch F1: 0.4516129032258065
Epoch:  314        4 Batch loss: 0.241570 Batch F1: 0.0
Epoch:  314        5 Batch loss: 0.199697 Batch F1: 0.0
Epoch:  314        6 Batch loss: 0.243320 Batch F1: 0.0
Epoch:  314        7 Batch loss: 0.219981 Batch F1: 0.0
Epoch:  314        8 Batch loss: 0.233806 Batch F1: 0.09523809523809525
Epoch:  314        9 Batch loss: 0.243360 Batch F1: 0.0
Epoch:  314       10 Batch loss: 0.185754 Batch F1: 0.0
Epoch:  314       11 Batch loss: 0.237561 Batch F1: 0.0
Epoch:  314       12 Batch loss: 0.205459 Batch F1: 0.0
Train Avg Loss  314: 0.224043

Train Avg F1  314: 0.1437852022529442

Val Avg Loss  314: 0.217791

Val Avg F1  314:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 315
--------------------------------------------------------------
Epoch:  315        1 Batch loss: 0.240192 Batch F1: 0.0
Epoch:  315        2 Batch loss: 0.231251 Batch F1: 0.0
Epoch:  315        3 Batch loss: 0.217460 Batch F1: 0.0
Epoch:  315        4 Batch loss: 0.204493 Batch F1: 0.2608695652173913
Epoch:  315        5 Batch loss: 0.232279 Batch F1: 0.3448275862068966
Epoch:  315        6 Batch loss: 0.221212 Batch F1: 0.19047619047619047
Epoch:  315        7 Batch loss: 0.211545 Batch F1: 0.19047619047619047
Epoch:  315        8 Batch loss: 0.237795 Batch F1: 0.09090909090909091
Epoch:  315        9 Batch loss: 0.210455 Batch F1: 0.0
Epoch:  315       10 Batch loss: 0.208589 Batch F1: 0.0
Epoch:  315       11 Batch loss: 0.222998 Batch F1: 0.4166666666666667
Epoch:  315       12 Batch loss: 0.251155 Batch F1: 0.2
Train Avg Loss  315: 0.224119

Train Avg F1  315: 0.14118544082936887

Val Avg Loss  315: 0.217828

Val Avg F1  315:  0.26633221850613154

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 316
--------------------------------------------------------------
Epoch:  316        1 Batch loss: 0.210847 Batch F1: 0.38095238095238093
Epoch:  316        2 Batch loss: 0.212849 Batch F1: 0.0
Epoch:  316        3 Batch loss: 0.223612 Batch F1: 0.0
Epoch:  316        4 Batch loss: 0.212958 Batch F1: 0.10526315789473684
Epoch:  316        5 Batch loss: 0.221909 Batch F1: 0.3
Epoch:  316        6 Batch loss: 0.243261 Batch F1: 0.4
Epoch:  316        7 Batch loss: 0.221424 Batch F1: 0.4166666666666667
Epoch:  316        8 Batch loss: 0.252323 Batch F1: 0.36363636363636365
Epoch:  316        9 Batch loss: 0.227551 Batch F1: 0.48275862068965514
Epoch:  316       10 Batch loss: 0.210506 Batch F1: 0.25
Epoch:  316       11 Batch loss: 0.224189 Batch F1: 0.32
Epoch:  316       12 Batch loss: 0.199464 Batch F1: 0.125
Train Avg Loss  316: 0.221741

Train Avg F1  316: 0.26202309915331695

Val Avg Loss  316: 0.220013

Val Avg F1  316:  0.245605138607167

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 317
--------------------------------------------------------------
Epoch:  317        1 Batch loss: 0.232377 Batch F1: 0.4
Epoch:  317        2 Batch loss: 0.192565 Batch F1: 0.4
Epoch:  317        3 Batch loss: 0.221141 Batch F1: 0.5714285714285714
Epoch:  317        4 Batch loss: 0.204440 Batch F1: 0.2
Epoch:  317        5 Batch loss: 0.238254 Batch F1: 0.43749999999999994
Epoch:  317        6 Batch loss: 0.236823 Batch F1: 0.30303030303030304
Epoch:  317        7 Batch loss: 0.213592 Batch F1: 0.4
Epoch:  317        8 Batch loss: 0.243535 Batch F1: 0.16
Epoch:  317        9 Batch loss: 0.231631 Batch F1: 0.3076923076923077
Epoch:  317       10 Batch loss: 0.221060 Batch F1: 0.09523809523809525
Epoch:  317       11 Batch loss: 0.210741 Batch F1: 0.125
Epoch:  317       12 Batch loss: 0.224136 Batch F1: 0.2222222222222222
Train Avg Loss  317: 0.222525

Train Avg F1  317: 0.301842624967625

Val Avg Loss  317: 0.218324

Val Avg F1  317:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 318
--------------------------------------------------------------
Epoch:  318        1 Batch loss: 0.201040 Batch F1: 0.1
Epoch:  318        2 Batch loss: 0.238550 Batch F1: 0.09523809523809525
Epoch:  318        3 Batch loss: 0.229031 Batch F1: 0.0
Epoch:  318        4 Batch loss: 0.230292 Batch F1: 0.0
Epoch:  318        5 Batch loss: 0.252108 Batch F1: 0.07407407407407407
Epoch:  318        6 Batch loss: 0.275776 Batch F1: 0.08333333333333334
Epoch:  318        7 Batch loss: 0.213554 Batch F1: 0.3333333333333333
Epoch:  318        8 Batch loss: 0.189345 Batch F1: 0.4999999999999999
Epoch:  318        9 Batch loss: 0.234342 Batch F1: 0.23076923076923075
Epoch:  318       10 Batch loss: 0.211080 Batch F1: 0.2
Epoch:  318       11 Batch loss: 0.206521 Batch F1: 0.4166666666666667
Epoch:  318       12 Batch loss: 0.188004 Batch F1: 0.5454545454545455
Train Avg Loss  318: 0.222470

Train Avg F1  318: 0.21490577323910656

Val Avg Loss  318: 0.218696

Val Avg F1  318:  0.2460063085063085

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 319
--------------------------------------------------------------
Epoch:  319        1 Batch loss: 0.261475 Batch F1: 0.42424242424242425
Epoch:  319        2 Batch loss: 0.177748 Batch F1: 0.36363636363636365
Epoch:  319        3 Batch loss: 0.205564 Batch F1: 0.5
Epoch:  319        4 Batch loss: 0.261263 Batch F1: 0.14814814814814814
Epoch:  319        5 Batch loss: 0.210653 Batch F1: 0.36363636363636365
Epoch:  319        6 Batch loss: 0.186886 Batch F1: 0.48
Epoch:  319        7 Batch loss: 0.218788 Batch F1: 0.2727272727272727
Epoch:  319        8 Batch loss: 0.215294 Batch F1: 0.1904761904761905
Epoch:  319        9 Batch loss: 0.207285 Batch F1: 0.27272727272727276
Epoch:  319       10 Batch loss: 0.251574 Batch F1: 0.13793103448275862
Epoch:  319       11 Batch loss: 0.232103 Batch F1: 0.3846153846153846
Epoch:  319       12 Batch loss: 0.238620 Batch F1: 0.2
Train Avg Loss  319: 0.222271

Train Avg F1  319: 0.31151170455768157

Val Avg Loss  319: 0.219217

Val Avg F1  319:  0.2435064935064935

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 320
--------------------------------------------------------------
Epoch:  320        1 Batch loss: 0.254577 Batch F1: 0.26666666666666666
Epoch:  320        2 Batch loss: 0.200522 Batch F1: 0.2857142857142857
Epoch:  320        3 Batch loss: 0.196007 Batch F1: 0.4
Epoch:  320        4 Batch loss: 0.205871 Batch F1: 0.23529411764705882
Epoch:  320        5 Batch loss: 0.205113 Batch F1: 0.1111111111111111
Epoch:  320        6 Batch loss: 0.220119 Batch F1: 0.0
Epoch:  320        7 Batch loss: 0.204720 Batch F1: 0.0
Epoch:  320        8 Batch loss: 0.250770 Batch F1: 0.0
Epoch:  320        9 Batch loss: 0.195449 Batch F1: 0.0
Epoch:  320       10 Batch loss: 0.276315 Batch F1: 0.07692307692307693
Epoch:  320       11 Batch loss: 0.237875 Batch F1: 0.08695652173913045
Epoch:  320       12 Batch loss: 0.232168 Batch F1: 0.4166666666666667
Train Avg Loss  320: 0.223292

Train Avg F1  320: 0.15661103720566635

Val Avg Loss  320: 0.221115

Val Avg F1  320:  0.23879812618943055

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 321
--------------------------------------------------------------
Epoch:  321        1 Batch loss: 0.207884 Batch F1: 0.3076923076923077
Epoch:  321        2 Batch loss: 0.222755 Batch F1: 0.5454545454545454
Epoch:  321        3 Batch loss: 0.210661 Batch F1: 0.42857142857142855
Epoch:  321        4 Batch loss: 0.256195 Batch F1: 0.23076923076923075
Epoch:  321        5 Batch loss: 0.243183 Batch F1: 0.2608695652173913
Epoch:  321        6 Batch loss: 0.209926 Batch F1: 0.0
Epoch:  321        7 Batch loss: 0.225774 Batch F1: 0.0
Epoch:  321        8 Batch loss: 0.265539 Batch F1: 0.0
Epoch:  321        9 Batch loss: 0.179188 Batch F1: 0.0
Epoch:  321       10 Batch loss: 0.216569 Batch F1: 0.0
Epoch:  321       11 Batch loss: 0.224150 Batch F1: 0.11764705882352941
Epoch:  321       12 Batch loss: 0.229300 Batch F1: 0.0
Train Avg Loss  321: 0.224260

Train Avg F1  321: 0.1575836780440361

Val Avg Loss  321: 0.218044

Val Avg F1  321:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 322
--------------------------------------------------------------
Epoch:  322        1 Batch loss: 0.231585 Batch F1: 0.0
Epoch:  322        2 Batch loss: 0.207696 Batch F1: 0.125
Epoch:  322        3 Batch loss: 0.181450 Batch F1: 0.0
Epoch:  322        4 Batch loss: 0.200449 Batch F1: 0.0
Epoch:  322        5 Batch loss: 0.248575 Batch F1: 0.0
Epoch:  322        6 Batch loss: 0.292612 Batch F1: 0.0
Epoch:  322        7 Batch loss: 0.214635 Batch F1: 0.0
Epoch:  322        8 Batch loss: 0.212731 Batch F1: 0.0
Epoch:  322        9 Batch loss: 0.220697 Batch F1: 0.32
Epoch:  322       10 Batch loss: 0.205988 Batch F1: 0.22222222222222224
Epoch:  322       11 Batch loss: 0.251355 Batch F1: 0.3448275862068966
Epoch:  322       12 Batch loss: 0.237564 Batch F1: 0.4285714285714285
Train Avg Loss  322: 0.225445

Train Avg F1  322: 0.12005176975004561

Val Avg Loss  322: 0.220841

Val Avg F1  322:  0.28603059581320445

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 323
--------------------------------------------------------------
Epoch:  323        1 Batch loss: 0.205026 Batch F1: 0.2222222222222222
Epoch:  323        2 Batch loss: 0.255872 Batch F1: 0.375
Epoch:  323        3 Batch loss: 0.212696 Batch F1: 0.6857142857142857
Epoch:  323        4 Batch loss: 0.230177 Batch F1: 0.35714285714285715
Epoch:  323        5 Batch loss: 0.226213 Batch F1: 0.33333333333333337
Epoch:  323        6 Batch loss: 0.190418 Batch F1: 0.5217391304347826
Epoch:  323        7 Batch loss: 0.256516 Batch F1: 0.3529411764705882
Epoch:  323        8 Batch loss: 0.178944 Batch F1: 0.125
Epoch:  323        9 Batch loss: 0.236658 Batch F1: 0.23076923076923073
Epoch:  323       10 Batch loss: 0.233405 Batch F1: 0.37037037037037035
Epoch:  323       11 Batch loss: 0.208849 Batch F1: 0.2857142857142857
Epoch:  323       12 Batch loss: 0.248701 Batch F1: 0.3478260869565218
Train Avg Loss  323: 0.223623

Train Avg F1  323: 0.3506477482607065

Val Avg Loss  323: 0.218507

Val Avg F1  323:  0.10055555555555555

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 324
--------------------------------------------------------------
Epoch:  324        1 Batch loss: 0.212616 Batch F1: 0.3333333333333333
Epoch:  324        2 Batch loss: 0.204030 Batch F1: 0.09523809523809523
Epoch:  324        3 Batch loss: 0.225875 Batch F1: 0.0
Epoch:  324        4 Batch loss: 0.231660 Batch F1: 0.1904761904761905
Epoch:  324        5 Batch loss: 0.220442 Batch F1: 0.0909090909090909
Epoch:  324        6 Batch loss: 0.237013 Batch F1: 0.1904761904761905
Epoch:  324        7 Batch loss: 0.196295 Batch F1: 0.3
Epoch:  324        8 Batch loss: 0.245623 Batch F1: 0.25806451612903225
Epoch:  324        9 Batch loss: 0.221525 Batch F1: 0.23529411764705882
Epoch:  324       10 Batch loss: 0.229484 Batch F1: 0.1739130434782609
Epoch:  324       11 Batch loss: 0.237160 Batch F1: 0.2608695652173913
Epoch:  324       12 Batch loss: 0.204673 Batch F1: 0.4210526315789473
Train Avg Loss  324: 0.222200

Train Avg F1  324: 0.21246889787363257

Val Avg Loss  324: 0.219222

Val Avg F1  324:  0.24788807519317263

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 325
--------------------------------------------------------------
Epoch:  325        1 Batch loss: 0.210931 Batch F1: 0.4
Epoch:  325        2 Batch loss: 0.227203 Batch F1: 0.25
Epoch:  325        3 Batch loss: 0.213152 Batch F1: 0.2608695652173913
Epoch:  325        4 Batch loss: 0.242365 Batch F1: 0.41379310344827586
Epoch:  325        5 Batch loss: 0.200585 Batch F1: 0.5
Epoch:  325        6 Batch loss: 0.213249 Batch F1: 0.4
Epoch:  325        7 Batch loss: 0.231011 Batch F1: 0.35714285714285715
Epoch:  325        8 Batch loss: 0.252176 Batch F1: 0.08
Epoch:  325        9 Batch loss: 0.190082 Batch F1: 0.4
Epoch:  325       10 Batch loss: 0.229846 Batch F1: 0.39999999999999997
Epoch:  325       11 Batch loss: 0.224949 Batch F1: 0.1739130434782609
Epoch:  325       12 Batch loss: 0.232495 Batch F1: 0.23529411764705882
Train Avg Loss  325: 0.222337

Train Avg F1  325: 0.32258439057782035

Val Avg Loss  325: 0.219156

Val Avg F1  325:  0.24966931216931215

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 326
--------------------------------------------------------------
Epoch:  326        1 Batch loss: 0.239196 Batch F1: 0.19047619047619047
Epoch:  326        2 Batch loss: 0.236141 Batch F1: 0.08695652173913042
Epoch:  326        3 Batch loss: 0.212440 Batch F1: 0.36363636363636365
Epoch:  326        4 Batch loss: 0.239215 Batch F1: 0.0
Epoch:  326        5 Batch loss: 0.188909 Batch F1: 0.0
Epoch:  326        6 Batch loss: 0.210114 Batch F1: 0.19999999999999998
Epoch:  326        7 Batch loss: 0.172079 Batch F1: 0.14285714285714288
Epoch:  326        8 Batch loss: 0.238842 Batch F1: 0.0
Epoch:  326        9 Batch loss: 0.201823 Batch F1: 0.0
Epoch:  326       10 Batch loss: 0.273168 Batch F1: 0.13333333333333333
Epoch:  326       11 Batch loss: 0.223173 Batch F1: 0.10526315789473684
Epoch:  326       12 Batch loss: 0.236492 Batch F1: 0.3
Train Avg Loss  326: 0.222633

Train Avg F1  326: 0.1268768924947415

Val Avg Loss  326: 0.218588

Val Avg F1  326:  0.266025641025641

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 327
--------------------------------------------------------------
Epoch:  327        1 Batch loss: 0.185178 Batch F1: 0.4545454545454546
Epoch:  327        2 Batch loss: 0.236745 Batch F1: 0.16666666666666666
Epoch:  327        3 Batch loss: 0.229423 Batch F1: 0.24
Epoch:  327        4 Batch loss: 0.234655 Batch F1: 0.23076923076923075
Epoch:  327        5 Batch loss: 0.206370 Batch F1: 0.5333333333333333
Epoch:  327        6 Batch loss: 0.205648 Batch F1: 0.56
Epoch:  327        7 Batch loss: 0.226829 Batch F1: 0.4
Epoch:  327        8 Batch loss: 0.230961 Batch F1: 0.25
Epoch:  327        9 Batch loss: 0.238500 Batch F1: 0.2857142857142857
Epoch:  327       10 Batch loss: 0.228608 Batch F1: 0.37037037037037035
Epoch:  327       11 Batch loss: 0.231681 Batch F1: 0.32
Epoch:  327       12 Batch loss: 0.222009 Batch F1: 0.0
Train Avg Loss  327: 0.223051

Train Avg F1  327: 0.31761661178327844

Val Avg Loss  327: 0.218587

Val Avg F1  327:  0.26627289377289376

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 328
--------------------------------------------------------------
Epoch:  328        1 Batch loss: 0.219559 Batch F1: 0.19047619047619047
Epoch:  328        2 Batch loss: 0.221374 Batch F1: 0.0
Epoch:  328        3 Batch loss: 0.222286 Batch F1: 0.0
Epoch:  328        4 Batch loss: 0.201974 Batch F1: 0.0
Epoch:  328        5 Batch loss: 0.222791 Batch F1: 0.0
Epoch:  328        6 Batch loss: 0.212679 Batch F1: 0.0
Epoch:  328        7 Batch loss: 0.232558 Batch F1: 0.0
Epoch:  328        8 Batch loss: 0.233833 Batch F1: 0.0
Epoch:  328        9 Batch loss: 0.224475 Batch F1: 0.32000000000000006
Epoch:  328       10 Batch loss: 0.189999 Batch F1: 0.5882352941176471
Epoch:  328       11 Batch loss: 0.249387 Batch F1: 0.21428571428571427
Epoch:  328       12 Batch loss: 0.251331 Batch F1: 0.09523809523809523
Train Avg Loss  328: 0.223520

Train Avg F1  328: 0.11735294117647059

Val Avg Loss  328: 0.219697

Val Avg F1  328:  0.2602564102564102

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 329
--------------------------------------------------------------
Epoch:  329        1 Batch loss: 0.203997 Batch F1: 0.19047619047619047
Epoch:  329        2 Batch loss: 0.224173 Batch F1: 0.3846153846153846
Epoch:  329        3 Batch loss: 0.231622 Batch F1: 0.09523809523809525
Epoch:  329        4 Batch loss: 0.225332 Batch F1: 0.39999999999999997
Epoch:  329        5 Batch loss: 0.235895 Batch F1: 0.39999999999999997
Epoch:  329        6 Batch loss: 0.223109 Batch F1: 0.4
Epoch:  329        7 Batch loss: 0.216997 Batch F1: 0.1739130434782609
Epoch:  329        8 Batch loss: 0.224410 Batch F1: 0.2608695652173913
Epoch:  329        9 Batch loss: 0.234339 Batch F1: 0.27586206896551724
Epoch:  329       10 Batch loss: 0.237275 Batch F1: 0.1739130434782609
Epoch:  329       11 Batch loss: 0.197756 Batch F1: 0.3529411764705882
Epoch:  329       12 Batch loss: 0.220834 Batch F1: 0.5384615384615385
Train Avg Loss  329: 0.222978

Train Avg F1  329: 0.30385750886676893

Val Avg Loss  329: 0.218315

Val Avg F1  329:  0.2565105946684894

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 330
--------------------------------------------------------------
Epoch:  330        1 Batch loss: 0.186760 Batch F1: 0.3529411764705882
Epoch:  330        2 Batch loss: 0.230504 Batch F1: 0.09523809523809525
Epoch:  330        3 Batch loss: 0.201629 Batch F1: 0.0
Epoch:  330        4 Batch loss: 0.219939 Batch F1: 0.0
Epoch:  330        5 Batch loss: 0.257813 Batch F1: 0.0
Epoch:  330        6 Batch loss: 0.243572 Batch F1: 0.0
Epoch:  330        7 Batch loss: 0.192059 Batch F1: 0.0
Epoch:  330        8 Batch loss: 0.224023 Batch F1: 0.0
Epoch:  330        9 Batch loss: 0.219992 Batch F1: 0.3333333333333333
Epoch:  330       10 Batch loss: 0.219095 Batch F1: 0.3333333333333333
Epoch:  330       11 Batch loss: 0.238930 Batch F1: 0.29629629629629634
Epoch:  330       12 Batch loss: 0.245884 Batch F1: 0.42857142857142855
Train Avg Loss  330: 0.223350

Train Avg F1  330: 0.1533094719369229

Val Avg Loss  330: 0.219572

Val Avg F1  330:  0.266424287856072

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 331
--------------------------------------------------------------
Epoch:  331        1 Batch loss: 0.204947 Batch F1: 0.5
Epoch:  331        2 Batch loss: 0.238942 Batch F1: 0.3333333333333333
Epoch:  331        3 Batch loss: 0.209931 Batch F1: 0.2857142857142857
Epoch:  331        4 Batch loss: 0.216329 Batch F1: 0.5454545454545455
Epoch:  331        5 Batch loss: 0.232571 Batch F1: 0.16666666666666666
Epoch:  331        6 Batch loss: 0.214686 Batch F1: 0.39999999999999997
Epoch:  331        7 Batch loss: 0.196498 Batch F1: 0.33333333333333337
Epoch:  331        8 Batch loss: 0.232590 Batch F1: 0.0
Epoch:  331        9 Batch loss: 0.242225 Batch F1: 0.0909090909090909
Epoch:  331       10 Batch loss: 0.229639 Batch F1: 0.0
Epoch:  331       11 Batch loss: 0.218307 Batch F1: 0.0
Epoch:  331       12 Batch loss: 0.240315 Batch F1: 0.18181818181818182
Train Avg Loss  331: 0.223082

Train Avg F1  331: 0.23643578643578644

Val Avg Loss  331: 0.219719

Val Avg F1  331:  0.24367102396514162

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 332
--------------------------------------------------------------
Epoch:  332        1 Batch loss: 0.191831 Batch F1: 0.3157894736842105
Epoch:  332        2 Batch loss: 0.264783 Batch F1: 0.3125
Epoch:  332        3 Batch loss: 0.217344 Batch F1: 0.3846153846153846
Epoch:  332        4 Batch loss: 0.211750 Batch F1: 0.46153846153846156
Epoch:  332        5 Batch loss: 0.219907 Batch F1: 0.37499999999999994
Epoch:  332        6 Batch loss: 0.216460 Batch F1: 0.09090909090909091
Epoch:  332        7 Batch loss: 0.238816 Batch F1: 0.3448275862068965
Epoch:  332        8 Batch loss: 0.232112 Batch F1: 0.29629629629629634
Epoch:  332        9 Batch loss: 0.231605 Batch F1: 0.0909090909090909
Epoch:  332       10 Batch loss: 0.201724 Batch F1: 0.4545454545454545
Epoch:  332       11 Batch loss: 0.239919 Batch F1: 0.09523809523809525
Epoch:  332       12 Batch loss: 0.196219 Batch F1: 0.125
Train Avg Loss  332: 0.221872

Train Avg F1  332: 0.2789307444952484

Val Avg Loss  332: 0.218401

Val Avg F1  332:  0.1853238866396761

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 333
--------------------------------------------------------------
Epoch:  333        1 Batch loss: 0.225181 Batch F1: 0.18181818181818182
Epoch:  333        2 Batch loss: 0.223263 Batch F1: 0.09523809523809523
Epoch:  333        3 Batch loss: 0.280525 Batch F1: 0.0
Epoch:  333        4 Batch loss: 0.201380 Batch F1: 0.0
Epoch:  333        5 Batch loss: 0.218896 Batch F1: 0.10526315789473684
Epoch:  333        6 Batch loss: 0.240176 Batch F1: 0.16
Epoch:  333        7 Batch loss: 0.213261 Batch F1: 0.33333333333333337
Epoch:  333        8 Batch loss: 0.220197 Batch F1: 0.5333333333333333
Epoch:  333        9 Batch loss: 0.182802 Batch F1: 0.5599999999999999
Epoch:  333       10 Batch loss: 0.239316 Batch F1: 0.2857142857142857
Epoch:  333       11 Batch loss: 0.228631 Batch F1: 0.25
Epoch:  333       12 Batch loss: 0.202894 Batch F1: 0.0
Train Avg Loss  333: 0.223044

Train Avg F1  333: 0.20872503227766384

Val Avg Loss  333: 0.217858

Val Avg F1  333:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 334
--------------------------------------------------------------
Epoch:  334        1 Batch loss: 0.210144 Batch F1: 0.0
Epoch:  334        2 Batch loss: 0.228869 Batch F1: 0.0
Epoch:  334        3 Batch loss: 0.213761 Batch F1: 0.0
Epoch:  334        4 Batch loss: 0.208415 Batch F1: 0.1
Epoch:  334        5 Batch loss: 0.223634 Batch F1: 0.10526315789473684
Epoch:  334        6 Batch loss: 0.211020 Batch F1: 0.4
Epoch:  334        7 Batch loss: 0.249105 Batch F1: 0.3448275862068966
Epoch:  334        8 Batch loss: 0.223815 Batch F1: 0.3333333333333333
Epoch:  334        9 Batch loss: 0.219542 Batch F1: 0.35714285714285715
Epoch:  334       10 Batch loss: 0.231157 Batch F1: 0.3703703703703704
Epoch:  334       11 Batch loss: 0.221846 Batch F1: 0.25
Epoch:  334       12 Batch loss: 0.230690 Batch F1: 0.21052631578947364
Train Avg Loss  334: 0.222667

Train Avg F1  334: 0.205955301728139

Val Avg Loss  334: 0.218531

Val Avg F1  334:  0.23065476190476192

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 335
--------------------------------------------------------------
Epoch:  335        1 Batch loss: 0.203573 Batch F1: 0.34782608695652173
Epoch:  335        2 Batch loss: 0.225066 Batch F1: 0.0
Epoch:  335        3 Batch loss: 0.253173 Batch F1: 0.0
Epoch:  335        4 Batch loss: 0.247830 Batch F1: 0.0
Epoch:  335        5 Batch loss: 0.236313 Batch F1: 0.0
Epoch:  335        6 Batch loss: 0.184965 Batch F1: 0.0
Epoch:  335        7 Batch loss: 0.231301 Batch F1: 0.0
Epoch:  335        8 Batch loss: 0.227255 Batch F1: 0.0
Epoch:  335        9 Batch loss: 0.223548 Batch F1: 0.18181818181818182
Epoch:  335       10 Batch loss: 0.185444 Batch F1: 0.0
Epoch:  335       11 Batch loss: 0.225999 Batch F1: 0.0
Epoch:  335       12 Batch loss: 0.233385 Batch F1: 0.10526315789473684
Train Avg Loss  335: 0.223154

Train Avg F1  335: 0.05290895222245337

Val Avg Loss  335: 0.218973

Val Avg F1  335:  0.27642857142857147

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 336
--------------------------------------------------------------
Epoch:  336        1 Batch loss: 0.250623 Batch F1: 0.23076923076923075
Epoch:  336        2 Batch loss: 0.252945 Batch F1: 0.26666666666666666
Epoch:  336        3 Batch loss: 0.224176 Batch F1: 0.41379310344827586
Epoch:  336        4 Batch loss: 0.211449 Batch F1: 0.45161290322580644
Epoch:  336        5 Batch loss: 0.241511 Batch F1: 0.41379310344827586
Epoch:  336        6 Batch loss: 0.208667 Batch F1: 0.5384615384615384
Epoch:  336        7 Batch loss: 0.203035 Batch F1: 0.5517241379310345
Epoch:  336        8 Batch loss: 0.216518 Batch F1: 0.5517241379310345
Epoch:  336        9 Batch loss: 0.228838 Batch F1: 0.25806451612903225
Epoch:  336       10 Batch loss: 0.191504 Batch F1: 0.4444444444444444
Epoch:  336       11 Batch loss: 0.234477 Batch F1: 0.0909090909090909
Epoch:  336       12 Batch loss: 0.215497 Batch F1: 0.23529411764705882
Train Avg Loss  336: 0.223270

Train Avg F1  336: 0.37060474925095743

Val Avg Loss  336: 0.217763

Val Avg F1  336:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 337
--------------------------------------------------------------
Epoch:  337        1 Batch loss: 0.235578 Batch F1: 0.09523809523809523
Epoch:  337        2 Batch loss: 0.216871 Batch F1: 0.0
Epoch:  337        3 Batch loss: 0.215428 Batch F1: 0.0
Epoch:  337        4 Batch loss: 0.220573 Batch F1: 0.1
Epoch:  337        5 Batch loss: 0.216645 Batch F1: 0.5185185185185185
Epoch:  337        6 Batch loss: 0.223482 Batch F1: 0.2
Epoch:  337        7 Batch loss: 0.201776 Batch F1: 0.21052631578947367
Epoch:  337        8 Batch loss: 0.274832 Batch F1: 0.0
Epoch:  337        9 Batch loss: 0.247800 Batch F1: 0.07142857142857142
Epoch:  337       10 Batch loss: 0.208972 Batch F1: 0.33333333333333337
Epoch:  337       11 Batch loss: 0.230214 Batch F1: 0.17391304347826086
Epoch:  337       12 Batch loss: 0.203085 Batch F1: 0.13333333333333336
Train Avg Loss  337: 0.224605

Train Avg F1  337: 0.15302426759329887

Val Avg Loss  337: 0.217369

Val Avg F1  337:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 338
--------------------------------------------------------------
Epoch:  338        1 Batch loss: 0.258139 Batch F1: 0.0
Epoch:  338        2 Batch loss: 0.215108 Batch F1: 0.0
Epoch:  338        3 Batch loss: 0.219189 Batch F1: 0.0
Epoch:  338        4 Batch loss: 0.208444 Batch F1: 0.0
Epoch:  338        5 Batch loss: 0.190614 Batch F1: 0.0
Epoch:  338        6 Batch loss: 0.270693 Batch F1: 0.0
Epoch:  338        7 Batch loss: 0.229198 Batch F1: 0.0
Epoch:  338        8 Batch loss: 0.235771 Batch F1: 0.0
Epoch:  338        9 Batch loss: 0.190539 Batch F1: 0.0
Epoch:  338       10 Batch loss: 0.210954 Batch F1: 0.1818181818181818
Epoch:  338       11 Batch loss: 0.246334 Batch F1: 0.37037037037037035
Epoch:  338       12 Batch loss: 0.225416 Batch F1: 0.2105263157894737
Train Avg Loss  338: 0.225033

Train Avg F1  338: 0.06355957233150215

Val Avg Loss  338: 0.219677

Val Avg F1  338:  0.3312770562770563

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 339
--------------------------------------------------------------
Epoch:  339        1 Batch loss: 0.215791 Batch F1: 0.44444444444444436
Epoch:  339        2 Batch loss: 0.207010 Batch F1: 0.2727272727272727
Epoch:  339        3 Batch loss: 0.230384 Batch F1: 0.4666666666666667
Epoch:  339        4 Batch loss: 0.221270 Batch F1: 0.42857142857142855
Epoch:  339        5 Batch loss: 0.199821 Batch F1: 0.4827586206896552
Epoch:  339        6 Batch loss: 0.248643 Batch F1: 0.26666666666666666
Epoch:  339        7 Batch loss: 0.205651 Batch F1: 0.30769230769230765
Epoch:  339        8 Batch loss: 0.260758 Batch F1: 0.24
Epoch:  339        9 Batch loss: 0.207300 Batch F1: 0.08695652173913042
Epoch:  339       10 Batch loss: 0.233754 Batch F1: 0.16666666666666666
Epoch:  339       11 Batch loss: 0.235726 Batch F1: 0.2
Epoch:  339       12 Batch loss: 0.203926 Batch F1: 0.125
Train Avg Loss  339: 0.222503

Train Avg F1  339: 0.29067921632201993

Val Avg Loss  339: 0.218054

Val Avg F1  339:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 340
--------------------------------------------------------------
Epoch:  340        1 Batch loss: 0.236064 Batch F1: 0.0
Epoch:  340        2 Batch loss: 0.274105 Batch F1: 0.07692307692307693
Epoch:  340        3 Batch loss: 0.206701 Batch F1: 0.0
Epoch:  340        4 Batch loss: 0.203010 Batch F1: 0.21052631578947367
Epoch:  340        5 Batch loss: 0.185688 Batch F1: 0.3333333333333333
Epoch:  340        6 Batch loss: 0.246448 Batch F1: 0.37499999999999994
Epoch:  340        7 Batch loss: 0.237594 Batch F1: 0.3333333333333333
Epoch:  340        8 Batch loss: 0.218676 Batch F1: 0.3870967741935483
Epoch:  340        9 Batch loss: 0.217259 Batch F1: 0.5833333333333334
Epoch:  340       10 Batch loss: 0.226326 Batch F1: 0.46153846153846156
Epoch:  340       11 Batch loss: 0.247498 Batch F1: 0.25
Epoch:  340       12 Batch loss: 0.177927 Batch F1: 0.14285714285714285
Train Avg Loss  340: 0.223108

Train Avg F1  340: 0.2628284809418086

Val Avg Loss  340: 0.219653

Val Avg F1  340:  0.26399331662489556

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 341
--------------------------------------------------------------
Epoch:  341        1 Batch loss: 0.225075 Batch F1: 0.5185185185185185
Epoch:  341        2 Batch loss: 0.214242 Batch F1: 0.2727272727272727
Epoch:  341        3 Batch loss: 0.232092 Batch F1: 0.16
Epoch:  341        4 Batch loss: 0.213226 Batch F1: 0.09523809523809523
Epoch:  341        5 Batch loss: 0.211386 Batch F1: 0.27272727272727276
Epoch:  341        6 Batch loss: 0.242153 Batch F1: 0.2608695652173913
Epoch:  341        7 Batch loss: 0.210445 Batch F1: 0.1818181818181818
Epoch:  341        8 Batch loss: 0.236477 Batch F1: 0.3448275862068965
Epoch:  341        9 Batch loss: 0.204516 Batch F1: 0.3
Epoch:  341       10 Batch loss: 0.238037 Batch F1: 0.1739130434782609
Epoch:  341       11 Batch loss: 0.227282 Batch F1: 0.09523809523809523
Epoch:  341       12 Batch loss: 0.212833 Batch F1: 0.31578947368421056
Train Avg Loss  341: 0.222314

Train Avg F1  341: 0.24930559207118297

Val Avg Loss  341: 0.218672

Val Avg F1  341:  0.25001616031027796

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 342
--------------------------------------------------------------
Epoch:  342        1 Batch loss: 0.269905 Batch F1: 0.4878048780487806
Epoch:  342        2 Batch loss: 0.222627 Batch F1: 0.3076923076923077
Epoch:  342        3 Batch loss: 0.214575 Batch F1: 0.21052631578947367
Epoch:  342        4 Batch loss: 0.220598 Batch F1: 0.28571428571428575
Epoch:  342        5 Batch loss: 0.197239 Batch F1: 0.4
Epoch:  342        6 Batch loss: 0.233502 Batch F1: 0.22222222222222224
Epoch:  342        7 Batch loss: 0.214928 Batch F1: 0.2
Epoch:  342        8 Batch loss: 0.202035 Batch F1: 0.2857142857142857
Epoch:  342        9 Batch loss: 0.206300 Batch F1: 0.23529411764705882
Epoch:  342       10 Batch loss: 0.189128 Batch F1: 0.0
Epoch:  342       11 Batch loss: 0.273078 Batch F1: 0.0
Epoch:  342       12 Batch loss: 0.235720 Batch F1: 0.0
Train Avg Loss  342: 0.223303

Train Avg F1  342: 0.21958070106903457

Val Avg Loss  342: 0.217519

Val Avg F1  342:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 343
--------------------------------------------------------------
Epoch:  343        1 Batch loss: 0.181863 Batch F1: 0.0
Epoch:  343        2 Batch loss: 0.247663 Batch F1: 0.0
Epoch:  343        3 Batch loss: 0.241851 Batch F1: 0.4864864864864865
Epoch:  343        4 Batch loss: 0.217236 Batch F1: 0.0
Epoch:  343        5 Batch loss: 0.219588 Batch F1: 0.37037037037037035
Epoch:  343        6 Batch loss: 0.203443 Batch F1: 0.0
Epoch:  343        7 Batch loss: 0.232843 Batch F1: 0.0
Epoch:  343        8 Batch loss: 0.188173 Batch F1: 0.0
Epoch:  343        9 Batch loss: 0.253394 Batch F1: 0.0
Epoch:  343       10 Batch loss: 0.230187 Batch F1: 0.0
Epoch:  343       11 Batch loss: 0.202190 Batch F1: 0.0
Epoch:  343       12 Batch loss: 0.280608 Batch F1: 0.0
Train Avg Loss  343: 0.224920

Train Avg F1  343: 0.07140473807140474

Val Avg Loss  343: 0.223027

Val Avg F1  343:  0.2522999222999223

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 344
--------------------------------------------------------------
Epoch:  344        1 Batch loss: 0.214992 Batch F1: 0.2857142857142857
Epoch:  344        2 Batch loss: 0.209025 Batch F1: 0.4210526315789474
Epoch:  344        3 Batch loss: 0.216820 Batch F1: 0.19047619047619047
Epoch:  344        4 Batch loss: 0.200608 Batch F1: 0.0
Epoch:  344        5 Batch loss: 0.225363 Batch F1: 0.0
Epoch:  344        6 Batch loss: 0.208287 Batch F1: 0.0
Epoch:  344        7 Batch loss: 0.267504 Batch F1: 0.0
Epoch:  344        8 Batch loss: 0.255631 Batch F1: 0.0
Epoch:  344        9 Batch loss: 0.252676 Batch F1: 0.2962962962962963
Epoch:  344       10 Batch loss: 0.236247 Batch F1: 0.631578947368421
Epoch:  344       11 Batch loss: 0.224106 Batch F1: 0.48484848484848486
Epoch:  344       12 Batch loss: 0.221263 Batch F1: 0.4
Train Avg Loss  344: 0.227710

Train Avg F1  344: 0.22583056969021878

Val Avg Loss  344: 0.226926

Val Avg F1  344:  0.35239841203800015

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 345
--------------------------------------------------------------
Epoch:  345        1 Batch loss: 0.234576 Batch F1: 0.3636363636363636
Epoch:  345        2 Batch loss: 0.241203 Batch F1: 0.27586206896551724
Epoch:  345        3 Batch loss: 0.217029 Batch F1: 0.31999999999999995
Epoch:  345        4 Batch loss: 0.219832 Batch F1: 0.0
Epoch:  345        5 Batch loss: 0.213665 Batch F1: 0.0
Epoch:  345        6 Batch loss: 0.239580 Batch F1: 0.0
Epoch:  345        7 Batch loss: 0.243646 Batch F1: 0.08695652173913042
Epoch:  345        8 Batch loss: 0.235815 Batch F1: 0.23999999999999996
Epoch:  345        9 Batch loss: 0.211444 Batch F1: 0.43478260869565216
Epoch:  345       10 Batch loss: 0.239271 Batch F1: 0.23076923076923075
Epoch:  345       11 Batch loss: 0.206367 Batch F1: 0.3
Epoch:  345       12 Batch loss: 0.180999 Batch F1: 0.33333333333333337
Train Avg Loss  345: 0.223619

Train Avg F1  345: 0.21544501059493562

Val Avg Loss  345: 0.217740

Val Avg F1  345:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 346
--------------------------------------------------------------
Epoch:  346        1 Batch loss: 0.265901 Batch F1: 0.0
Epoch:  346        2 Batch loss: 0.234003 Batch F1: 0.0
Epoch:  346        3 Batch loss: 0.227271 Batch F1: 0.0
Epoch:  346        4 Batch loss: 0.261736 Batch F1: 0.0
Epoch:  346        5 Batch loss: 0.229558 Batch F1: 0.23076923076923075
Epoch:  346        6 Batch loss: 0.212866 Batch F1: 0.2
Epoch:  346        7 Batch loss: 0.223529 Batch F1: 0.35714285714285715
Epoch:  346        8 Batch loss: 0.225103 Batch F1: 0.3636363636363636
Epoch:  346        9 Batch loss: 0.215262 Batch F1: 0.27272727272727276
Epoch:  346       10 Batch loss: 0.193797 Batch F1: 0.1111111111111111
Epoch:  346       11 Batch loss: 0.218747 Batch F1: 0.34782608695652173
Epoch:  346       12 Batch loss: 0.190490 Batch F1: 0.0
Train Avg Loss  346: 0.224855

Train Avg F1  346: 0.15693441019527976

Val Avg Loss  346: 0.217217

Val Avg F1  346:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 347
--------------------------------------------------------------
Epoch:  347        1 Batch loss: 0.216051 Batch F1: 0.0
Epoch:  347        2 Batch loss: 0.188268 Batch F1: 0.0
Epoch:  347        3 Batch loss: 0.228716 Batch F1: 0.0
Epoch:  347        4 Batch loss: 0.244763 Batch F1: 0.0
Epoch:  347        5 Batch loss: 0.220613 Batch F1: 0.1
Epoch:  347        6 Batch loss: 0.219530 Batch F1: 0.30769230769230765
Epoch:  347        7 Batch loss: 0.235663 Batch F1: 0.25
Epoch:  347        8 Batch loss: 0.229943 Batch F1: 0.39999999999999997
Epoch:  347        9 Batch loss: 0.219369 Batch F1: 0.0
Epoch:  347       10 Batch loss: 0.247673 Batch F1: 0.0
Epoch:  347       11 Batch loss: 0.217047 Batch F1: 0.0
Epoch:  347       12 Batch loss: 0.222266 Batch F1: 0.33333333333333337
Train Avg Loss  347: 0.224159

Train Avg F1  347: 0.11591880341880341

Val Avg Loss  347: 0.219169

Val Avg F1  347:  0.2670807453416149

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 348
--------------------------------------------------------------
Epoch:  348        1 Batch loss: 0.233822 Batch F1: 0.2857142857142857
Epoch:  348        2 Batch loss: 0.235068 Batch F1: 0.27586206896551724
Epoch:  348        3 Batch loss: 0.253127 Batch F1: 0.17391304347826086
Epoch:  348        4 Batch loss: 0.245930 Batch F1: 0.1739130434782609
Epoch:  348        5 Batch loss: 0.163656 Batch F1: 0.0
Epoch:  348        6 Batch loss: 0.209197 Batch F1: 0.0
Epoch:  348        7 Batch loss: 0.253125 Batch F1: 0.0
Epoch:  348        8 Batch loss: 0.259470 Batch F1: 0.0
Epoch:  348        9 Batch loss: 0.208971 Batch F1: 0.0
Epoch:  348       10 Batch loss: 0.226558 Batch F1: 0.09523809523809523
Epoch:  348       11 Batch loss: 0.192541 Batch F1: 0.0
Epoch:  348       12 Batch loss: 0.214925 Batch F1: 0.1
Train Avg Loss  348: 0.224699

Train Avg F1  348: 0.09205337807286833

Val Avg Loss  348: 0.218489

Val Avg F1  348:  0.04653679653679653

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 349
--------------------------------------------------------------
Epoch:  349        1 Batch loss: 0.252496 Batch F1: 0.08
Epoch:  349        2 Batch loss: 0.237888 Batch F1: 0.1739130434782609
Epoch:  349        3 Batch loss: 0.209234 Batch F1: 0.47619047619047616
Epoch:  349        4 Batch loss: 0.210457 Batch F1: 0.10526315789473684
Epoch:  349        5 Batch loss: 0.220237 Batch F1: 0.0
Epoch:  349        6 Batch loss: 0.202979 Batch F1: 0.0
Epoch:  349        7 Batch loss: 0.238905 Batch F1: 0.0
Epoch:  349        8 Batch loss: 0.232973 Batch F1: 0.2857142857142857
Epoch:  349        9 Batch loss: 0.197734 Batch F1: 0.23529411764705882
Epoch:  349       10 Batch loss: 0.221558 Batch F1: 0.25
Epoch:  349       11 Batch loss: 0.223344 Batch F1: 0.2857142857142857
Epoch:  349       12 Batch loss: 0.228618 Batch F1: 0.3
Train Avg Loss  349: 0.223035

Train Avg F1  349: 0.18267411388659202

Val Avg Loss  349: 0.219582

Val Avg F1  349:  0.2531958379784467

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 350
--------------------------------------------------------------
Epoch:  350        1 Batch loss: 0.203276 Batch F1: 0.2105263157894737
Epoch:  350        2 Batch loss: 0.184734 Batch F1: 0.5217391304347827
Epoch:  350        3 Batch loss: 0.262583 Batch F1: 0.2857142857142857
Epoch:  350        4 Batch loss: 0.212363 Batch F1: 0.19047619047619047
Epoch:  350        5 Batch loss: 0.200674 Batch F1: 0.4615384615384615
Epoch:  350        6 Batch loss: 0.226800 Batch F1: 0.35714285714285715
Epoch:  350        7 Batch loss: 0.223701 Batch F1: 0.2962962962962963
Epoch:  350        8 Batch loss: 0.219096 Batch F1: 0.41379310344827586
Epoch:  350        9 Batch loss: 0.229808 Batch F1: 0.30769230769230765
Epoch:  350       10 Batch loss: 0.280789 Batch F1: 0.3225806451612903
Epoch:  350       11 Batch loss: 0.213438 Batch F1: 0.34782608695652173
Epoch:  350       12 Batch loss: 0.211451 Batch F1: 0.3809523809523809
Train Avg Loss  350: 0.222393

Train Avg F1  350: 0.3413565051335936

Val Avg Loss  350: 0.218540

Val Avg F1  350:  0.25532777567260323

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 351
--------------------------------------------------------------
Epoch:  351        1 Batch loss: 0.222162 Batch F1: 0.3846153846153846
Epoch:  351        2 Batch loss: 0.208313 Batch F1: 0.36363636363636365
Epoch:  351        3 Batch loss: 0.211881 Batch F1: 0.34782608695652173
Epoch:  351        4 Batch loss: 0.211067 Batch F1: 0.3333333333333333
Epoch:  351        5 Batch loss: 0.189012 Batch F1: 0.11764705882352941
Epoch:  351        6 Batch loss: 0.233179 Batch F1: 0.0
Epoch:  351        7 Batch loss: 0.204788 Batch F1: 0.27272727272727276
Epoch:  351        8 Batch loss: 0.216768 Batch F1: 0.2608695652173913
Epoch:  351        9 Batch loss: 0.207173 Batch F1: 0.46153846153846156
Epoch:  351       10 Batch loss: 0.272334 Batch F1: 0.0
Epoch:  351       11 Batch loss: 0.246817 Batch F1: 0.09523809523809525
Epoch:  351       12 Batch loss: 0.243797 Batch F1: 0.23999999999999996
Train Avg Loss  351: 0.222274

Train Avg F1  351: 0.2397859685071961

Val Avg Loss  351: 0.220327

Val Avg F1  351:  0.22399774138904577

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 352
--------------------------------------------------------------
Epoch:  352        1 Batch loss: 0.220152 Batch F1: 0.2608695652173913
Epoch:  352        2 Batch loss: 0.254939 Batch F1: 0.4864864864864865
Epoch:  352        3 Batch loss: 0.236290 Batch F1: 0.24000000000000005
Epoch:  352        4 Batch loss: 0.228375 Batch F1: 0.2962962962962963
Epoch:  352        5 Batch loss: 0.206099 Batch F1: 0.21052631578947367
Epoch:  352        6 Batch loss: 0.236251 Batch F1: 0.0909090909090909
Epoch:  352        7 Batch loss: 0.211028 Batch F1: 0.0
Epoch:  352        8 Batch loss: 0.225623 Batch F1: 0.0
Epoch:  352        9 Batch loss: 0.199455 Batch F1: 0.0
Epoch:  352       10 Batch loss: 0.224186 Batch F1: 0.0
Epoch:  352       11 Batch loss: 0.220799 Batch F1: 0.0
Epoch:  352       12 Batch loss: 0.242627 Batch F1: 0.0
Train Avg Loss  352: 0.225485

Train Avg F1  352: 0.1320906462248949

Val Avg Loss  352: 0.218933

Val Avg F1  352:  0.12896825396825395

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 353
--------------------------------------------------------------
Epoch:  353        1 Batch loss: 0.213652 Batch F1: 0.1818181818181818
Epoch:  353        2 Batch loss: 0.238114 Batch F1: 0.23076923076923075
Epoch:  353        3 Batch loss: 0.218812 Batch F1: 0.32
Epoch:  353        4 Batch loss: 0.208821 Batch F1: 0.4615384615384615
Epoch:  353        5 Batch loss: 0.218424 Batch F1: 0.19999999999999998
Epoch:  353        6 Batch loss: 0.217222 Batch F1: 0.3636363636363636
Epoch:  353        7 Batch loss: 0.239193 Batch F1: 0.41379310344827586
Epoch:  353        8 Batch loss: 0.225439 Batch F1: 0.1818181818181818
Epoch:  353        9 Batch loss: 0.256946 Batch F1: 0.29629629629629634
Epoch:  353       10 Batch loss: 0.215301 Batch F1: 0.1818181818181818
Epoch:  353       11 Batch loss: 0.213016 Batch F1: 0.41379310344827586
Epoch:  353       12 Batch loss: 0.197219 Batch F1: 0.4761904761904762
Train Avg Loss  353: 0.221846

Train Avg F1  353: 0.3101226317318271

Val Avg Loss  353: 0.219365

Val Avg F1  353:  0.24374039938556066

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 354
--------------------------------------------------------------
Epoch:  354        1 Batch loss: 0.232415 Batch F1: 0.3448275862068966
Epoch:  354        2 Batch loss: 0.232038 Batch F1: 0.08
Epoch:  354        3 Batch loss: 0.224257 Batch F1: 0.3448275862068966
Epoch:  354        4 Batch loss: 0.187532 Batch F1: 0.5833333333333334
Epoch:  354        5 Batch loss: 0.209228 Batch F1: 0.5
Epoch:  354        6 Batch loss: 0.236943 Batch F1: 0.25
Epoch:  354        7 Batch loss: 0.208317 Batch F1: 0.3478260869565218
Epoch:  354        8 Batch loss: 0.232704 Batch F1: 0.24
Epoch:  354        9 Batch loss: 0.244205 Batch F1: 0.09090909090909091
Epoch:  354       10 Batch loss: 0.224935 Batch F1: 0.1904761904761905
Epoch:  354       11 Batch loss: 0.238290 Batch F1: 0.08695652173913043
Epoch:  354       12 Batch loss: 0.192543 Batch F1: 0.0
Train Avg Loss  354: 0.221951

Train Avg F1  354: 0.25492969965233836

Val Avg Loss  354: 0.217830

Val Avg F1  354:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 355
--------------------------------------------------------------
Epoch:  355        1 Batch loss: 0.278092 Batch F1: 0.0
Epoch:  355        2 Batch loss: 0.203200 Batch F1: 0.0
Epoch:  355        3 Batch loss: 0.216492 Batch F1: 0.0
Epoch:  355        4 Batch loss: 0.216679 Batch F1: 0.0
Epoch:  355        5 Batch loss: 0.261879 Batch F1: 0.0
Epoch:  355        6 Batch loss: 0.215179 Batch F1: 0.0
Epoch:  355        7 Batch loss: 0.205624 Batch F1: 0.0
Epoch:  355        8 Batch loss: 0.217887 Batch F1: 0.0
Epoch:  355        9 Batch loss: 0.221454 Batch F1: 0.0
Epoch:  355       10 Batch loss: 0.241902 Batch F1: 0.07999999999999999
Epoch:  355       11 Batch loss: 0.202705 Batch F1: 0.0
Epoch:  355       12 Batch loss: 0.194702 Batch F1: 0.13333333333333333
Train Avg Loss  355: 0.222983

Train Avg F1  355: 0.017777777777777778

Val Avg Loss  355: 0.218691

Val Avg F1  355:  0.26107769423558896

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 356
--------------------------------------------------------------
Epoch:  356        1 Batch loss: 0.249333 Batch F1: 0.16
Epoch:  356        2 Batch loss: 0.200243 Batch F1: 0.5
Epoch:  356        3 Batch loss: 0.198363 Batch F1: 0.36363636363636365
Epoch:  356        4 Batch loss: 0.232408 Batch F1: 0.42857142857142855
Epoch:  356        5 Batch loss: 0.206535 Batch F1: 0.32
Epoch:  356        6 Batch loss: 0.253416 Batch F1: 0.06896551724137931
Epoch:  356        7 Batch loss: 0.183170 Batch F1: 0.5217391304347825
Epoch:  356        8 Batch loss: 0.276258 Batch F1: 0.2702702702702703
Epoch:  356        9 Batch loss: 0.214140 Batch F1: 0.3
Epoch:  356       10 Batch loss: 0.191140 Batch F1: 0.4761904761904762
Epoch:  356       11 Batch loss: 0.232897 Batch F1: 0.25
Epoch:  356       12 Batch loss: 0.235974 Batch F1: 0.26086956521739124
Train Avg Loss  356: 0.222823

Train Avg F1  356: 0.3266868959635076

Val Avg Loss  356: 0.218388

Val Avg F1  356:  0.26807261366084895

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 357
--------------------------------------------------------------
Epoch:  357        1 Batch loss: 0.218782 Batch F1: 0.2608695652173913
Epoch:  357        2 Batch loss: 0.220114 Batch F1: 0.4166666666666667
Epoch:  357        3 Batch loss: 0.247452 Batch F1: 0.21428571428571427
Epoch:  357        4 Batch loss: 0.219596 Batch F1: 0.28571428571428575
Epoch:  357        5 Batch loss: 0.221374 Batch F1: 0.5
Epoch:  357        6 Batch loss: 0.252557 Batch F1: 0.3333333333333333
Epoch:  357        7 Batch loss: 0.183711 Batch F1: 0.25000000000000006
Epoch:  357        8 Batch loss: 0.208408 Batch F1: 0.2
Epoch:  357        9 Batch loss: 0.214815 Batch F1: 0.5333333333333333
Epoch:  357       10 Batch loss: 0.244959 Batch F1: 0.29629629629629634
Epoch:  357       11 Batch loss: 0.224895 Batch F1: 0.16
Epoch:  357       12 Batch loss: 0.215568 Batch F1: 0.11764705882352941
Train Avg Loss  357: 0.222686

Train Avg F1  357: 0.2973455211392126

Val Avg Loss  357: 0.219341

Val Avg F1  357:  0.2457750582750583

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 358
--------------------------------------------------------------
Epoch:  358        1 Batch loss: 0.204113 Batch F1: 0.2
Epoch:  358        2 Batch loss: 0.238489 Batch F1: 0.20689655172413793
Epoch:  358        3 Batch loss: 0.248697 Batch F1: 0.4
Epoch:  358        4 Batch loss: 0.200189 Batch F1: 0.28571428571428575
Epoch:  358        5 Batch loss: 0.237782 Batch F1: 0.43749999999999994
Epoch:  358        6 Batch loss: 0.283578 Batch F1: 0.37837837837837834
Epoch:  358        7 Batch loss: 0.223781 Batch F1: 0.24
Epoch:  358        8 Batch loss: 0.222072 Batch F1: 0.39999999999999997
Epoch:  358        9 Batch loss: 0.190222 Batch F1: 0.1111111111111111
Epoch:  358       10 Batch loss: 0.221773 Batch F1: 0.0
Epoch:  358       11 Batch loss: 0.206245 Batch F1: 0.3636363636363636
Epoch:  358       12 Batch loss: 0.173523 Batch F1: 0.42857142857142855
Train Avg Loss  358: 0.220872

Train Avg F1  358: 0.2876506765946421

Val Avg Loss  358: 0.218183

Val Avg F1  358:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 359
--------------------------------------------------------------
Epoch:  359        1 Batch loss: 0.226387 Batch F1: 0.0
Epoch:  359        2 Batch loss: 0.217660 Batch F1: 0.0
Epoch:  359        3 Batch loss: 0.198936 Batch F1: 0.45454545454545453
Epoch:  359        4 Batch loss: 0.231821 Batch F1: 0.37037037037037035
Epoch:  359        5 Batch loss: 0.237440 Batch F1: 0.42424242424242425
Epoch:  359        6 Batch loss: 0.228678 Batch F1: 0.28571428571428575
Epoch:  359        7 Batch loss: 0.261932 Batch F1: 0.2580645161290322
Epoch:  359        8 Batch loss: 0.223284 Batch F1: 0.2608695652173913
Epoch:  359        9 Batch loss: 0.251290 Batch F1: 0.27586206896551724
Epoch:  359       10 Batch loss: 0.221471 Batch F1: 0.0
Epoch:  359       11 Batch loss: 0.216632 Batch F1: 0.0
Epoch:  359       12 Batch loss: 0.174115 Batch F1: 0.0
Train Avg Loss  359: 0.224137

Train Avg F1  359: 0.1941390570987063

Val Avg Loss  359: 0.219107

Val Avg F1  359:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 360
--------------------------------------------------------------
Epoch:  360        1 Batch loss: 0.191979 Batch F1: 0.0
Epoch:  360        2 Batch loss: 0.255046 Batch F1: 0.0
Epoch:  360        3 Batch loss: 0.235606 Batch F1: 0.0
Epoch:  360        4 Batch loss: 0.205620 Batch F1: 0.0
Epoch:  360        5 Batch loss: 0.206446 Batch F1: 0.3
Epoch:  360        6 Batch loss: 0.216472 Batch F1: 0.3846153846153846
Epoch:  360        7 Batch loss: 0.189038 Batch F1: 0.25
Epoch:  360        8 Batch loss: 0.238097 Batch F1: 0.16666666666666666
Epoch:  360        9 Batch loss: 0.237924 Batch F1: 0.0
Epoch:  360       10 Batch loss: 0.250152 Batch F1: 0.0
Epoch:  360       11 Batch loss: 0.231594 Batch F1: 0.0
Epoch:  360       12 Batch loss: 0.268249 Batch F1: 0.0
Train Avg Loss  360: 0.227185

Train Avg F1  360: 0.09177350427350428

Val Avg Loss  360: 0.218273

Val Avg F1  360:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 361
--------------------------------------------------------------
Epoch:  361        1 Batch loss: 0.246486 Batch F1: 0.08695652173913045
Epoch:  361        2 Batch loss: 0.199964 Batch F1: 0.23529411764705882
Epoch:  361        3 Batch loss: 0.229765 Batch F1: 0.3636363636363636
Epoch:  361        4 Batch loss: 0.204998 Batch F1: 0.36363636363636365
Epoch:  361        5 Batch loss: 0.197322 Batch F1: 0.2222222222222222
Epoch:  361        6 Batch loss: 0.219781 Batch F1: 0.08695652173913045
Epoch:  361        7 Batch loss: 0.241561 Batch F1: 0.16666666666666669
Epoch:  361        8 Batch loss: 0.244471 Batch F1: 0.375
Epoch:  361        9 Batch loss: 0.233512 Batch F1: 0.23076923076923075
Epoch:  361       10 Batch loss: 0.206710 Batch F1: 0.5
Epoch:  361       11 Batch loss: 0.217999 Batch F1: 0.2
Epoch:  361       12 Batch loss: 0.250172 Batch F1: 0.25
Train Avg Loss  361: 0.224395

Train Avg F1  361: 0.25676150067134723

Val Avg Loss  361: 0.218982

Val Avg F1  361:  0.08522727272727272

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 362
--------------------------------------------------------------
Epoch:  362        1 Batch loss: 0.227424 Batch F1: 0.09523809523809525
Epoch:  362        2 Batch loss: 0.185681 Batch F1: 0.0
Epoch:  362        3 Batch loss: 0.236688 Batch F1: 0.0
Epoch:  362        4 Batch loss: 0.215148 Batch F1: 0.0
Epoch:  362        5 Batch loss: 0.182572 Batch F1: 0.0
Epoch:  362        6 Batch loss: 0.218657 Batch F1: 0.0
Epoch:  362        7 Batch loss: 0.254420 Batch F1: 0.0
Epoch:  362        8 Batch loss: 0.236739 Batch F1: 0.0
Epoch:  362        9 Batch loss: 0.264335 Batch F1: 0.07407407407407407
Epoch:  362       10 Batch loss: 0.231568 Batch F1: 0.37037037037037035
Epoch:  362       11 Batch loss: 0.201199 Batch F1: 0.33333333333333337
Epoch:  362       12 Batch loss: 0.234788 Batch F1: 0.1
Train Avg Loss  362: 0.224102

Train Avg F1  362: 0.08108465608465608

Val Avg Loss  362: 0.219021

Val Avg F1  362:  0.2631752305665349

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 363
--------------------------------------------------------------
Epoch:  363        1 Batch loss: 0.230623 Batch F1: 0.42857142857142855
Epoch:  363        2 Batch loss: 0.191386 Batch F1: 0.23529411764705882
Epoch:  363        3 Batch loss: 0.193118 Batch F1: 0.10526315789473684
Epoch:  363        4 Batch loss: 0.226332 Batch F1: 0.0
Epoch:  363        5 Batch loss: 0.208468 Batch F1: 0.0
Epoch:  363        6 Batch loss: 0.244307 Batch F1: 0.0
Epoch:  363        7 Batch loss: 0.214272 Batch F1: 0.0
Epoch:  363        8 Batch loss: 0.215928 Batch F1: 0.0
Epoch:  363        9 Batch loss: 0.217865 Batch F1: 0.0
Epoch:  363       10 Batch loss: 0.243019 Batch F1: 0.0
Epoch:  363       11 Batch loss: 0.259197 Batch F1: 0.0
Epoch:  363       12 Batch loss: 0.237050 Batch F1: 0.10526315789473684
Train Avg Loss  363: 0.223464

Train Avg F1  363: 0.07286598850066342

Val Avg Loss  363: 0.220698

Val Avg F1  363:  0.3092546820995097

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 364
--------------------------------------------------------------
Epoch:  364        1 Batch loss: 0.190279 Batch F1: 0.41666666666666663
Epoch:  364        2 Batch loss: 0.213040 Batch F1: 0.5384615384615385
Epoch:  364        3 Batch loss: 0.207589 Batch F1: 0.5833333333333334
Epoch:  364        4 Batch loss: 0.232434 Batch F1: 0.24
Epoch:  364        5 Batch loss: 0.210656 Batch F1: 0.32
Epoch:  364        6 Batch loss: 0.214058 Batch F1: 0.18181818181818182
Epoch:  364        7 Batch loss: 0.255358 Batch F1: 0.0
Epoch:  364        8 Batch loss: 0.233896 Batch F1: 0.0
Epoch:  364        9 Batch loss: 0.239194 Batch F1: 0.26666666666666666
Epoch:  364       10 Batch loss: 0.223163 Batch F1: 0.3846153846153846
Epoch:  364       11 Batch loss: 0.224620 Batch F1: 0.4827586206896552
Epoch:  364       12 Batch loss: 0.240840 Batch F1: 0.4444444444444444
Train Avg Loss  364: 0.223761

Train Avg F1  364: 0.3215637363913226

Val Avg Loss  364: 0.223544

Val Avg F1  364:  0.33045999893825984

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 365
--------------------------------------------------------------
Epoch:  365        1 Batch loss: 0.202734 Batch F1: 0.5454545454545455
Epoch:  365        2 Batch loss: 0.219624 Batch F1: 0.25
Epoch:  365        3 Batch loss: 0.214840 Batch F1: 0.4166666666666667
Epoch:  365        4 Batch loss: 0.196337 Batch F1: 0.28571428571428575
Epoch:  365        5 Batch loss: 0.214677 Batch F1: 0.34782608695652173
Epoch:  365        6 Batch loss: 0.193459 Batch F1: 0.2222222222222222
Epoch:  365        7 Batch loss: 0.235131 Batch F1: 0.0
Epoch:  365        8 Batch loss: 0.215792 Batch F1: 0.0
Epoch:  365        9 Batch loss: 0.246273 Batch F1: 0.3870967741935483
Epoch:  365       10 Batch loss: 0.224874 Batch F1: 0.2962962962962963
Epoch:  365       11 Batch loss: 0.252752 Batch F1: 0.3529411764705882
Epoch:  365       12 Batch loss: 0.270854 Batch F1: 0.2727272727272727
Train Avg Loss  365: 0.223946

Train Avg F1  365: 0.28141211055849563

Val Avg Loss  365: 0.222266

Val Avg F1  365:  0.3148484848484848

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 366
--------------------------------------------------------------
Epoch:  366        1 Batch loss: 0.200088 Batch F1: 0.5
Epoch:  366        2 Batch loss: 0.211762 Batch F1: 0.33333333333333337
Epoch:  366        3 Batch loss: 0.188270 Batch F1: 0.45454545454545453
Epoch:  366        4 Batch loss: 0.209057 Batch F1: 0.1
Epoch:  366        5 Batch loss: 0.194690 Batch F1: 0.0
Epoch:  366        6 Batch loss: 0.260811 Batch F1: 0.0
Epoch:  366        7 Batch loss: 0.252117 Batch F1: 0.0
Epoch:  366        8 Batch loss: 0.221926 Batch F1: 0.0
Epoch:  366        9 Batch loss: 0.252294 Batch F1: 0.0
Epoch:  366       10 Batch loss: 0.241764 Batch F1: 0.0
Epoch:  366       11 Batch loss: 0.244889 Batch F1: 0.0
Epoch:  366       12 Batch loss: 0.228799 Batch F1: 0.19999999999999998
Train Avg Loss  366: 0.225539

Train Avg F1  366: 0.13232323232323231

Val Avg Loss  366: 0.219174

Val Avg F1  366:  0.2379322888150543

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 367
--------------------------------------------------------------
Epoch:  367        1 Batch loss: 0.222301 Batch F1: 0.27272727272727276
Epoch:  367        2 Batch loss: 0.205800 Batch F1: 0.3846153846153846
Epoch:  367        3 Batch loss: 0.238530 Batch F1: 0.24
Epoch:  367        4 Batch loss: 0.205601 Batch F1: 0.5333333333333333
Epoch:  367        5 Batch loss: 0.224823 Batch F1: 0.35714285714285715
Epoch:  367        6 Batch loss: 0.233125 Batch F1: 0.27586206896551724
Epoch:  367        7 Batch loss: 0.199196 Batch F1: 0.4545454545454545
Epoch:  367        8 Batch loss: 0.237518 Batch F1: 0.3870967741935484
Epoch:  367        9 Batch loss: 0.218001 Batch F1: 0.2857142857142857
Epoch:  367       10 Batch loss: 0.231349 Batch F1: 0.0
Epoch:  367       11 Batch loss: 0.226200 Batch F1: 0.1111111111111111
Epoch:  367       12 Batch loss: 0.233573 Batch F1: 0.0
Train Avg Loss  367: 0.223001

Train Avg F1  367: 0.2751790451957304

Val Avg Loss  367: 0.217525

Val Avg F1  367:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 368
--------------------------------------------------------------
Epoch:  368        1 Batch loss: 0.250433 Batch F1: 0.0
Epoch:  368        2 Batch loss: 0.272319 Batch F1: 0.0
Epoch:  368        3 Batch loss: 0.217022 Batch F1: 0.0
Epoch:  368        4 Batch loss: 0.182651 Batch F1: 0.5
Epoch:  368        5 Batch loss: 0.222203 Batch F1: 0.0
Epoch:  368        6 Batch loss: 0.220338 Batch F1: 0.42857142857142855
Epoch:  368        7 Batch loss: 0.197990 Batch F1: 0.4166666666666667
Epoch:  368        8 Batch loss: 0.238949 Batch F1: 0.37499999999999994
Epoch:  368        9 Batch loss: 0.214442 Batch F1: 0.4
Epoch:  368       10 Batch loss: 0.215614 Batch F1: 0.41379310344827586
Epoch:  368       11 Batch loss: 0.219408 Batch F1: 0.2
Epoch:  368       12 Batch loss: 0.226994 Batch F1: 0.2857142857142857
Train Avg Loss  368: 0.223197

Train Avg F1  368: 0.2516454570333881

Val Avg Loss  368: 0.219721

Val Avg F1  368:  0.25902116402116404

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 369
--------------------------------------------------------------
Epoch:  369        1 Batch loss: 0.222359 Batch F1: 0.39999999999999997
Epoch:  369        2 Batch loss: 0.212167 Batch F1: 0.0
Epoch:  369        3 Batch loss: 0.230037 Batch F1: 0.09523809523809523
Epoch:  369        4 Batch loss: 0.241773 Batch F1: 0.0
Epoch:  369        5 Batch loss: 0.193310 Batch F1: 0.0
Epoch:  369        6 Batch loss: 0.201309 Batch F1: 0.0
Epoch:  369        7 Batch loss: 0.223118 Batch F1: 0.0
Epoch:  369        8 Batch loss: 0.229718 Batch F1: 0.0
Epoch:  369        9 Batch loss: 0.218935 Batch F1: 0.0
Epoch:  369       10 Batch loss: 0.235238 Batch F1: 0.0
Epoch:  369       11 Batch loss: 0.256777 Batch F1: 0.3225806451612903
Epoch:  369       12 Batch loss: 0.205389 Batch F1: 0.56
Train Avg Loss  369: 0.222511

Train Avg F1  369: 0.11481822836661547

Val Avg Loss  369: 0.223473

Val Avg F1  369:  0.3289353657095592

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 370
--------------------------------------------------------------
Epoch:  370        1 Batch loss: 0.215110 Batch F1: 0.4615384615384615
Epoch:  370        2 Batch loss: 0.219538 Batch F1: 0.26086956521739135
Epoch:  370        3 Batch loss: 0.278667 Batch F1: 0.1875
Epoch:  370        4 Batch loss: 0.255957 Batch F1: 0.3125
Epoch:  370        5 Batch loss: 0.212514 Batch F1: 0.5
Epoch:  370        6 Batch loss: 0.232729 Batch F1: 0.29629629629629634
Epoch:  370        7 Batch loss: 0.221668 Batch F1: 0.4827586206896552
Epoch:  370        8 Batch loss: 0.225438 Batch F1: 0.4
Epoch:  370        9 Batch loss: 0.213897 Batch F1: 0.5806451612903226
Epoch:  370       10 Batch loss: 0.209778 Batch F1: 0.2727272727272727
Epoch:  370       11 Batch loss: 0.210087 Batch F1: 0.27272727272727276
Epoch:  370       12 Batch loss: 0.197019 Batch F1: 0.45454545454545453
Train Avg Loss  370: 0.224367

Train Avg F1  370: 0.3735090087526772

Val Avg Loss  370: 0.218562

Val Avg F1  370:  0.2427104899930987

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 371
--------------------------------------------------------------
Epoch:  371        1 Batch loss: 0.185192 Batch F1: 0.47619047619047616
Epoch:  371        2 Batch loss: 0.221520 Batch F1: 0.0
Epoch:  371        3 Batch loss: 0.196775 Batch F1: 0.125
Epoch:  371        4 Batch loss: 0.233905 Batch F1: 0.0
Epoch:  371        5 Batch loss: 0.262110 Batch F1: 0.0
Epoch:  371        6 Batch loss: 0.248364 Batch F1: 0.0909090909090909
Epoch:  371        7 Batch loss: 0.208032 Batch F1: 0.0
Epoch:  371        8 Batch loss: 0.212693 Batch F1: 0.0
Epoch:  371        9 Batch loss: 0.229041 Batch F1: 0.4666666666666666
Epoch:  371       10 Batch loss: 0.252750 Batch F1: 0.20689655172413796
Epoch:  371       11 Batch loss: 0.223798 Batch F1: 0.25
Epoch:  371       12 Batch loss: 0.206037 Batch F1: 0.39999999999999997
Train Avg Loss  371: 0.223351

Train Avg F1  371: 0.1679718987908643

Val Avg Loss  371: 0.219841

Val Avg F1  371:  0.25441919191919193

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 372
--------------------------------------------------------------
Epoch:  372        1 Batch loss: 0.198287 Batch F1: 0.125
Epoch:  372        2 Batch loss: 0.233572 Batch F1: 0.17391304347826086
Epoch:  372        3 Batch loss: 0.228558 Batch F1: 0.2727272727272727
Epoch:  372        4 Batch loss: 0.205303 Batch F1: 0.0
Epoch:  372        5 Batch loss: 0.179186 Batch F1: 0.0
Epoch:  372        6 Batch loss: 0.273734 Batch F1: 0.0
Epoch:  372        7 Batch loss: 0.238962 Batch F1: 0.0
Epoch:  372        8 Batch loss: 0.233251 Batch F1: 0.0
Epoch:  372        9 Batch loss: 0.222042 Batch F1: 0.5
Epoch:  372       10 Batch loss: 0.210891 Batch F1: 0.5384615384615384
Epoch:  372       11 Batch loss: 0.246387 Batch F1: 0.3783783783783784
Epoch:  372       12 Batch loss: 0.206154 Batch F1: 0.13333333333333333
Train Avg Loss  372: 0.223027

Train Avg F1  372: 0.17681779719823199

Val Avg Loss  372: 0.220014

Val Avg F1  372:  0.25119565217391304

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 373
--------------------------------------------------------------
Epoch:  373        1 Batch loss: 0.230166 Batch F1: 0.4
Epoch:  373        2 Batch loss: 0.199565 Batch F1: 0.21052631578947364
Epoch:  373        3 Batch loss: 0.192109 Batch F1: 0.4347826086956522
Epoch:  373        4 Batch loss: 0.232984 Batch F1: 0.3333333333333333
Epoch:  373        5 Batch loss: 0.193153 Batch F1: 0.3809523809523809
Epoch:  373        6 Batch loss: 0.212877 Batch F1: 0.2857142857142857
Epoch:  373        7 Batch loss: 0.230783 Batch F1: 0.25
Epoch:  373        8 Batch loss: 0.214822 Batch F1: 0.5
Epoch:  373        9 Batch loss: 0.224332 Batch F1: 0.3846153846153846
Epoch:  373       10 Batch loss: 0.225836 Batch F1: 0.31999999999999995
Epoch:  373       11 Batch loss: 0.291211 Batch F1: 0.13333333333333333
Epoch:  373       12 Batch loss: 0.218442 Batch F1: 0.2727272727272727
Train Avg Loss  373: 0.222190

Train Avg F1  373: 0.325498742930093

Val Avg Loss  373: 0.217453

Val Avg F1  373:  0.26517273576097106

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 374
--------------------------------------------------------------
Epoch:  374        1 Batch loss: 0.199415 Batch F1: 0.3636363636363636
Epoch:  374        2 Batch loss: 0.230134 Batch F1: 0.18181818181818182
Epoch:  374        3 Batch loss: 0.188737 Batch F1: 0.23529411764705882
Epoch:  374        4 Batch loss: 0.217185 Batch F1: 0.39999999999999997
Epoch:  374        5 Batch loss: 0.215575 Batch F1: 0.19047619047619047
Epoch:  374        6 Batch loss: 0.239985 Batch F1: 0.4705882352941176
Epoch:  374        7 Batch loss: 0.261107 Batch F1: 0.25806451612903225
Epoch:  374        8 Batch loss: 0.229556 Batch F1: 0.1818181818181818
Epoch:  374        9 Batch loss: 0.233734 Batch F1: 0.42424242424242425
Epoch:  374       10 Batch loss: 0.221445 Batch F1: 0.4285714285714285
Epoch:  374       11 Batch loss: 0.209231 Batch F1: 0.39999999999999997
Epoch:  374       12 Batch loss: 0.224229 Batch F1: 0.2222222222222222
Train Avg Loss  374: 0.222528

Train Avg F1  374: 0.31306098848793346

Val Avg Loss  374: 0.219564

Val Avg F1  374:  0.2670355731225297

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 375
--------------------------------------------------------------
Epoch:  375        1 Batch loss: 0.216014 Batch F1: 0.09523809523809523
Epoch:  375        2 Batch loss: 0.169080 Batch F1: 0.0
Epoch:  375        3 Batch loss: 0.204951 Batch F1: 0.125
Epoch:  375        4 Batch loss: 0.245770 Batch F1: 0.0
Epoch:  375        5 Batch loss: 0.233220 Batch F1: 0.0
Epoch:  375        6 Batch loss: 0.200498 Batch F1: 0.0
Epoch:  375        7 Batch loss: 0.279712 Batch F1: 0.07999999999999999
Epoch:  375        8 Batch loss: 0.207907 Batch F1: 0.1111111111111111
Epoch:  375        9 Batch loss: 0.218935 Batch F1: 0.4347826086956522
Epoch:  375       10 Batch loss: 0.233783 Batch F1: 0.23076923076923075
Epoch:  375       11 Batch loss: 0.242140 Batch F1: 0.411764705882353
Epoch:  375       12 Batch loss: 0.227388 Batch F1: 0.10526315789473684
Train Avg Loss  375: 0.223283

Train Avg F1  375: 0.13282740913259827

Val Avg Loss  375: 0.219598

Val Avg F1  375:  0.25887528924613323

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 376
--------------------------------------------------------------
Epoch:  376        1 Batch loss: 0.242615 Batch F1: 0.2608695652173913
Epoch:  376        2 Batch loss: 0.188968 Batch F1: 0.3157894736842105
Epoch:  376        3 Batch loss: 0.264202 Batch F1: 0.0
Epoch:  376        4 Batch loss: 0.205763 Batch F1: 0.0
Epoch:  376        5 Batch loss: 0.233074 Batch F1: 0.0
Epoch:  376        6 Batch loss: 0.214280 Batch F1: 0.0
Epoch:  376        7 Batch loss: 0.228034 Batch F1: 0.2222222222222222
Epoch:  376        8 Batch loss: 0.230143 Batch F1: 0.3076923076923077
Epoch:  376        9 Batch loss: 0.235143 Batch F1: 0.35714285714285715
Epoch:  376       10 Batch loss: 0.201741 Batch F1: 0.4166666666666667
Epoch:  376       11 Batch loss: 0.219427 Batch F1: 0.3333333333333333
Epoch:  376       12 Batch loss: 0.205139 Batch F1: 0.14285714285714288
Train Avg Loss  376: 0.222377

Train Avg F1  376: 0.19638113073467764

Val Avg Loss  376: 0.219834

Val Avg F1  376:  0.23878205128205127

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 377
--------------------------------------------------------------
Epoch:  377        1 Batch loss: 0.204056 Batch F1: 0.2608695652173913
Epoch:  377        2 Batch loss: 0.218898 Batch F1: 0.17391304347826086
Epoch:  377        3 Batch loss: 0.267663 Batch F1: 0.25806451612903225
Epoch:  377        4 Batch loss: 0.232805 Batch F1: 0.22222222222222218
Epoch:  377        5 Batch loss: 0.234778 Batch F1: 0.27586206896551724
Epoch:  377        6 Batch loss: 0.177791 Batch F1: 0.4761904761904762
Epoch:  377        7 Batch loss: 0.222758 Batch F1: 0.3478260869565218
Epoch:  377        8 Batch loss: 0.198674 Batch F1: 0.5217391304347826
Epoch:  377        9 Batch loss: 0.239068 Batch F1: 0.0
Epoch:  377       10 Batch loss: 0.222698 Batch F1: 0.32
Epoch:  377       11 Batch loss: 0.213700 Batch F1: 0.46153846153846156
Epoch:  377       12 Batch loss: 0.235513 Batch F1: 0.27272727272727276
Train Avg Loss  377: 0.222367

Train Avg F1  377: 0.29924607032166156

Val Avg Loss  377: 0.218734

Val Avg F1  377:  0.25843274372686137

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 378
--------------------------------------------------------------
Epoch:  378        1 Batch loss: 0.222281 Batch F1: 0.36363636363636365
Epoch:  378        2 Batch loss: 0.217316 Batch F1: 0.3478260869565218
Epoch:  378        3 Batch loss: 0.227359 Batch F1: 0.3333333333333333
Epoch:  378        4 Batch loss: 0.198615 Batch F1: 0.38095238095238093
Epoch:  378        5 Batch loss: 0.233061 Batch F1: 0.2608695652173913
Epoch:  378        6 Batch loss: 0.226324 Batch F1: 0.32
Epoch:  378        7 Batch loss: 0.194748 Batch F1: 0.19047619047619047
Epoch:  378        8 Batch loss: 0.235684 Batch F1: 0.3076923076923077
Epoch:  378        9 Batch loss: 0.204171 Batch F1: 0.0
Epoch:  378       10 Batch loss: 0.247452 Batch F1: 0.4444444444444444
Epoch:  378       11 Batch loss: 0.230514 Batch F1: 0.32
Epoch:  378       12 Batch loss: 0.226560 Batch F1: 0.46153846153846156
Train Avg Loss  378: 0.222007

Train Avg F1  378: 0.31089742785394964

Val Avg Loss  378: 0.219109

Val Avg F1  378:  0.24366972896384664

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 379
--------------------------------------------------------------
Epoch:  379        1 Batch loss: 0.266093 Batch F1: 0.3448275862068965
Epoch:  379        2 Batch loss: 0.229323 Batch F1: 0.33333333333333326
Epoch:  379        3 Batch loss: 0.231852 Batch F1: 0.3333333333333333
Epoch:  379        4 Batch loss: 0.220946 Batch F1: 0.26086956521739124
Epoch:  379        5 Batch loss: 0.243053 Batch F1: 0.3225806451612903
Epoch:  379        6 Batch loss: 0.222073 Batch F1: 0.27586206896551724
Epoch:  379        7 Batch loss: 0.240981 Batch F1: 0.1739130434782609
Epoch:  379        8 Batch loss: 0.196452 Batch F1: 0.56
Epoch:  379        9 Batch loss: 0.193814 Batch F1: 0.36363636363636365
Epoch:  379       10 Batch loss: 0.187990 Batch F1: 0.5
Epoch:  379       11 Batch loss: 0.196797 Batch F1: 0.2857142857142857
Epoch:  379       12 Batch loss: 0.243915 Batch F1: 0.3478260869565218
Train Avg Loss  379: 0.222774

Train Avg F1  379: 0.34182469266693283

Val Avg Loss  379: 0.217611

Val Avg F1  379:  0.1839285714285714

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 380
--------------------------------------------------------------
Epoch:  380        1 Batch loss: 0.233230 Batch F1: 0.3448275862068966
Epoch:  380        2 Batch loss: 0.218418 Batch F1: 0.3846153846153846
Epoch:  380        3 Batch loss: 0.226464 Batch F1: 0.2727272727272727
Epoch:  380        4 Batch loss: 0.222376 Batch F1: 0.34782608695652173
Epoch:  380        5 Batch loss: 0.221693 Batch F1: 0.4444444444444444
Epoch:  380        6 Batch loss: 0.218252 Batch F1: 0.30769230769230765
Epoch:  380        7 Batch loss: 0.225121 Batch F1: 0.21052631578947367
Epoch:  380        8 Batch loss: 0.224016 Batch F1: 0.3333333333333333
Epoch:  380        9 Batch loss: 0.213727 Batch F1: 0.19047619047619047
Epoch:  380       10 Batch loss: 0.228912 Batch F1: 0.2727272727272727
Epoch:  380       11 Batch loss: 0.225476 Batch F1: 0.0
Epoch:  380       12 Batch loss: 0.211506 Batch F1: 0.3157894736842105
Train Avg Loss  380: 0.222433

Train Avg F1  380: 0.2854154723877757

Val Avg Loss  380: 0.218685

Val Avg F1  380:  0.2626705653021442

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 381
--------------------------------------------------------------
Epoch:  381        1 Batch loss: 0.273820 Batch F1: 0.1935483870967742
Epoch:  381        2 Batch loss: 0.221585 Batch F1: 0.48
Epoch:  381        3 Batch loss: 0.201932 Batch F1: 0.6153846153846154
Epoch:  381        4 Batch loss: 0.207270 Batch F1: 0.5
Epoch:  381        5 Batch loss: 0.233851 Batch F1: 0.0909090909090909
Epoch:  381        6 Batch loss: 0.208438 Batch F1: 0.09523809523809525
Epoch:  381        7 Batch loss: 0.210908 Batch F1: 0.09523809523809525
Epoch:  381        8 Batch loss: 0.210351 Batch F1: 0.0
Epoch:  381        9 Batch loss: 0.212212 Batch F1: 0.0
Epoch:  381       10 Batch loss: 0.244900 Batch F1: 0.0
Epoch:  381       11 Batch loss: 0.211814 Batch F1: 0.0
Epoch:  381       12 Batch loss: 0.251769 Batch F1: 0.0
Train Avg Loss  381: 0.224071

Train Avg F1  381: 0.1725265236555559

Val Avg Loss  381: 0.219415

Val Avg F1  381:  0.26590909090909093

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 382
--------------------------------------------------------------
Epoch:  382        1 Batch loss: 0.208029 Batch F1: 0.2857142857142857
Epoch:  382        2 Batch loss: 0.249953 Batch F1: 0.36363636363636365
Epoch:  382        3 Batch loss: 0.207566 Batch F1: 0.36363636363636365
Epoch:  382        4 Batch loss: 0.252959 Batch F1: 0.3225806451612903
Epoch:  382        5 Batch loss: 0.221230 Batch F1: 0.42857142857142855
Epoch:  382        6 Batch loss: 0.216074 Batch F1: 0.4
Epoch:  382        7 Batch loss: 0.220485 Batch F1: 0.2727272727272727
Epoch:  382        8 Batch loss: 0.218129 Batch F1: 0.2
Epoch:  382        9 Batch loss: 0.247988 Batch F1: 0.0
Epoch:  382       10 Batch loss: 0.188786 Batch F1: 0.26666666666666666
Epoch:  382       11 Batch loss: 0.214881 Batch F1: 0.10526315789473684
Epoch:  382       12 Batch loss: 0.229615 Batch F1: 0.0
Train Avg Loss  382: 0.222974

Train Avg F1  382: 0.250733015334034

Val Avg Loss  382: 0.217240

Val Avg F1  382:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 383
--------------------------------------------------------------
Epoch:  383        1 Batch loss: 0.261905 Batch F1: 0.16666666666666669
Epoch:  383        2 Batch loss: 0.191381 Batch F1: 0.11764705882352941
Epoch:  383        3 Batch loss: 0.215790 Batch F1: 0.39999999999999997
Epoch:  383        4 Batch loss: 0.240329 Batch F1: 0.27586206896551724
Epoch:  383        5 Batch loss: 0.239667 Batch F1: 0.3870967741935483
Epoch:  383        6 Batch loss: 0.201043 Batch F1: 0.6086956521739131
Epoch:  383        7 Batch loss: 0.246254 Batch F1: 0.4666666666666666
Epoch:  383        8 Batch loss: 0.194123 Batch F1: 0.3333333333333333
Epoch:  383        9 Batch loss: 0.211427 Batch F1: 0.23529411764705882
Epoch:  383       10 Batch loss: 0.223717 Batch F1: 0.4
Epoch:  383       11 Batch loss: 0.208433 Batch F1: 0.0
Epoch:  383       12 Batch loss: 0.261452 Batch F1: 0.0
Train Avg Loss  383: 0.224627

Train Avg F1  383: 0.2826051948725195

Val Avg Loss  383: 0.217592

Val Avg F1  383:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 384
--------------------------------------------------------------
Epoch:  384        1 Batch loss: 0.205278 Batch F1: 0.0
Epoch:  384        2 Batch loss: 0.239601 Batch F1: 0.0
Epoch:  384        3 Batch loss: 0.230409 Batch F1: 0.08695652173913045
Epoch:  384        4 Batch loss: 0.221016 Batch F1: 0.1
Epoch:  384        5 Batch loss: 0.227448 Batch F1: 0.3870967741935483
Epoch:  384        6 Batch loss: 0.225783 Batch F1: 0.1
Epoch:  384        7 Batch loss: 0.207406 Batch F1: 0.5806451612903226
Epoch:  384        8 Batch loss: 0.234084 Batch F1: 0.4
Epoch:  384        9 Batch loss: 0.228309 Batch F1: 0.2962962962962963
Epoch:  384       10 Batch loss: 0.233587 Batch F1: 0.37037037037037035
Epoch:  384       11 Batch loss: 0.217229 Batch F1: 0.18181818181818182
Epoch:  384       12 Batch loss: 0.203078 Batch F1: 0.0
Train Avg Loss  384: 0.222769

Train Avg F1  384: 0.20859860880898748

Val Avg Loss  384: 0.218469

Val Avg F1  384:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 385
--------------------------------------------------------------
Epoch:  385        1 Batch loss: 0.259638 Batch F1: 0.0
Epoch:  385        2 Batch loss: 0.230444 Batch F1: 0.0
Epoch:  385        3 Batch loss: 0.240090 Batch F1: 0.0
Epoch:  385        4 Batch loss: 0.202177 Batch F1: 0.0
Epoch:  385        5 Batch loss: 0.193699 Batch F1: 0.0
Epoch:  385        6 Batch loss: 0.222276 Batch F1: 0.0
Epoch:  385        7 Batch loss: 0.213756 Batch F1: 0.2857142857142857
Epoch:  385        8 Batch loss: 0.223794 Batch F1: 0.1739130434782609
Epoch:  385        9 Batch loss: 0.212599 Batch F1: 0.5384615384615384
Epoch:  385       10 Batch loss: 0.221692 Batch F1: 0.11111111111111112
Epoch:  385       11 Batch loss: 0.231551 Batch F1: 0.1
Epoch:  385       12 Batch loss: 0.241637 Batch F1: 0.27272727272727276
Train Avg Loss  385: 0.224446

Train Avg F1  385: 0.1234939376243724

Val Avg Loss  385: 0.219176

Val Avg F1  385:  0.222400954308849

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 386
--------------------------------------------------------------
Epoch:  386        1 Batch loss: 0.212735 Batch F1: 0.2857142857142857
Epoch:  386        2 Batch loss: 0.205561 Batch F1: 0.32
Epoch:  386        3 Batch loss: 0.271825 Batch F1: 0.06896551724137931
Epoch:  386        4 Batch loss: 0.220109 Batch F1: 0.09523809523809523
Epoch:  386        5 Batch loss: 0.248487 Batch F1: 0.08333333333333334
Epoch:  386        6 Batch loss: 0.209948 Batch F1: 0.2857142857142857
Epoch:  386        7 Batch loss: 0.209495 Batch F1: 0.10526315789473684
Epoch:  386        8 Batch loss: 0.231994 Batch F1: 0.0909090909090909
Epoch:  386        9 Batch loss: 0.190203 Batch F1: 0.5217391304347825
Epoch:  386       10 Batch loss: 0.226767 Batch F1: 0.2608695652173913
Epoch:  386       11 Batch loss: 0.219226 Batch F1: 0.19047619047619047
Epoch:  386       12 Batch loss: 0.217788 Batch F1: 0.47619047619047616
Train Avg Loss  386: 0.222011

Train Avg F1  386: 0.2320344273636706

Val Avg Loss  386: 0.218985

Val Avg F1  386:  0.2530034235916589

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 387
--------------------------------------------------------------
Epoch:  387        1 Batch loss: 0.218513 Batch F1: 0.19047619047619047
Epoch:  387        2 Batch loss: 0.231475 Batch F1: 0.1818181818181818
Epoch:  387        3 Batch loss: 0.188390 Batch F1: 0.3157894736842105
Epoch:  387        4 Batch loss: 0.201762 Batch F1: 0.2105263157894737
Epoch:  387        5 Batch loss: 0.222070 Batch F1: 0.4666666666666667
Epoch:  387        6 Batch loss: 0.233537 Batch F1: 0.21428571428571425
Epoch:  387        7 Batch loss: 0.247725 Batch F1: 0.14814814814814814
Epoch:  387        8 Batch loss: 0.218789 Batch F1: 0.41379310344827586
Epoch:  387        9 Batch loss: 0.218620 Batch F1: 0.3076923076923077
Epoch:  387       10 Batch loss: 0.258377 Batch F1: 0.21428571428571427
Epoch:  387       11 Batch loss: 0.227691 Batch F1: 0.3478260869565218
Epoch:  387       12 Batch loss: 0.193868 Batch F1: 0.6
Train Avg Loss  387: 0.221735

Train Avg F1  387: 0.30094232527095044

Val Avg Loss  387: 0.220435

Val Avg F1  387:  0.28214860823556476

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 388
--------------------------------------------------------------
Epoch:  388        1 Batch loss: 0.206023 Batch F1: 0.43478260869565216
Epoch:  388        2 Batch loss: 0.252237 Batch F1: 0.14285714285714285
Epoch:  388        3 Batch loss: 0.230438 Batch F1: 0.3333333333333333
Epoch:  388        4 Batch loss: 0.247676 Batch F1: 0.2580645161290323
Epoch:  388        5 Batch loss: 0.214981 Batch F1: 0.5185185185185185
Epoch:  388        6 Batch loss: 0.211611 Batch F1: 0.5
Epoch:  388        7 Batch loss: 0.220087 Batch F1: 0.3076923076923077
Epoch:  388        8 Batch loss: 0.197261 Batch F1: 0.2
Epoch:  388        9 Batch loss: 0.232321 Batch F1: 0.0
Epoch:  388       10 Batch loss: 0.238255 Batch F1: 0.0
Epoch:  388       11 Batch loss: 0.197238 Batch F1: 0.125
Epoch:  388       12 Batch loss: 0.209451 Batch F1: 0.0
Train Avg Loss  388: 0.221465

Train Avg F1  388: 0.2350207022688323

Val Avg Loss  388: 0.217324

Val Avg F1  388:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 389
--------------------------------------------------------------
Epoch:  389        1 Batch loss: 0.254707 Batch F1: 0.0
Epoch:  389        2 Batch loss: 0.198892 Batch F1: 0.0
Epoch:  389        3 Batch loss: 0.216753 Batch F1: 0.0
Epoch:  389        4 Batch loss: 0.243061 Batch F1: 0.0
Epoch:  389        5 Batch loss: 0.254300 Batch F1: 0.07407407407407407
Epoch:  389        6 Batch loss: 0.204035 Batch F1: 0.27272727272727276
Epoch:  389        7 Batch loss: 0.227253 Batch F1: 0.37037037037037035
Epoch:  389        8 Batch loss: 0.204135 Batch F1: 0.5
Epoch:  389        9 Batch loss: 0.215647 Batch F1: 0.32
Epoch:  389       10 Batch loss: 0.230328 Batch F1: 0.1818181818181818
Epoch:  389       11 Batch loss: 0.207225 Batch F1: 0.4166666666666667
Epoch:  389       12 Batch loss: 0.229406 Batch F1: 0.0
Train Avg Loss  389: 0.223812

Train Avg F1  389: 0.17797138047138047

Val Avg Loss  389: 0.217084

Val Avg F1  389:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 390
--------------------------------------------------------------
Epoch:  390        1 Batch loss: 0.196168 Batch F1: 0.0
Epoch:  390        2 Batch loss: 0.262265 Batch F1: 0.0
Epoch:  390        3 Batch loss: 0.210386 Batch F1: 0.19047619047619047
Epoch:  390        4 Batch loss: 0.217181 Batch F1: 0.3846153846153846
Epoch:  390        5 Batch loss: 0.213145 Batch F1: 0.3333333333333333
Epoch:  390        6 Batch loss: 0.185493 Batch F1: 0.64
Epoch:  390        7 Batch loss: 0.220899 Batch F1: 0.411764705882353
Epoch:  390        8 Batch loss: 0.226599 Batch F1: 0.36363636363636365
Epoch:  390        9 Batch loss: 0.264672 Batch F1: 0.27586206896551724
Epoch:  390       10 Batch loss: 0.266167 Batch F1: 0.30303030303030304
Epoch:  390       11 Batch loss: 0.221515 Batch F1: 0.4
Epoch:  390       12 Batch loss: 0.195010 Batch F1: 0.12500000000000003
Train Avg Loss  390: 0.223292

Train Avg F1  390: 0.2856431958282871

Val Avg Loss  390: 0.219503

Val Avg F1  390:  0.27125603864734305

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 391
--------------------------------------------------------------
Epoch:  391        1 Batch loss: 0.204353 Batch F1: 0.0
Epoch:  391        2 Batch loss: 0.199264 Batch F1: 0.43478260869565216
Epoch:  391        3 Batch loss: 0.207889 Batch F1: 0.0
Epoch:  391        4 Batch loss: 0.228082 Batch F1: 0.10526315789473684
Epoch:  391        5 Batch loss: 0.213479 Batch F1: 0.0
Epoch:  391        6 Batch loss: 0.242015 Batch F1: 0.0
Epoch:  391        7 Batch loss: 0.252140 Batch F1: 0.0
Epoch:  391        8 Batch loss: 0.237595 Batch F1: 0.0
Epoch:  391        9 Batch loss: 0.236654 Batch F1: 0.09523809523809523
Epoch:  391       10 Batch loss: 0.234131 Batch F1: 0.37037037037037035
Epoch:  391       11 Batch loss: 0.220252 Batch F1: 0.2608695652173913
Epoch:  391       12 Batch loss: 0.202165 Batch F1: 0.4
Train Avg Loss  391: 0.223168

Train Avg F1  391: 0.13887698311802052

Val Avg Loss  391: 0.220409

Val Avg F1  391:  0.23763736263736263

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 392
--------------------------------------------------------------
Epoch:  392        1 Batch loss: 0.208158 Batch F1: 0.32
Epoch:  392        2 Batch loss: 0.223294 Batch F1: 0.10526315789473685
Epoch:  392        3 Batch loss: 0.237450 Batch F1: 0.3225806451612903
Epoch:  392        4 Batch loss: 0.188871 Batch F1: 0.5833333333333334
Epoch:  392        5 Batch loss: 0.235216 Batch F1: 0.16
Epoch:  392        6 Batch loss: 0.189034 Batch F1: 0.39999999999999997
Epoch:  392        7 Batch loss: 0.218968 Batch F1: 0.26086956521739124
Epoch:  392        8 Batch loss: 0.247732 Batch F1: 0.21428571428571427
Epoch:  392        9 Batch loss: 0.224930 Batch F1: 0.4
Epoch:  392       10 Batch loss: 0.237897 Batch F1: 0.2727272727272727
Epoch:  392       11 Batch loss: 0.260574 Batch F1: 0.3870967741935484
Epoch:  392       12 Batch loss: 0.200144 Batch F1: 0.0
Train Avg Loss  392: 0.222689

Train Avg F1  392: 0.28551303856777394

Val Avg Loss  392: 0.219200

Val Avg F1  392:  0.23876324824600684

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 393
--------------------------------------------------------------
Epoch:  393        1 Batch loss: 0.225015 Batch F1: 0.3448275862068966
Epoch:  393        2 Batch loss: 0.195957 Batch F1: 0.2222222222222222
Epoch:  393        3 Batch loss: 0.218832 Batch F1: 0.21052631578947364
Epoch:  393        4 Batch loss: 0.244776 Batch F1: 0.0
Epoch:  393        5 Batch loss: 0.227445 Batch F1: 0.0
Epoch:  393        6 Batch loss: 0.210763 Batch F1: 0.0
Epoch:  393        7 Batch loss: 0.231907 Batch F1: 0.0909090909090909
Epoch:  393        8 Batch loss: 0.213583 Batch F1: 0.0
Epoch:  393        9 Batch loss: 0.229378 Batch F1: 0.2608695652173913
Epoch:  393       10 Batch loss: 0.220537 Batch F1: 0.3846153846153846
Epoch:  393       11 Batch loss: 0.191944 Batch F1: 0.380952380952381
Epoch:  393       12 Batch loss: 0.270360 Batch F1: 0.35714285714285715
Train Avg Loss  393: 0.223375

Train Avg F1  393: 0.1876721169213081

Val Avg Loss  393: 0.218640

Val Avg F1  393:  0.25548245614035087

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 394
--------------------------------------------------------------
Epoch:  394        1 Batch loss: 0.201021 Batch F1: 0.0
Epoch:  394        2 Batch loss: 0.242343 Batch F1: 0.41379310344827586
Epoch:  394        3 Batch loss: 0.205535 Batch F1: 0.2222222222222222
Epoch:  394        4 Batch loss: 0.222507 Batch F1: 0.3846153846153846
Epoch:  394        5 Batch loss: 0.219014 Batch F1: 0.3636363636363636
Epoch:  394        6 Batch loss: 0.251968 Batch F1: 0.2962962962962963
Epoch:  394        7 Batch loss: 0.220850 Batch F1: 0.10526315789473685
Epoch:  394        8 Batch loss: 0.224887 Batch F1: 0.1739130434782609
Epoch:  394        9 Batch loss: 0.214494 Batch F1: 0.5333333333333333
Epoch:  394       10 Batch loss: 0.208213 Batch F1: 0.3703703703703704
Epoch:  394       11 Batch loss: 0.199245 Batch F1: 0.42857142857142855
Epoch:  394       12 Batch loss: 0.262706 Batch F1: 0.0
Train Avg Loss  394: 0.222732

Train Avg F1  394: 0.27433455865555606

Val Avg Loss  394: 0.219263

Val Avg F1  394:  0.24702107279693486

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 395
--------------------------------------------------------------
Epoch:  395        1 Batch loss: 0.202966 Batch F1: 0.3
Epoch:  395        2 Batch loss: 0.234454 Batch F1: 0.39999999999999997
Epoch:  395        3 Batch loss: 0.216635 Batch F1: 0.19047619047619047
Epoch:  395        4 Batch loss: 0.251609 Batch F1: 0.48648648648648646
Epoch:  395        5 Batch loss: 0.176373 Batch F1: 0.2222222222222222
Epoch:  395        6 Batch loss: 0.232377 Batch F1: 0.29629629629629634
Epoch:  395        7 Batch loss: 0.209055 Batch F1: 0.37037037037037035
Epoch:  395        8 Batch loss: 0.247444 Batch F1: 0.16666666666666666
Epoch:  395        9 Batch loss: 0.222964 Batch F1: 0.25
Epoch:  395       10 Batch loss: 0.251938 Batch F1: 0.28571428571428575
Epoch:  395       11 Batch loss: 0.195834 Batch F1: 0.3333333333333333
Epoch:  395       12 Batch loss: 0.223799 Batch F1: 0.3333333333333333
Train Avg Loss  395: 0.222121

Train Avg F1  395: 0.3029082654082654

Val Avg Loss  395: 0.218494

Val Avg F1  395:  0.2587097684923772

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 396
--------------------------------------------------------------
Epoch:  396        1 Batch loss: 0.218195 Batch F1: 0.0909090909090909
Epoch:  396        2 Batch loss: 0.222440 Batch F1: 0.19047619047619047
Epoch:  396        3 Batch loss: 0.228231 Batch F1: 0.34782608695652173
Epoch:  396        4 Batch loss: 0.199586 Batch F1: 0.28571428571428575
Epoch:  396        5 Batch loss: 0.213161 Batch F1: 0.3636363636363636
Epoch:  396        6 Batch loss: 0.246657 Batch F1: 0.3333333333333333
Epoch:  396        7 Batch loss: 0.228574 Batch F1: 0.43749999999999994
Epoch:  396        8 Batch loss: 0.251034 Batch F1: 0.2758620689655173
Epoch:  396        9 Batch loss: 0.197610 Batch F1: 0.1111111111111111
Epoch:  396       10 Batch loss: 0.208972 Batch F1: 0.3846153846153846
Epoch:  396       11 Batch loss: 0.223192 Batch F1: 0.44444444444444436
Epoch:  396       12 Batch loss: 0.226043 Batch F1: 0.3333333333333333
Train Avg Loss  396: 0.221975

Train Avg F1  396: 0.299896807791298

Val Avg Loss  396: 0.219316

Val Avg F1  396:  0.24287135278514588

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 397
--------------------------------------------------------------
Epoch:  397        1 Batch loss: 0.265985 Batch F1: 0.35294117647058826
Epoch:  397        2 Batch loss: 0.227493 Batch F1: 0.21428571428571425
Epoch:  397        3 Batch loss: 0.227200 Batch F1: 0.48275862068965514
Epoch:  397        4 Batch loss: 0.200420 Batch F1: 0.5
Epoch:  397        5 Batch loss: 0.233310 Batch F1: 0.2962962962962963
Epoch:  397        6 Batch loss: 0.205156 Batch F1: 0.32
Epoch:  397        7 Batch loss: 0.209960 Batch F1: 0.2
Epoch:  397        8 Batch loss: 0.231884 Batch F1: 0.27272727272727276
Epoch:  397        9 Batch loss: 0.221666 Batch F1: 0.36363636363636365
Epoch:  397       10 Batch loss: 0.171861 Batch F1: 0.13333333333333336
Epoch:  397       11 Batch loss: 0.276370 Batch F1: 0.07142857142857144
Epoch:  397       12 Batch loss: 0.188515 Batch F1: 0.35294117647058826
Train Avg Loss  397: 0.221652

Train Avg F1  397: 0.2966957104448653

Val Avg Loss  397: 0.217516

Val Avg F1  397:  0.2303113553113553

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 398
--------------------------------------------------------------
Epoch:  398        1 Batch loss: 0.225969 Batch F1: 0.1
Epoch:  398        2 Batch loss: 0.207542 Batch F1: 0.4166666666666667
Epoch:  398        3 Batch loss: 0.218380 Batch F1: 0.4444444444444444
Epoch:  398        4 Batch loss: 0.203790 Batch F1: 0.08695652173913043
Epoch:  398        5 Batch loss: 0.235591 Batch F1: 0.2857142857142857
Epoch:  398        6 Batch loss: 0.228386 Batch F1: 0.34782608695652173
Epoch:  398        7 Batch loss: 0.196829 Batch F1: 0.2222222222222222
Epoch:  398        8 Batch loss: 0.256662 Batch F1: 0.3125
Epoch:  398        9 Batch loss: 0.246040 Batch F1: 0.3225806451612903
Epoch:  398       10 Batch loss: 0.215907 Batch F1: 0.38461538461538464
Epoch:  398       11 Batch loss: 0.202117 Batch F1: 0.3157894736842105
Epoch:  398       12 Batch loss: 0.227825 Batch F1: 0.36363636363636365
Train Avg Loss  398: 0.222087

Train Avg F1  398: 0.3002460079033767

Val Avg Loss  398: 0.218799

Val Avg F1  398:  0.2629281949934124

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 399
--------------------------------------------------------------
Epoch:  399        1 Batch loss: 0.232407 Batch F1: 0.2608695652173913
Epoch:  399        2 Batch loss: 0.230612 Batch F1: 0.09999999999999999
Epoch:  399        3 Batch loss: 0.232925 Batch F1: 0.2962962962962963
Epoch:  399        4 Batch loss: 0.205062 Batch F1: 0.2857142857142857
Epoch:  399        5 Batch loss: 0.192202 Batch F1: 0.48
Epoch:  399        6 Batch loss: 0.282981 Batch F1: 0.13333333333333333
Epoch:  399        7 Batch loss: 0.237482 Batch F1: 0.36363636363636365
Epoch:  399        8 Batch loss: 0.194554 Batch F1: 0.11764705882352941
Epoch:  399        9 Batch loss: 0.199454 Batch F1: 0.5384615384615384
Epoch:  399       10 Batch loss: 0.203795 Batch F1: 0.3636363636363636
Epoch:  399       11 Batch loss: 0.250570 Batch F1: 0.3529411764705882
Epoch:  399       12 Batch loss: 0.198273 Batch F1: 0.35294117647058826
Train Avg Loss  399: 0.221693

Train Avg F1  399: 0.3037897631716899

Val Avg Loss  399: 0.219017

Val Avg F1  399:  0.23211462450592885

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 400
--------------------------------------------------------------
Epoch:  400        1 Batch loss: 0.223726 Batch F1: 0.3846153846153846
Epoch:  400        2 Batch loss: 0.233984 Batch F1: 0.16000000000000003
Epoch:  400        3 Batch loss: 0.221519 Batch F1: 0.23999999999999996
Epoch:  400        4 Batch loss: 0.227675 Batch F1: 0.32
Epoch:  400        5 Batch loss: 0.232274 Batch F1: 0.4444444444444444
Epoch:  400        6 Batch loss: 0.225011 Batch F1: 0.0
Epoch:  400        7 Batch loss: 0.222172 Batch F1: 0.4
Epoch:  400        8 Batch loss: 0.205585 Batch F1: 0.56
Epoch:  400        9 Batch loss: 0.213753 Batch F1: 0.1904761904761905
Epoch:  400       10 Batch loss: 0.195360 Batch F1: 0.10526315789473684
Epoch:  400       11 Batch loss: 0.254598 Batch F1: 0.17391304347826084
Epoch:  400       12 Batch loss: 0.206846 Batch F1: 0.25
Train Avg Loss  400: 0.221875

Train Avg F1  400: 0.2690593517424181

Val Avg Loss  400: 0.218380

Val Avg F1  400:  0.26681159420289857

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 401
--------------------------------------------------------------
Epoch:  401        1 Batch loss: 0.248065 Batch F1: 0.23076923076923078
Epoch:  401        2 Batch loss: 0.246767 Batch F1: 0.36363636363636365
Epoch:  401        3 Batch loss: 0.237638 Batch F1: 0.23076923076923075
Epoch:  401        4 Batch loss: 0.228193 Batch F1: 0.2727272727272727
Epoch:  401        5 Batch loss: 0.202131 Batch F1: 0.0
Epoch:  401        6 Batch loss: 0.230254 Batch F1: 0.0
Epoch:  401        7 Batch loss: 0.234829 Batch F1: 0.0
Epoch:  401        8 Batch loss: 0.216252 Batch F1: 0.0
Epoch:  401        9 Batch loss: 0.267904 Batch F1: 0.0
Epoch:  401       10 Batch loss: 0.189087 Batch F1: 0.14285714285714288
Epoch:  401       11 Batch loss: 0.196474 Batch F1: 0.0
Epoch:  401       12 Batch loss: 0.197088 Batch F1: 0.5217391304347825
Train Avg Loss  401: 0.224557

Train Avg F1  401: 0.1468748642661686

Val Avg Loss  401: 0.220896

Val Avg F1  401:  0.34375

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 402
--------------------------------------------------------------
Epoch:  402        1 Batch loss: 0.211402 Batch F1: 0.21052631578947364
Epoch:  402        2 Batch loss: 0.216809 Batch F1: 0.2727272727272727
Epoch:  402        3 Batch loss: 0.236030 Batch F1: 0.0
Epoch:  402        4 Batch loss: 0.229042 Batch F1: 0.0
Epoch:  402        5 Batch loss: 0.248054 Batch F1: 0.0
Epoch:  402        6 Batch loss: 0.233319 Batch F1: 0.0
Epoch:  402        7 Batch loss: 0.216842 Batch F1: 0.0
Epoch:  402        8 Batch loss: 0.215925 Batch F1: 0.10526315789473684
Epoch:  402        9 Batch loss: 0.248579 Batch F1: 0.07692307692307693
Epoch:  402       10 Batch loss: 0.227814 Batch F1: 0.09090909090909091
Epoch:  402       11 Batch loss: 0.218055 Batch F1: 0.3478260869565218
Epoch:  402       12 Batch loss: 0.198895 Batch F1: 0.4
Train Avg Loss  402: 0.225064

Train Avg F1  402: 0.12534791676668108

Val Avg Loss  402: 0.218192

Val Avg F1  402:  0.2752564464520986

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 403
--------------------------------------------------------------
Epoch:  403        1 Batch loss: 0.190533 Batch F1: 0.26666666666666666
Epoch:  403        2 Batch loss: 0.225786 Batch F1: 0.0
Epoch:  403        3 Batch loss: 0.198967 Batch F1: 0.0
Epoch:  403        4 Batch loss: 0.239806 Batch F1: 0.0
Epoch:  403        5 Batch loss: 0.269405 Batch F1: 0.0
Epoch:  403        6 Batch loss: 0.228102 Batch F1: 0.1739130434782609
Epoch:  403        7 Batch loss: 0.222228 Batch F1: 0.27272727272727276
Epoch:  403        8 Batch loss: 0.197443 Batch F1: 0.2222222222222222
Epoch:  403        9 Batch loss: 0.248597 Batch F1: 0.3448275862068965
Epoch:  403       10 Batch loss: 0.199439 Batch F1: 0.0
Epoch:  403       11 Batch loss: 0.230413 Batch F1: 0.0909090909090909
Epoch:  403       12 Batch loss: 0.234390 Batch F1: 0.2608695652173913
Train Avg Loss  403: 0.223759

Train Avg F1  403: 0.1360112872856501

Val Avg Loss  403: 0.218266

Val Avg F1  403:  0.2563485920684063

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 404
--------------------------------------------------------------
Epoch:  404        1 Batch loss: 0.229400 Batch F1: 0.3448275862068965
Epoch:  404        2 Batch loss: 0.217830 Batch F1: 0.4444444444444444
Epoch:  404        3 Batch loss: 0.202665 Batch F1: 0.3636363636363636
Epoch:  404        4 Batch loss: 0.241928 Batch F1: 0.3448275862068966
Epoch:  404        5 Batch loss: 0.224575 Batch F1: 0.33333333333333326
Epoch:  404        6 Batch loss: 0.213946 Batch F1: 0.09523809523809523
Epoch:  404        7 Batch loss: 0.218056 Batch F1: 0.2962962962962963
Epoch:  404        8 Batch loss: 0.233217 Batch F1: 0.0
Epoch:  404        9 Batch loss: 0.215394 Batch F1: 0.0
Epoch:  404       10 Batch loss: 0.195031 Batch F1: 0.0
Epoch:  404       11 Batch loss: 0.247521 Batch F1: 0.0
Epoch:  404       12 Batch loss: 0.246492 Batch F1: 0.0
Train Avg Loss  404: 0.223838

Train Avg F1  404: 0.18521697544686047

Val Avg Loss  404: 0.218502

Val Avg F1  404:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 405
--------------------------------------------------------------
Epoch:  405        1 Batch loss: 0.228750 Batch F1: 0.0
Epoch:  405        2 Batch loss: 0.239918 Batch F1: 0.0
Epoch:  405        3 Batch loss: 0.176402 Batch F1: 0.0
Epoch:  405        4 Batch loss: 0.205442 Batch F1: 0.0
Epoch:  405        5 Batch loss: 0.227913 Batch F1: 0.0
Epoch:  405        6 Batch loss: 0.260883 Batch F1: 0.0
Epoch:  405        7 Batch loss: 0.222474 Batch F1: 0.0
Epoch:  405        8 Batch loss: 0.233033 Batch F1: 0.0
Epoch:  405        9 Batch loss: 0.231146 Batch F1: 0.0
Epoch:  405       10 Batch loss: 0.202660 Batch F1: 0.4166666666666667
Epoch:  405       11 Batch loss: 0.247344 Batch F1: 0.33333333333333326
Epoch:  405       12 Batch loss: 0.225401 Batch F1: 0.5625000000000001
Train Avg Loss  405: 0.225114

Train Avg F1  405: 0.109375

Val Avg Loss  405: 0.221931

Val Avg F1  405:  0.32444444444444437

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 406
--------------------------------------------------------------
Epoch:  406        1 Batch loss: 0.241149 Batch F1: 0.3076923076923077
Epoch:  406        2 Batch loss: 0.225966 Batch F1: 0.0
Epoch:  406        3 Batch loss: 0.235686 Batch F1: 0.0
Epoch:  406        4 Batch loss: 0.219775 Batch F1: 0.0
Epoch:  406        5 Batch loss: 0.229726 Batch F1: 0.0
Epoch:  406        6 Batch loss: 0.211106 Batch F1: 0.0
Epoch:  406        7 Batch loss: 0.214415 Batch F1: 0.0
Epoch:  406        8 Batch loss: 0.194897 Batch F1: 0.0
Epoch:  406        9 Batch loss: 0.255179 Batch F1: 0.0
Epoch:  406       10 Batch loss: 0.210085 Batch F1: 0.19047619047619047
Epoch:  406       11 Batch loss: 0.243603 Batch F1: 0.27586206896551724
Epoch:  406       12 Batch loss: 0.213605 Batch F1: 0.4
Train Avg Loss  406: 0.224600

Train Avg F1  406: 0.09783588059450128

Val Avg Loss  406: 0.219737

Val Avg F1  406:  0.25124521072796935

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 407
--------------------------------------------------------------
Epoch:  407        1 Batch loss: 0.229010 Batch F1: 0.23076923076923078
Epoch:  407        2 Batch loss: 0.244257 Batch F1: 0.3870967741935483
Epoch:  407        3 Batch loss: 0.210397 Batch F1: 0.2857142857142857
Epoch:  407        4 Batch loss: 0.219631 Batch F1: 0.19047619047619047
Epoch:  407        5 Batch loss: 0.209891 Batch F1: 0.0
Epoch:  407        6 Batch loss: 0.237333 Batch F1: 0.0
Epoch:  407        7 Batch loss: 0.259006 Batch F1: 0.0
Epoch:  407        8 Batch loss: 0.189760 Batch F1: 0.13333333333333333
Epoch:  407        9 Batch loss: 0.191600 Batch F1: 0.0
Epoch:  407       10 Batch loss: 0.226439 Batch F1: 0.0
Epoch:  407       11 Batch loss: 0.223661 Batch F1: 0.0
Epoch:  407       12 Batch loss: 0.240677 Batch F1: 0.0
Train Avg Loss  407: 0.223472

Train Avg F1  407: 0.10228248454054904

Val Avg Loss  407: 0.217254

Val Avg F1  407:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 408
--------------------------------------------------------------
Epoch:  408        1 Batch loss: 0.213554 Batch F1: 0.0
Epoch:  408        2 Batch loss: 0.224563 Batch F1: 0.0
Epoch:  408        3 Batch loss: 0.221222 Batch F1: 0.0
Epoch:  408        4 Batch loss: 0.198689 Batch F1: 0.2608695652173913
Epoch:  408        5 Batch loss: 0.235197 Batch F1: 0.3571428571428571
Epoch:  408        6 Batch loss: 0.231817 Batch F1: 0.26666666666666666
Epoch:  408        7 Batch loss: 0.224312 Batch F1: 0.1
Epoch:  408        8 Batch loss: 0.202552 Batch F1: 0.5217391304347827
Epoch:  408        9 Batch loss: 0.220950 Batch F1: 0.3333333333333333
Epoch:  408       10 Batch loss: 0.223292 Batch F1: 0.2
Epoch:  408       11 Batch loss: 0.247012 Batch F1: 0.08
Epoch:  408       12 Batch loss: 0.227470 Batch F1: 0.1111111111111111
Train Avg Loss  408: 0.222552

Train Avg F1  408: 0.18590522199217852

Val Avg Loss  408: 0.218414

Val Avg F1  408:  0.23748353096179184

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 409
--------------------------------------------------------------
Epoch:  409        1 Batch loss: 0.227725 Batch F1: 0.1
Epoch:  409        2 Batch loss: 0.229167 Batch F1: 0.0
Epoch:  409        3 Batch loss: 0.237999 Batch F1: 0.0
Epoch:  409        4 Batch loss: 0.230568 Batch F1: 0.0
Epoch:  409        5 Batch loss: 0.225074 Batch F1: 0.0
Epoch:  409        6 Batch loss: 0.207444 Batch F1: 0.0
Epoch:  409        7 Batch loss: 0.215039 Batch F1: 0.0
Epoch:  409        8 Batch loss: 0.227596 Batch F1: 0.0
Epoch:  409        9 Batch loss: 0.234616 Batch F1: 0.1739130434782609
Epoch:  409       10 Batch loss: 0.224025 Batch F1: 0.3225806451612903
Epoch:  409       11 Batch loss: 0.205303 Batch F1: 0.6153846153846153
Epoch:  409       12 Batch loss: 0.199871 Batch F1: 0.48
Train Avg Loss  409: 0.222036

Train Avg F1  409: 0.14098985866868055

Val Avg Loss  409: 0.221418

Val Avg F1  409:  0.325527950310559

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 410
--------------------------------------------------------------
Epoch:  410        1 Batch loss: 0.189107 Batch F1: 0.6206896551724139
Epoch:  410        2 Batch loss: 0.229418 Batch F1: 0.4571428571428572
Epoch:  410        3 Batch loss: 0.204926 Batch F1: 0.3478260869565218
Epoch:  410        4 Batch loss: 0.196323 Batch F1: 0.4444444444444445
Epoch:  410        5 Batch loss: 0.255862 Batch F1: 0.14814814814814814
Epoch:  410        6 Batch loss: 0.197502 Batch F1: 0.21052631578947367
Epoch:  410        7 Batch loss: 0.221587 Batch F1: 0.3846153846153846
Epoch:  410        8 Batch loss: 0.228269 Batch F1: 0.25
Epoch:  410        9 Batch loss: 0.248877 Batch F1: 0.4285714285714285
Epoch:  410       10 Batch loss: 0.243309 Batch F1: 0.16666666666666666
Epoch:  410       11 Batch loss: 0.237806 Batch F1: 0.25
Epoch:  410       12 Batch loss: 0.212199 Batch F1: 0.375
Train Avg Loss  410: 0.222099

Train Avg F1  410: 0.3403025822922781

Val Avg Loss  410: 0.217522

Val Avg F1  410:  0.19358974358974357

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 411
--------------------------------------------------------------
Epoch:  411        1 Batch loss: 0.185997 Batch F1: 0.0
Epoch:  411        2 Batch loss: 0.216957 Batch F1: 0.1
Epoch:  411        3 Batch loss: 0.256449 Batch F1: 0.0
Epoch:  411        4 Batch loss: 0.292511 Batch F1: 0.0
Epoch:  411        5 Batch loss: 0.212439 Batch F1: 0.0
Epoch:  411        6 Batch loss: 0.205759 Batch F1: 0.0
Epoch:  411        7 Batch loss: 0.211242 Batch F1: 0.4
Epoch:  411        8 Batch loss: 0.227323 Batch F1: 0.3846153846153846
Epoch:  411        9 Batch loss: 0.209871 Batch F1: 0.34782608695652173
Epoch:  411       10 Batch loss: 0.222016 Batch F1: 0.25
Epoch:  411       11 Batch loss: 0.240764 Batch F1: 0.16666666666666666
Epoch:  411       12 Batch loss: 0.205798 Batch F1: 0.3157894736842105
Train Avg Loss  411: 0.223927

Train Avg F1  411: 0.16374146766023198

Val Avg Loss  411: 0.217983

Val Avg F1  411:  0.23769748769748772

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 412
--------------------------------------------------------------
Epoch:  412        1 Batch loss: 0.181598 Batch F1: 0.26666666666666666
Epoch:  412        2 Batch loss: 0.212757 Batch F1: 0.1818181818181818
Epoch:  412        3 Batch loss: 0.209470 Batch F1: 0.0
Epoch:  412        4 Batch loss: 0.272940 Batch F1: 0.0
Epoch:  412        5 Batch loss: 0.201131 Batch F1: 0.0
Epoch:  412        6 Batch loss: 0.252930 Batch F1: 0.0
Epoch:  412        7 Batch loss: 0.169273 Batch F1: 0.0
Epoch:  412        8 Batch loss: 0.223046 Batch F1: 0.25
Epoch:  412        9 Batch loss: 0.223137 Batch F1: 0.5161290322580645
Epoch:  412       10 Batch loss: 0.250825 Batch F1: 0.29411764705882354
Epoch:  412       11 Batch loss: 0.232129 Batch F1: 0.4827586206896552
Epoch:  412       12 Batch loss: 0.247336 Batch F1: 0.25
Train Avg Loss  412: 0.223048

Train Avg F1  412: 0.18679084570761598

Val Avg Loss  412: 0.222693

Val Avg F1  412:  0.2185897435897436

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 413
--------------------------------------------------------------
Epoch:  413        1 Batch loss: 0.241592 Batch F1: 0.22222222222222218
Epoch:  413        2 Batch loss: 0.227364 Batch F1: 0.0
Epoch:  413        3 Batch loss: 0.227431 Batch F1: 0.0
Epoch:  413        4 Batch loss: 0.246638 Batch F1: 0.0
Epoch:  413        5 Batch loss: 0.209306 Batch F1: 0.0
Epoch:  413        6 Batch loss: 0.233551 Batch F1: 0.0
Epoch:  413        7 Batch loss: 0.244901 Batch F1: 0.0
Epoch:  413        8 Batch loss: 0.241774 Batch F1: 0.08695652173913042
Epoch:  413        9 Batch loss: 0.215660 Batch F1: 0.41379310344827586
Epoch:  413       10 Batch loss: 0.229526 Batch F1: 0.1
Epoch:  413       11 Batch loss: 0.202277 Batch F1: 0.0
Epoch:  413       12 Batch loss: 0.204970 Batch F1: 0.0
Train Avg Loss  413: 0.227083

Train Avg F1  413: 0.06858098728413571

Val Avg Loss  413: 0.217854

Val Avg F1  413:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 414
--------------------------------------------------------------
Epoch:  414        1 Batch loss: 0.209809 Batch F1: 0.0
Epoch:  414        2 Batch loss: 0.262158 Batch F1: 0.0
Epoch:  414        3 Batch loss: 0.233327 Batch F1: 0.0
Epoch:  414        4 Batch loss: 0.250504 Batch F1: 0.0
Epoch:  414        5 Batch loss: 0.231143 Batch F1: 0.0
Epoch:  414        6 Batch loss: 0.201245 Batch F1: 0.125
Epoch:  414        7 Batch loss: 0.206558 Batch F1: 0.47058823529411764
Epoch:  414        8 Batch loss: 0.246186 Batch F1: 0.0
Epoch:  414        9 Batch loss: 0.198683 Batch F1: 0.0
Epoch:  414       10 Batch loss: 0.218914 Batch F1: 0.0
Epoch:  414       11 Batch loss: 0.227546 Batch F1: 0.0
Epoch:  414       12 Batch loss: 0.268757 Batch F1: 0.0
Train Avg Loss  414: 0.229569

Train Avg F1  414: 0.04963235294117647

Val Avg Loss  414: 0.218948

Val Avg F1  414:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 415
--------------------------------------------------------------
Epoch:  415        1 Batch loss: 0.201041 Batch F1: 0.0
Epoch:  415        2 Batch loss: 0.200108 Batch F1: 0.0
Epoch:  415        3 Batch loss: 0.212192 Batch F1: 0.0
Epoch:  415        4 Batch loss: 0.245808 Batch F1: 0.0
Epoch:  415        5 Batch loss: 0.229738 Batch F1: 0.0
Epoch:  415        6 Batch loss: 0.199819 Batch F1: 0.0
Epoch:  415        7 Batch loss: 0.230787 Batch F1: 0.0
Epoch:  415        8 Batch loss: 0.213907 Batch F1: 0.3333333333333333
Epoch:  415        9 Batch loss: 0.197921 Batch F1: 0.2
Epoch:  415       10 Batch loss: 0.254528 Batch F1: 0.07407407407407407
Epoch:  415       11 Batch loss: 0.264325 Batch F1: 0.3529411764705882
Epoch:  415       12 Batch loss: 0.230678 Batch F1: 0.3846153846153846
Train Avg Loss  415: 0.223404

Train Avg F1  415: 0.11208033070778167

Val Avg Loss  415: 0.224204

Val Avg F1  415:  0.3353296703296703

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 416
--------------------------------------------------------------
Epoch:  416        1 Batch loss: 0.239746 Batch F1: 0.39999999999999997
Epoch:  416        2 Batch loss: 0.241823 Batch F1: 0.39999999999999997
Epoch:  416        3 Batch loss: 0.210223 Batch F1: 0.5
Epoch:  416        4 Batch loss: 0.232431 Batch F1: 0.2962962962962963
Epoch:  416        5 Batch loss: 0.221098 Batch F1: 0.6060606060606061
Epoch:  416        6 Batch loss: 0.203642 Batch F1: 0.4545454545454545
Epoch:  416        7 Batch loss: 0.213018 Batch F1: 0.37037037037037035
Epoch:  416        8 Batch loss: 0.227313 Batch F1: 0.09523809523809525
Epoch:  416        9 Batch loss: 0.230112 Batch F1: 0.0
Epoch:  416       10 Batch loss: 0.227051 Batch F1: 0.0909090909090909
Epoch:  416       11 Batch loss: 0.227622 Batch F1: 0.28571428571428575
Epoch:  416       12 Batch loss: 0.223293 Batch F1: 0.23529411764705885
Train Avg Loss  416: 0.224781

Train Avg F1  416: 0.31120235973177146

Val Avg Loss  416: 0.218008

Val Avg F1  416:  0.027777777777777776

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 417
--------------------------------------------------------------
Epoch:  417        1 Batch loss: 0.217765 Batch F1: 0.09523809523809525
Epoch:  417        2 Batch loss: 0.244768 Batch F1: 0.0
Epoch:  417        3 Batch loss: 0.199835 Batch F1: 0.0
Epoch:  417        4 Batch loss: 0.182654 Batch F1: 0.0
Epoch:  417        5 Batch loss: 0.202211 Batch F1: 0.11764705882352941
Epoch:  417        6 Batch loss: 0.254822 Batch F1: 0.0
Epoch:  417        7 Batch loss: 0.227724 Batch F1: 0.0
Epoch:  417        8 Batch loss: 0.190322 Batch F1: 0.25
Epoch:  417        9 Batch loss: 0.234925 Batch F1: 0.5625000000000001
Epoch:  417       10 Batch loss: 0.233711 Batch F1: 0.3076923076923077
Epoch:  417       11 Batch loss: 0.228200 Batch F1: 0.31999999999999995
Epoch:  417       12 Batch loss: 0.267832 Batch F1: 0.08695652173913045
Train Avg Loss  417: 0.223731

Train Avg F1  417: 0.14500283195775523

Val Avg Loss  417: 0.219408

Val Avg F1  417:  0.2685507246376812

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 418
--------------------------------------------------------------
Epoch:  418        1 Batch loss: 0.231419 Batch F1: 0.26086956521739124
Epoch:  418        2 Batch loss: 0.229458 Batch F1: 0.19047619047619047
Epoch:  418        3 Batch loss: 0.245365 Batch F1: 0.20689655172413793
Epoch:  418        4 Batch loss: 0.214685 Batch F1: 0.3333333333333333
Epoch:  418        5 Batch loss: 0.188022 Batch F1: 0.16666666666666669
Epoch:  418        6 Batch loss: 0.207285 Batch F1: 0.1
Epoch:  418        7 Batch loss: 0.219735 Batch F1: 0.0
Epoch:  418        8 Batch loss: 0.241947 Batch F1: 0.0
Epoch:  418        9 Batch loss: 0.211711 Batch F1: 0.32
Epoch:  418       10 Batch loss: 0.212374 Batch F1: 0.33333333333333337
Epoch:  418       11 Batch loss: 0.215898 Batch F1: 0.5161290322580646
Epoch:  418       12 Batch loss: 0.263638 Batch F1: 0.16
Train Avg Loss  418: 0.223461

Train Avg F1  418: 0.21564205608409315

Val Avg Loss  418: 0.219606

Val Avg F1  418:  0.25062408986894114

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 419
--------------------------------------------------------------
Epoch:  419        1 Batch loss: 0.232030 Batch F1: 0.2608695652173913
Epoch:  419        2 Batch loss: 0.206769 Batch F1: 0.3846153846153846
Epoch:  419        3 Batch loss: 0.235196 Batch F1: 0.33333333333333337
Epoch:  419        4 Batch loss: 0.227651 Batch F1: 0.16666666666666666
Epoch:  419        5 Batch loss: 0.242150 Batch F1: 0.3846153846153846
Epoch:  419        6 Batch loss: 0.215934 Batch F1: 0.5
Epoch:  419        7 Batch loss: 0.184647 Batch F1: 0.2222222222222222
Epoch:  419        8 Batch loss: 0.241030 Batch F1: 0.2962962962962963
Epoch:  419        9 Batch loss: 0.182716 Batch F1: 0.4210526315789473
Epoch:  419       10 Batch loss: 0.231473 Batch F1: 0.0
Epoch:  419       11 Batch loss: 0.237429 Batch F1: 0.0
Epoch:  419       12 Batch loss: 0.231722 Batch F1: 0.0
Train Avg Loss  419: 0.222396

Train Avg F1  419: 0.24747262371213555

Val Avg Loss  419: 0.218317

Val Avg F1  419:  0.1777046482928836

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 420
--------------------------------------------------------------
Epoch:  420        1 Batch loss: 0.232236 Batch F1: 0.2962962962962963
Epoch:  420        2 Batch loss: 0.249977 Batch F1: 0.33333333333333326
Epoch:  420        3 Batch loss: 0.231876 Batch F1: 0.17391304347826086
Epoch:  420        4 Batch loss: 0.218121 Batch F1: 0.6111111111111112
Epoch:  420        5 Batch loss: 0.228068 Batch F1: 0.5
Epoch:  420        6 Batch loss: 0.222115 Batch F1: 0.36363636363636365
Epoch:  420        7 Batch loss: 0.243877 Batch F1: 0.2758620689655173
Epoch:  420        8 Batch loss: 0.230517 Batch F1: 0.37037037037037035
Epoch:  420        9 Batch loss: 0.193579 Batch F1: 0.22222222222222224
Epoch:  420       10 Batch loss: 0.208593 Batch F1: 0.10526315789473684
Epoch:  420       11 Batch loss: 0.224515 Batch F1: 0.0
Epoch:  420       12 Batch loss: 0.171445 Batch F1: 0.0
Train Avg Loss  420: 0.221243

Train Avg F1  420: 0.271000663942351

Val Avg Loss  420: 0.217829

Val Avg F1  420:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 421
--------------------------------------------------------------
Epoch:  421        1 Batch loss: 0.204719 Batch F1: 0.0
Epoch:  421        2 Batch loss: 0.228344 Batch F1: 0.0
Epoch:  421        3 Batch loss: 0.256764 Batch F1: 0.0
Epoch:  421        4 Batch loss: 0.213603 Batch F1: 0.0
Epoch:  421        5 Batch loss: 0.209531 Batch F1: 0.0
Epoch:  421        6 Batch loss: 0.216445 Batch F1: 0.0
Epoch:  421        7 Batch loss: 0.209742 Batch F1: 0.0
Epoch:  421        8 Batch loss: 0.246463 Batch F1: 0.16
Epoch:  421        9 Batch loss: 0.215305 Batch F1: 0.1739130434782609
Epoch:  421       10 Batch loss: 0.245428 Batch F1: 0.33333333333333326
Epoch:  421       11 Batch loss: 0.218530 Batch F1: 0.3846153846153846
Epoch:  421       12 Batch loss: 0.221894 Batch F1: 0.41379310344827586
Train Avg Loss  421: 0.223897

Train Avg F1  421: 0.12213790540627122

Val Avg Loss  421: 0.221756

Val Avg F1  421:  0.3553723908918406

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 422
--------------------------------------------------------------
Epoch:  422        1 Batch loss: 0.197994 Batch F1: 0.4615384615384615
Epoch:  422        2 Batch loss: 0.220242 Batch F1: 0.18181818181818182
Epoch:  422        3 Batch loss: 0.218136 Batch F1: 0.0
Epoch:  422        4 Batch loss: 0.275458 Batch F1: 0.07142857142857142
Epoch:  422        5 Batch loss: 0.216564 Batch F1: 0.5217391304347826
Epoch:  422        6 Batch loss: 0.212626 Batch F1: 0.42857142857142855
Epoch:  422        7 Batch loss: 0.233909 Batch F1: 0.3333333333333333
Epoch:  422        8 Batch loss: 0.209303 Batch F1: 0.2857142857142857
Epoch:  422        9 Batch loss: 0.230380 Batch F1: 0.0
Epoch:  422       10 Batch loss: 0.236351 Batch F1: 0.0909090909090909
Epoch:  422       11 Batch loss: 0.219724 Batch F1: 0.0
Epoch:  422       12 Batch loss: 0.227550 Batch F1: 0.0
Train Avg Loss  422: 0.224853

Train Avg F1  422: 0.19792104031234461

Val Avg Loss  422: 0.218107

Val Avg F1  422:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 423
--------------------------------------------------------------
Epoch:  423        1 Batch loss: 0.204993 Batch F1: 0.1111111111111111
Epoch:  423        2 Batch loss: 0.205782 Batch F1: 0.0
Epoch:  423        3 Batch loss: 0.207210 Batch F1: 0.0
Epoch:  423        4 Batch loss: 0.235415 Batch F1: 0.0
Epoch:  423        5 Batch loss: 0.225949 Batch F1: 0.0
Epoch:  423        6 Batch loss: 0.229125 Batch F1: 0.0
Epoch:  423        7 Batch loss: 0.218982 Batch F1: 0.0
Epoch:  423        8 Batch loss: 0.213112 Batch F1: 0.0
Epoch:  423        9 Batch loss: 0.234690 Batch F1: 0.0
Epoch:  423       10 Batch loss: 0.234088 Batch F1: 0.0909090909090909
Epoch:  423       11 Batch loss: 0.236514 Batch F1: 0.4666666666666667
Epoch:  423       12 Batch loss: 0.225847 Batch F1: 0.4166666666666667
Train Avg Loss  423: 0.222642

Train Avg F1  423: 0.09044612794612794

Val Avg Loss  423: 0.220626

Val Avg F1  423:  0.33022210699161697

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 424
--------------------------------------------------------------
Epoch:  424        1 Batch loss: 0.234312 Batch F1: 0.16666666666666666
Epoch:  424        2 Batch loss: 0.187243 Batch F1: 0.37499999999999994
Epoch:  424        3 Batch loss: 0.257574 Batch F1: 0.20689655172413793
Epoch:  424        4 Batch loss: 0.212576 Batch F1: 0.43478260869565216
Epoch:  424        5 Batch loss: 0.227956 Batch F1: 0.0
Epoch:  424        6 Batch loss: 0.200353 Batch F1: 0.0
Epoch:  424        7 Batch loss: 0.245769 Batch F1: 0.0
Epoch:  424        8 Batch loss: 0.232393 Batch F1: 0.0
Epoch:  424        9 Batch loss: 0.210830 Batch F1: 0.0
Epoch:  424       10 Batch loss: 0.222613 Batch F1: 0.30769230769230765
Epoch:  424       11 Batch loss: 0.211725 Batch F1: 0.38461538461538464
Epoch:  424       12 Batch loss: 0.247732 Batch F1: 0.6060606060606061
Train Avg Loss  424: 0.224256

Train Avg F1  424: 0.20680951045456294

Val Avg Loss  424: 0.225365

Val Avg F1  424:  0.31419729695591764

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 425
--------------------------------------------------------------
Epoch:  425        1 Batch loss: 0.202254 Batch F1: 0.5
Epoch:  425        2 Batch loss: 0.212577 Batch F1: 0.5806451612903226
Epoch:  425        3 Batch loss: 0.227637 Batch F1: 0.23076923076923075
Epoch:  425        4 Batch loss: 0.229742 Batch F1: 0.25
Epoch:  425        5 Batch loss: 0.226897 Batch F1: 0.27272727272727276
Epoch:  425        6 Batch loss: 0.210201 Batch F1: 0.0
Epoch:  425        7 Batch loss: 0.220305 Batch F1: 0.0
Epoch:  425        8 Batch loss: 0.221651 Batch F1: 0.0
Epoch:  425        9 Batch loss: 0.247860 Batch F1: 0.0
Epoch:  425       10 Batch loss: 0.238733 Batch F1: 0.0
Epoch:  425       11 Batch loss: 0.224287 Batch F1: 0.2727272727272727
Epoch:  425       12 Batch loss: 0.246977 Batch F1: 0.4516129032258065
Train Avg Loss  425: 0.225760

Train Avg F1  425: 0.21320682006165878

Val Avg Loss  425: 0.223628

Val Avg F1  425:  0.33685064935064934

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 426
--------------------------------------------------------------
Epoch:  426        1 Batch loss: 0.237802 Batch F1: 0.2608695652173913
Epoch:  426        2 Batch loss: 0.222798 Batch F1: 0.25
Epoch:  426        3 Batch loss: 0.195656 Batch F1: 0.0
Epoch:  426        4 Batch loss: 0.231627 Batch F1: 0.0
Epoch:  426        5 Batch loss: 0.215476 Batch F1: 0.0
Epoch:  426        6 Batch loss: 0.264802 Batch F1: 0.0
Epoch:  426        7 Batch loss: 0.230772 Batch F1: 0.0
Epoch:  426        8 Batch loss: 0.224455 Batch F1: 0.0
Epoch:  426        9 Batch loss: 0.223025 Batch F1: 0.3846153846153846
Epoch:  426       10 Batch loss: 0.215731 Batch F1: 0.4444444444444444
Epoch:  426       11 Batch loss: 0.208709 Batch F1: 0.5925925925925926
Epoch:  426       12 Batch loss: 0.245647 Batch F1: 0.1904761904761905
Train Avg Loss  426: 0.226375

Train Avg F1  426: 0.17691651477883363

Val Avg Loss  426: 0.219633

Val Avg F1  426:  0.26722943722943726

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 427
--------------------------------------------------------------
Epoch:  427        1 Batch loss: 0.239205 Batch F1: 0.1739130434782609
Epoch:  427        2 Batch loss: 0.263439 Batch F1: 0.3225806451612903
Epoch:  427        3 Batch loss: 0.195942 Batch F1: 0.1904761904761905
Epoch:  427        4 Batch loss: 0.245916 Batch F1: 0.25
Epoch:  427        5 Batch loss: 0.201591 Batch F1: 0.2
Epoch:  427        6 Batch loss: 0.185642 Batch F1: 0.0
Epoch:  427        7 Batch loss: 0.216152 Batch F1: 0.11764705882352941
Epoch:  427        8 Batch loss: 0.227980 Batch F1: 0.0
Epoch:  427        9 Batch loss: 0.216844 Batch F1: 0.0
Epoch:  427       10 Batch loss: 0.243144 Batch F1: 0.0
Epoch:  427       11 Batch loss: 0.201566 Batch F1: 0.5333333333333333
Epoch:  427       12 Batch loss: 0.249331 Batch F1: 0.2
Train Avg Loss  427: 0.223896

Train Avg F1  427: 0.16566252260605036

Val Avg Loss  427: 0.221659

Val Avg F1  427:  0.3193019943019943

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 428
--------------------------------------------------------------
Epoch:  428        1 Batch loss: 0.235634 Batch F1: 0.4864864864864865
Epoch:  428        2 Batch loss: 0.245040 Batch F1: 0.23999999999999996
Epoch:  428        3 Batch loss: 0.250600 Batch F1: 0.37037037037037035
Epoch:  428        4 Batch loss: 0.243291 Batch F1: 0.3076923076923077
Epoch:  428        5 Batch loss: 0.197321 Batch F1: 0.5833333333333334
Epoch:  428        6 Batch loss: 0.203557 Batch F1: 0.4615384615384615
Epoch:  428        7 Batch loss: 0.211478 Batch F1: 0.0
Epoch:  428        8 Batch loss: 0.206952 Batch F1: 0.0
Epoch:  428        9 Batch loss: 0.233125 Batch F1: 0.0
Epoch:  428       10 Batch loss: 0.205522 Batch F1: 0.0
Epoch:  428       11 Batch loss: 0.240281 Batch F1: 0.0
Epoch:  428       12 Batch loss: 0.239381 Batch F1: 0.0
Train Avg Loss  428: 0.226015

Train Avg F1  428: 0.20411841328507996

Val Avg Loss  428: 0.223005

Val Avg F1  428:  0.27212732919254656

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 429
--------------------------------------------------------------
Epoch:  429        1 Batch loss: 0.243405 Batch F1: 0.35294117647058826
Epoch:  429        2 Batch loss: 0.225705 Batch F1: 0.4666666666666666
Epoch:  429        3 Batch loss: 0.217921 Batch F1: 0.5000000000000001
Epoch:  429        4 Batch loss: 0.261572 Batch F1: 0.25806451612903225
Epoch:  429        5 Batch loss: 0.236002 Batch F1: 0.5185185185185185
Epoch:  429        6 Batch loss: 0.205509 Batch F1: 0.3333333333333333
Epoch:  429        7 Batch loss: 0.218764 Batch F1: 0.0
Epoch:  429        8 Batch loss: 0.212984 Batch F1: 0.0
Epoch:  429        9 Batch loss: 0.245614 Batch F1: 0.0
Epoch:  429       10 Batch loss: 0.283892 Batch F1: 0.0
Epoch:  429       11 Batch loss: 0.187317 Batch F1: 0.0
Epoch:  429       12 Batch loss: 0.227395 Batch F1: 0.0
Train Avg Loss  429: 0.230507

Train Avg F1  429: 0.2024603509265116

Val Avg Loss  429: 0.219016

Val Avg F1  429:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 430
--------------------------------------------------------------
Epoch:  430        1 Batch loss: 0.202663 Batch F1: 0.0
Epoch:  430        2 Batch loss: 0.239608 Batch F1: 0.0
Epoch:  430        3 Batch loss: 0.221965 Batch F1: 0.0
Epoch:  430        4 Batch loss: 0.223161 Batch F1: 0.35714285714285715
Epoch:  430        5 Batch loss: 0.210746 Batch F1: 0.33333333333333337
Epoch:  430        6 Batch loss: 0.231089 Batch F1: 0.24000000000000005
Epoch:  430        7 Batch loss: 0.239848 Batch F1: 0.0
Epoch:  430        8 Batch loss: 0.234595 Batch F1: 0.0
Epoch:  430        9 Batch loss: 0.220657 Batch F1: 0.0
Epoch:  430       10 Batch loss: 0.205683 Batch F1: 0.0
Epoch:  430       11 Batch loss: 0.224256 Batch F1: 0.0
Epoch:  430       12 Batch loss: 0.261466 Batch F1: 0.0
Train Avg Loss  430: 0.226311

Train Avg F1  430: 0.07753968253968253

Val Avg Loss  430: 0.218273

Val Avg F1  430:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 431
--------------------------------------------------------------
Epoch:  431        1 Batch loss: 0.216208 Batch F1: 0.0
Epoch:  431        2 Batch loss: 0.201220 Batch F1: 0.0
Epoch:  431        3 Batch loss: 0.276472 Batch F1: 0.0
Epoch:  431        4 Batch loss: 0.222310 Batch F1: 0.0
Epoch:  431        5 Batch loss: 0.204074 Batch F1: 0.36363636363636365
Epoch:  431        6 Batch loss: 0.240016 Batch F1: 0.0
Epoch:  431        7 Batch loss: 0.247926 Batch F1: 0.0
Epoch:  431        8 Batch loss: 0.226639 Batch F1: 0.10526315789473684
Epoch:  431        9 Batch loss: 0.218656 Batch F1: 0.24999999999999997
Epoch:  431       10 Batch loss: 0.209648 Batch F1: 0.0
Epoch:  431       11 Batch loss: 0.198706 Batch F1: 0.0
Epoch:  431       12 Batch loss: 0.232361 Batch F1: 0.0
Train Avg Loss  431: 0.224520

Train Avg F1  431: 0.05990829346092504

Val Avg Loss  431: 0.218136

Val Avg F1  431:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 432
--------------------------------------------------------------
Epoch:  432        1 Batch loss: 0.204633 Batch F1: 0.0
Epoch:  432        2 Batch loss: 0.249257 Batch F1: 0.0
Epoch:  432        3 Batch loss: 0.201865 Batch F1: 0.0
Epoch:  432        4 Batch loss: 0.181489 Batch F1: 0.0
Epoch:  432        5 Batch loss: 0.203071 Batch F1: 0.0
Epoch:  432        6 Batch loss: 0.245808 Batch F1: 0.0
Epoch:  432        7 Batch loss: 0.227127 Batch F1: 0.0
Epoch:  432        8 Batch loss: 0.255584 Batch F1: 0.0
Epoch:  432        9 Batch loss: 0.207973 Batch F1: 0.2666666666666667
Epoch:  432       10 Batch loss: 0.229464 Batch F1: 0.0
Epoch:  432       11 Batch loss: 0.223149 Batch F1: 0.4166666666666667
Epoch:  432       12 Batch loss: 0.251614 Batch F1: 0.3870967741935484
Train Avg Loss  432: 0.223419

Train Avg F1  432: 0.08920250896057347

Val Avg Loss  432: 0.221539

Val Avg F1  432:  0.23916666666666667

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 433
--------------------------------------------------------------
Epoch:  433        1 Batch loss: 0.211203 Batch F1: 0.5161290322580646
Epoch:  433        2 Batch loss: 0.245712 Batch F1: 0.47058823529411764
Epoch:  433        3 Batch loss: 0.246525 Batch F1: 0.28571428571428575
Epoch:  433        4 Batch loss: 0.229688 Batch F1: 0.5499999999999999
Epoch:  433        5 Batch loss: 0.206141 Batch F1: 0.5185185185185186
Epoch:  433        6 Batch loss: 0.194578 Batch F1: 0.5333333333333333
Epoch:  433        7 Batch loss: 0.210391 Batch F1: 0.34782608695652173
Epoch:  433        8 Batch loss: 0.233330 Batch F1: 0.4000000000000001
Epoch:  433        9 Batch loss: 0.252672 Batch F1: 0.4571428571428571
Epoch:  433       10 Batch loss: 0.228887 Batch F1: 0.24
Epoch:  433       11 Batch loss: 0.238138 Batch F1: 0.16666666666666669
Epoch:  433       12 Batch loss: 0.175296 Batch F1: 0.19999999999999998
Train Avg Loss  433: 0.222713

Train Avg F1  433: 0.39049325132369717

Val Avg Loss  433: 0.217688

Val Avg F1  433:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 434
--------------------------------------------------------------
Epoch:  434        1 Batch loss: 0.219693 Batch F1: 0.0
Epoch:  434        2 Batch loss: 0.180237 Batch F1: 0.0
Epoch:  434        3 Batch loss: 0.253841 Batch F1: 0.0
Epoch:  434        4 Batch loss: 0.228239 Batch F1: 0.0
Epoch:  434        5 Batch loss: 0.255725 Batch F1: 0.0
Epoch:  434        6 Batch loss: 0.202770 Batch F1: 0.0
Epoch:  434        7 Batch loss: 0.231097 Batch F1: 0.0
Epoch:  434        8 Batch loss: 0.254200 Batch F1: 0.0
Epoch:  434        9 Batch loss: 0.184091 Batch F1: 0.14285714285714288
Epoch:  434       10 Batch loss: 0.215333 Batch F1: 0.1904761904761905
Epoch:  434       11 Batch loss: 0.235077 Batch F1: 0.27586206896551724
Epoch:  434       12 Batch loss: 0.229646 Batch F1: 0.47619047619047616
Train Avg Loss  434: 0.224162

Train Avg F1  434: 0.09044882320744389

Val Avg Loss  434: 0.219733

Val Avg F1  434:  0.2562937062937063

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 435
--------------------------------------------------------------
Epoch:  435        1 Batch loss: 0.216450 Batch F1: 0.25
Epoch:  435        2 Batch loss: 0.240086 Batch F1: 0.25
Epoch:  435        3 Batch loss: 0.237005 Batch F1: 0.23076923076923075
Epoch:  435        4 Batch loss: 0.229058 Batch F1: 0.24999999999999997
Epoch:  435        5 Batch loss: 0.252942 Batch F1: 0.2962962962962963
Epoch:  435        6 Batch loss: 0.200395 Batch F1: 0.3157894736842105
Epoch:  435        7 Batch loss: 0.210343 Batch F1: 0.36363636363636365
Epoch:  435        8 Batch loss: 0.198003 Batch F1: 0.4166666666666667
Epoch:  435        9 Batch loss: 0.206322 Batch F1: 0.10526315789473684
Epoch:  435       10 Batch loss: 0.256192 Batch F1: 0.0
Epoch:  435       11 Batch loss: 0.207940 Batch F1: 0.09523809523809523
Epoch:  435       12 Batch loss: 0.218704 Batch F1: 0.11764705882352941
Train Avg Loss  435: 0.222787

Train Avg F1  435: 0.22427552858409414

Val Avg Loss  435: 0.219331

Val Avg F1  435:  0.23363095238095238

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 436
--------------------------------------------------------------
Epoch:  436        1 Batch loss: 0.243425 Batch F1: 0.4
Epoch:  436        2 Batch loss: 0.227047 Batch F1: 0.1818181818181818
Epoch:  436        3 Batch loss: 0.222704 Batch F1: 0.24
Epoch:  436        4 Batch loss: 0.197142 Batch F1: 0.47619047619047616
Epoch:  436        5 Batch loss: 0.211078 Batch F1: 0.3703703703703704
Epoch:  436        6 Batch loss: 0.214546 Batch F1: 0.4444444444444445
Epoch:  436        7 Batch loss: 0.201287 Batch F1: 0.36363636363636365
Epoch:  436        8 Batch loss: 0.222933 Batch F1: 0.5
Epoch:  436        9 Batch loss: 0.227481 Batch F1: 0.25
Epoch:  436       10 Batch loss: 0.230663 Batch F1: 0.08695652173913045
Epoch:  436       11 Batch loss: 0.240327 Batch F1: 0.16
Epoch:  436       12 Batch loss: 0.228765 Batch F1: 0.11764705882352941
Train Avg Loss  436: 0.222283

Train Avg F1  436: 0.29925528475187474

Val Avg Loss  436: 0.217856

Val Avg F1  436:  0.24978070175438596

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 437
--------------------------------------------------------------
Epoch:  437        1 Batch loss: 0.203673 Batch F1: 0.3636363636363636
Epoch:  437        2 Batch loss: 0.179692 Batch F1: 0.4
Epoch:  437        3 Batch loss: 0.247123 Batch F1: 0.08
Epoch:  437        4 Batch loss: 0.174952 Batch F1: 0.3529411764705882
Epoch:  437        5 Batch loss: 0.241492 Batch F1: 0.1739130434782609
Epoch:  437        6 Batch loss: 0.205582 Batch F1: 0.0
Epoch:  437        7 Batch loss: 0.228222 Batch F1: 0.0
Epoch:  437        8 Batch loss: 0.237504 Batch F1: 0.08
Epoch:  437        9 Batch loss: 0.205646 Batch F1: 0.10526315789473684
Epoch:  437       10 Batch loss: 0.265991 Batch F1: 0.14285714285714288
Epoch:  437       11 Batch loss: 0.244242 Batch F1: 0.2857142857142857
Epoch:  437       12 Batch loss: 0.227074 Batch F1: 0.4
Train Avg Loss  437: 0.221766

Train Avg F1  437: 0.19869376417094817

Val Avg Loss  437: 0.219827

Val Avg F1  437:  0.23894110275689223

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 438
--------------------------------------------------------------
Epoch:  438        1 Batch loss: 0.196796 Batch F1: 0.15384615384615385
Epoch:  438        2 Batch loss: 0.222375 Batch F1: 0.2962962962962963
Epoch:  438        3 Batch loss: 0.243813 Batch F1: 0.42424242424242425
Epoch:  438        4 Batch loss: 0.226027 Batch F1: 0.1818181818181818
Epoch:  438        5 Batch loss: 0.212846 Batch F1: 0.36363636363636365
Epoch:  438        6 Batch loss: 0.240989 Batch F1: 0.27586206896551724
Epoch:  438        7 Batch loss: 0.247942 Batch F1: 0.4
Epoch:  438        8 Batch loss: 0.195938 Batch F1: 0.36363636363636365
Epoch:  438        9 Batch loss: 0.249985 Batch F1: 0.2758620689655173
Epoch:  438       10 Batch loss: 0.213059 Batch F1: 0.38095238095238093
Epoch:  438       11 Batch loss: 0.216758 Batch F1: 0.24
Epoch:  438       12 Batch loss: 0.206864 Batch F1: 0.0
Train Avg Loss  438: 0.222783

Train Avg F1  438: 0.27967935852993325

Val Avg Loss  438: 0.217646

Val Avg F1  438:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 439
--------------------------------------------------------------
Epoch:  439        1 Batch loss: 0.225087 Batch F1: 0.09523809523809523
Epoch:  439        2 Batch loss: 0.256258 Batch F1: 0.0
Epoch:  439        3 Batch loss: 0.208033 Batch F1: 0.3
Epoch:  439        4 Batch loss: 0.219725 Batch F1: 0.32
Epoch:  439        5 Batch loss: 0.224770 Batch F1: 0.4347826086956522
Epoch:  439        6 Batch loss: 0.180846 Batch F1: 0.0
Epoch:  439        7 Batch loss: 0.234285 Batch F1: 0.0
Epoch:  439        8 Batch loss: 0.247047 Batch F1: 0.0
Epoch:  439        9 Batch loss: 0.222357 Batch F1: 0.0
Epoch:  439       10 Batch loss: 0.242349 Batch F1: 0.28571428571428575
Epoch:  439       11 Batch loss: 0.234622 Batch F1: 0.16000000000000003
Epoch:  439       12 Batch loss: 0.175717 Batch F1: 0.0
Train Avg Loss  439: 0.222591

Train Avg F1  439: 0.13297791580400276

Val Avg Loss  439: 0.219176

Val Avg F1  439:  0.25355072463768114

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 440
--------------------------------------------------------------
Epoch:  440        1 Batch loss: 0.230396 Batch F1: 0.3333333333333333
Epoch:  440        2 Batch loss: 0.237567 Batch F1: 0.08333333333333333
Epoch:  440        3 Batch loss: 0.213987 Batch F1: 0.2
Epoch:  440        4 Batch loss: 0.258935 Batch F1: 0.0909090909090909
Epoch:  440        5 Batch loss: 0.185605 Batch F1: 0.0
Epoch:  440        6 Batch loss: 0.198354 Batch F1: 0.0
Epoch:  440        7 Batch loss: 0.221008 Batch F1: 0.0
Epoch:  440        8 Batch loss: 0.201898 Batch F1: 0.4761904761904762
Epoch:  440        9 Batch loss: 0.228997 Batch F1: 0.1818181818181818
Epoch:  440       10 Batch loss: 0.217266 Batch F1: 0.3846153846153846
Epoch:  440       11 Batch loss: 0.235841 Batch F1: 0.24
Epoch:  440       12 Batch loss: 0.237019 Batch F1: 0.3846153846153846
Train Avg Loss  440: 0.222239

Train Avg F1  440: 0.1979012654012654

Val Avg Loss  440: 0.219946

Val Avg F1  440:  0.2339875201288245

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 441
--------------------------------------------------------------
Epoch:  441        1 Batch loss: 0.214921 Batch F1: 0.2962962962962963
Epoch:  441        2 Batch loss: 0.225928 Batch F1: 0.41379310344827586
Epoch:  441        3 Batch loss: 0.253595 Batch F1: 0.26666666666666666
Epoch:  441        4 Batch loss: 0.210906 Batch F1: 0.1111111111111111
Epoch:  441        5 Batch loss: 0.246457 Batch F1: 0.3125
Epoch:  441        6 Batch loss: 0.207267 Batch F1: 0.4347826086956522
Epoch:  441        7 Batch loss: 0.226349 Batch F1: 0.28571428571428575
Epoch:  441        8 Batch loss: 0.228965 Batch F1: 0.16666666666666666
Epoch:  441        9 Batch loss: 0.210581 Batch F1: 0.3809523809523809
Epoch:  441       10 Batch loss: 0.205739 Batch F1: 0.39999999999999997
Epoch:  441       11 Batch loss: 0.209255 Batch F1: 0.3846153846153846
Epoch:  441       12 Batch loss: 0.225198 Batch F1: 0.3157894736842105
Train Avg Loss  441: 0.222097

Train Avg F1  441: 0.3140739981542442

Val Avg Loss  441: 0.218521

Val Avg F1  441:  0.23335320074450508

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 442
--------------------------------------------------------------
Epoch:  442        1 Batch loss: 0.197701 Batch F1: 0.34782608695652173
Epoch:  442        2 Batch loss: 0.234077 Batch F1: 0.24999999999999997
Epoch:  442        3 Batch loss: 0.197654 Batch F1: 0.45454545454545453
Epoch:  442        4 Batch loss: 0.223151 Batch F1: 0.2608695652173913
Epoch:  442        5 Batch loss: 0.221119 Batch F1: 0.0
Epoch:  442        6 Batch loss: 0.208671 Batch F1: 0.2
Epoch:  442        7 Batch loss: 0.243221 Batch F1: 0.0
Epoch:  442        8 Batch loss: 0.199321 Batch F1: 0.0
Epoch:  442        9 Batch loss: 0.213343 Batch F1: 0.21052631578947367
Epoch:  442       10 Batch loss: 0.209068 Batch F1: 0.3478260869565218
Epoch:  442       11 Batch loss: 0.266885 Batch F1: 0.3125
Epoch:  442       12 Batch loss: 0.258110 Batch F1: 0.30769230769230765
Train Avg Loss  442: 0.222693

Train Avg F1  442: 0.22431548476313923

Val Avg Loss  442: 0.219103

Val Avg F1  442:  0.2492372234935164

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 443
--------------------------------------------------------------
Epoch:  443        1 Batch loss: 0.244259 Batch F1: 0.22222222222222224
Epoch:  443        2 Batch loss: 0.203947 Batch F1: 0.4800000000000001
Epoch:  443        3 Batch loss: 0.197366 Batch F1: 0.3478260869565218
Epoch:  443        4 Batch loss: 0.230270 Batch F1: 0.19047619047619047
Epoch:  443        5 Batch loss: 0.252202 Batch F1: 0.4
Epoch:  443        6 Batch loss: 0.270870 Batch F1: 0.13333333333333333
Epoch:  443        7 Batch loss: 0.203782 Batch F1: 0.3
Epoch:  443        8 Batch loss: 0.212079 Batch F1: 0.3870967741935484
Epoch:  443        9 Batch loss: 0.239722 Batch F1: 0.3333333333333333
Epoch:  443       10 Batch loss: 0.218345 Batch F1: 0.0
Epoch:  443       11 Batch loss: 0.194626 Batch F1: 0.45454545454545453
Epoch:  443       12 Batch loss: 0.189725 Batch F1: 0.5833333333333334
Train Avg Loss  443: 0.221433

Train Avg F1  443: 0.31934722736616145

Val Avg Loss  443: 0.218555

Val Avg F1  443:  0.27005772005772005

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 444
--------------------------------------------------------------
Epoch:  444        1 Batch loss: 0.235644 Batch F1: 0.2608695652173913
Epoch:  444        2 Batch loss: 0.220174 Batch F1: 0.39999999999999997
Epoch:  444        3 Batch loss: 0.247832 Batch F1: 0.27586206896551724
Epoch:  444        4 Batch loss: 0.201202 Batch F1: 0.4166666666666667
Epoch:  444        5 Batch loss: 0.244534 Batch F1: 0.0909090909090909
Epoch:  444        6 Batch loss: 0.212169 Batch F1: 0.4347826086956522
Epoch:  444        7 Batch loss: 0.174162 Batch F1: 0.125
Epoch:  444        8 Batch loss: 0.249928 Batch F1: 0.0
Epoch:  444        9 Batch loss: 0.190274 Batch F1: 0.0
Epoch:  444       10 Batch loss: 0.230334 Batch F1: 0.0
Epoch:  444       11 Batch loss: 0.240512 Batch F1: 0.0
Epoch:  444       12 Batch loss: 0.220154 Batch F1: 0.0
Train Avg Loss  444: 0.222243

Train Avg F1  444: 0.16700750003785983

Val Avg Loss  444: 0.218403

Val Avg F1  444:  0.2600250626566416

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 445
--------------------------------------------------------------
Epoch:  445        1 Batch loss: 0.230286 Batch F1: 0.2962962962962963
Epoch:  445        2 Batch loss: 0.189206 Batch F1: 0.26666666666666666
Epoch:  445        3 Batch loss: 0.252828 Batch F1: 0.23076923076923073
Epoch:  445        4 Batch loss: 0.200503 Batch F1: 0.22222222222222224
Epoch:  445        5 Batch loss: 0.244796 Batch F1: 0.16
Epoch:  445        6 Batch loss: 0.215541 Batch F1: 0.0
Epoch:  445        7 Batch loss: 0.231302 Batch F1: 0.24000000000000002
Epoch:  445        8 Batch loss: 0.233563 Batch F1: 0.4
Epoch:  445        9 Batch loss: 0.216854 Batch F1: 0.46153846153846156
Epoch:  445       10 Batch loss: 0.199923 Batch F1: 0.3333333333333333
Epoch:  445       11 Batch loss: 0.237479 Batch F1: 0.21428571428571427
Epoch:  445       12 Batch loss: 0.206368 Batch F1: 0.48
Train Avg Loss  445: 0.221554

Train Avg F1  445: 0.27542599375932714

Val Avg Loss  445: 0.219615

Val Avg F1  445:  0.3322829131652661

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 446
--------------------------------------------------------------
Epoch:  446        1 Batch loss: 0.249727 Batch F1: 0.4117647058823529
Epoch:  446        2 Batch loss: 0.212507 Batch F1: 0.38095238095238093
Epoch:  446        3 Batch loss: 0.208638 Batch F1: 0.4666666666666666
Epoch:  446        4 Batch loss: 0.188636 Batch F1: 0.6428571428571429
Epoch:  446        5 Batch loss: 0.249461 Batch F1: 0.3870967741935483
Epoch:  446        6 Batch loss: 0.215180 Batch F1: 0.36363636363636365
Epoch:  446        7 Batch loss: 0.213472 Batch F1: 0.19047619047619047
Epoch:  446        8 Batch loss: 0.241013 Batch F1: 0.35714285714285715
Epoch:  446        9 Batch loss: 0.213582 Batch F1: 0.0
Epoch:  446       10 Batch loss: 0.227803 Batch F1: 0.17391304347826084
Epoch:  446       11 Batch loss: 0.250134 Batch F1: 0.0
Epoch:  446       12 Batch loss: 0.204535 Batch F1: 0.25
Train Avg Loss  446: 0.222891

Train Avg F1  446: 0.302042177107147

Val Avg Loss  446: 0.218829

Val Avg F1  446:  0.2564673913043478

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 447
--------------------------------------------------------------
Epoch:  447        1 Batch loss: 0.233293 Batch F1: 0.37037037037037035
Epoch:  447        2 Batch loss: 0.222044 Batch F1: 0.1739130434782609
Epoch:  447        3 Batch loss: 0.237264 Batch F1: 0.3225806451612903
Epoch:  447        4 Batch loss: 0.200567 Batch F1: 0.10526315789473684
Epoch:  447        5 Batch loss: 0.238477 Batch F1: 0.3846153846153846
Epoch:  447        6 Batch loss: 0.206418 Batch F1: 0.5517241379310345
Epoch:  447        7 Batch loss: 0.225850 Batch F1: 0.27272727272727276
Epoch:  447        8 Batch loss: 0.219088 Batch F1: 0.10526315789473684
Epoch:  447        9 Batch loss: 0.197057 Batch F1: 0.0
Epoch:  447       10 Batch loss: 0.237438 Batch F1: 0.0
Epoch:  447       11 Batch loss: 0.208091 Batch F1: 0.0
Epoch:  447       12 Batch loss: 0.251693 Batch F1: 0.19047619047619047
Train Avg Loss  447: 0.223107

Train Avg F1  447: 0.20641111337910645

Val Avg Loss  447: 0.218411

Val Avg F1  447:  0.16103778467908902

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 448
--------------------------------------------------------------
Epoch:  448        1 Batch loss: 0.198136 Batch F1: 0.10526315789473685
Epoch:  448        2 Batch loss: 0.201842 Batch F1: 0.0
Epoch:  448        3 Batch loss: 0.239979 Batch F1: 0.0
Epoch:  448        4 Batch loss: 0.250955 Batch F1: 0.15384615384615383
Epoch:  448        5 Batch loss: 0.209852 Batch F1: 0.19047619047619047
Epoch:  448        6 Batch loss: 0.214869 Batch F1: 0.2727272727272727
Epoch:  448        7 Batch loss: 0.227690 Batch F1: 0.2962962962962963
Epoch:  448        8 Batch loss: 0.253185 Batch F1: 0.27586206896551724
Epoch:  448        9 Batch loss: 0.249022 Batch F1: 0.3225806451612903
Epoch:  448       10 Batch loss: 0.200025 Batch F1: 0.6153846153846154
Epoch:  448       11 Batch loss: 0.191284 Batch F1: 0.4
Epoch:  448       12 Batch loss: 0.236947 Batch F1: 0.3846153846153846
Train Avg Loss  448: 0.222815

Train Avg F1  448: 0.2514209821139548

Val Avg Loss  448: 0.219634

Val Avg F1  448:  0.24444627433757868

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 449
--------------------------------------------------------------
Epoch:  449        1 Batch loss: 0.186590 Batch F1: 0.4210526315789474
Epoch:  449        2 Batch loss: 0.188136 Batch F1: 0.125
Epoch:  449        3 Batch loss: 0.211223 Batch F1: 0.4375
Epoch:  449        4 Batch loss: 0.209850 Batch F1: 0.2
Epoch:  449        5 Batch loss: 0.282376 Batch F1: 0.28571428571428575
Epoch:  449        6 Batch loss: 0.282595 Batch F1: 0.33333333333333337
Epoch:  449        7 Batch loss: 0.166445 Batch F1: 0.3529411764705882
Epoch:  449        8 Batch loss: 0.243673 Batch F1: 0.4705882352941176
Epoch:  449        9 Batch loss: 0.192494 Batch F1: 0.13333333333333333
Epoch:  449       10 Batch loss: 0.244592 Batch F1: 0.37500000000000006
Epoch:  449       11 Batch loss: 0.203868 Batch F1: 0.21052631578947364
Epoch:  449       12 Batch loss: 0.256692 Batch F1: 0.1
Train Avg Loss  449: 0.222378

Train Avg F1  449: 0.2870824426261733

Val Avg Loss  449: 0.218546

Val Avg F1  449:  0.2455877616747182

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 450
--------------------------------------------------------------
Epoch:  450        1 Batch loss: 0.221136 Batch F1: 0.09523809523809525
Epoch:  450        2 Batch loss: 0.185328 Batch F1: 0.26666666666666666
Epoch:  450        3 Batch loss: 0.186705 Batch F1: 0.38095238095238093
Epoch:  450        4 Batch loss: 0.209235 Batch F1: 0.0
Epoch:  450        5 Batch loss: 0.236382 Batch F1: 0.1
Epoch:  450        6 Batch loss: 0.216985 Batch F1: 0.0
Epoch:  450        7 Batch loss: 0.203371 Batch F1: 0.0
Epoch:  450        8 Batch loss: 0.248870 Batch F1: 0.0
Epoch:  450        9 Batch loss: 0.217091 Batch F1: 0.0
Epoch:  450       10 Batch loss: 0.249844 Batch F1: 0.0
Epoch:  450       11 Batch loss: 0.232405 Batch F1: 0.0
Epoch:  450       12 Batch loss: 0.276493 Batch F1: 0.23076923076923075
Train Avg Loss  450: 0.223654

Train Avg F1  450: 0.08946886446886447

Val Avg Loss  450: 0.221997

Val Avg F1  450:  0.30509768009768007

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 451
--------------------------------------------------------------
Epoch:  451        1 Batch loss: 0.226063 Batch F1: 0.2222222222222222
Epoch:  451        2 Batch loss: 0.207372 Batch F1: 0.4800000000000001
Epoch:  451        3 Batch loss: 0.212457 Batch F1: 0.3478260869565218
Epoch:  451        4 Batch loss: 0.221675 Batch F1: 0.0
Epoch:  451        5 Batch loss: 0.207059 Batch F1: 0.0
Epoch:  451        6 Batch loss: 0.241750 Batch F1: 0.0
Epoch:  451        7 Batch loss: 0.238449 Batch F1: 0.09523809523809523
Epoch:  451        8 Batch loss: 0.244027 Batch F1: 0.3870967741935483
Epoch:  451        9 Batch loss: 0.203621 Batch F1: 0.5454545454545454
Epoch:  451       10 Batch loss: 0.235688 Batch F1: 0.15384615384615385
Epoch:  451       11 Batch loss: 0.237456 Batch F1: 0.37499999999999994
Epoch:  451       12 Batch loss: 0.216231 Batch F1: 0.4
Train Avg Loss  451: 0.224321

Train Avg F1  451: 0.2505569898259239

Val Avg Loss  451: 0.220282

Val Avg F1  451:  0.2499355290303566

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 452
--------------------------------------------------------------
Epoch:  452        1 Batch loss: 0.230911 Batch F1: 0.18181818181818182
Epoch:  452        2 Batch loss: 0.202897 Batch F1: 0.4347826086956522
Epoch:  452        3 Batch loss: 0.232936 Batch F1: 0.32
Epoch:  452        4 Batch loss: 0.247634 Batch F1: 0.16666666666666666
Epoch:  452        5 Batch loss: 0.209868 Batch F1: 0.4
Epoch:  452        6 Batch loss: 0.208544 Batch F1: 0.0
Epoch:  452        7 Batch loss: 0.223844 Batch F1: 0.0
Epoch:  452        8 Batch loss: 0.198685 Batch F1: 0.0
Epoch:  452        9 Batch loss: 0.220648 Batch F1: 0.0
Epoch:  452       10 Batch loss: 0.260629 Batch F1: 0.0
Epoch:  452       11 Batch loss: 0.211202 Batch F1: 0.09999999999999999
Epoch:  452       12 Batch loss: 0.248415 Batch F1: 0.35714285714285715
Train Avg Loss  452: 0.224684

Train Avg F1  452: 0.16336752619361317

Val Avg Loss  452: 0.222082

Val Avg F1  452:  0.26939946018893385

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 453
--------------------------------------------------------------
Epoch:  453        1 Batch loss: 0.218360 Batch F1: 0.5161290322580646
Epoch:  453        2 Batch loss: 0.236121 Batch F1: 0.3225806451612903
Epoch:  453        3 Batch loss: 0.225482 Batch F1: 0.1739130434782609
Epoch:  453        4 Batch loss: 0.233463 Batch F1: 0.1
Epoch:  453        5 Batch loss: 0.216560 Batch F1: 0.3
Epoch:  453        6 Batch loss: 0.204932 Batch F1: 0.3
Epoch:  453        7 Batch loss: 0.277494 Batch F1: 0.0
Epoch:  453        8 Batch loss: 0.228458 Batch F1: 0.0
Epoch:  453        9 Batch loss: 0.214273 Batch F1: 0.4166666666666667
Epoch:  453       10 Batch loss: 0.224181 Batch F1: 0.2857142857142857
Epoch:  453       11 Batch loss: 0.202008 Batch F1: 0.3333333333333333
Epoch:  453       12 Batch loss: 0.202707 Batch F1: 0.23529411764705885
Train Avg Loss  453: 0.223670

Train Avg F1  453: 0.24863592702158008

Val Avg Loss  453: 0.220021

Val Avg F1  453:  0.25165782493368705

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 454
--------------------------------------------------------------
Epoch:  454        1 Batch loss: 0.220727 Batch F1: 0.1739130434782609
Epoch:  454        2 Batch loss: 0.200067 Batch F1: 0.3333333333333333
Epoch:  454        3 Batch loss: 0.217144 Batch F1: 0.21052631578947367
Epoch:  454        4 Batch loss: 0.247957 Batch F1: 0.08695652173913043
Epoch:  454        5 Batch loss: 0.259108 Batch F1: 0.0
Epoch:  454        6 Batch loss: 0.220939 Batch F1: 0.09090909090909091
Epoch:  454        7 Batch loss: 0.230403 Batch F1: 0.1739130434782609
Epoch:  454        8 Batch loss: 0.252723 Batch F1: 0.43750000000000006
Epoch:  454        9 Batch loss: 0.203438 Batch F1: 0.4
Epoch:  454       10 Batch loss: 0.201926 Batch F1: 0.3333333333333333
Epoch:  454       11 Batch loss: 0.211278 Batch F1: 0.33333333333333337
Epoch:  454       12 Batch loss: 0.205289 Batch F1: 0.14285714285714285
Train Avg Loss  454: 0.222583

Train Avg F1  454: 0.2263812631876133

Val Avg Loss  454: 0.219405

Val Avg F1  454:  0.24047619047619048

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 455
--------------------------------------------------------------
Epoch:  455        1 Batch loss: 0.219742 Batch F1: 0.23999999999999996
Epoch:  455        2 Batch loss: 0.193736 Batch F1: 0.41666666666666663
Epoch:  455        3 Batch loss: 0.223414 Batch F1: 0.4
Epoch:  455        4 Batch loss: 0.240425 Batch F1: 0.46153846153846156
Epoch:  455        5 Batch loss: 0.203638 Batch F1: 0.3809523809523809
Epoch:  455        6 Batch loss: 0.233686 Batch F1: 0.0
Epoch:  455        7 Batch loss: 0.220126 Batch F1: 0.09090909090909091
Epoch:  455        8 Batch loss: 0.255646 Batch F1: 0.14814814814814814
Epoch:  455        9 Batch loss: 0.229293 Batch F1: 0.24
Epoch:  455       10 Batch loss: 0.215991 Batch F1: 0.09999999999999999
Epoch:  455       11 Batch loss: 0.204866 Batch F1: 0.3478260869565218
Epoch:  455       12 Batch loss: 0.241815 Batch F1: 0.3157894736842105
Train Avg Loss  455: 0.223532

Train Avg F1  455: 0.2618191924046234

Val Avg Loss  455: 0.218716

Val Avg F1  455:  0.2633458646616541

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 456
--------------------------------------------------------------
Epoch:  456        1 Batch loss: 0.217702 Batch F1: 0.3333333333333333
Epoch:  456        2 Batch loss: 0.240597 Batch F1: 0.09090909090909091
Epoch:  456        3 Batch loss: 0.206713 Batch F1: 0.0
Epoch:  456        4 Batch loss: 0.203255 Batch F1: 0.11764705882352941
Epoch:  456        5 Batch loss: 0.244375 Batch F1: 0.0
Epoch:  456        6 Batch loss: 0.237674 Batch F1: 0.0
Epoch:  456        7 Batch loss: 0.238704 Batch F1: 0.17391304347826086
Epoch:  456        8 Batch loss: 0.196043 Batch F1: 0.48
Epoch:  456        9 Batch loss: 0.195197 Batch F1: 0.0
Epoch:  456       10 Batch loss: 0.228434 Batch F1: 0.0
Epoch:  456       11 Batch loss: 0.195820 Batch F1: 0.0
Epoch:  456       12 Batch loss: 0.285348 Batch F1: 0.0
Train Avg Loss  456: 0.224155

Train Avg F1  456: 0.09965021054535121

Val Avg Loss  456: 0.218468

Val Avg F1  456:  0.24810667974283537

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 457
--------------------------------------------------------------
Epoch:  457        1 Batch loss: 0.208857 Batch F1: 0.2222222222222222
Epoch:  457        2 Batch loss: 0.253171 Batch F1: 0.0
Epoch:  457        3 Batch loss: 0.201517 Batch F1: 0.23529411764705882
Epoch:  457        4 Batch loss: 0.170094 Batch F1: 0.26666666666666666
Epoch:  457        5 Batch loss: 0.263356 Batch F1: 0.16
Epoch:  457        6 Batch loss: 0.234363 Batch F1: 0.5
Epoch:  457        7 Batch loss: 0.206702 Batch F1: 0.3
Epoch:  457        8 Batch loss: 0.231793 Batch F1: 0.0
Epoch:  457        9 Batch loss: 0.254881 Batch F1: 0.0
Epoch:  457       10 Batch loss: 0.187464 Batch F1: 0.13333333333333333
Epoch:  457       11 Batch loss: 0.235207 Batch F1: 0.42857142857142855
Epoch:  457       12 Batch loss: 0.231000 Batch F1: 0.2727272727272727
Train Avg Loss  457: 0.223200

Train Avg F1  457: 0.20990125343066515

Val Avg Loss  457: 0.218763

Val Avg F1  457:  0.24497756091683984

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 458
--------------------------------------------------------------
Epoch:  458        1 Batch loss: 0.227785 Batch F1: 0.09090909090909091
Epoch:  458        2 Batch loss: 0.198178 Batch F1: 0.46153846153846156
Epoch:  458        3 Batch loss: 0.194656 Batch F1: 0.2222222222222222
Epoch:  458        4 Batch loss: 0.247259 Batch F1: 0.37500000000000006
Epoch:  458        5 Batch loss: 0.211897 Batch F1: 0.3333333333333333
Epoch:  458        6 Batch loss: 0.198638 Batch F1: 0.28571428571428575
Epoch:  458        7 Batch loss: 0.240701 Batch F1: 0.2
Epoch:  458        8 Batch loss: 0.255035 Batch F1: 0.0
Epoch:  458        9 Batch loss: 0.205980 Batch F1: 0.0
Epoch:  458       10 Batch loss: 0.184372 Batch F1: 0.0
Epoch:  458       11 Batch loss: 0.284182 Batch F1: 0.0
Epoch:  458       12 Batch loss: 0.242580 Batch F1: 0.11764705882352941
Train Avg Loss  458: 0.224272

Train Avg F1  458: 0.17386370437841026

Val Avg Loss  458: 0.218568

Val Avg F1  458:  0.24838471713471713

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 459
--------------------------------------------------------------
Epoch:  459        1 Batch loss: 0.236707 Batch F1: 0.3333333333333333
Epoch:  459        2 Batch loss: 0.192881 Batch F1: 0.36363636363636365
Epoch:  459        3 Batch loss: 0.233750 Batch F1: 0.2222222222222222
Epoch:  459        4 Batch loss: 0.198742 Batch F1: 0.125
Epoch:  459        5 Batch loss: 0.236262 Batch F1: 0.4848484848484849
Epoch:  459        6 Batch loss: 0.206191 Batch F1: 0.1111111111111111
Epoch:  459        7 Batch loss: 0.210687 Batch F1: 0.2857142857142857
Epoch:  459        8 Batch loss: 0.228714 Batch F1: 0.39999999999999997
Epoch:  459        9 Batch loss: 0.239167 Batch F1: 0.4
Epoch:  459       10 Batch loss: 0.252885 Batch F1: 0.2
Epoch:  459       11 Batch loss: 0.211339 Batch F1: 0.4166666666666667
Epoch:  459       12 Batch loss: 0.219078 Batch F1: 0.28571428571428575
Train Avg Loss  459: 0.222200

Train Avg F1  459: 0.30235389610389607

Val Avg Loss  459: 0.220008

Val Avg F1  459:  0.2697802197802198

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 460
--------------------------------------------------------------
Epoch:  460        1 Batch loss: 0.200663 Batch F1: 0.2
Epoch:  460        2 Batch loss: 0.192195 Batch F1: 0.3846153846153846
Epoch:  460        3 Batch loss: 0.247200 Batch F1: 0.08
Epoch:  460        4 Batch loss: 0.198412 Batch F1: 0.25
Epoch:  460        5 Batch loss: 0.198412 Batch F1: 0.3636363636363636
Epoch:  460        6 Batch loss: 0.207748 Batch F1: 0.2
Epoch:  460        7 Batch loss: 0.225791 Batch F1: 0.0
Epoch:  460        8 Batch loss: 0.248917 Batch F1: 0.0
Epoch:  460        9 Batch loss: 0.210894 Batch F1: 0.09523809523809525
Epoch:  460       10 Batch loss: 0.227310 Batch F1: 0.08333333333333333
Epoch:  460       11 Batch loss: 0.275372 Batch F1: 0.20689655172413793
Epoch:  460       12 Batch loss: 0.236035 Batch F1: 0.3
Train Avg Loss  460: 0.222412

Train Avg F1  460: 0.18030997737894286

Val Avg Loss  460: 0.219319

Val Avg F1  460:  0.2500841750841751

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 461
--------------------------------------------------------------
Epoch:  461        1 Batch loss: 0.224894 Batch F1: 0.37037037037037035
Epoch:  461        2 Batch loss: 0.181005 Batch F1: 0.26666666666666666
Epoch:  461        3 Batch loss: 0.229934 Batch F1: 0.45161290322580644
Epoch:  461        4 Batch loss: 0.235924 Batch F1: 0.24
Epoch:  461        5 Batch loss: 0.209615 Batch F1: 0.46153846153846156
Epoch:  461        6 Batch loss: 0.213663 Batch F1: 0.2
Epoch:  461        7 Batch loss: 0.246155 Batch F1: 0.2962962962962963
Epoch:  461        8 Batch loss: 0.237868 Batch F1: 0.1818181818181818
Epoch:  461        9 Batch loss: 0.195616 Batch F1: 0.47619047619047616
Epoch:  461       10 Batch loss: 0.209558 Batch F1: 0.3
Epoch:  461       11 Batch loss: 0.232361 Batch F1: 0.0
Epoch:  461       12 Batch loss: 0.268541 Batch F1: 0.16
Train Avg Loss  461: 0.223761

Train Avg F1  461: 0.28370777967552163

Val Avg Loss  461: 0.219616

Val Avg F1  461:  0.2331709962012458

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 462
--------------------------------------------------------------
Epoch:  462        1 Batch loss: 0.220884 Batch F1: 0.2608695652173913
Epoch:  462        2 Batch loss: 0.222430 Batch F1: 0.5
Epoch:  462        3 Batch loss: 0.216550 Batch F1: 0.5161290322580646
Epoch:  462        4 Batch loss: 0.213877 Batch F1: 0.5217391304347827
Epoch:  462        5 Batch loss: 0.219508 Batch F1: 0.37037037037037035
Epoch:  462        6 Batch loss: 0.234384 Batch F1: 0.4
Epoch:  462        7 Batch loss: 0.197961 Batch F1: 0.5
Epoch:  462        8 Batch loss: 0.228835 Batch F1: 0.25
Epoch:  462        9 Batch loss: 0.200786 Batch F1: 0.3333333333333333
Epoch:  462       10 Batch loss: 0.238357 Batch F1: 0.3076923076923077
Epoch:  462       11 Batch loss: 0.220003 Batch F1: 0.18181818181818182
Epoch:  462       12 Batch loss: 0.271475 Batch F1: 0.0
Train Avg Loss  462: 0.223754

Train Avg F1  462: 0.3451626600937026

Val Avg Loss  462: 0.218181

Val Avg F1  462:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 463
--------------------------------------------------------------
Epoch:  463        1 Batch loss: 0.202807 Batch F1: 0.0
Epoch:  463        2 Batch loss: 0.184028 Batch F1: 0.0
Epoch:  463        3 Batch loss: 0.196098 Batch F1: 0.0
Epoch:  463        4 Batch loss: 0.236667 Batch F1: 0.0
Epoch:  463        5 Batch loss: 0.234537 Batch F1: 0.1
Epoch:  463        6 Batch loss: 0.208909 Batch F1: 0.0
Epoch:  463        7 Batch loss: 0.208871 Batch F1: 0.09999999999999999
Epoch:  463        8 Batch loss: 0.245768 Batch F1: 0.32
Epoch:  463        9 Batch loss: 0.231091 Batch F1: 0.37037037037037035
Epoch:  463       10 Batch loss: 0.245985 Batch F1: 0.21428571428571425
Epoch:  463       11 Batch loss: 0.253286 Batch F1: 0.14285714285714285
Epoch:  463       12 Batch loss: 0.211251 Batch F1: 0.4761904761904762
Train Avg Loss  463: 0.221608

Train Avg F1  463: 0.14364197530864198

Val Avg Loss  463: 0.221766

Val Avg F1  463:  0.3055161684193942

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 464
--------------------------------------------------------------
Epoch:  464        1 Batch loss: 0.213656 Batch F1: 0.5294117647058824
Epoch:  464        2 Batch loss: 0.242801 Batch F1: 0.45161290322580644
Epoch:  464        3 Batch loss: 0.221145 Batch F1: 0.48
Epoch:  464        4 Batch loss: 0.239869 Batch F1: 0.21428571428571427
Epoch:  464        5 Batch loss: 0.226673 Batch F1: 0.2608695652173913
Epoch:  464        6 Batch loss: 0.218158 Batch F1: 0.0
Epoch:  464        7 Batch loss: 0.234366 Batch F1: 0.23076923076923073
Epoch:  464        8 Batch loss: 0.239575 Batch F1: 0.23076923076923078
Epoch:  464        9 Batch loss: 0.193613 Batch F1: 0.22222222222222224
Epoch:  464       10 Batch loss: 0.206772 Batch F1: 0.48
Epoch:  464       11 Batch loss: 0.210786 Batch F1: 0.38095238095238093
Epoch:  464       12 Batch loss: 0.217158 Batch F1: 0.21052631578947367
Train Avg Loss  464: 0.222048

Train Avg F1  464: 0.3076182773281111

Val Avg Loss  464: 0.217528

Val Avg F1  464:  0.2441325536062378

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 465
--------------------------------------------------------------
Epoch:  465        1 Batch loss: 0.218116 Batch F1: 0.3333333333333333
Epoch:  465        2 Batch loss: 0.256632 Batch F1: 0.24999999999999997
Epoch:  465        3 Batch loss: 0.231511 Batch F1: 0.2222222222222222
Epoch:  465        4 Batch loss: 0.217405 Batch F1: 0.125
Epoch:  465        5 Batch loss: 0.230986 Batch F1: 0.4666666666666667
Epoch:  465        6 Batch loss: 0.233722 Batch F1: 0.22222222222222224
Epoch:  465        7 Batch loss: 0.224473 Batch F1: 0.41379310344827586
Epoch:  465        8 Batch loss: 0.225176 Batch F1: 0.37499999999999994
Epoch:  465        9 Batch loss: 0.217333 Batch F1: 0.19047619047619044
Epoch:  465       10 Batch loss: 0.203166 Batch F1: 0.43478260869565216
Epoch:  465       11 Batch loss: 0.207568 Batch F1: 0.22222222222222224
Epoch:  465       12 Batch loss: 0.203973 Batch F1: 0.0
Train Avg Loss  465: 0.222505

Train Avg F1  465: 0.2713098807738988

Val Avg Loss  465: 0.218012

Val Avg F1  465:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 466
--------------------------------------------------------------
Epoch:  466        1 Batch loss: 0.249396 Batch F1: 0.0
Epoch:  466        2 Batch loss: 0.175873 Batch F1: 0.0
Epoch:  466        3 Batch loss: 0.230445 Batch F1: 0.0
Epoch:  466        4 Batch loss: 0.220766 Batch F1: 0.17391304347826086
Epoch:  466        5 Batch loss: 0.203389 Batch F1: 0.34782608695652173
Epoch:  466        6 Batch loss: 0.234463 Batch F1: 0.41379310344827586
Epoch:  466        7 Batch loss: 0.227054 Batch F1: 0.30769230769230765
Epoch:  466        8 Batch loss: 0.210283 Batch F1: 0.11764705882352941
Epoch:  466        9 Batch loss: 0.216358 Batch F1: 0.22222222222222224
Epoch:  466       10 Batch loss: 0.218741 Batch F1: 0.0
Epoch:  466       11 Batch loss: 0.239577 Batch F1: 0.0
Epoch:  466       12 Batch loss: 0.269938 Batch F1: 0.0
Train Avg Loss  466: 0.224690

Train Avg F1  466: 0.1319244852184265

Val Avg Loss  466: 0.218575

Val Avg F1  466:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 467
--------------------------------------------------------------
Epoch:  467        1 Batch loss: 0.281425 Batch F1: 0.0
Epoch:  467        2 Batch loss: 0.240426 Batch F1: 0.0
Epoch:  467        3 Batch loss: 0.212233 Batch F1: 0.5333333333333333
Epoch:  467        4 Batch loss: 0.238896 Batch F1: 0.3333333333333333
Epoch:  467        5 Batch loss: 0.234547 Batch F1: 0.35714285714285715
Epoch:  467        6 Batch loss: 0.222386 Batch F1: 0.1
Epoch:  467        7 Batch loss: 0.217616 Batch F1: 0.0
Epoch:  467        8 Batch loss: 0.226104 Batch F1: 0.0
Epoch:  467        9 Batch loss: 0.229511 Batch F1: 0.0
Epoch:  467       10 Batch loss: 0.203496 Batch F1: 0.0
Epoch:  467       11 Batch loss: 0.193914 Batch F1: 0.2222222222222222
Epoch:  467       12 Batch loss: 0.214162 Batch F1: 0.0
Train Avg Loss  467: 0.226226

Train Avg F1  467: 0.12883597883597886

Val Avg Loss  467: 0.218832

Val Avg F1  467:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 468
--------------------------------------------------------------
Epoch:  468        1 Batch loss: 0.216442 Batch F1: 0.0
Epoch:  468        2 Batch loss: 0.188930 Batch F1: 0.0
Epoch:  468        3 Batch loss: 0.264483 Batch F1: 0.0
Epoch:  468        4 Batch loss: 0.201766 Batch F1: 0.0
Epoch:  468        5 Batch loss: 0.244627 Batch F1: 0.0
Epoch:  468        6 Batch loss: 0.237209 Batch F1: 0.1739130434782609
Epoch:  468        7 Batch loss: 0.210249 Batch F1: 0.48
Epoch:  468        8 Batch loss: 0.212078 Batch F1: 0.5714285714285714
Epoch:  468        9 Batch loss: 0.247295 Batch F1: 0.5555555555555556
Epoch:  468       10 Batch loss: 0.245440 Batch F1: 0.4285714285714285
Epoch:  468       11 Batch loss: 0.216802 Batch F1: 0.2
Epoch:  468       12 Batch loss: 0.245351 Batch F1: 0.09090909090909091
Train Avg Loss  468: 0.227556

Train Avg F1  468: 0.2083648074952423

Val Avg Loss  468: 0.218359

Val Avg F1  468:  0.12512531328320803

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 469
--------------------------------------------------------------
Epoch:  469        1 Batch loss: 0.171559 Batch F1: 0.25
Epoch:  469        2 Batch loss: 0.256040 Batch F1: 0.0
Epoch:  469        3 Batch loss: 0.238223 Batch F1: 0.0
Epoch:  469        4 Batch loss: 0.204556 Batch F1: 0.0
Epoch:  469        5 Batch loss: 0.203797 Batch F1: 0.0
Epoch:  469        6 Batch loss: 0.193850 Batch F1: 0.0
Epoch:  469        7 Batch loss: 0.207648 Batch F1: 0.0
Epoch:  469        8 Batch loss: 0.254850 Batch F1: 0.0
Epoch:  469        9 Batch loss: 0.229339 Batch F1: 0.0
Epoch:  469       10 Batch loss: 0.249758 Batch F1: 0.0
Epoch:  469       11 Batch loss: 0.245362 Batch F1: 0.0
Epoch:  469       12 Batch loss: 0.239195 Batch F1: 0.39999999999999997
Train Avg Loss  469: 0.224515

Train Avg F1  469: 0.05416666666666666

Val Avg Loss  469: 0.229708

Val Avg F1  469:  0.3520289855072464

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 470
--------------------------------------------------------------
Epoch:  470        1 Batch loss: 0.236640 Batch F1: 0.4444444444444444
Epoch:  470        2 Batch loss: 0.246660 Batch F1: 0.5199999999999999
Epoch:  470        3 Batch loss: 0.267979 Batch F1: 0.4
Epoch:  470        4 Batch loss: 0.230953 Batch F1: 0.5128205128205129
Epoch:  470        5 Batch loss: 0.230309 Batch F1: 0.7428571428571429
Epoch:  470        6 Batch loss: 0.214630 Batch F1: 0.6
Epoch:  470        7 Batch loss: 0.244774 Batch F1: 0.08333333333333334
Epoch:  470        8 Batch loss: 0.211391 Batch F1: 0.31578947368421056
Epoch:  470        9 Batch loss: 0.193966 Batch F1: 0.0
Epoch:  470       10 Batch loss: 0.206641 Batch F1: 0.0
Epoch:  470       11 Batch loss: 0.216844 Batch F1: 0.0
Epoch:  470       12 Batch loss: 0.182885 Batch F1: 0.0
Train Avg Loss  470: 0.223639

Train Avg F1  470: 0.30160374226163705

Val Avg Loss  470: 0.218493

Val Avg F1  470:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 471
--------------------------------------------------------------
Epoch:  471        1 Batch loss: 0.299203 Batch F1: 0.0
Epoch:  471        2 Batch loss: 0.200299 Batch F1: 0.0
Epoch:  471        3 Batch loss: 0.260663 Batch F1: 0.0
Epoch:  471        4 Batch loss: 0.180578 Batch F1: 0.4
Epoch:  471        5 Batch loss: 0.208731 Batch F1: 0.10526315789473684
Epoch:  471        6 Batch loss: 0.265127 Batch F1: 0.0
Epoch:  471        7 Batch loss: 0.213961 Batch F1: 0.24999999999999997
Epoch:  471        8 Batch loss: 0.192364 Batch F1: 0.4761904761904762
Epoch:  471        9 Batch loss: 0.248804 Batch F1: 0.2962962962962963
Epoch:  471       10 Batch loss: 0.202100 Batch F1: 0.48
Epoch:  471       11 Batch loss: 0.214446 Batch F1: 0.19047619047619047
Epoch:  471       12 Batch loss: 0.213023 Batch F1: 0.3333333333333333
Train Avg Loss  471: 0.224941

Train Avg F1  471: 0.21096328784925278

Val Avg Loss  471: 0.218673

Val Avg F1  471:  0.2697326203208556

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 472
--------------------------------------------------------------
Epoch:  472        1 Batch loss: 0.286710 Batch F1: 0.21428571428571427
Epoch:  472        2 Batch loss: 0.203091 Batch F1: 0.2222222222222222
Epoch:  472        3 Batch loss: 0.212352 Batch F1: 0.32
Epoch:  472        4 Batch loss: 0.199670 Batch F1: 0.31999999999999995
Epoch:  472        5 Batch loss: 0.205166 Batch F1: 0.1111111111111111
Epoch:  472        6 Batch loss: 0.200032 Batch F1: 0.4166666666666667
Epoch:  472        7 Batch loss: 0.209134 Batch F1: 0.4
Epoch:  472        8 Batch loss: 0.229608 Batch F1: 0.32
Epoch:  472        9 Batch loss: 0.210798 Batch F1: 0.31999999999999995
Epoch:  472       10 Batch loss: 0.210126 Batch F1: 0.0
Epoch:  472       11 Batch loss: 0.260110 Batch F1: 0.26666666666666666
Epoch:  472       12 Batch loss: 0.248614 Batch F1: 0.23999999999999996
Train Avg Loss  472: 0.222951

Train Avg F1  472: 0.262579365079365

Val Avg Loss  472: 0.217866

Val Avg F1  472:  0.25903078319140027

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 473
--------------------------------------------------------------
Epoch:  473        1 Batch loss: 0.221987 Batch F1: 0.46153846153846156
Epoch:  473        2 Batch loss: 0.248170 Batch F1: 0.1818181818181818
Epoch:  473        3 Batch loss: 0.238619 Batch F1: 0.28571428571428575
Epoch:  473        4 Batch loss: 0.196371 Batch F1: 0.43478260869565216
Epoch:  473        5 Batch loss: 0.226641 Batch F1: 0.24
Epoch:  473        6 Batch loss: 0.224251 Batch F1: 0.29629629629629634
Epoch:  473        7 Batch loss: 0.197070 Batch F1: 0.34782608695652173
Epoch:  473        8 Batch loss: 0.210574 Batch F1: 0.2105263157894737
Epoch:  473        9 Batch loss: 0.224003 Batch F1: 0.5806451612903226
Epoch:  473       10 Batch loss: 0.208020 Batch F1: 0.24000000000000002
Epoch:  473       11 Batch loss: 0.238417 Batch F1: 0.25
Epoch:  473       12 Batch loss: 0.230952 Batch F1: 0.0
Train Avg Loss  473: 0.222090

Train Avg F1  473: 0.2940956165082663

Val Avg Loss  473: 0.219203

Val Avg F1  473:  0.24107085346215784

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 474
--------------------------------------------------------------
Epoch:  474        1 Batch loss: 0.194797 Batch F1: 0.5833333333333334
Epoch:  474        2 Batch loss: 0.270187 Batch F1: 0.30303030303030304
Epoch:  474        3 Batch loss: 0.212667 Batch F1: 0.1818181818181818
Epoch:  474        4 Batch loss: 0.179646 Batch F1: 0.3157894736842105
Epoch:  474        5 Batch loss: 0.215677 Batch F1: 0.5333333333333333
Epoch:  474        6 Batch loss: 0.209238 Batch F1: 0.18181818181818182
Epoch:  474        7 Batch loss: 0.251382 Batch F1: 0.16000000000000003
Epoch:  474        8 Batch loss: 0.209486 Batch F1: 0.4
Epoch:  474        9 Batch loss: 0.215046 Batch F1: 0.2727272727272727
Epoch:  474       10 Batch loss: 0.224090 Batch F1: 0.3333333333333333
Epoch:  474       11 Batch loss: 0.246099 Batch F1: 0.23076923076923073
Epoch:  474       12 Batch loss: 0.233721 Batch F1: 0.31578947368421056
Train Avg Loss  474: 0.221836

Train Avg F1  474: 0.31764517646096596

Val Avg Loss  474: 0.218726

Val Avg F1  474:  0.23305840031112263

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 475
--------------------------------------------------------------
Epoch:  475        1 Batch loss: 0.250248 Batch F1: 0.18181818181818182
Epoch:  475        2 Batch loss: 0.234886 Batch F1: 0.35714285714285715
Epoch:  475        3 Batch loss: 0.236767 Batch F1: 0.2857142857142857
Epoch:  475        4 Batch loss: 0.235004 Batch F1: 0.30769230769230765
Epoch:  475        5 Batch loss: 0.209819 Batch F1: 0.3076923076923077
Epoch:  475        6 Batch loss: 0.231677 Batch F1: 0.4571428571428571
Epoch:  475        7 Batch loss: 0.197179 Batch F1: 0.3157894736842105
Epoch:  475        8 Batch loss: 0.256459 Batch F1: 0.20689655172413793
Epoch:  475        9 Batch loss: 0.220295 Batch F1: 0.2857142857142857
Epoch:  475       10 Batch loss: 0.169861 Batch F1: 0.5454545454545455
Epoch:  475       11 Batch loss: 0.229755 Batch F1: 0.375
Epoch:  475       12 Batch loss: 0.182476 Batch F1: 0.16666666666666669
Train Avg Loss  475: 0.221202

Train Avg F1  475: 0.31606036003722027

Val Avg Loss  475: 0.218326

Val Avg F1  475:  0.25271739130434784

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 476
--------------------------------------------------------------
Epoch:  476        1 Batch loss: 0.221953 Batch F1: 0.16666666666666666
Epoch:  476        2 Batch loss: 0.214075 Batch F1: 0.2857142857142857
Epoch:  476        3 Batch loss: 0.233721 Batch F1: 0.32
Epoch:  476        4 Batch loss: 0.240271 Batch F1: 0.48648648648648646
Epoch:  476        5 Batch loss: 0.228098 Batch F1: 0.3846153846153846
Epoch:  476        6 Batch loss: 0.228533 Batch F1: 0.3846153846153846
Epoch:  476        7 Batch loss: 0.203567 Batch F1: 0.2105263157894737
Epoch:  476        8 Batch loss: 0.208252 Batch F1: 0.2
Epoch:  476        9 Batch loss: 0.217717 Batch F1: 0.2962962962962963
Epoch:  476       10 Batch loss: 0.229741 Batch F1: 0.42857142857142855
Epoch:  476       11 Batch loss: 0.208942 Batch F1: 0.19047619047619044
Epoch:  476       12 Batch loss: 0.229802 Batch F1: 0.1111111111111111
Train Avg Loss  476: 0.222056

Train Avg F1  476: 0.28875662919522566

Val Avg Loss  476: 0.218007

Val Avg F1  476:  0.23080180688876342

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 477
--------------------------------------------------------------
Epoch:  477        1 Batch loss: 0.244758 Batch F1: 0.33333333333333337
Epoch:  477        2 Batch loss: 0.266523 Batch F1: 0.3448275862068965
Epoch:  477        3 Batch loss: 0.235018 Batch F1: 0.35714285714285715
Epoch:  477        4 Batch loss: 0.223085 Batch F1: 0.24
Epoch:  477        5 Batch loss: 0.215164 Batch F1: 0.39999999999999997
Epoch:  477        6 Batch loss: 0.232294 Batch F1: 0.4666666666666667
Epoch:  477        7 Batch loss: 0.212580 Batch F1: 0.36363636363636365
Epoch:  477        8 Batch loss: 0.230815 Batch F1: 0.3478260869565218
Epoch:  477        9 Batch loss: 0.185936 Batch F1: 0.608695652173913
Epoch:  477       10 Batch loss: 0.172668 Batch F1: 0.25
Epoch:  477       11 Batch loss: 0.253905 Batch F1: 0.0
Epoch:  477       12 Batch loss: 0.201725 Batch F1: 0.0
Train Avg Loss  477: 0.222873

Train Avg F1  477: 0.3093440455097127

Val Avg Loss  477: 0.217783

Val Avg F1  477:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 478
--------------------------------------------------------------
Epoch:  478        1 Batch loss: 0.242227 Batch F1: 0.0
Epoch:  478        2 Batch loss: 0.242876 Batch F1: 0.0
Epoch:  478        3 Batch loss: 0.213038 Batch F1: 0.2857142857142857
Epoch:  478        4 Batch loss: 0.241845 Batch F1: 0.32000000000000006
Epoch:  478        5 Batch loss: 0.217693 Batch F1: 0.0
Epoch:  478        6 Batch loss: 0.181980 Batch F1: 0.15384615384615385
Epoch:  478        7 Batch loss: 0.246091 Batch F1: 0.0
Epoch:  478        8 Batch loss: 0.225779 Batch F1: 0.0
Epoch:  478        9 Batch loss: 0.229881 Batch F1: 0.0
Epoch:  478       10 Batch loss: 0.219558 Batch F1: 0.08333333333333333
Epoch:  478       11 Batch loss: 0.222654 Batch F1: 0.0
Epoch:  478       12 Batch loss: 0.209456 Batch F1: 0.0
Train Avg Loss  478: 0.224423

Train Avg F1  478: 0.07024114774114774

Val Avg Loss  478: 0.218412

Val Avg F1  478:  0.24891304347826088

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 479
--------------------------------------------------------------
Epoch:  479        1 Batch loss: 0.230874 Batch F1: 0.27272727272727276
Epoch:  479        2 Batch loss: 0.253015 Batch F1: 0.3888888888888889
Epoch:  479        3 Batch loss: 0.210312 Batch F1: 0.26086956521739124
Epoch:  479        4 Batch loss: 0.221432 Batch F1: 0.3703703703703704
Epoch:  479        5 Batch loss: 0.224750 Batch F1: 0.3333333333333333
Epoch:  479        6 Batch loss: 0.219873 Batch F1: 0.35714285714285715
Epoch:  479        7 Batch loss: 0.244534 Batch F1: 0.16666666666666669
Epoch:  479        8 Batch loss: 0.215359 Batch F1: 0.19047619047619047
Epoch:  479        9 Batch loss: 0.253666 Batch F1: 0.07692307692307693
Epoch:  479       10 Batch loss: 0.195037 Batch F1: 0.42105263157894735
Epoch:  479       11 Batch loss: 0.194629 Batch F1: 0.3333333333333333
Epoch:  479       12 Batch loss: 0.212280 Batch F1: 0.4444444444444445
Train Avg Loss  479: 0.222980

Train Avg F1  479: 0.3013523859252311

Val Avg Loss  479: 0.217749

Val Avg F1  479:  0.12535885167464114

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 480
--------------------------------------------------------------
Epoch:  480        1 Batch loss: 0.224039 Batch F1: 0.10526315789473684
Epoch:  480        2 Batch loss: 0.237233 Batch F1: 0.0
Epoch:  480        3 Batch loss: 0.235509 Batch F1: 0.0
Epoch:  480        4 Batch loss: 0.225419 Batch F1: 0.0
Epoch:  480        5 Batch loss: 0.246024 Batch F1: 0.0
Epoch:  480        6 Batch loss: 0.212618 Batch F1: 0.0
Epoch:  480        7 Batch loss: 0.219540 Batch F1: 0.1
Epoch:  480        8 Batch loss: 0.229768 Batch F1: 0.2962962962962963
Epoch:  480        9 Batch loss: 0.219884 Batch F1: 0.25
Epoch:  480       10 Batch loss: 0.230943 Batch F1: 0.35714285714285715
Epoch:  480       11 Batch loss: 0.207115 Batch F1: 0.43478260869565216
Epoch:  480       12 Batch loss: 0.188707 Batch F1: 0.0
Train Avg Loss  480: 0.223066

Train Avg F1  480: 0.1286237433357952

Val Avg Loss  480: 0.218563

Val Avg F1  480:  0.25865800865800864

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 481
--------------------------------------------------------------
Epoch:  481        1 Batch loss: 0.179000 Batch F1: 0.3529411764705882
Epoch:  481        2 Batch loss: 0.244835 Batch F1: 0.0
Epoch:  481        3 Batch loss: 0.224122 Batch F1: 0.0
Epoch:  481        4 Batch loss: 0.254927 Batch F1: 0.0
Epoch:  481        5 Batch loss: 0.212540 Batch F1: 0.0
Epoch:  481        6 Batch loss: 0.258389 Batch F1: 0.0
Epoch:  481        7 Batch loss: 0.194748 Batch F1: 0.0
Epoch:  481        8 Batch loss: 0.203740 Batch F1: 0.0
Epoch:  481        9 Batch loss: 0.252884 Batch F1: 0.0
Epoch:  481       10 Batch loss: 0.218479 Batch F1: 0.23076923076923078
Epoch:  481       11 Batch loss: 0.240502 Batch F1: 0.2608695652173913
Epoch:  481       12 Batch loss: 0.200474 Batch F1: 0.3333333333333333
Train Avg Loss  481: 0.223720

Train Avg F1  481: 0.09815944214921196

Val Avg Loss  481: 0.220123

Val Avg F1  481:  0.26297230848861286

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 482
--------------------------------------------------------------
Epoch:  482        1 Batch loss: 0.239608 Batch F1: 0.37037037037037035
Epoch:  482        2 Batch loss: 0.224404 Batch F1: 0.25
Epoch:  482        3 Batch loss: 0.236370 Batch F1: 0.4666666666666666
Epoch:  482        4 Batch loss: 0.204938 Batch F1: 0.3846153846153846
Epoch:  482        5 Batch loss: 0.189760 Batch F1: 0.3
Epoch:  482        6 Batch loss: 0.218347 Batch F1: 0.1904761904761905
Epoch:  482        7 Batch loss: 0.197803 Batch F1: 0.0
Epoch:  482        8 Batch loss: 0.254546 Batch F1: 0.0
Epoch:  482        9 Batch loss: 0.235415 Batch F1: 0.0
Epoch:  482       10 Batch loss: 0.212690 Batch F1: 0.27272727272727276
Epoch:  482       11 Batch loss: 0.236294 Batch F1: 0.21428571428571427
Epoch:  482       12 Batch loss: 0.227476 Batch F1: 0.39999999999999997
Train Avg Loss  482: 0.223138

Train Avg F1  482: 0.23742846659513328

Val Avg Loss  482: 0.219918

Val Avg F1  482:  0.2333109689499142

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 483
--------------------------------------------------------------
Epoch:  483        1 Batch loss: 0.187439 Batch F1: 0.2222222222222222
Epoch:  483        2 Batch loss: 0.240635 Batch F1: 0.32
Epoch:  483        3 Batch loss: 0.208764 Batch F1: 0.3809523809523809
Epoch:  483        4 Batch loss: 0.239852 Batch F1: 0.0
Epoch:  483        5 Batch loss: 0.223093 Batch F1: 0.0
Epoch:  483        6 Batch loss: 0.251453 Batch F1: 0.0
Epoch:  483        7 Batch loss: 0.226981 Batch F1: 0.0
Epoch:  483        8 Batch loss: 0.258350 Batch F1: 0.07692307692307693
Epoch:  483        9 Batch loss: 0.195717 Batch F1: 0.5217391304347827
Epoch:  483       10 Batch loss: 0.225017 Batch F1: 0.3333333333333333
Epoch:  483       11 Batch loss: 0.210857 Batch F1: 0.1904761904761905
Epoch:  483       12 Batch loss: 0.218722 Batch F1: 0.31578947368421056
Train Avg Loss  483: 0.223907

Train Avg F1  483: 0.19678631733551644

Val Avg Loss  483: 0.218396

Val Avg F1  483:  0.23277777777777778

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 484
--------------------------------------------------------------
Epoch:  484        1 Batch loss: 0.225471 Batch F1: 0.25
Epoch:  484        2 Batch loss: 0.207841 Batch F1: 0.3
Epoch:  484        3 Batch loss: 0.205748 Batch F1: 0.0
Epoch:  484        4 Batch loss: 0.224707 Batch F1: 0.0
Epoch:  484        5 Batch loss: 0.218509 Batch F1: 0.09523809523809523
Epoch:  484        6 Batch loss: 0.230678 Batch F1: 0.0
Epoch:  484        7 Batch loss: 0.241025 Batch F1: 0.0
Epoch:  484        8 Batch loss: 0.201972 Batch F1: 0.31578947368421056
Epoch:  484        9 Batch loss: 0.223411 Batch F1: 0.18181818181818182
Epoch:  484       10 Batch loss: 0.254193 Batch F1: 0.16
Epoch:  484       11 Batch loss: 0.233609 Batch F1: 0.3870967741935483
Epoch:  484       12 Batch loss: 0.211584 Batch F1: 0.38461538461538464
Train Avg Loss  484: 0.223229

Train Avg F1  484: 0.17287982579578506

Val Avg Loss  484: 0.224192

Val Avg F1  484:  0.327324973876698

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 485
--------------------------------------------------------------
Epoch:  485        1 Batch loss: 0.232721 Batch F1: 0.39999999999999997
Epoch:  485        2 Batch loss: 0.216883 Batch F1: 0.41379310344827586
Epoch:  485        3 Batch loss: 0.219006 Batch F1: 0.3333333333333333
Epoch:  485        4 Batch loss: 0.186545 Batch F1: 0.5925925925925926
Epoch:  485        5 Batch loss: 0.224585 Batch F1: 0.37037037037037035
Epoch:  485        6 Batch loss: 0.198912 Batch F1: 0.13333333333333336
Epoch:  485        7 Batch loss: 0.222251 Batch F1: 0.1904761904761905
Epoch:  485        8 Batch loss: 0.241498 Batch F1: 0.0909090909090909
Epoch:  485        9 Batch loss: 0.226925 Batch F1: 0.0
Epoch:  485       10 Batch loss: 0.249132 Batch F1: 0.0
Epoch:  485       11 Batch loss: 0.212264 Batch F1: 0.0
Epoch:  485       12 Batch loss: 0.237481 Batch F1: 0.16666666666666666
Train Avg Loss  485: 0.222350

Train Avg F1  485: 0.2242895567608211

Val Avg Loss  485: 0.218266

Val Avg F1  485:  0.13636363636363635

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 486
--------------------------------------------------------------
Epoch:  486        1 Batch loss: 0.261282 Batch F1: 0.14285714285714285
Epoch:  486        2 Batch loss: 0.265618 Batch F1: 0.3636363636363636
Epoch:  486        3 Batch loss: 0.166598 Batch F1: 0.4615384615384615
Epoch:  486        4 Batch loss: 0.214002 Batch F1: 0.11111111111111112
Epoch:  486        5 Batch loss: 0.187936 Batch F1: 0.5833333333333334
Epoch:  486        6 Batch loss: 0.245296 Batch F1: 0.36363636363636365
Epoch:  486        7 Batch loss: 0.220186 Batch F1: 0.1818181818181818
Epoch:  486        8 Batch loss: 0.216281 Batch F1: 0.1904761904761905
Epoch:  486        9 Batch loss: 0.215669 Batch F1: 0.18181818181818182
Epoch:  486       10 Batch loss: 0.223641 Batch F1: 0.2
Epoch:  486       11 Batch loss: 0.247098 Batch F1: 0.35714285714285715
Epoch:  486       12 Batch loss: 0.239163 Batch F1: 0.2608695652173913
Train Avg Loss  486: 0.225231

Train Avg F1  486: 0.28318647938213154

Val Avg Loss  486: 0.218429

Val Avg F1  486:  0.26096491228070173

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 487
--------------------------------------------------------------
Epoch:  487        1 Batch loss: 0.215848 Batch F1: 0.39999999999999997
Epoch:  487        2 Batch loss: 0.232538 Batch F1: 0.24999999999999997
Epoch:  487        3 Batch loss: 0.237602 Batch F1: 0.3448275862068965
Epoch:  487        4 Batch loss: 0.210981 Batch F1: 0.32
Epoch:  487        5 Batch loss: 0.216336 Batch F1: 0.27272727272727276
Epoch:  487        6 Batch loss: 0.228953 Batch F1: 0.41379310344827586
Epoch:  487        7 Batch loss: 0.267066 Batch F1: 0.2
Epoch:  487        8 Batch loss: 0.191681 Batch F1: 0.4210526315789473
Epoch:  487        9 Batch loss: 0.220332 Batch F1: 0.1
Epoch:  487       10 Batch loss: 0.225113 Batch F1: 0.1
Epoch:  487       11 Batch loss: 0.186457 Batch F1: 0.1111111111111111
Epoch:  487       12 Batch loss: 0.245522 Batch F1: 0.1111111111111111
Train Avg Loss  487: 0.223202

Train Avg F1  487: 0.2537185680153013

Val Avg Loss  487: 0.218093

Val Avg F1  487:  0.16666666666666669

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 488
--------------------------------------------------------------
Epoch:  488        1 Batch loss: 0.242436 Batch F1: 0.28571428571428575
Epoch:  488        2 Batch loss: 0.211660 Batch F1: 0.3809523809523809
Epoch:  488        3 Batch loss: 0.262907 Batch F1: 0.08333333333333333
Epoch:  488        4 Batch loss: 0.201717 Batch F1: 0.1111111111111111
Epoch:  488        5 Batch loss: 0.198260 Batch F1: 0.125
Epoch:  488        6 Batch loss: 0.217120 Batch F1: 0.0
Epoch:  488        7 Batch loss: 0.190616 Batch F1: 0.0
Epoch:  488        8 Batch loss: 0.222912 Batch F1: 0.0
Epoch:  488        9 Batch loss: 0.221959 Batch F1: 0.09523809523809523
Epoch:  488       10 Batch loss: 0.242988 Batch F1: 0.21428571428571427
Epoch:  488       11 Batch loss: 0.266032 Batch F1: 0.27586206896551724
Epoch:  488       12 Batch loss: 0.193203 Batch F1: 0.3529411764705882
Train Avg Loss  488: 0.222651

Train Avg F1  488: 0.1603698471725855

Val Avg Loss  488: 0.219427

Val Avg F1  488:  0.2589000638569604

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 489
--------------------------------------------------------------
Epoch:  489        1 Batch loss: 0.263168 Batch F1: 0.25806451612903225
Epoch:  489        2 Batch loss: 0.225403 Batch F1: 0.3846153846153846
Epoch:  489        3 Batch loss: 0.217438 Batch F1: 0.5517241379310346
Epoch:  489        4 Batch loss: 0.199533 Batch F1: 0.5185185185185185
Epoch:  489        5 Batch loss: 0.220007 Batch F1: 0.2608695652173913
Epoch:  489        6 Batch loss: 0.230554 Batch F1: 0.18181818181818182
Epoch:  489        7 Batch loss: 0.225860 Batch F1: 0.0
Epoch:  489        8 Batch loss: 0.204624 Batch F1: 0.0
Epoch:  489        9 Batch loss: 0.244004 Batch F1: 0.0
Epoch:  489       10 Batch loss: 0.202958 Batch F1: 0.0
Epoch:  489       11 Batch loss: 0.217375 Batch F1: 0.0
Epoch:  489       12 Batch loss: 0.229633 Batch F1: 0.2
Train Avg Loss  489: 0.223380

Train Avg F1  489: 0.19630085868579528

Val Avg Loss  489: 0.217898

Val Avg F1  489:  0.25757575757575757

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 490
--------------------------------------------------------------
Epoch:  490        1 Batch loss: 0.204500 Batch F1: 0.13333333333333336
Epoch:  490        2 Batch loss: 0.214394 Batch F1: 0.3
Epoch:  490        3 Batch loss: 0.252922 Batch F1: 0.0
Epoch:  490        4 Batch loss: 0.228408 Batch F1: 0.0909090909090909
Epoch:  490        5 Batch loss: 0.245707 Batch F1: 0.07692307692307693
Epoch:  490        6 Batch loss: 0.213634 Batch F1: 0.1904761904761905
Epoch:  490        7 Batch loss: 0.220149 Batch F1: 0.25
Epoch:  490        8 Batch loss: 0.244848 Batch F1: 0.21428571428571425
Epoch:  490        9 Batch loss: 0.208293 Batch F1: 0.3636363636363636
Epoch:  490       10 Batch loss: 0.197072 Batch F1: 0.34782608695652173
Epoch:  490       11 Batch loss: 0.234158 Batch F1: 0.37037037037037035
Epoch:  490       12 Batch loss: 0.205417 Batch F1: 0.4
Train Avg Loss  490: 0.222458

Train Avg F1  490: 0.2281466855742218

Val Avg Loss  490: 0.218318

Val Avg F1  490:  0.2428709734201725

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 491
--------------------------------------------------------------
Epoch:  491        1 Batch loss: 0.231412 Batch F1: 0.24999999999999997
Epoch:  491        2 Batch loss: 0.223782 Batch F1: 0.37037037037037035
Epoch:  491        3 Batch loss: 0.232438 Batch F1: 0.24
Epoch:  491        4 Batch loss: 0.218638 Batch F1: 0.5
Epoch:  491        5 Batch loss: 0.264095 Batch F1: 0.16666666666666666
Epoch:  491        6 Batch loss: 0.180987 Batch F1: 0.56
Epoch:  491        7 Batch loss: 0.222175 Batch F1: 0.41379310344827586
Epoch:  491        8 Batch loss: 0.243702 Batch F1: 0.3333333333333333
Epoch:  491        9 Batch loss: 0.201205 Batch F1: 0.4
Epoch:  491       10 Batch loss: 0.222954 Batch F1: 0.34782608695652173
Epoch:  491       11 Batch loss: 0.215095 Batch F1: 0.2
Epoch:  491       12 Batch loss: 0.206629 Batch F1: 0.0
Train Avg Loss  491: 0.221926

Train Avg F1  491: 0.315165796731264

Val Avg Loss  491: 0.217508

Val Avg F1  491:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 492
--------------------------------------------------------------
Epoch:  492        1 Batch loss: 0.206208 Batch F1: 0.0
Epoch:  492        2 Batch loss: 0.178281 Batch F1: 0.0
Epoch:  492        3 Batch loss: 0.228253 Batch F1: 0.0
Epoch:  492        4 Batch loss: 0.224447 Batch F1: 0.0
Epoch:  492        5 Batch loss: 0.259209 Batch F1: 0.0
Epoch:  492        6 Batch loss: 0.248478 Batch F1: 0.22222222222222224
Epoch:  492        7 Batch loss: 0.201044 Batch F1: 0.43478260869565216
Epoch:  492        8 Batch loss: 0.208026 Batch F1: 0.48275862068965514
Epoch:  492        9 Batch loss: 0.221349 Batch F1: 0.32
Epoch:  492       10 Batch loss: 0.254093 Batch F1: 0.2580645161290322
Epoch:  492       11 Batch loss: 0.229691 Batch F1: 0.2727272727272727
Epoch:  492       12 Batch loss: 0.232904 Batch F1: 0.21052631578947367
Train Avg Loss  492: 0.224332

Train Avg F1  492: 0.183423463021109

Val Avg Loss  492: 0.218021

Val Avg F1  492:  0.25018402649981597

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 493
--------------------------------------------------------------
Epoch:  493        1 Batch loss: 0.241787 Batch F1: 0.16666666666666666
Epoch:  493        2 Batch loss: 0.198963 Batch F1: 0.0
Epoch:  493        3 Batch loss: 0.213102 Batch F1: 0.0
Epoch:  493        4 Batch loss: 0.219636 Batch F1: 0.0
Epoch:  493        5 Batch loss: 0.208297 Batch F1: 0.0
Epoch:  493        6 Batch loss: 0.222194 Batch F1: 0.0
Epoch:  493        7 Batch loss: 0.201839 Batch F1: 0.0
Epoch:  493        8 Batch loss: 0.256414 Batch F1: 0.07407407407407407
Epoch:  493        9 Batch loss: 0.232633 Batch F1: 0.3333333333333333
Epoch:  493       10 Batch loss: 0.219044 Batch F1: 0.3846153846153846
Epoch:  493       11 Batch loss: 0.230337 Batch F1: 0.25
Epoch:  493       12 Batch loss: 0.254298 Batch F1: 0.0
Train Avg Loss  493: 0.224879

Train Avg F1  493: 0.10072412155745487

Val Avg Loss  493: 0.220621

Val Avg F1  493:  0.05

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 494
--------------------------------------------------------------
Epoch:  494        1 Batch loss: 0.221563 Batch F1: 0.0
Epoch:  494        2 Batch loss: 0.197035 Batch F1: 0.0
Epoch:  494        3 Batch loss: 0.222034 Batch F1: 0.1111111111111111
Epoch:  494        4 Batch loss: 0.267773 Batch F1: 0.0
Epoch:  494        5 Batch loss: 0.239255 Batch F1: 0.08695652173913045
Epoch:  494        6 Batch loss: 0.231079 Batch F1: 0.0
Epoch:  494        7 Batch loss: 0.240127 Batch F1: 0.1739130434782609
Epoch:  494        8 Batch loss: 0.196004 Batch F1: 0.6666666666666667
Epoch:  494        9 Batch loss: 0.234108 Batch F1: 0.4666666666666667
Epoch:  494       10 Batch loss: 0.200789 Batch F1: 0.3157894736842105
Epoch:  494       11 Batch loss: 0.220317 Batch F1: 0.31999999999999995
Epoch:  494       12 Batch loss: 0.221972 Batch F1: 0.2608695652173913
Train Avg Loss  494: 0.224338

Train Avg F1  494: 0.2001644207136198

Val Avg Loss  494: 0.218429

Val Avg F1  494:  0.2450153711023276

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 495
--------------------------------------------------------------
Epoch:  495        1 Batch loss: 0.190448 Batch F1: 0.36363636363636365
Epoch:  495        2 Batch loss: 0.200257 Batch F1: 0.2857142857142857
Epoch:  495        3 Batch loss: 0.236128 Batch F1: 0.24
Epoch:  495        4 Batch loss: 0.249595 Batch F1: 0.22222222222222218
Epoch:  495        5 Batch loss: 0.228480 Batch F1: 0.2727272727272727
Epoch:  495        6 Batch loss: 0.213639 Batch F1: 0.46153846153846156
Epoch:  495        7 Batch loss: 0.238714 Batch F1: 0.3870967741935483
Epoch:  495        8 Batch loss: 0.221072 Batch F1: 0.24
Epoch:  495        9 Batch loss: 0.209301 Batch F1: 0.4166666666666667
Epoch:  495       10 Batch loss: 0.230030 Batch F1: 0.3870967741935484
Epoch:  495       11 Batch loss: 0.232241 Batch F1: 0.15384615384615385
Epoch:  495       12 Batch loss: 0.221251 Batch F1: 0.0
Train Avg Loss  495: 0.222596

Train Avg F1  495: 0.2858787478948769

Val Avg Loss  495: 0.217084

Val Avg F1  495:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 496
--------------------------------------------------------------
Epoch:  496        1 Batch loss: 0.225386 Batch F1: 0.0
Epoch:  496        2 Batch loss: 0.234483 Batch F1: 0.0
Epoch:  496        3 Batch loss: 0.259034 Batch F1: 0.0
Epoch:  496        4 Batch loss: 0.174605 Batch F1: 0.0
Epoch:  496        5 Batch loss: 0.210800 Batch F1: 0.0
Epoch:  496        6 Batch loss: 0.243561 Batch F1: 0.0
Epoch:  496        7 Batch loss: 0.256081 Batch F1: 0.0
Epoch:  496        8 Batch loss: 0.214582 Batch F1: 0.09999999999999999
Epoch:  496        9 Batch loss: 0.241481 Batch F1: 0.26666666666666666
Epoch:  496       10 Batch loss: 0.228820 Batch F1: 0.37037037037037035
Epoch:  496       11 Batch loss: 0.193246 Batch F1: 0.5
Epoch:  496       12 Batch loss: 0.229587 Batch F1: 0.13333333333333333
Train Avg Loss  496: 0.225972

Train Avg F1  496: 0.11419753086419752

Val Avg Loss  496: 0.218370

Val Avg F1  496:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 497
--------------------------------------------------------------
Epoch:  497        1 Batch loss: 0.226328 Batch F1: 0.0
Epoch:  497        2 Batch loss: 0.255461 Batch F1: 0.0
Epoch:  497        3 Batch loss: 0.223097 Batch F1: 0.0
Epoch:  497        4 Batch loss: 0.227711 Batch F1: 0.0
Epoch:  497        5 Batch loss: 0.184620 Batch F1: 0.0
Epoch:  497        6 Batch loss: 0.213120 Batch F1: 0.0
Epoch:  497        7 Batch loss: 0.250848 Batch F1: 0.0
Epoch:  497        8 Batch loss: 0.259586 Batch F1: 0.26666666666666666
Epoch:  497        9 Batch loss: 0.199784 Batch F1: 0.125
Epoch:  497       10 Batch loss: 0.238212 Batch F1: 0.4242424242424242
Epoch:  497       11 Batch loss: 0.189587 Batch F1: 0.5384615384615384
Epoch:  497       12 Batch loss: 0.222713 Batch F1: 0.0
Train Avg Loss  497: 0.224256

Train Avg F1  497: 0.11286421911421911

Val Avg Loss  497: 0.218887

Val Avg F1  497:  0.25095154442980533

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 498
--------------------------------------------------------------
Epoch:  498        1 Batch loss: 0.231091 Batch F1: 0.41379310344827586
Epoch:  498        2 Batch loss: 0.205427 Batch F1: 0.2
Epoch:  498        3 Batch loss: 0.278729 Batch F1: 0.0
Epoch:  498        4 Batch loss: 0.212005 Batch F1: 0.0
Epoch:  498        5 Batch loss: 0.246393 Batch F1: 0.07692307692307693
Epoch:  498        6 Batch loss: 0.246590 Batch F1: 0.16666666666666666
Epoch:  498        7 Batch loss: 0.204148 Batch F1: 0.125
Epoch:  498        8 Batch loss: 0.212744 Batch F1: 0.4
Epoch:  498        9 Batch loss: 0.204572 Batch F1: 0.39999999999999997
Epoch:  498       10 Batch loss: 0.216720 Batch F1: 0.3636363636363636
Epoch:  498       11 Batch loss: 0.234494 Batch F1: 0.37037037037037035
Epoch:  498       12 Batch loss: 0.189293 Batch F1: 0.0
Train Avg Loss  498: 0.223517

Train Avg F1  498: 0.20969913175372945

Val Avg Loss  498: 0.217630

Val Avg F1  498:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 499
--------------------------------------------------------------
Epoch:  499        1 Batch loss: 0.181639 Batch F1: 0.0
Epoch:  499        2 Batch loss: 0.227737 Batch F1: 0.0
Epoch:  499        3 Batch loss: 0.298055 Batch F1: 0.0
Epoch:  499        4 Batch loss: 0.211152 Batch F1: 0.0
Epoch:  499        5 Batch loss: 0.192362 Batch F1: 0.0
Epoch:  499        6 Batch loss: 0.232555 Batch F1: 0.0
Epoch:  499        7 Batch loss: 0.219582 Batch F1: 0.0
Epoch:  499        8 Batch loss: 0.217224 Batch F1: 0.0
Epoch:  499        9 Batch loss: 0.209623 Batch F1: 0.0
Epoch:  499       10 Batch loss: 0.229884 Batch F1: 0.0
Epoch:  499       11 Batch loss: 0.228919 Batch F1: 0.0
Epoch:  499       12 Batch loss: 0.246174 Batch F1: 0.0
Train Avg Loss  499: 0.224576

Train Avg F1  499: 0.0

Val Avg Loss  499: 0.221777

Val Avg F1  499:  0.2347689075630252

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 500
--------------------------------------------------------------
Epoch:  500        1 Batch loss: 0.205026 Batch F1: 0.5217391304347826
Epoch:  500        2 Batch loss: 0.204273 Batch F1: 0.7058823529411765
Epoch:  500        3 Batch loss: 0.246817 Batch F1: 0.3448275862068966
Epoch:  500        4 Batch loss: 0.220128 Batch F1: 0.2105263157894737
Epoch:  500        5 Batch loss: 0.247957 Batch F1: 0.21428571428571427
Epoch:  500        6 Batch loss: 0.208481 Batch F1: 0.10526315789473684
Epoch:  500        7 Batch loss: 0.227445 Batch F1: 0.34782608695652173
Epoch:  500        8 Batch loss: 0.210356 Batch F1: 0.0
Epoch:  500        9 Batch loss: 0.223661 Batch F1: 0.4516129032258065
Epoch:  500       10 Batch loss: 0.197543 Batch F1: 0.125
Epoch:  500       11 Batch loss: 0.273916 Batch F1: 0.25806451612903225
Epoch:  500       12 Batch loss: 0.217373 Batch F1: 0.3636363636363636
Train Avg Loss  500: 0.223581

Train Avg F1  500: 0.3040553439583754

Val Avg Loss  500: 0.219500

Val Avg F1  500:  0.24724025974025976

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 501
--------------------------------------------------------------
Epoch:  501        1 Batch loss: 0.239870 Batch F1: 0.26666666666666666
Epoch:  501        2 Batch loss: 0.203606 Batch F1: 0.4615384615384615
Epoch:  501        3 Batch loss: 0.245548 Batch F1: 0.375
Epoch:  501        4 Batch loss: 0.242812 Batch F1: 0.3448275862068966
Epoch:  501        5 Batch loss: 0.193624 Batch F1: 0.4799999999999999
Epoch:  501        6 Batch loss: 0.210946 Batch F1: 0.2857142857142857
Epoch:  501        7 Batch loss: 0.251316 Batch F1: 0.14814814814814817
Epoch:  501        8 Batch loss: 0.196443 Batch F1: 0.4
Epoch:  501        9 Batch loss: 0.217002 Batch F1: 0.2608695652173913
Epoch:  501       10 Batch loss: 0.218354 Batch F1: 0.19999999999999998
Epoch:  501       11 Batch loss: 0.240472 Batch F1: 0.3448275862068965
Epoch:  501       12 Batch loss: 0.207722 Batch F1: 0.23529411764705882
Train Avg Loss  501: 0.222310

Train Avg F1  501: 0.3169072014454838

Val Avg Loss  501: 0.217295

Val Avg F1  501:  0.23965050967339296

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 502
--------------------------------------------------------------
Epoch:  502        1 Batch loss: 0.234432 Batch F1: 0.09999999999999999
Epoch:  502        2 Batch loss: 0.241565 Batch F1: 0.33333333333333337
Epoch:  502        3 Batch loss: 0.234598 Batch F1: 0.5714285714285714
Epoch:  502        4 Batch loss: 0.207098 Batch F1: 0.10526315789473684
Epoch:  502        5 Batch loss: 0.239259 Batch F1: 0.2857142857142857
Epoch:  502        6 Batch loss: 0.207223 Batch F1: 0.4827586206896552
Epoch:  502        7 Batch loss: 0.189121 Batch F1: 0.4800000000000001
Epoch:  502        8 Batch loss: 0.231199 Batch F1: 0.4999999999999999
Epoch:  502        9 Batch loss: 0.239549 Batch F1: 0.35714285714285715
Epoch:  502       10 Batch loss: 0.203142 Batch F1: 0.23529411764705885
Epoch:  502       11 Batch loss: 0.198108 Batch F1: 0.19047619047619044
Epoch:  502       12 Batch loss: 0.251149 Batch F1: 0.0
Train Avg Loss  502: 0.223037

Train Avg F1  502: 0.3034509278605574

Val Avg Loss  502: 0.218364

Val Avg F1  502:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 503
--------------------------------------------------------------
Epoch:  503        1 Batch loss: 0.201816 Batch F1: 0.0
Epoch:  503        2 Batch loss: 0.213719 Batch F1: 0.0
Epoch:  503        3 Batch loss: 0.216438 Batch F1: 0.0
Epoch:  503        4 Batch loss: 0.238375 Batch F1: 0.0
Epoch:  503        5 Batch loss: 0.283754 Batch F1: 0.0
Epoch:  503        6 Batch loss: 0.235208 Batch F1: 0.0
Epoch:  503        7 Batch loss: 0.231092 Batch F1: 0.0
Epoch:  503        8 Batch loss: 0.208154 Batch F1: 0.0
Epoch:  503        9 Batch loss: 0.218581 Batch F1: 0.0
Epoch:  503       10 Batch loss: 0.252261 Batch F1: 0.0
Epoch:  503       11 Batch loss: 0.207684 Batch F1: 0.0
Epoch:  503       12 Batch loss: 0.242417 Batch F1: 0.0
Train Avg Loss  503: 0.229125

Train Avg F1  503: 0.0

Val Avg Loss  503: 0.221369

Val Avg F1  503:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 504
--------------------------------------------------------------
Epoch:  504        1 Batch loss: 0.238670 Batch F1: 0.0909090909090909
Epoch:  504        2 Batch loss: 0.234486 Batch F1: 0.0909090909090909
Epoch:  504        3 Batch loss: 0.208110 Batch F1: 0.22222222222222224
Epoch:  504        4 Batch loss: 0.233038 Batch F1: 0.0
Epoch:  504        5 Batch loss: 0.211239 Batch F1: 0.1
Epoch:  504        6 Batch loss: 0.202231 Batch F1: 0.0
Epoch:  504        7 Batch loss: 0.200305 Batch F1: 0.0
Epoch:  504        8 Batch loss: 0.221266 Batch F1: 0.0
Epoch:  504        9 Batch loss: 0.196709 Batch F1: 0.0
Epoch:  504       10 Batch loss: 0.270724 Batch F1: 0.0
Epoch:  504       11 Batch loss: 0.238714 Batch F1: 0.0
Epoch:  504       12 Batch loss: 0.234398 Batch F1: 0.2
Train Avg Loss  504: 0.224157

Train Avg F1  504: 0.05867003367003367

Val Avg Loss  504: 0.219251

Val Avg F1  504:  0.2660714285714286

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 505
--------------------------------------------------------------
Epoch:  505        1 Batch loss: 0.232172 Batch F1: 0.1818181818181818
Epoch:  505        2 Batch loss: 0.224337 Batch F1: 0.23076923076923075
Epoch:  505        3 Batch loss: 0.239904 Batch F1: 0.2962962962962963
Epoch:  505        4 Batch loss: 0.203352 Batch F1: 0.36363636363636365
Epoch:  505        5 Batch loss: 0.205024 Batch F1: 0.3
Epoch:  505        6 Batch loss: 0.196677 Batch F1: 0.27272727272727276
Epoch:  505        7 Batch loss: 0.221315 Batch F1: 0.5161290322580644
Epoch:  505        8 Batch loss: 0.174581 Batch F1: 0.23529411764705882
Epoch:  505        9 Batch loss: 0.241902 Batch F1: 0.22222222222222218
Epoch:  505       10 Batch loss: 0.226693 Batch F1: 0.0
Epoch:  505       11 Batch loss: 0.256530 Batch F1: 0.26666666666666666
Epoch:  505       12 Batch loss: 0.260068 Batch F1: 0.09523809523809523
Train Avg Loss  505: 0.223546

Train Avg F1  505: 0.2483997899399544

Val Avg Loss  505: 0.219605

Val Avg F1  505:  0.18948412698412698

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 506
--------------------------------------------------------------
Epoch:  506        1 Batch loss: 0.223233 Batch F1: 0.2857142857142857
Epoch:  506        2 Batch loss: 0.220228 Batch F1: 0.5
Epoch:  506        3 Batch loss: 0.211689 Batch F1: 0.6111111111111112
Epoch:  506        4 Batch loss: 0.236545 Batch F1: 0.3703703703703703
Epoch:  506        5 Batch loss: 0.224222 Batch F1: 0.0
Epoch:  506        6 Batch loss: 0.248811 Batch F1: 0.0
Epoch:  506        7 Batch loss: 0.222835 Batch F1: 0.0
Epoch:  506        8 Batch loss: 0.213786 Batch F1: 0.0
Epoch:  506        9 Batch loss: 0.235260 Batch F1: 0.0
Epoch:  506       10 Batch loss: 0.223664 Batch F1: 0.0
Epoch:  506       11 Batch loss: 0.215821 Batch F1: 0.0
Epoch:  506       12 Batch loss: 0.210022 Batch F1: 0.0
Train Avg Loss  506: 0.223843

Train Avg F1  506: 0.1472663139329806

Val Avg Loss  506: 0.217281

Val Avg F1  506:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 507
--------------------------------------------------------------
Epoch:  507        1 Batch loss: 0.207764 Batch F1: 0.0
Epoch:  507        2 Batch loss: 0.157362 Batch F1: 0.0
Epoch:  507        3 Batch loss: 0.198681 Batch F1: 0.0
Epoch:  507        4 Batch loss: 0.206753 Batch F1: 0.0
Epoch:  507        5 Batch loss: 0.282496 Batch F1: 0.0
Epoch:  507        6 Batch loss: 0.261581 Batch F1: 0.0
Epoch:  507        7 Batch loss: 0.240146 Batch F1: 0.0
Epoch:  507        8 Batch loss: 0.233478 Batch F1: 0.0
Epoch:  507        9 Batch loss: 0.225537 Batch F1: 0.3846153846153846
Epoch:  507       10 Batch loss: 0.240165 Batch F1: 0.27586206896551724
Epoch:  507       11 Batch loss: 0.225062 Batch F1: 0.5
Epoch:  507       12 Batch loss: 0.215794 Batch F1: 0.6153846153846153
Train Avg Loss  507: 0.224568

Train Avg F1  507: 0.14798850574712644

Val Avg Loss  507: 0.223216

Val Avg F1  507:  0.3296387520525452

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 508
--------------------------------------------------------------
Epoch:  508        1 Batch loss: 0.234205 Batch F1: 0.37499999999999994
Epoch:  508        2 Batch loss: 0.211518 Batch F1: 0.3
Epoch:  508        3 Batch loss: 0.265433 Batch F1: 0.4
Epoch:  508        4 Batch loss: 0.197457 Batch F1: 0.36363636363636365
Epoch:  508        5 Batch loss: 0.234184 Batch F1: 0.2727272727272727
Epoch:  508        6 Batch loss: 0.224857 Batch F1: 0.1904761904761905
Epoch:  508        7 Batch loss: 0.195412 Batch F1: 0.0
Epoch:  508        8 Batch loss: 0.248344 Batch F1: 0.0
Epoch:  508        9 Batch loss: 0.230900 Batch F1: 0.2727272727272727
Epoch:  508       10 Batch loss: 0.220626 Batch F1: 0.2608695652173913
Epoch:  508       11 Batch loss: 0.215451 Batch F1: 0.3703703703703704
Epoch:  508       12 Batch loss: 0.196289 Batch F1: 0.26666666666666666
Train Avg Loss  508: 0.222890

Train Avg F1  508: 0.2560394751517939

Val Avg Loss  508: 0.219418

Val Avg F1  508:  0.24219329058038733

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 509
--------------------------------------------------------------
Epoch:  509        1 Batch loss: 0.251607 Batch F1: 0.35714285714285715
Epoch:  509        2 Batch loss: 0.206215 Batch F1: 0.0
Epoch:  509        3 Batch loss: 0.209502 Batch F1: 0.3333333333333333
Epoch:  509        4 Batch loss: 0.225185 Batch F1: 0.19047619047619044
Epoch:  509        5 Batch loss: 0.200794 Batch F1: 0.0
Epoch:  509        6 Batch loss: 0.239943 Batch F1: 0.08695652173913045
Epoch:  509        7 Batch loss: 0.210480 Batch F1: 0.2
Epoch:  509        8 Batch loss: 0.265956 Batch F1: 0.2666666666666667
Epoch:  509        9 Batch loss: 0.219350 Batch F1: 0.5333333333333333
Epoch:  509       10 Batch loss: 0.232756 Batch F1: 0.4705882352941177
Epoch:  509       11 Batch loss: 0.212779 Batch F1: 0.48000000000000004
Epoch:  509       12 Batch loss: 0.209585 Batch F1: 0.125
Train Avg Loss  509: 0.223679

Train Avg F1  509: 0.2536247614988024

Val Avg Loss  509: 0.218150

Val Avg F1  509:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 510
--------------------------------------------------------------
Epoch:  510        1 Batch loss: 0.258668 Batch F1: 0.0
Epoch:  510        2 Batch loss: 0.254277 Batch F1: 0.0
Epoch:  510        3 Batch loss: 0.214272 Batch F1: 0.0
Epoch:  510        4 Batch loss: 0.224943 Batch F1: 0.0
Epoch:  510        5 Batch loss: 0.235835 Batch F1: 0.0
Epoch:  510        6 Batch loss: 0.212321 Batch F1: 0.0
Epoch:  510        7 Batch loss: 0.186511 Batch F1: 0.0
Epoch:  510        8 Batch loss: 0.217591 Batch F1: 0.0
Epoch:  510        9 Batch loss: 0.210221 Batch F1: 0.0
Epoch:  510       10 Batch loss: 0.214292 Batch F1: 0.0
Epoch:  510       11 Batch loss: 0.238387 Batch F1: 0.08333333333333333
Epoch:  510       12 Batch loss: 0.210900 Batch F1: 0.23529411764705885
Train Avg Loss  510: 0.223185

Train Avg F1  510: 0.02655228758169935

Val Avg Loss  510: 0.218964

Val Avg F1  510:  0.272281679672984

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 511
--------------------------------------------------------------
Epoch:  511        1 Batch loss: 0.264517 Batch F1: 0.3225806451612903
Epoch:  511        2 Batch loss: 0.204244 Batch F1: 0.42857142857142855
Epoch:  511        3 Batch loss: 0.235028 Batch F1: 0.48275862068965514
Epoch:  511        4 Batch loss: 0.215318 Batch F1: 0.23076923076923078
Epoch:  511        5 Batch loss: 0.200980 Batch F1: 0.5
Epoch:  511        6 Batch loss: 0.240096 Batch F1: 0.41379310344827586
Epoch:  511        7 Batch loss: 0.183102 Batch F1: 0.3076923076923077
Epoch:  511        8 Batch loss: 0.239804 Batch F1: 0.1818181818181818
Epoch:  511        9 Batch loss: 0.217330 Batch F1: 0.09523809523809525
Epoch:  511       10 Batch loss: 0.243476 Batch F1: 0.0
Epoch:  511       11 Batch loss: 0.235390 Batch F1: 0.0
Epoch:  511       12 Batch loss: 0.193743 Batch F1: 0.0
Train Avg Loss  511: 0.222752

Train Avg F1  511: 0.2469351344490388

Val Avg Loss  511: 0.217768

Val Avg F1  511:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 512
--------------------------------------------------------------
Epoch:  512        1 Batch loss: 0.204617 Batch F1: 0.0
Epoch:  512        2 Batch loss: 0.208840 Batch F1: 0.3333333333333333
Epoch:  512        3 Batch loss: 0.212716 Batch F1: 0.38095238095238093
Epoch:  512        4 Batch loss: 0.263885 Batch F1: 0.08695652173913042
Epoch:  512        5 Batch loss: 0.225390 Batch F1: 0.30769230769230765
Epoch:  512        6 Batch loss: 0.175752 Batch F1: 0.38095238095238093
Epoch:  512        7 Batch loss: 0.224997 Batch F1: 0.21052631578947367
Epoch:  512        8 Batch loss: 0.212437 Batch F1: 0.4
Epoch:  512        9 Batch loss: 0.235975 Batch F1: 0.3448275862068965
Epoch:  512       10 Batch loss: 0.254886 Batch F1: 0.21428571428571427
Epoch:  512       11 Batch loss: 0.220425 Batch F1: 0.4666666666666667
Epoch:  512       12 Batch loss: 0.220487 Batch F1: 0.22222222222222224
Train Avg Loss  512: 0.221701

Train Avg F1  512: 0.2790346191533756

Val Avg Loss  512: 0.220122

Val Avg F1  512:  0.3193718797167073

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 513
--------------------------------------------------------------
Epoch:  513        1 Batch loss: 0.232864 Batch F1: 0.26666666666666666
Epoch:  513        2 Batch loss: 0.215258 Batch F1: 0.3703703703703704
Epoch:  513        3 Batch loss: 0.203581 Batch F1: 0.3333333333333333
Epoch:  513        4 Batch loss: 0.247202 Batch F1: 0.23999999999999996
Epoch:  513        5 Batch loss: 0.205715 Batch F1: 0.41666666666666663
Epoch:  513        6 Batch loss: 0.203698 Batch F1: 0.0
Epoch:  513        7 Batch loss: 0.248919 Batch F1: 0.0
Epoch:  513        8 Batch loss: 0.219079 Batch F1: 0.1111111111111111
Epoch:  513        9 Batch loss: 0.224216 Batch F1: 0.1
Epoch:  513       10 Batch loss: 0.244426 Batch F1: 0.0
Epoch:  513       11 Batch loss: 0.196448 Batch F1: 0.09523809523809525
Epoch:  513       12 Batch loss: 0.233844 Batch F1: 0.1904761904761905
Train Avg Loss  513: 0.222937

Train Avg F1  513: 0.17698853615520285

Val Avg Loss  513: 0.220286

Val Avg F1  513:  0.24523809523809526

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 514
--------------------------------------------------------------
Epoch:  514        1 Batch loss: 0.216961 Batch F1: 0.4166666666666667
Epoch:  514        2 Batch loss: 0.214667 Batch F1: 0.5185185185185185
Epoch:  514        3 Batch loss: 0.226095 Batch F1: 0.5
Epoch:  514        4 Batch loss: 0.198168 Batch F1: 0.46153846153846156
Epoch:  514        5 Batch loss: 0.226505 Batch F1: 0.26086956521739124
Epoch:  514        6 Batch loss: 0.216757 Batch F1: 0.4444444444444445
Epoch:  514        7 Batch loss: 0.224436 Batch F1: 0.47058823529411764
Epoch:  514        8 Batch loss: 0.243827 Batch F1: 0.23076923076923078
Epoch:  514        9 Batch loss: 0.238461 Batch F1: 0.24
Epoch:  514       10 Batch loss: 0.233195 Batch F1: 0.28571428571428575
Epoch:  514       11 Batch loss: 0.214596 Batch F1: 0.41379310344827586
Epoch:  514       12 Batch loss: 0.215560 Batch F1: 0.125
Train Avg Loss  514: 0.222436

Train Avg F1  514: 0.363991875967616

Val Avg Loss  514: 0.219156

Val Avg F1  514:  0.26726495726495725

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 515
--------------------------------------------------------------
Epoch:  515        1 Batch loss: 0.225617 Batch F1: 0.2222222222222222
Epoch:  515        2 Batch loss: 0.212158 Batch F1: 0.0
Epoch:  515        3 Batch loss: 0.233877 Batch F1: 0.48484848484848486
Epoch:  515        4 Batch loss: 0.239834 Batch F1: 0.0
Epoch:  515        5 Batch loss: 0.195192 Batch F1: 0.25
Epoch:  515        6 Batch loss: 0.214111 Batch F1: 0.2727272727272727
Epoch:  515        7 Batch loss: 0.187578 Batch F1: 0.0
Epoch:  515        8 Batch loss: 0.235341 Batch F1: 0.0
Epoch:  515        9 Batch loss: 0.222038 Batch F1: 0.09523809523809525
Epoch:  515       10 Batch loss: 0.254886 Batch F1: 0.0
Epoch:  515       11 Batch loss: 0.226949 Batch F1: 0.5000000000000001
Epoch:  515       12 Batch loss: 0.224482 Batch F1: 0.4166666666666667
Train Avg Loss  515: 0.222672

Train Avg F1  515: 0.18680856180856178

Val Avg Loss  515: 0.223973

Val Avg F1  515:  0.3443627450980392

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 516
--------------------------------------------------------------
Epoch:  516        1 Batch loss: 0.227665 Batch F1: 0.30769230769230765
Epoch:  516        2 Batch loss: 0.257990 Batch F1: 0.36363636363636365
Epoch:  516        3 Batch loss: 0.243507 Batch F1: 0.3225806451612903
Epoch:  516        4 Batch loss: 0.235045 Batch F1: 0.28571428571428575
Epoch:  516        5 Batch loss: 0.201510 Batch F1: 0.64
Epoch:  516        6 Batch loss: 0.206698 Batch F1: 0.2857142857142857
Epoch:  516        7 Batch loss: 0.262415 Batch F1: 0.21428571428571427
Epoch:  516        8 Batch loss: 0.240294 Batch F1: 0.0
Epoch:  516        9 Batch loss: 0.206118 Batch F1: 0.0
Epoch:  516       10 Batch loss: 0.216722 Batch F1: 0.0
Epoch:  516       11 Batch loss: 0.206570 Batch F1: 0.0
Epoch:  516       12 Batch loss: 0.176544 Batch F1: 0.15384615384615385
Train Avg Loss  516: 0.223423

Train Avg F1  516: 0.2144558130042001

Val Avg Loss  516: 0.217234

Val Avg F1  516:  0.17429368876737295

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 517
--------------------------------------------------------------
Epoch:  517        1 Batch loss: 0.256184 Batch F1: 0.0
Epoch:  517        2 Batch loss: 0.256656 Batch F1: 0.21428571428571427
Epoch:  517        3 Batch loss: 0.217447 Batch F1: 0.2727272727272727
Epoch:  517        4 Batch loss: 0.216255 Batch F1: 0.2608695652173913
Epoch:  517        5 Batch loss: 0.210257 Batch F1: 0.21052631578947367
Epoch:  517        6 Batch loss: 0.221536 Batch F1: 0.2727272727272727
Epoch:  517        7 Batch loss: 0.194397 Batch F1: 0.46153846153846156
Epoch:  517        8 Batch loss: 0.241948 Batch F1: 0.16666666666666666
Epoch:  517        9 Batch loss: 0.221792 Batch F1: 0.2857142857142857
Epoch:  517       10 Batch loss: 0.198247 Batch F1: 0.4
Epoch:  517       11 Batch loss: 0.226103 Batch F1: 0.5405405405405406
Epoch:  517       12 Batch loss: 0.205752 Batch F1: 0.35294117647058826
Train Avg Loss  517: 0.222215

Train Avg F1  517: 0.28654477263980566

Val Avg Loss  517: 0.218551

Val Avg F1  517:  0.25794133402829056

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 518
--------------------------------------------------------------
Epoch:  518        1 Batch loss: 0.210992 Batch F1: 0.3333333333333333
Epoch:  518        2 Batch loss: 0.242816 Batch F1: 0.35714285714285715
Epoch:  518        3 Batch loss: 0.228103 Batch F1: 0.11764705882352941
Epoch:  518        4 Batch loss: 0.167940 Batch F1: 0.2857142857142857
Epoch:  518        5 Batch loss: 0.207022 Batch F1: 0.26086956521739124
Epoch:  518        6 Batch loss: 0.209778 Batch F1: 0.41379310344827586
Epoch:  518        7 Batch loss: 0.227331 Batch F1: 0.35714285714285715
Epoch:  518        8 Batch loss: 0.220587 Batch F1: 0.0
Epoch:  518        9 Batch loss: 0.238524 Batch F1: 0.37037037037037035
Epoch:  518       10 Batch loss: 0.231078 Batch F1: 0.41379310344827586
Epoch:  518       11 Batch loss: 0.249016 Batch F1: 0.14814814814814817
Epoch:  518       12 Batch loss: 0.235003 Batch F1: 0.36363636363636365
Train Avg Loss  518: 0.222349

Train Avg F1  518: 0.2851325872021407

Val Avg Loss  518: 0.219482

Val Avg F1  518:  0.2459641084867945

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 519
--------------------------------------------------------------
Epoch:  519        1 Batch loss: 0.246356 Batch F1: 0.14814814814814814
Epoch:  519        2 Batch loss: 0.204366 Batch F1: 0.6399999999999999
Epoch:  519        3 Batch loss: 0.240918 Batch F1: 0.24
Epoch:  519        4 Batch loss: 0.189758 Batch F1: 0.2857142857142857
Epoch:  519        5 Batch loss: 0.262377 Batch F1: 0.20689655172413793
Epoch:  519        6 Batch loss: 0.201746 Batch F1: 0.3478260869565218
Epoch:  519        7 Batch loss: 0.229891 Batch F1: 0.32
Epoch:  519        8 Batch loss: 0.208457 Batch F1: 0.34782608695652173
Epoch:  519        9 Batch loss: 0.208777 Batch F1: 0.32
Epoch:  519       10 Batch loss: 0.244546 Batch F1: 0.09523809523809525
Epoch:  519       11 Batch loss: 0.235990 Batch F1: 0.23076923076923078
Epoch:  519       12 Batch loss: 0.198613 Batch F1: 0.5
Train Avg Loss  519: 0.222650

Train Avg F1  519: 0.30686820712557844

Val Avg Loss  519: 0.218645

Val Avg F1  519:  0.2519586391869001

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 520
--------------------------------------------------------------
Epoch:  520        1 Batch loss: 0.235648 Batch F1: 0.25
Epoch:  520        2 Batch loss: 0.214749 Batch F1: 0.44444444444444436
Epoch:  520        3 Batch loss: 0.203675 Batch F1: 0.4166666666666667
Epoch:  520        4 Batch loss: 0.219725 Batch F1: 0.3846153846153846
Epoch:  520        5 Batch loss: 0.203195 Batch F1: 0.3157894736842105
Epoch:  520        6 Batch loss: 0.214649 Batch F1: 0.0
Epoch:  520        7 Batch loss: 0.288619 Batch F1: 0.0
Epoch:  520        8 Batch loss: 0.201356 Batch F1: 0.0
Epoch:  520        9 Batch loss: 0.239901 Batch F1: 0.0
Epoch:  520       10 Batch loss: 0.245607 Batch F1: 0.0
Epoch:  520       11 Batch loss: 0.201214 Batch F1: 0.4
Epoch:  520       12 Batch loss: 0.215566 Batch F1: 0.2105263157894737
Train Avg Loss  520: 0.223658

Train Avg F1  520: 0.201836857100015

Val Avg Loss  520: 0.217938

Val Avg F1  520:  0.24247863247863247

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 521
--------------------------------------------------------------
Epoch:  521        1 Batch loss: 0.262573 Batch F1: 0.3125
Epoch:  521        2 Batch loss: 0.223563 Batch F1: 0.32
Epoch:  521        3 Batch loss: 0.229075 Batch F1: 0.30769230769230765
Epoch:  521        4 Batch loss: 0.200610 Batch F1: 0.3
Epoch:  521        5 Batch loss: 0.244997 Batch F1: 0.3448275862068966
Epoch:  521        6 Batch loss: 0.216263 Batch F1: 0.48
Epoch:  521        7 Batch loss: 0.195524 Batch F1: 0.33333333333333337
Epoch:  521        8 Batch loss: 0.200603 Batch F1: 0.4444444444444444
Epoch:  521        9 Batch loss: 0.248392 Batch F1: 0.15384615384615383
Epoch:  521       10 Batch loss: 0.212662 Batch F1: 0.4
Epoch:  521       11 Batch loss: 0.208820 Batch F1: 0.4166666666666667
Epoch:  521       12 Batch loss: 0.233197 Batch F1: 0.10526315789473684
Train Avg Loss  521: 0.223023

Train Avg F1  521: 0.3265478041737116

Val Avg Loss  521: 0.218610

Val Avg F1  521:  0.2595238095238095

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 522
--------------------------------------------------------------
Epoch:  522        1 Batch loss: 0.216303 Batch F1: 0.48275862068965514
Epoch:  522        2 Batch loss: 0.203493 Batch F1: 0.23076923076923078
Epoch:  522        3 Batch loss: 0.200934 Batch F1: 0.3636363636363636
Epoch:  522        4 Batch loss: 0.223036 Batch F1: 0.4444444444444444
Epoch:  522        5 Batch loss: 0.202219 Batch F1: 0.5517241379310344
Epoch:  522        6 Batch loss: 0.242308 Batch F1: 0.3225806451612903
Epoch:  522        7 Batch loss: 0.238029 Batch F1: 0.4
Epoch:  522        8 Batch loss: 0.170326 Batch F1: 0.0
Epoch:  522        9 Batch loss: 0.266761 Batch F1: 0.17391304347826086
Epoch:  522       10 Batch loss: 0.218638 Batch F1: 0.0
Epoch:  522       11 Batch loss: 0.275411 Batch F1: 0.0
Epoch:  522       12 Batch loss: 0.227305 Batch F1: 0.0
Train Avg Loss  522: 0.223730

Train Avg F1  522: 0.24748554050918994

Val Avg Loss  522: 0.216891

Val Avg F1  522:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 523
--------------------------------------------------------------
Epoch:  523        1 Batch loss: 0.207771 Batch F1: 0.0
Epoch:  523        2 Batch loss: 0.239191 Batch F1: 0.0
Epoch:  523        3 Batch loss: 0.179713 Batch F1: 0.0
Epoch:  523        4 Batch loss: 0.232836 Batch F1: 0.0
Epoch:  523        5 Batch loss: 0.203459 Batch F1: 0.0
Epoch:  523        6 Batch loss: 0.235013 Batch F1: 0.0
Epoch:  523        7 Batch loss: 0.191339 Batch F1: 0.0
Epoch:  523        8 Batch loss: 0.252823 Batch F1: 0.0
Epoch:  523        9 Batch loss: 0.209105 Batch F1: 0.0
Epoch:  523       10 Batch loss: 0.245028 Batch F1: 0.2222222222222222
Epoch:  523       11 Batch loss: 0.245948 Batch F1: 0.2962962962962963
Epoch:  523       12 Batch loss: 0.223937 Batch F1: 0.5217391304347825
Train Avg Loss  523: 0.222180

Train Avg F1  523: 0.08668813741277508

Val Avg Loss  523: 0.221811

Val Avg F1  523:  0.353411306042885

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 524
--------------------------------------------------------------
Epoch:  524        1 Batch loss: 0.233759 Batch F1: 0.37037037037037035
Epoch:  524        2 Batch loss: 0.203720 Batch F1: 0.1111111111111111
Epoch:  524        3 Batch loss: 0.227514 Batch F1: 0.0
Epoch:  524        4 Batch loss: 0.277323 Batch F1: 0.0
Epoch:  524        5 Batch loss: 0.176634 Batch F1: 0.0
Epoch:  524        6 Batch loss: 0.250435 Batch F1: 0.0
Epoch:  524        7 Batch loss: 0.201910 Batch F1: 0.0
Epoch:  524        8 Batch loss: 0.246387 Batch F1: 0.0
Epoch:  524        9 Batch loss: 0.241678 Batch F1: 0.0
Epoch:  524       10 Batch loss: 0.227980 Batch F1: 0.0
Epoch:  524       11 Batch loss: 0.216036 Batch F1: 0.4999999999999999
Epoch:  524       12 Batch loss: 0.217638 Batch F1: 0.3
Train Avg Loss  524: 0.226751

Train Avg F1  524: 0.10679012345679012

Val Avg Loss  524: 0.220093

Val Avg F1  524:  0.26212215320910975

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 525
--------------------------------------------------------------
Epoch:  525        1 Batch loss: 0.226669 Batch F1: 0.42424242424242425
Epoch:  525        2 Batch loss: 0.237405 Batch F1: 0.19999999999999998
Epoch:  525        3 Batch loss: 0.205927 Batch F1: 0.4
Epoch:  525        4 Batch loss: 0.205040 Batch F1: 0.36363636363636365
Epoch:  525        5 Batch loss: 0.233480 Batch F1: 0.25
Epoch:  525        6 Batch loss: 0.235550 Batch F1: 0.2857142857142857
Epoch:  525        7 Batch loss: 0.201535 Batch F1: 0.0
Epoch:  525        8 Batch loss: 0.250220 Batch F1: 0.0
Epoch:  525        9 Batch loss: 0.205768 Batch F1: 0.38095238095238093
Epoch:  525       10 Batch loss: 0.193845 Batch F1: 0.11764705882352941
Epoch:  525       11 Batch loss: 0.246274 Batch F1: 0.21428571428571427
Epoch:  525       12 Batch loss: 0.228394 Batch F1: 0.2222222222222222
Train Avg Loss  525: 0.222509

Train Avg F1  525: 0.2382250374897434

Val Avg Loss  525: 0.218251

Val Avg F1  525:  0.2613978127136022

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 526
--------------------------------------------------------------
Epoch:  526        1 Batch loss: 0.235406 Batch F1: 0.09523809523809525
Epoch:  526        2 Batch loss: 0.248423 Batch F1: 0.43750000000000006
Epoch:  526        3 Batch loss: 0.194568 Batch F1: 0.28571428571428575
Epoch:  526        4 Batch loss: 0.207639 Batch F1: 0.30769230769230765
Epoch:  526        5 Batch loss: 0.255285 Batch F1: 0.27586206896551724
Epoch:  526        6 Batch loss: 0.218803 Batch F1: 0.3076923076923077
Epoch:  526        7 Batch loss: 0.211824 Batch F1: 0.4
Epoch:  526        8 Batch loss: 0.223272 Batch F1: 0.24
Epoch:  526        9 Batch loss: 0.211456 Batch F1: 0.2222222222222222
Epoch:  526       10 Batch loss: 0.228971 Batch F1: 0.28571428571428575
Epoch:  526       11 Batch loss: 0.209426 Batch F1: 0.4166666666666667
Epoch:  526       12 Batch loss: 0.218091 Batch F1: 0.2857142857142857
Train Avg Loss  526: 0.221930

Train Avg F1  526: 0.2966680438016645

Val Avg Loss  526: 0.218145

Val Avg F1  526:  0.2600935828877005

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 527
--------------------------------------------------------------
Epoch:  527        1 Batch loss: 0.200669 Batch F1: 0.27272727272727276
Epoch:  527        2 Batch loss: 0.239660 Batch F1: 0.0
Epoch:  527        3 Batch loss: 0.214562 Batch F1: 0.0
Epoch:  527        4 Batch loss: 0.249735 Batch F1: 0.0
Epoch:  527        5 Batch loss: 0.221363 Batch F1: 0.0
Epoch:  527        6 Batch loss: 0.254036 Batch F1: 0.0
Epoch:  527        7 Batch loss: 0.201088 Batch F1: 0.45454545454545453
Epoch:  527        8 Batch loss: 0.197294 Batch F1: 0.3333333333333333
Epoch:  527        9 Batch loss: 0.209771 Batch F1: 0.2727272727272727
Epoch:  527       10 Batch loss: 0.182854 Batch F1: 0.3333333333333333
Epoch:  527       11 Batch loss: 0.250659 Batch F1: 0.3448275862068966
Epoch:  527       12 Batch loss: 0.260355 Batch F1: 0.19999999999999998
Train Avg Loss  527: 0.223504

Train Avg F1  527: 0.1842911877394636

Val Avg Loss  527: 0.217866

Val Avg F1  527:  0.2510172053010928

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 528
--------------------------------------------------------------
Epoch:  528        1 Batch loss: 0.206869 Batch F1: 0.32
Epoch:  528        2 Batch loss: 0.211986 Batch F1: 0.3333333333333333
Epoch:  528        3 Batch loss: 0.204728 Batch F1: 0.2
Epoch:  528        4 Batch loss: 0.190038 Batch F1: 0.4347826086956522
Epoch:  528        5 Batch loss: 0.195746 Batch F1: 0.3333333333333333
Epoch:  528        6 Batch loss: 0.221013 Batch F1: 0.3333333333333333
Epoch:  528        7 Batch loss: 0.268252 Batch F1: 0.25
Epoch:  528        8 Batch loss: 0.234482 Batch F1: 0.41379310344827586
Epoch:  528        9 Batch loss: 0.218746 Batch F1: 0.4
Epoch:  528       10 Batch loss: 0.243566 Batch F1: 0.3448275862068965
Epoch:  528       11 Batch loss: 0.224986 Batch F1: 0.37037037037037035
Epoch:  528       12 Batch loss: 0.241118 Batch F1: 0.18181818181818185
Train Avg Loss  528: 0.221794

Train Avg F1  528: 0.32629932087828134

Val Avg Loss  528: 0.219269

Val Avg F1  528:  0.2605676328502416

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 529
--------------------------------------------------------------
Epoch:  529        1 Batch loss: 0.230296 Batch F1: 0.15999999999999998
Epoch:  529        2 Batch loss: 0.234164 Batch F1: 0.30769230769230765
Epoch:  529        3 Batch loss: 0.209978 Batch F1: 0.28571428571428575
Epoch:  529        4 Batch loss: 0.228973 Batch F1: 0.1739130434782609
Epoch:  529        5 Batch loss: 0.235883 Batch F1: 0.0
Epoch:  529        6 Batch loss: 0.211820 Batch F1: 0.0
Epoch:  529        7 Batch loss: 0.222332 Batch F1: 0.0
Epoch:  529        8 Batch loss: 0.224469 Batch F1: 0.0
Epoch:  529        9 Batch loss: 0.204677 Batch F1: 0.11764705882352941
Epoch:  529       10 Batch loss: 0.259071 Batch F1: 0.07407407407407407
Epoch:  529       11 Batch loss: 0.201401 Batch F1: 0.22222222222222224
Epoch:  529       12 Batch loss: 0.202996 Batch F1: 0.5217391304347826
Train Avg Loss  529: 0.222172

Train Avg F1  529: 0.15525017686995524

Val Avg Loss  529: 0.218256

Val Avg F1  529:  0.2598516679399033

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 530
--------------------------------------------------------------
Epoch:  530        1 Batch loss: 0.215494 Batch F1: 0.25
Epoch:  530        2 Batch loss: 0.218487 Batch F1: 0.1111111111111111
Epoch:  530        3 Batch loss: 0.225299 Batch F1: 0.08333333333333333
Epoch:  530        4 Batch loss: 0.251717 Batch F1: 0.4242424242424242
Epoch:  530        5 Batch loss: 0.238717 Batch F1: 0.0
Epoch:  530        6 Batch loss: 0.207175 Batch F1: 0.5185185185185185
Epoch:  530        7 Batch loss: 0.198373 Batch F1: 0.5
Epoch:  530        8 Batch loss: 0.187656 Batch F1: 0.6666666666666667
Epoch:  530        9 Batch loss: 0.217297 Batch F1: 0.36363636363636365
Epoch:  530       10 Batch loss: 0.261925 Batch F1: 0.25806451612903225
Epoch:  530       11 Batch loss: 0.206852 Batch F1: 0.5
Epoch:  530       12 Batch loss: 0.242347 Batch F1: 0.1
Train Avg Loss  530: 0.222612

Train Avg F1  530: 0.31463107780312083

Val Avg Loss  530: 0.217939

Val Avg F1  530:  0.23154477101845522

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 531
--------------------------------------------------------------
Epoch:  531        1 Batch loss: 0.210133 Batch F1: 0.5
Epoch:  531        2 Batch loss: 0.241346 Batch F1: 0.3448275862068966
Epoch:  531        3 Batch loss: 0.208170 Batch F1: 0.3
Epoch:  531        4 Batch loss: 0.241961 Batch F1: 0.20689655172413793
Epoch:  531        5 Batch loss: 0.232247 Batch F1: 0.18181818181818182
Epoch:  531        6 Batch loss: 0.207555 Batch F1: 0.18181818181818182
Epoch:  531        7 Batch loss: 0.233585 Batch F1: 0.39999999999999997
Epoch:  531        8 Batch loss: 0.214935 Batch F1: 0.2
Epoch:  531        9 Batch loss: 0.271733 Batch F1: 0.13793103448275865
Epoch:  531       10 Batch loss: 0.188861 Batch F1: 0.3636363636363636
Epoch:  531       11 Batch loss: 0.220526 Batch F1: 0.23999999999999996
Epoch:  531       12 Batch loss: 0.191276 Batch F1: 0.5000000000000001
Train Avg Loss  531: 0.221861

Train Avg F1  531: 0.29641065830721003

Val Avg Loss  531: 0.217947

Val Avg F1  531:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 532
--------------------------------------------------------------
Epoch:  532        1 Batch loss: 0.247150 Batch F1: 0.08695652173913042
Epoch:  532        2 Batch loss: 0.179533 Batch F1: 0.0
Epoch:  532        3 Batch loss: 0.227529 Batch F1: 0.0
Epoch:  532        4 Batch loss: 0.207338 Batch F1: 0.0
Epoch:  532        5 Batch loss: 0.253796 Batch F1: 0.0
Epoch:  532        6 Batch loss: 0.228677 Batch F1: 0.0
Epoch:  532        7 Batch loss: 0.219050 Batch F1: 0.0
Epoch:  532        8 Batch loss: 0.226956 Batch F1: 0.0
Epoch:  532        9 Batch loss: 0.204677 Batch F1: 0.0
Epoch:  532       10 Batch loss: 0.234589 Batch F1: 0.0
Epoch:  532       11 Batch loss: 0.232527 Batch F1: 0.411764705882353
Epoch:  532       12 Batch loss: 0.250135 Batch F1: 0.2727272727272727
Train Avg Loss  532: 0.225996

Train Avg F1  532: 0.06428737502906301

Val Avg Loss  532: 0.221575

Val Avg F1  532:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 533
--------------------------------------------------------------
Epoch:  533        1 Batch loss: 0.218868 Batch F1: 0.0
Epoch:  533        2 Batch loss: 0.233487 Batch F1: 0.0
Epoch:  533        3 Batch loss: 0.222707 Batch F1: 0.0
Epoch:  533        4 Batch loss: 0.223162 Batch F1: 0.0
Epoch:  533        5 Batch loss: 0.252208 Batch F1: 0.0
Epoch:  533        6 Batch loss: 0.232390 Batch F1: 0.0
Epoch:  533        7 Batch loss: 0.214821 Batch F1: 0.0
Epoch:  533        8 Batch loss: 0.261248 Batch F1: 0.0
Epoch:  533        9 Batch loss: 0.215887 Batch F1: 0.0
Epoch:  533       10 Batch loss: 0.233977 Batch F1: 0.0
Epoch:  533       11 Batch loss: 0.230115 Batch F1: 0.0
Epoch:  533       12 Batch loss: 0.216850 Batch F1: 0.0
Train Avg Loss  533: 0.229643

Train Avg F1  533: 0.0

Val Avg Loss  533: 0.219582

Val Avg F1  533:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 534
--------------------------------------------------------------
Epoch:  534        1 Batch loss: 0.217780 Batch F1: 0.0
Epoch:  534        2 Batch loss: 0.266722 Batch F1: 0.0
Epoch:  534        3 Batch loss: 0.205064 Batch F1: 0.23529411764705882
Epoch:  534        4 Batch loss: 0.215674 Batch F1: 0.0
Epoch:  534        5 Batch loss: 0.275842 Batch F1: 0.0
Epoch:  534        6 Batch loss: 0.208429 Batch F1: 0.0
Epoch:  534        7 Batch loss: 0.256778 Batch F1: 0.08333333333333334
Epoch:  534        8 Batch loss: 0.242460 Batch F1: 0.3846153846153846
Epoch:  534        9 Batch loss: 0.222618 Batch F1: 0.08695652173913045
Epoch:  534       10 Batch loss: 0.221922 Batch F1: 0.0
Epoch:  534       11 Batch loss: 0.190480 Batch F1: 0.0
Epoch:  534       12 Batch loss: 0.213914 Batch F1: 0.0
Train Avg Loss  534: 0.228140

Train Avg F1  534: 0.0658499464445756

Val Avg Loss  534: 0.217392

Val Avg F1  534:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 535
--------------------------------------------------------------
Epoch:  535        1 Batch loss: 0.217979 Batch F1: 0.0
Epoch:  535        2 Batch loss: 0.195933 Batch F1: 0.0
Epoch:  535        3 Batch loss: 0.258674 Batch F1: 0.0
Epoch:  535        4 Batch loss: 0.244080 Batch F1: 0.0
Epoch:  535        5 Batch loss: 0.220119 Batch F1: 0.0
Epoch:  535        6 Batch loss: 0.238437 Batch F1: 0.0
Epoch:  535        7 Batch loss: 0.213709 Batch F1: 0.0
Epoch:  535        8 Batch loss: 0.217484 Batch F1: 0.0
Epoch:  535        9 Batch loss: 0.257096 Batch F1: 0.0
Epoch:  535       10 Batch loss: 0.191348 Batch F1: 0.0
Epoch:  535       11 Batch loss: 0.265108 Batch F1: 0.0
Epoch:  535       12 Batch loss: 0.203064 Batch F1: 0.0
Train Avg Loss  535: 0.226919

Train Avg F1  535: 0.0

Val Avg Loss  535: 0.218633

Val Avg F1  535:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 536
--------------------------------------------------------------
Epoch:  536        1 Batch loss: 0.200805 Batch F1: 0.0
Epoch:  536        2 Batch loss: 0.216894 Batch F1: 0.0
Epoch:  536        3 Batch loss: 0.223347 Batch F1: 0.0
Epoch:  536        4 Batch loss: 0.256809 Batch F1: 0.0
Epoch:  536        5 Batch loss: 0.219904 Batch F1: 0.0
Epoch:  536        6 Batch loss: 0.217611 Batch F1: 0.0
Epoch:  536        7 Batch loss: 0.206168 Batch F1: 0.0
Epoch:  536        8 Batch loss: 0.262544 Batch F1: 0.0
Epoch:  536        9 Batch loss: 0.263469 Batch F1: 0.17647058823529413
Epoch:  536       10 Batch loss: 0.230645 Batch F1: 0.5853658536585366
Epoch:  536       11 Batch loss: 0.229481 Batch F1: 0.20689655172413793
Epoch:  536       12 Batch loss: 0.230599 Batch F1: 0.4
Train Avg Loss  536: 0.229856

Train Avg F1  536: 0.11406108280149739

Val Avg Loss  536: 0.221944

Val Avg F1  536:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 537
--------------------------------------------------------------
Epoch:  537        1 Batch loss: 0.234201 Batch F1: 0.0
Epoch:  537        2 Batch loss: 0.224246 Batch F1: 0.0
Epoch:  537        3 Batch loss: 0.248296 Batch F1: 0.0
Epoch:  537        4 Batch loss: 0.223712 Batch F1: 0.0
Epoch:  537        5 Batch loss: 0.234412 Batch F1: 0.0
Epoch:  537        6 Batch loss: 0.237029 Batch F1: 0.0
Epoch:  537        7 Batch loss: 0.212677 Batch F1: 0.0
Epoch:  537        8 Batch loss: 0.215147 Batch F1: 0.0
Epoch:  537        9 Batch loss: 0.214497 Batch F1: 0.0
Epoch:  537       10 Batch loss: 0.240001 Batch F1: 0.0
Epoch:  537       11 Batch loss: 0.209319 Batch F1: 0.0
Epoch:  537       12 Batch loss: 0.253083 Batch F1: 0.0
Train Avg Loss  537: 0.228885

Train Avg F1  537: 0.0

Val Avg Loss  537: 0.217824

Val Avg F1  537:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 538
--------------------------------------------------------------
Epoch:  538        1 Batch loss: 0.221453 Batch F1: 0.0
Epoch:  538        2 Batch loss: 0.207972 Batch F1: 0.0
Epoch:  538        3 Batch loss: 0.185518 Batch F1: 0.0
Epoch:  538        4 Batch loss: 0.238010 Batch F1: 0.0
Epoch:  538        5 Batch loss: 0.226232 Batch F1: 0.0
Epoch:  538        6 Batch loss: 0.273131 Batch F1: 0.0
Epoch:  538        7 Batch loss: 0.196819 Batch F1: 0.2
Epoch:  538        8 Batch loss: 0.208292 Batch F1: 0.19047619047619044
Epoch:  538        9 Batch loss: 0.228710 Batch F1: 0.30769230769230765
Epoch:  538       10 Batch loss: 0.247130 Batch F1: 0.3225806451612903
Epoch:  538       11 Batch loss: 0.215258 Batch F1: 0.1818181818181818
Epoch:  538       12 Batch loss: 0.245530 Batch F1: 0.35714285714285715
Train Avg Loss  538: 0.224505

Train Avg F1  538: 0.12997584852423563

Val Avg Loss  538: 0.225952

Val Avg F1  538:  0.31856714499892913

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 539
--------------------------------------------------------------
Epoch:  539        1 Batch loss: 0.217178 Batch F1: 0.4
Epoch:  539        2 Batch loss: 0.222323 Batch F1: 0.5365853658536586
Epoch:  539        3 Batch loss: 0.243309 Batch F1: 0.45
Epoch:  539        4 Batch loss: 0.223021 Batch F1: 0.47058823529411764
Epoch:  539        5 Batch loss: 0.214755 Batch F1: 0.5
Epoch:  539        6 Batch loss: 0.263217 Batch F1: 0.3888888888888889
Epoch:  539        7 Batch loss: 0.193782 Batch F1: 0.0
Epoch:  539        8 Batch loss: 0.203644 Batch F1: 0.0
Epoch:  539        9 Batch loss: 0.246263 Batch F1: 0.0
Epoch:  539       10 Batch loss: 0.218639 Batch F1: 0.0
Epoch:  539       11 Batch loss: 0.226464 Batch F1: 0.0
Epoch:  539       12 Batch loss: 0.234728 Batch F1: 0.0
Train Avg Loss  539: 0.225610

Train Avg F1  539: 0.22883854083638877

Val Avg Loss  539: 0.217451

Val Avg F1  539:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 540
--------------------------------------------------------------
Epoch:  540        1 Batch loss: 0.229700 Batch F1: 0.0
Epoch:  540        2 Batch loss: 0.243621 Batch F1: 0.0
Epoch:  540        3 Batch loss: 0.219980 Batch F1: 0.0
Epoch:  540        4 Batch loss: 0.244446 Batch F1: 0.23076923076923075
Epoch:  540        5 Batch loss: 0.227279 Batch F1: 0.1739130434782609
Epoch:  540        6 Batch loss: 0.220184 Batch F1: 0.2857142857142857
Epoch:  540        7 Batch loss: 0.223208 Batch F1: 0.1904761904761905
Epoch:  540        8 Batch loss: 0.210616 Batch F1: 0.2
Epoch:  540        9 Batch loss: 0.231077 Batch F1: 0.0
Epoch:  540       10 Batch loss: 0.264053 Batch F1: 0.0
Epoch:  540       11 Batch loss: 0.191818 Batch F1: 0.0
Epoch:  540       12 Batch loss: 0.203217 Batch F1: 0.0
Train Avg Loss  540: 0.225766

Train Avg F1  540: 0.09007272920316399

Val Avg Loss  540: 0.217843

Val Avg F1  540:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 541
--------------------------------------------------------------
Epoch:  541        1 Batch loss: 0.236974 Batch F1: 0.0
Epoch:  541        2 Batch loss: 0.223246 Batch F1: 0.0
Epoch:  541        3 Batch loss: 0.234114 Batch F1: 0.0
Epoch:  541        4 Batch loss: 0.224010 Batch F1: 0.0
Epoch:  541        5 Batch loss: 0.199941 Batch F1: 0.0
Epoch:  541        6 Batch loss: 0.198672 Batch F1: 0.0
Epoch:  541        7 Batch loss: 0.217712 Batch F1: 0.0
Epoch:  541        8 Batch loss: 0.206502 Batch F1: 0.2727272727272727
Epoch:  541        9 Batch loss: 0.230548 Batch F1: 0.30769230769230765
Epoch:  541       10 Batch loss: 0.245641 Batch F1: 0.39999999999999997
Epoch:  541       11 Batch loss: 0.242208 Batch F1: 0.3225806451612903
Epoch:  541       12 Batch loss: 0.228690 Batch F1: 0.4210526315789474
Train Avg Loss  541: 0.224022

Train Avg F1  541: 0.14367107142998484

Val Avg Loss  541: 0.224463

Val Avg F1  541:  0.31751674582876627

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 542
--------------------------------------------------------------
Epoch:  542        1 Batch loss: 0.217259 Batch F1: 0.5333333333333333
Epoch:  542        2 Batch loss: 0.225589 Batch F1: 0.5
Epoch:  542        3 Batch loss: 0.245927 Batch F1: 0.15999999999999998
Epoch:  542        4 Batch loss: 0.217248 Batch F1: 0.39999999999999997
Epoch:  542        5 Batch loss: 0.265047 Batch F1: 0.4
Epoch:  542        6 Batch loss: 0.225910 Batch F1: 0.3448275862068965
Epoch:  542        7 Batch loss: 0.191387 Batch F1: 0.43478260869565216
Epoch:  542        8 Batch loss: 0.216102 Batch F1: 0.2608695652173913
Epoch:  542        9 Batch loss: 0.208069 Batch F1: 0.2222222222222222
Epoch:  542       10 Batch loss: 0.248115 Batch F1: 0.0
Epoch:  542       11 Batch loss: 0.202661 Batch F1: 0.0
Epoch:  542       12 Batch loss: 0.240869 Batch F1: 0.1111111111111111
Train Avg Loss  542: 0.225349

Train Avg F1  542: 0.28059553556555056

Val Avg Loss  542: 0.218472

Val Avg F1  542:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 543
--------------------------------------------------------------
Epoch:  543        1 Batch loss: 0.232518 Batch F1: 0.09523809523809523
Epoch:  543        2 Batch loss: 0.227233 Batch F1: 0.42857142857142855
Epoch:  543        3 Batch loss: 0.236595 Batch F1: 0.16000000000000003
Epoch:  543        4 Batch loss: 0.206668 Batch F1: 0.5517241379310345
Epoch:  543        5 Batch loss: 0.240001 Batch F1: 0.2727272727272727
Epoch:  543        6 Batch loss: 0.232643 Batch F1: 0.17391304347826086
Epoch:  543        7 Batch loss: 0.207885 Batch F1: 0.4
Epoch:  543        8 Batch loss: 0.224285 Batch F1: 0.1739130434782609
Epoch:  543        9 Batch loss: 0.232455 Batch F1: 0.3076923076923077
Epoch:  543       10 Batch loss: 0.226021 Batch F1: 0.30769230769230765
Epoch:  543       11 Batch loss: 0.211774 Batch F1: 0.0
Epoch:  543       12 Batch loss: 0.218660 Batch F1: 0.0
Train Avg Loss  543: 0.224728

Train Avg F1  543: 0.239289303067414

Val Avg Loss  543: 0.218856

Val Avg F1  543:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 544
--------------------------------------------------------------
Epoch:  544        1 Batch loss: 0.242087 Batch F1: 0.0
Epoch:  544        2 Batch loss: 0.230488 Batch F1: 0.0
Epoch:  544        3 Batch loss: 0.269198 Batch F1: 0.0
Epoch:  544        4 Batch loss: 0.248579 Batch F1: 0.0
Epoch:  544        5 Batch loss: 0.234155 Batch F1: 0.3636363636363636
Epoch:  544        6 Batch loss: 0.197168 Batch F1: 0.25000000000000006
Epoch:  544        7 Batch loss: 0.222522 Batch F1: 0.0
Epoch:  544        8 Batch loss: 0.213846 Batch F1: 0.0
Epoch:  544        9 Batch loss: 0.191576 Batch F1: 0.13333333333333333
Epoch:  544       10 Batch loss: 0.217019 Batch F1: 0.0
Epoch:  544       11 Batch loss: 0.209560 Batch F1: 0.0
Epoch:  544       12 Batch loss: 0.216381 Batch F1: 0.0
Train Avg Loss  544: 0.224382

Train Avg F1  544: 0.062247474747474746

Val Avg Loss  544: 0.218275

Val Avg F1  544:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 545
--------------------------------------------------------------
Epoch:  545        1 Batch loss: 0.260252 Batch F1: 0.08333333333333333
Epoch:  545        2 Batch loss: 0.214525 Batch F1: 0.0
Epoch:  545        3 Batch loss: 0.193294 Batch F1: 0.4210526315789473
Epoch:  545        4 Batch loss: 0.215255 Batch F1: 0.36363636363636365
Epoch:  545        5 Batch loss: 0.205776 Batch F1: 0.31578947368421056
Epoch:  545        6 Batch loss: 0.259837 Batch F1: 0.2222222222222222
Epoch:  545        7 Batch loss: 0.214753 Batch F1: 0.3333333333333333
Epoch:  545        8 Batch loss: 0.195708 Batch F1: 0.0
Epoch:  545        9 Batch loss: 0.227948 Batch F1: 0.33333333333333326
Epoch:  545       10 Batch loss: 0.274110 Batch F1: 0.25
Epoch:  545       11 Batch loss: 0.238312 Batch F1: 0.32
Epoch:  545       12 Batch loss: 0.168784 Batch F1: 0.588235294117647
Train Avg Loss  545: 0.222380

Train Avg F1  545: 0.26924466543661585

Val Avg Loss  545: 0.219450

Val Avg F1  545:  0.22045454545454546

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 546
--------------------------------------------------------------
Epoch:  546        1 Batch loss: 0.220539 Batch F1: 0.2608695652173913
Epoch:  546        2 Batch loss: 0.240119 Batch F1: 0.24
Epoch:  546        3 Batch loss: 0.233425 Batch F1: 0.37500000000000006
Epoch:  546        4 Batch loss: 0.238282 Batch F1: 0.08
Epoch:  546        5 Batch loss: 0.215814 Batch F1: 0.34782608695652173
Epoch:  546        6 Batch loss: 0.223771 Batch F1: 0.5555555555555556
Epoch:  546        7 Batch loss: 0.197851 Batch F1: 0.4799999999999999
Epoch:  546        8 Batch loss: 0.222185 Batch F1: 0.3478260869565218
Epoch:  546        9 Batch loss: 0.226780 Batch F1: 0.29629629629629634
Epoch:  546       10 Batch loss: 0.204848 Batch F1: 0.3478260869565218
Epoch:  546       11 Batch loss: 0.231146 Batch F1: 0.35714285714285715
Epoch:  546       12 Batch loss: 0.206158 Batch F1: 0.3333333333333333
Train Avg Loss  546: 0.221743

Train Avg F1  546: 0.3351396557012499

Val Avg Loss  546: 0.219103

Val Avg F1  546:  0.2593010853880419

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 547
--------------------------------------------------------------
Epoch:  547        1 Batch loss: 0.211583 Batch F1: 0.39999999999999997
Epoch:  547        2 Batch loss: 0.233747 Batch F1: 0.2962962962962963
Epoch:  547        3 Batch loss: 0.219528 Batch F1: 0.42857142857142855
Epoch:  547        4 Batch loss: 0.234075 Batch F1: 0.24
Epoch:  547        5 Batch loss: 0.217138 Batch F1: 0.27272727272727276
Epoch:  547        6 Batch loss: 0.199251 Batch F1: 0.4444444444444444
Epoch:  547        7 Batch loss: 0.192587 Batch F1: 0.3809523809523809
Epoch:  547        8 Batch loss: 0.204875 Batch F1: 0.26086956521739124
Epoch:  547        9 Batch loss: 0.272741 Batch F1: 0.16666666666666666
Epoch:  547       10 Batch loss: 0.221098 Batch F1: 0.30769230769230765
Epoch:  547       11 Batch loss: 0.226691 Batch F1: 0.25
Epoch:  547       12 Batch loss: 0.229963 Batch F1: 0.2727272727272727
Train Avg Loss  547: 0.221940

Train Avg F1  547: 0.31007896960795506

Val Avg Loss  547: 0.218643

Val Avg F1  547:  0.25695319173580045

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 548
--------------------------------------------------------------
Epoch:  548        1 Batch loss: 0.213707 Batch F1: 0.4166666666666667
Epoch:  548        2 Batch loss: 0.194093 Batch F1: 0.34782608695652173
Epoch:  548        3 Batch loss: 0.201203 Batch F1: 0.11764705882352941
Epoch:  548        4 Batch loss: 0.210237 Batch F1: 0.3636363636363636
Epoch:  548        5 Batch loss: 0.263945 Batch F1: 0.0
Epoch:  548        6 Batch loss: 0.200430 Batch F1: 0.21052631578947367
Epoch:  548        7 Batch loss: 0.242861 Batch F1: 0.3076923076923077
Epoch:  548        8 Batch loss: 0.219343 Batch F1: 0.48
Epoch:  548        9 Batch loss: 0.260380 Batch F1: 0.30303030303030304
Epoch:  548       10 Batch loss: 0.219941 Batch F1: 0.32
Epoch:  548       11 Batch loss: 0.202111 Batch F1: 0.18181818181818182
Epoch:  548       12 Batch loss: 0.237187 Batch F1: 0.25
Train Avg Loss  548: 0.222120

Train Avg F1  548: 0.27490360703444566

Val Avg Loss  548: 0.218979

Val Avg F1  548:  0.2501449275362319

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 549
--------------------------------------------------------------
Epoch:  549        1 Batch loss: 0.219218 Batch F1: 0.3333333333333333
Epoch:  549        2 Batch loss: 0.208883 Batch F1: 0.37037037037037035
Epoch:  549        3 Batch loss: 0.218700 Batch F1: 0.3333333333333333
Epoch:  549        4 Batch loss: 0.260014 Batch F1: 0.25806451612903225
Epoch:  549        5 Batch loss: 0.188497 Batch F1: 0.3333333333333333
Epoch:  549        6 Batch loss: 0.225477 Batch F1: 0.23999999999999996
Epoch:  549        7 Batch loss: 0.235006 Batch F1: 0.25
Epoch:  549        8 Batch loss: 0.241939 Batch F1: 0.3870967741935483
Epoch:  549        9 Batch loss: 0.175090 Batch F1: 0.6153846153846153
Epoch:  549       10 Batch loss: 0.211979 Batch F1: 0.3636363636363636
Epoch:  549       11 Batch loss: 0.228628 Batch F1: 0.46153846153846156
Epoch:  549       12 Batch loss: 0.253397 Batch F1: 0.09523809523809523
Train Avg Loss  549: 0.222236

Train Avg F1  549: 0.33677743304087393

Val Avg Loss  549: 0.219687

Val Avg F1  549:  0.24019607843137258

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 550
--------------------------------------------------------------
Epoch:  550        1 Batch loss: 0.203528 Batch F1: 0.4166666666666667
Epoch:  550        2 Batch loss: 0.231210 Batch F1: 0.23999999999999996
Epoch:  550        3 Batch loss: 0.225282 Batch F1: 0.1739130434782609
Epoch:  550        4 Batch loss: 0.217604 Batch F1: 0.4827586206896552
Epoch:  550        5 Batch loss: 0.206089 Batch F1: 0.48
Epoch:  550        6 Batch loss: 0.205459 Batch F1: 0.39999999999999997
Epoch:  550        7 Batch loss: 0.192760 Batch F1: 0.47619047619047616
Epoch:  550        8 Batch loss: 0.236166 Batch F1: 0.3125
Epoch:  550        9 Batch loss: 0.216357 Batch F1: 0.3333333333333333
Epoch:  550       10 Batch loss: 0.257870 Batch F1: 0.23076923076923075
Epoch:  550       11 Batch loss: 0.235706 Batch F1: 0.35714285714285715
Epoch:  550       12 Batch loss: 0.235782 Batch F1: 0.38095238095238093
Train Avg Loss  550: 0.221984

Train Avg F1  550: 0.3570188841019051

Val Avg Loss  550: 0.217952

Val Avg F1  550:  0.22857142857142856

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 551
--------------------------------------------------------------
Epoch:  551        1 Batch loss: 0.206969 Batch F1: 0.21052631578947367
Epoch:  551        2 Batch loss: 0.184046 Batch F1: 0.4
Epoch:  551        3 Batch loss: 0.225593 Batch F1: 0.41379310344827586
Epoch:  551        4 Batch loss: 0.243081 Batch F1: 0.23076923076923073
Epoch:  551        5 Batch loss: 0.237362 Batch F1: 0.0909090909090909
Epoch:  551        6 Batch loss: 0.189309 Batch F1: 0.3157894736842105
Epoch:  551        7 Batch loss: 0.235833 Batch F1: 0.3448275862068966
Epoch:  551        8 Batch loss: 0.270804 Batch F1: 0.14285714285714285
Epoch:  551        9 Batch loss: 0.204921 Batch F1: 0.43478260869565216
Epoch:  551       10 Batch loss: 0.215123 Batch F1: 0.2857142857142857
Epoch:  551       11 Batch loss: 0.249371 Batch F1: 0.4444444444444444
Epoch:  551       12 Batch loss: 0.198847 Batch F1: 0.26666666666666666
Train Avg Loss  551: 0.221772

Train Avg F1  551: 0.29842332909878083

Val Avg Loss  551: 0.218259

Val Avg F1  551:  0.2699019607843137

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 552
--------------------------------------------------------------
Epoch:  552        1 Batch loss: 0.213907 Batch F1: 0.21052631578947367
Epoch:  552        2 Batch loss: 0.222721 Batch F1: 0.4285714285714285
Epoch:  552        3 Batch loss: 0.236004 Batch F1: 0.23076923076923075
Epoch:  552        4 Batch loss: 0.234088 Batch F1: 0.35714285714285715
Epoch:  552        5 Batch loss: 0.223313 Batch F1: 0.30769230769230765
Epoch:  552        6 Batch loss: 0.217366 Batch F1: 0.21052631578947364
Epoch:  552        7 Batch loss: 0.207114 Batch F1: 0.16666666666666666
Epoch:  552        8 Batch loss: 0.256064 Batch F1: 0.27586206896551724
Epoch:  552        9 Batch loss: 0.233351 Batch F1: 0.2608695652173913
Epoch:  552       10 Batch loss: 0.216560 Batch F1: 0.39999999999999997
Epoch:  552       11 Batch loss: 0.190385 Batch F1: 0.3529411764705882
Epoch:  552       12 Batch loss: 0.218603 Batch F1: 0.3478260869565218
Train Avg Loss  552: 0.222456

Train Avg F1  552: 0.2957828350026214

Val Avg Loss  552: 0.218811

Val Avg F1  552:  0.22166666666666668

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 553
--------------------------------------------------------------
Epoch:  553        1 Batch loss: 0.207942 Batch F1: 0.2727272727272727
Epoch:  553        2 Batch loss: 0.204001 Batch F1: 0.3157894736842105
Epoch:  553        3 Batch loss: 0.245395 Batch F1: 0.21428571428571427
Epoch:  553        4 Batch loss: 0.184772 Batch F1: 0.4444444444444444
Epoch:  553        5 Batch loss: 0.225550 Batch F1: 0.35714285714285715
Epoch:  553        6 Batch loss: 0.234535 Batch F1: 0.3846153846153846
Epoch:  553        7 Batch loss: 0.189915 Batch F1: 0.23529411764705882
Epoch:  553        8 Batch loss: 0.277514 Batch F1: 0.13793103448275862
Epoch:  553        9 Batch loss: 0.250891 Batch F1: 0.2857142857142857
Epoch:  553       10 Batch loss: 0.230712 Batch F1: 0.24
Epoch:  553       11 Batch loss: 0.185085 Batch F1: 0.5
Epoch:  553       12 Batch loss: 0.229661 Batch F1: 0.4166666666666667
Train Avg Loss  553: 0.222164

Train Avg F1  553: 0.31705093761755443

Val Avg Loss  553: 0.219263

Val Avg F1  553:  0.24823415312545746

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 554
--------------------------------------------------------------
Epoch:  554        1 Batch loss: 0.199602 Batch F1: 0.4827586206896552
Epoch:  554        2 Batch loss: 0.275632 Batch F1: 0.1935483870967742
Epoch:  554        3 Batch loss: 0.239777 Batch F1: 0.1739130434782609
Epoch:  554        4 Batch loss: 0.178513 Batch F1: 0.5
Epoch:  554        5 Batch loss: 0.227629 Batch F1: 0.2857142857142857
Epoch:  554        6 Batch loss: 0.207543 Batch F1: 0.34782608695652173
Epoch:  554        7 Batch loss: 0.233679 Batch F1: 0.08695652173913045
Epoch:  554        8 Batch loss: 0.217443 Batch F1: 0.34782608695652173
Epoch:  554        9 Batch loss: 0.216382 Batch F1: 0.0
Epoch:  554       10 Batch loss: 0.202044 Batch F1: 0.5517241379310345
Epoch:  554       11 Batch loss: 0.240178 Batch F1: 0.25
Epoch:  554       12 Batch loss: 0.226882 Batch F1: 0.3478260869565218
Train Avg Loss  554: 0.222109

Train Avg F1  554: 0.29734110479322556

Val Avg Loss  554: 0.218404

Val Avg F1  554:  0.2364607170099161

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 555
--------------------------------------------------------------
Epoch:  555        1 Batch loss: 0.221371 Batch F1: 0.3
Epoch:  555        2 Batch loss: 0.220672 Batch F1: 0.1739130434782609
Epoch:  555        3 Batch loss: 0.234776 Batch F1: 0.4242424242424242
Epoch:  555        4 Batch loss: 0.226289 Batch F1: 0.35714285714285715
Epoch:  555        5 Batch loss: 0.215605 Batch F1: 0.32
Epoch:  555        6 Batch loss: 0.247133 Batch F1: 0.26666666666666666
Epoch:  555        7 Batch loss: 0.209754 Batch F1: 0.43478260869565216
Epoch:  555        8 Batch loss: 0.222916 Batch F1: 0.39999999999999997
Epoch:  555        9 Batch loss: 0.206142 Batch F1: 0.4166666666666667
Epoch:  555       10 Batch loss: 0.212623 Batch F1: 0.19047619047619047
Epoch:  555       11 Batch loss: 0.215309 Batch F1: 0.3333333333333333
Epoch:  555       12 Batch loss: 0.235550 Batch F1: 0.1904761904761905
Train Avg Loss  555: 0.222345

Train Avg F1  555: 0.31730833176485357

Val Avg Loss  555: 0.217462

Val Avg F1  555:  0.17454212454212453

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 556
--------------------------------------------------------------
Epoch:  556        1 Batch loss: 0.210900 Batch F1: 0.4166666666666667
Epoch:  556        2 Batch loss: 0.183106 Batch F1: 0.38095238095238093
Epoch:  556        3 Batch loss: 0.212412 Batch F1: 0.25
Epoch:  556        4 Batch loss: 0.251574 Batch F1: 0.3870967741935483
Epoch:  556        5 Batch loss: 0.194846 Batch F1: 0.4
Epoch:  556        6 Batch loss: 0.243609 Batch F1: 0.22222222222222224
Epoch:  556        7 Batch loss: 0.250893 Batch F1: 0.4117647058823529
Epoch:  556        8 Batch loss: 0.231909 Batch F1: 0.11111111111111112
Epoch:  556        9 Batch loss: 0.227990 Batch F1: 0.3
Epoch:  556       10 Batch loss: 0.246510 Batch F1: 0.0
Epoch:  556       11 Batch loss: 0.207828 Batch F1: 0.0
Epoch:  556       12 Batch loss: 0.212060 Batch F1: 0.0
Train Avg Loss  556: 0.222803

Train Avg F1  556: 0.2399844884190235

Val Avg Loss  556: 0.217321

Val Avg F1  556:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 557
--------------------------------------------------------------
Epoch:  557        1 Batch loss: 0.190920 Batch F1: 0.0
Epoch:  557        2 Batch loss: 0.233588 Batch F1: 0.0
Epoch:  557        3 Batch loss: 0.230991 Batch F1: 0.0
Epoch:  557        4 Batch loss: 0.183644 Batch F1: 0.0
Epoch:  557        5 Batch loss: 0.232404 Batch F1: 0.0
Epoch:  557        6 Batch loss: 0.226975 Batch F1: 0.0
Epoch:  557        7 Batch loss: 0.220206 Batch F1: 0.0
Epoch:  557        8 Batch loss: 0.254343 Batch F1: 0.0
Epoch:  557        9 Batch loss: 0.219257 Batch F1: 0.0
Epoch:  557       10 Batch loss: 0.218056 Batch F1: 0.35714285714285715
Epoch:  557       11 Batch loss: 0.251849 Batch F1: 0.35294117647058826
Epoch:  557       12 Batch loss: 0.215221 Batch F1: 0.6666666666666665
Train Avg Loss  557: 0.223121

Train Avg F1  557: 0.11472922502334267

Val Avg Loss  557: 0.228942

Val Avg F1  557:  0.41012341587999485

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 558
--------------------------------------------------------------
Epoch:  558        1 Batch loss: 0.210707 Batch F1: 0.5714285714285714
Epoch:  558        2 Batch loss: 0.221883 Batch F1: 0.2962962962962963
Epoch:  558        3 Batch loss: 0.239351 Batch F1: 0.0
Epoch:  558        4 Batch loss: 0.243612 Batch F1: 0.0
Epoch:  558        5 Batch loss: 0.187766 Batch F1: 0.0
Epoch:  558        6 Batch loss: 0.191222 Batch F1: 0.0
Epoch:  558        7 Batch loss: 0.222316 Batch F1: 0.0
Epoch:  558        8 Batch loss: 0.229544 Batch F1: 0.0
Epoch:  558        9 Batch loss: 0.195812 Batch F1: 0.0
Epoch:  558       10 Batch loss: 0.281930 Batch F1: 0.0
Epoch:  558       11 Batch loss: 0.246095 Batch F1: 0.14285714285714288
Epoch:  558       12 Batch loss: 0.235470 Batch F1: 0.56
Train Avg Loss  558: 0.225476

Train Avg F1  558: 0.13088183421516755

Val Avg Loss  558: 0.226684

Val Avg F1  558:  0.3500000000000001

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 559
--------------------------------------------------------------
Epoch:  559        1 Batch loss: 0.242294 Batch F1: 0.4736842105263159
Epoch:  559        2 Batch loss: 0.265288 Batch F1: 0.2758620689655173
Epoch:  559        3 Batch loss: 0.226389 Batch F1: 0.33333333333333337
Epoch:  559        4 Batch loss: 0.218507 Batch F1: 0.25
Epoch:  559        5 Batch loss: 0.214314 Batch F1: 0.0
Epoch:  559        6 Batch loss: 0.238159 Batch F1: 0.0
Epoch:  559        7 Batch loss: 0.237751 Batch F1: 0.0
Epoch:  559        8 Batch loss: 0.215381 Batch F1: 0.0
Epoch:  559        9 Batch loss: 0.235192 Batch F1: 0.0
Epoch:  559       10 Batch loss: 0.209066 Batch F1: 0.0
Epoch:  559       11 Batch loss: 0.196540 Batch F1: 0.0
Epoch:  559       12 Batch loss: 0.217249 Batch F1: 0.0
Train Avg Loss  559: 0.226344

Train Avg F1  559: 0.11107330106876388

Val Avg Loss  559: 0.216909

Val Avg F1  559:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 560
--------------------------------------------------------------
Epoch:  560        1 Batch loss: 0.234124 Batch F1: 0.0
Epoch:  560        2 Batch loss: 0.229330 Batch F1: 0.0
Epoch:  560        3 Batch loss: 0.218051 Batch F1: 0.0
Epoch:  560        4 Batch loss: 0.228516 Batch F1: 0.0
Epoch:  560        5 Batch loss: 0.230872 Batch F1: 0.0
Epoch:  560        6 Batch loss: 0.214299 Batch F1: 0.5185185185185185
Epoch:  560        7 Batch loss: 0.247290 Batch F1: 0.26666666666666666
Epoch:  560        8 Batch loss: 0.197519 Batch F1: 0.45454545454545453
Epoch:  560        9 Batch loss: 0.188379 Batch F1: 0.608695652173913
Epoch:  560       10 Batch loss: 0.215995 Batch F1: 0.2608695652173913
Epoch:  560       11 Batch loss: 0.238795 Batch F1: 0.0
Epoch:  560       12 Batch loss: 0.250484 Batch F1: 0.0
Train Avg Loss  560: 0.224471

Train Avg F1  560: 0.175774654760162

Val Avg Loss  560: 0.217737

Val Avg F1  560:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 561
--------------------------------------------------------------
Epoch:  561        1 Batch loss: 0.165279 Batch F1: 0.0
Epoch:  561        2 Batch loss: 0.219012 Batch F1: 0.0
Epoch:  561        3 Batch loss: 0.267174 Batch F1: 0.0
Epoch:  561        4 Batch loss: 0.228737 Batch F1: 0.0
Epoch:  561        5 Batch loss: 0.221284 Batch F1: 0.2
Epoch:  561        6 Batch loss: 0.243229 Batch F1: 0.411764705882353
Epoch:  561        7 Batch loss: 0.223523 Batch F1: 0.4
Epoch:  561        8 Batch loss: 0.223459 Batch F1: 0.5
Epoch:  561        9 Batch loss: 0.223696 Batch F1: 0.17391304347826086
Epoch:  561       10 Batch loss: 0.229798 Batch F1: 0.3225806451612903
Epoch:  561       11 Batch loss: 0.203104 Batch F1: 0.25
Epoch:  561       12 Batch loss: 0.248098 Batch F1: 0.2727272727272727
Train Avg Loss  561: 0.224699

Train Avg F1  561: 0.21091547227076476

Val Avg Loss  561: 0.218159

Val Avg F1  561:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 562
--------------------------------------------------------------
Epoch:  562        1 Batch loss: 0.244172 Batch F1: 0.0
Epoch:  562        2 Batch loss: 0.185377 Batch F1: 0.13333333333333333
Epoch:  562        3 Batch loss: 0.188429 Batch F1: 0.0
Epoch:  562        4 Batch loss: 0.278587 Batch F1: 0.0
Epoch:  562        5 Batch loss: 0.218759 Batch F1: 0.0
Epoch:  562        6 Batch loss: 0.229656 Batch F1: 0.0
Epoch:  562        7 Batch loss: 0.266733 Batch F1: 0.0
Epoch:  562        8 Batch loss: 0.214973 Batch F1: 0.0
Epoch:  562        9 Batch loss: 0.202376 Batch F1: 0.0
Epoch:  562       10 Batch loss: 0.225362 Batch F1: 0.0
Epoch:  562       11 Batch loss: 0.233419 Batch F1: 0.5454545454545455
Epoch:  562       12 Batch loss: 0.212005 Batch F1: 0.26666666666666666
Train Avg Loss  562: 0.224987

Train Avg F1  562: 0.0787878787878788

Val Avg Loss  562: 0.220262

Val Avg F1  562:  0.214573732718894

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 563
--------------------------------------------------------------
Epoch:  563        1 Batch loss: 0.221507 Batch F1: 0.3448275862068966
Epoch:  563        2 Batch loss: 0.230834 Batch F1: 0.35714285714285715
Epoch:  563        3 Batch loss: 0.220429 Batch F1: 0.0
Epoch:  563        4 Batch loss: 0.257852 Batch F1: 0.0
Epoch:  563        5 Batch loss: 0.209969 Batch F1: 0.0
Epoch:  563        6 Batch loss: 0.217627 Batch F1: 0.0
Epoch:  563        7 Batch loss: 0.176840 Batch F1: 0.0
Epoch:  563        8 Batch loss: 0.226519 Batch F1: 0.0
Epoch:  563        9 Batch loss: 0.222522 Batch F1: 0.0
Epoch:  563       10 Batch loss: 0.211718 Batch F1: 0.0
Epoch:  563       11 Batch loss: 0.242848 Batch F1: 0.08333333333333333
Epoch:  563       12 Batch loss: 0.248023 Batch F1: 0.3076923076923077
Train Avg Loss  563: 0.223891

Train Avg F1  563: 0.09108300703128291

Val Avg Loss  563: 0.219716

Val Avg F1  563:  0.22771739130434782

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 564
--------------------------------------------------------------
Epoch:  564        1 Batch loss: 0.223270 Batch F1: 0.41379310344827586
Epoch:  564        2 Batch loss: 0.207711 Batch F1: 0.3703703703703703
Epoch:  564        3 Batch loss: 0.228796 Batch F1: 0.5806451612903225
Epoch:  564        4 Batch loss: 0.238130 Batch F1: 0.32
Epoch:  564        5 Batch loss: 0.202189 Batch F1: 0.48
Epoch:  564        6 Batch loss: 0.227833 Batch F1: 0.41379310344827586
Epoch:  564        7 Batch loss: 0.252464 Batch F1: 0.36363636363636365
Epoch:  564        8 Batch loss: 0.255228 Batch F1: 0.1818181818181818
Epoch:  564        9 Batch loss: 0.207667 Batch F1: 0.0
Epoch:  564       10 Batch loss: 0.221282 Batch F1: 0.0
Epoch:  564       11 Batch loss: 0.202672 Batch F1: 0.0
Epoch:  564       12 Batch loss: 0.209087 Batch F1: 0.0
Train Avg Loss  564: 0.223027

Train Avg F1  564: 0.2603380236676492

Val Avg Loss  564: 0.218140

Val Avg F1  564:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 565
--------------------------------------------------------------
Epoch:  565        1 Batch loss: 0.228906 Batch F1: 0.0
Epoch:  565        2 Batch loss: 0.224285 Batch F1: 0.0
Epoch:  565        3 Batch loss: 0.200511 Batch F1: 0.0
Epoch:  565        4 Batch loss: 0.212370 Batch F1: 0.3
Epoch:  565        5 Batch loss: 0.221463 Batch F1: 0.3478260869565218
Epoch:  565        6 Batch loss: 0.241641 Batch F1: 0.0
Epoch:  565        7 Batch loss: 0.258572 Batch F1: 0.07999999999999999
Epoch:  565        8 Batch loss: 0.234645 Batch F1: 0.10526315789473684
Epoch:  565        9 Batch loss: 0.220914 Batch F1: 0.1904761904761905
Epoch:  565       10 Batch loss: 0.221878 Batch F1: 0.5
Epoch:  565       11 Batch loss: 0.216414 Batch F1: 0.5161290322580646
Epoch:  565       12 Batch loss: 0.200641 Batch F1: 0.5217391304347826
Train Avg Loss  565: 0.223520

Train Avg F1  565: 0.21345279983502471

Val Avg Loss  565: 0.220407

Val Avg F1  565:  0.24021645021645022

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 566
--------------------------------------------------------------
Epoch:  566        1 Batch loss: 0.200665 Batch F1: 0.3636363636363637
Epoch:  566        2 Batch loss: 0.221956 Batch F1: 0.0
Epoch:  566        3 Batch loss: 0.223779 Batch F1: 0.0
Epoch:  566        4 Batch loss: 0.255878 Batch F1: 0.0
Epoch:  566        5 Batch loss: 0.226758 Batch F1: 0.0
Epoch:  566        6 Batch loss: 0.226754 Batch F1: 0.0
Epoch:  566        7 Batch loss: 0.266604 Batch F1: 0.08695652173913045
Epoch:  566        8 Batch loss: 0.233507 Batch F1: 0.35714285714285715
Epoch:  566        9 Batch loss: 0.210232 Batch F1: 0.2857142857142857
Epoch:  566       10 Batch loss: 0.207158 Batch F1: 0.6153846153846153
Epoch:  566       11 Batch loss: 0.217608 Batch F1: 0.46153846153846156
Epoch:  566       12 Batch loss: 0.210053 Batch F1: 0.6086956521739131
Train Avg Loss  566: 0.225079

Train Avg F1  566: 0.23158906311080227

Val Avg Loss  566: 0.222526

Val Avg F1  566:  0.3200757575757575

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 567
--------------------------------------------------------------
Epoch:  567        1 Batch loss: 0.222327 Batch F1: 0.5333333333333333
Epoch:  567        2 Batch loss: 0.207735 Batch F1: 0.5
Epoch:  567        3 Batch loss: 0.229261 Batch F1: 0.23076923076923078
Epoch:  567        4 Batch loss: 0.219960 Batch F1: 0.27272727272727276
Epoch:  567        5 Batch loss: 0.241236 Batch F1: 0.14814814814814817
Epoch:  567        6 Batch loss: 0.225691 Batch F1: 0.18181818181818182
Epoch:  567        7 Batch loss: 0.202239 Batch F1: 0.0
Epoch:  567        8 Batch loss: 0.194101 Batch F1: 0.0
Epoch:  567        9 Batch loss: 0.192771 Batch F1: 0.0
Epoch:  567       10 Batch loss: 0.218899 Batch F1: 0.0
Epoch:  567       11 Batch loss: 0.296966 Batch F1: 0.0
Epoch:  567       12 Batch loss: 0.234425 Batch F1: 0.3333333333333333
Train Avg Loss  567: 0.223801

Train Avg F1  567: 0.18334412501079167

Val Avg Loss  567: 0.217948

Val Avg F1  567:  0.2641525141525142

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 568
--------------------------------------------------------------
Epoch:  568        1 Batch loss: 0.206273 Batch F1: 0.2222222222222222
Epoch:  568        2 Batch loss: 0.264575 Batch F1: 0.25806451612903225
Epoch:  568        3 Batch loss: 0.203716 Batch F1: 0.15384615384615385
Epoch:  568        4 Batch loss: 0.210096 Batch F1: 0.25
Epoch:  568        5 Batch loss: 0.205768 Batch F1: 0.4166666666666667
Epoch:  568        6 Batch loss: 0.202646 Batch F1: 0.3
Epoch:  568        7 Batch loss: 0.230151 Batch F1: 0.1
Epoch:  568        8 Batch loss: 0.235079 Batch F1: 0.08695652173913045
Epoch:  568        9 Batch loss: 0.239012 Batch F1: 0.0
Epoch:  568       10 Batch loss: 0.248281 Batch F1: 0.07692307692307693
Epoch:  568       11 Batch loss: 0.220917 Batch F1: 0.4
Epoch:  568       12 Batch loss: 0.203768 Batch F1: 0.45454545454545453
Train Avg Loss  568: 0.222524

Train Avg F1  568: 0.22660205100597808

Val Avg Loss  568: 0.219830

Val Avg F1  568:  0.24116427432216905

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 569
--------------------------------------------------------------
Epoch:  569        1 Batch loss: 0.200965 Batch F1: 0.36363636363636365
Epoch:  569        2 Batch loss: 0.216118 Batch F1: 0.41379310344827586
Epoch:  569        3 Batch loss: 0.216480 Batch F1: 0.5
Epoch:  569        4 Batch loss: 0.192337 Batch F1: 0.56
Epoch:  569        5 Batch loss: 0.216459 Batch F1: 0.19047619047619047
Epoch:  569        6 Batch loss: 0.228129 Batch F1: 0.25
Epoch:  569        7 Batch loss: 0.177805 Batch F1: 0.2857142857142857
Epoch:  569        8 Batch loss: 0.236958 Batch F1: 0.32
Epoch:  569        9 Batch loss: 0.238084 Batch F1: 0.0
Epoch:  569       10 Batch loss: 0.269003 Batch F1: 0.0
Epoch:  569       11 Batch loss: 0.266499 Batch F1: 0.0
Epoch:  569       12 Batch loss: 0.244125 Batch F1: 0.0
Train Avg Loss  569: 0.225247

Train Avg F1  569: 0.240301661939593

Val Avg Loss  569: 0.220133

Val Avg F1  569:  0.24867724867724866

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 570
--------------------------------------------------------------
Epoch:  570        1 Batch loss: 0.227832 Batch F1: 0.23076923076923078
Epoch:  570        2 Batch loss: 0.231355 Batch F1: 0.3076923076923077
Epoch:  570        3 Batch loss: 0.226163 Batch F1: 0.31999999999999995
Epoch:  570        4 Batch loss: 0.215581 Batch F1: 0.42857142857142855
Epoch:  570        5 Batch loss: 0.229831 Batch F1: 0.47058823529411764
Epoch:  570        6 Batch loss: 0.234264 Batch F1: 0.39999999999999997
Epoch:  570        7 Batch loss: 0.196041 Batch F1: 0.3
Epoch:  570        8 Batch loss: 0.241505 Batch F1: 0.4516129032258065
Epoch:  570        9 Batch loss: 0.210119 Batch F1: 0.3
Epoch:  570       10 Batch loss: 0.228955 Batch F1: 0.1818181818181818
Epoch:  570       11 Batch loss: 0.221081 Batch F1: 0.0
Epoch:  570       12 Batch loss: 0.227581 Batch F1: 0.0
Train Avg Loss  570: 0.224192

Train Avg F1  570: 0.28258769061425604

Val Avg Loss  570: 0.217012

Val Avg F1  570:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 571
--------------------------------------------------------------
Epoch:  571        1 Batch loss: 0.230163 Batch F1: 0.0
Epoch:  571        2 Batch loss: 0.223596 Batch F1: 0.1
Epoch:  571        3 Batch loss: 0.210015 Batch F1: 0.32
Epoch:  571        4 Batch loss: 0.234077 Batch F1: 0.25
Epoch:  571        5 Batch loss: 0.238110 Batch F1: 0.37037037037037035
Epoch:  571        6 Batch loss: 0.205411 Batch F1: 0.5333333333333333
Epoch:  571        7 Batch loss: 0.236337 Batch F1: 0.24
Epoch:  571        8 Batch loss: 0.235535 Batch F1: 0.46153846153846156
Epoch:  571        9 Batch loss: 0.180195 Batch F1: 0.0
Epoch:  571       10 Batch loss: 0.235142 Batch F1: 0.0
Epoch:  571       11 Batch loss: 0.232037 Batch F1: 0.0
Epoch:  571       12 Batch loss: 0.230102 Batch F1: 0.0
Train Avg Loss  571: 0.224227

Train Avg F1  571: 0.18960351377018045

Val Avg Loss  571: 0.217267

Val Avg F1  571:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 572
--------------------------------------------------------------
Epoch:  572        1 Batch loss: 0.250580 Batch F1: 0.0
Epoch:  572        2 Batch loss: 0.226140 Batch F1: 0.16666666666666669
Epoch:  572        3 Batch loss: 0.214657 Batch F1: 0.3
Epoch:  572        4 Batch loss: 0.201704 Batch F1: 0.13333333333333333
Epoch:  572        5 Batch loss: 0.245541 Batch F1: 0.2857142857142857
Epoch:  572        6 Batch loss: 0.235630 Batch F1: 0.37499999999999994
Epoch:  572        7 Batch loss: 0.219952 Batch F1: 0.45161290322580644
Epoch:  572        8 Batch loss: 0.215453 Batch F1: 0.5161290322580644
Epoch:  572        9 Batch loss: 0.208503 Batch F1: 0.23529411764705882
Epoch:  572       10 Batch loss: 0.201577 Batch F1: 0.4
Epoch:  572       11 Batch loss: 0.202725 Batch F1: 0.3
Epoch:  572       12 Batch loss: 0.280153 Batch F1: 0.09090909090909091
Train Avg Loss  572: 0.225218

Train Avg F1  572: 0.2712216191461922

Val Avg Loss  572: 0.218272

Val Avg F1  572:  0.02631578947368421

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 573
--------------------------------------------------------------
Epoch:  573        1 Batch loss: 0.249397 Batch F1: 0.14285714285714285
Epoch:  573        2 Batch loss: 0.201067 Batch F1: 0.0
Epoch:  573        3 Batch loss: 0.213010 Batch F1: 0.0
Epoch:  573        4 Batch loss: 0.202837 Batch F1: 0.0
Epoch:  573        5 Batch loss: 0.218080 Batch F1: 0.0
Epoch:  573        6 Batch loss: 0.255694 Batch F1: 0.0
Epoch:  573        7 Batch loss: 0.190373 Batch F1: 0.14285714285714288
Epoch:  573        8 Batch loss: 0.229390 Batch F1: 0.08695652173913042
Epoch:  573        9 Batch loss: 0.217320 Batch F1: 0.3478260869565218
Epoch:  573       10 Batch loss: 0.244191 Batch F1: 0.16666666666666666
Epoch:  573       11 Batch loss: 0.218702 Batch F1: 0.09090909090909091
Epoch:  573       12 Batch loss: 0.239818 Batch F1: 0.2105263157894737
Train Avg Loss  573: 0.223323

Train Avg F1  573: 0.0990499139812641

Val Avg Loss  573: 0.218606

Val Avg F1  573:  0.26352813852813856

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 574
--------------------------------------------------------------
Epoch:  574        1 Batch loss: 0.203031 Batch F1: 0.43478260869565216
Epoch:  574        2 Batch loss: 0.216306 Batch F1: 0.0
Epoch:  574        3 Batch loss: 0.207631 Batch F1: 0.125
Epoch:  574        4 Batch loss: 0.244941 Batch F1: 0.0
Epoch:  574        5 Batch loss: 0.226427 Batch F1: 0.0
Epoch:  574        6 Batch loss: 0.235813 Batch F1: 0.3448275862068965
Epoch:  574        7 Batch loss: 0.220555 Batch F1: 0.3478260869565218
Epoch:  574        8 Batch loss: 0.216326 Batch F1: 0.24
Epoch:  574        9 Batch loss: 0.230610 Batch F1: 0.2962962962962963
Epoch:  574       10 Batch loss: 0.235007 Batch F1: 0.3225806451612903
Epoch:  574       11 Batch loss: 0.219450 Batch F1: 0.3846153846153846
Epoch:  574       12 Batch loss: 0.211138 Batch F1: 0.5263157894736842
Train Avg Loss  574: 0.222270

Train Avg F1  574: 0.2518536997838105

Val Avg Loss  574: 0.221224

Val Avg F1  574:  0.32964280846589694

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 575
--------------------------------------------------------------
Epoch:  575        1 Batch loss: 0.238901 Batch F1: 0.35294117647058826
Epoch:  575        2 Batch loss: 0.240993 Batch F1: 0.5142857142857142
Epoch:  575        3 Batch loss: 0.214059 Batch F1: 0.4166666666666667
Epoch:  575        4 Batch loss: 0.244618 Batch F1: 0.5
Epoch:  575        5 Batch loss: 0.224600 Batch F1: 0.5
Epoch:  575        6 Batch loss: 0.204897 Batch F1: 0.3846153846153846
Epoch:  575        7 Batch loss: 0.221286 Batch F1: 0.38095238095238093
Epoch:  575        8 Batch loss: 0.229923 Batch F1: 0.4666666666666667
Epoch:  575        9 Batch loss: 0.231125 Batch F1: 0.5
Epoch:  575       10 Batch loss: 0.218785 Batch F1: 0.3478260869565218
Epoch:  575       11 Batch loss: 0.193449 Batch F1: 0.3
Epoch:  575       12 Batch loss: 0.200422 Batch F1: 0.3157894736842105
Train Avg Loss  575: 0.221921

Train Avg F1  575: 0.41497862919151113

Val Avg Loss  575: 0.217939

Val Avg F1  575:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 576
--------------------------------------------------------------
Epoch:  576        1 Batch loss: 0.196757 Batch F1: 0.11764705882352941
Epoch:  576        2 Batch loss: 0.255753 Batch F1: 0.0
Epoch:  576        3 Batch loss: 0.204600 Batch F1: 0.0
Epoch:  576        4 Batch loss: 0.194390 Batch F1: 0.0
Epoch:  576        5 Batch loss: 0.229670 Batch F1: 0.0
Epoch:  576        6 Batch loss: 0.246594 Batch F1: 0.0
Epoch:  576        7 Batch loss: 0.224355 Batch F1: 0.0
Epoch:  576        8 Batch loss: 0.223096 Batch F1: 0.1
Epoch:  576        9 Batch loss: 0.213099 Batch F1: 0.1111111111111111
Epoch:  576       10 Batch loss: 0.216730 Batch F1: 0.0
Epoch:  576       11 Batch loss: 0.246683 Batch F1: 0.08
Epoch:  576       12 Batch loss: 0.223616 Batch F1: 0.1111111111111111
Train Avg Loss  576: 0.222945

Train Avg F1  576: 0.043322440087145975

Val Avg Loss  576: 0.218731

Val Avg F1  576:  0.2487190748060313

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 577
--------------------------------------------------------------
Epoch:  577        1 Batch loss: 0.220965 Batch F1: 0.2
Epoch:  577        2 Batch loss: 0.226170 Batch F1: 0.37037037037037035
Epoch:  577        3 Batch loss: 0.206407 Batch F1: 0.3478260869565218
Epoch:  577        4 Batch loss: 0.210911 Batch F1: 0.4285714285714285
Epoch:  577        5 Batch loss: 0.259432 Batch F1: 0.13793103448275862
Epoch:  577        6 Batch loss: 0.192296 Batch F1: 0.47619047619047616
Epoch:  577        7 Batch loss: 0.208399 Batch F1: 0.39999999999999997
Epoch:  577        8 Batch loss: 0.192867 Batch F1: 0.25
Epoch:  577        9 Batch loss: 0.214103 Batch F1: 0.0
Epoch:  577       10 Batch loss: 0.275496 Batch F1: 0.0
Epoch:  577       11 Batch loss: 0.244496 Batch F1: 0.0
Epoch:  577       12 Batch loss: 0.237124 Batch F1: 0.2
Train Avg Loss  577: 0.224055

Train Avg F1  577: 0.23424078304762963

Val Avg Loss  577: 0.218535

Val Avg F1  577:  0.2617692452475061

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 578
--------------------------------------------------------------
Epoch:  578        1 Batch loss: 0.233489 Batch F1: 0.25
Epoch:  578        2 Batch loss: 0.215028 Batch F1: 0.1
Epoch:  578        3 Batch loss: 0.247188 Batch F1: 0.16
Epoch:  578        4 Batch loss: 0.212387 Batch F1: 0.2
Epoch:  578        5 Batch loss: 0.228769 Batch F1: 0.5333333333333333
Epoch:  578        6 Batch loss: 0.212034 Batch F1: 0.09523809523809525
Epoch:  578        7 Batch loss: 0.195435 Batch F1: 0.0
Epoch:  578        8 Batch loss: 0.243581 Batch F1: 0.0
Epoch:  578        9 Batch loss: 0.222188 Batch F1: 0.0
Epoch:  578       10 Batch loss: 0.235119 Batch F1: 0.07999999999999999
Epoch:  578       11 Batch loss: 0.252269 Batch F1: 0.3125
Epoch:  578       12 Batch loss: 0.188909 Batch F1: 0.3529411764705882
Train Avg Loss  578: 0.223866

Train Avg F1  578: 0.17366771708683473

Val Avg Loss  578: 0.219791

Val Avg F1  578:  0.2404783510500389

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 579
--------------------------------------------------------------
Epoch:  579        1 Batch loss: 0.231055 Batch F1: 0.0
Epoch:  579        2 Batch loss: 0.223186 Batch F1: 0.35714285714285715
Epoch:  579        3 Batch loss: 0.242383 Batch F1: 0.43750000000000006
Epoch:  579        4 Batch loss: 0.230543 Batch F1: 0.23999999999999996
Epoch:  579        5 Batch loss: 0.239276 Batch F1: 0.08695652173913045
Epoch:  579        6 Batch loss: 0.210947 Batch F1: 0.1904761904761905
Epoch:  579        7 Batch loss: 0.207698 Batch F1: 0.5185185185185185
Epoch:  579        8 Batch loss: 0.214106 Batch F1: 0.0
Epoch:  579        9 Batch loss: 0.204636 Batch F1: 0.10526315789473684
Epoch:  579       10 Batch loss: 0.215703 Batch F1: 0.1
Epoch:  579       11 Batch loss: 0.215089 Batch F1: 0.19047619047619047
Epoch:  579       12 Batch loss: 0.231418 Batch F1: 0.3
Train Avg Loss  579: 0.222170

Train Avg F1  579: 0.21052778635396865

Val Avg Loss  579: 0.218688

Val Avg F1  579:  0.25496031746031744

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 580
--------------------------------------------------------------
Epoch:  580        1 Batch loss: 0.201558 Batch F1: 0.36363636363636365
Epoch:  580        2 Batch loss: 0.226450 Batch F1: 0.16666666666666669
Epoch:  580        3 Batch loss: 0.244432 Batch F1: 0.25806451612903225
Epoch:  580        4 Batch loss: 0.208285 Batch F1: 0.43478260869565216
Epoch:  580        5 Batch loss: 0.232285 Batch F1: 0.30769230769230765
Epoch:  580        6 Batch loss: 0.191769 Batch F1: 0.13333333333333333
Epoch:  580        7 Batch loss: 0.227361 Batch F1: 0.0
Epoch:  580        8 Batch loss: 0.233484 Batch F1: 0.0
Epoch:  580        9 Batch loss: 0.219338 Batch F1: 0.1904761904761905
Epoch:  580       10 Batch loss: 0.246043 Batch F1: 0.3448275862068965
Epoch:  580       11 Batch loss: 0.220045 Batch F1: 0.33333333333333337
Epoch:  580       12 Batch loss: 0.225908 Batch F1: 0.1111111111111111
Train Avg Loss  580: 0.223080

Train Avg F1  580: 0.22032700144007392

Val Avg Loss  580: 0.220305

Val Avg F1  580:  0.23975951584647237

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 581
--------------------------------------------------------------
Epoch:  581        1 Batch loss: 0.240284 Batch F1: 0.19354838709677416
Epoch:  581        2 Batch loss: 0.248747 Batch F1: 0.37037037037037035
Epoch:  581        3 Batch loss: 0.230161 Batch F1: 0.4444444444444445
Epoch:  581        4 Batch loss: 0.221209 Batch F1: 0.09090909090909091
Epoch:  581        5 Batch loss: 0.221708 Batch F1: 0.35714285714285715
Epoch:  581        6 Batch loss: 0.249364 Batch F1: 0.17391304347826086
Epoch:  581        7 Batch loss: 0.229143 Batch F1: 0.37037037037037035
Epoch:  581        8 Batch loss: 0.236464 Batch F1: 0.1904761904761905
Epoch:  581        9 Batch loss: 0.187257 Batch F1: 0.3157894736842105
Epoch:  581       10 Batch loss: 0.231159 Batch F1: 0.0
Epoch:  581       11 Batch loss: 0.174148 Batch F1: 0.3076923076923077
Epoch:  581       12 Batch loss: 0.207316 Batch F1: 0.0
Train Avg Loss  581: 0.223080

Train Avg F1  581: 0.23455471130540642

Val Avg Loss  581: 0.217991

Val Avg F1  581:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 582
--------------------------------------------------------------
Epoch:  582        1 Batch loss: 0.197684 Batch F1: 0.0
Epoch:  582        2 Batch loss: 0.278461 Batch F1: 0.0
Epoch:  582        3 Batch loss: 0.231912 Batch F1: 0.0
Epoch:  582        4 Batch loss: 0.220070 Batch F1: 0.0
Epoch:  582        5 Batch loss: 0.227934 Batch F1: 0.0
Epoch:  582        6 Batch loss: 0.225579 Batch F1: 0.0909090909090909
Epoch:  582        7 Batch loss: 0.228178 Batch F1: 0.09523809523809523
Epoch:  582        8 Batch loss: 0.238908 Batch F1: 0.23076923076923073
Epoch:  582        9 Batch loss: 0.238568 Batch F1: 0.25
Epoch:  582       10 Batch loss: 0.193911 Batch F1: 0.0
Epoch:  582       11 Batch loss: 0.207029 Batch F1: 0.0
Epoch:  582       12 Batch loss: 0.207733 Batch F1: 0.125
Train Avg Loss  582: 0.224664

Train Avg F1  582: 0.06599303474303474

Val Avg Loss  582: 0.218187

Val Avg F1  582:  0.022727272727272728

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 583
--------------------------------------------------------------
Epoch:  583        1 Batch loss: 0.203862 Batch F1: 0.19047619047619047
Epoch:  583        2 Batch loss: 0.201204 Batch F1: 0.0
Epoch:  583        3 Batch loss: 0.277319 Batch F1: 0.19354838709677416
Epoch:  583        4 Batch loss: 0.212689 Batch F1: 0.31578947368421056
Epoch:  583        5 Batch loss: 0.232867 Batch F1: 0.16000000000000003
Epoch:  583        6 Batch loss: 0.263553 Batch F1: 0.3225806451612903
Epoch:  583        7 Batch loss: 0.195297 Batch F1: 0.5
Epoch:  583        8 Batch loss: 0.233117 Batch F1: 0.35714285714285715
Epoch:  583        9 Batch loss: 0.211792 Batch F1: 0.2
Epoch:  583       10 Batch loss: 0.204298 Batch F1: 0.4166666666666667
Epoch:  583       11 Batch loss: 0.209121 Batch F1: 0.2857142857142857
Epoch:  583       12 Batch loss: 0.226186 Batch F1: 0.35294117647058826
Train Avg Loss  583: 0.222609

Train Avg F1  583: 0.27457164020107194

Val Avg Loss  583: 0.217568

Val Avg F1  583:  0.26714766714766713

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 584
--------------------------------------------------------------
Epoch:  584        1 Batch loss: 0.212713 Batch F1: 0.2608695652173913
Epoch:  584        2 Batch loss: 0.194463 Batch F1: 0.0
Epoch:  584        3 Batch loss: 0.212771 Batch F1: 0.0
Epoch:  584        4 Batch loss: 0.223990 Batch F1: 0.0
Epoch:  584        5 Batch loss: 0.175780 Batch F1: 0.0
Epoch:  584        6 Batch loss: 0.227854 Batch F1: 0.0
Epoch:  584        7 Batch loss: 0.242753 Batch F1: 0.0
Epoch:  584        8 Batch loss: 0.207377 Batch F1: 0.0
Epoch:  584        9 Batch loss: 0.256278 Batch F1: 0.0
Epoch:  584       10 Batch loss: 0.246695 Batch F1: 0.08695652173913045
Epoch:  584       11 Batch loss: 0.237986 Batch F1: 0.3333333333333333
Epoch:  584       12 Batch loss: 0.252587 Batch F1: 0.3846153846153846
Train Avg Loss  584: 0.224271

Train Avg F1  584: 0.08881456707543663

Val Avg Loss  584: 0.224601

Val Avg F1  584:  0.3303713527851459

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 585
--------------------------------------------------------------
Epoch:  585        1 Batch loss: 0.237651 Batch F1: 0.32
Epoch:  585        2 Batch loss: 0.242207 Batch F1: 0.42857142857142855
Epoch:  585        3 Batch loss: 0.238489 Batch F1: 0.32
Epoch:  585        4 Batch loss: 0.211414 Batch F1: 0.5625
Epoch:  585        5 Batch loss: 0.223910 Batch F1: 0.24
Epoch:  585        6 Batch loss: 0.240665 Batch F1: 0.2
Epoch:  585        7 Batch loss: 0.211513 Batch F1: 0.25
Epoch:  585        8 Batch loss: 0.239805 Batch F1: 0.35714285714285715
Epoch:  585        9 Batch loss: 0.222075 Batch F1: 0.30769230769230765
Epoch:  585       10 Batch loss: 0.233258 Batch F1: 0.2608695652173913
Epoch:  585       11 Batch loss: 0.182941 Batch F1: 0.3157894736842105
Epoch:  585       12 Batch loss: 0.196811 Batch F1: 0.0
Train Avg Loss  585: 0.223395

Train Avg F1  585: 0.29688046935901624

Val Avg Loss  585: 0.217386

Val Avg F1  585:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 586
--------------------------------------------------------------
Epoch:  586        1 Batch loss: 0.239591 Batch F1: 0.0
Epoch:  586        2 Batch loss: 0.205243 Batch F1: 0.0
Epoch:  586        3 Batch loss: 0.253806 Batch F1: 0.3333333333333333
Epoch:  586        4 Batch loss: 0.227907 Batch F1: 0.3333333333333333
Epoch:  586        5 Batch loss: 0.221220 Batch F1: 0.5161290322580646
Epoch:  586        6 Batch loss: 0.230320 Batch F1: 0.375
Epoch:  586        7 Batch loss: 0.237581 Batch F1: 0.16
Epoch:  586        8 Batch loss: 0.204925 Batch F1: 0.26086956521739135
Epoch:  586        9 Batch loss: 0.198768 Batch F1: 0.11764705882352941
Epoch:  586       10 Batch loss: 0.249764 Batch F1: 0.0
Epoch:  586       11 Batch loss: 0.186507 Batch F1: 0.0
Epoch:  586       12 Batch loss: 0.237167 Batch F1: 0.2
Train Avg Loss  586: 0.224400

Train Avg F1  586: 0.19135936024713765

Val Avg Loss  586: 0.218082

Val Avg F1  586:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 587
--------------------------------------------------------------
Epoch:  587        1 Batch loss: 0.194391 Batch F1: 0.0
Epoch:  587        2 Batch loss: 0.228927 Batch F1: 0.0
Epoch:  587        3 Batch loss: 0.207950 Batch F1: 0.0
Epoch:  587        4 Batch loss: 0.212308 Batch F1: 0.0
Epoch:  587        5 Batch loss: 0.255595 Batch F1: 0.0
Epoch:  587        6 Batch loss: 0.209192 Batch F1: 0.2727272727272727
Epoch:  587        7 Batch loss: 0.227956 Batch F1: 0.1111111111111111
Epoch:  587        8 Batch loss: 0.242128 Batch F1: 0.16000000000000003
Epoch:  587        9 Batch loss: 0.234382 Batch F1: 0.2608695652173913
Epoch:  587       10 Batch loss: 0.199792 Batch F1: 0.6363636363636364
Epoch:  587       11 Batch loss: 0.222794 Batch F1: 0.24
Epoch:  587       12 Batch loss: 0.238777 Batch F1: 0.18181818181818182
Train Avg Loss  587: 0.222849

Train Avg F1  587: 0.15524081393646613

Val Avg Loss  587: 0.219353

Val Avg F1  587:  0.24927307879673608

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 588
--------------------------------------------------------------
Epoch:  588        1 Batch loss: 0.236919 Batch F1: 0.37037037037037035
Epoch:  588        2 Batch loss: 0.236800 Batch F1: 0.32
Epoch:  588        3 Batch loss: 0.208126 Batch F1: 0.2727272727272727
Epoch:  588        4 Batch loss: 0.221193 Batch F1: 0.27272727272727276
Epoch:  588        5 Batch loss: 0.210346 Batch F1: 0.11764705882352941
Epoch:  588        6 Batch loss: 0.227744 Batch F1: 0.0
Epoch:  588        7 Batch loss: 0.223063 Batch F1: 0.0
Epoch:  588        8 Batch loss: 0.185824 Batch F1: 0.0
Epoch:  588        9 Batch loss: 0.233789 Batch F1: 0.0
Epoch:  588       10 Batch loss: 0.220795 Batch F1: 0.0
Epoch:  588       11 Batch loss: 0.239932 Batch F1: 0.20689655172413796
Epoch:  588       12 Batch loss: 0.242388 Batch F1: 0.09523809523809523
Train Avg Loss  588: 0.223910

Train Avg F1  588: 0.13796721846755652

Val Avg Loss  588: 0.220499

Val Avg F1  588:  0.27262649692523466

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 589
--------------------------------------------------------------
Epoch:  589        1 Batch loss: 0.216193 Batch F1: 0.46153846153846156
Epoch:  589        2 Batch loss: 0.236469 Batch F1: 0.08333333333333333
Epoch:  589        3 Batch loss: 0.236875 Batch F1: 0.33333333333333326
Epoch:  589        4 Batch loss: 0.206501 Batch F1: 0.4166666666666667
Epoch:  589        5 Batch loss: 0.221366 Batch F1: 0.25
Epoch:  589        6 Batch loss: 0.210790 Batch F1: 0.10526315789473684
Epoch:  589        7 Batch loss: 0.230740 Batch F1: 0.32
Epoch:  589        8 Batch loss: 0.226079 Batch F1: 0.4375
Epoch:  589        9 Batch loss: 0.210571 Batch F1: 0.19047619047619047
Epoch:  589       10 Batch loss: 0.244312 Batch F1: 0.08333333333333333
Epoch:  589       11 Batch loss: 0.230475 Batch F1: 0.37037037037037035
Epoch:  589       12 Batch loss: 0.200778 Batch F1: 0.25
Train Avg Loss  589: 0.222596

Train Avg F1  589: 0.27515123724553553

Val Avg Loss  589: 0.220252

Val Avg F1  589:  0.2445031055900621

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 590
--------------------------------------------------------------
Epoch:  590        1 Batch loss: 0.252930 Batch F1: 0.30303030303030304
Epoch:  590        2 Batch loss: 0.245352 Batch F1: 0.08333333333333334
Epoch:  590        3 Batch loss: 0.223760 Batch F1: 0.5161290322580645
Epoch:  590        4 Batch loss: 0.231599 Batch F1: 0.25
Epoch:  590        5 Batch loss: 0.219775 Batch F1: 0.35714285714285715
Epoch:  590        6 Batch loss: 0.182205 Batch F1: 0.4615384615384615
Epoch:  590        7 Batch loss: 0.203835 Batch F1: 0.125
Epoch:  590        8 Batch loss: 0.209892 Batch F1: 0.0
Epoch:  590        9 Batch loss: 0.243964 Batch F1: 0.0
Epoch:  590       10 Batch loss: 0.254668 Batch F1: 0.26666666666666666
Epoch:  590       11 Batch loss: 0.220320 Batch F1: 0.7027027027027026
Epoch:  590       12 Batch loss: 0.241903 Batch F1: 0.3703703703703703
Train Avg Loss  590: 0.227517

Train Avg F1  590: 0.28632614392022987

Val Avg Loss  590: 0.229138

Val Avg F1  590:  0.3504395604395604

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 591
--------------------------------------------------------------
Epoch:  591        1 Batch loss: 0.235780 Batch F1: 0.4
Epoch:  591        2 Batch loss: 0.229621 Batch F1: 0.24
Epoch:  591        3 Batch loss: 0.177054 Batch F1: 0.0
Epoch:  591        4 Batch loss: 0.284005 Batch F1: 0.0
Epoch:  591        5 Batch loss: 0.227683 Batch F1: 0.0
Epoch:  591        6 Batch loss: 0.204601 Batch F1: 0.0
Epoch:  591        7 Batch loss: 0.222962 Batch F1: 0.0
Epoch:  591        8 Batch loss: 0.212967 Batch F1: 0.0
Epoch:  591        9 Batch loss: 0.202194 Batch F1: 0.0
Epoch:  591       10 Batch loss: 0.257581 Batch F1: 0.0
Epoch:  591       11 Batch loss: 0.206504 Batch F1: 0.5
Epoch:  591       12 Batch loss: 0.253615 Batch F1: 0.23999999999999996
Train Avg Loss  591: 0.226214

Train Avg F1  591: 0.115

Val Avg Loss  591: 0.221502

Val Avg F1  591:  0.30911185588604945

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 592
--------------------------------------------------------------
Epoch:  592        1 Batch loss: 0.205764 Batch F1: 0.2857142857142857
Epoch:  592        2 Batch loss: 0.207149 Batch F1: 0.38095238095238093
Epoch:  592        3 Batch loss: 0.214072 Batch F1: 0.3636363636363636
Epoch:  592        4 Batch loss: 0.262556 Batch F1: 0.36363636363636365
Epoch:  592        5 Batch loss: 0.228273 Batch F1: 0.1818181818181818
Epoch:  592        6 Batch loss: 0.208626 Batch F1: 0.44444444444444436
Epoch:  592        7 Batch loss: 0.246111 Batch F1: 0.411764705882353
Epoch:  592        8 Batch loss: 0.210757 Batch F1: 0.3846153846153846
Epoch:  592        9 Batch loss: 0.235535 Batch F1: 0.45714285714285713
Epoch:  592       10 Batch loss: 0.223220 Batch F1: 0.5000000000000001
Epoch:  592       11 Batch loss: 0.198722 Batch F1: 0.41666666666666663
Epoch:  592       12 Batch loss: 0.255228 Batch F1: 0.0
Train Avg Loss  592: 0.224668

Train Avg F1  592: 0.34919930287577344

Val Avg Loss  592: 0.217995

Val Avg F1  592:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 593
--------------------------------------------------------------
Epoch:  593        1 Batch loss: 0.225578 Batch F1: 0.0
Epoch:  593        2 Batch loss: 0.230521 Batch F1: 0.0
Epoch:  593        3 Batch loss: 0.259733 Batch F1: 0.0
Epoch:  593        4 Batch loss: 0.226940 Batch F1: 0.0
Epoch:  593        5 Batch loss: 0.199491 Batch F1: 0.0
Epoch:  593        6 Batch loss: 0.252981 Batch F1: 0.0
Epoch:  593        7 Batch loss: 0.200790 Batch F1: 0.0
Epoch:  593        8 Batch loss: 0.219795 Batch F1: 0.09523809523809523
Epoch:  593        9 Batch loss: 0.221769 Batch F1: 0.0
Epoch:  593       10 Batch loss: 0.211371 Batch F1: 0.0
Epoch:  593       11 Batch loss: 0.227775 Batch F1: 0.0
Epoch:  593       12 Batch loss: 0.213419 Batch F1: 0.26666666666666666
Train Avg Loss  593: 0.224180

Train Avg F1  593: 0.03015873015873016

Val Avg Loss  593: 0.218553

Val Avg F1  593:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 594
--------------------------------------------------------------
Epoch:  594        1 Batch loss: 0.226133 Batch F1: 0.0
Epoch:  594        2 Batch loss: 0.229714 Batch F1: 0.0
Epoch:  594        3 Batch loss: 0.204259 Batch F1: 0.0
Epoch:  594        4 Batch loss: 0.187542 Batch F1: 0.0
Epoch:  594        5 Batch loss: 0.212454 Batch F1: 0.0
Epoch:  594        6 Batch loss: 0.267218 Batch F1: 0.0
Epoch:  594        7 Batch loss: 0.202200 Batch F1: 0.0
Epoch:  594        8 Batch loss: 0.272119 Batch F1: 0.0
Epoch:  594        9 Batch loss: 0.231396 Batch F1: 0.0
Epoch:  594       10 Batch loss: 0.231772 Batch F1: 0.0
Epoch:  594       11 Batch loss: 0.222820 Batch F1: 0.39999999999999997
Epoch:  594       12 Batch loss: 0.195898 Batch F1: 0.3809523809523809
Train Avg Loss  594: 0.223627

Train Avg F1  594: 0.06507936507936507

Val Avg Loss  594: 0.220402

Val Avg F1  594:  0.25114468864468864

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 595
--------------------------------------------------------------
Epoch:  595        1 Batch loss: 0.225706 Batch F1: 0.5142857142857142
Epoch:  595        2 Batch loss: 0.243297 Batch F1: 0.16
Epoch:  595        3 Batch loss: 0.224280 Batch F1: 0.39999999999999997
Epoch:  595        4 Batch loss: 0.243216 Batch F1: 0.4848484848484849
Epoch:  595        5 Batch loss: 0.209844 Batch F1: 0.44444444444444436
Epoch:  595        6 Batch loss: 0.233358 Batch F1: 0.3846153846153846
Epoch:  595        7 Batch loss: 0.217487 Batch F1: 0.5161290322580645
Epoch:  595        8 Batch loss: 0.194347 Batch F1: 0.4799999999999999
Epoch:  595        9 Batch loss: 0.241152 Batch F1: 0.2962962962962963
Epoch:  595       10 Batch loss: 0.238839 Batch F1: 0.2727272727272727
Epoch:  595       11 Batch loss: 0.243057 Batch F1: 0.23999999999999996
Epoch:  595       12 Batch loss: 0.158060 Batch F1: 0.1818181818181818
Train Avg Loss  595: 0.222720

Train Avg F1  595: 0.3645970676078203

Val Avg Loss  595: 0.218302

Val Avg F1  595:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 596
--------------------------------------------------------------
Epoch:  596        1 Batch loss: 0.221920 Batch F1: 0.0
Epoch:  596        2 Batch loss: 0.214172 Batch F1: 0.0
Epoch:  596        3 Batch loss: 0.210326 Batch F1: 0.0
Epoch:  596        4 Batch loss: 0.198393 Batch F1: 0.0
Epoch:  596        5 Batch loss: 0.251205 Batch F1: 0.0
Epoch:  596        6 Batch loss: 0.224482 Batch F1: 0.0
Epoch:  596        7 Batch loss: 0.228510 Batch F1: 0.0
Epoch:  596        8 Batch loss: 0.205592 Batch F1: 0.11764705882352941
Epoch:  596        9 Batch loss: 0.230621 Batch F1: 0.0
Epoch:  596       10 Batch loss: 0.238591 Batch F1: 0.0
Epoch:  596       11 Batch loss: 0.231423 Batch F1: 0.0
Epoch:  596       12 Batch loss: 0.251289 Batch F1: 0.1
Train Avg Loss  596: 0.225544

Train Avg F1  596: 0.018137254901960786

Val Avg Loss  596: 0.219188

Val Avg F1  596:  0.1478433402346446

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 597
--------------------------------------------------------------
Epoch:  597        1 Batch loss: 0.210617 Batch F1: 0.11764705882352941
Epoch:  597        2 Batch loss: 0.215137 Batch F1: 0.43478260869565216
Epoch:  597        3 Batch loss: 0.248296 Batch F1: 0.06896551724137931
Epoch:  597        4 Batch loss: 0.226603 Batch F1: 0.4666666666666667
Epoch:  597        5 Batch loss: 0.229743 Batch F1: 0.3333333333333333
Epoch:  597        6 Batch loss: 0.221864 Batch F1: 0.23076923076923078
Epoch:  597        7 Batch loss: 0.246898 Batch F1: 0.20689655172413793
Epoch:  597        8 Batch loss: 0.213177 Batch F1: 0.3157894736842105
Epoch:  597        9 Batch loss: 0.235281 Batch F1: 0.33333333333333326
Epoch:  597       10 Batch loss: 0.215074 Batch F1: 0.09090909090909091
Epoch:  597       11 Batch loss: 0.207436 Batch F1: 0.0
Epoch:  597       12 Batch loss: 0.207568 Batch F1: 0.0
Train Avg Loss  597: 0.223141

Train Avg F1  597: 0.21659107209838036

Val Avg Loss  597: 0.217189

Val Avg F1  597:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 598
--------------------------------------------------------------
Epoch:  598        1 Batch loss: 0.267320 Batch F1: 0.0
Epoch:  598        2 Batch loss: 0.260889 Batch F1: 0.0
Epoch:  598        3 Batch loss: 0.232122 Batch F1: 0.0
Epoch:  598        4 Batch loss: 0.196198 Batch F1: 0.5454545454545455
Epoch:  598        5 Batch loss: 0.211669 Batch F1: 0.5
Epoch:  598        6 Batch loss: 0.206197 Batch F1: 0.1739130434782609
Epoch:  598        7 Batch loss: 0.226471 Batch F1: 0.37037037037037035
Epoch:  598        8 Batch loss: 0.234166 Batch F1: 0.3333333333333333
Epoch:  598        9 Batch loss: 0.226166 Batch F1: 0.25
Epoch:  598       10 Batch loss: 0.200038 Batch F1: 0.42105263157894735
Epoch:  598       11 Batch loss: 0.202863 Batch F1: 0.0
Epoch:  598       12 Batch loss: 0.232979 Batch F1: 0.0
Train Avg Loss  598: 0.224757

Train Avg F1  598: 0.21617699368462143

Val Avg Loss  598: 0.217765

Val Avg F1  598:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 599
--------------------------------------------------------------
Epoch:  599        1 Batch loss: 0.195017 Batch F1: 0.0
Epoch:  599        2 Batch loss: 0.246513 Batch F1: 0.15384615384615383
Epoch:  599        3 Batch loss: 0.208190 Batch F1: 0.0
Epoch:  599        4 Batch loss: 0.229715 Batch F1: 0.37037037037037035
Epoch:  599        5 Batch loss: 0.270890 Batch F1: 0.26666666666666666
Epoch:  599        6 Batch loss: 0.191043 Batch F1: 0.13333333333333333
Epoch:  599        7 Batch loss: 0.201546 Batch F1: 0.4
Epoch:  599        8 Batch loss: 0.209970 Batch F1: 0.2857142857142857
Epoch:  599        9 Batch loss: 0.216574 Batch F1: 0.3846153846153846
Epoch:  599       10 Batch loss: 0.213256 Batch F1: 0.1818181818181818
Epoch:  599       11 Batch loss: 0.233528 Batch F1: 0.2608695652173913
Epoch:  599       12 Batch loss: 0.273377 Batch F1: 0.1739130434782609
Train Avg Loss  599: 0.224135

Train Avg F1  599: 0.21759558208833565

Val Avg Loss  599: 0.218107

Val Avg F1  599:  0.18885836385836385

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 600
--------------------------------------------------------------
Epoch:  600        1 Batch loss: 0.242947 Batch F1: 0.08
Epoch:  600        2 Batch loss: 0.168246 Batch F1: 0.5555555555555556
Epoch:  600        3 Batch loss: 0.242922 Batch F1: 0.16666666666666669
Epoch:  600        4 Batch loss: 0.187656 Batch F1: 0.33333333333333337
Epoch:  600        5 Batch loss: 0.211146 Batch F1: 0.1111111111111111
Epoch:  600        6 Batch loss: 0.218083 Batch F1: 0.10526315789473684
Epoch:  600        7 Batch loss: 0.224279 Batch F1: 0.0
Epoch:  600        8 Batch loss: 0.260559 Batch F1: 0.0
Epoch:  600        9 Batch loss: 0.235380 Batch F1: 0.0
Epoch:  600       10 Batch loss: 0.215050 Batch F1: 0.42857142857142855
Epoch:  600       11 Batch loss: 0.218630 Batch F1: 0.39999999999999997
Epoch:  600       12 Batch loss: 0.258270 Batch F1: 0.16
Train Avg Loss  600: 0.223597

Train Avg F1  600: 0.19504177109440268

Val Avg Loss  600: 0.220902

Val Avg F1  600:  0.2511111111111111

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 601
--------------------------------------------------------------
Epoch:  601        1 Batch loss: 0.261898 Batch F1: 0.29411764705882354
Epoch:  601        2 Batch loss: 0.185089 Batch F1: 0.5
Epoch:  601        3 Batch loss: 0.235593 Batch F1: 0.32000000000000006
Epoch:  601        4 Batch loss: 0.199292 Batch F1: 0.0
Epoch:  601        5 Batch loss: 0.225342 Batch F1: 0.0
Epoch:  601        6 Batch loss: 0.199348 Batch F1: 0.13333333333333333
Epoch:  601        7 Batch loss: 0.222081 Batch F1: 0.0
Epoch:  601        8 Batch loss: 0.186755 Batch F1: 0.0
Epoch:  601        9 Batch loss: 0.261151 Batch F1: 0.0
Epoch:  601       10 Batch loss: 0.268596 Batch F1: 0.07142857142857142
Epoch:  601       11 Batch loss: 0.195975 Batch F1: 0.3157894736842105
Epoch:  601       12 Batch loss: 0.241780 Batch F1: 0.0909090909090909
Train Avg Loss  601: 0.223575

Train Avg F1  601: 0.1437981763678358

Val Avg Loss  601: 0.219869

Val Avg F1  601:  0.2516751364577452

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 602
--------------------------------------------------------------
Epoch:  602        1 Batch loss: 0.222054 Batch F1: 0.37037037037037035
Epoch:  602        2 Batch loss: 0.229545 Batch F1: 0.44444444444444436
Epoch:  602        3 Batch loss: 0.220430 Batch F1: 0.35714285714285715
Epoch:  602        4 Batch loss: 0.203907 Batch F1: 0.37037037037037035
Epoch:  602        5 Batch loss: 0.235462 Batch F1: 0.18181818181818182
Epoch:  602        6 Batch loss: 0.216198 Batch F1: 0.18181818181818182
Epoch:  602        7 Batch loss: 0.195843 Batch F1: 0.1111111111111111
Epoch:  602        8 Batch loss: 0.242062 Batch F1: 0.2962962962962963
Epoch:  602        9 Batch loss: 0.242191 Batch F1: 0.23076923076923075
Epoch:  602       10 Batch loss: 0.225262 Batch F1: 0.3636363636363636
Epoch:  602       11 Batch loss: 0.223098 Batch F1: 0.16
Epoch:  602       12 Batch loss: 0.205396 Batch F1: 0.380952380952381
Train Avg Loss  602: 0.221787

Train Avg F1  602: 0.2873941490608158

Val Avg Loss  602: 0.218157

Val Avg F1  602:  0.04772727272727273

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 603
--------------------------------------------------------------
Epoch:  603        1 Batch loss: 0.228323 Batch F1: 0.09523809523809525
Epoch:  603        2 Batch loss: 0.206702 Batch F1: 0.3846153846153846
Epoch:  603        3 Batch loss: 0.241777 Batch F1: 0.0
Epoch:  603        4 Batch loss: 0.245423 Batch F1: 0.0
Epoch:  603        5 Batch loss: 0.237753 Batch F1: 0.23076923076923078
Epoch:  603        6 Batch loss: 0.211288 Batch F1: 0.3
Epoch:  603        7 Batch loss: 0.216066 Batch F1: 0.3333333333333333
Epoch:  603        8 Batch loss: 0.219862 Batch F1: 0.2608695652173913
Epoch:  603        9 Batch loss: 0.209083 Batch F1: 0.19999999999999998
Epoch:  603       10 Batch loss: 0.197607 Batch F1: 0.4799999999999999
Epoch:  603       11 Batch loss: 0.212840 Batch F1: 0.3
Epoch:  603       12 Batch loss: 0.237606 Batch F1: 0.2608695652173913
Train Avg Loss  603: 0.222027

Train Avg F1  603: 0.2371412645325688

Val Avg Loss  603: 0.218782

Val Avg F1  603:  0.24243256743256744

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 604
--------------------------------------------------------------
Epoch:  604        1 Batch loss: 0.260527 Batch F1: 0.21428571428571427
Epoch:  604        2 Batch loss: 0.202547 Batch F1: 0.34782608695652173
Epoch:  604        3 Batch loss: 0.221027 Batch F1: 0.3870967741935484
Epoch:  604        4 Batch loss: 0.225972 Batch F1: 0.5000000000000001
Epoch:  604        5 Batch loss: 0.223429 Batch F1: 0.30769230769230765
Epoch:  604        6 Batch loss: 0.242929 Batch F1: 0.3870967741935484
Epoch:  604        7 Batch loss: 0.243992 Batch F1: 0.16
Epoch:  604        8 Batch loss: 0.216627 Batch F1: 0.3076923076923077
Epoch:  604        9 Batch loss: 0.201072 Batch F1: 0.5517241379310345
Epoch:  604       10 Batch loss: 0.196653 Batch F1: 0.2
Epoch:  604       11 Batch loss: 0.227377 Batch F1: 0.2727272727272727
Epoch:  604       12 Batch loss: 0.195202 Batch F1: 0.25
Train Avg Loss  604: 0.221446

Train Avg F1  604: 0.3238451146393546

Val Avg Loss  604: 0.219233

Val Avg F1  604:  0.26553790412486067

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 605
--------------------------------------------------------------
Epoch:  605        1 Batch loss: 0.243601 Batch F1: 0.3448275862068965
Epoch:  605        2 Batch loss: 0.207523 Batch F1: 0.41379310344827586
Epoch:  605        3 Batch loss: 0.212522 Batch F1: 0.3636363636363636
Epoch:  605        4 Batch loss: 0.227328 Batch F1: 0.2857142857142857
Epoch:  605        5 Batch loss: 0.241517 Batch F1: 0.3076923076923077
Epoch:  605        6 Batch loss: 0.203059 Batch F1: 0.2
Epoch:  605        7 Batch loss: 0.179652 Batch F1: 0.4545454545454546
Epoch:  605        8 Batch loss: 0.213384 Batch F1: 0.24
Epoch:  605        9 Batch loss: 0.244669 Batch F1: 0.2758620689655173
Epoch:  605       10 Batch loss: 0.249448 Batch F1: 0.16
Epoch:  605       11 Batch loss: 0.212436 Batch F1: 0.4166666666666667
Epoch:  605       12 Batch loss: 0.229572 Batch F1: 0.2857142857142857
Train Avg Loss  605: 0.222059

Train Avg F1  605: 0.31237101021583774

Val Avg Loss  605: 0.218247

Val Avg F1  605:  0.28660968660968655

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 606
--------------------------------------------------------------
Epoch:  606        1 Batch loss: 0.225870 Batch F1: 0.4166666666666667
Epoch:  606        2 Batch loss: 0.250428 Batch F1: 0.16666666666666666
Epoch:  606        3 Batch loss: 0.250016 Batch F1: 0.3870967741935483
Epoch:  606        4 Batch loss: 0.225319 Batch F1: 0.42857142857142855
Epoch:  606        5 Batch loss: 0.243274 Batch F1: 0.27586206896551724
Epoch:  606        6 Batch loss: 0.228304 Batch F1: 0.39999999999999997
Epoch:  606        7 Batch loss: 0.192379 Batch F1: 0.5217391304347826
Epoch:  606        8 Batch loss: 0.204902 Batch F1: 0.3846153846153846
Epoch:  606        9 Batch loss: 0.218878 Batch F1: 0.30769230769230765
Epoch:  606       10 Batch loss: 0.210050 Batch F1: 0.3
Epoch:  606       11 Batch loss: 0.200752 Batch F1: 0.0
Epoch:  606       12 Batch loss: 0.221060 Batch F1: 0.0
Train Avg Loss  606: 0.222603

Train Avg F1  606: 0.2990758689838585

Val Avg Loss  606: 0.217291

Val Avg F1  606:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 607
--------------------------------------------------------------
Epoch:  607        1 Batch loss: 0.224071 Batch F1: 0.0
Epoch:  607        2 Batch loss: 0.221479 Batch F1: 0.0
Epoch:  607        3 Batch loss: 0.204955 Batch F1: 0.0
Epoch:  607        4 Batch loss: 0.218939 Batch F1: 0.0
Epoch:  607        5 Batch loss: 0.211377 Batch F1: 0.0
Epoch:  607        6 Batch loss: 0.263138 Batch F1: 0.0
Epoch:  607        7 Batch loss: 0.235379 Batch F1: 0.0
Epoch:  607        8 Batch loss: 0.206085 Batch F1: 0.3636363636363636
Epoch:  607        9 Batch loss: 0.226039 Batch F1: 0.18181818181818182
Epoch:  607       10 Batch loss: 0.202062 Batch F1: 0.48
Epoch:  607       11 Batch loss: 0.235085 Batch F1: 0.39999999999999997
Epoch:  607       12 Batch loss: 0.243376 Batch F1: 0.3809523809523809
Train Avg Loss  607: 0.224332

Train Avg F1  607: 0.15053391053391052

Val Avg Loss  607: 0.219177

Val Avg F1  607:  0.2483437615016562

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 608
--------------------------------------------------------------
Epoch:  608        1 Batch loss: 0.223711 Batch F1: 0.24
Epoch:  608        2 Batch loss: 0.230767 Batch F1: 0.23999999999999996
Epoch:  608        3 Batch loss: 0.238226 Batch F1: 0.24999999999999997
Epoch:  608        4 Batch loss: 0.204413 Batch F1: 0.34782608695652173
Epoch:  608        5 Batch loss: 0.244370 Batch F1: 0.24
Epoch:  608        6 Batch loss: 0.210239 Batch F1: 0.4666666666666666
Epoch:  608        7 Batch loss: 0.243726 Batch F1: 0.1739130434782609
Epoch:  608        8 Batch loss: 0.212597 Batch F1: 0.1818181818181818
Epoch:  608        9 Batch loss: 0.245651 Batch F1: 0.25806451612903225
Epoch:  608       10 Batch loss: 0.219522 Batch F1: 0.4166666666666667
Epoch:  608       11 Batch loss: 0.189983 Batch F1: 0.4210526315789473
Epoch:  608       12 Batch loss: 0.197917 Batch F1: 0.38095238095238093
Train Avg Loss  608: 0.221760

Train Avg F1  608: 0.3014133478538882

Val Avg Loss  608: 0.218562

Val Avg F1  608:  0.25847069597069594

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 609
--------------------------------------------------------------
Epoch:  609        1 Batch loss: 0.217159 Batch F1: 0.34782608695652173
Epoch:  609        2 Batch loss: 0.198001 Batch F1: 0.48
Epoch:  609        3 Batch loss: 0.196762 Batch F1: 0.11764705882352941
Epoch:  609        4 Batch loss: 0.225148 Batch F1: 0.2857142857142857
Epoch:  609        5 Batch loss: 0.244991 Batch F1: 0.3333333333333333
Epoch:  609        6 Batch loss: 0.225491 Batch F1: 0.1739130434782609
Epoch:  609        7 Batch loss: 0.224675 Batch F1: 0.35714285714285715
Epoch:  609        8 Batch loss: 0.208095 Batch F1: 0.3846153846153846
Epoch:  609        9 Batch loss: 0.198724 Batch F1: 0.3529411764705882
Epoch:  609       10 Batch loss: 0.234701 Batch F1: 0.32
Epoch:  609       11 Batch loss: 0.214831 Batch F1: 0.2727272727272727
Epoch:  609       12 Batch loss: 0.291898 Batch F1: 0.16
Train Avg Loss  609: 0.223373

Train Avg F1  609: 0.29882170827183613

Val Avg Loss  609: 0.217756

Val Avg F1  609:  0.21994365928189458

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 610
--------------------------------------------------------------
Epoch:  610        1 Batch loss: 0.240193 Batch F1: 0.10526315789473684
Epoch:  610        2 Batch loss: 0.232828 Batch F1: 0.26086956521739124
Epoch:  610        3 Batch loss: 0.174330 Batch F1: 0.13333333333333333
Epoch:  610        4 Batch loss: 0.199288 Batch F1: 0.0
Epoch:  610        5 Batch loss: 0.196341 Batch F1: 0.0
Epoch:  610        6 Batch loss: 0.248866 Batch F1: 0.0
Epoch:  610        7 Batch loss: 0.227971 Batch F1: 0.0909090909090909
Epoch:  610        8 Batch loss: 0.238193 Batch F1: 0.0
Epoch:  610        9 Batch loss: 0.242549 Batch F1: 0.35714285714285715
Epoch:  610       10 Batch loss: 0.222910 Batch F1: 0.30769230769230765
Epoch:  610       11 Batch loss: 0.232834 Batch F1: 0.3448275862068966
Epoch:  610       12 Batch loss: 0.217387 Batch F1: 0.2608695652173913
Train Avg Loss  610: 0.222808

Train Avg F1  610: 0.15507562196783375

Val Avg Loss  610: 0.219906

Val Avg F1  610:  0.2499074074074074

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 611
--------------------------------------------------------------
Epoch:  611        1 Batch loss: 0.222070 Batch F1: 0.35714285714285715
Epoch:  611        2 Batch loss: 0.210893 Batch F1: 0.42857142857142855
Epoch:  611        3 Batch loss: 0.232478 Batch F1: 0.41379310344827586
Epoch:  611        4 Batch loss: 0.259348 Batch F1: 0.3225806451612903
Epoch:  611        5 Batch loss: 0.269372 Batch F1: 0.3529411764705882
Epoch:  611        6 Batch loss: 0.245859 Batch F1: 0.4848484848484849
Epoch:  611        7 Batch loss: 0.219927 Batch F1: 0.37037037037037035
Epoch:  611        8 Batch loss: 0.203875 Batch F1: 0.2727272727272727
Epoch:  611        9 Batch loss: 0.195043 Batch F1: 0.125
Epoch:  611       10 Batch loss: 0.187117 Batch F1: 0.38095238095238093
Epoch:  611       11 Batch loss: 0.207487 Batch F1: 0.0
Epoch:  611       12 Batch loss: 0.208781 Batch F1: 0.0
Train Avg Loss  611: 0.221854

Train Avg F1  611: 0.29241064330774574

Val Avg Loss  611: 0.217366

Val Avg F1  611:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 612
--------------------------------------------------------------
Epoch:  612        1 Batch loss: 0.227330 Batch F1: 0.0
Epoch:  612        2 Batch loss: 0.220929 Batch F1: 0.0
Epoch:  612        3 Batch loss: 0.204016 Batch F1: 0.0
Epoch:  612        4 Batch loss: 0.200620 Batch F1: 0.0
Epoch:  612        5 Batch loss: 0.262260 Batch F1: 0.0
Epoch:  612        6 Batch loss: 0.236262 Batch F1: 0.0
Epoch:  612        7 Batch loss: 0.262193 Batch F1: 0.0
Epoch:  612        8 Batch loss: 0.215540 Batch F1: 0.46153846153846156
Epoch:  612        9 Batch loss: 0.230248 Batch F1: 0.48275862068965514
Epoch:  612       10 Batch loss: 0.203231 Batch F1: 0.4545454545454546
Epoch:  612       11 Batch loss: 0.233086 Batch F1: 0.18181818181818182
Epoch:  612       12 Batch loss: 0.210122 Batch F1: 0.0
Train Avg Loss  612: 0.225486

Train Avg F1  612: 0.13172172654931277

Val Avg Loss  612: 0.217252

Val Avg F1  612:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 613
--------------------------------------------------------------
Epoch:  613        1 Batch loss: 0.204059 Batch F1: 0.0
Epoch:  613        2 Batch loss: 0.221939 Batch F1: 0.0
Epoch:  613        3 Batch loss: 0.292154 Batch F1: 0.0
Epoch:  613        4 Batch loss: 0.227275 Batch F1: 0.0
Epoch:  613        5 Batch loss: 0.199357 Batch F1: 0.0
Epoch:  613        6 Batch loss: 0.233532 Batch F1: 0.0
Epoch:  613        7 Batch loss: 0.193836 Batch F1: 0.0
Epoch:  613        8 Batch loss: 0.230522 Batch F1: 0.0
Epoch:  613        9 Batch loss: 0.221001 Batch F1: 0.2727272727272727
Epoch:  613       10 Batch loss: 0.224310 Batch F1: 0.24
Epoch:  613       11 Batch loss: 0.233488 Batch F1: 0.41379310344827586
Epoch:  613       12 Batch loss: 0.222589 Batch F1: 0.2857142857142857
Train Avg Loss  613: 0.225339

Train Avg F1  613: 0.10101955515748617

Val Avg Loss  613: 0.219095

Val Avg F1  613:  0.15348583877995645

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 614
--------------------------------------------------------------
Epoch:  614        1 Batch loss: 0.225466 Batch F1: 0.16666666666666666
Epoch:  614        2 Batch loss: 0.219914 Batch F1: 0.1
Epoch:  614        3 Batch loss: 0.219946 Batch F1: 0.0
Epoch:  614        4 Batch loss: 0.249539 Batch F1: 0.0
Epoch:  614        5 Batch loss: 0.186747 Batch F1: 0.0
Epoch:  614        6 Batch loss: 0.212017 Batch F1: 0.0
Epoch:  614        7 Batch loss: 0.173812 Batch F1: 0.0
Epoch:  614        8 Batch loss: 0.318238 Batch F1: 0.0
Epoch:  614        9 Batch loss: 0.230319 Batch F1: 0.0
Epoch:  614       10 Batch loss: 0.245074 Batch F1: 0.2962962962962963
Epoch:  614       11 Batch loss: 0.208468 Batch F1: 0.42857142857142855
Epoch:  614       12 Batch loss: 0.214971 Batch F1: 0.3809523809523809
Train Avg Loss  614: 0.225376

Train Avg F1  614: 0.11437389770723104

Val Avg Loss  614: 0.219867

Val Avg F1  614:  0.2515734265734266

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 615
--------------------------------------------------------------
Epoch:  615        1 Batch loss: 0.229357 Batch F1: 0.4137931034482759
Epoch:  615        2 Batch loss: 0.197644 Batch F1: 0.23529411764705882
Epoch:  615        3 Batch loss: 0.259046 Batch F1: 0.0
Epoch:  615        4 Batch loss: 0.214595 Batch F1: 0.4166666666666667
Epoch:  615        5 Batch loss: 0.230348 Batch F1: 0.0
Epoch:  615        6 Batch loss: 0.228482 Batch F1: 0.08333333333333333
Epoch:  615        7 Batch loss: 0.226553 Batch F1: 0.32
Epoch:  615        8 Batch loss: 0.215539 Batch F1: 0.4615384615384615
Epoch:  615        9 Batch loss: 0.222376 Batch F1: 0.09523809523809522
Epoch:  615       10 Batch loss: 0.185489 Batch F1: 0.3
Epoch:  615       11 Batch loss: 0.220628 Batch F1: 0.0
Epoch:  615       12 Batch loss: 0.259937 Batch F1: 0.0
Train Avg Loss  615: 0.224166

Train Avg F1  615: 0.19382198148932428

Val Avg Loss  615: 0.217632

Val Avg F1  615:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 616
--------------------------------------------------------------
Epoch:  616        1 Batch loss: 0.219900 Batch F1: 0.0
Epoch:  616        2 Batch loss: 0.231246 Batch F1: 0.0
Epoch:  616        3 Batch loss: 0.227104 Batch F1: 0.0
Epoch:  616        4 Batch loss: 0.183783 Batch F1: 0.4
Epoch:  616        5 Batch loss: 0.217428 Batch F1: 0.16666666666666666
Epoch:  616        6 Batch loss: 0.200223 Batch F1: 0.1
Epoch:  616        7 Batch loss: 0.210279 Batch F1: 0.1904761904761905
Epoch:  616        8 Batch loss: 0.213019 Batch F1: 0.2857142857142857
Epoch:  616        9 Batch loss: 0.237958 Batch F1: 0.1
Epoch:  616       10 Batch loss: 0.282906 Batch F1: 0.26666666666666666
Epoch:  616       11 Batch loss: 0.204960 Batch F1: 0.46153846153846156
Epoch:  616       12 Batch loss: 0.244752 Batch F1: 0.24
Train Avg Loss  616: 0.222796

Train Avg F1  616: 0.18425518925518927

Val Avg Loss  616: 0.220085

Val Avg F1  616:  0.23562111801242233

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 617
--------------------------------------------------------------
Epoch:  617        1 Batch loss: 0.198515 Batch F1: 0.2105263157894737
Epoch:  617        2 Batch loss: 0.220204 Batch F1: 0.3846153846153846
Epoch:  617        3 Batch loss: 0.256601 Batch F1: 0.23529411764705882
Epoch:  617        4 Batch loss: 0.242626 Batch F1: 0.3076923076923077
Epoch:  617        5 Batch loss: 0.230111 Batch F1: 0.41379310344827586
Epoch:  617        6 Batch loss: 0.241730 Batch F1: 0.1739130434782609
Epoch:  617        7 Batch loss: 0.225203 Batch F1: 0.3846153846153846
Epoch:  617        8 Batch loss: 0.190088 Batch F1: 0.45454545454545453
Epoch:  617        9 Batch loss: 0.185578 Batch F1: 0.5925925925925927
Epoch:  617       10 Batch loss: 0.262346 Batch F1: 0.13333333333333333
Epoch:  617       11 Batch loss: 0.208880 Batch F1: 0.125
Epoch:  617       12 Batch loss: 0.215017 Batch F1: 0.31578947368421056
Train Avg Loss  617: 0.223075

Train Avg F1  617: 0.31097587595347814

Val Avg Loss  617: 0.218303

Val Avg F1  617:  0.2726193826813022

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 618
--------------------------------------------------------------
Epoch:  618        1 Batch loss: 0.207102 Batch F1: 0.23529411764705882
Epoch:  618        2 Batch loss: 0.220366 Batch F1: 0.41379310344827586
Epoch:  618        3 Batch loss: 0.238039 Batch F1: 0.2857142857142857
Epoch:  618        4 Batch loss: 0.212146 Batch F1: 0.1739130434782609
Epoch:  618        5 Batch loss: 0.240299 Batch F1: 0.16666666666666666
Epoch:  618        6 Batch loss: 0.217440 Batch F1: 0.34782608695652173
Epoch:  618        7 Batch loss: 0.196701 Batch F1: 0.4999999999999999
Epoch:  618        8 Batch loss: 0.223968 Batch F1: 0.5161290322580645
Epoch:  618        9 Batch loss: 0.217319 Batch F1: 0.16666666666666666
Epoch:  618       10 Batch loss: 0.207570 Batch F1: 0.36363636363636365
Epoch:  618       11 Batch loss: 0.205907 Batch F1: 0.0
Epoch:  618       12 Batch loss: 0.294812 Batch F1: 0.0
Train Avg Loss  618: 0.223472

Train Avg F1  618: 0.26413661387268034

Val Avg Loss  618: 0.217628

Val Avg F1  618:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 619
--------------------------------------------------------------
Epoch:  619        1 Batch loss: 0.223804 Batch F1: 0.0
Epoch:  619        2 Batch loss: 0.214955 Batch F1: 0.0
Epoch:  619        3 Batch loss: 0.214939 Batch F1: 0.1904761904761905
Epoch:  619        4 Batch loss: 0.212604 Batch F1: 0.09999999999999999
Epoch:  619        5 Batch loss: 0.222593 Batch F1: 0.0
Epoch:  619        6 Batch loss: 0.225584 Batch F1: 0.5185185185185185
Epoch:  619        7 Batch loss: 0.224549 Batch F1: 0.09999999999999999
Epoch:  619        8 Batch loss: 0.228204 Batch F1: 0.08000000000000002
Epoch:  619        9 Batch loss: 0.229001 Batch F1: 0.3076923076923077
Epoch:  619       10 Batch loss: 0.205591 Batch F1: 0.1
Epoch:  619       11 Batch loss: 0.205720 Batch F1: 0.46153846153846156
Epoch:  619       12 Batch loss: 0.261953 Batch F1: 0.37037037037037035
Train Avg Loss  619: 0.222458

Train Avg F1  619: 0.18571632071632072

Val Avg Loss  619: 0.219417

Val Avg F1  619:  0.24544602698650675

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 620
--------------------------------------------------------------
Epoch:  620        1 Batch loss: 0.227563 Batch F1: 0.2
Epoch:  620        2 Batch loss: 0.261975 Batch F1: 0.20689655172413796
Epoch:  620        3 Batch loss: 0.226529 Batch F1: 0.27586206896551724
Epoch:  620        4 Batch loss: 0.207895 Batch F1: 0.33333333333333337
Epoch:  620        5 Batch loss: 0.203476 Batch F1: 0.10526315789473685
Epoch:  620        6 Batch loss: 0.272486 Batch F1: 0.25
Epoch:  620        7 Batch loss: 0.198796 Batch F1: 0.4615384615384615
Epoch:  620        8 Batch loss: 0.192934 Batch F1: 0.3333333333333333
Epoch:  620        9 Batch loss: 0.243974 Batch F1: 0.43750000000000006
Epoch:  620       10 Batch loss: 0.189503 Batch F1: 0.22222222222222224
Epoch:  620       11 Batch loss: 0.230505 Batch F1: 0.35714285714285715
Epoch:  620       12 Batch loss: 0.219104 Batch F1: 0.38095238095238093
Train Avg Loss  620: 0.222895

Train Avg F1  620: 0.29700369725891507

Val Avg Loss  620: 0.220926

Val Avg F1  620:  0.317012987012987

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 621
--------------------------------------------------------------
Epoch:  621        1 Batch loss: 0.201809 Batch F1: 0.5517241379310345
Epoch:  621        2 Batch loss: 0.233846 Batch F1: 0.37037037037037035
Epoch:  621        3 Batch loss: 0.194673 Batch F1: 0.5
Epoch:  621        4 Batch loss: 0.221102 Batch F1: 0.4
Epoch:  621        5 Batch loss: 0.222437 Batch F1: 0.4666666666666666
Epoch:  621        6 Batch loss: 0.212355 Batch F1: 0.3703703703703703
Epoch:  621        7 Batch loss: 0.232727 Batch F1: 0.19047619047619047
Epoch:  621        8 Batch loss: 0.210353 Batch F1: 0.21052631578947367
Epoch:  621        9 Batch loss: 0.215865 Batch F1: 0.1818181818181818
Epoch:  621       10 Batch loss: 0.242069 Batch F1: 0.0
Epoch:  621       11 Batch loss: 0.246484 Batch F1: 0.0
Epoch:  621       12 Batch loss: 0.242634 Batch F1: 0.0
Train Avg Loss  621: 0.223029

Train Avg F1  621: 0.27016268611852395

Val Avg Loss  621: 0.218405

Val Avg F1  621:  0.027777777777777776

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 622
--------------------------------------------------------------
Epoch:  622        1 Batch loss: 0.229333 Batch F1: 0.08
Epoch:  622        2 Batch loss: 0.261879 Batch F1: 0.27586206896551724
Epoch:  622        3 Batch loss: 0.216332 Batch F1: 0.16666666666666669
Epoch:  622        4 Batch loss: 0.234738 Batch F1: 0.0
Epoch:  622        5 Batch loss: 0.223817 Batch F1: 0.0
Epoch:  622        6 Batch loss: 0.226404 Batch F1: 0.0
Epoch:  622        7 Batch loss: 0.224590 Batch F1: 0.0
Epoch:  622        8 Batch loss: 0.211214 Batch F1: 0.0
Epoch:  622        9 Batch loss: 0.204440 Batch F1: 0.0
Epoch:  622       10 Batch loss: 0.211453 Batch F1: 0.125
Epoch:  622       11 Batch loss: 0.214067 Batch F1: 0.0
Epoch:  622       12 Batch loss: 0.224182 Batch F1: 0.4210526315789474
Train Avg Loss  622: 0.223537

Train Avg F1  622: 0.08904844726759427

Val Avg Loss  622: 0.221277

Val Avg F1  622:  0.2477272727272727

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 623
--------------------------------------------------------------
Epoch:  623        1 Batch loss: 0.242662 Batch F1: 0.5405405405405406
Epoch:  623        2 Batch loss: 0.241056 Batch F1: 0.39999999999999997
Epoch:  623        3 Batch loss: 0.210581 Batch F1: 0.34782608695652173
Epoch:  623        4 Batch loss: 0.212502 Batch F1: 0.11764705882352941
Epoch:  623        5 Batch loss: 0.215811 Batch F1: 0.0
Epoch:  623        6 Batch loss: 0.224990 Batch F1: 0.0
Epoch:  623        7 Batch loss: 0.207644 Batch F1: 0.0
Epoch:  623        8 Batch loss: 0.269303 Batch F1: 0.0
Epoch:  623        9 Batch loss: 0.230115 Batch F1: 0.0
Epoch:  623       10 Batch loss: 0.225818 Batch F1: 0.0
Epoch:  623       11 Batch loss: 0.224743 Batch F1: 0.11111111111111112
Epoch:  623       12 Batch loss: 0.213901 Batch F1: 0.45454545454545453
Train Avg Loss  623: 0.226594

Train Avg F1  623: 0.16430585433142977

Val Avg Loss  623: 0.222842

Val Avg F1  623:  0.25608766233766234

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 624
--------------------------------------------------------------
Epoch:  624        1 Batch loss: 0.256496 Batch F1: 0.16666666666666666
Epoch:  624        2 Batch loss: 0.217980 Batch F1: 0.0
Epoch:  624        3 Batch loss: 0.202776 Batch F1: 0.0
Epoch:  624        4 Batch loss: 0.217651 Batch F1: 0.0
Epoch:  624        5 Batch loss: 0.218965 Batch F1: 0.0
Epoch:  624        6 Batch loss: 0.178357 Batch F1: 0.0
Epoch:  624        7 Batch loss: 0.201160 Batch F1: 0.0
Epoch:  624        8 Batch loss: 0.228201 Batch F1: 0.0
Epoch:  624        9 Batch loss: 0.246676 Batch F1: 0.0
Epoch:  624       10 Batch loss: 0.245063 Batch F1: 0.0
Epoch:  624       11 Batch loss: 0.250089 Batch F1: 0.15384615384615385
Epoch:  624       12 Batch loss: 0.222341 Batch F1: 0.5384615384615384
Train Avg Loss  624: 0.223813

Train Avg F1  624: 0.07158119658119658

Val Avg Loss  624: 0.236215

Val Avg F1  624:  0.479734219269103

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 625
--------------------------------------------------------------
Epoch:  625        1 Batch loss: 0.242082 Batch F1: 0.6122448979591837
Epoch:  625        2 Batch loss: 0.219027 Batch F1: 0.6153846153846154
Epoch:  625        3 Batch loss: 0.229828 Batch F1: 0.6938775510204083
Epoch:  625        4 Batch loss: 0.222366 Batch F1: 0.0
Epoch:  625        5 Batch loss: 0.236186 Batch F1: 0.0
Epoch:  625        6 Batch loss: 0.222994 Batch F1: 0.0
Epoch:  625        7 Batch loss: 0.244035 Batch F1: 0.0
Epoch:  625        8 Batch loss: 0.255357 Batch F1: 0.0
Epoch:  625        9 Batch loss: 0.205359 Batch F1: 0.0
Epoch:  625       10 Batch loss: 0.236665 Batch F1: 0.1904761904761905
Epoch:  625       11 Batch loss: 0.215456 Batch F1: 0.0
Epoch:  625       12 Batch loss: 0.216199 Batch F1: 0.0
Train Avg Loss  625: 0.228796

Train Avg F1  625: 0.17599860457003316

Val Avg Loss  625: 0.219326

Val Avg F1  625:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 626
--------------------------------------------------------------
Epoch:  626        1 Batch loss: 0.229356 Batch F1: 0.0
Epoch:  626        2 Batch loss: 0.245920 Batch F1: 0.32000000000000006
Epoch:  626        3 Batch loss: 0.217976 Batch F1: 0.23076923076923075
Epoch:  626        4 Batch loss: 0.201723 Batch F1: 0.5714285714285714
Epoch:  626        5 Batch loss: 0.225651 Batch F1: 0.21052631578947364
Epoch:  626        6 Batch loss: 0.197544 Batch F1: 0.0
Epoch:  626        7 Batch loss: 0.241164 Batch F1: 0.0
Epoch:  626        8 Batch loss: 0.267649 Batch F1: 0.0
Epoch:  626        9 Batch loss: 0.203477 Batch F1: 0.0
Epoch:  626       10 Batch loss: 0.209788 Batch F1: 0.0
Epoch:  626       11 Batch loss: 0.235406 Batch F1: 0.0
Epoch:  626       12 Batch loss: 0.223938 Batch F1: 0.0
Train Avg Loss  626: 0.224966

Train Avg F1  626: 0.11106034316560633

Val Avg Loss  626: 0.219073

Val Avg F1  626:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 627
--------------------------------------------------------------
Epoch:  627        1 Batch loss: 0.248988 Batch F1: 0.0
Epoch:  627        2 Batch loss: 0.219994 Batch F1: 0.10526315789473684
Epoch:  627        3 Batch loss: 0.227938 Batch F1: 0.3448275862068965
Epoch:  627        4 Batch loss: 0.240106 Batch F1: 0.3870967741935484
Epoch:  627        5 Batch loss: 0.235174 Batch F1: 0.41379310344827586
Epoch:  627        6 Batch loss: 0.215326 Batch F1: 0.4827586206896552
Epoch:  627        7 Batch loss: 0.256682 Batch F1: 0.3125
Epoch:  627        8 Batch loss: 0.205559 Batch F1: 0.2857142857142857
Epoch:  627        9 Batch loss: 0.192023 Batch F1: 0.13333333333333333
Epoch:  627       10 Batch loss: 0.192106 Batch F1: 0.0
Epoch:  627       11 Batch loss: 0.218827 Batch F1: 0.0
Epoch:  627       12 Batch loss: 0.252910 Batch F1: 0.0
Train Avg Loss  627: 0.225469

Train Avg F1  627: 0.20544057179006095

Val Avg Loss  627: 0.218917

Val Avg F1  627:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 628
--------------------------------------------------------------
Epoch:  628        1 Batch loss: 0.201390 Batch F1: 0.0
Epoch:  628        2 Batch loss: 0.261515 Batch F1: 0.0
Epoch:  628        3 Batch loss: 0.239712 Batch F1: 0.0
Epoch:  628        4 Batch loss: 0.225102 Batch F1: 0.0
Epoch:  628        5 Batch loss: 0.230961 Batch F1: 0.0
Epoch:  628        6 Batch loss: 0.219220 Batch F1: 0.0
Epoch:  628        7 Batch loss: 0.219317 Batch F1: 0.0
Epoch:  628        8 Batch loss: 0.236665 Batch F1: 0.0
Epoch:  628        9 Batch loss: 0.232362 Batch F1: 0.09523809523809523
Epoch:  628       10 Batch loss: 0.227043 Batch F1: 0.0
Epoch:  628       11 Batch loss: 0.216270 Batch F1: 0.0
Epoch:  628       12 Batch loss: 0.202005 Batch F1: 0.0
Train Avg Loss  628: 0.225964

Train Avg F1  628: 0.007936507936507936

Val Avg Loss  628: 0.218117

Val Avg F1  628:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 629
--------------------------------------------------------------
Epoch:  629        1 Batch loss: 0.201671 Batch F1: 0.0
Epoch:  629        2 Batch loss: 0.239375 Batch F1: 0.0
Epoch:  629        3 Batch loss: 0.232527 Batch F1: 0.0
Epoch:  629        4 Batch loss: 0.262049 Batch F1: 0.0
Epoch:  629        5 Batch loss: 0.237302 Batch F1: 0.0
Epoch:  629        6 Batch loss: 0.240660 Batch F1: 0.0
Epoch:  629        7 Batch loss: 0.244454 Batch F1: 0.0
Epoch:  629        8 Batch loss: 0.192693 Batch F1: 0.0
Epoch:  629        9 Batch loss: 0.224019 Batch F1: 0.0
Epoch:  629       10 Batch loss: 0.204193 Batch F1: 0.18181818181818182
Epoch:  629       11 Batch loss: 0.205405 Batch F1: 0.21052631578947364
Epoch:  629       12 Batch loss: 0.217751 Batch F1: 0.42857142857142855
Train Avg Loss  629: 0.225175

Train Avg F1  629: 0.06840966051492366

Val Avg Loss  629: 0.219628

Val Avg F1  629:  0.24934968413229286

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 630
--------------------------------------------------------------
Epoch:  630        1 Batch loss: 0.219990 Batch F1: 0.3333333333333333
Epoch:  630        2 Batch loss: 0.235130 Batch F1: 0.0909090909090909
Epoch:  630        3 Batch loss: 0.234715 Batch F1: 0.0
Epoch:  630        4 Batch loss: 0.230649 Batch F1: 0.0
Epoch:  630        5 Batch loss: 0.218507 Batch F1: 0.0
Epoch:  630        6 Batch loss: 0.232803 Batch F1: 0.0
Epoch:  630        7 Batch loss: 0.211271 Batch F1: 0.2608695652173913
Epoch:  630        8 Batch loss: 0.214740 Batch F1: 0.27272727272727276
Epoch:  630        9 Batch loss: 0.243835 Batch F1: 0.09523809523809523
Epoch:  630       10 Batch loss: 0.222183 Batch F1: 0.4444444444444444
Epoch:  630       11 Batch loss: 0.218877 Batch F1: 0.5
Epoch:  630       12 Batch loss: 0.212266 Batch F1: 0.3529411764705882
Train Avg Loss  630: 0.224580

Train Avg F1  630: 0.19587191486168465

Val Avg Loss  630: 0.222013

Val Avg F1  630:  0.34616977225672874

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 631
--------------------------------------------------------------
Epoch:  631        1 Batch loss: 0.220757 Batch F1: 0.5
Epoch:  631        2 Batch loss: 0.213963 Batch F1: 0.4615384615384615
Epoch:  631        3 Batch loss: 0.194508 Batch F1: 0.4210526315789473
Epoch:  631        4 Batch loss: 0.271828 Batch F1: 0.368421052631579
Epoch:  631        5 Batch loss: 0.226997 Batch F1: 0.3870967741935483
Epoch:  631        6 Batch loss: 0.230576 Batch F1: 0.0909090909090909
Epoch:  631        7 Batch loss: 0.253573 Batch F1: 0.23076923076923073
Epoch:  631        8 Batch loss: 0.205104 Batch F1: 0.2608695652173913
Epoch:  631        9 Batch loss: 0.237363 Batch F1: 0.3571428571428571
Epoch:  631       10 Batch loss: 0.223150 Batch F1: 0.19047619047619047
Epoch:  631       11 Batch loss: 0.206729 Batch F1: 0.0
Epoch:  631       12 Batch loss: 0.177977 Batch F1: 0.4444444444444444
Train Avg Loss  631: 0.221877

Train Avg F1  631: 0.3093933582418118

Val Avg Loss  631: 0.218572

Val Avg F1  631:  0.28568376068376067

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 632
--------------------------------------------------------------
Epoch:  632        1 Batch loss: 0.233137 Batch F1: 0.24999999999999997
Epoch:  632        2 Batch loss: 0.215455 Batch F1: 0.10526315789473684
Epoch:  632        3 Batch loss: 0.221410 Batch F1: 0.37037037037037035
Epoch:  632        4 Batch loss: 0.241223 Batch F1: 0.19047619047619047
Epoch:  632        5 Batch loss: 0.221399 Batch F1: 0.4285714285714285
Epoch:  632        6 Batch loss: 0.247464 Batch F1: 0.5294117647058824
Epoch:  632        7 Batch loss: 0.232977 Batch F1: 0.3076923076923077
Epoch:  632        8 Batch loss: 0.192734 Batch F1: 0.2727272727272727
Epoch:  632        9 Batch loss: 0.219664 Batch F1: 0.1
Epoch:  632       10 Batch loss: 0.204375 Batch F1: 0.36363636363636365
Epoch:  632       11 Batch loss: 0.231099 Batch F1: 0.2962962962962963
Epoch:  632       12 Batch loss: 0.207349 Batch F1: 0.2727272727272727
Train Avg Loss  632: 0.222357

Train Avg F1  632: 0.2905977020915101

Val Avg Loss  632: 0.219642

Val Avg F1  632:  0.273161479043832

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 633
--------------------------------------------------------------
Epoch:  633        1 Batch loss: 0.239676 Batch F1: 0.3076923076923077
Epoch:  633        2 Batch loss: 0.180159 Batch F1: 0.4
Epoch:  633        3 Batch loss: 0.249663 Batch F1: 0.3448275862068966
Epoch:  633        4 Batch loss: 0.254404 Batch F1: 0.29629629629629634
Epoch:  633        5 Batch loss: 0.245871 Batch F1: 0.1818181818181818
Epoch:  633        6 Batch loss: 0.188585 Batch F1: 0.4166666666666667
Epoch:  633        7 Batch loss: 0.215269 Batch F1: 0.18181818181818182
Epoch:  633        8 Batch loss: 0.190915 Batch F1: 0.3
Epoch:  633        9 Batch loss: 0.230703 Batch F1: 0.29629629629629634
Epoch:  633       10 Batch loss: 0.240494 Batch F1: 0.23076923076923075
Epoch:  633       11 Batch loss: 0.235623 Batch F1: 0.4705882352941176
Epoch:  633       12 Batch loss: 0.183795 Batch F1: 0.14285714285714285
Train Avg Loss  633: 0.221263

Train Avg F1  633: 0.2974691771429432

Val Avg Loss  633: 0.219402

Val Avg F1  633:  0.25908119658119655

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 634
--------------------------------------------------------------
Epoch:  634        1 Batch loss: 0.219583 Batch F1: 0.09523809523809523
Epoch:  634        2 Batch loss: 0.207250 Batch F1: 0.2727272727272727
Epoch:  634        3 Batch loss: 0.244357 Batch F1: 0.375
Epoch:  634        4 Batch loss: 0.225359 Batch F1: 0.32
Epoch:  634        5 Batch loss: 0.209773 Batch F1: 0.3636363636363636
Epoch:  634        6 Batch loss: 0.233850 Batch F1: 0.17391304347826086
Epoch:  634        7 Batch loss: 0.227976 Batch F1: 0.19047619047619047
Epoch:  634        8 Batch loss: 0.194182 Batch F1: 0.6399999999999999
Epoch:  634        9 Batch loss: 0.237574 Batch F1: 0.24
Epoch:  634       10 Batch loss: 0.229058 Batch F1: 0.44444444444444436
Epoch:  634       11 Batch loss: 0.215845 Batch F1: 0.4666666666666667
Epoch:  634       12 Batch loss: 0.213066 Batch F1: 0.13333333333333333
Train Avg Loss  634: 0.221489

Train Avg F1  634: 0.30961961750005224

Val Avg Loss  634: 0.219213

Val Avg F1  634:  0.24287306896002545

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 635
--------------------------------------------------------------
Epoch:  635        1 Batch loss: 0.248362 Batch F1: 0.27586206896551724
Epoch:  635        2 Batch loss: 0.233635 Batch F1: 0.2727272727272727
Epoch:  635        3 Batch loss: 0.206218 Batch F1: 0.5
Epoch:  635        4 Batch loss: 0.196035 Batch F1: 0.47619047619047616
Epoch:  635        5 Batch loss: 0.240909 Batch F1: 0.24
Epoch:  635        6 Batch loss: 0.246327 Batch F1: 0.16
Epoch:  635        7 Batch loss: 0.196228 Batch F1: 0.19047619047619047
Epoch:  635        8 Batch loss: 0.241207 Batch F1: 0.22222222222222218
Epoch:  635        9 Batch loss: 0.213537 Batch F1: 0.39999999999999997
Epoch:  635       10 Batch loss: 0.206662 Batch F1: 0.3478260869565218
Epoch:  635       11 Batch loss: 0.237054 Batch F1: 0.3428571428571428
Epoch:  635       12 Batch loss: 0.189560 Batch F1: 0.4
Train Avg Loss  635: 0.221311

Train Avg F1  635: 0.3190134550329453

Val Avg Loss  635: 0.219419

Val Avg F1  635:  0.24543956043956044

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 636
--------------------------------------------------------------
Epoch:  636        1 Batch loss: 0.204501 Batch F1: 0.1111111111111111
Epoch:  636        2 Batch loss: 0.248695 Batch F1: 0.43750000000000006
Epoch:  636        3 Batch loss: 0.202014 Batch F1: 0.2
Epoch:  636        4 Batch loss: 0.215327 Batch F1: 0.3
Epoch:  636        5 Batch loss: 0.239289 Batch F1: 0.09523809523809523
Epoch:  636        6 Batch loss: 0.229574 Batch F1: 0.4827586206896552
Epoch:  636        7 Batch loss: 0.225589 Batch F1: 0.2608695652173913
Epoch:  636        8 Batch loss: 0.207914 Batch F1: 0.5185185185185185
Epoch:  636        9 Batch loss: 0.227216 Batch F1: 0.37037037037037035
Epoch:  636       10 Batch loss: 0.206986 Batch F1: 0.3478260869565218
Epoch:  636       11 Batch loss: 0.216997 Batch F1: 0.24
Epoch:  636       12 Batch loss: 0.238990 Batch F1: 0.25
Train Avg Loss  636: 0.221924

Train Avg F1  636: 0.3011826973418053

Val Avg Loss  636: 0.219471

Val Avg F1  636:  0.23545680898622076

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 637
--------------------------------------------------------------
Epoch:  637        1 Batch loss: 0.209944 Batch F1: 0.3
Epoch:  637        2 Batch loss: 0.229635 Batch F1: 0.4375
Epoch:  637        3 Batch loss: 0.233229 Batch F1: 0.25
Epoch:  637        4 Batch loss: 0.261826 Batch F1: 0.2941176470588235
Epoch:  637        5 Batch loss: 0.245839 Batch F1: 0.08695652173913043
Epoch:  637        6 Batch loss: 0.188940 Batch F1: 0.0
Epoch:  637        7 Batch loss: 0.213669 Batch F1: 0.0
Epoch:  637        8 Batch loss: 0.203346 Batch F1: 0.0
Epoch:  637        9 Batch loss: 0.218692 Batch F1: 0.19999999999999998
Epoch:  637       10 Batch loss: 0.210154 Batch F1: 0.0
Epoch:  637       11 Batch loss: 0.255479 Batch F1: 0.30303030303030304
Epoch:  637       12 Batch loss: 0.197737 Batch F1: 0.6428571428571429
Train Avg Loss  637: 0.222374

Train Avg F1  637: 0.20953846789044997

Val Avg Loss  637: 0.220063

Val Avg F1  637:  0.2453113553113553

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 638
--------------------------------------------------------------
Epoch:  638        1 Batch loss: 0.216068 Batch F1: 0.35714285714285715
Epoch:  638        2 Batch loss: 0.205652 Batch F1: 0.4799999999999999
Epoch:  638        3 Batch loss: 0.241602 Batch F1: 0.27586206896551724
Epoch:  638        4 Batch loss: 0.227461 Batch F1: 0.3333333333333333
Epoch:  638        5 Batch loss: 0.267703 Batch F1: 0.30303030303030304
Epoch:  638        6 Batch loss: 0.236889 Batch F1: 0.27272727272727276
Epoch:  638        7 Batch loss: 0.208899 Batch F1: 0.33333333333333337
Epoch:  638        8 Batch loss: 0.228043 Batch F1: 0.28571428571428575
Epoch:  638        9 Batch loss: 0.224996 Batch F1: 0.39999999999999997
Epoch:  638       10 Batch loss: 0.192958 Batch F1: 0.13333333333333336
Epoch:  638       11 Batch loss: 0.203288 Batch F1: 0.5714285714285714
Epoch:  638       12 Batch loss: 0.225228 Batch F1: 0.10526315789473684
Train Avg Loss  638: 0.223232

Train Avg F1  638: 0.320930709741962

Val Avg Loss  638: 0.218178

Val Avg F1  638:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 639
--------------------------------------------------------------
Epoch:  639        1 Batch loss: 0.266993 Batch F1: 0.08
Epoch:  639        2 Batch loss: 0.222475 Batch F1: 0.2
Epoch:  639        3 Batch loss: 0.243533 Batch F1: 0.42424242424242425
Epoch:  639        4 Batch loss: 0.206149 Batch F1: 0.36363636363636365
Epoch:  639        5 Batch loss: 0.222344 Batch F1: 0.1818181818181818
Epoch:  639        6 Batch loss: 0.204557 Batch F1: 0.3846153846153846
Epoch:  639        7 Batch loss: 0.251983 Batch F1: 0.21428571428571427
Epoch:  639        8 Batch loss: 0.203513 Batch F1: 0.11764705882352941
Epoch:  639        9 Batch loss: 0.203834 Batch F1: 0.32
Epoch:  639       10 Batch loss: 0.200423 Batch F1: 0.09523809523809525
Epoch:  639       11 Batch loss: 0.218212 Batch F1: 0.0
Epoch:  639       12 Batch loss: 0.228559 Batch F1: 0.0
Train Avg Loss  639: 0.222715

Train Avg F1  639: 0.1984569352216411

Val Avg Loss  639: 0.217181

Val Avg F1  639:  0.056547619047619055

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 640
--------------------------------------------------------------
Epoch:  640        1 Batch loss: 0.220054 Batch F1: 0.1739130434782609
Epoch:  640        2 Batch loss: 0.220149 Batch F1: 0.18181818181818182
Epoch:  640        3 Batch loss: 0.208216 Batch F1: 0.31999999999999995
Epoch:  640        4 Batch loss: 0.198225 Batch F1: 0.5454545454545455
Epoch:  640        5 Batch loss: 0.215744 Batch F1: 0.31999999999999995
Epoch:  640        6 Batch loss: 0.225120 Batch F1: 0.4
Epoch:  640        7 Batch loss: 0.228965 Batch F1: 0.27272727272727276
Epoch:  640        8 Batch loss: 0.229994 Batch F1: 0.48275862068965514
Epoch:  640        9 Batch loss: 0.219237 Batch F1: 0.2857142857142857
Epoch:  640       10 Batch loss: 0.201082 Batch F1: 0.43478260869565216
Epoch:  640       11 Batch loss: 0.241720 Batch F1: 0.08695652173913043
Epoch:  640       12 Batch loss: 0.270853 Batch F1: 0.09523809523809523
Train Avg Loss  640: 0.223280

Train Avg F1  640: 0.29994693129625666

Val Avg Loss  640: 0.219135

Val Avg F1  640:  0.24132352941176471

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 641
--------------------------------------------------------------
Epoch:  641        1 Batch loss: 0.228875 Batch F1: 0.30769230769230765
Epoch:  641        2 Batch loss: 0.221346 Batch F1: 0.48275862068965514
Epoch:  641        3 Batch loss: 0.227314 Batch F1: 0.18181818181818182
Epoch:  641        4 Batch loss: 0.218946 Batch F1: 0.2727272727272727
Epoch:  641        5 Batch loss: 0.209196 Batch F1: 0.4
Epoch:  641        6 Batch loss: 0.224141 Batch F1: 0.3448275862068965
Epoch:  641        7 Batch loss: 0.228478 Batch F1: 0.32000000000000006
Epoch:  641        8 Batch loss: 0.222774 Batch F1: 0.2962962962962963
Epoch:  641        9 Batch loss: 0.224861 Batch F1: 0.3846153846153846
Epoch:  641       10 Batch loss: 0.236435 Batch F1: 0.23999999999999996
Epoch:  641       11 Batch loss: 0.193881 Batch F1: 0.2222222222222222
Epoch:  641       12 Batch loss: 0.230976 Batch F1: 0.3
Train Avg Loss  641: 0.222269

Train Avg F1  641: 0.3127464893556847

Val Avg Loss  641: 0.219012

Val Avg F1  641:  0.2711366319102892

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 642
--------------------------------------------------------------
Epoch:  642        1 Batch loss: 0.214916 Batch F1: 0.3076923076923077
Epoch:  642        2 Batch loss: 0.295481 Batch F1: 0.24242424242424243
Epoch:  642        3 Batch loss: 0.217697 Batch F1: 0.3076923076923077
Epoch:  642        4 Batch loss: 0.247237 Batch F1: 0.28571428571428575
Epoch:  642        5 Batch loss: 0.227727 Batch F1: 0.23999999999999996
Epoch:  642        6 Batch loss: 0.200339 Batch F1: 0.3
Epoch:  642        7 Batch loss: 0.199481 Batch F1: 0.4
Epoch:  642        8 Batch loss: 0.193387 Batch F1: 0.4210526315789474
Epoch:  642        9 Batch loss: 0.212857 Batch F1: 0.38095238095238093
Epoch:  642       10 Batch loss: 0.229122 Batch F1: 0.09999999999999999
Epoch:  642       11 Batch loss: 0.225653 Batch F1: 0.0
Epoch:  642       12 Batch loss: 0.207163 Batch F1: 0.0
Train Avg Loss  642: 0.222588

Train Avg F1  642: 0.24879401300453932

Val Avg Loss  642: 0.217765

Val Avg F1  642:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 643
--------------------------------------------------------------
Epoch:  643        1 Batch loss: 0.224014 Batch F1: 0.0
Epoch:  643        2 Batch loss: 0.239329 Batch F1: 0.17391304347826086
Epoch:  643        3 Batch loss: 0.220475 Batch F1: 0.38095238095238093
Epoch:  643        4 Batch loss: 0.249793 Batch F1: 0.2962962962962963
Epoch:  643        5 Batch loss: 0.243359 Batch F1: 0.23076923076923075
Epoch:  643        6 Batch loss: 0.217949 Batch F1: 0.2962962962962963
Epoch:  643        7 Batch loss: 0.231416 Batch F1: 0.0909090909090909
Epoch:  643        8 Batch loss: 0.230243 Batch F1: 0.45714285714285713
Epoch:  643        9 Batch loss: 0.202222 Batch F1: 0.2608695652173913
Epoch:  643       10 Batch loss: 0.189670 Batch F1: 0.34782608695652173
Epoch:  643       11 Batch loss: 0.207382 Batch F1: 0.0
Epoch:  643       12 Batch loss: 0.214363 Batch F1: 0.0
Train Avg Loss  643: 0.222518

Train Avg F1  643: 0.21124790400152715

Val Avg Loss  643: 0.217637

Val Avg F1  643:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 644
--------------------------------------------------------------
Epoch:  644        1 Batch loss: 0.190647 Batch F1: 0.0
Epoch:  644        2 Batch loss: 0.218001 Batch F1: 0.0
Epoch:  644        3 Batch loss: 0.211697 Batch F1: 0.0
Epoch:  644        4 Batch loss: 0.259747 Batch F1: 0.3125
Epoch:  644        5 Batch loss: 0.226682 Batch F1: 0.32
Epoch:  644        6 Batch loss: 0.207768 Batch F1: 0.19047619047619047
Epoch:  644        7 Batch loss: 0.224395 Batch F1: 0.3076923076923077
Epoch:  644        8 Batch loss: 0.207272 Batch F1: 0.36363636363636365
Epoch:  644        9 Batch loss: 0.231374 Batch F1: 0.09523809523809523
Epoch:  644       10 Batch loss: 0.221613 Batch F1: 0.0
Epoch:  644       11 Batch loss: 0.229860 Batch F1: 0.0
Epoch:  644       12 Batch loss: 0.250532 Batch F1: 0.0
Train Avg Loss  644: 0.223299

Train Avg F1  644: 0.1324619130869131

Val Avg Loss  644: 0.219439

Val Avg F1  644:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 645
--------------------------------------------------------------
Epoch:  645        1 Batch loss: 0.231750 Batch F1: 0.0
Epoch:  645        2 Batch loss: 0.238680 Batch F1: 0.0
Epoch:  645        3 Batch loss: 0.233587 Batch F1: 0.0
Epoch:  645        4 Batch loss: 0.233454 Batch F1: 0.0
Epoch:  645        5 Batch loss: 0.220468 Batch F1: 0.0
Epoch:  645        6 Batch loss: 0.221012 Batch F1: 0.0
Epoch:  645        7 Batch loss: 0.224013 Batch F1: 0.0
Epoch:  645        8 Batch loss: 0.212766 Batch F1: 0.0
Epoch:  645        9 Batch loss: 0.231495 Batch F1: 0.0
Epoch:  645       10 Batch loss: 0.221740 Batch F1: 0.0
Epoch:  645       11 Batch loss: 0.207305 Batch F1: 0.0
Epoch:  645       12 Batch loss: 0.246351 Batch F1: 0.0
Train Avg Loss  645: 0.226885

Train Avg F1  645: 0.0

Val Avg Loss  645: 0.220769

Val Avg F1  645:  0.2613533245339053

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 646
--------------------------------------------------------------
Epoch:  646        1 Batch loss: 0.247884 Batch F1: 0.3870967741935483
Epoch:  646        2 Batch loss: 0.219514 Batch F1: 0.5714285714285714
Epoch:  646        3 Batch loss: 0.230930 Batch F1: 0.5185185185185186
Epoch:  646        4 Batch loss: 0.244196 Batch F1: 0.27586206896551724
Epoch:  646        5 Batch loss: 0.238251 Batch F1: 0.0
Epoch:  646        6 Batch loss: 0.198976 Batch F1: 0.0
Epoch:  646        7 Batch loss: 0.246054 Batch F1: 0.0
Epoch:  646        8 Batch loss: 0.219544 Batch F1: 0.0
Epoch:  646        9 Batch loss: 0.188339 Batch F1: 0.0
Epoch:  646       10 Batch loss: 0.246413 Batch F1: 0.0
Epoch:  646       11 Batch loss: 0.215788 Batch F1: 0.0
Epoch:  646       12 Batch loss: 0.210543 Batch F1: 0.4347826086956522
Train Avg Loss  646: 0.225536

Train Avg F1  646: 0.182307378483484

Val Avg Loss  646: 0.219005

Val Avg F1  646:  0.25227513227513226

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 647
--------------------------------------------------------------
Epoch:  647        1 Batch loss: 0.254360 Batch F1: 0.28571428571428575
Epoch:  647        2 Batch loss: 0.232510 Batch F1: 0.37037037037037035
Epoch:  647        3 Batch loss: 0.209213 Batch F1: 0.5185185185185185
Epoch:  647        4 Batch loss: 0.218999 Batch F1: 0.5333333333333333
Epoch:  647        5 Batch loss: 0.241231 Batch F1: 0.3478260869565218
Epoch:  647        6 Batch loss: 0.233253 Batch F1: 0.2962962962962963
Epoch:  647        7 Batch loss: 0.230033 Batch F1: 0.34782608695652173
Epoch:  647        8 Batch loss: 0.226092 Batch F1: 0.0
Epoch:  647        9 Batch loss: 0.199379 Batch F1: 0.23529411764705882
Epoch:  647       10 Batch loss: 0.182961 Batch F1: 0.0
Epoch:  647       11 Batch loss: 0.196034 Batch F1: 0.0
Epoch:  647       12 Batch loss: 0.262196 Batch F1: 0.0
Train Avg Loss  647: 0.223855

Train Avg F1  647: 0.24459825798274223

Val Avg Loss  647: 0.217407

Val Avg F1  647:  0.1568986568986569

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 648
--------------------------------------------------------------
Epoch:  648        1 Batch loss: 0.238726 Batch F1: 0.1
Epoch:  648        2 Batch loss: 0.227420 Batch F1: 0.3571428571428571
Epoch:  648        3 Batch loss: 0.185049 Batch F1: 0.4761904761904762
Epoch:  648        4 Batch loss: 0.213109 Batch F1: 0.4444444444444445
Epoch:  648        5 Batch loss: 0.217202 Batch F1: 0.24
Epoch:  648        6 Batch loss: 0.211957 Batch F1: 0.44444444444444436
Epoch:  648        7 Batch loss: 0.228294 Batch F1: 0.44444444444444436
Epoch:  648        8 Batch loss: 0.259239 Batch F1: 0.33333333333333326
Epoch:  648        9 Batch loss: 0.239084 Batch F1: 0.16
Epoch:  648       10 Batch loss: 0.236608 Batch F1: 0.2580645161290322
Epoch:  648       11 Batch loss: 0.225642 Batch F1: 0.25
Epoch:  648       12 Batch loss: 0.181981 Batch F1: 0.4
Train Avg Loss  648: 0.222026

Train Avg F1  648: 0.32567204301075264

Val Avg Loss  648: 0.219376

Val Avg F1  648:  0.22539738195418418

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 649
--------------------------------------------------------------
Epoch:  649        1 Batch loss: 0.195771 Batch F1: 0.5185185185185185
Epoch:  649        2 Batch loss: 0.223884 Batch F1: 0.0
Epoch:  649        3 Batch loss: 0.192992 Batch F1: 0.45454545454545453
Epoch:  649        4 Batch loss: 0.241256 Batch F1: 0.23076923076923073
Epoch:  649        5 Batch loss: 0.244479 Batch F1: 0.0
Epoch:  649        6 Batch loss: 0.183835 Batch F1: 0.35294117647058826
Epoch:  649        7 Batch loss: 0.199266 Batch F1: 0.31578947368421056
Epoch:  649        8 Batch loss: 0.255667 Batch F1: 0.07692307692307693
Epoch:  649        9 Batch loss: 0.241300 Batch F1: 0.23076923076923075
Epoch:  649       10 Batch loss: 0.234114 Batch F1: 0.17391304347826086
Epoch:  649       11 Batch loss: 0.233800 Batch F1: 0.32
Epoch:  649       12 Batch loss: 0.222325 Batch F1: 0.2857142857142857
Train Avg Loss  649: 0.222391

Train Avg F1  649: 0.246656957572738

Val Avg Loss  649: 0.219218

Val Avg F1  649:  0.24883540372670807

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 650
--------------------------------------------------------------
Epoch:  650        1 Batch loss: 0.221980 Batch F1: 0.26086956521739124
Epoch:  650        2 Batch loss: 0.219625 Batch F1: 0.3846153846153846
Epoch:  650        3 Batch loss: 0.186310 Batch F1: 0.3
Epoch:  650        4 Batch loss: 0.224369 Batch F1: 0.4666666666666666
Epoch:  650        5 Batch loss: 0.248051 Batch F1: 0.3870967741935484
Epoch:  650        6 Batch loss: 0.283781 Batch F1: 0.3428571428571429
Epoch:  650        7 Batch loss: 0.223158 Batch F1: 0.41379310344827586
Epoch:  650        8 Batch loss: 0.216494 Batch F1: 0.3703703703703704
Epoch:  650        9 Batch loss: 0.232014 Batch F1: 0.35714285714285715
Epoch:  650       10 Batch loss: 0.188371 Batch F1: 0.3529411764705882
Epoch:  650       11 Batch loss: 0.231199 Batch F1: 0.0
Epoch:  650       12 Batch loss: 0.199957 Batch F1: 0.0
Train Avg Loss  650: 0.222942

Train Avg F1  650: 0.30302942008185213

Val Avg Loss  650: 0.217784

Val Avg F1  650:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 651
--------------------------------------------------------------
Epoch:  651        1 Batch loss: 0.251644 Batch F1: 0.0
Epoch:  651        2 Batch loss: 0.248147 Batch F1: 0.0
Epoch:  651        3 Batch loss: 0.180402 Batch F1: 0.0
Epoch:  651        4 Batch loss: 0.215493 Batch F1: 0.0
Epoch:  651        5 Batch loss: 0.241526 Batch F1: 0.0
Epoch:  651        6 Batch loss: 0.193983 Batch F1: 0.0
Epoch:  651        7 Batch loss: 0.232278 Batch F1: 0.0
Epoch:  651        8 Batch loss: 0.236543 Batch F1: 0.0
Epoch:  651        9 Batch loss: 0.241024 Batch F1: 0.0
Epoch:  651       10 Batch loss: 0.203704 Batch F1: 0.2
Epoch:  651       11 Batch loss: 0.221021 Batch F1: 0.25
Epoch:  651       12 Batch loss: 0.239379 Batch F1: 0.2727272727272727
Train Avg Loss  651: 0.225429

Train Avg F1  651: 0.06022727272727272

Val Avg Loss  651: 0.218697

Val Avg F1  651:  0.2677098264054786

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 652
--------------------------------------------------------------
Epoch:  652        1 Batch loss: 0.218862 Batch F1: 0.42857142857142855
Epoch:  652        2 Batch loss: 0.224641 Batch F1: 0.24
Epoch:  652        3 Batch loss: 0.210716 Batch F1: 0.3636363636363636
Epoch:  652        4 Batch loss: 0.193995 Batch F1: 0.4
Epoch:  652        5 Batch loss: 0.191581 Batch F1: 0.46153846153846156
Epoch:  652        6 Batch loss: 0.229934 Batch F1: 0.0
Epoch:  652        7 Batch loss: 0.188765 Batch F1: 0.13333333333333336
Epoch:  652        8 Batch loss: 0.292356 Batch F1: 0.06451612903225806
Epoch:  652        9 Batch loss: 0.232530 Batch F1: 0.0
Epoch:  652       10 Batch loss: 0.227701 Batch F1: 0.3076923076923077
Epoch:  652       11 Batch loss: 0.219581 Batch F1: 0.26086956521739124
Epoch:  652       12 Batch loss: 0.251976 Batch F1: 0.2
Train Avg Loss  652: 0.223553

Train Avg F1  652: 0.23834646575179533

Val Avg Loss  652: 0.220171

Val Avg F1  652:  0.24187830687830691

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 653
--------------------------------------------------------------
Epoch:  653        1 Batch loss: 0.237641 Batch F1: 0.35714285714285715
Epoch:  653        2 Batch loss: 0.238445 Batch F1: 0.21428571428571427
Epoch:  653        3 Batch loss: 0.239166 Batch F1: 0.32
Epoch:  653        4 Batch loss: 0.192216 Batch F1: 0.21052631578947367
Epoch:  653        5 Batch loss: 0.228498 Batch F1: 0.5185185185185185
Epoch:  653        6 Batch loss: 0.193352 Batch F1: 0.0
Epoch:  653        7 Batch loss: 0.242601 Batch F1: 0.08695652173913045
Epoch:  653        8 Batch loss: 0.250137 Batch F1: 0.0
Epoch:  653        9 Batch loss: 0.200535 Batch F1: 0.0
Epoch:  653       10 Batch loss: 0.220868 Batch F1: 0.0
Epoch:  653       11 Batch loss: 0.223706 Batch F1: 0.1818181818181818
Epoch:  653       12 Batch loss: 0.208468 Batch F1: 0.4444444444444445
Train Avg Loss  653: 0.222969

Train Avg F1  653: 0.19447437947819335

Val Avg Loss  653: 0.217916

Val Avg F1  653:  0.236969696969697

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 654
--------------------------------------------------------------
Epoch:  654        1 Batch loss: 0.209727 Batch F1: 0.19047619047619047
Epoch:  654        2 Batch loss: 0.227250 Batch F1: 0.4
Epoch:  654        3 Batch loss: 0.233887 Batch F1: 0.16666666666666666
Epoch:  654        4 Batch loss: 0.216365 Batch F1: 0.4666666666666667
Epoch:  654        5 Batch loss: 0.231922 Batch F1: 0.37037037037037035
Epoch:  654        6 Batch loss: 0.237444 Batch F1: 0.3846153846153846
Epoch:  654        7 Batch loss: 0.206557 Batch F1: 0.46153846153846156
Epoch:  654        8 Batch loss: 0.179404 Batch F1: 0.37499999999999994
Epoch:  654        9 Batch loss: 0.265504 Batch F1: 0.20689655172413796
Epoch:  654       10 Batch loss: 0.186627 Batch F1: 0.3529411764705882
Epoch:  654       11 Batch loss: 0.252934 Batch F1: 0.0
Epoch:  654       12 Batch loss: 0.233096 Batch F1: 0.1
Train Avg Loss  654: 0.223393

Train Avg F1  654: 0.28959762237737224

Val Avg Loss  654: 0.216994

Val Avg F1  654:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 655
--------------------------------------------------------------
Epoch:  655        1 Batch loss: 0.201944 Batch F1: 0.09523809523809525
Epoch:  655        2 Batch loss: 0.251089 Batch F1: 0.23076923076923075
Epoch:  655        3 Batch loss: 0.237392 Batch F1: 0.0
Epoch:  655        4 Batch loss: 0.201204 Batch F1: 0.31578947368421056
Epoch:  655        5 Batch loss: 0.185096 Batch F1: 0.42105263157894735
Epoch:  655        6 Batch loss: 0.237591 Batch F1: 0.3448275862068966
Epoch:  655        7 Batch loss: 0.225789 Batch F1: 0.4166666666666667
Epoch:  655        8 Batch loss: 0.214229 Batch F1: 0.4444444444444444
Epoch:  655        9 Batch loss: 0.222144 Batch F1: 0.3
Epoch:  655       10 Batch loss: 0.226427 Batch F1: 0.1818181818181818
Epoch:  655       11 Batch loss: 0.220491 Batch F1: 0.09523809523809525
Epoch:  655       12 Batch loss: 0.255926 Batch F1: 0.0
Train Avg Loss  655: 0.223277

Train Avg F1  655: 0.23715370047039738

Val Avg Loss  655: 0.217932

Val Avg F1  655:  0.022727272727272724

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 656
--------------------------------------------------------------
Epoch:  656        1 Batch loss: 0.204952 Batch F1: 0.23529411764705882
Epoch:  656        2 Batch loss: 0.210431 Batch F1: 0.09523809523809525
Epoch:  656        3 Batch loss: 0.216380 Batch F1: 0.0
Epoch:  656        4 Batch loss: 0.210229 Batch F1: 0.08695652173913043
Epoch:  656        5 Batch loss: 0.229300 Batch F1: 0.09523809523809525
Epoch:  656        6 Batch loss: 0.221404 Batch F1: 0.2608695652173913
Epoch:  656        7 Batch loss: 0.229620 Batch F1: 0.41379310344827586
Epoch:  656        8 Batch loss: 0.227265 Batch F1: 0.2962962962962963
Epoch:  656        9 Batch loss: 0.264393 Batch F1: 0.14285714285714288
Epoch:  656       10 Batch loss: 0.207511 Batch F1: 0.38095238095238093
Epoch:  656       11 Batch loss: 0.226818 Batch F1: 0.30769230769230765
Epoch:  656       12 Batch loss: 0.224271 Batch F1: 0.4
Train Avg Loss  656: 0.222715

Train Avg F1  656: 0.22626563552718118

Val Avg Loss  656: 0.219012

Val Avg F1  656:  0.2548306249494704

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 657
--------------------------------------------------------------
Epoch:  657        1 Batch loss: 0.205046 Batch F1: 0.3
Epoch:  657        2 Batch loss: 0.205757 Batch F1: 0.0
Epoch:  657        3 Batch loss: 0.188587 Batch F1: 0.0
Epoch:  657        4 Batch loss: 0.228164 Batch F1: 0.0
Epoch:  657        5 Batch loss: 0.209035 Batch F1: 0.42857142857142855
Epoch:  657        6 Batch loss: 0.235911 Batch F1: 0.16
Epoch:  657        7 Batch loss: 0.225693 Batch F1: 0.30769230769230765
Epoch:  657        8 Batch loss: 0.243022 Batch F1: 0.16666666666666669
Epoch:  657        9 Batch loss: 0.231679 Batch F1: 0.1
Epoch:  657       10 Batch loss: 0.222170 Batch F1: 0.09999999999999999
Epoch:  657       11 Batch loss: 0.261621 Batch F1: 0.0
Epoch:  657       12 Batch loss: 0.223496 Batch F1: 0.3
Train Avg Loss  657: 0.223349

Train Avg F1  657: 0.15524420024420027

Val Avg Loss  657: 0.223328

Val Avg F1  657:  0.2608495752123938

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 658
--------------------------------------------------------------
Epoch:  658        1 Batch loss: 0.244943 Batch F1: 0.07692307692307693
Epoch:  658        2 Batch loss: 0.229892 Batch F1: 0.37499999999999994
Epoch:  658        3 Batch loss: 0.224413 Batch F1: 0.3333333333333333
Epoch:  658        4 Batch loss: 0.237493 Batch F1: 0.2962962962962963
Epoch:  658        5 Batch loss: 0.230221 Batch F1: 0.32000000000000006
Epoch:  658        6 Batch loss: 0.205002 Batch F1: 0.18181818181818182
Epoch:  658        7 Batch loss: 0.235911 Batch F1: 0.0
Epoch:  658        8 Batch loss: 0.219153 Batch F1: 0.0
Epoch:  658        9 Batch loss: 0.263359 Batch F1: 0.15384615384615385
Epoch:  658       10 Batch loss: 0.201081 Batch F1: 0.5217391304347826
Epoch:  658       11 Batch loss: 0.212670 Batch F1: 0.3809523809523809
Epoch:  658       12 Batch loss: 0.174553 Batch F1: 0.0
Train Avg Loss  658: 0.223224

Train Avg F1  658: 0.21999237946701714

Val Avg Loss  658: 0.218287

Val Avg F1  658:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 659
--------------------------------------------------------------
Epoch:  659        1 Batch loss: 0.173016 Batch F1: 0.0
Epoch:  659        2 Batch loss: 0.209868 Batch F1: 0.0
Epoch:  659        3 Batch loss: 0.273918 Batch F1: 0.0
Epoch:  659        4 Batch loss: 0.266532 Batch F1: 0.0
Epoch:  659        5 Batch loss: 0.208027 Batch F1: 0.0
Epoch:  659        6 Batch loss: 0.244896 Batch F1: 0.0
Epoch:  659        7 Batch loss: 0.230781 Batch F1: 0.09523809523809523
Epoch:  659        8 Batch loss: 0.226589 Batch F1: 0.36363636363636365
Epoch:  659        9 Batch loss: 0.230507 Batch F1: 0.4
Epoch:  659       10 Batch loss: 0.229352 Batch F1: 0.32000000000000006
Epoch:  659       11 Batch loss: 0.231543 Batch F1: 0.0
Epoch:  659       12 Batch loss: 0.209770 Batch F1: 0.0
Train Avg Loss  659: 0.227900

Train Avg F1  659: 0.09823953823953824

Val Avg Loss  659: 0.219549

Val Avg F1  659:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 660
--------------------------------------------------------------
Epoch:  660        1 Batch loss: 0.221464 Batch F1: 0.0
Epoch:  660        2 Batch loss: 0.230564 Batch F1: 0.09523809523809523
Epoch:  660        3 Batch loss: 0.224197 Batch F1: 0.0
Epoch:  660        4 Batch loss: 0.197918 Batch F1: 0.0
Epoch:  660        5 Batch loss: 0.239559 Batch F1: 0.0
Epoch:  660        6 Batch loss: 0.234146 Batch F1: 0.0
Epoch:  660        7 Batch loss: 0.231949 Batch F1: 0.0
Epoch:  660        8 Batch loss: 0.190976 Batch F1: 0.0
Epoch:  660        9 Batch loss: 0.226958 Batch F1: 0.0
Epoch:  660       10 Batch loss: 0.223252 Batch F1: 0.0
Epoch:  660       11 Batch loss: 0.227766 Batch F1: 0.1818181818181818
Epoch:  660       12 Batch loss: 0.237957 Batch F1: 0.27272727272727276
Train Avg Loss  660: 0.223892

Train Avg F1  660: 0.04581529581529581

Val Avg Loss  660: 0.226567

Val Avg F1  660:  0.41010436432637576

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 661
--------------------------------------------------------------
Epoch:  661        1 Batch loss: 0.238118 Batch F1: 0.45714285714285713
Epoch:  661        2 Batch loss: 0.222697 Batch F1: 0.0
Epoch:  661        3 Batch loss: 0.192489 Batch F1: 0.0
Epoch:  661        4 Batch loss: 0.232277 Batch F1: 0.0
Epoch:  661        5 Batch loss: 0.237525 Batch F1: 0.0
Epoch:  661        6 Batch loss: 0.247183 Batch F1: 0.0
Epoch:  661        7 Batch loss: 0.231559 Batch F1: 0.0
Epoch:  661        8 Batch loss: 0.219929 Batch F1: 0.0
Epoch:  661        9 Batch loss: 0.227766 Batch F1: 0.0
Epoch:  661       10 Batch loss: 0.211600 Batch F1: 0.0
Epoch:  661       11 Batch loss: 0.213550 Batch F1: 0.37037037037037035
Epoch:  661       12 Batch loss: 0.225751 Batch F1: 0.27272727272727276
Train Avg Loss  661: 0.225037

Train Avg F1  661: 0.09168670835337502

Val Avg Loss  661: 0.222510

Val Avg F1  661:  0.30384490061909414

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 662
--------------------------------------------------------------
Epoch:  662        1 Batch loss: 0.248816 Batch F1: 0.3448275862068965
Epoch:  662        2 Batch loss: 0.207689 Batch F1: 0.6153846153846153
Epoch:  662        3 Batch loss: 0.199857 Batch F1: 0.6153846153846154
Epoch:  662        4 Batch loss: 0.222987 Batch F1: 0.3870967741935483
Epoch:  662        5 Batch loss: 0.241695 Batch F1: 0.16666666666666666
Epoch:  662        6 Batch loss: 0.228674 Batch F1: 0.23076923076923078
Epoch:  662        7 Batch loss: 0.202495 Batch F1: 0.36363636363636365
Epoch:  662        8 Batch loss: 0.182169 Batch F1: 0.3157894736842105
Epoch:  662        9 Batch loss: 0.242207 Batch F1: 0.0
Epoch:  662       10 Batch loss: 0.271021 Batch F1: 0.0
Epoch:  662       11 Batch loss: 0.187557 Batch F1: 0.0
Epoch:  662       12 Batch loss: 0.255482 Batch F1: 0.09523809523809525
Train Avg Loss  662: 0.224221

Train Avg F1  662: 0.26123278509702025

Val Avg Loss  662: 0.218467

Val Avg F1  662:  0.23812724014336917

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 663
--------------------------------------------------------------
Epoch:  663        1 Batch loss: 0.241100 Batch F1: 0.2962962962962963
Epoch:  663        2 Batch loss: 0.229848 Batch F1: 0.1
Epoch:  663        3 Batch loss: 0.231943 Batch F1: 0.4
Epoch:  663        4 Batch loss: 0.235581 Batch F1: 0.21428571428571427
Epoch:  663        5 Batch loss: 0.198546 Batch F1: 0.4761904761904762
Epoch:  663        6 Batch loss: 0.218417 Batch F1: 0.09523809523809523
Epoch:  663        7 Batch loss: 0.251537 Batch F1: 0.35714285714285715
Epoch:  663        8 Batch loss: 0.208126 Batch F1: 0.31578947368421056
Epoch:  663        9 Batch loss: 0.206535 Batch F1: 0.3
Epoch:  663       10 Batch loss: 0.228670 Batch F1: 0.4
Epoch:  663       11 Batch loss: 0.212510 Batch F1: 0.30769230769230765
Epoch:  663       12 Batch loss: 0.209085 Batch F1: 0.3
Train Avg Loss  663: 0.222658

Train Avg F1  663: 0.2968862683774964

Val Avg Loss  663: 0.217968

Val Avg F1  663:  0.2826923076923077

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 664
--------------------------------------------------------------
Epoch:  664        1 Batch loss: 0.230031 Batch F1: 0.39999999999999997
Epoch:  664        2 Batch loss: 0.224882 Batch F1: 0.0909090909090909
Epoch:  664        3 Batch loss: 0.223351 Batch F1: 0.1
Epoch:  664        4 Batch loss: 0.221816 Batch F1: 0.24999999999999997
Epoch:  664        5 Batch loss: 0.190295 Batch F1: 0.14285714285714288
Epoch:  664        6 Batch loss: 0.216845 Batch F1: 0.4827586206896552
Epoch:  664        7 Batch loss: 0.248335 Batch F1: 0.0
Epoch:  664        8 Batch loss: 0.228689 Batch F1: 0.0
Epoch:  664        9 Batch loss: 0.222775 Batch F1: 0.2608695652173913
Epoch:  664       10 Batch loss: 0.205394 Batch F1: 0.4285714285714285
Epoch:  664       11 Batch loss: 0.227128 Batch F1: 0.39999999999999997
Epoch:  664       12 Batch loss: 0.225341 Batch F1: 0.3333333333333333
Train Avg Loss  664: 0.222074

Train Avg F1  664: 0.2407749317981702

Val Avg Loss  664: 0.219730

Val Avg F1  664:  0.2206699751861042

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 665
--------------------------------------------------------------
Epoch:  665        1 Batch loss: 0.199540 Batch F1: 0.4347826086956522
Epoch:  665        2 Batch loss: 0.223664 Batch F1: 0.31999999999999995
Epoch:  665        3 Batch loss: 0.184604 Batch F1: 0.0
Epoch:  665        4 Batch loss: 0.208899 Batch F1: 0.3478260869565218
Epoch:  665        5 Batch loss: 0.251184 Batch F1: 0.0
Epoch:  665        6 Batch loss: 0.246965 Batch F1: 0.0
Epoch:  665        7 Batch loss: 0.191055 Batch F1: 0.0
Epoch:  665        8 Batch loss: 0.240336 Batch F1: 0.0
Epoch:  665        9 Batch loss: 0.216610 Batch F1: 0.08695652173913045
Epoch:  665       10 Batch loss: 0.242977 Batch F1: 0.15384615384615385
Epoch:  665       11 Batch loss: 0.245571 Batch F1: 0.2962962962962963
Epoch:  665       12 Batch loss: 0.217091 Batch F1: 0.3478260869565218
Train Avg Loss  665: 0.222375

Train Avg F1  665: 0.16562781287418968

Val Avg Loss  665: 0.220481

Val Avg F1  665:  0.27025539517822783

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 666
--------------------------------------------------------------
Epoch:  666        1 Batch loss: 0.219394 Batch F1: 0.4444444444444445
Epoch:  666        2 Batch loss: 0.234916 Batch F1: 0.2857142857142857
Epoch:  666        3 Batch loss: 0.237185 Batch F1: 0.2962962962962963
Epoch:  666        4 Batch loss: 0.221807 Batch F1: 0.23076923076923078
Epoch:  666        5 Batch loss: 0.241556 Batch F1: 0.23076923076923073
Epoch:  666        6 Batch loss: 0.238336 Batch F1: 0.0
Epoch:  666        7 Batch loss: 0.199007 Batch F1: 0.3636363636363636
Epoch:  666        8 Batch loss: 0.222594 Batch F1: 0.0
Epoch:  666        9 Batch loss: 0.215955 Batch F1: 0.0
Epoch:  666       10 Batch loss: 0.210865 Batch F1: 0.0
Epoch:  666       11 Batch loss: 0.238489 Batch F1: 0.09090909090909091
Epoch:  666       12 Batch loss: 0.214082 Batch F1: 0.34782608695652173
Train Avg Loss  666: 0.224516

Train Avg F1  666: 0.19086375245795537

Val Avg Loss  666: 0.220092

Val Avg F1  666:  0.2424099040705211

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 667
--------------------------------------------------------------
Epoch:  667        1 Batch loss: 0.257327 Batch F1: 0.20689655172413793
Epoch:  667        2 Batch loss: 0.237643 Batch F1: 0.26666666666666666
Epoch:  667        3 Batch loss: 0.232740 Batch F1: 0.4444444444444444
Epoch:  667        4 Batch loss: 0.221394 Batch F1: 0.4999999999999999
Epoch:  667        5 Batch loss: 0.235739 Batch F1: 0.3846153846153846
Epoch:  667        6 Batch loss: 0.219399 Batch F1: 0.1739130434782609
Epoch:  667        7 Batch loss: 0.234286 Batch F1: 0.39999999999999997
Epoch:  667        8 Batch loss: 0.216304 Batch F1: 0.1111111111111111
Epoch:  667        9 Batch loss: 0.186484 Batch F1: 0.0
Epoch:  667       10 Batch loss: 0.217027 Batch F1: 0.0
Epoch:  667       11 Batch loss: 0.229627 Batch F1: 0.0
Epoch:  667       12 Batch loss: 0.186165 Batch F1: 0.4
Train Avg Loss  667: 0.222845

Train Avg F1  667: 0.2406372668366671

Val Avg Loss  667: 0.218297

Val Avg F1  667:  0.05756578947368421

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 668
--------------------------------------------------------------
Epoch:  668        1 Batch loss: 0.216886 Batch F1: 0.10526315789473684
Epoch:  668        2 Batch loss: 0.238418 Batch F1: 0.0
Epoch:  668        3 Batch loss: 0.223560 Batch F1: 0.44444444444444436
Epoch:  668        4 Batch loss: 0.214996 Batch F1: 0.2608695652173913
Epoch:  668        5 Batch loss: 0.217749 Batch F1: 0.41379310344827586
Epoch:  668        6 Batch loss: 0.234979 Batch F1: 0.4137931034482759
Epoch:  668        7 Batch loss: 0.220126 Batch F1: 0.3157894736842105
Epoch:  668        8 Batch loss: 0.273928 Batch F1: 0.28571428571428575
Epoch:  668        9 Batch loss: 0.214106 Batch F1: 0.3
Epoch:  668       10 Batch loss: 0.208296 Batch F1: 0.21052631578947367
Epoch:  668       11 Batch loss: 0.201676 Batch F1: 0.1111111111111111
Epoch:  668       12 Batch loss: 0.208475 Batch F1: 0.11764705882352941
Train Avg Loss  668: 0.222766

Train Avg F1  668: 0.24824596829797785

Val Avg Loss  668: 0.218192

Val Avg F1  668:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 669
--------------------------------------------------------------
Epoch:  669        1 Batch loss: 0.208783 Batch F1: 0.1111111111111111
Epoch:  669        2 Batch loss: 0.197848 Batch F1: 0.0
Epoch:  669        3 Batch loss: 0.195786 Batch F1: 0.0
Epoch:  669        4 Batch loss: 0.225210 Batch F1: 0.1739130434782609
Epoch:  669        5 Batch loss: 0.253362 Batch F1: 0.0
Epoch:  669        6 Batch loss: 0.273010 Batch F1: 0.15384615384615385
Epoch:  669        7 Batch loss: 0.212289 Batch F1: 0.27586206896551724
Epoch:  669        8 Batch loss: 0.218052 Batch F1: 0.5
Epoch:  669        9 Batch loss: 0.218303 Batch F1: 0.23999999999999996
Epoch:  669       10 Batch loss: 0.222519 Batch F1: 0.5517241379310346
Epoch:  669       11 Batch loss: 0.229861 Batch F1: 0.22222222222222224
Epoch:  669       12 Batch loss: 0.225893 Batch F1: 0.21052631578947367
Train Avg Loss  669: 0.223410

Train Avg F1  669: 0.20326708777864777

Val Avg Loss  669: 0.218563

Val Avg F1  669:  0.11458333333333334

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 670
--------------------------------------------------------------
Epoch:  670        1 Batch loss: 0.177002 Batch F1: 0.16666666666666669
Epoch:  670        2 Batch loss: 0.243942 Batch F1: 0.0
Epoch:  670        3 Batch loss: 0.211219 Batch F1: 0.0
Epoch:  670        4 Batch loss: 0.247846 Batch F1: 0.0
Epoch:  670        5 Batch loss: 0.219976 Batch F1: 0.0
Epoch:  670        6 Batch loss: 0.233697 Batch F1: 0.0
Epoch:  670        7 Batch loss: 0.209121 Batch F1: 0.0
Epoch:  670        8 Batch loss: 0.260330 Batch F1: 0.0
Epoch:  670        9 Batch loss: 0.216518 Batch F1: 0.39999999999999997
Epoch:  670       10 Batch loss: 0.226819 Batch F1: 0.25
Epoch:  670       11 Batch loss: 0.193881 Batch F1: 0.0
Epoch:  670       12 Batch loss: 0.256916 Batch F1: 0.0
Train Avg Loss  670: 0.224772

Train Avg F1  670: 0.06805555555555555

Val Avg Loss  670: 0.218281

Val Avg F1  670:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 671
--------------------------------------------------------------
Epoch:  671        1 Batch loss: 0.226498 Batch F1: 0.0
Epoch:  671        2 Batch loss: 0.214150 Batch F1: 0.44444444444444436
Epoch:  671        3 Batch loss: 0.239303 Batch F1: 0.23076923076923075
Epoch:  671        4 Batch loss: 0.230972 Batch F1: 0.4
Epoch:  671        5 Batch loss: 0.232096 Batch F1: 0.5142857142857143
Epoch:  671        6 Batch loss: 0.217265 Batch F1: 0.39999999999999997
Epoch:  671        7 Batch loss: 0.217249 Batch F1: 0.2222222222222222
Epoch:  671        8 Batch loss: 0.251337 Batch F1: 0.29629629629629634
Epoch:  671        9 Batch loss: 0.211054 Batch F1: 0.3
Epoch:  671       10 Batch loss: 0.204629 Batch F1: 0.0
Epoch:  671       11 Batch loss: 0.214713 Batch F1: 0.0
Epoch:  671       12 Batch loss: 0.223721 Batch F1: 0.0
Train Avg Loss  671: 0.223582

Train Avg F1  671: 0.23400149233482567

Val Avg Loss  671: 0.217762

Val Avg F1  671:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 672
--------------------------------------------------------------
Epoch:  672        1 Batch loss: 0.197445 Batch F1: 0.0
Epoch:  672        2 Batch loss: 0.223369 Batch F1: 0.0
Epoch:  672        3 Batch loss: 0.237555 Batch F1: 0.0
Epoch:  672        4 Batch loss: 0.206773 Batch F1: 0.125
Epoch:  672        5 Batch loss: 0.193435 Batch F1: 0.14285714285714285
Epoch:  672        6 Batch loss: 0.255479 Batch F1: 0.07692307692307693
Epoch:  672        7 Batch loss: 0.240024 Batch F1: 0.0
Epoch:  672        8 Batch loss: 0.247625 Batch F1: 0.0
Epoch:  672        9 Batch loss: 0.230688 Batch F1: 0.37037037037037035
Epoch:  672       10 Batch loss: 0.222887 Batch F1: 0.25
Epoch:  672       11 Batch loss: 0.213932 Batch F1: 0.48
Epoch:  672       12 Batch loss: 0.202482 Batch F1: 0.28571428571428575
Train Avg Loss  672: 0.222641

Train Avg F1  672: 0.14423873965540632

Val Avg Loss  672: 0.221424

Val Avg F1  672:  0.32954545454545453

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 673
--------------------------------------------------------------
Epoch:  673        1 Batch loss: 0.210650 Batch F1: 0.5
Epoch:  673        2 Batch loss: 0.218037 Batch F1: 0.4444444444444444
Epoch:  673        3 Batch loss: 0.222101 Batch F1: 0.5
Epoch:  673        4 Batch loss: 0.249594 Batch F1: 0.2758620689655173
Epoch:  673        5 Batch loss: 0.209994 Batch F1: 0.18181818181818182
Epoch:  673        6 Batch loss: 0.248530 Batch F1: 0.21428571428571425
Epoch:  673        7 Batch loss: 0.228712 Batch F1: 0.3870967741935483
Epoch:  673        8 Batch loss: 0.236553 Batch F1: 0.33333333333333326
Epoch:  673        9 Batch loss: 0.197083 Batch F1: 0.5
Epoch:  673       10 Batch loss: 0.199062 Batch F1: 0.23529411764705882
Epoch:  673       11 Batch loss: 0.225452 Batch F1: 0.3636363636363636
Epoch:  673       12 Batch loss: 0.219691 Batch F1: 0.35294117647058826
Train Avg Loss  673: 0.222122

Train Avg F1  673: 0.35739268123289586

Val Avg Loss  673: 0.218898

Val Avg F1  673:  0.2698135198135198

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 674
--------------------------------------------------------------
Epoch:  674        1 Batch loss: 0.215533 Batch F1: 0.3333333333333333
Epoch:  674        2 Batch loss: 0.217961 Batch F1: 0.10526315789473684
Epoch:  674        3 Batch loss: 0.224759 Batch F1: 0.08695652173913045
Epoch:  674        4 Batch loss: 0.223778 Batch F1: 0.0
Epoch:  674        5 Batch loss: 0.207074 Batch F1: 0.0
Epoch:  674        6 Batch loss: 0.190602 Batch F1: 0.0
Epoch:  674        7 Batch loss: 0.206127 Batch F1: 0.0
Epoch:  674        8 Batch loss: 0.255548 Batch F1: 0.2962962962962963
Epoch:  674        9 Batch loss: 0.271199 Batch F1: 0.24242424242424246
Epoch:  674       10 Batch loss: 0.209118 Batch F1: 0.3846153846153846
Epoch:  674       11 Batch loss: 0.257252 Batch F1: 0.20689655172413793
Epoch:  674       12 Batch loss: 0.190260 Batch F1: 0.15384615384615383
Train Avg Loss  674: 0.222434

Train Avg F1  674: 0.15080263682278464

Val Avg Loss  674: 0.220169

Val Avg F1  674:  0.22745601173020527

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 675
--------------------------------------------------------------
Epoch:  675        1 Batch loss: 0.208380 Batch F1: 0.5625000000000001
Epoch:  675        2 Batch loss: 0.228165 Batch F1: 0.2962962962962963
Epoch:  675        3 Batch loss: 0.211753 Batch F1: 0.0
Epoch:  675        4 Batch loss: 0.208544 Batch F1: 0.0
Epoch:  675        5 Batch loss: 0.256029 Batch F1: 0.0
Epoch:  675        6 Batch loss: 0.234230 Batch F1: 0.0
Epoch:  675        7 Batch loss: 0.175339 Batch F1: 0.0
Epoch:  675        8 Batch loss: 0.225826 Batch F1: 0.0
Epoch:  675        9 Batch loss: 0.252017 Batch F1: 0.0
Epoch:  675       10 Batch loss: 0.231962 Batch F1: 0.0
Epoch:  675       11 Batch loss: 0.238344 Batch F1: 0.0
Epoch:  675       12 Batch loss: 0.203966 Batch F1: 0.4
Train Avg Loss  675: 0.222880

Train Avg F1  675: 0.1048996913580247

Val Avg Loss  675: 0.225080

Val Avg F1  675:  0.33518437465805884

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 676
--------------------------------------------------------------
Epoch:  676        1 Batch loss: 0.209661 Batch F1: 0.6249999999999999
Epoch:  676        2 Batch loss: 0.222016 Batch F1: 0.5128205128205129
Epoch:  676        3 Batch loss: 0.232296 Batch F1: 0.5555555555555556
Epoch:  676        4 Batch loss: 0.199570 Batch F1: 0.0
Epoch:  676        5 Batch loss: 0.238059 Batch F1: 0.0
Epoch:  676        6 Batch loss: 0.253947 Batch F1: 0.0
Epoch:  676        7 Batch loss: 0.225344 Batch F1: 0.0
Epoch:  676        8 Batch loss: 0.220207 Batch F1: 0.0
Epoch:  676        9 Batch loss: 0.199014 Batch F1: 0.0
Epoch:  676       10 Batch loss: 0.234977 Batch F1: 0.0
Epoch:  676       11 Batch loss: 0.239735 Batch F1: 0.0
Epoch:  676       12 Batch loss: 0.250131 Batch F1: 0.0
Train Avg Loss  676: 0.227080

Train Avg F1  676: 0.14111467236467237

Val Avg Loss  676: 0.217686

Val Avg F1  676:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 677
--------------------------------------------------------------
Epoch:  677        1 Batch loss: 0.218813 Batch F1: 0.0
Epoch:  677        2 Batch loss: 0.228251 Batch F1: 0.0
Epoch:  677        3 Batch loss: 0.203638 Batch F1: 0.10526315789473682
Epoch:  677        4 Batch loss: 0.219000 Batch F1: 0.23999999999999996
Epoch:  677        5 Batch loss: 0.258209 Batch F1: 0.0
Epoch:  677        6 Batch loss: 0.230211 Batch F1: 0.27272727272727276
Epoch:  677        7 Batch loss: 0.217746 Batch F1: 0.5185185185185185
Epoch:  677        8 Batch loss: 0.263164 Batch F1: 0.20689655172413793
Epoch:  677        9 Batch loss: 0.217690 Batch F1: 0.3846153846153846
Epoch:  677       10 Batch loss: 0.224848 Batch F1: 0.588235294117647
Epoch:  677       11 Batch loss: 0.218241 Batch F1: 0.4827586206896552
Epoch:  677       12 Batch loss: 0.203025 Batch F1: 0.15384615384615385
Train Avg Loss  677: 0.225236

Train Avg F1  677: 0.24607174617779223

Val Avg Loss  677: 0.218104

Val Avg F1  677:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 678
--------------------------------------------------------------
Epoch:  678        1 Batch loss: 0.202403 Batch F1: 0.1111111111111111
Epoch:  678        2 Batch loss: 0.217963 Batch F1: 0.0
Epoch:  678        3 Batch loss: 0.248079 Batch F1: 0.0
Epoch:  678        4 Batch loss: 0.226330 Batch F1: 0.0
Epoch:  678        5 Batch loss: 0.211081 Batch F1: 0.0
Epoch:  678        6 Batch loss: 0.202785 Batch F1: 0.0
Epoch:  678        7 Batch loss: 0.265717 Batch F1: 0.0
Epoch:  678        8 Batch loss: 0.195225 Batch F1: 0.0
Epoch:  678        9 Batch loss: 0.227826 Batch F1: 0.41379310344827586
Epoch:  678       10 Batch loss: 0.251933 Batch F1: 0.0
Epoch:  678       11 Batch loss: 0.210757 Batch F1: 0.41379310344827586
Epoch:  678       12 Batch loss: 0.229055 Batch F1: 0.125
Train Avg Loss  678: 0.224096

Train Avg F1  678: 0.08864144316730523

Val Avg Loss  678: 0.220804

Val Avg F1  678:  0.2565429739342783

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 679
--------------------------------------------------------------
Epoch:  679        1 Batch loss: 0.205147 Batch F1: 0.19047619047619047
Epoch:  679        2 Batch loss: 0.257744 Batch F1: 0.0
Epoch:  679        3 Batch loss: 0.200740 Batch F1: 0.0
Epoch:  679        4 Batch loss: 0.218084 Batch F1: 0.0
Epoch:  679        5 Batch loss: 0.206295 Batch F1: 0.0
Epoch:  679        6 Batch loss: 0.229583 Batch F1: 0.0
Epoch:  679        7 Batch loss: 0.243248 Batch F1: 0.0
Epoch:  679        8 Batch loss: 0.213106 Batch F1: 0.0
Epoch:  679        9 Batch loss: 0.199446 Batch F1: 0.0
Epoch:  679       10 Batch loss: 0.256829 Batch F1: 0.0
Epoch:  679       11 Batch loss: 0.211364 Batch F1: 0.0909090909090909
Epoch:  679       12 Batch loss: 0.239230 Batch F1: 0.4666666666666667
Train Avg Loss  679: 0.223401

Train Avg F1  679: 0.06233766233766234

Val Avg Loss  679: 0.219753

Val Avg F1  679:  0.2673578595317726

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 680
--------------------------------------------------------------
Epoch:  680        1 Batch loss: 0.211794 Batch F1: 0.23999999999999996
Epoch:  680        2 Batch loss: 0.228943 Batch F1: 0.4666666666666667
Epoch:  680        3 Batch loss: 0.215567 Batch F1: 0.4827586206896552
Epoch:  680        4 Batch loss: 0.232574 Batch F1: 0.5405405405405406
Epoch:  680        5 Batch loss: 0.233284 Batch F1: 0.32
Epoch:  680        6 Batch loss: 0.223078 Batch F1: 0.32
Epoch:  680        7 Batch loss: 0.236357 Batch F1: 0.4285714285714285
Epoch:  680        8 Batch loss: 0.222462 Batch F1: 0.41379310344827586
Epoch:  680        9 Batch loss: 0.184646 Batch F1: 0.37499999999999994
Epoch:  680       10 Batch loss: 0.255887 Batch F1: 0.0
Epoch:  680       11 Batch loss: 0.181704 Batch F1: 0.0
Epoch:  680       12 Batch loss: 0.266585 Batch F1: 0.0
Train Avg Loss  680: 0.224407

Train Avg F1  680: 0.2989441966597139

Val Avg Loss  680: 0.220579

Val Avg F1  680:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 681
--------------------------------------------------------------
Epoch:  681        1 Batch loss: 0.241283 Batch F1: 0.0
Epoch:  681        2 Batch loss: 0.265025 Batch F1: 0.0
Epoch:  681        3 Batch loss: 0.235677 Batch F1: 0.0
Epoch:  681        4 Batch loss: 0.231197 Batch F1: 0.0
Epoch:  681        5 Batch loss: 0.220776 Batch F1: 0.0
Epoch:  681        6 Batch loss: 0.220742 Batch F1: 0.0
Epoch:  681        7 Batch loss: 0.220691 Batch F1: 0.0
Epoch:  681        8 Batch loss: 0.237453 Batch F1: 0.0
Epoch:  681        9 Batch loss: 0.230275 Batch F1: 0.0
Epoch:  681       10 Batch loss: 0.224776 Batch F1: 0.0
Epoch:  681       11 Batch loss: 0.227160 Batch F1: 0.0
Epoch:  681       12 Batch loss: 0.238912 Batch F1: 0.0
Train Avg Loss  681: 0.232831

Train Avg F1  681: 0.0

Val Avg Loss  681: 0.220954

Val Avg F1  681:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 682
--------------------------------------------------------------
Epoch:  682        1 Batch loss: 0.237560 Batch F1: 0.0
Epoch:  682        2 Batch loss: 0.252542 Batch F1: 0.0
Epoch:  682        3 Batch loss: 0.232348 Batch F1: 0.0
Epoch:  682        4 Batch loss: 0.226466 Batch F1: 0.0
Epoch:  682        5 Batch loss: 0.234187 Batch F1: 0.0
Epoch:  682        6 Batch loss: 0.200830 Batch F1: 0.0
Epoch:  682        7 Batch loss: 0.227743 Batch F1: 0.0
Epoch:  682        8 Batch loss: 0.237609 Batch F1: 0.0
Epoch:  682        9 Batch loss: 0.247126 Batch F1: 0.0
Epoch:  682       10 Batch loss: 0.219927 Batch F1: 0.0
Epoch:  682       11 Batch loss: 0.212155 Batch F1: 0.0
Epoch:  682       12 Batch loss: 0.221441 Batch F1: 0.0
Train Avg Loss  682: 0.229161

Train Avg F1  682: 0.0

Val Avg Loss  682: 0.221512

Val Avg F1  682:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 683
--------------------------------------------------------------
Epoch:  683        1 Batch loss: 0.248221 Batch F1: 0.0
Epoch:  683        2 Batch loss: 0.217837 Batch F1: 0.0
Epoch:  683        3 Batch loss: 0.231969 Batch F1: 0.0
Epoch:  683        4 Batch loss: 0.253844 Batch F1: 0.0
Epoch:  683        5 Batch loss: 0.217243 Batch F1: 0.1111111111111111
Epoch:  683        6 Batch loss: 0.205550 Batch F1: 0.0
Epoch:  683        7 Batch loss: 0.235126 Batch F1: 0.0
Epoch:  683        8 Batch loss: 0.241008 Batch F1: 0.0
Epoch:  683        9 Batch loss: 0.204655 Batch F1: 0.11111111111111112
Epoch:  683       10 Batch loss: 0.243674 Batch F1: 0.25
Epoch:  683       11 Batch loss: 0.218552 Batch F1: 0.1
Epoch:  683       12 Batch loss: 0.200475 Batch F1: 0.0
Train Avg Loss  683: 0.226513

Train Avg F1  683: 0.047685185185185185

Val Avg Loss  683: 0.219281

Val Avg F1  683:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 684
--------------------------------------------------------------
Epoch:  684        1 Batch loss: 0.206521 Batch F1: 0.0
Epoch:  684        2 Batch loss: 0.240463 Batch F1: 0.0
Epoch:  684        3 Batch loss: 0.227793 Batch F1: 0.0
Epoch:  684        4 Batch loss: 0.250876 Batch F1: 0.07692307692307693
Epoch:  684        5 Batch loss: 0.203353 Batch F1: 0.3157894736842105
Epoch:  684        6 Batch loss: 0.243504 Batch F1: 0.29629629629629634
Epoch:  684        7 Batch loss: 0.253142 Batch F1: 0.24
Epoch:  684        8 Batch loss: 0.236382 Batch F1: 0.0
Epoch:  684        9 Batch loss: 0.214562 Batch F1: 0.0
Epoch:  684       10 Batch loss: 0.205687 Batch F1: 0.0
Epoch:  684       11 Batch loss: 0.211269 Batch F1: 0.0
Epoch:  684       12 Batch loss: 0.223483 Batch F1: 0.0
Train Avg Loss  684: 0.226419

Train Avg F1  684: 0.07741740390863198

Val Avg Loss  684: 0.219707

Val Avg F1  684:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 685
--------------------------------------------------------------
Epoch:  685        1 Batch loss: 0.203458 Batch F1: 0.0
Epoch:  685        2 Batch loss: 0.241479 Batch F1: 0.0
Epoch:  685        3 Batch loss: 0.196258 Batch F1: 0.0
Epoch:  685        4 Batch loss: 0.226752 Batch F1: 0.0
Epoch:  685        5 Batch loss: 0.204827 Batch F1: 0.23529411764705882
Epoch:  685        6 Batch loss: 0.257394 Batch F1: 0.0
Epoch:  685        7 Batch loss: 0.232874 Batch F1: 0.3636363636363636
Epoch:  685        8 Batch loss: 0.209473 Batch F1: 0.5714285714285715
Epoch:  685        9 Batch loss: 0.219188 Batch F1: 0.3703703703703704
Epoch:  685       10 Batch loss: 0.252250 Batch F1: 0.24999999999999997
Epoch:  685       11 Batch loss: 0.219466 Batch F1: 0.19047619047619047
Epoch:  685       12 Batch loss: 0.255366 Batch F1: 0.0
Train Avg Loss  685: 0.226565

Train Avg F1  685: 0.16510046779654622

Val Avg Loss  685: 0.218178

Val Avg F1  685:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 686
--------------------------------------------------------------
Epoch:  686        1 Batch loss: 0.211912 Batch F1: 0.0
Epoch:  686        2 Batch loss: 0.243423 Batch F1: 0.0
Epoch:  686        3 Batch loss: 0.222480 Batch F1: 0.0
Epoch:  686        4 Batch loss: 0.229521 Batch F1: 0.0
Epoch:  686        5 Batch loss: 0.259020 Batch F1: 0.0
Epoch:  686        6 Batch loss: 0.251779 Batch F1: 0.0
Epoch:  686        7 Batch loss: 0.223056 Batch F1: 0.0
Epoch:  686        8 Batch loss: 0.227513 Batch F1: 0.41379310344827586
Epoch:  686        9 Batch loss: 0.233584 Batch F1: 0.3571428571428571
Epoch:  686       10 Batch loss: 0.214187 Batch F1: 0.25000000000000006
Epoch:  686       11 Batch loss: 0.200635 Batch F1: 0.0
Epoch:  686       12 Batch loss: 0.215961 Batch F1: 0.0
Train Avg Loss  686: 0.227756

Train Avg F1  686: 0.08507799671592775

Val Avg Loss  686: 0.218238

Val Avg F1  686:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 687
--------------------------------------------------------------
Epoch:  687        1 Batch loss: 0.223988 Batch F1: 0.0
Epoch:  687        2 Batch loss: 0.229088 Batch F1: 0.0
Epoch:  687        3 Batch loss: 0.221806 Batch F1: 0.0
Epoch:  687        4 Batch loss: 0.238691 Batch F1: 0.0
Epoch:  687        5 Batch loss: 0.209402 Batch F1: 0.0
Epoch:  687        6 Batch loss: 0.240207 Batch F1: 0.0
Epoch:  687        7 Batch loss: 0.242253 Batch F1: 0.0
Epoch:  687        8 Batch loss: 0.227361 Batch F1: 0.0
Epoch:  687        9 Batch loss: 0.200319 Batch F1: 0.0
Epoch:  687       10 Batch loss: 0.222292 Batch F1: 0.0
Epoch:  687       11 Batch loss: 0.235062 Batch F1: 0.0
Epoch:  687       12 Batch loss: 0.232146 Batch F1: 0.25
Train Avg Loss  687: 0.226884

Train Avg F1  687: 0.020833333333333332

Val Avg Loss  687: 0.219606

Val Avg F1  687:  0.263982683982684

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 688
--------------------------------------------------------------
Epoch:  688        1 Batch loss: 0.221743 Batch F1: 0.2857142857142857
Epoch:  688        2 Batch loss: 0.241145 Batch F1: 0.0
Epoch:  688        3 Batch loss: 0.239482 Batch F1: 0.0
Epoch:  688        4 Batch loss: 0.216498 Batch F1: 0.1904761904761905
Epoch:  688        5 Batch loss: 0.218584 Batch F1: 0.2
Epoch:  688        6 Batch loss: 0.214462 Batch F1: 0.2727272727272727
Epoch:  688        7 Batch loss: 0.201439 Batch F1: 0.23529411764705882
Epoch:  688        8 Batch loss: 0.205370 Batch F1: 0.0
Epoch:  688        9 Batch loss: 0.256892 Batch F1: 0.0
Epoch:  688       10 Batch loss: 0.251025 Batch F1: 0.0
Epoch:  688       11 Batch loss: 0.231704 Batch F1: 0.0
Epoch:  688       12 Batch loss: 0.202922 Batch F1: 0.33333333333333337
Train Avg Loss  688: 0.225106

Train Avg F1  688: 0.12646209999151178

Val Avg Loss  688: 0.221740

Val Avg F1  688:  0.25024464263594703

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 689
--------------------------------------------------------------
Epoch:  689        1 Batch loss: 0.213439 Batch F1: 0.35714285714285715
Epoch:  689        2 Batch loss: 0.244252 Batch F1: 0.30303030303030304
Epoch:  689        3 Batch loss: 0.216761 Batch F1: 0.5384615384615385
Epoch:  689        4 Batch loss: 0.228460 Batch F1: 0.48275862068965514
Epoch:  689        5 Batch loss: 0.233736 Batch F1: 0.5
Epoch:  689        6 Batch loss: 0.198124 Batch F1: 0.42105263157894735
Epoch:  689        7 Batch loss: 0.221461 Batch F1: 0.30769230769230765
Epoch:  689        8 Batch loss: 0.229025 Batch F1: 0.4827586206896552
Epoch:  689        9 Batch loss: 0.210197 Batch F1: 0.1111111111111111
Epoch:  689       10 Batch loss: 0.213842 Batch F1: 0.2857142857142857
Epoch:  689       11 Batch loss: 0.223981 Batch F1: 0.1739130434782609
Epoch:  689       12 Batch loss: 0.238719 Batch F1: 0.0
Train Avg Loss  689: 0.222666

Train Avg F1  689: 0.3303029432990768

Val Avg Loss  689: 0.217367

Val Avg F1  689:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 690
--------------------------------------------------------------
Epoch:  690        1 Batch loss: 0.211207 Batch F1: 0.0
Epoch:  690        2 Batch loss: 0.221764 Batch F1: 0.0
Epoch:  690        3 Batch loss: 0.210423 Batch F1: 0.0
Epoch:  690        4 Batch loss: 0.213095 Batch F1: 0.0
Epoch:  690        5 Batch loss: 0.204201 Batch F1: 0.0
Epoch:  690        6 Batch loss: 0.250533 Batch F1: 0.0
Epoch:  690        7 Batch loss: 0.191153 Batch F1: 0.0
Epoch:  690        8 Batch loss: 0.274532 Batch F1: 0.0
Epoch:  690        9 Batch loss: 0.230296 Batch F1: 0.1818181818181818
Epoch:  690       10 Batch loss: 0.209279 Batch F1: 0.3636363636363636
Epoch:  690       11 Batch loss: 0.205235 Batch F1: 0.3333333333333333
Epoch:  690       12 Batch loss: 0.265079 Batch F1: 0.2857142857142857
Train Avg Loss  690: 0.223900

Train Avg F1  690: 0.09704184704184704

Val Avg Loss  690: 0.221120

Val Avg F1  690:  0.32522821381517036

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 691
--------------------------------------------------------------
Epoch:  691        1 Batch loss: 0.251555 Batch F1: 0.08
Epoch:  691        2 Batch loss: 0.238609 Batch F1: 0.3448275862068965
Epoch:  691        3 Batch loss: 0.205271 Batch F1: 0.19047619047619047
Epoch:  691        4 Batch loss: 0.224617 Batch F1: 0.41379310344827586
Epoch:  691        5 Batch loss: 0.205182 Batch F1: 0.27272727272727276
Epoch:  691        6 Batch loss: 0.213439 Batch F1: 0.30769230769230765
Epoch:  691        7 Batch loss: 0.214551 Batch F1: 0.22222222222222224
Epoch:  691        8 Batch loss: 0.231965 Batch F1: 0.42857142857142855
Epoch:  691        9 Batch loss: 0.208856 Batch F1: 0.44444444444444436
Epoch:  691       10 Batch loss: 0.229155 Batch F1: 0.4666666666666666
Epoch:  691       11 Batch loss: 0.221932 Batch F1: 0.0
Epoch:  691       12 Batch loss: 0.225263 Batch F1: 0.36363636363636365
Train Avg Loss  691: 0.222533

Train Avg F1  691: 0.29458813217433905

Val Avg Loss  691: 0.218907

Val Avg F1  691:  0.2550925925925926

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 692
--------------------------------------------------------------
Epoch:  692        1 Batch loss: 0.205681 Batch F1: 0.28571428571428575
Epoch:  692        2 Batch loss: 0.227226 Batch F1: 0.4285714285714285
Epoch:  692        3 Batch loss: 0.226316 Batch F1: 0.17391304347826086
Epoch:  692        4 Batch loss: 0.218325 Batch F1: 0.28571428571428575
Epoch:  692        5 Batch loss: 0.224172 Batch F1: 0.2608695652173913
Epoch:  692        6 Batch loss: 0.217021 Batch F1: 0.4347826086956522
Epoch:  692        7 Batch loss: 0.221689 Batch F1: 0.3846153846153846
Epoch:  692        8 Batch loss: 0.188043 Batch F1: 0.5714285714285714
Epoch:  692        9 Batch loss: 0.240419 Batch F1: 0.23076923076923075
Epoch:  692       10 Batch loss: 0.242305 Batch F1: 0.0909090909090909
Epoch:  692       11 Batch loss: 0.227123 Batch F1: 0.37037037037037035
Epoch:  692       12 Batch loss: 0.232380 Batch F1: 0.4
Train Avg Loss  692: 0.222558

Train Avg F1  692: 0.32647148879032933

Val Avg Loss  692: 0.221503

Val Avg F1  692:  0.31400281640556243

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 693
--------------------------------------------------------------
Epoch:  693        1 Batch loss: 0.231053 Batch F1: 0.47058823529411764
Epoch:  693        2 Batch loss: 0.183575 Batch F1: 0.4999999999999999
Epoch:  693        3 Batch loss: 0.230199 Batch F1: 0.3703703703703704
Epoch:  693        4 Batch loss: 0.201562 Batch F1: 0.3
Epoch:  693        5 Batch loss: 0.251538 Batch F1: 0.24000000000000002
Epoch:  693        6 Batch loss: 0.265180 Batch F1: 0.23076923076923073
Epoch:  693        7 Batch loss: 0.176747 Batch F1: 0.14285714285714288
Epoch:  693        8 Batch loss: 0.234239 Batch F1: 0.08695652173913045
Epoch:  693        9 Batch loss: 0.238197 Batch F1: 0.1818181818181818
Epoch:  693       10 Batch loss: 0.209291 Batch F1: 0.32000000000000006
Epoch:  693       11 Batch loss: 0.233229 Batch F1: 0.2608695652173913
Epoch:  693       12 Batch loss: 0.216961 Batch F1: 0.2857142857142857
Train Avg Loss  693: 0.222648

Train Avg F1  693: 0.2824952944816542

Val Avg Loss  693: 0.219633

Val Avg F1  693:  0.25177600177600173

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 694
--------------------------------------------------------------
Epoch:  694        1 Batch loss: 0.220002 Batch F1: 0.1
Epoch:  694        2 Batch loss: 0.215647 Batch F1: 0.37037037037037035
Epoch:  694        3 Batch loss: 0.213396 Batch F1: 0.5625000000000001
Epoch:  694        4 Batch loss: 0.222587 Batch F1: 0.41379310344827586
Epoch:  694        5 Batch loss: 0.266549 Batch F1: 0.3529411764705882
Epoch:  694        6 Batch loss: 0.227508 Batch F1: 0.18181818181818182
Epoch:  694        7 Batch loss: 0.244420 Batch F1: 0.4516129032258065
Epoch:  694        8 Batch loss: 0.208095 Batch F1: 0.48
Epoch:  694        9 Batch loss: 0.207984 Batch F1: 0.39999999999999997
Epoch:  694       10 Batch loss: 0.234074 Batch F1: 0.4516129032258065
Epoch:  694       11 Batch loss: 0.189163 Batch F1: 0.64
Epoch:  694       12 Batch loss: 0.214489 Batch F1: 0.13333333333333336
Train Avg Loss  694: 0.221993

Train Avg F1  694: 0.3781651643243636

Val Avg Loss  694: 0.217643

Val Avg F1  694:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 695
--------------------------------------------------------------
Epoch:  695        1 Batch loss: 0.232831 Batch F1: 0.09090909090909091
Epoch:  695        2 Batch loss: 0.206385 Batch F1: 0.0
Epoch:  695        3 Batch loss: 0.175032 Batch F1: 0.0
Epoch:  695        4 Batch loss: 0.227317 Batch F1: 0.0
Epoch:  695        5 Batch loss: 0.221305 Batch F1: 0.0
Epoch:  695        6 Batch loss: 0.281050 Batch F1: 0.0
Epoch:  695        7 Batch loss: 0.231386 Batch F1: 0.0
Epoch:  695        8 Batch loss: 0.222158 Batch F1: 0.25
Epoch:  695        9 Batch loss: 0.226782 Batch F1: 0.18181818181818182
Epoch:  695       10 Batch loss: 0.227155 Batch F1: 0.37499999999999994
Epoch:  695       11 Batch loss: 0.227147 Batch F1: 0.3076923076923077
Epoch:  695       12 Batch loss: 0.212367 Batch F1: 0.125
Train Avg Loss  695: 0.224243

Train Avg F1  695: 0.11086829836829837

Val Avg Loss  695: 0.220533

Val Avg F1  695:  0.24126774996340217

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 696
--------------------------------------------------------------
Epoch:  696        1 Batch loss: 0.208553 Batch F1: 0.2857142857142857
Epoch:  696        2 Batch loss: 0.197469 Batch F1: 0.3478260869565218
Epoch:  696        3 Batch loss: 0.230413 Batch F1: 0.45161290322580644
Epoch:  696        4 Batch loss: 0.240241 Batch F1: 0.16666666666666669
Epoch:  696        5 Batch loss: 0.230063 Batch F1: 0.36363636363636365
Epoch:  696        6 Batch loss: 0.212729 Batch F1: 0.2727272727272727
Epoch:  696        7 Batch loss: 0.229852 Batch F1: 0.32
Epoch:  696        8 Batch loss: 0.227963 Batch F1: 0.3703703703703703
Epoch:  696        9 Batch loss: 0.234636 Batch F1: 0.16666666666666666
Epoch:  696       10 Batch loss: 0.250891 Batch F1: 0.39999999999999997
Epoch:  696       11 Batch loss: 0.201200 Batch F1: 0.21052631578947367
Epoch:  696       12 Batch loss: 0.203781 Batch F1: 0.39999999999999997
Train Avg Loss  696: 0.222316

Train Avg F1  696: 0.31297891097945224

Val Avg Loss  696: 0.218647

Val Avg F1  696:  0.24387045416457181

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 697
--------------------------------------------------------------
Epoch:  697        1 Batch loss: 0.203032 Batch F1: 0.2
Epoch:  697        2 Batch loss: 0.205121 Batch F1: 0.11111111111111112
Epoch:  697        3 Batch loss: 0.200033 Batch F1: 0.125
Epoch:  697        4 Batch loss: 0.243128 Batch F1: 0.0
Epoch:  697        5 Batch loss: 0.213543 Batch F1: 0.0
Epoch:  697        6 Batch loss: 0.262531 Batch F1: 0.0
Epoch:  697        7 Batch loss: 0.193527 Batch F1: 0.0
Epoch:  697        8 Batch loss: 0.217585 Batch F1: 0.0
Epoch:  697        9 Batch loss: 0.240894 Batch F1: 0.1739130434782609
Epoch:  697       10 Batch loss: 0.229753 Batch F1: 0.24
Epoch:  697       11 Batch loss: 0.260081 Batch F1: 0.2962962962962963
Epoch:  697       12 Batch loss: 0.205447 Batch F1: 0.5384615384615385
Train Avg Loss  697: 0.222890

Train Avg F1  697: 0.14039849911226723

Val Avg Loss  697: 0.219333

Val Avg F1  697:  0.2565993788819876

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 698
--------------------------------------------------------------
Epoch:  698        1 Batch loss: 0.217210 Batch F1: 0.2
Epoch:  698        2 Batch loss: 0.216609 Batch F1: 0.4166666666666667
Epoch:  698        3 Batch loss: 0.218049 Batch F1: 0.3478260869565218
Epoch:  698        4 Batch loss: 0.198283 Batch F1: 0.3636363636363636
Epoch:  698        5 Batch loss: 0.226947 Batch F1: 0.17391304347826086
Epoch:  698        6 Batch loss: 0.208242 Batch F1: 0.0
Epoch:  698        7 Batch loss: 0.216721 Batch F1: 0.0
Epoch:  698        8 Batch loss: 0.229055 Batch F1: 0.0
Epoch:  698        9 Batch loss: 0.216911 Batch F1: 0.30769230769230765
Epoch:  698       10 Batch loss: 0.259073 Batch F1: 0.3225806451612903
Epoch:  698       11 Batch loss: 0.230121 Batch F1: 0.16666666666666666
Epoch:  698       12 Batch loss: 0.234719 Batch F1: 0.5454545454545455
Train Avg Loss  698: 0.222662

Train Avg F1  698: 0.2370363604760519

Val Avg Loss  698: 0.222790

Val Avg F1  698:  0.3315609122060735

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 699
--------------------------------------------------------------
Epoch:  699        1 Batch loss: 0.203331 Batch F1: 0.4545454545454546
Epoch:  699        2 Batch loss: 0.235306 Batch F1: 0.30769230769230765
Epoch:  699        3 Batch loss: 0.216971 Batch F1: 0.28571428571428575
Epoch:  699        4 Batch loss: 0.198175 Batch F1: 0.4166666666666667
Epoch:  699        5 Batch loss: 0.226325 Batch F1: 0.1904761904761905
Epoch:  699        6 Batch loss: 0.203073 Batch F1: 0.38095238095238093
Epoch:  699        7 Batch loss: 0.262836 Batch F1: 0.07999999999999999
Epoch:  699        8 Batch loss: 0.259042 Batch F1: 0.375
Epoch:  699        9 Batch loss: 0.203870 Batch F1: 0.4
Epoch:  699       10 Batch loss: 0.212639 Batch F1: 0.3
Epoch:  699       11 Batch loss: 0.212542 Batch F1: 0.3333333333333333
Epoch:  699       12 Batch loss: 0.245705 Batch F1: 0.25
Train Avg Loss  699: 0.223318

Train Avg F1  699: 0.3145317182817183

Val Avg Loss  699: 0.219776

Val Avg F1  699:  0.2550962523788611

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 700
--------------------------------------------------------------
Epoch:  700        1 Batch loss: 0.209524 Batch F1: 0.3846153846153846
Epoch:  700        2 Batch loss: 0.238148 Batch F1: 0.32
Epoch:  700        3 Batch loss: 0.200915 Batch F1: 0.39999999999999997
Epoch:  700        4 Batch loss: 0.236899 Batch F1: 0.15384615384615383
Epoch:  700        5 Batch loss: 0.194675 Batch F1: 0.38095238095238093
Epoch:  700        6 Batch loss: 0.196022 Batch F1: 0.2857142857142857
Epoch:  700        7 Batch loss: 0.198685 Batch F1: 0.4166666666666667
Epoch:  700        8 Batch loss: 0.226848 Batch F1: 0.2608695652173913
Epoch:  700        9 Batch loss: 0.249904 Batch F1: 0.23076923076923075
Epoch:  700       10 Batch loss: 0.222256 Batch F1: 0.32
Epoch:  700       11 Batch loss: 0.262629 Batch F1: 0.22222222222222218
Epoch:  700       12 Batch loss: 0.229729 Batch F1: 0.45454545454545453
Train Avg Loss  700: 0.222186

Train Avg F1  700: 0.31918344537909754

Val Avg Loss  700: 0.218817

Val Avg F1  700:  0.24196068632350493

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 701
--------------------------------------------------------------
Epoch:  701        1 Batch loss: 0.233931 Batch F1: 0.22222222222222224
Epoch:  701        2 Batch loss: 0.219532 Batch F1: 0.3703703703703704
Epoch:  701        3 Batch loss: 0.214203 Batch F1: 0.5161290322580645
Epoch:  701        4 Batch loss: 0.237789 Batch F1: 0.4444444444444444
Epoch:  701        5 Batch loss: 0.226175 Batch F1: 0.48275862068965514
Epoch:  701        6 Batch loss: 0.215075 Batch F1: 0.46153846153846156
Epoch:  701        7 Batch loss: 0.242352 Batch F1: 0.39999999999999997
Epoch:  701        8 Batch loss: 0.230106 Batch F1: 0.2608695652173913
Epoch:  701        9 Batch loss: 0.209403 Batch F1: 0.4
Epoch:  701       10 Batch loss: 0.203163 Batch F1: 0.0
Epoch:  701       11 Batch loss: 0.225334 Batch F1: 0.0
Epoch:  701       12 Batch loss: 0.217534 Batch F1: 0.0
Train Avg Loss  701: 0.222883

Train Avg F1  701: 0.29652772639505076

Val Avg Loss  701: 0.218249

Val Avg F1  701:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 702
--------------------------------------------------------------
Epoch:  702        1 Batch loss: 0.230407 Batch F1: 0.0
Epoch:  702        2 Batch loss: 0.248766 Batch F1: 0.0
Epoch:  702        3 Batch loss: 0.204752 Batch F1: 0.0
Epoch:  702        4 Batch loss: 0.209017 Batch F1: 0.0
Epoch:  702        5 Batch loss: 0.194160 Batch F1: 0.0
Epoch:  702        6 Batch loss: 0.230158 Batch F1: 0.0
Epoch:  702        7 Batch loss: 0.244837 Batch F1: 0.0
Epoch:  702        8 Batch loss: 0.230340 Batch F1: 0.0
Epoch:  702        9 Batch loss: 0.210736 Batch F1: 0.0
Epoch:  702       10 Batch loss: 0.252134 Batch F1: 0.0
Epoch:  702       11 Batch loss: 0.237063 Batch F1: 0.41379310344827586
Epoch:  702       12 Batch loss: 0.218112 Batch F1: 0.4761904761904762
Train Avg Loss  702: 0.225874

Train Avg F1  702: 0.07416529830322934

Val Avg Loss  702: 0.222807

Val Avg F1  702:  0.24073260073260072

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 703
--------------------------------------------------------------
Epoch:  703        1 Batch loss: 0.220555 Batch F1: 0.3846153846153846
Epoch:  703        2 Batch loss: 0.215490 Batch F1: 0.39999999999999997
Epoch:  703        3 Batch loss: 0.260361 Batch F1: 0.16
Epoch:  703        4 Batch loss: 0.193716 Batch F1: 0.45454545454545453
Epoch:  703        5 Batch loss: 0.198305 Batch F1: 0.0
Epoch:  703        6 Batch loss: 0.246878 Batch F1: 0.1
Epoch:  703        7 Batch loss: 0.229044 Batch F1: 0.0
Epoch:  703        8 Batch loss: 0.234343 Batch F1: 0.0
Epoch:  703        9 Batch loss: 0.203778 Batch F1: 0.11764705882352941
Epoch:  703       10 Batch loss: 0.257692 Batch F1: 0.0
Epoch:  703       11 Batch loss: 0.201471 Batch F1: 0.5185185185185185
Epoch:  703       12 Batch loss: 0.225175 Batch F1: 0.10526315789473684
Train Avg Loss  703: 0.223901

Train Avg F1  703: 0.18671579786646864

Val Avg Loss  703: 0.220096

Val Avg F1  703:  0.24433637881913745

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 704
--------------------------------------------------------------
Epoch:  704        1 Batch loss: 0.229276 Batch F1: 0.3478260869565218
Epoch:  704        2 Batch loss: 0.211105 Batch F1: 0.5384615384615384
Epoch:  704        3 Batch loss: 0.229662 Batch F1: 0.3333333333333333
Epoch:  704        4 Batch loss: 0.221612 Batch F1: 0.42857142857142855
Epoch:  704        5 Batch loss: 0.228383 Batch F1: 0.2222222222222222
Epoch:  704        6 Batch loss: 0.204863 Batch F1: 0.33333333333333337
Epoch:  704        7 Batch loss: 0.196078 Batch F1: 0.28571428571428575
Epoch:  704        8 Batch loss: 0.178872 Batch F1: 0.0
Epoch:  704        9 Batch loss: 0.252381 Batch F1: 0.0
Epoch:  704       10 Batch loss: 0.252256 Batch F1: 0.0
Epoch:  704       11 Batch loss: 0.228152 Batch F1: 0.0
Epoch:  704       12 Batch loss: 0.252102 Batch F1: 0.0
Train Avg Loss  704: 0.223728

Train Avg F1  704: 0.20745518571605528

Val Avg Loss  704: 0.218745

Val Avg F1  704:  0.075

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 705
--------------------------------------------------------------
Epoch:  705        1 Batch loss: 0.233831 Batch F1: 0.2608695652173913
Epoch:  705        2 Batch loss: 0.255610 Batch F1: 0.16
Epoch:  705        3 Batch loss: 0.200713 Batch F1: 0.0
Epoch:  705        4 Batch loss: 0.222053 Batch F1: 0.3846153846153846
Epoch:  705        5 Batch loss: 0.214198 Batch F1: 0.2608695652173913
Epoch:  705        6 Batch loss: 0.213922 Batch F1: 0.4
Epoch:  705        7 Batch loss: 0.174445 Batch F1: 0.3157894736842105
Epoch:  705        8 Batch loss: 0.215971 Batch F1: 0.24
Epoch:  705        9 Batch loss: 0.204044 Batch F1: 0.4
Epoch:  705       10 Batch loss: 0.247557 Batch F1: 0.30769230769230765
Epoch:  705       11 Batch loss: 0.245362 Batch F1: 0.4
Epoch:  705       12 Batch loss: 0.247478 Batch F1: 0.08695652173913042
Train Avg Loss  705: 0.222932

Train Avg F1  705: 0.2680660681804846

Val Avg Loss  705: 0.218265

Val Avg F1  705:  0.24698975700119866

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 706
--------------------------------------------------------------
Epoch:  706        1 Batch loss: 0.226067 Batch F1: 0.37037037037037035
Epoch:  706        2 Batch loss: 0.228312 Batch F1: 0.44444444444444436
Epoch:  706        3 Batch loss: 0.265380 Batch F1: 0.13333333333333333
Epoch:  706        4 Batch loss: 0.203798 Batch F1: 0.5625
Epoch:  706        5 Batch loss: 0.181577 Batch F1: 0.5217391304347827
Epoch:  706        6 Batch loss: 0.239192 Batch F1: 0.5142857142857143
Epoch:  706        7 Batch loss: 0.208941 Batch F1: 0.4166666666666667
Epoch:  706        8 Batch loss: 0.275248 Batch F1: 0.0
Epoch:  706        9 Batch loss: 0.217071 Batch F1: 0.30769230769230765
Epoch:  706       10 Batch loss: 0.206491 Batch F1: 0.1111111111111111
Epoch:  706       11 Batch loss: 0.194658 Batch F1: 0.0
Epoch:  706       12 Batch loss: 0.232709 Batch F1: 0.0
Train Avg Loss  706: 0.223287

Train Avg F1  706: 0.2818452565282275

Val Avg Loss  706: 0.218281

Val Avg F1  706:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 707
--------------------------------------------------------------
Epoch:  707        1 Batch loss: 0.236345 Batch F1: 0.0
Epoch:  707        2 Batch loss: 0.260289 Batch F1: 0.0
Epoch:  707        3 Batch loss: 0.188188 Batch F1: 0.0
Epoch:  707        4 Batch loss: 0.178488 Batch F1: 0.0
Epoch:  707        5 Batch loss: 0.239283 Batch F1: 0.0
Epoch:  707        6 Batch loss: 0.241182 Batch F1: 0.0
Epoch:  707        7 Batch loss: 0.214377 Batch F1: 0.0
Epoch:  707        8 Batch loss: 0.211765 Batch F1: 0.0
Epoch:  707        9 Batch loss: 0.228874 Batch F1: 0.0
Epoch:  707       10 Batch loss: 0.267701 Batch F1: 0.0
Epoch:  707       11 Batch loss: 0.207656 Batch F1: 0.21052631578947367
Epoch:  707       12 Batch loss: 0.226012 Batch F1: 0.4444444444444444
Train Avg Loss  707: 0.225013

Train Avg F1  707: 0.05458089668615984

Val Avg Loss  707: 0.219109

Val Avg F1  707:  0.24404761904761904

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 708
--------------------------------------------------------------
Epoch:  708        1 Batch loss: 0.260849 Batch F1: 0.18181818181818182
Epoch:  708        2 Batch loss: 0.184266 Batch F1: 0.42105263157894735
Epoch:  708        3 Batch loss: 0.195779 Batch F1: 0.2857142857142857
Epoch:  708        4 Batch loss: 0.222861 Batch F1: 0.5333333333333333
Epoch:  708        5 Batch loss: 0.236592 Batch F1: 0.27272727272727276
Epoch:  708        6 Batch loss: 0.199801 Batch F1: 0.2727272727272727
Epoch:  708        7 Batch loss: 0.235144 Batch F1: 0.2
Epoch:  708        8 Batch loss: 0.228440 Batch F1: 0.16666666666666666
Epoch:  708        9 Batch loss: 0.221061 Batch F1: 0.29629629629629634
Epoch:  708       10 Batch loss: 0.224859 Batch F1: 0.2608695652173913
Epoch:  708       11 Batch loss: 0.248314 Batch F1: 0.23076923076923075
Epoch:  708       12 Batch loss: 0.215371 Batch F1: 0.2222222222222222
Train Avg Loss  708: 0.222778

Train Avg F1  708: 0.2786830799225917

Val Avg Loss  708: 0.222191

Val Avg F1  708:  0.3146398061966085

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 709
--------------------------------------------------------------
Epoch:  709        1 Batch loss: 0.213638 Batch F1: 0.37037037037037035
Epoch:  709        2 Batch loss: 0.240419 Batch F1: 0.4242424242424242
Epoch:  709        3 Batch loss: 0.229691 Batch F1: 0.4705882352941177
Epoch:  709        4 Batch loss: 0.218061 Batch F1: 0.3636363636363636
Epoch:  709        5 Batch loss: 0.228973 Batch F1: 0.0
Epoch:  709        6 Batch loss: 0.211683 Batch F1: 0.3333333333333333
Epoch:  709        7 Batch loss: 0.234815 Batch F1: 0.29629629629629634
Epoch:  709        8 Batch loss: 0.223689 Batch F1: 0.25
Epoch:  709        9 Batch loss: 0.224295 Batch F1: 0.4615384615384615
Epoch:  709       10 Batch loss: 0.234848 Batch F1: 0.2608695652173913
Epoch:  709       11 Batch loss: 0.208619 Batch F1: 0.25
Epoch:  709       12 Batch loss: 0.212142 Batch F1: 0.0
Train Avg Loss  709: 0.223406

Train Avg F1  709: 0.2900729208273965

Val Avg Loss  709: 0.217091

Val Avg F1  709:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 710
--------------------------------------------------------------
Epoch:  710        1 Batch loss: 0.214235 Batch F1: 0.0
Epoch:  710        2 Batch loss: 0.190295 Batch F1: 0.0
Epoch:  710        3 Batch loss: 0.206409 Batch F1: 0.0
Epoch:  710        4 Batch loss: 0.229917 Batch F1: 0.0
Epoch:  710        5 Batch loss: 0.227133 Batch F1: 0.0
Epoch:  710        6 Batch loss: 0.230675 Batch F1: 0.0
Epoch:  710        7 Batch loss: 0.250151 Batch F1: 0.24000000000000002
Epoch:  710        8 Batch loss: 0.226540 Batch F1: 0.35714285714285715
Epoch:  710        9 Batch loss: 0.211424 Batch F1: 0.2
Epoch:  710       10 Batch loss: 0.256998 Batch F1: 0.28571428571428575
Epoch:  710       11 Batch loss: 0.199779 Batch F1: 0.3157894736842105
Epoch:  710       12 Batch loss: 0.251424 Batch F1: 0.3076923076923077
Train Avg Loss  710: 0.224582

Train Avg F1  710: 0.1421949103528051

Val Avg Loss  710: 0.216888

Val Avg F1  710:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 711
--------------------------------------------------------------
Epoch:  711        1 Batch loss: 0.265476 Batch F1: 0.0
Epoch:  711        2 Batch loss: 0.217156 Batch F1: 0.0
Epoch:  711        3 Batch loss: 0.186644 Batch F1: 0.0
Epoch:  711        4 Batch loss: 0.241429 Batch F1: 0.0
Epoch:  711        5 Batch loss: 0.229573 Batch F1: 0.0
Epoch:  711        6 Batch loss: 0.207905 Batch F1: 0.0
Epoch:  711        7 Batch loss: 0.223881 Batch F1: 0.0
Epoch:  711        8 Batch loss: 0.258122 Batch F1: 0.0
Epoch:  711        9 Batch loss: 0.229559 Batch F1: 0.10526315789473684
Epoch:  711       10 Batch loss: 0.208960 Batch F1: 0.3846153846153846
Epoch:  711       11 Batch loss: 0.240040 Batch F1: 0.33333333333333337
Epoch:  711       12 Batch loss: 0.197644 Batch F1: 0.47058823529411764
Train Avg Loss  711: 0.225532

Train Avg F1  711: 0.10781667592813104

Val Avg Loss  711: 0.218908

Val Avg F1  711:  0.0988235294117647

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 712
--------------------------------------------------------------
Epoch:  712        1 Batch loss: 0.221389 Batch F1: 0.1904761904761905
Epoch:  712        2 Batch loss: 0.221608 Batch F1: 0.0
Epoch:  712        3 Batch loss: 0.208100 Batch F1: 0.2857142857142857
Epoch:  712        4 Batch loss: 0.242843 Batch F1: 0.23076923076923075
Epoch:  712        5 Batch loss: 0.217039 Batch F1: 0.25
Epoch:  712        6 Batch loss: 0.281177 Batch F1: 0.07142857142857142
Epoch:  712        7 Batch loss: 0.205834 Batch F1: 0.4
Epoch:  712        8 Batch loss: 0.208925 Batch F1: 0.5
Epoch:  712        9 Batch loss: 0.226311 Batch F1: 0.25
Epoch:  712       10 Batch loss: 0.209994 Batch F1: 0.28571428571428575
Epoch:  712       11 Batch loss: 0.238136 Batch F1: 0.0
Epoch:  712       12 Batch loss: 0.201975 Batch F1: 0.0
Train Avg Loss  712: 0.223611

Train Avg F1  712: 0.2053418803418803

Val Avg Loss  712: 0.217660

Val Avg F1  712:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 713
--------------------------------------------------------------
Epoch:  713        1 Batch loss: 0.233027 Batch F1: 0.0
Epoch:  713        2 Batch loss: 0.199318 Batch F1: 0.10526315789473684
Epoch:  713        3 Batch loss: 0.194897 Batch F1: 0.0
Epoch:  713        4 Batch loss: 0.234019 Batch F1: 0.0
Epoch:  713        5 Batch loss: 0.243992 Batch F1: 0.0
Epoch:  713        6 Batch loss: 0.213435 Batch F1: 0.43478260869565216
Epoch:  713        7 Batch loss: 0.259824 Batch F1: 0.15384615384615385
Epoch:  713        8 Batch loss: 0.189698 Batch F1: 0.28571428571428575
Epoch:  713        9 Batch loss: 0.255599 Batch F1: 0.25
Epoch:  713       10 Batch loss: 0.204204 Batch F1: 0.2222222222222222
Epoch:  713       11 Batch loss: 0.214777 Batch F1: 0.0
Epoch:  713       12 Batch loss: 0.244638 Batch F1: 0.0
Train Avg Loss  713: 0.223952

Train Avg F1  713: 0.1209857023644209

Val Avg Loss  713: 0.218180

Val Avg F1  713:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 714
--------------------------------------------------------------
Epoch:  714        1 Batch loss: 0.210831 Batch F1: 0.0
Epoch:  714        2 Batch loss: 0.203326 Batch F1: 0.0
Epoch:  714        3 Batch loss: 0.228823 Batch F1: 0.0
Epoch:  714        4 Batch loss: 0.197395 Batch F1: 0.0
Epoch:  714        5 Batch loss: 0.215244 Batch F1: 0.09090909090909091
Epoch:  714        6 Batch loss: 0.210846 Batch F1: 0.5185185185185185
Epoch:  714        7 Batch loss: 0.266858 Batch F1: 0.14814814814814814
Epoch:  714        8 Batch loss: 0.195933 Batch F1: 0.125
Epoch:  714        9 Batch loss: 0.295807 Batch F1: 0.4444444444444445
Epoch:  714       10 Batch loss: 0.223713 Batch F1: 0.30769230769230765
Epoch:  714       11 Batch loss: 0.190250 Batch F1: 0.2727272727272727
Epoch:  714       12 Batch loss: 0.233418 Batch F1: 0.1818181818181818
Train Avg Loss  714: 0.222704

Train Avg F1  714: 0.17410483035483035

Val Avg Loss  714: 0.220646

Val Avg F1  714:  0.24698275862068966

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 715
--------------------------------------------------------------
Epoch:  715        1 Batch loss: 0.203862 Batch F1: 0.5
Epoch:  715        2 Batch loss: 0.223429 Batch F1: 0.25
Epoch:  715        3 Batch loss: 0.240140 Batch F1: 0.1904761904761905
Epoch:  715        4 Batch loss: 0.226833 Batch F1: 0.24
Epoch:  715        5 Batch loss: 0.172628 Batch F1: 0.0
Epoch:  715        6 Batch loss: 0.234133 Batch F1: 0.0
Epoch:  715        7 Batch loss: 0.258509 Batch F1: 0.07142857142857142
Epoch:  715        8 Batch loss: 0.270806 Batch F1: 0.25806451612903225
Epoch:  715        9 Batch loss: 0.197414 Batch F1: 0.2
Epoch:  715       10 Batch loss: 0.233018 Batch F1: 0.35714285714285715
Epoch:  715       11 Batch loss: 0.205153 Batch F1: 0.4347826086956522
Epoch:  715       12 Batch loss: 0.214896 Batch F1: 0.3
Train Avg Loss  715: 0.223402

Train Avg F1  715: 0.23349122865602526

Val Avg Loss  715: 0.220253

Val Avg F1  715:  0.24837412587412588

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 716
--------------------------------------------------------------
Epoch:  716        1 Batch loss: 0.226443 Batch F1: 0.18181818181818182
Epoch:  716        2 Batch loss: 0.178126 Batch F1: 0.5263157894736842
Epoch:  716        3 Batch loss: 0.249049 Batch F1: 0.2580645161290322
Epoch:  716        4 Batch loss: 0.240347 Batch F1: 0.35714285714285715
Epoch:  716        5 Batch loss: 0.228587 Batch F1: 0.0
Epoch:  716        6 Batch loss: 0.204093 Batch F1: 0.0
Epoch:  716        7 Batch loss: 0.182148 Batch F1: 0.0
Epoch:  716        8 Batch loss: 0.235765 Batch F1: 0.0
Epoch:  716        9 Batch loss: 0.231845 Batch F1: 0.0
Epoch:  716       10 Batch loss: 0.240739 Batch F1: 0.0
Epoch:  716       11 Batch loss: 0.227224 Batch F1: 0.08695652173913045
Epoch:  716       12 Batch loss: 0.225314 Batch F1: 0.11764705882352941
Train Avg Loss  716: 0.222473

Train Avg F1  716: 0.1273287437605346

Val Avg Loss  716: 0.220566

Val Avg F1  716:  0.2481527093596059

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 717
--------------------------------------------------------------
Epoch:  717        1 Batch loss: 0.200181 Batch F1: 0.36363636363636365
Epoch:  717        2 Batch loss: 0.236832 Batch F1: 0.3225806451612903
Epoch:  717        3 Batch loss: 0.203208 Batch F1: 0.23529411764705882
Epoch:  717        4 Batch loss: 0.233998 Batch F1: 0.2962962962962963
Epoch:  717        5 Batch loss: 0.216095 Batch F1: 0.41379310344827586
Epoch:  717        6 Batch loss: 0.237756 Batch F1: 0.4285714285714285
Epoch:  717        7 Batch loss: 0.226092 Batch F1: 0.2608695652173913
Epoch:  717        8 Batch loss: 0.217959 Batch F1: 0.30769230769230765
Epoch:  717        9 Batch loss: 0.228304 Batch F1: 0.16
Epoch:  717       10 Batch loss: 0.232407 Batch F1: 0.3448275862068966
Epoch:  717       11 Batch loss: 0.194489 Batch F1: 0.32
Epoch:  717       12 Batch loss: 0.243034 Batch F1: 0.2857142857142857
Train Avg Loss  717: 0.222529

Train Avg F1  717: 0.31160630829929953

Val Avg Loss  717: 0.218314

Val Avg F1  717:  0.2658526256352343

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 718
--------------------------------------------------------------
Epoch:  718        1 Batch loss: 0.198683 Batch F1: 0.0
Epoch:  718        2 Batch loss: 0.231067 Batch F1: 0.09523809523809525
Epoch:  718        3 Batch loss: 0.211339 Batch F1: 0.0
Epoch:  718        4 Batch loss: 0.259633 Batch F1: 0.0
Epoch:  718        5 Batch loss: 0.201076 Batch F1: 0.0
Epoch:  718        6 Batch loss: 0.203206 Batch F1: 0.26086956521739124
Epoch:  718        7 Batch loss: 0.184053 Batch F1: 0.38095238095238093
Epoch:  718        8 Batch loss: 0.247130 Batch F1: 0.3333333333333333
Epoch:  718        9 Batch loss: 0.253101 Batch F1: 0.3076923076923077
Epoch:  718       10 Batch loss: 0.229306 Batch F1: 0.32
Epoch:  718       11 Batch loss: 0.238253 Batch F1: 0.37499999999999994
Epoch:  718       12 Batch loss: 0.215761 Batch F1: 0.4210526315789474
Train Avg Loss  718: 0.222717

Train Avg F1  718: 0.20784485950103795

Val Avg Loss  718: 0.219430

Val Avg F1  718:  0.24855361792787817

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 719
--------------------------------------------------------------
Epoch:  719        1 Batch loss: 0.202524 Batch F1: 0.28571428571428575
Epoch:  719        2 Batch loss: 0.228193 Batch F1: 0.23076923076923075
Epoch:  719        3 Batch loss: 0.208008 Batch F1: 0.4
Epoch:  719        4 Batch loss: 0.228512 Batch F1: 0.42857142857142855
Epoch:  719        5 Batch loss: 0.240546 Batch F1: 0.3333333333333333
Epoch:  719        6 Batch loss: 0.215664 Batch F1: 0.30769230769230765
Epoch:  719        7 Batch loss: 0.262059 Batch F1: 0.26666666666666666
Epoch:  719        8 Batch loss: 0.210464 Batch F1: 0.3478260869565218
Epoch:  719        9 Batch loss: 0.217159 Batch F1: 0.39999999999999997
Epoch:  719       10 Batch loss: 0.216064 Batch F1: 0.5333333333333333
Epoch:  719       11 Batch loss: 0.220366 Batch F1: 0.16666666666666666
Epoch:  719       12 Batch loss: 0.210985 Batch F1: 0.42105263157894735
Train Avg Loss  719: 0.221712

Train Avg F1  719: 0.3434688309402268

Val Avg Loss  719: 0.218977

Val Avg F1  719:  0.2625200886070451

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 720
--------------------------------------------------------------
Epoch:  720        1 Batch loss: 0.200472 Batch F1: 0.36363636363636365
Epoch:  720        2 Batch loss: 0.231704 Batch F1: 0.45161290322580644
Epoch:  720        3 Batch loss: 0.209273 Batch F1: 0.38095238095238093
Epoch:  720        4 Batch loss: 0.186782 Batch F1: 0.125
Epoch:  720        5 Batch loss: 0.271234 Batch F1: 0.0
Epoch:  720        6 Batch loss: 0.238070 Batch F1: 0.0
Epoch:  720        7 Batch loss: 0.204150 Batch F1: 0.5833333333333334
Epoch:  720        8 Batch loss: 0.217189 Batch F1: 0.3333333333333333
Epoch:  720        9 Batch loss: 0.219415 Batch F1: 0.19047619047619047
Epoch:  720       10 Batch loss: 0.193913 Batch F1: 0.13333333333333333
Epoch:  720       11 Batch loss: 0.246155 Batch F1: 0.41379310344827586
Epoch:  720       12 Batch loss: 0.258198 Batch F1: 0.37037037037037035
Train Avg Loss  720: 0.223046

Train Avg F1  720: 0.278820109342449

Val Avg Loss  720: 0.218761

Val Avg F1  720:  0.2716511177609575

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 721
--------------------------------------------------------------
Epoch:  721        1 Batch loss: 0.238968 Batch F1: 0.35714285714285715
Epoch:  721        2 Batch loss: 0.198190 Batch F1: 0.45454545454545453
Epoch:  721        3 Batch loss: 0.235130 Batch F1: 0.25
Epoch:  721        4 Batch loss: 0.213276 Batch F1: 0.23999999999999996
Epoch:  721        5 Batch loss: 0.234412 Batch F1: 0.16666666666666666
Epoch:  721        6 Batch loss: 0.239041 Batch F1: 0.2857142857142857
Epoch:  721        7 Batch loss: 0.220595 Batch F1: 0.29629629629629634
Epoch:  721        8 Batch loss: 0.240587 Batch F1: 0.3225806451612903
Epoch:  721        9 Batch loss: 0.209604 Batch F1: 0.46153846153846156
Epoch:  721       10 Batch loss: 0.227335 Batch F1: 0.23999999999999996
Epoch:  721       11 Batch loss: 0.200829 Batch F1: 0.46153846153846156
Epoch:  721       12 Batch loss: 0.200205 Batch F1: 0.15384615384615385
Train Avg Loss  721: 0.221514

Train Avg F1  721: 0.3074891068708273

Val Avg Loss  721: 0.218993

Val Avg F1  721:  0.25651522390652826

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 722
--------------------------------------------------------------
Epoch:  722        1 Batch loss: 0.219824 Batch F1: 0.5185185185185185
Epoch:  722        2 Batch loss: 0.217333 Batch F1: 0.2857142857142857
Epoch:  722        3 Batch loss: 0.187559 Batch F1: 0.38095238095238093
Epoch:  722        4 Batch loss: 0.230061 Batch F1: 0.16666666666666669
Epoch:  722        5 Batch loss: 0.244124 Batch F1: 0.18181818181818182
Epoch:  722        6 Batch loss: 0.232008 Batch F1: 0.4705882352941177
Epoch:  722        7 Batch loss: 0.228181 Batch F1: 0.5333333333333333
Epoch:  722        8 Batch loss: 0.228904 Batch F1: 0.25
Epoch:  722        9 Batch loss: 0.233323 Batch F1: 0.21428571428571427
Epoch:  722       10 Batch loss: 0.240535 Batch F1: 0.29629629629629634
Epoch:  722       11 Batch loss: 0.201068 Batch F1: 0.2
Epoch:  722       12 Batch loss: 0.209402 Batch F1: 0.2222222222222222
Train Avg Loss  722: 0.222694

Train Avg F1  722: 0.3100329862584765

Val Avg Loss  722: 0.218117

Val Avg F1  722:  0.2510914064622505

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 723
--------------------------------------------------------------
Epoch:  723        1 Batch loss: 0.216028 Batch F1: 0.3076923076923077
Epoch:  723        2 Batch loss: 0.225225 Batch F1: 0.2105263157894737
Epoch:  723        3 Batch loss: 0.230932 Batch F1: 0.09523809523809523
Epoch:  723        4 Batch loss: 0.224237 Batch F1: 0.0
Epoch:  723        5 Batch loss: 0.195262 Batch F1: 0.0
Epoch:  723        6 Batch loss: 0.198712 Batch F1: 0.0
Epoch:  723        7 Batch loss: 0.209498 Batch F1: 0.0
Epoch:  723        8 Batch loss: 0.247139 Batch F1: 0.0
Epoch:  723        9 Batch loss: 0.254716 Batch F1: 0.0
Epoch:  723       10 Batch loss: 0.255899 Batch F1: 0.08333333333333333
Epoch:  723       11 Batch loss: 0.203278 Batch F1: 0.125
Epoch:  723       12 Batch loss: 0.227840 Batch F1: 0.2857142857142857
Train Avg Loss  723: 0.224064

Train Avg F1  723: 0.09229202814729132

Val Avg Loss  723: 0.220673

Val Avg F1  723:  0.2532781228433402

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 724
--------------------------------------------------------------
Epoch:  724        1 Batch loss: 0.226994 Batch F1: 0.3333333333333333
Epoch:  724        2 Batch loss: 0.230816 Batch F1: 0.32
Epoch:  724        3 Batch loss: 0.243566 Batch F1: 0.21428571428571427
Epoch:  724        4 Batch loss: 0.227382 Batch F1: 0.25
Epoch:  724        5 Batch loss: 0.229530 Batch F1: 0.4444444444444444
Epoch:  724        6 Batch loss: 0.217730 Batch F1: 0.29629629629629634
Epoch:  724        7 Batch loss: 0.220054 Batch F1: 0.44444444444444436
Epoch:  724        8 Batch loss: 0.197747 Batch F1: 0.5
Epoch:  724        9 Batch loss: 0.214838 Batch F1: 0.28571428571428575
Epoch:  724       10 Batch loss: 0.204734 Batch F1: 0.09523809523809525
Epoch:  724       11 Batch loss: 0.207852 Batch F1: 0.0
Epoch:  724       12 Batch loss: 0.259367 Batch F1: 0.0
Train Avg Loss  724: 0.223384

Train Avg F1  724: 0.2653130511463845

Val Avg Loss  724: 0.216681

Val Avg F1  724:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 725
--------------------------------------------------------------
Epoch:  725        1 Batch loss: 0.249672 Batch F1: 0.0
Epoch:  725        2 Batch loss: 0.226672 Batch F1: 0.18181818181818182
Epoch:  725        3 Batch loss: 0.225884 Batch F1: 0.5161290322580645
Epoch:  725        4 Batch loss: 0.220602 Batch F1: 0.4
Epoch:  725        5 Batch loss: 0.255716 Batch F1: 0.39999999999999997
Epoch:  725        6 Batch loss: 0.216423 Batch F1: 0.4444444444444444
Epoch:  725        7 Batch loss: 0.203666 Batch F1: 0.3333333333333333
Epoch:  725        8 Batch loss: 0.227825 Batch F1: 0.0
Epoch:  725        9 Batch loss: 0.194202 Batch F1: 0.0
Epoch:  725       10 Batch loss: 0.243194 Batch F1: 0.0
Epoch:  725       11 Batch loss: 0.201039 Batch F1: 0.0
Epoch:  725       12 Batch loss: 0.224891 Batch F1: 0.0
Train Avg Loss  725: 0.224149

Train Avg F1  725: 0.18964374932116868

Val Avg Loss  725: 0.218147

Val Avg F1  725:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 726
--------------------------------------------------------------
Epoch:  726        1 Batch loss: 0.233353 Batch F1: 0.0
Epoch:  726        2 Batch loss: 0.200682 Batch F1: 0.0
Epoch:  726        3 Batch loss: 0.236282 Batch F1: 0.15384615384615383
Epoch:  726        4 Batch loss: 0.205837 Batch F1: 0.19047619047619044
Epoch:  726        5 Batch loss: 0.251120 Batch F1: 0.2962962962962963
Epoch:  726        6 Batch loss: 0.242305 Batch F1: 0.16666666666666666
Epoch:  726        7 Batch loss: 0.218073 Batch F1: 0.42857142857142855
Epoch:  726        8 Batch loss: 0.217944 Batch F1: 0.4166666666666667
Epoch:  726        9 Batch loss: 0.237879 Batch F1: 0.3225806451612903
Epoch:  726       10 Batch loss: 0.215709 Batch F1: 0.23076923076923078
Epoch:  726       11 Batch loss: 0.204614 Batch F1: 0.380952380952381
Epoch:  726       12 Batch loss: 0.224215 Batch F1: 0.19047619047619047
Train Avg Loss  726: 0.224001

Train Avg F1  726: 0.23144182082354123

Val Avg Loss  726: 0.218891

Val Avg F1  726:  0.2602887308769662

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 727
--------------------------------------------------------------
Epoch:  727        1 Batch loss: 0.216149 Batch F1: 0.4444444444444444
Epoch:  727        2 Batch loss: 0.234893 Batch F1: 0.1904761904761905
Epoch:  727        3 Batch loss: 0.230094 Batch F1: 0.4666666666666667
Epoch:  727        4 Batch loss: 0.229771 Batch F1: 0.1
Epoch:  727        5 Batch loss: 0.221243 Batch F1: 0.0
Epoch:  727        6 Batch loss: 0.239891 Batch F1: 0.3076923076923077
Epoch:  727        7 Batch loss: 0.249660 Batch F1: 0.3333333333333333
Epoch:  727        8 Batch loss: 0.222950 Batch F1: 0.2608695652173913
Epoch:  727        9 Batch loss: 0.194970 Batch F1: 0.38095238095238093
Epoch:  727       10 Batch loss: 0.214852 Batch F1: 0.25
Epoch:  727       11 Batch loss: 0.221281 Batch F1: 0.25
Epoch:  727       12 Batch loss: 0.192566 Batch F1: 0.15384615384615385
Train Avg Loss  727: 0.222360

Train Avg F1  727: 0.2615234202190724

Val Avg Loss  727: 0.219055

Val Avg F1  727:  0.2656277056277056

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 728
--------------------------------------------------------------
Epoch:  728        1 Batch loss: 0.218353 Batch F1: 0.23529411764705882
Epoch:  728        2 Batch loss: 0.252734 Batch F1: 0.06666666666666667
Epoch:  728        3 Batch loss: 0.222305 Batch F1: 0.0
Epoch:  728        4 Batch loss: 0.207314 Batch F1: 0.1111111111111111
Epoch:  728        5 Batch loss: 0.210335 Batch F1: 0.09090909090909091
Epoch:  728        6 Batch loss: 0.199873 Batch F1: 0.38095238095238093
Epoch:  728        7 Batch loss: 0.198936 Batch F1: 0.4
Epoch:  728        8 Batch loss: 0.214812 Batch F1: 0.3636363636363636
Epoch:  728        9 Batch loss: 0.233155 Batch F1: 0.1818181818181818
Epoch:  728       10 Batch loss: 0.250337 Batch F1: 0.14285714285714288
Epoch:  728       11 Batch loss: 0.238422 Batch F1: 0.3333333333333333
Epoch:  728       12 Batch loss: 0.221191 Batch F1: 0.0
Train Avg Loss  728: 0.222314

Train Avg F1  728: 0.1922148657442775

Val Avg Loss  728: 0.218507

Val Avg F1  728:  0.2682109557109557

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 729
--------------------------------------------------------------
Epoch:  729        1 Batch loss: 0.214548 Batch F1: 0.46153846153846156
Epoch:  729        2 Batch loss: 0.212594 Batch F1: 0.4
Epoch:  729        3 Batch loss: 0.234313 Batch F1: 0.41379310344827586
Epoch:  729        4 Batch loss: 0.208904 Batch F1: 0.3333333333333333
Epoch:  729        5 Batch loss: 0.194362 Batch F1: 0.25
Epoch:  729        6 Batch loss: 0.250344 Batch F1: 0.2580645161290322
Epoch:  729        7 Batch loss: 0.248203 Batch F1: 0.20689655172413793
Epoch:  729        8 Batch loss: 0.232149 Batch F1: 0.22222222222222218
Epoch:  729        9 Batch loss: 0.224048 Batch F1: 0.25
Epoch:  729       10 Batch loss: 0.215465 Batch F1: 0.29629629629629634
Epoch:  729       11 Batch loss: 0.216797 Batch F1: 0.48275862068965514
Epoch:  729       12 Batch loss: 0.215141 Batch F1: 0.125
Train Avg Loss  729: 0.222239

Train Avg F1  729: 0.3083252587817846

Val Avg Loss  729: 0.218647

Val Avg F1  729:  0.25626456876456877

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 730
--------------------------------------------------------------
Epoch:  730        1 Batch loss: 0.248467 Batch F1: 0.3870967741935483
Epoch:  730        2 Batch loss: 0.214321 Batch F1: 0.3
Epoch:  730        3 Batch loss: 0.257501 Batch F1: 0.1875
Epoch:  730        4 Batch loss: 0.216095 Batch F1: 0.1818181818181818
Epoch:  730        5 Batch loss: 0.222652 Batch F1: 0.32
Epoch:  730        6 Batch loss: 0.211218 Batch F1: 0.2666666666666667
Epoch:  730        7 Batch loss: 0.236054 Batch F1: 0.4666666666666667
Epoch:  730        8 Batch loss: 0.198918 Batch F1: 0.2857142857142857
Epoch:  730        9 Batch loss: 0.219422 Batch F1: 0.09999999999999999
Epoch:  730       10 Batch loss: 0.202309 Batch F1: 0.5185185185185185
Epoch:  730       11 Batch loss: 0.196478 Batch F1: 0.34782608695652173
Epoch:  730       12 Batch loss: 0.242380 Batch F1: 0.2608695652173913
Train Avg Loss  730: 0.222151

Train Avg F1  730: 0.3018897288126484

Val Avg Loss  730: 0.219065

Val Avg F1  730:  0.2363095238095238

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 731
--------------------------------------------------------------
Epoch:  731        1 Batch loss: 0.217342 Batch F1: 0.36363636363636365
Epoch:  731        2 Batch loss: 0.186653 Batch F1: 0.2222222222222222
Epoch:  731        3 Batch loss: 0.204957 Batch F1: 0.2
Epoch:  731        4 Batch loss: 0.234675 Batch F1: 0.32
Epoch:  731        5 Batch loss: 0.236568 Batch F1: 0.24
Epoch:  731        6 Batch loss: 0.254322 Batch F1: 0.07142857142857142
Epoch:  731        7 Batch loss: 0.228656 Batch F1: 0.28571428571428575
Epoch:  731        8 Batch loss: 0.205371 Batch F1: 0.4
Epoch:  731        9 Batch loss: 0.220490 Batch F1: 0.39999999999999997
Epoch:  731       10 Batch loss: 0.205409 Batch F1: 0.3809523809523809
Epoch:  731       11 Batch loss: 0.252214 Batch F1: 0.3225806451612903
Epoch:  731       12 Batch loss: 0.216815 Batch F1: 0.3
Train Avg Loss  731: 0.221956

Train Avg F1  731: 0.29221120575959286

Val Avg Loss  731: 0.217783

Val Avg F1  731:  0.26458810068649885

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 732
--------------------------------------------------------------
Epoch:  732        1 Batch loss: 0.205385 Batch F1: 0.1904761904761905
Epoch:  732        2 Batch loss: 0.233173 Batch F1: 0.29629629629629634
Epoch:  732        3 Batch loss: 0.212986 Batch F1: 0.34782608695652173
Epoch:  732        4 Batch loss: 0.217367 Batch F1: 0.5
Epoch:  732        5 Batch loss: 0.202812 Batch F1: 0.11111111111111112
Epoch:  732        6 Batch loss: 0.217689 Batch F1: 0.2222222222222222
Epoch:  732        7 Batch loss: 0.245426 Batch F1: 0.0
Epoch:  732        8 Batch loss: 0.235278 Batch F1: 0.0
Epoch:  732        9 Batch loss: 0.233293 Batch F1: 0.0
Epoch:  732       10 Batch loss: 0.227048 Batch F1: 0.18181818181818182
Epoch:  732       11 Batch loss: 0.223651 Batch F1: 0.37037037037037035
Epoch:  732       12 Batch loss: 0.231521 Batch F1: 0.41666666666666663
Train Avg Loss  732: 0.223802

Train Avg F1  732: 0.21973226049313008

Val Avg Loss  732: 0.222725

Val Avg F1  732:  0.32014144026887653

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 733
--------------------------------------------------------------
Epoch:  733        1 Batch loss: 0.217678 Batch F1: 0.3478260869565218
Epoch:  733        2 Batch loss: 0.226065 Batch F1: 0.1818181818181818
Epoch:  733        3 Batch loss: 0.224731 Batch F1: 0.1739130434782609
Epoch:  733        4 Batch loss: 0.214149 Batch F1: 0.0
Epoch:  733        5 Batch loss: 0.235164 Batch F1: 0.08695652173913042
Epoch:  733        6 Batch loss: 0.228099 Batch F1: 0.23076923076923078
Epoch:  733        7 Batch loss: 0.232497 Batch F1: 0.1818181818181818
Epoch:  733        8 Batch loss: 0.241138 Batch F1: 0.08695652173913042
Epoch:  733        9 Batch loss: 0.216172 Batch F1: 0.1904761904761905
Epoch:  733       10 Batch loss: 0.203048 Batch F1: 0.46153846153846156
Epoch:  733       11 Batch loss: 0.207541 Batch F1: 0.5384615384615385
Epoch:  733       12 Batch loss: 0.230503 Batch F1: 0.1111111111111111
Train Avg Loss  733: 0.223065

Train Avg F1  733: 0.21597042249216167

Val Avg Loss  733: 0.219378

Val Avg F1  733:  0.25391120683897683

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 734
--------------------------------------------------------------
Epoch:  734        1 Batch loss: 0.225249 Batch F1: 0.2857142857142857
Epoch:  734        2 Batch loss: 0.252197 Batch F1: 0.16
Epoch:  734        3 Batch loss: 0.235103 Batch F1: 0.25
Epoch:  734        4 Batch loss: 0.222832 Batch F1: 0.5625
Epoch:  734        5 Batch loss: 0.243340 Batch F1: 0.20689655172413793
Epoch:  734        6 Batch loss: 0.231556 Batch F1: 0.39999999999999997
Epoch:  734        7 Batch loss: 0.181021 Batch F1: 0.2105263157894737
Epoch:  734        8 Batch loss: 0.198293 Batch F1: 0.5925925925925926
Epoch:  734        9 Batch loss: 0.247036 Batch F1: 0.3448275862068965
Epoch:  734       10 Batch loss: 0.199426 Batch F1: 0.0
Epoch:  734       11 Batch loss: 0.204696 Batch F1: 0.11764705882352941
Epoch:  734       12 Batch loss: 0.236222 Batch F1: 0.0
Train Avg Loss  734: 0.223081

Train Avg F1  734: 0.26089203257090965

Val Avg Loss  734: 0.217218

Val Avg F1  734:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 735
--------------------------------------------------------------
Epoch:  735        1 Batch loss: 0.266943 Batch F1: 0.0
Epoch:  735        2 Batch loss: 0.217342 Batch F1: 0.0
Epoch:  735        3 Batch loss: 0.243047 Batch F1: 0.14814814814814814
Epoch:  735        4 Batch loss: 0.204548 Batch F1: 0.11764705882352941
Epoch:  735        5 Batch loss: 0.205504 Batch F1: 0.26086956521739124
Epoch:  735        6 Batch loss: 0.243461 Batch F1: 0.3448275862068965
Epoch:  735        7 Batch loss: 0.210612 Batch F1: 0.27272727272727276
Epoch:  735        8 Batch loss: 0.226267 Batch F1: 0.2962962962962963
Epoch:  735        9 Batch loss: 0.184963 Batch F1: 0.39999999999999997
Epoch:  735       10 Batch loss: 0.224071 Batch F1: 0.0
Epoch:  735       11 Batch loss: 0.251028 Batch F1: 0.0
Epoch:  735       12 Batch loss: 0.207802 Batch F1: 0.0
Train Avg Loss  735: 0.223799

Train Avg F1  735: 0.15337632728496117

Val Avg Loss  735: 0.217387

Val Avg F1  735:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 736
--------------------------------------------------------------
Epoch:  736        1 Batch loss: 0.214249 Batch F1: 0.0
Epoch:  736        2 Batch loss: 0.262044 Batch F1: 0.0
Epoch:  736        3 Batch loss: 0.250816 Batch F1: 0.0
Epoch:  736        4 Batch loss: 0.209410 Batch F1: 0.36363636363636365
Epoch:  736        5 Batch loss: 0.233244 Batch F1: 0.1739130434782609
Epoch:  736        6 Batch loss: 0.212531 Batch F1: 0.44444444444444436
Epoch:  736        7 Batch loss: 0.227065 Batch F1: 0.29629629629629634
Epoch:  736        8 Batch loss: 0.212590 Batch F1: 0.5333333333333333
Epoch:  736        9 Batch loss: 0.191583 Batch F1: 0.0
Epoch:  736       10 Batch loss: 0.215815 Batch F1: 0.0
Epoch:  736       11 Batch loss: 0.222230 Batch F1: 0.0
Epoch:  736       12 Batch loss: 0.228843 Batch F1: 0.0
Train Avg Loss  736: 0.223368

Train Avg F1  736: 0.15096862343239156

Val Avg Loss  736: 0.219301

Val Avg F1  736:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 737
--------------------------------------------------------------
Epoch:  737        1 Batch loss: 0.249373 Batch F1: 0.0
Epoch:  737        2 Batch loss: 0.197199 Batch F1: 0.46153846153846156
Epoch:  737        3 Batch loss: 0.239101 Batch F1: 0.33333333333333326
Epoch:  737        4 Batch loss: 0.223426 Batch F1: 0.4444444444444444
Epoch:  737        5 Batch loss: 0.190016 Batch F1: 0.41666666666666663
Epoch:  737        6 Batch loss: 0.223115 Batch F1: 0.09999999999999999
Epoch:  737        7 Batch loss: 0.240686 Batch F1: 0.3448275862068965
Epoch:  737        8 Batch loss: 0.248197 Batch F1: 0.0
Epoch:  737        9 Batch loss: 0.233151 Batch F1: 0.08333333333333334
Epoch:  737       10 Batch loss: 0.222913 Batch F1: 0.3333333333333333
Epoch:  737       11 Batch loss: 0.220677 Batch F1: 0.19047619047619047
Epoch:  737       12 Batch loss: 0.194466 Batch F1: 0.47058823529411764
Train Avg Loss  737: 0.223526

Train Avg F1  737: 0.26487846538556475

Val Avg Loss  737: 0.218317

Val Avg F1  737:  0.21382458121588557

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 738
--------------------------------------------------------------
Epoch:  738        1 Batch loss: 0.203434 Batch F1: 0.2222222222222222
Epoch:  738        2 Batch loss: 0.247177 Batch F1: 0.0
Epoch:  738        3 Batch loss: 0.209235 Batch F1: 0.0
Epoch:  738        4 Batch loss: 0.193259 Batch F1: 0.11764705882352941
Epoch:  738        5 Batch loss: 0.194161 Batch F1: 0.0
Epoch:  738        6 Batch loss: 0.232102 Batch F1: 0.0
Epoch:  738        7 Batch loss: 0.238338 Batch F1: 0.09523809523809523
Epoch:  738        8 Batch loss: 0.230151 Batch F1: 0.0
Epoch:  738        9 Batch loss: 0.268336 Batch F1: 0.0
Epoch:  738       10 Batch loss: 0.229036 Batch F1: 0.09090909090909091
Epoch:  738       11 Batch loss: 0.179333 Batch F1: 0.16666666666666669
Epoch:  738       12 Batch loss: 0.250858 Batch F1: 0.1818181818181818
Train Avg Loss  738: 0.222952

Train Avg F1  738: 0.07287510963981551

Val Avg Loss  738: 0.218863

Val Avg F1  738:  0.2577440675266762

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 739
--------------------------------------------------------------
Epoch:  739        1 Batch loss: 0.204031 Batch F1: 0.3
Epoch:  739        2 Batch loss: 0.259706 Batch F1: 0.4
Epoch:  739        3 Batch loss: 0.228522 Batch F1: 0.3333333333333333
Epoch:  739        4 Batch loss: 0.214511 Batch F1: 0.33333333333333337
Epoch:  739        5 Batch loss: 0.252237 Batch F1: 0.3225806451612903
Epoch:  739        6 Batch loss: 0.218716 Batch F1: 0.16666666666666666
Epoch:  739        7 Batch loss: 0.218648 Batch F1: 0.32
Epoch:  739        8 Batch loss: 0.218800 Batch F1: 0.4444444444444445
Epoch:  739        9 Batch loss: 0.204938 Batch F1: 0.3333333333333333
Epoch:  739       10 Batch loss: 0.221848 Batch F1: 0.32
Epoch:  739       11 Batch loss: 0.199548 Batch F1: 0.4444444444444444
Epoch:  739       12 Batch loss: 0.228075 Batch F1: 0.19999999999999998
Train Avg Loss  739: 0.222465

Train Avg F1  739: 0.3265113500597372

Val Avg Loss  739: 0.217914

Val Avg F1  739:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 740
--------------------------------------------------------------
Epoch:  740        1 Batch loss: 0.209030 Batch F1: 0.0
Epoch:  740        2 Batch loss: 0.239579 Batch F1: 0.0
Epoch:  740        3 Batch loss: 0.236033 Batch F1: 0.0
Epoch:  740        4 Batch loss: 0.201094 Batch F1: 0.09999999999999999
Epoch:  740        5 Batch loss: 0.223422 Batch F1: 0.0
Epoch:  740        6 Batch loss: 0.225605 Batch F1: 0.0
Epoch:  740        7 Batch loss: 0.217347 Batch F1: 0.4799999999999999
Epoch:  740        8 Batch loss: 0.249139 Batch F1: 0.0
Epoch:  740        9 Batch loss: 0.218489 Batch F1: 0.3846153846153846
Epoch:  740       10 Batch loss: 0.243615 Batch F1: 0.5454545454545455
Epoch:  740       11 Batch loss: 0.207642 Batch F1: 0.5517241379310345
Epoch:  740       12 Batch loss: 0.193312 Batch F1: 0.6
Train Avg Loss  740: 0.222026

Train Avg F1  740: 0.22181617233341375

Val Avg Loss  740: 0.219118

Val Avg F1  740:  0.28985645933014353

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 741
--------------------------------------------------------------
Epoch:  741        1 Batch loss: 0.216683 Batch F1: 0.32
Epoch:  741        2 Batch loss: 0.191845 Batch F1: 0.125
Epoch:  741        3 Batch loss: 0.200545 Batch F1: 0.1111111111111111
Epoch:  741        4 Batch loss: 0.232718 Batch F1: 0.0
Epoch:  741        5 Batch loss: 0.222184 Batch F1: 0.0
Epoch:  741        6 Batch loss: 0.223887 Batch F1: 0.0
Epoch:  741        7 Batch loss: 0.237409 Batch F1: 0.2608695652173913
Epoch:  741        8 Batch loss: 0.250147 Batch F1: 0.0
Epoch:  741        9 Batch loss: 0.206135 Batch F1: 0.3846153846153846
Epoch:  741       10 Batch loss: 0.241953 Batch F1: 0.0
Epoch:  741       11 Batch loss: 0.216399 Batch F1: 0.0
Epoch:  741       12 Batch loss: 0.234639 Batch F1: 0.1
Train Avg Loss  741: 0.222879

Train Avg F1  741: 0.10846633841199059

Val Avg Loss  741: 0.221171

Val Avg F1  741:  0.26699158485273494

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 742
--------------------------------------------------------------
Epoch:  742        1 Batch loss: 0.218256 Batch F1: 0.29629629629629634
Epoch:  742        2 Batch loss: 0.248772 Batch F1: 0.43749999999999994
Epoch:  742        3 Batch loss: 0.204937 Batch F1: 0.3333333333333333
Epoch:  742        4 Batch loss: 0.239374 Batch F1: 0.09523809523809523
Epoch:  742        5 Batch loss: 0.231601 Batch F1: 0.0
Epoch:  742        6 Batch loss: 0.200480 Batch F1: 0.2222222222222222
Epoch:  742        7 Batch loss: 0.207431 Batch F1: 0.33333333333333337
Epoch:  742        8 Batch loss: 0.233605 Batch F1: 0.0
Epoch:  742        9 Batch loss: 0.226561 Batch F1: 0.0
Epoch:  742       10 Batch loss: 0.200137 Batch F1: 0.11764705882352941
Epoch:  742       11 Batch loss: 0.235010 Batch F1: 0.0
Epoch:  742       12 Batch loss: 0.248767 Batch F1: 0.0
Train Avg Loss  742: 0.224578

Train Avg F1  742: 0.15296419493723415

Val Avg Loss  742: 0.217409

Val Avg F1  742:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 743
--------------------------------------------------------------
Epoch:  743        1 Batch loss: 0.237733 Batch F1: 0.0
Epoch:  743        2 Batch loss: 0.247296 Batch F1: 0.0
Epoch:  743        3 Batch loss: 0.240321 Batch F1: 0.0
Epoch:  743        4 Batch loss: 0.216490 Batch F1: 0.2608695652173913
Epoch:  743        5 Batch loss: 0.205411 Batch F1: 0.2857142857142857
Epoch:  743        6 Batch loss: 0.268495 Batch F1: 0.25
Epoch:  743        7 Batch loss: 0.211839 Batch F1: 0.37037037037037035
Epoch:  743        8 Batch loss: 0.204722 Batch F1: 0.5925925925925926
Epoch:  743        9 Batch loss: 0.222269 Batch F1: 0.6060606060606061
Epoch:  743       10 Batch loss: 0.197663 Batch F1: 0.64
Epoch:  743       11 Batch loss: 0.210448 Batch F1: 0.12500000000000003
Epoch:  743       12 Batch loss: 0.213251 Batch F1: 0.0
Train Avg Loss  743: 0.222995

Train Avg F1  743: 0.26088395166293715

Val Avg Loss  743: 0.217800

Val Avg F1  743:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 744
--------------------------------------------------------------
Epoch:  744        1 Batch loss: 0.249074 Batch F1: 0.0
Epoch:  744        2 Batch loss: 0.208573 Batch F1: 0.0
Epoch:  744        3 Batch loss: 0.243837 Batch F1: 0.0
Epoch:  744        4 Batch loss: 0.230462 Batch F1: 0.0
Epoch:  744        5 Batch loss: 0.220469 Batch F1: 0.0
Epoch:  744        6 Batch loss: 0.205512 Batch F1: 0.0
Epoch:  744        7 Batch loss: 0.212269 Batch F1: 0.0
Epoch:  744        8 Batch loss: 0.215859 Batch F1: 0.33333333333333337
Epoch:  744        9 Batch loss: 0.204510 Batch F1: 0.42857142857142855
Epoch:  744       10 Batch loss: 0.230879 Batch F1: 0.48275862068965514
Epoch:  744       11 Batch loss: 0.244877 Batch F1: 0.2857142857142857
Epoch:  744       12 Batch loss: 0.235707 Batch F1: 0.2222222222222222
Train Avg Loss  744: 0.225169

Train Avg F1  744: 0.14604999087757708

Val Avg Loss  744: 0.218354

Val Avg F1  744:  0.24607843137254903

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 745
--------------------------------------------------------------
Epoch:  745        1 Batch loss: 0.229619 Batch F1: 0.37037037037037035
Epoch:  745        2 Batch loss: 0.189581 Batch F1: 0.0
Epoch:  745        3 Batch loss: 0.241341 Batch F1: 0.1
Epoch:  745        4 Batch loss: 0.230082 Batch F1: 0.32
Epoch:  745        5 Batch loss: 0.184986 Batch F1: 0.39999999999999997
Epoch:  745        6 Batch loss: 0.239514 Batch F1: 0.0
Epoch:  745        7 Batch loss: 0.220313 Batch F1: 0.0
Epoch:  745        8 Batch loss: 0.219973 Batch F1: 0.1
Epoch:  745        9 Batch loss: 0.207787 Batch F1: 0.09523809523809523
Epoch:  745       10 Batch loss: 0.262290 Batch F1: 0.4117647058823529
Epoch:  745       11 Batch loss: 0.238231 Batch F1: 0.2222222222222222
Epoch:  745       12 Batch loss: 0.222376 Batch F1: 0.2857142857142857
Train Avg Loss  745: 0.223841

Train Avg F1  745: 0.19210913995227719

Val Avg Loss  745: 0.220779

Val Avg F1  745:  0.2416243177112742

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 746
--------------------------------------------------------------
Epoch:  746        1 Batch loss: 0.227139 Batch F1: 0.4666666666666666
Epoch:  746        2 Batch loss: 0.237845 Batch F1: 0.42424242424242425
Epoch:  746        3 Batch loss: 0.200091 Batch F1: 0.21052631578947367
Epoch:  746        4 Batch loss: 0.211676 Batch F1: 0.35714285714285715
Epoch:  746        5 Batch loss: 0.233079 Batch F1: 0.0
Epoch:  746        6 Batch loss: 0.188171 Batch F1: 0.0
Epoch:  746        7 Batch loss: 0.207392 Batch F1: 0.0
Epoch:  746        8 Batch loss: 0.252067 Batch F1: 0.0
Epoch:  746        9 Batch loss: 0.247790 Batch F1: 0.0
Epoch:  746       10 Batch loss: 0.240003 Batch F1: 0.0
Epoch:  746       11 Batch loss: 0.231603 Batch F1: 0.2962962962962963
Epoch:  746       12 Batch loss: 0.215122 Batch F1: 0.21052631578947364
Train Avg Loss  746: 0.224331

Train Avg F1  746: 0.16378340632726598

Val Avg Loss  746: 0.221599

Val Avg F1  746:  0.2646825396825397

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 747
--------------------------------------------------------------
Epoch:  747        1 Batch loss: 0.210583 Batch F1: 0.42857142857142855
Epoch:  747        2 Batch loss: 0.228146 Batch F1: 0.0
Epoch:  747        3 Batch loss: 0.220804 Batch F1: 0.17391304347826086
Epoch:  747        4 Batch loss: 0.233204 Batch F1: 0.09523809523809525
Epoch:  747        5 Batch loss: 0.211673 Batch F1: 0.3
Epoch:  747        6 Batch loss: 0.197670 Batch F1: 0.0
Epoch:  747        7 Batch loss: 0.237933 Batch F1: 0.09090909090909091
Epoch:  747        8 Batch loss: 0.235943 Batch F1: 0.0
Epoch:  747        9 Batch loss: 0.224875 Batch F1: 0.0
Epoch:  747       10 Batch loss: 0.229932 Batch F1: 0.11111111111111112
Epoch:  747       11 Batch loss: 0.233703 Batch F1: 0.0
Epoch:  747       12 Batch loss: 0.214513 Batch F1: 0.11764705882352941
Train Avg Loss  747: 0.223248

Train Avg F1  747: 0.10978248567762633

Val Avg Loss  747: 0.218919

Val Avg F1  747:  0.1752173913043478

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 748
--------------------------------------------------------------
Epoch:  748        1 Batch loss: 0.231585 Batch F1: 0.32
Epoch:  748        2 Batch loss: 0.196311 Batch F1: 0.45454545454545453
Epoch:  748        3 Batch loss: 0.241292 Batch F1: 0.08
Epoch:  748        4 Batch loss: 0.258308 Batch F1: 0.33333333333333337
Epoch:  748        5 Batch loss: 0.220520 Batch F1: 0.19047619047619047
Epoch:  748        6 Batch loss: 0.238914 Batch F1: 0.2857142857142857
Epoch:  748        7 Batch loss: 0.230933 Batch F1: 0.27586206896551724
Epoch:  748        8 Batch loss: 0.218422 Batch F1: 0.3333333333333333
Epoch:  748        9 Batch loss: 0.224097 Batch F1: 0.4166666666666667
Epoch:  748       10 Batch loss: 0.213968 Batch F1: 0.5714285714285715
Epoch:  748       11 Batch loss: 0.184919 Batch F1: 0.5
Epoch:  748       12 Batch loss: 0.217646 Batch F1: 0.2
Train Avg Loss  748: 0.223076

Train Avg F1  748: 0.3301133253719461

Val Avg Loss  748: 0.219142

Val Avg F1  748:  0.26202861952861956

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 749
--------------------------------------------------------------
Epoch:  749        1 Batch loss: 0.232309 Batch F1: 0.4444444444444444
Epoch:  749        2 Batch loss: 0.191687 Batch F1: 0.2
Epoch:  749        3 Batch loss: 0.173660 Batch F1: 0.0
Epoch:  749        4 Batch loss: 0.271150 Batch F1: 0.0
Epoch:  749        5 Batch loss: 0.202906 Batch F1: 0.1111111111111111
Epoch:  749        6 Batch loss: 0.258742 Batch F1: 0.28571428571428575
Epoch:  749        7 Batch loss: 0.220150 Batch F1: 0.10526315789473685
Epoch:  749        8 Batch loss: 0.240602 Batch F1: 0.16666666666666666
Epoch:  749        9 Batch loss: 0.211681 Batch F1: 0.2608695652173913
Epoch:  749       10 Batch loss: 0.210192 Batch F1: 0.1111111111111111
Epoch:  749       11 Batch loss: 0.221107 Batch F1: 0.10526315789473684
Epoch:  749       12 Batch loss: 0.254703 Batch F1: 0.0
Train Avg Loss  749: 0.224074

Train Avg F1  749: 0.14920362500454035

Val Avg Loss  749: 0.217515

Val Avg F1  749:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 750
--------------------------------------------------------------
Epoch:  750        1 Batch loss: 0.214789 Batch F1: 0.0
Epoch:  750        2 Batch loss: 0.221555 Batch F1: 0.1111111111111111
Epoch:  750        3 Batch loss: 0.232745 Batch F1: 0.0
Epoch:  750        4 Batch loss: 0.226203 Batch F1: 0.0
Epoch:  750        5 Batch loss: 0.212539 Batch F1: 0.125
Epoch:  750        6 Batch loss: 0.238050 Batch F1: 0.0
Epoch:  750        7 Batch loss: 0.202581 Batch F1: 0.21052631578947367
Epoch:  750        8 Batch loss: 0.231102 Batch F1: 0.25
Epoch:  750        9 Batch loss: 0.216791 Batch F1: 0.4444444444444444
Epoch:  750       10 Batch loss: 0.214997 Batch F1: 0.17391304347826086
Epoch:  750       11 Batch loss: 0.227624 Batch F1: 0.35714285714285715
Epoch:  750       12 Batch loss: 0.226575 Batch F1: 0.2727272727272727
Train Avg Loss  750: 0.222129

Train Avg F1  750: 0.162072087057785

Val Avg Loss  750: 0.220441

Val Avg F1  750:  0.27805145046524354

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 751
--------------------------------------------------------------
Epoch:  751        1 Batch loss: 0.204900 Batch F1: 0.21052631578947364
Epoch:  751        2 Batch loss: 0.243016 Batch F1: 0.2962962962962963
Epoch:  751        3 Batch loss: 0.209020 Batch F1: 0.2727272727272727
Epoch:  751        4 Batch loss: 0.219641 Batch F1: 0.39999999999999997
Epoch:  751        5 Batch loss: 0.232288 Batch F1: 0.22222222222222218
Epoch:  751        6 Batch loss: 0.241251 Batch F1: 0.3448275862068965
Epoch:  751        7 Batch loss: 0.232034 Batch F1: 0.4666666666666667
Epoch:  751        8 Batch loss: 0.261005 Batch F1: 0.28571428571428575
Epoch:  751        9 Batch loss: 0.212405 Batch F1: 0.3333333333333333
Epoch:  751       10 Batch loss: 0.194528 Batch F1: 0.5833333333333334
Epoch:  751       11 Batch loss: 0.220066 Batch F1: 0.2727272727272727
Epoch:  751       12 Batch loss: 0.212037 Batch F1: 0.4
Train Avg Loss  751: 0.223516

Train Avg F1  751: 0.34069788208475443

Val Avg Loss  751: 0.217507

Val Avg F1  751:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 752
--------------------------------------------------------------
Epoch:  752        1 Batch loss: 0.209950 Batch F1: 0.0
Epoch:  752        2 Batch loss: 0.236984 Batch F1: 0.0
Epoch:  752        3 Batch loss: 0.237049 Batch F1: 0.1904761904761905
Epoch:  752        4 Batch loss: 0.226697 Batch F1: 0.21052631578947364
Epoch:  752        5 Batch loss: 0.194629 Batch F1: 0.23529411764705882
Epoch:  752        6 Batch loss: 0.203496 Batch F1: 0.0
Epoch:  752        7 Batch loss: 0.249084 Batch F1: 0.0
Epoch:  752        8 Batch loss: 0.199893 Batch F1: 0.4
Epoch:  752        9 Batch loss: 0.228359 Batch F1: 0.08333333333333333
Epoch:  752       10 Batch loss: 0.215974 Batch F1: 0.34782608695652173
Epoch:  752       11 Batch loss: 0.253609 Batch F1: 0.25
Epoch:  752       12 Batch loss: 0.226092 Batch F1: 0.1111111111111111
Train Avg Loss  752: 0.223485

Train Avg F1  752: 0.15238059627614076

Val Avg Loss  752: 0.219654

Val Avg F1  752:  0.2584782608695652

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 753
--------------------------------------------------------------
Epoch:  753        1 Batch loss: 0.197077 Batch F1: 0.14285714285714288
Epoch:  753        2 Batch loss: 0.212090 Batch F1: 0.08695652173913045
Epoch:  753        3 Batch loss: 0.208686 Batch F1: 0.0
Epoch:  753        4 Batch loss: 0.227944 Batch F1: 0.0
Epoch:  753        5 Batch loss: 0.237510 Batch F1: 0.0
Epoch:  753        6 Batch loss: 0.253953 Batch F1: 0.0
Epoch:  753        7 Batch loss: 0.224769 Batch F1: 0.0
Epoch:  753        8 Batch loss: 0.224882 Batch F1: 0.0
Epoch:  753        9 Batch loss: 0.223661 Batch F1: 0.1904761904761905
Epoch:  753       10 Batch loss: 0.221993 Batch F1: 0.0
Epoch:  753       11 Batch loss: 0.220369 Batch F1: 0.10526315789473685
Epoch:  753       12 Batch loss: 0.219562 Batch F1: 0.4999999999999999
Train Avg Loss  753: 0.222708

Train Avg F1  753: 0.08546275108060004

Val Avg Loss  753: 0.222021

Val Avg F1  753:  0.2649943534726143

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 754
--------------------------------------------------------------
Epoch:  754        1 Batch loss: 0.220452 Batch F1: 0.31999999999999995
Epoch:  754        2 Batch loss: 0.251645 Batch F1: 0.26666666666666666
Epoch:  754        3 Batch loss: 0.230694 Batch F1: 0.5
Epoch:  754        4 Batch loss: 0.207738 Batch F1: 0.5333333333333333
Epoch:  754        5 Batch loss: 0.232041 Batch F1: 0.41379310344827586
Epoch:  754        6 Batch loss: 0.192475 Batch F1: 0.6666666666666666
Epoch:  754        7 Batch loss: 0.172707 Batch F1: 0.39999999999999997
Epoch:  754        8 Batch loss: 0.239082 Batch F1: 0.0
Epoch:  754        9 Batch loss: 0.255247 Batch F1: 0.0
Epoch:  754       10 Batch loss: 0.230982 Batch F1: 0.0
Epoch:  754       11 Batch loss: 0.235739 Batch F1: 0.0
Epoch:  754       12 Batch loss: 0.219775 Batch F1: 0.0
Train Avg Loss  754: 0.224048

Train Avg F1  754: 0.25837164750957853

Val Avg Loss  754: 0.218971

Val Avg F1  754:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 755
--------------------------------------------------------------
Epoch:  755        1 Batch loss: 0.226583 Batch F1: 0.0
Epoch:  755        2 Batch loss: 0.253603 Batch F1: 0.07142857142857142
Epoch:  755        3 Batch loss: 0.189871 Batch F1: 0.5
Epoch:  755        4 Batch loss: 0.194891 Batch F1: 0.4210526315789474
Epoch:  755        5 Batch loss: 0.240561 Batch F1: 0.37500000000000006
Epoch:  755        6 Batch loss: 0.239415 Batch F1: 0.09523809523809522
Epoch:  755        7 Batch loss: 0.218453 Batch F1: 0.1904761904761905
Epoch:  755        8 Batch loss: 0.218606 Batch F1: 0.3703703703703704
Epoch:  755        9 Batch loss: 0.243700 Batch F1: 0.06896551724137931
Epoch:  755       10 Batch loss: 0.199359 Batch F1: 0.12500000000000003
Epoch:  755       11 Batch loss: 0.226015 Batch F1: 0.11764705882352941
Epoch:  755       12 Batch loss: 0.242280 Batch F1: 0.0
Train Avg Loss  755: 0.224445

Train Avg F1  755: 0.19459820292975696

Val Avg Loss  755: 0.217809

Val Avg F1  755:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 756
--------------------------------------------------------------
Epoch:  756        1 Batch loss: 0.213662 Batch F1: 0.0
Epoch:  756        2 Batch loss: 0.244431 Batch F1: 0.0
Epoch:  756        3 Batch loss: 0.149171 Batch F1: 0.0
Epoch:  756        4 Batch loss: 0.260019 Batch F1: 0.0
Epoch:  756        5 Batch loss: 0.236758 Batch F1: 0.0
Epoch:  756        6 Batch loss: 0.268536 Batch F1: 0.07999999999999999
Epoch:  756        7 Batch loss: 0.207530 Batch F1: 0.2608695652173913
Epoch:  756        8 Batch loss: 0.233962 Batch F1: 0.2962962962962963
Epoch:  756        9 Batch loss: 0.247050 Batch F1: 0.30303030303030304
Epoch:  756       10 Batch loss: 0.212377 Batch F1: 0.4444444444444445
Epoch:  756       11 Batch loss: 0.198692 Batch F1: 0.7142857142857143
Epoch:  756       12 Batch loss: 0.217762 Batch F1: 0.3
Train Avg Loss  756: 0.224163

Train Avg F1  756: 0.19991052693951242

Val Avg Loss  756: 0.219467

Val Avg F1  756:  0.2598912198912199

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 757
--------------------------------------------------------------
Epoch:  757        1 Batch loss: 0.226384 Batch F1: 0.0
Epoch:  757        2 Batch loss: 0.211532 Batch F1: 0.0
Epoch:  757        3 Batch loss: 0.226152 Batch F1: 0.0
Epoch:  757        4 Batch loss: 0.230937 Batch F1: 0.0
Epoch:  757        5 Batch loss: 0.245759 Batch F1: 0.0
Epoch:  757        6 Batch loss: 0.228517 Batch F1: 0.0
Epoch:  757        7 Batch loss: 0.220659 Batch F1: 0.34782608695652173
Epoch:  757        8 Batch loss: 0.210320 Batch F1: 0.45454545454545453
Epoch:  757        9 Batch loss: 0.206271 Batch F1: 0.2
Epoch:  757       10 Batch loss: 0.222546 Batch F1: 0.30769230769230765
Epoch:  757       11 Batch loss: 0.197046 Batch F1: 0.10526315789473684
Epoch:  757       12 Batch loss: 0.251971 Batch F1: 0.10526315789473684
Train Avg Loss  757: 0.223174

Train Avg F1  757: 0.1267158470819798

Val Avg Loss  757: 0.218422

Val Avg F1  757:  0.047619047619047616

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 758
--------------------------------------------------------------
Epoch:  758        1 Batch loss: 0.238162 Batch F1: 0.09090909090909091
Epoch:  758        2 Batch loss: 0.211988 Batch F1: 0.1111111111111111
Epoch:  758        3 Batch loss: 0.262103 Batch F1: 0.0
Epoch:  758        4 Batch loss: 0.231462 Batch F1: 0.0
Epoch:  758        5 Batch loss: 0.196578 Batch F1: 0.1
Epoch:  758        6 Batch loss: 0.229072 Batch F1: 0.1904761904761905
Epoch:  758        7 Batch loss: 0.206328 Batch F1: 0.21052631578947364
Epoch:  758        8 Batch loss: 0.235593 Batch F1: 0.37500000000000006
Epoch:  758        9 Batch loss: 0.196683 Batch F1: 0.5185185185185185
Epoch:  758       10 Batch loss: 0.214149 Batch F1: 0.3333333333333333
Epoch:  758       11 Batch loss: 0.205953 Batch F1: 0.3
Epoch:  758       12 Batch loss: 0.241209 Batch F1: 0.10526315789473684
Train Avg Loss  758: 0.222440

Train Avg F1  758: 0.1945948098360379

Val Avg Loss  758: 0.218685

Val Avg F1  758:  0.21781015037593981

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 759
--------------------------------------------------------------
Epoch:  759        1 Batch loss: 0.216889 Batch F1: 0.4444444444444444
Epoch:  759        2 Batch loss: 0.231018 Batch F1: 0.3846153846153846
Epoch:  759        3 Batch loss: 0.200478 Batch F1: 0.48
Epoch:  759        4 Batch loss: 0.286366 Batch F1: 0.25806451612903225
Epoch:  759        5 Batch loss: 0.231438 Batch F1: 0.3333333333333333
Epoch:  759        6 Batch loss: 0.241297 Batch F1: 0.25
Epoch:  759        7 Batch loss: 0.250800 Batch F1: 0.3225806451612903
Epoch:  759        8 Batch loss: 0.174440 Batch F1: 0.47058823529411764
Epoch:  759        9 Batch loss: 0.190029 Batch F1: 0.1818181818181818
Epoch:  759       10 Batch loss: 0.187556 Batch F1: 0.0
Epoch:  759       11 Batch loss: 0.251265 Batch F1: 0.08695652173913045
Epoch:  759       12 Batch loss: 0.210213 Batch F1: 0.0
Train Avg Loss  759: 0.222649

Train Avg F1  759: 0.2677001052112429

Val Avg Loss  759: 0.219610

Val Avg F1  759:  0.07332643202208419

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 760
--------------------------------------------------------------
Epoch:  760        1 Batch loss: 0.233622 Batch F1: 0.16666666666666666
Epoch:  760        2 Batch loss: 0.239533 Batch F1: 0.16
Epoch:  760        3 Batch loss: 0.220074 Batch F1: 0.46153846153846156
Epoch:  760        4 Batch loss: 0.211885 Batch F1: 0.5333333333333333
Epoch:  760        5 Batch loss: 0.193311 Batch F1: 0.4
Epoch:  760        6 Batch loss: 0.212106 Batch F1: 0.3333333333333333
Epoch:  760        7 Batch loss: 0.222595 Batch F1: 0.09090909090909091
Epoch:  760        8 Batch loss: 0.266758 Batch F1: 0.14814814814814817
Epoch:  760        9 Batch loss: 0.243168 Batch F1: 0.4137931034482759
Epoch:  760       10 Batch loss: 0.206616 Batch F1: 0.4285714285714285
Epoch:  760       11 Batch loss: 0.214246 Batch F1: 0.21052631578947367
Epoch:  760       12 Batch loss: 0.203125 Batch F1: 0.3157894736842105
Train Avg Loss  760: 0.222253

Train Avg F1  760: 0.3052174462852019

Val Avg Loss  760: 0.220300

Val Avg F1  760:  0.24244639376218322

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 761
--------------------------------------------------------------
Epoch:  761        1 Batch loss: 0.226636 Batch F1: 0.28571428571428575
Epoch:  761        2 Batch loss: 0.218541 Batch F1: 0.37037037037037035
Epoch:  761        3 Batch loss: 0.211478 Batch F1: 0.35714285714285715
Epoch:  761        4 Batch loss: 0.246880 Batch F1: 0.24
Epoch:  761        5 Batch loss: 0.234385 Batch F1: 0.29629629629629634
Epoch:  761        6 Batch loss: 0.242433 Batch F1: 0.32
Epoch:  761        7 Batch loss: 0.186160 Batch F1: 0.3157894736842105
Epoch:  761        8 Batch loss: 0.181014 Batch F1: 0.3
Epoch:  761        9 Batch loss: 0.225665 Batch F1: 0.0
Epoch:  761       10 Batch loss: 0.242690 Batch F1: 0.21428571428571425
Epoch:  761       11 Batch loss: 0.231598 Batch F1: 0.08333333333333333
Epoch:  761       12 Batch loss: 0.208098 Batch F1: 0.26666666666666666
Train Avg Loss  761: 0.221298

Train Avg F1  761: 0.25413324979114454

Val Avg Loss  761: 0.218332

Val Avg F1  761:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 762
--------------------------------------------------------------
Epoch:  762        1 Batch loss: 0.175922 Batch F1: 0.0
Epoch:  762        2 Batch loss: 0.204572 Batch F1: 0.0
Epoch:  762        3 Batch loss: 0.223794 Batch F1: 0.0
Epoch:  762        4 Batch loss: 0.221304 Batch F1: 0.0
Epoch:  762        5 Batch loss: 0.251859 Batch F1: 0.0
Epoch:  762        6 Batch loss: 0.283905 Batch F1: 0.0
Epoch:  762        7 Batch loss: 0.201132 Batch F1: 0.25
Epoch:  762        8 Batch loss: 0.206590 Batch F1: 0.36363636363636365
Epoch:  762        9 Batch loss: 0.222080 Batch F1: 0.4827586206896552
Epoch:  762       10 Batch loss: 0.241039 Batch F1: 0.08333333333333333
Epoch:  762       11 Batch loss: 0.247899 Batch F1: 0.4
Epoch:  762       12 Batch loss: 0.192502 Batch F1: 0.37499999999999994
Train Avg Loss  762: 0.222717

Train Avg F1  762: 0.16289402647161266

Val Avg Loss  762: 0.222669

Val Avg F1  762:  0.34058377896613184

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 763
--------------------------------------------------------------
Epoch:  763        1 Batch loss: 0.201656 Batch F1: 0.4347826086956522
Epoch:  763        2 Batch loss: 0.218949 Batch F1: 0.26086956521739135
Epoch:  763        3 Batch loss: 0.209691 Batch F1: 0.3636363636363636
Epoch:  763        4 Batch loss: 0.244823 Batch F1: 0.5
Epoch:  763        5 Batch loss: 0.215594 Batch F1: 0.17391304347826086
Epoch:  763        6 Batch loss: 0.205607 Batch F1: 0.2857142857142857
Epoch:  763        7 Batch loss: 0.211925 Batch F1: 0.0
Epoch:  763        8 Batch loss: 0.215694 Batch F1: 0.125
Epoch:  763        9 Batch loss: 0.232902 Batch F1: 0.0
Epoch:  763       10 Batch loss: 0.224843 Batch F1: 0.0
Epoch:  763       11 Batch loss: 0.260597 Batch F1: 0.0
Epoch:  763       12 Batch loss: 0.236882 Batch F1: 0.0
Train Avg Loss  763: 0.223264

Train Avg F1  763: 0.17865965556182947

Val Avg Loss  763: 0.221643

Val Avg F1  763:  0.2775657625732588

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 764
--------------------------------------------------------------
Epoch:  764        1 Batch loss: 0.211755 Batch F1: 0.3333333333333333
Epoch:  764        2 Batch loss: 0.221968 Batch F1: 0.5555555555555556
Epoch:  764        3 Batch loss: 0.238744 Batch F1: 0.27586206896551724
Epoch:  764        4 Batch loss: 0.225544 Batch F1: 0.4666666666666667
Epoch:  764        5 Batch loss: 0.208742 Batch F1: 0.5
Epoch:  764        6 Batch loss: 0.237332 Batch F1: 0.4242424242424242
Epoch:  764        7 Batch loss: 0.222582 Batch F1: 0.18181818181818182
Epoch:  764        8 Batch loss: 0.229158 Batch F1: 0.24
Epoch:  764        9 Batch loss: 0.242413 Batch F1: 0.0
Epoch:  764       10 Batch loss: 0.203160 Batch F1: 0.0
Epoch:  764       11 Batch loss: 0.204222 Batch F1: 0.0
Epoch:  764       12 Batch loss: 0.210221 Batch F1: 0.0
Train Avg Loss  764: 0.221320

Train Avg F1  764: 0.24812318588180657

Val Avg Loss  764: 0.218190

Val Avg F1  764:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 765
--------------------------------------------------------------
Epoch:  765        1 Batch loss: 0.262266 Batch F1: 0.0
Epoch:  765        2 Batch loss: 0.225265 Batch F1: 0.09523809523809523
Epoch:  765        3 Batch loss: 0.232418 Batch F1: 0.48275862068965514
Epoch:  765        4 Batch loss: 0.218198 Batch F1: 0.43750000000000006
Epoch:  765        5 Batch loss: 0.226697 Batch F1: 0.39999999999999997
Epoch:  765        6 Batch loss: 0.197257 Batch F1: 0.6
Epoch:  765        7 Batch loss: 0.214085 Batch F1: 0.3333333333333333
Epoch:  765        8 Batch loss: 0.239331 Batch F1: 0.08695652173913045
Epoch:  765        9 Batch loss: 0.233307 Batch F1: 0.1904761904761905
Epoch:  765       10 Batch loss: 0.220703 Batch F1: 0.0
Epoch:  765       11 Batch loss: 0.250291 Batch F1: 0.08333333333333334
Epoch:  765       12 Batch loss: 0.193983 Batch F1: 0.0
Train Avg Loss  765: 0.226150

Train Avg F1  765: 0.22579967456747818

Val Avg Loss  765: 0.218106

Val Avg F1  765:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 766
--------------------------------------------------------------
Epoch:  766        1 Batch loss: 0.235203 Batch F1: 0.0
Epoch:  766        2 Batch loss: 0.272894 Batch F1: 0.0
Epoch:  766        3 Batch loss: 0.204735 Batch F1: 0.0
Epoch:  766        4 Batch loss: 0.205192 Batch F1: 0.0
Epoch:  766        5 Batch loss: 0.234382 Batch F1: 0.0
Epoch:  766        6 Batch loss: 0.202957 Batch F1: 0.0
Epoch:  766        7 Batch loss: 0.217871 Batch F1: 0.0
Epoch:  766        8 Batch loss: 0.242700 Batch F1: 0.0
Epoch:  766        9 Batch loss: 0.246899 Batch F1: 0.0
Epoch:  766       10 Batch loss: 0.207155 Batch F1: 0.0
Epoch:  766       11 Batch loss: 0.225011 Batch F1: 0.0
Epoch:  766       12 Batch loss: 0.227368 Batch F1: 0.0
Train Avg Loss  766: 0.226864

Train Avg F1  766: 0.0

Val Avg Loss  766: 0.220739

Val Avg F1  766:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 767
--------------------------------------------------------------
Epoch:  767        1 Batch loss: 0.208484 Batch F1: 0.0
Epoch:  767        2 Batch loss: 0.212107 Batch F1: 0.0
Epoch:  767        3 Batch loss: 0.219414 Batch F1: 0.0
Epoch:  767        4 Batch loss: 0.271640 Batch F1: 0.07692307692307693
Epoch:  767        5 Batch loss: 0.191126 Batch F1: 0.0
Epoch:  767        6 Batch loss: 0.276090 Batch F1: 0.0
Epoch:  767        7 Batch loss: 0.205185 Batch F1: 0.125
Epoch:  767        8 Batch loss: 0.194354 Batch F1: 0.0
Epoch:  767        9 Batch loss: 0.223476 Batch F1: 0.0
Epoch:  767       10 Batch loss: 0.229659 Batch F1: 0.0
Epoch:  767       11 Batch loss: 0.198440 Batch F1: 0.125
Epoch:  767       12 Batch loss: 0.266186 Batch F1: 0.0909090909090909
Train Avg Loss  767: 0.224680

Train Avg F1  767: 0.03481934731934732

Val Avg Loss  767: 0.219845

Val Avg F1  767:  0.2726247987117552

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 768
--------------------------------------------------------------
Epoch:  768        1 Batch loss: 0.211845 Batch F1: 0.3157894736842105
Epoch:  768        2 Batch loss: 0.199184 Batch F1: 0.34782608695652173
Epoch:  768        3 Batch loss: 0.208947 Batch F1: 0.36363636363636365
Epoch:  768        4 Batch loss: 0.195077 Batch F1: 0.33333333333333337
Epoch:  768        5 Batch loss: 0.229311 Batch F1: 0.08333333333333334
Epoch:  768        6 Batch loss: 0.282637 Batch F1: 0.14814814814814817
Epoch:  768        7 Batch loss: 0.210659 Batch F1: 0.32
Epoch:  768        8 Batch loss: 0.206558 Batch F1: 0.34782608695652173
Epoch:  768        9 Batch loss: 0.215633 Batch F1: 0.24
Epoch:  768       10 Batch loss: 0.209386 Batch F1: 0.38461538461538464
Epoch:  768       11 Batch loss: 0.237501 Batch F1: 0.33333333333333337
Epoch:  768       12 Batch loss: 0.276425 Batch F1: 0.24999999999999997
Train Avg Loss  768: 0.223597

Train Avg F1  768: 0.28898679533309585

Val Avg Loss  768: 0.219788

Val Avg F1  768:  0.2713773681515617

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 769
--------------------------------------------------------------
Epoch:  769        1 Batch loss: 0.223374 Batch F1: 0.2857142857142857
Epoch:  769        2 Batch loss: 0.236566 Batch F1: 0.46153846153846156
Epoch:  769        3 Batch loss: 0.225314 Batch F1: 0.37037037037037035
Epoch:  769        4 Batch loss: 0.218630 Batch F1: 0.5454545454545454
Epoch:  769        5 Batch loss: 0.230086 Batch F1: 0.4848484848484849
Epoch:  769        6 Batch loss: 0.233862 Batch F1: 0.3870967741935483
Epoch:  769        7 Batch loss: 0.192271 Batch F1: 0.47619047619047616
Epoch:  769        8 Batch loss: 0.198154 Batch F1: 0.45454545454545453
Epoch:  769        9 Batch loss: 0.192924 Batch F1: 0.5454545454545455
Epoch:  769       10 Batch loss: 0.237865 Batch F1: 0.3870967741935484
Epoch:  769       11 Batch loss: 0.255964 Batch F1: 0.0
Epoch:  769       12 Batch loss: 0.218782 Batch F1: 0.0
Train Avg Loss  769: 0.221983

Train Avg F1  769: 0.36652584770864344

Val Avg Loss  769: 0.217204

Val Avg F1  769:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 770
--------------------------------------------------------------
Epoch:  770        1 Batch loss: 0.248033 Batch F1: 0.0
Epoch:  770        2 Batch loss: 0.287665 Batch F1: 0.07142857142857142
Epoch:  770        3 Batch loss: 0.205472 Batch F1: 0.0
Epoch:  770        4 Batch loss: 0.261915 Batch F1: 0.0
Epoch:  770        5 Batch loss: 0.198063 Batch F1: 0.3636363636363636
Epoch:  770        6 Batch loss: 0.217977 Batch F1: 0.30769230769230765
Epoch:  770        7 Batch loss: 0.208791 Batch F1: 0.2222222222222222
Epoch:  770        8 Batch loss: 0.213649 Batch F1: 0.3333333333333333
Epoch:  770        9 Batch loss: 0.211740 Batch F1: 0.09999999999999999
Epoch:  770       10 Batch loss: 0.229193 Batch F1: 0.0
Epoch:  770       11 Batch loss: 0.184747 Batch F1: 0.0
Epoch:  770       12 Batch loss: 0.230316 Batch F1: 0.0
Train Avg Loss  770: 0.224797

Train Avg F1  770: 0.11652606652606652

Val Avg Loss  770: 0.217333

Val Avg F1  770:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 771
--------------------------------------------------------------
Epoch:  771        1 Batch loss: 0.251057 Batch F1: 0.0
Epoch:  771        2 Batch loss: 0.230127 Batch F1: 0.0
Epoch:  771        3 Batch loss: 0.232373 Batch F1: 0.16666666666666666
Epoch:  771        4 Batch loss: 0.188633 Batch F1: 0.33333333333333337
Epoch:  771        5 Batch loss: 0.212473 Batch F1: 0.19047619047619044
Epoch:  771        6 Batch loss: 0.203777 Batch F1: 0.34782608695652173
Epoch:  771        7 Batch loss: 0.223999 Batch F1: 0.4166666666666667
Epoch:  771        8 Batch loss: 0.200683 Batch F1: 0.11764705882352941
Epoch:  771        9 Batch loss: 0.275407 Batch F1: 0.0
Epoch:  771       10 Batch loss: 0.193624 Batch F1: 0.22222222222222224
Epoch:  771       11 Batch loss: 0.190005 Batch F1: 0.21052631578947367
Epoch:  771       12 Batch loss: 0.305873 Batch F1: 0.0
Train Avg Loss  771: 0.225669

Train Avg F1  771: 0.16711371174455036

Val Avg Loss  771: 0.218797

Val Avg F1  771:  0.2583934583934584

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 772
--------------------------------------------------------------
Epoch:  772        1 Batch loss: 0.209992 Batch F1: 0.27272727272727276
Epoch:  772        2 Batch loss: 0.239059 Batch F1: 0.43750000000000006
Epoch:  772        3 Batch loss: 0.214763 Batch F1: 0.1904761904761905
Epoch:  772        4 Batch loss: 0.237842 Batch F1: 0.4666666666666666
Epoch:  772        5 Batch loss: 0.194778 Batch F1: 0.3333333333333333
Epoch:  772        6 Batch loss: 0.215970 Batch F1: 0.2962962962962963
Epoch:  772        7 Batch loss: 0.209756 Batch F1: 0.36363636363636365
Epoch:  772        8 Batch loss: 0.241637 Batch F1: 0.27586206896551724
Epoch:  772        9 Batch loss: 0.206922 Batch F1: 0.3
Epoch:  772       10 Batch loss: 0.209997 Batch F1: 0.4210526315789473
Epoch:  772       11 Batch loss: 0.268284 Batch F1: 0.07407407407407407
Epoch:  772       12 Batch loss: 0.225022 Batch F1: 0.0
Train Avg Loss  772: 0.222835

Train Avg F1  772: 0.28596874147955514

Val Avg Loss  772: 0.218593

Val Avg F1  772:  0.026315789473684213

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 773
--------------------------------------------------------------
Epoch:  773        1 Batch loss: 0.236786 Batch F1: 0.09090909090909091
Epoch:  773        2 Batch loss: 0.241852 Batch F1: 0.16
Epoch:  773        3 Batch loss: 0.220938 Batch F1: 0.35714285714285715
Epoch:  773        4 Batch loss: 0.207980 Batch F1: 0.32
Epoch:  773        5 Batch loss: 0.222199 Batch F1: 0.45161290322580644
Epoch:  773        6 Batch loss: 0.200550 Batch F1: 0.3
Epoch:  773        7 Batch loss: 0.211846 Batch F1: 0.09523809523809523
Epoch:  773        8 Batch loss: 0.219522 Batch F1: 0.34782608695652173
Epoch:  773        9 Batch loss: 0.239886 Batch F1: 0.4444444444444445
Epoch:  773       10 Batch loss: 0.227231 Batch F1: 0.2962962962962963
Epoch:  773       11 Batch loss: 0.210694 Batch F1: 0.3333333333333333
Epoch:  773       12 Batch loss: 0.222510 Batch F1: 0.4347826086956522
Train Avg Loss  773: 0.221833

Train Avg F1  773: 0.3026321430201748

Val Avg Loss  773: 0.218657

Val Avg F1  773:  0.15601851851851853

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 774
--------------------------------------------------------------
Epoch:  774        1 Batch loss: 0.215703 Batch F1: 0.1111111111111111
Epoch:  774        2 Batch loss: 0.221642 Batch F1: 0.0
Epoch:  774        3 Batch loss: 0.204999 Batch F1: 0.0
Epoch:  774        4 Batch loss: 0.217480 Batch F1: 0.08333333333333333
Epoch:  774        5 Batch loss: 0.226867 Batch F1: 0.37037037037037035
Epoch:  774        6 Batch loss: 0.196184 Batch F1: 0.5
Epoch:  774        7 Batch loss: 0.206330 Batch F1: 0.2222222222222222
Epoch:  774        8 Batch loss: 0.232346 Batch F1: 0.3846153846153846
Epoch:  774        9 Batch loss: 0.231058 Batch F1: 0.25
Epoch:  774       10 Batch loss: 0.240653 Batch F1: 0.2857142857142857
Epoch:  774       11 Batch loss: 0.214232 Batch F1: 0.1818181818181818
Epoch:  774       12 Batch loss: 0.270687 Batch F1: 0.07692307692307691
Train Avg Loss  774: 0.223182

Train Avg F1  774: 0.20550899717566384

Val Avg Loss  774: 0.219227

Val Avg F1  774:  0.27155483405483405

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 775
--------------------------------------------------------------
Epoch:  775        1 Batch loss: 0.269193 Batch F1: 0.3125
Epoch:  775        2 Batch loss: 0.226238 Batch F1: 0.44444444444444436
Epoch:  775        3 Batch loss: 0.192289 Batch F1: 0.5
Epoch:  775        4 Batch loss: 0.193587 Batch F1: 0.3333333333333333
Epoch:  775        5 Batch loss: 0.246822 Batch F1: 0.2666666666666667
Epoch:  775        6 Batch loss: 0.225190 Batch F1: 0.4666666666666667
Epoch:  775        7 Batch loss: 0.213297 Batch F1: 0.25
Epoch:  775        8 Batch loss: 0.231893 Batch F1: 0.16666666666666666
Epoch:  775        9 Batch loss: 0.229484 Batch F1: 0.3846153846153846
Epoch:  775       10 Batch loss: 0.211863 Batch F1: 0.1111111111111111
Epoch:  775       11 Batch loss: 0.204609 Batch F1: 0.3
Epoch:  775       12 Batch loss: 0.228990 Batch F1: 0.11111111111111112
Train Avg Loss  775: 0.222788

Train Avg F1  775: 0.303926282051282

Val Avg Loss  775: 0.217181

Val Avg F1  775:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 776
--------------------------------------------------------------
Epoch:  776        1 Batch loss: 0.242251 Batch F1: 0.0
Epoch:  776        2 Batch loss: 0.233886 Batch F1: 0.0
Epoch:  776        3 Batch loss: 0.194041 Batch F1: 0.0
Epoch:  776        4 Batch loss: 0.255710 Batch F1: 0.0
Epoch:  776        5 Batch loss: 0.215478 Batch F1: 0.0
Epoch:  776        6 Batch loss: 0.205366 Batch F1: 0.11764705882352941
Epoch:  776        7 Batch loss: 0.251663 Batch F1: 0.07999999999999999
Epoch:  776        8 Batch loss: 0.260716 Batch F1: 0.25
Epoch:  776        9 Batch loss: 0.223592 Batch F1: 0.09523809523809523
Epoch:  776       10 Batch loss: 0.205640 Batch F1: 0.3529411764705882
Epoch:  776       11 Batch loss: 0.191874 Batch F1: 0.380952380952381
Epoch:  776       12 Batch loss: 0.206872 Batch F1: 0.125
Train Avg Loss  776: 0.223924

Train Avg F1  776: 0.11681489262371615

Val Avg Loss  776: 0.217800

Val Avg F1  776:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 777
--------------------------------------------------------------
Epoch:  777        1 Batch loss: 0.236684 Batch F1: 0.0
Epoch:  777        2 Batch loss: 0.186640 Batch F1: 0.0
Epoch:  777        3 Batch loss: 0.245069 Batch F1: 0.0
Epoch:  777        4 Batch loss: 0.246150 Batch F1: 0.27586206896551724
Epoch:  777        5 Batch loss: 0.234005 Batch F1: 0.16666666666666666
Epoch:  777        6 Batch loss: 0.206031 Batch F1: 0.38095238095238093
Epoch:  777        7 Batch loss: 0.220778 Batch F1: 0.19047619047619047
Epoch:  777        8 Batch loss: 0.246009 Batch F1: 0.3225806451612903
Epoch:  777        9 Batch loss: 0.207791 Batch F1: 0.43478260869565216
Epoch:  777       10 Batch loss: 0.220887 Batch F1: 0.4242424242424242
Epoch:  777       11 Batch loss: 0.217293 Batch F1: 0.3
Epoch:  777       12 Batch loss: 0.208983 Batch F1: 0.14285714285714285
Train Avg Loss  777: 0.223027

Train Avg F1  777: 0.2198683440014387

Val Avg Loss  777: 0.217260

Val Avg F1  777:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 778
--------------------------------------------------------------
Epoch:  778        1 Batch loss: 0.246089 Batch F1: 0.0
Epoch:  778        2 Batch loss: 0.244973 Batch F1: 0.0
Epoch:  778        3 Batch loss: 0.201346 Batch F1: 0.3
Epoch:  778        4 Batch loss: 0.199796 Batch F1: 0.3
Epoch:  778        5 Batch loss: 0.206659 Batch F1: 0.36363636363636365
Epoch:  778        6 Batch loss: 0.224484 Batch F1: 0.09523809523809525
Epoch:  778        7 Batch loss: 0.229944 Batch F1: 0.2962962962962963
Epoch:  778        8 Batch loss: 0.268934 Batch F1: 0.25806451612903225
Epoch:  778        9 Batch loss: 0.214461 Batch F1: 0.4
Epoch:  778       10 Batch loss: 0.176488 Batch F1: 0.4444444444444445
Epoch:  778       11 Batch loss: 0.204142 Batch F1: 0.3478260869565218
Epoch:  778       12 Batch loss: 0.264053 Batch F1: 0.18181818181818182
Train Avg Loss  778: 0.223447

Train Avg F1  778: 0.24894366537657797

Val Avg Loss  778: 0.218997

Val Avg F1  778:  0.26436507936507936

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 779
--------------------------------------------------------------
Epoch:  779        1 Batch loss: 0.211061 Batch F1: 0.2857142857142857
Epoch:  779        2 Batch loss: 0.236052 Batch F1: 0.37037037037037035
Epoch:  779        3 Batch loss: 0.229595 Batch F1: 0.24
Epoch:  779        4 Batch loss: 0.222076 Batch F1: 0.5000000000000001
Epoch:  779        5 Batch loss: 0.210148 Batch F1: 0.22222222222222224
Epoch:  779        6 Batch loss: 0.209973 Batch F1: 0.1111111111111111
Epoch:  779        7 Batch loss: 0.205881 Batch F1: 0.4166666666666667
Epoch:  779        8 Batch loss: 0.201917 Batch F1: 0.11111111111111112
Epoch:  779        9 Batch loss: 0.239543 Batch F1: 0.1818181818181818
Epoch:  779       10 Batch loss: 0.248803 Batch F1: 0.35714285714285715
Epoch:  779       11 Batch loss: 0.223887 Batch F1: 0.17391304347826086
Epoch:  779       12 Batch loss: 0.226841 Batch F1: 0.4210526315789473
Train Avg Loss  779: 0.222148

Train Avg F1  779: 0.28259354010116783

Val Avg Loss  779: 0.218901

Val Avg F1  779:  0.24270289097875306

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 780
--------------------------------------------------------------
Epoch:  780        1 Batch loss: 0.212620 Batch F1: 0.1904761904761905
Epoch:  780        2 Batch loss: 0.259918 Batch F1: 0.16
Epoch:  780        3 Batch loss: 0.209769 Batch F1: 0.23529411764705882
Epoch:  780        4 Batch loss: 0.246599 Batch F1: 0.35714285714285715
Epoch:  780        5 Batch loss: 0.238210 Batch F1: 0.22222222222222218
Epoch:  780        6 Batch loss: 0.220244 Batch F1: 0.25
Epoch:  780        7 Batch loss: 0.197521 Batch F1: 0.3529411764705882
Epoch:  780        8 Batch loss: 0.211145 Batch F1: 0.4545454545454545
Epoch:  780        9 Batch loss: 0.237371 Batch F1: 0.14814814814814817
Epoch:  780       10 Batch loss: 0.194209 Batch F1: 0.3478260869565218
Epoch:  780       11 Batch loss: 0.219826 Batch F1: 0.0
Epoch:  780       12 Batch loss: 0.215194 Batch F1: 0.3
Train Avg Loss  780: 0.221885

Train Avg F1  780: 0.25154968780075343

Val Avg Loss  780: 0.219197

Val Avg F1  780:  0.25339920948616607

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 781
--------------------------------------------------------------
Epoch:  781        1 Batch loss: 0.206074 Batch F1: 0.3
Epoch:  781        2 Batch loss: 0.203890 Batch F1: 0.45454545454545453
Epoch:  781        3 Batch loss: 0.235551 Batch F1: 0.32000000000000006
Epoch:  781        4 Batch loss: 0.201913 Batch F1: 0.36363636363636365
Epoch:  781        5 Batch loss: 0.220897 Batch F1: 0.2857142857142857
Epoch:  781        6 Batch loss: 0.233652 Batch F1: 0.08695652173913043
Epoch:  781        7 Batch loss: 0.217207 Batch F1: 0.5185185185185185
Epoch:  781        8 Batch loss: 0.228940 Batch F1: 0.23076923076923078
Epoch:  781        9 Batch loss: 0.236903 Batch F1: 0.09523809523809522
Epoch:  781       10 Batch loss: 0.192315 Batch F1: 0.22222222222222224
Epoch:  781       11 Batch loss: 0.224172 Batch F1: 0.37037037037037035
Epoch:  781       12 Batch loss: 0.270816 Batch F1: 0.4
Train Avg Loss  781: 0.222694

Train Avg F1  781: 0.30399758856280595

Val Avg Loss  781: 0.219169

Val Avg F1  781:  0.2510673234811166

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 782
--------------------------------------------------------------
Epoch:  782        1 Batch loss: 0.237345 Batch F1: 0.25
Epoch:  782        2 Batch loss: 0.235940 Batch F1: 0.25
Epoch:  782        3 Batch loss: 0.228966 Batch F1: 0.3448275862068965
Epoch:  782        4 Batch loss: 0.212903 Batch F1: 0.16666666666666669
Epoch:  782        5 Batch loss: 0.218820 Batch F1: 0.4
Epoch:  782        6 Batch loss: 0.239149 Batch F1: 0.3636363636363637
Epoch:  782        7 Batch loss: 0.210607 Batch F1: 0.5
Epoch:  782        8 Batch loss: 0.161385 Batch F1: 0.75
Epoch:  782        9 Batch loss: 0.242446 Batch F1: 0.0
Epoch:  782       10 Batch loss: 0.219057 Batch F1: 0.0
Epoch:  782       11 Batch loss: 0.247272 Batch F1: 0.0
Epoch:  782       12 Batch loss: 0.217235 Batch F1: 0.0
Train Avg Loss  782: 0.222594

Train Avg F1  782: 0.25209421804249393

Val Avg Loss  782: 0.217698

Val Avg F1  782:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 783
--------------------------------------------------------------
Epoch:  783        1 Batch loss: 0.218098 Batch F1: 0.0
Epoch:  783        2 Batch loss: 0.208758 Batch F1: 0.0
Epoch:  783        3 Batch loss: 0.187216 Batch F1: 0.0
Epoch:  783        4 Batch loss: 0.254769 Batch F1: 0.08333333333333333
Epoch:  783        5 Batch loss: 0.191302 Batch F1: 0.35294117647058826
Epoch:  783        6 Batch loss: 0.188649 Batch F1: 0.2
Epoch:  783        7 Batch loss: 0.271846 Batch F1: 0.14285714285714285
Epoch:  783        8 Batch loss: 0.207995 Batch F1: 0.4166666666666667
Epoch:  783        9 Batch loss: 0.222898 Batch F1: 0.2
Epoch:  783       10 Batch loss: 0.236019 Batch F1: 0.16000000000000003
Epoch:  783       11 Batch loss: 0.254848 Batch F1: 0.07407407407407408
Epoch:  783       12 Batch loss: 0.232015 Batch F1: 0.46153846153846156
Train Avg Loss  783: 0.222868

Train Avg F1  783: 0.1742842379116889

Val Avg Loss  783: 0.220452

Val Avg F1  783:  0.25148809523809523

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 784
--------------------------------------------------------------
Epoch:  784        1 Batch loss: 0.216057 Batch F1: 0.37037037037037035
Epoch:  784        2 Batch loss: 0.231588 Batch F1: 0.30769230769230765
Epoch:  784        3 Batch loss: 0.225428 Batch F1: 0.5161290322580644
Epoch:  784        4 Batch loss: 0.209021 Batch F1: 0.3333333333333333
Epoch:  784        5 Batch loss: 0.213298 Batch F1: 0.5161290322580646
Epoch:  784        6 Batch loss: 0.231229 Batch F1: 0.41379310344827586
Epoch:  784        7 Batch loss: 0.224833 Batch F1: 0.27272727272727276
Epoch:  784        8 Batch loss: 0.248916 Batch F1: 0.08333333333333334
Epoch:  784        9 Batch loss: 0.245586 Batch F1: 0.3846153846153846
Epoch:  784       10 Batch loss: 0.192142 Batch F1: 0.45454545454545453
Epoch:  784       11 Batch loss: 0.239618 Batch F1: 0.23076923076923075
Epoch:  784       12 Batch loss: 0.185925 Batch F1: 0.26666666666666666
Train Avg Loss  784: 0.221970

Train Avg F1  784: 0.34584204350147996

Val Avg Loss  784: 0.217490

Val Avg F1  784:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 785
--------------------------------------------------------------
Epoch:  785        1 Batch loss: 0.239864 Batch F1: 0.0
Epoch:  785        2 Batch loss: 0.226096 Batch F1: 0.0
Epoch:  785        3 Batch loss: 0.236681 Batch F1: 0.0
Epoch:  785        4 Batch loss: 0.229136 Batch F1: 0.28571428571428575
Epoch:  785        5 Batch loss: 0.241232 Batch F1: 0.28571428571428575
Epoch:  785        6 Batch loss: 0.209860 Batch F1: 0.2608695652173913
Epoch:  785        7 Batch loss: 0.199710 Batch F1: 0.46153846153846156
Epoch:  785        8 Batch loss: 0.225211 Batch F1: 0.3333333333333333
Epoch:  785        9 Batch loss: 0.220095 Batch F1: 0.1
Epoch:  785       10 Batch loss: 0.226780 Batch F1: 0.09523809523809523
Epoch:  785       11 Batch loss: 0.176838 Batch F1: 0.0
Epoch:  785       12 Batch loss: 0.255062 Batch F1: 0.0
Train Avg Loss  785: 0.223880

Train Avg F1  785: 0.15186733556298773

Val Avg Loss  785: 0.217704

Val Avg F1  785:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 786
--------------------------------------------------------------
Epoch:  786        1 Batch loss: 0.248783 Batch F1: 0.0
Epoch:  786        2 Batch loss: 0.244911 Batch F1: 0.0
Epoch:  786        3 Batch loss: 0.222186 Batch F1: 0.2962962962962963
Epoch:  786        4 Batch loss: 0.176721 Batch F1: 0.43478260869565216
Epoch:  786        5 Batch loss: 0.204980 Batch F1: 0.3333333333333333
Epoch:  786        6 Batch loss: 0.263677 Batch F1: 0.21428571428571427
Epoch:  786        7 Batch loss: 0.199499 Batch F1: 0.46153846153846156
Epoch:  786        8 Batch loss: 0.233804 Batch F1: 0.23076923076923073
Epoch:  786        9 Batch loss: 0.199740 Batch F1: 0.5
Epoch:  786       10 Batch loss: 0.223165 Batch F1: 0.46153846153846156
Epoch:  786       11 Batch loss: 0.237871 Batch F1: 0.17391304347826086
Epoch:  786       12 Batch loss: 0.213314 Batch F1: 0.23529411764705882
Train Avg Loss  786: 0.222388

Train Avg F1  786: 0.27847927229853914

Val Avg Loss  786: 0.218331

Val Avg F1  786:  0.18305860805860805

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 787
--------------------------------------------------------------
Epoch:  787        1 Batch loss: 0.238993 Batch F1: 0.0909090909090909
Epoch:  787        2 Batch loss: 0.235225 Batch F1: 0.08695652173913045
Epoch:  787        3 Batch loss: 0.228774 Batch F1: 0.0
Epoch:  787        4 Batch loss: 0.227854 Batch F1: 0.48275862068965514
Epoch:  787        5 Batch loss: 0.177735 Batch F1: 0.16666666666666669
Epoch:  787        6 Batch loss: 0.237021 Batch F1: 0.2222222222222222
Epoch:  787        7 Batch loss: 0.200329 Batch F1: 0.3809523809523809
Epoch:  787        8 Batch loss: 0.239488 Batch F1: 0.17391304347826086
Epoch:  787        9 Batch loss: 0.199405 Batch F1: 0.38095238095238093
Epoch:  787       10 Batch loss: 0.218764 Batch F1: 0.31999999999999995
Epoch:  787       11 Batch loss: 0.235859 Batch F1: 0.16666666666666666
Epoch:  787       12 Batch loss: 0.240375 Batch F1: 0.1904761904761905
Train Avg Loss  787: 0.223319

Train Avg F1  787: 0.22187281539605375

Val Avg Loss  787: 0.218413

Val Avg F1  787:  0.23657407407407408

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 788
--------------------------------------------------------------
Epoch:  788        1 Batch loss: 0.235843 Batch F1: 0.08695652173913042
Epoch:  788        2 Batch loss: 0.223327 Batch F1: 0.3846153846153846
Epoch:  788        3 Batch loss: 0.217225 Batch F1: 0.3448275862068966
Epoch:  788        4 Batch loss: 0.240571 Batch F1: 0.375
Epoch:  788        5 Batch loss: 0.211583 Batch F1: 0.43749999999999994
Epoch:  788        6 Batch loss: 0.228545 Batch F1: 0.4166666666666667
Epoch:  788        7 Batch loss: 0.227610 Batch F1: 0.2857142857142857
Epoch:  788        8 Batch loss: 0.234037 Batch F1: 0.35714285714285715
Epoch:  788        9 Batch loss: 0.213998 Batch F1: 0.26086956521739124
Epoch:  788       10 Batch loss: 0.207921 Batch F1: 0.4
Epoch:  788       11 Batch loss: 0.201433 Batch F1: 0.0
Epoch:  788       12 Batch loss: 0.228334 Batch F1: 0.0
Train Avg Loss  788: 0.222536

Train Avg F1  788: 0.27910773894188434

Val Avg Loss  788: 0.218365

Val Avg F1  788:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 789
--------------------------------------------------------------
Epoch:  789        1 Batch loss: 0.235109 Batch F1: 0.0
Epoch:  789        2 Batch loss: 0.237022 Batch F1: 0.0
Epoch:  789        3 Batch loss: 0.242550 Batch F1: 0.0
Epoch:  789        4 Batch loss: 0.164710 Batch F1: 0.0
Epoch:  789        5 Batch loss: 0.249306 Batch F1: 0.0
Epoch:  789        6 Batch loss: 0.216646 Batch F1: 0.2
Epoch:  789        7 Batch loss: 0.180389 Batch F1: 0.2857142857142857
Epoch:  789        8 Batch loss: 0.193033 Batch F1: 0.0
Epoch:  789        9 Batch loss: 0.195233 Batch F1: 0.0
Epoch:  789       10 Batch loss: 0.270106 Batch F1: 0.0
Epoch:  789       11 Batch loss: 0.283339 Batch F1: 0.07407407407407407
Epoch:  789       12 Batch loss: 0.238827 Batch F1: 0.2727272727272727
Train Avg Loss  789: 0.225523

Train Avg F1  789: 0.06937630270963603

Val Avg Loss  789: 0.222804

Val Avg F1  789:  0.22502443792766375

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 790
--------------------------------------------------------------
Epoch:  790        1 Batch loss: 0.224947 Batch F1: 0.5
Epoch:  790        2 Batch loss: 0.242624 Batch F1: 0.2962962962962963
Epoch:  790        3 Batch loss: 0.214597 Batch F1: 0.6666666666666667
Epoch:  790        4 Batch loss: 0.259603 Batch F1: 0.43243243243243246
Epoch:  790        5 Batch loss: 0.223715 Batch F1: 0.4444444444444444
Epoch:  790        6 Batch loss: 0.229034 Batch F1: 0.3076923076923077
Epoch:  790        7 Batch loss: 0.200407 Batch F1: 0.11764705882352941
Epoch:  790        8 Batch loss: 0.224257 Batch F1: 0.09523809523809523
Epoch:  790        9 Batch loss: 0.188444 Batch F1: 0.0
Epoch:  790       10 Batch loss: 0.247807 Batch F1: 0.0
Epoch:  790       11 Batch loss: 0.229589 Batch F1: 0.0
Epoch:  790       12 Batch loss: 0.211561 Batch F1: 0.0
Train Avg Loss  790: 0.224715

Train Avg F1  790: 0.23836810846614767

Val Avg Loss  790: 0.218233

Val Avg F1  790:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 791
--------------------------------------------------------------
Epoch:  791        1 Batch loss: 0.213459 Batch F1: 0.0
Epoch:  791        2 Batch loss: 0.219549 Batch F1: 0.0
Epoch:  791        3 Batch loss: 0.207229 Batch F1: 0.0
Epoch:  791        4 Batch loss: 0.246019 Batch F1: 0.0
Epoch:  791        5 Batch loss: 0.238646 Batch F1: 0.0
Epoch:  791        6 Batch loss: 0.199433 Batch F1: 0.0
Epoch:  791        7 Batch loss: 0.223436 Batch F1: 0.0
Epoch:  791        8 Batch loss: 0.224722 Batch F1: 0.0
Epoch:  791        9 Batch loss: 0.270054 Batch F1: 0.07692307692307693
Epoch:  791       10 Batch loss: 0.219337 Batch F1: 0.3846153846153846
Epoch:  791       11 Batch loss: 0.201660 Batch F1: 0.33333333333333337
Epoch:  791       12 Batch loss: 0.228041 Batch F1: 0.36363636363636365
Train Avg Loss  791: 0.224299

Train Avg F1  791: 0.09654234654234654

Val Avg Loss  791: 0.219631

Val Avg F1  791:  0.07045454545454546

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 792
--------------------------------------------------------------
Epoch:  792        1 Batch loss: 0.226653 Batch F1: 0.08695652173913045
Epoch:  792        2 Batch loss: 0.203287 Batch F1: 0.125
Epoch:  792        3 Batch loss: 0.237370 Batch F1: 0.08333333333333333
Epoch:  792        4 Batch loss: 0.208379 Batch F1: 0.0
Epoch:  792        5 Batch loss: 0.204146 Batch F1: 0.0
Epoch:  792        6 Batch loss: 0.237283 Batch F1: 0.0
Epoch:  792        7 Batch loss: 0.225775 Batch F1: 0.0
Epoch:  792        8 Batch loss: 0.213165 Batch F1: 0.28571428571428575
Epoch:  792        9 Batch loss: 0.241389 Batch F1: 0.16
Epoch:  792       10 Batch loss: 0.210499 Batch F1: 0.11764705882352941
Epoch:  792       11 Batch loss: 0.224867 Batch F1: 0.0
Epoch:  792       12 Batch loss: 0.240358 Batch F1: 0.4444444444444445
Train Avg Loss  792: 0.222764

Train Avg F1  792: 0.10859130367122695

Val Avg Loss  792: 0.219432

Val Avg F1  792:  0.2941248823479079

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 793
--------------------------------------------------------------
Epoch:  793        1 Batch loss: 0.269830 Batch F1: 0.21428571428571427
Epoch:  793        2 Batch loss: 0.237065 Batch F1: 0.33333333333333337
Epoch:  793        3 Batch loss: 0.183995 Batch F1: 0.64
Epoch:  793        4 Batch loss: 0.229833 Batch F1: 0.4516129032258065
Epoch:  793        5 Batch loss: 0.189015 Batch F1: 0.45454545454545453
Epoch:  793        6 Batch loss: 0.225176 Batch F1: 0.37499999999999994
Epoch:  793        7 Batch loss: 0.220556 Batch F1: 0.08695652173913043
Epoch:  793        8 Batch loss: 0.197421 Batch F1: 0.48
Epoch:  793        9 Batch loss: 0.243759 Batch F1: 0.16666666666666669
Epoch:  793       10 Batch loss: 0.239672 Batch F1: 0.27272727272727276
Epoch:  793       11 Batch loss: 0.215648 Batch F1: 0.0
Epoch:  793       12 Batch loss: 0.219712 Batch F1: 0.0
Train Avg Loss  793: 0.222640

Train Avg F1  793: 0.2895939888769482

Val Avg Loss  793: 0.217736

Val Avg F1  793:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 794
--------------------------------------------------------------
Epoch:  794        1 Batch loss: 0.215834 Batch F1: 0.0
Epoch:  794        2 Batch loss: 0.254591 Batch F1: 0.0
Epoch:  794        3 Batch loss: 0.188186 Batch F1: 0.3157894736842105
Epoch:  794        4 Batch loss: 0.233409 Batch F1: 0.20689655172413793
Epoch:  794        5 Batch loss: 0.205204 Batch F1: 0.380952380952381
Epoch:  794        6 Batch loss: 0.223054 Batch F1: 0.24
Epoch:  794        7 Batch loss: 0.222403 Batch F1: 0.36363636363636365
Epoch:  794        8 Batch loss: 0.222399 Batch F1: 0.32000000000000006
Epoch:  794        9 Batch loss: 0.196498 Batch F1: 0.3157894736842105
Epoch:  794       10 Batch loss: 0.221000 Batch F1: 0.2
Epoch:  794       11 Batch loss: 0.254367 Batch F1: 0.0
Epoch:  794       12 Batch loss: 0.246617 Batch F1: 0.0
Train Avg Loss  794: 0.223630

Train Avg F1  794: 0.19525535364010863

Val Avg Loss  794: 0.217154

Val Avg F1  794:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 795
--------------------------------------------------------------
Epoch:  795        1 Batch loss: 0.214687 Batch F1: 0.0
Epoch:  795        2 Batch loss: 0.222251 Batch F1: 0.10526315789473684
Epoch:  795        3 Batch loss: 0.220117 Batch F1: 0.0
Epoch:  795        4 Batch loss: 0.215571 Batch F1: 0.46153846153846156
Epoch:  795        5 Batch loss: 0.229407 Batch F1: 0.41379310344827586
Epoch:  795        6 Batch loss: 0.255167 Batch F1: 0.36363636363636365
Epoch:  795        7 Batch loss: 0.201847 Batch F1: 0.4761904761904762
Epoch:  795        8 Batch loss: 0.215193 Batch F1: 0.28571428571428575
Epoch:  795        9 Batch loss: 0.232549 Batch F1: 0.0
Epoch:  795       10 Batch loss: 0.214781 Batch F1: 0.0
Epoch:  795       11 Batch loss: 0.234688 Batch F1: 0.0
Epoch:  795       12 Batch loss: 0.240145 Batch F1: 0.0
Train Avg Loss  795: 0.224700

Train Avg F1  795: 0.17551132070188333

Val Avg Loss  795: 0.217127

Val Avg F1  795:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 796
--------------------------------------------------------------
Epoch:  796        1 Batch loss: 0.228445 Batch F1: 0.0
Epoch:  796        2 Batch loss: 0.239390 Batch F1: 0.0
Epoch:  796        3 Batch loss: 0.202714 Batch F1: 0.0
Epoch:  796        4 Batch loss: 0.219208 Batch F1: 0.1904761904761905
Epoch:  796        5 Batch loss: 0.252468 Batch F1: 0.21428571428571427
Epoch:  796        6 Batch loss: 0.172254 Batch F1: 0.4444444444444445
Epoch:  796        7 Batch loss: 0.223167 Batch F1: 0.38461538461538464
Epoch:  796        8 Batch loss: 0.217006 Batch F1: 0.4
Epoch:  796        9 Batch loss: 0.206038 Batch F1: 0.2857142857142857
Epoch:  796       10 Batch loss: 0.220792 Batch F1: 0.3
Epoch:  796       11 Batch loss: 0.243607 Batch F1: 0.3448275862068966
Epoch:  796       12 Batch loss: 0.247813 Batch F1: 0.16666666666666669
Train Avg Loss  796: 0.222742

Train Avg F1  796: 0.22758585603413184

Val Avg Loss  796: 0.219338

Val Avg F1  796:  0.24855699855699856

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 797
--------------------------------------------------------------
Epoch:  797        1 Batch loss: 0.224725 Batch F1: 0.4
Epoch:  797        2 Batch loss: 0.252982 Batch F1: 0.3529411764705882
Epoch:  797        3 Batch loss: 0.190092 Batch F1: 0.4444444444444444
Epoch:  797        4 Batch loss: 0.212104 Batch F1: 0.1904761904761905
Epoch:  797        5 Batch loss: 0.226818 Batch F1: 0.4
Epoch:  797        6 Batch loss: 0.257488 Batch F1: 0.07407407407407407
Epoch:  797        7 Batch loss: 0.239800 Batch F1: 0.16666666666666666
Epoch:  797        8 Batch loss: 0.219934 Batch F1: 0.39999999999999997
Epoch:  797        9 Batch loss: 0.185157 Batch F1: 0.38095238095238093
Epoch:  797       10 Batch loss: 0.209666 Batch F1: 0.3
Epoch:  797       11 Batch loss: 0.213882 Batch F1: 0.4
Epoch:  797       12 Batch loss: 0.236249 Batch F1: 0.1904761904761905
Train Avg Loss  797: 0.222408

Train Avg F1  797: 0.3083359269633779

Val Avg Loss  797: 0.219011

Val Avg F1  797:  0.2619565217391304

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 798
--------------------------------------------------------------
Epoch:  798        1 Batch loss: 0.207243 Batch F1: 0.2
Epoch:  798        2 Batch loss: 0.225772 Batch F1: 0.18181818181818182
Epoch:  798        3 Batch loss: 0.253897 Batch F1: 0.3076923076923077
Epoch:  798        4 Batch loss: 0.216601 Batch F1: 0.37037037037037035
Epoch:  798        5 Batch loss: 0.213479 Batch F1: 0.5142857142857143
Epoch:  798        6 Batch loss: 0.223629 Batch F1: 0.2
Epoch:  798        7 Batch loss: 0.202460 Batch F1: 0.2222222222222222
Epoch:  798        8 Batch loss: 0.234004 Batch F1: 0.0
Epoch:  798        9 Batch loss: 0.214597 Batch F1: 0.0
Epoch:  798       10 Batch loss: 0.262693 Batch F1: 0.07999999999999999
Epoch:  798       11 Batch loss: 0.214257 Batch F1: 0.2608695652173913
Epoch:  798       12 Batch loss: 0.205296 Batch F1: 0.3333333333333333
Train Avg Loss  798: 0.222827

Train Avg F1  798: 0.22254930791162675

Val Avg Loss  798: 0.218223

Val Avg F1  798:  0.2893874643874644

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 799
--------------------------------------------------------------
Epoch:  799        1 Batch loss: 0.231971 Batch F1: 0.28571428571428575
Epoch:  799        2 Batch loss: 0.199725 Batch F1: 0.2105263157894737
Epoch:  799        3 Batch loss: 0.193323 Batch F1: 0.4
Epoch:  799        4 Batch loss: 0.222191 Batch F1: 0.0
Epoch:  799        5 Batch loss: 0.239528 Batch F1: 0.0
Epoch:  799        6 Batch loss: 0.220900 Batch F1: 0.2727272727272727
Epoch:  799        7 Batch loss: 0.216816 Batch F1: 0.17391304347826086
Epoch:  799        8 Batch loss: 0.248695 Batch F1: 0.43749999999999994
Epoch:  799        9 Batch loss: 0.214271 Batch F1: 0.3333333333333333
Epoch:  799       10 Batch loss: 0.207900 Batch F1: 0.31999999999999995
Epoch:  799       11 Batch loss: 0.213901 Batch F1: 0.21052631578947367
Epoch:  799       12 Batch loss: 0.260868 Batch F1: 0.0
Train Avg Loss  799: 0.222507

Train Avg F1  799: 0.2203533805693417

Val Avg Loss  799: 0.217976

Val Avg F1  799:  0.21110983981693365

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 800
--------------------------------------------------------------
Epoch:  800        1 Batch loss: 0.179142 Batch F1: 0.4
Epoch:  800        2 Batch loss: 0.284955 Batch F1: 0.21428571428571425
Epoch:  800        3 Batch loss: 0.194074 Batch F1: 0.2857142857142857
Epoch:  800        4 Batch loss: 0.238208 Batch F1: 0.23076923076923078
Epoch:  800        5 Batch loss: 0.257080 Batch F1: 0.15384615384615385
Epoch:  800        6 Batch loss: 0.215361 Batch F1: 0.3478260869565218
Epoch:  800        7 Batch loss: 0.177664 Batch F1: 0.4210526315789473
Epoch:  800        8 Batch loss: 0.235422 Batch F1: 0.35714285714285715
Epoch:  800        9 Batch loss: 0.180560 Batch F1: 0.3
Epoch:  800       10 Batch loss: 0.231086 Batch F1: 0.09090909090909091
Epoch:  800       11 Batch loss: 0.227284 Batch F1: 0.0
Epoch:  800       12 Batch loss: 0.250778 Batch F1: 0.0
Train Avg Loss  800: 0.222635

Train Avg F1  800: 0.23346217093356678

Val Avg Loss  800: 0.217415

Val Avg F1  800:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 801
--------------------------------------------------------------
Epoch:  801        1 Batch loss: 0.256465 Batch F1: 0.0
Epoch:  801        2 Batch loss: 0.222092 Batch F1: 0.0
Epoch:  801        3 Batch loss: 0.224029 Batch F1: 0.31999999999999995
Epoch:  801        4 Batch loss: 0.231984 Batch F1: 0.09090909090909091
Epoch:  801        5 Batch loss: 0.229470 Batch F1: 0.35714285714285715
Epoch:  801        6 Batch loss: 0.230527 Batch F1: 0.5882352941176471
Epoch:  801        7 Batch loss: 0.240781 Batch F1: 0.16666666666666666
Epoch:  801        8 Batch loss: 0.217676 Batch F1: 0.3870967741935484
Epoch:  801        9 Batch loss: 0.200844 Batch F1: 0.2857142857142857
Epoch:  801       10 Batch loss: 0.172396 Batch F1: 0.23529411764705882
Epoch:  801       11 Batch loss: 0.203004 Batch F1: 0.0
Epoch:  801       12 Batch loss: 0.272924 Batch F1: 0.0
Train Avg Loss  801: 0.225183

Train Avg F1  801: 0.20258825719926288

Val Avg Loss  801: 0.218409

Val Avg F1  801:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 802
--------------------------------------------------------------
Epoch:  802        1 Batch loss: 0.252529 Batch F1: 0.0
Epoch:  802        2 Batch loss: 0.204727 Batch F1: 0.0
Epoch:  802        3 Batch loss: 0.184498 Batch F1: 0.0
Epoch:  802        4 Batch loss: 0.244591 Batch F1: 0.0
Epoch:  802        5 Batch loss: 0.234147 Batch F1: 0.0
Epoch:  802        6 Batch loss: 0.212423 Batch F1: 0.0
Epoch:  802        7 Batch loss: 0.236857 Batch F1: 0.0
Epoch:  802        8 Batch loss: 0.232483 Batch F1: 0.09090909090909091
Epoch:  802        9 Batch loss: 0.205222 Batch F1: 0.3
Epoch:  802       10 Batch loss: 0.245435 Batch F1: 0.28571428571428575
Epoch:  802       11 Batch loss: 0.230126 Batch F1: 0.1904761904761905
Epoch:  802       12 Batch loss: 0.196184 Batch F1: 0.4347826086956522
Train Avg Loss  802: 0.223268

Train Avg F1  802: 0.10849018131626827

Val Avg Loss  802: 0.219829

Val Avg F1  802:  0.26659843779409

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 803
--------------------------------------------------------------
Epoch:  803        1 Batch loss: 0.195732 Batch F1: 0.3157894736842105
Epoch:  803        2 Batch loss: 0.235013 Batch F1: 0.3846153846153846
Epoch:  803        3 Batch loss: 0.217239 Batch F1: 0.4615384615384615
Epoch:  803        4 Batch loss: 0.251637 Batch F1: 0.22222222222222218
Epoch:  803        5 Batch loss: 0.246749 Batch F1: 0.19354838709677416
Epoch:  803        6 Batch loss: 0.188706 Batch F1: 0.3157894736842105
Epoch:  803        7 Batch loss: 0.209617 Batch F1: 0.3478260869565218
Epoch:  803        8 Batch loss: 0.207166 Batch F1: 0.0
Epoch:  803        9 Batch loss: 0.242500 Batch F1: 0.0
Epoch:  803       10 Batch loss: 0.247249 Batch F1: 0.0
Epoch:  803       11 Batch loss: 0.222734 Batch F1: 0.0
Epoch:  803       12 Batch loss: 0.210302 Batch F1: 0.28571428571428575
Train Avg Loss  803: 0.222887

Train Avg F1  803: 0.2105869812926726

Val Avg Loss  803: 0.220565

Val Avg F1  803:  0.2562166718838383

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 804
--------------------------------------------------------------
Epoch:  804        1 Batch loss: 0.202762 Batch F1: 0.43478260869565216
Epoch:  804        2 Batch loss: 0.198228 Batch F1: 0.4166666666666667
Epoch:  804        3 Batch loss: 0.220902 Batch F1: 0.24000000000000002
Epoch:  804        4 Batch loss: 0.260875 Batch F1: 0.3333333333333333
Epoch:  804        5 Batch loss: 0.228363 Batch F1: 0.5161290322580644
Epoch:  804        6 Batch loss: 0.231842 Batch F1: 0.2962962962962963
Epoch:  804        7 Batch loss: 0.239460 Batch F1: 0.4666666666666667
Epoch:  804        8 Batch loss: 0.234264 Batch F1: 0.24
Epoch:  804        9 Batch loss: 0.211990 Batch F1: 0.27272727272727276
Epoch:  804       10 Batch loss: 0.214163 Batch F1: 0.0
Epoch:  804       11 Batch loss: 0.263161 Batch F1: 0.0
Epoch:  804       12 Batch loss: 0.175031 Batch F1: 0.0
Train Avg Loss  804: 0.223420

Train Avg F1  804: 0.26805015638699603

Val Avg Loss  804: 0.219389

Val Avg F1  804:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 805
--------------------------------------------------------------
Epoch:  805        1 Batch loss: 0.236207 Batch F1: 0.0
Epoch:  805        2 Batch loss: 0.214357 Batch F1: 0.0
Epoch:  805        3 Batch loss: 0.237900 Batch F1: 0.0
Epoch:  805        4 Batch loss: 0.230683 Batch F1: 0.0
Epoch:  805        5 Batch loss: 0.230198 Batch F1: 0.0
Epoch:  805        6 Batch loss: 0.238245 Batch F1: 0.0
Epoch:  805        7 Batch loss: 0.208382 Batch F1: 0.0
Epoch:  805        8 Batch loss: 0.233277 Batch F1: 0.0
Epoch:  805        9 Batch loss: 0.219182 Batch F1: 0.19047619047619047
Epoch:  805       10 Batch loss: 0.200613 Batch F1: 0.5
Epoch:  805       11 Batch loss: 0.250270 Batch F1: 0.4
Epoch:  805       12 Batch loss: 0.210429 Batch F1: 0.0
Train Avg Loss  805: 0.225812

Train Avg F1  805: 0.09087301587301588

Val Avg Loss  805: 0.218235

Val Avg F1  805:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 806
--------------------------------------------------------------
Epoch:  806        1 Batch loss: 0.238171 Batch F1: 0.0
Epoch:  806        2 Batch loss: 0.244701 Batch F1: 0.3448275862068965
Epoch:  806        3 Batch loss: 0.223162 Batch F1: 0.31999999999999995
Epoch:  806        4 Batch loss: 0.223343 Batch F1: 0.32
Epoch:  806        5 Batch loss: 0.258886 Batch F1: 0.3125
Epoch:  806        6 Batch loss: 0.207975 Batch F1: 0.5
Epoch:  806        7 Batch loss: 0.206596 Batch F1: 0.5999999999999999
Epoch:  806        8 Batch loss: 0.203976 Batch F1: 0.38095238095238093
Epoch:  806        9 Batch loss: 0.230649 Batch F1: 0.34782608695652173
Epoch:  806       10 Batch loss: 0.226426 Batch F1: 0.0
Epoch:  806       11 Batch loss: 0.188153 Batch F1: 0.0
Epoch:  806       12 Batch loss: 0.220564 Batch F1: 0.0
Train Avg Loss  806: 0.222717

Train Avg F1  806: 0.26050883784298323

Val Avg Loss  806: 0.217109

Val Avg F1  806:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 807
--------------------------------------------------------------
Epoch:  807        1 Batch loss: 0.179823 Batch F1: 0.0
Epoch:  807        2 Batch loss: 0.238080 Batch F1: 0.0
Epoch:  807        3 Batch loss: 0.213668 Batch F1: 0.0
Epoch:  807        4 Batch loss: 0.233928 Batch F1: 0.0
Epoch:  807        5 Batch loss: 0.255017 Batch F1: 0.0
Epoch:  807        6 Batch loss: 0.208625 Batch F1: 0.0
Epoch:  807        7 Batch loss: 0.217024 Batch F1: 0.0
Epoch:  807        8 Batch loss: 0.229919 Batch F1: 0.2608695652173913
Epoch:  807        9 Batch loss: 0.231253 Batch F1: 0.4
Epoch:  807       10 Batch loss: 0.209937 Batch F1: 0.39999999999999997
Epoch:  807       11 Batch loss: 0.228748 Batch F1: 0.41379310344827586
Epoch:  807       12 Batch loss: 0.254746 Batch F1: 0.23076923076923075
Train Avg Loss  807: 0.225064

Train Avg F1  807: 0.14211932495290816

Val Avg Loss  807: 0.220283

Val Avg F1  807:  0.25786697560310756

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 808
--------------------------------------------------------------
Epoch:  808        1 Batch loss: 0.242085 Batch F1: 0.27586206896551724
Epoch:  808        2 Batch loss: 0.206403 Batch F1: 0.2727272727272727
Epoch:  808        3 Batch loss: 0.223279 Batch F1: 0.26086956521739135
Epoch:  808        4 Batch loss: 0.251698 Batch F1: 0.0
Epoch:  808        5 Batch loss: 0.188154 Batch F1: 0.13333333333333333
Epoch:  808        6 Batch loss: 0.224339 Batch F1: 0.0
Epoch:  808        7 Batch loss: 0.213612 Batch F1: 0.0
Epoch:  808        8 Batch loss: 0.211420 Batch F1: 0.0
Epoch:  808        9 Batch loss: 0.210870 Batch F1: 0.0
Epoch:  808       10 Batch loss: 0.229055 Batch F1: 0.0909090909090909
Epoch:  808       11 Batch loss: 0.253750 Batch F1: 0.27586206896551724
Epoch:  808       12 Batch loss: 0.224374 Batch F1: 0.2857142857142857
Train Avg Loss  808: 0.223253

Train Avg F1  808: 0.1329398071527007

Val Avg Loss  808: 0.220254

Val Avg F1  808:  0.2630952380952381

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 809
--------------------------------------------------------------
Epoch:  809        1 Batch loss: 0.199531 Batch F1: 0.5
Epoch:  809        2 Batch loss: 0.289049 Batch F1: 0.2777777777777778
Epoch:  809        3 Batch loss: 0.207361 Batch F1: 0.3157894736842105
Epoch:  809        4 Batch loss: 0.192185 Batch F1: 0.5833333333333334
Epoch:  809        5 Batch loss: 0.233063 Batch F1: 0.23076923076923075
Epoch:  809        6 Batch loss: 0.239665 Batch F1: 0.0
Epoch:  809        7 Batch loss: 0.204483 Batch F1: 0.0
Epoch:  809        8 Batch loss: 0.173837 Batch F1: 0.0
Epoch:  809        9 Batch loss: 0.259068 Batch F1: 0.0
Epoch:  809       10 Batch loss: 0.259931 Batch F1: 0.0
Epoch:  809       11 Batch loss: 0.239358 Batch F1: 0.08695652173913045
Epoch:  809       12 Batch loss: 0.202158 Batch F1: 0.13333333333333336
Train Avg Loss  809: 0.224974

Train Avg F1  809: 0.1773299725530847

Val Avg Loss  809: 0.219390

Val Avg F1  809:  0.2506835269993165

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 810
--------------------------------------------------------------
Epoch:  810        1 Batch loss: 0.191247 Batch F1: 0.56
Epoch:  810        2 Batch loss: 0.255844 Batch F1: 0.35714285714285715
Epoch:  810        3 Batch loss: 0.254132 Batch F1: 0.3636363636363636
Epoch:  810        4 Batch loss: 0.244114 Batch F1: 0.5555555555555556
Epoch:  810        5 Batch loss: 0.240450 Batch F1: 0.43243243243243246
Epoch:  810        6 Batch loss: 0.196940 Batch F1: 0.4347826086956522
Epoch:  810        7 Batch loss: 0.199849 Batch F1: 0.2222222222222222
Epoch:  810        8 Batch loss: 0.205931 Batch F1: 0.0
Epoch:  810        9 Batch loss: 0.248384 Batch F1: 0.0
Epoch:  810       10 Batch loss: 0.212360 Batch F1: 0.0
Epoch:  810       11 Batch loss: 0.228370 Batch F1: 0.0
Epoch:  810       12 Batch loss: 0.239724 Batch F1: 0.0
Train Avg Loss  810: 0.226445

Train Avg F1  810: 0.24381433664042362

Val Avg Loss  810: 0.218240

Val Avg F1  810:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 811
--------------------------------------------------------------
Epoch:  811        1 Batch loss: 0.238429 Batch F1: 0.0
Epoch:  811        2 Batch loss: 0.275039 Batch F1: 0.0
Epoch:  811        3 Batch loss: 0.217225 Batch F1: 0.0
Epoch:  811        4 Batch loss: 0.224354 Batch F1: 0.23076923076923078
Epoch:  811        5 Batch loss: 0.232387 Batch F1: 0.5714285714285715
Epoch:  811        6 Batch loss: 0.216078 Batch F1: 0.3333333333333333
Epoch:  811        7 Batch loss: 0.244136 Batch F1: 0.27586206896551724
Epoch:  811        8 Batch loss: 0.227399 Batch F1: 0.16666666666666666
Epoch:  811        9 Batch loss: 0.210927 Batch F1: 0.3846153846153846
Epoch:  811       10 Batch loss: 0.192095 Batch F1: 0.26666666666666666
Epoch:  811       11 Batch loss: 0.224799 Batch F1: 0.0
Epoch:  811       12 Batch loss: 0.227407 Batch F1: 0.0
Train Avg Loss  811: 0.227523

Train Avg F1  811: 0.18577849353711426

Val Avg Loss  811: 0.219264

Val Avg F1  811:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 812
--------------------------------------------------------------
Epoch:  812        1 Batch loss: 0.242733 Batch F1: 0.0
Epoch:  812        2 Batch loss: 0.221446 Batch F1: 0.0
Epoch:  812        3 Batch loss: 0.223353 Batch F1: 0.0
Epoch:  812        4 Batch loss: 0.208723 Batch F1: 0.0
Epoch:  812        5 Batch loss: 0.217252 Batch F1: 0.0
Epoch:  812        6 Batch loss: 0.224624 Batch F1: 0.0
Epoch:  812        7 Batch loss: 0.205677 Batch F1: 0.0
Epoch:  812        8 Batch loss: 0.184508 Batch F1: 0.0
Epoch:  812        9 Batch loss: 0.254746 Batch F1: 0.0
Epoch:  812       10 Batch loss: 0.238929 Batch F1: 0.0
Epoch:  812       11 Batch loss: 0.254409 Batch F1: 0.0
Epoch:  812       12 Batch loss: 0.243057 Batch F1: 0.0
Train Avg Loss  812: 0.226622

Train Avg F1  812: 0.0

Val Avg Loss  812: 0.224992

Val Avg F1  812:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 813
--------------------------------------------------------------
Epoch:  813        1 Batch loss: 0.225947 Batch F1: 0.0
Epoch:  813        2 Batch loss: 0.244354 Batch F1: 0.08695652173913045
Epoch:  813        3 Batch loss: 0.254711 Batch F1: 0.07407407407407407
Epoch:  813        4 Batch loss: 0.219434 Batch F1: 0.0
Epoch:  813        5 Batch loss: 0.236482 Batch F1: 0.0
Epoch:  813        6 Batch loss: 0.212806 Batch F1: 0.13333333333333333
Epoch:  813        7 Batch loss: 0.208835 Batch F1: 0.0
Epoch:  813        8 Batch loss: 0.195264 Batch F1: 0.0
Epoch:  813        9 Batch loss: 0.217192 Batch F1: 0.0
Epoch:  813       10 Batch loss: 0.233684 Batch F1: 0.09523809523809525
Epoch:  813       11 Batch loss: 0.224293 Batch F1: 0.0
Epoch:  813       12 Batch loss: 0.219177 Batch F1: 0.0
Train Avg Loss  813: 0.224348

Train Avg F1  813: 0.03246683536538609

Val Avg Loss  813: 0.218581

Val Avg F1  813:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 814
--------------------------------------------------------------
Epoch:  814        1 Batch loss: 0.218404 Batch F1: 0.0
Epoch:  814        2 Batch loss: 0.178557 Batch F1: 0.125
Epoch:  814        3 Batch loss: 0.208843 Batch F1: 0.09523809523809523
Epoch:  814        4 Batch loss: 0.211466 Batch F1: 0.1739130434782609
Epoch:  814        5 Batch loss: 0.235859 Batch F1: 0.3703703703703704
Epoch:  814        6 Batch loss: 0.190566 Batch F1: 0.2
Epoch:  814        7 Batch loss: 0.196641 Batch F1: 0.31578947368421056
Epoch:  814        8 Batch loss: 0.258681 Batch F1: 0.0
Epoch:  814        9 Batch loss: 0.248050 Batch F1: 0.0
Epoch:  814       10 Batch loss: 0.233152 Batch F1: 0.24
Epoch:  814       11 Batch loss: 0.248327 Batch F1: 0.24
Epoch:  814       12 Batch loss: 0.251017 Batch F1: 0.39999999999999997
Train Avg Loss  814: 0.223297

Train Avg F1  814: 0.1800259152309114

Val Avg Loss  814: 0.225690

Val Avg F1  814:  0.3408333333333333

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 815
--------------------------------------------------------------
Epoch:  815        1 Batch loss: 0.233074 Batch F1: 0.41379310344827586
Epoch:  815        2 Batch loss: 0.213203 Batch F1: 0.5454545454545454
Epoch:  815        3 Batch loss: 0.243248 Batch F1: 0.4864864864864865
Epoch:  815        4 Batch loss: 0.228249 Batch F1: 0.5806451612903226
Epoch:  815        5 Batch loss: 0.239254 Batch F1: 0.2758620689655172
Epoch:  815        6 Batch loss: 0.241463 Batch F1: 0.24
Epoch:  815        7 Batch loss: 0.246896 Batch F1: 0.35714285714285715
Epoch:  815        8 Batch loss: 0.191468 Batch F1: 0.0
Epoch:  815        9 Batch loss: 0.227743 Batch F1: 0.0
Epoch:  815       10 Batch loss: 0.257487 Batch F1: 0.0
Epoch:  815       11 Batch loss: 0.170537 Batch F1: 0.0
Epoch:  815       12 Batch loss: 0.200237 Batch F1: 0.0
Train Avg Loss  815: 0.224405

Train Avg F1  815: 0.2416153518990004

Val Avg Loss  815: 0.218231

Val Avg F1  815:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 816
--------------------------------------------------------------
Epoch:  816        1 Batch loss: 0.177081 Batch F1: 0.0
Epoch:  816        2 Batch loss: 0.226368 Batch F1: 0.0
Epoch:  816        3 Batch loss: 0.219960 Batch F1: 0.0
Epoch:  816        4 Batch loss: 0.206340 Batch F1: 0.0
Epoch:  816        5 Batch loss: 0.218458 Batch F1: 0.0
Epoch:  816        6 Batch loss: 0.242880 Batch F1: 0.0
Epoch:  816        7 Batch loss: 0.256026 Batch F1: 0.0
Epoch:  816        8 Batch loss: 0.219324 Batch F1: 0.08695652173913045
Epoch:  816        9 Batch loss: 0.231954 Batch F1: 0.3076923076923077
Epoch:  816       10 Batch loss: 0.232190 Batch F1: 0.39999999999999997
Epoch:  816       11 Batch loss: 0.229062 Batch F1: 0.4166666666666667
Epoch:  816       12 Batch loss: 0.239301 Batch F1: 0.2
Train Avg Loss  816: 0.224912

Train Avg F1  816: 0.11760962467484205

Val Avg Loss  816: 0.223795

Val Avg F1  816:  0.3213891842924101

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 817
--------------------------------------------------------------
Epoch:  817        1 Batch loss: 0.241970 Batch F1: 0.39999999999999997
Epoch:  817        2 Batch loss: 0.220480 Batch F1: 0.48275862068965514
Epoch:  817        3 Batch loss: 0.213981 Batch F1: 0.25
Epoch:  817        4 Batch loss: 0.181592 Batch F1: 0.16666666666666669
Epoch:  817        5 Batch loss: 0.255925 Batch F1: 0.0
Epoch:  817        6 Batch loss: 0.229480 Batch F1: 0.0
Epoch:  817        7 Batch loss: 0.230473 Batch F1: 0.0
Epoch:  817        8 Batch loss: 0.246186 Batch F1: 0.0
Epoch:  817        9 Batch loss: 0.189300 Batch F1: 0.0
Epoch:  817       10 Batch loss: 0.230405 Batch F1: 0.0
Epoch:  817       11 Batch loss: 0.206959 Batch F1: 0.5
Epoch:  817       12 Batch loss: 0.250685 Batch F1: 0.2608695652173913
Train Avg Loss  817: 0.224786

Train Avg F1  817: 0.1716912377144761

Val Avg Loss  817: 0.222482

Val Avg F1  817:  0.34213471713471716

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 818
--------------------------------------------------------------
Epoch:  818        1 Batch loss: 0.243341 Batch F1: 0.24999999999999997
Epoch:  818        2 Batch loss: 0.221255 Batch F1: 0.3
Epoch:  818        3 Batch loss: 0.243025 Batch F1: 0.2857142857142857
Epoch:  818        4 Batch loss: 0.234945 Batch F1: 0.3225806451612903
Epoch:  818        5 Batch loss: 0.227589 Batch F1: 0.4
Epoch:  818        6 Batch loss: 0.210314 Batch F1: 0.2608695652173913
Epoch:  818        7 Batch loss: 0.211847 Batch F1: 0.32
Epoch:  818        8 Batch loss: 0.217431 Batch F1: 0.3478260869565218
Epoch:  818        9 Batch loss: 0.240491 Batch F1: 0.35714285714285715
Epoch:  818       10 Batch loss: 0.233873 Batch F1: 0.22222222222222218
Epoch:  818       11 Batch loss: 0.170625 Batch F1: 0.4210526315789474
Epoch:  818       12 Batch loss: 0.221353 Batch F1: 0.3809523809523809
Train Avg Loss  818: 0.223007

Train Avg F1  818: 0.32236338957882477

Val Avg Loss  818: 0.219508

Val Avg F1  818:  0.24481673636865778

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 819
--------------------------------------------------------------
Epoch:  819        1 Batch loss: 0.214338 Batch F1: 0.4285714285714285
Epoch:  819        2 Batch loss: 0.220248 Batch F1: 0.18181818181818182
Epoch:  819        3 Batch loss: 0.199411 Batch F1: 0.46153846153846156
Epoch:  819        4 Batch loss: 0.232956 Batch F1: 0.16
Epoch:  819        5 Batch loss: 0.203464 Batch F1: 0.43478260869565216
Epoch:  819        6 Batch loss: 0.262044 Batch F1: 0.15384615384615385
Epoch:  819        7 Batch loss: 0.212109 Batch F1: 0.4444444444444445
Epoch:  819        8 Batch loss: 0.213053 Batch F1: 0.3478260869565218
Epoch:  819        9 Batch loss: 0.223061 Batch F1: 0.1111111111111111
Epoch:  819       10 Batch loss: 0.227615 Batch F1: 0.24999999999999997
Epoch:  819       11 Batch loss: 0.212494 Batch F1: 0.21052631578947367
Epoch:  819       12 Batch loss: 0.243621 Batch F1: 0.37037037037037035
Train Avg Loss  819: 0.222035

Train Avg F1  819: 0.29623626359514993

Val Avg Loss  819: 0.218703

Val Avg F1  819:  0.26022727272727275

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 820
--------------------------------------------------------------
Epoch:  820        1 Batch loss: 0.243170 Batch F1: 0.4
Epoch:  820        2 Batch loss: 0.180643 Batch F1: 0.380952380952381
Epoch:  820        3 Batch loss: 0.232872 Batch F1: 0.4444444444444444
Epoch:  820        4 Batch loss: 0.222395 Batch F1: 0.24
Epoch:  820        5 Batch loss: 0.236486 Batch F1: 0.1818181818181818
Epoch:  820        6 Batch loss: 0.195175 Batch F1: 0.19047619047619047
Epoch:  820        7 Batch loss: 0.246961 Batch F1: 0.16000000000000003
Epoch:  820        8 Batch loss: 0.225441 Batch F1: 0.19999999999999998
Epoch:  820        9 Batch loss: 0.224474 Batch F1: 0.5
Epoch:  820       10 Batch loss: 0.203110 Batch F1: 0.36363636363636365
Epoch:  820       11 Batch loss: 0.235044 Batch F1: 0.2608695652173913
Epoch:  820       12 Batch loss: 0.218371 Batch F1: 0.36363636363636365
Train Avg Loss  820: 0.222012

Train Avg F1  820: 0.30715279084844305

Val Avg Loss  820: 0.218876

Val Avg F1  820:  0.24788359788359787

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 821
--------------------------------------------------------------
Epoch:  821        1 Batch loss: 0.216051 Batch F1: 0.3333333333333333
Epoch:  821        2 Batch loss: 0.257305 Batch F1: 0.2
Epoch:  821        3 Batch loss: 0.232061 Batch F1: 0.3448275862068966
Epoch:  821        4 Batch loss: 0.212669 Batch F1: 0.32
Epoch:  821        5 Batch loss: 0.240825 Batch F1: 0.26086956521739135
Epoch:  821        6 Batch loss: 0.215066 Batch F1: 0.1739130434782609
Epoch:  821        7 Batch loss: 0.215658 Batch F1: 0.27272727272727276
Epoch:  821        8 Batch loss: 0.201360 Batch F1: 0.3
Epoch:  821        9 Batch loss: 0.197887 Batch F1: 0.5217391304347826
Epoch:  821       10 Batch loss: 0.190028 Batch F1: 0.23529411764705882
Epoch:  821       11 Batch loss: 0.237099 Batch F1: 0.0
Epoch:  821       12 Batch loss: 0.257518 Batch F1: 0.0
Train Avg Loss  821: 0.222794

Train Avg F1  821: 0.24689200408708303

Val Avg Loss  821: 0.218255

Val Avg F1  821:  0.21994565217391304

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 822
--------------------------------------------------------------
Epoch:  822        1 Batch loss: 0.273222 Batch F1: 0.21428571428571425
Epoch:  822        2 Batch loss: 0.222911 Batch F1: 0.1739130434782609
Epoch:  822        3 Batch loss: 0.203268 Batch F1: 0.3703703703703704
Epoch:  822        4 Batch loss: 0.224948 Batch F1: 0.4666666666666667
Epoch:  822        5 Batch loss: 0.189156 Batch F1: 0.64
Epoch:  822        6 Batch loss: 0.210437 Batch F1: 0.4545454545454546
Epoch:  822        7 Batch loss: 0.230369 Batch F1: 0.25
Epoch:  822        8 Batch loss: 0.228474 Batch F1: 0.3448275862068965
Epoch:  822        9 Batch loss: 0.211442 Batch F1: 0.0
Epoch:  822       10 Batch loss: 0.225085 Batch F1: 0.0909090909090909
Epoch:  822       11 Batch loss: 0.205573 Batch F1: 0.10526315789473684
Epoch:  822       12 Batch loss: 0.252666 Batch F1: 0.1
Train Avg Loss  822: 0.223129

Train Avg F1  822: 0.2675650903630992

Val Avg Loss  822: 0.218537

Val Avg F1  822:  0.26275450331514405

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 823
--------------------------------------------------------------
Epoch:  823        1 Batch loss: 0.232927 Batch F1: 0.32
Epoch:  823        2 Batch loss: 0.241740 Batch F1: 0.37500000000000006
Epoch:  823        3 Batch loss: 0.210200 Batch F1: 0.5925925925925926
Epoch:  823        4 Batch loss: 0.237914 Batch F1: 0.16
Epoch:  823        5 Batch loss: 0.182421 Batch F1: 0.3809523809523809
Epoch:  823        6 Batch loss: 0.209977 Batch F1: 0.0
Epoch:  823        7 Batch loss: 0.229840 Batch F1: 0.0
Epoch:  823        8 Batch loss: 0.217379 Batch F1: 0.0
Epoch:  823        9 Batch loss: 0.208227 Batch F1: 0.0
Epoch:  823       10 Batch loss: 0.256512 Batch F1: 0.0
Epoch:  823       11 Batch loss: 0.205875 Batch F1: 0.0
Epoch:  823       12 Batch loss: 0.246225 Batch F1: 0.0
Train Avg Loss  823: 0.223270

Train Avg F1  823: 0.15237874779541447

Val Avg Loss  823: 0.219275

Val Avg F1  823:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 824
--------------------------------------------------------------
Epoch:  824        1 Batch loss: 0.211389 Batch F1: 0.1904761904761905
Epoch:  824        2 Batch loss: 0.246174 Batch F1: 0.14814814814814814
Epoch:  824        3 Batch loss: 0.211787 Batch F1: 0.5
Epoch:  824        4 Batch loss: 0.227152 Batch F1: 0.3333333333333333
Epoch:  824        5 Batch loss: 0.217648 Batch F1: 0.5161290322580645
Epoch:  824        6 Batch loss: 0.249235 Batch F1: 0.23076923076923078
Epoch:  824        7 Batch loss: 0.208495 Batch F1: 0.3
Epoch:  824        8 Batch loss: 0.187572 Batch F1: 0.33333333333333337
Epoch:  824        9 Batch loss: 0.198599 Batch F1: 0.11764705882352941
Epoch:  824       10 Batch loss: 0.241558 Batch F1: 0.24
Epoch:  824       11 Batch loss: 0.250561 Batch F1: 0.22222222222222218
Epoch:  824       12 Batch loss: 0.222312 Batch F1: 0.21052631578947367
Train Avg Loss  824: 0.222707

Train Avg F1  824: 0.27854873876279385

Val Avg Loss  824: 0.218041

Val Avg F1  824:  0.20790043290043292

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 825
--------------------------------------------------------------
Epoch:  825        1 Batch loss: 0.249571 Batch F1: 0.0909090909090909
Epoch:  825        2 Batch loss: 0.179411 Batch F1: 0.3529411764705882
Epoch:  825        3 Batch loss: 0.213883 Batch F1: 0.09523809523809525
Epoch:  825        4 Batch loss: 0.214313 Batch F1: 0.0
Epoch:  825        5 Batch loss: 0.212012 Batch F1: 0.0
Epoch:  825        6 Batch loss: 0.224675 Batch F1: 0.25
Epoch:  825        7 Batch loss: 0.244643 Batch F1: 0.25
Epoch:  825        8 Batch loss: 0.227317 Batch F1: 0.35714285714285715
Epoch:  825        9 Batch loss: 0.235813 Batch F1: 0.23076923076923073
Epoch:  825       10 Batch loss: 0.268177 Batch F1: 0.27586206896551724
Epoch:  825       11 Batch loss: 0.201083 Batch F1: 0.21052631578947367
Epoch:  825       12 Batch loss: 0.184684 Batch F1: 0.4
Train Avg Loss  825: 0.221299

Train Avg F1  825: 0.2094490696070711

Val Avg Loss  825: 0.220183

Val Avg F1  825:  0.268695652173913

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 826
--------------------------------------------------------------
Epoch:  826        1 Batch loss: 0.189148 Batch F1: 0.35294117647058826
Epoch:  826        2 Batch loss: 0.256148 Batch F1: 0.21428571428571427
Epoch:  826        3 Batch loss: 0.220277 Batch F1: 0.37037037037037035
Epoch:  826        4 Batch loss: 0.180627 Batch F1: 0.5
Epoch:  826        5 Batch loss: 0.224992 Batch F1: 0.17391304347826084
Epoch:  826        6 Batch loss: 0.241340 Batch F1: 0.3870967741935483
Epoch:  826        7 Batch loss: 0.214216 Batch F1: 0.4
Epoch:  826        8 Batch loss: 0.268755 Batch F1: 0.30303030303030304
Epoch:  826        9 Batch loss: 0.237731 Batch F1: 0.2727272727272727
Epoch:  826       10 Batch loss: 0.226013 Batch F1: 0.3333333333333333
Epoch:  826       11 Batch loss: 0.209467 Batch F1: 0.0
Epoch:  826       12 Batch loss: 0.212476 Batch F1: 0.0
Train Avg Loss  826: 0.223432

Train Avg F1  826: 0.2756414989907826

Val Avg Loss  826: 0.216787

Val Avg F1  826:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 827
--------------------------------------------------------------
Epoch:  827        1 Batch loss: 0.242048 Batch F1: 0.0
Epoch:  827        2 Batch loss: 0.236205 Batch F1: 0.0
Epoch:  827        3 Batch loss: 0.228435 Batch F1: 0.0
Epoch:  827        4 Batch loss: 0.227165 Batch F1: 0.0
Epoch:  827        5 Batch loss: 0.246891 Batch F1: 0.0
Epoch:  827        6 Batch loss: 0.203114 Batch F1: 0.5185185185185185
Epoch:  827        7 Batch loss: 0.236211 Batch F1: 0.19047619047619047
Epoch:  827        8 Batch loss: 0.237066 Batch F1: 0.4117647058823529
Epoch:  827        9 Batch loss: 0.188102 Batch F1: 0.125
Epoch:  827       10 Batch loss: 0.205955 Batch F1: 0.11764705882352941
Epoch:  827       11 Batch loss: 0.247151 Batch F1: 0.0
Epoch:  827       12 Batch loss: 0.205624 Batch F1: 0.0
Train Avg Loss  827: 0.225331

Train Avg F1  827: 0.11361720614171594

Val Avg Loss  827: 0.218186

Val Avg F1  827:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 828
--------------------------------------------------------------
Epoch:  828        1 Batch loss: 0.266824 Batch F1: 0.0
Epoch:  828        2 Batch loss: 0.238333 Batch F1: 0.0
Epoch:  828        3 Batch loss: 0.224062 Batch F1: 0.3846153846153846
Epoch:  828        4 Batch loss: 0.226090 Batch F1: 0.4285714285714285
Epoch:  828        5 Batch loss: 0.197238 Batch F1: 0.38095238095238093
Epoch:  828        6 Batch loss: 0.217817 Batch F1: 0.3846153846153846
Epoch:  828        7 Batch loss: 0.204821 Batch F1: 0.22222222222222224
Epoch:  828        8 Batch loss: 0.185555 Batch F1: 0.0
Epoch:  828        9 Batch loss: 0.265814 Batch F1: 0.0
Epoch:  828       10 Batch loss: 0.238669 Batch F1: 0.0
Epoch:  828       11 Batch loss: 0.241304 Batch F1: 0.0
Epoch:  828       12 Batch loss: 0.169363 Batch F1: 0.5
Train Avg Loss  828: 0.222991

Train Avg F1  828: 0.19174806674806674

Val Avg Loss  828: 0.219099

Val Avg F1  828:  0.2505411255411255

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 829
--------------------------------------------------------------
Epoch:  829        1 Batch loss: 0.205292 Batch F1: 0.4166666666666667
Epoch:  829        2 Batch loss: 0.235775 Batch F1: 0.0909090909090909
Epoch:  829        3 Batch loss: 0.219208 Batch F1: 0.46153846153846156
Epoch:  829        4 Batch loss: 0.232560 Batch F1: 0.21428571428571427
Epoch:  829        5 Batch loss: 0.189230 Batch F1: 0.4166666666666667
Epoch:  829        6 Batch loss: 0.201362 Batch F1: 0.4166666666666667
Epoch:  829        7 Batch loss: 0.237905 Batch F1: 0.42424242424242425
Epoch:  829        8 Batch loss: 0.248587 Batch F1: 0.35714285714285715
Epoch:  829        9 Batch loss: 0.222743 Batch F1: 0.27272727272727276
Epoch:  829       10 Batch loss: 0.246931 Batch F1: 0.26666666666666666
Epoch:  829       11 Batch loss: 0.205846 Batch F1: 0.4
Epoch:  829       12 Batch loss: 0.225377 Batch F1: 0.2
Train Avg Loss  829: 0.222568

Train Avg F1  829: 0.32812604062604067

Val Avg Loss  829: 0.218118

Val Avg F1  829:  0.23188405797101447

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 830
--------------------------------------------------------------
Epoch:  830        1 Batch loss: 0.238720 Batch F1: 0.35714285714285715
Epoch:  830        2 Batch loss: 0.192316 Batch F1: 0.0
Epoch:  830        3 Batch loss: 0.201347 Batch F1: 0.0
Epoch:  830        4 Batch loss: 0.208068 Batch F1: 0.0
Epoch:  830        5 Batch loss: 0.239130 Batch F1: 0.0
Epoch:  830        6 Batch loss: 0.203458 Batch F1: 0.1
Epoch:  830        7 Batch loss: 0.209905 Batch F1: 0.27272727272727276
Epoch:  830        8 Batch loss: 0.250348 Batch F1: 0.3076923076923077
Epoch:  830        9 Batch loss: 0.243059 Batch F1: 0.07692307692307693
Epoch:  830       10 Batch loss: 0.249101 Batch F1: 0.20689655172413793
Epoch:  830       11 Batch loss: 0.213890 Batch F1: 0.4761904761904762
Epoch:  830       12 Batch loss: 0.228063 Batch F1: 0.2857142857142857
Train Avg Loss  830: 0.223117

Train Avg F1  830: 0.1736072356762012

Val Avg Loss  830: 0.219746

Val Avg F1  830:  0.08832565284178186

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 831
--------------------------------------------------------------
Epoch:  831        1 Batch loss: 0.190689 Batch F1: 0.0
Epoch:  831        2 Batch loss: 0.211186 Batch F1: 0.0
Epoch:  831        3 Batch loss: 0.200434 Batch F1: 0.0
Epoch:  831        4 Batch loss: 0.203971 Batch F1: 0.0
Epoch:  831        5 Batch loss: 0.232000 Batch F1: 0.0
Epoch:  831        6 Batch loss: 0.243316 Batch F1: 0.0
Epoch:  831        7 Batch loss: 0.235205 Batch F1: 0.0
Epoch:  831        8 Batch loss: 0.214970 Batch F1: 0.22222222222222224
Epoch:  831        9 Batch loss: 0.260664 Batch F1: 0.13793103448275865
Epoch:  831       10 Batch loss: 0.222824 Batch F1: 0.3478260869565218
Epoch:  831       11 Batch loss: 0.225472 Batch F1: 0.42857142857142855
Epoch:  831       12 Batch loss: 0.240782 Batch F1: 0.5294117647058824
Train Avg Loss  831: 0.223459

Train Avg F1  831: 0.13883021141156782

Val Avg Loss  831: 0.224553

Val Avg F1  831:  0.35190629117259553

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 832
--------------------------------------------------------------
Epoch:  832        1 Batch loss: 0.217304 Batch F1: 0.34782608695652173
Epoch:  832        2 Batch loss: 0.207029 Batch F1: 0.5517241379310345
Epoch:  832        3 Batch loss: 0.244705 Batch F1: 0.5
Epoch:  832        4 Batch loss: 0.256795 Batch F1: 0.27586206896551724
Epoch:  832        5 Batch loss: 0.218462 Batch F1: 0.35714285714285715
Epoch:  832        6 Batch loss: 0.215490 Batch F1: 0.3333333333333333
Epoch:  832        7 Batch loss: 0.237776 Batch F1: 0.3571428571428571
Epoch:  832        8 Batch loss: 0.211316 Batch F1: 0.23529411764705882
Epoch:  832        9 Batch loss: 0.227091 Batch F1: 0.0
Epoch:  832       10 Batch loss: 0.198959 Batch F1: 0.0
Epoch:  832       11 Batch loss: 0.216846 Batch F1: 0.0
Epoch:  832       12 Batch loss: 0.243453 Batch F1: 0.0
Train Avg Loss  832: 0.224602

Train Avg F1  832: 0.24652712159326504

Val Avg Loss  832: 0.217126

Val Avg F1  832:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 833
--------------------------------------------------------------
Epoch:  833        1 Batch loss: 0.195595 Batch F1: 0.0
Epoch:  833        2 Batch loss: 0.259675 Batch F1: 0.19354838709677416
Epoch:  833        3 Batch loss: 0.240307 Batch F1: 0.45161290322580644
Epoch:  833        4 Batch loss: 0.212017 Batch F1: 0.380952380952381
Epoch:  833        5 Batch loss: 0.226326 Batch F1: 0.0
Epoch:  833        6 Batch loss: 0.199677 Batch F1: 0.0
Epoch:  833        7 Batch loss: 0.235112 Batch F1: 0.0
Epoch:  833        8 Batch loss: 0.210677 Batch F1: 0.0
Epoch:  833        9 Batch loss: 0.239361 Batch F1: 0.0
Epoch:  833       10 Batch loss: 0.245720 Batch F1: 0.22222222222222218
Epoch:  833       11 Batch loss: 0.230350 Batch F1: 0.4137931034482759
Epoch:  833       12 Batch loss: 0.212805 Batch F1: 0.5263157894736842
Train Avg Loss  833: 0.225635

Train Avg F1  833: 0.18237039886826198

Val Avg Loss  833: 0.220824

Val Avg F1  833:  0.2513504611330698

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 834
--------------------------------------------------------------
Epoch:  834        1 Batch loss: 0.216029 Batch F1: 0.0
Epoch:  834        2 Batch loss: 0.242945 Batch F1: 0.0
Epoch:  834        3 Batch loss: 0.224278 Batch F1: 0.0
Epoch:  834        4 Batch loss: 0.226216 Batch F1: 0.0
Epoch:  834        5 Batch loss: 0.217605 Batch F1: 0.0
Epoch:  834        6 Batch loss: 0.234377 Batch F1: 0.0
Epoch:  834        7 Batch loss: 0.223286 Batch F1: 0.0
Epoch:  834        8 Batch loss: 0.208873 Batch F1: 0.0
Epoch:  834        9 Batch loss: 0.257942 Batch F1: 0.0
Epoch:  834       10 Batch loss: 0.182625 Batch F1: 0.0
Epoch:  834       11 Batch loss: 0.193065 Batch F1: 0.0
Epoch:  834       12 Batch loss: 0.285101 Batch F1: 0.0
Train Avg Loss  834: 0.226029

Train Avg F1  834: 0.0

Val Avg Loss  834: 0.218046

Val Avg F1  834:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 835
--------------------------------------------------------------
Epoch:  835        1 Batch loss: 0.235247 Batch F1: 0.0
Epoch:  835        2 Batch loss: 0.239264 Batch F1: 0.0
Epoch:  835        3 Batch loss: 0.262276 Batch F1: 0.3225806451612903
Epoch:  835        4 Batch loss: 0.232741 Batch F1: 0.16
Epoch:  835        5 Batch loss: 0.211380 Batch F1: 0.5517241379310345
Epoch:  835        6 Batch loss: 0.221586 Batch F1: 0.625
Epoch:  835        7 Batch loss: 0.219106 Batch F1: 0.4615384615384615
Epoch:  835        8 Batch loss: 0.226305 Batch F1: 0.2857142857142857
Epoch:  835        9 Batch loss: 0.229748 Batch F1: 0.37037037037037035
Epoch:  835       10 Batch loss: 0.212682 Batch F1: 0.46153846153846156
Epoch:  835       11 Batch loss: 0.210617 Batch F1: 0.0
Epoch:  835       12 Batch loss: 0.179401 Batch F1: 0.3333333333333333
Train Avg Loss  835: 0.223363

Train Avg F1  835: 0.2976499746322698

Val Avg Loss  835: 0.218151

Val Avg F1  835:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 836
--------------------------------------------------------------
Epoch:  836        1 Batch loss: 0.227876 Batch F1: 0.0
Epoch:  836        2 Batch loss: 0.239419 Batch F1: 0.0
Epoch:  836        3 Batch loss: 0.201794 Batch F1: 0.21052631578947367
Epoch:  836        4 Batch loss: 0.274198 Batch F1: 0.20689655172413793
Epoch:  836        5 Batch loss: 0.191969 Batch F1: 0.2857142857142857
Epoch:  836        6 Batch loss: 0.253441 Batch F1: 0.14814814814814814
Epoch:  836        7 Batch loss: 0.228417 Batch F1: 0.2962962962962963
Epoch:  836        8 Batch loss: 0.223188 Batch F1: 0.3846153846153846
Epoch:  836        9 Batch loss: 0.219788 Batch F1: 0.19047619047619044
Epoch:  836       10 Batch loss: 0.186200 Batch F1: 0.2
Epoch:  836       11 Batch loss: 0.230520 Batch F1: 0.2962962962962963
Epoch:  836       12 Batch loss: 0.185646 Batch F1: 0.5000000000000001
Train Avg Loss  836: 0.221871

Train Avg F1  836: 0.22658078908835108

Val Avg Loss  836: 0.218687

Val Avg F1  836:  0.26383399209486164

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 837
--------------------------------------------------------------
Epoch:  837        1 Batch loss: 0.194520 Batch F1: 0.21052631578947364
Epoch:  837        2 Batch loss: 0.217693 Batch F1: 0.0
Epoch:  837        3 Batch loss: 0.248982 Batch F1: 0.0
Epoch:  837        4 Batch loss: 0.176192 Batch F1: 0.0
Epoch:  837        5 Batch loss: 0.196947 Batch F1: 0.0
Epoch:  837        6 Batch loss: 0.247973 Batch F1: 0.0
Epoch:  837        7 Batch loss: 0.197594 Batch F1: 0.0
Epoch:  837        8 Batch loss: 0.254061 Batch F1: 0.0
Epoch:  837        9 Batch loss: 0.248091 Batch F1: 0.0
Epoch:  837       10 Batch loss: 0.222789 Batch F1: 0.27272727272727276
Epoch:  837       11 Batch loss: 0.227769 Batch F1: 0.24
Epoch:  837       12 Batch loss: 0.247112 Batch F1: 0.0
Train Avg Loss  837: 0.223310

Train Avg F1  837: 0.06027113237639553

Val Avg Loss  837: 0.218823

Val Avg F1  837:  0.1357323232323232

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 838
--------------------------------------------------------------
Epoch:  838        1 Batch loss: 0.248059 Batch F1: 0.08333333333333334
Epoch:  838        2 Batch loss: 0.218296 Batch F1: 0.19047619047619047
Epoch:  838        3 Batch loss: 0.238851 Batch F1: 0.24999999999999997
Epoch:  838        4 Batch loss: 0.243934 Batch F1: 0.4
Epoch:  838        5 Batch loss: 0.231288 Batch F1: 0.3076923076923077
Epoch:  838        6 Batch loss: 0.223234 Batch F1: 0.38709677419354843
Epoch:  838        7 Batch loss: 0.217244 Batch F1: 0.0
Epoch:  838        8 Batch loss: 0.207730 Batch F1: 0.0
Epoch:  838        9 Batch loss: 0.261309 Batch F1: 0.0
Epoch:  838       10 Batch loss: 0.213214 Batch F1: 0.0
Epoch:  838       11 Batch loss: 0.208522 Batch F1: 0.0
Epoch:  838       12 Batch loss: 0.202790 Batch F1: 0.0
Train Avg Loss  838: 0.226206

Train Avg F1  838: 0.13488321714128168

Val Avg Loss  838: 0.217118

Val Avg F1  838:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 839
--------------------------------------------------------------
Epoch:  839        1 Batch loss: 0.211495 Batch F1: 0.0
Epoch:  839        2 Batch loss: 0.201567 Batch F1: 0.0
Epoch:  839        3 Batch loss: 0.212129 Batch F1: 0.0
Epoch:  839        4 Batch loss: 0.223944 Batch F1: 0.19047619047619047
Epoch:  839        5 Batch loss: 0.244059 Batch F1: 0.45161290322580644
Epoch:  839        6 Batch loss: 0.201999 Batch F1: 0.38095238095238093
Epoch:  839        7 Batch loss: 0.229901 Batch F1: 0.36363636363636365
Epoch:  839        8 Batch loss: 0.225040 Batch F1: 0.3703703703703703
Epoch:  839        9 Batch loss: 0.247645 Batch F1: 0.37499999999999994
Epoch:  839       10 Batch loss: 0.238080 Batch F1: 0.4848484848484849
Epoch:  839       11 Batch loss: 0.200133 Batch F1: 0.2727272727272727
Epoch:  839       12 Batch loss: 0.266094 Batch F1: 0.16
Train Avg Loss  839: 0.225174

Train Avg F1  839: 0.25413533051973913

Val Avg Loss  839: 0.218059

Val Avg F1  839:  0.18813915553045987

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 840
--------------------------------------------------------------
Epoch:  840        1 Batch loss: 0.224550 Batch F1: 0.4
Epoch:  840        2 Batch loss: 0.226979 Batch F1: 0.19047619047619047
Epoch:  840        3 Batch loss: 0.211841 Batch F1: 0.0
Epoch:  840        4 Batch loss: 0.246903 Batch F1: 0.0
Epoch:  840        5 Batch loss: 0.216861 Batch F1: 0.0
Epoch:  840        6 Batch loss: 0.212692 Batch F1: 0.0
Epoch:  840        7 Batch loss: 0.221041 Batch F1: 0.0
Epoch:  840        8 Batch loss: 0.211482 Batch F1: 0.2222222222222222
Epoch:  840        9 Batch loss: 0.216150 Batch F1: 0.0
Epoch:  840       10 Batch loss: 0.222546 Batch F1: 0.0
Epoch:  840       11 Batch loss: 0.213383 Batch F1: 0.0
Epoch:  840       12 Batch loss: 0.247377 Batch F1: 0.10526315789473684
Train Avg Loss  840: 0.222650

Train Avg F1  840: 0.07649679754942913

Val Avg Loss  840: 0.218497

Val Avg F1  840:  0.052777777777777785

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 841
--------------------------------------------------------------
Epoch:  841        1 Batch loss: 0.220349 Batch F1: 0.0
Epoch:  841        2 Batch loss: 0.238443 Batch F1: 0.4
Epoch:  841        3 Batch loss: 0.236654 Batch F1: 0.5
Epoch:  841        4 Batch loss: 0.210852 Batch F1: 0.6
Epoch:  841        5 Batch loss: 0.217199 Batch F1: 0.2222222222222222
Epoch:  841        6 Batch loss: 0.223661 Batch F1: 0.10526315789473684
Epoch:  841        7 Batch loss: 0.213674 Batch F1: 0.4166666666666667
Epoch:  841        8 Batch loss: 0.238965 Batch F1: 0.20689655172413793
Epoch:  841        9 Batch loss: 0.230678 Batch F1: 0.16666666666666666
Epoch:  841       10 Batch loss: 0.204151 Batch F1: 0.4166666666666667
Epoch:  841       11 Batch loss: 0.220020 Batch F1: 0.19047619047619047
Epoch:  841       12 Batch loss: 0.213893 Batch F1: 0.23529411764705882
Train Avg Loss  841: 0.222378

Train Avg F1  841: 0.28834601999702886

Val Avg Loss  841: 0.217970

Val Avg F1  841:  0.2234677087618264

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 842
--------------------------------------------------------------
Epoch:  842        1 Batch loss: 0.216212 Batch F1: 0.19047619047619047
Epoch:  842        2 Batch loss: 0.229784 Batch F1: 0.0
Epoch:  842        3 Batch loss: 0.218971 Batch F1: 0.0
Epoch:  842        4 Batch loss: 0.210776 Batch F1: 0.0
Epoch:  842        5 Batch loss: 0.248296 Batch F1: 0.0
Epoch:  842        6 Batch loss: 0.276407 Batch F1: 0.0
Epoch:  842        7 Batch loss: 0.227732 Batch F1: 0.0
Epoch:  842        8 Batch loss: 0.213184 Batch F1: 0.41666666666666663
Epoch:  842        9 Batch loss: 0.203555 Batch F1: 0.3636363636363636
Epoch:  842       10 Batch loss: 0.218118 Batch F1: 0.5333333333333333
Epoch:  842       11 Batch loss: 0.212784 Batch F1: 0.1
Epoch:  842       12 Batch loss: 0.207040 Batch F1: 0.0
Train Avg Loss  842: 0.223572

Train Avg F1  842: 0.1336760461760462

Val Avg Loss  842: 0.219475

Val Avg F1  842:  0.25173611111111116

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 843
--------------------------------------------------------------
Epoch:  843        1 Batch loss: 0.241208 Batch F1: 0.4137931034482759
Epoch:  843        2 Batch loss: 0.213492 Batch F1: 0.2222222222222222
Epoch:  843        3 Batch loss: 0.212435 Batch F1: 0.1
Epoch:  843        4 Batch loss: 0.262741 Batch F1: 0.0
Epoch:  843        5 Batch loss: 0.233710 Batch F1: 0.08695652173913045
Epoch:  843        6 Batch loss: 0.180283 Batch F1: 0.608695652173913
Epoch:  843        7 Batch loss: 0.219918 Batch F1: 0.1818181818181818
Epoch:  843        8 Batch loss: 0.229840 Batch F1: 0.0
Epoch:  843        9 Batch loss: 0.228544 Batch F1: 0.4615384615384615
Epoch:  843       10 Batch loss: 0.192811 Batch F1: 0.25
Epoch:  843       11 Batch loss: 0.225289 Batch F1: 0.3125
Epoch:  843       12 Batch loss: 0.231649 Batch F1: 0.34782608695652173
Train Avg Loss  843: 0.222660

Train Avg F1  843: 0.24877918582472555

Val Avg Loss  843: 0.218980

Val Avg F1  843:  0.2601851851851852

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 844
--------------------------------------------------------------
Epoch:  844        1 Batch loss: 0.213718 Batch F1: 0.39999999999999997
Epoch:  844        2 Batch loss: 0.223278 Batch F1: 0.4
Epoch:  844        3 Batch loss: 0.229579 Batch F1: 0.24
Epoch:  844        4 Batch loss: 0.229258 Batch F1: 0.23076923076923078
Epoch:  844        5 Batch loss: 0.207018 Batch F1: 0.48
Epoch:  844        6 Batch loss: 0.183497 Batch F1: 0.5714285714285715
Epoch:  844        7 Batch loss: 0.220202 Batch F1: 0.37037037037037035
Epoch:  844        8 Batch loss: 0.216052 Batch F1: 0.2
Epoch:  844        9 Batch loss: 0.241371 Batch F1: 0.0
Epoch:  844       10 Batch loss: 0.242455 Batch F1: 0.0
Epoch:  844       11 Batch loss: 0.257243 Batch F1: 0.0
Epoch:  844       12 Batch loss: 0.203660 Batch F1: 0.0
Train Avg Loss  844: 0.222278

Train Avg F1  844: 0.2410473477140144

Val Avg Loss  844: 0.216481

Val Avg F1  844:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 845
--------------------------------------------------------------
Epoch:  845        1 Batch loss: 0.246860 Batch F1: 0.0
Epoch:  845        2 Batch loss: 0.241207 Batch F1: 0.0
Epoch:  845        3 Batch loss: 0.185522 Batch F1: 0.375
Epoch:  845        4 Batch loss: 0.234243 Batch F1: 0.18181818181818182
Epoch:  845        5 Batch loss: 0.182069 Batch F1: 0.35294117647058826
Epoch:  845        6 Batch loss: 0.213309 Batch F1: 0.11764705882352941
Epoch:  845        7 Batch loss: 0.209211 Batch F1: 0.09999999999999999
Epoch:  845        8 Batch loss: 0.234753 Batch F1: 0.0
Epoch:  845        9 Batch loss: 0.239845 Batch F1: 0.0
Epoch:  845       10 Batch loss: 0.220970 Batch F1: 0.0
Epoch:  845       11 Batch loss: 0.241807 Batch F1: 0.20689655172413793
Epoch:  845       12 Batch loss: 0.245383 Batch F1: 0.125
Train Avg Loss  845: 0.224598

Train Avg F1  845: 0.1216085807363698

Val Avg Loss  845: 0.220470

Val Avg F1  845:  0.2400997150997151

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 846
--------------------------------------------------------------
Epoch:  846        1 Batch loss: 0.224152 Batch F1: 0.3846153846153846
Epoch:  846        2 Batch loss: 0.228663 Batch F1: 0.42424242424242425
Epoch:  846        3 Batch loss: 0.213656 Batch F1: 0.32
Epoch:  846        4 Batch loss: 0.206694 Batch F1: 0.3846153846153846
Epoch:  846        5 Batch loss: 0.218912 Batch F1: 0.2608695652173913
Epoch:  846        6 Batch loss: 0.275575 Batch F1: 0.25806451612903225
Epoch:  846        7 Batch loss: 0.231621 Batch F1: 0.25806451612903225
Epoch:  846        8 Batch loss: 0.241903 Batch F1: 0.3333333333333333
Epoch:  846        9 Batch loss: 0.211277 Batch F1: 0.11764705882352941
Epoch:  846       10 Batch loss: 0.164472 Batch F1: 0.7368421052631579
Epoch:  846       11 Batch loss: 0.237424 Batch F1: 0.2857142857142857
Epoch:  846       12 Batch loss: 0.212817 Batch F1: 0.3529411764705882
Train Avg Loss  846: 0.222264

Train Avg F1  846: 0.343079145879462

Val Avg Loss  846: 0.218402

Val Avg F1  846:  0.23573232323232324

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 847
--------------------------------------------------------------
Epoch:  847        1 Batch loss: 0.214065 Batch F1: 0.1739130434782609
Epoch:  847        2 Batch loss: 0.219197 Batch F1: 0.3333333333333333
Epoch:  847        3 Batch loss: 0.213263 Batch F1: 0.1818181818181818
Epoch:  847        4 Batch loss: 0.227863 Batch F1: 0.0
Epoch:  847        5 Batch loss: 0.199736 Batch F1: 0.0
Epoch:  847        6 Batch loss: 0.259968 Batch F1: 0.0
Epoch:  847        7 Batch loss: 0.224212 Batch F1: 0.2727272727272727
Epoch:  847        8 Batch loss: 0.244151 Batch F1: 0.08695652173913042
Epoch:  847        9 Batch loss: 0.215824 Batch F1: 0.2
Epoch:  847       10 Batch loss: 0.198502 Batch F1: 0.4166666666666667
Epoch:  847       11 Batch loss: 0.212446 Batch F1: 0.23999999999999996
Epoch:  847       12 Batch loss: 0.234861 Batch F1: 0.5333333333333333
Train Avg Loss  847: 0.222007

Train Avg F1  847: 0.2032290294246816

Val Avg Loss  847: 0.218810

Val Avg F1  847:  0.25766594516594515

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 848
--------------------------------------------------------------
Epoch:  848        1 Batch loss: 0.255756 Batch F1: 0.24
Epoch:  848        2 Batch loss: 0.228051 Batch F1: 0.23999999999999996
Epoch:  848        3 Batch loss: 0.177339 Batch F1: 0.5454545454545455
Epoch:  848        4 Batch loss: 0.216474 Batch F1: 0.09523809523809523
Epoch:  848        5 Batch loss: 0.238124 Batch F1: 0.3076923076923077
Epoch:  848        6 Batch loss: 0.205041 Batch F1: 0.4827586206896552
Epoch:  848        7 Batch loss: 0.201419 Batch F1: 0.3478260869565218
Epoch:  848        8 Batch loss: 0.247775 Batch F1: 0.5000000000000001
Epoch:  848        9 Batch loss: 0.199104 Batch F1: 0.0
Epoch:  848       10 Batch loss: 0.223405 Batch F1: 0.4516129032258065
Epoch:  848       11 Batch loss: 0.249821 Batch F1: 0.16
Epoch:  848       12 Batch loss: 0.215214 Batch F1: 0.2
Train Avg Loss  848: 0.221460

Train Avg F1  848: 0.29754854660474434

Val Avg Loss  848: 0.219595

Val Avg F1  848:  0.22861047546402238

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 849
--------------------------------------------------------------
Epoch:  849        1 Batch loss: 0.213449 Batch F1: 0.43749999999999994
Epoch:  849        2 Batch loss: 0.206827 Batch F1: 0.34782608695652173
Epoch:  849        3 Batch loss: 0.254765 Batch F1: 0.22222222222222218
Epoch:  849        4 Batch loss: 0.211074 Batch F1: 0.36363636363636365
Epoch:  849        5 Batch loss: 0.191339 Batch F1: 0.2
Epoch:  849        6 Batch loss: 0.197077 Batch F1: 0.4166666666666667
Epoch:  849        7 Batch loss: 0.230978 Batch F1: 0.34782608695652173
Epoch:  849        8 Batch loss: 0.238454 Batch F1: 0.17391304347826086
Epoch:  849        9 Batch loss: 0.219973 Batch F1: 0.17391304347826086
Epoch:  849       10 Batch loss: 0.230708 Batch F1: 0.19047619047619047
Epoch:  849       11 Batch loss: 0.226868 Batch F1: 0.5161290322580644
Epoch:  849       12 Batch loss: 0.238653 Batch F1: 0.10526315789473684
Train Avg Loss  849: 0.221681

Train Avg F1  849: 0.29128099116865075

Val Avg Loss  849: 0.219347

Val Avg F1  849:  0.2517235926628716

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 850
--------------------------------------------------------------
Epoch:  850        1 Batch loss: 0.231303 Batch F1: 0.24
Epoch:  850        2 Batch loss: 0.195863 Batch F1: 0.3333333333333333
Epoch:  850        3 Batch loss: 0.184766 Batch F1: 0.43478260869565216
Epoch:  850        4 Batch loss: 0.231763 Batch F1: 0.21428571428571427
Epoch:  850        5 Batch loss: 0.227330 Batch F1: 0.3571428571428571
Epoch:  850        6 Batch loss: 0.246072 Batch F1: 0.3125
Epoch:  850        7 Batch loss: 0.203809 Batch F1: 0.43478260869565216
Epoch:  850        8 Batch loss: 0.221535 Batch F1: 0.29629629629629634
Epoch:  850        9 Batch loss: 0.190155 Batch F1: 0.5833333333333334
Epoch:  850       10 Batch loss: 0.240608 Batch F1: 0.24000000000000005
Epoch:  850       11 Batch loss: 0.285803 Batch F1: 0.21428571428571427
Epoch:  850       12 Batch loss: 0.212098 Batch F1: 0.31578947368421056
Train Avg Loss  850: 0.222592

Train Avg F1  850: 0.3313776616460637

Val Avg Loss  850: 0.218854

Val Avg F1  850:  0.2744939271255061

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 851
--------------------------------------------------------------
Epoch:  851        1 Batch loss: 0.220236 Batch F1: 0.31999999999999995
Epoch:  851        2 Batch loss: 0.238591 Batch F1: 0.0
Epoch:  851        3 Batch loss: 0.231086 Batch F1: 0.08
Epoch:  851        4 Batch loss: 0.237678 Batch F1: 0.0
Epoch:  851        5 Batch loss: 0.217527 Batch F1: 0.2608695652173913
Epoch:  851        6 Batch loss: 0.217569 Batch F1: 0.25
Epoch:  851        7 Batch loss: 0.205934 Batch F1: 0.3809523809523809
Epoch:  851        8 Batch loss: 0.238269 Batch F1: 0.5405405405405406
Epoch:  851        9 Batch loss: 0.261387 Batch F1: 0.3243243243243243
Epoch:  851       10 Batch loss: 0.175118 Batch F1: 0.6250000000000001
Epoch:  851       11 Batch loss: 0.208103 Batch F1: 0.4
Epoch:  851       12 Batch loss: 0.222842 Batch F1: 0.13333333333333333
Train Avg Loss  851: 0.222862

Train Avg F1  851: 0.27625167869733086

Val Avg Loss  851: 0.218898

Val Avg F1  851:  0.25

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 852
--------------------------------------------------------------
Epoch:  852        1 Batch loss: 0.240063 Batch F1: 0.4375
Epoch:  852        2 Batch loss: 0.192449 Batch F1: 0.4444444444444444
Epoch:  852        3 Batch loss: 0.227544 Batch F1: 0.0
Epoch:  852        4 Batch loss: 0.195692 Batch F1: 0.0
Epoch:  852        5 Batch loss: 0.206466 Batch F1: 0.0
Epoch:  852        6 Batch loss: 0.238722 Batch F1: 0.0
Epoch:  852        7 Batch loss: 0.255699 Batch F1: 0.0
Epoch:  852        8 Batch loss: 0.193425 Batch F1: 0.0
Epoch:  852        9 Batch loss: 0.249407 Batch F1: 0.0
Epoch:  852       10 Batch loss: 0.257269 Batch F1: 0.0
Epoch:  852       11 Batch loss: 0.207700 Batch F1: 0.2857142857142857
Epoch:  852       12 Batch loss: 0.230979 Batch F1: 0.19047619047619047
Train Avg Loss  852: 0.224618

Train Avg F1  852: 0.11317791005291006

Val Avg Loss  852: 0.218357

Val Avg F1  852:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 853
--------------------------------------------------------------
Epoch:  853        1 Batch loss: 0.204840 Batch F1: 0.0
Epoch:  853        2 Batch loss: 0.215710 Batch F1: 0.0
Epoch:  853        3 Batch loss: 0.249432 Batch F1: 0.0
Epoch:  853        4 Batch loss: 0.234932 Batch F1: 0.0
Epoch:  853        5 Batch loss: 0.275086 Batch F1: 0.0
Epoch:  853        6 Batch loss: 0.245586 Batch F1: 0.0
Epoch:  853        7 Batch loss: 0.253683 Batch F1: 0.0
Epoch:  853        8 Batch loss: 0.223923 Batch F1: 0.0
Epoch:  853        9 Batch loss: 0.222578 Batch F1: 0.46153846153846156
Epoch:  853       10 Batch loss: 0.220980 Batch F1: 0.43478260869565216
Epoch:  853       11 Batch loss: 0.215696 Batch F1: 0.21052631578947367
Epoch:  853       12 Batch loss: 0.215540 Batch F1: 0.0
Train Avg Loss  853: 0.231499

Train Avg F1  853: 0.09223728216863229

Val Avg Loss  853: 0.218099

Val Avg F1  853:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 854
--------------------------------------------------------------
Epoch:  854        1 Batch loss: 0.227366 Batch F1: 0.0
Epoch:  854        2 Batch loss: 0.231002 Batch F1: 0.0
Epoch:  854        3 Batch loss: 0.252663 Batch F1: 0.0
Epoch:  854        4 Batch loss: 0.213255 Batch F1: 0.34782608695652173
Epoch:  854        5 Batch loss: 0.224018 Batch F1: 0.5555555555555556
Epoch:  854        6 Batch loss: 0.222505 Batch F1: 0.3076923076923077
Epoch:  854        7 Batch loss: 0.273812 Batch F1: 0.25806451612903225
Epoch:  854        8 Batch loss: 0.222950 Batch F1: 0.27272727272727276
Epoch:  854        9 Batch loss: 0.221917 Batch F1: 0.2727272727272727
Epoch:  854       10 Batch loss: 0.177159 Batch F1: 0.1818181818181818
Epoch:  854       11 Batch loss: 0.233811 Batch F1: 0.0
Epoch:  854       12 Batch loss: 0.197089 Batch F1: 0.0
Train Avg Loss  854: 0.224796

Train Avg F1  854: 0.18303426613384535

Val Avg Loss  854: 0.217664

Val Avg F1  854:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 855
--------------------------------------------------------------
Epoch:  855        1 Batch loss: 0.238143 Batch F1: 0.0
Epoch:  855        2 Batch loss: 0.219277 Batch F1: 0.0
Epoch:  855        3 Batch loss: 0.233432 Batch F1: 0.0
Epoch:  855        4 Batch loss: 0.212513 Batch F1: 0.0
Epoch:  855        5 Batch loss: 0.189883 Batch F1: 0.0
Epoch:  855        6 Batch loss: 0.205186 Batch F1: 0.09999999999999999
Epoch:  855        7 Batch loss: 0.238859 Batch F1: 0.17391304347826084
Epoch:  855        8 Batch loss: 0.209238 Batch F1: 0.19047619047619047
Epoch:  855        9 Batch loss: 0.227239 Batch F1: 0.35714285714285715
Epoch:  855       10 Batch loss: 0.246350 Batch F1: 0.09090909090909091
Epoch:  855       11 Batch loss: 0.223935 Batch F1: 0.4615384615384615
Epoch:  855       12 Batch loss: 0.239471 Batch F1: 0.1904761904761905
Train Avg Loss  855: 0.223627

Train Avg F1  855: 0.1303713195017543

Val Avg Loss  855: 0.219422

Val Avg F1  855:  0.19294871794871796

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 856
--------------------------------------------------------------
Epoch:  856        1 Batch loss: 0.240375 Batch F1: 0.2666666666666667
Epoch:  856        2 Batch loss: 0.224724 Batch F1: 0.25
Epoch:  856        3 Batch loss: 0.251651 Batch F1: 0.36363636363636365
Epoch:  856        4 Batch loss: 0.230726 Batch F1: 0.32
Epoch:  856        5 Batch loss: 0.217119 Batch F1: 0.31578947368421056
Epoch:  856        6 Batch loss: 0.218688 Batch F1: 0.23076923076923075
Epoch:  856        7 Batch loss: 0.203379 Batch F1: 0.2857142857142857
Epoch:  856        8 Batch loss: 0.231662 Batch F1: 0.4
Epoch:  856        9 Batch loss: 0.204394 Batch F1: 0.1111111111111111
Epoch:  856       10 Batch loss: 0.209992 Batch F1: 0.0
Epoch:  856       11 Batch loss: 0.244790 Batch F1: 0.0
Epoch:  856       12 Batch loss: 0.196791 Batch F1: 0.0
Train Avg Loss  856: 0.222858

Train Avg F1  856: 0.2119739276318224

Val Avg Loss  856: 0.216981

Val Avg F1  856:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 857
--------------------------------------------------------------
Epoch:  857        1 Batch loss: 0.233666 Batch F1: 0.0
Epoch:  857        2 Batch loss: 0.189850 Batch F1: 0.0
Epoch:  857        3 Batch loss: 0.258827 Batch F1: 0.0
Epoch:  857        4 Batch loss: 0.207080 Batch F1: 0.0
Epoch:  857        5 Batch loss: 0.208377 Batch F1: 0.0
Epoch:  857        6 Batch loss: 0.220886 Batch F1: 0.0
Epoch:  857        7 Batch loss: 0.252849 Batch F1: 0.0
Epoch:  857        8 Batch loss: 0.257431 Batch F1: 0.0
Epoch:  857        9 Batch loss: 0.198222 Batch F1: 0.43478260869565216
Epoch:  857       10 Batch loss: 0.209269 Batch F1: 0.3636363636363637
Epoch:  857       11 Batch loss: 0.233828 Batch F1: 0.14814814814814814
Epoch:  857       12 Batch loss: 0.204910 Batch F1: 0.36363636363636365
Train Avg Loss  857: 0.222933

Train Avg F1  857: 0.10918362367637731

Val Avg Loss  857: 0.220772

Val Avg F1  857:  0.2549459397285484

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 858
--------------------------------------------------------------
Epoch:  858        1 Batch loss: 0.198167 Batch F1: 0.43478260869565216
Epoch:  858        2 Batch loss: 0.222346 Batch F1: 0.39999999999999997
Epoch:  858        3 Batch loss: 0.198016 Batch F1: 0.2222222222222222
Epoch:  858        4 Batch loss: 0.227514 Batch F1: 0.24
Epoch:  858        5 Batch loss: 0.185843 Batch F1: 0.5217391304347826
Epoch:  858        6 Batch loss: 0.253438 Batch F1: 0.2
Epoch:  858        7 Batch loss: 0.234905 Batch F1: 0.17391304347826086
Epoch:  858        8 Batch loss: 0.229768 Batch F1: 0.4666666666666666
Epoch:  858        9 Batch loss: 0.262425 Batch F1: 0.08333333333333333
Epoch:  858       10 Batch loss: 0.243908 Batch F1: 0.23076923076923073
Epoch:  858       11 Batch loss: 0.213819 Batch F1: 0.3
Epoch:  858       12 Batch loss: 0.205714 Batch F1: 0.33333333333333337
Train Avg Loss  858: 0.222989

Train Avg F1  858: 0.30056329741112353

Val Avg Loss  858: 0.221063

Val Avg F1  858:  0.26610885733603784

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 859
--------------------------------------------------------------
Epoch:  859        1 Batch loss: 0.237449 Batch F1: 0.21428571428571425
Epoch:  859        2 Batch loss: 0.234313 Batch F1: 0.18181818181818182
Epoch:  859        3 Batch loss: 0.228740 Batch F1: 0.35714285714285715
Epoch:  859        4 Batch loss: 0.205730 Batch F1: 0.4545454545454545
Epoch:  859        5 Batch loss: 0.228856 Batch F1: 0.2608695652173913
Epoch:  859        6 Batch loss: 0.189542 Batch F1: 0.5454545454545454
Epoch:  859        7 Batch loss: 0.238760 Batch F1: 0.2962962962962963
Epoch:  859        8 Batch loss: 0.245683 Batch F1: 0.3333333333333333
Epoch:  859        9 Batch loss: 0.226729 Batch F1: 0.16666666666666666
Epoch:  859       10 Batch loss: 0.218254 Batch F1: 0.41379310344827586
Epoch:  859       11 Batch loss: 0.216459 Batch F1: 0.0
Epoch:  859       12 Batch loss: 0.206222 Batch F1: 0.25
Train Avg Loss  859: 0.223061

Train Avg F1  859: 0.2895171431840597

Val Avg Loss  859: 0.217582

Val Avg F1  859:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 860
--------------------------------------------------------------
Epoch:  860        1 Batch loss: 0.259282 Batch F1: 0.0
Epoch:  860        2 Batch loss: 0.204703 Batch F1: 0.0
Epoch:  860        3 Batch loss: 0.200355 Batch F1: 0.0
Epoch:  860        4 Batch loss: 0.243464 Batch F1: 0.21428571428571425
Epoch:  860        5 Batch loss: 0.229402 Batch F1: 0.3448275862068966
Epoch:  860        6 Batch loss: 0.247057 Batch F1: 0.24
Epoch:  860        7 Batch loss: 0.221720 Batch F1: 0.3333333333333333
Epoch:  860        8 Batch loss: 0.193968 Batch F1: 0.46153846153846156
Epoch:  860        9 Batch loss: 0.218777 Batch F1: 0.33333333333333337
Epoch:  860       10 Batch loss: 0.235083 Batch F1: 0.0909090909090909
Epoch:  860       11 Batch loss: 0.176128 Batch F1: 0.0
Epoch:  860       12 Batch loss: 0.225880 Batch F1: 0.0
Train Avg Loss  860: 0.221318

Train Avg F1  860: 0.1681856266339025

Val Avg Loss  860: 0.224202

Val Avg F1  860:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 861
--------------------------------------------------------------
Epoch:  861        1 Batch loss: 0.202611 Batch F1: 0.0
Epoch:  861        2 Batch loss: 0.304665 Batch F1: 0.0
Epoch:  861        3 Batch loss: 0.218403 Batch F1: 0.0
Epoch:  861        4 Batch loss: 0.222259 Batch F1: 0.0
Epoch:  861        5 Batch loss: 0.253428 Batch F1: 0.0
Epoch:  861        6 Batch loss: 0.249758 Batch F1: 0.3870967741935483
Epoch:  861        7 Batch loss: 0.235721 Batch F1: 0.5454545454545454
Epoch:  861        8 Batch loss: 0.245236 Batch F1: 0.22222222222222224
Epoch:  861        9 Batch loss: 0.210385 Batch F1: 0.6
Epoch:  861       10 Batch loss: 0.203701 Batch F1: 0.3
Epoch:  861       11 Batch loss: 0.226191 Batch F1: 0.0
Epoch:  861       12 Batch loss: 0.221181 Batch F1: 0.0
Train Avg Loss  861: 0.232795

Train Avg F1  861: 0.17123112848919297

Val Avg Loss  861: 0.217908

Val Avg F1  861:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 862
--------------------------------------------------------------
Epoch:  862        1 Batch loss: 0.219073 Batch F1: 0.0
Epoch:  862        2 Batch loss: 0.247941 Batch F1: 0.0
Epoch:  862        3 Batch loss: 0.241037 Batch F1: 0.0
Epoch:  862        4 Batch loss: 0.220764 Batch F1: 0.31578947368421056
Epoch:  862        5 Batch loss: 0.229445 Batch F1: 0.15384615384615383
Epoch:  862        6 Batch loss: 0.228745 Batch F1: 0.23076923076923078
Epoch:  862        7 Batch loss: 0.223816 Batch F1: 0.42857142857142855
Epoch:  862        8 Batch loss: 0.203020 Batch F1: 0.0
Epoch:  862        9 Batch loss: 0.239776 Batch F1: 0.0
Epoch:  862       10 Batch loss: 0.232542 Batch F1: 0.09523809523809525
Epoch:  862       11 Batch loss: 0.210335 Batch F1: 0.4615384615384615
Epoch:  862       12 Batch loss: 0.218235 Batch F1: 0.23529411764705885
Train Avg Loss  862: 0.226227

Train Avg F1  862: 0.1600872467745533

Val Avg Loss  862: 0.222130

Val Avg F1  862:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 863
--------------------------------------------------------------
Epoch:  863        1 Batch loss: 0.307249 Batch F1: 0.0
Epoch:  863        2 Batch loss: 0.230880 Batch F1: 0.0
Epoch:  863        3 Batch loss: 0.228510 Batch F1: 0.0
Epoch:  863        4 Batch loss: 0.201706 Batch F1: 0.3333333333333333
Epoch:  863        5 Batch loss: 0.240158 Batch F1: 0.25
Epoch:  863        6 Batch loss: 0.201421 Batch F1: 0.380952380952381
Epoch:  863        7 Batch loss: 0.210079 Batch F1: 0.46153846153846156
Epoch:  863        8 Batch loss: 0.240175 Batch F1: 0.0
Epoch:  863        9 Batch loss: 0.234163 Batch F1: 0.0
Epoch:  863       10 Batch loss: 0.221447 Batch F1: 0.0
Epoch:  863       11 Batch loss: 0.215512 Batch F1: 0.0
Epoch:  863       12 Batch loss: 0.203682 Batch F1: 0.0
Train Avg Loss  863: 0.227915

Train Avg F1  863: 0.1188186813186813

Val Avg Loss  863: 0.217998

Val Avg F1  863:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 864
--------------------------------------------------------------
Epoch:  864        1 Batch loss: 0.216929 Batch F1: 0.0
Epoch:  864        2 Batch loss: 0.204236 Batch F1: 0.0
Epoch:  864        3 Batch loss: 0.249714 Batch F1: 0.0
Epoch:  864        4 Batch loss: 0.203490 Batch F1: 0.0
Epoch:  864        5 Batch loss: 0.198752 Batch F1: 0.125
Epoch:  864        6 Batch loss: 0.238298 Batch F1: 0.0
Epoch:  864        7 Batch loss: 0.233203 Batch F1: 0.09090909090909091
Epoch:  864        8 Batch loss: 0.234034 Batch F1: 0.2608695652173913
Epoch:  864        9 Batch loss: 0.206767 Batch F1: 0.18181818181818182
Epoch:  864       10 Batch loss: 0.237379 Batch F1: 0.16666666666666666
Epoch:  864       11 Batch loss: 0.189303 Batch F1: 0.2105263157894737
Epoch:  864       12 Batch loss: 0.269362 Batch F1: 0.3333333333333333
Train Avg Loss  864: 0.223456

Train Avg F1  864: 0.11409359614451148

Val Avg Loss  864: 0.220671

Val Avg F1  864:  0.32226469182990924

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 865
--------------------------------------------------------------
Epoch:  865        1 Batch loss: 0.257424 Batch F1: 0.3636363636363636
Epoch:  865        2 Batch loss: 0.230227 Batch F1: 0.4516129032258065
Epoch:  865        3 Batch loss: 0.249645 Batch F1: 0.30303030303030304
Epoch:  865        4 Batch loss: 0.202859 Batch F1: 0.23529411764705882
Epoch:  865        5 Batch loss: 0.199682 Batch F1: 0.11764705882352941
Epoch:  865        6 Batch loss: 0.207169 Batch F1: 0.22222222222222224
Epoch:  865        7 Batch loss: 0.221584 Batch F1: 0.0
Epoch:  865        8 Batch loss: 0.172239 Batch F1: 0.0
Epoch:  865        9 Batch loss: 0.247249 Batch F1: 0.0
Epoch:  865       10 Batch loss: 0.213649 Batch F1: 0.0
Epoch:  865       11 Batch loss: 0.253869 Batch F1: 0.0
Epoch:  865       12 Batch loss: 0.240067 Batch F1: 0.0
Train Avg Loss  865: 0.224639

Train Avg F1  865: 0.14112024738210696

Val Avg Loss  865: 0.218169

Val Avg F1  865:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 866
--------------------------------------------------------------
Epoch:  866        1 Batch loss: 0.211361 Batch F1: 0.0
Epoch:  866        2 Batch loss: 0.245484 Batch F1: 0.09523809523809523
Epoch:  866        3 Batch loss: 0.235086 Batch F1: 0.08695652173913045
Epoch:  866        4 Batch loss: 0.208775 Batch F1: 0.38095238095238093
Epoch:  866        5 Batch loss: 0.238400 Batch F1: 0.29629629629629634
Epoch:  866        6 Batch loss: 0.244245 Batch F1: 0.3571428571428571
Epoch:  866        7 Batch loss: 0.203300 Batch F1: 0.34782608695652173
Epoch:  866        8 Batch loss: 0.229035 Batch F1: 0.2857142857142857
Epoch:  866        9 Batch loss: 0.199244 Batch F1: 0.3157894736842105
Epoch:  866       10 Batch loss: 0.224198 Batch F1: 0.2608695652173913
Epoch:  866       11 Batch loss: 0.221628 Batch F1: 0.32000000000000006
Epoch:  866       12 Batch loss: 0.208476 Batch F1: 0.2727272727272727
Train Avg Loss  866: 0.222436

Train Avg F1  866: 0.25162606963903683

Val Avg Loss  866: 0.218624

Val Avg F1  866:  0.2630663615560641

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 867
--------------------------------------------------------------
Epoch:  867        1 Batch loss: 0.234768 Batch F1: 0.16
Epoch:  867        2 Batch loss: 0.222618 Batch F1: 0.10526315789473684
Epoch:  867        3 Batch loss: 0.206942 Batch F1: 0.42857142857142855
Epoch:  867        4 Batch loss: 0.242952 Batch F1: 0.32
Epoch:  867        5 Batch loss: 0.262527 Batch F1: 0.25806451612903225
Epoch:  867        6 Batch loss: 0.217721 Batch F1: 0.6451612903225806
Epoch:  867        7 Batch loss: 0.211158 Batch F1: 0.3333333333333333
Epoch:  867        8 Batch loss: 0.206778 Batch F1: 0.32
Epoch:  867        9 Batch loss: 0.204054 Batch F1: 0.5714285714285714
Epoch:  867       10 Batch loss: 0.236362 Batch F1: 0.38461538461538464
Epoch:  867       11 Batch loss: 0.215297 Batch F1: 0.17391304347826086
Epoch:  867       12 Batch loss: 0.215792 Batch F1: 0.35294117647058826
Train Avg Loss  867: 0.223081

Train Avg F1  867: 0.3377743251869931

Val Avg Loss  867: 0.218268

Val Avg F1  867:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 868
--------------------------------------------------------------
Epoch:  868        1 Batch loss: 0.226512 Batch F1: 0.0
Epoch:  868        2 Batch loss: 0.238414 Batch F1: 0.0
Epoch:  868        3 Batch loss: 0.214681 Batch F1: 0.1111111111111111
Epoch:  868        4 Batch loss: 0.254189 Batch F1: 0.08695652173913042
Epoch:  868        5 Batch loss: 0.242495 Batch F1: 0.0
Epoch:  868        6 Batch loss: 0.241230 Batch F1: 0.08
Epoch:  868        7 Batch loss: 0.214320 Batch F1: 0.2105263157894737
Epoch:  868        8 Batch loss: 0.199961 Batch F1: 0.125
Epoch:  868        9 Batch loss: 0.213520 Batch F1: 0.44444444444444436
Epoch:  868       10 Batch loss: 0.200563 Batch F1: 0.2105263157894737
Epoch:  868       11 Batch loss: 0.206868 Batch F1: 0.19047619047619047
Epoch:  868       12 Batch loss: 0.220866 Batch F1: 0.0
Train Avg Loss  868: 0.222801

Train Avg F1  868: 0.12158674161248532

Val Avg Loss  868: 0.218243

Val Avg F1  868:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 869
--------------------------------------------------------------
Epoch:  869        1 Batch loss: 0.242234 Batch F1: 0.0
Epoch:  869        2 Batch loss: 0.204196 Batch F1: 0.09523809523809525
Epoch:  869        3 Batch loss: 0.186478 Batch F1: 0.42105263157894735
Epoch:  869        4 Batch loss: 0.201652 Batch F1: 0.3478260869565218
Epoch:  869        5 Batch loss: 0.219702 Batch F1: 0.3333333333333333
Epoch:  869        6 Batch loss: 0.215261 Batch F1: 0.1
Epoch:  869        7 Batch loss: 0.212859 Batch F1: 0.11764705882352941
Epoch:  869        8 Batch loss: 0.207439 Batch F1: 0.4347826086956522
Epoch:  869        9 Batch loss: 0.231968 Batch F1: 0.1818181818181818
Epoch:  869       10 Batch loss: 0.267039 Batch F1: 0.3888888888888889
Epoch:  869       11 Batch loss: 0.217205 Batch F1: 0.1818181818181818
Epoch:  869       12 Batch loss: 0.261627 Batch F1: 0.25
Train Avg Loss  869: 0.222305

Train Avg F1  869: 0.23770042226261098

Val Avg Loss  869: 0.218872

Val Avg F1  869:  0.26563436563436565

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 870
--------------------------------------------------------------
Epoch:  870        1 Batch loss: 0.234158 Batch F1: 0.16
Epoch:  870        2 Batch loss: 0.228133 Batch F1: 0.23076923076923073
Epoch:  870        3 Batch loss: 0.201454 Batch F1: 0.11111111111111112
Epoch:  870        4 Batch loss: 0.281697 Batch F1: 0.25
Epoch:  870        5 Batch loss: 0.244376 Batch F1: 0.08333333333333334
Epoch:  870        6 Batch loss: 0.212114 Batch F1: 0.18181818181818185
Epoch:  870        7 Batch loss: 0.194305 Batch F1: 0.4444444444444445
Epoch:  870        8 Batch loss: 0.222348 Batch F1: 0.1904761904761905
Epoch:  870        9 Batch loss: 0.208357 Batch F1: 0.09999999999999999
Epoch:  870       10 Batch loss: 0.225632 Batch F1: 0.1904761904761905
Epoch:  870       11 Batch loss: 0.201221 Batch F1: 0.3157894736842105
Epoch:  870       12 Batch loss: 0.235683 Batch F1: 0.2608695652173913
Train Avg Loss  870: 0.224123

Train Avg F1  870: 0.2099239767775237

Val Avg Loss  870: 0.218103

Val Avg F1  870:  0.17120927318295737

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 871
--------------------------------------------------------------
Epoch:  871        1 Batch loss: 0.214759 Batch F1: 0.32
Epoch:  871        2 Batch loss: 0.221226 Batch F1: 0.23529411764705882
Epoch:  871        3 Batch loss: 0.199361 Batch F1: 0.4347826086956522
Epoch:  871        4 Batch loss: 0.226245 Batch F1: 0.16666666666666669
Epoch:  871        5 Batch loss: 0.229247 Batch F1: 0.1904761904761905
Epoch:  871        6 Batch loss: 0.211700 Batch F1: 0.38095238095238093
Epoch:  871        7 Batch loss: 0.227394 Batch F1: 0.3333333333333333
Epoch:  871        8 Batch loss: 0.223154 Batch F1: 0.17391304347826086
Epoch:  871        9 Batch loss: 0.250362 Batch F1: 0.13793103448275862
Epoch:  871       10 Batch loss: 0.196043 Batch F1: 0.10526315789473682
Epoch:  871       11 Batch loss: 0.244251 Batch F1: 0.27586206896551724
Epoch:  871       12 Batch loss: 0.216400 Batch F1: 0.4615384615384615
Train Avg Loss  871: 0.221678

Train Avg F1  871: 0.2680010886775848

Val Avg Loss  871: 0.220078

Val Avg F1  871:  0.2814285714285715

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 872
--------------------------------------------------------------
Epoch:  872        1 Batch loss: 0.169372 Batch F1: 0.5
Epoch:  872        2 Batch loss: 0.207392 Batch F1: 0.36363636363636365
Epoch:  872        3 Batch loss: 0.234519 Batch F1: 0.22222222222222218
Epoch:  872        4 Batch loss: 0.232261 Batch F1: 0.25
Epoch:  872        5 Batch loss: 0.220769 Batch F1: 0.29629629629629634
Epoch:  872        6 Batch loss: 0.232629 Batch F1: 0.1818181818181818
Epoch:  872        7 Batch loss: 0.220556 Batch F1: 0.37037037037037035
Epoch:  872        8 Batch loss: 0.247268 Batch F1: 0.27586206896551724
Epoch:  872        9 Batch loss: 0.260290 Batch F1: 0.20689655172413793
Epoch:  872       10 Batch loss: 0.217706 Batch F1: 0.3333333333333333
Epoch:  872       11 Batch loss: 0.213096 Batch F1: 0.4166666666666667
Epoch:  872       12 Batch loss: 0.200830 Batch F1: 0.21052631578947364
Train Avg Loss  872: 0.221391

Train Avg F1  872: 0.30230236423521356

Val Avg Loss  872: 0.219674

Val Avg F1  872:  0.2501831501831502

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 873
--------------------------------------------------------------
Epoch:  873        1 Batch loss: 0.192782 Batch F1: 0.43478260869565216
Epoch:  873        2 Batch loss: 0.203456 Batch F1: 0.21052631578947364
Epoch:  873        3 Batch loss: 0.196129 Batch F1: 0.1111111111111111
Epoch:  873        4 Batch loss: 0.231007 Batch F1: 0.16666666666666666
Epoch:  873        5 Batch loss: 0.209234 Batch F1: 0.3333333333333333
Epoch:  873        6 Batch loss: 0.225405 Batch F1: 0.16666666666666666
Epoch:  873        7 Batch loss: 0.263289 Batch F1: 0.0
Epoch:  873        8 Batch loss: 0.204955 Batch F1: 0.3636363636363636
Epoch:  873        9 Batch loss: 0.241779 Batch F1: 0.3448275862068965
Epoch:  873       10 Batch loss: 0.195166 Batch F1: 0.28571428571428575
Epoch:  873       11 Batch loss: 0.260155 Batch F1: 0.19999999999999998
Epoch:  873       12 Batch loss: 0.242375 Batch F1: 0.3478260869565218
Train Avg Loss  873: 0.222144

Train Avg F1  873: 0.24709091873141428

Val Avg Loss  873: 0.220655

Val Avg F1  873:  0.3269149831649832

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 874
--------------------------------------------------------------
Epoch:  874        1 Batch loss: 0.208422 Batch F1: 0.5384615384615385
Epoch:  874        2 Batch loss: 0.190118 Batch F1: 0.5833333333333334
Epoch:  874        3 Batch loss: 0.244698 Batch F1: 0.07692307692307693
Epoch:  874        4 Batch loss: 0.263412 Batch F1: 0.08
Epoch:  874        5 Batch loss: 0.238174 Batch F1: 0.3225806451612903
Epoch:  874        6 Batch loss: 0.240569 Batch F1: 0.2962962962962963
Epoch:  874        7 Batch loss: 0.223111 Batch F1: 0.31999999999999995
Epoch:  874        8 Batch loss: 0.197549 Batch F1: 0.34782608695652173
Epoch:  874        9 Batch loss: 0.227191 Batch F1: 0.2857142857142857
Epoch:  874       10 Batch loss: 0.254525 Batch F1: 0.21428571428571427
Epoch:  874       11 Batch loss: 0.205965 Batch F1: 0.32
Epoch:  874       12 Batch loss: 0.164509 Batch F1: 0.37499999999999994
Train Avg Loss  874: 0.221520

Train Avg F1  874: 0.3133684147610047

Val Avg Loss  874: 0.218612

Val Avg F1  874:  0.26021645021645023

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 875
--------------------------------------------------------------
Epoch:  875        1 Batch loss: 0.200876 Batch F1: 0.2105263157894737
Epoch:  875        2 Batch loss: 0.208059 Batch F1: 0.3157894736842105
Epoch:  875        3 Batch loss: 0.226618 Batch F1: 0.0
Epoch:  875        4 Batch loss: 0.274611 Batch F1: 0.0
Epoch:  875        5 Batch loss: 0.226845 Batch F1: 0.0
Epoch:  875        6 Batch loss: 0.223568 Batch F1: 0.0
Epoch:  875        7 Batch loss: 0.203228 Batch F1: 0.0
Epoch:  875        8 Batch loss: 0.216399 Batch F1: 0.09523809523809523
Epoch:  875        9 Batch loss: 0.216008 Batch F1: 0.08333333333333333
Epoch:  875       10 Batch loss: 0.210764 Batch F1: 0.2
Epoch:  875       11 Batch loss: 0.243040 Batch F1: 0.5454545454545454
Epoch:  875       12 Batch loss: 0.222845 Batch F1: 0.38095238095238093
Train Avg Loss  875: 0.222738

Train Avg F1  875: 0.15260784537100328

Val Avg Loss  875: 0.222206

Val Avg F1  875:  0.3019675925925926

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 876
--------------------------------------------------------------
Epoch:  876        1 Batch loss: 0.205484 Batch F1: 0.56
Epoch:  876        2 Batch loss: 0.223504 Batch F1: 0.16666666666666669
Epoch:  876        3 Batch loss: 0.257097 Batch F1: 0.09090909090909091
Epoch:  876        4 Batch loss: 0.211090 Batch F1: 0.25
Epoch:  876        5 Batch loss: 0.228481 Batch F1: 0.30769230769230765
Epoch:  876        6 Batch loss: 0.220022 Batch F1: 0.18181818181818182
Epoch:  876        7 Batch loss: 0.214480 Batch F1: 0.36363636363636365
Epoch:  876        8 Batch loss: 0.191654 Batch F1: 0.0
Epoch:  876        9 Batch loss: 0.228582 Batch F1: 0.0
Epoch:  876       10 Batch loss: 0.259473 Batch F1: 0.0
Epoch:  876       11 Batch loss: 0.214901 Batch F1: 0.10526315789473684
Epoch:  876       12 Batch loss: 0.220318 Batch F1: 0.2222222222222222
Train Avg Loss  876: 0.222924

Train Avg F1  876: 0.18735066590329752

Val Avg Loss  876: 0.219266

Val Avg F1  876:  0.25689865689865693

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 877
--------------------------------------------------------------
Epoch:  877        1 Batch loss: 0.250858 Batch F1: 0.16666666666666666
Epoch:  877        2 Batch loss: 0.197134 Batch F1: 0.2
Epoch:  877        3 Batch loss: 0.206720 Batch F1: 0.3333333333333333
Epoch:  877        4 Batch loss: 0.281009 Batch F1: 0.14285714285714285
Epoch:  877        5 Batch loss: 0.230091 Batch F1: 0.5
Epoch:  877        6 Batch loss: 0.201813 Batch F1: 0.28571428571428575
Epoch:  877        7 Batch loss: 0.224105 Batch F1: 0.5161290322580645
Epoch:  877        8 Batch loss: 0.250389 Batch F1: 0.22222222222222218
Epoch:  877        9 Batch loss: 0.221693 Batch F1: 0.3333333333333333
Epoch:  877       10 Batch loss: 0.178437 Batch F1: 0.5263157894736842
Epoch:  877       11 Batch loss: 0.208599 Batch F1: 0.32000000000000006
Epoch:  877       12 Batch loss: 0.215078 Batch F1: 0.25
Train Avg Loss  877: 0.222161

Train Avg F1  877: 0.31638098382156105

Val Avg Loss  877: 0.219462

Val Avg F1  877:  0.2563146997929607

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 878
--------------------------------------------------------------
Epoch:  878        1 Batch loss: 0.223323 Batch F1: 0.29629629629629634
Epoch:  878        2 Batch loss: 0.191983 Batch F1: 0.5714285714285715
Epoch:  878        3 Batch loss: 0.261247 Batch F1: 0.21428571428571427
Epoch:  878        4 Batch loss: 0.225959 Batch F1: 0.26086956521739124
Epoch:  878        5 Batch loss: 0.192985 Batch F1: 0.35294117647058826
Epoch:  878        6 Batch loss: 0.210108 Batch F1: 0.2857142857142857
Epoch:  878        7 Batch loss: 0.219072 Batch F1: 0.25
Epoch:  878        8 Batch loss: 0.203892 Batch F1: 0.2857142857142857
Epoch:  878        9 Batch loss: 0.268684 Batch F1: 0.3125
Epoch:  878       10 Batch loss: 0.224377 Batch F1: 0.16
Epoch:  878       11 Batch loss: 0.235010 Batch F1: 0.2962962962962963
Epoch:  878       12 Batch loss: 0.213332 Batch F1: 0.4761904761904762
Train Avg Loss  878: 0.222498

Train Avg F1  878: 0.3135197223011588

Val Avg Loss  878: 0.220728

Val Avg F1  878:  0.2253205128205128

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 879
--------------------------------------------------------------
Epoch:  879        1 Batch loss: 0.235834 Batch F1: 0.16000000000000003
Epoch:  879        2 Batch loss: 0.198888 Batch F1: 0.4827586206896552
Epoch:  879        3 Batch loss: 0.228730 Batch F1: 0.1739130434782609
Epoch:  879        4 Batch loss: 0.213959 Batch F1: 0.32
Epoch:  879        5 Batch loss: 0.173973 Batch F1: 0.4444444444444444
Epoch:  879        6 Batch loss: 0.228473 Batch F1: 0.19999999999999998
Epoch:  879        7 Batch loss: 0.201577 Batch F1: 0.125
Epoch:  879        8 Batch loss: 0.242948 Batch F1: 0.0
Epoch:  879        9 Batch loss: 0.192213 Batch F1: 0.0
Epoch:  879       10 Batch loss: 0.278841 Batch F1: 0.07142857142857144
Epoch:  879       11 Batch loss: 0.247989 Batch F1: 0.32
Epoch:  879       12 Batch loss: 0.223417 Batch F1: 0.37037037037037035
Train Avg Loss  879: 0.222237

Train Avg F1  879: 0.22232625420094185

Val Avg Loss  879: 0.221526

Val Avg F1  879:  0.33180354267310785

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 880
--------------------------------------------------------------
Epoch:  880        1 Batch loss: 0.198998 Batch F1: 0.4800000000000001
Epoch:  880        2 Batch loss: 0.231167 Batch F1: 0.3333333333333333
Epoch:  880        3 Batch loss: 0.222383 Batch F1: 0.30769230769230765
Epoch:  880        4 Batch loss: 0.208968 Batch F1: 0.37037037037037035
Epoch:  880        5 Batch loss: 0.227627 Batch F1: 0.16666666666666666
Epoch:  880        6 Batch loss: 0.250470 Batch F1: 0.47058823529411764
Epoch:  880        7 Batch loss: 0.228824 Batch F1: 0.3333333333333333
Epoch:  880        8 Batch loss: 0.220532 Batch F1: 0.19047619047619047
Epoch:  880        9 Batch loss: 0.202547 Batch F1: 0.3846153846153846
Epoch:  880       10 Batch loss: 0.214038 Batch F1: 0.24
Epoch:  880       11 Batch loss: 0.216765 Batch F1: 0.1111111111111111
Epoch:  880       12 Batch loss: 0.256195 Batch F1: 0.24
Train Avg Loss  880: 0.223210

Train Avg F1  880: 0.30234891107440126

Val Avg Loss  880: 0.218551

Val Avg F1  880:  0.19013888888888889

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 881
--------------------------------------------------------------
Epoch:  881        1 Batch loss: 0.238455 Batch F1: 0.23076923076923073
Epoch:  881        2 Batch loss: 0.229067 Batch F1: 0.4848484848484849
Epoch:  881        3 Batch loss: 0.216612 Batch F1: 0.2105263157894737
Epoch:  881        4 Batch loss: 0.224407 Batch F1: 0.26086956521739124
Epoch:  881        5 Batch loss: 0.216786 Batch F1: 0.24999999999999997
Epoch:  881        6 Batch loss: 0.202250 Batch F1: 0.28571428571428575
Epoch:  881        7 Batch loss: 0.262347 Batch F1: 0.07407407407407408
Epoch:  881        8 Batch loss: 0.223212 Batch F1: 0.4285714285714285
Epoch:  881        9 Batch loss: 0.219256 Batch F1: 0.4347826086956522
Epoch:  881       10 Batch loss: 0.217531 Batch F1: 0.28571428571428575
Epoch:  881       11 Batch loss: 0.213215 Batch F1: 0.32
Epoch:  881       12 Batch loss: 0.189624 Batch F1: 0.42105263157894735
Train Avg Loss  881: 0.221064

Train Avg F1  881: 0.30724357591443785

Val Avg Loss  881: 0.218743

Val Avg F1  881:  0.22406015037593982

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 882
--------------------------------------------------------------
Epoch:  882        1 Batch loss: 0.230959 Batch F1: 0.22222222222222218
Epoch:  882        2 Batch loss: 0.219777 Batch F1: 0.2
Epoch:  882        3 Batch loss: 0.226042 Batch F1: 0.1739130434782609
Epoch:  882        4 Batch loss: 0.234746 Batch F1: 0.0
Epoch:  882        5 Batch loss: 0.216995 Batch F1: 0.09999999999999999
Epoch:  882        6 Batch loss: 0.219756 Batch F1: 0.23076923076923073
Epoch:  882        7 Batch loss: 0.216702 Batch F1: 0.32
Epoch:  882        8 Batch loss: 0.249375 Batch F1: 0.3333333333333333
Epoch:  882        9 Batch loss: 0.228789 Batch F1: 0.2727272727272727
Epoch:  882       10 Batch loss: 0.200095 Batch F1: 0.47619047619047616
Epoch:  882       11 Batch loss: 0.214570 Batch F1: 0.27272727272727276
Epoch:  882       12 Batch loss: 0.196792 Batch F1: 0.43478260869565216
Train Avg Loss  882: 0.221216

Train Avg F1  882: 0.25305545501197674

Val Avg Loss  882: 0.219324

Val Avg F1  882:  0.26616479925303455

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 883
--------------------------------------------------------------
Epoch:  883        1 Batch loss: 0.175926 Batch F1: 0.4
Epoch:  883        2 Batch loss: 0.215559 Batch F1: 0.19999999999999998
Epoch:  883        3 Batch loss: 0.209996 Batch F1: 0.11764705882352941
Epoch:  883        4 Batch loss: 0.268754 Batch F1: 0.0
Epoch:  883        5 Batch loss: 0.227468 Batch F1: 0.08695652173913045
Epoch:  883        6 Batch loss: 0.254417 Batch F1: 0.08
Epoch:  883        7 Batch loss: 0.201210 Batch F1: 0.5333333333333333
Epoch:  883        8 Batch loss: 0.282885 Batch F1: 0.2285714285714286
Epoch:  883        9 Batch loss: 0.241119 Batch F1: 0.5161290322580644
Epoch:  883       10 Batch loss: 0.214926 Batch F1: 0.3846153846153846
Epoch:  883       11 Batch loss: 0.207768 Batch F1: 0.2857142857142857
Epoch:  883       12 Batch loss: 0.182054 Batch F1: 0.16666666666666669
Train Avg Loss  883: 0.223507

Train Avg F1  883: 0.2499694759768186

Val Avg Loss  883: 0.217873

Val Avg F1  883:  0.020833333333333332

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 884
--------------------------------------------------------------
Epoch:  884        1 Batch loss: 0.196693 Batch F1: 0.11764705882352941
Epoch:  884        2 Batch loss: 0.266978 Batch F1: 0.0
Epoch:  884        3 Batch loss: 0.240338 Batch F1: 0.0
Epoch:  884        4 Batch loss: 0.206559 Batch F1: 0.0
Epoch:  884        5 Batch loss: 0.213764 Batch F1: 0.0
Epoch:  884        6 Batch loss: 0.196943 Batch F1: 0.0
Epoch:  884        7 Batch loss: 0.237461 Batch F1: 0.0
Epoch:  884        8 Batch loss: 0.258163 Batch F1: 0.0
Epoch:  884        9 Batch loss: 0.194741 Batch F1: 0.0
Epoch:  884       10 Batch loss: 0.199547 Batch F1: 0.1111111111111111
Epoch:  884       11 Batch loss: 0.264626 Batch F1: 0.08
Epoch:  884       12 Batch loss: 0.212498 Batch F1: 0.27272727272727276
Train Avg Loss  884: 0.224026

Train Avg F1  884: 0.048457120221826105

Val Avg Loss  884: 0.221780

Val Avg F1  884:  0.2716450216450217

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 885
--------------------------------------------------------------
Epoch:  885        1 Batch loss: 0.232796 Batch F1: 0.37499999999999994
Epoch:  885        2 Batch loss: 0.204930 Batch F1: 0.34782608695652173
Epoch:  885        3 Batch loss: 0.198610 Batch F1: 0.36363636363636365
Epoch:  885        4 Batch loss: 0.200948 Batch F1: 0.43478260869565216
Epoch:  885        5 Batch loss: 0.204515 Batch F1: 0.3636363636363636
Epoch:  885        6 Batch loss: 0.237746 Batch F1: 0.0
Epoch:  885        7 Batch loss: 0.268771 Batch F1: 0.0
Epoch:  885        8 Batch loss: 0.205938 Batch F1: 0.11764705882352941
Epoch:  885        9 Batch loss: 0.247120 Batch F1: 0.3125
Epoch:  885       10 Batch loss: 0.219072 Batch F1: 0.2608695652173913
Epoch:  885       11 Batch loss: 0.250853 Batch F1: 0.2608695652173913
Epoch:  885       12 Batch loss: 0.216283 Batch F1: 0.10526315789473685
Train Avg Loss  885: 0.223965

Train Avg F1  885: 0.2451692308398291

Val Avg Loss  885: 0.218577

Val Avg F1  885:  0.18106060606060606

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 886
--------------------------------------------------------------
Epoch:  886        1 Batch loss: 0.181880 Batch F1: 0.0
Epoch:  886        2 Batch loss: 0.250366 Batch F1: 0.0
Epoch:  886        3 Batch loss: 0.239633 Batch F1: 0.0
Epoch:  886        4 Batch loss: 0.252337 Batch F1: 0.0
Epoch:  886        5 Batch loss: 0.206741 Batch F1: 0.0
Epoch:  886        6 Batch loss: 0.193295 Batch F1: 0.0
Epoch:  886        7 Batch loss: 0.197140 Batch F1: 0.0
Epoch:  886        8 Batch loss: 0.233438 Batch F1: 0.0
Epoch:  886        9 Batch loss: 0.227515 Batch F1: 0.0
Epoch:  886       10 Batch loss: 0.230603 Batch F1: 0.0
Epoch:  886       11 Batch loss: 0.228755 Batch F1: 0.0
Epoch:  886       12 Batch loss: 0.248081 Batch F1: 0.0
Train Avg Loss  886: 0.224149

Train Avg F1  886: 0.0

Val Avg Loss  886: 0.218896

Val Avg F1  886:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 887
--------------------------------------------------------------
Epoch:  887        1 Batch loss: 0.226731 Batch F1: 0.0
Epoch:  887        2 Batch loss: 0.228477 Batch F1: 0.3846153846153846
Epoch:  887        3 Batch loss: 0.235503 Batch F1: 0.2857142857142857
Epoch:  887        4 Batch loss: 0.231993 Batch F1: 0.4
Epoch:  887        5 Batch loss: 0.234241 Batch F1: 0.32
Epoch:  887        6 Batch loss: 0.178917 Batch F1: 0.8387096774193548
Epoch:  887        7 Batch loss: 0.207056 Batch F1: 0.3
Epoch:  887        8 Batch loss: 0.221510 Batch F1: 0.32
Epoch:  887        9 Batch loss: 0.227504 Batch F1: 0.18181818181818182
Epoch:  887       10 Batch loss: 0.222274 Batch F1: 0.0
Epoch:  887       11 Batch loss: 0.220370 Batch F1: 0.0
Epoch:  887       12 Batch loss: 0.259930 Batch F1: 0.0
Train Avg Loss  887: 0.224542

Train Avg F1  887: 0.2525714607972672

Val Avg Loss  887: 0.217546

Val Avg F1  887:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 888
--------------------------------------------------------------
Epoch:  888        1 Batch loss: 0.230565 Batch F1: 0.09523809523809523
Epoch:  888        2 Batch loss: 0.215178 Batch F1: 0.3333333333333333
Epoch:  888        3 Batch loss: 0.234320 Batch F1: 0.37037037037037035
Epoch:  888        4 Batch loss: 0.222833 Batch F1: 0.6
Epoch:  888        5 Batch loss: 0.239358 Batch F1: 0.16666666666666669
Epoch:  888        6 Batch loss: 0.267751 Batch F1: 0.0
Epoch:  888        7 Batch loss: 0.194842 Batch F1: 0.0
Epoch:  888        8 Batch loss: 0.192858 Batch F1: 0.25
Epoch:  888        9 Batch loss: 0.214041 Batch F1: 0.0
Epoch:  888       10 Batch loss: 0.221021 Batch F1: 0.0
Epoch:  888       11 Batch loss: 0.226355 Batch F1: 0.0
Epoch:  888       12 Batch loss: 0.228203 Batch F1: 0.0
Train Avg Loss  888: 0.223944

Train Avg F1  888: 0.15130070546737212

Val Avg Loss  888: 0.218210

Val Avg F1  888:  0.2577352472089314

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 889
--------------------------------------------------------------
Epoch:  889        1 Batch loss: 0.222655 Batch F1: 0.2962962962962963
Epoch:  889        2 Batch loss: 0.230059 Batch F1: 0.3225806451612903
Epoch:  889        3 Batch loss: 0.222466 Batch F1: 0.5454545454545455
Epoch:  889        4 Batch loss: 0.240723 Batch F1: 0.3703703703703704
Epoch:  889        5 Batch loss: 0.203019 Batch F1: 0.3636363636363637
Epoch:  889        6 Batch loss: 0.213705 Batch F1: 0.30769230769230765
Epoch:  889        7 Batch loss: 0.233556 Batch F1: 0.0
Epoch:  889        8 Batch loss: 0.264585 Batch F1: 0.07692307692307693
Epoch:  889        9 Batch loss: 0.207792 Batch F1: 0.0
Epoch:  889       10 Batch loss: 0.204846 Batch F1: 0.0
Epoch:  889       11 Batch loss: 0.231866 Batch F1: 0.0
Epoch:  889       12 Batch loss: 0.201510 Batch F1: 0.0
Train Avg Loss  889: 0.223065

Train Avg F1  889: 0.19024613379452093

Val Avg Loss  889: 0.217080

Val Avg F1  889:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 890
--------------------------------------------------------------
Epoch:  890        1 Batch loss: 0.206984 Batch F1: 0.0
Epoch:  890        2 Batch loss: 0.236644 Batch F1: 0.0
Epoch:  890        3 Batch loss: 0.177240 Batch F1: 0.0
Epoch:  890        4 Batch loss: 0.217717 Batch F1: 0.0
Epoch:  890        5 Batch loss: 0.248260 Batch F1: 0.0
Epoch:  890        6 Batch loss: 0.203704 Batch F1: 0.0
Epoch:  890        7 Batch loss: 0.237092 Batch F1: 0.19047619047619047
Epoch:  890        8 Batch loss: 0.238747 Batch F1: 0.23076923076923078
Epoch:  890        9 Batch loss: 0.230674 Batch F1: 0.4444444444444444
Epoch:  890       10 Batch loss: 0.228614 Batch F1: 0.16666666666666666
Epoch:  890       11 Batch loss: 0.188251 Batch F1: 0.5384615384615384
Epoch:  890       12 Batch loss: 0.281493 Batch F1: 0.08333333333333333
Train Avg Loss  890: 0.224618

Train Avg F1  890: 0.13784595034595035

Val Avg Loss  890: 0.218920

Val Avg F1  890:  0.09818023319167483

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 891
--------------------------------------------------------------
Epoch:  891        1 Batch loss: 0.249826 Batch F1: 0.08695652173913045
Epoch:  891        2 Batch loss: 0.235450 Batch F1: 0.09523809523809525
Epoch:  891        3 Batch loss: 0.210638 Batch F1: 0.2608695652173913
Epoch:  891        4 Batch loss: 0.208109 Batch F1: 0.37037037037037035
Epoch:  891        5 Batch loss: 0.236943 Batch F1: 0.24
Epoch:  891        6 Batch loss: 0.186965 Batch F1: 0.4545454545454545
Epoch:  891        7 Batch loss: 0.198647 Batch F1: 0.5333333333333333
Epoch:  891        8 Batch loss: 0.224860 Batch F1: 0.37037037037037035
Epoch:  891        9 Batch loss: 0.241200 Batch F1: 0.2727272727272727
Epoch:  891       10 Batch loss: 0.212558 Batch F1: 0.1111111111111111
Epoch:  891       11 Batch loss: 0.238150 Batch F1: 0.08333333333333334
Epoch:  891       12 Batch loss: 0.232326 Batch F1: 0.0
Train Avg Loss  891: 0.222973

Train Avg F1  891: 0.23990461899882187

Val Avg Loss  891: 0.218119

Val Avg F1  891:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 892
--------------------------------------------------------------
Epoch:  892        1 Batch loss: 0.245977 Batch F1: 0.0
Epoch:  892        2 Batch loss: 0.204992 Batch F1: 0.0
Epoch:  892        3 Batch loss: 0.260297 Batch F1: 0.0
Epoch:  892        4 Batch loss: 0.234959 Batch F1: 0.0
Epoch:  892        5 Batch loss: 0.224599 Batch F1: 0.0
Epoch:  892        6 Batch loss: 0.207392 Batch F1: 0.34782608695652173
Epoch:  892        7 Batch loss: 0.242513 Batch F1: 0.2222222222222222
Epoch:  892        8 Batch loss: 0.212667 Batch F1: 0.2
Epoch:  892        9 Batch loss: 0.210589 Batch F1: 0.4
Epoch:  892       10 Batch loss: 0.208075 Batch F1: 0.1818181818181818
Epoch:  892       11 Batch loss: 0.213241 Batch F1: 0.39999999999999997
Epoch:  892       12 Batch loss: 0.212140 Batch F1: 0.14285714285714288
Train Avg Loss  892: 0.223120

Train Avg F1  892: 0.15789363615450572

Val Avg Loss  892: 0.216641

Val Avg F1  892:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 893
--------------------------------------------------------------
Epoch:  893        1 Batch loss: 0.208337 Batch F1: 0.0
Epoch:  893        2 Batch loss: 0.192882 Batch F1: 0.0
Epoch:  893        3 Batch loss: 0.276766 Batch F1: 0.0
Epoch:  893        4 Batch loss: 0.185354 Batch F1: 0.0
Epoch:  893        5 Batch loss: 0.207032 Batch F1: 0.0
Epoch:  893        6 Batch loss: 0.242381 Batch F1: 0.0
Epoch:  893        7 Batch loss: 0.212527 Batch F1: 0.24999999999999997
Epoch:  893        8 Batch loss: 0.235870 Batch F1: 0.21428571428571425
Epoch:  893        9 Batch loss: 0.217978 Batch F1: 0.6060606060606061
Epoch:  893       10 Batch loss: 0.245839 Batch F1: 0.25
Epoch:  893       11 Batch loss: 0.209289 Batch F1: 0.5185185185185185
Epoch:  893       12 Batch loss: 0.256666 Batch F1: 0.4444444444444444
Train Avg Loss  893: 0.224243

Train Avg F1  893: 0.19027577360910697

Val Avg Loss  893: 0.219859

Val Avg F1  893:  0.25557971014492753

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 894
--------------------------------------------------------------
Epoch:  894        1 Batch loss: 0.225573 Batch F1: 0.42424242424242425
Epoch:  894        2 Batch loss: 0.243454 Batch F1: 0.24
Epoch:  894        3 Batch loss: 0.168056 Batch F1: 0.4210526315789474
Epoch:  894        4 Batch loss: 0.212062 Batch F1: 0.0
Epoch:  894        5 Batch loss: 0.195730 Batch F1: 0.0
Epoch:  894        6 Batch loss: 0.240249 Batch F1: 0.0
Epoch:  894        7 Batch loss: 0.219408 Batch F1: 0.0
Epoch:  894        8 Batch loss: 0.207180 Batch F1: 0.0
Epoch:  894        9 Batch loss: 0.254385 Batch F1: 0.0
Epoch:  894       10 Batch loss: 0.246868 Batch F1: 0.0
Epoch:  894       11 Batch loss: 0.248921 Batch F1: 0.0
Epoch:  894       12 Batch loss: 0.243241 Batch F1: 0.27272727272727276
Train Avg Loss  894: 0.225427

Train Avg F1  894: 0.1131685273790537

Val Avg Loss  894: 0.228107

Val Avg F1  894:  0.2663951545530493

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 895
--------------------------------------------------------------
Epoch:  895        1 Batch loss: 0.248333 Batch F1: 0.42424242424242425
Epoch:  895        2 Batch loss: 0.220488 Batch F1: 0.3
Epoch:  895        3 Batch loss: 0.243122 Batch F1: 0.45161290322580644
Epoch:  895        4 Batch loss: 0.247089 Batch F1: 0.0
Epoch:  895        5 Batch loss: 0.209721 Batch F1: 0.0
Epoch:  895        6 Batch loss: 0.199968 Batch F1: 0.0
Epoch:  895        7 Batch loss: 0.200167 Batch F1: 0.0
Epoch:  895        8 Batch loss: 0.246749 Batch F1: 0.0
Epoch:  895        9 Batch loss: 0.236044 Batch F1: 0.0
Epoch:  895       10 Batch loss: 0.231845 Batch F1: 0.0
Epoch:  895       11 Batch loss: 0.226532 Batch F1: 0.0
Epoch:  895       12 Batch loss: 0.231377 Batch F1: 0.0
Train Avg Loss  895: 0.228453

Train Avg F1  895: 0.09798794395568589

Val Avg Loss  895: 0.225868

Val Avg F1  895:  0.2754054083788065

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 896
--------------------------------------------------------------
Epoch:  896        1 Batch loss: 0.227403 Batch F1: 0.0
Epoch:  896        2 Batch loss: 0.229126 Batch F1: 0.3870967741935483
Epoch:  896        3 Batch loss: 0.253505 Batch F1: 0.20689655172413793
Epoch:  896        4 Batch loss: 0.233382 Batch F1: 0.31999999999999995
Epoch:  896        5 Batch loss: 0.244159 Batch F1: 0.08695652173913042
Epoch:  896        6 Batch loss: 0.238996 Batch F1: 0.0
Epoch:  896        7 Batch loss: 0.203454 Batch F1: 0.0
Epoch:  896        8 Batch loss: 0.195755 Batch F1: 0.0
Epoch:  896        9 Batch loss: 0.234624 Batch F1: 0.0
Epoch:  896       10 Batch loss: 0.202036 Batch F1: 0.0
Epoch:  896       11 Batch loss: 0.213658 Batch F1: 0.2857142857142857
Epoch:  896       12 Batch loss: 0.224461 Batch F1: 0.2222222222222222
Train Avg Loss  896: 0.225047

Train Avg F1  896: 0.12574052963277704

Val Avg Loss  896: 0.220555

Val Avg F1  896:  0.24201873810569463

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 897
--------------------------------------------------------------
Epoch:  897        1 Batch loss: 0.201189 Batch F1: 0.3333333333333333
Epoch:  897        2 Batch loss: 0.228540 Batch F1: 0.28571428571428575
Epoch:  897        3 Batch loss: 0.209581 Batch F1: 0.26086956521739124
Epoch:  897        4 Batch loss: 0.217986 Batch F1: 0.3448275862068965
Epoch:  897        5 Batch loss: 0.235084 Batch F1: 0.26086956521739124
Epoch:  897        6 Batch loss: 0.213182 Batch F1: 0.5454545454545455
Epoch:  897        7 Batch loss: 0.262929 Batch F1: 0.45714285714285713
Epoch:  897        8 Batch loss: 0.200561 Batch F1: 0.15384615384615385
Epoch:  897        9 Batch loss: 0.203316 Batch F1: 0.2727272727272727
Epoch:  897       10 Batch loss: 0.250017 Batch F1: 0.22222222222222224
Epoch:  897       11 Batch loss: 0.195349 Batch F1: 0.45454545454545453
Epoch:  897       12 Batch loss: 0.256131 Batch F1: 0.0
Train Avg Loss  897: 0.222822

Train Avg F1  897: 0.29929607013565035

Val Avg Loss  897: 0.217000

Val Avg F1  897:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 898
--------------------------------------------------------------
Epoch:  898        1 Batch loss: 0.284666 Batch F1: 0.0
Epoch:  898        2 Batch loss: 0.202343 Batch F1: 0.0
Epoch:  898        3 Batch loss: 0.255118 Batch F1: 0.3125
Epoch:  898        4 Batch loss: 0.212190 Batch F1: 0.1111111111111111
Epoch:  898        5 Batch loss: 0.258289 Batch F1: 0.24242424242424246
Epoch:  898        6 Batch loss: 0.202688 Batch F1: 0.5833333333333334
Epoch:  898        7 Batch loss: 0.206330 Batch F1: 0.39999999999999997
Epoch:  898        8 Batch loss: 0.200607 Batch F1: 0.42857142857142855
Epoch:  898        9 Batch loss: 0.203496 Batch F1: 0.44444444444444436
Epoch:  898       10 Batch loss: 0.187378 Batch F1: 0.4
Epoch:  898       11 Batch loss: 0.231982 Batch F1: 0.2608695652173913
Epoch:  898       12 Batch loss: 0.243101 Batch F1: 0.0
Train Avg Loss  898: 0.224016

Train Avg F1  898: 0.2652711770918292

Val Avg Loss  898: 0.218131

Val Avg F1  898:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 899
--------------------------------------------------------------
Epoch:  899        1 Batch loss: 0.231575 Batch F1: 0.0
Epoch:  899        2 Batch loss: 0.262050 Batch F1: 0.0
Epoch:  899        3 Batch loss: 0.197482 Batch F1: 0.0
Epoch:  899        4 Batch loss: 0.212461 Batch F1: 0.0
Epoch:  899        5 Batch loss: 0.247755 Batch F1: 0.0
Epoch:  899        6 Batch loss: 0.241011 Batch F1: 0.0
Epoch:  899        7 Batch loss: 0.201282 Batch F1: 0.0
Epoch:  899        8 Batch loss: 0.205938 Batch F1: 0.0
Epoch:  899        9 Batch loss: 0.194038 Batch F1: 0.0
Epoch:  899       10 Batch loss: 0.242126 Batch F1: 0.0
Epoch:  899       11 Batch loss: 0.238153 Batch F1: 0.0
Epoch:  899       12 Batch loss: 0.230525 Batch F1: 0.0
Train Avg Loss  899: 0.225366

Train Avg F1  899: 0.0

Val Avg Loss  899: 0.218308

Val Avg F1  899:  0.1767251461988304

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 900
--------------------------------------------------------------
Epoch:  900        1 Batch loss: 0.260841 Batch F1: 0.14285714285714285
Epoch:  900        2 Batch loss: 0.214620 Batch F1: 0.2857142857142857
Epoch:  900        3 Batch loss: 0.229468 Batch F1: 0.25
Epoch:  900        4 Batch loss: 0.221863 Batch F1: 0.34782608695652173
Epoch:  900        5 Batch loss: 0.194068 Batch F1: 0.28571428571428575
Epoch:  900        6 Batch loss: 0.235686 Batch F1: 0.14814814814814814
Epoch:  900        7 Batch loss: 0.241821 Batch F1: 0.4137931034482759
Epoch:  900        8 Batch loss: 0.216199 Batch F1: 0.125
Epoch:  900        9 Batch loss: 0.211889 Batch F1: 0.0
Epoch:  900       10 Batch loss: 0.213919 Batch F1: 0.1111111111111111
Epoch:  900       11 Batch loss: 0.248078 Batch F1: 0.3125
Epoch:  900       12 Batch loss: 0.189291 Batch F1: 0.3333333333333333
Train Avg Loss  900: 0.223145

Train Avg F1  900: 0.2296664581069254

Val Avg Loss  900: 0.218436

Val Avg F1  900:  0.15869565217391304

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 901
--------------------------------------------------------------
Epoch:  901        1 Batch loss: 0.216124 Batch F1: 0.2727272727272727
Epoch:  901        2 Batch loss: 0.203573 Batch F1: 0.3333333333333333
Epoch:  901        3 Batch loss: 0.203205 Batch F1: 0.0
Epoch:  901        4 Batch loss: 0.203506 Batch F1: 0.0
Epoch:  901        5 Batch loss: 0.217231 Batch F1: 0.0
Epoch:  901        6 Batch loss: 0.251705 Batch F1: 0.0
Epoch:  901        7 Batch loss: 0.248511 Batch F1: 0.0
Epoch:  901        8 Batch loss: 0.231844 Batch F1: 0.0
Epoch:  901        9 Batch loss: 0.209316 Batch F1: 0.0
Epoch:  901       10 Batch loss: 0.218372 Batch F1: 0.45161290322580644
Epoch:  901       11 Batch loss: 0.239789 Batch F1: 0.2608695652173913
Epoch:  901       12 Batch loss: 0.228362 Batch F1: 0.2857142857142857
Train Avg Loss  901: 0.222628

Train Avg F1  901: 0.13368811335150746

Val Avg Loss  901: 0.220122

Val Avg F1  901:  0.2643537496985773

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 902
--------------------------------------------------------------
Epoch:  902        1 Batch loss: 0.226720 Batch F1: 0.1818181818181818
Epoch:  902        2 Batch loss: 0.211419 Batch F1: 0.5161290322580645
Epoch:  902        3 Batch loss: 0.239495 Batch F1: 0.16666666666666666
Epoch:  902        4 Batch loss: 0.220498 Batch F1: 0.4137931034482759
Epoch:  902        5 Batch loss: 0.207487 Batch F1: 0.33333333333333337
Epoch:  902        6 Batch loss: 0.234591 Batch F1: 0.3333333333333333
Epoch:  902        7 Batch loss: 0.245217 Batch F1: 0.37037037037037035
Epoch:  902        8 Batch loss: 0.218948 Batch F1: 0.0
Epoch:  902        9 Batch loss: 0.220632 Batch F1: 0.0
Epoch:  902       10 Batch loss: 0.238463 Batch F1: 0.0
Epoch:  902       11 Batch loss: 0.223212 Batch F1: 0.0
Epoch:  902       12 Batch loss: 0.186773 Batch F1: 0.14285714285714288
Train Avg Loss  902: 0.222788

Train Avg F1  902: 0.2048584303404474

Val Avg Loss  902: 0.220306

Val Avg F1  902:  0.248695652173913

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 903
--------------------------------------------------------------
Epoch:  903        1 Batch loss: 0.237452 Batch F1: 0.21428571428571427
Epoch:  903        2 Batch loss: 0.197957 Batch F1: 0.6428571428571428
Epoch:  903        3 Batch loss: 0.210301 Batch F1: 0.5185185185185185
Epoch:  903        4 Batch loss: 0.236333 Batch F1: 0.3870967741935484
Epoch:  903        5 Batch loss: 0.191963 Batch F1: 0.5
Epoch:  903        6 Batch loss: 0.182875 Batch F1: 0.13333333333333333
Epoch:  903        7 Batch loss: 0.236007 Batch F1: 0.0
Epoch:  903        8 Batch loss: 0.240752 Batch F1: 0.0
Epoch:  903        9 Batch loss: 0.254519 Batch F1: 0.0
Epoch:  903       10 Batch loss: 0.215208 Batch F1: 0.0
Epoch:  903       11 Batch loss: 0.238444 Batch F1: 0.0
Epoch:  903       12 Batch loss: 0.253992 Batch F1: 0.0
Train Avg Loss  903: 0.224650

Train Avg F1  903: 0.1996742902656881

Val Avg Loss  903: 0.220158

Val Avg F1  903:  0.16058079982565107

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 904
--------------------------------------------------------------
Epoch:  904        1 Batch loss: 0.221375 Batch F1: 0.17391304347826084
Epoch:  904        2 Batch loss: 0.225747 Batch F1: 0.21428571428571427
Epoch:  904        3 Batch loss: 0.217042 Batch F1: 0.5384615384615384
Epoch:  904        4 Batch loss: 0.222493 Batch F1: 0.33333333333333337
Epoch:  904        5 Batch loss: 0.249390 Batch F1: 0.47058823529411764
Epoch:  904        6 Batch loss: 0.203461 Batch F1: 0.3157894736842105
Epoch:  904        7 Batch loss: 0.223903 Batch F1: 0.39999999999999997
Epoch:  904        8 Batch loss: 0.206972 Batch F1: 0.32
Epoch:  904        9 Batch loss: 0.254529 Batch F1: 0.0
Epoch:  904       10 Batch loss: 0.242535 Batch F1: 0.0
Epoch:  904       11 Batch loss: 0.207003 Batch F1: 0.0
Epoch:  904       12 Batch loss: 0.248550 Batch F1: 0.0
Train Avg Loss  904: 0.226917

Train Avg F1  904: 0.23053094487809792

Val Avg Loss  904: 0.218786

Val Avg F1  904:  0.19807692307692307

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 905
--------------------------------------------------------------
Epoch:  905        1 Batch loss: 0.254343 Batch F1: 0.19999999999999998
Epoch:  905        2 Batch loss: 0.228667 Batch F1: 0.5
Epoch:  905        3 Batch loss: 0.220615 Batch F1: 0.3333333333333333
Epoch:  905        4 Batch loss: 0.240047 Batch F1: 0.3125
Epoch:  905        5 Batch loss: 0.218460 Batch F1: 0.09523809523809523
Epoch:  905        6 Batch loss: 0.235041 Batch F1: 0.0
Epoch:  905        7 Batch loss: 0.204011 Batch F1: 0.0
Epoch:  905        8 Batch loss: 0.213571 Batch F1: 0.0
Epoch:  905        9 Batch loss: 0.251162 Batch F1: 0.0
Epoch:  905       10 Batch loss: 0.206337 Batch F1: 0.0
Epoch:  905       11 Batch loss: 0.218306 Batch F1: 0.0
Epoch:  905       12 Batch loss: 0.213426 Batch F1: 0.33333333333333326
Train Avg Loss  905: 0.225332

Train Avg F1  905: 0.1478670634920635

Val Avg Loss  905: 0.217768

Val Avg F1  905:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 906
--------------------------------------------------------------
Epoch:  906        1 Batch loss: 0.229327 Batch F1: 0.0
Epoch:  906        2 Batch loss: 0.181679 Batch F1: 0.3157894736842105
Epoch:  906        3 Batch loss: 0.199773 Batch F1: 0.1111111111111111
Epoch:  906        4 Batch loss: 0.272269 Batch F1: 0.08
Epoch:  906        5 Batch loss: 0.235567 Batch F1: 0.1818181818181818
Epoch:  906        6 Batch loss: 0.224494 Batch F1: 0.1
Epoch:  906        7 Batch loss: 0.243648 Batch F1: 0.0
Epoch:  906        8 Batch loss: 0.201198 Batch F1: 0.0
Epoch:  906        9 Batch loss: 0.224971 Batch F1: 0.25
Epoch:  906       10 Batch loss: 0.235296 Batch F1: 0.4
Epoch:  906       11 Batch loss: 0.222672 Batch F1: 0.41379310344827586
Epoch:  906       12 Batch loss: 0.219656 Batch F1: 0.36363636363636365
Train Avg Loss  906: 0.224212

Train Avg F1  906: 0.18467901947484525

Val Avg Loss  906: 0.219984

Val Avg F1  906:  0.23119879672299026

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 907
--------------------------------------------------------------
Epoch:  907        1 Batch loss: 0.216614 Batch F1: 0.25
Epoch:  907        2 Batch loss: 0.207308 Batch F1: 0.0
Epoch:  907        3 Batch loss: 0.203867 Batch F1: 0.0
Epoch:  907        4 Batch loss: 0.239629 Batch F1: 0.0
Epoch:  907        5 Batch loss: 0.208769 Batch F1: 0.0
Epoch:  907        6 Batch loss: 0.222927 Batch F1: 0.0
Epoch:  907        7 Batch loss: 0.219416 Batch F1: 0.0
Epoch:  907        8 Batch loss: 0.229587 Batch F1: 0.0
Epoch:  907        9 Batch loss: 0.219453 Batch F1: 0.0
Epoch:  907       10 Batch loss: 0.231870 Batch F1: 0.0
Epoch:  907       11 Batch loss: 0.224393 Batch F1: 0.37037037037037035
Epoch:  907       12 Batch loss: 0.249692 Batch F1: 0.3333333333333333
Train Avg Loss  907: 0.222794

Train Avg F1  907: 0.07947530864197531

Val Avg Loss  907: 0.222488

Val Avg F1  907:  0.3439010989010989

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 908
--------------------------------------------------------------
Epoch:  908        1 Batch loss: 0.228597 Batch F1: 0.4117647058823529
Epoch:  908        2 Batch loss: 0.220215 Batch F1: 0.4827586206896552
Epoch:  908        3 Batch loss: 0.220571 Batch F1: 0.6
Epoch:  908        4 Batch loss: 0.227470 Batch F1: 0.30769230769230765
Epoch:  908        5 Batch loss: 0.242755 Batch F1: 0.14814814814814814
Epoch:  908        6 Batch loss: 0.202369 Batch F1: 0.4166666666666667
Epoch:  908        7 Batch loss: 0.231449 Batch F1: 0.4
Epoch:  908        8 Batch loss: 0.226782 Batch F1: 0.32000000000000006
Epoch:  908        9 Batch loss: 0.224031 Batch F1: 0.48
Epoch:  908       10 Batch loss: 0.225698 Batch F1: 0.18181818181818182
Epoch:  908       11 Batch loss: 0.232432 Batch F1: 0.37037037037037035
Epoch:  908       12 Batch loss: 0.194370 Batch F1: 0.0
Train Avg Loss  908: 0.223062

Train Avg F1  908: 0.34326825010564027

Val Avg Loss  908: 0.219616

Val Avg F1  908:  0.23076923076923073

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 909
--------------------------------------------------------------
Epoch:  909        1 Batch loss: 0.218999 Batch F1: 0.2608695652173913
Epoch:  909        2 Batch loss: 0.259488 Batch F1: 0.14285714285714288
Epoch:  909        3 Batch loss: 0.195558 Batch F1: 0.11764705882352941
Epoch:  909        4 Batch loss: 0.168573 Batch F1: 0.5
Epoch:  909        5 Batch loss: 0.224847 Batch F1: 0.22222222222222224
Epoch:  909        6 Batch loss: 0.272260 Batch F1: 0.25806451612903225
Epoch:  909        7 Batch loss: 0.208777 Batch F1: 0.19047619047619047
Epoch:  909        8 Batch loss: 0.216737 Batch F1: 0.37037037037037035
Epoch:  909        9 Batch loss: 0.217779 Batch F1: 0.4166666666666667
Epoch:  909       10 Batch loss: 0.239608 Batch F1: 0.43749999999999994
Epoch:  909       11 Batch loss: 0.227889 Batch F1: 0.26666666666666666
Epoch:  909       12 Batch loss: 0.211579 Batch F1: 0.42105263157894735
Train Avg Loss  909: 0.221841

Train Avg F1  909: 0.30036608591734665

Val Avg Loss  909: 0.218155

Val Avg F1  909:  0.26507122507122505

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 910
--------------------------------------------------------------
Epoch:  910        1 Batch loss: 0.183032 Batch F1: 0.0
Epoch:  910        2 Batch loss: 0.205594 Batch F1: 0.3333333333333333
Epoch:  910        3 Batch loss: 0.254463 Batch F1: 0.4
Epoch:  910        4 Batch loss: 0.246707 Batch F1: 0.3448275862068966
Epoch:  910        5 Batch loss: 0.234949 Batch F1: 0.23076923076923078
Epoch:  910        6 Batch loss: 0.208580 Batch F1: 0.10526315789473684
Epoch:  910        7 Batch loss: 0.218847 Batch F1: 0.21052631578947367
Epoch:  910        8 Batch loss: 0.208153 Batch F1: 0.1818181818181818
Epoch:  910        9 Batch loss: 0.245103 Batch F1: 0.19999999999999998
Epoch:  910       10 Batch loss: 0.189839 Batch F1: 0.10526315789473684
Epoch:  910       11 Batch loss: 0.219796 Batch F1: 0.2
Epoch:  910       12 Batch loss: 0.255597 Batch F1: 0.4
Train Avg Loss  910: 0.222555

Train Avg F1  910: 0.22598341364221586

Val Avg Loss  910: 0.218192

Val Avg F1  910:  0.23369565217391303

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 911
--------------------------------------------------------------
Epoch:  911        1 Batch loss: 0.222125 Batch F1: 0.3846153846153846
Epoch:  911        2 Batch loss: 0.208530 Batch F1: 0.1
Epoch:  911        3 Batch loss: 0.234786 Batch F1: 0.25
Epoch:  911        4 Batch loss: 0.199905 Batch F1: 0.3
Epoch:  911        5 Batch loss: 0.183691 Batch F1: 0.4545454545454545
Epoch:  911        6 Batch loss: 0.201076 Batch F1: 0.27272727272727276
Epoch:  911        7 Batch loss: 0.239996 Batch F1: 0.3448275862068966
Epoch:  911        8 Batch loss: 0.269694 Batch F1: 0.3125
Epoch:  911        9 Batch loss: 0.213066 Batch F1: 0.2608695652173913
Epoch:  911       10 Batch loss: 0.233769 Batch F1: 0.1818181818181818
Epoch:  911       11 Batch loss: 0.231855 Batch F1: 0.3448275862068965
Epoch:  911       12 Batch loss: 0.231631 Batch F1: 0.3846153846153846
Train Avg Loss  911: 0.222510

Train Avg F1  911: 0.29927886799607184

Val Avg Loss  911: 0.218806

Val Avg F1  911:  0.2613753999623565

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 912
--------------------------------------------------------------
Epoch:  912        1 Batch loss: 0.234794 Batch F1: 0.17391304347826084
Epoch:  912        2 Batch loss: 0.226216 Batch F1: 0.2962962962962963
Epoch:  912        3 Batch loss: 0.247457 Batch F1: 0.32
Epoch:  912        4 Batch loss: 0.200416 Batch F1: 0.5384615384615384
Epoch:  912        5 Batch loss: 0.234015 Batch F1: 0.4
Epoch:  912        6 Batch loss: 0.202700 Batch F1: 0.5161290322580645
Epoch:  912        7 Batch loss: 0.219223 Batch F1: 0.2608695652173913
Epoch:  912        8 Batch loss: 0.212100 Batch F1: 0.11111111111111112
Epoch:  912        9 Batch loss: 0.199585 Batch F1: 0.2222222222222222
Epoch:  912       10 Batch loss: 0.243009 Batch F1: 0.0
Epoch:  912       11 Batch loss: 0.269433 Batch F1: 0.0
Epoch:  912       12 Batch loss: 0.216746 Batch F1: 0.0
Train Avg Loss  912: 0.225474

Train Avg F1  912: 0.23658356742040706

Val Avg Loss  912: 0.222407

Val Avg F1  912:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 913
--------------------------------------------------------------
Epoch:  913        1 Batch loss: 0.221734 Batch F1: 0.0
Epoch:  913        2 Batch loss: 0.232223 Batch F1: 0.0
Epoch:  913        3 Batch loss: 0.231839 Batch F1: 0.08695652173913045
Epoch:  913        4 Batch loss: 0.213087 Batch F1: 0.0
Epoch:  913        5 Batch loss: 0.222390 Batch F1: 0.0
Epoch:  913        6 Batch loss: 0.191480 Batch F1: 0.0
Epoch:  913        7 Batch loss: 0.213038 Batch F1: 0.0
Epoch:  913        8 Batch loss: 0.190123 Batch F1: 0.0
Epoch:  913        9 Batch loss: 0.263534 Batch F1: 0.0
Epoch:  913       10 Batch loss: 0.258024 Batch F1: 0.0
Epoch:  913       11 Batch loss: 0.254108 Batch F1: 0.0
Epoch:  913       12 Batch loss: 0.224291 Batch F1: 0.5
Train Avg Loss  913: 0.226323

Train Avg F1  913: 0.04891304347826087

Val Avg Loss  913: 0.227522

Val Avg F1  913:  0.3372825091575092

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 914
--------------------------------------------------------------
Epoch:  914        1 Batch loss: 0.210895 Batch F1: 0.5714285714285715
Epoch:  914        2 Batch loss: 0.249178 Batch F1: 0.21428571428571427
Epoch:  914        3 Batch loss: 0.222345 Batch F1: 0.34782608695652173
Epoch:  914        4 Batch loss: 0.233787 Batch F1: 0.28571428571428575
Epoch:  914        5 Batch loss: 0.211135 Batch F1: 0.1111111111111111
Epoch:  914        6 Batch loss: 0.218783 Batch F1: 0.1
Epoch:  914        7 Batch loss: 0.224945 Batch F1: 0.0
Epoch:  914        8 Batch loss: 0.208037 Batch F1: 0.0
Epoch:  914        9 Batch loss: 0.253508 Batch F1: 0.0
Epoch:  914       10 Batch loss: 0.245360 Batch F1: 0.0
Epoch:  914       11 Batch loss: 0.202170 Batch F1: 0.0
Epoch:  914       12 Batch loss: 0.219113 Batch F1: 0.0
Train Avg Loss  914: 0.224938

Train Avg F1  914: 0.1358638141246837

Val Avg Loss  914: 0.218287

Val Avg F1  914:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 915
--------------------------------------------------------------
Epoch:  915        1 Batch loss: 0.217916 Batch F1: 0.0
Epoch:  915        2 Batch loss: 0.216961 Batch F1: 0.10526315789473682
Epoch:  915        3 Batch loss: 0.219255 Batch F1: 0.18181818181818182
Epoch:  915        4 Batch loss: 0.205651 Batch F1: 0.32
Epoch:  915        5 Batch loss: 0.235672 Batch F1: 0.3076923076923077
Epoch:  915        6 Batch loss: 0.207677 Batch F1: 0.5384615384615384
Epoch:  915        7 Batch loss: 0.207588 Batch F1: 0.3846153846153846
Epoch:  915        8 Batch loss: 0.236544 Batch F1: 0.2727272727272727
Epoch:  915        9 Batch loss: 0.247917 Batch F1: 0.2857142857142857
Epoch:  915       10 Batch loss: 0.228261 Batch F1: 0.0
Epoch:  915       11 Batch loss: 0.234134 Batch F1: 0.09090909090909091
Epoch:  915       12 Batch loss: 0.219199 Batch F1: 0.11764705882352941
Train Avg Loss  915: 0.223065

Train Avg F1  915: 0.21707068988802736

Val Avg Loss  915: 0.219108

Val Avg F1  915:  0.11825396825396825

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 916
--------------------------------------------------------------
Epoch:  916        1 Batch loss: 0.178633 Batch F1: 0.4
Epoch:  916        2 Batch loss: 0.233495 Batch F1: 0.16000000000000003
Epoch:  916        3 Batch loss: 0.208708 Batch F1: 0.48
Epoch:  916        4 Batch loss: 0.211137 Batch F1: 0.3846153846153846
Epoch:  916        5 Batch loss: 0.203527 Batch F1: 0.33333333333333337
Epoch:  916        6 Batch loss: 0.220059 Batch F1: 0.30769230769230765
Epoch:  916        7 Batch loss: 0.252708 Batch F1: 0.14814814814814814
Epoch:  916        8 Batch loss: 0.219906 Batch F1: 0.08695652173913043
Epoch:  916        9 Batch loss: 0.225126 Batch F1: 0.46153846153846156
Epoch:  916       10 Batch loss: 0.251418 Batch F1: 0.23076923076923075
Epoch:  916       11 Batch loss: 0.219158 Batch F1: 0.41379310344827586
Epoch:  916       12 Batch loss: 0.238638 Batch F1: 0.3333333333333333
Train Avg Loss  916: 0.221876

Train Avg F1  916: 0.31168165205146714

Val Avg Loss  916: 0.219585

Val Avg F1  916:  0.2510507246376812

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 917
--------------------------------------------------------------
Epoch:  917        1 Batch loss: 0.188254 Batch F1: 0.3157894736842105
Epoch:  917        2 Batch loss: 0.251567 Batch F1: 0.1818181818181818
Epoch:  917        3 Batch loss: 0.226068 Batch F1: 0.16666666666666666
Epoch:  917        4 Batch loss: 0.211062 Batch F1: 0.19047619047619047
Epoch:  917        5 Batch loss: 0.204045 Batch F1: 0.3478260869565218
Epoch:  917        6 Batch loss: 0.210454 Batch F1: 0.25
Epoch:  917        7 Batch loss: 0.289424 Batch F1: 0.30303030303030304
Epoch:  917        8 Batch loss: 0.201440 Batch F1: 0.4166666666666667
Epoch:  917        9 Batch loss: 0.221353 Batch F1: 0.23076923076923078
Epoch:  917       10 Batch loss: 0.211379 Batch F1: 0.42857142857142855
Epoch:  917       11 Batch loss: 0.226541 Batch F1: 0.09523809523809523
Epoch:  917       12 Batch loss: 0.222980 Batch F1: 0.2727272727272727
Train Avg Loss  917: 0.222047

Train Avg F1  917: 0.26663163305039733

Val Avg Loss  917: 0.218464

Val Avg F1  917:  0.2095444577352472

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 918
--------------------------------------------------------------
Epoch:  918        1 Batch loss: 0.220566 Batch F1: 0.1818181818181818
Epoch:  918        2 Batch loss: 0.212136 Batch F1: 0.0
Epoch:  918        3 Batch loss: 0.237115 Batch F1: 0.08333333333333333
Epoch:  918        4 Batch loss: 0.223293 Batch F1: 0.0
Epoch:  918        5 Batch loss: 0.224870 Batch F1: 0.0
Epoch:  918        6 Batch loss: 0.234323 Batch F1: 0.09523809523809525
Epoch:  918        7 Batch loss: 0.223051 Batch F1: 0.39999999999999997
Epoch:  918        8 Batch loss: 0.217553 Batch F1: 0.0
Epoch:  918        9 Batch loss: 0.260308 Batch F1: 0.0
Epoch:  918       10 Batch loss: 0.210325 Batch F1: 0.10526315789473684
Epoch:  918       11 Batch loss: 0.198384 Batch F1: 0.1111111111111111
Epoch:  918       12 Batch loss: 0.210116 Batch F1: 0.2222222222222222
Train Avg Loss  918: 0.222670

Train Avg F1  918: 0.09991550846814005

Val Avg Loss  918: 0.218739

Val Avg F1  918:  0.2537037037037037

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 919
--------------------------------------------------------------
Epoch:  919        1 Batch loss: 0.240961 Batch F1: 0.2857142857142857
Epoch:  919        2 Batch loss: 0.240831 Batch F1: 0.3225806451612903
Epoch:  919        3 Batch loss: 0.226849 Batch F1: 0.1818181818181818
Epoch:  919        4 Batch loss: 0.238367 Batch F1: 0.22222222222222218
Epoch:  919        5 Batch loss: 0.183353 Batch F1: 0.0
Epoch:  919        6 Batch loss: 0.214095 Batch F1: 0.3846153846153846
Epoch:  919        7 Batch loss: 0.202426 Batch F1: 0.25000000000000006
Epoch:  919        8 Batch loss: 0.200456 Batch F1: 0.0
Epoch:  919        9 Batch loss: 0.239644 Batch F1: 0.0
Epoch:  919       10 Batch loss: 0.228470 Batch F1: 0.0
Epoch:  919       11 Batch loss: 0.236697 Batch F1: 0.0
Epoch:  919       12 Batch loss: 0.228670 Batch F1: 0.32
Train Avg Loss  919: 0.223402

Train Avg F1  919: 0.16391255996094706

Val Avg Loss  919: 0.224103

Val Avg F1  919:  0.3269230769230769

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 920
--------------------------------------------------------------
Epoch:  920        1 Batch loss: 0.228923 Batch F1: 0.35714285714285715
Epoch:  920        2 Batch loss: 0.220260 Batch F1: 0.36363636363636365
Epoch:  920        3 Batch loss: 0.218615 Batch F1: 0.0
Epoch:  920        4 Batch loss: 0.230353 Batch F1: 0.0
Epoch:  920        5 Batch loss: 0.209857 Batch F1: 0.1111111111111111
Epoch:  920        6 Batch loss: 0.211195 Batch F1: 0.0
Epoch:  920        7 Batch loss: 0.257840 Batch F1: 0.0
Epoch:  920        8 Batch loss: 0.221221 Batch F1: 0.0
Epoch:  920        9 Batch loss: 0.233271 Batch F1: 0.2222222222222222
Epoch:  920       10 Batch loss: 0.185846 Batch F1: 0.37499999999999994
Epoch:  920       11 Batch loss: 0.221464 Batch F1: 0.0
Epoch:  920       12 Batch loss: 0.273524 Batch F1: 0.0
Train Avg Loss  920: 0.226031

Train Avg F1  920: 0.11909271284271283

Val Avg Loss  920: 0.216953

Val Avg F1  920:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 921
--------------------------------------------------------------
Epoch:  921        1 Batch loss: 0.216649 Batch F1: 0.0
Epoch:  921        2 Batch loss: 0.220667 Batch F1: 0.2857142857142857
Epoch:  921        3 Batch loss: 0.235670 Batch F1: 0.1739130434782609
Epoch:  921        4 Batch loss: 0.180069 Batch F1: 0.33333333333333337
Epoch:  921        5 Batch loss: 0.225186 Batch F1: 0.09090909090909091
Epoch:  921        6 Batch loss: 0.218788 Batch F1: 0.2608695652173913
Epoch:  921        7 Batch loss: 0.215417 Batch F1: 0.39999999999999997
Epoch:  921        8 Batch loss: 0.230654 Batch F1: 0.37037037037037035
Epoch:  921        9 Batch loss: 0.234905 Batch F1: 0.3448275862068966
Epoch:  921       10 Batch loss: 0.215940 Batch F1: 0.4
Epoch:  921       11 Batch loss: 0.225238 Batch F1: 0.4
Epoch:  921       12 Batch loss: 0.240043 Batch F1: 0.4999999999999999
Train Avg Loss  921: 0.221602

Train Avg F1  921: 0.2966614396024691

Val Avg Loss  921: 0.222220

Val Avg F1  921:  0.3188021655763591

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 922
--------------------------------------------------------------
Epoch:  922        1 Batch loss: 0.248442 Batch F1: 0.37499999999999994
Epoch:  922        2 Batch loss: 0.259747 Batch F1: 0.23999999999999996
Epoch:  922        3 Batch loss: 0.206266 Batch F1: 0.5384615384615384
Epoch:  922        4 Batch loss: 0.231513 Batch F1: 0.23076923076923078
Epoch:  922        5 Batch loss: 0.231724 Batch F1: 0.16
Epoch:  922        6 Batch loss: 0.203047 Batch F1: 0.10526315789473684
Epoch:  922        7 Batch loss: 0.239160 Batch F1: 0.16
Epoch:  922        8 Batch loss: 0.215990 Batch F1: 0.4799999999999999
Epoch:  922        9 Batch loss: 0.201498 Batch F1: 0.4
Epoch:  922       10 Batch loss: 0.182043 Batch F1: 0.3157894736842105
Epoch:  922       11 Batch loss: 0.263454 Batch F1: 0.20689655172413793
Epoch:  922       12 Batch loss: 0.183291 Batch F1: 0.3529411764705882
Train Avg Loss  922: 0.222181

Train Avg F1  922: 0.29709342741703687

Val Avg Loss  922: 0.219283

Val Avg F1  922:  0.24547619047619046

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 923
--------------------------------------------------------------
Epoch:  923        1 Batch loss: 0.221737 Batch F1: 0.1818181818181818
Epoch:  923        2 Batch loss: 0.227490 Batch F1: 0.20689655172413793
Epoch:  923        3 Batch loss: 0.212406 Batch F1: 0.11764705882352941
Epoch:  923        4 Batch loss: 0.189852 Batch F1: 0.21052631578947367
Epoch:  923        5 Batch loss: 0.222602 Batch F1: 0.0
Epoch:  923        6 Batch loss: 0.208107 Batch F1: 0.0
Epoch:  923        7 Batch loss: 0.268986 Batch F1: 0.0
Epoch:  923        8 Batch loss: 0.236094 Batch F1: 0.33333333333333337
Epoch:  923        9 Batch loss: 0.243015 Batch F1: 0.37500000000000006
Epoch:  923       10 Batch loss: 0.210486 Batch F1: 0.43478260869565216
Epoch:  923       11 Batch loss: 0.235700 Batch F1: 0.3636363636363636
Epoch:  923       12 Batch loss: 0.189936 Batch F1: 0.25
Train Avg Loss  923: 0.222201

Train Avg F1  923: 0.20613670115172267

Val Avg Loss  923: 0.217625

Val Avg F1  923:  0.23716743782533256

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 924
--------------------------------------------------------------
Epoch:  924        1 Batch loss: 0.244462 Batch F1: 0.24999999999999997
Epoch:  924        2 Batch loss: 0.220203 Batch F1: 0.07999999999999999
Epoch:  924        3 Batch loss: 0.261143 Batch F1: 0.1739130434782609
Epoch:  924        4 Batch loss: 0.252619 Batch F1: 0.20689655172413796
Epoch:  924        5 Batch loss: 0.192028 Batch F1: 0.4
Epoch:  924        6 Batch loss: 0.250667 Batch F1: 0.2222222222222222
Epoch:  924        7 Batch loss: 0.227771 Batch F1: 0.18181818181818182
Epoch:  924        8 Batch loss: 0.233190 Batch F1: 0.09523809523809525
Epoch:  924        9 Batch loss: 0.181601 Batch F1: 0.0
Epoch:  924       10 Batch loss: 0.225280 Batch F1: 0.0
Epoch:  924       11 Batch loss: 0.185435 Batch F1: 0.0
Epoch:  924       12 Batch loss: 0.227533 Batch F1: 0.0
Train Avg Loss  924: 0.225161

Train Avg F1  924: 0.1341740078734082

Val Avg Loss  924: 0.217947

Val Avg F1  924:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 925
--------------------------------------------------------------
Epoch:  925        1 Batch loss: 0.243597 Batch F1: 0.0
Epoch:  925        2 Batch loss: 0.236467 Batch F1: 0.0
Epoch:  925        3 Batch loss: 0.231327 Batch F1: 0.18181818181818182
Epoch:  925        4 Batch loss: 0.223363 Batch F1: 0.5
Epoch:  925        5 Batch loss: 0.210722 Batch F1: 0.5
Epoch:  925        6 Batch loss: 0.223882 Batch F1: 0.4999999999999999
Epoch:  925        7 Batch loss: 0.238163 Batch F1: 0.09523809523809523
Epoch:  925        8 Batch loss: 0.224406 Batch F1: 0.25
Epoch:  925        9 Batch loss: 0.201249 Batch F1: 0.0
Epoch:  925       10 Batch loss: 0.191750 Batch F1: 0.0
Epoch:  925       11 Batch loss: 0.236041 Batch F1: 0.0
Epoch:  925       12 Batch loss: 0.243171 Batch F1: 0.0
Train Avg Loss  925: 0.225345

Train Avg F1  925: 0.16892135642135642

Val Avg Loss  925: 0.217467

Val Avg F1  925:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 926
--------------------------------------------------------------
Epoch:  926        1 Batch loss: 0.238807 Batch F1: 0.0
Epoch:  926        2 Batch loss: 0.221592 Batch F1: 0.3076923076923077
Epoch:  926        3 Batch loss: 0.205105 Batch F1: 0.3703703703703703
Epoch:  926        4 Batch loss: 0.220121 Batch F1: 0.3846153846153846
Epoch:  926        5 Batch loss: 0.222843 Batch F1: 0.5333333333333333
Epoch:  926        6 Batch loss: 0.235553 Batch F1: 0.3076923076923077
Epoch:  926        7 Batch loss: 0.198519 Batch F1: 0.3157894736842105
Epoch:  926        8 Batch loss: 0.231876 Batch F1: 0.27272727272727276
Epoch:  926        9 Batch loss: 0.213952 Batch F1: 0.2857142857142857
Epoch:  926       10 Batch loss: 0.256430 Batch F1: 0.0
Epoch:  926       11 Batch loss: 0.248887 Batch F1: 0.0
Epoch:  926       12 Batch loss: 0.185906 Batch F1: 0.0
Train Avg Loss  926: 0.223299

Train Avg F1  926: 0.23149456131912272

Val Avg Loss  926: 0.217447

Val Avg F1  926:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 927
--------------------------------------------------------------
Epoch:  927        1 Batch loss: 0.247815 Batch F1: 0.0
Epoch:  927        2 Batch loss: 0.225911 Batch F1: 0.2608695652173913
Epoch:  927        3 Batch loss: 0.228221 Batch F1: 0.24
Epoch:  927        4 Batch loss: 0.191589 Batch F1: 0.43478260869565216
Epoch:  927        5 Batch loss: 0.204787 Batch F1: 0.28571428571428575
Epoch:  927        6 Batch loss: 0.212258 Batch F1: 0.2
Epoch:  927        7 Batch loss: 0.205506 Batch F1: 0.27272727272727276
Epoch:  927        8 Batch loss: 0.249198 Batch F1: 0.3448275862068966
Epoch:  927        9 Batch loss: 0.203719 Batch F1: 0.4
Epoch:  927       10 Batch loss: 0.222592 Batch F1: 0.35714285714285715
Epoch:  927       11 Batch loss: 0.256339 Batch F1: 0.0
Epoch:  927       12 Batch loss: 0.230064 Batch F1: 0.33333333333333337
Train Avg Loss  927: 0.223167

Train Avg F1  927: 0.2607831257531407

Val Avg Loss  927: 0.218819

Val Avg F1  927:  0.247512077294686

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 928
--------------------------------------------------------------
Epoch:  928        1 Batch loss: 0.209585 Batch F1: 0.3
Epoch:  928        2 Batch loss: 0.217897 Batch F1: 0.2
Epoch:  928        3 Batch loss: 0.185131 Batch F1: 0.0
Epoch:  928        4 Batch loss: 0.201793 Batch F1: 0.1818181818181818
Epoch:  928        5 Batch loss: 0.244664 Batch F1: 0.0
Epoch:  928        6 Batch loss: 0.244988 Batch F1: 0.0
Epoch:  928        7 Batch loss: 0.232757 Batch F1: 0.09523809523809523
Epoch:  928        8 Batch loss: 0.209170 Batch F1: 0.4285714285714285
Epoch:  928        9 Batch loss: 0.250263 Batch F1: 0.16000000000000003
Epoch:  928       10 Batch loss: 0.218990 Batch F1: 0.37037037037037035
Epoch:  928       11 Batch loss: 0.234728 Batch F1: 0.30769230769230765
Epoch:  928       12 Batch loss: 0.224239 Batch F1: 0.2857142857142857
Train Avg Loss  928: 0.222851

Train Avg F1  928: 0.1941170557837224

Val Avg Loss  928: 0.220188

Val Avg F1  928:  0.25815850815850816

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 929
--------------------------------------------------------------
Epoch:  929        1 Batch loss: 0.221518 Batch F1: 0.1818181818181818
Epoch:  929        2 Batch loss: 0.226745 Batch F1: 0.35714285714285715
Epoch:  929        3 Batch loss: 0.197802 Batch F1: 0.39999999999999997
Epoch:  929        4 Batch loss: 0.239822 Batch F1: 0.3448275862068966
Epoch:  929        5 Batch loss: 0.271691 Batch F1: 0.3529411764705882
Epoch:  929        6 Batch loss: 0.216213 Batch F1: 0.23999999999999996
Epoch:  929        7 Batch loss: 0.209748 Batch F1: 0.5
Epoch:  929        8 Batch loss: 0.212828 Batch F1: 0.4827586206896552
Epoch:  929        9 Batch loss: 0.222747 Batch F1: 0.3333333333333333
Epoch:  929       10 Batch loss: 0.221077 Batch F1: 0.3333333333333333
Epoch:  929       11 Batch loss: 0.212818 Batch F1: 0.2727272727272727
Epoch:  929       12 Batch loss: 0.211062 Batch F1: 0.2105263157894737
Train Avg Loss  929: 0.222006

Train Avg F1  929: 0.33411738979263267

Val Avg Loss  929: 0.217703

Val Avg F1  929:  0.024999999999999998

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 930
--------------------------------------------------------------
Epoch:  930        1 Batch loss: 0.228632 Batch F1: 0.09523809523809525
Epoch:  930        2 Batch loss: 0.242160 Batch F1: 0.0
Epoch:  930        3 Batch loss: 0.214999 Batch F1: 0.10526315789473684
Epoch:  930        4 Batch loss: 0.209214 Batch F1: 0.38461538461538464
Epoch:  930        5 Batch loss: 0.218600 Batch F1: 0.2962962962962963
Epoch:  930        6 Batch loss: 0.237491 Batch F1: 0.16666666666666669
Epoch:  930        7 Batch loss: 0.209903 Batch F1: 0.32
Epoch:  930        8 Batch loss: 0.203920 Batch F1: 0.47619047619047616
Epoch:  930        9 Batch loss: 0.207008 Batch F1: 0.5714285714285714
Epoch:  930       10 Batch loss: 0.214681 Batch F1: 0.0
Epoch:  930       11 Batch loss: 0.243129 Batch F1: 0.0
Epoch:  930       12 Batch loss: 0.246181 Batch F1: 0.19047619047619047
Train Avg Loss  930: 0.222993

Train Avg F1  930: 0.21718123656720154

Val Avg Loss  930: 0.220464

Val Avg F1  930:  0.25513157894736843

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 931
--------------------------------------------------------------
Epoch:  931        1 Batch loss: 0.223499 Batch F1: 0.3846153846153846
Epoch:  931        2 Batch loss: 0.179265 Batch F1: 0.5925925925925927
Epoch:  931        3 Batch loss: 0.186210 Batch F1: 0.3157894736842105
Epoch:  931        4 Batch loss: 0.242622 Batch F1: 0.23076923076923073
Epoch:  931        5 Batch loss: 0.202543 Batch F1: 0.5806451612903226
Epoch:  931        6 Batch loss: 0.231776 Batch F1: 0.16666666666666669
Epoch:  931        7 Batch loss: 0.266506 Batch F1: 0.07692307692307693
Epoch:  931        8 Batch loss: 0.220014 Batch F1: 0.10526315789473685
Epoch:  931        9 Batch loss: 0.220293 Batch F1: 0.16666666666666666
Epoch:  931       10 Batch loss: 0.229280 Batch F1: 0.1818181818181818
Epoch:  931       11 Batch loss: 0.224115 Batch F1: 0.4166666666666667
Epoch:  931       12 Batch loss: 0.248988 Batch F1: 0.2
Train Avg Loss  931: 0.222926

Train Avg F1  931: 0.28486802163231134

Val Avg Loss  931: 0.217355

Val Avg F1  931:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 932
--------------------------------------------------------------
Epoch:  932        1 Batch loss: 0.224260 Batch F1: 0.0
Epoch:  932        2 Batch loss: 0.236564 Batch F1: 0.0
Epoch:  932        3 Batch loss: 0.212813 Batch F1: 0.0
Epoch:  932        4 Batch loss: 0.226024 Batch F1: 0.0
Epoch:  932        5 Batch loss: 0.250493 Batch F1: 0.0
Epoch:  932        6 Batch loss: 0.195544 Batch F1: 0.0
Epoch:  932        7 Batch loss: 0.237072 Batch F1: 0.09523809523809523
Epoch:  932        8 Batch loss: 0.243953 Batch F1: 0.17391304347826084
Epoch:  932        9 Batch loss: 0.206982 Batch F1: 0.2222222222222222
Epoch:  932       10 Batch loss: 0.223068 Batch F1: 0.0
Epoch:  932       11 Batch loss: 0.208470 Batch F1: 0.0
Epoch:  932       12 Batch loss: 0.229265 Batch F1: 0.0
Train Avg Loss  932: 0.224542

Train Avg F1  932: 0.04094778007821486

Val Avg Loss  932: 0.218850

Val Avg F1  932:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 933
--------------------------------------------------------------
Epoch:  933        1 Batch loss: 0.260224 Batch F1: 0.0
Epoch:  933        2 Batch loss: 0.247561 Batch F1: 0.0
Epoch:  933        3 Batch loss: 0.196139 Batch F1: 0.0
Epoch:  933        4 Batch loss: 0.223151 Batch F1: 0.2608695652173913
Epoch:  933        5 Batch loss: 0.193357 Batch F1: 0.23529411764705882
Epoch:  933        6 Batch loss: 0.215702 Batch F1: 0.30769230769230765
Epoch:  933        7 Batch loss: 0.250508 Batch F1: 0.3333333333333333
Epoch:  933        8 Batch loss: 0.209625 Batch F1: 0.2105263157894737
Epoch:  933        9 Batch loss: 0.227976 Batch F1: 0.3846153846153846
Epoch:  933       10 Batch loss: 0.213052 Batch F1: 0.3846153846153846
Epoch:  933       11 Batch loss: 0.215538 Batch F1: 0.3333333333333333
Epoch:  933       12 Batch loss: 0.231846 Batch F1: 0.27272727272727276
Train Avg Loss  933: 0.223723

Train Avg F1  933: 0.22691725124757833

Val Avg Loss  933: 0.220352

Val Avg F1  933:  0.25908119658119655

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 934
--------------------------------------------------------------
Epoch:  934        1 Batch loss: 0.224433 Batch F1: 0.3333333333333333
Epoch:  934        2 Batch loss: 0.202247 Batch F1: 0.2727272727272727
Epoch:  934        3 Batch loss: 0.195048 Batch F1: 0.2857142857142857
Epoch:  934        4 Batch loss: 0.226123 Batch F1: 0.39999999999999997
Epoch:  934        5 Batch loss: 0.234090 Batch F1: 0.35714285714285715
Epoch:  934        6 Batch loss: 0.220267 Batch F1: 0.3846153846153846
Epoch:  934        7 Batch loss: 0.239617 Batch F1: 0.41379310344827586
Epoch:  934        8 Batch loss: 0.237197 Batch F1: 0.3846153846153846
Epoch:  934        9 Batch loss: 0.230361 Batch F1: 0.27586206896551724
Epoch:  934       10 Batch loss: 0.200907 Batch F1: 0.21052631578947367
Epoch:  934       11 Batch loss: 0.238925 Batch F1: 0.0
Epoch:  934       12 Batch loss: 0.230438 Batch F1: 0.0
Train Avg Loss  934: 0.223304

Train Avg F1  934: 0.27652750052931535

Val Avg Loss  934: 0.218382

Val Avg F1  934:  0.04777777777777778

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 935
--------------------------------------------------------------
Epoch:  935        1 Batch loss: 0.218398 Batch F1: 0.1
Epoch:  935        2 Batch loss: 0.198175 Batch F1: 0.1111111111111111
Epoch:  935        3 Batch loss: 0.208072 Batch F1: 0.0
Epoch:  935        4 Batch loss: 0.243916 Batch F1: 0.0
Epoch:  935        5 Batch loss: 0.232079 Batch F1: 0.0
Epoch:  935        6 Batch loss: 0.196414 Batch F1: 0.1
Epoch:  935        7 Batch loss: 0.237959 Batch F1: 0.08695652173913042
Epoch:  935        8 Batch loss: 0.232602 Batch F1: 0.1818181818181818
Epoch:  935        9 Batch loss: 0.223426 Batch F1: 0.24999999999999997
Epoch:  935       10 Batch loss: 0.225918 Batch F1: 0.23076923076923073
Epoch:  935       11 Batch loss: 0.214983 Batch F1: 0.2222222222222222
Epoch:  935       12 Batch loss: 0.227131 Batch F1: 0.4347826086956522
Train Avg Loss  935: 0.221589

Train Avg F1  935: 0.1431383230296274

Val Avg Loss  935: 0.224559

Val Avg F1  935:  0.3570156695156695

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 936
--------------------------------------------------------------
Epoch:  936        1 Batch loss: 0.199834 Batch F1: 0.5
Epoch:  936        2 Batch loss: 0.271293 Batch F1: 0.3870967741935484
Epoch:  936        3 Batch loss: 0.232256 Batch F1: 0.37500000000000006
Epoch:  936        4 Batch loss: 0.252324 Batch F1: 0.25
Epoch:  936        5 Batch loss: 0.201873 Batch F1: 0.4615384615384615
Epoch:  936        6 Batch loss: 0.222590 Batch F1: 0.09523809523809525
Epoch:  936        7 Batch loss: 0.254193 Batch F1: 0.07692307692307693
Epoch:  936        8 Batch loss: 0.205577 Batch F1: 0.42857142857142855
Epoch:  936        9 Batch loss: 0.218772 Batch F1: 0.1
Epoch:  936       10 Batch loss: 0.193224 Batch F1: 0.2857142857142857
Epoch:  936       11 Batch loss: 0.197696 Batch F1: 0.2222222222222222
Epoch:  936       12 Batch loss: 0.221377 Batch F1: 0.43478260869565216
Train Avg Loss  936: 0.222584

Train Avg F1  936: 0.30142391275806424

Val Avg Loss  936: 0.218341

Val Avg F1  936:  0.24763157894736842

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 937
--------------------------------------------------------------
Epoch:  937        1 Batch loss: 0.225809 Batch F1: 0.3333333333333333
Epoch:  937        2 Batch loss: 0.185481 Batch F1: 0.0
Epoch:  937        3 Batch loss: 0.200930 Batch F1: 0.0
Epoch:  937        4 Batch loss: 0.184216 Batch F1: 0.0
Epoch:  937        5 Batch loss: 0.184598 Batch F1: 0.0
Epoch:  937        6 Batch loss: 0.248804 Batch F1: 0.0
Epoch:  937        7 Batch loss: 0.245609 Batch F1: 0.0
Epoch:  937        8 Batch loss: 0.233939 Batch F1: 0.0
Epoch:  937        9 Batch loss: 0.210527 Batch F1: 0.1818181818181818
Epoch:  937       10 Batch loss: 0.220646 Batch F1: 0.4
Epoch:  937       11 Batch loss: 0.232346 Batch F1: 0.5
Epoch:  937       12 Batch loss: 0.269479 Batch F1: 0.4583333333333333
Train Avg Loss  937: 0.220199

Train Avg F1  937: 0.15612373737373736

Val Avg Loss  937: 0.239669

Val Avg F1  937:  0.41709485836308424

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 938
--------------------------------------------------------------
Epoch:  938        1 Batch loss: 0.243781 Batch F1: 0.39024390243902435
Epoch:  938        2 Batch loss: 0.227438 Batch F1: 0.1904761904761905
Epoch:  938        3 Batch loss: 0.245297 Batch F1: 0.0
Epoch:  938        4 Batch loss: 0.202772 Batch F1: 0.0
Epoch:  938        5 Batch loss: 0.217858 Batch F1: 0.0
Epoch:  938        6 Batch loss: 0.239323 Batch F1: 0.0
Epoch:  938        7 Batch loss: 0.266532 Batch F1: 0.0
Epoch:  938        8 Batch loss: 0.256943 Batch F1: 0.0
Epoch:  938        9 Batch loss: 0.210235 Batch F1: 0.0
Epoch:  938       10 Batch loss: 0.250553 Batch F1: 0.0
Epoch:  938       11 Batch loss: 0.225080 Batch F1: 0.0
Epoch:  938       12 Batch loss: 0.229518 Batch F1: 0.5384615384615384
Train Avg Loss  938: 0.234611

Train Avg F1  938: 0.09326513594806278

Val Avg Loss  938: 0.229406

Val Avg F1  938:  0.11703081232492997

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 939
--------------------------------------------------------------
Epoch:  939        1 Batch loss: 0.246294 Batch F1: 0.26666666666666666
Epoch:  939        2 Batch loss: 0.216467 Batch F1: 0.3
Epoch:  939        3 Batch loss: 0.218942 Batch F1: 0.0
Epoch:  939        4 Batch loss: 0.185350 Batch F1: 0.0
Epoch:  939        5 Batch loss: 0.192763 Batch F1: 0.0
Epoch:  939        6 Batch loss: 0.209167 Batch F1: 0.0
Epoch:  939        7 Batch loss: 0.237855 Batch F1: 0.0
Epoch:  939        8 Batch loss: 0.231489 Batch F1: 0.0
Epoch:  939        9 Batch loss: 0.251237 Batch F1: 0.0
Epoch:  939       10 Batch loss: 0.236321 Batch F1: 0.0
Epoch:  939       11 Batch loss: 0.259877 Batch F1: 0.0
Epoch:  939       12 Batch loss: 0.234668 Batch F1: 0.56
Train Avg Loss  939: 0.226703

Train Avg F1  939: 0.0938888888888889

Val Avg Loss  939: 0.243473

Val Avg F1  939:  0.44060336367483277

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 940
--------------------------------------------------------------
Epoch:  940        1 Batch loss: 0.252488 Batch F1: 0.5599999999999999
Epoch:  940        2 Batch loss: 0.244335 Batch F1: 0.5454545454545454
Epoch:  940        3 Batch loss: 0.237335 Batch F1: 0.5
Epoch:  940        4 Batch loss: 0.231051 Batch F1: 0.4800000000000001
Epoch:  940        5 Batch loss: 0.231139 Batch F1: 0.0
Epoch:  940        6 Batch loss: 0.244455 Batch F1: 0.0
Epoch:  940        7 Batch loss: 0.225104 Batch F1: 0.0
Epoch:  940        8 Batch loss: 0.212901 Batch F1: 0.0
Epoch:  940        9 Batch loss: 0.252863 Batch F1: 0.0
Epoch:  940       10 Batch loss: 0.202727 Batch F1: 0.0
Epoch:  940       11 Batch loss: 0.187282 Batch F1: 0.0
Epoch:  940       12 Batch loss: 0.183823 Batch F1: 0.0
Train Avg Loss  940: 0.225458

Train Avg F1  940: 0.1737878787878788

Val Avg Loss  940: 0.217871

Val Avg F1  940:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 941
--------------------------------------------------------------
Epoch:  941        1 Batch loss: 0.236371 Batch F1: 0.0
Epoch:  941        2 Batch loss: 0.238483 Batch F1: 0.0
Epoch:  941        3 Batch loss: 0.245484 Batch F1: 0.0
Epoch:  941        4 Batch loss: 0.240129 Batch F1: 0.32000000000000006
Epoch:  941        5 Batch loss: 0.199419 Batch F1: 0.5
Epoch:  941        6 Batch loss: 0.224578 Batch F1: 0.45161290322580644
Epoch:  941        7 Batch loss: 0.233888 Batch F1: 0.3846153846153846
Epoch:  941        8 Batch loss: 0.216579 Batch F1: 0.41379310344827586
Epoch:  941        9 Batch loss: 0.219343 Batch F1: 0.31999999999999995
Epoch:  941       10 Batch loss: 0.199958 Batch F1: 0.56
Epoch:  941       11 Batch loss: 0.208497 Batch F1: 0.3478260869565218
Epoch:  941       12 Batch loss: 0.240541 Batch F1: 0.21052631578947364
Train Avg Loss  941: 0.225273

Train Avg F1  941: 0.2923644828362885

Val Avg Loss  941: 0.218581

Val Avg F1  941:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 942
--------------------------------------------------------------
Epoch:  942        1 Batch loss: 0.207865 Batch F1: 0.0
Epoch:  942        2 Batch loss: 0.240630 Batch F1: 0.0
Epoch:  942        3 Batch loss: 0.217010 Batch F1: 0.0
Epoch:  942        4 Batch loss: 0.230840 Batch F1: 0.0
Epoch:  942        5 Batch loss: 0.221054 Batch F1: 0.0
Epoch:  942        6 Batch loss: 0.215903 Batch F1: 0.0
Epoch:  942        7 Batch loss: 0.222141 Batch F1: 0.10526315789473684
Epoch:  942        8 Batch loss: 0.247071 Batch F1: 0.0909090909090909
Epoch:  942        9 Batch loss: 0.207703 Batch F1: 0.17391304347826086
Epoch:  942       10 Batch loss: 0.235716 Batch F1: 0.08695652173913045
Epoch:  942       11 Batch loss: 0.225049 Batch F1: 0.1
Epoch:  942       12 Batch loss: 0.197646 Batch F1: 0.5384615384615384
Train Avg Loss  942: 0.222386

Train Avg F1  942: 0.09129194604022979

Val Avg Loss  942: 0.221058

Val Avg F1  942:  0.2730895915678524

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 943
--------------------------------------------------------------
Epoch:  943        1 Batch loss: 0.219585 Batch F1: 0.1739130434782609
Epoch:  943        2 Batch loss: 0.211623 Batch F1: 0.30769230769230765
Epoch:  943        3 Batch loss: 0.234785 Batch F1: 0.39999999999999997
Epoch:  943        4 Batch loss: 0.239924 Batch F1: 0.37037037037037035
Epoch:  943        5 Batch loss: 0.209159 Batch F1: 0.2222222222222222
Epoch:  943        6 Batch loss: 0.200208 Batch F1: 0.5333333333333333
Epoch:  943        7 Batch loss: 0.257381 Batch F1: 0.3225806451612903
Epoch:  943        8 Batch loss: 0.234021 Batch F1: 0.1739130434782609
Epoch:  943        9 Batch loss: 0.221435 Batch F1: 0.36363636363636365
Epoch:  943       10 Batch loss: 0.203102 Batch F1: 0.22222222222222224
Epoch:  943       11 Batch loss: 0.237964 Batch F1: 0.2857142857142857
Epoch:  943       12 Batch loss: 0.193212 Batch F1: 0.11764705882352941
Train Avg Loss  943: 0.221867

Train Avg F1  943: 0.29110374134437056

Val Avg Loss  943: 0.218899

Val Avg F1  943:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 944
--------------------------------------------------------------
Epoch:  944        1 Batch loss: 0.216174 Batch F1: 0.1739130434782609
Epoch:  944        2 Batch loss: 0.246932 Batch F1: 0.0
Epoch:  944        3 Batch loss: 0.221454 Batch F1: 0.15384615384615385
Epoch:  944        4 Batch loss: 0.250764 Batch F1: 0.08
Epoch:  944        5 Batch loss: 0.201447 Batch F1: 0.46153846153846156
Epoch:  944        6 Batch loss: 0.230709 Batch F1: 0.2608695652173913
Epoch:  944        7 Batch loss: 0.233257 Batch F1: 0.3076923076923077
Epoch:  944        8 Batch loss: 0.208225 Batch F1: 0.2608695652173913
Epoch:  944        9 Batch loss: 0.222215 Batch F1: 0.46153846153846156
Epoch:  944       10 Batch loss: 0.217767 Batch F1: 0.10526315789473684
Epoch:  944       11 Batch loss: 0.234004 Batch F1: 0.09523809523809523
Epoch:  944       12 Batch loss: 0.177642 Batch F1: 0.42857142857142855
Train Avg Loss  944: 0.221716

Train Avg F1  944: 0.2324450200193907

Val Avg Loss  944: 0.219396

Val Avg F1  944:  0.26707868155236575

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 945
--------------------------------------------------------------
Epoch:  945        1 Batch loss: 0.194622 Batch F1: 0.34782608695652173
Epoch:  945        2 Batch loss: 0.255380 Batch F1: 0.23076923076923073
Epoch:  945        3 Batch loss: 0.238749 Batch F1: 0.3333333333333333
Epoch:  945        4 Batch loss: 0.231953 Batch F1: 0.5555555555555556
Epoch:  945        5 Batch loss: 0.216585 Batch F1: 0.4
Epoch:  945        6 Batch loss: 0.202758 Batch F1: 0.5625
Epoch:  945        7 Batch loss: 0.210205 Batch F1: 0.36363636363636365
Epoch:  945        8 Batch loss: 0.191644 Batch F1: 0.5517241379310345
Epoch:  945        9 Batch loss: 0.225428 Batch F1: 0.3076923076923077
Epoch:  945       10 Batch loss: 0.276499 Batch F1: 0.3333333333333333
Epoch:  945       11 Batch loss: 0.200611 Batch F1: 0.3
Epoch:  945       12 Batch loss: 0.218698 Batch F1: 0.0
Train Avg Loss  945: 0.221927

Train Avg F1  945: 0.3571975291006401

Val Avg Loss  945: 0.217410

Val Avg F1  945:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 946
--------------------------------------------------------------
Epoch:  946        1 Batch loss: 0.180023 Batch F1: 0.0
Epoch:  946        2 Batch loss: 0.271607 Batch F1: 0.0
Epoch:  946        3 Batch loss: 0.235023 Batch F1: 0.0
Epoch:  946        4 Batch loss: 0.205733 Batch F1: 0.0
Epoch:  946        5 Batch loss: 0.220925 Batch F1: 0.0
Epoch:  946        6 Batch loss: 0.244832 Batch F1: 0.0
Epoch:  946        7 Batch loss: 0.221046 Batch F1: 0.0
Epoch:  946        8 Batch loss: 0.224652 Batch F1: 0.10526315789473684
Epoch:  946        9 Batch loss: 0.230894 Batch F1: 0.4666666666666667
Epoch:  946       10 Batch loss: 0.249415 Batch F1: 0.15384615384615383
Epoch:  946       11 Batch loss: 0.209593 Batch F1: 0.31578947368421056
Epoch:  946       12 Batch loss: 0.205630 Batch F1: 0.11764705882352941
Train Avg Loss  946: 0.224948

Train Avg F1  946: 0.09660104257627478

Val Avg Loss  946: 0.218747

Val Avg F1  946:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 947
--------------------------------------------------------------
Epoch:  947        1 Batch loss: 0.231802 Batch F1: 0.0
Epoch:  947        2 Batch loss: 0.236241 Batch F1: 0.35714285714285715
Epoch:  947        3 Batch loss: 0.238395 Batch F1: 0.41379310344827586
Epoch:  947        4 Batch loss: 0.201904 Batch F1: 0.5714285714285714
Epoch:  947        5 Batch loss: 0.227013 Batch F1: 0.45161290322580644
Epoch:  947        6 Batch loss: 0.232360 Batch F1: 0.23076923076923078
Epoch:  947        7 Batch loss: 0.176668 Batch F1: 0.28571428571428575
Epoch:  947        8 Batch loss: 0.225034 Batch F1: 0.0
Epoch:  947        9 Batch loss: 0.208342 Batch F1: 0.0
Epoch:  947       10 Batch loss: 0.259336 Batch F1: 0.0
Epoch:  947       11 Batch loss: 0.243249 Batch F1: 0.0
Epoch:  947       12 Batch loss: 0.211611 Batch F1: 0.125
Train Avg Loss  947: 0.224330

Train Avg F1  947: 0.20295507931075227

Val Avg Loss  947: 0.217270

Val Avg F1  947:  0.20225279106858052

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 948
--------------------------------------------------------------
Epoch:  948        1 Batch loss: 0.228251 Batch F1: 0.16666666666666669
Epoch:  948        2 Batch loss: 0.227194 Batch F1: 0.1739130434782609
Epoch:  948        3 Batch loss: 0.225910 Batch F1: 0.30769230769230765
Epoch:  948        4 Batch loss: 0.233634 Batch F1: 0.28571428571428575
Epoch:  948        5 Batch loss: 0.216593 Batch F1: 0.39999999999999997
Epoch:  948        6 Batch loss: 0.212867 Batch F1: 0.4166666666666667
Epoch:  948        7 Batch loss: 0.235898 Batch F1: 0.25
Epoch:  948        8 Batch loss: 0.195695 Batch F1: 0.25
Epoch:  948        9 Batch loss: 0.209309 Batch F1: 0.0
Epoch:  948       10 Batch loss: 0.240520 Batch F1: 0.0
Epoch:  948       11 Batch loss: 0.218211 Batch F1: 0.0
Epoch:  948       12 Batch loss: 0.244152 Batch F1: 0.0
Train Avg Loss  948: 0.224020

Train Avg F1  948: 0.18755441418484897

Val Avg Loss  948: 0.218125

Val Avg F1  948:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 949
--------------------------------------------------------------
Epoch:  949        1 Batch loss: 0.238464 Batch F1: 0.0
Epoch:  949        2 Batch loss: 0.269728 Batch F1: 0.15384615384615385
Epoch:  949        3 Batch loss: 0.209196 Batch F1: 0.45454545454545453
Epoch:  949        4 Batch loss: 0.219779 Batch F1: 0.25
Epoch:  949        5 Batch loss: 0.210877 Batch F1: 0.2962962962962963
Epoch:  949        6 Batch loss: 0.234212 Batch F1: 0.3529411764705882
Epoch:  949        7 Batch loss: 0.219056 Batch F1: 0.3846153846153846
Epoch:  949        8 Batch loss: 0.203596 Batch F1: 0.48484848484848486
Epoch:  949        9 Batch loss: 0.220369 Batch F1: 0.2857142857142857
Epoch:  949       10 Batch loss: 0.209456 Batch F1: 0.21052631578947364
Epoch:  949       11 Batch loss: 0.230651 Batch F1: 0.3703703703703704
Epoch:  949       12 Batch loss: 0.216468 Batch F1: 0.3157894736842105
Train Avg Loss  949: 0.223488

Train Avg F1  949: 0.2966244496817252

Val Avg Loss  949: 0.218494

Val Avg F1  949:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 950
--------------------------------------------------------------
Epoch:  950        1 Batch loss: 0.241113 Batch F1: 0.0
Epoch:  950        2 Batch loss: 0.195244 Batch F1: 0.0
Epoch:  950        3 Batch loss: 0.195809 Batch F1: 0.0
Epoch:  950        4 Batch loss: 0.186452 Batch F1: 0.0
Epoch:  950        5 Batch loss: 0.245991 Batch F1: 0.0
Epoch:  950        6 Batch loss: 0.230134 Batch F1: 0.0
Epoch:  950        7 Batch loss: 0.255056 Batch F1: 0.0
Epoch:  950        8 Batch loss: 0.240129 Batch F1: 0.08333333333333334
Epoch:  950        9 Batch loss: 0.225268 Batch F1: 0.39999999999999997
Epoch:  950       10 Batch loss: 0.232933 Batch F1: 0.3448275862068966
Epoch:  950       11 Batch loss: 0.220742 Batch F1: 0.19047619047619044
Epoch:  950       12 Batch loss: 0.214277 Batch F1: 0.25
Train Avg Loss  950: 0.223596

Train Avg F1  950: 0.10571975916803501

Val Avg Loss  950: 0.219246

Val Avg F1  950:  0.16490683229813663

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 951
--------------------------------------------------------------
Epoch:  951        1 Batch loss: 0.211108 Batch F1: 0.17391304347826086
Epoch:  951        2 Batch loss: 0.225783 Batch F1: 0.3448275862068966
Epoch:  951        3 Batch loss: 0.230721 Batch F1: 0.2857142857142857
Epoch:  951        4 Batch loss: 0.234782 Batch F1: 0.14814814814814814
Epoch:  951        5 Batch loss: 0.252976 Batch F1: 0.16666666666666666
Epoch:  951        6 Batch loss: 0.231281 Batch F1: 0.4347826086956522
Epoch:  951        7 Batch loss: 0.212333 Batch F1: 0.48
Epoch:  951        8 Batch loss: 0.242692 Batch F1: 0.25
Epoch:  951        9 Batch loss: 0.212540 Batch F1: 0.0
Epoch:  951       10 Batch loss: 0.191872 Batch F1: 0.11111111111111112
Epoch:  951       11 Batch loss: 0.194424 Batch F1: 0.0
Epoch:  951       12 Batch loss: 0.247132 Batch F1: 0.0
Train Avg Loss  951: 0.223970

Train Avg F1  951: 0.19959695416841847

Val Avg Loss  951: 0.217808

Val Avg F1  951:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 952
--------------------------------------------------------------
Epoch:  952        1 Batch loss: 0.220672 Batch F1: 0.0
Epoch:  952        2 Batch loss: 0.234244 Batch F1: 0.0
Epoch:  952        3 Batch loss: 0.195336 Batch F1: 0.125
Epoch:  952        4 Batch loss: 0.226885 Batch F1: 0.0
Epoch:  952        5 Batch loss: 0.205639 Batch F1: 0.10526315789473684
Epoch:  952        6 Batch loss: 0.205452 Batch F1: 0.22222222222222224
Epoch:  952        7 Batch loss: 0.221406 Batch F1: 0.41379310344827586
Epoch:  952        8 Batch loss: 0.221929 Batch F1: 0.31999999999999995
Epoch:  952        9 Batch loss: 0.226752 Batch F1: 0.42857142857142855
Epoch:  952       10 Batch loss: 0.248460 Batch F1: 0.13793103448275862
Epoch:  952       11 Batch loss: 0.238132 Batch F1: 0.30769230769230765
Epoch:  952       12 Batch loss: 0.221122 Batch F1: 0.3
Train Avg Loss  952: 0.222169

Train Avg F1  952: 0.19670610452597745

Val Avg Loss  952: 0.220145

Val Avg F1  952:  0.2817725752508361

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 953
--------------------------------------------------------------
Epoch:  953        1 Batch loss: 0.183376 Batch F1: 0.26666666666666666
Epoch:  953        2 Batch loss: 0.263374 Batch F1: 0.27586206896551724
Epoch:  953        3 Batch loss: 0.233533 Batch F1: 0.3076923076923077
Epoch:  953        4 Batch loss: 0.233831 Batch F1: 0.08333333333333333
Epoch:  953        5 Batch loss: 0.214767 Batch F1: 0.0
Epoch:  953        6 Batch loss: 0.186940 Batch F1: 0.14285714285714288
Epoch:  953        7 Batch loss: 0.252427 Batch F1: 0.14814814814814814
Epoch:  953        8 Batch loss: 0.210531 Batch F1: 0.3333333333333333
Epoch:  953        9 Batch loss: 0.258591 Batch F1: 0.22222222222222218
Epoch:  953       10 Batch loss: 0.203592 Batch F1: 0.21052631578947367
Epoch:  953       11 Batch loss: 0.238831 Batch F1: 0.35714285714285715
Epoch:  953       12 Batch loss: 0.181185 Batch F1: 0.4
Train Avg Loss  953: 0.221748

Train Avg F1  953: 0.2289820330125835

Val Avg Loss  953: 0.220076

Val Avg F1  953:  0.2256455559400861

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 954
--------------------------------------------------------------
Epoch:  954        1 Batch loss: 0.232487 Batch F1: 0.37037037037037035
Epoch:  954        2 Batch loss: 0.209230 Batch F1: 0.43478260869565216
Epoch:  954        3 Batch loss: 0.218787 Batch F1: 0.2608695652173913
Epoch:  954        4 Batch loss: 0.210197 Batch F1: 0.3636363636363636
Epoch:  954        5 Batch loss: 0.223550 Batch F1: 0.17391304347826086
Epoch:  954        6 Batch loss: 0.220101 Batch F1: 0.2608695652173913
Epoch:  954        7 Batch loss: 0.202448 Batch F1: 0.30769230769230765
Epoch:  954        8 Batch loss: 0.222642 Batch F1: 0.32
Epoch:  954        9 Batch loss: 0.196202 Batch F1: 0.43478260869565216
Epoch:  954       10 Batch loss: 0.240691 Batch F1: 0.26666666666666666
Epoch:  954       11 Batch loss: 0.232903 Batch F1: 0.28571428571428575
Epoch:  954       12 Batch loss: 0.257801 Batch F1: 0.24
Train Avg Loss  954: 0.222253

Train Avg F1  954: 0.30994144878202845

Val Avg Loss  954: 0.218582

Val Avg F1  954:  0.22941176470588234

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 955
--------------------------------------------------------------
Epoch:  955        1 Batch loss: 0.219218 Batch F1: 0.3846153846153846
Epoch:  955        2 Batch loss: 0.211388 Batch F1: 0.27272727272727276
Epoch:  955        3 Batch loss: 0.225781 Batch F1: 0.1818181818181818
Epoch:  955        4 Batch loss: 0.215612 Batch F1: 0.4
Epoch:  955        5 Batch loss: 0.220708 Batch F1: 0.2857142857142857
Epoch:  955        6 Batch loss: 0.206939 Batch F1: 0.28571428571428575
Epoch:  955        7 Batch loss: 0.216089 Batch F1: 0.3333333333333333
Epoch:  955        8 Batch loss: 0.225830 Batch F1: 0.24
Epoch:  955        9 Batch loss: 0.247932 Batch F1: 0.28571428571428575
Epoch:  955       10 Batch loss: 0.215957 Batch F1: 0.3478260869565218
Epoch:  955       11 Batch loss: 0.220973 Batch F1: 0.3333333333333333
Epoch:  955       12 Batch loss: 0.224898 Batch F1: 0.25
Train Avg Loss  955: 0.220944

Train Avg F1  955: 0.3000663708272404

Val Avg Loss  955: 0.220077

Val Avg F1  955:  0.2879871175523349

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 956
--------------------------------------------------------------
Epoch:  956        1 Batch loss: 0.222979 Batch F1: 0.2608695652173913
Epoch:  956        2 Batch loss: 0.233770 Batch F1: 0.3870967741935483
Epoch:  956        3 Batch loss: 0.241570 Batch F1: 0.25806451612903225
Epoch:  956        4 Batch loss: 0.204166 Batch F1: 0.0
Epoch:  956        5 Batch loss: 0.234155 Batch F1: 0.37037037037037035
Epoch:  956        6 Batch loss: 0.191461 Batch F1: 0.3
Epoch:  956        7 Batch loss: 0.260834 Batch F1: 0.07407407407407407
Epoch:  956        8 Batch loss: 0.196359 Batch F1: 0.30769230769230765
Epoch:  956        9 Batch loss: 0.195673 Batch F1: 0.4
Epoch:  956       10 Batch loss: 0.214754 Batch F1: 0.3809523809523809
Epoch:  956       11 Batch loss: 0.221075 Batch F1: 0.32
Epoch:  956       12 Batch loss: 0.248090 Batch F1: 0.3846153846153846
Train Avg Loss  956: 0.222074

Train Avg F1  956: 0.28697794777037416

Val Avg Loss  956: 0.219431

Val Avg F1  956:  0.25255233494363927

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 957
--------------------------------------------------------------
Epoch:  957        1 Batch loss: 0.227495 Batch F1: 0.09523809523809523
Epoch:  957        2 Batch loss: 0.204259 Batch F1: 0.4166666666666667
Epoch:  957        3 Batch loss: 0.198022 Batch F1: 0.4166666666666667
Epoch:  957        4 Batch loss: 0.213598 Batch F1: 0.2105263157894737
Epoch:  957        5 Batch loss: 0.222154 Batch F1: 0.3448275862068965
Epoch:  957        6 Batch loss: 0.230434 Batch F1: 0.4242424242424242
Epoch:  957        7 Batch loss: 0.277460 Batch F1: 0.17647058823529413
Epoch:  957        8 Batch loss: 0.227829 Batch F1: 0.29629629629629634
Epoch:  957        9 Batch loss: 0.253376 Batch F1: 0.25
Epoch:  957       10 Batch loss: 0.204346 Batch F1: 0.5185185185185186
Epoch:  957       11 Batch loss: 0.199494 Batch F1: 0.43478260869565216
Epoch:  957       12 Batch loss: 0.203351 Batch F1: 0.11764705882352941
Train Avg Loss  957: 0.221818

Train Avg F1  957: 0.3084902354482928

Val Avg Loss  957: 0.220543

Val Avg F1  957:  0.3197045707915273

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 958
--------------------------------------------------------------
Epoch:  958        1 Batch loss: 0.223786 Batch F1: 0.33333333333333326
Epoch:  958        2 Batch loss: 0.212901 Batch F1: 0.3333333333333333
Epoch:  958        3 Batch loss: 0.219201 Batch F1: 0.1111111111111111
Epoch:  958        4 Batch loss: 0.218471 Batch F1: 0.25
Epoch:  958        5 Batch loss: 0.220277 Batch F1: 0.30769230769230765
Epoch:  958        6 Batch loss: 0.230306 Batch F1: 0.2
Epoch:  958        7 Batch loss: 0.220418 Batch F1: 0.1904761904761905
Epoch:  958        8 Batch loss: 0.220847 Batch F1: 0.18181818181818182
Epoch:  958        9 Batch loss: 0.238244 Batch F1: 0.08695652173913042
Epoch:  958       10 Batch loss: 0.226334 Batch F1: 0.25
Epoch:  958       11 Batch loss: 0.203248 Batch F1: 0.0
Epoch:  958       12 Batch loss: 0.226345 Batch F1: 0.5714285714285715
Train Avg Loss  958: 0.221698

Train Avg F1  958: 0.23467912924434664

Val Avg Loss  958: 0.218167

Val Avg F1  958:  0.22275641025641027

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 959
--------------------------------------------------------------
Epoch:  959        1 Batch loss: 0.225400 Batch F1: 0.2608695652173913
Epoch:  959        2 Batch loss: 0.284034 Batch F1: 0.24242424242424246
Epoch:  959        3 Batch loss: 0.216872 Batch F1: 0.25
Epoch:  959        4 Batch loss: 0.210507 Batch F1: 0.30769230769230765
Epoch:  959        5 Batch loss: 0.240936 Batch F1: 0.14285714285714288
Epoch:  959        6 Batch loss: 0.202914 Batch F1: 0.25
Epoch:  959        7 Batch loss: 0.198578 Batch F1: 0.4827586206896552
Epoch:  959        8 Batch loss: 0.211472 Batch F1: 0.48275862068965514
Epoch:  959        9 Batch loss: 0.215048 Batch F1: 0.2857142857142857
Epoch:  959       10 Batch loss: 0.230085 Batch F1: 0.4827586206896552
Epoch:  959       11 Batch loss: 0.207568 Batch F1: 0.2
Epoch:  959       12 Batch loss: 0.220088 Batch F1: 0.22222222222222224
Train Avg Loss  959: 0.221959

Train Avg F1  959: 0.3008379690163798

Val Avg Loss  959: 0.218457

Val Avg F1  959:  0.24057504873294347

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 960
--------------------------------------------------------------
Epoch:  960        1 Batch loss: 0.232054 Batch F1: 0.29629629629629634
Epoch:  960        2 Batch loss: 0.204719 Batch F1: 0.4166666666666667
Epoch:  960        3 Batch loss: 0.190919 Batch F1: 0.3636363636363636
Epoch:  960        4 Batch loss: 0.239530 Batch F1: 0.25806451612903225
Epoch:  960        5 Batch loss: 0.218759 Batch F1: 0.3333333333333333
Epoch:  960        6 Batch loss: 0.213814 Batch F1: 0.2727272727272727
Epoch:  960        7 Batch loss: 0.211750 Batch F1: 0.34782608695652173
Epoch:  960        8 Batch loss: 0.192305 Batch F1: 0.0
Epoch:  960        9 Batch loss: 0.240798 Batch F1: 0.0
Epoch:  960       10 Batch loss: 0.284603 Batch F1: 0.0
Epoch:  960       11 Batch loss: 0.226583 Batch F1: 0.0
Epoch:  960       12 Batch loss: 0.233954 Batch F1: 0.0
Train Avg Loss  960: 0.224149

Train Avg F1  960: 0.1907125446454572

Val Avg Loss  960: 0.223500

Val Avg F1  960:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 961
--------------------------------------------------------------
Epoch:  961        1 Batch loss: 0.220409 Batch F1: 0.0
Epoch:  961        2 Batch loss: 0.241606 Batch F1: 0.0
Epoch:  961        3 Batch loss: 0.208993 Batch F1: 0.0
Epoch:  961        4 Batch loss: 0.245659 Batch F1: 0.0
Epoch:  961        5 Batch loss: 0.239733 Batch F1: 0.0
Epoch:  961        6 Batch loss: 0.221317 Batch F1: 0.0
Epoch:  961        7 Batch loss: 0.202356 Batch F1: 0.0
Epoch:  961        8 Batch loss: 0.252200 Batch F1: 0.0
Epoch:  961        9 Batch loss: 0.176247 Batch F1: 0.0
Epoch:  961       10 Batch loss: 0.220535 Batch F1: 0.0
Epoch:  961       11 Batch loss: 0.224431 Batch F1: 0.0
Epoch:  961       12 Batch loss: 0.265070 Batch F1: 0.0
Train Avg Loss  961: 0.226546

Train Avg F1  961: 0.0

Val Avg Loss  961: 0.220443

Val Avg F1  961:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 962
--------------------------------------------------------------
Epoch:  962        1 Batch loss: 0.228886 Batch F1: 0.0
Epoch:  962        2 Batch loss: 0.237298 Batch F1: 0.0
Epoch:  962        3 Batch loss: 0.215429 Batch F1: 0.0
Epoch:  962        4 Batch loss: 0.200732 Batch F1: 0.2857142857142857
Epoch:  962        5 Batch loss: 0.247910 Batch F1: 0.07142857142857142
Epoch:  962        6 Batch loss: 0.224328 Batch F1: 0.0909090909090909
Epoch:  962        7 Batch loss: 0.222631 Batch F1: 0.3636363636363636
Epoch:  962        8 Batch loss: 0.197192 Batch F1: 0.0
Epoch:  962        9 Batch loss: 0.245586 Batch F1: 0.0
Epoch:  962       10 Batch loss: 0.218916 Batch F1: 0.0
Epoch:  962       11 Batch loss: 0.261097 Batch F1: 0.0
Epoch:  962       12 Batch loss: 0.210480 Batch F1: 0.0
Train Avg Loss  962: 0.225874

Train Avg F1  962: 0.06764069264069263

Val Avg Loss  962: 0.218111

Val Avg F1  962:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 963
--------------------------------------------------------------
Epoch:  963        1 Batch loss: 0.244772 Batch F1: 0.0
Epoch:  963        2 Batch loss: 0.235564 Batch F1: 0.0
Epoch:  963        3 Batch loss: 0.213976 Batch F1: 0.0
Epoch:  963        4 Batch loss: 0.201819 Batch F1: 0.0
Epoch:  963        5 Batch loss: 0.239555 Batch F1: 0.0
Epoch:  963        6 Batch loss: 0.244936 Batch F1: 0.0
Epoch:  963        7 Batch loss: 0.236526 Batch F1: 0.0
Epoch:  963        8 Batch loss: 0.222005 Batch F1: 0.09523809523809525
Epoch:  963        9 Batch loss: 0.212714 Batch F1: 0.3333333333333333
Epoch:  963       10 Batch loss: 0.204883 Batch F1: 0.0
Epoch:  963       11 Batch loss: 0.250024 Batch F1: 0.0
Epoch:  963       12 Batch loss: 0.227487 Batch F1: 0.0
Train Avg Loss  963: 0.227855

Train Avg F1  963: 0.03571428571428571

Val Avg Loss  963: 0.217724

Val Avg F1  963:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 964
--------------------------------------------------------------
Epoch:  964        1 Batch loss: 0.176175 Batch F1: 0.0
Epoch:  964        2 Batch loss: 0.237087 Batch F1: 0.0
Epoch:  964        3 Batch loss: 0.184017 Batch F1: 0.0
Epoch:  964        4 Batch loss: 0.230582 Batch F1: 0.0
Epoch:  964        5 Batch loss: 0.265846 Batch F1: 0.0
Epoch:  964        6 Batch loss: 0.214914 Batch F1: 0.0
Epoch:  964        7 Batch loss: 0.236295 Batch F1: 0.0
Epoch:  964        8 Batch loss: 0.224276 Batch F1: 0.33333333333333337
Epoch:  964        9 Batch loss: 0.233635 Batch F1: 0.2222222222222222
Epoch:  964       10 Batch loss: 0.229480 Batch F1: 0.2727272727272727
Epoch:  964       11 Batch loss: 0.213867 Batch F1: 0.37037037037037035
Epoch:  964       12 Batch loss: 0.235299 Batch F1: 0.48
Train Avg Loss  964: 0.223456

Train Avg F1  964: 0.13988776655443322

Val Avg Loss  964: 0.222394

Val Avg F1  964:  0.33064814814814814

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 965
--------------------------------------------------------------
Epoch:  965        1 Batch loss: 0.204742 Batch F1: 0.5882352941176471
Epoch:  965        2 Batch loss: 0.202076 Batch F1: 0.36363636363636365
Epoch:  965        3 Batch loss: 0.191130 Batch F1: 0.25
Epoch:  965        4 Batch loss: 0.238419 Batch F1: 0.0
Epoch:  965        5 Batch loss: 0.225402 Batch F1: 0.0
Epoch:  965        6 Batch loss: 0.281822 Batch F1: 0.0
Epoch:  965        7 Batch loss: 0.210091 Batch F1: 0.0
Epoch:  965        8 Batch loss: 0.206165 Batch F1: 0.0
Epoch:  965        9 Batch loss: 0.228637 Batch F1: 0.0
Epoch:  965       10 Batch loss: 0.224036 Batch F1: 0.38095238095238093
Epoch:  965       11 Batch loss: 0.271297 Batch F1: 0.20689655172413793
Epoch:  965       12 Batch loss: 0.228839 Batch F1: 0.4166666666666667
Train Avg Loss  965: 0.226055

Train Avg F1  965: 0.18386560475809968

Val Avg Loss  965: 0.221699

Val Avg F1  965:  0.25556302270011944

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 966
--------------------------------------------------------------
Epoch:  966        1 Batch loss: 0.230057 Batch F1: 0.2727272727272727
Epoch:  966        2 Batch loss: 0.228135 Batch F1: 0.35714285714285715
Epoch:  966        3 Batch loss: 0.211595 Batch F1: 0.43478260869565216
Epoch:  966        4 Batch loss: 0.226271 Batch F1: 0.2857142857142857
Epoch:  966        5 Batch loss: 0.191115 Batch F1: 0.2222222222222222
Epoch:  966        6 Batch loss: 0.279154 Batch F1: 0.0
Epoch:  966        7 Batch loss: 0.224342 Batch F1: 0.0
Epoch:  966        8 Batch loss: 0.205853 Batch F1: 0.5
Epoch:  966        9 Batch loss: 0.234124 Batch F1: 0.0
Epoch:  966       10 Batch loss: 0.228740 Batch F1: 0.0909090909090909
Epoch:  966       11 Batch loss: 0.219679 Batch F1: 0.08333333333333333
Epoch:  966       12 Batch loss: 0.211054 Batch F1: 0.2
Train Avg Loss  966: 0.224177

Train Avg F1  966: 0.2039026392287262

Val Avg Loss  966: 0.218331

Val Avg F1  966:  0.18606876215571866

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 967
--------------------------------------------------------------
Epoch:  967        1 Batch loss: 0.237968 Batch F1: 0.18181818181818182
Epoch:  967        2 Batch loss: 0.202659 Batch F1: 0.5217391304347826
Epoch:  967        3 Batch loss: 0.260079 Batch F1: 0.16
Epoch:  967        4 Batch loss: 0.214492 Batch F1: 0.3870967741935484
Epoch:  967        5 Batch loss: 0.205559 Batch F1: 0.2
Epoch:  967        6 Batch loss: 0.230597 Batch F1: 0.1818181818181818
Epoch:  967        7 Batch loss: 0.232498 Batch F1: 0.4
Epoch:  967        8 Batch loss: 0.198093 Batch F1: 0.36363636363636365
Epoch:  967        9 Batch loss: 0.196749 Batch F1: 0.47058823529411764
Epoch:  967       10 Batch loss: 0.215143 Batch F1: 0.0909090909090909
Epoch:  967       11 Batch loss: 0.218024 Batch F1: 0.11764705882352941
Epoch:  967       12 Batch loss: 0.281740 Batch F1: 0.0
Train Avg Loss  967: 0.224467

Train Avg F1  967: 0.256271084743983

Val Avg Loss  967: 0.218654

Val Avg F1  967:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 968
--------------------------------------------------------------
Epoch:  968        1 Batch loss: 0.208929 Batch F1: 0.0
Epoch:  968        2 Batch loss: 0.232494 Batch F1: 0.0
Epoch:  968        3 Batch loss: 0.217019 Batch F1: 0.0
Epoch:  968        4 Batch loss: 0.201094 Batch F1: 0.0
Epoch:  968        5 Batch loss: 0.222410 Batch F1: 0.0
Epoch:  968        6 Batch loss: 0.201151 Batch F1: 0.0
Epoch:  968        7 Batch loss: 0.213728 Batch F1: 0.0
Epoch:  968        8 Batch loss: 0.249178 Batch F1: 0.0
Epoch:  968        9 Batch loss: 0.233390 Batch F1: 0.09090909090909091
Epoch:  968       10 Batch loss: 0.262142 Batch F1: 0.13793103448275862
Epoch:  968       11 Batch loss: 0.199140 Batch F1: 0.5
Epoch:  968       12 Batch loss: 0.260429 Batch F1: 0.2727272727272727
Train Avg Loss  968: 0.225092

Train Avg F1  968: 0.08346394984326018

Val Avg Loss  968: 0.218474

Val Avg F1  968:  0.2532282532282532

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 969
--------------------------------------------------------------
Epoch:  969        1 Batch loss: 0.245066 Batch F1: 0.15384615384615385
Epoch:  969        2 Batch loss: 0.240153 Batch F1: 0.48484848484848486
Epoch:  969        3 Batch loss: 0.243887 Batch F1: 0.3448275862068966
Epoch:  969        4 Batch loss: 0.189610 Batch F1: 0.5217391304347826
Epoch:  969        5 Batch loss: 0.193821 Batch F1: 0.13333333333333336
Epoch:  969        6 Batch loss: 0.222235 Batch F1: 0.0
Epoch:  969        7 Batch loss: 0.240568 Batch F1: 0.0
Epoch:  969        8 Batch loss: 0.231125 Batch F1: 0.0
Epoch:  969        9 Batch loss: 0.254602 Batch F1: 0.08
Epoch:  969       10 Batch loss: 0.200818 Batch F1: 0.38095238095238093
Epoch:  969       11 Batch loss: 0.202244 Batch F1: 0.23529411764705882
Epoch:  969       12 Batch loss: 0.249876 Batch F1: 0.2727272727272727
Train Avg Loss  969: 0.226167

Train Avg F1  969: 0.21729737166636362

Val Avg Loss  969: 0.218430

Val Avg F1  969:  0.26664477285166943

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 970
--------------------------------------------------------------
Epoch:  970        1 Batch loss: 0.222597 Batch F1: 0.26086956521739124
Epoch:  970        2 Batch loss: 0.189857 Batch F1: 0.5217391304347827
Epoch:  970        3 Batch loss: 0.226383 Batch F1: 0.0
Epoch:  970        4 Batch loss: 0.251909 Batch F1: 0.0
Epoch:  970        5 Batch loss: 0.262017 Batch F1: 0.08
Epoch:  970        6 Batch loss: 0.236878 Batch F1: 0.2857142857142857
Epoch:  970        7 Batch loss: 0.219985 Batch F1: 0.3846153846153846
Epoch:  970        8 Batch loss: 0.213158 Batch F1: 0.46153846153846156
Epoch:  970        9 Batch loss: 0.194662 Batch F1: 0.3529411764705882
Epoch:  970       10 Batch loss: 0.210580 Batch F1: 0.2857142857142857
Epoch:  970       11 Batch loss: 0.243614 Batch F1: 0.0
Epoch:  970       12 Batch loss: 0.222009 Batch F1: 0.0
Train Avg Loss  970: 0.224471

Train Avg F1  970: 0.21942769080876498

Val Avg Loss  970: 0.217619

Val Avg F1  970:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 971
--------------------------------------------------------------
Epoch:  971        1 Batch loss: 0.222219 Batch F1: 0.0
Epoch:  971        2 Batch loss: 0.248532 Batch F1: 0.0
Epoch:  971        3 Batch loss: 0.226184 Batch F1: 0.0
Epoch:  971        4 Batch loss: 0.206232 Batch F1: 0.11764705882352941
Epoch:  971        5 Batch loss: 0.214445 Batch F1: 0.0
Epoch:  971        6 Batch loss: 0.217497 Batch F1: 0.0
Epoch:  971        7 Batch loss: 0.225939 Batch F1: 0.0
Epoch:  971        8 Batch loss: 0.209084 Batch F1: 0.0
Epoch:  971        9 Batch loss: 0.212673 Batch F1: 0.0
Epoch:  971       10 Batch loss: 0.226471 Batch F1: 0.1
Epoch:  971       11 Batch loss: 0.228585 Batch F1: 0.0
Epoch:  971       12 Batch loss: 0.247098 Batch F1: 0.0
Train Avg Loss  971: 0.223747

Train Avg F1  971: 0.018137254901960786

Val Avg Loss  971: 0.219480

Val Avg F1  971:  0.2521321070234114

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 972
--------------------------------------------------------------
Epoch:  972        1 Batch loss: 0.210703 Batch F1: 0.4166666666666667
Epoch:  972        2 Batch loss: 0.235207 Batch F1: 0.29629629629629634
Epoch:  972        3 Batch loss: 0.212258 Batch F1: 0.4615384615384615
Epoch:  972        4 Batch loss: 0.222802 Batch F1: 0.3478260869565218
Epoch:  972        5 Batch loss: 0.240239 Batch F1: 0.3448275862068965
Epoch:  972        6 Batch loss: 0.215824 Batch F1: 0.41666666666666663
Epoch:  972        7 Batch loss: 0.241327 Batch F1: 0.23076923076923075
Epoch:  972        8 Batch loss: 0.228556 Batch F1: 0.32
Epoch:  972        9 Batch loss: 0.213184 Batch F1: 0.39999999999999997
Epoch:  972       10 Batch loss: 0.222202 Batch F1: 0.1818181818181818
Epoch:  972       11 Batch loss: 0.223738 Batch F1: 0.41379310344827586
Epoch:  972       12 Batch loss: 0.207808 Batch F1: 0.43478260869565216
Train Avg Loss  972: 0.222821

Train Avg F1  972: 0.3554154074219041

Val Avg Loss  972: 0.219548

Val Avg F1  972:  0.23446874762664233

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 973
--------------------------------------------------------------
Epoch:  973        1 Batch loss: 0.227543 Batch F1: 0.3703703703703704
Epoch:  973        2 Batch loss: 0.207181 Batch F1: 0.3846153846153846
Epoch:  973        3 Batch loss: 0.230243 Batch F1: 0.3333333333333333
Epoch:  973        4 Batch loss: 0.197357 Batch F1: 0.25
Epoch:  973        5 Batch loss: 0.184908 Batch F1: 0.43478260869565216
Epoch:  973        6 Batch loss: 0.172614 Batch F1: 0.2857142857142857
Epoch:  973        7 Batch loss: 0.247890 Batch F1: 0.37037037037037035
Epoch:  973        8 Batch loss: 0.234151 Batch F1: 0.2
Epoch:  973        9 Batch loss: 0.217818 Batch F1: 0.09523809523809525
Epoch:  973       10 Batch loss: 0.267102 Batch F1: 0.22222222222222218
Epoch:  973       11 Batch loss: 0.239318 Batch F1: 0.22222222222222224
Epoch:  973       12 Batch loss: 0.245463 Batch F1: 0.3333333333333333
Train Avg Loss  973: 0.222632

Train Avg F1  973: 0.29185018550960584

Val Avg Loss  973: 0.220470

Val Avg F1  973:  0.33488758553274683

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 974
--------------------------------------------------------------
Epoch:  974        1 Batch loss: 0.232650 Batch F1: 0.44444444444444436
Epoch:  974        2 Batch loss: 0.229240 Batch F1: 0.39999999999999997
Epoch:  974        3 Batch loss: 0.235586 Batch F1: 0.48648648648648657
Epoch:  974        4 Batch loss: 0.238730 Batch F1: 0.37037037037037035
Epoch:  974        5 Batch loss: 0.240202 Batch F1: 0.5128205128205129
Epoch:  974        6 Batch loss: 0.218387 Batch F1: 0.5
Epoch:  974        7 Batch loss: 0.212589 Batch F1: 0.2
Epoch:  974        8 Batch loss: 0.217459 Batch F1: 0.4516129032258065
Epoch:  974        9 Batch loss: 0.201756 Batch F1: 0.1904761904761905
Epoch:  974       10 Batch loss: 0.232002 Batch F1: 0.25
Epoch:  974       11 Batch loss: 0.211781 Batch F1: 0.2
Epoch:  974       12 Batch loss: 0.197077 Batch F1: 0.0
Train Avg Loss  974: 0.222288

Train Avg F1  974: 0.3338509089853176

Val Avg Loss  974: 0.217180

Val Avg F1  974:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 975
--------------------------------------------------------------
Epoch:  975        1 Batch loss: 0.223006 Batch F1: 0.0
Epoch:  975        2 Batch loss: 0.209097 Batch F1: 0.0
Epoch:  975        3 Batch loss: 0.203723 Batch F1: 0.0
Epoch:  975        4 Batch loss: 0.223288 Batch F1: 0.0
Epoch:  975        5 Batch loss: 0.219138 Batch F1: 0.0
Epoch:  975        6 Batch loss: 0.260461 Batch F1: 0.0
Epoch:  975        7 Batch loss: 0.211650 Batch F1: 0.0
Epoch:  975        8 Batch loss: 0.237866 Batch F1: 0.15384615384615385
Epoch:  975        9 Batch loss: 0.227415 Batch F1: 0.29629629629629634
Epoch:  975       10 Batch loss: 0.223987 Batch F1: 0.25
Epoch:  975       11 Batch loss: 0.207854 Batch F1: 0.42857142857142855
Epoch:  975       12 Batch loss: 0.236773 Batch F1: 0.28571428571428575
Train Avg Loss  975: 0.223688

Train Avg F1  975: 0.11786901370234705

Val Avg Loss  975: 0.219355

Val Avg F1  975:  0.25384615384615383

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 976
--------------------------------------------------------------
Epoch:  976        1 Batch loss: 0.227896 Batch F1: 0.16666666666666669
Epoch:  976        2 Batch loss: 0.226190 Batch F1: 0.2608695652173913
Epoch:  976        3 Batch loss: 0.238672 Batch F1: 0.0
Epoch:  976        4 Batch loss: 0.226050 Batch F1: 0.09999999999999999
Epoch:  976        5 Batch loss: 0.215750 Batch F1: 0.0
Epoch:  976        6 Batch loss: 0.225431 Batch F1: 0.0909090909090909
Epoch:  976        7 Batch loss: 0.202719 Batch F1: 0.3333333333333333
Epoch:  976        8 Batch loss: 0.228779 Batch F1: 0.24999999999999997
Epoch:  976        9 Batch loss: 0.229833 Batch F1: 0.45161290322580644
Epoch:  976       10 Batch loss: 0.194865 Batch F1: 0.4444444444444445
Epoch:  976       11 Batch loss: 0.244543 Batch F1: 0.25806451612903225
Epoch:  976       12 Batch loss: 0.208834 Batch F1: 0.47619047619047616
Train Avg Loss  976: 0.222463

Train Avg F1  976: 0.23600758300968683

Val Avg Loss  976: 0.217464

Val Avg F1  976:  0.18154761904761904

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 977
--------------------------------------------------------------
Epoch:  977        1 Batch loss: 0.198628 Batch F1: 0.0
Epoch:  977        2 Batch loss: 0.204277 Batch F1: 0.0
Epoch:  977        3 Batch loss: 0.239591 Batch F1: 0.0
Epoch:  977        4 Batch loss: 0.215842 Batch F1: 0.0
Epoch:  977        5 Batch loss: 0.218856 Batch F1: 0.0
Epoch:  977        6 Batch loss: 0.258848 Batch F1: 0.0
Epoch:  977        7 Batch loss: 0.214639 Batch F1: 0.0
Epoch:  977        8 Batch loss: 0.241065 Batch F1: 0.0
Epoch:  977        9 Batch loss: 0.275418 Batch F1: 0.0
Epoch:  977       10 Batch loss: 0.201508 Batch F1: 0.0
Epoch:  977       11 Batch loss: 0.192237 Batch F1: 0.4
Epoch:  977       12 Batch loss: 0.232446 Batch F1: 0.39999999999999997
Train Avg Loss  977: 0.224446

Train Avg F1  977: 0.06666666666666667

Val Avg Loss  977: 0.221851

Val Avg F1  977:  0.3562582345191041

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 978
--------------------------------------------------------------
Epoch:  978        1 Batch loss: 0.217406 Batch F1: 0.4848484848484849
Epoch:  978        2 Batch loss: 0.227385 Batch F1: 0.3870967741935484
Epoch:  978        3 Batch loss: 0.239509 Batch F1: 0.25806451612903225
Epoch:  978        4 Batch loss: 0.201492 Batch F1: 0.6153846153846153
Epoch:  978        5 Batch loss: 0.219279 Batch F1: 0.38095238095238093
Epoch:  978        6 Batch loss: 0.198753 Batch F1: 0.0
Epoch:  978        7 Batch loss: 0.213073 Batch F1: 0.0
Epoch:  978        8 Batch loss: 0.236493 Batch F1: 0.0
Epoch:  978        9 Batch loss: 0.233207 Batch F1: 0.0
Epoch:  978       10 Batch loss: 0.264023 Batch F1: 0.0
Epoch:  978       11 Batch loss: 0.221692 Batch F1: 0.0
Epoch:  978       12 Batch loss: 0.195768 Batch F1: 0.13333333333333336
Train Avg Loss  978: 0.222340

Train Avg F1  978: 0.18830667540344959

Val Avg Loss  978: 0.220654

Val Avg F1  978:  0.31406641604010027

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 979
--------------------------------------------------------------
Epoch:  979        1 Batch loss: 0.224390 Batch F1: 0.4666666666666667
Epoch:  979        2 Batch loss: 0.201932 Batch F1: 0.6
Epoch:  979        3 Batch loss: 0.236472 Batch F1: 0.3636363636363637
Epoch:  979        4 Batch loss: 0.227041 Batch F1: 0.4285714285714285
Epoch:  979        5 Batch loss: 0.207497 Batch F1: 0.48
Epoch:  979        6 Batch loss: 0.220242 Batch F1: 0.38461538461538464
Epoch:  979        7 Batch loss: 0.194891 Batch F1: 0.3333333333333333
Epoch:  979        8 Batch loss: 0.212442 Batch F1: 0.0
Epoch:  979        9 Batch loss: 0.249665 Batch F1: 0.0
Epoch:  979       10 Batch loss: 0.216556 Batch F1: 0.0
Epoch:  979       11 Batch loss: 0.238818 Batch F1: 0.1111111111111111
Epoch:  979       12 Batch loss: 0.249466 Batch F1: 0.0
Train Avg Loss  979: 0.223284

Train Avg F1  979: 0.263994523994524

Val Avg Loss  979: 0.217422

Val Avg F1  979:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 980
--------------------------------------------------------------
Epoch:  980        1 Batch loss: 0.221648 Batch F1: 0.0
Epoch:  980        2 Batch loss: 0.248495 Batch F1: 0.15384615384615385
Epoch:  980        3 Batch loss: 0.245333 Batch F1: 0.2962962962962963
Epoch:  980        4 Batch loss: 0.248480 Batch F1: 0.37499999999999994
Epoch:  980        5 Batch loss: 0.228366 Batch F1: 0.46153846153846156
Epoch:  980        6 Batch loss: 0.246831 Batch F1: 0.2857142857142857
Epoch:  980        7 Batch loss: 0.216371 Batch F1: 0.5161290322580645
Epoch:  980        8 Batch loss: 0.230321 Batch F1: 0.3448275862068965
Epoch:  980        9 Batch loss: 0.183103 Batch F1: 0.3
Epoch:  980       10 Batch loss: 0.196189 Batch F1: 0.0
Epoch:  980       11 Batch loss: 0.249380 Batch F1: 0.0
Epoch:  980       12 Batch loss: 0.179758 Batch F1: 0.0
Train Avg Loss  980: 0.224523

Train Avg F1  980: 0.2277793179883465

Val Avg Loss  980: 0.218840

Val Avg F1  980:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 981
--------------------------------------------------------------
Epoch:  981        1 Batch loss: 0.219756 Batch F1: 0.0
Epoch:  981        2 Batch loss: 0.219720 Batch F1: 0.0
Epoch:  981        3 Batch loss: 0.250752 Batch F1: 0.0
Epoch:  981        4 Batch loss: 0.243701 Batch F1: 0.0
Epoch:  981        5 Batch loss: 0.242665 Batch F1: 0.0
Epoch:  981        6 Batch loss: 0.252571 Batch F1: 0.0
Epoch:  981        7 Batch loss: 0.235803 Batch F1: 0.0
Epoch:  981        8 Batch loss: 0.223846 Batch F1: 0.14285714285714288
Epoch:  981        9 Batch loss: 0.213479 Batch F1: 0.0
Epoch:  981       10 Batch loss: 0.231568 Batch F1: 0.0
Epoch:  981       11 Batch loss: 0.239549 Batch F1: 0.0
Epoch:  981       12 Batch loss: 0.193287 Batch F1: 0.0
Train Avg Loss  981: 0.230558

Train Avg F1  981: 0.011904761904761906

Val Avg Loss  981: 0.217464

Val Avg F1  981:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 982
--------------------------------------------------------------
Epoch:  982        1 Batch loss: 0.213877 Batch F1: 0.0
Epoch:  982        2 Batch loss: 0.195142 Batch F1: 0.0
Epoch:  982        3 Batch loss: 0.235755 Batch F1: 0.0
Epoch:  982        4 Batch loss: 0.219598 Batch F1: 0.0
Epoch:  982        5 Batch loss: 0.214103 Batch F1: 0.0
Epoch:  982        6 Batch loss: 0.173819 Batch F1: 0.0
Epoch:  982        7 Batch loss: 0.248012 Batch F1: 0.0
Epoch:  982        8 Batch loss: 0.233833 Batch F1: 0.0
Epoch:  982        9 Batch loss: 0.208705 Batch F1: 0.0
Epoch:  982       10 Batch loss: 0.292876 Batch F1: 0.0
Epoch:  982       11 Batch loss: 0.258406 Batch F1: 0.0
Epoch:  982       12 Batch loss: 0.215709 Batch F1: 0.4761904761904762
Train Avg Loss  982: 0.225820

Train Avg F1  982: 0.03968253968253969

Val Avg Loss  982: 0.225409

Val Avg F1  982:  0.2511655011655012

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 983
--------------------------------------------------------------
Epoch:  983        1 Batch loss: 0.223185 Batch F1: 0.1739130434782609
Epoch:  983        2 Batch loss: 0.241088 Batch F1: 0.4571428571428572
Epoch:  983        3 Batch loss: 0.223204 Batch F1: 0.27272727272727276
Epoch:  983        4 Batch loss: 0.258081 Batch F1: 0.3125
Epoch:  983        5 Batch loss: 0.225844 Batch F1: 0.5185185185185185
Epoch:  983        6 Batch loss: 0.221461 Batch F1: 0.5
Epoch:  983        7 Batch loss: 0.200134 Batch F1: 0.2
Epoch:  983        8 Batch loss: 0.208607 Batch F1: 0.0
Epoch:  983        9 Batch loss: 0.204612 Batch F1: 0.0
Epoch:  983       10 Batch loss: 0.260515 Batch F1: 0.0
Epoch:  983       11 Batch loss: 0.216566 Batch F1: 0.0
Epoch:  983       12 Batch loss: 0.217568 Batch F1: 0.0
Train Avg Loss  983: 0.225072

Train Avg F1  983: 0.2029001409889091

Val Avg Loss  983: 0.217796

Val Avg F1  983:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 984
--------------------------------------------------------------
Epoch:  984        1 Batch loss: 0.213430 Batch F1: 0.0
Epoch:  984        2 Batch loss: 0.207744 Batch F1: 0.0
Epoch:  984        3 Batch loss: 0.235991 Batch F1: 0.0
Epoch:  984        4 Batch loss: 0.244319 Batch F1: 0.35714285714285715
Epoch:  984        5 Batch loss: 0.208478 Batch F1: 0.23529411764705882
Epoch:  984        6 Batch loss: 0.230366 Batch F1: 0.09523809523809523
Epoch:  984        7 Batch loss: 0.254425 Batch F1: 0.07142857142857142
Epoch:  984        8 Batch loss: 0.190764 Batch F1: 0.5384615384615384
Epoch:  984        9 Batch loss: 0.218534 Batch F1: 0.48275862068965514
Epoch:  984       10 Batch loss: 0.217203 Batch F1: 0.5
Epoch:  984       11 Batch loss: 0.216781 Batch F1: 0.2857142857142857
Epoch:  984       12 Batch loss: 0.235391 Batch F1: 0.2
Train Avg Loss  984: 0.222786

Train Avg F1  984: 0.23050317386017183

Val Avg Loss  984: 0.218512

Val Avg F1  984:  0.2058080808080808

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 985
--------------------------------------------------------------
Epoch:  985        1 Batch loss: 0.221019 Batch F1: 0.34782608695652173
Epoch:  985        2 Batch loss: 0.198474 Batch F1: 0.27272727272727276
Epoch:  985        3 Batch loss: 0.232991 Batch F1: 0.4
Epoch:  985        4 Batch loss: 0.201645 Batch F1: 0.19047619047619047
Epoch:  985        5 Batch loss: 0.199333 Batch F1: 0.2222222222222222
Epoch:  985        6 Batch loss: 0.241078 Batch F1: 0.16
Epoch:  985        7 Batch loss: 0.204215 Batch F1: 0.4166666666666667
Epoch:  985        8 Batch loss: 0.237770 Batch F1: 0.39999999999999997
Epoch:  985        9 Batch loss: 0.215543 Batch F1: 0.25
Epoch:  985       10 Batch loss: 0.220975 Batch F1: 0.3333333333333333
Epoch:  985       11 Batch loss: 0.263930 Batch F1: 0.26666666666666666
Epoch:  985       12 Batch loss: 0.229137 Batch F1: 0.3157894736842105
Train Avg Loss  985: 0.222176

Train Avg F1  985: 0.29797565939442366

Val Avg Loss  985: 0.221032

Val Avg F1  985:  0.32498271744595275

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 986
--------------------------------------------------------------
Epoch:  986        1 Batch loss: 0.206904 Batch F1: 0.48
Epoch:  986        2 Batch loss: 0.202335 Batch F1: 0.48
Epoch:  986        3 Batch loss: 0.230900 Batch F1: 0.4285714285714285
Epoch:  986        4 Batch loss: 0.225441 Batch F1: 0.23076923076923078
Epoch:  986        5 Batch loss: 0.208807 Batch F1: 0.2857142857142857
Epoch:  986        6 Batch loss: 0.248195 Batch F1: 0.24
Epoch:  986        7 Batch loss: 0.229308 Batch F1: 0.09090909090909091
Epoch:  986        8 Batch loss: 0.258607 Batch F1: 0.0
Epoch:  986        9 Batch loss: 0.195384 Batch F1: 0.47619047619047616
Epoch:  986       10 Batch loss: 0.212313 Batch F1: 0.3703703703703704
Epoch:  986       11 Batch loss: 0.217129 Batch F1: 0.3333333333333333
Epoch:  986       12 Batch loss: 0.236634 Batch F1: 0.19047619047619044
Train Avg Loss  986: 0.222663

Train Avg F1  986: 0.3005278671945338

Val Avg Loss  986: 0.219266

Val Avg F1  986:  0.2844954250985106

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 987
--------------------------------------------------------------
Epoch:  987        1 Batch loss: 0.197836 Batch F1: 0.125
Epoch:  987        2 Batch loss: 0.229839 Batch F1: 0.24
Epoch:  987        3 Batch loss: 0.202750 Batch F1: 0.3636363636363636
Epoch:  987        4 Batch loss: 0.280392 Batch F1: 0.06896551724137932
Epoch:  987        5 Batch loss: 0.215403 Batch F1: 0.0
Epoch:  987        6 Batch loss: 0.218479 Batch F1: 0.0
Epoch:  987        7 Batch loss: 0.230021 Batch F1: 0.0
Epoch:  987        8 Batch loss: 0.232224 Batch F1: 0.09523809523809523
Epoch:  987        9 Batch loss: 0.204031 Batch F1: 0.0
Epoch:  987       10 Batch loss: 0.212676 Batch F1: 0.16666666666666669
Epoch:  987       11 Batch loss: 0.220208 Batch F1: 0.37037037037037035
Epoch:  987       12 Batch loss: 0.232663 Batch F1: 0.2857142857142857
Train Avg Loss  987: 0.223044

Train Avg F1  987: 0.1429659415722634

Val Avg Loss  987: 0.218799

Val Avg F1  987:  0.25702433766949895

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 988
--------------------------------------------------------------
Epoch:  988        1 Batch loss: 0.243093 Batch F1: 0.1739130434782609
Epoch:  988        2 Batch loss: 0.241558 Batch F1: 0.33333333333333337
Epoch:  988        3 Batch loss: 0.216696 Batch F1: 0.4
Epoch:  988        4 Batch loss: 0.232568 Batch F1: 0.4
Epoch:  988        5 Batch loss: 0.223034 Batch F1: 0.29629629629629634
Epoch:  988        6 Batch loss: 0.234549 Batch F1: 0.26666666666666666
Epoch:  988        7 Batch loss: 0.207632 Batch F1: 0.4166666666666667
Epoch:  988        8 Batch loss: 0.218266 Batch F1: 0.37037037037037035
Epoch:  988        9 Batch loss: 0.196223 Batch F1: 0.3636363636363636
Epoch:  988       10 Batch loss: 0.206960 Batch F1: 0.2222222222222222
Epoch:  988       11 Batch loss: 0.215195 Batch F1: 0.1
Epoch:  988       12 Batch loss: 0.236667 Batch F1: 0.0
Train Avg Loss  988: 0.222703

Train Avg F1  988: 0.278592080222515

Val Avg Loss  988: 0.217228

Val Avg F1  988:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 989
--------------------------------------------------------------
Epoch:  989        1 Batch loss: 0.243475 Batch F1: 0.0
Epoch:  989        2 Batch loss: 0.251365 Batch F1: 0.0
Epoch:  989        3 Batch loss: 0.226908 Batch F1: 0.0
Epoch:  989        4 Batch loss: 0.226640 Batch F1: 0.08695652173913042
Epoch:  989        5 Batch loss: 0.244652 Batch F1: 0.3076923076923077
Epoch:  989        6 Batch loss: 0.236116 Batch F1: 0.32000000000000006
Epoch:  989        7 Batch loss: 0.209542 Batch F1: 0.2
Epoch:  989        8 Batch loss: 0.224163 Batch F1: 0.2857142857142857
Epoch:  989        9 Batch loss: 0.203132 Batch F1: 0.1111111111111111
Epoch:  989       10 Batch loss: 0.243394 Batch F1: 0.0
Epoch:  989       11 Batch loss: 0.204013 Batch F1: 0.0
Epoch:  989       12 Batch loss: 0.173363 Batch F1: 0.0
Train Avg Loss  989: 0.223897

Train Avg F1  989: 0.10928951885473626

Val Avg Loss  989: 0.216567

Val Avg F1  989:  0.0

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 990
--------------------------------------------------------------
Epoch:  990        1 Batch loss: 0.211388 Batch F1: 0.0
Epoch:  990        2 Batch loss: 0.228691 Batch F1: 0.0
Epoch:  990        3 Batch loss: 0.205618 Batch F1: 0.0
Epoch:  990        4 Batch loss: 0.202311 Batch F1: 0.23529411764705882
Epoch:  990        5 Batch loss: 0.233119 Batch F1: 0.22222222222222218
Epoch:  990        6 Batch loss: 0.220942 Batch F1: 0.5000000000000001
Epoch:  990        7 Batch loss: 0.205719 Batch F1: 0.10526315789473685
Epoch:  990        8 Batch loss: 0.236691 Batch F1: 0.28571428571428575
Epoch:  990        9 Batch loss: 0.225151 Batch F1: 0.5161290322580645
Epoch:  990       10 Batch loss: 0.254130 Batch F1: 0.17391304347826086
Epoch:  990       11 Batch loss: 0.204382 Batch F1: 0.4615384615384615
Epoch:  990       12 Batch loss: 0.248312 Batch F1: 0.2
Train Avg Loss  990: 0.223038

Train Avg F1  990: 0.22500619339609093

Val Avg Loss  990: 0.217513

Val Avg F1  990:  0.2199074074074074

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 991
--------------------------------------------------------------
Epoch:  991        1 Batch loss: 0.227424 Batch F1: 0.3478260869565218
Epoch:  991        2 Batch loss: 0.207394 Batch F1: 0.0
Epoch:  991        3 Batch loss: 0.203046 Batch F1: 0.0
Epoch:  991        4 Batch loss: 0.184641 Batch F1: 0.0
Epoch:  991        5 Batch loss: 0.227047 Batch F1: 0.1
Epoch:  991        6 Batch loss: 0.261533 Batch F1: 0.39999999999999997
Epoch:  991        7 Batch loss: 0.209913 Batch F1: 0.3846153846153846
Epoch:  991        8 Batch loss: 0.254871 Batch F1: 0.07407407407407407
Epoch:  991        9 Batch loss: 0.210650 Batch F1: 0.21052631578947367
Epoch:  991       10 Batch loss: 0.243212 Batch F1: 0.23076923076923075
Epoch:  991       11 Batch loss: 0.212175 Batch F1: 0.3333333333333333
Epoch:  991       12 Batch loss: 0.245523 Batch F1: 0.23076923076923078
Train Avg Loss  991: 0.223953

Train Avg F1  991: 0.19265947135893743

Val Avg Loss  991: 0.219212

Val Avg F1  991:  0.26861067993791105

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 992
--------------------------------------------------------------
Epoch:  992        1 Batch loss: 0.215740 Batch F1: 0.39999999999999997
Epoch:  992        2 Batch loss: 0.220957 Batch F1: 0.1904761904761905
Epoch:  992        3 Batch loss: 0.203186 Batch F1: 0.31578947368421056
Epoch:  992        4 Batch loss: 0.234536 Batch F1: 0.3448275862068966
Epoch:  992        5 Batch loss: 0.204800 Batch F1: 0.42857142857142855
Epoch:  992        6 Batch loss: 0.224637 Batch F1: 0.0
Epoch:  992        7 Batch loss: 0.254368 Batch F1: 0.16666666666666669
Epoch:  992        8 Batch loss: 0.215754 Batch F1: 0.11764705882352941
Epoch:  992        9 Batch loss: 0.248001 Batch F1: 0.0
Epoch:  992       10 Batch loss: 0.234146 Batch F1: 0.0
Epoch:  992       11 Batch loss: 0.184928 Batch F1: 0.0
Epoch:  992       12 Batch loss: 0.233734 Batch F1: 0.09999999999999999
Train Avg Loss  992: 0.222899

Train Avg F1  992: 0.17199820036907687

Val Avg Loss  992: 0.218782

Val Avg F1  992:  0.20299516908212561

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 993
--------------------------------------------------------------
Epoch:  993        1 Batch loss: 0.233876 Batch F1: 0.1
Epoch:  993        2 Batch loss: 0.204863 Batch F1: 0.2727272727272727
Epoch:  993        3 Batch loss: 0.228774 Batch F1: 0.2857142857142857
Epoch:  993        4 Batch loss: 0.207292 Batch F1: 0.1111111111111111
Epoch:  993        5 Batch loss: 0.216862 Batch F1: 0.1
Epoch:  993        6 Batch loss: 0.224267 Batch F1: 0.23076923076923073
Epoch:  993        7 Batch loss: 0.247748 Batch F1: 0.34285714285714286
Epoch:  993        8 Batch loss: 0.222732 Batch F1: 0.2857142857142857
Epoch:  993        9 Batch loss: 0.215431 Batch F1: 0.31999999999999995
Epoch:  993       10 Batch loss: 0.237083 Batch F1: 0.16666666666666666
Epoch:  993       11 Batch loss: 0.212324 Batch F1: 0.11111111111111112
Epoch:  993       12 Batch loss: 0.215510 Batch F1: 0.46153846153846156
Train Avg Loss  993: 0.222230

Train Avg F1  993: 0.23235079735079733

Val Avg Loss  993: 0.219511

Val Avg F1  993:  0.236607812265707

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 994
--------------------------------------------------------------
Epoch:  994        1 Batch loss: 0.251159 Batch F1: 0.26666666666666666
Epoch:  994        2 Batch loss: 0.210581 Batch F1: 0.42857142857142855
Epoch:  994        3 Batch loss: 0.253607 Batch F1: 0.2352941176470588
Epoch:  994        4 Batch loss: 0.215056 Batch F1: 0.2857142857142857
Epoch:  994        5 Batch loss: 0.159514 Batch F1: 0.4285714285714285
Epoch:  994        6 Batch loss: 0.245505 Batch F1: 0.25
Epoch:  994        7 Batch loss: 0.230435 Batch F1: 0.43750000000000006
Epoch:  994        8 Batch loss: 0.185850 Batch F1: 0.45454545454545453
Epoch:  994        9 Batch loss: 0.258190 Batch F1: 0.08000000000000002
Epoch:  994       10 Batch loss: 0.180712 Batch F1: 0.4
Epoch:  994       11 Batch loss: 0.231837 Batch F1: 0.23076923076923078
Epoch:  994       12 Batch loss: 0.242918 Batch F1: 0.2
Train Avg Loss  994: 0.222114

Train Avg F1  994: 0.3081360510404628

Val Avg Loss  994: 0.218288

Val Avg F1  994:  0.26468710089399744

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 995
--------------------------------------------------------------
Epoch:  995        1 Batch loss: 0.227845 Batch F1: 0.2608695652173913
Epoch:  995        2 Batch loss: 0.195181 Batch F1: 0.36363636363636365
Epoch:  995        3 Batch loss: 0.245854 Batch F1: 0.2857142857142857
Epoch:  995        4 Batch loss: 0.209039 Batch F1: 0.4166666666666667
Epoch:  995        5 Batch loss: 0.232478 Batch F1: 0.1739130434782609
Epoch:  995        6 Batch loss: 0.232464 Batch F1: 0.0
Epoch:  995        7 Batch loss: 0.208005 Batch F1: 0.0
Epoch:  995        8 Batch loss: 0.247672 Batch F1: 0.3448275862068966
Epoch:  995        9 Batch loss: 0.222001 Batch F1: 0.37037037037037035
Epoch:  995       10 Batch loss: 0.204613 Batch F1: 0.36363636363636365
Epoch:  995       11 Batch loss: 0.213654 Batch F1: 0.30769230769230765
Epoch:  995       12 Batch loss: 0.238684 Batch F1: 0.11764705882352941
Train Avg Loss  995: 0.223124

Train Avg F1  995: 0.250414467620203

Val Avg Loss  995: 0.218971

Val Avg F1  995:  0.2854985754985755

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 996
--------------------------------------------------------------
Epoch:  996        1 Batch loss: 0.257663 Batch F1: 0.08695652173913043
Epoch:  996        2 Batch loss: 0.215429 Batch F1: 0.48
Epoch:  996        3 Batch loss: 0.199582 Batch F1: 0.3478260869565218
Epoch:  996        4 Batch loss: 0.201529 Batch F1: 0.1111111111111111
Epoch:  996        5 Batch loss: 0.187800 Batch F1: 0.0
Epoch:  996        6 Batch loss: 0.298488 Batch F1: 0.0
Epoch:  996        7 Batch loss: 0.190238 Batch F1: 0.0
Epoch:  996        8 Batch loss: 0.218914 Batch F1: 0.09523809523809525
Epoch:  996        9 Batch loss: 0.241247 Batch F1: 0.25
Epoch:  996       10 Batch loss: 0.199749 Batch F1: 0.2857142857142857
Epoch:  996       11 Batch loss: 0.199585 Batch F1: 0.5185185185185185
Epoch:  996       12 Batch loss: 0.275761 Batch F1: 0.1739130434782609
Train Avg Loss  996: 0.223832

Train Avg F1  996: 0.19577313856299364

Val Avg Loss  996: 0.219851

Val Avg F1  996:  0.26837412587412585

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 997
--------------------------------------------------------------
Epoch:  997        1 Batch loss: 0.272842 Batch F1: 0.06896551724137931
Epoch:  997        2 Batch loss: 0.207804 Batch F1: 0.36363636363636365
Epoch:  997        3 Batch loss: 0.212526 Batch F1: 0.3333333333333333
Epoch:  997        4 Batch loss: 0.227552 Batch F1: 0.3333333333333333
Epoch:  997        5 Batch loss: 0.218781 Batch F1: 0.2962962962962963
Epoch:  997        6 Batch loss: 0.230887 Batch F1: 0.2962962962962963
Epoch:  997        7 Batch loss: 0.214541 Batch F1: 0.19047619047619047
Epoch:  997        8 Batch loss: 0.190162 Batch F1: 0.3333333333333333
Epoch:  997        9 Batch loss: 0.223769 Batch F1: 0.1
Epoch:  997       10 Batch loss: 0.227026 Batch F1: 0.0
Epoch:  997       11 Batch loss: 0.218627 Batch F1: 0.0
Epoch:  997       12 Batch loss: 0.229353 Batch F1: 0.0
Train Avg Loss  997: 0.222822

Train Avg F1  997: 0.19297255532887717

Val Avg Loss  997: 0.219269

Val Avg F1  997:  0.27079718527086943

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 998
--------------------------------------------------------------
Epoch:  998        1 Batch loss: 0.236207 Batch F1: 0.16
Epoch:  998        2 Batch loss: 0.242959 Batch F1: 0.36363636363636365
Epoch:  998        3 Batch loss: 0.188597 Batch F1: 0.47058823529411764
Epoch:  998        4 Batch loss: 0.243803 Batch F1: 0.33333333333333337
Epoch:  998        5 Batch loss: 0.219934 Batch F1: 0.48275862068965514
Epoch:  998        6 Batch loss: 0.223108 Batch F1: 0.0
Epoch:  998        7 Batch loss: 0.246716 Batch F1: 0.21428571428571427
Epoch:  998        8 Batch loss: 0.189335 Batch F1: 0.22222222222222224
Epoch:  998        9 Batch loss: 0.224783 Batch F1: 0.3846153846153846
Epoch:  998       10 Batch loss: 0.212038 Batch F1: 0.4545454545454545
Epoch:  998       11 Batch loss: 0.210197 Batch F1: 0.4
Epoch:  998       12 Batch loss: 0.229292 Batch F1: 0.1111111111111111
Train Avg Loss  998: 0.222247

Train Avg F1  998: 0.2997580366444464

Val Avg Loss  998: 0.217677

Val Avg F1  998:  0.16985645933014354

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 999
--------------------------------------------------------------
Epoch:  999        1 Batch loss: 0.210722 Batch F1: 0.125
Epoch:  999        2 Batch loss: 0.257040 Batch F1: 0.08333333333333333
Epoch:  999        3 Batch loss: 0.184569 Batch F1: 0.0
Epoch:  999        4 Batch loss: 0.222692 Batch F1: 0.0
Epoch:  999        5 Batch loss: 0.199292 Batch F1: 0.09523809523809523
Epoch:  999        6 Batch loss: 0.226108 Batch F1: 0.17391304347826086
Epoch:  999        7 Batch loss: 0.206771 Batch F1: 0.34782608695652173
Epoch:  999        8 Batch loss: 0.196542 Batch F1: 0.46153846153846156
Epoch:  999        9 Batch loss: 0.254682 Batch F1: 0.27586206896551724
Epoch:  999       10 Batch loss: 0.229742 Batch F1: 0.35714285714285715
Epoch:  999       11 Batch loss: 0.239556 Batch F1: 0.4666666666666667
Epoch:  999       12 Batch loss: 0.232085 Batch F1: 0.2857142857142857
Train Avg Loss  999: 0.221650

Train Avg F1  999: 0.22268624158616665

Val Avg Loss  999: 0.218477

Val Avg F1  999:  0.24387959866220738

Optimal Val loss (Epoch 270): 0.2160559967160225

Epoch 1000
--------------------------------------------------------------
Epoch: 1000        1 Batch loss: 0.214072 Batch F1: 0.25
Epoch: 1000        2 Batch loss: 0.210060 Batch F1: 0.2
Epoch: 1000        3 Batch loss: 0.245392 Batch F1: 0.09090909090909091
Epoch: 1000        4 Batch loss: 0.194927 Batch F1: 0.125
Epoch: 1000        5 Batch loss: 0.203873 Batch F1: 0.0
Epoch: 1000        6 Batch loss: 0.256558 Batch F1: 0.0
Epoch: 1000        7 Batch loss: 0.213874 Batch F1: 0.0
Epoch: 1000        8 Batch loss: 0.245056 Batch F1: 0.0
Epoch: 1000        9 Batch loss: 0.213233 Batch F1: 0.0
Epoch: 1000       10 Batch loss: 0.208332 Batch F1: 0.0
Epoch: 1000       11 Batch loss: 0.244377 Batch F1: 0.0
Epoch: 1000       12 Batch loss: 0.224559 Batch F1: 0.4166666666666667
Train Avg Loss 1000: 0.222860

Train Avg F1 1000: 0.09021464646464646

Val Avg Loss 1000: 0.224326

Val Avg F1 1000:  0.3495310857789636

Optimal Val loss (Epoch 270): 0.2160559967160225

Done!
