Removed 3 of 595
Removed 0 of 198
Removed 0 of 198
Model with variable positions in join nodes
Loss function: MSELoss
Optimizer: LR [0.01] weight decay [0.0005]
Epoch 1
--------------------------------------------------------------
Epoch:    1        1 Batch loss: 0.245550 Batch F1: 0.0
Epoch:    1        2 Batch loss: 0.176841 Batch F1: 0.0
Epoch:    1        3 Batch loss: 0.186764 Batch F1: 0.0
Epoch:    1        4 Batch loss: 0.166933 Batch F1: 0.0
Epoch:    1        5 Batch loss: 0.185468 Batch F1: 0.0
Epoch:    1        6 Batch loss: 0.156507 Batch F1: 0.0
Epoch:    1        7 Batch loss: 0.222080 Batch F1: 0.0
Epoch:    1        8 Batch loss: 0.119955 Batch F1: 0.0
Epoch:    1        9 Batch loss: 0.127491 Batch F1: 0.0
Epoch:    1       10 Batch loss: 0.171768 Batch F1: 0.0
Epoch:    1       11 Batch loss: 0.160028 Batch F1: 0.0
Epoch:    1       12 Batch loss: 0.079272 Batch F1: 0.0
Train Avg Loss    1: 0.166555

Train Avg F1    1: 0.0

Val Avg Loss    1: 0.149129

Val Avg F1    1:  0.0

Optimal Val loss (Epoch 1): 0.14912852086126804

Epoch 2
--------------------------------------------------------------
Epoch:    2        1 Batch loss: 0.108464 Batch F1: 0.0
Epoch:    2        2 Batch loss: 0.147885 Batch F1: 0.0
Epoch:    2        3 Batch loss: 0.148255 Batch F1: 0.0
Epoch:    2        4 Batch loss: 0.205139 Batch F1: 0.0
Epoch:    2        5 Batch loss: 0.148910 Batch F1: 0.0
Epoch:    2        6 Batch loss: 0.220717 Batch F1: 0.0
Epoch:    2        7 Batch loss: 0.106158 Batch F1: 0.0
Epoch:    2        8 Batch loss: 0.120454 Batch F1: 0.0
Epoch:    2        9 Batch loss: 0.134481 Batch F1: 0.0
Epoch:    2       10 Batch loss: 0.148194 Batch F1: 0.0
Epoch:    2       11 Batch loss: 0.134365 Batch F1: 0.0
Epoch:    2       12 Batch loss: 0.185854 Batch F1: 0.0
Train Avg Loss    2: 0.150740

Train Avg F1    2: 0.0

Val Avg Loss    2: 0.149002

Val Avg F1    2:  0.0

Optimal Val loss (Epoch 2): 0.14900203607976437

Epoch 3
--------------------------------------------------------------
Epoch:    3        1 Batch loss: 0.196412 Batch F1: 0.0
Epoch:    3        2 Batch loss: 0.134196 Batch F1: 0.0
Epoch:    3        3 Batch loss: 0.160427 Batch F1: 0.0
Epoch:    3        4 Batch loss: 0.123458 Batch F1: 0.0
Epoch:    3        5 Batch loss: 0.134067 Batch F1: 0.0
Epoch:    3        6 Batch loss: 0.203512 Batch F1: 0.0
Epoch:    3        7 Batch loss: 0.119971 Batch F1: 0.0
Epoch:    3        8 Batch loss: 0.120181 Batch F1: 0.0
Epoch:    3        9 Batch loss: 0.134314 Batch F1: 0.0
Epoch:    3       10 Batch loss: 0.091476 Batch F1: 0.0
Epoch:    3       11 Batch loss: 0.191994 Batch F1: 0.0
Epoch:    3       12 Batch loss: 0.207361 Batch F1: 0.0
Train Avg Loss    3: 0.151447

Train Avg F1    3: 0.0

Val Avg Loss    3: 0.149240

Val Avg F1    3:  0.0

Optimal Val loss (Epoch 2): 0.14900203607976437

Epoch 4
--------------------------------------------------------------
Epoch:    4        1 Batch loss: 0.119976 Batch F1: 0.0
Epoch:    4        2 Batch loss: 0.202428 Batch F1: 0.0
Epoch:    4        3 Batch loss: 0.081707 Batch F1: 0.0
Epoch:    4        4 Batch loss: 0.082662 Batch F1: 0.0
Epoch:    4        5 Batch loss: 0.120935 Batch F1: 0.0
Epoch:    4        6 Batch loss: 0.213359 Batch F1: 0.0
Epoch:    4        7 Batch loss: 0.160100 Batch F1: 0.0
Epoch:    4        8 Batch loss: 0.185016 Batch F1: 0.0
Epoch:    4        9 Batch loss: 0.169998 Batch F1: 0.0
Epoch:    4       10 Batch loss: 0.135689 Batch F1: 0.0
Epoch:    4       11 Batch loss: 0.138000 Batch F1: 0.0
Epoch:    4       12 Batch loss: 0.176825 Batch F1: 0.0
Train Avg Loss    4: 0.148891

Train Avg F1    4: 0.0

Val Avg Loss    4: 0.146126

Val Avg F1    4:  0.0

Optimal Val loss (Epoch 4): 0.1461259052157402

Epoch 5
--------------------------------------------------------------
Epoch:    5        1 Batch loss: 0.100960 Batch F1: 0.0
Epoch:    5        2 Batch loss: 0.193841 Batch F1: 0.0
Epoch:    5        3 Batch loss: 0.144465 Batch F1: 0.0
Epoch:    5        4 Batch loss: 0.143267 Batch F1: 0.0
Epoch:    5        5 Batch loss: 0.110420 Batch F1: 0.0
Epoch:    5        6 Batch loss: 0.133579 Batch F1: 0.0
Epoch:    5        7 Batch loss: 0.118327 Batch F1: 0.0
Epoch:    5        8 Batch loss: 0.206068 Batch F1: 0.0
Epoch:    5        9 Batch loss: 0.141451 Batch F1: 0.0
Epoch:    5       10 Batch loss: 0.155379 Batch F1: 0.0
Epoch:    5       11 Batch loss: 0.140146 Batch F1: 0.0
Epoch:    5       12 Batch loss: 0.156498 Batch F1: 0.0
Train Avg Loss    5: 0.145367

Train Avg F1    5: 0.0

Val Avg Loss    5: 0.142303

Val Avg F1    5:  0.0

Optimal Val loss (Epoch 5): 0.1423029787838459

Epoch 6
--------------------------------------------------------------
Epoch:    6        1 Batch loss: 0.167745 Batch F1: 0.0
Epoch:    6        2 Batch loss: 0.149191 Batch F1: 0.0
Epoch:    6        3 Batch loss: 0.154271 Batch F1: 0.0
Epoch:    6        4 Batch loss: 0.098273 Batch F1: 0.0
Epoch:    6        5 Batch loss: 0.152048 Batch F1: 0.0
Epoch:    6        6 Batch loss: 0.140392 Batch F1: 0.0
Epoch:    6        7 Batch loss: 0.156682 Batch F1: 0.0
Epoch:    6        8 Batch loss: 0.157505 Batch F1: 0.0
Epoch:    6        9 Batch loss: 0.159345 Batch F1: 0.0
Epoch:    6       10 Batch loss: 0.106403 Batch F1: 0.0
Epoch:    6       11 Batch loss: 0.117661 Batch F1: 0.0
Epoch:    6       12 Batch loss: 0.155341 Batch F1: 0.0
Train Avg Loss    6: 0.142905

Train Avg F1    6: 0.0

Val Avg Loss    6: 0.144417

Val Avg F1    6:  0.0

Optimal Val loss (Epoch 5): 0.1423029787838459

Epoch 7
--------------------------------------------------------------
Epoch:    7        1 Batch loss: 0.130916 Batch F1: 0.0
Epoch:    7        2 Batch loss: 0.231320 Batch F1: 0.0
Epoch:    7        3 Batch loss: 0.117958 Batch F1: 0.0
Epoch:    7        4 Batch loss: 0.116215 Batch F1: 0.0
Epoch:    7        5 Batch loss: 0.145132 Batch F1: 0.0
Epoch:    7        6 Batch loss: 0.143922 Batch F1: 0.0
Epoch:    7        7 Batch loss: 0.131310 Batch F1: 0.0
Epoch:    7        8 Batch loss: 0.153748 Batch F1: 0.0
Epoch:    7        9 Batch loss: 0.144823 Batch F1: 0.0
Epoch:    7       10 Batch loss: 0.152161 Batch F1: 0.0
Epoch:    7       11 Batch loss: 0.106974 Batch F1: 0.0
Epoch:    7       12 Batch loss: 0.132785 Batch F1: 0.0
Train Avg Loss    7: 0.142272

Train Avg F1    7: 0.0

Val Avg Loss    7: 0.139313

Val Avg F1    7:  0.0

Optimal Val loss (Epoch 7): 0.1393129900097847

Epoch 8
--------------------------------------------------------------
Epoch:    8        1 Batch loss: 0.168339 Batch F1: 0.0
Epoch:    8        2 Batch loss: 0.125245 Batch F1: 0.0
Epoch:    8        3 Batch loss: 0.126264 Batch F1: 0.0
Epoch:    8        4 Batch loss: 0.185932 Batch F1: 0.0
Epoch:    8        5 Batch loss: 0.168442 Batch F1: 0.0
Epoch:    8        6 Batch loss: 0.118006 Batch F1: 0.0
Epoch:    8        7 Batch loss: 0.159446 Batch F1: 0.0
Epoch:    8        8 Batch loss: 0.135500 Batch F1: 0.0
Epoch:    8        9 Batch loss: 0.104651 Batch F1: 0.0
Epoch:    8       10 Batch loss: 0.107817 Batch F1: 0.0
Epoch:    8       11 Batch loss: 0.147275 Batch F1: 0.0
Epoch:    8       12 Batch loss: 0.176961 Batch F1: 0.0
Train Avg Loss    8: 0.143656

Train Avg F1    8: 0.0

Val Avg Loss    8: 0.141759

Val Avg F1    8:  0.0

Optimal Val loss (Epoch 7): 0.1393129900097847

Epoch 9
--------------------------------------------------------------
Epoch:    9        1 Batch loss: 0.151787 Batch F1: 0.0
Epoch:    9        2 Batch loss: 0.133321 Batch F1: 0.0
Epoch:    9        3 Batch loss: 0.113061 Batch F1: 0.0
Epoch:    9        4 Batch loss: 0.185750 Batch F1: 0.0
Epoch:    9        5 Batch loss: 0.092754 Batch F1: 0.0
Epoch:    9        6 Batch loss: 0.118585 Batch F1: 0.0
Epoch:    9        7 Batch loss: 0.169721 Batch F1: 0.0
Epoch:    9        8 Batch loss: 0.173608 Batch F1: 0.0
Epoch:    9        9 Batch loss: 0.136303 Batch F1: 0.0
Epoch:    9       10 Batch loss: 0.144295 Batch F1: 0.0
Epoch:    9       11 Batch loss: 0.142346 Batch F1: 0.0
Epoch:    9       12 Batch loss: 0.120670 Batch F1: 0.0
Train Avg Loss    9: 0.140183

Train Avg F1    9: 0.0

Val Avg Loss    9: 0.136958

Val Avg F1    9:  0.0

Optimal Val loss (Epoch 9): 0.13695758022367954

Epoch 10
--------------------------------------------------------------
Epoch:   10        1 Batch loss: 0.133506 Batch F1: 0.0
Epoch:   10        2 Batch loss: 0.192193 Batch F1: 0.0
Epoch:   10        3 Batch loss: 0.147525 Batch F1: 0.0
Epoch:   10        4 Batch loss: 0.157613 Batch F1: 0.0
Epoch:   10        5 Batch loss: 0.119852 Batch F1: 0.0
Epoch:   10        6 Batch loss: 0.122425 Batch F1: 0.0
Epoch:   10        7 Batch loss: 0.157226 Batch F1: 0.0
Epoch:   10        8 Batch loss: 0.182582 Batch F1: 0.0
Epoch:   10        9 Batch loss: 0.114902 Batch F1: 0.0
Epoch:   10       10 Batch loss: 0.108528 Batch F1: 0.0
Epoch:   10       11 Batch loss: 0.099264 Batch F1: 0.0
Epoch:   10       12 Batch loss: 0.140796 Batch F1: 0.0
Train Avg Loss   10: 0.139701

Train Avg F1   10: 0.0

Val Avg Loss   10: 0.135098

Val Avg F1   10:  0.0

Optimal Val loss (Epoch 10): 0.13509849831461906

Epoch 11
--------------------------------------------------------------
Epoch:   11        1 Batch loss: 0.149316 Batch F1: 0.0
Epoch:   11        2 Batch loss: 0.136998 Batch F1: 0.0
Epoch:   11        3 Batch loss: 0.110870 Batch F1: 0.0
Epoch:   11        4 Batch loss: 0.177435 Batch F1: 0.0
Epoch:   11        5 Batch loss: 0.164067 Batch F1: 0.0
Epoch:   11        6 Batch loss: 0.134520 Batch F1: 0.0
Epoch:   11        7 Batch loss: 0.136349 Batch F1: 0.0
Epoch:   11        8 Batch loss: 0.123516 Batch F1: 0.0
Epoch:   11        9 Batch loss: 0.132086 Batch F1: 0.0
Epoch:   11       10 Batch loss: 0.103253 Batch F1: 0.0
Epoch:   11       11 Batch loss: 0.125133 Batch F1: 0.0
Epoch:   11       12 Batch loss: 0.122185 Batch F1: 0.0
Train Avg Loss   11: 0.134644

Train Avg F1   11: 0.0

Val Avg Loss   11: 0.129021

Val Avg F1   11:  0.0

Optimal Val loss (Epoch 11): 0.12902119010686874

Epoch 12
--------------------------------------------------------------
Epoch:   12        1 Batch loss: 0.126496 Batch F1: 0.0
Epoch:   12        2 Batch loss: 0.134153 Batch F1: 0.0
Epoch:   12        3 Batch loss: 0.124045 Batch F1: 0.0
Epoch:   12        4 Batch loss: 0.120937 Batch F1: 0.0
Epoch:   12        5 Batch loss: 0.096561 Batch F1: 0.0
Epoch:   12        6 Batch loss: 0.155756 Batch F1: 0.0
Epoch:   12        7 Batch loss: 0.157082 Batch F1: 0.0
Epoch:   12        8 Batch loss: 0.137066 Batch F1: 0.0
Epoch:   12        9 Batch loss: 0.065260 Batch F1: 0.0
Epoch:   12       10 Batch loss: 0.142903 Batch F1: 0.0
Epoch:   12       11 Batch loss: 0.167659 Batch F1: 0.0
Epoch:   12       12 Batch loss: 0.102517 Batch F1: 0.0
Train Avg Loss   12: 0.127536

Train Avg F1   12: 0.0

Val Avg Loss   12: 0.122911

Val Avg F1   12:  0.0

Optimal Val loss (Epoch 12): 0.12291137129068375

Epoch 13
--------------------------------------------------------------
Epoch:   13        1 Batch loss: 0.122335 Batch F1: 0.0
Epoch:   13        2 Batch loss: 0.114020 Batch F1: 0.0
Epoch:   13        3 Batch loss: 0.069869 Batch F1: 0.0
Epoch:   13        4 Batch loss: 0.123112 Batch F1: 0.0
Epoch:   13        5 Batch loss: 0.207921 Batch F1: 0.0
Epoch:   13        6 Batch loss: 0.129078 Batch F1: 0.0
Epoch:   13        7 Batch loss: 0.128682 Batch F1: 0.0
Epoch:   13        8 Batch loss: 0.119133 Batch F1: 0.6666666666666666
Epoch:   13        9 Batch loss: 0.100979 Batch F1: 0.0
Epoch:   13       10 Batch loss: 0.151060 Batch F1: 0.0
Epoch:   13       11 Batch loss: 0.105796 Batch F1: 0.0
Epoch:   13       12 Batch loss: 0.175070 Batch F1: 0.0
Train Avg Loss   13: 0.128921

Train Avg F1   13: 0.05555555555555555

Val Avg Loss   13: 0.130781

Val Avg F1   13:  0.0

Optimal Val loss (Epoch 12): 0.12291137129068375

Epoch 14
--------------------------------------------------------------
Epoch:   14        1 Batch loss: 0.155583 Batch F1: 0.0
Epoch:   14        2 Batch loss: 0.164251 Batch F1: 0.0
Epoch:   14        3 Batch loss: 0.126834 Batch F1: 0.0
Epoch:   14        4 Batch loss: 0.138283 Batch F1: 0.0
Epoch:   14        5 Batch loss: 0.113006 Batch F1: 0.0
Epoch:   14        6 Batch loss: 0.109844 Batch F1: 0.0
Epoch:   14        7 Batch loss: 0.087869 Batch F1: 0.0
Epoch:   14        8 Batch loss: 0.216988 Batch F1: 0.0
Epoch:   14        9 Batch loss: 0.109129 Batch F1: 0.0
Epoch:   14       10 Batch loss: 0.094511 Batch F1: 0.0
Epoch:   14       11 Batch loss: 0.090119 Batch F1: 0.5714285714285715
Epoch:   14       12 Batch loss: 0.114549 Batch F1: 0.0
Train Avg Loss   14: 0.126747

Train Avg F1   14: 0.04761904761904762

Val Avg Loss   14: 0.121085

Val Avg F1   14:  0.0

Optimal Val loss (Epoch 14): 0.12108545750379562

Epoch 15
--------------------------------------------------------------
Epoch:   15        1 Batch loss: 0.127719 Batch F1: 0.0
Epoch:   15        2 Batch loss: 0.105542 Batch F1: 0.0
Epoch:   15        3 Batch loss: 0.117346 Batch F1: 0.0
Epoch:   15        4 Batch loss: 0.178389 Batch F1: 0.0
Epoch:   15        5 Batch loss: 0.088215 Batch F1: 0.0
Epoch:   15        6 Batch loss: 0.075861 Batch F1: 0.0
Epoch:   15        7 Batch loss: 0.127542 Batch F1: 0.0
Epoch:   15        8 Batch loss: 0.141117 Batch F1: 0.0
Epoch:   15        9 Batch loss: 0.069660 Batch F1: 0.0
Epoch:   15       10 Batch loss: 0.162150 Batch F1: 0.0
Epoch:   15       11 Batch loss: 0.104424 Batch F1: 0.0
Epoch:   15       12 Batch loss: 0.122947 Batch F1: 0.0
Train Avg Loss   15: 0.118409

Train Avg F1   15: 0.0

Val Avg Loss   15: 0.119362

Val Avg F1   15:  0.4305555555555556

Optimal Val loss (Epoch 15): 0.11936211585998535

Epoch 16
--------------------------------------------------------------
Epoch:   16        1 Batch loss: 0.151245 Batch F1: 0.375
Epoch:   16        2 Batch loss: 0.087592 Batch F1: 0.7499999999999999
Epoch:   16        3 Batch loss: 0.152390 Batch F1: 0.14285714285714288
Epoch:   16        4 Batch loss: 0.111458 Batch F1: 0.0
Epoch:   16        5 Batch loss: 0.129285 Batch F1: 0.0
Epoch:   16        6 Batch loss: 0.099962 Batch F1: 0.0
Epoch:   16        7 Batch loss: 0.085938 Batch F1: 0.0
Epoch:   16        8 Batch loss: 0.065379 Batch F1: 0.0
Epoch:   16        9 Batch loss: 0.186661 Batch F1: 0.0
Epoch:   16       10 Batch loss: 0.097662 Batch F1: 0.0
Epoch:   16       11 Batch loss: 0.139576 Batch F1: 0.0
Epoch:   16       12 Batch loss: 0.109818 Batch F1: 0.0
Train Avg Loss   16: 0.118081

Train Avg F1   16: 0.1056547619047619

Val Avg Loss   16: 0.116904

Val Avg F1   16:  0.0

Optimal Val loss (Epoch 16): 0.11690389923751354

Epoch 17
--------------------------------------------------------------
Epoch:   17        1 Batch loss: 0.156733 Batch F1: 0.0
Epoch:   17        2 Batch loss: 0.108362 Batch F1: 0.0
Epoch:   17        3 Batch loss: 0.088701 Batch F1: 0.0
Epoch:   17        4 Batch loss: 0.141984 Batch F1: 0.0
Epoch:   17        5 Batch loss: 0.120151 Batch F1: 0.0
Epoch:   17        6 Batch loss: 0.126196 Batch F1: 0.0
Epoch:   17        7 Batch loss: 0.091719 Batch F1: 0.0
Epoch:   17        8 Batch loss: 0.095208 Batch F1: 0.0
Epoch:   17        9 Batch loss: 0.110447 Batch F1: 0.0
Epoch:   17       10 Batch loss: 0.098346 Batch F1: 0.0
Epoch:   17       11 Batch loss: 0.148683 Batch F1: 0.0
Epoch:   17       12 Batch loss: 0.103863 Batch F1: 0.2857142857142857
Train Avg Loss   17: 0.115866

Train Avg F1   17: 0.023809523809523808

Val Avg Loss   17: 0.109111

Val Avg F1   17:  0.18333333333333332

Optimal Val loss (Epoch 17): 0.10911146178841591

Epoch 18
--------------------------------------------------------------
Epoch:   18        1 Batch loss: 0.105231 Batch F1: 0.0
Epoch:   18        2 Batch loss: 0.115089 Batch F1: 0.0
Epoch:   18        3 Batch loss: 0.113433 Batch F1: 0.0
Epoch:   18        4 Batch loss: 0.098621 Batch F1: 0.2222222222222222
Epoch:   18        5 Batch loss: 0.117973 Batch F1: 0.0
Epoch:   18        6 Batch loss: 0.125799 Batch F1: 0.0
Epoch:   18        7 Batch loss: 0.098238 Batch F1: 0.6
Epoch:   18        8 Batch loss: 0.097413 Batch F1: 0.2222222222222222
Epoch:   18        9 Batch loss: 0.124411 Batch F1: 0.0
Epoch:   18       10 Batch loss: 0.154941 Batch F1: 0.0
Epoch:   18       11 Batch loss: 0.108979 Batch F1: 0.0
Epoch:   18       12 Batch loss: 0.091403 Batch F1: 0.2857142857142857
Train Avg Loss   18: 0.112628

Train Avg F1   18: 0.11084656084656082

Val Avg Loss   18: 0.111457

Val Avg F1   18:  0.18452380952380953

Optimal Val loss (Epoch 17): 0.10911146178841591

Epoch 19
--------------------------------------------------------------
Epoch:   19        1 Batch loss: 0.114035 Batch F1: 0.0
Epoch:   19        2 Batch loss: 0.091163 Batch F1: 0.2857142857142857
Epoch:   19        3 Batch loss: 0.106285 Batch F1: 0.19999999999999998
Epoch:   19        4 Batch loss: 0.135183 Batch F1: 0.0
Epoch:   19        5 Batch loss: 0.083225 Batch F1: 0.0
Epoch:   19        6 Batch loss: 0.093942 Batch F1: 0.0
Epoch:   19        7 Batch loss: 0.072627 Batch F1: 0.2857142857142857
Epoch:   19        8 Batch loss: 0.077533 Batch F1: 0.2857142857142857
Epoch:   19        9 Batch loss: 0.157713 Batch F1: 0.25
Epoch:   19       10 Batch loss: 0.153408 Batch F1: 0.125
Epoch:   19       11 Batch loss: 0.139765 Batch F1: 0.37499999999999994
Epoch:   19       12 Batch loss: 0.085306 Batch F1: 0.4444444444444445
Train Avg Loss   19: 0.109182

Train Avg F1   19: 0.18763227513227512

Val Avg Loss   19: 0.104318

Val Avg F1   19:  0.20101010101010103

Optimal Val loss (Epoch 19): 0.10431751795113087

Epoch 20
--------------------------------------------------------------
Epoch:   20        1 Batch loss: 0.096891 Batch F1: 0.0
Epoch:   20        2 Batch loss: 0.121536 Batch F1: 0.0
Epoch:   20        3 Batch loss: 0.078097 Batch F1: 0.0
Epoch:   20        4 Batch loss: 0.104325 Batch F1: 0.0
Epoch:   20        5 Batch loss: 0.130689 Batch F1: 0.0
Epoch:   20        6 Batch loss: 0.105743 Batch F1: 0.2
Epoch:   20        7 Batch loss: 0.097659 Batch F1: 0.0
Epoch:   20        8 Batch loss: 0.100921 Batch F1: 0.0
Epoch:   20        9 Batch loss: 0.137233 Batch F1: 0.14285714285714288
Epoch:   20       10 Batch loss: 0.077454 Batch F1: 0.0
Epoch:   20       11 Batch loss: 0.086115 Batch F1: 0.6153846153846153
Epoch:   20       12 Batch loss: 0.141861 Batch F1: 0.2857142857142857
Train Avg Loss   20: 0.106544

Train Avg F1   20: 0.10366300366300367

Val Avg Loss   20: 0.113432

Val Avg F1   20:  0.5558608058608058

Optimal Val loss (Epoch 19): 0.10431751795113087

Epoch 21
--------------------------------------------------------------
Epoch:   21        1 Batch loss: 0.125988 Batch F1: 0.6363636363636365
Epoch:   21        2 Batch loss: 0.120610 Batch F1: 0.5714285714285714
Epoch:   21        3 Batch loss: 0.123528 Batch F1: 0.0
Epoch:   21        4 Batch loss: 0.078130 Batch F1: 0.0
Epoch:   21        5 Batch loss: 0.094879 Batch F1: 0.0
Epoch:   21        6 Batch loss: 0.111825 Batch F1: 0.0
Epoch:   21        7 Batch loss: 0.157534 Batch F1: 0.0
Epoch:   21        8 Batch loss: 0.067781 Batch F1: 0.0
Epoch:   21        9 Batch loss: 0.098459 Batch F1: 0.0
Epoch:   21       10 Batch loss: 0.098265 Batch F1: 0.2222222222222222
Epoch:   21       11 Batch loss: 0.142742 Batch F1: 0.14285714285714288
Epoch:   21       12 Batch loss: 0.114548 Batch F1: 0.36363636363636365
Train Avg Loss   21: 0.111191

Train Avg F1   21: 0.1613756613756614

Val Avg Loss   21: 0.107011

Val Avg F1   21:  0.19128787878787878

Optimal Val loss (Epoch 19): 0.10431751795113087

Epoch 22
--------------------------------------------------------------
Epoch:   22        1 Batch loss: 0.110814 Batch F1: 0.5
Epoch:   22        2 Batch loss: 0.101022 Batch F1: 0.5714285714285715
Epoch:   22        3 Batch loss: 0.101016 Batch F1: 0.0
Epoch:   22        4 Batch loss: 0.101000 Batch F1: 0.0
Epoch:   22        5 Batch loss: 0.115378 Batch F1: 0.0
Epoch:   22        6 Batch loss: 0.126726 Batch F1: 0.0
Epoch:   22        7 Batch loss: 0.120682 Batch F1: 0.4615384615384615
Epoch:   22        8 Batch loss: 0.092675 Batch F1: 0.5
Epoch:   22        9 Batch loss: 0.107778 Batch F1: 0.42857142857142855
Epoch:   22       10 Batch loss: 0.102426 Batch F1: 0.0
Epoch:   22       11 Batch loss: 0.131043 Batch F1: 0.0
Epoch:   22       12 Batch loss: 0.053638 Batch F1: 0.5
Train Avg Loss   22: 0.105350

Train Avg F1   22: 0.24679487179487178

Val Avg Loss   22: 0.104779

Val Avg F1   22:  0.0

Optimal Val loss (Epoch 19): 0.10431751795113087

Epoch 23
--------------------------------------------------------------
Epoch:   23        1 Batch loss: 0.102227 Batch F1: 0.0
Epoch:   23        2 Batch loss: 0.126302 Batch F1: 0.15384615384615385
Epoch:   23        3 Batch loss: 0.087278 Batch F1: 0.19999999999999998
Epoch:   23        4 Batch loss: 0.104267 Batch F1: 0.0
Epoch:   23        5 Batch loss: 0.083123 Batch F1: 0.4
Epoch:   23        6 Batch loss: 0.147531 Batch F1: 0.125
Epoch:   23        7 Batch loss: 0.106969 Batch F1: 0.3076923076923077
Epoch:   23        8 Batch loss: 0.099323 Batch F1: 0.19999999999999998
Epoch:   23        9 Batch loss: 0.107224 Batch F1: 0.19999999999999998
Epoch:   23       10 Batch loss: 0.092796 Batch F1: 0.2
Epoch:   23       11 Batch loss: 0.105064 Batch F1: 0.18181818181818182
Epoch:   23       12 Batch loss: 0.087777 Batch F1: 0.0
Train Avg Loss   23: 0.104157

Train Avg F1   23: 0.16402972027972026

Val Avg Loss   23: 0.100676

Val Avg F1   23:  0.03333333333333333

Optimal Val loss (Epoch 23): 0.10067574121057987

Epoch 24
--------------------------------------------------------------
Epoch:   24        1 Batch loss: 0.127623 Batch F1: 0.0
Epoch:   24        2 Batch loss: 0.111640 Batch F1: 0.16666666666666669
Epoch:   24        3 Batch loss: 0.115965 Batch F1: 0.35294117647058826
Epoch:   24        4 Batch loss: 0.123370 Batch F1: 0.5263157894736842
Epoch:   24        5 Batch loss: 0.114992 Batch F1: 0.46153846153846156
Epoch:   24        6 Batch loss: 0.093803 Batch F1: 0.3636363636363636
Epoch:   24        7 Batch loss: 0.073186 Batch F1: 0.0
Epoch:   24        8 Batch loss: 0.071101 Batch F1: 0.0
Epoch:   24        9 Batch loss: 0.106418 Batch F1: 0.0
Epoch:   24       10 Batch loss: 0.082901 Batch F1: 0.0
Epoch:   24       11 Batch loss: 0.134683 Batch F1: 0.0
Epoch:   24       12 Batch loss: 0.109240 Batch F1: 0.0
Train Avg Loss   24: 0.105410

Train Avg F1   24: 0.155924871482147

Val Avg Loss   24: 0.107395

Val Avg F1   24:  0.0

Optimal Val loss (Epoch 23): 0.10067574121057987

Epoch 25
--------------------------------------------------------------
Epoch:   25        1 Batch loss: 0.071813 Batch F1: 0.0
Epoch:   25        2 Batch loss: 0.075431 Batch F1: 0.0
Epoch:   25        3 Batch loss: 0.129424 Batch F1: 0.0
Epoch:   25        4 Batch loss: 0.083144 Batch F1: 0.0
Epoch:   25        5 Batch loss: 0.095933 Batch F1: 0.22222222222222224
Epoch:   25        6 Batch loss: 0.076967 Batch F1: 0.2857142857142857
Epoch:   25        7 Batch loss: 0.118584 Batch F1: 0.0
Epoch:   25        8 Batch loss: 0.134892 Batch F1: 0.0
Epoch:   25        9 Batch loss: 0.143623 Batch F1: 0.2222222222222222
Epoch:   25       10 Batch loss: 0.111879 Batch F1: 0.7058823529411764
Epoch:   25       11 Batch loss: 0.124268 Batch F1: 0.19999999999999998
Epoch:   25       12 Batch loss: 0.106678 Batch F1: 0.0
Train Avg Loss   25: 0.106053

Train Avg F1   25: 0.1363367569249922

Val Avg Loss   25: 0.099239

Val Avg F1   25:  0.03333333333333333

Optimal Val loss (Epoch 25): 0.09923921711742878

Epoch 26
--------------------------------------------------------------
Epoch:   26        1 Batch loss: 0.079229 Batch F1: 0.2857142857142857
Epoch:   26        2 Batch loss: 0.141563 Batch F1: 0.0
Epoch:   26        3 Batch loss: 0.093330 Batch F1: 0.0
Epoch:   26        4 Batch loss: 0.089366 Batch F1: 0.0
Epoch:   26        5 Batch loss: 0.113962 Batch F1: 0.0
Epoch:   26        6 Batch loss: 0.078602 Batch F1: 0.0
Epoch:   26        7 Batch loss: 0.111237 Batch F1: 0.16666666666666669
Epoch:   26        8 Batch loss: 0.090590 Batch F1: 0.5
Epoch:   26        9 Batch loss: 0.102797 Batch F1: 0.16666666666666669
Epoch:   26       10 Batch loss: 0.103020 Batch F1: 0.33333333333333337
Epoch:   26       11 Batch loss: 0.109946 Batch F1: 0.0
Epoch:   26       12 Batch loss: 0.115753 Batch F1: 0.0
Train Avg Loss   26: 0.102450

Train Avg F1   26: 0.12103174603174605

Val Avg Loss   26: 0.099783

Val Avg F1   26:  0.0

Optimal Val loss (Epoch 25): 0.09923921711742878

Epoch 27
--------------------------------------------------------------
Epoch:   27        1 Batch loss: 0.065329 Batch F1: 0.0
Epoch:   27        2 Batch loss: 0.111136 Batch F1: 0.0
Epoch:   27        3 Batch loss: 0.117624 Batch F1: 0.0
Epoch:   27        4 Batch loss: 0.133159 Batch F1: 0.0
Epoch:   27        5 Batch loss: 0.122346 Batch F1: 0.15384615384615385
Epoch:   27        6 Batch loss: 0.089589 Batch F1: 0.6
Epoch:   27        7 Batch loss: 0.118510 Batch F1: 0.6666666666666665
Epoch:   27        8 Batch loss: 0.088598 Batch F1: 0.2222222222222222
Epoch:   27        9 Batch loss: 0.087947 Batch F1: 0.0
Epoch:   27       10 Batch loss: 0.079358 Batch F1: 0.0
Epoch:   27       11 Batch loss: 0.116293 Batch F1: 0.0
Epoch:   27       12 Batch loss: 0.086408 Batch F1: 0.25
Train Avg Loss   27: 0.101358

Train Avg F1   27: 0.15772792022792023

Val Avg Loss   27: 0.097345

Val Avg F1   27:  0.0

Optimal Val loss (Epoch 27): 0.09734546951949596

Epoch 28
--------------------------------------------------------------
Epoch:   28        1 Batch loss: 0.120566 Batch F1: 0.0
Epoch:   28        2 Batch loss: 0.080085 Batch F1: 0.0
Epoch:   28        3 Batch loss: 0.115072 Batch F1: 0.2666666666666667
Epoch:   28        4 Batch loss: 0.101693 Batch F1: 0.7692307692307693
Epoch:   28        5 Batch loss: 0.093597 Batch F1: 0.4444444444444445
Epoch:   28        6 Batch loss: 0.053170 Batch F1: 0.5
Epoch:   28        7 Batch loss: 0.109379 Batch F1: 0.0
Epoch:   28        8 Batch loss: 0.199530 Batch F1: 0.0
Epoch:   28        9 Batch loss: 0.114180 Batch F1: 0.16666666666666669
Epoch:   28       10 Batch loss: 0.077875 Batch F1: 0.0
Epoch:   28       11 Batch loss: 0.085422 Batch F1: 0.5714285714285715
Epoch:   28       12 Batch loss: 0.139598 Batch F1: 0.4444444444444444
Train Avg Loss   28: 0.107514

Train Avg F1   28: 0.2635734635734636

Val Avg Loss   28: 0.099354

Val Avg F1   28:  0.1

Optimal Val loss (Epoch 27): 0.09734546951949596

Epoch 29
--------------------------------------------------------------
Epoch:   29        1 Batch loss: 0.127647 Batch F1: 0.14285714285714288
Epoch:   29        2 Batch loss: 0.082743 Batch F1: 0.0
Epoch:   29        3 Batch loss: 0.107002 Batch F1: 0.3076923076923077
Epoch:   29        4 Batch loss: 0.087405 Batch F1: 0.25
Epoch:   29        5 Batch loss: 0.091522 Batch F1: 0.36363636363636365
Epoch:   29        6 Batch loss: 0.111020 Batch F1: 0.19999999999999998
Epoch:   29        7 Batch loss: 0.107821 Batch F1: 0.0
Epoch:   29        8 Batch loss: 0.063338 Batch F1: 0.4
Epoch:   29        9 Batch loss: 0.081098 Batch F1: 0.0
Epoch:   29       10 Batch loss: 0.110062 Batch F1: 0.0
Epoch:   29       11 Batch loss: 0.115920 Batch F1: 0.375
Epoch:   29       12 Batch loss: 0.114084 Batch F1: 0.18181818181818182
Train Avg Loss   29: 0.099972

Train Avg F1   29: 0.18508366633366632

Val Avg Loss   29: 0.095777

Val Avg F1   29:  0.22601010101010102

Optimal Val loss (Epoch 29): 0.09577714279294014

Epoch 30
--------------------------------------------------------------
Epoch:   30        1 Batch loss: 0.085073 Batch F1: 0.25
Epoch:   30        2 Batch loss: 0.100584 Batch F1: 0.6153846153846153
Epoch:   30        3 Batch loss: 0.105201 Batch F1: 0.5882352941176471
Epoch:   30        4 Batch loss: 0.103872 Batch F1: 0.33333333333333337
Epoch:   30        5 Batch loss: 0.097912 Batch F1: 0.5
Epoch:   30        6 Batch loss: 0.110364 Batch F1: 0.375
Epoch:   30        7 Batch loss: 0.120622 Batch F1: 0.30769230769230765
Epoch:   30        8 Batch loss: 0.081647 Batch F1: 0.6153846153846153
Epoch:   30        9 Batch loss: 0.053576 Batch F1: 0.7499999999999999
Epoch:   30       10 Batch loss: 0.115455 Batch F1: 0.0
Epoch:   30       11 Batch loss: 0.085883 Batch F1: 0.0
Epoch:   30       12 Batch loss: 0.073209 Batch F1: 0.0
Train Avg Loss   30: 0.094450

Train Avg F1   30: 0.3612525138260432

Val Avg Loss   30: 0.103072

Val Avg F1   30:  0.0

Optimal Val loss (Epoch 29): 0.09577714279294014

Epoch 31
--------------------------------------------------------------
Epoch:   31        1 Batch loss: 0.063445 Batch F1: 0.0
Epoch:   31        2 Batch loss: 0.084550 Batch F1: 0.0
Epoch:   31        3 Batch loss: 0.145493 Batch F1: 0.0
Epoch:   31        4 Batch loss: 0.088393 Batch F1: 0.0
Epoch:   31        5 Batch loss: 0.119070 Batch F1: 0.0
Epoch:   31        6 Batch loss: 0.080220 Batch F1: 0.7272727272727273
Epoch:   31        7 Batch loss: 0.108017 Batch F1: 0.8235294117647058
Epoch:   31        8 Batch loss: 0.105852 Batch F1: 0.8
Epoch:   31        9 Batch loss: 0.095334 Batch F1: 0.0
Epoch:   31       10 Batch loss: 0.098839 Batch F1: 0.0
Epoch:   31       11 Batch loss: 0.122879 Batch F1: 0.0
Epoch:   31       12 Batch loss: 0.120197 Batch F1: 0.0
Train Avg Loss   31: 0.102691

Train Avg F1   31: 0.19590017825311942

Val Avg Loss   31: 0.095768

Val Avg F1   31:  0.0

Optimal Val loss (Epoch 31): 0.09576769731938839

Epoch 32
--------------------------------------------------------------
Epoch:   32        1 Batch loss: 0.068104 Batch F1: 0.0
Epoch:   32        2 Batch loss: 0.106542 Batch F1: 0.5
Epoch:   32        3 Batch loss: 0.100406 Batch F1: 0.5882352941176471
Epoch:   32        4 Batch loss: 0.100380 Batch F1: 0.42857142857142855
Epoch:   32        5 Batch loss: 0.095301 Batch F1: 0.4444444444444445
Epoch:   32        6 Batch loss: 0.104989 Batch F1: 0.16666666666666669
Epoch:   32        7 Batch loss: 0.080641 Batch F1: 0.0
Epoch:   32        8 Batch loss: 0.112149 Batch F1: 0.15384615384615385
Epoch:   32        9 Batch loss: 0.069678 Batch F1: 0.4444444444444445
Epoch:   32       10 Batch loss: 0.100513 Batch F1: 0.19999999999999998
Epoch:   32       11 Batch loss: 0.085636 Batch F1: 0.7692307692307693
Epoch:   32       12 Batch loss: 0.128333 Batch F1: 0.15384615384615385
Train Avg Loss   32: 0.096056

Train Avg F1   32: 0.320773779597309

Val Avg Loss   32: 0.091210

Val Avg F1   32:  0.2845238095238095

Optimal Val loss (Epoch 32): 0.0912100113928318

Epoch 33
--------------------------------------------------------------
Epoch:   33        1 Batch loss: 0.087799 Batch F1: 0.3636363636363636
Epoch:   33        2 Batch loss: 0.092631 Batch F1: 0.30769230769230765
Epoch:   33        3 Batch loss: 0.093204 Batch F1: 0.0
Epoch:   33        4 Batch loss: 0.094867 Batch F1: 0.19999999999999998
Epoch:   33        5 Batch loss: 0.106346 Batch F1: 0.16666666666666669
Epoch:   33        6 Batch loss: 0.066524 Batch F1: 0.2857142857142857
Epoch:   33        7 Batch loss: 0.099116 Batch F1: 0.19999999999999998
Epoch:   33        8 Batch loss: 0.095016 Batch F1: 0.5714285714285714
Epoch:   33        9 Batch loss: 0.106763 Batch F1: 0.0
Epoch:   33       10 Batch loss: 0.091474 Batch F1: 0.16666666666666669
Epoch:   33       11 Batch loss: 0.093457 Batch F1: 0.7999999999999999
Epoch:   33       12 Batch loss: 0.087808 Batch F1: 0.4
Train Avg Loss   33: 0.092917

Train Avg F1   33: 0.28848373848373843

Val Avg Loss   33: 0.087681

Val Avg F1   33:  0.0

Optimal Val loss (Epoch 33): 0.0876810010522604

Epoch 34
--------------------------------------------------------------
Epoch:   34        1 Batch loss: 0.084624 Batch F1: 0.2222222222222222
Epoch:   34        2 Batch loss: 0.102053 Batch F1: 0.0
Epoch:   34        3 Batch loss: 0.099634 Batch F1: 0.2857142857142857
Epoch:   34        4 Batch loss: 0.109223 Batch F1: 0.8571428571428571
Epoch:   34        5 Batch loss: 0.085794 Batch F1: 0.8333333333333333
Epoch:   34        6 Batch loss: 0.113502 Batch F1: 0.0
Epoch:   34        7 Batch loss: 0.090131 Batch F1: 0.2222222222222222
Epoch:   34        8 Batch loss: 0.056532 Batch F1: 0.0
Epoch:   34        9 Batch loss: 0.076907 Batch F1: 0.0
Epoch:   34       10 Batch loss: 0.105448 Batch F1: 0.18181818181818182
Epoch:   34       11 Batch loss: 0.096024 Batch F1: 0.18181818181818182
Epoch:   34       12 Batch loss: 0.113663 Batch F1: 0.16666666666666669
Train Avg Loss   34: 0.094461

Train Avg F1   34: 0.2459114959114959

Val Avg Loss   34: 0.109653

Val Avg F1   34:  0.7850934153565733

Optimal Val loss (Epoch 33): 0.0876810010522604

Epoch 35
--------------------------------------------------------------
Epoch:   35        1 Batch loss: 0.128114 Batch F1: 0.8000000000000002
Epoch:   35        2 Batch loss: 0.143160 Batch F1: 0.7058823529411764
Epoch:   35        3 Batch loss: 0.101615 Batch F1: 0.18181818181818182
Epoch:   35        4 Batch loss: 0.079362 Batch F1: 0.25
Epoch:   35        5 Batch loss: 0.123998 Batch F1: 0.18181818181818182
Epoch:   35        6 Batch loss: 0.160556 Batch F1: 0.0
Epoch:   35        7 Batch loss: 0.102318 Batch F1: 0.0
Epoch:   35        8 Batch loss: 0.074277 Batch F1: 0.0
Epoch:   35        9 Batch loss: 0.092434 Batch F1: 0.4
Epoch:   35       10 Batch loss: 0.065288 Batch F1: 0.0
Epoch:   35       11 Batch loss: 0.093930 Batch F1: 0.3333333333333333
Epoch:   35       12 Batch loss: 0.092618 Batch F1: 0.2222222222222222
Train Avg Loss   35: 0.104806

Train Avg F1   35: 0.2562561893444247

Val Avg Loss   35: 0.094496

Val Avg F1   35:  0.19128787878787878

Optimal Val loss (Epoch 33): 0.0876810010522604

Epoch 36
--------------------------------------------------------------
Epoch:   36        1 Batch loss: 0.097518 Batch F1: 0.18181818181818182
Epoch:   36        2 Batch loss: 0.089614 Batch F1: 0.4615384615384615
Epoch:   36        3 Batch loss: 0.086894 Batch F1: 0.6666666666666667
Epoch:   36        4 Batch loss: 0.085405 Batch F1: 0.5
Epoch:   36        5 Batch loss: 0.111873 Batch F1: 0.4
Epoch:   36        6 Batch loss: 0.135061 Batch F1: 0.14285714285714288
Epoch:   36        7 Batch loss: 0.066708 Batch F1: 0.0
Epoch:   36        8 Batch loss: 0.117309 Batch F1: 0.39999999999999997
Epoch:   36        9 Batch loss: 0.081361 Batch F1: 0.4
Epoch:   36       10 Batch loss: 0.086454 Batch F1: 0.0
Epoch:   36       11 Batch loss: 0.074281 Batch F1: 0.4444444444444445
Epoch:   36       12 Batch loss: 0.134678 Batch F1: 0.0
Train Avg Loss   36: 0.097263

Train Avg F1   36: 0.29977707477707477

Val Avg Loss   36: 0.093064

Val Avg F1   36:  0.0

Optimal Val loss (Epoch 33): 0.0876810010522604

Epoch 37
--------------------------------------------------------------
Epoch:   37        1 Batch loss: 0.092345 Batch F1: 0.0
Epoch:   37        2 Batch loss: 0.085473 Batch F1: 0.19999999999999998
Epoch:   37        3 Batch loss: 0.111408 Batch F1: 0.18181818181818182
Epoch:   37        4 Batch loss: 0.075872 Batch F1: 0.5
Epoch:   37        5 Batch loss: 0.088882 Batch F1: 0.5454545454545454
Epoch:   37        6 Batch loss: 0.088537 Batch F1: 0.7272727272727273
Epoch:   37        7 Batch loss: 0.125621 Batch F1: 0.0
Epoch:   37        8 Batch loss: 0.096530 Batch F1: 0.0
Epoch:   37        9 Batch loss: 0.099466 Batch F1: 0.16666666666666669
Epoch:   37       10 Batch loss: 0.091270 Batch F1: 0.0
Epoch:   37       11 Batch loss: 0.081377 Batch F1: 0.0
Epoch:   37       12 Batch loss: 0.086739 Batch F1: 0.0
Train Avg Loss   37: 0.093627

Train Avg F1   37: 0.1934343434343434

Val Avg Loss   37: 0.090825

Val Avg F1   37:  0.08712121212121213

Optimal Val loss (Epoch 33): 0.0876810010522604

Epoch 38
--------------------------------------------------------------
Epoch:   38        1 Batch loss: 0.097336 Batch F1: 0.18181818181818182
Epoch:   38        2 Batch loss: 0.093569 Batch F1: 0.3636363636363636
Epoch:   38        3 Batch loss: 0.098396 Batch F1: 0.5882352941176471
Epoch:   38        4 Batch loss: 0.086804 Batch F1: 0.5714285714285715
Epoch:   38        5 Batch loss: 0.117471 Batch F1: 0.375
Epoch:   38        6 Batch loss: 0.083768 Batch F1: 0.0
Epoch:   38        7 Batch loss: 0.103962 Batch F1: 0.0
Epoch:   38        8 Batch loss: 0.080985 Batch F1: 0.0
Epoch:   38        9 Batch loss: 0.095305 Batch F1: 0.16666666666666669
Epoch:   38       10 Batch loss: 0.078498 Batch F1: 0.5
Epoch:   38       11 Batch loss: 0.072528 Batch F1: 0.4
Epoch:   38       12 Batch loss: 0.093941 Batch F1: 0.0
Train Avg Loss   38: 0.091880

Train Avg F1   38: 0.26223208980561924

Val Avg Loss   38: 0.085681

Val Avg F1   38:  0.5011904761904762

Optimal Val loss (Epoch 38): 0.08568122982978821

Epoch 39
--------------------------------------------------------------
Epoch:   39        1 Batch loss: 0.075864 Batch F1: 0.0
Epoch:   39        2 Batch loss: 0.097592 Batch F1: 0.3636363636363636
Epoch:   39        3 Batch loss: 0.083209 Batch F1: 0.6
Epoch:   39        4 Batch loss: 0.075930 Batch F1: 0.5
Epoch:   39        5 Batch loss: 0.076903 Batch F1: 0.0
Epoch:   39        6 Batch loss: 0.113096 Batch F1: 0.15384615384615385
Epoch:   39        7 Batch loss: 0.092164 Batch F1: 0.3636363636363636
Epoch:   39        8 Batch loss: 0.094221 Batch F1: 0.5882352941176471
Epoch:   39        9 Batch loss: 0.087950 Batch F1: 0.7142857142857143
Epoch:   39       10 Batch loss: 0.063071 Batch F1: 0.6666666666666666
Epoch:   39       11 Batch loss: 0.120212 Batch F1: 0.5
Epoch:   39       12 Batch loss: 0.072342 Batch F1: 0.4444444444444445
Train Avg Loss   39: 0.087713

Train Avg F1   39: 0.4078959167194462

Val Avg Loss   39: 0.081044

Val Avg F1   39:  0.821584008097166

Optimal Val loss (Epoch 39): 0.08104449696838856

Epoch 40
--------------------------------------------------------------
Epoch:   40        1 Batch loss: 0.088285 Batch F1: 0.8421052631578948
Epoch:   40        2 Batch loss: 0.103941 Batch F1: 0.8181818181818181
Epoch:   40        3 Batch loss: 0.077611 Batch F1: 0.888888888888889
Epoch:   40        4 Batch loss: 0.072393 Batch F1: 0.888888888888889
Epoch:   40        5 Batch loss: 0.100791 Batch F1: 0.16666666666666669
Epoch:   40        6 Batch loss: 0.079685 Batch F1: 0.0
Epoch:   40        7 Batch loss: 0.111234 Batch F1: 0.0
Epoch:   40        8 Batch loss: 0.061620 Batch F1: 0.25
Epoch:   40        9 Batch loss: 0.069992 Batch F1: 0.25
Epoch:   40       10 Batch loss: 0.097082 Batch F1: 0.6666666666666666
Epoch:   40       11 Batch loss: 0.110217 Batch F1: 0.8
Epoch:   40       12 Batch loss: 0.078993 Batch F1: 1.0
Train Avg Loss   40: 0.087654

Train Avg F1   40: 0.5476165160375687

Val Avg Loss   40: 0.082882

Val Avg F1   40:  0.0

Optimal Val loss (Epoch 39): 0.08104449696838856

Epoch 41
--------------------------------------------------------------
Epoch:   41        1 Batch loss: 0.095528 Batch F1: 0.0
Epoch:   41        2 Batch loss: 0.054617 Batch F1: 0.0
Epoch:   41        3 Batch loss: 0.097050 Batch F1: 0.0
Epoch:   41        4 Batch loss: 0.121007 Batch F1: 0.0
Epoch:   41        5 Batch loss: 0.095213 Batch F1: 0.9
Epoch:   41        6 Batch loss: 0.112346 Batch F1: 0.761904761904762
Epoch:   41        7 Batch loss: 0.084245 Batch F1: 1.0
Epoch:   41        8 Batch loss: 0.084671 Batch F1: 0.888888888888889
Epoch:   41        9 Batch loss: 0.103192 Batch F1: 0.0
Epoch:   41       10 Batch loss: 0.089211 Batch F1: 0.18181818181818182
Epoch:   41       11 Batch loss: 0.065212 Batch F1: 0.0
Epoch:   41       12 Batch loss: 0.075717 Batch F1: 0.0
Train Avg Loss   41: 0.089834

Train Avg F1   41: 0.3110509860509861

Val Avg Loss   41: 0.077514

Val Avg F1   41:  0.6187229437229437

Optimal Val loss (Epoch 41): 0.07751404494047165

Epoch 42
--------------------------------------------------------------
Epoch:   42        1 Batch loss: 0.099659 Batch F1: 0.5882352941176471
Epoch:   42        2 Batch loss: 0.096847 Batch F1: 0.5
Epoch:   42        3 Batch loss: 0.083591 Batch F1: 0.8571428571428571
Epoch:   42        4 Batch loss: 0.070959 Batch F1: 0.6
Epoch:   42        5 Batch loss: 0.064473 Batch F1: 0.7272727272727273
Epoch:   42        6 Batch loss: 0.060446 Batch F1: 0.0
Epoch:   42        7 Batch loss: 0.083243 Batch F1: 0.0
Epoch:   42        8 Batch loss: 0.113335 Batch F1: 0.0
Epoch:   42        9 Batch loss: 0.117412 Batch F1: 0.0
Epoch:   42       10 Batch loss: 0.082004 Batch F1: 0.6666666666666666
Epoch:   42       11 Batch loss: 0.069414 Batch F1: 1.0
Epoch:   42       12 Batch loss: 0.072249 Batch F1: 0.923076923076923
Train Avg Loss   42: 0.084469

Train Avg F1   42: 0.4885328723564018

Val Avg Loss   42: 0.079167

Val Avg F1   42:  0.9244949494949495

Optimal Val loss (Epoch 41): 0.07751404494047165

Epoch 43
--------------------------------------------------------------
Epoch:   43        1 Batch loss: 0.091979 Batch F1: 0.9
Epoch:   43        2 Batch loss: 0.068965 Batch F1: 0.7499999999999999
Epoch:   43        3 Batch loss: 0.069482 Batch F1: 0.0
Epoch:   43        4 Batch loss: 0.101383 Batch F1: 0.2666666666666667
Epoch:   43        5 Batch loss: 0.101385 Batch F1: 0.0
Epoch:   43        6 Batch loss: 0.065850 Batch F1: 0.0
Epoch:   43        7 Batch loss: 0.096021 Batch F1: 0.631578947368421
Epoch:   43        8 Batch loss: 0.108406 Batch F1: 0.7826086956521738
Epoch:   43        9 Batch loss: 0.094663 Batch F1: 0.8750000000000001
Epoch:   43       10 Batch loss: 0.066127 Batch F1: 0.7272727272727273
Epoch:   43       11 Batch loss: 0.105311 Batch F1: 0.0
Epoch:   43       12 Batch loss: 0.070578 Batch F1: 0.0
Train Avg Loss   43: 0.086679

Train Avg F1   43: 0.4110939197466657

Val Avg Loss   43: 0.104812

Val Avg F1   43:  0.0

Optimal Val loss (Epoch 41): 0.07751404494047165

Epoch 44
--------------------------------------------------------------
Epoch:   44        1 Batch loss: 0.101181 Batch F1: 0.0
Epoch:   44        2 Batch loss: 0.100362 Batch F1: 0.0
Epoch:   44        3 Batch loss: 0.067131 Batch F1: 0.0
Epoch:   44        4 Batch loss: 0.076976 Batch F1: 0.8750000000000001
Epoch:   44        5 Batch loss: 0.097713 Batch F1: 0.5
Epoch:   44        6 Batch loss: 0.075262 Batch F1: 0.6
Epoch:   44        7 Batch loss: 0.078985 Batch F1: 0.625
Epoch:   44        8 Batch loss: 0.084945 Batch F1: 0.5
Epoch:   44        9 Batch loss: 0.099381 Batch F1: 0.888888888888889
Epoch:   44       10 Batch loss: 0.091713 Batch F1: 0.18181818181818182
Epoch:   44       11 Batch loss: 0.105141 Batch F1: 0.16666666666666669
Epoch:   44       12 Batch loss: 0.098248 Batch F1: 0.2222222222222222
Train Avg Loss   44: 0.089753

Train Avg F1   44: 0.37996632996633

Val Avg Loss   44: 0.082721

Val Avg F1   44:  0.48420329670329665

Optimal Val loss (Epoch 41): 0.07751404494047165

Epoch 45
--------------------------------------------------------------
Epoch:   45        1 Batch loss: 0.091430 Batch F1: 0.6666666666666666
Epoch:   45        2 Batch loss: 0.068345 Batch F1: 0.8
Epoch:   45        3 Batch loss: 0.059250 Batch F1: 0.7499999999999999
Epoch:   45        4 Batch loss: 0.068089 Batch F1: 0.0
Epoch:   45        5 Batch loss: 0.080123 Batch F1: 0.2222222222222222
Epoch:   45        6 Batch loss: 0.099203 Batch F1: 0.0
Epoch:   45        7 Batch loss: 0.098678 Batch F1: 0.5263157894736842
Epoch:   45        8 Batch loss: 0.077502 Batch F1: 0.7777777777777777
Epoch:   45        9 Batch loss: 0.091947 Batch F1: 0.5333333333333333
Epoch:   45       10 Batch loss: 0.105692 Batch F1: 0.5
Epoch:   45       11 Batch loss: 0.102592 Batch F1: 0.15384615384615385
Epoch:   45       12 Batch loss: 0.109210 Batch F1: 0.0
Train Avg Loss   45: 0.087672

Train Avg F1   45: 0.4108468286099865

Val Avg Loss   45: 0.081217

Val Avg F1   45:  0.0

Optimal Val loss (Epoch 41): 0.07751404494047165

Epoch 46
--------------------------------------------------------------
Epoch:   46        1 Batch loss: 0.111005 Batch F1: 0.0
Epoch:   46        2 Batch loss: 0.071022 Batch F1: 0.33333333333333337
Epoch:   46        3 Batch loss: 0.087986 Batch F1: 0.6153846153846153
Epoch:   46        4 Batch loss: 0.110877 Batch F1: 0.5263157894736842
Epoch:   46        5 Batch loss: 0.085902 Batch F1: 0.3636363636363636
Epoch:   46        6 Batch loss: 0.098826 Batch F1: 0.4
Epoch:   46        7 Batch loss: 0.070924 Batch F1: 0.7142857142857143
Epoch:   46        8 Batch loss: 0.070859 Batch F1: 0.7272727272727273
Epoch:   46        9 Batch loss: 0.062687 Batch F1: 0.6666666666666666
Epoch:   46       10 Batch loss: 0.057511 Batch F1: 0.0
Epoch:   46       11 Batch loss: 0.078655 Batch F1: 0.2222222222222222
Epoch:   46       12 Batch loss: 0.100867 Batch F1: 0.5333333333333333
Train Avg Loss   46: 0.083927

Train Avg F1   46: 0.4252042304673884

Val Avg Loss   46: 0.081650

Val Avg F1   46:  0.6277777777777778

Optimal Val loss (Epoch 41): 0.07751404494047165

Epoch 47
--------------------------------------------------------------
Epoch:   47        1 Batch loss: 0.095899 Batch F1: 0.4444444444444445
Epoch:   47        2 Batch loss: 0.071483 Batch F1: 0.8181818181818181
Epoch:   47        3 Batch loss: 0.086412 Batch F1: 0.6666666666666666
Epoch:   47        4 Batch loss: 0.058486 Batch F1: 0.6
Epoch:   47        5 Batch loss: 0.085013 Batch F1: 0.42857142857142855
Epoch:   47        6 Batch loss: 0.069110 Batch F1: 0.4444444444444445
Epoch:   47        7 Batch loss: 0.073070 Batch F1: 0.5
Epoch:   47        8 Batch loss: 0.072827 Batch F1: 0.7499999999999999
Epoch:   47        9 Batch loss: 0.118122 Batch F1: 0.6666666666666666
Epoch:   47       10 Batch loss: 0.089874 Batch F1: 0.8571428571428571
Epoch:   47       11 Batch loss: 0.077505 Batch F1: 0.8571428571428571
Epoch:   47       12 Batch loss: 0.087037 Batch F1: 0.5454545454545454
Train Avg Loss   47: 0.082070

Train Avg F1   47: 0.631559644059644

Val Avg Loss   47: 0.078372

Val Avg F1   47:  0.0

Optimal Val loss (Epoch 41): 0.07751404494047165

Epoch 48
--------------------------------------------------------------
Epoch:   48        1 Batch loss: 0.062409 Batch F1: 0.0
Epoch:   48        2 Batch loss: 0.094033 Batch F1: 0.0
Epoch:   48        3 Batch loss: 0.104448 Batch F1: 0.0
Epoch:   48        4 Batch loss: 0.083173 Batch F1: 0.5
Epoch:   48        5 Batch loss: 0.088567 Batch F1: 0.4615384615384615
Epoch:   48        6 Batch loss: 0.094491 Batch F1: 0.888888888888889
Epoch:   48        7 Batch loss: 0.058776 Batch F1: 1.0
Epoch:   48        8 Batch loss: 0.083280 Batch F1: 0.8695652173913044
Epoch:   48        9 Batch loss: 0.086808 Batch F1: 0.6153846153846153
Epoch:   48       10 Batch loss: 0.075488 Batch F1: 0.6666666666666666
Epoch:   48       11 Batch loss: 0.059762 Batch F1: 0.6666666666666666
Epoch:   48       12 Batch loss: 0.077528 Batch F1: 0.0
Train Avg Loss   48: 0.080730

Train Avg F1   48: 0.47239254304471695

Val Avg Loss   48: 0.074735

Val Avg F1   48:  0.5781799899446959

Optimal Val loss (Epoch 48): 0.0747350137680769

Epoch 49
--------------------------------------------------------------
Epoch:   49        1 Batch loss: 0.067869 Batch F1: 0.8235294117647058
Epoch:   49        2 Batch loss: 0.077792 Batch F1: 0.888888888888889
Epoch:   49        3 Batch loss: 0.090286 Batch F1: 0.8235294117647058
Epoch:   49        4 Batch loss: 0.100287 Batch F1: 0.7692307692307693
Epoch:   49        5 Batch loss: 0.082520 Batch F1: 0.8695652173913044
Epoch:   49        6 Batch loss: 0.065184 Batch F1: 0.888888888888889
Epoch:   49        7 Batch loss: 0.087688 Batch F1: 0.7777777777777778
Epoch:   49        8 Batch loss: 0.075915 Batch F1: 0.4
Epoch:   49        9 Batch loss: 0.051222 Batch F1: 0.6
Epoch:   49       10 Batch loss: 0.090078 Batch F1: 0.4615384615384615
Epoch:   49       11 Batch loss: 0.059848 Batch F1: 0.33333333333333337
Epoch:   49       12 Batch loss: 0.077048 Batch F1: 0.0
Train Avg Loss   49: 0.077145

Train Avg F1   49: 0.636356846714903

Val Avg Loss   49: 0.081235

Val Avg F1   49:  0.0

Optimal Val loss (Epoch 48): 0.0747350137680769

Epoch 50
--------------------------------------------------------------
Epoch:   50        1 Batch loss: 0.091052 Batch F1: 0.0
Epoch:   50        2 Batch loss: 0.066853 Batch F1: 0.4444444444444445
Epoch:   50        3 Batch loss: 0.079755 Batch F1: 0.4
Epoch:   50        4 Batch loss: 0.066527 Batch F1: 0.7142857142857143
Epoch:   50        5 Batch loss: 0.074924 Batch F1: 0.5714285714285715
Epoch:   50        6 Batch loss: 0.061779 Batch F1: 0.9411764705882353
Epoch:   50        7 Batch loss: 0.095065 Batch F1: 0.9166666666666666
Epoch:   50        8 Batch loss: 0.077004 Batch F1: 0.8235294117647058
Epoch:   50        9 Batch loss: 0.076302 Batch F1: 0.9473684210526316
Epoch:   50       10 Batch loss: 0.072149 Batch F1: 0.7692307692307693
Epoch:   50       11 Batch loss: 0.072827 Batch F1: 0.0
Epoch:   50       12 Batch loss: 0.072458 Batch F1: 0.25
Train Avg Loss   50: 0.075558

Train Avg F1   50: 0.5648442057884783

Val Avg Loss   50: 0.076786

Val Avg F1   50:  0.14285714285714285

Optimal Val loss (Epoch 48): 0.0747350137680769

Epoch 51
--------------------------------------------------------------
Epoch:   51        1 Batch loss: 0.062857 Batch F1: 0.0
Epoch:   51        2 Batch loss: 0.070995 Batch F1: 0.5454545454545454
Epoch:   51        3 Batch loss: 0.071211 Batch F1: 0.5454545454545454
Epoch:   51        4 Batch loss: 0.082523 Batch F1: 0.6153846153846153
Epoch:   51        5 Batch loss: 0.091524 Batch F1: 0.3333333333333333
Epoch:   51        6 Batch loss: 0.081260 Batch F1: 0.19999999999999998
Epoch:   51        7 Batch loss: 0.056979 Batch F1: 0.2857142857142857
Epoch:   51        8 Batch loss: 0.108455 Batch F1: 0.6
Epoch:   51        9 Batch loss: 0.077029 Batch F1: 1.0
Epoch:   51       10 Batch loss: 0.089324 Batch F1: 0.8
Epoch:   51       11 Batch loss: 0.090701 Batch F1: 0.0
Epoch:   51       12 Batch loss: 0.069120 Batch F1: 0.6
Train Avg Loss   51: 0.079331

Train Avg F1   51: 0.46044511044511044

Val Avg Loss   51: 0.073354

Val Avg F1   51:  0.5670995670995671

Optimal Val loss (Epoch 51): 0.07335433550179005

Epoch 52
--------------------------------------------------------------
Epoch:   52        1 Batch loss: 0.112720 Batch F1: 0.4444444444444445
Epoch:   52        2 Batch loss: 0.075949 Batch F1: 0.8
Epoch:   52        3 Batch loss: 0.089384 Batch F1: 0.8750000000000001
Epoch:   52        4 Batch loss: 0.084006 Batch F1: 0.9523809523809523
Epoch:   52        5 Batch loss: 0.071935 Batch F1: 0.8571428571428571
Epoch:   52        6 Batch loss: 0.082536 Batch F1: 0.5
Epoch:   52        7 Batch loss: 0.057138 Batch F1: 0.33333333333333337
Epoch:   52        8 Batch loss: 0.083710 Batch F1: 0.5714285714285715
Epoch:   52        9 Batch loss: 0.065543 Batch F1: 0.4444444444444445
Epoch:   52       10 Batch loss: 0.090784 Batch F1: 0.42857142857142855
Epoch:   52       11 Batch loss: 0.049721 Batch F1: 0.8
Epoch:   52       12 Batch loss: 0.066068 Batch F1: 0.5714285714285715
Train Avg Loss   52: 0.077458

Train Avg F1   52: 0.6315145502645502

Val Avg Loss   52: 0.070050

Val Avg F1   52:  0.8001685814185814

Optimal Val loss (Epoch 52): 0.07005035690963268

Epoch 53
--------------------------------------------------------------
Epoch:   53        1 Batch loss: 0.091959 Batch F1: 0.6666666666666666
Epoch:   53        2 Batch loss: 0.076633 Batch F1: 0.9166666666666666
Epoch:   53        3 Batch loss: 0.074756 Batch F1: 1.0
Epoch:   53        4 Batch loss: 0.082526 Batch F1: 0.7499999999999999
Epoch:   53        5 Batch loss: 0.055267 Batch F1: 0.5
Epoch:   53        6 Batch loss: 0.058706 Batch F1: 0.0
Epoch:   53        7 Batch loss: 0.084826 Batch F1: 0.0
Epoch:   53        8 Batch loss: 0.078328 Batch F1: 0.33333333333333337
Epoch:   53        9 Batch loss: 0.077630 Batch F1: 0.8750000000000001
Epoch:   53       10 Batch loss: 0.067590 Batch F1: 0.9411764705882353
Epoch:   53       11 Batch loss: 0.090528 Batch F1: 0.8571428571428571
Epoch:   53       12 Batch loss: 0.074362 Batch F1: 0.9333333333333333
Train Avg Loss   53: 0.076093

Train Avg F1   53: 0.6477766106442576

Val Avg Loss   53: 0.069245

Val Avg F1   53:  0.7044400452488688

Optimal Val loss (Epoch 53): 0.06924484670162201

Epoch 54
--------------------------------------------------------------
Epoch:   54        1 Batch loss: 0.072234 Batch F1: 0.6666666666666666
Epoch:   54        2 Batch loss: 0.059748 Batch F1: 0.0
Epoch:   54        3 Batch loss: 0.111534 Batch F1: 0.0
Epoch:   54        4 Batch loss: 0.065001 Batch F1: 0.2222222222222222
Epoch:   54        5 Batch loss: 0.095647 Batch F1: 0.625
Epoch:   54        6 Batch loss: 0.093075 Batch F1: 0.7368421052631579
Epoch:   54        7 Batch loss: 0.074376 Batch F1: 0.9523809523809523
Epoch:   54        8 Batch loss: 0.069307 Batch F1: 0.7058823529411764
Epoch:   54        9 Batch loss: 0.065127 Batch F1: 0.6
Epoch:   54       10 Batch loss: 0.053380 Batch F1: 0.5714285714285715
Epoch:   54       11 Batch loss: 0.086056 Batch F1: 0.33333333333333337
Epoch:   54       12 Batch loss: 0.056484 Batch F1: 0.5
Train Avg Loss   54: 0.075164

Train Avg F1   54: 0.49281301701967334

Val Avg Loss   54: 0.075012

Val Avg F1   54:  0.5244588744588744

Optimal Val loss (Epoch 53): 0.06924484670162201

Epoch 55
--------------------------------------------------------------
Epoch:   55        1 Batch loss: 0.042868 Batch F1: 0.6666666666666666
Epoch:   55        2 Batch loss: 0.061731 Batch F1: 0.0
Epoch:   55        3 Batch loss: 0.103233 Batch F1: 0.0
Epoch:   55        4 Batch loss: 0.065455 Batch F1: 0.9333333333333333
Epoch:   55        5 Batch loss: 0.092511 Batch F1: 0.6666666666666666
Epoch:   55        6 Batch loss: 0.072719 Batch F1: 0.9523809523809523
Epoch:   55        7 Batch loss: 0.076906 Batch F1: 0.5882352941176471
Epoch:   55        8 Batch loss: 0.064488 Batch F1: 0.5
Epoch:   55        9 Batch loss: 0.077679 Batch F1: 0.7058823529411764
Epoch:   55       10 Batch loss: 0.098236 Batch F1: 0.42857142857142855
Epoch:   55       11 Batch loss: 0.084271 Batch F1: 0.625
Epoch:   55       12 Batch loss: 0.070655 Batch F1: 0.6666666666666666
Train Avg Loss   55: 0.075896

Train Avg F1   55: 0.5611169467787116

Val Avg Loss   55: 0.072721

Val Avg F1   55:  0.9280185758513932

Optimal Val loss (Epoch 53): 0.06924484670162201

Epoch 56
--------------------------------------------------------------
Epoch:   56        1 Batch loss: 0.077882 Batch F1: 0.9523809523809523
Epoch:   56        2 Batch loss: 0.096884 Batch F1: 0.88
Epoch:   56        3 Batch loss: 0.091369 Batch F1: 0.7142857142857143
Epoch:   56        4 Batch loss: 0.079288 Batch F1: 0.9
Epoch:   56        5 Batch loss: 0.080032 Batch F1: 0.4444444444444445
Epoch:   56        6 Batch loss: 0.080529 Batch F1: 0.0
Epoch:   56        7 Batch loss: 0.070578 Batch F1: 0.0
Epoch:   56        8 Batch loss: 0.081141 Batch F1: 0.4615384615384615
Epoch:   56        9 Batch loss: 0.074201 Batch F1: 1.0
Epoch:   56       10 Batch loss: 0.065322 Batch F1: 1.0
Epoch:   56       11 Batch loss: 0.068005 Batch F1: 1.0
Epoch:   56       12 Batch loss: 0.046126 Batch F1: 1.0
Train Avg Loss   56: 0.075946

Train Avg F1   56: 0.6960541310541309

Val Avg Loss   56: 0.077758

Val Avg F1   56:  0.3903769841269841

Optimal Val loss (Epoch 53): 0.06924484670162201

Epoch 57
--------------------------------------------------------------
Epoch:   57        1 Batch loss: 0.036437 Batch F1: 0.6666666666666666
Epoch:   57        2 Batch loss: 0.081359 Batch F1: 0.0
Epoch:   57        3 Batch loss: 0.115430 Batch F1: 0.0
Epoch:   57        4 Batch loss: 0.059061 Batch F1: 0.5
Epoch:   57        5 Batch loss: 0.073461 Batch F1: 0.6666666666666666
Epoch:   57        6 Batch loss: 0.102147 Batch F1: 0.5555555555555556
Epoch:   57        7 Batch loss: 0.066624 Batch F1: 0.6666666666666666
Epoch:   57        8 Batch loss: 0.086329 Batch F1: 0.42857142857142855
Epoch:   57        9 Batch loss: 0.086815 Batch F1: 0.4615384615384615
Epoch:   57       10 Batch loss: 0.127172 Batch F1: 0.5
Epoch:   57       11 Batch loss: 0.061467 Batch F1: 1.0
Epoch:   57       12 Batch loss: 0.086995 Batch F1: 0.7999999999999999
Train Avg Loss   57: 0.081941

Train Avg F1   57: 0.5204721204721204

Val Avg Loss   57: 0.068623

Val Avg F1   57:  0.9195906432748538

Optimal Val loss (Epoch 57): 0.06862303148955107

Epoch 58
--------------------------------------------------------------
Epoch:   58        1 Batch loss: 0.074595 Batch F1: 0.8235294117647058
Epoch:   58        2 Batch loss: 0.086985 Batch F1: 0.5714285714285715
Epoch:   58        3 Batch loss: 0.055556 Batch F1: 0.2857142857142857
Epoch:   58        4 Batch loss: 0.082365 Batch F1: 0.5714285714285715
Epoch:   58        5 Batch loss: 0.102106 Batch F1: 0.4444444444444445
Epoch:   58        6 Batch loss: 0.080921 Batch F1: 0.8571428571428571
Epoch:   58        7 Batch loss: 0.150587 Batch F1: 0.47619047619047616
Epoch:   58        8 Batch loss: 0.085908 Batch F1: 0.7499999999999999
Epoch:   58        9 Batch loss: 0.074068 Batch F1: 0.0
Epoch:   58       10 Batch loss: 0.069913 Batch F1: 0.0
Epoch:   58       11 Batch loss: 0.138951 Batch F1: 0.0
Epoch:   58       12 Batch loss: 0.115729 Batch F1: 0.0
Train Avg Loss   58: 0.093140

Train Avg F1   58: 0.39832321817615934

Val Avg Loss   58: 0.086985

Val Avg F1   58:  0.0

Optimal Val loss (Epoch 57): 0.06862303148955107

Epoch 59
--------------------------------------------------------------
Epoch:   59        1 Batch loss: 0.073835 Batch F1: 0.0
Epoch:   59        2 Batch loss: 0.067642 Batch F1: 0.0
Epoch:   59        3 Batch loss: 0.106911 Batch F1: 0.8
Epoch:   59        4 Batch loss: 0.071483 Batch F1: 0.5
Epoch:   59        5 Batch loss: 0.080124 Batch F1: 0.0
Epoch:   59        6 Batch loss: 0.090991 Batch F1: 0.4
Epoch:   59        7 Batch loss: 0.075865 Batch F1: 0.8571428571428571
Epoch:   59        8 Batch loss: 0.112370 Batch F1: 0.7777777777777778
Epoch:   59        9 Batch loss: 0.065639 Batch F1: 0.6666666666666666
Epoch:   59       10 Batch loss: 0.117215 Batch F1: 0.16666666666666669
Epoch:   59       11 Batch loss: 0.061822 Batch F1: 0.0
Epoch:   59       12 Batch loss: 0.114684 Batch F1: 0.0
Train Avg Loss   59: 0.086548

Train Avg F1   59: 0.34735449735449736

Val Avg Loss   59: 0.085281

Val Avg F1   59:  0.17243867243867245

Optimal Val loss (Epoch 57): 0.06862303148955107

Epoch 60
--------------------------------------------------------------
Epoch:   60        1 Batch loss: 0.078624 Batch F1: 0.19999999999999998
Epoch:   60        2 Batch loss: 0.076630 Batch F1: 0.5
Epoch:   60        3 Batch loss: 0.065800 Batch F1: 1.0
Epoch:   60        4 Batch loss: 0.115761 Batch F1: 0.7586206896551724
Epoch:   60        5 Batch loss: 0.071318 Batch F1: 0.7272727272727273
Epoch:   60        6 Batch loss: 0.081348 Batch F1: 0.8235294117647058
Epoch:   60        7 Batch loss: 0.089221 Batch F1: 0.5333333333333333
Epoch:   60        8 Batch loss: 0.085703 Batch F1: 0.4
Epoch:   60        9 Batch loss: 0.055636 Batch F1: 0.7499999999999999
Epoch:   60       10 Batch loss: 0.098660 Batch F1: 0.5
Epoch:   60       11 Batch loss: 0.082860 Batch F1: 0.7499999999999999
Epoch:   60       12 Batch loss: 0.079846 Batch F1: 0.2857142857142857
Train Avg Loss   60: 0.081784

Train Avg F1   60: 0.6023725373116854

Val Avg Loss   60: 0.074410

Val Avg F1   60:  0.5425420168067226

Optimal Val loss (Epoch 57): 0.06862303148955107

Epoch 61
--------------------------------------------------------------
Epoch:   61        1 Batch loss: 0.064603 Batch F1: 0.6666666666666666
Epoch:   61        2 Batch loss: 0.059070 Batch F1: 0.5714285714285715
Epoch:   61        3 Batch loss: 0.074699 Batch F1: 0.5454545454545454
Epoch:   61        4 Batch loss: 0.072470 Batch F1: 0.6666666666666666
Epoch:   61        5 Batch loss: 0.063667 Batch F1: 0.5454545454545454
Epoch:   61        6 Batch loss: 0.076359 Batch F1: 0.5
Epoch:   61        7 Batch loss: 0.076683 Batch F1: 0.6666666666666666
Epoch:   61        8 Batch loss: 0.098330 Batch F1: 0.5
Epoch:   61        9 Batch loss: 0.071796 Batch F1: 0.6666666666666666
Epoch:   61       10 Batch loss: 0.094032 Batch F1: 0.8333333333333333
Epoch:   61       11 Batch loss: 0.080987 Batch F1: 0.7777777777777778
Epoch:   61       12 Batch loss: 0.103840 Batch F1: 0.823529411764706
Train Avg Loss   61: 0.078045

Train Avg F1   61: 0.6469704043233454

Val Avg Loss   61: 0.075841

Val Avg F1   61:  0.9152303836514364

Optimal Val loss (Epoch 57): 0.06862303148955107

Epoch 62
--------------------------------------------------------------
Epoch:   62        1 Batch loss: 0.083467 Batch F1: 0.888888888888889
Epoch:   62        2 Batch loss: 0.065215 Batch F1: 0.5
Epoch:   62        3 Batch loss: 0.103840 Batch F1: 0.14285714285714288
Epoch:   62        4 Batch loss: 0.061824 Batch F1: 0.0
Epoch:   62        5 Batch loss: 0.052951 Batch F1: 0.0
Epoch:   62        6 Batch loss: 0.080092 Batch F1: 0.0
Epoch:   62        7 Batch loss: 0.090868 Batch F1: 0.16666666666666669
Epoch:   62        8 Batch loss: 0.085699 Batch F1: 0.9473684210526316
Epoch:   62        9 Batch loss: 0.081136 Batch F1: 0.9523809523809523
Epoch:   62       10 Batch loss: 0.067772 Batch F1: 1.0
Epoch:   62       11 Batch loss: 0.079473 Batch F1: 0.9523809523809523
Epoch:   62       12 Batch loss: 0.092722 Batch F1: 0.2222222222222222
Train Avg Loss   62: 0.078755

Train Avg F1   62: 0.48106377053745475

Val Avg Loss   62: 0.073397

Val Avg F1   62:  0.567857142857143

Optimal Val loss (Epoch 57): 0.06862303148955107

Epoch 63
--------------------------------------------------------------
Epoch:   63        1 Batch loss: 0.065385 Batch F1: 0.4444444444444445
Epoch:   63        2 Batch loss: 0.109180 Batch F1: 0.5714285714285715
Epoch:   63        3 Batch loss: 0.093970 Batch F1: 0.6666666666666666
Epoch:   63        4 Batch loss: 0.071846 Batch F1: 0.8571428571428571
Epoch:   63        5 Batch loss: 0.079490 Batch F1: 0.8750000000000001
Epoch:   63        6 Batch loss: 0.071905 Batch F1: 0.888888888888889
Epoch:   63        7 Batch loss: 0.055726 Batch F1: 0.5714285714285715
Epoch:   63        8 Batch loss: 0.070764 Batch F1: 0.4
Epoch:   63        9 Batch loss: 0.100548 Batch F1: 0.33333333333333337
Epoch:   63       10 Batch loss: 0.082898 Batch F1: 0.33333333333333337
Epoch:   63       11 Batch loss: 0.072435 Batch F1: 0.4444444444444445
Epoch:   63       12 Batch loss: 0.060903 Batch F1: 0.6666666666666666
Train Avg Loss   63: 0.077921

Train Avg F1   63: 0.5877314814814815

Val Avg Loss   63: 0.072584

Val Avg F1   63:  0.5968253968253968

Optimal Val loss (Epoch 57): 0.06862303148955107

Epoch 64
--------------------------------------------------------------
Epoch:   64        1 Batch loss: 0.055395 Batch F1: 0.5714285714285715
Epoch:   64        2 Batch loss: 0.088768 Batch F1: 0.6666666666666666
Epoch:   64        3 Batch loss: 0.088059 Batch F1: 0.7058823529411764
Epoch:   64        4 Batch loss: 0.071103 Batch F1: 0.9333333333333333
Epoch:   64        5 Batch loss: 0.113233 Batch F1: 0.8666666666666666
Epoch:   64        6 Batch loss: 0.072990 Batch F1: 1.0
Epoch:   64        7 Batch loss: 0.066696 Batch F1: 0.8
Epoch:   64        8 Batch loss: 0.051492 Batch F1: 0.888888888888889
Epoch:   64        9 Batch loss: 0.115286 Batch F1: 0.4210526315789474
Epoch:   64       10 Batch loss: 0.046896 Batch F1: 0.8
Epoch:   64       11 Batch loss: 0.070197 Batch F1: 0.6666666666666666
Epoch:   64       12 Batch loss: 0.079590 Batch F1: 0.9333333333333333
Train Avg Loss   64: 0.076642

Train Avg F1   64: 0.7711599259586875

Val Avg Loss   64: 0.070264

Val Avg F1   64:  0.8240079365079366

Optimal Val loss (Epoch 57): 0.06862303148955107

Epoch 65
--------------------------------------------------------------
Epoch:   65        1 Batch loss: 0.077989 Batch F1: 0.875
Epoch:   65        2 Batch loss: 0.073514 Batch F1: 0.7142857142857143
Epoch:   65        3 Batch loss: 0.119066 Batch F1: 0.35294117647058826
Epoch:   65        4 Batch loss: 0.065277 Batch F1: 0.7142857142857143
Epoch:   65        5 Batch loss: 0.063175 Batch F1: 0.6
Epoch:   65        6 Batch loss: 0.057934 Batch F1: 1.0
Epoch:   65        7 Batch loss: 0.081685 Batch F1: 0.8750000000000001
Epoch:   65        8 Batch loss: 0.062056 Batch F1: 1.0
Epoch:   65        9 Batch loss: 0.067630 Batch F1: 0.923076923076923
Epoch:   65       10 Batch loss: 0.065627 Batch F1: 0.7272727272727273
Epoch:   65       11 Batch loss: 0.071232 Batch F1: 0.4
Epoch:   65       12 Batch loss: 0.092663 Batch F1: 0.5714285714285715
Train Avg Loss   65: 0.074821

Train Avg F1   65: 0.7294409022350199

Val Avg Loss   65: 0.071071

Val Avg F1   65:  0.5768398268398268

Optimal Val loss (Epoch 57): 0.06862303148955107

Epoch 66
--------------------------------------------------------------
Epoch:   66        1 Batch loss: 0.074554 Batch F1: 0.5
Epoch:   66        2 Batch loss: 0.086744 Batch F1: 0.5555555555555556
Epoch:   66        3 Batch loss: 0.062212 Batch F1: 0.8571428571428571
Epoch:   66        4 Batch loss: 0.095358 Batch F1: 0.8695652173913044
Epoch:   66        5 Batch loss: 0.080925 Batch F1: 0.9333333333333333
Epoch:   66        6 Batch loss: 0.074855 Batch F1: 0.8
Epoch:   66        7 Batch loss: 0.061577 Batch F1: 0.2857142857142857
Epoch:   66        8 Batch loss: 0.079042 Batch F1: 0.5714285714285715
Epoch:   66        9 Batch loss: 0.062088 Batch F1: 0.5
Epoch:   66       10 Batch loss: 0.063841 Batch F1: 0.5454545454545454
Epoch:   66       11 Batch loss: 0.082906 Batch F1: 0.5333333333333333
Epoch:   66       12 Batch loss: 0.082280 Batch F1: 0.25
Train Avg Loss   66: 0.075532

Train Avg F1   66: 0.6001273082794821

Val Avg Loss   66: 0.070299

Val Avg F1   66:  0.7882936507936508

Optimal Val loss (Epoch 57): 0.06862303148955107

Epoch 67
--------------------------------------------------------------
Epoch:   67        1 Batch loss: 0.071177 Batch F1: 0.7777777777777778
Epoch:   67        2 Batch loss: 0.088536 Batch F1: 0.8333333333333333
Epoch:   67        3 Batch loss: 0.093685 Batch F1: 0.7000000000000001
Epoch:   67        4 Batch loss: 0.082635 Batch F1: 0.5
Epoch:   67        5 Batch loss: 0.039636 Batch F1: 0.8
Epoch:   67        6 Batch loss: 0.077718 Batch F1: 0.5714285714285715
Epoch:   67        7 Batch loss: 0.073320 Batch F1: 0.5
Epoch:   67        8 Batch loss: 0.097128 Batch F1: 0.7857142857142858
Epoch:   67        9 Batch loss: 0.048660 Batch F1: 1.0
Epoch:   67       10 Batch loss: 0.074673 Batch F1: 0.9473684210526316
Epoch:   67       11 Batch loss: 0.082143 Batch F1: 0.8750000000000001
Epoch:   67       12 Batch loss: 0.088409 Batch F1: 0.4444444444444445
Train Avg Loss   67: 0.076477

Train Avg F1   67: 0.7279222361459204

Val Avg Loss   67: 0.068064

Val Avg F1   67:  0.6031746031746031

Optimal Val loss (Epoch 67): 0.06806353572756052

Epoch 68
--------------------------------------------------------------
Epoch:   68        1 Batch loss: 0.083079 Batch F1: 0.42857142857142855
Epoch:   68        2 Batch loss: 0.088121 Batch F1: 0.19999999999999998
Epoch:   68        3 Batch loss: 0.091121 Batch F1: 0.47058823529411764
Epoch:   68        4 Batch loss: 0.066631 Batch F1: 0.8
Epoch:   68        5 Batch loss: 0.083798 Batch F1: 1.0
Epoch:   68        6 Batch loss: 0.083672 Batch F1: 0.8750000000000001
Epoch:   68        7 Batch loss: 0.074028 Batch F1: 0.8571428571428571
Epoch:   68        8 Batch loss: 0.053733 Batch F1: 0.8571428571428571
Epoch:   68        9 Batch loss: 0.083639 Batch F1: 0.7058823529411764
Epoch:   68       10 Batch loss: 0.077428 Batch F1: 0.3636363636363636
Epoch:   68       11 Batch loss: 0.061560 Batch F1: 0.33333333333333337
Epoch:   68       12 Batch loss: 0.065948 Batch F1: 0.7692307692307693
Train Avg Loss   68: 0.076063

Train Avg F1   68: 0.6383773497744085

Val Avg Loss   68: 0.071484

Val Avg F1   68:  0.5125152625152626

Optimal Val loss (Epoch 67): 0.06806353572756052

Epoch 69
--------------------------------------------------------------
Epoch:   69        1 Batch loss: 0.055413 Batch F1: 0.4
Epoch:   69        2 Batch loss: 0.067043 Batch F1: 0.4444444444444445
Epoch:   69        3 Batch loss: 0.063062 Batch F1: 0.8421052631578948
Epoch:   69        4 Batch loss: 0.076997 Batch F1: 0.2222222222222222
Epoch:   69        5 Batch loss: 0.077937 Batch F1: 0.5
Epoch:   69        6 Batch loss: 0.096448 Batch F1: 0.8
Epoch:   69        7 Batch loss: 0.087920 Batch F1: 0.8750000000000001
Epoch:   69        8 Batch loss: 0.088609 Batch F1: 0.9411764705882353
Epoch:   69        9 Batch loss: 0.071556 Batch F1: 0.9523809523809523
Epoch:   69       10 Batch loss: 0.072045 Batch F1: 0.5
Epoch:   69       11 Batch loss: 0.063133 Batch F1: 0.0
Epoch:   69       12 Batch loss: 0.079048 Batch F1: 0.0
Train Avg Loss   69: 0.074934

Train Avg F1   69: 0.5397774460661459

Val Avg Loss   69: 0.069514

Val Avg F1   69:  0.606060606060606

Optimal Val loss (Epoch 67): 0.06806353572756052

Epoch 70
--------------------------------------------------------------
Epoch:   70        1 Batch loss: 0.063599 Batch F1: 0.6666666666666666
Epoch:   70        2 Batch loss: 0.079819 Batch F1: 0.9090909090909091
Epoch:   70        3 Batch loss: 0.073847 Batch F1: 0.8235294117647058
Epoch:   70        4 Batch loss: 0.077906 Batch F1: 0.9473684210526316
Epoch:   70        5 Batch loss: 0.063979 Batch F1: 1.0
Epoch:   70        6 Batch loss: 0.088882 Batch F1: 0.33333333333333337
Epoch:   70        7 Batch loss: 0.042143 Batch F1: 0.7499999999999999
Epoch:   70        8 Batch loss: 0.090895 Batch F1: 0.5882352941176471
Epoch:   70        9 Batch loss: 0.081638 Batch F1: 0.0
Epoch:   70       10 Batch loss: 0.063751 Batch F1: 0.4444444444444445
Epoch:   70       11 Batch loss: 0.098949 Batch F1: 0.375
Epoch:   70       12 Batch loss: 0.067728 Batch F1: 0.25
Train Avg Loss   70: 0.074428

Train Avg F1   70: 0.5906390400391949

Val Avg Loss   70: 0.068451

Val Avg F1   70:  0.8944444444444445

Optimal Val loss (Epoch 67): 0.06806353572756052

Epoch 71
--------------------------------------------------------------
Epoch:   71        1 Batch loss: 0.062467 Batch F1: 0.8571428571428571
Epoch:   71        2 Batch loss: 0.078654 Batch F1: 0.9523809523809523
Epoch:   71        3 Batch loss: 0.061176 Batch F1: 1.0
Epoch:   71        4 Batch loss: 0.085771 Batch F1: 0.8571428571428571
Epoch:   71        5 Batch loss: 0.079200 Batch F1: 0.9
Epoch:   71        6 Batch loss: 0.088423 Batch F1: 0.8421052631578948
Epoch:   71        7 Batch loss: 0.062175 Batch F1: 0.923076923076923
Epoch:   71        8 Batch loss: 0.071720 Batch F1: 0.8571428571428571
Epoch:   71        9 Batch loss: 0.071418 Batch F1: 0.923076923076923
Epoch:   71       10 Batch loss: 0.061635 Batch F1: 0.923076923076923
Epoch:   71       11 Batch loss: 0.076900 Batch F1: 0.33333333333333337
Epoch:   71       12 Batch loss: 0.071775 Batch F1: 0.6666666666666666
Train Avg Loss   71: 0.072610

Train Avg F1   71: 0.8362621296831824

Val Avg Loss   71: 0.067130

Val Avg F1   71:  0.5594017094017094

Optimal Val loss (Epoch 71): 0.06713004875928164

Epoch 72
--------------------------------------------------------------
Epoch:   72        1 Batch loss: 0.070518 Batch F1: 0.5454545454545454
Epoch:   72        2 Batch loss: 0.082255 Batch F1: 0.7058823529411764
Epoch:   72        3 Batch loss: 0.067803 Batch F1: 0.9411764705882353
Epoch:   72        4 Batch loss: 0.077470 Batch F1: 0.9523809523809523
Epoch:   72        5 Batch loss: 0.069925 Batch F1: 0.8571428571428571
Epoch:   72        6 Batch loss: 0.083794 Batch F1: 0.8235294117647058
Epoch:   72        7 Batch loss: 0.067990 Batch F1: 0.6666666666666666
Epoch:   72        8 Batch loss: 0.077504 Batch F1: 0.6153846153846153
Epoch:   72        9 Batch loss: 0.062454 Batch F1: 0.6153846153846153
Epoch:   72       10 Batch loss: 0.071823 Batch F1: 0.5714285714285715
Epoch:   72       11 Batch loss: 0.055034 Batch F1: 0.5
Epoch:   72       12 Batch loss: 0.062990 Batch F1: 0.7272727272727273
Train Avg Loss   72: 0.070797

Train Avg F1   72: 0.7101419822008056

Val Avg Loss   72: 0.066825

Val Avg F1   72:  0.8388480392156863

Optimal Val loss (Epoch 72): 0.06682484038174152

Epoch 73
--------------------------------------------------------------
Epoch:   73        1 Batch loss: 0.067536 Batch F1: 0.7692307692307693
Epoch:   73        2 Batch loss: 0.067217 Batch F1: 0.7692307692307693
Epoch:   73        3 Batch loss: 0.061384 Batch F1: 0.7142857142857143
Epoch:   73        4 Batch loss: 0.091071 Batch F1: 0.631578947368421
Epoch:   73        5 Batch loss: 0.080103 Batch F1: 0.4615384615384615
Epoch:   73        6 Batch loss: 0.060105 Batch F1: 0.6666666666666666
Epoch:   73        7 Batch loss: 0.070081 Batch F1: 0.9523809523809523
Epoch:   73        8 Batch loss: 0.066184 Batch F1: 0.8333333333333333
Epoch:   73        9 Batch loss: 0.064966 Batch F1: 1.0
Epoch:   73       10 Batch loss: 0.084123 Batch F1: 0.42857142857142855
Epoch:   73       11 Batch loss: 0.090587 Batch F1: 0.4
Epoch:   73       12 Batch loss: 0.072942 Batch F1: 0.7692307692307693
Train Avg Loss   73: 0.073025

Train Avg F1   73: 0.6996706509864405

Val Avg Loss   73: 0.067060

Val Avg F1   73:  0.7327380952380952

Optimal Val loss (Epoch 72): 0.06682484038174152

Epoch 74
--------------------------------------------------------------
Epoch:   74        1 Batch loss: 0.095417 Batch F1: 0.7272727272727273
Epoch:   74        2 Batch loss: 0.070739 Batch F1: 0.8571428571428571
Epoch:   74        3 Batch loss: 0.075193 Batch F1: 0.8333333333333334
Epoch:   74        4 Batch loss: 0.081254 Batch F1: 0.8235294117647058
Epoch:   74        5 Batch loss: 0.061138 Batch F1: 0.8
Epoch:   74        6 Batch loss: 0.072072 Batch F1: 0.6153846153846153
Epoch:   74        7 Batch loss: 0.058594 Batch F1: 0.4
Epoch:   74        8 Batch loss: 0.049038 Batch F1: 0.5714285714285715
Epoch:   74        9 Batch loss: 0.097285 Batch F1: 0.5
Epoch:   74       10 Batch loss: 0.068990 Batch F1: 0.4615384615384615
Epoch:   74       11 Batch loss: 0.089698 Batch F1: 0.9523809523809523
Epoch:   74       12 Batch loss: 0.089466 Batch F1: 0.9411764705882353
Train Avg Loss   74: 0.075740

Train Avg F1   74: 0.7069322834028716

Val Avg Loss   74: 0.066969

Val Avg F1   74:  0.6249999999999999

Optimal Val loss (Epoch 72): 0.06682484038174152

Epoch 75
--------------------------------------------------------------
Epoch:   75        1 Batch loss: 0.082055 Batch F1: 0.2222222222222222
Epoch:   75        2 Batch loss: 0.096418 Batch F1: 0.375
Epoch:   75        3 Batch loss: 0.078971 Batch F1: 0.4
Epoch:   75        4 Batch loss: 0.068266 Batch F1: 0.5454545454545454
Epoch:   75        5 Batch loss: 0.067778 Batch F1: 0.5454545454545454
Epoch:   75        6 Batch loss: 0.092967 Batch F1: 0.8
Epoch:   75        7 Batch loss: 0.059066 Batch F1: 0.9090909090909091
Epoch:   75        8 Batch loss: 0.073373 Batch F1: 0.9333333333333333
Epoch:   75        9 Batch loss: 0.071796 Batch F1: 1.0
Epoch:   75       10 Batch loss: 0.080931 Batch F1: 1.0
Epoch:   75       11 Batch loss: 0.073566 Batch F1: 0.7142857142857143
Epoch:   75       12 Batch loss: 0.065754 Batch F1: 0.6666666666666666
Train Avg Loss   75: 0.075912

Train Avg F1   75: 0.6759589947089948

Val Avg Loss   75: 0.069867

Val Avg F1   75:  0.6236044657097288

Optimal Val loss (Epoch 72): 0.06682484038174152

Epoch 76
--------------------------------------------------------------
Epoch:   76        1 Batch loss: 0.052040 Batch F1: 0.8
Epoch:   76        2 Batch loss: 0.057929 Batch F1: 0.5714285714285715
Epoch:   76        3 Batch loss: 0.091540 Batch F1: 0.5
Epoch:   76        4 Batch loss: 0.087932 Batch F1: 0.5882352941176471
Epoch:   76        5 Batch loss: 0.094277 Batch F1: 0.3636363636363636
Epoch:   76        6 Batch loss: 0.078173 Batch F1: 1.0
Epoch:   76        7 Batch loss: 0.076384 Batch F1: 1.0
Epoch:   76        8 Batch loss: 0.061684 Batch F1: 0.8571428571428571
Epoch:   76        9 Batch loss: 0.061563 Batch F1: 0.6666666666666666
Epoch:   76       10 Batch loss: 0.082065 Batch F1: 0.4615384615384615
Epoch:   76       11 Batch loss: 0.097769 Batch F1: 0.18181818181818182
Epoch:   76       12 Batch loss: 0.086109 Batch F1: 0.5
Train Avg Loss   76: 0.077289

Train Avg F1   76: 0.6242055330290625

Val Avg Loss   76: 0.065556

Val Avg F1   76:  0.7149572649572649

Optimal Val loss (Epoch 76): 0.0655561201274395

Epoch 77
--------------------------------------------------------------
Epoch:   77        1 Batch loss: 0.064754 Batch F1: 0.7499999999999999
Epoch:   77        2 Batch loss: 0.078861 Batch F1: 0.8571428571428571
Epoch:   77        3 Batch loss: 0.078644 Batch F1: 0.888888888888889
Epoch:   77        4 Batch loss: 0.073261 Batch F1: 0.9411764705882353
Epoch:   77        5 Batch loss: 0.073050 Batch F1: 0.3636363636363636
Epoch:   77        6 Batch loss: 0.059114 Batch F1: 0.7499999999999999
Epoch:   77        7 Batch loss: 0.103450 Batch F1: 0.2666666666666667
Epoch:   77        8 Batch loss: 0.080917 Batch F1: 0.5
Epoch:   77        9 Batch loss: 0.098802 Batch F1: 0.6363636363636364
Epoch:   77       10 Batch loss: 0.086646 Batch F1: 0.888888888888889
Epoch:   77       11 Batch loss: 0.066508 Batch F1: 0.625
Epoch:   77       12 Batch loss: 0.060991 Batch F1: 0.5714285714285715
Train Avg Loss   77: 0.077083

Train Avg F1   77: 0.6699326953003424

Val Avg Loss   77: 0.080676

Val Avg F1   77:  0.2109002109002109

Optimal Val loss (Epoch 76): 0.0655561201274395

Epoch 78
--------------------------------------------------------------
Epoch:   78        1 Batch loss: 0.060355 Batch F1: 0.0
Epoch:   78        2 Batch loss: 0.131874 Batch F1: 0.0
Epoch:   78        3 Batch loss: 0.058861 Batch F1: 0.8333333333333333
Epoch:   78        4 Batch loss: 0.072235 Batch F1: 0.9411764705882353
Epoch:   78        5 Batch loss: 0.084696 Batch F1: 0.9411764705882353
Epoch:   78        6 Batch loss: 0.050643 Batch F1: 0.7692307692307693
Epoch:   78        7 Batch loss: 0.063783 Batch F1: 0.6
Epoch:   78        8 Batch loss: 0.084199 Batch F1: 0.2222222222222222
Epoch:   78        9 Batch loss: 0.111077 Batch F1: 0.4
Epoch:   78       10 Batch loss: 0.094842 Batch F1: 0.3076923076923077
Epoch:   78       11 Batch loss: 0.082958 Batch F1: 0.888888888888889
Epoch:   78       12 Batch loss: 0.096734 Batch F1: 0.9411764705882353
Train Avg Loss   78: 0.082688

Train Avg F1   78: 0.570408077761019

Val Avg Loss   78: 0.067777

Val Avg F1   78:  0.6234299516908213

Optimal Val loss (Epoch 76): 0.0655561201274395

Epoch 79
--------------------------------------------------------------
Epoch:   79        1 Batch loss: 0.052046 Batch F1: 0.7499999999999999
Epoch:   79        2 Batch loss: 0.103294 Batch F1: 0.47058823529411764
Epoch:   79        3 Batch loss: 0.069446 Batch F1: 0.5454545454545454
Epoch:   79        4 Batch loss: 0.073549 Batch F1: 0.5
Epoch:   79        5 Batch loss: 0.072100 Batch F1: 0.4615384615384615
Epoch:   79        6 Batch loss: 0.092156 Batch F1: 0.42857142857142855
Epoch:   79        7 Batch loss: 0.069205 Batch F1: 0.9411764705882353
Epoch:   79        8 Batch loss: 0.058006 Batch F1: 1.0
Epoch:   79        9 Batch loss: 0.087083 Batch F1: 0.8235294117647058
Epoch:   79       10 Batch loss: 0.072586 Batch F1: 0.5454545454545454
Epoch:   79       11 Batch loss: 0.083593 Batch F1: 0.6666666666666666
Epoch:   79       12 Batch loss: 0.074707 Batch F1: 0.5
Train Avg Loss   79: 0.075648

Train Avg F1   79: 0.6360816471110587

Val Avg Loss   79: 0.067329

Val Avg F1   79:  0.7620341614906831

Optimal Val loss (Epoch 76): 0.0655561201274395

Epoch 80
--------------------------------------------------------------
Epoch:   80        1 Batch loss: 0.049913 Batch F1: 0.7499999999999999
Epoch:   80        2 Batch loss: 0.061950 Batch F1: 0.9411764705882353
Epoch:   80        3 Batch loss: 0.058890 Batch F1: 0.6666666666666666
Epoch:   80        4 Batch loss: 0.081159 Batch F1: 0.5714285714285715
Epoch:   80        5 Batch loss: 0.076256 Batch F1: 0.2222222222222222
Epoch:   80        6 Batch loss: 0.094949 Batch F1: 0.4
Epoch:   80        7 Batch loss: 0.070934 Batch F1: 0.5714285714285715
Epoch:   80        8 Batch loss: 0.064766 Batch F1: 0.8
Epoch:   80        9 Batch loss: 0.098895 Batch F1: 0.761904761904762
Epoch:   80       10 Batch loss: 0.054214 Batch F1: 1.0
Epoch:   80       11 Batch loss: 0.121340 Batch F1: 0.782608695652174
Epoch:   80       12 Batch loss: 0.048411 Batch F1: 0.8571428571428571
Train Avg Loss   80: 0.073473

Train Avg F1   80: 0.6937149014195049

Val Avg Loss   80: 0.066693

Val Avg F1   80:  0.5882518796992481

Optimal Val loss (Epoch 76): 0.0655561201274395

Epoch 81
--------------------------------------------------------------
Epoch:   81        1 Batch loss: 0.078385 Batch F1: 0.5714285714285715
Epoch:   81        2 Batch loss: 0.061803 Batch F1: 0.4444444444444445
Epoch:   81        3 Batch loss: 0.080050 Batch F1: 0.625
Epoch:   81        4 Batch loss: 0.069373 Batch F1: 0.7499999999999999
Epoch:   81        5 Batch loss: 0.060170 Batch F1: 0.5
Epoch:   81        6 Batch loss: 0.075133 Batch F1: 0.6153846153846153
Epoch:   81        7 Batch loss: 0.105765 Batch F1: 0.72
Epoch:   81        8 Batch loss: 0.066616 Batch F1: 1.0
Epoch:   81        9 Batch loss: 0.069832 Batch F1: 0.9565217391304348
Epoch:   81       10 Batch loss: 0.075312 Batch F1: 1.0
Epoch:   81       11 Batch loss: 0.086275 Batch F1: 0.8
Epoch:   81       12 Batch loss: 0.040795 Batch F1: 0.8
Train Avg Loss   81: 0.072459

Train Avg F1   81: 0.7318982808656722

Val Avg Loss   81: 0.068926

Val Avg F1   81:  0.5599358974358973

Optimal Val loss (Epoch 76): 0.0655561201274395

Epoch 82
--------------------------------------------------------------
Epoch:   82        1 Batch loss: 0.078618 Batch F1: 0.33333333333333337
Epoch:   82        2 Batch loss: 0.050331 Batch F1: 0.6666666666666666
Epoch:   82        3 Batch loss: 0.126761 Batch F1: 0.0
Epoch:   82        4 Batch loss: 0.070744 Batch F1: 0.6153846153846153
Epoch:   82        5 Batch loss: 0.079227 Batch F1: 0.0
Epoch:   82        6 Batch loss: 0.068383 Batch F1: 0.7272727272727273
Epoch:   82        7 Batch loss: 0.068059 Batch F1: 0.9523809523809523
Epoch:   82        8 Batch loss: 0.072411 Batch F1: 0.9411764705882353
Epoch:   82        9 Batch loss: 0.059307 Batch F1: 0.9090909090909091
Epoch:   82       10 Batch loss: 0.076964 Batch F1: 0.8235294117647058
Epoch:   82       11 Batch loss: 0.076163 Batch F1: 0.8
Epoch:   82       12 Batch loss: 0.057076 Batch F1: 1.0
Train Avg Loss   82: 0.073670

Train Avg F1   82: 0.6474029238735121

Val Avg Loss   82: 0.070417

Val Avg F1   82:  0.6919934640522876

Optimal Val loss (Epoch 76): 0.0655561201274395

Epoch 83
--------------------------------------------------------------
Epoch:   83        1 Batch loss: 0.058869 Batch F1: 0.7272727272727272
Epoch:   83        2 Batch loss: 0.082465 Batch F1: 0.5
Epoch:   83        3 Batch loss: 0.068536 Batch F1: 0.8235294117647058
Epoch:   83        4 Batch loss: 0.054802 Batch F1: 0.7272727272727273
Epoch:   83        5 Batch loss: 0.086301 Batch F1: 0.5714285714285715
Epoch:   83        6 Batch loss: 0.069033 Batch F1: 0.5454545454545454
Epoch:   83        7 Batch loss: 0.088882 Batch F1: 0.4615384615384615
Epoch:   83        8 Batch loss: 0.054790 Batch F1: 0.9090909090909091
Epoch:   83        9 Batch loss: 0.091373 Batch F1: 0.5882352941176471
Epoch:   83       10 Batch loss: 0.061197 Batch F1: 0.6666666666666666
Epoch:   83       11 Batch loss: 0.079271 Batch F1: 0.5555555555555556
Epoch:   83       12 Batch loss: 0.072808 Batch F1: 0.6153846153846153
Train Avg Loss   83: 0.072361

Train Avg F1   83: 0.6409524571289277

Val Avg Loss   83: 0.066677

Val Avg F1   83:  0.9257309941520468

Optimal Val loss (Epoch 76): 0.0655561201274395

Epoch 84
--------------------------------------------------------------
Epoch:   84        1 Batch loss: 0.047799 Batch F1: 0.888888888888889
Epoch:   84        2 Batch loss: 0.078811 Batch F1: 0.888888888888889
Epoch:   84        3 Batch loss: 0.073670 Batch F1: 0.8
Epoch:   84        4 Batch loss: 0.074693 Batch F1: 0.8333333333333333
Epoch:   84        5 Batch loss: 0.064377 Batch F1: 0.7272727272727273
Epoch:   84        6 Batch loss: 0.078447 Batch F1: 0.0
Epoch:   84        7 Batch loss: 0.093276 Batch F1: 0.0
Epoch:   84        8 Batch loss: 0.070225 Batch F1: 0.5
Epoch:   84        9 Batch loss: 0.094083 Batch F1: 0.5263157894736842
Epoch:   84       10 Batch loss: 0.070574 Batch F1: 0.8750000000000001
Epoch:   84       11 Batch loss: 0.066390 Batch F1: 1.0
Epoch:   84       12 Batch loss: 0.078041 Batch F1: 1.0
Train Avg Loss   84: 0.074199

Train Avg F1   84: 0.6699749689881269

Val Avg Loss   84: 0.065887

Val Avg F1   84:  0.9263574660633485

Optimal Val loss (Epoch 76): 0.0655561201274395

Epoch 85
--------------------------------------------------------------
Epoch:   85        1 Batch loss: 0.062203 Batch F1: 0.923076923076923
Epoch:   85        2 Batch loss: 0.080306 Batch F1: 0.3636363636363636
Epoch:   85        3 Batch loss: 0.079838 Batch F1: 0.5
Epoch:   85        4 Batch loss: 0.070229 Batch F1: 0.6153846153846153
Epoch:   85        5 Batch loss: 0.071996 Batch F1: 0.5714285714285715
Epoch:   85        6 Batch loss: 0.058411 Batch F1: 0.6666666666666666
Epoch:   85        7 Batch loss: 0.085035 Batch F1: 0.5555555555555556
Epoch:   85        8 Batch loss: 0.068716 Batch F1: 0.8571428571428571
Epoch:   85        9 Batch loss: 0.050182 Batch F1: 1.0
Epoch:   85       10 Batch loss: 0.080002 Batch F1: 0.42857142857142855
Epoch:   85       11 Batch loss: 0.078207 Batch F1: 0.6153846153846153
Epoch:   85       12 Batch loss: 0.075504 Batch F1: 0.8235294117647058
Train Avg Loss   85: 0.071719

Train Avg F1   85: 0.6600314173843586

Val Avg Loss   85: 0.065419

Val Avg F1   85:  0.8102941176470588

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 86
--------------------------------------------------------------
Epoch:   86        1 Batch loss: 0.051871 Batch F1: 1.0
Epoch:   86        2 Batch loss: 0.082266 Batch F1: 0.42857142857142855
Epoch:   86        3 Batch loss: 0.064081 Batch F1: 0.25
Epoch:   86        4 Batch loss: 0.090039 Batch F1: 0.5
Epoch:   86        5 Batch loss: 0.078077 Batch F1: 0.6666666666666666
Epoch:   86        6 Batch loss: 0.080162 Batch F1: 0.8695652173913044
Epoch:   86        7 Batch loss: 0.080255 Batch F1: 0.9523809523809523
Epoch:   86        8 Batch loss: 0.079101 Batch F1: 0.8571428571428571
Epoch:   86        9 Batch loss: 0.078390 Batch F1: 0.888888888888889
Epoch:   86       10 Batch loss: 0.063269 Batch F1: 0.923076923076923
Epoch:   86       11 Batch loss: 0.039937 Batch F1: 0.6666666666666666
Epoch:   86       12 Batch loss: 0.081827 Batch F1: 0.0
Train Avg Loss   86: 0.072439

Train Avg F1   86: 0.666913300065474

Val Avg Loss   86: 0.076985

Val Avg F1   86:  0.0

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 87
--------------------------------------------------------------
Epoch:   87        1 Batch loss: 0.081104 Batch F1: 0.16666666666666669
Epoch:   87        2 Batch loss: 0.088087 Batch F1: 0.0
Epoch:   87        3 Batch loss: 0.087964 Batch F1: 0.5333333333333333
Epoch:   87        4 Batch loss: 0.054430 Batch F1: 1.0
Epoch:   87        5 Batch loss: 0.071720 Batch F1: 0.9473684210526316
Epoch:   87        6 Batch loss: 0.089785 Batch F1: 0.8571428571428571
Epoch:   87        7 Batch loss: 0.062825 Batch F1: 0.7142857142857143
Epoch:   87        8 Batch loss: 0.071435 Batch F1: 0.8421052631578948
Epoch:   87        9 Batch loss: 0.077374 Batch F1: 0.5714285714285715
Epoch:   87       10 Batch loss: 0.081777 Batch F1: 0.3636363636363636
Epoch:   87       11 Batch loss: 0.086379 Batch F1: 0.888888888888889
Epoch:   87       12 Batch loss: 0.067218 Batch F1: 0.6666666666666666
Train Avg Loss   87: 0.076675

Train Avg F1   87: 0.629293562188299

Val Avg Loss   87: 0.068178

Val Avg F1   87:  0.5928571428571429

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 88
--------------------------------------------------------------
Epoch:   88        1 Batch loss: 0.081057 Batch F1: 0.5882352941176471
Epoch:   88        2 Batch loss: 0.083551 Batch F1: 0.4615384615384615
Epoch:   88        3 Batch loss: 0.049530 Batch F1: 0.7272727272727273
Epoch:   88        4 Batch loss: 0.095016 Batch F1: 0.5263157894736842
Epoch:   88        5 Batch loss: 0.064698 Batch F1: 0.4
Epoch:   88        6 Batch loss: 0.054437 Batch F1: 0.6666666666666666
Epoch:   88        7 Batch loss: 0.079296 Batch F1: 0.3636363636363636
Epoch:   88        8 Batch loss: 0.068285 Batch F1: 0.4444444444444445
Epoch:   88        9 Batch loss: 0.090634 Batch F1: 0.4615384615384615
Epoch:   88       10 Batch loss: 0.076259 Batch F1: 0.4615384615384615
Epoch:   88       11 Batch loss: 0.087683 Batch F1: 0.5882352941176471
Epoch:   88       12 Batch loss: 0.056859 Batch F1: 1.0
Train Avg Loss   88: 0.073942

Train Avg F1   88: 0.557451830362047

Val Avg Loss   88: 0.066553

Val Avg F1   88:  0.9283882783882784

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 89
--------------------------------------------------------------
Epoch:   89        1 Batch loss: 0.071169 Batch F1: 0.888888888888889
Epoch:   89        2 Batch loss: 0.091247 Batch F1: 0.9
Epoch:   89        3 Batch loss: 0.063476 Batch F1: 0.9333333333333333
Epoch:   89        4 Batch loss: 0.075228 Batch F1: 0.9
Epoch:   89        5 Batch loss: 0.078050 Batch F1: 0.8421052631578948
Epoch:   89        6 Batch loss: 0.072524 Batch F1: 0.7692307692307693
Epoch:   89        7 Batch loss: 0.053045 Batch F1: 0.6666666666666666
Epoch:   89        8 Batch loss: 0.094310 Batch F1: 0.7272727272727273
Epoch:   89        9 Batch loss: 0.071866 Batch F1: 0.4
Epoch:   89       10 Batch loss: 0.056612 Batch F1: 0.0
Epoch:   89       11 Batch loss: 0.073465 Batch F1: 0.761904761904762
Epoch:   89       12 Batch loss: 0.064071 Batch F1: 0.888888888888889
Train Avg Loss   89: 0.072089

Train Avg F1   89: 0.7231909416119944

Val Avg Loss   89: 0.066438

Val Avg F1   89:  0.8211038961038961

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 90
--------------------------------------------------------------
Epoch:   90        1 Batch loss: 0.055049 Batch F1: 0.9090909090909091
Epoch:   90        2 Batch loss: 0.062048 Batch F1: 0.4444444444444445
Epoch:   90        3 Batch loss: 0.089481 Batch F1: 0.19999999999999998
Epoch:   90        4 Batch loss: 0.106328 Batch F1: 0.0
Epoch:   90        5 Batch loss: 0.087013 Batch F1: 0.5
Epoch:   90        6 Batch loss: 0.069111 Batch F1: 0.9090909090909091
Epoch:   90        7 Batch loss: 0.069392 Batch F1: 0.9411764705882353
Epoch:   90        8 Batch loss: 0.057173 Batch F1: 1.0
Epoch:   90        9 Batch loss: 0.061286 Batch F1: 0.8333333333333333
Epoch:   90       10 Batch loss: 0.088993 Batch F1: 0.761904761904762
Epoch:   90       11 Batch loss: 0.070246 Batch F1: 0.7777777777777778
Epoch:   90       12 Batch loss: 0.065300 Batch F1: 1.0
Train Avg Loss   90: 0.073452

Train Avg F1   90: 0.6897348838525309

Val Avg Loss   90: 0.067812

Val Avg F1   90:  0.8215277777777777

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 91
--------------------------------------------------------------
Epoch:   91        1 Batch loss: 0.069712 Batch F1: 0.9090909090909091
Epoch:   91        2 Batch loss: 0.088155 Batch F1: 0.5714285714285715
Epoch:   91        3 Batch loss: 0.071967 Batch F1: 0.7142857142857143
Epoch:   91        4 Batch loss: 0.075401 Batch F1: 0.25
Epoch:   91        5 Batch loss: 0.069052 Batch F1: 0.4444444444444445
Epoch:   91        6 Batch loss: 0.073921 Batch F1: 0.625
Epoch:   91        7 Batch loss: 0.059830 Batch F1: 0.6666666666666666
Epoch:   91        8 Batch loss: 0.059022 Batch F1: 0.5
Epoch:   91        9 Batch loss: 0.108677 Batch F1: 0.6666666666666666
Epoch:   91       10 Batch loss: 0.076946 Batch F1: 0.9473684210526316
Epoch:   91       11 Batch loss: 0.061888 Batch F1: 1.0
Epoch:   91       12 Batch loss: 0.072565 Batch F1: 0.8
Train Avg Loss   91: 0.073928

Train Avg F1   91: 0.6745792828029672

Val Avg Loss   91: 0.066832

Val Avg F1   91:  0.7380952380952381

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 92
--------------------------------------------------------------
Epoch:   92        1 Batch loss: 0.047294 Batch F1: 0.9090909090909091
Epoch:   92        2 Batch loss: 0.034967 Batch F1: 1.0
Epoch:   92        3 Batch loss: 0.111167 Batch F1: 0.0
Epoch:   92        4 Batch loss: 0.075665 Batch F1: 0.5
Epoch:   92        5 Batch loss: 0.066877 Batch F1: 0.6666666666666666
Epoch:   92        6 Batch loss: 0.082390 Batch F1: 0.8421052631578948
Epoch:   92        7 Batch loss: 0.050842 Batch F1: 1.0
Epoch:   92        8 Batch loss: 0.078318 Batch F1: 0.4615384615384615
Epoch:   92        9 Batch loss: 0.078195 Batch F1: 0.5
Epoch:   92       10 Batch loss: 0.079431 Batch F1: 0.33333333333333337
Epoch:   92       11 Batch loss: 0.102095 Batch F1: 0.0
Epoch:   92       12 Batch loss: 0.080680 Batch F1: 1.0
Train Avg Loss   92: 0.073993

Train Avg F1   92: 0.6010612194822721

Val Avg Loss   92: 0.068644

Val Avg F1   92:  0.9293907846539425

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 93
--------------------------------------------------------------
Epoch:   93        1 Batch loss: 0.066847 Batch F1: 0.9333333333333333
Epoch:   93        2 Batch loss: 0.073915 Batch F1: 0.9090909090909091
Epoch:   93        3 Batch loss: 0.068392 Batch F1: 0.9473684210526316
Epoch:   93        4 Batch loss: 0.060579 Batch F1: 0.888888888888889
Epoch:   93        5 Batch loss: 0.084541 Batch F1: 0.0
Epoch:   93        6 Batch loss: 0.086632 Batch F1: 0.0
Epoch:   93        7 Batch loss: 0.093616 Batch F1: 0.5555555555555556
Epoch:   93        8 Batch loss: 0.045601 Batch F1: 1.0
Epoch:   93        9 Batch loss: 0.064862 Batch F1: 1.0
Epoch:   93       10 Batch loss: 0.079425 Batch F1: 0.9473684210526316
Epoch:   93       11 Batch loss: 0.074747 Batch F1: 0.9523809523809523
Epoch:   93       12 Batch loss: 0.080795 Batch F1: 0.7777777777777778
Train Avg Loss   93: 0.073329

Train Avg F1   93: 0.7426470215943901

Val Avg Loss   93: 0.065947

Val Avg F1   93:  0.6867961759602627

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 94
--------------------------------------------------------------
Epoch:   94        1 Batch loss: 0.079095 Batch F1: 0.4615384615384615
Epoch:   94        2 Batch loss: 0.080242 Batch F1: 0.6666666666666666
Epoch:   94        3 Batch loss: 0.063040 Batch F1: 0.7692307692307693
Epoch:   94        4 Batch loss: 0.074337 Batch F1: 0.25
Epoch:   94        5 Batch loss: 0.068540 Batch F1: 0.0
Epoch:   94        6 Batch loss: 0.069474 Batch F1: 0.2222222222222222
Epoch:   94        7 Batch loss: 0.094330 Batch F1: 0.5555555555555556
Epoch:   94        8 Batch loss: 0.070767 Batch F1: 0.6153846153846153
Epoch:   94        9 Batch loss: 0.064456 Batch F1: 0.8750000000000001
Epoch:   94       10 Batch loss: 0.081078 Batch F1: 0.8235294117647058
Epoch:   94       11 Batch loss: 0.078264 Batch F1: 0.962962962962963
Epoch:   94       12 Batch loss: 0.074514 Batch F1: 0.8571428571428571
Train Avg Loss   94: 0.074845

Train Avg F1   94: 0.5882694602057347

Val Avg Loss   94: 0.065776

Val Avg F1   94:  0.6518315018315018

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 95
--------------------------------------------------------------
Epoch:   95        1 Batch loss: 0.069148 Batch F1: 0.5454545454545454
Epoch:   95        2 Batch loss: 0.072819 Batch F1: 0.6666666666666666
Epoch:   95        3 Batch loss: 0.047585 Batch F1: 0.5
Epoch:   95        4 Batch loss: 0.124025 Batch F1: 0.3
Epoch:   95        5 Batch loss: 0.084564 Batch F1: 0.8571428571428571
Epoch:   95        6 Batch loss: 0.087711 Batch F1: 1.0
Epoch:   95        7 Batch loss: 0.095048 Batch F1: 0.0
Epoch:   95        8 Batch loss: 0.111377 Batch F1: 0.0
Epoch:   95        9 Batch loss: 0.058241 Batch F1: 0.0
Epoch:   95       10 Batch loss: 0.098734 Batch F1: 0.0
Epoch:   95       11 Batch loss: 0.096495 Batch F1: 0.0
Epoch:   95       12 Batch loss: 0.079539 Batch F1: 0.5454545454545454
Train Avg Loss   95: 0.085440

Train Avg F1   95: 0.3678932178932179

Val Avg Loss   95: 0.066897

Val Avg F1   95:  0.5883012820512821

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 96
--------------------------------------------------------------
Epoch:   96        1 Batch loss: 0.069237 Batch F1: 0.761904761904762
Epoch:   96        2 Batch loss: 0.085669 Batch F1: 0.8571428571428571
Epoch:   96        3 Batch loss: 0.078866 Batch F1: 0.8
Epoch:   96        4 Batch loss: 0.098537 Batch F1: 0.3636363636363636
Epoch:   96        5 Batch loss: 0.079451 Batch F1: 0.8235294117647058
Epoch:   96        6 Batch loss: 0.080149 Batch F1: 0.7272727272727273
Epoch:   96        7 Batch loss: 0.037867 Batch F1: 0.8571428571428571
Epoch:   96        8 Batch loss: 0.176993 Batch F1: 0.0
Epoch:   96        9 Batch loss: 0.082968 Batch F1: 0.4
Epoch:   96       10 Batch loss: 0.067167 Batch F1: 0.7499999999999999
Epoch:   96       11 Batch loss: 0.070243 Batch F1: 0.8750000000000001
Epoch:   96       12 Batch loss: 0.068537 Batch F1: 0.888888888888889
Train Avg Loss   96: 0.082974

Train Avg F1   96: 0.6753764889794303

Val Avg Loss   96: 0.069330

Val Avg F1   96:  0.5844606782106783

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 97
--------------------------------------------------------------
Epoch:   97        1 Batch loss: 0.077343 Batch F1: 0.5
Epoch:   97        2 Batch loss: 0.069602 Batch F1: 0.6153846153846153
Epoch:   97        3 Batch loss: 0.059090 Batch F1: 0.6
Epoch:   97        4 Batch loss: 0.082629 Batch F1: 0.5714285714285715
Epoch:   97        5 Batch loss: 0.068529 Batch F1: 0.5454545454545454
Epoch:   97        6 Batch loss: 0.073075 Batch F1: 0.6666666666666666
Epoch:   97        7 Batch loss: 0.066788 Batch F1: 0.7142857142857143
Epoch:   97        8 Batch loss: 0.087299 Batch F1: 0.6666666666666666
Epoch:   97        9 Batch loss: 0.068974 Batch F1: 0.4615384615384615
Epoch:   97       10 Batch loss: 0.079863 Batch F1: 0.8750000000000001
Epoch:   97       11 Batch loss: 0.101954 Batch F1: 0.7499999999999999
Epoch:   97       12 Batch loss: 0.096147 Batch F1: 0.3636363636363636
Train Avg Loss   97: 0.077608

Train Avg F1   97: 0.6108384670884671

Val Avg Loss   97: 0.071543

Val Avg F1   97:  0.5648310023310023

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 98
--------------------------------------------------------------
Epoch:   98        1 Batch loss: 0.073229 Batch F1: 0.4444444444444445
Epoch:   98        2 Batch loss: 0.081285 Batch F1: 0.6666666666666666
Epoch:   98        3 Batch loss: 0.069708 Batch F1: 0.6666666666666666
Epoch:   98        4 Batch loss: 0.082319 Batch F1: 0.5333333333333333
Epoch:   98        5 Batch loss: 0.061416 Batch F1: 0.7692307692307693
Epoch:   98        6 Batch loss: 0.065592 Batch F1: 0.7692307692307693
Epoch:   98        7 Batch loss: 0.079634 Batch F1: 0.4615384615384615
Epoch:   98        8 Batch loss: 0.063281 Batch F1: 0.0
Epoch:   98        9 Batch loss: 0.085186 Batch F1: 0.5
Epoch:   98       10 Batch loss: 0.058943 Batch F1: 0.8571428571428571
Epoch:   98       11 Batch loss: 0.107571 Batch F1: 0.6363636363636364
Epoch:   98       12 Batch loss: 0.074954 Batch F1: 0.6
Train Avg Loss   98: 0.075260

Train Avg F1   98: 0.5753848003848003

Val Avg Loss   98: 0.068224

Val Avg F1   98:  0.925944669365722

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 99
--------------------------------------------------------------
Epoch:   99        1 Batch loss: 0.071307 Batch F1: 0.9411764705882353
Epoch:   99        2 Batch loss: 0.069291 Batch F1: 0.6666666666666666
Epoch:   99        3 Batch loss: 0.060049 Batch F1: 0.9333333333333333
Epoch:   99        4 Batch loss: 0.053845 Batch F1: 0.5714285714285715
Epoch:   99        5 Batch loss: 0.076374 Batch F1: 0.5
Epoch:   99        6 Batch loss: 0.091626 Batch F1: 0.2857142857142857
Epoch:   99        7 Batch loss: 0.093728 Batch F1: 0.18181818181818182
Epoch:   99        8 Batch loss: 0.078020 Batch F1: 0.8235294117647058
Epoch:   99        9 Batch loss: 0.078287 Batch F1: 0.967741935483871
Epoch:   99       10 Batch loss: 0.079150 Batch F1: 0.9565217391304348
Epoch:   99       11 Batch loss: 0.056666 Batch F1: 1.0
Epoch:   99       12 Batch loss: 0.074711 Batch F1: 1.0
Train Avg Loss   99: 0.073588

Train Avg F1   99: 0.7356608829940239

Val Avg Loss   99: 0.069384

Val Avg F1   99:  0.5836134453781512

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 100
--------------------------------------------------------------
Epoch:  100        1 Batch loss: 0.078164 Batch F1: 0.6666666666666666
Epoch:  100        2 Batch loss: 0.070207 Batch F1: 0.7142857142857143
Epoch:  100        3 Batch loss: 0.068794 Batch F1: 0.4444444444444445
Epoch:  100        4 Batch loss: 0.077975 Batch F1: 0.5333333333333333
Epoch:  100        5 Batch loss: 0.069740 Batch F1: 0.7499999999999999
Epoch:  100        6 Batch loss: 0.083038 Batch F1: 0.9
Epoch:  100        7 Batch loss: 0.081847 Batch F1: 0.8571428571428571
Epoch:  100        8 Batch loss: 0.078334 Batch F1: 0.888888888888889
Epoch:  100        9 Batch loss: 0.055671 Batch F1: 0.6666666666666666
Epoch:  100       10 Batch loss: 0.067890 Batch F1: 0.7142857142857143
Epoch:  100       11 Batch loss: 0.086610 Batch F1: 0.0
Epoch:  100       12 Batch loss: 0.085456 Batch F1: 0.4
Train Avg Loss  100: 0.075310

Train Avg F1  100: 0.6279761904761906

Val Avg Loss  100: 0.071489

Val Avg F1  100:  0.5753968253968255

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 101
--------------------------------------------------------------
Epoch:  101        1 Batch loss: 0.075756 Batch F1: 0.4
Epoch:  101        2 Batch loss: 0.061085 Batch F1: 0.6
Epoch:  101        3 Batch loss: 0.060799 Batch F1: 0.5
Epoch:  101        4 Batch loss: 0.063196 Batch F1: 0.7692307692307693
Epoch:  101        5 Batch loss: 0.077757 Batch F1: 0.8421052631578948
Epoch:  101        6 Batch loss: 0.057340 Batch F1: 0.923076923076923
Epoch:  101        7 Batch loss: 0.064373 Batch F1: 1.0
Epoch:  101        8 Batch loss: 0.099745 Batch F1: 0.8333333333333333
Epoch:  101        9 Batch loss: 0.056804 Batch F1: 1.0
Epoch:  101       10 Batch loss: 0.074062 Batch F1: 0.9600000000000001
Epoch:  101       11 Batch loss: 0.085054 Batch F1: 0.888888888888889
Epoch:  101       12 Batch loss: 0.084691 Batch F1: 0.7142857142857143
Train Avg Loss  101: 0.071722

Train Avg F1  101: 0.7859100743311269

Val Avg Loss  101: 0.066564

Val Avg F1  101:  0.9066833751044276

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 102
--------------------------------------------------------------
Epoch:  102        1 Batch loss: 0.075892 Batch F1: 0.9411764705882353
Epoch:  102        2 Batch loss: 0.077844 Batch F1: 0.9600000000000001
Epoch:  102        3 Batch loss: 0.057201 Batch F1: 1.0
Epoch:  102        4 Batch loss: 0.074977 Batch F1: 0.8235294117647058
Epoch:  102        5 Batch loss: 0.080237 Batch F1: 0.8421052631578948
Epoch:  102        6 Batch loss: 0.050878 Batch F1: 0.8
Epoch:  102        7 Batch loss: 0.087987 Batch F1: 0.7000000000000001
Epoch:  102        8 Batch loss: 0.058418 Batch F1: 0.4444444444444445
Epoch:  102        9 Batch loss: 0.067148 Batch F1: 0.5
Epoch:  102       10 Batch loss: 0.069300 Batch F1: 0.8421052631578948
Epoch:  102       11 Batch loss: 0.063598 Batch F1: 0.5714285714285715
Epoch:  102       12 Batch loss: 0.082731 Batch F1: 0.6666666666666666
Train Avg Loss  102: 0.070518

Train Avg F1  102: 0.7576213409340343

Val Avg Loss  102: 0.066349

Val Avg F1  102:  0.5828947368421052

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 103
--------------------------------------------------------------
Epoch:  103        1 Batch loss: 0.050198 Batch F1: 0.7499999999999999
Epoch:  103        2 Batch loss: 0.097301 Batch F1: 0.4
Epoch:  103        3 Batch loss: 0.089263 Batch F1: 0.18181818181818182
Epoch:  103        4 Batch loss: 0.051430 Batch F1: 0.8333333333333333
Epoch:  103        5 Batch loss: 0.065448 Batch F1: 0.7142857142857143
Epoch:  103        6 Batch loss: 0.074069 Batch F1: 1.0
Epoch:  103        7 Batch loss: 0.066952 Batch F1: 0.9411764705882353
Epoch:  103        8 Batch loss: 0.089164 Batch F1: 0.6666666666666666
Epoch:  103        9 Batch loss: 0.062244 Batch F1: 0.6666666666666666
Epoch:  103       10 Batch loss: 0.057570 Batch F1: 0.4444444444444445
Epoch:  103       11 Batch loss: 0.082512 Batch F1: 0.5
Epoch:  103       12 Batch loss: 0.070837 Batch F1: 0.923076923076923
Train Avg Loss  103: 0.071416

Train Avg F1  103: 0.6684557000733472

Val Avg Loss  103: 0.066447

Val Avg F1  103:  0.8193910256410257

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 104
--------------------------------------------------------------
Epoch:  104        1 Batch loss: 0.052403 Batch F1: 0.6666666666666666
Epoch:  104        2 Batch loss: 0.042941 Batch F1: 0.6666666666666666
Epoch:  104        3 Batch loss: 0.059614 Batch F1: 0.2857142857142857
Epoch:  104        4 Batch loss: 0.098737 Batch F1: 0.0
Epoch:  104        5 Batch loss: 0.100541 Batch F1: 0.375
Epoch:  104        6 Batch loss: 0.073436 Batch F1: 0.9411764705882353
Epoch:  104        7 Batch loss: 0.073840 Batch F1: 0.8
Epoch:  104        8 Batch loss: 0.059885 Batch F1: 0.8571428571428571
Epoch:  104        9 Batch loss: 0.098324 Batch F1: 0.88
Epoch:  104       10 Batch loss: 0.076988 Batch F1: 0.8750000000000001
Epoch:  104       11 Batch loss: 0.071037 Batch F1: 0.8421052631578948
Epoch:  104       12 Batch loss: 0.090655 Batch F1: 0.8235294117647058
Train Avg Loss  104: 0.074867

Train Avg F1  104: 0.667750135141776

Val Avg Loss  104: 0.070652

Val Avg F1  104:  0.9264705882352942

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 105
--------------------------------------------------------------
Epoch:  105        1 Batch loss: 0.068263 Batch F1: 0.9523809523809523
Epoch:  105        2 Batch loss: 0.092375 Batch F1: 0.923076923076923
Epoch:  105        3 Batch loss: 0.073303 Batch F1: 0.888888888888889
Epoch:  105        4 Batch loss: 0.060846 Batch F1: 1.0
Epoch:  105        5 Batch loss: 0.060243 Batch F1: 0.923076923076923
Epoch:  105        6 Batch loss: 0.069046 Batch F1: 0.7368421052631579
Epoch:  105        7 Batch loss: 0.071618 Batch F1: 0.7058823529411764
Epoch:  105        8 Batch loss: 0.074419 Batch F1: 0.8571428571428571
Epoch:  105        9 Batch loss: 0.066495 Batch F1: 0.7272727272727273
Epoch:  105       10 Batch loss: 0.062028 Batch F1: 0.6666666666666666
Epoch:  105       11 Batch loss: 0.060349 Batch F1: 0.6666666666666666
Epoch:  105       12 Batch loss: 0.078010 Batch F1: 0.0
Train Avg Loss  105: 0.069750

Train Avg F1  105: 0.7539914219480782

Val Avg Loss  105: 0.068557

Val Avg F1  105:  0.6809637730690362

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 106
--------------------------------------------------------------
Epoch:  106        1 Batch loss: 0.084967 Batch F1: 0.5333333333333333
Epoch:  106        2 Batch loss: 0.066104 Batch F1: 0.9411764705882353
Epoch:  106        3 Batch loss: 0.087865 Batch F1: 0.8888888888888888
Epoch:  106        4 Batch loss: 0.070057 Batch F1: 0.5454545454545454
Epoch:  106        5 Batch loss: 0.056213 Batch F1: 0.0
Epoch:  106        6 Batch loss: 0.073840 Batch F1: 0.0
Epoch:  106        7 Batch loss: 0.091723 Batch F1: 0.0
Epoch:  106        8 Batch loss: 0.098015 Batch F1: 0.13333333333333333
Epoch:  106        9 Batch loss: 0.110173 Batch F1: 0.761904761904762
Epoch:  106       10 Batch loss: 0.065716 Batch F1: 0.9333333333333333
Epoch:  106       11 Batch loss: 0.078440 Batch F1: 0.3636363636363636
Epoch:  106       12 Batch loss: 0.060860 Batch F1: 0.6
Train Avg Loss  106: 0.078664

Train Avg F1  106: 0.4750884192060662

Val Avg Loss  106: 0.071012

Val Avg F1  106:  0.5525389643036702

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 107
--------------------------------------------------------------
Epoch:  107        1 Batch loss: 0.092871 Batch F1: 0.19999999999999998
Epoch:  107        2 Batch loss: 0.061613 Batch F1: 0.2857142857142857
Epoch:  107        3 Batch loss: 0.095578 Batch F1: 0.375
Epoch:  107        4 Batch loss: 0.075224 Batch F1: 0.888888888888889
Epoch:  107        5 Batch loss: 0.069087 Batch F1: 1.0
Epoch:  107        6 Batch loss: 0.062294 Batch F1: 1.0
Epoch:  107        7 Batch loss: 0.063768 Batch F1: 0.9090909090909091
Epoch:  107        8 Batch loss: 0.079751 Batch F1: 0.7499999999999999
Epoch:  107        9 Batch loss: 0.072124 Batch F1: 0.6153846153846153
Epoch:  107       10 Batch loss: 0.106846 Batch F1: 0.15384615384615385
Epoch:  107       11 Batch loss: 0.084607 Batch F1: 0.5333333333333333
Epoch:  107       12 Batch loss: 0.060671 Batch F1: 0.7499999999999999
Train Avg Loss  107: 0.077036

Train Avg F1  107: 0.6217715155215154

Val Avg Loss  107: 0.065997

Val Avg F1  107:  0.5819327731092436

Optimal Val loss (Epoch 85): 0.06541894935071468

Epoch 108
--------------------------------------------------------------
Epoch:  108        1 Batch loss: 0.069278 Batch F1: 0.6153846153846153
Epoch:  108        2 Batch loss: 0.074351 Batch F1: 0.3076923076923077
Epoch:  108        3 Batch loss: 0.092695 Batch F1: 0.7058823529411764
Epoch:  108        4 Batch loss: 0.090135 Batch F1: 0.7499999999999999
Epoch:  108        5 Batch loss: 0.073594 Batch F1: 0.8571428571428571
Epoch:  108        6 Batch loss: 0.046229 Batch F1: 0.5714285714285715
Epoch:  108        7 Batch loss: 0.081826 Batch F1: 0.42857142857142855
Epoch:  108        8 Batch loss: 0.077699 Batch F1: 0.7777777777777778
Epoch:  108        9 Batch loss: 0.086700 Batch F1: 0.375
Epoch:  108       10 Batch loss: 0.049878 Batch F1: 1.0
Epoch:  108       11 Batch loss: 0.081446 Batch F1: 0.8750000000000001
Epoch:  108       12 Batch loss: 0.061506 Batch F1: 0.7499999999999999
Train Avg Loss  108: 0.073778

Train Avg F1  108: 0.6678233259115611

Val Avg Loss  108: 0.065360

Val Avg F1  108:  0.8826756576756577

Optimal Val loss (Epoch 108): 0.06535973772406578

Epoch 109
--------------------------------------------------------------
Epoch:  109        1 Batch loss: 0.067807 Batch F1: 0.8571428571428571
Epoch:  109        2 Batch loss: 0.084317 Batch F1: 0.4615384615384615
Epoch:  109        3 Batch loss: 0.075057 Batch F1: 0.5882352941176471
Epoch:  109        4 Batch loss: 0.081983 Batch F1: 0.5333333333333333
Epoch:  109        5 Batch loss: 0.062924 Batch F1: 0.4444444444444445
Epoch:  109        6 Batch loss: 0.071198 Batch F1: 0.7142857142857143
Epoch:  109        7 Batch loss: 0.045949 Batch F1: 1.0
Epoch:  109        8 Batch loss: 0.079073 Batch F1: 0.42857142857142855
Epoch:  109        9 Batch loss: 0.075568 Batch F1: 0.5714285714285715
Epoch:  109       10 Batch loss: 0.077281 Batch F1: 0.4615384615384615
Epoch:  109       11 Batch loss: 0.064943 Batch F1: 0.8235294117647058
Epoch:  109       12 Batch loss: 0.063656 Batch F1: 1.0
Train Avg Loss  109: 0.070813

Train Avg F1  109: 0.6570039981804687

Val Avg Loss  109: 0.066582

Val Avg F1  109:  0.8696630167218402

Optimal Val loss (Epoch 108): 0.06535973772406578

Epoch 110
--------------------------------------------------------------
Epoch:  110        1 Batch loss: 0.068072 Batch F1: 0.9600000000000001
Epoch:  110        2 Batch loss: 0.092381 Batch F1: 0.7368421052631579
Epoch:  110        3 Batch loss: 0.073626 Batch F1: 0.9333333333333333
Epoch:  110        4 Batch loss: 0.064033 Batch F1: 0.7777777777777778
Epoch:  110        5 Batch loss: 0.070130 Batch F1: 0.8571428571428571
Epoch:  110        6 Batch loss: 0.061141 Batch F1: 0.6666666666666666
Epoch:  110        7 Batch loss: 0.093766 Batch F1: 0.4
Epoch:  110        8 Batch loss: 0.051460 Batch F1: 0.0
Epoch:  110        9 Batch loss: 0.069342 Batch F1: 0.33333333333333337
Epoch:  110       10 Batch loss: 0.057129 Batch F1: 0.6666666666666666
Epoch:  110       11 Batch loss: 0.079220 Batch F1: 0.8235294117647058
Epoch:  110       12 Batch loss: 0.055086 Batch F1: 1.0
Train Avg Loss  110: 0.069615

Train Avg F1  110: 0.6796076793290414

Val Avg Loss  110: 0.064481

Val Avg F1  110:  0.9080357142857143

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 111
--------------------------------------------------------------
Epoch:  111        1 Batch loss: 0.055920 Batch F1: 0.7499999999999999
Epoch:  111        2 Batch loss: 0.075323 Batch F1: 0.6666666666666666
Epoch:  111        3 Batch loss: 0.063291 Batch F1: 0.8333333333333333
Epoch:  111        4 Batch loss: 0.081153 Batch F1: 0.7058823529411764
Epoch:  111        5 Batch loss: 0.068371 Batch F1: 0.6153846153846153
Epoch:  111        6 Batch loss: 0.061744 Batch F1: 0.9565217391304348
Epoch:  111        7 Batch loss: 0.073116 Batch F1: 0.9411764705882353
Epoch:  111        8 Batch loss: 0.085060 Batch F1: 0.8571428571428571
Epoch:  111        9 Batch loss: 0.068983 Batch F1: 0.9523809523809523
Epoch:  111       10 Batch loss: 0.068739 Batch F1: 0.9473684210526316
Epoch:  111       11 Batch loss: 0.076367 Batch F1: 0.6153846153846153
Epoch:  111       12 Batch loss: 0.060358 Batch F1: 0.7272727272727273
Train Avg Loss  111: 0.069869

Train Avg F1  111: 0.7973762292731871

Val Avg Loss  111: 0.066665

Val Avg F1  111:  0.5943223443223442

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 112
--------------------------------------------------------------
Epoch:  112        1 Batch loss: 0.046443 Batch F1: 0.4
Epoch:  112        2 Batch loss: 0.068689 Batch F1: 0.6666666666666666
Epoch:  112        3 Batch loss: 0.099333 Batch F1: 0.5714285714285715
Epoch:  112        4 Batch loss: 0.063474 Batch F1: 0.7142857142857143
Epoch:  112        5 Batch loss: 0.069542 Batch F1: 0.7142857142857143
Epoch:  112        6 Batch loss: 0.067756 Batch F1: 0.6666666666666666
Epoch:  112        7 Batch loss: 0.087920 Batch F1: 0.5263157894736842
Epoch:  112        8 Batch loss: 0.065152 Batch F1: 0.923076923076923
Epoch:  112        9 Batch loss: 0.056407 Batch F1: 0.7692307692307693
Epoch:  112       10 Batch loss: 0.075900 Batch F1: 0.4615384615384615
Epoch:  112       11 Batch loss: 0.070698 Batch F1: 0.3636363636363636
Epoch:  112       12 Batch loss: 0.090216 Batch F1: 0.3636363636363636
Train Avg Loss  112: 0.071794

Train Avg F1  112: 0.5950640003271582

Val Avg Loss  112: 0.064820

Val Avg F1  112:  0.692496229260935

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 113
--------------------------------------------------------------
Epoch:  113        1 Batch loss: 0.043920 Batch F1: 0.7499999999999999
Epoch:  113        2 Batch loss: 0.060655 Batch F1: 0.7499999999999999
Epoch:  113        3 Batch loss: 0.069714 Batch F1: 0.625
Epoch:  113        4 Batch loss: 0.093276 Batch F1: 0.8
Epoch:  113        5 Batch loss: 0.077985 Batch F1: 0.9
Epoch:  113        6 Batch loss: 0.080123 Batch F1: 0.8333333333333333
Epoch:  113        7 Batch loss: 0.058806 Batch F1: 0.8571428571428571
Epoch:  113        8 Batch loss: 0.077650 Batch F1: 0.888888888888889
Epoch:  113        9 Batch loss: 0.076401 Batch F1: 0.6153846153846153
Epoch:  113       10 Batch loss: 0.064610 Batch F1: 0.25
Epoch:  113       11 Batch loss: 0.082336 Batch F1: 0.42857142857142855
Epoch:  113       12 Batch loss: 0.064036 Batch F1: 0.923076923076923
Train Avg Loss  113: 0.070793

Train Avg F1  113: 0.7184498371998371

Val Avg Loss  113: 0.069218

Val Avg F1  113:  0.9206088029617441

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 114
--------------------------------------------------------------
Epoch:  114        1 Batch loss: 0.074110 Batch F1: 0.9333333333333333
Epoch:  114        2 Batch loss: 0.064151 Batch F1: 0.8235294117647058
Epoch:  114        3 Batch loss: 0.086511 Batch F1: 0.5333333333333333
Epoch:  114        4 Batch loss: 0.056409 Batch F1: 0.6153846153846153
Epoch:  114        5 Batch loss: 0.056723 Batch F1: 0.33333333333333337
Epoch:  114        6 Batch loss: 0.090429 Batch F1: 0.47058823529411764
Epoch:  114        7 Batch loss: 0.063039 Batch F1: 0.9
Epoch:  114        8 Batch loss: 0.063492 Batch F1: 0.923076923076923
Epoch:  114        9 Batch loss: 0.074916 Batch F1: 0.9
Epoch:  114       10 Batch loss: 0.072446 Batch F1: 0.9411764705882353
Epoch:  114       11 Batch loss: 0.062143 Batch F1: 0.8
Epoch:  114       12 Batch loss: 0.074071 Batch F1: 0.5454545454545454
Train Avg Loss  114: 0.069870

Train Avg F1  114: 0.726600850130262

Val Avg Loss  114: 0.069592

Val Avg F1  114:  0.6011904761904762

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 115
--------------------------------------------------------------
Epoch:  115        1 Batch loss: 0.092035 Batch F1: 0.7000000000000001
Epoch:  115        2 Batch loss: 0.070487 Batch F1: 0.5
Epoch:  115        3 Batch loss: 0.068247 Batch F1: 0.4
Epoch:  115        4 Batch loss: 0.073316 Batch F1: 0.9523809523809523
Epoch:  115        5 Batch loss: 0.073257 Batch F1: 1.0
Epoch:  115        6 Batch loss: 0.076368 Batch F1: 0.8571428571428571
Epoch:  115        7 Batch loss: 0.062580 Batch F1: 0.2857142857142857
Epoch:  115        8 Batch loss: 0.101009 Batch F1: 0.0
Epoch:  115        9 Batch loss: 0.056252 Batch F1: 0.0
Epoch:  115       10 Batch loss: 0.083703 Batch F1: 0.625
Epoch:  115       11 Batch loss: 0.072063 Batch F1: 0.3636363636363636
Epoch:  115       12 Batch loss: 0.073004 Batch F1: 0.5
Train Avg Loss  115: 0.075193

Train Avg F1  115: 0.5153228715728715

Val Avg Loss  115: 0.067657

Val Avg F1  115:  0.9160912190963342

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 116
--------------------------------------------------------------
Epoch:  116        1 Batch loss: 0.090788 Batch F1: 0.923076923076923
Epoch:  116        2 Batch loss: 0.075591 Batch F1: 1.0
Epoch:  116        3 Batch loss: 0.079050 Batch F1: 0.9166666666666666
Epoch:  116        4 Batch loss: 0.085828 Batch F1: 0.8421052631578948
Epoch:  116        5 Batch loss: 0.077262 Batch F1: 0.9090909090909091
Epoch:  116        6 Batch loss: 0.075857 Batch F1: 0.7142857142857143
Epoch:  116        7 Batch loss: 0.085204 Batch F1: 0.0
Epoch:  116        8 Batch loss: 0.088727 Batch F1: 0.5882352941176471
Epoch:  116        9 Batch loss: 0.091820 Batch F1: 0.6
Epoch:  116       10 Batch loss: 0.077891 Batch F1: 0.8571428571428571
Epoch:  116       11 Batch loss: 0.057728 Batch F1: 0.4444444444444445
Epoch:  116       12 Batch loss: 0.048736 Batch F1: 0.7499999999999999
Train Avg Loss  116: 0.077873

Train Avg F1  116: 0.7120873393319213

Val Avg Loss  116: 0.074847

Val Avg F1  116:  0.5664278531925591

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 117
--------------------------------------------------------------
Epoch:  117        1 Batch loss: 0.071740 Batch F1: 0.6153846153846153
Epoch:  117        2 Batch loss: 0.059136 Batch F1: 0.0
Epoch:  117        3 Batch loss: 0.076522 Batch F1: 0.6666666666666666
Epoch:  117        4 Batch loss: 0.117532 Batch F1: 0.47619047619047616
Epoch:  117        5 Batch loss: 0.056874 Batch F1: 0.6666666666666666
Epoch:  117        6 Batch loss: 0.060830 Batch F1: 0.9411764705882353
Epoch:  117        7 Batch loss: 0.075667 Batch F1: 0.9473684210526316
Epoch:  117        8 Batch loss: 0.052338 Batch F1: 1.0
Epoch:  117        9 Batch loss: 0.110490 Batch F1: 0.4
Epoch:  117       10 Batch loss: 0.079175 Batch F1: 0.5
Epoch:  117       11 Batch loss: 0.090677 Batch F1: 0.3076923076923077
Epoch:  117       12 Batch loss: 0.059312 Batch F1: 0.888888888888889
Train Avg Loss  117: 0.075858

Train Avg F1  117: 0.6175028760942074

Val Avg Loss  117: 0.065515

Val Avg F1  117:  0.8744245524296677

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 118
--------------------------------------------------------------
Epoch:  118        1 Batch loss: 0.081559 Batch F1: 0.7499999999999999
Epoch:  118        2 Batch loss: 0.076647 Batch F1: 0.8235294117647058
Epoch:  118        3 Batch loss: 0.056409 Batch F1: 0.9333333333333333
Epoch:  118        4 Batch loss: 0.096465 Batch F1: 0.761904761904762
Epoch:  118        5 Batch loss: 0.084425 Batch F1: 0.8421052631578948
Epoch:  118        6 Batch loss: 0.069405 Batch F1: 0.823529411764706
Epoch:  118        7 Batch loss: 0.072003 Batch F1: 0.8750000000000001
Epoch:  118        8 Batch loss: 0.079090 Batch F1: 0.9411764705882353
Epoch:  118        9 Batch loss: 0.072100 Batch F1: 0.9600000000000001
Epoch:  118       10 Batch loss: 0.051471 Batch F1: 0.6666666666666666
Epoch:  118       11 Batch loss: 0.041243 Batch F1: 0.4
Epoch:  118       12 Batch loss: 0.082188 Batch F1: 0.5714285714285715
Train Avg Loss  118: 0.071917

Train Avg F1  118: 0.7790561575507396

Val Avg Loss  118: 0.071270

Val Avg F1  118:  0.5858974358974359

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 119
--------------------------------------------------------------
Epoch:  119        1 Batch loss: 0.058835 Batch F1: 0.7499999999999999
Epoch:  119        2 Batch loss: 0.082751 Batch F1: 0.5882352941176471
Epoch:  119        3 Batch loss: 0.088441 Batch F1: 0.8421052631578948
Epoch:  119        4 Batch loss: 0.076102 Batch F1: 1.0
Epoch:  119        5 Batch loss: 0.081077 Batch F1: 0.2222222222222222
Epoch:  119        6 Batch loss: 0.071880 Batch F1: 0.0
Epoch:  119        7 Batch loss: 0.068679 Batch F1: 0.7142857142857143
Epoch:  119        8 Batch loss: 0.109704 Batch F1: 0.47058823529411764
Epoch:  119        9 Batch loss: 0.083328 Batch F1: 0.5882352941176471
Epoch:  119       10 Batch loss: 0.061780 Batch F1: 0.7272727272727273
Epoch:  119       11 Batch loss: 0.054439 Batch F1: 1.0
Epoch:  119       12 Batch loss: 0.076098 Batch F1: 0.8
Train Avg Loss  119: 0.076093

Train Avg F1  119: 0.6419120625389975

Val Avg Loss  119: 0.067781

Val Avg F1  119:  0.5931818181818181

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 120
--------------------------------------------------------------
Epoch:  120        1 Batch loss: 0.086693 Batch F1: 0.5333333333333333
Epoch:  120        2 Batch loss: 0.046313 Batch F1: 0.4
Epoch:  120        3 Batch loss: 0.069276 Batch F1: 0.6666666666666666
Epoch:  120        4 Batch loss: 0.104198 Batch F1: 0.4
Epoch:  120        5 Batch loss: 0.057709 Batch F1: 0.33333333333333337
Epoch:  120        6 Batch loss: 0.071802 Batch F1: 0.5714285714285715
Epoch:  120        7 Batch loss: 0.078263 Batch F1: 0.7272727272727273
Epoch:  120        8 Batch loss: 0.062678 Batch F1: 0.8571428571428571
Epoch:  120        9 Batch loss: 0.070883 Batch F1: 0.9411764705882353
Epoch:  120       10 Batch loss: 0.066765 Batch F1: 0.923076923076923
Epoch:  120       11 Batch loss: 0.074223 Batch F1: 0.7777777777777778
Epoch:  120       12 Batch loss: 0.078110 Batch F1: 0.8750000000000001
Train Avg Loss  120: 0.072243

Train Avg F1  120: 0.6671840550517022

Val Avg Loss  120: 0.066417

Val Avg F1  120:  0.7575

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 121
--------------------------------------------------------------
Epoch:  121        1 Batch loss: 0.088857 Batch F1: 0.5333333333333333
Epoch:  121        2 Batch loss: 0.064315 Batch F1: 0.8
Epoch:  121        3 Batch loss: 0.067783 Batch F1: 0.2857142857142857
Epoch:  121        4 Batch loss: 0.064462 Batch F1: 0.6666666666666666
Epoch:  121        5 Batch loss: 0.100677 Batch F1: 0.15384615384615385
Epoch:  121        6 Batch loss: 0.080919 Batch F1: 0.625
Epoch:  121        7 Batch loss: 0.053655 Batch F1: 1.0
Epoch:  121        8 Batch loss: 0.086521 Batch F1: 0.9230769230769231
Epoch:  121        9 Batch loss: 0.070861 Batch F1: 0.9090909090909091
Epoch:  121       10 Batch loss: 0.053471 Batch F1: 1.0
Epoch:  121       11 Batch loss: 0.073538 Batch F1: 0.9411764705882353
Epoch:  121       12 Batch loss: 0.062236 Batch F1: 0.7692307692307693
Train Avg Loss  121: 0.072275

Train Avg F1  121: 0.7172612926289398

Val Avg Loss  121: 0.065693

Val Avg F1  121:  0.7315705128205128

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 122
--------------------------------------------------------------
Epoch:  122        1 Batch loss: 0.065360 Batch F1: 0.7272727272727273
Epoch:  122        2 Batch loss: 0.063364 Batch F1: 0.6666666666666666
Epoch:  122        3 Batch loss: 0.073896 Batch F1: 0.5714285714285715
Epoch:  122        4 Batch loss: 0.113068 Batch F1: 0.0
Epoch:  122        5 Batch loss: 0.083047 Batch F1: 0.5714285714285715
Epoch:  122        6 Batch loss: 0.068710 Batch F1: 0.9333333333333333
Epoch:  122        7 Batch loss: 0.094852 Batch F1: 0.846153846153846
Epoch:  122        8 Batch loss: 0.052783 Batch F1: 0.888888888888889
Epoch:  122        9 Batch loss: 0.059709 Batch F1: 0.9411764705882353
Epoch:  122       10 Batch loss: 0.051790 Batch F1: 0.7499999999999999
Epoch:  122       11 Batch loss: 0.087717 Batch F1: 0.8
Epoch:  122       12 Batch loss: 0.031340 Batch F1: 1.0
Train Avg Loss  122: 0.070470

Train Avg F1  122: 0.7246957563134034

Val Avg Loss  122: 0.064878

Val Avg F1  122:  0.7051169590643276

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 123
--------------------------------------------------------------
Epoch:  123        1 Batch loss: 0.052211 Batch F1: 0.8333333333333333
Epoch:  123        2 Batch loss: 0.071107 Batch F1: 0.7142857142857143
Epoch:  123        3 Batch loss: 0.052668 Batch F1: 0.5714285714285715
Epoch:  123        4 Batch loss: 0.075665 Batch F1: 0.5333333333333333
Epoch:  123        5 Batch loss: 0.050783 Batch F1: 0.2857142857142857
Epoch:  123        6 Batch loss: 0.099957 Batch F1: 0.782608695652174
Epoch:  123        7 Batch loss: 0.083598 Batch F1: 0.7999999999999999
Epoch:  123        8 Batch loss: 0.085251 Batch F1: 0.846153846153846
Epoch:  123        9 Batch loss: 0.073698 Batch F1: 0.8571428571428571
Epoch:  123       10 Batch loss: 0.067047 Batch F1: 0.7272727272727273
Epoch:  123       11 Batch loss: 0.061737 Batch F1: 0.6
Epoch:  123       12 Batch loss: 0.063251 Batch F1: 0.6
Train Avg Loss  123: 0.069748

Train Avg F1  123: 0.6792727803597368

Val Avg Loss  123: 0.066582

Val Avg F1  123:  0.5794075205839911

Optimal Val loss (Epoch 110): 0.06448078621178865

Epoch 124
--------------------------------------------------------------
Epoch:  124        1 Batch loss: 0.056133 Batch F1: 0.6666666666666666
Epoch:  124        2 Batch loss: 0.056953 Batch F1: 0.0
Epoch:  124        3 Batch loss: 0.072682 Batch F1: 0.625
Epoch:  124        4 Batch loss: 0.048449 Batch F1: 0.8571428571428571
Epoch:  124        5 Batch loss: 0.068324 Batch F1: 0.888888888888889
Epoch:  124        6 Batch loss: 0.055452 Batch F1: 0.8333333333333333
Epoch:  124        7 Batch loss: 0.087568 Batch F1: 0.7368421052631579
Epoch:  124        8 Batch loss: 0.084715 Batch F1: 0.7777777777777778
Epoch:  124        9 Batch loss: 0.087360 Batch F1: 0.8181818181818181
Epoch:  124       10 Batch loss: 0.055339 Batch F1: 1.0
Epoch:  124       11 Batch loss: 0.066811 Batch F1: 1.0
Epoch:  124       12 Batch loss: 0.094154 Batch F1: 0.4615384615384615
Train Avg Loss  124: 0.069495

Train Avg F1  124: 0.7221143257327468

Val Avg Loss  124: 0.064376

Val Avg F1  124:  0.6742063492063491

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 125
--------------------------------------------------------------
Epoch:  125        1 Batch loss: 0.062288 Batch F1: 0.888888888888889
Epoch:  125        2 Batch loss: 0.063203 Batch F1: 0.7142857142857143
Epoch:  125        3 Batch loss: 0.085294 Batch F1: 0.7000000000000001
Epoch:  125        4 Batch loss: 0.055897 Batch F1: 0.6666666666666666
Epoch:  125        5 Batch loss: 0.070730 Batch F1: 0.8
Epoch:  125        6 Batch loss: 0.055087 Batch F1: 0.9333333333333333
Epoch:  125        7 Batch loss: 0.068278 Batch F1: 0.8571428571428571
Epoch:  125        8 Batch loss: 0.068892 Batch F1: 0.5454545454545454
Epoch:  125        9 Batch loss: 0.046045 Batch F1: 0.0
Epoch:  125       10 Batch loss: 0.116622 Batch F1: 0.14285714285714288
Epoch:  125       11 Batch loss: 0.079863 Batch F1: 0.18181818181818182
Epoch:  125       12 Batch loss: 0.078389 Batch F1: 0.7142857142857143
Train Avg Loss  125: 0.070882

Train Avg F1  125: 0.5953944203944204

Val Avg Loss  125: 0.085832

Val Avg F1  125:  0.8241626794258373

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 126
--------------------------------------------------------------
Epoch:  126        1 Batch loss: 0.082230 Batch F1: 0.923076923076923
Epoch:  126        2 Batch loss: 0.067418 Batch F1: 0.8750000000000001
Epoch:  126        3 Batch loss: 0.075114 Batch F1: 0.33333333333333337
Epoch:  126        4 Batch loss: 0.077524 Batch F1: 0.0
Epoch:  126        5 Batch loss: 0.106811 Batch F1: 0.25
Epoch:  126        6 Batch loss: 0.074661 Batch F1: 0.8235294117647058
Epoch:  126        7 Batch loss: 0.084871 Batch F1: 0.8421052631578948
Epoch:  126        8 Batch loss: 0.071549 Batch F1: 0.8333333333333333
Epoch:  126        9 Batch loss: 0.060803 Batch F1: 0.7692307692307693
Epoch:  126       10 Batch loss: 0.086768 Batch F1: 0.42857142857142855
Epoch:  126       11 Batch loss: 0.067268 Batch F1: 0.4
Epoch:  126       12 Batch loss: 0.052365 Batch F1: 0.8333333333333333
Train Avg Loss  126: 0.075615

Train Avg F1  126: 0.6092928163168101

Val Avg Loss  126: 0.068177

Val Avg F1  126:  0.592857142857143

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 127
--------------------------------------------------------------
Epoch:  127        1 Batch loss: 0.083415 Batch F1: 0.5882352941176471
Epoch:  127        2 Batch loss: 0.075623 Batch F1: 0.5714285714285715
Epoch:  127        3 Batch loss: 0.090825 Batch F1: 0.782608695652174
Epoch:  127        4 Batch loss: 0.073491 Batch F1: 0.8235294117647058
Epoch:  127        5 Batch loss: 0.070440 Batch F1: 0.8
Epoch:  127        6 Batch loss: 0.073901 Batch F1: 0.8750000000000001
Epoch:  127        7 Batch loss: 0.069487 Batch F1: 1.0
Epoch:  127        8 Batch loss: 0.064384 Batch F1: 0.8333333333333333
Epoch:  127        9 Batch loss: 0.077214 Batch F1: 0.923076923076923
Epoch:  127       10 Batch loss: 0.071642 Batch F1: 1.0
Epoch:  127       11 Batch loss: 0.062579 Batch F1: 0.7272727272727273
Epoch:  127       12 Batch loss: 0.054925 Batch F1: 0.33333333333333337
Train Avg Loss  127: 0.072327

Train Avg F1  127: 0.7714848574982845

Val Avg Loss  127: 0.068272

Val Avg F1  127:  0.5877325289089995

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 128
--------------------------------------------------------------
Epoch:  128        1 Batch loss: 0.062948 Batch F1: 0.2857142857142857
Epoch:  128        2 Batch loss: 0.054887 Batch F1: 0.7692307692307693
Epoch:  128        3 Batch loss: 0.094250 Batch F1: 0.42857142857142855
Epoch:  128        4 Batch loss: 0.078414 Batch F1: 0.4615384615384615
Epoch:  128        5 Batch loss: 0.059012 Batch F1: 0.7692307692307693
Epoch:  128        6 Batch loss: 0.064487 Batch F1: 0.7499999999999999
Epoch:  128        7 Batch loss: 0.067471 Batch F1: 0.7692307692307693
Epoch:  128        8 Batch loss: 0.053739 Batch F1: 0.8333333333333333
Epoch:  128        9 Batch loss: 0.084313 Batch F1: 0.5333333333333333
Epoch:  128       10 Batch loss: 0.100523 Batch F1: 0.6666666666666666
Epoch:  128       11 Batch loss: 0.092220 Batch F1: 0.7058823529411765
Epoch:  128       12 Batch loss: 0.059715 Batch F1: 1.0
Train Avg Loss  128: 0.072665

Train Avg F1  128: 0.6643943474825827

Val Avg Loss  128: 0.067005

Val Avg F1  128:  0.5912247474747474

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 129
--------------------------------------------------------------
Epoch:  129        1 Batch loss: 0.085222 Batch F1: 0.19999999999999998
Epoch:  129        2 Batch loss: 0.075733 Batch F1: 0.0
Epoch:  129        3 Batch loss: 0.085903 Batch F1: 0.2666666666666667
Epoch:  129        4 Batch loss: 0.052076 Batch F1: 0.888888888888889
Epoch:  129        5 Batch loss: 0.068040 Batch F1: 0.9411764705882353
Epoch:  129        6 Batch loss: 0.104713 Batch F1: 0.8666666666666666
Epoch:  129        7 Batch loss: 0.071523 Batch F1: 0.9473684210526316
Epoch:  129        8 Batch loss: 0.054932 Batch F1: 0.9090909090909091
Epoch:  129        9 Batch loss: 0.077486 Batch F1: 0.7777777777777778
Epoch:  129       10 Batch loss: 0.046372 Batch F1: 0.888888888888889
Epoch:  129       11 Batch loss: 0.070532 Batch F1: 0.5454545454545454
Epoch:  129       12 Batch loss: 0.066828 Batch F1: 0.5
Train Avg Loss  129: 0.071613

Train Avg F1  129: 0.6443316029229341

Val Avg Loss  129: 0.071780

Val Avg F1  129:  0.5729166666666666

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 130
--------------------------------------------------------------
Epoch:  130        1 Batch loss: 0.063023 Batch F1: 0.8235294117647058
Epoch:  130        2 Batch loss: 0.068269 Batch F1: 0.6153846153846153
Epoch:  130        3 Batch loss: 0.082786 Batch F1: 0.42857142857142855
Epoch:  130        4 Batch loss: 0.067986 Batch F1: 0.9333333333333333
Epoch:  130        5 Batch loss: 0.091269 Batch F1: 0.9
Epoch:  130        6 Batch loss: 0.064639 Batch F1: 1.0
Epoch:  130        7 Batch loss: 0.060386 Batch F1: 0.7142857142857143
Epoch:  130        8 Batch loss: 0.095382 Batch F1: 0.5
Epoch:  130        9 Batch loss: 0.103958 Batch F1: 0.2857142857142857
Epoch:  130       10 Batch loss: 0.050320 Batch F1: 0.4
Epoch:  130       11 Batch loss: 0.081470 Batch F1: 0.6666666666666666
Epoch:  130       12 Batch loss: 0.038952 Batch F1: 1.0
Train Avg Loss  130: 0.072370

Train Avg F1  130: 0.6889571213100624

Val Avg Loss  130: 0.068389

Val Avg F1  130:  0.8533653846153846

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 131
--------------------------------------------------------------
Epoch:  131        1 Batch loss: 0.093349 Batch F1: 0.9166666666666666
Epoch:  131        2 Batch loss: 0.095457 Batch F1: 0.88
Epoch:  131        3 Batch loss: 0.080847 Batch F1: 0.9565217391304348
Epoch:  131        4 Batch loss: 0.063190 Batch F1: 1.0
Epoch:  131        5 Batch loss: 0.065523 Batch F1: 0.5
Epoch:  131        6 Batch loss: 0.033309 Batch F1: 0.8
Epoch:  131        7 Batch loss: 0.081666 Batch F1: 0.0
Epoch:  131        8 Batch loss: 0.064353 Batch F1: 0.0
Epoch:  131        9 Batch loss: 0.075022 Batch F1: 0.7058823529411764
Epoch:  131       10 Batch loss: 0.062132 Batch F1: 0.923076923076923
Epoch:  131       11 Batch loss: 0.092260 Batch F1: 0.7499999999999999
Epoch:  131       12 Batch loss: 0.068261 Batch F1: 0.33333333333333337
Train Avg Loss  131: 0.072947

Train Avg F1  131: 0.6471234179290445

Val Avg Loss  131: 0.065911

Val Avg F1  131:  0.5923076923076923

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 132
--------------------------------------------------------------
Epoch:  132        1 Batch loss: 0.088508 Batch F1: 0.4
Epoch:  132        2 Batch loss: 0.083478 Batch F1: 0.33333333333333337
Epoch:  132        3 Batch loss: 0.061989 Batch F1: 0.5
Epoch:  132        4 Batch loss: 0.075027 Batch F1: 0.8571428571428571
Epoch:  132        5 Batch loss: 0.062177 Batch F1: 1.0
Epoch:  132        6 Batch loss: 0.075424 Batch F1: 0.5714285714285715
Epoch:  132        7 Batch loss: 0.066065 Batch F1: 0.6153846153846153
Epoch:  132        8 Batch loss: 0.089256 Batch F1: 0.4
Epoch:  132        9 Batch loss: 0.059490 Batch F1: 0.7272727272727273
Epoch:  132       10 Batch loss: 0.068133 Batch F1: 0.4
Epoch:  132       11 Batch loss: 0.066085 Batch F1: 0.8571428571428571
Epoch:  132       12 Batch loss: 0.072218 Batch F1: 0.8695652173913044
Train Avg Loss  132: 0.072321

Train Avg F1  132: 0.6276058482580222

Val Avg Loss  132: 0.065278

Val Avg F1  132:  0.8127705627705628

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 133
--------------------------------------------------------------
Epoch:  133        1 Batch loss: 0.066863 Batch F1: 0.6666666666666666
Epoch:  133        2 Batch loss: 0.076248 Batch F1: 0.7272727272727273
Epoch:  133        3 Batch loss: 0.058979 Batch F1: 1.0
Epoch:  133        4 Batch loss: 0.053499 Batch F1: 1.0
Epoch:  133        5 Batch loss: 0.068395 Batch F1: 0.6666666666666666
Epoch:  133        6 Batch loss: 0.066672 Batch F1: 0.7142857142857143
Epoch:  133        7 Batch loss: 0.063436 Batch F1: 0.6666666666666666
Epoch:  133        8 Batch loss: 0.057161 Batch F1: 0.4444444444444445
Epoch:  133        9 Batch loss: 0.090852 Batch F1: 0.7499999999999999
Epoch:  133       10 Batch loss: 0.077974 Batch F1: 0.9473684210526316
Epoch:  133       11 Batch loss: 0.071422 Batch F1: 0.6666666666666666
Epoch:  133       12 Batch loss: 0.110150 Batch F1: 0.18181818181818182
Train Avg Loss  133: 0.071804

Train Avg F1  133: 0.7026546796283638

Val Avg Loss  133: 0.065563

Val Avg F1  133:  0.5491677912730544

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 134
--------------------------------------------------------------
Epoch:  134        1 Batch loss: 0.061136 Batch F1: 0.4444444444444445
Epoch:  134        2 Batch loss: 0.063383 Batch F1: 0.5
Epoch:  134        3 Batch loss: 0.073646 Batch F1: 0.5714285714285715
Epoch:  134        4 Batch loss: 0.082004 Batch F1: 0.5333333333333333
Epoch:  134        5 Batch loss: 0.069181 Batch F1: 0.4444444444444445
Epoch:  134        6 Batch loss: 0.084436 Batch F1: 0.4615384615384615
Epoch:  134        7 Batch loss: 0.064824 Batch F1: 0.8
Epoch:  134        8 Batch loss: 0.068814 Batch F1: 0.8
Epoch:  134        9 Batch loss: 0.080582 Batch F1: 0.8421052631578948
Epoch:  134       10 Batch loss: 0.063323 Batch F1: 0.7142857142857143
Epoch:  134       11 Batch loss: 0.068902 Batch F1: 0.7692307692307693
Epoch:  134       12 Batch loss: 0.085784 Batch F1: 0.9523809523809523
Train Avg Loss  134: 0.072168

Train Avg F1  134: 0.6527659961870488

Val Avg Loss  134: 0.065071

Val Avg F1  134:  0.9021645021645022

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 135
--------------------------------------------------------------
Epoch:  135        1 Batch loss: 0.067863 Batch F1: 1.0
Epoch:  135        2 Batch loss: 0.068927 Batch F1: 0.9333333333333333
Epoch:  135        3 Batch loss: 0.057595 Batch F1: 0.6666666666666666
Epoch:  135        4 Batch loss: 0.057762 Batch F1: 0.8
Epoch:  135        5 Batch loss: 0.121782 Batch F1: 0.33333333333333337
Epoch:  135        6 Batch loss: 0.087023 Batch F1: 0.8
Epoch:  135        7 Batch loss: 0.061881 Batch F1: 1.0
Epoch:  135        8 Batch loss: 0.087108 Batch F1: 0.9523809523809523
Epoch:  135        9 Batch loss: 0.056996 Batch F1: 1.0
Epoch:  135       10 Batch loss: 0.060143 Batch F1: 0.6
Epoch:  135       11 Batch loss: 0.095148 Batch F1: 0.19999999999999998
Epoch:  135       12 Batch loss: 0.058261 Batch F1: 0.8333333333333333
Train Avg Loss  135: 0.073374

Train Avg F1  135: 0.759920634920635

Val Avg Loss  135: 0.068245

Val Avg F1  135:  0.5764705882352941

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 136
--------------------------------------------------------------
Epoch:  136        1 Batch loss: 0.101050 Batch F1: 0.631578947368421
Epoch:  136        2 Batch loss: 0.065916 Batch F1: 0.6153846153846153
Epoch:  136        3 Batch loss: 0.070503 Batch F1: 0.9523809523809523
Epoch:  136        4 Batch loss: 0.069059 Batch F1: 1.0
Epoch:  136        5 Batch loss: 0.070489 Batch F1: 0.9166666666666666
Epoch:  136        6 Batch loss: 0.063197 Batch F1: 0.6666666666666665
Epoch:  136        7 Batch loss: 0.079050 Batch F1: 0.3636363636363636
Epoch:  136        8 Batch loss: 0.076986 Batch F1: 0.2222222222222222
Epoch:  136        9 Batch loss: 0.075781 Batch F1: 0.6666666666666666
Epoch:  136       10 Batch loss: 0.071467 Batch F1: 1.0
Epoch:  136       11 Batch loss: 0.075963 Batch F1: 0.7142857142857143
Epoch:  136       12 Batch loss: 0.078901 Batch F1: 0.6666666666666666
Train Avg Loss  136: 0.074864

Train Avg F1  136: 0.7013462901620797

Val Avg Loss  136: 0.073294

Val Avg F1  136:  0.5528812974465149

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 137
--------------------------------------------------------------
Epoch:  137        1 Batch loss: 0.054855 Batch F1: 0.8571428571428571
Epoch:  137        2 Batch loss: 0.083328 Batch F1: 0.5714285714285715
Epoch:  137        3 Batch loss: 0.061228 Batch F1: 0.6153846153846153
Epoch:  137        4 Batch loss: 0.097437 Batch F1: 0.8695652173913044
Epoch:  137        5 Batch loss: 0.107376 Batch F1: 0.8
Epoch:  137        6 Batch loss: 0.075169 Batch F1: 0.4
Epoch:  137        7 Batch loss: 0.057423 Batch F1: 0.6666666666666666
Epoch:  137        8 Batch loss: 0.136446 Batch F1: 0.0
Epoch:  137        9 Batch loss: 0.073271 Batch F1: 0.0
Epoch:  137       10 Batch loss: 0.072326 Batch F1: 0.7692307692307693
Epoch:  137       11 Batch loss: 0.079465 Batch F1: 0.888888888888889
Epoch:  137       12 Batch loss: 0.081291 Batch F1: 0.9333333333333333
Train Avg Loss  137: 0.081635

Train Avg F1  137: 0.614303409955584

Val Avg Loss  137: 0.070471

Val Avg F1  137:  0.8681512605042017

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 138
--------------------------------------------------------------
Epoch:  138        1 Batch loss: 0.083244 Batch F1: 0.9166666666666666
Epoch:  138        2 Batch loss: 0.070005 Batch F1: 0.6153846153846153
Epoch:  138        3 Batch loss: 0.103051 Batch F1: 0.2857142857142857
Epoch:  138        4 Batch loss: 0.075779 Batch F1: 0.5
Epoch:  138        5 Batch loss: 0.074942 Batch F1: 0.923076923076923
Epoch:  138        6 Batch loss: 0.075168 Batch F1: 0.5
Epoch:  138        7 Batch loss: 0.065144 Batch F1: 0.7142857142857143
Epoch:  138        8 Batch loss: 0.079284 Batch F1: 0.2222222222222222
Epoch:  138        9 Batch loss: 0.070525 Batch F1: 0.8
Epoch:  138       10 Batch loss: 0.067962 Batch F1: 0.7058823529411764
Epoch:  138       11 Batch loss: 0.053415 Batch F1: 0.888888888888889
Epoch:  138       12 Batch loss: 0.066750 Batch F1: 0.7272727272727273
Train Avg Loss  138: 0.073772

Train Avg F1  138: 0.6499495330377684

Val Avg Loss  138: 0.067810

Val Avg F1  138:  0.8392857142857143

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 139
--------------------------------------------------------------
Epoch:  139        1 Batch loss: 0.082719 Batch F1: 0.8235294117647058
Epoch:  139        2 Batch loss: 0.043430 Batch F1: 1.0
Epoch:  139        3 Batch loss: 0.084648 Batch F1: 0.33333333333333337
Epoch:  139        4 Batch loss: 0.060465 Batch F1: 0.7142857142857143
Epoch:  139        5 Batch loss: 0.062071 Batch F1: 0.6
Epoch:  139        6 Batch loss: 0.068771 Batch F1: 0.7499999999999999
Epoch:  139        7 Batch loss: 0.064158 Batch F1: 1.0
Epoch:  139        8 Batch loss: 0.074301 Batch F1: 0.25
Epoch:  139        9 Batch loss: 0.106452 Batch F1: 0.35294117647058826
Epoch:  139       10 Batch loss: 0.068836 Batch F1: 0.6666666666666666
Epoch:  139       11 Batch loss: 0.088856 Batch F1: 0.5
Epoch:  139       12 Batch loss: 0.069220 Batch F1: 0.9333333333333333
Train Avg Loss  139: 0.072827

Train Avg F1  139: 0.6603408029878618

Val Avg Loss  139: 0.068197

Val Avg F1  139:  0.9314938684503902

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 140
--------------------------------------------------------------
Epoch:  140        1 Batch loss: 0.072392 Batch F1: 0.9333333333333333
Epoch:  140        2 Batch loss: 0.083539 Batch F1: 0.631578947368421
Epoch:  140        3 Batch loss: 0.054965 Batch F1: 0.33333333333333337
Epoch:  140        4 Batch loss: 0.102901 Batch F1: 0.47058823529411764
Epoch:  140        5 Batch loss: 0.060666 Batch F1: 0.923076923076923
Epoch:  140        6 Batch loss: 0.073212 Batch F1: 0.5333333333333333
Epoch:  140        7 Batch loss: 0.070313 Batch F1: 0.7142857142857143
Epoch:  140        8 Batch loss: 0.057617 Batch F1: 0.7272727272727273
Epoch:  140        9 Batch loss: 0.075320 Batch F1: 0.7368421052631579
Epoch:  140       10 Batch loss: 0.071070 Batch F1: 0.8235294117647058
Epoch:  140       11 Batch loss: 0.062237 Batch F1: 0.9090909090909091
Epoch:  140       12 Batch loss: 0.064726 Batch F1: 0.923076923076923
Train Avg Loss  140: 0.070747

Train Avg F1  140: 0.7216118247077999

Val Avg Loss  140: 0.067328

Val Avg F1  140:  0.8678571428571428

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 141
--------------------------------------------------------------
Epoch:  141        1 Batch loss: 0.087962 Batch F1: 0.8421052631578948
Epoch:  141        2 Batch loss: 0.060830 Batch F1: 0.8750000000000001
Epoch:  141        3 Batch loss: 0.057713 Batch F1: 0.5454545454545454
Epoch:  141        4 Batch loss: 0.092079 Batch F1: 0.631578947368421
Epoch:  141        5 Batch loss: 0.044892 Batch F1: 0.6666666666666666
Epoch:  141        6 Batch loss: 0.078362 Batch F1: 0.761904761904762
Epoch:  141        7 Batch loss: 0.060523 Batch F1: 1.0
Epoch:  141        8 Batch loss: 0.067329 Batch F1: 0.9411764705882353
Epoch:  141        9 Batch loss: 0.082531 Batch F1: 0.4615384615384615
Epoch:  141       10 Batch loss: 0.075777 Batch F1: 0.2222222222222222
Epoch:  141       11 Batch loss: 0.082811 Batch F1: 0.5
Epoch:  141       12 Batch loss: 0.055228 Batch F1: 0.8571428571428571
Train Avg Loss  141: 0.070503

Train Avg F1  141: 0.6920658496703389

Val Avg Loss  141: 0.064811

Val Avg F1  141:  0.7433823529411764

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 142
--------------------------------------------------------------
Epoch:  142        1 Batch loss: 0.072685 Batch F1: 0.7368421052631579
Epoch:  142        2 Batch loss: 0.071181 Batch F1: 0.9655172413793104
Epoch:  142        3 Batch loss: 0.083339 Batch F1: 0.875
Epoch:  142        4 Batch loss: 0.046409 Batch F1: 0.8571428571428571
Epoch:  142        5 Batch loss: 0.073829 Batch F1: 0.5
Epoch:  142        6 Batch loss: 0.111632 Batch F1: 0.4210526315789474
Epoch:  142        7 Batch loss: 0.066573 Batch F1: 0.6153846153846153
Epoch:  142        8 Batch loss: 0.092258 Batch F1: 0.6666666666666666
Epoch:  142        9 Batch loss: 0.080308 Batch F1: 0.7499999999999999
Epoch:  142       10 Batch loss: 0.066495 Batch F1: 0.888888888888889
Epoch:  142       11 Batch loss: 0.076025 Batch F1: 0.6666666666666666
Epoch:  142       12 Batch loss: 0.071822 Batch F1: 0.2857142857142857
Train Avg Loss  142: 0.076046

Train Avg F1  142: 0.685739663223783

Val Avg Loss  142: 0.078123

Val Avg F1  142:  0.0

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 143
--------------------------------------------------------------
Epoch:  143        1 Batch loss: 0.077674 Batch F1: 0.0
Epoch:  143        2 Batch loss: 0.067825 Batch F1: 0.25
Epoch:  143        3 Batch loss: 0.073827 Batch F1: 0.5
Epoch:  143        4 Batch loss: 0.076986 Batch F1: 0.625
Epoch:  143        5 Batch loss: 0.078456 Batch F1: 0.5333333333333333
Epoch:  143        6 Batch loss: 0.059824 Batch F1: 0.6666666666666666
Epoch:  143        7 Batch loss: 0.078203 Batch F1: 0.888888888888889
Epoch:  143        8 Batch loss: 0.082476 Batch F1: 0.923076923076923
Epoch:  143        9 Batch loss: 0.082646 Batch F1: 0.7272727272727273
Epoch:  143       10 Batch loss: 0.067950 Batch F1: 0.8
Epoch:  143       11 Batch loss: 0.086705 Batch F1: 0.8235294117647058
Epoch:  143       12 Batch loss: 0.064129 Batch F1: 0.6
Train Avg Loss  143: 0.074725

Train Avg F1  143: 0.6114806625836037

Val Avg Loss  143: 0.068145

Val Avg F1  143:  0.6000000000000001

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 144
--------------------------------------------------------------
Epoch:  144        1 Batch loss: 0.065035 Batch F1: 0.5714285714285715
Epoch:  144        2 Batch loss: 0.072428 Batch F1: 0.6666666666666666
Epoch:  144        3 Batch loss: 0.071981 Batch F1: 0.5
Epoch:  144        4 Batch loss: 0.068695 Batch F1: 0.7368421052631579
Epoch:  144        5 Batch loss: 0.089679 Batch F1: 0.7058823529411764
Epoch:  144        6 Batch loss: 0.063940 Batch F1: 1.0
Epoch:  144        7 Batch loss: 0.076728 Batch F1: 0.5333333333333333
Epoch:  144        8 Batch loss: 0.065743 Batch F1: 0.5454545454545454
Epoch:  144        9 Batch loss: 0.065137 Batch F1: 0.4
Epoch:  144       10 Batch loss: 0.088891 Batch F1: 0.5882352941176471
Epoch:  144       11 Batch loss: 0.059786 Batch F1: 0.7272727272727273
Epoch:  144       12 Batch loss: 0.054809 Batch F1: 0.8571428571428571
Train Avg Loss  144: 0.070238

Train Avg F1  144: 0.6526882044683902

Val Avg Loss  144: 0.068096

Val Avg F1  144:  0.8143539467068879

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 145
--------------------------------------------------------------
Epoch:  145        1 Batch loss: 0.082694 Batch F1: 0.7368421052631579
Epoch:  145        2 Batch loss: 0.085012 Batch F1: 0.7999999999999999
Epoch:  145        3 Batch loss: 0.057991 Batch F1: 1.0
Epoch:  145        4 Batch loss: 0.062360 Batch F1: 0.923076923076923
Epoch:  145        5 Batch loss: 0.101695 Batch F1: 0.6399999999999999
Epoch:  145        6 Batch loss: 0.056558 Batch F1: 0.923076923076923
Epoch:  145        7 Batch loss: 0.064647 Batch F1: 0.923076923076923
Epoch:  145        8 Batch loss: 0.074967 Batch F1: 0.8750000000000001
Epoch:  145        9 Batch loss: 0.068498 Batch F1: 0.6666666666666666
Epoch:  145       10 Batch loss: 0.058423 Batch F1: 0.7692307692307693
Epoch:  145       11 Batch loss: 0.082267 Batch F1: 0.33333333333333337
Epoch:  145       12 Batch loss: 0.055672 Batch F1: 0.6666666666666666
Train Avg Loss  145: 0.070899

Train Avg F1  145: 0.7714141925326136

Val Avg Loss  145: 0.068875

Val Avg F1  145:  0.6094246031746031

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 146
--------------------------------------------------------------
Epoch:  146        1 Batch loss: 0.079716 Batch F1: 0.3636363636363636
Epoch:  146        2 Batch loss: 0.058374 Batch F1: 0.5
Epoch:  146        3 Batch loss: 0.069036 Batch F1: 0.6153846153846153
Epoch:  146        4 Batch loss: 0.065037 Batch F1: 0.6
Epoch:  146        5 Batch loss: 0.086357 Batch F1: 0.6666666666666666
Epoch:  146        6 Batch loss: 0.067597 Batch F1: 0.6666666666666666
Epoch:  146        7 Batch loss: 0.075671 Batch F1: 0.7142857142857143
Epoch:  146        8 Batch loss: 0.071881 Batch F1: 0.6666666666666666
Epoch:  146        9 Batch loss: 0.076805 Batch F1: 0.7272727272727273
Epoch:  146       10 Batch loss: 0.068717 Batch F1: 0.5714285714285715
Epoch:  146       11 Batch loss: 0.054794 Batch F1: 0.8750000000000001
Epoch:  146       12 Batch loss: 0.074410 Batch F1: 0.8
Train Avg Loss  146: 0.070700

Train Avg F1  146: 0.6472506660006659

Val Avg Loss  146: 0.068684

Val Avg F1  146:  0.828654970760234

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 147
--------------------------------------------------------------
Epoch:  147        1 Batch loss: 0.064553 Batch F1: 0.9333333333333333
Epoch:  147        2 Batch loss: 0.079863 Batch F1: 0.761904761904762
Epoch:  147        3 Batch loss: 0.075443 Batch F1: 0.5454545454545454
Epoch:  147        4 Batch loss: 0.063717 Batch F1: 0.8
Epoch:  147        5 Batch loss: 0.071926 Batch F1: 0.7058823529411764
Epoch:  147        6 Batch loss: 0.064637 Batch F1: 0.25
Epoch:  147        7 Batch loss: 0.068697 Batch F1: 0.25
Epoch:  147        8 Batch loss: 0.064882 Batch F1: 0.6153846153846153
Epoch:  147        9 Batch loss: 0.073912 Batch F1: 0.625
Epoch:  147       10 Batch loss: 0.066039 Batch F1: 0.8235294117647058
Epoch:  147       11 Batch loss: 0.075276 Batch F1: 0.7272727272727273
Epoch:  147       12 Batch loss: 0.067947 Batch F1: 0.8571428571428571
Train Avg Loss  147: 0.069741

Train Avg F1  147: 0.6579087170998935

Val Avg Loss  147: 0.066372

Val Avg F1  147:  0.879257792860734

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 148
--------------------------------------------------------------
Epoch:  148        1 Batch loss: 0.047856 Batch F1: 0.923076923076923
Epoch:  148        2 Batch loss: 0.082419 Batch F1: 0.6666666666666666
Epoch:  148        3 Batch loss: 0.070134 Batch F1: 0.8
Epoch:  148        4 Batch loss: 0.062720 Batch F1: 1.0
Epoch:  148        5 Batch loss: 0.077877 Batch F1: 0.8421052631578948
Epoch:  148        6 Batch loss: 0.085183 Batch F1: 0.8695652173913044
Epoch:  148        7 Batch loss: 0.053949 Batch F1: 1.0
Epoch:  148        8 Batch loss: 0.063147 Batch F1: 0.923076923076923
Epoch:  148        9 Batch loss: 0.072812 Batch F1: 0.5714285714285715
Epoch:  148       10 Batch loss: 0.076887 Batch F1: 0.4615384615384615
Epoch:  148       11 Batch loss: 0.085769 Batch F1: 0.3636363636363636
Epoch:  148       12 Batch loss: 0.064188 Batch F1: 0.2857142857142857
Train Avg Loss  148: 0.070245

Train Avg F1  148: 0.7255673896406162

Val Avg Loss  148: 0.065435

Val Avg F1  148:  0.6169467787114845

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 149
--------------------------------------------------------------
Epoch:  149        1 Batch loss: 0.061351 Batch F1: 0.6666666666666666
Epoch:  149        2 Batch loss: 0.062737 Batch F1: 0.6
Epoch:  149        3 Batch loss: 0.083436 Batch F1: 0.7499999999999999
Epoch:  149        4 Batch loss: 0.051741 Batch F1: 0.888888888888889
Epoch:  149        5 Batch loss: 0.056787 Batch F1: 0.4444444444444445
Epoch:  149        6 Batch loss: 0.057339 Batch F1: 0.6
Epoch:  149        7 Batch loss: 0.059943 Batch F1: 0.8
Epoch:  149        8 Batch loss: 0.089264 Batch F1: 0.4
Epoch:  149        9 Batch loss: 0.071392 Batch F1: 0.5714285714285715
Epoch:  149       10 Batch loss: 0.085639 Batch F1: 0.8750000000000001
Epoch:  149       11 Batch loss: 0.074216 Batch F1: 0.9
Epoch:  149       12 Batch loss: 0.076834 Batch F1: 0.9600000000000001
Train Avg Loss  149: 0.069223

Train Avg F1  149: 0.704702380952381

Val Avg Loss  149: 0.067879

Val Avg F1  149:  0.9353146853146852

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 150
--------------------------------------------------------------
Epoch:  150        1 Batch loss: 0.074029 Batch F1: 0.8571428571428571
Epoch:  150        2 Batch loss: 0.065698 Batch F1: 0.9090909090909091
Epoch:  150        3 Batch loss: 0.072046 Batch F1: 0.7777777777777778
Epoch:  150        4 Batch loss: 0.067452 Batch F1: 0.9565217391304348
Epoch:  150        5 Batch loss: 0.064125 Batch F1: 0.33333333333333337
Epoch:  150        6 Batch loss: 0.074728 Batch F1: 0.2222222222222222
Epoch:  150        7 Batch loss: 0.091778 Batch F1: 0.0
Epoch:  150        8 Batch loss: 0.059277 Batch F1: 0.25
Epoch:  150        9 Batch loss: 0.075581 Batch F1: 0.5714285714285715
Epoch:  150       10 Batch loss: 0.065614 Batch F1: 0.6153846153846153
Epoch:  150       11 Batch loss: 0.063053 Batch F1: 0.6153846153846153
Epoch:  150       12 Batch loss: 0.074438 Batch F1: 0.8333333333333333
Train Avg Loss  150: 0.070651

Train Avg F1  150: 0.5784683311857224

Val Avg Loss  150: 0.066145

Val Avg F1  150:  0.8953804347826086

Optimal Val loss (Epoch 124): 0.06437635608017445

Epoch 151
--------------------------------------------------------------
Epoch:  151        1 Batch loss: 0.069248 Batch F1: 0.9333333333333333
Epoch:  151        2 Batch loss: 0.063311 Batch F1: 0.8571428571428571
Epoch:  151        3 Batch loss: 0.062947 Batch F1: 0.8
Epoch:  151        4 Batch loss: 0.061233 Batch F1: 0.888888888888889
Epoch:  151        5 Batch loss: 0.068779 Batch F1: 0.4
Epoch:  151        6 Batch loss: 0.105677 Batch F1: 0.35294117647058826
Epoch:  151        7 Batch loss: 0.082235 Batch F1: 0.5714285714285715
Epoch:  151        8 Batch loss: 0.083967 Batch F1: 0.8
Epoch:  151        9 Batch loss: 0.045955 Batch F1: 1.0
Epoch:  151       10 Batch loss: 0.092903 Batch F1: 0.8571428571428571
Epoch:  151       11 Batch loss: 0.065062 Batch F1: 0.923076923076923
Epoch:  151       12 Batch loss: 0.072749 Batch F1: 0.888888888888889
Train Avg Loss  151: 0.072839

Train Avg F1  151: 0.7727369580310756

Val Avg Loss  151: 0.064354

Val Avg F1  151:  0.9235119047619049

Optimal Val loss (Epoch 151): 0.06435393635183573

Epoch 152
--------------------------------------------------------------
Epoch:  152        1 Batch loss: 0.061171 Batch F1: 0.9411764705882353
Epoch:  152        2 Batch loss: 0.076929 Batch F1: 0.4615384615384615
Epoch:  152        3 Batch loss: 0.079154 Batch F1: 0.7000000000000001
Epoch:  152        4 Batch loss: 0.059993 Batch F1: 0.6
Epoch:  152        5 Batch loss: 0.066628 Batch F1: 0.6153846153846153
Epoch:  152        6 Batch loss: 0.082734 Batch F1: 0.8
Epoch:  152        7 Batch loss: 0.062863 Batch F1: 0.888888888888889
Epoch:  152        8 Batch loss: 0.096188 Batch F1: 0.6363636363636364
Epoch:  152        9 Batch loss: 0.082014 Batch F1: 0.6666666666666666
Epoch:  152       10 Batch loss: 0.081356 Batch F1: 0.8
Epoch:  152       11 Batch loss: 0.045622 Batch F1: 0.8
Epoch:  152       12 Batch loss: 0.050775 Batch F1: 0.7499999999999999
Train Avg Loss  152: 0.070452

Train Avg F1  152: 0.7216682282858754

Val Avg Loss  152: 0.073180

Val Avg F1  152:  0.5580086580086581

Optimal Val loss (Epoch 151): 0.06435393635183573

Epoch 153
--------------------------------------------------------------
Epoch:  153        1 Batch loss: 0.081793 Batch F1: 0.0
Epoch:  153        2 Batch loss: 0.085333 Batch F1: 0.16666666666666669
Epoch:  153        3 Batch loss: 0.078643 Batch F1: 0.7499999999999999
Epoch:  153        4 Batch loss: 0.098112 Batch F1: 0.7826086956521738
Epoch:  153        5 Batch loss: 0.077106 Batch F1: 0.9411764705882353
Epoch:  153        6 Batch loss: 0.075317 Batch F1: 0.8750000000000001
Epoch:  153        7 Batch loss: 0.064923 Batch F1: 0.8571428571428571
Epoch:  153        8 Batch loss: 0.061084 Batch F1: 0.6
Epoch:  153        9 Batch loss: 0.067237 Batch F1: 0.6666666666666666
Epoch:  153       10 Batch loss: 0.072453 Batch F1: 0.8181818181818181
Epoch:  153       11 Batch loss: 0.074631 Batch F1: 0.3636363636363636
Epoch:  153       12 Batch loss: 0.051120 Batch F1: 1.0
Train Avg Loss  153: 0.073979

Train Avg F1  153: 0.6517566282112317

Val Avg Loss  153: 0.071707

Val Avg F1  153:  0.5772283272283273

Optimal Val loss (Epoch 151): 0.06435393635183573

Epoch 154
--------------------------------------------------------------
Epoch:  154        1 Batch loss: 0.085455 Batch F1: 0.0
Epoch:  154        2 Batch loss: 0.094263 Batch F1: 0.5
Epoch:  154        3 Batch loss: 0.060686 Batch F1: 0.7692307692307693
Epoch:  154        4 Batch loss: 0.107599 Batch F1: 0.45454545454545453
Epoch:  154        5 Batch loss: 0.059584 Batch F1: 0.888888888888889
Epoch:  154        6 Batch loss: 0.062808 Batch F1: 0.923076923076923
Epoch:  154        7 Batch loss: 0.070383 Batch F1: 0.8333333333333333
Epoch:  154        8 Batch loss: 0.067215 Batch F1: 0.8
Epoch:  154        9 Batch loss: 0.086869 Batch F1: 0.5
Epoch:  154       10 Batch loss: 0.066046 Batch F1: 0.6666666666666666
Epoch:  154       11 Batch loss: 0.048484 Batch F1: 0.888888888888889
Epoch:  154       12 Batch loss: 0.064207 Batch F1: 0.8571428571428571
Train Avg Loss  154: 0.072800

Train Avg F1  154: 0.6734811484811485

Val Avg Loss  154: 0.065134

Val Avg F1  154:  0.59375

Optimal Val loss (Epoch 151): 0.06435393635183573

Epoch 155
--------------------------------------------------------------
Epoch:  155        1 Batch loss: 0.080426 Batch F1: 0.4615384615384615
Epoch:  155        2 Batch loss: 0.073814 Batch F1: 0.25
Epoch:  155        3 Batch loss: 0.066708 Batch F1: 0.7777777777777778
Epoch:  155        4 Batch loss: 0.061941 Batch F1: 0.6666666666666666
Epoch:  155        5 Batch loss: 0.073143 Batch F1: 0.5714285714285715
Epoch:  155        6 Batch loss: 0.074762 Batch F1: 0.4615384615384615
Epoch:  155        7 Batch loss: 0.079418 Batch F1: 0.5454545454545454
Epoch:  155        8 Batch loss: 0.068239 Batch F1: 0.8750000000000001
Epoch:  155        9 Batch loss: 0.049866 Batch F1: 1.0
Epoch:  155       10 Batch loss: 0.070048 Batch F1: 0.9333333333333333
Epoch:  155       11 Batch loss: 0.071233 Batch F1: 0.888888888888889
Epoch:  155       12 Batch loss: 0.065929 Batch F1: 1.0
Train Avg Loss  155: 0.069627

Train Avg F1  155: 0.7026355588855591

Val Avg Loss  155: 0.067049

Val Avg F1  155:  0.7288461538461538

Optimal Val loss (Epoch 151): 0.06435393635183573

Epoch 156
--------------------------------------------------------------
Epoch:  156        1 Batch loss: 0.098247 Batch F1: 0.4
Epoch:  156        2 Batch loss: 0.060641 Batch F1: 0.8571428571428571
Epoch:  156        3 Batch loss: 0.048692 Batch F1: 0.923076923076923
Epoch:  156        4 Batch loss: 0.070433 Batch F1: 0.8571428571428571
Epoch:  156        5 Batch loss: 0.080121 Batch F1: 0.9600000000000001
Epoch:  156        6 Batch loss: 0.060989 Batch F1: 1.0
Epoch:  156        7 Batch loss: 0.061585 Batch F1: 0.5454545454545454
Epoch:  156        8 Batch loss: 0.066466 Batch F1: 0.6153846153846153
Epoch:  156        9 Batch loss: 0.103304 Batch F1: 0.5882352941176471
Epoch:  156       10 Batch loss: 0.070227 Batch F1: 0.5
Epoch:  156       11 Batch loss: 0.081096 Batch F1: 0.19999999999999998
Epoch:  156       12 Batch loss: 0.070541 Batch F1: 0.7142857142857143
Train Avg Loss  156: 0.072695

Train Avg F1  156: 0.6800602338837632

Val Avg Loss  156: 0.068885

Val Avg F1  156:  0.8959207459207459

Optimal Val loss (Epoch 151): 0.06435393635183573

Epoch 157
--------------------------------------------------------------
Epoch:  157        1 Batch loss: 0.056828 Batch F1: 0.8
Epoch:  157        2 Batch loss: 0.077011 Batch F1: 0.823529411764706
Epoch:  157        3 Batch loss: 0.082147 Batch F1: 0.8181818181818181
Epoch:  157        4 Batch loss: 0.090465 Batch F1: 0.4
Epoch:  157        5 Batch loss: 0.068640 Batch F1: 0.2222222222222222
Epoch:  157        6 Batch loss: 0.071567 Batch F1: 0.5
Epoch:  157        7 Batch loss: 0.083634 Batch F1: 0.5333333333333333
Epoch:  157        8 Batch loss: 0.056020 Batch F1: 0.5714285714285715
Epoch:  157        9 Batch loss: 0.068208 Batch F1: 0.8
Epoch:  157       10 Batch loss: 0.067484 Batch F1: 0.8235294117647058
Epoch:  157       11 Batch loss: 0.072459 Batch F1: 0.8
Epoch:  157       12 Batch loss: 0.070802 Batch F1: 1.0
Train Avg Loss  157: 0.072105

Train Avg F1  157: 0.6743520640579463

Val Avg Loss  157: 0.064531

Val Avg F1  157:  0.8797385620915034

Optimal Val loss (Epoch 151): 0.06435393635183573

Epoch 158
--------------------------------------------------------------
Epoch:  158        1 Batch loss: 0.059848 Batch F1: 0.8333333333333333
Epoch:  158        2 Batch loss: 0.065419 Batch F1: 0.6666666666666666
Epoch:  158        3 Batch loss: 0.070379 Batch F1: 0.6666666666666666
Epoch:  158        4 Batch loss: 0.063204 Batch F1: 0.0
Epoch:  158        5 Batch loss: 0.089003 Batch F1: 0.4
Epoch:  158        6 Batch loss: 0.071878 Batch F1: 0.7499999999999999
Epoch:  158        7 Batch loss: 0.061209 Batch F1: 0.8571428571428571
Epoch:  158        8 Batch loss: 0.082038 Batch F1: 0.9
Epoch:  158        9 Batch loss: 0.080103 Batch F1: 0.8235294117647058
Epoch:  158       10 Batch loss: 0.057452 Batch F1: 0.9411764705882353
Epoch:  158       11 Batch loss: 0.063977 Batch F1: 0.6666666666666666
Epoch:  158       12 Batch loss: 0.076433 Batch F1: 0.5
Train Avg Loss  158: 0.070079

Train Avg F1  158: 0.6670985060690944

Val Avg Loss  158: 0.063887

Val Avg F1  158:  0.6185064935064934

Optimal Val loss (Epoch 158): 0.06388736516237259

Epoch 159
--------------------------------------------------------------
Epoch:  159        1 Batch loss: 0.069710 Batch F1: 0.5
Epoch:  159        2 Batch loss: 0.059795 Batch F1: 0.888888888888889
Epoch:  159        3 Batch loss: 0.078764 Batch F1: 0.9090909090909091
Epoch:  159        4 Batch loss: 0.075529 Batch F1: 0.8888888888888888
Epoch:  159        5 Batch loss: 0.069204 Batch F1: 0.9285714285714286
Epoch:  159        6 Batch loss: 0.083895 Batch F1: 0.888888888888889
Epoch:  159        7 Batch loss: 0.053392 Batch F1: 0.923076923076923
Epoch:  159        8 Batch loss: 0.068450 Batch F1: 0.6
Epoch:  159        9 Batch loss: 0.045560 Batch F1: 1.0
Epoch:  159       10 Batch loss: 0.082166 Batch F1: 0.3636363636363636
Epoch:  159       11 Batch loss: 0.073557 Batch F1: 0.6153846153846153
Epoch:  159       12 Batch loss: 0.062728 Batch F1: 0.2857142857142857
Train Avg Loss  159: 0.068562

Train Avg F1  159: 0.7326784326784327

Val Avg Loss  159: 0.067239

Val Avg F1  159:  0.6125541125541125

Optimal Val loss (Epoch 158): 0.06388736516237259

Epoch 160
--------------------------------------------------------------
Epoch:  160        1 Batch loss: 0.077991 Batch F1: 0.3636363636363636
Epoch:  160        2 Batch loss: 0.072761 Batch F1: 0.4
Epoch:  160        3 Batch loss: 0.066626 Batch F1: 0.8333333333333333
Epoch:  160        4 Batch loss: 0.075599 Batch F1: 0.9473684210526316
Epoch:  160        5 Batch loss: 0.074887 Batch F1: 0.9565217391304348
Epoch:  160        6 Batch loss: 0.059497 Batch F1: 0.8571428571428571
Epoch:  160        7 Batch loss: 0.074327 Batch F1: 0.9090909090909091
Epoch:  160        8 Batch loss: 0.055616 Batch F1: 0.888888888888889
Epoch:  160        9 Batch loss: 0.062508 Batch F1: 0.7499999999999999
Epoch:  160       10 Batch loss: 0.072347 Batch F1: 0.6153846153846153
Epoch:  160       11 Batch loss: 0.061996 Batch F1: 0.7368421052631579
Epoch:  160       12 Batch loss: 0.074076 Batch F1: 0.8
Train Avg Loss  160: 0.069019

Train Avg F1  160: 0.754850769410266

Val Avg Loss  160: 0.063121

Val Avg F1  160:  0.7994152046783626

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 161
--------------------------------------------------------------
Epoch:  161        1 Batch loss: 0.044132 Batch F1: 1.0
Epoch:  161        2 Batch loss: 0.091047 Batch F1: 0.42857142857142855
Epoch:  161        3 Batch loss: 0.083863 Batch F1: 0.6
Epoch:  161        4 Batch loss: 0.073446 Batch F1: 0.8
Epoch:  161        5 Batch loss: 0.060482 Batch F1: 0.7499999999999999
Epoch:  161        6 Batch loss: 0.078769 Batch F1: 0.4615384615384615
Epoch:  161        7 Batch loss: 0.081605 Batch F1: 0.4615384615384615
Epoch:  161        8 Batch loss: 0.065840 Batch F1: 0.5454545454545454
Epoch:  161        9 Batch loss: 0.069613 Batch F1: 0.2222222222222222
Epoch:  161       10 Batch loss: 0.064516 Batch F1: 0.4444444444444445
Epoch:  161       11 Batch loss: 0.046688 Batch F1: 1.0
Epoch:  161       12 Batch loss: 0.090022 Batch F1: 0.9166666666666666
Train Avg Loss  161: 0.070835

Train Avg F1  161: 0.635869685869686

Val Avg Loss  161: 0.066256

Val Avg F1  161:  0.9198996655518394

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 162
--------------------------------------------------------------
Epoch:  162        1 Batch loss: 0.069741 Batch F1: 0.9411764705882353
Epoch:  162        2 Batch loss: 0.075560 Batch F1: 0.8421052631578948
Epoch:  162        3 Batch loss: 0.068206 Batch F1: 0.8
Epoch:  162        4 Batch loss: 0.061086 Batch F1: 1.0
Epoch:  162        5 Batch loss: 0.074521 Batch F1: 0.9565217391304348
Epoch:  162        6 Batch loss: 0.081340 Batch F1: 0.8235294117647058
Epoch:  162        7 Batch loss: 0.071540 Batch F1: 0.5454545454545454
Epoch:  162        8 Batch loss: 0.051830 Batch F1: 0.8333333333333333
Epoch:  162        9 Batch loss: 0.094182 Batch F1: 0.16666666666666669
Epoch:  162       10 Batch loss: 0.082924 Batch F1: 0.7777777777777778
Epoch:  162       11 Batch loss: 0.065551 Batch F1: 0.9090909090909091
Epoch:  162       12 Batch loss: 0.044626 Batch F1: 1.0
Train Avg Loss  162: 0.070092

Train Avg F1  162: 0.7996380097470418

Val Avg Loss  162: 0.064916

Val Avg F1  162:  0.5947802197802198

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 163
--------------------------------------------------------------
Epoch:  163        1 Batch loss: 0.056112 Batch F1: 0.6666666666666666
Epoch:  163        2 Batch loss: 0.067974 Batch F1: 0.6153846153846153
Epoch:  163        3 Batch loss: 0.042346 Batch F1: 0.8
Epoch:  163        4 Batch loss: 0.069226 Batch F1: 0.4444444444444445
Epoch:  163        5 Batch loss: 0.073306 Batch F1: 0.4615384615384615
Epoch:  163        6 Batch loss: 0.041434 Batch F1: 1.0
Epoch:  163        7 Batch loss: 0.076563 Batch F1: 0.8421052631578948
Epoch:  163        8 Batch loss: 0.088801 Batch F1: 0.8
Epoch:  163        9 Batch loss: 0.091082 Batch F1: 0.8181818181818181
Epoch:  163       10 Batch loss: 0.084009 Batch F1: 0.42857142857142855
Epoch:  163       11 Batch loss: 0.076732 Batch F1: 0.7142857142857143
Epoch:  163       12 Batch loss: 0.067492 Batch F1: 0.9
Train Avg Loss  163: 0.069590

Train Avg F1  163: 0.7075982010192536

Val Avg Loss  163: 0.065253

Val Avg F1  163:  0.832031857031857

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 164
--------------------------------------------------------------
Epoch:  164        1 Batch loss: 0.063369 Batch F1: 0.8333333333333333
Epoch:  164        2 Batch loss: 0.053687 Batch F1: 0.9090909090909091
Epoch:  164        3 Batch loss: 0.075128 Batch F1: 0.5714285714285715
Epoch:  164        4 Batch loss: 0.053273 Batch F1: 0.6666666666666666
Epoch:  164        5 Batch loss: 0.053903 Batch F1: 0.6
Epoch:  164        6 Batch loss: 0.081336 Batch F1: 0.625
Epoch:  164        7 Batch loss: 0.095912 Batch F1: 0.7368421052631577
Epoch:  164        8 Batch loss: 0.059945 Batch F1: 1.0
Epoch:  164        9 Batch loss: 0.056428 Batch F1: 0.888888888888889
Epoch:  164       10 Batch loss: 0.083327 Batch F1: 0.625
Epoch:  164       11 Batch loss: 0.066106 Batch F1: 0.4444444444444445
Epoch:  164       12 Batch loss: 0.111525 Batch F1: 0.4444444444444445
Train Avg Loss  164: 0.071162

Train Avg F1  164: 0.6954282802967015

Val Avg Loss  164: 0.065056

Val Avg F1  164:  0.8848096348096347

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 165
--------------------------------------------------------------
Epoch:  165        1 Batch loss: 0.066415 Batch F1: 0.888888888888889
Epoch:  165        2 Batch loss: 0.075912 Batch F1: 0.962962962962963
Epoch:  165        3 Batch loss: 0.082491 Batch F1: 0.875
Epoch:  165        4 Batch loss: 0.050826 Batch F1: 1.0
Epoch:  165        5 Batch loss: 0.058957 Batch F1: 0.6666666666666666
Epoch:  165        6 Batch loss: 0.067752 Batch F1: 0.0
Epoch:  165        7 Batch loss: 0.061631 Batch F1: 0.4444444444444445
Epoch:  165        8 Batch loss: 0.081562 Batch F1: 0.3636363636363636
Epoch:  165        9 Batch loss: 0.077022 Batch F1: 0.7058823529411764
Epoch:  165       10 Batch loss: 0.110040 Batch F1: 0.375
Epoch:  165       11 Batch loss: 0.075486 Batch F1: 0.7692307692307693
Epoch:  165       12 Batch loss: 0.098215 Batch F1: 0.923076923076923
Train Avg Loss  165: 0.075526

Train Avg F1  165: 0.6645657809873496

Val Avg Loss  165: 0.068126

Val Avg F1  165:  0.8438467492260062

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 166
--------------------------------------------------------------
Epoch:  166        1 Batch loss: 0.071246 Batch F1: 0.7142857142857143
Epoch:  166        2 Batch loss: 0.084666 Batch F1: 0.4
Epoch:  166        3 Batch loss: 0.097042 Batch F1: 0.631578947368421
Epoch:  166        4 Batch loss: 0.094462 Batch F1: 0.4615384615384615
Epoch:  166        5 Batch loss: 0.058452 Batch F1: 0.888888888888889
Epoch:  166        6 Batch loss: 0.068896 Batch F1: 0.6666666666666666
Epoch:  166        7 Batch loss: 0.058287 Batch F1: 0.8571428571428571
Epoch:  166        8 Batch loss: 0.064815 Batch F1: 0.7058823529411764
Epoch:  166        9 Batch loss: 0.048832 Batch F1: 0.5714285714285715
Epoch:  166       10 Batch loss: 0.082375 Batch F1: 0.7000000000000001
Epoch:  166       11 Batch loss: 0.093366 Batch F1: 0.8571428571428572
Epoch:  166       12 Batch loss: 0.080267 Batch F1: 0.4
Train Avg Loss  166: 0.075225

Train Avg F1  166: 0.6545462764503012

Val Avg Loss  166: 0.073457

Val Avg F1  166:  0.5177815605447184

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 167
--------------------------------------------------------------
Epoch:  167        1 Batch loss: 0.050584 Batch F1: 0.5714285714285715
Epoch:  167        2 Batch loss: 0.090667 Batch F1: 0.0
Epoch:  167        3 Batch loss: 0.086727 Batch F1: 0.18181818181818182
Epoch:  167        4 Batch loss: 0.054893 Batch F1: 0.7692307692307693
Epoch:  167        5 Batch loss: 0.065755 Batch F1: 1.0
Epoch:  167        6 Batch loss: 0.060823 Batch F1: 0.9473684210526316
Epoch:  167        7 Batch loss: 0.087469 Batch F1: 0.7499999999999999
Epoch:  167        8 Batch loss: 0.044741 Batch F1: 1.0
Epoch:  167        9 Batch loss: 0.084906 Batch F1: 0.6666666666666666
Epoch:  167       10 Batch loss: 0.080019 Batch F1: 0.3636363636363636
Epoch:  167       11 Batch loss: 0.094206 Batch F1: 0.4
Epoch:  167       12 Batch loss: 0.093539 Batch F1: 0.33333333333333337
Train Avg Loss  167: 0.074527

Train Avg F1  167: 0.5819568589305432

Val Avg Loss  167: 0.065655

Val Avg F1  167:  0.6875

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 168
--------------------------------------------------------------
Epoch:  168        1 Batch loss: 0.070833 Batch F1: 0.7142857142857143
Epoch:  168        2 Batch loss: 0.083541 Batch F1: 0.8421052631578948
Epoch:  168        3 Batch loss: 0.094598 Batch F1: 0.8695652173913044
Epoch:  168        4 Batch loss: 0.088451 Batch F1: 0.8571428571428571
Epoch:  168        5 Batch loss: 0.077109 Batch F1: 0.9411764705882353
Epoch:  168        6 Batch loss: 0.068269 Batch F1: 0.9523809523809523
Epoch:  168        7 Batch loss: 0.049866 Batch F1: 1.0
Epoch:  168        8 Batch loss: 0.066652 Batch F1: 0.6666666666666666
Epoch:  168        9 Batch loss: 0.043147 Batch F1: 0.7499999999999999
Epoch:  168       10 Batch loss: 0.053419 Batch F1: 0.7272727272727273
Epoch:  168       11 Batch loss: 0.066163 Batch F1: 0.4444444444444445
Epoch:  168       12 Batch loss: 0.080505 Batch F1: 0.4
Train Avg Loss  168: 0.070213

Train Avg F1  168: 0.7637533594442331

Val Avg Loss  168: 0.065414

Val Avg F1  168:  0.6009140316205533

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 169
--------------------------------------------------------------
Epoch:  169        1 Batch loss: 0.090521 Batch F1: 0.6
Epoch:  169        2 Batch loss: 0.069070 Batch F1: 1.0
Epoch:  169        3 Batch loss: 0.077232 Batch F1: 0.7692307692307693
Epoch:  169        4 Batch loss: 0.071593 Batch F1: 0.9473684210526316
Epoch:  169        5 Batch loss: 0.059443 Batch F1: 0.8
Epoch:  169        6 Batch loss: 0.075139 Batch F1: 0.33333333333333337
Epoch:  169        7 Batch loss: 0.063572 Batch F1: 0.6666666666666666
Epoch:  169        8 Batch loss: 0.056477 Batch F1: 0.6
Epoch:  169        9 Batch loss: 0.094225 Batch F1: 0.5
Epoch:  169       10 Batch loss: 0.057110 Batch F1: 0.888888888888889
Epoch:  169       11 Batch loss: 0.045008 Batch F1: 1.0
Epoch:  169       12 Batch loss: 0.091950 Batch F1: 0.4444444444444445
Train Avg Loss  169: 0.070945

Train Avg F1  169: 0.7124943769680612

Val Avg Loss  169: 0.064756

Val Avg F1  169:  0.5754776269482152

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 170
--------------------------------------------------------------
Epoch:  170        1 Batch loss: 0.082464 Batch F1: 0.33333333333333337
Epoch:  170        2 Batch loss: 0.093749 Batch F1: 0.42857142857142855
Epoch:  170        3 Batch loss: 0.077144 Batch F1: 0.5882352941176471
Epoch:  170        4 Batch loss: 0.056554 Batch F1: 0.923076923076923
Epoch:  170        5 Batch loss: 0.066793 Batch F1: 1.0
Epoch:  170        6 Batch loss: 0.069824 Batch F1: 0.9411764705882353
Epoch:  170        7 Batch loss: 0.054819 Batch F1: 0.9090909090909091
Epoch:  170        8 Batch loss: 0.054794 Batch F1: 0.4444444444444445
Epoch:  170        9 Batch loss: 0.100043 Batch F1: 0.6666666666666666
Epoch:  170       10 Batch loss: 0.071307 Batch F1: 0.5714285714285715
Epoch:  170       11 Batch loss: 0.073071 Batch F1: 0.4444444444444445
Epoch:  170       12 Batch loss: 0.077815 Batch F1: 0.8
Train Avg Loss  170: 0.073198

Train Avg F1  170: 0.6708723738135504

Val Avg Loss  170: 0.069247

Val Avg F1  170:  0.8298076923076922

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 171
--------------------------------------------------------------
Epoch:  171        1 Batch loss: 0.077405 Batch F1: 0.8
Epoch:  171        2 Batch loss: 0.057345 Batch F1: 0.8333333333333333
Epoch:  171        3 Batch loss: 0.102253 Batch F1: 0.4444444444444445
Epoch:  171        4 Batch loss: 0.054847 Batch F1: 0.7272727272727273
Epoch:  171        5 Batch loss: 0.081685 Batch F1: 0.0
Epoch:  171        6 Batch loss: 0.082748 Batch F1: 0.2222222222222222
Epoch:  171        7 Batch loss: 0.065799 Batch F1: 0.5454545454545454
Epoch:  171        8 Batch loss: 0.076341 Batch F1: 0.33333333333333337
Epoch:  171        9 Batch loss: 0.062969 Batch F1: 0.9473684210526316
Epoch:  171       10 Batch loss: 0.071313 Batch F1: 0.8750000000000001
Epoch:  171       11 Batch loss: 0.051322 Batch F1: 1.0
Epoch:  171       12 Batch loss: 0.092806 Batch F1: 0.7777777777777778
Train Avg Loss  171: 0.073069

Train Avg F1  171: 0.6255172337409179

Val Avg Loss  171: 0.065362

Val Avg F1  171:  0.93875

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 172
--------------------------------------------------------------
Epoch:  172        1 Batch loss: 0.063830 Batch F1: 0.9411764705882353
Epoch:  172        2 Batch loss: 0.059613 Batch F1: 1.0
Epoch:  172        3 Batch loss: 0.082990 Batch F1: 0.9523809523809523
Epoch:  172        4 Batch loss: 0.079888 Batch F1: 0.823529411764706
Epoch:  172        5 Batch loss: 0.072206 Batch F1: 0.888888888888889
Epoch:  172        6 Batch loss: 0.067805 Batch F1: 0.8
Epoch:  172        7 Batch loss: 0.062853 Batch F1: 1.0
Epoch:  172        8 Batch loss: 0.072591 Batch F1: 0.7692307692307693
Epoch:  172        9 Batch loss: 0.070261 Batch F1: 0.8571428571428571
Epoch:  172       10 Batch loss: 0.069857 Batch F1: 0.4444444444444445
Epoch:  172       11 Batch loss: 0.055053 Batch F1: 0.6666666666666666
Epoch:  172       12 Batch loss: 0.076287 Batch F1: 0.6153846153846153
Train Avg Loss  172: 0.069436

Train Avg F1  172: 0.8132370897076778

Val Avg Loss  172: 0.064743

Val Avg F1  172:  0.5693528693528693

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 173
--------------------------------------------------------------
Epoch:  173        1 Batch loss: 0.058917 Batch F1: 0.4444444444444445
Epoch:  173        2 Batch loss: 0.079468 Batch F1: 0.19999999999999998
Epoch:  173        3 Batch loss: 0.072354 Batch F1: 0.4615384615384615
Epoch:  173        4 Batch loss: 0.063077 Batch F1: 0.4444444444444445
Epoch:  173        5 Batch loss: 0.080823 Batch F1: 0.8695652173913044
Epoch:  173        6 Batch loss: 0.045473 Batch F1: 0.888888888888889
Epoch:  173        7 Batch loss: 0.058130 Batch F1: 0.6666666666666666
Epoch:  173        8 Batch loss: 0.076111 Batch F1: 0.7000000000000001
Epoch:  173        9 Batch loss: 0.071189 Batch F1: 0.6666666666666666
Epoch:  173       10 Batch loss: 0.065868 Batch F1: 0.4444444444444445
Epoch:  173       11 Batch loss: 0.079916 Batch F1: 0.5
Epoch:  173       12 Batch loss: 0.083550 Batch F1: 0.6666666666666666
Train Avg Loss  173: 0.069573

Train Avg F1  173: 0.5794438250959991

Val Avg Loss  173: 0.065781

Val Avg F1  173:  0.9244245524296675

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 174
--------------------------------------------------------------
Epoch:  174        1 Batch loss: 0.068836 Batch F1: 1.0
Epoch:  174        2 Batch loss: 0.078945 Batch F1: 0.8235294117647058
Epoch:  174        3 Batch loss: 0.065029 Batch F1: 0.9333333333333333
Epoch:  174        4 Batch loss: 0.070688 Batch F1: 0.6153846153846153
Epoch:  174        5 Batch loss: 0.102716 Batch F1: 0.5454545454545454
Epoch:  174        6 Batch loss: 0.080011 Batch F1: 0.8750000000000001
Epoch:  174        7 Batch loss: 0.077053 Batch F1: 0.888888888888889
Epoch:  174        8 Batch loss: 0.068301 Batch F1: 0.923076923076923
Epoch:  174        9 Batch loss: 0.063442 Batch F1: 0.6666666666666666
Epoch:  174       10 Batch loss: 0.035883 Batch F1: 0.5
Epoch:  174       11 Batch loss: 0.105256 Batch F1: 0.5555555555555556
Epoch:  174       12 Batch loss: 0.062120 Batch F1: 0.5
Train Avg Loss  174: 0.073190

Train Avg F1  174: 0.735574161677103

Val Avg Loss  174: 0.072703

Val Avg F1  174:  0.45884615384615385

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 175
--------------------------------------------------------------
Epoch:  175        1 Batch loss: 0.068136 Batch F1: 0.5454545454545454
Epoch:  175        2 Batch loss: 0.047723 Batch F1: 0.6666666666666666
Epoch:  175        3 Batch loss: 0.060803 Batch F1: 0.6
Epoch:  175        4 Batch loss: 0.072572 Batch F1: 0.5714285714285715
Epoch:  175        5 Batch loss: 0.104919 Batch F1: 0.6666666666666666
Epoch:  175        6 Batch loss: 0.079413 Batch F1: 1.0
Epoch:  175        7 Batch loss: 0.086640 Batch F1: 0.6666666666666666
Epoch:  175        8 Batch loss: 0.054820 Batch F1: 0.6666666666666666
Epoch:  175        9 Batch loss: 0.068356 Batch F1: 0.5
Epoch:  175       10 Batch loss: 0.075467 Batch F1: 0.5
Epoch:  175       11 Batch loss: 0.065186 Batch F1: 0.6153846153846153
Epoch:  175       12 Batch loss: 0.092983 Batch F1: 0.6666666666666666
Train Avg Loss  175: 0.073085

Train Avg F1  175: 0.6388000888000888

Val Avg Loss  175: 0.070675

Val Avg F1  175:  0.91875

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 176
--------------------------------------------------------------
Epoch:  176        1 Batch loss: 0.069801 Batch F1: 1.0
Epoch:  176        2 Batch loss: 0.064779 Batch F1: 0.923076923076923
Epoch:  176        3 Batch loss: 0.059003 Batch F1: 0.8571428571428571
Epoch:  176        4 Batch loss: 0.056517 Batch F1: 0.6666666666666666
Epoch:  176        5 Batch loss: 0.095166 Batch F1: 0.7142857142857143
Epoch:  176        6 Batch loss: 0.106886 Batch F1: 0.2666666666666667
Epoch:  176        7 Batch loss: 0.057208 Batch F1: 0.8333333333333333
Epoch:  176        8 Batch loss: 0.071795 Batch F1: 0.9333333333333333
Epoch:  176        9 Batch loss: 0.081731 Batch F1: 0.8235294117647058
Epoch:  176       10 Batch loss: 0.062867 Batch F1: 0.6
Epoch:  176       11 Batch loss: 0.079372 Batch F1: 0.7000000000000001
Epoch:  176       12 Batch loss: 0.080688 Batch F1: 0.5
Train Avg Loss  176: 0.073818

Train Avg F1  176: 0.7348362421891833

Val Avg Loss  176: 0.079725

Val Avg F1  176:  0.9235933048433048

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 177
--------------------------------------------------------------
Epoch:  177        1 Batch loss: 0.101138 Batch F1: 0.896551724137931
Epoch:  177        2 Batch loss: 0.111836 Batch F1: 0.75
Epoch:  177        3 Batch loss: 0.062681 Batch F1: 0.7692307692307693
Epoch:  177        4 Batch loss: 0.071975 Batch F1: 0.0
Epoch:  177        5 Batch loss: 0.152218 Batch F1: 0.0
Epoch:  177        6 Batch loss: 0.095280 Batch F1: 0.5
Epoch:  177        7 Batch loss: 0.087920 Batch F1: 0.4615384615384615
Epoch:  177        8 Batch loss: 0.061242 Batch F1: 0.6
Epoch:  177        9 Batch loss: 0.061289 Batch F1: 1.0
Epoch:  177       10 Batch loss: 0.075291 Batch F1: 0.8421052631578948
Epoch:  177       11 Batch loss: 0.082433 Batch F1: 0.625
Epoch:  177       12 Batch loss: 0.079712 Batch F1: 0.6666666666666666
Train Avg Loss  177: 0.086918

Train Avg F1  177: 0.5925910737276436

Val Avg Loss  177: 0.073414

Val Avg F1  177:  0.678255404725993

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 178
--------------------------------------------------------------
Epoch:  178        1 Batch loss: 0.071796 Batch F1: 0.8
Epoch:  178        2 Batch loss: 0.072388 Batch F1: 0.8421052631578948
Epoch:  178        3 Batch loss: 0.087146 Batch F1: 0.19999999999999998
Epoch:  178        4 Batch loss: 0.094848 Batch F1: 0.9166666666666666
Epoch:  178        5 Batch loss: 0.081834 Batch F1: 0.923076923076923
Epoch:  178        6 Batch loss: 0.062660 Batch F1: 0.5
Epoch:  178        7 Batch loss: 0.120432 Batch F1: 0.0
Epoch:  178        8 Batch loss: 0.071692 Batch F1: 0.5454545454545454
Epoch:  178        9 Batch loss: 0.062847 Batch F1: 0.8421052631578948
Epoch:  178       10 Batch loss: 0.084457 Batch F1: 0.8
Epoch:  178       11 Batch loss: 0.064048 Batch F1: 1.0
Epoch:  178       12 Batch loss: 0.076863 Batch F1: 0.6666666666666666
Train Avg Loss  178: 0.079251

Train Avg F1  178: 0.6696729440150492

Val Avg Loss  178: 0.069189

Val Avg F1  178:  0.5928643724696356

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 179
--------------------------------------------------------------
Epoch:  179        1 Batch loss: 0.071459 Batch F1: 0.625
Epoch:  179        2 Batch loss: 0.091663 Batch F1: 0.42857142857142855
Epoch:  179        3 Batch loss: 0.066871 Batch F1: 0.4444444444444445
Epoch:  179        4 Batch loss: 0.061696 Batch F1: 0.6666666666666666
Epoch:  179        5 Batch loss: 0.084473 Batch F1: 0.3636363636363636
Epoch:  179        6 Batch loss: 0.073162 Batch F1: 0.6
Epoch:  179        7 Batch loss: 0.104056 Batch F1: 0.5
Epoch:  179        8 Batch loss: 0.084152 Batch F1: 0.9
Epoch:  179        9 Batch loss: 0.062338 Batch F1: 0.8333333333333333
Epoch:  179       10 Batch loss: 0.074625 Batch F1: 0.9565217391304348
Epoch:  179       11 Batch loss: 0.058091 Batch F1: 0.6
Epoch:  179       12 Batch loss: 0.061998 Batch F1: 0.6
Train Avg Loss  179: 0.074549

Train Avg F1  179: 0.6265144979818892

Val Avg Loss  179: 0.072081

Val Avg F1  179:  0.5841658341658341

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 180
--------------------------------------------------------------
Epoch:  180        1 Batch loss: 0.060167 Batch F1: 0.2857142857142857
Epoch:  180        2 Batch loss: 0.104708 Batch F1: 0.6666666666666666
Epoch:  180        3 Batch loss: 0.109803 Batch F1: 0.375
Epoch:  180        4 Batch loss: 0.058165 Batch F1: 0.8571428571428571
Epoch:  180        5 Batch loss: 0.081494 Batch F1: 0.9565217391304348
Epoch:  180        6 Batch loss: 0.061379 Batch F1: 1.0
Epoch:  180        7 Batch loss: 0.073803 Batch F1: 0.7272727272727273
Epoch:  180        8 Batch loss: 0.081045 Batch F1: 0.6153846153846153
Epoch:  180        9 Batch loss: 0.056598 Batch F1: 0.7272727272727273
Epoch:  180       10 Batch loss: 0.047159 Batch F1: 0.4
Epoch:  180       11 Batch loss: 0.099606 Batch F1: 0.0
Epoch:  180       12 Batch loss: 0.090486 Batch F1: 0.0
Train Avg Loss  180: 0.077034

Train Avg F1  180: 0.5509146348820262

Val Avg Loss  180: 0.077873

Val Avg F1  180:  0.7374999999999999

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 181
--------------------------------------------------------------
Epoch:  181        1 Batch loss: 0.110054 Batch F1: 0.42857142857142855
Epoch:  181        2 Batch loss: 0.101345 Batch F1: 0.9655172413793104
Epoch:  181        3 Batch loss: 0.090972 Batch F1: 0.7999999999999999
Epoch:  181        4 Batch loss: 0.085247 Batch F1: 0.42857142857142855
Epoch:  181        5 Batch loss: 0.089482 Batch F1: 0.5
Epoch:  181        6 Batch loss: 0.073687 Batch F1: 0.0
Epoch:  181        7 Batch loss: 0.060697 Batch F1: 0.4444444444444445
Epoch:  181        8 Batch loss: 0.082444 Batch F1: 0.6
Epoch:  181        9 Batch loss: 0.062097 Batch F1: 0.8571428571428571
Epoch:  181       10 Batch loss: 0.069903 Batch F1: 0.7692307692307693
Epoch:  181       11 Batch loss: 0.063767 Batch F1: 0.7142857142857143
Epoch:  181       12 Batch loss: 0.059743 Batch F1: 0.5
Train Avg Loss  181: 0.079120

Train Avg F1  181: 0.583980323635496

Val Avg Loss  181: 0.072611

Val Avg F1  181:  0.5788461538461538

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 182
--------------------------------------------------------------
Epoch:  182        1 Batch loss: 0.048271 Batch F1: 0.5714285714285715
Epoch:  182        2 Batch loss: 0.069021 Batch F1: 0.4444444444444445
Epoch:  182        3 Batch loss: 0.114170 Batch F1: 0.5
Epoch:  182        4 Batch loss: 0.087009 Batch F1: 0.3076923076923077
Epoch:  182        5 Batch loss: 0.070118 Batch F1: 1.0
Epoch:  182        6 Batch loss: 0.080409 Batch F1: 0.9166666666666666
Epoch:  182        7 Batch loss: 0.066198 Batch F1: 1.0
Epoch:  182        8 Batch loss: 0.062732 Batch F1: 0.7272727272727273
Epoch:  182        9 Batch loss: 0.083806 Batch F1: 0.5714285714285715
Epoch:  182       10 Batch loss: 0.070434 Batch F1: 0.5
Epoch:  182       11 Batch loss: 0.081193 Batch F1: 0.4615384615384615
Epoch:  182       12 Batch loss: 0.066538 Batch F1: 0.6666666666666666
Train Avg Loss  182: 0.074992

Train Avg F1  182: 0.6389282014282015

Val Avg Loss  182: 0.069054

Val Avg F1  182:  0.6222222222222222

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 183
--------------------------------------------------------------
Epoch:  183        1 Batch loss: 0.061233 Batch F1: 0.4444444444444445
Epoch:  183        2 Batch loss: 0.072445 Batch F1: 0.3636363636363636
Epoch:  183        3 Batch loss: 0.061380 Batch F1: 0.8571428571428571
Epoch:  183        4 Batch loss: 0.074089 Batch F1: 0.5
Epoch:  183        5 Batch loss: 0.088535 Batch F1: 0.19999999999999998
Epoch:  183        6 Batch loss: 0.090429 Batch F1: 0.5882352941176471
Epoch:  183        7 Batch loss: 0.049517 Batch F1: 0.7272727272727273
Epoch:  183        8 Batch loss: 0.066983 Batch F1: 0.4
Epoch:  183        9 Batch loss: 0.082515 Batch F1: 0.7272727272727273
Epoch:  183       10 Batch loss: 0.079049 Batch F1: 0.7499999999999999
Epoch:  183       11 Batch loss: 0.062191 Batch F1: 0.6666666666666666
Epoch:  183       12 Batch loss: 0.069487 Batch F1: 0.923076923076923
Train Avg Loss  183: 0.071488

Train Avg F1  183: 0.5956456669691965

Val Avg Loss  183: 0.066197

Val Avg F1  183:  0.8705882352941177

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 184
--------------------------------------------------------------
Epoch:  184        1 Batch loss: 0.086630 Batch F1: 0.8
Epoch:  184        2 Batch loss: 0.070949 Batch F1: 0.8750000000000001
Epoch:  184        3 Batch loss: 0.052996 Batch F1: 0.9090909090909091
Epoch:  184        4 Batch loss: 0.069916 Batch F1: 0.9
Epoch:  184        5 Batch loss: 0.057293 Batch F1: 0.9473684210526316
Epoch:  184        6 Batch loss: 0.066791 Batch F1: 0.2222222222222222
Epoch:  184        7 Batch loss: 0.069385 Batch F1: 0.6666666666666666
Epoch:  184        8 Batch loss: 0.066764 Batch F1: 0.8333333333333333
Epoch:  184        9 Batch loss: 0.081798 Batch F1: 0.625
Epoch:  184       10 Batch loss: 0.083119 Batch F1: 0.7058823529411764
Epoch:  184       11 Batch loss: 0.077605 Batch F1: 0.9565217391304348
Epoch:  184       12 Batch loss: 0.062495 Batch F1: 1.0
Train Avg Loss  184: 0.070478

Train Avg F1  184: 0.786757137036448

Val Avg Loss  184: 0.064450

Val Avg F1  184:  0.7738095238095238

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 185
--------------------------------------------------------------
Epoch:  185        1 Batch loss: 0.054793 Batch F1: 1.0
Epoch:  185        2 Batch loss: 0.055658 Batch F1: 0.7272727272727273
Epoch:  185        3 Batch loss: 0.076539 Batch F1: 0.4615384615384615
Epoch:  185        4 Batch loss: 0.056792 Batch F1: 0.7272727272727273
Epoch:  185        5 Batch loss: 0.056776 Batch F1: 0.4444444444444445
Epoch:  185        6 Batch loss: 0.092126 Batch F1: 0.3076923076923077
Epoch:  185        7 Batch loss: 0.067869 Batch F1: 0.7777777777777778
Epoch:  185        8 Batch loss: 0.066228 Batch F1: 0.9411764705882353
Epoch:  185        9 Batch loss: 0.090465 Batch F1: 0.888888888888889
Epoch:  185       10 Batch loss: 0.078132 Batch F1: 0.8
Epoch:  185       11 Batch loss: 0.077814 Batch F1: 0.6666666666666666
Epoch:  185       12 Batch loss: 0.052415 Batch F1: 0.5714285714285715
Train Avg Loss  185: 0.068801

Train Avg F1  185: 0.6928465869642341

Val Avg Loss  185: 0.066895

Val Avg F1  185:  0.5988970588235294

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 186
--------------------------------------------------------------
Epoch:  186        1 Batch loss: 0.111119 Batch F1: 0.25
Epoch:  186        2 Batch loss: 0.046600 Batch F1: 0.5714285714285715
Epoch:  186        3 Batch loss: 0.083228 Batch F1: 0.5333333333333333
Epoch:  186        4 Batch loss: 0.058941 Batch F1: 0.8
Epoch:  186        5 Batch loss: 0.049837 Batch F1: 1.0
Epoch:  186        6 Batch loss: 0.074295 Batch F1: 0.8421052631578948
Epoch:  186        7 Batch loss: 0.065290 Batch F1: 0.8750000000000001
Epoch:  186        8 Batch loss: 0.066995 Batch F1: 0.8333333333333333
Epoch:  186        9 Batch loss: 0.072160 Batch F1: 0.9411764705882353
Epoch:  186       10 Batch loss: 0.066906 Batch F1: 0.6666666666666666
Epoch:  186       11 Batch loss: 0.061479 Batch F1: 0.8750000000000001
Epoch:  186       12 Batch loss: 0.103055 Batch F1: 0.631578947368421
Train Avg Loss  186: 0.071659

Train Avg F1  186: 0.7349685488230381

Val Avg Loss  186: 0.063852

Val Avg F1  186:  0.7077838827838827

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 187
--------------------------------------------------------------
Epoch:  187        1 Batch loss: 0.066910 Batch F1: 0.888888888888889
Epoch:  187        2 Batch loss: 0.065699 Batch F1: 0.9
Epoch:  187        3 Batch loss: 0.076902 Batch F1: 0.7692307692307693
Epoch:  187        4 Batch loss: 0.061958 Batch F1: 0.8
Epoch:  187        5 Batch loss: 0.085017 Batch F1: 0.761904761904762
Epoch:  187        6 Batch loss: 0.061217 Batch F1: 0.8333333333333333
Epoch:  187        7 Batch loss: 0.065144 Batch F1: 0.8
Epoch:  187        8 Batch loss: 0.067430 Batch F1: 0.6666666666666666
Epoch:  187        9 Batch loss: 0.069223 Batch F1: 0.5454545454545454
Epoch:  187       10 Batch loss: 0.058243 Batch F1: 0.5714285714285715
Epoch:  187       11 Batch loss: 0.067416 Batch F1: 0.6153846153846153
Epoch:  187       12 Batch loss: 0.098444 Batch F1: 0.6666666666666666
Train Avg Loss  187: 0.070300

Train Avg F1  187: 0.7349132349132348

Val Avg Loss  187: 0.063602

Val Avg F1  187:  0.8071348940914158

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 188
--------------------------------------------------------------
Epoch:  188        1 Batch loss: 0.080081 Batch F1: 0.8
Epoch:  188        2 Batch loss: 0.064217 Batch F1: 0.8750000000000001
Epoch:  188        3 Batch loss: 0.050418 Batch F1: 1.0
Epoch:  188        4 Batch loss: 0.068782 Batch F1: 0.5714285714285715
Epoch:  188        5 Batch loss: 0.088508 Batch F1: 0.42857142857142855
Epoch:  188        6 Batch loss: 0.067724 Batch F1: 0.5454545454545454
Epoch:  188        7 Batch loss: 0.053840 Batch F1: 0.6
Epoch:  188        8 Batch loss: 0.073893 Batch F1: 0.5
Epoch:  188        9 Batch loss: 0.064442 Batch F1: 0.4
Epoch:  188       10 Batch loss: 0.061607 Batch F1: 0.6666666666666666
Epoch:  188       11 Batch loss: 0.088376 Batch F1: 0.896551724137931
Epoch:  188       12 Batch loss: 0.065803 Batch F1: 0.9090909090909091
Train Avg Loss  188: 0.068974

Train Avg F1  188: 0.6827303204458377

Val Avg Loss  188: 0.069075

Val Avg F1  188:  0.9270833333333334

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 189
--------------------------------------------------------------
Epoch:  189        1 Batch loss: 0.076829 Batch F1: 0.9473684210526316
Epoch:  189        2 Batch loss: 0.050795 Batch F1: 0.6666666666666666
Epoch:  189        3 Batch loss: 0.072419 Batch F1: 0.5333333333333333
Epoch:  189        4 Batch loss: 0.104513 Batch F1: 0.5
Epoch:  189        5 Batch loss: 0.073144 Batch F1: 0.5
Epoch:  189        6 Batch loss: 0.067358 Batch F1: 0.6
Epoch:  189        7 Batch loss: 0.045903 Batch F1: 0.8
Epoch:  189        8 Batch loss: 0.077556 Batch F1: 0.7777777777777778
Epoch:  189        9 Batch loss: 0.050731 Batch F1: 0.8
Epoch:  189       10 Batch loss: 0.077107 Batch F1: 0.33333333333333337
Epoch:  189       11 Batch loss: 0.082380 Batch F1: 0.6
Epoch:  189       12 Batch loss: 0.091086 Batch F1: 0.8421052631578948
Train Avg Loss  189: 0.072485

Train Avg F1  189: 0.6583820662768031

Val Avg Loss  189: 0.066016

Val Avg F1  189:  0.9314393939393939

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 190
--------------------------------------------------------------
Epoch:  190        1 Batch loss: 0.065614 Batch F1: 0.8750000000000001
Epoch:  190        2 Batch loss: 0.065473 Batch F1: 0.923076923076923
Epoch:  190        3 Batch loss: 0.077393 Batch F1: 0.888888888888889
Epoch:  190        4 Batch loss: 0.075122 Batch F1: 0.9090909090909091
Epoch:  190        5 Batch loss: 0.084162 Batch F1: 0.8571428571428571
Epoch:  190        6 Batch loss: 0.061827 Batch F1: 0.923076923076923
Epoch:  190        7 Batch loss: 0.043619 Batch F1: 1.0
Epoch:  190        8 Batch loss: 0.047432 Batch F1: 0.6666666666666666
Epoch:  190        9 Batch loss: 0.086426 Batch F1: 0.3076923076923077
Epoch:  190       10 Batch loss: 0.100873 Batch F1: 0.0
Epoch:  190       11 Batch loss: 0.072485 Batch F1: 0.761904761904762
Epoch:  190       12 Batch loss: 0.063735 Batch F1: 0.8333333333333333
Train Avg Loss  190: 0.070347

Train Avg F1  190: 0.7454894642394644

Val Avg Loss  190: 0.074100

Val Avg F1  190:  0.9160633484162897

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 191
--------------------------------------------------------------
Epoch:  191        1 Batch loss: 0.079066 Batch F1: 0.6666666666666666
Epoch:  191        2 Batch loss: 0.075353 Batch F1: 1.0
Epoch:  191        3 Batch loss: 0.053488 Batch F1: 0.6666666666666666
Epoch:  191        4 Batch loss: 0.042601 Batch F1: 0.6666666666666666
Epoch:  191        5 Batch loss: 0.096523 Batch F1: 0.5
Epoch:  191        6 Batch loss: 0.101499 Batch F1: 0.6
Epoch:  191        7 Batch loss: 0.078429 Batch F1: 0.6666666666666666
Epoch:  191        8 Batch loss: 0.073096 Batch F1: 0.6153846153846153
Epoch:  191        9 Batch loss: 0.083064 Batch F1: 0.8750000000000001
Epoch:  191       10 Batch loss: 0.077100 Batch F1: 0.8333333333333334
Epoch:  191       11 Batch loss: 0.086657 Batch F1: 0.7499999999999999
Epoch:  191       12 Batch loss: 0.062131 Batch F1: 0.6153846153846153
Train Avg Loss  191: 0.075751

Train Avg F1  191: 0.7046474358974358

Val Avg Loss  191: 0.070229

Val Avg F1  191:  0.5543672014260249

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 192
--------------------------------------------------------------
Epoch:  192        1 Batch loss: 0.050810 Batch F1: 0.8
Epoch:  192        2 Batch loss: 0.061937 Batch F1: 0.5
Epoch:  192        3 Batch loss: 0.083618 Batch F1: 0.0
Epoch:  192        4 Batch loss: 0.101637 Batch F1: 0.16666666666666669
Epoch:  192        5 Batch loss: 0.094125 Batch F1: 0.8181818181818181
Epoch:  192        6 Batch loss: 0.068242 Batch F1: 1.0
Epoch:  192        7 Batch loss: 0.096117 Batch F1: 0.6666666666666666
Epoch:  192        8 Batch loss: 0.069182 Batch F1: 0.7692307692307693
Epoch:  192        9 Batch loss: 0.060940 Batch F1: 0.6666666666666666
Epoch:  192       10 Batch loss: 0.109994 Batch F1: 0.13333333333333333
Epoch:  192       11 Batch loss: 0.095159 Batch F1: 0.5882352941176471
Epoch:  192       12 Batch loss: 0.077971 Batch F1: 0.7692307692307693
Train Avg Loss  192: 0.080811

Train Avg F1  192: 0.5731843320078615

Val Avg Loss  192: 0.074707

Val Avg F1  192:  0.9195333651855391

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 193
--------------------------------------------------------------
Epoch:  193        1 Batch loss: 0.081049 Batch F1: 0.923076923076923
Epoch:  193        2 Batch loss: 0.065371 Batch F1: 1.0
Epoch:  193        3 Batch loss: 0.101619 Batch F1: 0.8181818181818181
Epoch:  193        4 Batch loss: 0.071492 Batch F1: 0.5
Epoch:  193        5 Batch loss: 0.099273 Batch F1: 0.5
Epoch:  193        6 Batch loss: 0.089508 Batch F1: 0.4615384615384615
Epoch:  193        7 Batch loss: 0.060347 Batch F1: 0.7142857142857143
Epoch:  193        8 Batch loss: 0.086212 Batch F1: 0.4615384615384615
Epoch:  193        9 Batch loss: 0.063482 Batch F1: 0.8
Epoch:  193       10 Batch loss: 0.069671 Batch F1: 0.7368421052631579
Epoch:  193       11 Batch loss: 0.062827 Batch F1: 0.6153846153846153
Epoch:  193       12 Batch loss: 0.055506 Batch F1: 0.7272727272727273
Train Avg Loss  193: 0.075530

Train Avg F1  193: 0.6881767355451566

Val Avg Loss  193: 0.065709

Val Avg F1  193:  0.65

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 194
--------------------------------------------------------------
Epoch:  194        1 Batch loss: 0.050290 Batch F1: 0.7272727272727273
Epoch:  194        2 Batch loss: 0.068199 Batch F1: 0.8
Epoch:  194        3 Batch loss: 0.065833 Batch F1: 0.7058823529411764
Epoch:  194        4 Batch loss: 0.080489 Batch F1: 0.4615384615384615
Epoch:  194        5 Batch loss: 0.053018 Batch F1: 0.5
Epoch:  194        6 Batch loss: 0.077781 Batch F1: 0.4
Epoch:  194        7 Batch loss: 0.097955 Batch F1: 0.15384615384615385
Epoch:  194        8 Batch loss: 0.058233 Batch F1: 0.6666666666666666
Epoch:  194        9 Batch loss: 0.076794 Batch F1: 0.8421052631578948
Epoch:  194       10 Batch loss: 0.069725 Batch F1: 0.9473684210526316
Epoch:  194       11 Batch loss: 0.067077 Batch F1: 0.888888888888889
Epoch:  194       12 Batch loss: 0.068708 Batch F1: 0.8571428571428571
Train Avg Loss  194: 0.069509

Train Avg F1  194: 0.6625593160422882

Val Avg Loss  194: 0.065826

Val Avg F1  194:  0.9436274509803921

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 195
--------------------------------------------------------------
Epoch:  195        1 Batch loss: 0.085004 Batch F1: 0.888888888888889
Epoch:  195        2 Batch loss: 0.081475 Batch F1: 0.9473684210526316
Epoch:  195        3 Batch loss: 0.059508 Batch F1: 1.0
Epoch:  195        4 Batch loss: 0.061583 Batch F1: 0.8750000000000001
Epoch:  195        5 Batch loss: 0.061089 Batch F1: 0.923076923076923
Epoch:  195        6 Batch loss: 0.060776 Batch F1: 0.5
Epoch:  195        7 Batch loss: 0.065212 Batch F1: 0.6
Epoch:  195        8 Batch loss: 0.037775 Batch F1: 0.9090909090909091
Epoch:  195        9 Batch loss: 0.125561 Batch F1: 0.23529411764705882
Epoch:  195       10 Batch loss: 0.073231 Batch F1: 0.5714285714285715
Epoch:  195       11 Batch loss: 0.076484 Batch F1: 0.7058823529411764
Epoch:  195       12 Batch loss: 0.057696 Batch F1: 1.0
Train Avg Loss  195: 0.070450

Train Avg F1  195: 0.7630025153438466

Val Avg Loss  195: 0.072910

Val Avg F1  195:  0.9195046439628483

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 196
--------------------------------------------------------------
Epoch:  196        1 Batch loss: 0.075562 Batch F1: 0.888888888888889
Epoch:  196        2 Batch loss: 0.087625 Batch F1: 0.7368421052631579
Epoch:  196        3 Batch loss: 0.076123 Batch F1: 0.8421052631578948
Epoch:  196        4 Batch loss: 0.053784 Batch F1: 1.0
Epoch:  196        5 Batch loss: 0.062552 Batch F1: 0.6153846153846153
Epoch:  196        6 Batch loss: 0.054292 Batch F1: 0.5
Epoch:  196        7 Batch loss: 0.092035 Batch F1: 0.47058823529411764
Epoch:  196        8 Batch loss: 0.079207 Batch F1: 0.4
Epoch:  196        9 Batch loss: 0.055376 Batch F1: 0.6
Epoch:  196       10 Batch loss: 0.079504 Batch F1: 0.33333333333333337
Epoch:  196       11 Batch loss: 0.076946 Batch F1: 0.9473684210526316
Epoch:  196       12 Batch loss: 0.062533 Batch F1: 1.0
Train Avg Loss  196: 0.071295

Train Avg F1  196: 0.6945425718645533

Val Avg Loss  196: 0.064087

Val Avg F1  196:  0.8279761904761905

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 197
--------------------------------------------------------------
Epoch:  197        1 Batch loss: 0.083047 Batch F1: 0.5333333333333333
Epoch:  197        2 Batch loss: 0.072058 Batch F1: 0.9565217391304348
Epoch:  197        3 Batch loss: 0.056329 Batch F1: 0.8
Epoch:  197        4 Batch loss: 0.079478 Batch F1: 0.6666666666666666
Epoch:  197        5 Batch loss: 0.056911 Batch F1: 0.9333333333333333
Epoch:  197        6 Batch loss: 0.056169 Batch F1: 0.6666666666666666
Epoch:  197        7 Batch loss: 0.056400 Batch F1: 0.2857142857142857
Epoch:  197        8 Batch loss: 0.055449 Batch F1: 0.6666666666666666
Epoch:  197        9 Batch loss: 0.071329 Batch F1: 0.3636363636363636
Epoch:  197       10 Batch loss: 0.095776 Batch F1: 0.5555555555555556
Epoch:  197       11 Batch loss: 0.082094 Batch F1: 0.625
Epoch:  197       12 Batch loss: 0.065333 Batch F1: 0.9333333333333333
Train Avg Loss  197: 0.069198

Train Avg F1  197: 0.6655356620030534

Val Avg Loss  197: 0.065472

Val Avg F1  197:  0.9261437908496731

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 198
--------------------------------------------------------------
Epoch:  198        1 Batch loss: 0.071238 Batch F1: 0.888888888888889
Epoch:  198        2 Batch loss: 0.063002 Batch F1: 1.0
Epoch:  198        3 Batch loss: 0.073478 Batch F1: 0.8750000000000001
Epoch:  198        4 Batch loss: 0.065532 Batch F1: 0.7142857142857143
Epoch:  198        5 Batch loss: 0.077575 Batch F1: 0.3076923076923077
Epoch:  198        6 Batch loss: 0.076972 Batch F1: 0.5714285714285715
Epoch:  198        7 Batch loss: 0.048820 Batch F1: 0.9090909090909091
Epoch:  198        8 Batch loss: 0.060076 Batch F1: 0.8571428571428571
Epoch:  198        9 Batch loss: 0.091954 Batch F1: 0.896551724137931
Epoch:  198       10 Batch loss: 0.064001 Batch F1: 1.0
Epoch:  198       11 Batch loss: 0.083420 Batch F1: 0.9090909090909091
Epoch:  198       12 Batch loss: 0.065753 Batch F1: 0.2857142857142857
Train Avg Loss  198: 0.070152

Train Avg F1  198: 0.7679071806226978

Val Avg Loss  198: 0.065356

Val Avg F1  198:  0.576007326007326

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 199
--------------------------------------------------------------
Epoch:  199        1 Batch loss: 0.085119 Batch F1: 0.33333333333333337
Epoch:  199        2 Batch loss: 0.048781 Batch F1: 0.6666666666666666
Epoch:  199        3 Batch loss: 0.069622 Batch F1: 0.8181818181818181
Epoch:  199        4 Batch loss: 0.054230 Batch F1: 0.8750000000000001
Epoch:  199        5 Batch loss: 0.069567 Batch F1: 0.8333333333333333
Epoch:  199        6 Batch loss: 0.088658 Batch F1: 0.7000000000000001
Epoch:  199        7 Batch loss: 0.064128 Batch F1: 0.7272727272727273
Epoch:  199        8 Batch loss: 0.071273 Batch F1: 0.6666666666666666
Epoch:  199        9 Batch loss: 0.072428 Batch F1: 0.0
Epoch:  199       10 Batch loss: 0.069421 Batch F1: 0.3636363636363636
Epoch:  199       11 Batch loss: 0.056406 Batch F1: 0.8571428571428571
Epoch:  199       12 Batch loss: 0.089354 Batch F1: 0.42857142857142855
Train Avg Loss  199: 0.069916

Train Avg F1  199: 0.6058170995670996

Val Avg Loss  199: 0.064251

Val Avg F1  199:  0.9135177687809266

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 200
--------------------------------------------------------------
Epoch:  200        1 Batch loss: 0.054183 Batch F1: 1.0
Epoch:  200        2 Batch loss: 0.070614 Batch F1: 1.0
Epoch:  200        3 Batch loss: 0.061922 Batch F1: 0.923076923076923
Epoch:  200        4 Batch loss: 0.065497 Batch F1: 0.7142857142857143
Epoch:  200        5 Batch loss: 0.084108 Batch F1: 0.5555555555555556
Epoch:  200        6 Batch loss: 0.051025 Batch F1: 0.8571428571428571
Epoch:  200        7 Batch loss: 0.042013 Batch F1: 0.888888888888889
Epoch:  200        8 Batch loss: 0.084772 Batch F1: 0.846153846153846
Epoch:  200        9 Batch loss: 0.116197 Batch F1: 0.6
Epoch:  200       10 Batch loss: 0.072452 Batch F1: 0.875
Epoch:  200       11 Batch loss: 0.058345 Batch F1: 1.0
Epoch:  200       12 Batch loss: 0.078029 Batch F1: 0.8750000000000001
Train Avg Loss  200: 0.069930

Train Avg F1  200: 0.8445919820919819

Val Avg Loss  200: 0.063266

Val Avg F1  200:  0.7975490196078431

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 201
--------------------------------------------------------------
Epoch:  201        1 Batch loss: 0.076281 Batch F1: 0.8421052631578948
Epoch:  201        2 Batch loss: 0.055812 Batch F1: 1.0
Epoch:  201        3 Batch loss: 0.049752 Batch F1: 1.0
Epoch:  201        4 Batch loss: 0.083699 Batch F1: 0.625
Epoch:  201        5 Batch loss: 0.057704 Batch F1: 0.8571428571428571
Epoch:  201        6 Batch loss: 0.066327 Batch F1: 0.625
Epoch:  201        7 Batch loss: 0.096392 Batch F1: 0.6363636363636364
Epoch:  201        8 Batch loss: 0.090173 Batch F1: 0.8571428571428571
Epoch:  201        9 Batch loss: 0.061565 Batch F1: 0.923076923076923
Epoch:  201       10 Batch loss: 0.068027 Batch F1: 1.0
Epoch:  201       11 Batch loss: 0.069077 Batch F1: 0.8750000000000001
Epoch:  201       12 Batch loss: 0.072014 Batch F1: 0.6666666666666666
Train Avg Loss  201: 0.070569

Train Avg F1  201: 0.8256248502959029

Val Avg Loss  201: 0.068847

Val Avg F1  201:  0.6098214285714285

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 202
--------------------------------------------------------------
Epoch:  202        1 Batch loss: 0.073152 Batch F1: 0.6153846153846153
Epoch:  202        2 Batch loss: 0.109833 Batch F1: 0.15384615384615385
Epoch:  202        3 Batch loss: 0.064193 Batch F1: 0.7142857142857143
Epoch:  202        4 Batch loss: 0.087834 Batch F1: 0.5263157894736842
Epoch:  202        5 Batch loss: 0.066406 Batch F1: 0.923076923076923
Epoch:  202        6 Batch loss: 0.080716 Batch F1: 0.8571428571428571
Epoch:  202        7 Batch loss: 0.077357 Batch F1: 0.782608695652174
Epoch:  202        8 Batch loss: 0.079378 Batch F1: 0.3636363636363636
Epoch:  202        9 Batch loss: 0.068909 Batch F1: 0.5714285714285715
Epoch:  202       10 Batch loss: 0.041788 Batch F1: 0.6666666666666666
Epoch:  202       11 Batch loss: 0.049646 Batch F1: 0.7272727272727273
Epoch:  202       12 Batch loss: 0.054362 Batch F1: 0.33333333333333337
Train Avg Loss  202: 0.071131

Train Avg F1  202: 0.6029165342666486

Val Avg Loss  202: 0.066062

Val Avg F1  202:  0.7208333333333332

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 203
--------------------------------------------------------------
Epoch:  203        1 Batch loss: 0.083904 Batch F1: 0.6666666666666666
Epoch:  203        2 Batch loss: 0.065474 Batch F1: 0.7692307692307693
Epoch:  203        3 Batch loss: 0.088235 Batch F1: 0.42857142857142855
Epoch:  203        4 Batch loss: 0.069825 Batch F1: 0.7499999999999999
Epoch:  203        5 Batch loss: 0.049022 Batch F1: 0.8
Epoch:  203        6 Batch loss: 0.081985 Batch F1: 0.6666666666666666
Epoch:  203        7 Batch loss: 0.047262 Batch F1: 0.8333333333333333
Epoch:  203        8 Batch loss: 0.067241 Batch F1: 0.6666666666666666
Epoch:  203        9 Batch loss: 0.073249 Batch F1: 0.9473684210526316
Epoch:  203       10 Batch loss: 0.057034 Batch F1: 1.0
Epoch:  203       11 Batch loss: 0.062317 Batch F1: 0.923076923076923
Epoch:  203       12 Batch loss: 0.092705 Batch F1: 0.5882352941176471
Train Avg Loss  203: 0.069854

Train Avg F1  203: 0.7533180141152278

Val Avg Loss  203: 0.063611

Val Avg F1  203:  0.807852564102564

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 204
--------------------------------------------------------------
Epoch:  204        1 Batch loss: 0.089250 Batch F1: 0.8181818181818181
Epoch:  204        2 Batch loss: 0.072916 Batch F1: 0.9600000000000001
Epoch:  204        3 Batch loss: 0.063081 Batch F1: 0.888888888888889
Epoch:  204        4 Batch loss: 0.072837 Batch F1: 0.8235294117647058
Epoch:  204        5 Batch loss: 0.064421 Batch F1: 0.7272727272727273
Epoch:  204        6 Batch loss: 0.065221 Batch F1: 0.5454545454545454
Epoch:  204        7 Batch loss: 0.044628 Batch F1: 0.7499999999999999
Epoch:  204        8 Batch loss: 0.066182 Batch F1: 0.4
Epoch:  204        9 Batch loss: 0.073349 Batch F1: 0.6153846153846153
Epoch:  204       10 Batch loss: 0.089945 Batch F1: 0.3076923076923077
Epoch:  204       11 Batch loss: 0.065071 Batch F1: 0.25
Epoch:  204       12 Batch loss: 0.083012 Batch F1: 0.7368421052631579
Train Avg Loss  204: 0.070826

Train Avg F1  204: 0.651937201658564

Val Avg Loss  204: 0.066333

Val Avg F1  204:  0.9235119047619049

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 205
--------------------------------------------------------------
Epoch:  205        1 Batch loss: 0.066953 Batch F1: 0.9473684210526316
Epoch:  205        2 Batch loss: 0.076136 Batch F1: 0.923076923076923
Epoch:  205        3 Batch loss: 0.067625 Batch F1: 1.0
Epoch:  205        4 Batch loss: 0.065384 Batch F1: 0.8571428571428571
Epoch:  205        5 Batch loss: 0.054873 Batch F1: 0.5
Epoch:  205        6 Batch loss: 0.072427 Batch F1: 0.7142857142857143
Epoch:  205        7 Batch loss: 0.055709 Batch F1: 0.5
Epoch:  205        8 Batch loss: 0.109155 Batch F1: 0.3076923076923077
Epoch:  205        9 Batch loss: 0.074964 Batch F1: 0.2222222222222222
Epoch:  205       10 Batch loss: 0.080631 Batch F1: 0.8
Epoch:  205       11 Batch loss: 0.095023 Batch F1: 0.8333333333333333
Epoch:  205       12 Batch loss: 0.088147 Batch F1: 0.9
Train Avg Loss  205: 0.075586

Train Avg F1  205: 0.7087601482338325

Val Avg Loss  205: 0.079608

Val Avg F1  205:  0.8879192702722114

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 206
--------------------------------------------------------------
Epoch:  206        1 Batch loss: 0.100500 Batch F1: 0.8333333333333333
Epoch:  206        2 Batch loss: 0.072285 Batch F1: 1.0
Epoch:  206        3 Batch loss: 0.059748 Batch F1: 0.4444444444444445
Epoch:  206        4 Batch loss: 0.100473 Batch F1: 0.0
Epoch:  206        5 Batch loss: 0.059690 Batch F1: 0.25
Epoch:  206        6 Batch loss: 0.056963 Batch F1: 0.6666666666666666
Epoch:  206        7 Batch loss: 0.068357 Batch F1: 0.6666666666666666
Epoch:  206        8 Batch loss: 0.076266 Batch F1: 0.6666666666666666
Epoch:  206        9 Batch loss: 0.090803 Batch F1: 0.42857142857142855
Epoch:  206       10 Batch loss: 0.068897 Batch F1: 0.888888888888889
Epoch:  206       11 Batch loss: 0.060386 Batch F1: 0.9090909090909091
Epoch:  206       12 Batch loss: 0.089336 Batch F1: 0.7142857142857143
Train Avg Loss  206: 0.075309

Train Avg F1  206: 0.62238455988456

Val Avg Loss  206: 0.069249

Val Avg F1  206:  0.9310866910866911

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 207
--------------------------------------------------------------
Epoch:  207        1 Batch loss: 0.081896 Batch F1: 0.9090909090909091
Epoch:  207        2 Batch loss: 0.089362 Batch F1: 0.88
Epoch:  207        3 Batch loss: 0.080275 Batch F1: 0.7368421052631579
Epoch:  207        4 Batch loss: 0.079249 Batch F1: 0.625
Epoch:  207        5 Batch loss: 0.062495 Batch F1: 0.9090909090909091
Epoch:  207        6 Batch loss: 0.062922 Batch F1: 0.6666666666666666
Epoch:  207        7 Batch loss: 0.048264 Batch F1: 0.8
Epoch:  207        8 Batch loss: 0.063334 Batch F1: 0.6666666666666666
Epoch:  207        9 Batch loss: 0.073133 Batch F1: 0.5714285714285715
Epoch:  207       10 Batch loss: 0.068297 Batch F1: 0.5454545454545454
Epoch:  207       11 Batch loss: 0.073101 Batch F1: 0.7142857142857143
Epoch:  207       12 Batch loss: 0.073349 Batch F1: 0.6666666666666666
Train Avg Loss  207: 0.071306

Train Avg F1  207: 0.7242660628844838

Val Avg Loss  207: 0.064605

Val Avg F1  207:  0.7121349238996297

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 208
--------------------------------------------------------------
Epoch:  208        1 Batch loss: 0.065714 Batch F1: 0.7777777777777777
Epoch:  208        2 Batch loss: 0.073886 Batch F1: 0.4615384615384615
Epoch:  208        3 Batch loss: 0.075565 Batch F1: 0.8
Epoch:  208        4 Batch loss: 0.067976 Batch F1: 0.6666666666666666
Epoch:  208        5 Batch loss: 0.058951 Batch F1: 0.5
Epoch:  208        6 Batch loss: 0.056796 Batch F1: 0.2857142857142857
Epoch:  208        7 Batch loss: 0.099970 Batch F1: 0.47058823529411764
Epoch:  208        8 Batch loss: 0.073060 Batch F1: 0.625
Epoch:  208        9 Batch loss: 0.060376 Batch F1: 0.7058823529411764
Epoch:  208       10 Batch loss: 0.084443 Batch F1: 0.8
Epoch:  208       11 Batch loss: 0.067525 Batch F1: 1.0
Epoch:  208       12 Batch loss: 0.087161 Batch F1: 0.9090909090909091
Train Avg Loss  208: 0.072619

Train Avg F1  208: 0.6668548907519495

Val Avg Loss  208: 0.067842

Val Avg F1  208:  0.9251276759016698

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 209
--------------------------------------------------------------
Epoch:  209        1 Batch loss: 0.090864 Batch F1: 0.7058823529411764
Epoch:  209        2 Batch loss: 0.072009 Batch F1: 0.9523809523809523
Epoch:  209        3 Batch loss: 0.064770 Batch F1: 0.8571428571428571
Epoch:  209        4 Batch loss: 0.075090 Batch F1: 0.4
Epoch:  209        5 Batch loss: 0.047817 Batch F1: 0.8333333333333333
Epoch:  209        6 Batch loss: 0.066480 Batch F1: 0.6666666666666666
Epoch:  209        7 Batch loss: 0.066475 Batch F1: 0.25
Epoch:  209        8 Batch loss: 0.094348 Batch F1: 0.5555555555555556
Epoch:  209        9 Batch loss: 0.093253 Batch F1: 0.3076923076923077
Epoch:  209       10 Batch loss: 0.060025 Batch F1: 0.9333333333333333
Epoch:  209       11 Batch loss: 0.070890 Batch F1: 0.9090909090909091
Epoch:  209       12 Batch loss: 0.078536 Batch F1: 0.9473684210526316
Train Avg Loss  209: 0.073380

Train Avg F1  209: 0.6932038907658103

Val Avg Loss  209: 0.064800

Val Avg F1  209:  0.9261278195488722

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 210
--------------------------------------------------------------
Epoch:  210        1 Batch loss: 0.065840 Batch F1: 0.9333333333333333
Epoch:  210        2 Batch loss: 0.074996 Batch F1: 0.7499999999999999
Epoch:  210        3 Batch loss: 0.085937 Batch F1: 0.9166666666666666
Epoch:  210        4 Batch loss: 0.062605 Batch F1: 0.8
Epoch:  210        5 Batch loss: 0.062136 Batch F1: 0.9473684210526316
Epoch:  210        6 Batch loss: 0.068856 Batch F1: 1.0
Epoch:  210        7 Batch loss: 0.070459 Batch F1: 1.0
Epoch:  210        8 Batch loss: 0.069221 Batch F1: 0.5454545454545454
Epoch:  210        9 Batch loss: 0.090322 Batch F1: 0.18181818181818182
Epoch:  210       10 Batch loss: 0.066309 Batch F1: 0.9
Epoch:  210       11 Batch loss: 0.046842 Batch F1: 0.5714285714285715
Epoch:  210       12 Batch loss: 0.081777 Batch F1: 0.19999999999999998
Train Avg Loss  210: 0.070442

Train Avg F1  210: 0.7288391433128275

Val Avg Loss  210: 0.067991

Val Avg F1  210:  0.8866666666666666

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 211
--------------------------------------------------------------
Epoch:  211        1 Batch loss: 0.070220 Batch F1: 0.9090909090909091
Epoch:  211        2 Batch loss: 0.085720 Batch F1: 0.9565217391304348
Epoch:  211        3 Batch loss: 0.069197 Batch F1: 0.7272727272727273
Epoch:  211        4 Batch loss: 0.063715 Batch F1: 0.7692307692307693
Epoch:  211        5 Batch loss: 0.057759 Batch F1: 0.6
Epoch:  211        6 Batch loss: 0.056370 Batch F1: 0.6
Epoch:  211        7 Batch loss: 0.072450 Batch F1: 0.25
Epoch:  211        8 Batch loss: 0.091507 Batch F1: 0.5882352941176471
Epoch:  211        9 Batch loss: 0.086495 Batch F1: 0.8
Epoch:  211       10 Batch loss: 0.065536 Batch F1: 0.9473684210526316
Epoch:  211       11 Batch loss: 0.079101 Batch F1: 0.9090909090909091
Epoch:  211       12 Batch loss: 0.083348 Batch F1: 0.6666666666666666
Train Avg Loss  211: 0.073452

Train Avg F1  211: 0.7269564529710578

Val Avg Loss  211: 0.064896

Val Avg F1  211:  0.9201754385964913

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 212
--------------------------------------------------------------
Epoch:  212        1 Batch loss: 0.074984 Batch F1: 1.0
Epoch:  212        2 Batch loss: 0.055455 Batch F1: 0.9090909090909091
Epoch:  212        3 Batch loss: 0.093003 Batch F1: 0.25
Epoch:  212        4 Batch loss: 0.089053 Batch F1: 0.7368421052631579
Epoch:  212        5 Batch loss: 0.073131 Batch F1: 0.9333333333333333
Epoch:  212        6 Batch loss: 0.066305 Batch F1: 0.9333333333333333
Epoch:  212        7 Batch loss: 0.080120 Batch F1: 0.9166666666666666
Epoch:  212        8 Batch loss: 0.067249 Batch F1: 1.0
Epoch:  212        9 Batch loss: 0.061370 Batch F1: 1.0
Epoch:  212       10 Batch loss: 0.058250 Batch F1: 0.33333333333333337
Epoch:  212       11 Batch loss: 0.047803 Batch F1: 0.5714285714285715
Epoch:  212       12 Batch loss: 0.104005 Batch F1: 0.0
Train Avg Loss  212: 0.072561

Train Avg F1  212: 0.7153356877041088

Val Avg Loss  212: 0.073781

Val Avg F1  212:  0.5454545454545454

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 213
--------------------------------------------------------------
Epoch:  213        1 Batch loss: 0.084502 Batch F1: 0.625
Epoch:  213        2 Batch loss: 0.054657 Batch F1: 0.6
Epoch:  213        3 Batch loss: 0.070290 Batch F1: 0.5
Epoch:  213        4 Batch loss: 0.070712 Batch F1: 0.9473684210526316
Epoch:  213        5 Batch loss: 0.094309 Batch F1: 0.6666666666666666
Epoch:  213        6 Batch loss: 0.062890 Batch F1: 0.6
Epoch:  213        7 Batch loss: 0.057595 Batch F1: 0.7142857142857143
Epoch:  213        8 Batch loss: 0.074243 Batch F1: 0.625
Epoch:  213        9 Batch loss: 0.052505 Batch F1: 0.5
Epoch:  213       10 Batch loss: 0.073472 Batch F1: 0.6153846153846153
Epoch:  213       11 Batch loss: 0.082436 Batch F1: 0.5
Epoch:  213       12 Batch loss: 0.089888 Batch F1: 0.5882352941176471
Train Avg Loss  213: 0.072292

Train Avg F1  213: 0.6234950592922729

Val Avg Loss  213: 0.065412

Val Avg F1  213:  0.9263574660633485

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 214
--------------------------------------------------------------
Epoch:  214        1 Batch loss: 0.055687 Batch F1: 1.0
Epoch:  214        2 Batch loss: 0.080695 Batch F1: 0.88
Epoch:  214        3 Batch loss: 0.063121 Batch F1: 0.888888888888889
Epoch:  214        4 Batch loss: 0.062551 Batch F1: 0.7142857142857143
Epoch:  214        5 Batch loss: 0.081878 Batch F1: 0.6666666666666666
Epoch:  214        6 Batch loss: 0.066321 Batch F1: 0.8
Epoch:  214        7 Batch loss: 0.066535 Batch F1: 0.9333333333333333
Epoch:  214        8 Batch loss: 0.081532 Batch F1: 0.8571428571428571
Epoch:  214        9 Batch loss: 0.074120 Batch F1: 0.8571428571428571
Epoch:  214       10 Batch loss: 0.054157 Batch F1: 0.6666666666666666
Epoch:  214       11 Batch loss: 0.075400 Batch F1: 0.2222222222222222
Epoch:  214       12 Batch loss: 0.080589 Batch F1: 0.0
Train Avg Loss  214: 0.070216

Train Avg F1  214: 0.707195767195767

Val Avg Loss  214: 0.063270

Val Avg F1  214:  0.6407203907203908

Optimal Val loss (Epoch 160): 0.0631214315071702

Epoch 215
--------------------------------------------------------------
Epoch:  215        1 Batch loss: 0.061775 Batch F1: 0.5454545454545454
Epoch:  215        2 Batch loss: 0.080245 Batch F1: 0.8421052631578948
Epoch:  215        3 Batch loss: 0.064525 Batch F1: 0.9411764705882353
Epoch:  215        4 Batch loss: 0.077662 Batch F1: 0.9523809523809523
Epoch:  215        5 Batch loss: 0.050400 Batch F1: 1.0
Epoch:  215        6 Batch loss: 0.068503 Batch F1: 0.9
Epoch:  215        7 Batch loss: 0.074207 Batch F1: 0.8571428571428571
Epoch:  215        8 Batch loss: 0.055642 Batch F1: 0.5454545454545454
Epoch:  215        9 Batch loss: 0.058614 Batch F1: 0.5
Epoch:  215       10 Batch loss: 0.081179 Batch F1: 0.3636363636363636
Epoch:  215       11 Batch loss: 0.084558 Batch F1: 0.782608695652174
Epoch:  215       12 Batch loss: 0.062035 Batch F1: 0.9090909090909091
Train Avg Loss  215: 0.068279

Train Avg F1  215: 0.7615875502132062

Val Avg Loss  215: 0.062821

Val Avg F1  215:  0.8302332535885169

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 216
--------------------------------------------------------------
Epoch:  216        1 Batch loss: 0.066757 Batch F1: 0.9
Epoch:  216        2 Batch loss: 0.052149 Batch F1: 1.0
Epoch:  216        3 Batch loss: 0.083658 Batch F1: 0.9600000000000001
Epoch:  216        4 Batch loss: 0.076291 Batch F1: 0.9523809523809523
Epoch:  216        5 Batch loss: 0.070246 Batch F1: 0.6
Epoch:  216        6 Batch loss: 0.059421 Batch F1: 0.2857142857142857
Epoch:  216        7 Batch loss: 0.061760 Batch F1: 0.4444444444444445
Epoch:  216        8 Batch loss: 0.099128 Batch F1: 0.5
Epoch:  216        9 Batch loss: 0.062054 Batch F1: 0.4444444444444445
Epoch:  216       10 Batch loss: 0.076157 Batch F1: 0.7058823529411764
Epoch:  216       11 Batch loss: 0.044044 Batch F1: 0.6666666666666666
Epoch:  216       12 Batch loss: 0.090320 Batch F1: 0.7058823529411764
Train Avg Loss  216: 0.070166

Train Avg F1  216: 0.6804512916277622

Val Avg Loss  216: 0.063754

Val Avg F1  216:  0.9142857142857144

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 217
--------------------------------------------------------------
Epoch:  217        1 Batch loss: 0.069949 Batch F1: 1.0
Epoch:  217        2 Batch loss: 0.072192 Batch F1: 1.0
Epoch:  217        3 Batch loss: 0.066414 Batch F1: 0.8571428571428571
Epoch:  217        4 Batch loss: 0.083354 Batch F1: 0.7058823529411764
Epoch:  217        5 Batch loss: 0.095901 Batch F1: 0.4
Epoch:  217        6 Batch loss: 0.045745 Batch F1: 0.8571428571428571
Epoch:  217        7 Batch loss: 0.083675 Batch F1: 0.8
Epoch:  217        8 Batch loss: 0.055972 Batch F1: 0.9090909090909091
Epoch:  217        9 Batch loss: 0.061092 Batch F1: 0.9090909090909091
Epoch:  217       10 Batch loss: 0.062992 Batch F1: 0.5454545454545454
Epoch:  217       11 Batch loss: 0.075149 Batch F1: 0.5714285714285715
Epoch:  217       12 Batch loss: 0.055867 Batch F1: 0.4
Train Avg Loss  217: 0.069025

Train Avg F1  217: 0.7462694168576521

Val Avg Loss  217: 0.068630

Val Avg F1  217:  0.5510936431989064

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 218
--------------------------------------------------------------
Epoch:  218        1 Batch loss: 0.078855 Batch F1: 0.5333333333333333
Epoch:  218        2 Batch loss: 0.047474 Batch F1: 0.5714285714285715
Epoch:  218        3 Batch loss: 0.077704 Batch F1: 0.4615384615384615
Epoch:  218        4 Batch loss: 0.088518 Batch F1: 0.7499999999999999
Epoch:  218        5 Batch loss: 0.077141 Batch F1: 0.8333333333333333
Epoch:  218        6 Batch loss: 0.074128 Batch F1: 0.8750000000000001
Epoch:  218        7 Batch loss: 0.080099 Batch F1: 0.8
Epoch:  218        8 Batch loss: 0.065183 Batch F1: 0.25
Epoch:  218        9 Batch loss: 0.078535 Batch F1: 0.625
Epoch:  218       10 Batch loss: 0.099864 Batch F1: 0.4
Epoch:  218       11 Batch loss: 0.055618 Batch F1: 0.7142857142857143
Epoch:  218       12 Batch loss: 0.048298 Batch F1: 0.8
Train Avg Loss  218: 0.072618

Train Avg F1  218: 0.6344932844932845

Val Avg Loss  218: 0.063627

Val Avg F1  218:  0.9018525592055003

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 219
--------------------------------------------------------------
Epoch:  219        1 Batch loss: 0.050812 Batch F1: 0.923076923076923
Epoch:  219        2 Batch loss: 0.063977 Batch F1: 0.7272727272727273
Epoch:  219        3 Batch loss: 0.055542 Batch F1: 0.4444444444444445
Epoch:  219        4 Batch loss: 0.065690 Batch F1: 0.5454545454545454
Epoch:  219        5 Batch loss: 0.072582 Batch F1: 0.3636363636363636
Epoch:  219        6 Batch loss: 0.088324 Batch F1: 0.8235294117647058
Epoch:  219        7 Batch loss: 0.079172 Batch F1: 0.7058823529411764
Epoch:  219        8 Batch loss: 0.068976 Batch F1: 0.7692307692307693
Epoch:  219        9 Batch loss: 0.056463 Batch F1: 0.4444444444444445
Epoch:  219       10 Batch loss: 0.100591 Batch F1: 0.7499999999999999
Epoch:  219       11 Batch loss: 0.076923 Batch F1: 0.9655172413793104
Epoch:  219       12 Batch loss: 0.064559 Batch F1: 0.8
Train Avg Loss  219: 0.070301

Train Avg F1  219: 0.6885407686371177

Val Avg Loss  219: 0.064691

Val Avg F1  219:  0.9032467532467532

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 220
--------------------------------------------------------------
Epoch:  220        1 Batch loss: 0.073147 Batch F1: 0.9
Epoch:  220        2 Batch loss: 0.056219 Batch F1: 0.8
Epoch:  220        3 Batch loss: 0.098009 Batch F1: 0.47058823529411764
Epoch:  220        4 Batch loss: 0.079309 Batch F1: 0.4615384615384615
Epoch:  220        5 Batch loss: 0.076660 Batch F1: 0.3636363636363636
Epoch:  220        6 Batch loss: 0.072827 Batch F1: 0.7058823529411764
Epoch:  220        7 Batch loss: 0.063877 Batch F1: 0.9333333333333333
Epoch:  220        8 Batch loss: 0.047010 Batch F1: 1.0
Epoch:  220        9 Batch loss: 0.073221 Batch F1: 0.6153846153846153
Epoch:  220       10 Batch loss: 0.073328 Batch F1: 0.2222222222222222
Epoch:  220       11 Batch loss: 0.041370 Batch F1: 0.6666666666666666
Epoch:  220       12 Batch loss: 0.087970 Batch F1: 0.5333333333333333
Train Avg Loss  220: 0.070246

Train Avg F1  220: 0.6393821320291909

Val Avg Loss  220: 0.064439

Val Avg F1  220:  0.8596362229102168

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 221
--------------------------------------------------------------
Epoch:  221        1 Batch loss: 0.065810 Batch F1: 0.9411764705882353
Epoch:  221        2 Batch loss: 0.057168 Batch F1: 1.0
Epoch:  221        3 Batch loss: 0.089537 Batch F1: 0.8571428571428571
Epoch:  221        4 Batch loss: 0.085400 Batch F1: 0.88
Epoch:  221        5 Batch loss: 0.066139 Batch F1: 0.9411764705882353
Epoch:  221        6 Batch loss: 0.067870 Batch F1: 0.8571428571428571
Epoch:  221        7 Batch loss: 0.069387 Batch F1: 0.8235294117647058
Epoch:  221        8 Batch loss: 0.061106 Batch F1: 0.8333333333333333
Epoch:  221        9 Batch loss: 0.061490 Batch F1: 0.6
Epoch:  221       10 Batch loss: 0.068858 Batch F1: 0.7142857142857143
Epoch:  221       11 Batch loss: 0.058118 Batch F1: 1.0
Epoch:  221       12 Batch loss: 0.076313 Batch F1: 0.5454545454545454
Train Avg Loss  221: 0.068933

Train Avg F1  221: 0.8327701383583735

Val Avg Loss  221: 0.064008

Val Avg F1  221:  0.7420454545454545

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 222
--------------------------------------------------------------
Epoch:  222        1 Batch loss: 0.070969 Batch F1: 0.7058823529411764
Epoch:  222        2 Batch loss: 0.065362 Batch F1: 1.0
Epoch:  222        3 Batch loss: 0.058988 Batch F1: 0.9333333333333333
Epoch:  222        4 Batch loss: 0.110423 Batch F1: 0.7586206896551725
Epoch:  222        5 Batch loss: 0.081563 Batch F1: 0.7499999999999999
Epoch:  222        6 Batch loss: 0.075578 Batch F1: 1.0
Epoch:  222        7 Batch loss: 0.055075 Batch F1: 0.8750000000000001
Epoch:  222        8 Batch loss: 0.068723 Batch F1: 0.5
Epoch:  222        9 Batch loss: 0.064256 Batch F1: 0.2857142857142857
Epoch:  222       10 Batch loss: 0.051022 Batch F1: 0.5714285714285715
Epoch:  222       11 Batch loss: 0.058602 Batch F1: 0.8750000000000001
Epoch:  222       12 Batch loss: 0.046607 Batch F1: 0.5714285714285715
Train Avg Loss  222: 0.067264

Train Avg F1  222: 0.7355339837084259

Val Avg Loss  222: 0.069066

Val Avg F1  222:  0.5839646464646464

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 223
--------------------------------------------------------------
Epoch:  223        1 Batch loss: 0.038673 Batch F1: 0.6666666666666666
Epoch:  223        2 Batch loss: 0.074715 Batch F1: 0.5
Epoch:  223        3 Batch loss: 0.064714 Batch F1: 0.7499999999999999
Epoch:  223        4 Batch loss: 0.069796 Batch F1: 0.2222222222222222
Epoch:  223        5 Batch loss: 0.052120 Batch F1: 0.6666666666666666
Epoch:  223        6 Batch loss: 0.096284 Batch F1: 0.8000000000000002
Epoch:  223        7 Batch loss: 0.080727 Batch F1: 0.8235294117647058
Epoch:  223        8 Batch loss: 0.096116 Batch F1: 0.8571428571428571
Epoch:  223        9 Batch loss: 0.067111 Batch F1: 1.0
Epoch:  223       10 Batch loss: 0.075119 Batch F1: 0.8571428571428571
Epoch:  223       11 Batch loss: 0.063938 Batch F1: 0.4444444444444445
Epoch:  223       12 Batch loss: 0.070495 Batch F1: 0.0
Train Avg Loss  223: 0.070817

Train Avg F1  223: 0.6323179271708683

Val Avg Loss  223: 0.080561

Val Avg F1  223:  0.0

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 224
--------------------------------------------------------------
Epoch:  224        1 Batch loss: 0.079679 Batch F1: 0.0
Epoch:  224        2 Batch loss: 0.090068 Batch F1: 0.631578947368421
Epoch:  224        3 Batch loss: 0.054840 Batch F1: 0.9411764705882353
Epoch:  224        4 Batch loss: 0.070971 Batch F1: 0.6666666666666666
Epoch:  224        5 Batch loss: 0.073079 Batch F1: 0.8333333333333333
Epoch:  224        6 Batch loss: 0.093997 Batch F1: 0.72
Epoch:  224        7 Batch loss: 0.054616 Batch F1: 0.8333333333333333
Epoch:  224        8 Batch loss: 0.094111 Batch F1: 0.8181818181818182
Epoch:  224        9 Batch loss: 0.072630 Batch F1: 0.9523809523809523
Epoch:  224       10 Batch loss: 0.067571 Batch F1: 0.6666666666666666
Epoch:  224       11 Batch loss: 0.066858 Batch F1: 0.8750000000000001
Epoch:  224       12 Batch loss: 0.068698 Batch F1: 0.0
Train Avg Loss  224: 0.073927

Train Avg F1  224: 0.6615265157099522

Val Avg Loss  224: 0.073218

Val Avg F1  224:  0.5895833333333333

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 225
--------------------------------------------------------------
Epoch:  225        1 Batch loss: 0.065596 Batch F1: 0.6666666666666666
Epoch:  225        2 Batch loss: 0.102971 Batch F1: 0.0
Epoch:  225        3 Batch loss: 0.070306 Batch F1: 0.6153846153846153
Epoch:  225        4 Batch loss: 0.082033 Batch F1: 0.9565217391304348
Epoch:  225        5 Batch loss: 0.073692 Batch F1: 1.0
Epoch:  225        6 Batch loss: 0.078654 Batch F1: 0.8750000000000001
Epoch:  225        7 Batch loss: 0.059592 Batch F1: 0.6666666666666666
Epoch:  225        8 Batch loss: 0.075604 Batch F1: 0.3636363636363636
Epoch:  225        9 Batch loss: 0.079105 Batch F1: 0.7499999999999999
Epoch:  225       10 Batch loss: 0.066105 Batch F1: 0.7142857142857143
Epoch:  225       11 Batch loss: 0.069115 Batch F1: 0.9090909090909091
Epoch:  225       12 Batch loss: 0.077965 Batch F1: 0.8571428571428571
Train Avg Loss  225: 0.075062

Train Avg F1  225: 0.6978662943336856

Val Avg Loss  225: 0.065981

Val Avg F1  225:  0.5843653250773994

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 226
--------------------------------------------------------------
Epoch:  226        1 Batch loss: 0.075686 Batch F1: 0.8
Epoch:  226        2 Batch loss: 0.108594 Batch F1: 0.4210526315789474
Epoch:  226        3 Batch loss: 0.072799 Batch F1: 0.888888888888889
Epoch:  226        4 Batch loss: 0.062268 Batch F1: 0.7499999999999999
Epoch:  226        5 Batch loss: 0.041088 Batch F1: 0.8571428571428571
Epoch:  226        6 Batch loss: 0.083058 Batch F1: 0.5
Epoch:  226        7 Batch loss: 0.068608 Batch F1: 0.19999999999999998
Epoch:  226        8 Batch loss: 0.048755 Batch F1: 0.5714285714285715
Epoch:  226        9 Batch loss: 0.080941 Batch F1: 0.5333333333333333
Epoch:  226       10 Batch loss: 0.056400 Batch F1: 0.33333333333333337
Epoch:  226       11 Batch loss: 0.071647 Batch F1: 0.5
Epoch:  226       12 Batch loss: 0.083671 Batch F1: 0.8
Train Avg Loss  226: 0.071126

Train Avg F1  226: 0.5962649679754942

Val Avg Loss  226: 0.064369

Val Avg F1  226:  0.8233436853002071

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 227
--------------------------------------------------------------
Epoch:  227        1 Batch loss: 0.095753 Batch F1: 0.7000000000000001
Epoch:  227        2 Batch loss: 0.069114 Batch F1: 1.0
Epoch:  227        3 Batch loss: 0.060507 Batch F1: 0.9333333333333333
Epoch:  227        4 Batch loss: 0.065671 Batch F1: 0.888888888888889
Epoch:  227        5 Batch loss: 0.075307 Batch F1: 0.5
Epoch:  227        6 Batch loss: 0.068447 Batch F1: 0.4
Epoch:  227        7 Batch loss: 0.051684 Batch F1: 0.8333333333333333
Epoch:  227        8 Batch loss: 0.053276 Batch F1: 0.5
Epoch:  227        9 Batch loss: 0.060860 Batch F1: 0.4444444444444445
Epoch:  227       10 Batch loss: 0.081808 Batch F1: 0.4615384615384615
Epoch:  227       11 Batch loss: 0.072957 Batch F1: 0.782608695652174
Epoch:  227       12 Batch loss: 0.078145 Batch F1: 0.8750000000000001
Train Avg Loss  227: 0.069461

Train Avg F1  227: 0.6932622630992197

Val Avg Loss  227: 0.064318

Val Avg F1  227:  0.8686274509803922

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 228
--------------------------------------------------------------
Epoch:  228        1 Batch loss: 0.047675 Batch F1: 1.0
Epoch:  228        2 Batch loss: 0.072873 Batch F1: 0.6666666666666666
Epoch:  228        3 Batch loss: 0.059531 Batch F1: 0.6666666666666666
Epoch:  228        4 Batch loss: 0.078360 Batch F1: 0.42857142857142855
Epoch:  228        5 Batch loss: 0.103044 Batch F1: 0.375
Epoch:  228        6 Batch loss: 0.058659 Batch F1: 0.5454545454545454
Epoch:  228        7 Batch loss: 0.091154 Batch F1: 0.9090909090909091
Epoch:  228        8 Batch loss: 0.086005 Batch F1: 0.8571428571428572
Epoch:  228        9 Batch loss: 0.066370 Batch F1: 0.9333333333333333
Epoch:  228       10 Batch loss: 0.091129 Batch F1: 0.42857142857142855
Epoch:  228       11 Batch loss: 0.064973 Batch F1: 0.6153846153846153
Epoch:  228       12 Batch loss: 0.047374 Batch F1: 0.8333333333333333
Train Avg Loss  228: 0.072262

Train Avg F1  228: 0.6882679820179821

Val Avg Loss  228: 0.066725

Val Avg F1  228:  0.591765873015873

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 229
--------------------------------------------------------------
Epoch:  229        1 Batch loss: 0.095573 Batch F1: 0.5714285714285715
Epoch:  229        2 Batch loss: 0.064387 Batch F1: 0.6153846153846153
Epoch:  229        3 Batch loss: 0.078435 Batch F1: 0.9
Epoch:  229        4 Batch loss: 0.057696 Batch F1: 1.0
Epoch:  229        5 Batch loss: 0.088399 Batch F1: 0.6666666666666666
Epoch:  229        6 Batch loss: 0.061082 Batch F1: 0.8750000000000001
Epoch:  229        7 Batch loss: 0.062577 Batch F1: 0.7499999999999999
Epoch:  229        8 Batch loss: 0.071888 Batch F1: 0.5714285714285715
Epoch:  229        9 Batch loss: 0.071650 Batch F1: 0.8
Epoch:  229       10 Batch loss: 0.077499 Batch F1: 0.9473684210526316
Epoch:  229       11 Batch loss: 0.066215 Batch F1: 0.9473684210526316
Epoch:  229       12 Batch loss: 0.062041 Batch F1: 0.9090909090909091
Train Avg Loss  229: 0.071454

Train Avg F1  229: 0.7961446813420497

Val Avg Loss  229: 0.064307

Val Avg F1  229:  0.9402582543314809

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 230
--------------------------------------------------------------
Epoch:  230        1 Batch loss: 0.062145 Batch F1: 1.0
Epoch:  230        2 Batch loss: 0.066939 Batch F1: 0.9090909090909091
Epoch:  230        3 Batch loss: 0.067034 Batch F1: 0.6666666666666666
Epoch:  230        4 Batch loss: 0.042940 Batch F1: 0.4
Epoch:  230        5 Batch loss: 0.107353 Batch F1: 0.5263157894736842
Epoch:  230        6 Batch loss: 0.090578 Batch F1: 0.18181818181818182
Epoch:  230        7 Batch loss: 0.062938 Batch F1: 0.5
Epoch:  230        8 Batch loss: 0.068984 Batch F1: 0.8
Epoch:  230        9 Batch loss: 0.062108 Batch F1: 0.9333333333333333
Epoch:  230       10 Batch loss: 0.085690 Batch F1: 0.8235294117647058
Epoch:  230       11 Batch loss: 0.061046 Batch F1: 1.0
Epoch:  230       12 Batch loss: 0.090394 Batch F1: 0.8235294117647058
Train Avg Loss  230: 0.072346

Train Avg F1  230: 0.7136903086593489

Val Avg Loss  230: 0.064332

Val Avg F1  230:  0.6185515873015873

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 231
--------------------------------------------------------------
Epoch:  231        1 Batch loss: 0.071344 Batch F1: 0.7142857142857143
Epoch:  231        2 Batch loss: 0.063043 Batch F1: 0.5
Epoch:  231        3 Batch loss: 0.059222 Batch F1: 0.5
Epoch:  231        4 Batch loss: 0.077974 Batch F1: 0.4615384615384615
Epoch:  231        5 Batch loss: 0.085761 Batch F1: 0.5882352941176471
Epoch:  231        6 Batch loss: 0.065936 Batch F1: 0.8235294117647058
Epoch:  231        7 Batch loss: 0.076064 Batch F1: 0.6
Epoch:  231        8 Batch loss: 0.046133 Batch F1: 0.9333333333333333
Epoch:  231        9 Batch loss: 0.070535 Batch F1: 0.888888888888889
Epoch:  231       10 Batch loss: 0.080369 Batch F1: 0.9523809523809523
Epoch:  231       11 Batch loss: 0.082185 Batch F1: 0.6666666666666666
Epoch:  231       12 Batch loss: 0.061784 Batch F1: 0.6666666666666666
Train Avg Loss  231: 0.070029

Train Avg F1  231: 0.6912937824702531

Val Avg Loss  231: 0.066219

Val Avg F1  231:  0.5754776269482151

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 232
--------------------------------------------------------------
Epoch:  232        1 Batch loss: 0.068273 Batch F1: 0.6
Epoch:  232        2 Batch loss: 0.086579 Batch F1: 0.5555555555555556
Epoch:  232        3 Batch loss: 0.084348 Batch F1: 0.88
Epoch:  232        4 Batch loss: 0.081515 Batch F1: 0.7999999999999999
Epoch:  232        5 Batch loss: 0.083957 Batch F1: 0.9565217391304348
Epoch:  232        6 Batch loss: 0.078642 Batch F1: 0.9473684210526316
Epoch:  232        7 Batch loss: 0.057003 Batch F1: 0.5
Epoch:  232        8 Batch loss: 0.058842 Batch F1: 0.0
Epoch:  232        9 Batch loss: 0.081659 Batch F1: 0.0
Epoch:  232       10 Batch loss: 0.068295 Batch F1: 0.4444444444444445
Epoch:  232       11 Batch loss: 0.090538 Batch F1: 0.3636363636363636
Epoch:  232       12 Batch loss: 0.053901 Batch F1: 0.8750000000000001
Train Avg Loss  232: 0.074463

Train Avg F1  232: 0.5768772103182859

Val Avg Loss  232: 0.065485

Val Avg F1  232:  0.5234487734487734

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 233
--------------------------------------------------------------
Epoch:  233        1 Batch loss: 0.067489 Batch F1: 0.4615384615384615
Epoch:  233        2 Batch loss: 0.055355 Batch F1: 0.9333333333333333
Epoch:  233        3 Batch loss: 0.073120 Batch F1: 0.888888888888889
Epoch:  233        4 Batch loss: 0.082043 Batch F1: 0.9
Epoch:  233        5 Batch loss: 0.081286 Batch F1: 0.8750000000000001
Epoch:  233        6 Batch loss: 0.078323 Batch F1: 0.8235294117647058
Epoch:  233        7 Batch loss: 0.053061 Batch F1: 0.8571428571428571
Epoch:  233        8 Batch loss: 0.099837 Batch F1: 0.375
Epoch:  233        9 Batch loss: 0.087618 Batch F1: 0.4444444444444445
Epoch:  233       10 Batch loss: 0.069176 Batch F1: 0.7692307692307693
Epoch:  233       11 Batch loss: 0.060502 Batch F1: 1.0
Epoch:  233       12 Batch loss: 0.058598 Batch F1: 0.8571428571428571
Train Avg Loss  233: 0.072201

Train Avg F1  233: 0.7654375852905265

Val Avg Loss  233: 0.064933

Val Avg F1  233:  0.6285714285714286

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 234
--------------------------------------------------------------
Epoch:  234        1 Batch loss: 0.065460 Batch F1: 0.25
Epoch:  234        2 Batch loss: 0.070903 Batch F1: 0.5714285714285715
Epoch:  234        3 Batch loss: 0.088619 Batch F1: 0.5
Epoch:  234        4 Batch loss: 0.059864 Batch F1: 0.7272727272727273
Epoch:  234        5 Batch loss: 0.064396 Batch F1: 0.9473684210526316
Epoch:  234        6 Batch loss: 0.072067 Batch F1: 0.8750000000000001
Epoch:  234        7 Batch loss: 0.063812 Batch F1: 0.9473684210526316
Epoch:  234        8 Batch loss: 0.065323 Batch F1: 0.9333333333333333
Epoch:  234        9 Batch loss: 0.066269 Batch F1: 0.8333333333333333
Epoch:  234       10 Batch loss: 0.066115 Batch F1: 0.6666666666666666
Epoch:  234       11 Batch loss: 0.081445 Batch F1: 0.761904761904762
Epoch:  234       12 Batch loss: 0.078716 Batch F1: 0.4
Train Avg Loss  234: 0.070249

Train Avg F1  234: 0.7011396863370548

Val Avg Loss  234: 0.065705

Val Avg F1  234:  0.5785714285714286

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 235
--------------------------------------------------------------
Epoch:  235        1 Batch loss: 0.089115 Batch F1: 0.5
Epoch:  235        2 Batch loss: 0.054503 Batch F1: 0.6666666666666666
Epoch:  235        3 Batch loss: 0.069951 Batch F1: 0.5454545454545454
Epoch:  235        4 Batch loss: 0.068056 Batch F1: 0.5454545454545454
Epoch:  235        5 Batch loss: 0.051542 Batch F1: 0.7272727272727273
Epoch:  235        6 Batch loss: 0.038152 Batch F1: 0.888888888888889
Epoch:  235        7 Batch loss: 0.081332 Batch F1: 0.6
Epoch:  235        8 Batch loss: 0.080641 Batch F1: 0.5555555555555556
Epoch:  235        9 Batch loss: 0.083573 Batch F1: 0.9411764705882353
Epoch:  235       10 Batch loss: 0.066089 Batch F1: 0.7692307692307693
Epoch:  235       11 Batch loss: 0.069023 Batch F1: 0.9333333333333333
Epoch:  235       12 Batch loss: 0.085402 Batch F1: 0.7499999999999999
Train Avg Loss  235: 0.069782

Train Avg F1  235: 0.7019194585371055

Val Avg Loss  235: 0.064858

Val Avg F1  235:  0.9142857142857144

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 236
--------------------------------------------------------------
Epoch:  236        1 Batch loss: 0.093031 Batch F1: 0.9166666666666666
Epoch:  236        2 Batch loss: 0.059277 Batch F1: 1.0
Epoch:  236        3 Batch loss: 0.069660 Batch F1: 1.0
Epoch:  236        4 Batch loss: 0.054977 Batch F1: 1.0
Epoch:  236        5 Batch loss: 0.064430 Batch F1: 0.5454545454545454
Epoch:  236        6 Batch loss: 0.077485 Batch F1: 0.7058823529411764
Epoch:  236        7 Batch loss: 0.094956 Batch F1: 0.375
Epoch:  236        8 Batch loss: 0.060974 Batch F1: 0.7272727272727273
Epoch:  236        9 Batch loss: 0.070217 Batch F1: 0.7272727272727273
Epoch:  236       10 Batch loss: 0.065729 Batch F1: 0.8
Epoch:  236       11 Batch loss: 0.059163 Batch F1: 0.25
Epoch:  236       12 Batch loss: 0.051152 Batch F1: 0.8
Train Avg Loss  236: 0.068421

Train Avg F1  236: 0.737295751633987

Val Avg Loss  236: 0.064478

Val Avg F1  236:  0.6562812187812188

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 237
--------------------------------------------------------------
Epoch:  237        1 Batch loss: 0.078480 Batch F1: 0.5555555555555556
Epoch:  237        2 Batch loss: 0.076574 Batch F1: 0.9
Epoch:  237        3 Batch loss: 0.052686 Batch F1: 1.0
Epoch:  237        4 Batch loss: 0.075013 Batch F1: 0.888888888888889
Epoch:  237        5 Batch loss: 0.062905 Batch F1: 0.8750000000000001
Epoch:  237        6 Batch loss: 0.057066 Batch F1: 0.9090909090909091
Epoch:  237        7 Batch loss: 0.068786 Batch F1: 0.888888888888889
Epoch:  237        8 Batch loss: 0.050923 Batch F1: 0.8571428571428571
Epoch:  237        9 Batch loss: 0.074203 Batch F1: 0.4615384615384615
Epoch:  237       10 Batch loss: 0.076396 Batch F1: 0.5714285714285715
Epoch:  237       11 Batch loss: 0.053171 Batch F1: 0.5714285714285715
Epoch:  237       12 Batch loss: 0.096560 Batch F1: 0.5
Train Avg Loss  237: 0.068563

Train Avg F1  237: 0.748246891996892

Val Avg Loss  237: 0.065503

Val Avg F1  237:  0.5555555555555557

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 238
--------------------------------------------------------------
Epoch:  238        1 Batch loss: 0.095821 Batch F1: 0.47058823529411764
Epoch:  238        2 Batch loss: 0.046081 Batch F1: 0.5714285714285715
Epoch:  238        3 Batch loss: 0.079476 Batch F1: 0.42857142857142855
Epoch:  238        4 Batch loss: 0.050302 Batch F1: 1.0
Epoch:  238        5 Batch loss: 0.070251 Batch F1: 0.33333333333333337
Epoch:  238        6 Batch loss: 0.056538 Batch F1: 0.7272727272727273
Epoch:  238        7 Batch loss: 0.075060 Batch F1: 0.7777777777777778
Epoch:  238        8 Batch loss: 0.064880 Batch F1: 0.8571428571428571
Epoch:  238        9 Batch loss: 0.079329 Batch F1: 0.8421052631578948
Epoch:  238       10 Batch loss: 0.060211 Batch F1: 0.9333333333333333
Epoch:  238       11 Batch loss: 0.068507 Batch F1: 0.8571428571428571
Epoch:  238       12 Batch loss: 0.071678 Batch F1: 0.6
Train Avg Loss  238: 0.068178

Train Avg F1  238: 0.6998913653712414

Val Avg Loss  238: 0.068524

Val Avg F1  238:  0.878416149068323

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 239
--------------------------------------------------------------
Epoch:  239        1 Batch loss: 0.060841 Batch F1: 0.9411764705882353
Epoch:  239        2 Batch loss: 0.066072 Batch F1: 0.7692307692307693
Epoch:  239        3 Batch loss: 0.065806 Batch F1: 0.6666666666666666
Epoch:  239        4 Batch loss: 0.114179 Batch F1: 0.4444444444444445
Epoch:  239        5 Batch loss: 0.065727 Batch F1: 0.4
Epoch:  239        6 Batch loss: 0.055330 Batch F1: 0.5714285714285715
Epoch:  239        7 Batch loss: 0.062780 Batch F1: 0.8
Epoch:  239        8 Batch loss: 0.080093 Batch F1: 0.8333333333333333
Epoch:  239        9 Batch loss: 0.057616 Batch F1: 0.9090909090909091
Epoch:  239       10 Batch loss: 0.056079 Batch F1: 1.0
Epoch:  239       11 Batch loss: 0.057638 Batch F1: 0.923076923076923
Epoch:  239       12 Batch loss: 0.099132 Batch F1: 0.5555555555555556
Train Avg Loss  239: 0.070108

Train Avg F1  239: 0.7345003036179506

Val Avg Loss  239: 0.064692

Val Avg F1  239:  0.5509049773755657

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 240
--------------------------------------------------------------
Epoch:  240        1 Batch loss: 0.093796 Batch F1: 0.4444444444444445
Epoch:  240        2 Batch loss: 0.056176 Batch F1: 0.888888888888889
Epoch:  240        3 Batch loss: 0.083590 Batch F1: 0.923076923076923
Epoch:  240        4 Batch loss: 0.072059 Batch F1: 0.923076923076923
Epoch:  240        5 Batch loss: 0.094929 Batch F1: 0.8
Epoch:  240        6 Batch loss: 0.058491 Batch F1: 0.9333333333333333
Epoch:  240        7 Batch loss: 0.046732 Batch F1: 0.9090909090909091
Epoch:  240        8 Batch loss: 0.095322 Batch F1: 0.16666666666666669
Epoch:  240        9 Batch loss: 0.066482 Batch F1: 0.7142857142857143
Epoch:  240       10 Batch loss: 0.081007 Batch F1: 0.7368421052631579
Epoch:  240       11 Batch loss: 0.059410 Batch F1: 0.923076923076923
Epoch:  240       12 Batch loss: 0.052239 Batch F1: 0.6666666666666666
Train Avg Loss  240: 0.071686

Train Avg F1  240: 0.7524541248225458

Val Avg Loss  240: 0.066953

Val Avg F1  240:  0.6049707602339182

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 241
--------------------------------------------------------------
Epoch:  241        1 Batch loss: 0.059483 Batch F1: 0.8571428571428571
Epoch:  241        2 Batch loss: 0.077602 Batch F1: 0.5
Epoch:  241        3 Batch loss: 0.081721 Batch F1: 0.42857142857142855
Epoch:  241        4 Batch loss: 0.077217 Batch F1: 1.0
Epoch:  241        5 Batch loss: 0.073019 Batch F1: 0.2222222222222222
Epoch:  241        6 Batch loss: 0.092212 Batch F1: 0.42857142857142855
Epoch:  241        7 Batch loss: 0.060599 Batch F1: 0.6666666666666666
Epoch:  241        8 Batch loss: 0.079598 Batch F1: 0.8571428571428571
Epoch:  241        9 Batch loss: 0.073762 Batch F1: 0.9411764705882353
Epoch:  241       10 Batch loss: 0.079464 Batch F1: 0.6666666666666665
Epoch:  241       11 Batch loss: 0.081071 Batch F1: 0.8571428571428571
Epoch:  241       12 Batch loss: 0.071426 Batch F1: 0.9411764705882353
Train Avg Loss  241: 0.075598

Train Avg F1  241: 0.6972066604419545

Val Avg Loss  241: 0.083359

Val Avg F1  241:  0.6235294117647059

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 242
--------------------------------------------------------------
Epoch:  242        1 Batch loss: 0.096427 Batch F1: 0.9
Epoch:  242        2 Batch loss: 0.108978 Batch F1: 0.19999999999999998
Epoch:  242        3 Batch loss: 0.112535 Batch F1: 0.47058823529411764
Epoch:  242        4 Batch loss: 0.052966 Batch F1: 0.4444444444444445
Epoch:  242        5 Batch loss: 0.095505 Batch F1: 0.6086956521739131
Epoch:  242        6 Batch loss: 0.086303 Batch F1: 0.8235294117647058
Epoch:  242        7 Batch loss: 0.077798 Batch F1: 0.8235294117647058
Epoch:  242        8 Batch loss: 0.056400 Batch F1: 0.9090909090909091
Epoch:  242        9 Batch loss: 0.067151 Batch F1: 0.5454545454545454
Epoch:  242       10 Batch loss: 0.052039 Batch F1: 0.5
Epoch:  242       11 Batch loss: 0.074787 Batch F1: 0.0
Epoch:  242       12 Batch loss: 0.081255 Batch F1: 0.25
Train Avg Loss  242: 0.080179

Train Avg F1  242: 0.5396110508322786

Val Avg Loss  242: 0.068962

Val Avg F1  242:  0.8905681818181819

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 243
--------------------------------------------------------------
Epoch:  243        1 Batch loss: 0.049729 Batch F1: 1.0
Epoch:  243        2 Batch loss: 0.072398 Batch F1: 0.962962962962963
Epoch:  243        3 Batch loss: 0.082946 Batch F1: 0.6666666666666666
Epoch:  243        4 Batch loss: 0.066967 Batch F1: 0.6
Epoch:  243        5 Batch loss: 0.055188 Batch F1: 0.7272727272727273
Epoch:  243        6 Batch loss: 0.103679 Batch F1: 0.42857142857142855
Epoch:  243        7 Batch loss: 0.072276 Batch F1: 0.2222222222222222
Epoch:  243        8 Batch loss: 0.086103 Batch F1: 0.923076923076923
Epoch:  243        9 Batch loss: 0.092117 Batch F1: 0.875
Epoch:  243       10 Batch loss: 0.055691 Batch F1: 1.0
Epoch:  243       11 Batch loss: 0.102595 Batch F1: 0.15384615384615385
Epoch:  243       12 Batch loss: 0.100342 Batch F1: 0.0
Train Avg Loss  243: 0.078336

Train Avg F1  243: 0.6299682570515904

Val Avg Loss  243: 0.074098

Val Avg F1  243:  0.5846320346320346

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 244
--------------------------------------------------------------
Epoch:  244        1 Batch loss: 0.055760 Batch F1: 0.6
Epoch:  244        2 Batch loss: 0.079821 Batch F1: 0.7000000000000001
Epoch:  244        3 Batch loss: 0.052985 Batch F1: 0.923076923076923
Epoch:  244        4 Batch loss: 0.086668 Batch F1: 0.7999999999999999
Epoch:  244        5 Batch loss: 0.064692 Batch F1: 0.9333333333333333
Epoch:  244        6 Batch loss: 0.093698 Batch F1: 0.7777777777777778
Epoch:  244        7 Batch loss: 0.076532 Batch F1: 0.9473684210526316
Epoch:  244        8 Batch loss: 0.051692 Batch F1: 0.8333333333333333
Epoch:  244        9 Batch loss: 0.072311 Batch F1: 0.5714285714285715
Epoch:  244       10 Batch loss: 0.068867 Batch F1: 0.5454545454545454
Epoch:  244       11 Batch loss: 0.076075 Batch F1: 0.7777777777777778
Epoch:  244       12 Batch loss: 0.087525 Batch F1: 0.2222222222222222
Train Avg Loss  244: 0.072219

Train Avg F1  244: 0.7193144087880929

Val Avg Loss  244: 0.066132

Val Avg F1  244:  0.6023391812865497

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 245
--------------------------------------------------------------
Epoch:  245        1 Batch loss: 0.075886 Batch F1: 0.5333333333333333
Epoch:  245        2 Batch loss: 0.063436 Batch F1: 0.7142857142857143
Epoch:  245        3 Batch loss: 0.087516 Batch F1: 0.5
Epoch:  245        4 Batch loss: 0.079808 Batch F1: 0.9
Epoch:  245        5 Batch loss: 0.070377 Batch F1: 0.923076923076923
Epoch:  245        6 Batch loss: 0.063079 Batch F1: 0.6
Epoch:  245        7 Batch loss: 0.083150 Batch F1: 0.7000000000000001
Epoch:  245        8 Batch loss: 0.060833 Batch F1: 0.6
Epoch:  245        9 Batch loss: 0.092967 Batch F1: 0.5882352941176471
Epoch:  245       10 Batch loss: 0.050963 Batch F1: 0.6
Epoch:  245       11 Batch loss: 0.068569 Batch F1: 0.7999999999999999
Epoch:  245       12 Batch loss: 0.050802 Batch F1: 1.0
Train Avg Loss  245: 0.070616

Train Avg F1  245: 0.704910938734468

Val Avg Loss  245: 0.065989

Val Avg F1  245:  0.6127136752136753

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 246
--------------------------------------------------------------
Epoch:  246        1 Batch loss: 0.060046 Batch F1: 0.5454545454545454
Epoch:  246        2 Batch loss: 0.065722 Batch F1: 0.6666666666666666
Epoch:  246        3 Batch loss: 0.049360 Batch F1: 0.8
Epoch:  246        4 Batch loss: 0.086983 Batch F1: 0.2857142857142857
Epoch:  246        5 Batch loss: 0.084262 Batch F1: 0.19999999999999998
Epoch:  246        6 Batch loss: 0.059787 Batch F1: 1.0
Epoch:  246        7 Batch loss: 0.078050 Batch F1: 0.923076923076923
Epoch:  246        8 Batch loss: 0.086364 Batch F1: 0.7499999999999999
Epoch:  246        9 Batch loss: 0.088390 Batch F1: 0.7777777777777778
Epoch:  246       10 Batch loss: 0.074701 Batch F1: 0.8695652173913044
Epoch:  246       11 Batch loss: 0.071074 Batch F1: 0.9411764705882353
Epoch:  246       12 Batch loss: 0.057169 Batch F1: 0.8
Train Avg Loss  246: 0.071826

Train Avg F1  246: 0.7132859905558115

Val Avg Loss  246: 0.067129

Val Avg F1  246:  0.6606442577030811

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 247
--------------------------------------------------------------
Epoch:  247        1 Batch loss: 0.088943 Batch F1: 0.4615384615384615
Epoch:  247        2 Batch loss: 0.056590 Batch F1: 1.0
Epoch:  247        3 Batch loss: 0.061361 Batch F1: 0.9333333333333333
Epoch:  247        4 Batch loss: 0.095137 Batch F1: 0.7499999999999999
Epoch:  247        5 Batch loss: 0.056607 Batch F1: 0.8571428571428571
Epoch:  247        6 Batch loss: 0.072218 Batch F1: 0.8
Epoch:  247        7 Batch loss: 0.057593 Batch F1: 0.8235294117647058
Epoch:  247        8 Batch loss: 0.068921 Batch F1: 0.6666666666666666
Epoch:  247        9 Batch loss: 0.050621 Batch F1: 0.6666666666666666
Epoch:  247       10 Batch loss: 0.103025 Batch F1: 0.6363636363636364
Epoch:  247       11 Batch loss: 0.086577 Batch F1: 0.16666666666666669
Epoch:  247       12 Batch loss: 0.061241 Batch F1: 1.0
Train Avg Loss  247: 0.071569

Train Avg F1  247: 0.7301589750119163

Val Avg Loss  247: 0.069739

Val Avg F1  247:  0.9356060606060606

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 248
--------------------------------------------------------------
Epoch:  248        1 Batch loss: 0.085884 Batch F1: 0.8695652173913044
Epoch:  248        2 Batch loss: 0.067507 Batch F1: 0.923076923076923
Epoch:  248        3 Batch loss: 0.057996 Batch F1: 0.9090909090909091
Epoch:  248        4 Batch loss: 0.085594 Batch F1: 0.5882352941176471
Epoch:  248        5 Batch loss: 0.062077 Batch F1: 0.25
Epoch:  248        6 Batch loss: 0.090326 Batch F1: 0.4
Epoch:  248        7 Batch loss: 0.074143 Batch F1: 0.8235294117647058
Epoch:  248        8 Batch loss: 0.075038 Batch F1: 0.888888888888889
Epoch:  248        9 Batch loss: 0.056372 Batch F1: 0.923076923076923
Epoch:  248       10 Batch loss: 0.076997 Batch F1: 0.8
Epoch:  248       11 Batch loss: 0.052414 Batch F1: 1.0
Epoch:  248       12 Batch loss: 0.060944 Batch F1: 0.6666666666666666
Train Avg Loss  248: 0.070441

Train Avg F1  248: 0.7535108528394973

Val Avg Loss  248: 0.063777

Val Avg F1  248:  0.511437908496732

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 249
--------------------------------------------------------------
Epoch:  249        1 Batch loss: 0.067565 Batch F1: 0.6153846153846153
Epoch:  249        2 Batch loss: 0.073760 Batch F1: 0.42857142857142855
Epoch:  249        3 Batch loss: 0.075050 Batch F1: 0.7368421052631579
Epoch:  249        4 Batch loss: 0.074007 Batch F1: 0.8421052631578948
Epoch:  249        5 Batch loss: 0.065235 Batch F1: 0.9411764705882353
Epoch:  249        6 Batch loss: 0.085003 Batch F1: 0.4
Epoch:  249        7 Batch loss: 0.064689 Batch F1: 0.6666666666666666
Epoch:  249        8 Batch loss: 0.047432 Batch F1: 0.6666666666666666
Epoch:  249        9 Batch loss: 0.098707 Batch F1: 0.6
Epoch:  249       10 Batch loss: 0.076422 Batch F1: 0.4615384615384615
Epoch:  249       11 Batch loss: 0.040116 Batch F1: 1.0
Epoch:  249       12 Batch loss: 0.050250 Batch F1: 1.0
Train Avg Loss  249: 0.068186

Train Avg F1  249: 0.6965793064864272

Val Avg Loss  249: 0.064792

Val Avg F1  249:  0.8410816912972086

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 250
--------------------------------------------------------------
Epoch:  250        1 Batch loss: 0.072725 Batch F1: 0.8421052631578948
Epoch:  250        2 Batch loss: 0.059459 Batch F1: 0.8
Epoch:  250        3 Batch loss: 0.085024 Batch F1: 0.888888888888889
Epoch:  250        4 Batch loss: 0.068603 Batch F1: 0.9333333333333333
Epoch:  250        5 Batch loss: 0.084440 Batch F1: 0.7499999999999999
Epoch:  250        6 Batch loss: 0.070084 Batch F1: 0.7499999999999999
Epoch:  250        7 Batch loss: 0.053340 Batch F1: 0.9090909090909091
Epoch:  250        8 Batch loss: 0.073230 Batch F1: 0.7000000000000001
Epoch:  250        9 Batch loss: 0.063899 Batch F1: 0.7142857142857143
Epoch:  250       10 Batch loss: 0.063683 Batch F1: 0.7692307692307693
Epoch:  250       11 Batch loss: 0.052079 Batch F1: 0.8
Epoch:  250       12 Batch loss: 0.064257 Batch F1: 0.6666666666666666
Train Avg Loss  250: 0.067569

Train Avg F1  250: 0.7936334620545148

Val Avg Loss  250: 0.066160

Val Avg F1  250:  0.5907738095238095

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 251
--------------------------------------------------------------
Epoch:  251        1 Batch loss: 0.084583 Batch F1: 0.3076923076923077
Epoch:  251        2 Batch loss: 0.074775 Batch F1: 0.7142857142857143
Epoch:  251        3 Batch loss: 0.067079 Batch F1: 0.9090909090909091
Epoch:  251        4 Batch loss: 0.059505 Batch F1: 0.8571428571428571
Epoch:  251        5 Batch loss: 0.074885 Batch F1: 0.5882352941176471
Epoch:  251        6 Batch loss: 0.066458 Batch F1: 0.7058823529411764
Epoch:  251        7 Batch loss: 0.065829 Batch F1: 0.888888888888889
Epoch:  251        8 Batch loss: 0.071401 Batch F1: 1.0
Epoch:  251        9 Batch loss: 0.065272 Batch F1: 1.0
Epoch:  251       10 Batch loss: 0.084445 Batch F1: 0.625
Epoch:  251       11 Batch loss: 0.063903 Batch F1: 0.5
Epoch:  251       12 Batch loss: 0.103060 Batch F1: 0.6666666666666666
Train Avg Loss  251: 0.073433

Train Avg F1  251: 0.7302404159021806

Val Avg Loss  251: 0.065047

Val Avg F1  251:  0.752859477124183

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 252
--------------------------------------------------------------
Epoch:  252        1 Batch loss: 0.076955 Batch F1: 0.7142857142857143
Epoch:  252        2 Batch loss: 0.071895 Batch F1: 1.0
Epoch:  252        3 Batch loss: 0.087229 Batch F1: 0.9166666666666666
Epoch:  252        4 Batch loss: 0.077380 Batch F1: 0.8571428571428572
Epoch:  252        5 Batch loss: 0.060005 Batch F1: 1.0
Epoch:  252        6 Batch loss: 0.076185 Batch F1: 0.8235294117647058
Epoch:  252        7 Batch loss: 0.116468 Batch F1: 0.35294117647058826
Epoch:  252        8 Batch loss: 0.086719 Batch F1: 0.4615384615384615
Epoch:  252        9 Batch loss: 0.075829 Batch F1: 0.6153846153846153
Epoch:  252       10 Batch loss: 0.058079 Batch F1: 0.923076923076923
Epoch:  252       11 Batch loss: 0.071353 Batch F1: 0.7499999999999999
Epoch:  252       12 Batch loss: 0.048549 Batch F1: 1.0
Train Avg Loss  252: 0.075554

Train Avg F1  252: 0.7845471521942109

Val Avg Loss  252: 0.068876

Val Avg F1  252:  0.8428571428571429

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 253
--------------------------------------------------------------
Epoch:  253        1 Batch loss: 0.058620 Batch F1: 0.8
Epoch:  253        2 Batch loss: 0.058487 Batch F1: 0.6
Epoch:  253        3 Batch loss: 0.080765 Batch F1: 0.3076923076923077
Epoch:  253        4 Batch loss: 0.089677 Batch F1: 0.16666666666666669
Epoch:  253        5 Batch loss: 0.083342 Batch F1: 0.625
Epoch:  253        6 Batch loss: 0.100162 Batch F1: 0.8461538461538461
Epoch:  253        7 Batch loss: 0.072571 Batch F1: 1.0
Epoch:  253        8 Batch loss: 0.058204 Batch F1: 0.9473684210526316
Epoch:  253        9 Batch loss: 0.077204 Batch F1: 0.9090909090909091
Epoch:  253       10 Batch loss: 0.080756 Batch F1: 0.6666666666666666
Epoch:  253       11 Batch loss: 0.061809 Batch F1: 0.6
Epoch:  253       12 Batch loss: 0.073639 Batch F1: 0.33333333333333337
Train Avg Loss  253: 0.074603

Train Avg F1  253: 0.6501643458880301

Val Avg Loss  253: 0.077556

Val Avg F1  253:  0.28525641025641024

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 254
--------------------------------------------------------------
Epoch:  254        1 Batch loss: 0.055786 Batch F1: 0.7272727272727273
Epoch:  254        2 Batch loss: 0.093088 Batch F1: 0.42857142857142855
Epoch:  254        3 Batch loss: 0.035836 Batch F1: 1.0
Epoch:  254        4 Batch loss: 0.075964 Batch F1: 0.6666666666666666
Epoch:  254        5 Batch loss: 0.088643 Batch F1: 0.9090909090909091
Epoch:  254        6 Batch loss: 0.100291 Batch F1: 0.888888888888889
Epoch:  254        7 Batch loss: 0.063408 Batch F1: 0.923076923076923
Epoch:  254        8 Batch loss: 0.070420 Batch F1: 1.0
Epoch:  254        9 Batch loss: 0.058233 Batch F1: 0.6666666666666666
Epoch:  254       10 Batch loss: 0.079919 Batch F1: 0.9090909090909091
Epoch:  254       11 Batch loss: 0.073277 Batch F1: 0.6666666666666666
Epoch:  254       12 Batch loss: 0.058494 Batch F1: 0.6666666666666666
Train Avg Loss  254: 0.071113

Train Avg F1  254: 0.7877215377215377

Val Avg Loss  254: 0.066083

Val Avg F1  254:  0.6937229437229436

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 255
--------------------------------------------------------------
Epoch:  255        1 Batch loss: 0.099275 Batch F1: 0.5263157894736842
Epoch:  255        2 Batch loss: 0.072120 Batch F1: 0.6153846153846153
Epoch:  255        3 Batch loss: 0.052857 Batch F1: 0.8
Epoch:  255        4 Batch loss: 0.066746 Batch F1: 0.6666666666666666
Epoch:  255        5 Batch loss: 0.058311 Batch F1: 0.4444444444444445
Epoch:  255        6 Batch loss: 0.072841 Batch F1: 0.4
Epoch:  255        7 Batch loss: 0.061000 Batch F1: 0.7058823529411764
Epoch:  255        8 Batch loss: 0.050878 Batch F1: 0.6666666666666666
Epoch:  255        9 Batch loss: 0.062640 Batch F1: 0.7272727272727273
Epoch:  255       10 Batch loss: 0.070407 Batch F1: 0.7000000000000001
Epoch:  255       11 Batch loss: 0.074581 Batch F1: 0.8333333333333333
Epoch:  255       12 Batch loss: 0.085804 Batch F1: 0.9090909090909091
Train Avg Loss  255: 0.068955

Train Avg F1  255: 0.6662547921061853

Val Avg Loss  255: 0.064822

Val Avg F1  255:  0.9308823529411765

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 256
--------------------------------------------------------------
Epoch:  256        1 Batch loss: 0.062054 Batch F1: 0.9333333333333333
Epoch:  256        2 Batch loss: 0.047997 Batch F1: 0.7499999999999999
Epoch:  256        3 Batch loss: 0.069674 Batch F1: 0.9655172413793104
Epoch:  256        4 Batch loss: 0.081739 Batch F1: 0.7058823529411764
Epoch:  256        5 Batch loss: 0.061079 Batch F1: 0.7692307692307693
Epoch:  256        6 Batch loss: 0.071142 Batch F1: 0.8235294117647058
Epoch:  256        7 Batch loss: 0.056056 Batch F1: 0.7499999999999999
Epoch:  256        8 Batch loss: 0.081276 Batch F1: 0.18181818181818182
Epoch:  256        9 Batch loss: 0.061245 Batch F1: 0.7142857142857143
Epoch:  256       10 Batch loss: 0.083011 Batch F1: 0.33333333333333337
Epoch:  256       11 Batch loss: 0.065497 Batch F1: 0.8
Epoch:  256       12 Batch loss: 0.075590 Batch F1: 0.8571428571428571
Train Avg Loss  256: 0.068030

Train Avg F1  256: 0.7153394329357817

Val Avg Loss  256: 0.063011

Val Avg F1  256:  0.8878787878787878

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 257
--------------------------------------------------------------
Epoch:  257        1 Batch loss: 0.060590 Batch F1: 1.0
Epoch:  257        2 Batch loss: 0.065643 Batch F1: 1.0
Epoch:  257        3 Batch loss: 0.067921 Batch F1: 0.8333333333333333
Epoch:  257        4 Batch loss: 0.075390 Batch F1: 0.8571428571428571
Epoch:  257        5 Batch loss: 0.056206 Batch F1: 0.8
Epoch:  257        6 Batch loss: 0.062131 Batch F1: 0.6666666666666666
Epoch:  257        7 Batch loss: 0.071021 Batch F1: 0.6666666666666666
Epoch:  257        8 Batch loss: 0.046351 Batch F1: 0.7499999999999999
Epoch:  257        9 Batch loss: 0.079646 Batch F1: 0.6666666666666666
Epoch:  257       10 Batch loss: 0.066096 Batch F1: 0.4615384615384615
Epoch:  257       11 Batch loss: 0.078236 Batch F1: 0.7499999999999999
Epoch:  257       12 Batch loss: 0.083912 Batch F1: 0.8571428571428571
Train Avg Loss  257: 0.067762

Train Avg F1  257: 0.7757631257631258

Val Avg Loss  257: 0.064045

Val Avg F1  257:  0.9244949494949495

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 258
--------------------------------------------------------------
Epoch:  258        1 Batch loss: 0.056253 Batch F1: 0.8571428571428571
Epoch:  258        2 Batch loss: 0.078987 Batch F1: 0.8750000000000001
Epoch:  258        3 Batch loss: 0.076569 Batch F1: 0.9090909090909091
Epoch:  258        4 Batch loss: 0.073175 Batch F1: 1.0
Epoch:  258        5 Batch loss: 0.063165 Batch F1: 1.0
Epoch:  258        6 Batch loss: 0.080356 Batch F1: 0.8421052631578948
Epoch:  258        7 Batch loss: 0.064153 Batch F1: 0.8571428571428571
Epoch:  258        8 Batch loss: 0.068049 Batch F1: 0.8235294117647058
Epoch:  258        9 Batch loss: 0.063428 Batch F1: 0.5
Epoch:  258       10 Batch loss: 0.076446 Batch F1: 0.5333333333333333
Epoch:  258       11 Batch loss: 0.038956 Batch F1: 0.0
Epoch:  258       12 Batch loss: 0.062592 Batch F1: 0.6666666666666666
Train Avg Loss  258: 0.066844

Train Avg F1  258: 0.7386676081916019

Val Avg Loss  258: 0.064087

Val Avg F1  258:  0.5769034886681945

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 259
--------------------------------------------------------------
Epoch:  259        1 Batch loss: 0.083871 Batch F1: 0.5555555555555556
Epoch:  259        2 Batch loss: 0.057262 Batch F1: 0.7499999999999999
Epoch:  259        3 Batch loss: 0.097456 Batch F1: 0.8571428571428571
Epoch:  259        4 Batch loss: 0.091889 Batch F1: 0.8235294117647058
Epoch:  259        5 Batch loss: 0.062734 Batch F1: 1.0
Epoch:  259        6 Batch loss: 0.056959 Batch F1: 0.7272727272727273
Epoch:  259        7 Batch loss: 0.063133 Batch F1: 0.4444444444444445
Epoch:  259        8 Batch loss: 0.069357 Batch F1: 0.7142857142857143
Epoch:  259        9 Batch loss: 0.063933 Batch F1: 0.7499999999999999
Epoch:  259       10 Batch loss: 0.065783 Batch F1: 0.7499999999999999
Epoch:  259       11 Batch loss: 0.074224 Batch F1: 0.7499999999999999
Epoch:  259       12 Batch loss: 0.069428 Batch F1: 0.888888888888889
Train Avg Loss  259: 0.071336

Train Avg F1  259: 0.7509266332795744

Val Avg Loss  259: 0.066726

Val Avg F1  259:  0.8994949494949496

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 260
--------------------------------------------------------------
Epoch:  260        1 Batch loss: 0.074295 Batch F1: 0.8571428571428571
Epoch:  260        2 Batch loss: 0.058131 Batch F1: 0.33333333333333337
Epoch:  260        3 Batch loss: 0.101039 Batch F1: 0.15384615384615385
Epoch:  260        4 Batch loss: 0.091503 Batch F1: 0.0
Epoch:  260        5 Batch loss: 0.067042 Batch F1: 0.33333333333333337
Epoch:  260        6 Batch loss: 0.082830 Batch F1: 0.6666666666666666
Epoch:  260        7 Batch loss: 0.084949 Batch F1: 0.9
Epoch:  260        8 Batch loss: 0.052268 Batch F1: 1.0
Epoch:  260        9 Batch loss: 0.068399 Batch F1: 0.9473684210526316
Epoch:  260       10 Batch loss: 0.072563 Batch F1: 1.0
Epoch:  260       11 Batch loss: 0.070880 Batch F1: 0.888888888888889
Epoch:  260       12 Batch loss: 0.069240 Batch F1: 0.9411764705882353
Train Avg Loss  260: 0.074428

Train Avg F1  260: 0.6684796770710083

Val Avg Loss  260: 0.065056

Val Avg F1  260:  0.9176113360323886

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 261
--------------------------------------------------------------
Epoch:  261        1 Batch loss: 0.074519 Batch F1: 0.8000000000000002
Epoch:  261        2 Batch loss: 0.076369 Batch F1: 0.7142857142857143
Epoch:  261        3 Batch loss: 0.072553 Batch F1: 0.33333333333333337
Epoch:  261        4 Batch loss: 0.085546 Batch F1: 0.631578947368421
Epoch:  261        5 Batch loss: 0.055355 Batch F1: 0.7272727272727273
Epoch:  261        6 Batch loss: 0.076869 Batch F1: 0.923076923076923
Epoch:  261        7 Batch loss: 0.082329 Batch F1: 0.8571428571428571
Epoch:  261        8 Batch loss: 0.071122 Batch F1: 0.888888888888889
Epoch:  261        9 Batch loss: 0.083913 Batch F1: 0.8235294117647058
Epoch:  261       10 Batch loss: 0.043114 Batch F1: 1.0
Epoch:  261       11 Batch loss: 0.050682 Batch F1: 0.9411764705882353
Epoch:  261       12 Batch loss: 0.081232 Batch F1: 0.8235294117647058
Train Avg Loss  261: 0.071134

Train Avg F1  261: 0.7886512237905428

Val Avg Loss  261: 0.065243

Val Avg F1  261:  0.8063596491228071

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 262
--------------------------------------------------------------
Epoch:  262        1 Batch loss: 0.098344 Batch F1: 0.782608695652174
Epoch:  262        2 Batch loss: 0.058587 Batch F1: 0.9473684210526316
Epoch:  262        3 Batch loss: 0.061230 Batch F1: 0.9333333333333333
Epoch:  262        4 Batch loss: 0.078263 Batch F1: 0.88
Epoch:  262        5 Batch loss: 0.061314 Batch F1: 0.6666666666666666
Epoch:  262        6 Batch loss: 0.054821 Batch F1: 0.5714285714285715
Epoch:  262        7 Batch loss: 0.052822 Batch F1: 0.5
Epoch:  262        8 Batch loss: 0.051674 Batch F1: 0.5714285714285715
Epoch:  262        9 Batch loss: 0.116083 Batch F1: 0.0
Epoch:  262       10 Batch loss: 0.052231 Batch F1: 0.6666666666666666
Epoch:  262       11 Batch loss: 0.079799 Batch F1: 0.4615384615384615
Epoch:  262       12 Batch loss: 0.085657 Batch F1: 0.42857142857142855
Train Avg Loss  262: 0.070902

Train Avg F1  262: 0.6174675680282088

Val Avg Loss  262: 0.064648

Val Avg F1  262:  0.9006060606060606

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 263
--------------------------------------------------------------
Epoch:  263        1 Batch loss: 0.053044 Batch F1: 1.0
Epoch:  263        2 Batch loss: 0.084304 Batch F1: 0.9333333333333333
Epoch:  263        3 Batch loss: 0.081103 Batch F1: 0.8888888888888888
Epoch:  263        4 Batch loss: 0.089709 Batch F1: 0.9166666666666666
Epoch:  263        5 Batch loss: 0.068357 Batch F1: 0.8750000000000001
Epoch:  263        6 Batch loss: 0.068294 Batch F1: 0.8
Epoch:  263        7 Batch loss: 0.066020 Batch F1: 0.6
Epoch:  263        8 Batch loss: 0.086722 Batch F1: 0.7000000000000001
Epoch:  263        9 Batch loss: 0.060942 Batch F1: 0.6666666666666666
Epoch:  263       10 Batch loss: 0.061710 Batch F1: 0.923076923076923
Epoch:  263       11 Batch loss: 0.059678 Batch F1: 1.0
Epoch:  263       12 Batch loss: 0.082205 Batch F1: 0.8
Train Avg Loss  263: 0.071840

Train Avg F1  263: 0.8419693732193733

Val Avg Loss  263: 0.063571

Val Avg F1  263:  0.9340643274853802

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 264
--------------------------------------------------------------
Epoch:  264        1 Batch loss: 0.068209 Batch F1: 0.7692307692307693
Epoch:  264        2 Batch loss: 0.065285 Batch F1: 0.8235294117647058
Epoch:  264        3 Batch loss: 0.092045 Batch F1: 0.72
Epoch:  264        4 Batch loss: 0.060871 Batch F1: 1.0
Epoch:  264        5 Batch loss: 0.075681 Batch F1: 0.7272727272727272
Epoch:  264        6 Batch loss: 0.065028 Batch F1: 0.9333333333333333
Epoch:  264        7 Batch loss: 0.053446 Batch F1: 0.6666666666666666
Epoch:  264        8 Batch loss: 0.077301 Batch F1: 0.6666666666666666
Epoch:  264        9 Batch loss: 0.085930 Batch F1: 0.625
Epoch:  264       10 Batch loss: 0.072900 Batch F1: 1.0
Epoch:  264       11 Batch loss: 0.074707 Batch F1: 0.9473684210526316
Epoch:  264       12 Batch loss: 0.058057 Batch F1: 1.0
Train Avg Loss  264: 0.070788

Train Avg F1  264: 0.8232556663322917

Val Avg Loss  264: 0.063262

Val Avg F1  264:  0.6092077856783739

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 265
--------------------------------------------------------------
Epoch:  265        1 Batch loss: 0.084830 Batch F1: 0.6666666666666666
Epoch:  265        2 Batch loss: 0.056424 Batch F1: 0.5
Epoch:  265        3 Batch loss: 0.068235 Batch F1: 0.6153846153846153
Epoch:  265        4 Batch loss: 0.053483 Batch F1: 0.8
Epoch:  265        5 Batch loss: 0.068785 Batch F1: 0.4
Epoch:  265        6 Batch loss: 0.068665 Batch F1: 0.7272727272727273
Epoch:  265        7 Batch loss: 0.091414 Batch F1: 0.888888888888889
Epoch:  265        8 Batch loss: 0.072567 Batch F1: 0.9473684210526316
Epoch:  265        9 Batch loss: 0.076236 Batch F1: 0.7142857142857143
Epoch:  265       10 Batch loss: 0.061406 Batch F1: 0.2857142857142857
Epoch:  265       11 Batch loss: 0.054919 Batch F1: 0.6666666666666666
Epoch:  265       12 Batch loss: 0.078940 Batch F1: 0.7368421052631579
Train Avg Loss  265: 0.069659

Train Avg F1  265: 0.6624241742662795

Val Avg Loss  265: 0.064142

Val Avg F1  265:  0.6297562087035771

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 266
--------------------------------------------------------------
Epoch:  266        1 Batch loss: 0.063965 Batch F1: 0.4
Epoch:  266        2 Batch loss: 0.060903 Batch F1: 0.8888888888888888
Epoch:  266        3 Batch loss: 0.078955 Batch F1: 0.9523809523809523
Epoch:  266        4 Batch loss: 0.059551 Batch F1: 0.8750000000000001
Epoch:  266        5 Batch loss: 0.061941 Batch F1: 0.9523809523809523
Epoch:  266        6 Batch loss: 0.081252 Batch F1: 0.6666666666666666
Epoch:  266        7 Batch loss: 0.076738 Batch F1: 0.6666666666666666
Epoch:  266        8 Batch loss: 0.054961 Batch F1: 0.6666666666666666
Epoch:  266        9 Batch loss: 0.066800 Batch F1: 0.6153846153846153
Epoch:  266       10 Batch loss: 0.082266 Batch F1: 0.6666666666666666
Epoch:  266       11 Batch loss: 0.076925 Batch F1: 0.7058823529411764
Epoch:  266       12 Batch loss: 0.055506 Batch F1: 0.8571428571428571
Train Avg Loss  266: 0.068314

Train Avg F1  266: 0.7428106071488426

Val Avg Loss  266: 0.064536

Val Avg F1  266:  0.8503496503496503

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 267
--------------------------------------------------------------
Epoch:  267        1 Batch loss: 0.104622 Batch F1: 0.7272727272727273
Epoch:  267        2 Batch loss: 0.046938 Batch F1: 1.0
Epoch:  267        3 Batch loss: 0.063805 Batch F1: 0.9
Epoch:  267        4 Batch loss: 0.060938 Batch F1: 0.8333333333333333
Epoch:  267        5 Batch loss: 0.057585 Batch F1: 0.0
Epoch:  267        6 Batch loss: 0.058552 Batch F1: 0.8421052631578948
Epoch:  267        7 Batch loss: 0.079920 Batch F1: 0.4615384615384615
Epoch:  267        8 Batch loss: 0.080329 Batch F1: 0.6666666666666666
Epoch:  267        9 Batch loss: 0.082041 Batch F1: 0.7777777777777778
Epoch:  267       10 Batch loss: 0.051904 Batch F1: 1.0
Epoch:  267       11 Batch loss: 0.061919 Batch F1: 0.9473684210526316
Epoch:  267       12 Batch loss: 0.071415 Batch F1: 0.923076923076923
Train Avg Loss  267: 0.068331

Train Avg F1  267: 0.7565949644897013

Val Avg Loss  267: 0.064774

Val Avg F1  267:  0.8420496943716758

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 268
--------------------------------------------------------------
Epoch:  268        1 Batch loss: 0.071412 Batch F1: 0.9
Epoch:  268        2 Batch loss: 0.070659 Batch F1: 0.761904761904762
Epoch:  268        3 Batch loss: 0.060773 Batch F1: 0.25
Epoch:  268        4 Batch loss: 0.066720 Batch F1: 0.888888888888889
Epoch:  268        5 Batch loss: 0.060943 Batch F1: 0.9473684210526316
Epoch:  268        6 Batch loss: 0.055314 Batch F1: 0.8571428571428571
Epoch:  268        7 Batch loss: 0.077599 Batch F1: 0.823529411764706
Epoch:  268        8 Batch loss: 0.061112 Batch F1: 0.923076923076923
Epoch:  268        9 Batch loss: 0.070058 Batch F1: 0.6153846153846153
Epoch:  268       10 Batch loss: 0.066529 Batch F1: 0.5454545454545454
Epoch:  268       11 Batch loss: 0.057577 Batch F1: 0.5
Epoch:  268       12 Batch loss: 0.100851 Batch F1: 0.33333333333333337
Train Avg Loss  268: 0.068296

Train Avg F1  268: 0.6955069798336052

Val Avg Loss  268: 0.065824

Val Avg F1  268:  0.6123366013071896

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 269
--------------------------------------------------------------
Epoch:  269        1 Batch loss: 0.063161 Batch F1: 0.8
Epoch:  269        2 Batch loss: 0.073599 Batch F1: 0.8571428571428571
Epoch:  269        3 Batch loss: 0.069809 Batch F1: 0.9333333333333333
Epoch:  269        4 Batch loss: 0.068944 Batch F1: 0.8
Epoch:  269        5 Batch loss: 0.080361 Batch F1: 0.8695652173913044
Epoch:  269        6 Batch loss: 0.073719 Batch F1: 0.7499999999999999
Epoch:  269        7 Batch loss: 0.056545 Batch F1: 0.7499999999999999
Epoch:  269        8 Batch loss: 0.062973 Batch F1: 1.0
Epoch:  269        9 Batch loss: 0.063329 Batch F1: 0.6666666666666666
Epoch:  269       10 Batch loss: 0.055443 Batch F1: 0.8
Epoch:  269       11 Batch loss: 0.071807 Batch F1: 0.9473684210526316
Epoch:  269       12 Batch loss: 0.066976 Batch F1: 0.6666666666666666
Train Avg Loss  269: 0.067222

Train Avg F1  269: 0.8200619301877884

Val Avg Loss  269: 0.062948

Val Avg F1  269:  0.8484492481203009

Optimal Val loss (Epoch 215): 0.06282148603349924

Epoch 270
--------------------------------------------------------------
Epoch:  270        1 Batch loss: 0.064379 Batch F1: 0.6666666666666666
Epoch:  270        2 Batch loss: 0.066491 Batch F1: 0.7499999999999999
Epoch:  270        3 Batch loss: 0.050456 Batch F1: 0.6666666666666666
Epoch:  270        4 Batch loss: 0.093400 Batch F1: 0.6086956521739131
Epoch:  270        5 Batch loss: 0.061687 Batch F1: 0.6666666666666665
Epoch:  270        6 Batch loss: 0.068180 Batch F1: 0.8421052631578948
Epoch:  270        7 Batch loss: 0.068341 Batch F1: 0.9523809523809523
Epoch:  270        8 Batch loss: 0.075022 Batch F1: 0.7777777777777778
Epoch:  270        9 Batch loss: 0.072737 Batch F1: 0.6666666666666666
Epoch:  270       10 Batch loss: 0.055072 Batch F1: 0.5714285714285715
Epoch:  270       11 Batch loss: 0.073014 Batch F1: 0.8421052631578948
Epoch:  270       12 Batch loss: 0.060028 Batch F1: 0.7272727272727273
Train Avg Loss  270: 0.067400

Train Avg F1  270: 0.7282027395013665

Val Avg Loss  270: 0.062689

Val Avg F1  270:  0.764102564102564

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 271
--------------------------------------------------------------
Epoch:  271        1 Batch loss: 0.063328 Batch F1: 0.7692307692307693
Epoch:  271        2 Batch loss: 0.056296 Batch F1: 0.6666666666666666
Epoch:  271        3 Batch loss: 0.076004 Batch F1: 0.4
Epoch:  271        4 Batch loss: 0.083015 Batch F1: 0.18181818181818182
Epoch:  271        5 Batch loss: 0.082777 Batch F1: 0.5
Epoch:  271        6 Batch loss: 0.057826 Batch F1: 0.8421052631578948
Epoch:  271        7 Batch loss: 0.066885 Batch F1: 0.8421052631578948
Epoch:  271        8 Batch loss: 0.060297 Batch F1: 0.888888888888889
Epoch:  271        9 Batch loss: 0.061251 Batch F1: 0.9090909090909091
Epoch:  271       10 Batch loss: 0.071174 Batch F1: 0.9600000000000001
Epoch:  271       11 Batch loss: 0.062064 Batch F1: 1.0
Epoch:  271       12 Batch loss: 0.075083 Batch F1: 0.8333333333333333
Train Avg Loss  271: 0.068000

Train Avg F1  271: 0.732769939612045

Val Avg Loss  271: 0.064407

Val Avg F1  271:  0.8581550802139037

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 272
--------------------------------------------------------------
Epoch:  272        1 Batch loss: 0.060056 Batch F1: 0.9523809523809523
Epoch:  272        2 Batch loss: 0.078273 Batch F1: 0.4
Epoch:  272        3 Batch loss: 0.055536 Batch F1: 0.6666666666666666
Epoch:  272        4 Batch loss: 0.073258 Batch F1: 0.2222222222222222
Epoch:  272        5 Batch loss: 0.076551 Batch F1: 0.5333333333333333
Epoch:  272        6 Batch loss: 0.057483 Batch F1: 0.8235294117647058
Epoch:  272        7 Batch loss: 0.101049 Batch F1: 0.8148148148148148
Epoch:  272        8 Batch loss: 0.054792 Batch F1: 0.8
Epoch:  272        9 Batch loss: 0.055617 Batch F1: 1.0
Epoch:  272       10 Batch loss: 0.048973 Batch F1: 0.9473684210526316
Epoch:  272       11 Batch loss: 0.082198 Batch F1: 0.3636363636363636
Epoch:  272       12 Batch loss: 0.064077 Batch F1: 0.7499999999999999
Train Avg Loss  272: 0.067322

Train Avg F1  272: 0.6894960154893074

Val Avg Loss  272: 0.067265

Val Avg F1  272:  0.6431277056277056

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 273
--------------------------------------------------------------
Epoch:  273        1 Batch loss: 0.082350 Batch F1: 0.7272727272727273
Epoch:  273        2 Batch loss: 0.064442 Batch F1: 0.9090909090909091
Epoch:  273        3 Batch loss: 0.061362 Batch F1: 0.6666666666666666
Epoch:  273        4 Batch loss: 0.089937 Batch F1: 0.6
Epoch:  273        5 Batch loss: 0.049706 Batch F1: 0.6666666666666666
Epoch:  273        6 Batch loss: 0.063118 Batch F1: 0.7368421052631579
Epoch:  273        7 Batch loss: 0.062986 Batch F1: 0.8333333333333333
Epoch:  273        8 Batch loss: 0.042976 Batch F1: 1.0
Epoch:  273        9 Batch loss: 0.073633 Batch F1: 0.7142857142857143
Epoch:  273       10 Batch loss: 0.103727 Batch F1: 0.5
Epoch:  273       11 Batch loss: 0.055252 Batch F1: 0.8333333333333333
Epoch:  273       12 Batch loss: 0.076235 Batch F1: 0.8
Train Avg Loss  273: 0.068810

Train Avg F1  273: 0.7489576213260424

Val Avg Loss  273: 0.065561

Val Avg F1  273:  0.8930323299888517

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 274
--------------------------------------------------------------
Epoch:  274        1 Batch loss: 0.071543 Batch F1: 0.962962962962963
Epoch:  274        2 Batch loss: 0.063747 Batch F1: 0.8571428571428571
Epoch:  274        3 Batch loss: 0.088665 Batch F1: 0.625
Epoch:  274        4 Batch loss: 0.062527 Batch F1: 0.7692307692307693
Epoch:  274        5 Batch loss: 0.075105 Batch F1: 0.7058823529411764
Epoch:  274        6 Batch loss: 0.077443 Batch F1: 0.7368421052631579
Epoch:  274        7 Batch loss: 0.049302 Batch F1: 0.7499999999999999
Epoch:  274        8 Batch loss: 0.056063 Batch F1: 0.8
Epoch:  274        9 Batch loss: 0.071556 Batch F1: 0.7777777777777778
Epoch:  274       10 Batch loss: 0.061726 Batch F1: 0.25
Epoch:  274       11 Batch loss: 0.061477 Batch F1: 0.4
Epoch:  274       12 Batch loss: 0.068758 Batch F1: 0.4
Train Avg Loss  274: 0.067326

Train Avg F1  274: 0.6695699021098918

Val Avg Loss  274: 0.063134

Val Avg F1  274:  0.7857142857142856

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 275
--------------------------------------------------------------
Epoch:  275        1 Batch loss: 0.065728 Batch F1: 0.6666666666666666
Epoch:  275        2 Batch loss: 0.058157 Batch F1: 0.9411764705882353
Epoch:  275        3 Batch loss: 0.061489 Batch F1: 0.8571428571428571
Epoch:  275        4 Batch loss: 0.069818 Batch F1: 0.9
Epoch:  275        5 Batch loss: 0.063717 Batch F1: 0.8
Epoch:  275        6 Batch loss: 0.068983 Batch F1: 0.7142857142857143
Epoch:  275        7 Batch loss: 0.075750 Batch F1: 0.8421052631578948
Epoch:  275        8 Batch loss: 0.068862 Batch F1: 0.9523809523809523
Epoch:  275        9 Batch loss: 0.056621 Batch F1: 0.9411764705882353
Epoch:  275       10 Batch loss: 0.060067 Batch F1: 0.923076923076923
Epoch:  275       11 Batch loss: 0.073597 Batch F1: 0.7499999999999999
Epoch:  275       12 Batch loss: 0.072406 Batch F1: 0.9333333333333333
Train Avg Loss  275: 0.066266

Train Avg F1  275: 0.8517787209350677

Val Avg Loss  275: 0.064180

Val Avg F1  275:  0.7342105263157895

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 276
--------------------------------------------------------------
Epoch:  276        1 Batch loss: 0.068207 Batch F1: 0.8421052631578948
Epoch:  276        2 Batch loss: 0.050762 Batch F1: 0.5714285714285715
Epoch:  276        3 Batch loss: 0.072987 Batch F1: 0.8181818181818181
Epoch:  276        4 Batch loss: 0.060916 Batch F1: 0.823529411764706
Epoch:  276        5 Batch loss: 0.077520 Batch F1: 0.5333333333333333
Epoch:  276        6 Batch loss: 0.067432 Batch F1: 0.6666666666666666
Epoch:  276        7 Batch loss: 0.079304 Batch F1: 0.8235294117647058
Epoch:  276        8 Batch loss: 0.051472 Batch F1: 0.8571428571428571
Epoch:  276        9 Batch loss: 0.073701 Batch F1: 0.8421052631578948
Epoch:  276       10 Batch loss: 0.062942 Batch F1: 0.8
Epoch:  276       11 Batch loss: 0.079796 Batch F1: 0.4
Epoch:  276       12 Batch loss: 0.061008 Batch F1: 0.8571428571428571
Train Avg Loss  276: 0.067171

Train Avg F1  276: 0.7362637878117754

Val Avg Loss  276: 0.063453

Val Avg F1  276:  0.7595682503770739

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 277
--------------------------------------------------------------
Epoch:  277        1 Batch loss: 0.059046 Batch F1: 0.5
Epoch:  277        2 Batch loss: 0.065289 Batch F1: 0.9090909090909091
Epoch:  277        3 Batch loss: 0.067624 Batch F1: 0.8750000000000001
Epoch:  277        4 Batch loss: 0.076797 Batch F1: 0.7777777777777778
Epoch:  277        5 Batch loss: 0.083143 Batch F1: 0.7272727272727273
Epoch:  277        6 Batch loss: 0.077484 Batch F1: 0.7142857142857143
Epoch:  277        7 Batch loss: 0.040526 Batch F1: 0.9090909090909091
Epoch:  277        8 Batch loss: 0.068659 Batch F1: 0.2222222222222222
Epoch:  277        9 Batch loss: 0.083158 Batch F1: 0.6666666666666666
Epoch:  277       10 Batch loss: 0.070236 Batch F1: 0.5
Epoch:  277       11 Batch loss: 0.065424 Batch F1: 0.9523809523809523
Epoch:  277       12 Batch loss: 0.066790 Batch F1: 0.9333333333333333
Train Avg Loss  277: 0.068681

Train Avg F1  277: 0.7239267676767677

Val Avg Loss  277: 0.067089

Val Avg F1  277:  0.9109351432880846

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 278
--------------------------------------------------------------
Epoch:  278        1 Batch loss: 0.075489 Batch F1: 0.8695652173913044
Epoch:  278        2 Batch loss: 0.092736 Batch F1: 0.7368421052631579
Epoch:  278        3 Batch loss: 0.065200 Batch F1: 0.8571428571428571
Epoch:  278        4 Batch loss: 0.072395 Batch F1: 0.5714285714285715
Epoch:  278        5 Batch loss: 0.064532 Batch F1: 0.888888888888889
Epoch:  278        6 Batch loss: 0.053717 Batch F1: 0.8
Epoch:  278        7 Batch loss: 0.060933 Batch F1: 0.2857142857142857
Epoch:  278        8 Batch loss: 0.057724 Batch F1: 0.8
Epoch:  278        9 Batch loss: 0.075278 Batch F1: 0.4615384615384615
Epoch:  278       10 Batch loss: 0.059031 Batch F1: 1.0
Epoch:  278       11 Batch loss: 0.099945 Batch F1: 0.75
Epoch:  278       12 Batch loss: 0.060930 Batch F1: 0.923076923076923
Train Avg Loss  278: 0.069826

Train Avg F1  278: 0.745349775870371

Val Avg Loss  278: 0.075210

Val Avg F1  278:  0.4964646464646464

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 279
--------------------------------------------------------------
Epoch:  279        1 Batch loss: 0.106258 Batch F1: 0.5263157894736842
Epoch:  279        2 Batch loss: 0.065735 Batch F1: 0.7692307692307693
Epoch:  279        3 Batch loss: 0.080836 Batch F1: 0.5882352941176471
Epoch:  279        4 Batch loss: 0.057626 Batch F1: 0.8
Epoch:  279        5 Batch loss: 0.077893 Batch F1: 0.9523809523809523
Epoch:  279        6 Batch loss: 0.070850 Batch F1: 0.9523809523809523
Epoch:  279        7 Batch loss: 0.062032 Batch F1: 0.6
Epoch:  279        8 Batch loss: 0.082271 Batch F1: 0.7777777777777778
Epoch:  279        9 Batch loss: 0.067340 Batch F1: 0.888888888888889
Epoch:  279       10 Batch loss: 0.052149 Batch F1: 0.923076923076923
Epoch:  279       11 Batch loss: 0.069222 Batch F1: 0.4
Epoch:  279       12 Batch loss: 0.068086 Batch F1: 0.0
Train Avg Loss  279: 0.071691

Train Avg F1  279: 0.6815239456106329

Val Avg Loss  279: 0.065140

Val Avg F1  279:  0.6355042016806722

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 280
--------------------------------------------------------------
Epoch:  280        1 Batch loss: 0.070901 Batch F1: 0.5
Epoch:  280        2 Batch loss: 0.058597 Batch F1: 0.9523809523809523
Epoch:  280        3 Batch loss: 0.085441 Batch F1: 0.8695652173913044
Epoch:  280        4 Batch loss: 0.065374 Batch F1: 0.9090909090909091
Epoch:  280        5 Batch loss: 0.050032 Batch F1: 1.0
Epoch:  280        6 Batch loss: 0.065470 Batch F1: 0.25
Epoch:  280        7 Batch loss: 0.098709 Batch F1: 0.0
Epoch:  280        8 Batch loss: 0.101534 Batch F1: 0.5882352941176471
Epoch:  280        9 Batch loss: 0.063322 Batch F1: 0.9411764705882353
Epoch:  280       10 Batch loss: 0.074034 Batch F1: 1.0
Epoch:  280       11 Batch loss: 0.090620 Batch F1: 0.8235294117647058
Epoch:  280       12 Batch loss: 0.056322 Batch F1: 0.5
Train Avg Loss  280: 0.073363

Train Avg F1  280: 0.6944981879444795

Val Avg Loss  280: 0.071261

Val Avg F1  280:  0.5930618401206637

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 281
--------------------------------------------------------------
Epoch:  281        1 Batch loss: 0.078055 Batch F1: 0.7142857142857143
Epoch:  281        2 Batch loss: 0.069790 Batch F1: 0.5714285714285715
Epoch:  281        3 Batch loss: 0.058708 Batch F1: 0.6666666666666666
Epoch:  281        4 Batch loss: 0.062074 Batch F1: 0.8
Epoch:  281        5 Batch loss: 0.079094 Batch F1: 0.4
Epoch:  281        6 Batch loss: 0.071539 Batch F1: 0.3636363636363636
Epoch:  281        7 Batch loss: 0.079999 Batch F1: 0.8
Epoch:  281        8 Batch loss: 0.067957 Batch F1: 0.9523809523809523
Epoch:  281        9 Batch loss: 0.075790 Batch F1: 0.9411764705882353
Epoch:  281       10 Batch loss: 0.079827 Batch F1: 0.625
Epoch:  281       11 Batch loss: 0.044519 Batch F1: 0.4
Epoch:  281       12 Batch loss: 0.095693 Batch F1: 0.2222222222222222
Train Avg Loss  281: 0.071921

Train Avg F1  281: 0.6213997467673938

Val Avg Loss  281: 0.074108

Val Avg F1  281:  0.5216346153846154

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 282
--------------------------------------------------------------
Epoch:  282        1 Batch loss: 0.059272 Batch F1: 0.6
Epoch:  282        2 Batch loss: 0.082908 Batch F1: 0.33333333333333337
Epoch:  282        3 Batch loss: 0.087337 Batch F1: 0.9032258064516129
Epoch:  282        4 Batch loss: 0.090258 Batch F1: 0.8750000000000001
Epoch:  282        5 Batch loss: 0.062684 Batch F1: 0.7272727272727273
Epoch:  282        6 Batch loss: 0.050874 Batch F1: 0.0
Epoch:  282        7 Batch loss: 0.103298 Batch F1: 0.0
Epoch:  282        8 Batch loss: 0.063124 Batch F1: 0.0
Epoch:  282        9 Batch loss: 0.082762 Batch F1: 0.6666666666666666
Epoch:  282       10 Batch loss: 0.075696 Batch F1: 0.8333333333333333
Epoch:  282       11 Batch loss: 0.066298 Batch F1: 1.0
Epoch:  282       12 Batch loss: 0.053004 Batch F1: 0.923076923076923
Train Avg Loss  282: 0.073126

Train Avg F1  282: 0.5718257325112164

Val Avg Loss  282: 0.063990

Val Avg F1  282:  0.8184697655285891

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 283
--------------------------------------------------------------
Epoch:  283        1 Batch loss: 0.066644 Batch F1: 1.0
Epoch:  283        2 Batch loss: 0.056847 Batch F1: 0.888888888888889
Epoch:  283        3 Batch loss: 0.042468 Batch F1: 0.888888888888889
Epoch:  283        4 Batch loss: 0.084969 Batch F1: 0.5333333333333333
Epoch:  283        5 Batch loss: 0.069943 Batch F1: 0.7499999999999999
Epoch:  283        6 Batch loss: 0.102339 Batch F1: 0.631578947368421
Epoch:  283        7 Batch loss: 0.081641 Batch F1: 0.7142857142857143
Epoch:  283        8 Batch loss: 0.085003 Batch F1: 0.4615384615384615
Epoch:  283        9 Batch loss: 0.057912 Batch F1: 0.4
Epoch:  283       10 Batch loss: 0.069826 Batch F1: 0.4
Epoch:  283       11 Batch loss: 0.052115 Batch F1: 0.7272727272727273
Epoch:  283       12 Batch loss: 0.086068 Batch F1: 0.625
Train Avg Loss  283: 0.071315

Train Avg F1  283: 0.6683989134647031

Val Avg Loss  283: 0.065123

Val Avg F1  283:  0.8423444976076555

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 284
--------------------------------------------------------------
Epoch:  284        1 Batch loss: 0.071178 Batch F1: 0.6
Epoch:  284        2 Batch loss: 0.085282 Batch F1: 0.9090909090909091
Epoch:  284        3 Batch loss: 0.056804 Batch F1: 1.0
Epoch:  284        4 Batch loss: 0.085271 Batch F1: 0.9523809523809523
Epoch:  284        5 Batch loss: 0.100153 Batch F1: 0.42857142857142855
Epoch:  284        6 Batch loss: 0.051175 Batch F1: 0.923076923076923
Epoch:  284        7 Batch loss: 0.055659 Batch F1: 0.8333333333333333
Epoch:  284        8 Batch loss: 0.041459 Batch F1: 0.7499999999999999
Epoch:  284        9 Batch loss: 0.112764 Batch F1: 0.375
Epoch:  284       10 Batch loss: 0.062958 Batch F1: 0.9473684210526316
Epoch:  284       11 Batch loss: 0.069434 Batch F1: 0.8750000000000001
Epoch:  284       12 Batch loss: 0.090904 Batch F1: 1.0
Train Avg Loss  284: 0.073587

Train Avg F1  284: 0.7994851639588482

Val Avg Loss  284: 0.067937

Val Avg F1  284:  0.9369913973494537

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 285
--------------------------------------------------------------
Epoch:  285        1 Batch loss: 0.079684 Batch F1: 1.0
Epoch:  285        2 Batch loss: 0.067719 Batch F1: 1.0
Epoch:  285        3 Batch loss: 0.065798 Batch F1: 0.9411764705882353
Epoch:  285        4 Batch loss: 0.073423 Batch F1: 0.7692307692307693
Epoch:  285        5 Batch loss: 0.052197 Batch F1: 0.8333333333333333
Epoch:  285        6 Batch loss: 0.074186 Batch F1: 0.5
Epoch:  285        7 Batch loss: 0.086472 Batch F1: 0.42857142857142855
Epoch:  285        8 Batch loss: 0.057351 Batch F1: 0.7272727272727273
Epoch:  285        9 Batch loss: 0.085877 Batch F1: 0.6666666666666666
Epoch:  285       10 Batch loss: 0.093460 Batch F1: 0.7777777777777777
Epoch:  285       11 Batch loss: 0.055238 Batch F1: 0.8333333333333333
Epoch:  285       12 Batch loss: 0.063140 Batch F1: 0.7692307692307693
Train Avg Loss  285: 0.071212

Train Avg F1  285: 0.7705494396670868

Val Avg Loss  285: 0.065868

Val Avg F1  285:  0.6026515151515152

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 286
--------------------------------------------------------------
Epoch:  286        1 Batch loss: 0.055936 Batch F1: 0.5
Epoch:  286        2 Batch loss: 0.067889 Batch F1: 0.5454545454545454
Epoch:  286        3 Batch loss: 0.065237 Batch F1: 0.7058823529411764
Epoch:  286        4 Batch loss: 0.087938 Batch F1: 0.42857142857142855
Epoch:  286        5 Batch loss: 0.069318 Batch F1: 1.0
Epoch:  286        6 Batch loss: 0.066843 Batch F1: 0.888888888888889
Epoch:  286        7 Batch loss: 0.085536 Batch F1: 0.7368421052631579
Epoch:  286        8 Batch loss: 0.088842 Batch F1: 0.7777777777777778
Epoch:  286        9 Batch loss: 0.061077 Batch F1: 0.7999999999999999
Epoch:  286       10 Batch loss: 0.059082 Batch F1: 0.8235294117647058
Epoch:  286       11 Batch loss: 0.069109 Batch F1: 0.7272727272727273
Epoch:  286       12 Batch loss: 0.064300 Batch F1: 0.6
Train Avg Loss  286: 0.070092

Train Avg F1  286: 0.7111849364945341

Val Avg Loss  286: 0.066410

Val Avg F1  286:  0.631578947368421

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 287
--------------------------------------------------------------
Epoch:  287        1 Batch loss: 0.071770 Batch F1: 0.2222222222222222
Epoch:  287        2 Batch loss: 0.065559 Batch F1: 0.7142857142857143
Epoch:  287        3 Batch loss: 0.081469 Batch F1: 0.4615384615384615
Epoch:  287        4 Batch loss: 0.065157 Batch F1: 0.6666666666666666
Epoch:  287        5 Batch loss: 0.072932 Batch F1: 0.7368421052631579
Epoch:  287        6 Batch loss: 0.066140 Batch F1: 0.7142857142857143
Epoch:  287        7 Batch loss: 0.062264 Batch F1: 1.0
Epoch:  287        8 Batch loss: 0.064523 Batch F1: 0.9333333333333333
Epoch:  287        9 Batch loss: 0.053707 Batch F1: 0.9090909090909091
Epoch:  287       10 Batch loss: 0.074661 Batch F1: 0.5714285714285715
Epoch:  287       11 Batch loss: 0.065936 Batch F1: 0.7499999999999999
Epoch:  287       12 Batch loss: 0.102864 Batch F1: 0.4
Train Avg Loss  287: 0.070582

Train Avg F1  287: 0.6733078081762293

Val Avg Loss  287: 0.063980

Val Avg F1  287:  0.7316464237516869

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 288
--------------------------------------------------------------
Epoch:  288        1 Batch loss: 0.062044 Batch F1: 0.8235294117647058
Epoch:  288        2 Batch loss: 0.050083 Batch F1: 0.9333333333333333
Epoch:  288        3 Batch loss: 0.060653 Batch F1: 1.0
Epoch:  288        4 Batch loss: 0.091010 Batch F1: 0.8695652173913044
Epoch:  288        5 Batch loss: 0.049880 Batch F1: 0.923076923076923
Epoch:  288        6 Batch loss: 0.074930 Batch F1: 0.5454545454545454
Epoch:  288        7 Batch loss: 0.098743 Batch F1: 0.7000000000000001
Epoch:  288        8 Batch loss: 0.070856 Batch F1: 0.6666666666666666
Epoch:  288        9 Batch loss: 0.064510 Batch F1: 0.8
Epoch:  288       10 Batch loss: 0.049172 Batch F1: 0.9090909090909091
Epoch:  288       11 Batch loss: 0.085096 Batch F1: 0.47058823529411764
Epoch:  288       12 Batch loss: 0.073278 Batch F1: 0.7777777777777778
Train Avg Loss  288: 0.069188

Train Avg F1  288: 0.7849235849875238

Val Avg Loss  288: 0.064228

Val Avg F1  288:  0.8133089133089132

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 289
--------------------------------------------------------------
Epoch:  289        1 Batch loss: 0.058905 Batch F1: 0.923076923076923
Epoch:  289        2 Batch loss: 0.070587 Batch F1: 1.0
Epoch:  289        3 Batch loss: 0.087020 Batch F1: 0.8571428571428571
Epoch:  289        4 Batch loss: 0.079966 Batch F1: 0.8421052631578948
Epoch:  289        5 Batch loss: 0.061263 Batch F1: 0.8750000000000001
Epoch:  289        6 Batch loss: 0.090153 Batch F1: 0.761904761904762
Epoch:  289        7 Batch loss: 0.073922 Batch F1: 0.8571428571428571
Epoch:  289        8 Batch loss: 0.066549 Batch F1: 0.875
Epoch:  289        9 Batch loss: 0.054540 Batch F1: 0.8
Epoch:  289       10 Batch loss: 0.062201 Batch F1: 0.9
Epoch:  289       11 Batch loss: 0.056717 Batch F1: 0.9333333333333333
Epoch:  289       12 Batch loss: 0.053755 Batch F1: 0.5
Train Avg Loss  289: 0.067965

Train Avg F1  289: 0.8437254996465522

Val Avg Loss  289: 0.065500

Val Avg F1  289:  0.5750891265597148

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 290
--------------------------------------------------------------
Epoch:  290        1 Batch loss: 0.081490 Batch F1: 0.5882352941176471
Epoch:  290        2 Batch loss: 0.081394 Batch F1: 0.5
Epoch:  290        3 Batch loss: 0.075419 Batch F1: 0.761904761904762
Epoch:  290        4 Batch loss: 0.056301 Batch F1: 1.0
Epoch:  290        5 Batch loss: 0.066734 Batch F1: 1.0
Epoch:  290        6 Batch loss: 0.063477 Batch F1: 0.888888888888889
Epoch:  290        7 Batch loss: 0.071777 Batch F1: 0.0
Epoch:  290        8 Batch loss: 0.062927 Batch F1: 0.2222222222222222
Epoch:  290        9 Batch loss: 0.085509 Batch F1: 0.33333333333333337
Epoch:  290       10 Batch loss: 0.082940 Batch F1: 0.0
Epoch:  290       11 Batch loss: 0.067943 Batch F1: 0.9473684210526316
Epoch:  290       12 Batch loss: 0.074445 Batch F1: 1.0
Train Avg Loss  290: 0.072530

Train Avg F1  290: 0.6034960767932904

Val Avg Loss  290: 0.068980

Val Avg F1  290:  0.9221595655806183

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 291
--------------------------------------------------------------
Epoch:  291        1 Batch loss: 0.065838 Batch F1: 1.0
Epoch:  291        2 Batch loss: 0.094071 Batch F1: 0.6363636363636364
Epoch:  291        3 Batch loss: 0.054270 Batch F1: 0.8
Epoch:  291        4 Batch loss: 0.057142 Batch F1: 0.923076923076923
Epoch:  291        5 Batch loss: 0.066742 Batch F1: 0.8750000000000001
Epoch:  291        6 Batch loss: 0.083399 Batch F1: 0.6153846153846153
Epoch:  291        7 Batch loss: 0.061191 Batch F1: 0.6153846153846153
Epoch:  291        8 Batch loss: 0.092229 Batch F1: 0.19999999999999998
Epoch:  291        9 Batch loss: 0.046604 Batch F1: 0.8571428571428571
Epoch:  291       10 Batch loss: 0.096113 Batch F1: 0.42857142857142855
Epoch:  291       11 Batch loss: 0.070038 Batch F1: 0.6153846153846153
Epoch:  291       12 Batch loss: 0.076328 Batch F1: 0.8
Train Avg Loss  291: 0.071997

Train Avg F1  291: 0.6971923909423908

Val Avg Loss  291: 0.067016

Val Avg F1  291:  0.8071428571428572

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 292
--------------------------------------------------------------
Epoch:  292        1 Batch loss: 0.073460 Batch F1: 0.8333333333333333
Epoch:  292        2 Batch loss: 0.056861 Batch F1: 0.8421052631578948
Epoch:  292        3 Batch loss: 0.068193 Batch F1: 0.8750000000000001
Epoch:  292        4 Batch loss: 0.056320 Batch F1: 0.8571428571428571
Epoch:  292        5 Batch loss: 0.063870 Batch F1: 0.5
Epoch:  292        6 Batch loss: 0.061471 Batch F1: 0.6666666666666666
Epoch:  292        7 Batch loss: 0.085518 Batch F1: 0.4615384615384615
Epoch:  292        8 Batch loss: 0.069389 Batch F1: 0.5714285714285715
Epoch:  292        9 Batch loss: 0.071711 Batch F1: 0.5454545454545454
Epoch:  292       10 Batch loss: 0.073089 Batch F1: 0.888888888888889
Epoch:  292       11 Batch loss: 0.079239 Batch F1: 0.8695652173913044
Epoch:  292       12 Batch loss: 0.077059 Batch F1: 0.9473684210526316
Train Avg Loss  292: 0.069682

Train Avg F1  292: 0.7382076855045964

Val Avg Loss  292: 0.064927

Val Avg F1  292:  0.9105590062111801

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 293
--------------------------------------------------------------
Epoch:  293        1 Batch loss: 0.067153 Batch F1: 0.888888888888889
Epoch:  293        2 Batch loss: 0.060676 Batch F1: 0.8
Epoch:  293        3 Batch loss: 0.075250 Batch F1: 0.9090909090909091
Epoch:  293        4 Batch loss: 0.088184 Batch F1: 0.8571428571428572
Epoch:  293        5 Batch loss: 0.066669 Batch F1: 0.7777777777777778
Epoch:  293        6 Batch loss: 0.107160 Batch F1: 0.7741935483870968
Epoch:  293        7 Batch loss: 0.054794 Batch F1: 1.0
Epoch:  293        8 Batch loss: 0.062172 Batch F1: 1.0
Epoch:  293        9 Batch loss: 0.077149 Batch F1: 0.7272727272727273
Epoch:  293       10 Batch loss: 0.043357 Batch F1: 0.6666666666666666
Epoch:  293       11 Batch loss: 0.091219 Batch F1: 0.625
Epoch:  293       12 Batch loss: 0.067354 Batch F1: 0.4444444444444445
Train Avg Loss  293: 0.071761

Train Avg F1  293: 0.7892064849726141

Val Avg Loss  293: 0.067412

Val Avg F1  293:  0.5839743589743589

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 294
--------------------------------------------------------------
Epoch:  294        1 Batch loss: 0.048056 Batch F1: 0.5
Epoch:  294        2 Batch loss: 0.071660 Batch F1: 0.7058823529411764
Epoch:  294        3 Batch loss: 0.073145 Batch F1: 0.8421052631578948
Epoch:  294        4 Batch loss: 0.067080 Batch F1: 1.0
Epoch:  294        5 Batch loss: 0.063084 Batch F1: 0.7692307692307693
Epoch:  294        6 Batch loss: 0.090809 Batch F1: 0.5555555555555556
Epoch:  294        7 Batch loss: 0.091507 Batch F1: 0.42857142857142855
Epoch:  294        8 Batch loss: 0.084488 Batch F1: 0.88
Epoch:  294        9 Batch loss: 0.083486 Batch F1: 0.9333333333333333
Epoch:  294       10 Batch loss: 0.100729 Batch F1: 0.6666666666666665
Epoch:  294       11 Batch loss: 0.051949 Batch F1: 0.888888888888889
Epoch:  294       12 Batch loss: 0.103252 Batch F1: 0.4615384615384615
Train Avg Loss  294: 0.077437

Train Avg F1  294: 0.7193143933236813

Val Avg Loss  294: 0.074740

Val Avg F1  294:  0.5546398046398047

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 295
--------------------------------------------------------------
Epoch:  295        1 Batch loss: 0.067606 Batch F1: 0.4444444444444445
Epoch:  295        2 Batch loss: 0.089239 Batch F1: 0.3076923076923077
Epoch:  295        3 Batch loss: 0.073163 Batch F1: 0.8235294117647058
Epoch:  295        4 Batch loss: 0.086644 Batch F1: 0.9166666666666666
Epoch:  295        5 Batch loss: 0.114586 Batch F1: 0.7058823529411765
Epoch:  295        6 Batch loss: 0.061190 Batch F1: 1.0
Epoch:  295        7 Batch loss: 0.078572 Batch F1: 0.7499999999999999
Epoch:  295        8 Batch loss: 0.066337 Batch F1: 0.5454545454545454
Epoch:  295        9 Batch loss: 0.097062 Batch F1: 0.5555555555555556
Epoch:  295       10 Batch loss: 0.082339 Batch F1: 0.5714285714285715
Epoch:  295       11 Batch loss: 0.062172 Batch F1: 0.5
Epoch:  295       12 Batch loss: 0.059151 Batch F1: 0.5714285714285715
Train Avg Loss  295: 0.078172

Train Avg F1  295: 0.6410068689480454

Val Avg Loss  295: 0.069696

Val Avg F1  295:  0.5309829059829059

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 296
--------------------------------------------------------------
Epoch:  296        1 Batch loss: 0.076851 Batch F1: 0.6153846153846153
Epoch:  296        2 Batch loss: 0.077097 Batch F1: 0.5
Epoch:  296        3 Batch loss: 0.073852 Batch F1: 0.4615384615384615
Epoch:  296        4 Batch loss: 0.065960 Batch F1: 0.888888888888889
Epoch:  296        5 Batch loss: 0.076109 Batch F1: 0.9523809523809523
Epoch:  296        6 Batch loss: 0.091580 Batch F1: 0.5882352941176471
Epoch:  296        7 Batch loss: 0.071054 Batch F1: 0.7692307692307693
Epoch:  296        8 Batch loss: 0.061936 Batch F1: 0.7692307692307693
Epoch:  296        9 Batch loss: 0.049547 Batch F1: 0.5714285714285715
Epoch:  296       10 Batch loss: 0.073924 Batch F1: 0.7499999999999999
Epoch:  296       11 Batch loss: 0.068466 Batch F1: 0.7272727272727273
Epoch:  296       12 Batch loss: 0.083548 Batch F1: 0.8
Train Avg Loss  296: 0.072494

Train Avg F1  296: 0.6994659207894501

Val Avg Loss  296: 0.066574

Val Avg F1  296:  0.9493966817496229

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 297
--------------------------------------------------------------
Epoch:  297        1 Batch loss: 0.059982 Batch F1: 0.923076923076923
Epoch:  297        2 Batch loss: 0.065887 Batch F1: 0.5
Epoch:  297        3 Batch loss: 0.060569 Batch F1: 0.4444444444444445
Epoch:  297        4 Batch loss: 0.065243 Batch F1: 0.7777777777777778
Epoch:  297        5 Batch loss: 0.081221 Batch F1: 0.42857142857142855
Epoch:  297        6 Batch loss: 0.089454 Batch F1: 0.4444444444444445
Epoch:  297        7 Batch loss: 0.070926 Batch F1: 1.0
Epoch:  297        8 Batch loss: 0.068537 Batch F1: 0.9090909090909091
Epoch:  297        9 Batch loss: 0.071529 Batch F1: 0.8
Epoch:  297       10 Batch loss: 0.078266 Batch F1: 0.7142857142857143
Epoch:  297       11 Batch loss: 0.091449 Batch F1: 0.5555555555555556
Epoch:  297       12 Batch loss: 0.082147 Batch F1: 0.6153846153846153
Train Avg Loss  297: 0.073767

Train Avg F1  297: 0.6760526510526511

Val Avg Loss  297: 0.070212

Val Avg F1  297:  0.8959330143540669

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 298
--------------------------------------------------------------
Epoch:  298        1 Batch loss: 0.091687 Batch F1: 0.75
Epoch:  298        2 Batch loss: 0.084121 Batch F1: 0.8333333333333334
Epoch:  298        3 Batch loss: 0.060289 Batch F1: 0.2857142857142857
Epoch:  298        4 Batch loss: 0.062315 Batch F1: 0.4444444444444445
Epoch:  298        5 Batch loss: 0.102250 Batch F1: 0.631578947368421
Epoch:  298        6 Batch loss: 0.107992 Batch F1: 0.2857142857142857
Epoch:  298        7 Batch loss: 0.066610 Batch F1: 0.7499999999999999
Epoch:  298        8 Batch loss: 0.084537 Batch F1: 0.9090909090909091
Epoch:  298        9 Batch loss: 0.079549 Batch F1: 1.0
Epoch:  298       10 Batch loss: 0.072141 Batch F1: 0.9333333333333333
Epoch:  298       11 Batch loss: 0.058282 Batch F1: 1.0
Epoch:  298       12 Batch loss: 0.052147 Batch F1: 0.923076923076923
Train Avg Loss  298: 0.076827

Train Avg F1  298: 0.7288572051729947

Val Avg Loss  298: 0.067168

Val Avg F1  298:  0.7247389865036924

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 299
--------------------------------------------------------------
Epoch:  299        1 Batch loss: 0.065852 Batch F1: 0.4
Epoch:  299        2 Batch loss: 0.040073 Batch F1: 0.6666666666666666
Epoch:  299        3 Batch loss: 0.116814 Batch F1: 0.13333333333333333
Epoch:  299        4 Batch loss: 0.074831 Batch F1: 0.7777777777777778
Epoch:  299        5 Batch loss: 0.067276 Batch F1: 0.8571428571428571
Epoch:  299        6 Batch loss: 0.074667 Batch F1: 1.0
Epoch:  299        7 Batch loss: 0.049328 Batch F1: 0.8
Epoch:  299        8 Batch loss: 0.097187 Batch F1: 0.5333333333333333
Epoch:  299        9 Batch loss: 0.068207 Batch F1: 0.5
Epoch:  299       10 Batch loss: 0.128495 Batch F1: 0.2222222222222222
Epoch:  299       11 Batch loss: 0.077175 Batch F1: 0.5454545454545454
Epoch:  299       12 Batch loss: 0.072612 Batch F1: 0.8
Train Avg Loss  299: 0.077710

Train Avg F1  299: 0.602994227994228

Val Avg Loss  299: 0.070725

Val Avg F1  299:  0.9098972922502334

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 300
--------------------------------------------------------------
Epoch:  300        1 Batch loss: 0.100671 Batch F1: 0.9032258064516129
Epoch:  300        2 Batch loss: 0.068664 Batch F1: 0.8571428571428571
Epoch:  300        3 Batch loss: 0.063945 Batch F1: 0.8421052631578948
Epoch:  300        4 Batch loss: 0.061368 Batch F1: 0.33333333333333337
Epoch:  300        5 Batch loss: 0.095124 Batch F1: 0.5263157894736842
Epoch:  300        6 Batch loss: 0.075025 Batch F1: 0.5
Epoch:  300        7 Batch loss: 0.099633 Batch F1: 0.5
Epoch:  300        8 Batch loss: 0.063156 Batch F1: 0.5
Epoch:  300        9 Batch loss: 0.064896 Batch F1: 0.8571428571428571
Epoch:  300       10 Batch loss: 0.056341 Batch F1: 1.0
Epoch:  300       11 Batch loss: 0.065182 Batch F1: 0.9411764705882353
Epoch:  300       12 Batch loss: 0.052991 Batch F1: 0.4
Train Avg Loss  300: 0.072250

Train Avg F1  300: 0.6800368647742062

Val Avg Loss  300: 0.071791

Val Avg F1  300:  0.3629679144385027

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 301
--------------------------------------------------------------
Epoch:  301        1 Batch loss: 0.090074 Batch F1: 0.5
Epoch:  301        2 Batch loss: 0.051065 Batch F1: 0.8333333333333333
Epoch:  301        3 Batch loss: 0.073090 Batch F1: 0.6153846153846153
Epoch:  301        4 Batch loss: 0.045371 Batch F1: 0.6666666666666666
Epoch:  301        5 Batch loss: 0.083708 Batch F1: 0.625
Epoch:  301        6 Batch loss: 0.069240 Batch F1: 0.5714285714285715
Epoch:  301        7 Batch loss: 0.064123 Batch F1: 0.6666666666666666
Epoch:  301        8 Batch loss: 0.074840 Batch F1: 0.4615384615384615
Epoch:  301        9 Batch loss: 0.084885 Batch F1: 0.5
Epoch:  301       10 Batch loss: 0.060017 Batch F1: 0.9
Epoch:  301       11 Batch loss: 0.053461 Batch F1: 0.8571428571428571
Epoch:  301       12 Batch loss: 0.072791 Batch F1: 1.0
Train Avg Loss  301: 0.068555

Train Avg F1  301: 0.6830967643467644

Val Avg Loss  301: 0.066681

Val Avg F1  301:  0.8630769230769231

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 302
--------------------------------------------------------------
Epoch:  302        1 Batch loss: 0.072204 Batch F1: 0.7272727272727273
Epoch:  302        2 Batch loss: 0.056494 Batch F1: 1.0
Epoch:  302        3 Batch loss: 0.080450 Batch F1: 0.3076923076923077
Epoch:  302        4 Batch loss: 0.060111 Batch F1: 0.2857142857142857
Epoch:  302        5 Batch loss: 0.083770 Batch F1: 0.6666666666666666
Epoch:  302        6 Batch loss: 0.064314 Batch F1: 0.625
Epoch:  302        7 Batch loss: 0.068252 Batch F1: 0.888888888888889
Epoch:  302        8 Batch loss: 0.070802 Batch F1: 0.8571428571428571
Epoch:  302        9 Batch loss: 0.068804 Batch F1: 0.923076923076923
Epoch:  302       10 Batch loss: 0.079946 Batch F1: 0.6666666666666666
Epoch:  302       11 Batch loss: 0.066543 Batch F1: 0.888888888888889
Epoch:  302       12 Batch loss: 0.073413 Batch F1: 0.6666666666666666
Train Avg Loss  302: 0.070425

Train Avg F1  302: 0.7086397398897399

Val Avg Loss  302: 0.065376

Val Avg F1  302:  0.912907268170426

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 303
--------------------------------------------------------------
Epoch:  303        1 Batch loss: 0.062271 Batch F1: 1.0
Epoch:  303        2 Batch loss: 0.051983 Batch F1: 0.7499999999999999
Epoch:  303        3 Batch loss: 0.067587 Batch F1: 0.9473684210526316
Epoch:  303        4 Batch loss: 0.059449 Batch F1: 0.8
Epoch:  303        5 Batch loss: 0.069158 Batch F1: 0.8
Epoch:  303        6 Batch loss: 0.077092 Batch F1: 0.3636363636363636
Epoch:  303        7 Batch loss: 0.094335 Batch F1: 0.2666666666666667
Epoch:  303        8 Batch loss: 0.073757 Batch F1: 0.8571428571428571
Epoch:  303        9 Batch loss: 0.077245 Batch F1: 0.8695652173913043
Epoch:  303       10 Batch loss: 0.079496 Batch F1: 0.9473684210526316
Epoch:  303       11 Batch loss: 0.043518 Batch F1: 0.888888888888889
Epoch:  303       12 Batch loss: 0.076255 Batch F1: 0.6666666666666666
Train Avg Loss  303: 0.069345

Train Avg F1  303: 0.7631086252081675

Val Avg Loss  303: 0.066777

Val Avg F1  303:  0.6128342245989304

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 304
--------------------------------------------------------------
Epoch:  304        1 Batch loss: 0.041945 Batch F1: 0.7499999999999999
Epoch:  304        2 Batch loss: 0.089805 Batch F1: 0.5333333333333333
Epoch:  304        3 Batch loss: 0.080774 Batch F1: 0.6666666666666666
Epoch:  304        4 Batch loss: 0.079078 Batch F1: 0.42857142857142855
Epoch:  304        5 Batch loss: 0.065524 Batch F1: 0.8
Epoch:  304        6 Batch loss: 0.068596 Batch F1: 0.9090909090909091
Epoch:  304        7 Batch loss: 0.059535 Batch F1: 0.9333333333333333
Epoch:  304        8 Batch loss: 0.076531 Batch F1: 0.7368421052631579
Epoch:  304        9 Batch loss: 0.078299 Batch F1: 0.7058823529411764
Epoch:  304       10 Batch loss: 0.066023 Batch F1: 0.8571428571428571
Epoch:  304       11 Batch loss: 0.067044 Batch F1: 0.6666666666666666
Epoch:  304       12 Batch loss: 0.080695 Batch F1: 0.8421052631578948
Train Avg Loss  304: 0.071154

Train Avg F1  304: 0.7358029096806186

Val Avg Loss  304: 0.064225

Val Avg F1  304:  0.7226107226107226

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 305
--------------------------------------------------------------
Epoch:  305        1 Batch loss: 0.070832 Batch F1: 0.888888888888889
Epoch:  305        2 Batch loss: 0.061665 Batch F1: 0.6
Epoch:  305        3 Batch loss: 0.061124 Batch F1: 0.9473684210526316
Epoch:  305        4 Batch loss: 0.089903 Batch F1: 0.761904761904762
Epoch:  305        5 Batch loss: 0.062964 Batch F1: 1.0
Epoch:  305        6 Batch loss: 0.058105 Batch F1: 0.923076923076923
Epoch:  305        7 Batch loss: 0.078275 Batch F1: 0.7999999999999999
Epoch:  305        8 Batch loss: 0.079014 Batch F1: 0.6666666666666666
Epoch:  305        9 Batch loss: 0.057557 Batch F1: 0.6
Epoch:  305       10 Batch loss: 0.079305 Batch F1: 0.72
Epoch:  305       11 Batch loss: 0.049036 Batch F1: 0.6666666666666666
Epoch:  305       12 Batch loss: 0.069798 Batch F1: 0.9090909090909091
Train Avg Loss  305: 0.068132

Train Avg F1  305: 0.7903052697789539

Val Avg Loss  305: 0.065098

Val Avg F1  305:  0.6200854700854701

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 306
--------------------------------------------------------------
Epoch:  306        1 Batch loss: 0.092066 Batch F1: 0.7692307692307693
Epoch:  306        2 Batch loss: 0.092007 Batch F1: 0.8333333333333333
Epoch:  306        3 Batch loss: 0.048201 Batch F1: 1.0
Epoch:  306        4 Batch loss: 0.063729 Batch F1: 0.9411764705882353
Epoch:  306        5 Batch loss: 0.068925 Batch F1: 0.9473684210526316
Epoch:  306        6 Batch loss: 0.072607 Batch F1: 0.923076923076923
Epoch:  306        7 Batch loss: 0.063072 Batch F1: 0.7142857142857143
Epoch:  306        8 Batch loss: 0.059732 Batch F1: 0.7272727272727273
Epoch:  306        9 Batch loss: 0.063242 Batch F1: 0.0
Epoch:  306       10 Batch loss: 0.104735 Batch F1: 0.0
Epoch:  306       11 Batch loss: 0.055883 Batch F1: 0.6666666666666666
Epoch:  306       12 Batch loss: 0.060157 Batch F1: 1.0
Train Avg Loss  306: 0.070363

Train Avg F1  306: 0.7102009187922501

Val Avg Loss  306: 0.065282

Val Avg F1  306:  0.9201754385964913

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 307
--------------------------------------------------------------
Epoch:  307        1 Batch loss: 0.070265 Batch F1: 0.9333333333333333
Epoch:  307        2 Batch loss: 0.063915 Batch F1: 0.8333333333333333
Epoch:  307        3 Batch loss: 0.059353 Batch F1: 0.9473684210526316
Epoch:  307        4 Batch loss: 0.064772 Batch F1: 0.7499999999999999
Epoch:  307        5 Batch loss: 0.104082 Batch F1: 0.7142857142857143
Epoch:  307        6 Batch loss: 0.042563 Batch F1: 0.888888888888889
Epoch:  307        7 Batch loss: 0.061492 Batch F1: 0.9473684210526316
Epoch:  307        8 Batch loss: 0.089703 Batch F1: 0.6153846153846153
Epoch:  307        9 Batch loss: 0.061941 Batch F1: 0.7692307692307693
Epoch:  307       10 Batch loss: 0.068841 Batch F1: 0.6666666666666666
Epoch:  307       11 Batch loss: 0.085887 Batch F1: 0.3636363636363636
Epoch:  307       12 Batch loss: 0.072690 Batch F1: 0.4444444444444445
Train Avg Loss  307: 0.070459

Train Avg F1  307: 0.7394950809424494

Val Avg Loss  307: 0.068938

Val Avg F1  307:  0.5684523809523809

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 308
--------------------------------------------------------------
Epoch:  308        1 Batch loss: 0.069583 Batch F1: 0.6153846153846153
Epoch:  308        2 Batch loss: 0.083295 Batch F1: 0.625
Epoch:  308        3 Batch loss: 0.070615 Batch F1: 0.8571428571428571
Epoch:  308        4 Batch loss: 0.069069 Batch F1: 0.8571428571428571
Epoch:  308        5 Batch loss: 0.083545 Batch F1: 0.8750000000000001
Epoch:  308        6 Batch loss: 0.065329 Batch F1: 1.0
Epoch:  308        7 Batch loss: 0.083600 Batch F1: 0.7999999999999999
Epoch:  308        8 Batch loss: 0.052641 Batch F1: 0.8333333333333333
Epoch:  308        9 Batch loss: 0.089831 Batch F1: 0.6666666666666666
Epoch:  308       10 Batch loss: 0.057029 Batch F1: 0.8
Epoch:  308       11 Batch loss: 0.063180 Batch F1: 0.6666666666666666
Epoch:  308       12 Batch loss: 0.035981 Batch F1: 0.8
Train Avg Loss  308: 0.068642

Train Avg F1  308: 0.783028083028083

Val Avg Loss  308: 0.065411

Val Avg F1  308:  0.5859943977591037

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 309
--------------------------------------------------------------
Epoch:  309        1 Batch loss: 0.099696 Batch F1: 0.6956521739130436
Epoch:  309        2 Batch loss: 0.050655 Batch F1: 0.8
Epoch:  309        3 Batch loss: 0.067700 Batch F1: 0.8333333333333333
Epoch:  309        4 Batch loss: 0.054942 Batch F1: 0.7272727272727273
Epoch:  309        5 Batch loss: 0.062274 Batch F1: 0.7142857142857143
Epoch:  309        6 Batch loss: 0.051531 Batch F1: 0.2857142857142857
Epoch:  309        7 Batch loss: 0.078452 Batch F1: 0.4615384615384615
Epoch:  309        8 Batch loss: 0.083209 Batch F1: 0.5333333333333333
Epoch:  309        9 Batch loss: 0.055900 Batch F1: 0.6666666666666666
Epoch:  309       10 Batch loss: 0.071826 Batch F1: 0.9600000000000001
Epoch:  309       11 Batch loss: 0.044189 Batch F1: 1.0
Epoch:  309       12 Batch loss: 0.103648 Batch F1: 0.7499999999999999
Train Avg Loss  309: 0.068669

Train Avg F1  309: 0.7023163913381305

Val Avg Loss  309: 0.064767

Val Avg F1  309:  0.8792960662525882

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 310
--------------------------------------------------------------
Epoch:  310        1 Batch loss: 0.072468 Batch F1: 0.8421052631578948
Epoch:  310        2 Batch loss: 0.067191 Batch F1: 0.9473684210526316
Epoch:  310        3 Batch loss: 0.054974 Batch F1: 1.0
Epoch:  310        4 Batch loss: 0.068968 Batch F1: 0.8571428571428572
Epoch:  310        5 Batch loss: 0.066915 Batch F1: 0.9090909090909091
Epoch:  310        6 Batch loss: 0.092122 Batch F1: 0.7777777777777778
Epoch:  310        7 Batch loss: 0.076483 Batch F1: 0.8
Epoch:  310        8 Batch loss: 0.054021 Batch F1: 1.0
Epoch:  310        9 Batch loss: 0.063711 Batch F1: 0.8750000000000001
Epoch:  310       10 Batch loss: 0.069403 Batch F1: 0.6666666666666666
Epoch:  310       11 Batch loss: 0.050545 Batch F1: 0.7499999999999999
Epoch:  310       12 Batch loss: 0.082272 Batch F1: 0.4
Train Avg Loss  310: 0.068256

Train Avg F1  310: 0.8187626579073948

Val Avg Loss  310: 0.066112

Val Avg F1  310:  0.5489379084967321

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 311
--------------------------------------------------------------
Epoch:  311        1 Batch loss: 0.072087 Batch F1: 0.5714285714285715
Epoch:  311        2 Batch loss: 0.068818 Batch F1: 0.8
Epoch:  311        3 Batch loss: 0.070498 Batch F1: 0.8
Epoch:  311        4 Batch loss: 0.064343 Batch F1: 0.8750000000000001
Epoch:  311        5 Batch loss: 0.084642 Batch F1: 0.9090909090909091
Epoch:  311        6 Batch loss: 0.066602 Batch F1: 0.9411764705882353
Epoch:  311        7 Batch loss: 0.080735 Batch F1: 0.9473684210526316
Epoch:  311        8 Batch loss: 0.070151 Batch F1: 0.7142857142857143
Epoch:  311        9 Batch loss: 0.045789 Batch F1: 1.0
Epoch:  311       10 Batch loss: 0.069532 Batch F1: 0.4
Epoch:  311       11 Batch loss: 0.070492 Batch F1: 0.4
Epoch:  311       12 Batch loss: 0.067979 Batch F1: 0.0
Train Avg Loss  311: 0.069306

Train Avg F1  311: 0.6965291738705052

Val Avg Loss  311: 0.071129

Val Avg F1  311:  0.5571548017200192

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 312
--------------------------------------------------------------
Epoch:  312        1 Batch loss: 0.083173 Batch F1: 0.5882352941176471
Epoch:  312        2 Batch loss: 0.084566 Batch F1: 0.9411764705882353
Epoch:  312        3 Batch loss: 0.082234 Batch F1: 0.8
Epoch:  312        4 Batch loss: 0.088222 Batch F1: 0.8181818181818181
Epoch:  312        5 Batch loss: 0.046685 Batch F1: 1.0
Epoch:  312        6 Batch loss: 0.068925 Batch F1: 0.8421052631578948
Epoch:  312        7 Batch loss: 0.069520 Batch F1: 0.8235294117647058
Epoch:  312        8 Batch loss: 0.080910 Batch F1: 0.7499999999999999
Epoch:  312        9 Batch loss: 0.066464 Batch F1: 0.8750000000000001
Epoch:  312       10 Batch loss: 0.045662 Batch F1: 1.0
Epoch:  312       11 Batch loss: 0.063047 Batch F1: 0.5
Epoch:  312       12 Batch loss: 0.071330 Batch F1: 0.2857142857142857
Train Avg Loss  312: 0.070895

Train Avg F1  312: 0.768661878627049

Val Avg Loss  312: 0.071885

Val Avg F1  312:  0.3

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 313
--------------------------------------------------------------
Epoch:  313        1 Batch loss: 0.074401 Batch F1: 0.2222222222222222
Epoch:  313        2 Batch loss: 0.061894 Batch F1: 0.5
Epoch:  313        3 Batch loss: 0.070134 Batch F1: 0.7142857142857143
Epoch:  313        4 Batch loss: 0.072966 Batch F1: 0.7499999999999999
Epoch:  313        5 Batch loss: 0.056062 Batch F1: 1.0
Epoch:  313        6 Batch loss: 0.088198 Batch F1: 0.88
Epoch:  313        7 Batch loss: 0.059029 Batch F1: 1.0
Epoch:  313        8 Batch loss: 0.075379 Batch F1: 0.8
Epoch:  313        9 Batch loss: 0.076478 Batch F1: 0.6666666666666666
Epoch:  313       10 Batch loss: 0.062946 Batch F1: 0.7999999999999999
Epoch:  313       11 Batch loss: 0.067575 Batch F1: 0.6153846153846153
Epoch:  313       12 Batch loss: 0.055515 Batch F1: 0.5714285714285715
Train Avg Loss  313: 0.068381

Train Avg F1  313: 0.7099989824989824

Val Avg Loss  313: 0.068420

Val Avg F1  313:  0.5804924242424242

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 314
--------------------------------------------------------------
Epoch:  314        1 Batch loss: 0.064399 Batch F1: 0.25
Epoch:  314        2 Batch loss: 0.035396 Batch F1: 0.6666666666666666
Epoch:  314        3 Batch loss: 0.096167 Batch F1: 0.4
Epoch:  314        4 Batch loss: 0.066534 Batch F1: 0.7777777777777778
Epoch:  314        5 Batch loss: 0.065963 Batch F1: 0.7692307692307693
Epoch:  314        6 Batch loss: 0.068486 Batch F1: 0.8
Epoch:  314        7 Batch loss: 0.065156 Batch F1: 1.0
Epoch:  314        8 Batch loss: 0.073194 Batch F1: 0.7272727272727273
Epoch:  314        9 Batch loss: 0.061257 Batch F1: 0.9090909090909091
Epoch:  314       10 Batch loss: 0.077534 Batch F1: 0.7368421052631579
Epoch:  314       11 Batch loss: 0.083602 Batch F1: 0.5714285714285715
Epoch:  314       12 Batch loss: 0.099650 Batch F1: 0.7000000000000001
Train Avg Loss  314: 0.071445

Train Avg F1  314: 0.6923591272275482

Val Avg Loss  314: 0.065279

Val Avg F1  314:  0.9507703081232493

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 315
--------------------------------------------------------------
Epoch:  315        1 Batch loss: 0.062742 Batch F1: 1.0
Epoch:  315        2 Batch loss: 0.067616 Batch F1: 0.9523809523809523
Epoch:  315        3 Batch loss: 0.065786 Batch F1: 1.0
Epoch:  315        4 Batch loss: 0.074728 Batch F1: 0.5714285714285715
Epoch:  315        5 Batch loss: 0.073924 Batch F1: 0.6153846153846153
Epoch:  315        6 Batch loss: 0.068357 Batch F1: 0.8235294117647058
Epoch:  315        7 Batch loss: 0.085973 Batch F1: 0.5
Epoch:  315        8 Batch loss: 0.091651 Batch F1: 0.7368421052631579
Epoch:  315        9 Batch loss: 0.059921 Batch F1: 0.888888888888889
Epoch:  315       10 Batch loss: 0.046179 Batch F1: 1.0
Epoch:  315       11 Batch loss: 0.075746 Batch F1: 0.7368421052631579
Epoch:  315       12 Batch loss: 0.060239 Batch F1: 1.0
Train Avg Loss  315: 0.069405

Train Avg F1  315: 0.8187747208645041

Val Avg Loss  315: 0.063230

Val Avg F1  315:  0.7694444444444444

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 316
--------------------------------------------------------------
Epoch:  316        1 Batch loss: 0.083151 Batch F1: 0.7368421052631579
Epoch:  316        2 Batch loss: 0.078368 Batch F1: 0.7058823529411764
Epoch:  316        3 Batch loss: 0.046941 Batch F1: 1.0
Epoch:  316        4 Batch loss: 0.061097 Batch F1: 0.6
Epoch:  316        5 Batch loss: 0.067800 Batch F1: 0.4615384615384615
Epoch:  316        6 Batch loss: 0.088296 Batch F1: 0.6956521739130436
Epoch:  316        7 Batch loss: 0.062276 Batch F1: 0.6666666666666666
Epoch:  316        8 Batch loss: 0.058927 Batch F1: 0.8333333333333333
Epoch:  316        9 Batch loss: 0.087639 Batch F1: 0.5
Epoch:  316       10 Batch loss: 0.066112 Batch F1: 0.9
Epoch:  316       11 Batch loss: 0.064259 Batch F1: 0.823529411764706
Epoch:  316       12 Batch loss: 0.037879 Batch F1: 1.0
Train Avg Loss  316: 0.066895

Train Avg F1  316: 0.743620375451712

Val Avg Loss  316: 0.065259

Val Avg F1  316:  0.5612745098039216

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 317
--------------------------------------------------------------
Epoch:  317        1 Batch loss: 0.068959 Batch F1: 0.7000000000000001
Epoch:  317        2 Batch loss: 0.061032 Batch F1: 0.5454545454545454
Epoch:  317        3 Batch loss: 0.074134 Batch F1: 0.5
Epoch:  317        4 Batch loss: 0.056071 Batch F1: 1.0
Epoch:  317        5 Batch loss: 0.056954 Batch F1: 0.7692307692307693
Epoch:  317        6 Batch loss: 0.067186 Batch F1: 0.888888888888889
Epoch:  317        7 Batch loss: 0.065449 Batch F1: 0.7692307692307693
Epoch:  317        8 Batch loss: 0.096810 Batch F1: 0.761904761904762
Epoch:  317        9 Batch loss: 0.063600 Batch F1: 1.0
Epoch:  317       10 Batch loss: 0.068067 Batch F1: 0.8
Epoch:  317       11 Batch loss: 0.068707 Batch F1: 0.7499999999999999
Epoch:  317       12 Batch loss: 0.063654 Batch F1: 0.9090909090909091
Train Avg Loss  317: 0.067552

Train Avg F1  317: 0.7828167203167201

Val Avg Loss  317: 0.064278

Val Avg F1  317:  0.8432449903038138

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 318
--------------------------------------------------------------
Epoch:  318        1 Batch loss: 0.061003 Batch F1: 0.7272727272727273
Epoch:  318        2 Batch loss: 0.073170 Batch F1: 0.5714285714285715
Epoch:  318        3 Batch loss: 0.069470 Batch F1: 0.6666666666666666
Epoch:  318        4 Batch loss: 0.099979 Batch F1: 0.5882352941176471
Epoch:  318        5 Batch loss: 0.057777 Batch F1: 1.0
Epoch:  318        6 Batch loss: 0.079230 Batch F1: 0.4444444444444445
Epoch:  318        7 Batch loss: 0.094192 Batch F1: 0.2857142857142857
Epoch:  318        8 Batch loss: 0.054938 Batch F1: 0.9411764705882353
Epoch:  318        9 Batch loss: 0.065822 Batch F1: 0.6153846153846153
Epoch:  318       10 Batch loss: 0.073965 Batch F1: 0.4615384615384615
Epoch:  318       11 Batch loss: 0.062540 Batch F1: 0.7499999999999999
Epoch:  318       12 Batch loss: 0.061446 Batch F1: 1.0
Train Avg Loss  318: 0.071128

Train Avg F1  318: 0.670988461429638

Val Avg Loss  318: 0.064535

Val Avg F1  318:  0.7181818181818183

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 319
--------------------------------------------------------------
Epoch:  319        1 Batch loss: 0.064405 Batch F1: 0.6
Epoch:  319        2 Batch loss: 0.069953 Batch F1: 0.8
Epoch:  319        3 Batch loss: 0.043594 Batch F1: 0.6666666666666666
Epoch:  319        4 Batch loss: 0.071396 Batch F1: 0.7058823529411764
Epoch:  319        5 Batch loss: 0.070784 Batch F1: 0.5714285714285715
Epoch:  319        6 Batch loss: 0.066850 Batch F1: 0.6
Epoch:  319        7 Batch loss: 0.074408 Batch F1: 0.8235294117647058
Epoch:  319        8 Batch loss: 0.064461 Batch F1: 1.0
Epoch:  319        9 Batch loss: 0.083785 Batch F1: 0.8
Epoch:  319       10 Batch loss: 0.087483 Batch F1: 0.625
Epoch:  319       11 Batch loss: 0.067614 Batch F1: 0.8
Epoch:  319       12 Batch loss: 0.060386 Batch F1: 0.923076923076923
Train Avg Loss  319: 0.068760

Train Avg F1  319: 0.7429653271565035

Val Avg Loss  319: 0.064155

Val Avg F1  319:  0.7308441558441559

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 320
--------------------------------------------------------------
Epoch:  320        1 Batch loss: 0.065685 Batch F1: 0.7272727272727273
Epoch:  320        2 Batch loss: 0.062164 Batch F1: 0.6
Epoch:  320        3 Batch loss: 0.092241 Batch F1: 0.6666666666666666
Epoch:  320        4 Batch loss: 0.108455 Batch F1: 0.6956521739130436
Epoch:  320        5 Batch loss: 0.063342 Batch F1: 0.9473684210526316
Epoch:  320        6 Batch loss: 0.072730 Batch F1: 1.0
Epoch:  320        7 Batch loss: 0.078459 Batch F1: 0.9166666666666666
Epoch:  320        8 Batch loss: 0.060131 Batch F1: 0.6666666666666666
Epoch:  320        9 Batch loss: 0.063248 Batch F1: 0.8
Epoch:  320       10 Batch loss: 0.052748 Batch F1: 0.5
Epoch:  320       11 Batch loss: 0.051941 Batch F1: 0.5
Epoch:  320       12 Batch loss: 0.059755 Batch F1: 0.2857142857142857
Train Avg Loss  320: 0.069242

Train Avg F1  320: 0.692167300662724

Val Avg Loss  320: 0.068730

Val Avg F1  320:  0.8055555555555555

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 321
--------------------------------------------------------------
Epoch:  321        1 Batch loss: 0.061687 Batch F1: 0.6666666666666666
Epoch:  321        2 Batch loss: 0.074943 Batch F1: 0.9523809523809523
Epoch:  321        3 Batch loss: 0.065651 Batch F1: 0.8571428571428571
Epoch:  321        4 Batch loss: 0.082418 Batch F1: 0.7058823529411764
Epoch:  321        5 Batch loss: 0.073111 Batch F1: 0.5
Epoch:  321        6 Batch loss: 0.051864 Batch F1: 0.923076923076923
Epoch:  321        7 Batch loss: 0.082561 Batch F1: 0.6666666666666666
Epoch:  321        8 Batch loss: 0.059638 Batch F1: 0.9090909090909091
Epoch:  321        9 Batch loss: 0.046244 Batch F1: 0.7272727272727273
Epoch:  321       10 Batch loss: 0.065752 Batch F1: 0.6666666666666666
Epoch:  321       11 Batch loss: 0.086068 Batch F1: 0.33333333333333337
Epoch:  321       12 Batch loss: 0.096246 Batch F1: 0.3076923076923077
Train Avg Loss  321: 0.070515

Train Avg F1  321: 0.6846560302442657

Val Avg Loss  321: 0.063087

Val Avg F1  321:  0.8163156288156288

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 322
--------------------------------------------------------------
Epoch:  322        1 Batch loss: 0.083111 Batch F1: 0.8
Epoch:  322        2 Batch loss: 0.080457 Batch F1: 0.9090909090909091
Epoch:  322        3 Batch loss: 0.065771 Batch F1: 0.9523809523809523
Epoch:  322        4 Batch loss: 0.085412 Batch F1: 0.888888888888889
Epoch:  322        5 Batch loss: 0.054601 Batch F1: 1.0
Epoch:  322        6 Batch loss: 0.067526 Batch F1: 1.0
Epoch:  322        7 Batch loss: 0.061069 Batch F1: 0.923076923076923
Epoch:  322        8 Batch loss: 0.094556 Batch F1: 0.761904761904762
Epoch:  322        9 Batch loss: 0.080237 Batch F1: 0.7499999999999999
Epoch:  322       10 Batch loss: 0.050023 Batch F1: 1.0
Epoch:  322       11 Batch loss: 0.043108 Batch F1: 1.0
Epoch:  322       12 Batch loss: 0.059792 Batch F1: 0.6666666666666666
Train Avg Loss  322: 0.068805

Train Avg F1  322: 0.8876674251674251

Val Avg Loss  322: 0.066930

Val Avg F1  322:  0.6255793226381461

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 323
--------------------------------------------------------------
Epoch:  323        1 Batch loss: 0.096139 Batch F1: 0.47058823529411764
Epoch:  323        2 Batch loss: 0.036549 Batch F1: 0.8571428571428571
Epoch:  323        3 Batch loss: 0.057072 Batch F1: 0.2857142857142857
Epoch:  323        4 Batch loss: 0.057773 Batch F1: 0.8
Epoch:  323        5 Batch loss: 0.100554 Batch F1: 0.5263157894736842
Epoch:  323        6 Batch loss: 0.062528 Batch F1: 0.9600000000000001
Epoch:  323        7 Batch loss: 0.087401 Batch F1: 0.7999999999999999
Epoch:  323        8 Batch loss: 0.075419 Batch F1: 0.9166666666666666
Epoch:  323        9 Batch loss: 0.068520 Batch F1: 0.6
Epoch:  323       10 Batch loss: 0.061474 Batch F1: 0.5
Epoch:  323       11 Batch loss: 0.075677 Batch F1: 0.5454545454545454
Epoch:  323       12 Batch loss: 0.095271 Batch F1: 0.0
Train Avg Loss  323: 0.072865

Train Avg F1  323: 0.6051568649788464

Val Avg Loss  323: 0.074060

Val Avg F1  323:  0.5811965811965812

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 324
--------------------------------------------------------------
Epoch:  324        1 Batch loss: 0.057513 Batch F1: 0.6
Epoch:  324        2 Batch loss: 0.050857 Batch F1: 0.5714285714285715
Epoch:  324        3 Batch loss: 0.074143 Batch F1: 0.5333333333333333
Epoch:  324        4 Batch loss: 0.071267 Batch F1: 0.6153846153846153
Epoch:  324        5 Batch loss: 0.074620 Batch F1: 0.9
Epoch:  324        6 Batch loss: 0.087734 Batch F1: 0.9473684210526316
Epoch:  324        7 Batch loss: 0.057611 Batch F1: 1.0
Epoch:  324        8 Batch loss: 0.070828 Batch F1: 0.8571428571428571
Epoch:  324        9 Batch loss: 0.090712 Batch F1: 0.4210526315789474
Epoch:  324       10 Batch loss: 0.089948 Batch F1: 0.7777777777777777
Epoch:  324       11 Batch loss: 0.087229 Batch F1: 0.8888888888888888
Epoch:  324       12 Batch loss: 0.067941 Batch F1: 0.7692307692307692
Train Avg Loss  324: 0.073367

Train Avg F1  324: 0.7401339888181994

Val Avg Loss  324: 0.065798

Val Avg F1  324:  0.91875

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 325
--------------------------------------------------------------
Epoch:  325        1 Batch loss: 0.073714 Batch F1: 0.8235294117647058
Epoch:  325        2 Batch loss: 0.059971 Batch F1: 0.5714285714285715
Epoch:  325        3 Batch loss: 0.067776 Batch F1: 0.25
Epoch:  325        4 Batch loss: 0.085370 Batch F1: 0.0
Epoch:  325        5 Batch loss: 0.088555 Batch F1: 0.5
Epoch:  325        6 Batch loss: 0.064892 Batch F1: 0.5454545454545454
Epoch:  325        7 Batch loss: 0.098906 Batch F1: 0.7826086956521738
Epoch:  325        8 Batch loss: 0.060205 Batch F1: 0.8571428571428571
Epoch:  325        9 Batch loss: 0.086455 Batch F1: 0.5882352941176471
Epoch:  325       10 Batch loss: 0.068676 Batch F1: 0.25
Epoch:  325       11 Batch loss: 0.096642 Batch F1: 0.761904761904762
Epoch:  325       12 Batch loss: 0.066054 Batch F1: 1.0
Train Avg Loss  325: 0.076435

Train Avg F1  325: 0.5775253447887718

Val Avg Loss  325: 0.066883

Val Avg F1  325:  0.9308823529411765

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 326
--------------------------------------------------------------
Epoch:  326        1 Batch loss: 0.069927 Batch F1: 0.8750000000000001
Epoch:  326        2 Batch loss: 0.097384 Batch F1: 0.8181818181818181
Epoch:  326        3 Batch loss: 0.062252 Batch F1: 0.4444444444444445
Epoch:  326        4 Batch loss: 0.086181 Batch F1: 0.6666666666666666
Epoch:  326        5 Batch loss: 0.074594 Batch F1: 0.7499999999999999
Epoch:  326        6 Batch loss: 0.063536 Batch F1: 0.8571428571428571
Epoch:  326        7 Batch loss: 0.062879 Batch F1: 0.9523809523809523
Epoch:  326        8 Batch loss: 0.068227 Batch F1: 1.0
Epoch:  326        9 Batch loss: 0.071666 Batch F1: 0.6666666666666666
Epoch:  326       10 Batch loss: 0.047391 Batch F1: 0.0
Epoch:  326       11 Batch loss: 0.082951 Batch F1: 0.0
Epoch:  326       12 Batch loss: 0.094843 Batch F1: 0.625
Train Avg Loss  326: 0.073486

Train Avg F1  326: 0.6379569504569506

Val Avg Loss  326: 0.072775

Val Avg F1  326:  0.9279054536794475

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 327
--------------------------------------------------------------
Epoch:  327        1 Batch loss: 0.087801 Batch F1: 0.9285714285714286
Epoch:  327        2 Batch loss: 0.065856 Batch F1: 1.0
Epoch:  327        3 Batch loss: 0.068969 Batch F1: 0.8333333333333333
Epoch:  327        4 Batch loss: 0.055132 Batch F1: 0.7142857142857143
Epoch:  327        5 Batch loss: 0.084067 Batch F1: 0.6666666666666666
Epoch:  327        6 Batch loss: 0.066368 Batch F1: 0.5
Epoch:  327        7 Batch loss: 0.054603 Batch F1: 0.6666666666666666
Epoch:  327        8 Batch loss: 0.108267 Batch F1: 0.35294117647058826
Epoch:  327        9 Batch loss: 0.080616 Batch F1: 0.5
Epoch:  327       10 Batch loss: 0.070556 Batch F1: 1.0
Epoch:  327       11 Batch loss: 0.061534 Batch F1: 0.8
Epoch:  327       12 Batch loss: 0.070122 Batch F1: 0.8571428571428571
Train Avg Loss  327: 0.072824

Train Avg F1  327: 0.734967320261438

Val Avg Loss  327: 0.065356

Val Avg F1  327:  0.6085218702865762

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 328
--------------------------------------------------------------
Epoch:  328        1 Batch loss: 0.074795 Batch F1: 0.5882352941176471
Epoch:  328        2 Batch loss: 0.069589 Batch F1: 0.5333333333333333
Epoch:  328        3 Batch loss: 0.052775 Batch F1: 1.0
Epoch:  328        4 Batch loss: 0.055265 Batch F1: 0.6666666666666666
Epoch:  328        5 Batch loss: 0.093793 Batch F1: 0.6666666666666666
Epoch:  328        6 Batch loss: 0.077970 Batch F1: 1.0
Epoch:  328        7 Batch loss: 0.068014 Batch F1: 1.0
Epoch:  328        8 Batch loss: 0.069328 Batch F1: 0.8750000000000001
Epoch:  328        9 Batch loss: 0.054639 Batch F1: 0.5714285714285715
Epoch:  328       10 Batch loss: 0.088448 Batch F1: 0.5
Epoch:  328       11 Batch loss: 0.060885 Batch F1: 0.6666666666666666
Epoch:  328       12 Batch loss: 0.078603 Batch F1: 0.6666666666666666
Train Avg Loss  328: 0.070342

Train Avg F1  328: 0.7278886554621847

Val Avg Loss  328: 0.065710

Val Avg F1  328:  0.6152777777777778

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 329
--------------------------------------------------------------
Epoch:  329        1 Batch loss: 0.055409 Batch F1: 0.7142857142857143
Epoch:  329        2 Batch loss: 0.083809 Batch F1: 0.4
Epoch:  329        3 Batch loss: 0.091245 Batch F1: 0.823529411764706
Epoch:  329        4 Batch loss: 0.066061 Batch F1: 0.8750000000000001
Epoch:  329        5 Batch loss: 0.070446 Batch F1: 0.9333333333333333
Epoch:  329        6 Batch loss: 0.046954 Batch F1: 1.0
Epoch:  329        7 Batch loss: 0.081364 Batch F1: 0.5333333333333333
Epoch:  329        8 Batch loss: 0.073090 Batch F1: 0.7777777777777778
Epoch:  329        9 Batch loss: 0.066437 Batch F1: 0.5
Epoch:  329       10 Batch loss: 0.053814 Batch F1: 0.6
Epoch:  329       11 Batch loss: 0.057932 Batch F1: 0.6666666666666666
Epoch:  329       12 Batch loss: 0.093771 Batch F1: 0.5
Train Avg Loss  329: 0.070028

Train Avg F1  329: 0.693660519763461

Val Avg Loss  329: 0.064652

Val Avg F1  329:  0.8937611408199644

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 330
--------------------------------------------------------------
Epoch:  330        1 Batch loss: 0.074055 Batch F1: 0.8421052631578948
Epoch:  330        2 Batch loss: 0.059247 Batch F1: 1.0
Epoch:  330        3 Batch loss: 0.064302 Batch F1: 0.9333333333333333
Epoch:  330        4 Batch loss: 0.076973 Batch F1: 0.9090909090909091
Epoch:  330        5 Batch loss: 0.072679 Batch F1: 0.888888888888889
Epoch:  330        6 Batch loss: 0.077587 Batch F1: 0.9523809523809523
Epoch:  330        7 Batch loss: 0.055812 Batch F1: 1.0
Epoch:  330        8 Batch loss: 0.064192 Batch F1: 0.7272727272727273
Epoch:  330        9 Batch loss: 0.077006 Batch F1: 0.8421052631578948
Epoch:  330       10 Batch loss: 0.061583 Batch F1: 0.2857142857142857
Epoch:  330       11 Batch loss: 0.077349 Batch F1: 0.8
Epoch:  330       12 Batch loss: 0.051671 Batch F1: 1.0
Train Avg Loss  330: 0.067705

Train Avg F1  330: 0.8484076352497407

Val Avg Loss  330: 0.064357

Val Avg F1  330:  0.6923076923076923

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 331
--------------------------------------------------------------
Epoch:  331        1 Batch loss: 0.065141 Batch F1: 0.7142857142857143
Epoch:  331        2 Batch loss: 0.067296 Batch F1: 0.5
Epoch:  331        3 Batch loss: 0.082438 Batch F1: 0.5
Epoch:  331        4 Batch loss: 0.041903 Batch F1: 0.6666666666666666
Epoch:  331        5 Batch loss: 0.045442 Batch F1: 0.6666666666666666
Epoch:  331        6 Batch loss: 0.078868 Batch F1: 0.6666666666666665
Epoch:  331        7 Batch loss: 0.077082 Batch F1: 0.7777777777777777
Epoch:  331        8 Batch loss: 0.058633 Batch F1: 0.9333333333333333
Epoch:  331        9 Batch loss: 0.071026 Batch F1: 0.625
Epoch:  331       10 Batch loss: 0.083720 Batch F1: 0.7368421052631579
Epoch:  331       11 Batch loss: 0.074342 Batch F1: 0.3636363636363636
Epoch:  331       12 Batch loss: 0.069311 Batch F1: 0.9473684210526316
Train Avg Loss  331: 0.067933

Train Avg F1  331: 0.6748536429457482

Val Avg Loss  331: 0.063372

Val Avg F1  331:  0.8235119047619048

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 332
--------------------------------------------------------------
Epoch:  332        1 Batch loss: 0.066459 Batch F1: 0.7777777777777778
Epoch:  332        2 Batch loss: 0.078160 Batch F1: 0.8750000000000001
Epoch:  332        3 Batch loss: 0.066149 Batch F1: 0.8235294117647058
Epoch:  332        4 Batch loss: 0.054791 Batch F1: 1.0
Epoch:  332        5 Batch loss: 0.065061 Batch F1: 0.888888888888889
Epoch:  332        6 Batch loss: 0.088492 Batch F1: 0.6666666666666666
Epoch:  332        7 Batch loss: 0.072806 Batch F1: 0.9
Epoch:  332        8 Batch loss: 0.073833 Batch F1: 0.8235294117647058
Epoch:  332        9 Batch loss: 0.073635 Batch F1: 0.5
Epoch:  332       10 Batch loss: 0.050109 Batch F1: 0.9090909090909091
Epoch:  332       11 Batch loss: 0.064850 Batch F1: 0.9411764705882353
Epoch:  332       12 Batch loss: 0.049695 Batch F1: 0.33333333333333337
Train Avg Loss  332: 0.067003

Train Avg F1  332: 0.7865827391562686

Val Avg Loss  332: 0.065234

Val Avg F1  332:  0.5980616605616605

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 333
--------------------------------------------------------------
Epoch:  333        1 Batch loss: 0.074082 Batch F1: 0.19999999999999998
Epoch:  333        2 Batch loss: 0.079291 Batch F1: 0.4615384615384615
Epoch:  333        3 Batch loss: 0.083417 Batch F1: 0.5
Epoch:  333        4 Batch loss: 0.055492 Batch F1: 0.875
Epoch:  333        5 Batch loss: 0.069398 Batch F1: 0.8333333333333333
Epoch:  333        6 Batch loss: 0.054006 Batch F1: 1.0
Epoch:  333        7 Batch loss: 0.061160 Batch F1: 0.8750000000000001
Epoch:  333        8 Batch loss: 0.048128 Batch F1: 0.5
Epoch:  333        9 Batch loss: 0.132232 Batch F1: 0.5
Epoch:  333       10 Batch loss: 0.068925 Batch F1: 0.4
Epoch:  333       11 Batch loss: 0.053262 Batch F1: 1.0
Epoch:  333       12 Batch loss: 0.072789 Batch F1: 0.9523809523809523
Train Avg Loss  333: 0.071015

Train Avg F1  333: 0.6747710622710623

Val Avg Loss  333: 0.068759

Val Avg F1  333:  0.9122023809523809

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 334
--------------------------------------------------------------
Epoch:  334        1 Batch loss: 0.052568 Batch F1: 0.923076923076923
Epoch:  334        2 Batch loss: 0.066015 Batch F1: 0.6
Epoch:  334        3 Batch loss: 0.057121 Batch F1: 0.6666666666666666
Epoch:  334        4 Batch loss: 0.038525 Batch F1: 0.4
Epoch:  334        5 Batch loss: 0.062594 Batch F1: 0.3636363636363636
Epoch:  334        6 Batch loss: 0.117640 Batch F1: 0.6
Epoch:  334        7 Batch loss: 0.093769 Batch F1: 0.9166666666666666
Epoch:  334        8 Batch loss: 0.078150 Batch F1: 0.9090909090909091
Epoch:  334        9 Batch loss: 0.079224 Batch F1: 0.9230769230769231
Epoch:  334       10 Batch loss: 0.072999 Batch F1: 0.9411764705882353
Epoch:  334       11 Batch loss: 0.072834 Batch F1: 0.8
Epoch:  334       12 Batch loss: 0.093163 Batch F1: 0.6153846153846153
Train Avg Loss  334: 0.073717

Train Avg F1  334: 0.7215646281822753

Val Avg Loss  334: 0.069394

Val Avg F1  334:  0.7224736048265459

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 335
--------------------------------------------------------------
Epoch:  335        1 Batch loss: 0.096894 Batch F1: 0.42857142857142855
Epoch:  335        2 Batch loss: 0.076302 Batch F1: 0.8571428571428571
Epoch:  335        3 Batch loss: 0.066323 Batch F1: 0.7692307692307693
Epoch:  335        4 Batch loss: 0.066401 Batch F1: 0.7499999999999999
Epoch:  335        5 Batch loss: 0.059857 Batch F1: 0.9333333333333333
Epoch:  335        6 Batch loss: 0.062200 Batch F1: 0.7272727272727273
Epoch:  335        7 Batch loss: 0.069561 Batch F1: 0.5
Epoch:  335        8 Batch loss: 0.100584 Batch F1: 0.47058823529411764
Epoch:  335        9 Batch loss: 0.067166 Batch F1: 0.6153846153846153
Epoch:  335       10 Batch loss: 0.055534 Batch F1: 0.5454545454545454
Epoch:  335       11 Batch loss: 0.062109 Batch F1: 0.8571428571428571
Epoch:  335       12 Batch loss: 0.060191 Batch F1: 1.0
Train Avg Loss  335: 0.070260

Train Avg F1  335: 0.7045101140689377

Val Avg Loss  335: 0.064903

Val Avg F1  335:  0.9006383712905452

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 336
--------------------------------------------------------------
Epoch:  336        1 Batch loss: 0.075840 Batch F1: 1.0
Epoch:  336        2 Batch loss: 0.055321 Batch F1: 0.9333333333333333
Epoch:  336        3 Batch loss: 0.085480 Batch F1: 0.5882352941176471
Epoch:  336        4 Batch loss: 0.086062 Batch F1: 0.6666666666666666
Epoch:  336        5 Batch loss: 0.059338 Batch F1: 0.6
Epoch:  336        6 Batch loss: 0.052933 Batch F1: 0.9333333333333333
Epoch:  336        7 Batch loss: 0.047687 Batch F1: 0.9333333333333333
Epoch:  336        8 Batch loss: 0.085715 Batch F1: 0.7777777777777778
Epoch:  336        9 Batch loss: 0.057832 Batch F1: 0.8333333333333333
Epoch:  336       10 Batch loss: 0.073792 Batch F1: 0.7058823529411764
Epoch:  336       11 Batch loss: 0.073336 Batch F1: 0.8
Epoch:  336       12 Batch loss: 0.059284 Batch F1: 0.8
Train Avg Loss  336: 0.067718

Train Avg F1  336: 0.7976579520697169

Val Avg Loss  336: 0.063420

Val Avg F1  336:  0.7802871148459383

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 337
--------------------------------------------------------------
Epoch:  337        1 Batch loss: 0.059904 Batch F1: 0.5
Epoch:  337        2 Batch loss: 0.066159 Batch F1: 0.9411764705882353
Epoch:  337        3 Batch loss: 0.073873 Batch F1: 0.9
Epoch:  337        4 Batch loss: 0.080053 Batch F1: 0.9090909090909091
Epoch:  337        5 Batch loss: 0.045622 Batch F1: 0.8333333333333333
Epoch:  337        6 Batch loss: 0.060399 Batch F1: 0.7692307692307693
Epoch:  337        7 Batch loss: 0.048640 Batch F1: 0.8571428571428571
Epoch:  337        8 Batch loss: 0.064046 Batch F1: 0.923076923076923
Epoch:  337        9 Batch loss: 0.054850 Batch F1: 0.7272727272727273
Epoch:  337       10 Batch loss: 0.102708 Batch F1: 0.4444444444444445
Epoch:  337       11 Batch loss: 0.082495 Batch F1: 0.8181818181818181
Epoch:  337       12 Batch loss: 0.083624 Batch F1: 0.6666666666666666
Train Avg Loss  337: 0.068531

Train Avg F1  337: 0.7741347432523903

Val Avg Loss  337: 0.063992

Val Avg F1  337:  0.9149797570850202

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 338
--------------------------------------------------------------
Epoch:  338        1 Batch loss: 0.062056 Batch F1: 0.923076923076923
Epoch:  338        2 Batch loss: 0.076490 Batch F1: 0.7999999999999999
Epoch:  338        3 Batch loss: 0.084162 Batch F1: 0.823529411764706
Epoch:  338        4 Batch loss: 0.071013 Batch F1: 0.888888888888889
Epoch:  338        5 Batch loss: 0.064050 Batch F1: 0.7499999999999999
Epoch:  338        6 Batch loss: 0.047588 Batch F1: 0.923076923076923
Epoch:  338        7 Batch loss: 0.068803 Batch F1: 0.8421052631578948
Epoch:  338        8 Batch loss: 0.078894 Batch F1: 0.7692307692307693
Epoch:  338        9 Batch loss: 0.063993 Batch F1: 0.8750000000000001
Epoch:  338       10 Batch loss: 0.062361 Batch F1: 0.9
Epoch:  338       11 Batch loss: 0.056967 Batch F1: 0.6666666666666666
Epoch:  338       12 Batch loss: 0.079702 Batch F1: 0.8333333333333333
Train Avg Loss  338: 0.068007

Train Avg F1  338: 0.8329090149330086

Val Avg Loss  338: 0.063068

Val Avg F1  338:  0.7282738095238095

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 339
--------------------------------------------------------------
Epoch:  339        1 Batch loss: 0.048040 Batch F1: 0.888888888888889
Epoch:  339        2 Batch loss: 0.079078 Batch F1: 0.33333333333333337
Epoch:  339        3 Batch loss: 0.061582 Batch F1: 0.5454545454545454
Epoch:  339        4 Batch loss: 0.067576 Batch F1: 0.3636363636363636
Epoch:  339        5 Batch loss: 0.079364 Batch F1: 0.8181818181818181
Epoch:  339        6 Batch loss: 0.059813 Batch F1: 0.8
Epoch:  339        7 Batch loss: 0.077418 Batch F1: 0.8421052631578948
Epoch:  339        8 Batch loss: 0.063698 Batch F1: 0.9090909090909091
Epoch:  339        9 Batch loss: 0.060192 Batch F1: 0.9411764705882353
Epoch:  339       10 Batch loss: 0.069675 Batch F1: 0.9473684210526316
Epoch:  339       11 Batch loss: 0.080034 Batch F1: 0.7692307692307693
Epoch:  339       12 Batch loss: 0.065844 Batch F1: 0.6
Train Avg Loss  339: 0.067693

Train Avg F1  339: 0.7298722318846158

Val Avg Loss  339: 0.065494

Val Avg F1  339:  0.7848039215686273

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 340
--------------------------------------------------------------
Epoch:  340        1 Batch loss: 0.063123 Batch F1: 0.8750000000000001
Epoch:  340        2 Batch loss: 0.074626 Batch F1: 0.6
Epoch:  340        3 Batch loss: 0.084097 Batch F1: 0.72
Epoch:  340        4 Batch loss: 0.069916 Batch F1: 0.6153846153846153
Epoch:  340        5 Batch loss: 0.065839 Batch F1: 0.8
Epoch:  340        6 Batch loss: 0.052448 Batch F1: 0.7499999999999999
Epoch:  340        7 Batch loss: 0.074291 Batch F1: 0.7499999999999999
Epoch:  340        8 Batch loss: 0.055055 Batch F1: 0.5714285714285715
Epoch:  340        9 Batch loss: 0.092692 Batch F1: 0.6
Epoch:  340       10 Batch loss: 0.052276 Batch F1: 0.2857142857142857
Epoch:  340       11 Batch loss: 0.079396 Batch F1: 0.4615384615384615
Epoch:  340       12 Batch loss: 0.055212 Batch F1: 0.9333333333333333
Train Avg Loss  340: 0.068248

Train Avg F1  340: 0.6635332722832723

Val Avg Loss  340: 0.067375

Val Avg F1  340:  0.923264042459089

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 341
--------------------------------------------------------------
Epoch:  341        1 Batch loss: 0.061770 Batch F1: 0.8333333333333334
Epoch:  341        2 Batch loss: 0.050141 Batch F1: 0.923076923076923
Epoch:  341        3 Batch loss: 0.060750 Batch F1: 0.8235294117647058
Epoch:  341        4 Batch loss: 0.079594 Batch F1: 0.5333333333333333
Epoch:  341        5 Batch loss: 0.112040 Batch F1: 0.375
Epoch:  341        6 Batch loss: 0.069779 Batch F1: 0.7692307692307693
Epoch:  341        7 Batch loss: 0.064231 Batch F1: 0.9473684210526316
Epoch:  341        8 Batch loss: 0.086785 Batch F1: 0.8461538461538461
Epoch:  341        9 Batch loss: 0.054082 Batch F1: 1.0
Epoch:  341       10 Batch loss: 0.076115 Batch F1: 0.923076923076923
Epoch:  341       11 Batch loss: 0.042895 Batch F1: 1.0
Epoch:  341       12 Batch loss: 0.075569 Batch F1: 0.3636363636363636
Train Avg Loss  341: 0.069479

Train Avg F1  341: 0.7781449437215691

Val Avg Loss  341: 0.065717

Val Avg F1  341:  0.5750000000000001

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 342
--------------------------------------------------------------
Epoch:  342        1 Batch loss: 0.034030 Batch F1: 0.8
Epoch:  342        2 Batch loss: 0.092365 Batch F1: 0.42857142857142855
Epoch:  342        3 Batch loss: 0.081406 Batch F1: 0.5882352941176471
Epoch:  342        4 Batch loss: 0.089067 Batch F1: 0.631578947368421
Epoch:  342        5 Batch loss: 0.077534 Batch F1: 0.4615384615384615
Epoch:  342        6 Batch loss: 0.071879 Batch F1: 0.8750000000000001
Epoch:  342        7 Batch loss: 0.052443 Batch F1: 1.0
Epoch:  342        8 Batch loss: 0.059136 Batch F1: 0.9333333333333333
Epoch:  342        9 Batch loss: 0.066520 Batch F1: 0.8571428571428571
Epoch:  342       10 Batch loss: 0.093086 Batch F1: 0.888888888888889
Epoch:  342       11 Batch loss: 0.062339 Batch F1: 0.9090909090909091
Epoch:  342       12 Batch loss: 0.059156 Batch F1: 1.0
Train Avg Loss  342: 0.069913

Train Avg F1  342: 0.7811150100043288

Val Avg Loss  342: 0.064895

Val Avg F1  342:  0.6457417582417583

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 343
--------------------------------------------------------------
Epoch:  343        1 Batch loss: 0.065630 Batch F1: 0.5714285714285715
Epoch:  343        2 Batch loss: 0.080295 Batch F1: 0.5333333333333333
Epoch:  343        3 Batch loss: 0.060063 Batch F1: 0.6
Epoch:  343        4 Batch loss: 0.058354 Batch F1: 0.7142857142857143
Epoch:  343        5 Batch loss: 0.083527 Batch F1: 0.7777777777777778
Epoch:  343        6 Batch loss: 0.085709 Batch F1: 0.8695652173913044
Epoch:  343        7 Batch loss: 0.096395 Batch F1: 0.6666666666666667
Epoch:  343        8 Batch loss: 0.065191 Batch F1: 0.9333333333333333
Epoch:  343        9 Batch loss: 0.050214 Batch F1: 0.8333333333333333
Epoch:  343       10 Batch loss: 0.053438 Batch F1: 0.5
Epoch:  343       11 Batch loss: 0.065073 Batch F1: 0.4
Epoch:  343       12 Batch loss: 0.062219 Batch F1: 0.33333333333333337
Train Avg Loss  343: 0.068842

Train Avg F1  343: 0.644421440073614

Val Avg Loss  343: 0.069429

Val Avg F1  343:  0.5723039215686274

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 344
--------------------------------------------------------------
Epoch:  344        1 Batch loss: 0.072469 Batch F1: 0.625
Epoch:  344        2 Batch loss: 0.059137 Batch F1: 0.9523809523809523
Epoch:  344        3 Batch loss: 0.073640 Batch F1: 0.6666666666666666
Epoch:  344        4 Batch loss: 0.077987 Batch F1: 0.8333333333333333
Epoch:  344        5 Batch loss: 0.061791 Batch F1: 1.0
Epoch:  344        6 Batch loss: 0.074095 Batch F1: 1.0
Epoch:  344        7 Batch loss: 0.068269 Batch F1: 0.9333333333333333
Epoch:  344        8 Batch loss: 0.064518 Batch F1: 0.8571428571428571
Epoch:  344        9 Batch loss: 0.055691 Batch F1: 0.8571428571428571
Epoch:  344       10 Batch loss: 0.057001 Batch F1: 0.6666666666666666
Epoch:  344       11 Batch loss: 0.082723 Batch F1: 0.4615384615384615
Epoch:  344       12 Batch loss: 0.113107 Batch F1: 0.5333333333333333
Train Avg Loss  344: 0.071702

Train Avg F1  344: 0.7822115384615383

Val Avg Loss  344: 0.067388

Val Avg F1  344:  0.5758771929824561

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 345
--------------------------------------------------------------
Epoch:  345        1 Batch loss: 0.074342 Batch F1: 0.19999999999999998
Epoch:  345        2 Batch loss: 0.057800 Batch F1: 1.0
Epoch:  345        3 Batch loss: 0.098531 Batch F1: 0.8333333333333333
Epoch:  345        4 Batch loss: 0.043525 Batch F1: 1.0
Epoch:  345        5 Batch loss: 0.072471 Batch F1: 0.9411764705882353
Epoch:  345        6 Batch loss: 0.083946 Batch F1: 0.8421052631578948
Epoch:  345        7 Batch loss: 0.049433 Batch F1: 0.7499999999999999
Epoch:  345        8 Batch loss: 0.095216 Batch F1: 0.33333333333333337
Epoch:  345        9 Batch loss: 0.093418 Batch F1: 0.7826086956521738
Epoch:  345       10 Batch loss: 0.106939 Batch F1: 0.0
Epoch:  345       11 Batch loss: 0.062532 Batch F1: 0.4
Epoch:  345       12 Batch loss: 0.062899 Batch F1: 0.6666666666666666
Train Avg Loss  345: 0.075088

Train Avg F1  345: 0.6457686468943031

Val Avg Loss  345: 0.065740

Val Avg F1  345:  0.6493783993783993

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 346
--------------------------------------------------------------
Epoch:  346        1 Batch loss: 0.066593 Batch F1: 0.6666666666666666
Epoch:  346        2 Batch loss: 0.074371 Batch F1: 0.42857142857142855
Epoch:  346        3 Batch loss: 0.051303 Batch F1: 0.7499999999999999
Epoch:  346        4 Batch loss: 0.085485 Batch F1: 0.5
Epoch:  346        5 Batch loss: 0.059949 Batch F1: 0.9090909090909091
Epoch:  346        6 Batch loss: 0.088252 Batch F1: 0.5
Epoch:  346        7 Batch loss: 0.063755 Batch F1: 0.4
Epoch:  346        8 Batch loss: 0.068968 Batch F1: 0.8
Epoch:  346        9 Batch loss: 0.045495 Batch F1: 0.9090909090909091
Epoch:  346       10 Batch loss: 0.106386 Batch F1: 0.7692307692307693
Epoch:  346       11 Batch loss: 0.058815 Batch F1: 0.923076923076923
Epoch:  346       12 Batch loss: 0.064064 Batch F1: 0.9333333333333333
Train Avg Loss  346: 0.069453

Train Avg F1  346: 0.7074217449217449

Val Avg Loss  346: 0.065631

Val Avg F1  346:  0.9325396825396826

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 347
--------------------------------------------------------------
Epoch:  347        1 Batch loss: 0.086917 Batch F1: 0.9333333333333333
Epoch:  347        2 Batch loss: 0.110881 Batch F1: 0.8
Epoch:  347        3 Batch loss: 0.057233 Batch F1: 0.9411764705882353
Epoch:  347        4 Batch loss: 0.046481 Batch F1: 1.0
Epoch:  347        5 Batch loss: 0.075910 Batch F1: 0.0
Epoch:  347        6 Batch loss: 0.054381 Batch F1: 0.0
Epoch:  347        7 Batch loss: 0.113738 Batch F1: 0.0
Epoch:  347        8 Batch loss: 0.116268 Batch F1: 0.0
Epoch:  347        9 Batch loss: 0.088630 Batch F1: 0.0
Epoch:  347       10 Batch loss: 0.083269 Batch F1: 0.5333333333333333
Epoch:  347       11 Batch loss: 0.065980 Batch F1: 0.7777777777777778
Epoch:  347       12 Batch loss: 0.079942 Batch F1: 0.9411764705882353
Train Avg Loss  347: 0.081636

Train Avg F1  347: 0.4938997821350763

Val Avg Loss  347: 0.075209

Val Avg F1  347:  0.9395192307692308

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 348
--------------------------------------------------------------
Epoch:  348        1 Batch loss: 0.089242 Batch F1: 0.888888888888889
Epoch:  348        2 Batch loss: 0.074167 Batch F1: 0.6
Epoch:  348        3 Batch loss: 0.091517 Batch F1: 0.18181818181818182
Epoch:  348        4 Batch loss: 0.085781 Batch F1: 0.28571428571428575
Epoch:  348        5 Batch loss: 0.117824 Batch F1: 0.47058823529411764
Epoch:  348        6 Batch loss: 0.067590 Batch F1: 0.7999999999999999
Epoch:  348        7 Batch loss: 0.058973 Batch F1: 0.8571428571428571
Epoch:  348        8 Batch loss: 0.081971 Batch F1: 0.4615384615384615
Epoch:  348        9 Batch loss: 0.079175 Batch F1: 0.7058823529411764
Epoch:  348       10 Batch loss: 0.084987 Batch F1: 0.6666666666666666
Epoch:  348       11 Batch loss: 0.061221 Batch F1: 0.9473684210526316
Epoch:  348       12 Batch loss: 0.065426 Batch F1: 0.923076923076923
Train Avg Loss  348: 0.079823

Train Avg F1  348: 0.6490571061778493

Val Avg Loss  348: 0.069774

Val Avg F1  348:  0.924937343358396

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 349
--------------------------------------------------------------
Epoch:  349        1 Batch loss: 0.068136 Batch F1: 1.0
Epoch:  349        2 Batch loss: 0.085258 Batch F1: 0.5714285714285715
Epoch:  349        3 Batch loss: 0.083689 Batch F1: 0.5
Epoch:  349        4 Batch loss: 0.070179 Batch F1: 0.6666666666666666
Epoch:  349        5 Batch loss: 0.070569 Batch F1: 0.8571428571428571
Epoch:  349        6 Batch loss: 0.075147 Batch F1: 0.625
Epoch:  349        7 Batch loss: 0.081000 Batch F1: 0.5
Epoch:  349        8 Batch loss: 0.066830 Batch F1: 0.2857142857142857
Epoch:  349        9 Batch loss: 0.066191 Batch F1: 0.8
Epoch:  349       10 Batch loss: 0.074071 Batch F1: 0.7058823529411764
Epoch:  349       11 Batch loss: 0.067164 Batch F1: 1.0
Epoch:  349       12 Batch loss: 0.077652 Batch F1: 1.0
Train Avg Loss  349: 0.073824

Train Avg F1  349: 0.7093195611577965

Val Avg Loss  349: 0.065887

Val Avg F1  349:  0.930952380952381

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 350
--------------------------------------------------------------
Epoch:  350        1 Batch loss: 0.057442 Batch F1: 0.888888888888889
Epoch:  350        2 Batch loss: 0.084303 Batch F1: 0.5882352941176471
Epoch:  350        3 Batch loss: 0.068113 Batch F1: 0.7499999999999999
Epoch:  350        4 Batch loss: 0.070946 Batch F1: 0.625
Epoch:  350        5 Batch loss: 0.075956 Batch F1: 0.761904761904762
Epoch:  350        6 Batch loss: 0.072464 Batch F1: 0.9
Epoch:  350        7 Batch loss: 0.051939 Batch F1: 1.0
Epoch:  350        8 Batch loss: 0.081812 Batch F1: 0.962962962962963
Epoch:  350        9 Batch loss: 0.070425 Batch F1: 0.8
Epoch:  350       10 Batch loss: 0.050590 Batch F1: 0.888888888888889
Epoch:  350       11 Batch loss: 0.094634 Batch F1: 0.16666666666666669
Epoch:  350       12 Batch loss: 0.074198 Batch F1: 0.25
Train Avg Loss  350: 0.071068

Train Avg F1  350: 0.7152122886191513

Val Avg Loss  350: 0.067132

Val Avg F1  350:  0.6038533834586466

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 351
--------------------------------------------------------------
Epoch:  351        1 Batch loss: 0.088120 Batch F1: 0.18181818181818182
Epoch:  351        2 Batch loss: 0.070330 Batch F1: 0.8181818181818181
Epoch:  351        3 Batch loss: 0.076078 Batch F1: 0.9
Epoch:  351        4 Batch loss: 0.083038 Batch F1: 0.8235294117647058
Epoch:  351        5 Batch loss: 0.071066 Batch F1: 0.888888888888889
Epoch:  351        6 Batch loss: 0.049731 Batch F1: 1.0
Epoch:  351        7 Batch loss: 0.076388 Batch F1: 0.7499999999999999
Epoch:  351        8 Batch loss: 0.069760 Batch F1: 0.7499999999999999
Epoch:  351        9 Batch loss: 0.070648 Batch F1: 0.8571428571428571
Epoch:  351       10 Batch loss: 0.052016 Batch F1: 0.0
Epoch:  351       11 Batch loss: 0.065932 Batch F1: 0.7142857142857143
Epoch:  351       12 Batch loss: 0.111316 Batch F1: 0.4
Train Avg Loss  351: 0.073702

Train Avg F1  351: 0.6736539060068472

Val Avg Loss  351: 0.067901

Val Avg F1  351:  0.6060606060606061

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 352
--------------------------------------------------------------
Epoch:  352        1 Batch loss: 0.050457 Batch F1: 0.8571428571428571
Epoch:  352        2 Batch loss: 0.069930 Batch F1: 0.8421052631578948
Epoch:  352        3 Batch loss: 0.078591 Batch F1: 0.7142857142857143
Epoch:  352        4 Batch loss: 0.105312 Batch F1: 0.8275862068965517
Epoch:  352        5 Batch loss: 0.053624 Batch F1: 0.8571428571428571
Epoch:  352        6 Batch loss: 0.076569 Batch F1: 0.5454545454545454
Epoch:  352        7 Batch loss: 0.077841 Batch F1: 0.8799999999999999
Epoch:  352        8 Batch loss: 0.052535 Batch F1: 0.6666666666666666
Epoch:  352        9 Batch loss: 0.075435 Batch F1: 0.5882352941176471
Epoch:  352       10 Batch loss: 0.074442 Batch F1: 0.6666666666666666
Epoch:  352       11 Batch loss: 0.056473 Batch F1: 0.8
Epoch:  352       12 Batch loss: 0.065466 Batch F1: 0.6666666666666666
Train Avg Loss  352: 0.069723

Train Avg F1  352: 0.7426627281831722

Val Avg Loss  352: 0.064499

Val Avg F1  352:  0.7770864004416637

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 353
--------------------------------------------------------------
Epoch:  353        1 Batch loss: 0.054029 Batch F1: 0.7499999999999999
Epoch:  353        2 Batch loss: 0.043510 Batch F1: 0.8571428571428571
Epoch:  353        3 Batch loss: 0.074261 Batch F1: 0.4615384615384615
Epoch:  353        4 Batch loss: 0.066707 Batch F1: 0.6666666666666666
Epoch:  353        5 Batch loss: 0.061396 Batch F1: 0.5454545454545454
Epoch:  353        6 Batch loss: 0.077044 Batch F1: 0.5333333333333333
Epoch:  353        7 Batch loss: 0.060593 Batch F1: 0.6666666666666666
Epoch:  353        8 Batch loss: 0.071889 Batch F1: 0.9411764705882353
Epoch:  353        9 Batch loss: 0.089139 Batch F1: 0.8
Epoch:  353       10 Batch loss: 0.092521 Batch F1: 0.88
Epoch:  353       11 Batch loss: 0.060158 Batch F1: 0.9333333333333333
Epoch:  353       12 Batch loss: 0.066694 Batch F1: 0.888888888888889
Train Avg Loss  353: 0.068162

Train Avg F1  353: 0.7436834353010823

Val Avg Loss  353: 0.064705

Val Avg F1  353:  0.9446640316205533

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 354
--------------------------------------------------------------
Epoch:  354        1 Batch loss: 0.057826 Batch F1: 0.9333333333333333
Epoch:  354        2 Batch loss: 0.090992 Batch F1: 0.9230769230769231
Epoch:  354        3 Batch loss: 0.060110 Batch F1: 0.888888888888889
Epoch:  354        4 Batch loss: 0.053265 Batch F1: 0.9411764705882353
Epoch:  354        5 Batch loss: 0.083656 Batch F1: 0.7000000000000001
Epoch:  354        6 Batch loss: 0.060106 Batch F1: 0.7692307692307693
Epoch:  354        7 Batch loss: 0.049444 Batch F1: 0.8333333333333333
Epoch:  354        8 Batch loss: 0.075865 Batch F1: 0.8
Epoch:  354        9 Batch loss: 0.075725 Batch F1: 0.7058823529411764
Epoch:  354       10 Batch loss: 0.068977 Batch F1: 0.7692307692307693
Epoch:  354       11 Batch loss: 0.060070 Batch F1: 0.8571428571428571
Epoch:  354       12 Batch loss: 0.083041 Batch F1: 0.8750000000000001
Train Avg Loss  354: 0.068256

Train Avg F1  354: 0.8330246414805239

Val Avg Loss  354: 0.063776

Val Avg F1  354:  0.8506944444444444

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 355
--------------------------------------------------------------
Epoch:  355        1 Batch loss: 0.065431 Batch F1: 0.6666666666666666
Epoch:  355        2 Batch loss: 0.101401 Batch F1: 0.5833333333333334
Epoch:  355        3 Batch loss: 0.074245 Batch F1: 0.5
Epoch:  355        4 Batch loss: 0.064732 Batch F1: 1.0
Epoch:  355        5 Batch loss: 0.056563 Batch F1: 0.888888888888889
Epoch:  355        6 Batch loss: 0.062416 Batch F1: 1.0
Epoch:  355        7 Batch loss: 0.093165 Batch F1: 0.9166666666666666
Epoch:  355        8 Batch loss: 0.061803 Batch F1: 0.8333333333333333
Epoch:  355        9 Batch loss: 0.049011 Batch F1: 0.888888888888889
Epoch:  355       10 Batch loss: 0.070639 Batch F1: 0.9333333333333333
Epoch:  355       11 Batch loss: 0.056517 Batch F1: 0.8571428571428571
Epoch:  355       12 Batch loss: 0.071380 Batch F1: 0.6153846153846153
Train Avg Loss  355: 0.068942

Train Avg F1  355: 0.8069698819698821

Val Avg Loss  355: 0.066195

Val Avg F1  355:  0.5693181818181818

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 356
--------------------------------------------------------------
Epoch:  356        1 Batch loss: 0.072477 Batch F1: 0.5714285714285715
Epoch:  356        2 Batch loss: 0.056283 Batch F1: 0.8235294117647058
Epoch:  356        3 Batch loss: 0.082046 Batch F1: 0.761904761904762
Epoch:  356        4 Batch loss: 0.079763 Batch F1: 0.6666666666666666
Epoch:  356        5 Batch loss: 0.064686 Batch F1: 0.9473684210526316
Epoch:  356        6 Batch loss: 0.074508 Batch F1: 0.9090909090909091
Epoch:  356        7 Batch loss: 0.069877 Batch F1: 0.9
Epoch:  356        8 Batch loss: 0.071082 Batch F1: 0.7272727272727273
Epoch:  356        9 Batch loss: 0.066250 Batch F1: 0.5
Epoch:  356       10 Batch loss: 0.068591 Batch F1: 0.5
Epoch:  356       11 Batch loss: 0.059959 Batch F1: 0.6
Epoch:  356       12 Batch loss: 0.057059 Batch F1: 0.6666666666666666
Train Avg Loss  356: 0.068548

Train Avg F1  356: 0.7144940113206367

Val Avg Loss  356: 0.063058

Val Avg F1  356:  0.7528594771241829

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 357
--------------------------------------------------------------
Epoch:  357        1 Batch loss: 0.051813 Batch F1: 0.6666666666666666
Epoch:  357        2 Batch loss: 0.064814 Batch F1: 0.5
Epoch:  357        3 Batch loss: 0.059039 Batch F1: 0.8333333333333333
Epoch:  357        4 Batch loss: 0.089762 Batch F1: 0.6086956521739131
Epoch:  357        5 Batch loss: 0.036592 Batch F1: 1.0
Epoch:  357        6 Batch loss: 0.108760 Batch F1: 0.5263157894736842
Epoch:  357        7 Batch loss: 0.080384 Batch F1: 0.782608695652174
Epoch:  357        8 Batch loss: 0.047644 Batch F1: 0.8
Epoch:  357        9 Batch loss: 0.058016 Batch F1: 0.8
Epoch:  357       10 Batch loss: 0.080908 Batch F1: 0.5714285714285715
Epoch:  357       11 Batch loss: 0.045552 Batch F1: 1.0
Epoch:  357       12 Batch loss: 0.086907 Batch F1: 0.4615384615384615
Train Avg Loss  357: 0.067516

Train Avg F1  357: 0.7125489308555669

Val Avg Loss  357: 0.063776

Val Avg F1  357:  0.6648351648351648

Optimal Val loss (Epoch 270): 0.06268877722322941

Epoch 358
--------------------------------------------------------------
Epoch:  358        1 Batch loss: 0.072705 Batch F1: 0.7058823529411764
Epoch:  358        2 Batch loss: 0.063476 Batch F1: 0.9
Epoch:  358        3 Batch loss: 0.065774 Batch F1: 0.6666666666666666
Epoch:  358        4 Batch loss: 0.086098 Batch F1: 0.761904761904762
Epoch:  358        5 Batch loss: 0.074996 Batch F1: 0.8421052631578948
Epoch:  358        6 Batch loss: 0.054278 Batch F1: 0.9090909090909091
Epoch:  358        7 Batch loss: 0.071889 Batch F1: 0.8571428571428571
Epoch:  358        8 Batch loss: 0.047169 Batch F1: 0.8
Epoch:  358        9 Batch loss: 0.078904 Batch F1: 0.7368421052631579
Epoch:  358       10 Batch loss: 0.075378 Batch F1: 0.7142857142857143
Epoch:  358       11 Batch loss: 0.057573 Batch F1: 0.8333333333333333
Epoch:  358       12 Batch loss: 0.057065 Batch F1: 0.6666666666666666
Train Avg Loss  358: 0.067109

Train Avg F1  358: 0.782826719204428

Val Avg Loss  358: 0.061409

Val Avg F1  358:  0.8585858585858586

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 359
--------------------------------------------------------------
Epoch:  359        1 Batch loss: 0.048074 Batch F1: 1.0
Epoch:  359        2 Batch loss: 0.048401 Batch F1: 0.9333333333333333
Epoch:  359        3 Batch loss: 0.098613 Batch F1: 0.7499999999999999
Epoch:  359        4 Batch loss: 0.060012 Batch F1: 0.7692307692307693
Epoch:  359        5 Batch loss: 0.064340 Batch F1: 0.8750000000000001
Epoch:  359        6 Batch loss: 0.073920 Batch F1: 0.8
Epoch:  359        7 Batch loss: 0.058092 Batch F1: 0.923076923076923
Epoch:  359        8 Batch loss: 0.084916 Batch F1: 0.8181818181818181
Epoch:  359        9 Batch loss: 0.073140 Batch F1: 0.6666666666666666
Epoch:  359       10 Batch loss: 0.076397 Batch F1: 0.8695652173913044
Epoch:  359       11 Batch loss: 0.060946 Batch F1: 0.8571428571428571
Epoch:  359       12 Batch loss: 0.046177 Batch F1: 0.8333333333333333
Train Avg Loss  359: 0.066086

Train Avg F1  359: 0.8412942431964172

Val Avg Loss  359: 0.062233

Val Avg F1  359:  0.7542032163742691

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 360
--------------------------------------------------------------
Epoch:  360        1 Batch loss: 0.045970 Batch F1: 0.9333333333333333
Epoch:  360        2 Batch loss: 0.077344 Batch F1: 0.7499999999999999
Epoch:  360        3 Batch loss: 0.052780 Batch F1: 0.8333333333333333
Epoch:  360        4 Batch loss: 0.063756 Batch F1: 0.5
Epoch:  360        5 Batch loss: 0.072423 Batch F1: 0.625
Epoch:  360        6 Batch loss: 0.087305 Batch F1: 0.16666666666666669
Epoch:  360        7 Batch loss: 0.089173 Batch F1: 0.8
Epoch:  360        8 Batch loss: 0.070146 Batch F1: 0.888888888888889
Epoch:  360        9 Batch loss: 0.072530 Batch F1: 0.8571428571428571
Epoch:  360       10 Batch loss: 0.055029 Batch F1: 0.8571428571428571
Epoch:  360       11 Batch loss: 0.088493 Batch F1: 0.631578947368421
Epoch:  360       12 Batch loss: 0.041173 Batch F1: 0.9090909090909091
Train Avg Loss  360: 0.068010

Train Avg F1  360: 0.7293481494139389

Val Avg Loss  360: 0.063635

Val Avg F1  360:  0.5982905982905983

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 361
--------------------------------------------------------------
Epoch:  361        1 Batch loss: 0.073682 Batch F1: 0.625
Epoch:  361        2 Batch loss: 0.069506 Batch F1: 0.7777777777777778
Epoch:  361        3 Batch loss: 0.078417 Batch F1: 0.9333333333333333
Epoch:  361        4 Batch loss: 0.066838 Batch F1: 0.9333333333333333
Epoch:  361        5 Batch loss: 0.086745 Batch F1: 0.8
Epoch:  361        6 Batch loss: 0.061318 Batch F1: 1.0
Epoch:  361        7 Batch loss: 0.061444 Batch F1: 0.7499999999999999
Epoch:  361        8 Batch loss: 0.062930 Batch F1: 0.5714285714285715
Epoch:  361        9 Batch loss: 0.067234 Batch F1: 0.6666666666666667
Epoch:  361       10 Batch loss: 0.082636 Batch F1: 0.7368421052631579
Epoch:  361       11 Batch loss: 0.090378 Batch F1: 0.8235294117647058
Epoch:  361       12 Batch loss: 0.051610 Batch F1: 1.0
Train Avg Loss  361: 0.071062

Train Avg F1  361: 0.8014925999639622

Val Avg Loss  361: 0.065668

Val Avg F1  361:  0.6753772543246228

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 362
--------------------------------------------------------------
Epoch:  362        1 Batch loss: 0.074687 Batch F1: 0.5
Epoch:  362        2 Batch loss: 0.074258 Batch F1: 0.7499999999999999
Epoch:  362        3 Batch loss: 0.064570 Batch F1: 0.8
Epoch:  362        4 Batch loss: 0.057303 Batch F1: 0.6666666666666666
Epoch:  362        5 Batch loss: 0.072947 Batch F1: 0.5333333333333333
Epoch:  362        6 Batch loss: 0.070632 Batch F1: 0.9230769230769231
Epoch:  362        7 Batch loss: 0.063986 Batch F1: 0.5714285714285715
Epoch:  362        8 Batch loss: 0.068845 Batch F1: 0.6666666666666666
Epoch:  362        9 Batch loss: 0.053572 Batch F1: 0.4
Epoch:  362       10 Batch loss: 0.064923 Batch F1: 0.0
Epoch:  362       11 Batch loss: 0.088970 Batch F1: 0.16666666666666669
Epoch:  362       12 Batch loss: 0.079024 Batch F1: 0.8
Train Avg Loss  362: 0.069476

Train Avg F1  362: 0.5648199023199023

Val Avg Loss  362: 0.064272

Val Avg F1  362:  0.9232034412955467

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 363
--------------------------------------------------------------
Epoch:  363        1 Batch loss: 0.059292 Batch F1: 0.8750000000000001
Epoch:  363        2 Batch loss: 0.058995 Batch F1: 0.9090909090909091
Epoch:  363        3 Batch loss: 0.063617 Batch F1: 0.8571428571428571
Epoch:  363        4 Batch loss: 0.046771 Batch F1: 0.8571428571428571
Epoch:  363        5 Batch loss: 0.063510 Batch F1: 0.6666666666666666
Epoch:  363        6 Batch loss: 0.063897 Batch F1: 0.6
Epoch:  363        7 Batch loss: 0.097470 Batch F1: 0.5
Epoch:  363        8 Batch loss: 0.074118 Batch F1: 0.5
Epoch:  363        9 Batch loss: 0.090115 Batch F1: 0.8
Epoch:  363       10 Batch loss: 0.086194 Batch F1: 0.962962962962963
Epoch:  363       11 Batch loss: 0.078284 Batch F1: 0.9333333333333333
Epoch:  363       12 Batch loss: 0.056507 Batch F1: 0.6666666666666666
Train Avg Loss  363: 0.069898

Train Avg F1  363: 0.760667187750521

Val Avg Loss  363: 0.064662

Val Avg F1  363:  0.6176900584795322

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 364
--------------------------------------------------------------
Epoch:  364        1 Batch loss: 0.073063 Batch F1: 0.4615384615384615
Epoch:  364        2 Batch loss: 0.089383 Batch F1: 0.42857142857142855
Epoch:  364        3 Batch loss: 0.068928 Batch F1: 0.5454545454545454
Epoch:  364        4 Batch loss: 0.087490 Batch F1: 0.782608695652174
Epoch:  364        5 Batch loss: 0.067384 Batch F1: 0.9523809523809523
Epoch:  364        6 Batch loss: 0.098862 Batch F1: 0.8181818181818182
Epoch:  364        7 Batch loss: 0.065178 Batch F1: 1.0
Epoch:  364        8 Batch loss: 0.046475 Batch F1: 0.888888888888889
Epoch:  364        9 Batch loss: 0.063142 Batch F1: 0.2857142857142857
Epoch:  364       10 Batch loss: 0.084359 Batch F1: 0.18181818181818182
Epoch:  364       11 Batch loss: 0.097808 Batch F1: 0.16666666666666669
Epoch:  364       12 Batch loss: 0.054012 Batch F1: 0.33333333333333337
Train Avg Loss  364: 0.074674

Train Avg F1  364: 0.570429771516728

Val Avg Loss  364: 0.067158

Val Avg F1  364:  0.625649881164587

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 365
--------------------------------------------------------------
Epoch:  365        1 Batch loss: 0.055378 Batch F1: 0.5
Epoch:  365        2 Batch loss: 0.066595 Batch F1: 0.9166666666666666
Epoch:  365        3 Batch loss: 0.062889 Batch F1: 0.875
Epoch:  365        4 Batch loss: 0.065491 Batch F1: 0.923076923076923
Epoch:  365        5 Batch loss: 0.060376 Batch F1: 1.0
Epoch:  365        6 Batch loss: 0.103168 Batch F1: 0.2666666666666667
Epoch:  365        7 Batch loss: 0.061612 Batch F1: 0.5454545454545454
Epoch:  365        8 Batch loss: 0.081481 Batch F1: 0.7499999999999999
Epoch:  365        9 Batch loss: 0.097348 Batch F1: 0.7058823529411764
Epoch:  365       10 Batch loss: 0.072210 Batch F1: 0.9090909090909091
Epoch:  365       11 Batch loss: 0.066492 Batch F1: 0.9090909090909091
Epoch:  365       12 Batch loss: 0.065091 Batch F1: 0.8333333333333333
Train Avg Loss  365: 0.071511

Train Avg F1  365: 0.7611885255267609

Val Avg Loss  365: 0.063596

Val Avg F1  365:  0.7900546821599453

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 366
--------------------------------------------------------------
Epoch:  366        1 Batch loss: 0.044986 Batch F1: 0.5
Epoch:  366        2 Batch loss: 0.095328 Batch F1: 0.6666666666666666
Epoch:  366        3 Batch loss: 0.068305 Batch F1: 0.7499999999999999
Epoch:  366        4 Batch loss: 0.094749 Batch F1: 0.35294117647058826
Epoch:  366        5 Batch loss: 0.073299 Batch F1: 0.9090909090909091
Epoch:  366        6 Batch loss: 0.064340 Batch F1: 0.9090909090909091
Epoch:  366        7 Batch loss: 0.062326 Batch F1: 0.923076923076923
Epoch:  366        8 Batch loss: 0.054016 Batch F1: 0.9090909090909091
Epoch:  366        9 Batch loss: 0.064673 Batch F1: 0.8571428571428571
Epoch:  366       10 Batch loss: 0.080460 Batch F1: 0.2222222222222222
Epoch:  366       11 Batch loss: 0.073978 Batch F1: 0.3636363636363636
Epoch:  366       12 Batch loss: 0.080506 Batch F1: 0.6153846153846153
Train Avg Loss  366: 0.071414

Train Avg F1  366: 0.6648619626560802

Val Avg Loss  366: 0.067428

Val Avg F1  366:  0.5696969696969697

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 367
--------------------------------------------------------------
Epoch:  367        1 Batch loss: 0.091685 Batch F1: 0.631578947368421
Epoch:  367        2 Batch loss: 0.072835 Batch F1: 0.7142857142857143
Epoch:  367        3 Batch loss: 0.061350 Batch F1: 0.8750000000000001
Epoch:  367        4 Batch loss: 0.080791 Batch F1: 0.7142857142857143
Epoch:  367        5 Batch loss: 0.055364 Batch F1: 0.8571428571428571
Epoch:  367        6 Batch loss: 0.055315 Batch F1: 0.923076923076923
Epoch:  367        7 Batch loss: 0.075436 Batch F1: 0.6153846153846153
Epoch:  367        8 Batch loss: 0.076982 Batch F1: 0.33333333333333337
Epoch:  367        9 Batch loss: 0.073668 Batch F1: 0.4615384615384615
Epoch:  367       10 Batch loss: 0.061778 Batch F1: 0.7142857142857143
Epoch:  367       11 Batch loss: 0.079474 Batch F1: 0.9285714285714286
Epoch:  367       12 Batch loss: 0.084864 Batch F1: 0.9090909090909091
Train Avg Loss  367: 0.072462

Train Avg F1  367: 0.7231312181970077

Val Avg Loss  367: 0.065006

Val Avg F1  367:  0.915982993988109

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 368
--------------------------------------------------------------
Epoch:  368        1 Batch loss: 0.075802 Batch F1: 0.7999999999999999
Epoch:  368        2 Batch loss: 0.055961 Batch F1: 0.7499999999999999
Epoch:  368        3 Batch loss: 0.080416 Batch F1: 0.5714285714285715
Epoch:  368        4 Batch loss: 0.113810 Batch F1: 0.33333333333333337
Epoch:  368        5 Batch loss: 0.072184 Batch F1: 0.42857142857142855
Epoch:  368        6 Batch loss: 0.078159 Batch F1: 0.6666666666666666
Epoch:  368        7 Batch loss: 0.069668 Batch F1: 0.8235294117647058
Epoch:  368        8 Batch loss: 0.067147 Batch F1: 0.9411764705882353
Epoch:  368        9 Batch loss: 0.061016 Batch F1: 1.0
Epoch:  368       10 Batch loss: 0.052549 Batch F1: 1.0
Epoch:  368       11 Batch loss: 0.065806 Batch F1: 0.8
Epoch:  368       12 Batch loss: 0.071676 Batch F1: 0.7272727272727273
Train Avg Loss  368: 0.072016

Train Avg F1  368: 0.736831550802139

Val Avg Loss  368: 0.067141

Val Avg F1  368:  0.653030303030303

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 369
--------------------------------------------------------------
Epoch:  369        1 Batch loss: 0.044171 Batch F1: 0.33333333333333337
Epoch:  369        2 Batch loss: 0.088173 Batch F1: 0.15384615384615385
Epoch:  369        3 Batch loss: 0.073534 Batch F1: 1.0
Epoch:  369        4 Batch loss: 0.086759 Batch F1: 0.875
Epoch:  369        5 Batch loss: 0.054509 Batch F1: 0.6666666666666666
Epoch:  369        6 Batch loss: 0.094693 Batch F1: 0.0
Epoch:  369        7 Batch loss: 0.055253 Batch F1: 0.6
Epoch:  369        8 Batch loss: 0.099335 Batch F1: 0.375
Epoch:  369        9 Batch loss: 0.065052 Batch F1: 0.923076923076923
Epoch:  369       10 Batch loss: 0.078934 Batch F1: 0.8333333333333333
Epoch:  369       11 Batch loss: 0.085096 Batch F1: 0.7499999999999999
Epoch:  369       12 Batch loss: 0.090312 Batch F1: 0.7777777777777778
Train Avg Loss  369: 0.076319

Train Avg F1  369: 0.6073361823361824

Val Avg Loss  369: 0.064097

Val Avg F1  369:  0.7507936507936508

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 370
--------------------------------------------------------------
Epoch:  370        1 Batch loss: 0.057995 Batch F1: 0.8
Epoch:  370        2 Batch loss: 0.050459 Batch F1: 1.0
Epoch:  370        3 Batch loss: 0.087743 Batch F1: 0.3636363636363636
Epoch:  370        4 Batch loss: 0.069216 Batch F1: 0.5454545454545454
Epoch:  370        5 Batch loss: 0.071263 Batch F1: 0.625
Epoch:  370        6 Batch loss: 0.088198 Batch F1: 0.5
Epoch:  370        7 Batch loss: 0.070508 Batch F1: 0.9333333333333333
Epoch:  370        8 Batch loss: 0.070199 Batch F1: 0.9565217391304348
Epoch:  370        9 Batch loss: 0.063248 Batch F1: 0.8750000000000001
Epoch:  370       10 Batch loss: 0.058497 Batch F1: 0.9473684210526316
Epoch:  370       11 Batch loss: 0.071673 Batch F1: 0.8750000000000001
Epoch:  370       12 Batch loss: 0.075640 Batch F1: 0.875
Train Avg Loss  370: 0.069553

Train Avg F1  370: 0.7746928668839425

Val Avg Loss  370: 0.063568

Val Avg F1  370:  0.9352676309198047

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 371
--------------------------------------------------------------
Epoch:  371        1 Batch loss: 0.054248 Batch F1: 1.0
Epoch:  371        2 Batch loss: 0.074026 Batch F1: 1.0
Epoch:  371        3 Batch loss: 0.094287 Batch F1: 0.7058823529411764
Epoch:  371        4 Batch loss: 0.070931 Batch F1: 0.8235294117647058
Epoch:  371        5 Batch loss: 0.058624 Batch F1: 0.7499999999999999
Epoch:  371        6 Batch loss: 0.063053 Batch F1: 0.7499999999999999
Epoch:  371        7 Batch loss: 0.062925 Batch F1: 0.5
Epoch:  371        8 Batch loss: 0.073688 Batch F1: 0.7058823529411764
Epoch:  371        9 Batch loss: 0.057176 Batch F1: 0.5
Epoch:  371       10 Batch loss: 0.070013 Batch F1: 0.7272727272727273
Epoch:  371       11 Batch loss: 0.067605 Batch F1: 1.0
Epoch:  371       12 Batch loss: 0.061107 Batch F1: 0.8
Train Avg Loss  371: 0.067307

Train Avg F1  371: 0.7718805704099823

Val Avg Loss  371: 0.066184

Val Avg F1  371:  0.8811274509803921

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 372
--------------------------------------------------------------
Epoch:  372        1 Batch loss: 0.090219 Batch F1: 0.8695652173913044
Epoch:  372        2 Batch loss: 0.068237 Batch F1: 0.8235294117647058
Epoch:  372        3 Batch loss: 0.086043 Batch F1: 0.6666666666666666
Epoch:  372        4 Batch loss: 0.061958 Batch F1: 0.9473684210526316
Epoch:  372        5 Batch loss: 0.071415 Batch F1: 0.8571428571428571
Epoch:  372        6 Batch loss: 0.032692 Batch F1: 1.0
Epoch:  372        7 Batch loss: 0.067874 Batch F1: 0.5454545454545454
Epoch:  372        8 Batch loss: 0.072339 Batch F1: 0.9
Epoch:  372        9 Batch loss: 0.065536 Batch F1: 0.5
Epoch:  372       10 Batch loss: 0.109399 Batch F1: 0.14285714285714288
Epoch:  372       11 Batch loss: 0.045842 Batch F1: 1.0
Epoch:  372       12 Batch loss: 0.060675 Batch F1: 0.923076923076923
Train Avg Loss  372: 0.069353

Train Avg F1  372: 0.7646384321172315

Val Avg Loss  372: 0.067479

Val Avg F1  372:  0.9198778195488723

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 373
--------------------------------------------------------------
Epoch:  373        1 Batch loss: 0.061210 Batch F1: 1.0
Epoch:  373        2 Batch loss: 0.058382 Batch F1: 0.8571428571428571
Epoch:  373        3 Batch loss: 0.071328 Batch F1: 0.9523809523809523
Epoch:  373        4 Batch loss: 0.094122 Batch F1: 0.5
Epoch:  373        5 Batch loss: 0.041805 Batch F1: 0.8333333333333333
Epoch:  373        6 Batch loss: 0.080269 Batch F1: 0.5333333333333333
Epoch:  373        7 Batch loss: 0.062955 Batch F1: 0.5454545454545454
Epoch:  373        8 Batch loss: 0.093461 Batch F1: 0.6666666666666666
Epoch:  373        9 Batch loss: 0.078067 Batch F1: 0.9090909090909091
Epoch:  373       10 Batch loss: 0.063472 Batch F1: 1.0
Epoch:  373       11 Batch loss: 0.067991 Batch F1: 0.7499999999999999
Epoch:  373       12 Batch loss: 0.063315 Batch F1: 0.5
Train Avg Loss  373: 0.069698

Train Avg F1  373: 0.7539502164502164

Val Avg Loss  373: 0.062755

Val Avg F1  373:  0.9095996732026144

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 374
--------------------------------------------------------------
Epoch:  374        1 Batch loss: 0.059691 Batch F1: 0.923076923076923
Epoch:  374        2 Batch loss: 0.072866 Batch F1: 0.5714285714285715
Epoch:  374        3 Batch loss: 0.048971 Batch F1: 0.8333333333333333
Epoch:  374        4 Batch loss: 0.103572 Batch F1: 0.18181818181818182
Epoch:  374        5 Batch loss: 0.091053 Batch F1: 0.5882352941176471
Epoch:  374        6 Batch loss: 0.053317 Batch F1: 0.6666666666666666
Epoch:  374        7 Batch loss: 0.052083 Batch F1: 0.6
Epoch:  374        8 Batch loss: 0.070048 Batch F1: 0.8
Epoch:  374        9 Batch loss: 0.074692 Batch F1: 0.8750000000000001
Epoch:  374       10 Batch loss: 0.072193 Batch F1: 0.9523809523809523
Epoch:  374       11 Batch loss: 0.077536 Batch F1: 0.8571428571428571
Epoch:  374       12 Batch loss: 0.062716 Batch F1: 1.0
Train Avg Loss  374: 0.069895

Train Avg F1  374: 0.7374235649970943

Val Avg Loss  374: 0.064277

Val Avg F1  374:  0.6990356325596601

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 375
--------------------------------------------------------------
Epoch:  375        1 Batch loss: 0.068692 Batch F1: 0.7272727272727273
Epoch:  375        2 Batch loss: 0.080262 Batch F1: 0.6086956521739131
Epoch:  375        3 Batch loss: 0.066684 Batch F1: 0.9523809523809523
Epoch:  375        4 Batch loss: 0.069128 Batch F1: 1.0
Epoch:  375        5 Batch loss: 0.062748 Batch F1: 0.8333333333333333
Epoch:  375        6 Batch loss: 0.078653 Batch F1: 0.4615384615384615
Epoch:  375        7 Batch loss: 0.086340 Batch F1: 0.19999999999999998
Epoch:  375        8 Batch loss: 0.063695 Batch F1: 0.0
Epoch:  375        9 Batch loss: 0.079650 Batch F1: 0.0
Epoch:  375       10 Batch loss: 0.079465 Batch F1: 0.6153846153846153
Epoch:  375       11 Batch loss: 0.070003 Batch F1: 0.8333333333333333
Epoch:  375       12 Batch loss: 0.052976 Batch F1: 1.0
Train Avg Loss  375: 0.071525

Train Avg F1  375: 0.6026615896181113

Val Avg Loss  375: 0.063334

Val Avg F1  375:  0.9318452380952381

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 376
--------------------------------------------------------------
Epoch:  376        1 Batch loss: 0.089400 Batch F1: 0.8235294117647058
Epoch:  376        2 Batch loss: 0.063659 Batch F1: 0.7142857142857143
Epoch:  376        3 Batch loss: 0.063778 Batch F1: 0.6666666666666666
Epoch:  376        4 Batch loss: 0.079673 Batch F1: 0.5
Epoch:  376        5 Batch loss: 0.068173 Batch F1: 0.7499999999999999
Epoch:  376        6 Batch loss: 0.066573 Batch F1: 0.7142857142857143
Epoch:  376        7 Batch loss: 0.065270 Batch F1: 0.25
Epoch:  376        8 Batch loss: 0.076326 Batch F1: 0.9523809523809523
Epoch:  376        9 Batch loss: 0.071415 Batch F1: 0.9411764705882353
Epoch:  376       10 Batch loss: 0.065440 Batch F1: 0.8235294117647058
Epoch:  376       11 Batch loss: 0.060185 Batch F1: 0.2857142857142857
Epoch:  376       12 Batch loss: 0.060112 Batch F1: 0.888888888888889
Train Avg Loss  376: 0.069167

Train Avg F1  376: 0.6925381263616557

Val Avg Loss  376: 0.062461

Val Avg F1  376:  0.6466144149967679

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 377
--------------------------------------------------------------
Epoch:  377        1 Batch loss: 0.052480 Batch F1: 0.8571428571428571
Epoch:  377        2 Batch loss: 0.093069 Batch F1: 0.5882352941176471
Epoch:  377        3 Batch loss: 0.080103 Batch F1: 0.3636363636363636
Epoch:  377        4 Batch loss: 0.050798 Batch F1: 0.9090909090909091
Epoch:  377        5 Batch loss: 0.080566 Batch F1: 0.6666666666666666
Epoch:  377        6 Batch loss: 0.063912 Batch F1: 0.9090909090909091
Epoch:  377        7 Batch loss: 0.067606 Batch F1: 0.8421052631578948
Epoch:  377        8 Batch loss: 0.057530 Batch F1: 1.0
Epoch:  377        9 Batch loss: 0.071621 Batch F1: 0.6666666666666666
Epoch:  377       10 Batch loss: 0.052982 Batch F1: 0.7272727272727273
Epoch:  377       11 Batch loss: 0.069715 Batch F1: 0.4615384615384615
Epoch:  377       12 Batch loss: 0.087039 Batch F1: 0.3636363636363636
Train Avg Loss  377: 0.068952

Train Avg F1  377: 0.6962568735014556

Val Avg Loss  377: 0.068245

Val Avg F1  377:  0.7396825396825397

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 378
--------------------------------------------------------------
Epoch:  378        1 Batch loss: 0.042949 Batch F1: 0.888888888888889
Epoch:  378        2 Batch loss: 0.060663 Batch F1: 0.6153846153846153
Epoch:  378        3 Batch loss: 0.084974 Batch F1: 0.782608695652174
Epoch:  378        4 Batch loss: 0.066870 Batch F1: 1.0
Epoch:  378        5 Batch loss: 0.073537 Batch F1: 0.9411764705882353
Epoch:  378        6 Batch loss: 0.094987 Batch F1: 0.761904761904762
Epoch:  378        7 Batch loss: 0.041217 Batch F1: 1.0
Epoch:  378        8 Batch loss: 0.056751 Batch F1: 0.8571428571428571
Epoch:  378        9 Batch loss: 0.094814 Batch F1: 0.4
Epoch:  378       10 Batch loss: 0.064705 Batch F1: 0.6
Epoch:  378       11 Batch loss: 0.073084 Batch F1: 0.6666666666666666
Epoch:  378       12 Batch loss: 0.087189 Batch F1: 0.8571428571428571
Train Avg Loss  378: 0.070145

Train Avg F1  378: 0.7809096511142547

Val Avg Loss  378: 0.067036

Val Avg F1  378:  0.6154532967032967

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 379
--------------------------------------------------------------
Epoch:  379        1 Batch loss: 0.094287 Batch F1: 0.5
Epoch:  379        2 Batch loss: 0.050056 Batch F1: 0.6
Epoch:  379        3 Batch loss: 0.057372 Batch F1: 0.8421052631578948
Epoch:  379        4 Batch loss: 0.069379 Batch F1: 0.7142857142857143
Epoch:  379        5 Batch loss: 0.067429 Batch F1: 0.9090909090909091
Epoch:  379        6 Batch loss: 0.072352 Batch F1: 0.5454545454545454
Epoch:  379        7 Batch loss: 0.065515 Batch F1: 0.6153846153846153
Epoch:  379        8 Batch loss: 0.078661 Batch F1: 0.5882352941176471
Epoch:  379        9 Batch loss: 0.058252 Batch F1: 0.4
Epoch:  379       10 Batch loss: 0.080379 Batch F1: 0.4615384615384615
Epoch:  379       11 Batch loss: 0.061341 Batch F1: 0.7499999999999999
Epoch:  379       12 Batch loss: 0.072745 Batch F1: 0.6
Train Avg Loss  379: 0.068981

Train Avg F1  379: 0.627174566919149

Val Avg Loss  379: 0.063039

Val Avg F1  379:  0.7343358395989975

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 380
--------------------------------------------------------------
Epoch:  380        1 Batch loss: 0.064447 Batch F1: 0.8
Epoch:  380        2 Batch loss: 0.052934 Batch F1: 0.923076923076923
Epoch:  380        3 Batch loss: 0.075835 Batch F1: 0.8571428571428571
Epoch:  380        4 Batch loss: 0.047347 Batch F1: 0.8571428571428571
Epoch:  380        5 Batch loss: 0.067469 Batch F1: 0.6153846153846153
Epoch:  380        6 Batch loss: 0.067841 Batch F1: 0.6
Epoch:  380        7 Batch loss: 0.078893 Batch F1: 0.9166666666666666
Epoch:  380        8 Batch loss: 0.066507 Batch F1: 0.9411764705882353
Epoch:  380        9 Batch loss: 0.060510 Batch F1: 0.8
Epoch:  380       10 Batch loss: 0.068767 Batch F1: 0.8
Epoch:  380       11 Batch loss: 0.052718 Batch F1: 0.8571428571428571
Epoch:  380       12 Batch loss: 0.094538 Batch F1: 0.6153846153846153
Train Avg Loss  380: 0.066484

Train Avg F1  380: 0.7985931552108023

Val Avg Loss  380: 0.063135

Val Avg F1  380:  0.7655677655677655

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 381
--------------------------------------------------------------
Epoch:  381        1 Batch loss: 0.084947 Batch F1: 0.5714285714285715
Epoch:  381        2 Batch loss: 0.057835 Batch F1: 0.6666666666666666
Epoch:  381        3 Batch loss: 0.070747 Batch F1: 0.7777777777777778
Epoch:  381        4 Batch loss: 0.067183 Batch F1: 0.7272727272727273
Epoch:  381        5 Batch loss: 0.047299 Batch F1: 1.0
Epoch:  381        6 Batch loss: 0.054522 Batch F1: 0.8571428571428571
Epoch:  381        7 Batch loss: 0.063541 Batch F1: 0.4
Epoch:  381        8 Batch loss: 0.084081 Batch F1: 0.6666666666666666
Epoch:  381        9 Batch loss: 0.069398 Batch F1: 0.6666666666666666
Epoch:  381       10 Batch loss: 0.073615 Batch F1: 0.7777777777777778
Epoch:  381       11 Batch loss: 0.049755 Batch F1: 0.9333333333333333
Epoch:  381       12 Batch loss: 0.079478 Batch F1: 0.8421052631578948
Train Avg Loss  381: 0.066867

Train Avg F1  381: 0.7405698589909117

Val Avg Loss  381: 0.062166

Val Avg F1  381:  0.9413752913752913

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 382
--------------------------------------------------------------
Epoch:  382        1 Batch loss: 0.047089 Batch F1: 1.0
Epoch:  382        2 Batch loss: 0.068221 Batch F1: 0.7272727272727273
Epoch:  382        3 Batch loss: 0.062745 Batch F1: 0.9090909090909091
Epoch:  382        4 Batch loss: 0.064588 Batch F1: 0.8571428571428571
Epoch:  382        5 Batch loss: 0.069714 Batch F1: 0.7058823529411764
Epoch:  382        6 Batch loss: 0.057255 Batch F1: 0.9473684210526316
Epoch:  382        7 Batch loss: 0.058957 Batch F1: 0.9090909090909091
Epoch:  382        8 Batch loss: 0.088661 Batch F1: 0.7272727272727273
Epoch:  382        9 Batch loss: 0.061848 Batch F1: 0.7692307692307693
Epoch:  382       10 Batch loss: 0.077008 Batch F1: 0.7692307692307693
Epoch:  382       11 Batch loss: 0.093279 Batch F1: 0.761904761904762
Epoch:  382       12 Batch loss: 0.059938 Batch F1: 0.7499999999999999
Train Avg Loss  382: 0.067442

Train Avg F1  382: 0.8194572670191866

Val Avg Loss  382: 0.062903

Val Avg F1  382:  0.9212503183091418

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 383
--------------------------------------------------------------
Epoch:  383        1 Batch loss: 0.054187 Batch F1: 1.0
Epoch:  383        2 Batch loss: 0.060088 Batch F1: 0.8333333333333333
Epoch:  383        3 Batch loss: 0.067336 Batch F1: 0.8
Epoch:  383        4 Batch loss: 0.060526 Batch F1: 0.923076923076923
Epoch:  383        5 Batch loss: 0.061908 Batch F1: 0.7142857142857143
Epoch:  383        6 Batch loss: 0.065882 Batch F1: 0.7692307692307693
Epoch:  383        7 Batch loss: 0.079400 Batch F1: 0.6666666666666666
Epoch:  383        8 Batch loss: 0.081965 Batch F1: 0.4615384615384615
Epoch:  383        9 Batch loss: 0.055346 Batch F1: 0.923076923076923
Epoch:  383       10 Batch loss: 0.067986 Batch F1: 0.7692307692307693
Epoch:  383       11 Batch loss: 0.086663 Batch F1: 0.7272727272727273
Epoch:  383       12 Batch loss: 0.052291 Batch F1: 0.7499999999999999
Train Avg Loss  383: 0.066131

Train Avg F1  383: 0.7781426906426906

Val Avg Loss  383: 0.063352

Val Avg F1  383:  0.7589285714285714

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 384
--------------------------------------------------------------
Epoch:  384        1 Batch loss: 0.064351 Batch F1: 0.2857142857142857
Epoch:  384        2 Batch loss: 0.070445 Batch F1: 0.7058823529411764
Epoch:  384        3 Batch loss: 0.065408 Batch F1: 0.7777777777777778
Epoch:  384        4 Batch loss: 0.062935 Batch F1: 0.4444444444444445
Epoch:  384        5 Batch loss: 0.075533 Batch F1: 0.5714285714285715
Epoch:  384        6 Batch loss: 0.061824 Batch F1: 0.8421052631578948
Epoch:  384        7 Batch loss: 0.082810 Batch F1: 0.3076923076923077
Epoch:  384        8 Batch loss: 0.048482 Batch F1: 0.8
Epoch:  384        9 Batch loss: 0.054128 Batch F1: 0.6
Epoch:  384       10 Batch loss: 0.077455 Batch F1: 0.42857142857142855
Epoch:  384       11 Batch loss: 0.059085 Batch F1: 0.7692307692307693
Epoch:  384       12 Batch loss: 0.060713 Batch F1: 0.7272727272727273
Train Avg Loss  384: 0.065264

Train Avg F1  384: 0.605009994019282

Val Avg Loss  384: 0.061906

Val Avg F1  384:  0.9403679653679654

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 385
--------------------------------------------------------------
Epoch:  385        1 Batch loss: 0.056659 Batch F1: 0.8571428571428571
Epoch:  385        2 Batch loss: 0.060815 Batch F1: 0.9090909090909091
Epoch:  385        3 Batch loss: 0.058915 Batch F1: 0.7499999999999999
Epoch:  385        4 Batch loss: 0.046920 Batch F1: 0.8750000000000001
Epoch:  385        5 Batch loss: 0.065137 Batch F1: 1.0
Epoch:  385        6 Batch loss: 0.072407 Batch F1: 0.4444444444444445
Epoch:  385        7 Batch loss: 0.067518 Batch F1: 0.8235294117647058
Epoch:  385        8 Batch loss: 0.075112 Batch F1: 0.625
Epoch:  385        9 Batch loss: 0.071000 Batch F1: 0.7368421052631579
Epoch:  385       10 Batch loss: 0.067158 Batch F1: 0.9565217391304348
Epoch:  385       11 Batch loss: 0.068556 Batch F1: 0.9473684210526316
Epoch:  385       12 Batch loss: 0.094501 Batch F1: 0.7999999999999999
Train Avg Loss  385: 0.067058

Train Avg F1  385: 0.810411657324095

Val Avg Loss  385: 0.063741

Val Avg F1  385:  0.9147727272727273

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 386
--------------------------------------------------------------
Epoch:  386        1 Batch loss: 0.059227 Batch F1: 0.8571428571428571
Epoch:  386        2 Batch loss: 0.051078 Batch F1: 0.5714285714285715
Epoch:  386        3 Batch loss: 0.056632 Batch F1: 0.8571428571428571
Epoch:  386        4 Batch loss: 0.072117 Batch F1: 0.5882352941176471
Epoch:  386        5 Batch loss: 0.072078 Batch F1: 0.5
Epoch:  386        6 Batch loss: 0.068788 Batch F1: 0.888888888888889
Epoch:  386        7 Batch loss: 0.083717 Batch F1: 0.8421052631578948
Epoch:  386        8 Batch loss: 0.075230 Batch F1: 0.9090909090909091
Epoch:  386        9 Batch loss: 0.064896 Batch F1: 0.9565217391304348
Epoch:  386       10 Batch loss: 0.063575 Batch F1: 1.0
Epoch:  386       11 Batch loss: 0.074991 Batch F1: 0.6666666666666666
Epoch:  386       12 Batch loss: 0.064763 Batch F1: 0.5714285714285715
Train Avg Loss  386: 0.067258

Train Avg F1  386: 0.7673876348496081

Val Avg Loss  386: 0.065442

Val Avg F1  386:  0.6128342245989304

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 387
--------------------------------------------------------------
Epoch:  387        1 Batch loss: 0.043679 Batch F1: 0.8
Epoch:  387        2 Batch loss: 0.100554 Batch F1: 0.3076923076923077
Epoch:  387        3 Batch loss: 0.045883 Batch F1: 0.5
Epoch:  387        4 Batch loss: 0.063512 Batch F1: 0.6666666666666666
Epoch:  387        5 Batch loss: 0.050186 Batch F1: 0.8
Epoch:  387        6 Batch loss: 0.076093 Batch F1: 0.8750000000000001
Epoch:  387        7 Batch loss: 0.054316 Batch F1: 0.923076923076923
Epoch:  387        8 Batch loss: 0.074158 Batch F1: 0.7142857142857143
Epoch:  387        9 Batch loss: 0.093018 Batch F1: 0.8695652173913044
Epoch:  387       10 Batch loss: 0.061224 Batch F1: 0.4444444444444445
Epoch:  387       11 Batch loss: 0.081202 Batch F1: 0.42857142857142855
Epoch:  387       12 Batch loss: 0.078704 Batch F1: 0.33333333333333337
Train Avg Loss  387: 0.068544

Train Avg F1  387: 0.6385530029551769

Val Avg Loss  387: 0.062502

Val Avg F1  387:  0.8017857142857143

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 388
--------------------------------------------------------------
Epoch:  388        1 Batch loss: 0.062721 Batch F1: 0.9
Epoch:  388        2 Batch loss: 0.060350 Batch F1: 1.0
Epoch:  388        3 Batch loss: 0.094314 Batch F1: 0.8695652173913044
Epoch:  388        4 Batch loss: 0.066736 Batch F1: 0.8
Epoch:  388        5 Batch loss: 0.062709 Batch F1: 0.9473684210526316
Epoch:  388        6 Batch loss: 0.074836 Batch F1: 0.888888888888889
Epoch:  388        7 Batch loss: 0.052778 Batch F1: 0.923076923076923
Epoch:  388        8 Batch loss: 0.079303 Batch F1: 0.8181818181818181
Epoch:  388        9 Batch loss: 0.074312 Batch F1: 0.7999999999999999
Epoch:  388       10 Batch loss: 0.074763 Batch F1: 0.9411764705882353
Epoch:  388       11 Batch loss: 0.046883 Batch F1: 0.923076923076923
Epoch:  388       12 Batch loss: 0.043736 Batch F1: 0.7499999999999999
Train Avg Loss  388: 0.066120

Train Avg F1  388: 0.880111221854727

Val Avg Loss  388: 0.063201

Val Avg F1  388:  0.7166281087333719

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 389
--------------------------------------------------------------
Epoch:  389        1 Batch loss: 0.066099 Batch F1: 0.5
Epoch:  389        2 Batch loss: 0.089814 Batch F1: 0.5
Epoch:  389        3 Batch loss: 0.063618 Batch F1: 0.7499999999999999
Epoch:  389        4 Batch loss: 0.110320 Batch F1: 0.2666666666666667
Epoch:  389        5 Batch loss: 0.066065 Batch F1: 0.888888888888889
Epoch:  389        6 Batch loss: 0.055670 Batch F1: 1.0
Epoch:  389        7 Batch loss: 0.061987 Batch F1: 0.888888888888889
Epoch:  389        8 Batch loss: 0.076420 Batch F1: 0.88
Epoch:  389        9 Batch loss: 0.054918 Batch F1: 1.0
Epoch:  389       10 Batch loss: 0.068195 Batch F1: 0.9523809523809523
Epoch:  389       11 Batch loss: 0.046088 Batch F1: 1.0
Epoch:  389       12 Batch loss: 0.059646 Batch F1: 0.33333333333333337
Train Avg Loss  389: 0.068237

Train Avg F1  389: 0.7466798941798941

Val Avg Loss  389: 0.068252

Val Avg F1  389:  0.5910364145658262

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 390
--------------------------------------------------------------
Epoch:  390        1 Batch loss: 0.064876 Batch F1: 0.5
Epoch:  390        2 Batch loss: 0.052765 Batch F1: 0.8
Epoch:  390        3 Batch loss: 0.070109 Batch F1: 0.7142857142857143
Epoch:  390        4 Batch loss: 0.064465 Batch F1: 0.5454545454545454
Epoch:  390        5 Batch loss: 0.042448 Batch F1: 1.0
Epoch:  390        6 Batch loss: 0.099776 Batch F1: 0.4
Epoch:  390        7 Batch loss: 0.066142 Batch F1: 0.7692307692307693
Epoch:  390        8 Batch loss: 0.067590 Batch F1: 0.8571428571428572
Epoch:  390        9 Batch loss: 0.071284 Batch F1: 0.823529411764706
Epoch:  390       10 Batch loss: 0.075187 Batch F1: 0.4615384615384615
Epoch:  390       11 Batch loss: 0.070771 Batch F1: 0.5333333333333333
Epoch:  390       12 Batch loss: 0.082109 Batch F1: 0.8
Train Avg Loss  390: 0.068960

Train Avg F1  390: 0.6837095910625322

Val Avg Loss  390: 0.063252

Val Avg F1  390:  0.8830753353973169

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 391
--------------------------------------------------------------
Epoch:  391        1 Batch loss: 0.066809 Batch F1: 0.8181818181818182
Epoch:  391        2 Batch loss: 0.069407 Batch F1: 0.8750000000000001
Epoch:  391        3 Batch loss: 0.054989 Batch F1: 1.0
Epoch:  391        4 Batch loss: 0.056173 Batch F1: 0.923076923076923
Epoch:  391        5 Batch loss: 0.062870 Batch F1: 0.8
Epoch:  391        6 Batch loss: 0.067200 Batch F1: 0.7142857142857143
Epoch:  391        7 Batch loss: 0.069195 Batch F1: 0.8333333333333333
Epoch:  391        8 Batch loss: 0.072879 Batch F1: 0.8
Epoch:  391        9 Batch loss: 0.074077 Batch F1: 0.6666666666666666
Epoch:  391       10 Batch loss: 0.075334 Batch F1: 0.7058823529411764
Epoch:  391       11 Batch loss: 0.078936 Batch F1: 0.9
Epoch:  391       12 Batch loss: 0.054527 Batch F1: 0.5714285714285715
Train Avg Loss  391: 0.066866

Train Avg F1  391: 0.8006546149928503

Val Avg Loss  391: 0.064353

Val Avg F1  391:  0.8612839366515836

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 392
--------------------------------------------------------------
Epoch:  392        1 Batch loss: 0.060356 Batch F1: 0.888888888888889
Epoch:  392        2 Batch loss: 0.062578 Batch F1: 0.8
Epoch:  392        3 Batch loss: 0.065932 Batch F1: 1.0
Epoch:  392        4 Batch loss: 0.076980 Batch F1: 0.5882352941176471
Epoch:  392        5 Batch loss: 0.068008 Batch F1: 0.8
Epoch:  392        6 Batch loss: 0.079148 Batch F1: 0.5
Epoch:  392        7 Batch loss: 0.071426 Batch F1: 0.8750000000000001
Epoch:  392        8 Batch loss: 0.066408 Batch F1: 0.8571428571428571
Epoch:  392        9 Batch loss: 0.065754 Batch F1: 0.8
Epoch:  392       10 Batch loss: 0.076321 Batch F1: 0.8
Epoch:  392       11 Batch loss: 0.058242 Batch F1: 1.0
Epoch:  392       12 Batch loss: 0.077944 Batch F1: 0.8
Train Avg Loss  392: 0.069091

Train Avg F1  392: 0.8091055866791161

Val Avg Loss  392: 0.062445

Val Avg F1  392:  0.8553163322185061

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 393
--------------------------------------------------------------
Epoch:  393        1 Batch loss: 0.060008 Batch F1: 0.8333333333333333
Epoch:  393        2 Batch loss: 0.061999 Batch F1: 0.5454545454545454
Epoch:  393        3 Batch loss: 0.076943 Batch F1: 0.2222222222222222
Epoch:  393        4 Batch loss: 0.084784 Batch F1: 0.5714285714285715
Epoch:  393        5 Batch loss: 0.072660 Batch F1: 0.8
Epoch:  393        6 Batch loss: 0.086868 Batch F1: 0.8695652173913044
Epoch:  393        7 Batch loss: 0.067986 Batch F1: 1.0
Epoch:  393        8 Batch loss: 0.061272 Batch F1: 1.0
Epoch:  393        9 Batch loss: 0.059205 Batch F1: 0.8571428571428571
Epoch:  393       10 Batch loss: 0.071654 Batch F1: 0.8695652173913044
Epoch:  393       11 Batch loss: 0.049731 Batch F1: 0.6666666666666666
Epoch:  393       12 Batch loss: 0.053638 Batch F1: 0.4
Train Avg Loss  393: 0.067229

Train Avg F1  393: 0.7196148859192338

Val Avg Loss  393: 0.070582

Val Avg F1  393:  0.3190359477124183

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 394
--------------------------------------------------------------
Epoch:  394        1 Batch loss: 0.079215 Batch F1: 0.19999999999999998
Epoch:  394        2 Batch loss: 0.073208 Batch F1: 0.5
Epoch:  394        3 Batch loss: 0.055553 Batch F1: 0.7272727272727273
Epoch:  394        4 Batch loss: 0.046020 Batch F1: 0.6666666666666666
Epoch:  394        5 Batch loss: 0.072504 Batch F1: 0.7777777777777778
Epoch:  394        6 Batch loss: 0.079483 Batch F1: 0.8695652173913044
Epoch:  394        7 Batch loss: 0.049606 Batch F1: 0.7499999999999999
Epoch:  394        8 Batch loss: 0.064324 Batch F1: 0.7142857142857143
Epoch:  394        9 Batch loss: 0.081898 Batch F1: 0.8333333333333333
Epoch:  394       10 Batch loss: 0.064116 Batch F1: 0.7692307692307693
Epoch:  394       11 Batch loss: 0.078017 Batch F1: 0.8
Epoch:  394       12 Batch loss: 0.063330 Batch F1: 0.8333333333333333
Train Avg Loss  394: 0.067273

Train Avg F1  394: 0.7034554616076355

Val Avg Loss  394: 0.062010

Val Avg F1  394:  0.8313624937154349

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 395
--------------------------------------------------------------
Epoch:  395        1 Batch loss: 0.047812 Batch F1: 1.0
Epoch:  395        2 Batch loss: 0.054229 Batch F1: 0.8333333333333333
Epoch:  395        3 Batch loss: 0.069064 Batch F1: 0.6666666666666666
Epoch:  395        4 Batch loss: 0.060821 Batch F1: 0.5454545454545454
Epoch:  395        5 Batch loss: 0.058367 Batch F1: 0.8421052631578948
Epoch:  395        6 Batch loss: 0.068660 Batch F1: 0.6666666666666666
Epoch:  395        7 Batch loss: 0.098292 Batch F1: 0.2857142857142857
Epoch:  395        8 Batch loss: 0.041959 Batch F1: 1.0
Epoch:  395        9 Batch loss: 0.097273 Batch F1: 0.631578947368421
Epoch:  395       10 Batch loss: 0.083817 Batch F1: 0.8
Epoch:  395       11 Batch loss: 0.066451 Batch F1: 0.8571428571428572
Epoch:  395       12 Batch loss: 0.059092 Batch F1: 1.0
Train Avg Loss  395: 0.067153

Train Avg F1  395: 0.7607218804587226

Val Avg Loss  395: 0.061579

Val Avg F1  395:  0.8468325791855202

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 396
--------------------------------------------------------------
Epoch:  396        1 Batch loss: 0.065491 Batch F1: 0.9565217391304348
Epoch:  396        2 Batch loss: 0.081465 Batch F1: 0.8421052631578948
Epoch:  396        3 Batch loss: 0.048676 Batch F1: 0.888888888888889
Epoch:  396        4 Batch loss: 0.092387 Batch F1: 0.782608695652174
Epoch:  396        5 Batch loss: 0.063924 Batch F1: 0.8
Epoch:  396        6 Batch loss: 0.059759 Batch F1: 0.9411764705882353
Epoch:  396        7 Batch loss: 0.057465 Batch F1: 0.9473684210526316
Epoch:  396        8 Batch loss: 0.081944 Batch F1: 0.888888888888889
Epoch:  396        9 Batch loss: 0.062320 Batch F1: 0.923076923076923
Epoch:  396       10 Batch loss: 0.053451 Batch F1: 0.8
Epoch:  396       11 Batch loss: 0.068679 Batch F1: 0.7692307692307693
Epoch:  396       12 Batch loss: 0.065779 Batch F1: 0.7272727272727273
Train Avg Loss  396: 0.066778

Train Avg F1  396: 0.8555948989116308

Val Avg Loss  396: 0.069296

Val Avg F1  396:  0.6369047619047619

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 397
--------------------------------------------------------------
Epoch:  397        1 Batch loss: 0.055582 Batch F1: 0.5714285714285715
Epoch:  397        2 Batch loss: 0.062573 Batch F1: 0.6
Epoch:  397        3 Batch loss: 0.069576 Batch F1: 0.25
Epoch:  397        4 Batch loss: 0.091762 Batch F1: 0.72
Epoch:  397        5 Batch loss: 0.076946 Batch F1: 0.8571428571428572
Epoch:  397        6 Batch loss: 0.075665 Batch F1: 0.923076923076923
Epoch:  397        7 Batch loss: 0.059021 Batch F1: 1.0
Epoch:  397        8 Batch loss: 0.065466 Batch F1: 0.6153846153846153
Epoch:  397        9 Batch loss: 0.094412 Batch F1: 0.35294117647058826
Epoch:  397       10 Batch loss: 0.052847 Batch F1: 0.9090909090909091
Epoch:  397       11 Batch loss: 0.086682 Batch F1: 0.5
Epoch:  397       12 Batch loss: 0.109602 Batch F1: 0.4
Train Avg Loss  397: 0.075011

Train Avg F1  397: 0.641588754382872

Val Avg Loss  397: 0.071197

Val Avg F1  397:  0.8711309523809524

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 398
--------------------------------------------------------------
Epoch:  398        1 Batch loss: 0.102078 Batch F1: 0.8181818181818181
Epoch:  398        2 Batch loss: 0.090032 Batch F1: 0.9090909090909091
Epoch:  398        3 Batch loss: 0.067523 Batch F1: 1.0
Epoch:  398        4 Batch loss: 0.076565 Batch F1: 0.7499999999999999
Epoch:  398        5 Batch loss: 0.071243 Batch F1: 0.4
Epoch:  398        6 Batch loss: 0.061505 Batch F1: 0.6
Epoch:  398        7 Batch loss: 0.072711 Batch F1: 0.7058823529411764
Epoch:  398        8 Batch loss: 0.043548 Batch F1: 0.5
Epoch:  398        9 Batch loss: 0.061700 Batch F1: 0.5454545454545454
Epoch:  398       10 Batch loss: 0.063142 Batch F1: 0.5454545454545454
Epoch:  398       11 Batch loss: 0.074113 Batch F1: 0.625
Epoch:  398       12 Batch loss: 0.074665 Batch F1: 0.888888888888889
Train Avg Loss  398: 0.071569

Train Avg F1  398: 0.6906627550009903

Val Avg Loss  398: 0.069705

Val Avg F1  398:  0.9254726890756304

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 399
--------------------------------------------------------------
Epoch:  399        1 Batch loss: 0.076687 Batch F1: 0.9523809523809523
Epoch:  399        2 Batch loss: 0.078404 Batch F1: 0.7058823529411764
Epoch:  399        3 Batch loss: 0.056704 Batch F1: 0.5
Epoch:  399        4 Batch loss: 0.077803 Batch F1: 0.5333333333333333
Epoch:  399        5 Batch loss: 0.055543 Batch F1: 0.9411764705882353
Epoch:  399        6 Batch loss: 0.091057 Batch F1: 0.6666666666666666
Epoch:  399        7 Batch loss: 0.065888 Batch F1: 0.888888888888889
Epoch:  399        8 Batch loss: 0.062903 Batch F1: 0.8235294117647058
Epoch:  399        9 Batch loss: 0.054675 Batch F1: 0.8571428571428571
Epoch:  399       10 Batch loss: 0.069776 Batch F1: 0.3636363636363636
Epoch:  399       11 Batch loss: 0.042585 Batch F1: 0.5714285714285715
Epoch:  399       12 Batch loss: 0.074553 Batch F1: 0.7777777777777778
Train Avg Loss  399: 0.067215

Train Avg F1  399: 0.7151536372124606

Val Avg Loss  399: 0.063289

Val Avg F1  399:  0.5970588235294118

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 400
--------------------------------------------------------------
Epoch:  400        1 Batch loss: 0.069898 Batch F1: 0.7058823529411764
Epoch:  400        2 Batch loss: 0.064176 Batch F1: 0.9090909090909091
Epoch:  400        3 Batch loss: 0.053267 Batch F1: 0.6666666666666666
Epoch:  400        4 Batch loss: 0.088366 Batch F1: 0.5882352941176471
Epoch:  400        5 Batch loss: 0.049785 Batch F1: 0.33333333333333337
Epoch:  400        6 Batch loss: 0.096023 Batch F1: 0.375
Epoch:  400        7 Batch loss: 0.064536 Batch F1: 0.6666666666666666
Epoch:  400        8 Batch loss: 0.057233 Batch F1: 0.6666666666666666
Epoch:  400        9 Batch loss: 0.069017 Batch F1: 0.8181818181818181
Epoch:  400       10 Batch loss: 0.055281 Batch F1: 0.6
Epoch:  400       11 Batch loss: 0.074900 Batch F1: 0.9333333333333333
Epoch:  400       12 Batch loss: 0.073317 Batch F1: 0.9
Train Avg Loss  400: 0.067983

Train Avg F1  400: 0.6802547534165182

Val Avg Loss  400: 0.064841

Val Avg F1  400:  0.9328648325358853

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 401
--------------------------------------------------------------
Epoch:  401        1 Batch loss: 0.055912 Batch F1: 1.0
Epoch:  401        2 Batch loss: 0.050508 Batch F1: 0.9090909090909091
Epoch:  401        3 Batch loss: 0.098821 Batch F1: 0.5882352941176471
Epoch:  401        4 Batch loss: 0.108974 Batch F1: 0.5714285714285715
Epoch:  401        5 Batch loss: 0.060177 Batch F1: 0.7499999999999999
Epoch:  401        6 Batch loss: 0.078520 Batch F1: 0.888888888888889
Epoch:  401        7 Batch loss: 0.077844 Batch F1: 0.823529411764706
Epoch:  401        8 Batch loss: 0.069102 Batch F1: 0.9333333333333333
Epoch:  401        9 Batch loss: 0.056146 Batch F1: 0.8
Epoch:  401       10 Batch loss: 0.051364 Batch F1: 0.7272727272727273
Epoch:  401       11 Batch loss: 0.083445 Batch F1: 0.631578947368421
Epoch:  401       12 Batch loss: 0.042979 Batch F1: 0.5
Train Avg Loss  401: 0.069483

Train Avg F1  401: 0.7602798402721004

Val Avg Loss  401: 0.063815

Val Avg F1  401:  0.7962251564225249

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 402
--------------------------------------------------------------
Epoch:  402        1 Batch loss: 0.071428 Batch F1: 0.7499999999999999
Epoch:  402        2 Batch loss: 0.092136 Batch F1: 0.5555555555555556
Epoch:  402        3 Batch loss: 0.061423 Batch F1: 0.9333333333333333
Epoch:  402        4 Batch loss: 0.059745 Batch F1: 0.923076923076923
Epoch:  402        5 Batch loss: 0.091376 Batch F1: 0.9375
Epoch:  402        6 Batch loss: 0.058918 Batch F1: 1.0
Epoch:  402        7 Batch loss: 0.072642 Batch F1: 0.7272727272727272
Epoch:  402        8 Batch loss: 0.071806 Batch F1: 0.8571428571428571
Epoch:  402        9 Batch loss: 0.067574 Batch F1: 0.9333333333333333
Epoch:  402       10 Batch loss: 0.058860 Batch F1: 0.6666666666666666
Epoch:  402       11 Batch loss: 0.063809 Batch F1: 0.4
Epoch:  402       12 Batch loss: 0.059777 Batch F1: 0.7272727272727273
Train Avg Loss  402: 0.069124

Train Avg F1  402: 0.7842628436378436

Val Avg Loss  402: 0.067221

Val Avg F1  402:  0.5811965811965811

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 403
--------------------------------------------------------------
Epoch:  403        1 Batch loss: 0.081045 Batch F1: 0.6666666666666666
Epoch:  403        2 Batch loss: 0.059888 Batch F1: 0.8
Epoch:  403        3 Batch loss: 0.076501 Batch F1: 0.9565217391304348
Epoch:  403        4 Batch loss: 0.079393 Batch F1: 0.9333333333333333
Epoch:  403        5 Batch loss: 0.073226 Batch F1: 1.0
Epoch:  403        6 Batch loss: 0.071015 Batch F1: 0.5
Epoch:  403        7 Batch loss: 0.082380 Batch F1: 0.5714285714285715
Epoch:  403        8 Batch loss: 0.102807 Batch F1: 0.4
Epoch:  403        9 Batch loss: 0.065319 Batch F1: 0.7499999999999999
Epoch:  403       10 Batch loss: 0.061323 Batch F1: 0.9411764705882353
Epoch:  403       11 Batch loss: 0.059943 Batch F1: 1.0
Epoch:  403       12 Batch loss: 0.055905 Batch F1: 1.0
Train Avg Loss  403: 0.072395

Train Avg F1  403: 0.7932605650956036

Val Avg Loss  403: 0.068598

Val Avg F1  403:  0.6054334554334555

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 404
--------------------------------------------------------------
Epoch:  404        1 Batch loss: 0.104989 Batch F1: 0.5263157894736842
Epoch:  404        2 Batch loss: 0.058261 Batch F1: 0.9411764705882353
Epoch:  404        3 Batch loss: 0.072451 Batch F1: 1.0
Epoch:  404        4 Batch loss: 0.063437 Batch F1: 0.923076923076923
Epoch:  404        5 Batch loss: 0.073482 Batch F1: 0.9090909090909091
Epoch:  404        6 Batch loss: 0.055380 Batch F1: 0.8750000000000001
Epoch:  404        7 Batch loss: 0.069929 Batch F1: 0.4615384615384615
Epoch:  404        8 Batch loss: 0.093033 Batch F1: 0.8
Epoch:  404        9 Batch loss: 0.079614 Batch F1: 0.7777777777777778
Epoch:  404       10 Batch loss: 0.054374 Batch F1: 0.7499999999999999
Epoch:  404       11 Batch loss: 0.068683 Batch F1: 0.5454545454545454
Epoch:  404       12 Batch loss: 0.054558 Batch F1: 0.7692307692307693
Train Avg Loss  404: 0.070683

Train Avg F1  404: 0.7732218038526089

Val Avg Loss  404: 0.065417

Val Avg F1  404:  0.6478937728937728

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 405
--------------------------------------------------------------
Epoch:  405        1 Batch loss: 0.066264 Batch F1: 0.4615384615384615
Epoch:  405        2 Batch loss: 0.088555 Batch F1: 0.8
Epoch:  405        3 Batch loss: 0.074900 Batch F1: 0.9090909090909091
Epoch:  405        4 Batch loss: 0.060833 Batch F1: 0.8571428571428571
Epoch:  405        5 Batch loss: 0.065608 Batch F1: 0.4444444444444444
Epoch:  405        6 Batch loss: 0.065083 Batch F1: 0.25
Epoch:  405        7 Batch loss: 0.067024 Batch F1: 0.5454545454545454
Epoch:  405        8 Batch loss: 0.070408 Batch F1: 0.6153846153846153
Epoch:  405        9 Batch loss: 0.056093 Batch F1: 1.0
Epoch:  405       10 Batch loss: 0.066268 Batch F1: 0.9473684210526316
Epoch:  405       11 Batch loss: 0.086291 Batch F1: 0.7272727272727272
Epoch:  405       12 Batch loss: 0.101407 Batch F1: 0.5555555555555556
Train Avg Loss  405: 0.072395

Train Avg F1  405: 0.6761043780780623

Val Avg Loss  405: 0.066546

Val Avg F1  405:  0.6256410256410257

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 406
--------------------------------------------------------------
Epoch:  406        1 Batch loss: 0.086116 Batch F1: 0.5333333333333333
Epoch:  406        2 Batch loss: 0.062833 Batch F1: 0.7142857142857143
Epoch:  406        3 Batch loss: 0.068780 Batch F1: 0.8750000000000001
Epoch:  406        4 Batch loss: 0.060207 Batch F1: 0.8333333333333333
Epoch:  406        5 Batch loss: 0.065673 Batch F1: 0.8
Epoch:  406        6 Batch loss: 0.072557 Batch F1: 0.6153846153846153
Epoch:  406        7 Batch loss: 0.065429 Batch F1: 0.0
Epoch:  406        8 Batch loss: 0.073970 Batch F1: 0.631578947368421
Epoch:  406        9 Batch loss: 0.079906 Batch F1: 0.4615384615384615
Epoch:  406       10 Batch loss: 0.079603 Batch F1: 0.7058823529411764
Epoch:  406       11 Batch loss: 0.086655 Batch F1: 0.6153846153846153
Epoch:  406       12 Batch loss: 0.055464 Batch F1: 0.9333333333333333
Train Avg Loss  406: 0.071433

Train Avg F1  406: 0.6432545589085836

Val Avg Loss  406: 0.067822

Val Avg F1  406:  0.9364988558352403

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 407
--------------------------------------------------------------
Epoch:  407        1 Batch loss: 0.075280 Batch F1: 0.9333333333333333
Epoch:  407        2 Batch loss: 0.064921 Batch F1: 0.7272727272727273
Epoch:  407        3 Batch loss: 0.056563 Batch F1: 0.9473684210526316
Epoch:  407        4 Batch loss: 0.082323 Batch F1: 0.42857142857142855
Epoch:  407        5 Batch loss: 0.071179 Batch F1: 0.5714285714285715
Epoch:  407        6 Batch loss: 0.086038 Batch F1: 0.6666666666666666
Epoch:  407        7 Batch loss: 0.054719 Batch F1: 0.9090909090909091
Epoch:  407        8 Batch loss: 0.059817 Batch F1: 1.0
Epoch:  407        9 Batch loss: 0.060702 Batch F1: 0.9473684210526316
Epoch:  407       10 Batch loss: 0.079635 Batch F1: 0.888888888888889
Epoch:  407       11 Batch loss: 0.068110 Batch F1: 0.8421052631578948
Epoch:  407       12 Batch loss: 0.064181 Batch F1: 0.7499999999999999
Train Avg Loss  407: 0.068622

Train Avg F1  407: 0.8010078858763071

Val Avg Loss  407: 0.062326

Val Avg F1  407:  0.8553675856307434

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 408
--------------------------------------------------------------
Epoch:  408        1 Batch loss: 0.090946 Batch F1: 0.8
Epoch:  408        2 Batch loss: 0.069547 Batch F1: 0.9090909090909091
Epoch:  408        3 Batch loss: 0.059208 Batch F1: 0.9411764705882353
Epoch:  408        4 Batch loss: 0.063236 Batch F1: 0.9411764705882353
Epoch:  408        5 Batch loss: 0.070923 Batch F1: 0.8333333333333333
Epoch:  408        6 Batch loss: 0.064152 Batch F1: 0.8571428571428571
Epoch:  408        7 Batch loss: 0.060595 Batch F1: 0.888888888888889
Epoch:  408        8 Batch loss: 0.054137 Batch F1: 0.4444444444444445
Epoch:  408        9 Batch loss: 0.070165 Batch F1: 0.5
Epoch:  408       10 Batch loss: 0.084876 Batch F1: 0.5263157894736842
Epoch:  408       11 Batch loss: 0.053019 Batch F1: 0.6666666666666666
Epoch:  408       12 Batch loss: 0.066854 Batch F1: 0.7499999999999999
Train Avg Loss  408: 0.067305

Train Avg F1  408: 0.7548529858514379

Val Avg Loss  408: 0.064117

Val Avg F1  408:  0.8074175824175824

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 409
--------------------------------------------------------------
Epoch:  409        1 Batch loss: 0.062672 Batch F1: 0.7692307692307692
Epoch:  409        2 Batch loss: 0.067978 Batch F1: 0.2857142857142857
Epoch:  409        3 Batch loss: 0.087601 Batch F1: 0.6399999999999999
Epoch:  409        4 Batch loss: 0.061917 Batch F1: 0.888888888888889
Epoch:  409        5 Batch loss: 0.071868 Batch F1: 0.9411764705882353
Epoch:  409        6 Batch loss: 0.043027 Batch F1: 0.8
Epoch:  409        7 Batch loss: 0.067499 Batch F1: 0.8750000000000001
Epoch:  409        8 Batch loss: 0.067782 Batch F1: 0.5714285714285715
Epoch:  409        9 Batch loss: 0.062587 Batch F1: 0.6666666666666666
Epoch:  409       10 Batch loss: 0.079198 Batch F1: 0.4
Epoch:  409       11 Batch loss: 0.067724 Batch F1: 0.46153846153846156
Epoch:  409       12 Batch loss: 0.080945 Batch F1: 0.75
Train Avg Loss  409: 0.068400

Train Avg F1  409: 0.6708036761713233

Val Avg Loss  409: 0.064784

Val Avg F1  409:  0.8968876518218624

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 410
--------------------------------------------------------------
Epoch:  410        1 Batch loss: 0.080840 Batch F1: 0.9600000000000001
Epoch:  410        2 Batch loss: 0.079406 Batch F1: 0.9565217391304348
Epoch:  410        3 Batch loss: 0.081577 Batch F1: 0.8421052631578948
Epoch:  410        4 Batch loss: 0.067085 Batch F1: 0.7999999999999999
Epoch:  410        5 Batch loss: 0.094565 Batch F1: 0.631578947368421
Epoch:  410        6 Batch loss: 0.069687 Batch F1: 0.7058823529411764
Epoch:  410        7 Batch loss: 0.049614 Batch F1: 0.9333333333333333
Epoch:  410        8 Batch loss: 0.072005 Batch F1: 0.9565217391304348
Epoch:  410        9 Batch loss: 0.053569 Batch F1: 0.888888888888889
Epoch:  410       10 Batch loss: 0.046507 Batch F1: 0.8571428571428571
Epoch:  410       11 Batch loss: 0.065173 Batch F1: 0.6666666666666666
Epoch:  410       12 Batch loss: 0.071077 Batch F1: 0.5
Train Avg Loss  410: 0.069259

Train Avg F1  410: 0.808220148980009

Val Avg Loss  410: 0.076509

Val Avg F1  410:  0.5424679487179487

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 411
--------------------------------------------------------------
Epoch:  411        1 Batch loss: 0.100050 Batch F1: 0.42857142857142855
Epoch:  411        2 Batch loss: 0.077671 Batch F1: 0.6666666666666666
Epoch:  411        3 Batch loss: 0.079229 Batch F1: 0.6153846153846153
Epoch:  411        4 Batch loss: 0.054706 Batch F1: 0.7272727272727273
Epoch:  411        5 Batch loss: 0.054946 Batch F1: 0.5
Epoch:  411        6 Batch loss: 0.063142 Batch F1: 0.6153846153846153
Epoch:  411        7 Batch loss: 0.056457 Batch F1: 0.8333333333333333
Epoch:  411        8 Batch loss: 0.079075 Batch F1: 1.0
Epoch:  411        9 Batch loss: 0.065496 Batch F1: 1.0
Epoch:  411       10 Batch loss: 0.066064 Batch F1: 0.9523809523809523
Epoch:  411       11 Batch loss: 0.070741 Batch F1: 1.0
Epoch:  411       12 Batch loss: 0.080147 Batch F1: 0.7142857142857143
Train Avg Loss  411: 0.070644

Train Avg F1  411: 0.7544400044400045

Val Avg Loss  411: 0.065375

Val Avg F1  411:  0.7682692307692307

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 412
--------------------------------------------------------------
Epoch:  412        1 Batch loss: 0.060254 Batch F1: 0.6666666666666666
Epoch:  412        2 Batch loss: 0.079103 Batch F1: 0.7058823529411764
Epoch:  412        3 Batch loss: 0.070881 Batch F1: 0.9
Epoch:  412        4 Batch loss: 0.065096 Batch F1: 1.0
Epoch:  412        5 Batch loss: 0.052131 Batch F1: 1.0
Epoch:  412        6 Batch loss: 0.054333 Batch F1: 0.6666666666666666
Epoch:  412        7 Batch loss: 0.100912 Batch F1: 0.5714285714285715
Epoch:  412        8 Batch loss: 0.085797 Batch F1: 0.9090909090909091
Epoch:  412        9 Batch loss: 0.070563 Batch F1: 0.888888888888889
Epoch:  412       10 Batch loss: 0.079577 Batch F1: 0.8571428571428571
Epoch:  412       11 Batch loss: 0.064280 Batch F1: 1.0
Epoch:  412       12 Batch loss: 0.061759 Batch F1: 0.888888888888889
Train Avg Loss  412: 0.070391

Train Avg F1  412: 0.8378879834762188

Val Avg Loss  412: 0.064439

Val Avg F1  412:  0.6127622377622377

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 413
--------------------------------------------------------------
Epoch:  413        1 Batch loss: 0.062935 Batch F1: 0.7272727272727273
Epoch:  413        2 Batch loss: 0.077802 Batch F1: 0.5714285714285715
Epoch:  413        3 Batch loss: 0.075142 Batch F1: 0.7058823529411764
Epoch:  413        4 Batch loss: 0.051331 Batch F1: 0.6666666666666666
Epoch:  413        5 Batch loss: 0.093684 Batch F1: 0.6666666666666666
Epoch:  413        6 Batch loss: 0.053758 Batch F1: 0.7272727272727273
Epoch:  413        7 Batch loss: 0.054307 Batch F1: 0.923076923076923
Epoch:  413        8 Batch loss: 0.078831 Batch F1: 0.7692307692307693
Epoch:  413        9 Batch loss: 0.083761 Batch F1: 0.7058823529411764
Epoch:  413       10 Batch loss: 0.073234 Batch F1: 0.9
Epoch:  413       11 Batch loss: 0.046589 Batch F1: 0.8
Epoch:  413       12 Batch loss: 0.086181 Batch F1: 0.7999999999999999
Train Avg Loss  413: 0.069796

Train Avg F1  413: 0.7469483131247839

Val Avg Loss  413: 0.064111

Val Avg F1  413:  0.736111111111111

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 414
--------------------------------------------------------------
Epoch:  414        1 Batch loss: 0.076607 Batch F1: 0.75
Epoch:  414        2 Batch loss: 0.054611 Batch F1: 0.8571428571428571
Epoch:  414        3 Batch loss: 0.065216 Batch F1: 0.2857142857142857
Epoch:  414        4 Batch loss: 0.079816 Batch F1: 0.5714285714285715
Epoch:  414        5 Batch loss: 0.074721 Batch F1: 0.3636363636363636
Epoch:  414        6 Batch loss: 0.062005 Batch F1: 0.6666666666666666
Epoch:  414        7 Batch loss: 0.052799 Batch F1: 0.9411764705882353
Epoch:  414        8 Batch loss: 0.082687 Batch F1: 0.9230769230769231
Epoch:  414        9 Batch loss: 0.055217 Batch F1: 1.0
Epoch:  414       10 Batch loss: 0.079802 Batch F1: 0.9
Epoch:  414       11 Batch loss: 0.052359 Batch F1: 0.8750000000000001
Epoch:  414       12 Batch loss: 0.066102 Batch F1: 0.5
Train Avg Loss  414: 0.066829

Train Avg F1  414: 0.719486844854492

Val Avg Loss  414: 0.066659

Val Avg F1  414:  0.5892156862745097

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 415
--------------------------------------------------------------
Epoch:  415        1 Batch loss: 0.060029 Batch F1: 0.6153846153846153
Epoch:  415        2 Batch loss: 0.043228 Batch F1: 0.5714285714285715
Epoch:  415        3 Batch loss: 0.094715 Batch F1: 0.5
Epoch:  415        4 Batch loss: 0.089077 Batch F1: 0.5263157894736842
Epoch:  415        5 Batch loss: 0.064841 Batch F1: 0.8
Epoch:  415        6 Batch loss: 0.086025 Batch F1: 0.8421052631578948
Epoch:  415        7 Batch loss: 0.075040 Batch F1: 0.888888888888889
Epoch:  415        8 Batch loss: 0.062881 Batch F1: 1.0
Epoch:  415        9 Batch loss: 0.078346 Batch F1: 0.9166666666666666
Epoch:  415       10 Batch loss: 0.069991 Batch F1: 0.8571428571428571
Epoch:  415       11 Batch loss: 0.053921 Batch F1: 0.9090909090909091
Epoch:  415       12 Batch loss: 0.040574 Batch F1: 0.8571428571428571
Train Avg Loss  415: 0.068222

Train Avg F1  415: 0.7736805348647454

Val Avg Loss  415: 0.064358

Val Avg F1  415:  0.5855314276366907

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 416
--------------------------------------------------------------
Epoch:  416        1 Batch loss: 0.063469 Batch F1: 0.5
Epoch:  416        2 Batch loss: 0.088148 Batch F1: 0.33333333333333337
Epoch:  416        3 Batch loss: 0.076176 Batch F1: 0.5333333333333333
Epoch:  416        4 Batch loss: 0.083325 Batch F1: 0.923076923076923
Epoch:  416        5 Batch loss: 0.056362 Batch F1: 1.0
Epoch:  416        6 Batch loss: 0.088492 Batch F1: 0.875
Epoch:  416        7 Batch loss: 0.053108 Batch F1: 0.9090909090909091
Epoch:  416        8 Batch loss: 0.085155 Batch F1: 0.5333333333333333
Epoch:  416        9 Batch loss: 0.065266 Batch F1: 0.6153846153846153
Epoch:  416       10 Batch loss: 0.072686 Batch F1: 0.6666666666666666
Epoch:  416       11 Batch loss: 0.056965 Batch F1: 0.8750000000000001
Epoch:  416       12 Batch loss: 0.075127 Batch F1: 0.5
Train Avg Loss  416: 0.072023

Train Avg F1  416: 0.688684926184926

Val Avg Loss  416: 0.061961

Val Avg F1  416:  0.8785014005602241

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 417
--------------------------------------------------------------
Epoch:  417        1 Batch loss: 0.056058 Batch F1: 0.8
Epoch:  417        2 Batch loss: 0.056104 Batch F1: 0.8333333333333333
Epoch:  417        3 Batch loss: 0.061806 Batch F1: 0.9411764705882353
Epoch:  417        4 Batch loss: 0.074689 Batch F1: 0.8333333333333333
Epoch:  417        5 Batch loss: 0.074985 Batch F1: 0.9
Epoch:  417        6 Batch loss: 0.065245 Batch F1: 0.8333333333333333
Epoch:  417        7 Batch loss: 0.083516 Batch F1: 0.9
Epoch:  417        8 Batch loss: 0.069995 Batch F1: 0.8695652173913044
Epoch:  417        9 Batch loss: 0.082658 Batch F1: 0.7272727272727273
Epoch:  417       10 Batch loss: 0.072018 Batch F1: 0.888888888888889
Epoch:  417       11 Batch loss: 0.069310 Batch F1: 0.8
Epoch:  417       12 Batch loss: 0.054736 Batch F1: 0.0
Train Avg Loss  417: 0.068427

Train Avg F1  417: 0.777241942011763

Val Avg Loss  417: 0.067434

Val Avg F1  417:  0.5595959595959596

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 418
--------------------------------------------------------------
Epoch:  418        1 Batch loss: 0.085807 Batch F1: 0.6363636363636364
Epoch:  418        2 Batch loss: 0.061007 Batch F1: 0.8235294117647058
Epoch:  418        3 Batch loss: 0.077326 Batch F1: 0.923076923076923
Epoch:  418        4 Batch loss: 0.066203 Batch F1: 0.888888888888889
Epoch:  418        5 Batch loss: 0.089071 Batch F1: 0.4615384615384615
Epoch:  418        6 Batch loss: 0.072389 Batch F1: 0.7058823529411764
Epoch:  418        7 Batch loss: 0.056994 Batch F1: 0.6666666666666666
Epoch:  418        8 Batch loss: 0.062329 Batch F1: 0.8571428571428571
Epoch:  418        9 Batch loss: 0.069668 Batch F1: 0.8
Epoch:  418       10 Batch loss: 0.066667 Batch F1: 0.6666666666666666
Epoch:  418       11 Batch loss: 0.039881 Batch F1: 0.6666666666666666
Epoch:  418       12 Batch loss: 0.102942 Batch F1: 0.3076923076923077
Train Avg Loss  418: 0.070857

Train Avg F1  418: 0.7003429032840799

Val Avg Loss  418: 0.063706

Val Avg F1  418:  0.7020676691729323

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 419
--------------------------------------------------------------
Epoch:  419        1 Batch loss: 0.066842 Batch F1: 0.7142857142857143
Epoch:  419        2 Batch loss: 0.072878 Batch F1: 0.8571428571428571
Epoch:  419        3 Batch loss: 0.062441 Batch F1: 0.9333333333333333
Epoch:  419        4 Batch loss: 0.077669 Batch F1: 0.5
Epoch:  419        5 Batch loss: 0.061323 Batch F1: 0.3636363636363636
Epoch:  419        6 Batch loss: 0.064965 Batch F1: 0.5454545454545454
Epoch:  419        7 Batch loss: 0.069995 Batch F1: 0.8571428571428571
Epoch:  419        8 Batch loss: 0.067555 Batch F1: 0.6666666666666666
Epoch:  419        9 Batch loss: 0.080207 Batch F1: 0.8421052631578948
Epoch:  419       10 Batch loss: 0.062471 Batch F1: 0.8750000000000001
Epoch:  419       11 Batch loss: 0.079670 Batch F1: 0.8421052631578948
Epoch:  419       12 Batch loss: 0.050660 Batch F1: 1.0
Train Avg Loss  419: 0.068056

Train Avg F1  419: 0.7497394053315105

Val Avg Loss  419: 0.063511

Val Avg F1  419:  0.9261803405572755

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 420
--------------------------------------------------------------
Epoch:  420        1 Batch loss: 0.060650 Batch F1: 0.9333333333333333
Epoch:  420        2 Batch loss: 0.060629 Batch F1: 0.7692307692307693
Epoch:  420        3 Batch loss: 0.062865 Batch F1: 0.8235294117647058
Epoch:  420        4 Batch loss: 0.037353 Batch F1: 0.8571428571428571
Epoch:  420        5 Batch loss: 0.086968 Batch F1: 0.4615384615384615
Epoch:  420        6 Batch loss: 0.094381 Batch F1: 0.2857142857142857
Epoch:  420        7 Batch loss: 0.073829 Batch F1: 0.5
Epoch:  420        8 Batch loss: 0.062011 Batch F1: 0.8750000000000001
Epoch:  420        9 Batch loss: 0.070197 Batch F1: 0.7692307692307693
Epoch:  420       10 Batch loss: 0.070037 Batch F1: 0.9523809523809523
Epoch:  420       11 Batch loss: 0.050363 Batch F1: 0.8
Epoch:  420       12 Batch loss: 0.079134 Batch F1: 0.6666666666666666
Train Avg Loss  420: 0.067368

Train Avg F1  420: 0.7244806255835669

Val Avg Loss  420: 0.062655

Val Avg F1  420:  0.8856060606060606

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 421
--------------------------------------------------------------
Epoch:  421        1 Batch loss: 0.089215 Batch F1: 0.88
Epoch:  421        2 Batch loss: 0.068966 Batch F1: 0.9090909090909091
Epoch:  421        3 Batch loss: 0.054707 Batch F1: 1.0
Epoch:  421        4 Batch loss: 0.073787 Batch F1: 0.9600000000000001
Epoch:  421        5 Batch loss: 0.062964 Batch F1: 1.0
Epoch:  421        6 Batch loss: 0.081482 Batch F1: 0.8181818181818181
Epoch:  421        7 Batch loss: 0.082711 Batch F1: 0.761904761904762
Epoch:  421        8 Batch loss: 0.056336 Batch F1: 0.8571428571428571
Epoch:  421        9 Batch loss: 0.053628 Batch F1: 1.0
Epoch:  421       10 Batch loss: 0.059678 Batch F1: 0.6
Epoch:  421       11 Batch loss: 0.060771 Batch F1: 0.6666666666666666
Epoch:  421       12 Batch loss: 0.081786 Batch F1: 0.5454545454545454
Train Avg Loss  421: 0.068836

Train Avg F1  421: 0.8332034632034632

Val Avg Loss  421: 0.063617

Val Avg F1  421:  0.6281114718614719

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 422
--------------------------------------------------------------
Epoch:  422        1 Batch loss: 0.073610 Batch F1: 0.5714285714285715
Epoch:  422        2 Batch loss: 0.086661 Batch F1: 0.5
Epoch:  422        3 Batch loss: 0.084691 Batch F1: 0.6666666666666666
Epoch:  422        4 Batch loss: 0.059968 Batch F1: 1.0
Epoch:  422        5 Batch loss: 0.065041 Batch F1: 0.9565217391304348
Epoch:  422        6 Batch loss: 0.073046 Batch F1: 0.823529411764706
Epoch:  422        7 Batch loss: 0.047166 Batch F1: 0.7499999999999999
Epoch:  422        8 Batch loss: 0.054579 Batch F1: 0.8333333333333333
Epoch:  422        9 Batch loss: 0.061315 Batch F1: 0.6666666666666666
Epoch:  422       10 Batch loss: 0.056893 Batch F1: 0.6
Epoch:  422       11 Batch loss: 0.067875 Batch F1: 0.5454545454545454
Epoch:  422       12 Batch loss: 0.098426 Batch F1: 0.3076923076923077
Train Avg Loss  422: 0.069106

Train Avg F1  422: 0.6851077701781026

Val Avg Loss  422: 0.064775

Val Avg F1  422:  0.7318181818181818

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 423
--------------------------------------------------------------
Epoch:  423        1 Batch loss: 0.064603 Batch F1: 0.6666666666666666
Epoch:  423        2 Batch loss: 0.053693 Batch F1: 1.0
Epoch:  423        3 Batch loss: 0.068959 Batch F1: 0.8421052631578948
Epoch:  423        4 Batch loss: 0.059485 Batch F1: 0.8888888888888888
Epoch:  423        5 Batch loss: 0.094168 Batch F1: 0.8571428571428571
Epoch:  423        6 Batch loss: 0.063753 Batch F1: 0.8750000000000001
Epoch:  423        7 Batch loss: 0.066003 Batch F1: 0.0
Epoch:  423        8 Batch loss: 0.098962 Batch F1: 0.47058823529411764
Epoch:  423        9 Batch loss: 0.075427 Batch F1: 0.6153846153846153
Epoch:  423       10 Batch loss: 0.070969 Batch F1: 0.8
Epoch:  423       11 Batch loss: 0.069917 Batch F1: 0.9
Epoch:  423       12 Batch loss: 0.060794 Batch F1: 0.7499999999999999
Train Avg Loss  423: 0.070561

Train Avg F1  423: 0.7221480438779199

Val Avg Loss  423: 0.062795

Val Avg F1  423:  0.7950126262626263

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 424
--------------------------------------------------------------
Epoch:  424        1 Batch loss: 0.071371 Batch F1: 0.9
Epoch:  424        2 Batch loss: 0.077551 Batch F1: 0.4615384615384615
Epoch:  424        3 Batch loss: 0.066445 Batch F1: 0.6666666666666666
Epoch:  424        4 Batch loss: 0.063984 Batch F1: 0.5714285714285715
Epoch:  424        5 Batch loss: 0.065093 Batch F1: 0.7272727272727273
Epoch:  424        6 Batch loss: 0.083208 Batch F1: 0.7058823529411764
Epoch:  424        7 Batch loss: 0.079047 Batch F1: 0.7499999999999999
Epoch:  424        8 Batch loss: 0.067610 Batch F1: 0.8421052631578948
Epoch:  424        9 Batch loss: 0.062217 Batch F1: 0.8571428571428571
Epoch:  424       10 Batch loss: 0.050167 Batch F1: 0.8571428571428571
Epoch:  424       11 Batch loss: 0.061803 Batch F1: 0.8
Epoch:  424       12 Batch loss: 0.068273 Batch F1: 0.9090909090909091
Train Avg Loss  424: 0.068064

Train Avg F1  424: 0.7540225555318433

Val Avg Loss  424: 0.067639

Val Avg F1  424:  0.6083333333333334

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 425
--------------------------------------------------------------
Epoch:  425        1 Batch loss: 0.075709 Batch F1: 0.4615384615384615
Epoch:  425        2 Batch loss: 0.063338 Batch F1: 0.8
Epoch:  425        3 Batch loss: 0.057348 Batch F1: 0.33333333333333337
Epoch:  425        4 Batch loss: 0.045145 Batch F1: 0.5714285714285715
Epoch:  425        5 Batch loss: 0.098744 Batch F1: 0.5263157894736842
Epoch:  425        6 Batch loss: 0.110780 Batch F1: 0.35294117647058826
Epoch:  425        7 Batch loss: 0.068280 Batch F1: 1.0
Epoch:  425        8 Batch loss: 0.078438 Batch F1: 0.9600000000000001
Epoch:  425        9 Batch loss: 0.063171 Batch F1: 1.0
Epoch:  425       10 Batch loss: 0.053722 Batch F1: 0.5
Epoch:  425       11 Batch loss: 0.085008 Batch F1: 0.4615384615384615
Epoch:  425       12 Batch loss: 0.047928 Batch F1: 0.6666666666666666
Train Avg Loss  425: 0.070634

Train Avg F1  425: 0.6361468717041473

Val Avg Loss  425: 0.073139

Val Avg F1  425:  0.7535485347985348

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 426
--------------------------------------------------------------
Epoch:  426        1 Batch loss: 0.078779 Batch F1: 0.8571428571428572
Epoch:  426        2 Batch loss: 0.073591 Batch F1: 0.7692307692307693
Epoch:  426        3 Batch loss: 0.074612 Batch F1: 0.9333333333333333
Epoch:  426        4 Batch loss: 0.083050 Batch F1: 0.9411764705882353
Epoch:  426        5 Batch loss: 0.068966 Batch F1: 0.6153846153846153
Epoch:  426        6 Batch loss: 0.076596 Batch F1: 0.5454545454545454
Epoch:  426        7 Batch loss: 0.090995 Batch F1: 0.5333333333333333
Epoch:  426        8 Batch loss: 0.048136 Batch F1: 0.6666666666666666
Epoch:  426        9 Batch loss: 0.078331 Batch F1: 0.4615384615384615
Epoch:  426       10 Batch loss: 0.069407 Batch F1: 0.7499999999999999
Epoch:  426       11 Batch loss: 0.064763 Batch F1: 0.9473684210526316
Epoch:  426       12 Batch loss: 0.082541 Batch F1: 0.9411764705882353
Train Avg Loss  426: 0.074147

Train Avg F1  426: 0.7468171620261402

Val Avg Loss  426: 0.067585

Val Avg F1  426:  0.7734962406015038

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 427
--------------------------------------------------------------
Epoch:  427        1 Batch loss: 0.094489 Batch F1: 0.8181818181818182
Epoch:  427        2 Batch loss: 0.070998 Batch F1: 0.25
Epoch:  427        3 Batch loss: 0.085678 Batch F1: 0.6666666666666666
Epoch:  427        4 Batch loss: 0.050811 Batch F1: 0.6666666666666666
Epoch:  427        5 Batch loss: 0.076178 Batch F1: 0.3636363636363636
Epoch:  427        6 Batch loss: 0.071632 Batch F1: 0.7777777777777778
Epoch:  427        7 Batch loss: 0.069702 Batch F1: 0.6666666666666666
Epoch:  427        8 Batch loss: 0.066223 Batch F1: 0.9473684210526316
Epoch:  427        9 Batch loss: 0.059073 Batch F1: 0.923076923076923
Epoch:  427       10 Batch loss: 0.077813 Batch F1: 0.8235294117647058
Epoch:  427       11 Batch loss: 0.053279 Batch F1: 1.0
Epoch:  427       12 Batch loss: 0.064762 Batch F1: 0.923076923076923
Train Avg Loss  427: 0.070053

Train Avg F1  427: 0.7355539698805953

Val Avg Loss  427: 0.064514

Val Avg F1  427:  0.6128342245989304

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 428
--------------------------------------------------------------
Epoch:  428        1 Batch loss: 0.060869 Batch F1: 0.2857142857142857
Epoch:  428        2 Batch loss: 0.047935 Batch F1: 0.8
Epoch:  428        3 Batch loss: 0.060688 Batch F1: 0.4444444444444445
Epoch:  428        4 Batch loss: 0.078176 Batch F1: 0.625
Epoch:  428        5 Batch loss: 0.114484 Batch F1: 0.4210526315789474
Epoch:  428        6 Batch loss: 0.110522 Batch F1: 0.7500000000000001
Epoch:  428        7 Batch loss: 0.059615 Batch F1: 1.0
Epoch:  428        8 Batch loss: 0.088895 Batch F1: 0.375
Epoch:  428        9 Batch loss: 0.037523 Batch F1: 0.8
Epoch:  428       10 Batch loss: 0.071630 Batch F1: 0.6
Epoch:  428       11 Batch loss: 0.075397 Batch F1: 0.4615384615384615
Epoch:  428       12 Batch loss: 0.059208 Batch F1: 0.8571428571428571
Train Avg Loss  428: 0.072079

Train Avg F1  428: 0.6183243900349162

Val Avg Loss  428: 0.062840

Val Avg F1  428:  0.8668875242404654

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 429
--------------------------------------------------------------
Epoch:  429        1 Batch loss: 0.045871 Batch F1: 1.0
Epoch:  429        2 Batch loss: 0.086724 Batch F1: 0.88
Epoch:  429        3 Batch loss: 0.072385 Batch F1: 0.9333333333333333
Epoch:  429        4 Batch loss: 0.074179 Batch F1: 0.923076923076923
Epoch:  429        5 Batch loss: 0.083553 Batch F1: 0.6666666666666666
Epoch:  429        6 Batch loss: 0.048136 Batch F1: 1.0
Epoch:  429        7 Batch loss: 0.078557 Batch F1: 0.5882352941176471
Epoch:  429        8 Batch loss: 0.066622 Batch F1: 0.9411764705882353
Epoch:  429        9 Batch loss: 0.053371 Batch F1: 0.923076923076923
Epoch:  429       10 Batch loss: 0.070756 Batch F1: 0.8
Epoch:  429       11 Batch loss: 0.077705 Batch F1: 0.6666666666666666
Epoch:  429       12 Batch loss: 0.077834 Batch F1: 0.8333333333333333
Train Avg Loss  429: 0.069641

Train Avg F1  429: 0.8462971342383107

Val Avg Loss  429: 0.062495

Val Avg F1  429:  0.8021978021978022

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 430
--------------------------------------------------------------
Epoch:  430        1 Batch loss: 0.060598 Batch F1: 0.7272727272727273
Epoch:  430        2 Batch loss: 0.057272 Batch F1: 0.6666666666666666
Epoch:  430        3 Batch loss: 0.076303 Batch F1: 0.5454545454545454
Epoch:  430        4 Batch loss: 0.078315 Batch F1: 0.625
Epoch:  430        5 Batch loss: 0.069181 Batch F1: 0.625
Epoch:  430        6 Batch loss: 0.071842 Batch F1: 0.19999999999999998
Epoch:  430        7 Batch loss: 0.041066 Batch F1: 1.0
Epoch:  430        8 Batch loss: 0.065816 Batch F1: 0.9473684210526316
Epoch:  430        9 Batch loss: 0.057675 Batch F1: 0.9
Epoch:  430       10 Batch loss: 0.090196 Batch F1: 0.625
Epoch:  430       11 Batch loss: 0.059877 Batch F1: 0.8750000000000001
Epoch:  430       12 Batch loss: 0.077196 Batch F1: 0.8571428571428571
Train Avg Loss  430: 0.067112

Train Avg F1  430: 0.7161587681324524

Val Avg Loss  430: 0.064181

Val Avg F1  430:  0.9142631561986401

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 431
--------------------------------------------------------------
Epoch:  431        1 Batch loss: 0.057901 Batch F1: 1.0
Epoch:  431        2 Batch loss: 0.077894 Batch F1: 0.9166666666666666
Epoch:  431        3 Batch loss: 0.066683 Batch F1: 0.8571428571428571
Epoch:  431        4 Batch loss: 0.069046 Batch F1: 0.9333333333333333
Epoch:  431        5 Batch loss: 0.055564 Batch F1: 1.0
Epoch:  431        6 Batch loss: 0.066682 Batch F1: 0.7777777777777778
Epoch:  431        7 Batch loss: 0.052397 Batch F1: 0.4
Epoch:  431        8 Batch loss: 0.050864 Batch F1: 0.6666666666666666
Epoch:  431        9 Batch loss: 0.076510 Batch F1: 0.3636363636363636
Epoch:  431       10 Batch loss: 0.100265 Batch F1: 0.47058823529411764
Epoch:  431       11 Batch loss: 0.081205 Batch F1: 0.7272727272727273
Epoch:  431       12 Batch loss: 0.066938 Batch F1: 0.888888888888889
Train Avg Loss  431: 0.068496

Train Avg F1  431: 0.7501644597232833

Val Avg Loss  431: 0.062520

Val Avg F1  431:  0.9466467746518898

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 432
--------------------------------------------------------------
Epoch:  432        1 Batch loss: 0.066665 Batch F1: 0.888888888888889
Epoch:  432        2 Batch loss: 0.059484 Batch F1: 1.0
Epoch:  432        3 Batch loss: 0.074880 Batch F1: 0.9
Epoch:  432        4 Batch loss: 0.069540 Batch F1: 0.9655172413793104
Epoch:  432        5 Batch loss: 0.060723 Batch F1: 0.9333333333333333
Epoch:  432        6 Batch loss: 0.064518 Batch F1: 0.923076923076923
Epoch:  432        7 Batch loss: 0.075183 Batch F1: 0.8421052631578948
Epoch:  432        8 Batch loss: 0.064878 Batch F1: 0.7692307692307693
Epoch:  432        9 Batch loss: 0.096026 Batch F1: 0.375
Epoch:  432       10 Batch loss: 0.069353 Batch F1: 0.4444444444444445
Epoch:  432       11 Batch loss: 0.055779 Batch F1: 0.9333333333333333
Epoch:  432       12 Batch loss: 0.046532 Batch F1: 1.0
Train Avg Loss  432: 0.066963

Train Avg F1  432: 0.8312441830704081

Val Avg Loss  432: 0.062936

Val Avg F1  432:  0.584920634920635

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 433
--------------------------------------------------------------
Epoch:  433        1 Batch loss: 0.062687 Batch F1: 0.2222222222222222
Epoch:  433        2 Batch loss: 0.048132 Batch F1: 0.7499999999999999
Epoch:  433        3 Batch loss: 0.090195 Batch F1: 0.42857142857142855
Epoch:  433        4 Batch loss: 0.060745 Batch F1: 0.2857142857142857
Epoch:  433        5 Batch loss: 0.064982 Batch F1: 0.4
Epoch:  433        6 Batch loss: 0.066300 Batch F1: 0.7058823529411764
Epoch:  433        7 Batch loss: 0.045864 Batch F1: 0.8750000000000001
Epoch:  433        8 Batch loss: 0.082701 Batch F1: 0.7368421052631579
Epoch:  433        9 Batch loss: 0.069617 Batch F1: 0.8
Epoch:  433       10 Batch loss: 0.066142 Batch F1: 0.888888888888889
Epoch:  433       11 Batch loss: 0.082664 Batch F1: 0.8695652173913043
Epoch:  433       12 Batch loss: 0.055356 Batch F1: 0.7692307692307692
Train Avg Loss  433: 0.066282

Train Avg F1  433: 0.6443264391852694

Val Avg Loss  433: 0.062744

Val Avg F1  433:  0.7590579710144928

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 434
--------------------------------------------------------------
Epoch:  434        1 Batch loss: 0.060591 Batch F1: 0.5714285714285715
Epoch:  434        2 Batch loss: 0.063885 Batch F1: 0.8
Epoch:  434        3 Batch loss: 0.055683 Batch F1: 0.5
Epoch:  434        4 Batch loss: 0.057333 Batch F1: 0.7142857142857143
Epoch:  434        5 Batch loss: 0.060136 Batch F1: 0.4444444444444445
Epoch:  434        6 Batch loss: 0.108351 Batch F1: 0.6399999999999999
Epoch:  434        7 Batch loss: 0.047673 Batch F1: 0.888888888888889
Epoch:  434        8 Batch loss: 0.046695 Batch F1: 0.888888888888889
Epoch:  434        9 Batch loss: 0.082828 Batch F1: 0.625
Epoch:  434       10 Batch loss: 0.074354 Batch F1: 0.8421052631578948
Epoch:  434       11 Batch loss: 0.071309 Batch F1: 0.9565217391304348
Epoch:  434       12 Batch loss: 0.090958 Batch F1: 0.8421052631578948
Train Avg Loss  434: 0.068316

Train Avg F1  434: 0.7261390644485611

Val Avg Loss  434: 0.068213

Val Avg F1  434:  0.9270833333333334

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 435
--------------------------------------------------------------
Epoch:  435        1 Batch loss: 0.071357 Batch F1: 0.962962962962963
Epoch:  435        2 Batch loss: 0.068322 Batch F1: 0.9473684210526316
Epoch:  435        3 Batch loss: 0.087353 Batch F1: 0.9655172413793104
Epoch:  435        4 Batch loss: 0.065840 Batch F1: 0.9473684210526316
Epoch:  435        5 Batch loss: 0.047997 Batch F1: 0.9090909090909091
Epoch:  435        6 Batch loss: 0.055288 Batch F1: 0.8333333333333333
Epoch:  435        7 Batch loss: 0.055222 Batch F1: 0.9090909090909091
Epoch:  435        8 Batch loss: 0.044295 Batch F1: 0.9090909090909091
Epoch:  435        9 Batch loss: 0.091787 Batch F1: 0.3076923076923077
Epoch:  435       10 Batch loss: 0.054404 Batch F1: 0.9090909090909091
Epoch:  435       11 Batch loss: 0.085632 Batch F1: 0.6666666666666666
Epoch:  435       12 Batch loss: 0.096449 Batch F1: 0.8
Train Avg Loss  435: 0.068662

Train Avg F1  435: 0.8389394158752901

Val Avg Loss  435: 0.064479

Val Avg F1  435:  0.7751885369532427

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 436
--------------------------------------------------------------
Epoch:  436        1 Batch loss: 0.058592 Batch F1: 0.9473684210526316
Epoch:  436        2 Batch loss: 0.070026 Batch F1: 0.823529411764706
Epoch:  436        3 Batch loss: 0.072465 Batch F1: 0.8235294117647058
Epoch:  436        4 Batch loss: 0.068813 Batch F1: 0.6666666666666666
Epoch:  436        5 Batch loss: 0.076621 Batch F1: 0.8
Epoch:  436        6 Batch loss: 0.041354 Batch F1: 0.6666666666666666
Epoch:  436        7 Batch loss: 0.059658 Batch F1: 0.8571428571428571
Epoch:  436        8 Batch loss: 0.058116 Batch F1: 0.5454545454545454
Epoch:  436        9 Batch loss: 0.088542 Batch F1: 0.5555555555555556
Epoch:  436       10 Batch loss: 0.099770 Batch F1: 0.631578947368421
Epoch:  436       11 Batch loss: 0.064314 Batch F1: 0.9333333333333333
Epoch:  436       12 Batch loss: 0.061752 Batch F1: 0.7692307692307693
Train Avg Loss  436: 0.068335

Train Avg F1  436: 0.7516713821667382

Val Avg Loss  436: 0.064288

Val Avg F1  436:  0.8833333333333333

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 437
--------------------------------------------------------------
Epoch:  437        1 Batch loss: 0.074377 Batch F1: 0.8
Epoch:  437        2 Batch loss: 0.085183 Batch F1: 0.7272727272727273
Epoch:  437        3 Batch loss: 0.051932 Batch F1: 0.8
Epoch:  437        4 Batch loss: 0.091441 Batch F1: 0.782608695652174
Epoch:  437        5 Batch loss: 0.070064 Batch F1: 0.9473684210526316
Epoch:  437        6 Batch loss: 0.073719 Batch F1: 0.7692307692307693
Epoch:  437        7 Batch loss: 0.058196 Batch F1: 0.8333333333333333
Epoch:  437        8 Batch loss: 0.053162 Batch F1: 0.8333333333333333
Epoch:  437        9 Batch loss: 0.039773 Batch F1: 0.9090909090909091
Epoch:  437       10 Batch loss: 0.074710 Batch F1: 0.5
Epoch:  437       11 Batch loss: 0.080594 Batch F1: 0.4615384615384615
Epoch:  437       12 Batch loss: 0.072705 Batch F1: 0.4
Train Avg Loss  437: 0.068821

Train Avg F1  437: 0.7303147208753615

Val Avg Loss  437: 0.063322

Val Avg F1  437:  0.8156045751633987

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 438
--------------------------------------------------------------
Epoch:  438        1 Batch loss: 0.073602 Batch F1: 0.7499999999999999
Epoch:  438        2 Batch loss: 0.073780 Batch F1: 0.7777777777777778
Epoch:  438        3 Batch loss: 0.044481 Batch F1: 0.8
Epoch:  438        4 Batch loss: 0.089379 Batch F1: 0.8421052631578948
Epoch:  438        5 Batch loss: 0.056634 Batch F1: 0.6666666666666666
Epoch:  438        6 Batch loss: 0.034606 Batch F1: 0.6666666666666666
Epoch:  438        7 Batch loss: 0.063096 Batch F1: 0.4444444444444445
Epoch:  438        8 Batch loss: 0.109717 Batch F1: 0.6
Epoch:  438        9 Batch loss: 0.067842 Batch F1: 0.6666666666666666
Epoch:  438       10 Batch loss: 0.069389 Batch F1: 0.8235294117647058
Epoch:  438       11 Batch loss: 0.065011 Batch F1: 0.9473684210526316
Epoch:  438       12 Batch loss: 0.071977 Batch F1: 0.9090909090909091
Train Avg Loss  438: 0.068293

Train Avg F1  438: 0.7411930189406969

Val Avg Loss  438: 0.069726

Val Avg F1  438:  0.9244565741276267

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 439
--------------------------------------------------------------
Epoch:  439        1 Batch loss: 0.056764 Batch F1: 0.8571428571428571
Epoch:  439        2 Batch loss: 0.073649 Batch F1: 1.0
Epoch:  439        3 Batch loss: 0.066032 Batch F1: 0.9333333333333333
Epoch:  439        4 Batch loss: 0.079898 Batch F1: 0.7777777777777778
Epoch:  439        5 Batch loss: 0.062024 Batch F1: 0.7692307692307692
Epoch:  439        6 Batch loss: 0.068438 Batch F1: 0.9
Epoch:  439        7 Batch loss: 0.061297 Batch F1: 0.8750000000000001
Epoch:  439        8 Batch loss: 0.068946 Batch F1: 0.6153846153846153
Epoch:  439        9 Batch loss: 0.093944 Batch F1: 0.4
Epoch:  439       10 Batch loss: 0.047439 Batch F1: 1.0
Epoch:  439       11 Batch loss: 0.084292 Batch F1: 0.6666666666666666
Epoch:  439       12 Batch loss: 0.080634 Batch F1: 0.8181818181818181
Train Avg Loss  439: 0.070280

Train Avg F1  439: 0.8010598198098199

Val Avg Loss  439: 0.067870

Val Avg F1  439:  0.9142857142857143

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 440
--------------------------------------------------------------
Epoch:  440        1 Batch loss: 0.079824 Batch F1: 0.8421052631578948
Epoch:  440        2 Batch loss: 0.073055 Batch F1: 0.7692307692307693
Epoch:  440        3 Batch loss: 0.077769 Batch F1: 0.625
Epoch:  440        4 Batch loss: 0.051556 Batch F1: 0.33333333333333337
Epoch:  440        5 Batch loss: 0.064512 Batch F1: 0.8
Epoch:  440        6 Batch loss: 0.078436 Batch F1: 0.962962962962963
Epoch:  440        7 Batch loss: 0.068264 Batch F1: 0.9333333333333333
Epoch:  440        8 Batch loss: 0.062065 Batch F1: 0.9523809523809523
Epoch:  440        9 Batch loss: 0.073769 Batch F1: 0.8888888888888888
Epoch:  440       10 Batch loss: 0.075805 Batch F1: 0.9473684210526316
Epoch:  440       11 Batch loss: 0.076659 Batch F1: 0.7692307692307693
Epoch:  440       12 Batch loss: 0.051262 Batch F1: 0.33333333333333337
Train Avg Loss  440: 0.069415

Train Avg F1  440: 0.7630973355754059

Val Avg Loss  440: 0.082396

Val Avg F1  440:  0.0

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 441
--------------------------------------------------------------
Epoch:  441        1 Batch loss: 0.101878 Batch F1: 0.0
Epoch:  441        2 Batch loss: 0.071426 Batch F1: 0.6153846153846153
Epoch:  441        3 Batch loss: 0.084032 Batch F1: 1.0
Epoch:  441        4 Batch loss: 0.077972 Batch F1: 0.8
Epoch:  441        5 Batch loss: 0.088791 Batch F1: 0.7368421052631579
Epoch:  441        6 Batch loss: 0.066985 Batch F1: 0.7499999999999999
Epoch:  441        7 Batch loss: 0.045805 Batch F1: 0.4
Epoch:  441        8 Batch loss: 0.085556 Batch F1: 0.5
Epoch:  441        9 Batch loss: 0.074131 Batch F1: 0.7368421052631579
Epoch:  441       10 Batch loss: 0.058854 Batch F1: 0.923076923076923
Epoch:  441       11 Batch loss: 0.058619 Batch F1: 0.888888888888889
Epoch:  441       12 Batch loss: 0.055885 Batch F1: 0.9090909090909091
Train Avg Loss  441: 0.072494

Train Avg F1  441: 0.6883437955806376

Val Avg Loss  441: 0.064938

Val Avg F1  441:  0.799702380952381

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 442
--------------------------------------------------------------
Epoch:  442        1 Batch loss: 0.072713 Batch F1: 0.8421052631578948
Epoch:  442        2 Batch loss: 0.075032 Batch F1: 0.8571428571428571
Epoch:  442        3 Batch loss: 0.071428 Batch F1: 0.8181818181818181
Epoch:  442        4 Batch loss: 0.053856 Batch F1: 0.8571428571428571
Epoch:  442        5 Batch loss: 0.062988 Batch F1: 0.923076923076923
Epoch:  442        6 Batch loss: 0.082352 Batch F1: 0.88
Epoch:  442        7 Batch loss: 0.063602 Batch F1: 0.923076923076923
Epoch:  442        8 Batch loss: 0.055059 Batch F1: 1.0
Epoch:  442        9 Batch loss: 0.067571 Batch F1: 0.8571428571428571
Epoch:  442       10 Batch loss: 0.064559 Batch F1: 0.8571428571428571
Epoch:  442       11 Batch loss: 0.066535 Batch F1: 0.5454545454545454
Epoch:  442       12 Batch loss: 0.083846 Batch F1: 0.6153846153846154
Train Avg Loss  442: 0.068295

Train Avg F1  442: 0.8313209597420123

Val Avg Loss  442: 0.065493

Val Avg F1  442:  0.6268939393939393

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 443
--------------------------------------------------------------
Epoch:  443        1 Batch loss: 0.084174 Batch F1: 0.3076923076923077
Epoch:  443        2 Batch loss: 0.052983 Batch F1: 0.7142857142857143
Epoch:  443        3 Batch loss: 0.051963 Batch F1: 0.9411764705882353
Epoch:  443        4 Batch loss: 0.058881 Batch F1: 0.6666666666666666
Epoch:  443        5 Batch loss: 0.061660 Batch F1: 0.4444444444444445
Epoch:  443        6 Batch loss: 0.063644 Batch F1: 0.6666666666666666
Epoch:  443        7 Batch loss: 0.063151 Batch F1: 0.7777777777777778
Epoch:  443        8 Batch loss: 0.059604 Batch F1: 0.4444444444444445
Epoch:  443        9 Batch loss: 0.081441 Batch F1: 0.33333333333333337
Epoch:  443       10 Batch loss: 0.087242 Batch F1: 0.6666666666666666
Epoch:  443       11 Batch loss: 0.084844 Batch F1: 0.7777777777777778
Epoch:  443       12 Batch loss: 0.055918 Batch F1: 0.8333333333333333
Train Avg Loss  443: 0.067125

Train Avg F1  443: 0.6311888003064473

Val Avg Loss  443: 0.065853

Val Avg F1  443:  0.874451754385965

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 444
--------------------------------------------------------------
Epoch:  444        1 Batch loss: 0.081925 Batch F1: 0.8799999999999999
Epoch:  444        2 Batch loss: 0.059462 Batch F1: 0.888888888888889
Epoch:  444        3 Batch loss: 0.055264 Batch F1: 0.888888888888889
Epoch:  444        4 Batch loss: 0.069650 Batch F1: 0.625
Epoch:  444        5 Batch loss: 0.067116 Batch F1: 0.7692307692307693
Epoch:  444        6 Batch loss: 0.067664 Batch F1: 0.6153846153846153
Epoch:  444        7 Batch loss: 0.066138 Batch F1: 0.4
Epoch:  444        8 Batch loss: 0.087943 Batch F1: 0.625
Epoch:  444        9 Batch loss: 0.067269 Batch F1: 0.7692307692307693
Epoch:  444       10 Batch loss: 0.067451 Batch F1: 0.9473684210526316
Epoch:  444       11 Batch loss: 0.074766 Batch F1: 0.888888888888889
Epoch:  444       12 Batch loss: 0.051578 Batch F1: 1.0
Train Avg Loss  444: 0.068019

Train Avg F1  444: 0.7748234367971211

Val Avg Loss  444: 0.063126

Val Avg F1  444:  0.758288770053476

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 445
--------------------------------------------------------------
Epoch:  445        1 Batch loss: 0.046470 Batch F1: 0.8571428571428571
Epoch:  445        2 Batch loss: 0.078246 Batch F1: 0.625
Epoch:  445        3 Batch loss: 0.091653 Batch F1: 0.5882352941176471
Epoch:  445        4 Batch loss: 0.092189 Batch F1: 0.4
Epoch:  445        5 Batch loss: 0.048956 Batch F1: 0.9333333333333333
Epoch:  445        6 Batch loss: 0.059899 Batch F1: 0.8750000000000001
Epoch:  445        7 Batch loss: 0.063061 Batch F1: 0.7272727272727272
Epoch:  445        8 Batch loss: 0.089151 Batch F1: 0.631578947368421
Epoch:  445        9 Batch loss: 0.062419 Batch F1: 0.7692307692307693
Epoch:  445       10 Batch loss: 0.067807 Batch F1: 0.7692307692307693
Epoch:  445       11 Batch loss: 0.086506 Batch F1: 0.6666666666666666
Epoch:  445       12 Batch loss: 0.053899 Batch F1: 1.0
Train Avg Loss  445: 0.070021

Train Avg F1  445: 0.7368909470302659

Val Avg Loss  445: 0.062627

Val Avg F1  445:  0.7920751633986927

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 446
--------------------------------------------------------------
Epoch:  446        1 Batch loss: 0.067594 Batch F1: 0.8750000000000001
Epoch:  446        2 Batch loss: 0.068730 Batch F1: 0.8695652173913044
Epoch:  446        3 Batch loss: 0.064894 Batch F1: 0.8
Epoch:  446        4 Batch loss: 0.066567 Batch F1: 0.8571428571428571
Epoch:  446        5 Batch loss: 0.074553 Batch F1: 0.8750000000000001
Epoch:  446        6 Batch loss: 0.038034 Batch F1: 1.0
Epoch:  446        7 Batch loss: 0.082935 Batch F1: 0.7000000000000001
Epoch:  446        8 Batch loss: 0.040133 Batch F1: 0.6666666666666666
Epoch:  446        9 Batch loss: 0.074983 Batch F1: 0.6153846153846153
Epoch:  446       10 Batch loss: 0.095724 Batch F1: 0.47058823529411764
Epoch:  446       11 Batch loss: 0.071821 Batch F1: 0.6666666666666666
Epoch:  446       12 Batch loss: 0.085881 Batch F1: 0.8750000000000001
Train Avg Loss  446: 0.069321

Train Avg F1  446: 0.772584521545519

Val Avg Loss  446: 0.065371

Val Avg F1  446:  0.9552941176470588

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 447
--------------------------------------------------------------
Epoch:  447        1 Batch loss: 0.052207 Batch F1: 1.0
Epoch:  447        2 Batch loss: 0.051163 Batch F1: 0.923076923076923
Epoch:  447        3 Batch loss: 0.075884 Batch F1: 0.5714285714285715
Epoch:  447        4 Batch loss: 0.068894 Batch F1: 0.7142857142857143
Epoch:  447        5 Batch loss: 0.046038 Batch F1: 0.6666666666666666
Epoch:  447        6 Batch loss: 0.069417 Batch F1: 0.7058823529411764
Epoch:  447        7 Batch loss: 0.061351 Batch F1: 0.7142857142857143
Epoch:  447        8 Batch loss: 0.086704 Batch F1: 0.7777777777777777
Epoch:  447        9 Batch loss: 0.074128 Batch F1: 0.7272727272727272
Epoch:  447       10 Batch loss: 0.090475 Batch F1: 0.7826086956521738
Epoch:  447       11 Batch loss: 0.078293 Batch F1: 0.8
Epoch:  447       12 Batch loss: 0.069188 Batch F1: 0.8750000000000001
Train Avg Loss  447: 0.068645

Train Avg F1  447: 0.7715237619489538

Val Avg Loss  447: 0.068795

Val Avg F1  447:  0.9271929824561405

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 448
--------------------------------------------------------------
Epoch:  448        1 Batch loss: 0.062476 Batch F1: 0.9333333333333333
Epoch:  448        2 Batch loss: 0.078794 Batch F1: 0.962962962962963
Epoch:  448        3 Batch loss: 0.074651 Batch F1: 0.6666666666666666
Epoch:  448        4 Batch loss: 0.068664 Batch F1: 0.6666666666666666
Epoch:  448        5 Batch loss: 0.068043 Batch F1: 0.6666666666666666
Epoch:  448        6 Batch loss: 0.038915 Batch F1: 0.8571428571428571
Epoch:  448        7 Batch loss: 0.062498 Batch F1: 0.7692307692307693
Epoch:  448        8 Batch loss: 0.077309 Batch F1: 0.19999999999999998
Epoch:  448        9 Batch loss: 0.073075 Batch F1: 0.5
Epoch:  448       10 Batch loss: 0.064623 Batch F1: 0.5
Epoch:  448       11 Batch loss: 0.077793 Batch F1: 0.5882352941176471
Epoch:  448       12 Batch loss: 0.080143 Batch F1: 0.8571428571428571
Train Avg Loss  448: 0.068915

Train Avg F1  448: 0.6806706728275356

Val Avg Loss  448: 0.065652

Val Avg F1  448:  0.936421937195931

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 449
--------------------------------------------------------------
Epoch:  449        1 Batch loss: 0.073435 Batch F1: 0.962962962962963
Epoch:  449        2 Batch loss: 0.058150 Batch F1: 0.9333333333333333
Epoch:  449        3 Batch loss: 0.078233 Batch F1: 0.9166666666666666
Epoch:  449        4 Batch loss: 0.069144 Batch F1: 0.7142857142857143
Epoch:  449        5 Batch loss: 0.055957 Batch F1: 0.5
Epoch:  449        6 Batch loss: 0.061570 Batch F1: 0.33333333333333337
Epoch:  449        7 Batch loss: 0.089064 Batch F1: 0.5882352941176471
Epoch:  449        8 Batch loss: 0.053580 Batch F1: 0.8333333333333333
Epoch:  449        9 Batch loss: 0.070386 Batch F1: 0.8571428571428571
Epoch:  449       10 Batch loss: 0.062863 Batch F1: 0.9523809523809523
Epoch:  449       11 Batch loss: 0.058545 Batch F1: 0.8
Epoch:  449       12 Batch loss: 0.088881 Batch F1: 0.8571428571428571
Train Avg Loss  449: 0.068317

Train Avg F1  449: 0.770734775391638

Val Avg Loss  449: 0.066039

Val Avg F1  449:  0.9051113360323886

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 450
--------------------------------------------------------------
Epoch:  450        1 Batch loss: 0.057484 Batch F1: 1.0
Epoch:  450        2 Batch loss: 0.068913 Batch F1: 0.9473684210526316
Epoch:  450        3 Batch loss: 0.078593 Batch F1: 0.888888888888889
Epoch:  450        4 Batch loss: 0.065583 Batch F1: 0.9565217391304348
Epoch:  450        5 Batch loss: 0.073713 Batch F1: 0.9411764705882353
Epoch:  450        6 Batch loss: 0.062357 Batch F1: 0.8333333333333333
Epoch:  450        7 Batch loss: 0.070745 Batch F1: 0.5
Epoch:  450        8 Batch loss: 0.065051 Batch F1: 0.6153846153846153
Epoch:  450        9 Batch loss: 0.084083 Batch F1: 0.19999999999999998
Epoch:  450       10 Batch loss: 0.073679 Batch F1: 0.5714285714285715
Epoch:  450       11 Batch loss: 0.053392 Batch F1: 0.8333333333333333
Epoch:  450       12 Batch loss: 0.064604 Batch F1: 0.7272727272727273
Train Avg Loss  450: 0.068183

Train Avg F1  450: 0.7512256750343975

Val Avg Loss  450: 0.063000

Val Avg F1  450:  0.9361413043478262

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 451
--------------------------------------------------------------
Epoch:  451        1 Batch loss: 0.055632 Batch F1: 1.0
Epoch:  451        2 Batch loss: 0.079257 Batch F1: 0.9
Epoch:  451        3 Batch loss: 0.069049 Batch F1: 0.9523809523809523
Epoch:  451        4 Batch loss: 0.066631 Batch F1: 0.8750000000000001
Epoch:  451        5 Batch loss: 0.068068 Batch F1: 0.9473684210526316
Epoch:  451        6 Batch loss: 0.063801 Batch F1: 0.9333333333333333
Epoch:  451        7 Batch loss: 0.077054 Batch F1: 0.3636363636363636
Epoch:  451        8 Batch loss: 0.066263 Batch F1: 0.25
Epoch:  451        9 Batch loss: 0.045586 Batch F1: 0.6666666666666666
Epoch:  451       10 Batch loss: 0.078639 Batch F1: 0.7499999999999999
Epoch:  451       11 Batch loss: 0.069074 Batch F1: 0.4
Epoch:  451       12 Batch loss: 0.050560 Batch F1: 0.8571428571428571
Train Avg Loss  451: 0.065801

Train Avg F1  451: 0.7412940495177338

Val Avg Loss  451: 0.062449

Val Avg F1  451:  0.9144478844169248

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 452
--------------------------------------------------------------
Epoch:  452        1 Batch loss: 0.074297 Batch F1: 0.888888888888889
Epoch:  452        2 Batch loss: 0.076144 Batch F1: 0.8571428571428571
Epoch:  452        3 Batch loss: 0.071363 Batch F1: 0.7692307692307693
Epoch:  452        4 Batch loss: 0.070397 Batch F1: 0.625
Epoch:  452        5 Batch loss: 0.065451 Batch F1: 0.5714285714285715
Epoch:  452        6 Batch loss: 0.072839 Batch F1: 0.9090909090909091
Epoch:  452        7 Batch loss: 0.058661 Batch F1: 0.7692307692307692
Epoch:  452        8 Batch loss: 0.081533 Batch F1: 0.8235294117647058
Epoch:  452        9 Batch loss: 0.072835 Batch F1: 0.9090909090909091
Epoch:  452       10 Batch loss: 0.059610 Batch F1: 0.8333333333333334
Epoch:  452       11 Batch loss: 0.062414 Batch F1: 0.888888888888889
Epoch:  452       12 Batch loss: 0.042090 Batch F1: 0.8571428571428571
Train Avg Loss  452: 0.067303

Train Avg F1  452: 0.8084998471027882

Val Avg Loss  452: 0.067586

Val Avg F1  452:  0.5825757575757576

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 453
--------------------------------------------------------------
Epoch:  453        1 Batch loss: 0.057475 Batch F1: 0.5
Epoch:  453        2 Batch loss: 0.047612 Batch F1: 0.6666666666666666
Epoch:  453        3 Batch loss: 0.070700 Batch F1: 0.5
Epoch:  453        4 Batch loss: 0.058549 Batch F1: 0.7499999999999999
Epoch:  453        5 Batch loss: 0.067025 Batch F1: 0.4285714285714285
Epoch:  453        6 Batch loss: 0.071161 Batch F1: 0.8571428571428571
Epoch:  453        7 Batch loss: 0.051738 Batch F1: 1.0
Epoch:  453        8 Batch loss: 0.083579 Batch F1: 0.8571428571428571
Epoch:  453        9 Batch loss: 0.086183 Batch F1: 0.8571428571428572
Epoch:  453       10 Batch loss: 0.059602 Batch F1: 0.8888888888888888
Epoch:  453       11 Batch loss: 0.055270 Batch F1: 0.5714285714285715
Epoch:  453       12 Batch loss: 0.104224 Batch F1: 0.7368421052631579
Train Avg Loss  453: 0.067760

Train Avg F1  453: 0.7178188526872736

Val Avg Loss  453: 0.063085

Val Avg F1  453:  0.7784568372803666

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 454
--------------------------------------------------------------
Epoch:  454        1 Batch loss: 0.086487 Batch F1: 0.7000000000000001
Epoch:  454        2 Batch loss: 0.056439 Batch F1: 1.0
Epoch:  454        3 Batch loss: 0.075244 Batch F1: 0.923076923076923
Epoch:  454        4 Batch loss: 0.053244 Batch F1: 0.923076923076923
Epoch:  454        5 Batch loss: 0.065231 Batch F1: 0.9411764705882353
Epoch:  454        6 Batch loss: 0.065055 Batch F1: 0.9090909090909091
Epoch:  454        7 Batch loss: 0.071374 Batch F1: 1.0
Epoch:  454        8 Batch loss: 0.066102 Batch F1: 0.5
Epoch:  454        9 Batch loss: 0.083547 Batch F1: 0.4
Epoch:  454       10 Batch loss: 0.063263 Batch F1: 0.7142857142857143
Epoch:  454       11 Batch loss: 0.055252 Batch F1: 0.7272727272727273
Epoch:  454       12 Batch loss: 0.065785 Batch F1: 0.6
Train Avg Loss  454: 0.067252

Train Avg F1  454: 0.7781649722826193

Val Avg Loss  454: 0.065441

Val Avg F1  454:  0.5777777777777778

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 455
--------------------------------------------------------------
Epoch:  455        1 Batch loss: 0.043112 Batch F1: 0.8
Epoch:  455        2 Batch loss: 0.085726 Batch F1: 0.6666666666666666
Epoch:  455        3 Batch loss: 0.049620 Batch F1: 0.923076923076923
Epoch:  455        4 Batch loss: 0.077844 Batch F1: 0.8695652173913044
Epoch:  455        5 Batch loss: 0.081468 Batch F1: 0.8235294117647058
Epoch:  455        6 Batch loss: 0.080140 Batch F1: 0.8421052631578948
Epoch:  455        7 Batch loss: 0.066639 Batch F1: 0.8421052631578948
Epoch:  455        8 Batch loss: 0.049884 Batch F1: 0.5714285714285715
Epoch:  455        9 Batch loss: 0.081299 Batch F1: 0.4615384615384615
Epoch:  455       10 Batch loss: 0.083160 Batch F1: 0.6666666666666666
Epoch:  455       11 Batch loss: 0.078572 Batch F1: 0.5
Epoch:  455       12 Batch loss: 0.043638 Batch F1: 0.33333333333333337
Train Avg Loss  455: 0.068425

Train Avg F1  455: 0.6916679815152018

Val Avg Loss  455: 0.062361

Val Avg F1  455:  0.856359649122807

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 456
--------------------------------------------------------------
Epoch:  456        1 Batch loss: 0.074158 Batch F1: 0.8235294117647058
Epoch:  456        2 Batch loss: 0.055988 Batch F1: 0.9333333333333333
Epoch:  456        3 Batch loss: 0.067186 Batch F1: 0.8750000000000001
Epoch:  456        4 Batch loss: 0.046173 Batch F1: 0.9090909090909091
Epoch:  456        5 Batch loss: 0.060625 Batch F1: 0.6666666666666666
Epoch:  456        6 Batch loss: 0.063361 Batch F1: 0.5
Epoch:  456        7 Batch loss: 0.089075 Batch F1: 0.5333333333333333
Epoch:  456        8 Batch loss: 0.055223 Batch F1: 0.6
Epoch:  456        9 Batch loss: 0.071646 Batch F1: 0.625
Epoch:  456       10 Batch loss: 0.079166 Batch F1: 0.5882352941176471
Epoch:  456       11 Batch loss: 0.063950 Batch F1: 0.9523809523809523
Epoch:  456       12 Batch loss: 0.075313 Batch F1: 0.9090909090909091
Train Avg Loss  456: 0.066822

Train Avg F1  456: 0.7429717341482046

Val Avg Loss  456: 0.062155

Val Avg F1  456:  0.7732600732600733

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 457
--------------------------------------------------------------
Epoch:  457        1 Batch loss: 0.085990 Batch F1: 0.631578947368421
Epoch:  457        2 Batch loss: 0.046740 Batch F1: 0.9090909090909091
Epoch:  457        3 Batch loss: 0.053109 Batch F1: 0.7142857142857143
Epoch:  457        4 Batch loss: 0.068474 Batch F1: 0.8421052631578948
Epoch:  457        5 Batch loss: 0.070537 Batch F1: 0.7272727272727273
Epoch:  457        6 Batch loss: 0.071026 Batch F1: 0.6666666666666666
Epoch:  457        7 Batch loss: 0.055696 Batch F1: 0.9
Epoch:  457        8 Batch loss: 0.062664 Batch F1: 0.6153846153846153
Epoch:  457        9 Batch loss: 0.065712 Batch F1: 0.7272727272727273
Epoch:  457       10 Batch loss: 0.072594 Batch F1: 0.888888888888889
Epoch:  457       11 Batch loss: 0.075275 Batch F1: 0.8750000000000001
Epoch:  457       12 Batch loss: 0.076868 Batch F1: 0.875
Train Avg Loss  457: 0.067057

Train Avg F1  457: 0.7810455382823805

Val Avg Loss  457: 0.063863

Val Avg F1  457:  0.8314636752136751

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 458
--------------------------------------------------------------
Epoch:  458        1 Batch loss: 0.054582 Batch F1: 0.923076923076923
Epoch:  458        2 Batch loss: 0.072780 Batch F1: 0.6153846153846153
Epoch:  458        3 Batch loss: 0.087394 Batch F1: 0.5263157894736842
Epoch:  458        4 Batch loss: 0.046078 Batch F1: 1.0
Epoch:  458        5 Batch loss: 0.065955 Batch F1: 0.9600000000000001
Epoch:  458        6 Batch loss: 0.072801 Batch F1: 0.9600000000000001
Epoch:  458        7 Batch loss: 0.099300 Batch F1: 0.625
Epoch:  458        8 Batch loss: 0.047309 Batch F1: 1.0
Epoch:  458        9 Batch loss: 0.077561 Batch F1: 0.7142857142857143
Epoch:  458       10 Batch loss: 0.079639 Batch F1: 0.7058823529411764
Epoch:  458       11 Batch loss: 0.056607 Batch F1: 0.888888888888889
Epoch:  458       12 Batch loss: 0.060658 Batch F1: 0.4444444444444445
Train Avg Loss  458: 0.068389

Train Avg F1  458: 0.7802732273746206

Val Avg Loss  458: 0.072262

Val Avg F1  458:  0.5858974358974358

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 459
--------------------------------------------------------------
Epoch:  459        1 Batch loss: 0.065522 Batch F1: 0.8235294117647058
Epoch:  459        2 Batch loss: 0.059672 Batch F1: 0.8750000000000001
Epoch:  459        3 Batch loss: 0.069901 Batch F1: 0.7058823529411764
Epoch:  459        4 Batch loss: 0.079382 Batch F1: 0.625
Epoch:  459        5 Batch loss: 0.056720 Batch F1: 0.8333333333333333
Epoch:  459        6 Batch loss: 0.071133 Batch F1: 0.6666666666666666
Epoch:  459        7 Batch loss: 0.077174 Batch F1: 0.5333333333333333
Epoch:  459        8 Batch loss: 0.075452 Batch F1: 0.7692307692307693
Epoch:  459        9 Batch loss: 0.051947 Batch F1: 0.8571428571428571
Epoch:  459       10 Batch loss: 0.087885 Batch F1: 0.42857142857142855
Epoch:  459       11 Batch loss: 0.080115 Batch F1: 0.7999999999999999
Epoch:  459       12 Batch loss: 0.077902 Batch F1: 0.8333333333333333
Train Avg Loss  459: 0.071067

Train Avg F1  459: 0.7292519571931336

Val Avg Loss  459: 0.063325

Val Avg F1  459:  0.8127199597787833

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 460
--------------------------------------------------------------
Epoch:  460        1 Batch loss: 0.079974 Batch F1: 0.6666666666666666
Epoch:  460        2 Batch loss: 0.054951 Batch F1: 0.8421052631578948
Epoch:  460        3 Batch loss: 0.066273 Batch F1: 0.0
Epoch:  460        4 Batch loss: 0.100364 Batch F1: 0.47619047619047616
Epoch:  460        5 Batch loss: 0.075406 Batch F1: 0.8571428571428571
Epoch:  460        6 Batch loss: 0.053084 Batch F1: 1.0
Epoch:  460        7 Batch loss: 0.071433 Batch F1: 0.8421052631578948
Epoch:  460        8 Batch loss: 0.079847 Batch F1: 0.8571428571428571
Epoch:  460        9 Batch loss: 0.062865 Batch F1: 0.923076923076923
Epoch:  460       10 Batch loss: 0.060820 Batch F1: 0.6153846153846153
Epoch:  460       11 Batch loss: 0.070253 Batch F1: 0.4
Epoch:  460       12 Batch loss: 0.057934 Batch F1: 0.8333333333333333
Train Avg Loss  460: 0.069433

Train Avg F1  460: 0.6927623546044598

Val Avg Loss  460: 0.062072

Val Avg F1  460:  0.8856442577030812

Optimal Val loss (Epoch 358): 0.061408779583871365

Epoch 461
--------------------------------------------------------------
Epoch:  461        1 Batch loss: 0.075133 Batch F1: 0.7142857142857143
Epoch:  461        2 Batch loss: 0.069517 Batch F1: 1.0
Epoch:  461        3 Batch loss: 0.054662 Batch F1: 0.9333333333333333
Epoch:  461        4 Batch loss: 0.076213 Batch F1: 0.9565217391304348
Epoch:  461        5 Batch loss: 0.052146 Batch F1: 1.0
Epoch:  461        6 Batch loss: 0.069475 Batch F1: 0.6
Epoch:  461        7 Batch loss: 0.057496 Batch F1: 0.6153846153846153
Epoch:  461        8 Batch loss: 0.079805 Batch F1: 0.7368421052631579
Epoch:  461        9 Batch loss: 0.066836 Batch F1: 0.3636363636363636
Epoch:  461       10 Batch loss: 0.071436 Batch F1: 0.4615384615384615
Epoch:  461       11 Batch loss: 0.054442 Batch F1: 0.888888888888889
Epoch:  461       12 Batch loss: 0.075644 Batch F1: 0.8571428571428571
Train Avg Loss  461: 0.066900

Train Avg F1  461: 0.7606311732169856

Val Avg Loss  461: 0.061337

Val Avg F1  461:  0.8472222222222223

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 462
--------------------------------------------------------------
Epoch:  462        1 Batch loss: 0.061464 Batch F1: 0.8
Epoch:  462        2 Batch loss: 0.075674 Batch F1: 0.3636363636363636
Epoch:  462        3 Batch loss: 0.073270 Batch F1: 0.4615384615384615
Epoch:  462        4 Batch loss: 0.067967 Batch F1: 0.8
Epoch:  462        5 Batch loss: 0.044168 Batch F1: 1.0
Epoch:  462        6 Batch loss: 0.085496 Batch F1: 0.8695652173913044
Epoch:  462        7 Batch loss: 0.055733 Batch F1: 1.0
Epoch:  462        8 Batch loss: 0.057985 Batch F1: 1.0
Epoch:  462        9 Batch loss: 0.065052 Batch F1: 0.9090909090909091
Epoch:  462       10 Batch loss: 0.056636 Batch F1: 1.0
Epoch:  462       11 Batch loss: 0.085289 Batch F1: 0.7058823529411764
Epoch:  462       12 Batch loss: 0.071927 Batch F1: 0.7272727272727273
Train Avg Loss  462: 0.066722

Train Avg F1  462: 0.8030821693225785

Val Avg Loss  462: 0.063846

Val Avg F1  462:  0.6261904761904762

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 463
--------------------------------------------------------------
Epoch:  463        1 Batch loss: 0.059548 Batch F1: 0.4
Epoch:  463        2 Batch loss: 0.056763 Batch F1: 0.7499999999999999
Epoch:  463        3 Batch loss: 0.064427 Batch F1: 0.5714285714285715
Epoch:  463        4 Batch loss: 0.060823 Batch F1: 0.8
Epoch:  463        5 Batch loss: 0.074252 Batch F1: 0.7142857142857143
Epoch:  463        6 Batch loss: 0.073193 Batch F1: 0.9
Epoch:  463        7 Batch loss: 0.060866 Batch F1: 0.9411764705882353
Epoch:  463        8 Batch loss: 0.053884 Batch F1: 0.7499999999999999
Epoch:  463        9 Batch loss: 0.067947 Batch F1: 0.7777777777777778
Epoch:  463       10 Batch loss: 0.066273 Batch F1: 0.8333333333333333
Epoch:  463       11 Batch loss: 0.071430 Batch F1: 0.7142857142857143
Epoch:  463       12 Batch loss: 0.084901 Batch F1: 0.4615384615384615
Train Avg Loss  463: 0.066192

Train Avg F1  463: 0.717818836936484

Val Avg Loss  463: 0.063002

Val Avg F1  463:  0.7407925407925408

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 464
--------------------------------------------------------------
Epoch:  464        1 Batch loss: 0.050260 Batch F1: 0.7499999999999999
Epoch:  464        2 Batch loss: 0.055238 Batch F1: 0.5454545454545454
Epoch:  464        3 Batch loss: 0.084920 Batch F1: 0.761904761904762
Epoch:  464        4 Batch loss: 0.061717 Batch F1: 0.923076923076923
Epoch:  464        5 Batch loss: 0.055093 Batch F1: 0.8571428571428571
Epoch:  464        6 Batch loss: 0.068578 Batch F1: 0.5714285714285715
Epoch:  464        7 Batch loss: 0.066219 Batch F1: 0.7777777777777778
Epoch:  464        8 Batch loss: 0.078531 Batch F1: 0.2222222222222222
Epoch:  464        9 Batch loss: 0.067759 Batch F1: 0.5
Epoch:  464       10 Batch loss: 0.078182 Batch F1: 0.625
Epoch:  464       11 Batch loss: 0.076309 Batch F1: 0.9473684210526316
Epoch:  464       12 Batch loss: 0.061451 Batch F1: 0.9333333333333333
Train Avg Loss  464: 0.067021

Train Avg F1  464: 0.7012257844494686

Val Avg Loss  464: 0.064015

Val Avg F1  464:  0.920054945054945

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 465
--------------------------------------------------------------
Epoch:  465        1 Batch loss: 0.083195 Batch F1: 0.962962962962963
Epoch:  465        2 Batch loss: 0.063708 Batch F1: 0.6666666666666666
Epoch:  465        3 Batch loss: 0.046337 Batch F1: 1.0
Epoch:  465        4 Batch loss: 0.066383 Batch F1: 0.9473684210526316
Epoch:  465        5 Batch loss: 0.079674 Batch F1: 0.7777777777777778
Epoch:  465        6 Batch loss: 0.086942 Batch F1: 0.8
Epoch:  465        7 Batch loss: 0.063123 Batch F1: 0.8571428571428571
Epoch:  465        8 Batch loss: 0.060146 Batch F1: 0.8750000000000001
Epoch:  465        9 Batch loss: 0.073238 Batch F1: 0.7777777777777777
Epoch:  465       10 Batch loss: 0.053300 Batch F1: 0.8
Epoch:  465       11 Batch loss: 0.056055 Batch F1: 0.6666666666666666
Epoch:  465       12 Batch loss: 0.072875 Batch F1: 0.7142857142857143
Train Avg Loss  465: 0.067081

Train Avg F1  465: 0.8204707370277545

Val Avg Loss  465: 0.068297

Val Avg F1  465:  0.624908424908425

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 466
--------------------------------------------------------------
Epoch:  466        1 Batch loss: 0.080472 Batch F1: 0.18181818181818182
Epoch:  466        2 Batch loss: 0.077747 Batch F1: 0.4615384615384615
Epoch:  466        3 Batch loss: 0.061090 Batch F1: 0.7272727272727273
Epoch:  466        4 Batch loss: 0.063226 Batch F1: 0.25
Epoch:  466        5 Batch loss: 0.061325 Batch F1: 0.6666666666666666
Epoch:  466        6 Batch loss: 0.069142 Batch F1: 0.9
Epoch:  466        7 Batch loss: 0.063592 Batch F1: 0.8333333333333333
Epoch:  466        8 Batch loss: 0.061267 Batch F1: 0.8750000000000001
Epoch:  466        9 Batch loss: 0.076959 Batch F1: 0.923076923076923
Epoch:  466       10 Batch loss: 0.080469 Batch F1: 0.7368421052631579
Epoch:  466       11 Batch loss: 0.069016 Batch F1: 1.0
Epoch:  466       12 Batch loss: 0.068231 Batch F1: 0.7499999999999999
Train Avg Loss  466: 0.069378

Train Avg F1  466: 0.6921290332474542

Val Avg Loss  466: 0.063138

Val Avg F1  466:  0.7178167420814479

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 467
--------------------------------------------------------------
Epoch:  467        1 Batch loss: 0.045561 Batch F1: 0.6666666666666666
Epoch:  467        2 Batch loss: 0.107046 Batch F1: 0.15384615384615385
Epoch:  467        3 Batch loss: 0.078177 Batch F1: 0.5
Epoch:  467        4 Batch loss: 0.055477 Batch F1: 0.33333333333333337
Epoch:  467        5 Batch loss: 0.075567 Batch F1: 0.6153846153846153
Epoch:  467        6 Batch loss: 0.072665 Batch F1: 0.4615384615384615
Epoch:  467        7 Batch loss: 0.073051 Batch F1: 0.631578947368421
Epoch:  467        8 Batch loss: 0.046662 Batch F1: 1.0
Epoch:  467        9 Batch loss: 0.072931 Batch F1: 0.888888888888889
Epoch:  467       10 Batch loss: 0.086093 Batch F1: 0.9285714285714286
Epoch:  467       11 Batch loss: 0.068304 Batch F1: 0.7999999999999999
Epoch:  467       12 Batch loss: 0.065617 Batch F1: 0.9333333333333333
Train Avg Loss  467: 0.070596

Train Avg F1  467: 0.6594284857442753

Val Avg Loss  467: 0.064428

Val Avg F1  467:  0.6833333333333333

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 468
--------------------------------------------------------------
Epoch:  468        1 Batch loss: 0.056863 Batch F1: 0.923076923076923
Epoch:  468        2 Batch loss: 0.083511 Batch F1: 0.5714285714285715
Epoch:  468        3 Batch loss: 0.059302 Batch F1: 0.5454545454545454
Epoch:  468        4 Batch loss: 0.063318 Batch F1: 0.8750000000000001
Epoch:  468        5 Batch loss: 0.079962 Batch F1: 0.8235294117647058
Epoch:  468        6 Batch loss: 0.051295 Batch F1: 0.888888888888889
Epoch:  468        7 Batch loss: 0.079703 Batch F1: 0.6
Epoch:  468        8 Batch loss: 0.073661 Batch F1: 0.6666666666666666
Epoch:  468        9 Batch loss: 0.059039 Batch F1: 0.6
Epoch:  468       10 Batch loss: 0.063770 Batch F1: 0.7272727272727273
Epoch:  468       11 Batch loss: 0.068998 Batch F1: 0.7777777777777778
Epoch:  468       12 Batch loss: 0.081487 Batch F1: 0.8
Train Avg Loss  468: 0.068409

Train Avg F1  468: 0.7332579593609005

Val Avg Loss  468: 0.063705

Val Avg F1  468:  0.9130718954248367

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 469
--------------------------------------------------------------
Epoch:  469        1 Batch loss: 0.058243 Batch F1: 1.0
Epoch:  469        2 Batch loss: 0.081099 Batch F1: 0.8000000000000002
Epoch:  469        3 Batch loss: 0.063170 Batch F1: 0.9333333333333333
Epoch:  469        4 Batch loss: 0.062202 Batch F1: 0.9
Epoch:  469        5 Batch loss: 0.065756 Batch F1: 0.6666666666666666
Epoch:  469        6 Batch loss: 0.065323 Batch F1: 0.9411764705882353
Epoch:  469        7 Batch loss: 0.065034 Batch F1: 0.8571428571428571
Epoch:  469        8 Batch loss: 0.050935 Batch F1: 1.0
Epoch:  469        9 Batch loss: 0.082092 Batch F1: 0.5
Epoch:  469       10 Batch loss: 0.060720 Batch F1: 0.4
Epoch:  469       11 Batch loss: 0.075100 Batch F1: 0.9565217391304348
Epoch:  469       12 Batch loss: 0.083325 Batch F1: 0.888888888888889
Train Avg Loss  469: 0.067750

Train Avg F1  469: 0.8203108296458681

Val Avg Loss  469: 0.067057

Val Avg F1  469:  0.8852941176470588

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 470
--------------------------------------------------------------
Epoch:  470        1 Batch loss: 0.079116 Batch F1: 0.6666666666666666
Epoch:  470        2 Batch loss: 0.038781 Batch F1: 0.5
Epoch:  470        3 Batch loss: 0.092394 Batch F1: 0.42857142857142855
Epoch:  470        4 Batch loss: 0.081363 Batch F1: 0.0
Epoch:  470        5 Batch loss: 0.045640 Batch F1: 0.33333333333333337
Epoch:  470        6 Batch loss: 0.084493 Batch F1: 0.8666666666666666
Epoch:  470        7 Batch loss: 0.071968 Batch F1: 0.8
Epoch:  470        8 Batch loss: 0.063371 Batch F1: 0.5714285714285715
Epoch:  470        9 Batch loss: 0.056556 Batch F1: 0.9333333333333333
Epoch:  470       10 Batch loss: 0.089387 Batch F1: 0.33333333333333337
Epoch:  470       11 Batch loss: 0.073011 Batch F1: 0.5
Epoch:  470       12 Batch loss: 0.089215 Batch F1: 0.962962962962963
Train Avg Loss  470: 0.072108

Train Avg F1  470: 0.5746913580246913

Val Avg Loss  470: 0.067614

Val Avg F1  470:  0.9360187553282182

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 471
--------------------------------------------------------------
Epoch:  471        1 Batch loss: 0.074147 Batch F1: 0.9090909090909091
Epoch:  471        2 Batch loss: 0.072505 Batch F1: 0.8421052631578948
Epoch:  471        3 Batch loss: 0.068396 Batch F1: 0.9411764705882353
Epoch:  471        4 Batch loss: 0.063343 Batch F1: 0.888888888888889
Epoch:  471        5 Batch loss: 0.057111 Batch F1: 1.0
Epoch:  471        6 Batch loss: 0.074411 Batch F1: 0.7777777777777778
Epoch:  471        7 Batch loss: 0.075776 Batch F1: 0.625
Epoch:  471        8 Batch loss: 0.086529 Batch F1: 0.3076923076923077
Epoch:  471        9 Batch loss: 0.076204 Batch F1: 0.8571428571428571
Epoch:  471       10 Batch loss: 0.063501 Batch F1: 0.9333333333333333
Epoch:  471       11 Batch loss: 0.051846 Batch F1: 1.0
Epoch:  471       12 Batch loss: 0.066155 Batch F1: 0.7692307692307693
Train Avg Loss  471: 0.069160

Train Avg F1  471: 0.8209532147419144

Val Avg Loss  471: 0.062288

Val Avg F1  471:  0.7925420168067225

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 472
--------------------------------------------------------------
Epoch:  472        1 Batch loss: 0.062491 Batch F1: 0.9333333333333333
Epoch:  472        2 Batch loss: 0.049046 Batch F1: 0.923076923076923
Epoch:  472        3 Batch loss: 0.058171 Batch F1: 0.33333333333333337
Epoch:  472        4 Batch loss: 0.090864 Batch F1: 0.47058823529411764
Epoch:  472        5 Batch loss: 0.072273 Batch F1: 0.5882352941176471
Epoch:  472        6 Batch loss: 0.085529 Batch F1: 0.7058823529411764
Epoch:  472        7 Batch loss: 0.060719 Batch F1: 1.0
Epoch:  472        8 Batch loss: 0.060969 Batch F1: 0.9333333333333333
Epoch:  472        9 Batch loss: 0.065440 Batch F1: 0.9473684210526316
Epoch:  472       10 Batch loss: 0.060307 Batch F1: 0.9
Epoch:  472       11 Batch loss: 0.096711 Batch F1: 0.761904761904762
Epoch:  472       12 Batch loss: 0.057223 Batch F1: 0.7499999999999999
Train Avg Loss  472: 0.068312

Train Avg F1  472: 0.7705879990322716

Val Avg Loss  472: 0.064659

Val Avg F1  472:  0.6416396103896104

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 473
--------------------------------------------------------------
Epoch:  473        1 Batch loss: 0.062376 Batch F1: 0.5454545454545454
Epoch:  473        2 Batch loss: 0.060622 Batch F1: 0.5
Epoch:  473        3 Batch loss: 0.077601 Batch F1: 0.5
Epoch:  473        4 Batch loss: 0.058360 Batch F1: 0.8
Epoch:  473        5 Batch loss: 0.055717 Batch F1: 0.9090909090909091
Epoch:  473        6 Batch loss: 0.087505 Batch F1: 0.8695652173913044
Epoch:  473        7 Batch loss: 0.037902 Batch F1: 0.888888888888889
Epoch:  473        8 Batch loss: 0.069988 Batch F1: 0.6
Epoch:  473        9 Batch loss: 0.064260 Batch F1: 0.5714285714285715
Epoch:  473       10 Batch loss: 0.079184 Batch F1: 0.9
Epoch:  473       11 Batch loss: 0.087339 Batch F1: 0.761904761904762
Epoch:  473       12 Batch loss: 0.075680 Batch F1: 0.7999999999999999
Train Avg Loss  473: 0.068044

Train Avg F1  473: 0.7205277411799152

Val Avg Loss  473: 0.061791

Val Avg F1  473:  0.9244200244200245

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 474
--------------------------------------------------------------
Epoch:  474        1 Batch loss: 0.079974 Batch F1: 0.88
Epoch:  474        2 Batch loss: 0.050417 Batch F1: 1.0
Epoch:  474        3 Batch loss: 0.077759 Batch F1: 0.888888888888889
Epoch:  474        4 Batch loss: 0.078219 Batch F1: 0.9565217391304348
Epoch:  474        5 Batch loss: 0.056860 Batch F1: 0.6
Epoch:  474        6 Batch loss: 0.074823 Batch F1: 0.4615384615384615
Epoch:  474        7 Batch loss: 0.055472 Batch F1: 0.5
Epoch:  474        8 Batch loss: 0.058301 Batch F1: 0.6
Epoch:  474        9 Batch loss: 0.056058 Batch F1: 0.7272727272727273
Epoch:  474       10 Batch loss: 0.091395 Batch F1: 0.2857142857142857
Epoch:  474       11 Batch loss: 0.072249 Batch F1: 0.6666666666666666
Epoch:  474       12 Batch loss: 0.058346 Batch F1: 1.0
Train Avg Loss  474: 0.067489

Train Avg F1  474: 0.7138835641009553

Val Avg Loss  474: 0.062675

Val Avg F1  474:  0.9141025641025641

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 475
--------------------------------------------------------------
Epoch:  475        1 Batch loss: 0.062476 Batch F1: 0.8750000000000001
Epoch:  475        2 Batch loss: 0.057696 Batch F1: 0.923076923076923
Epoch:  475        3 Batch loss: 0.061369 Batch F1: 0.7272727272727273
Epoch:  475        4 Batch loss: 0.057598 Batch F1: 0.8571428571428571
Epoch:  475        5 Batch loss: 0.063942 Batch F1: 0.7499999999999999
Epoch:  475        6 Batch loss: 0.040010 Batch F1: 0.8571428571428571
Epoch:  475        7 Batch loss: 0.053943 Batch F1: 0.888888888888889
Epoch:  475        8 Batch loss: 0.080181 Batch F1: 0.5
Epoch:  475        9 Batch loss: 0.085480 Batch F1: 0.42857142857142855
Epoch:  475       10 Batch loss: 0.085430 Batch F1: 0.8333333333333333
Epoch:  475       11 Batch loss: 0.097528 Batch F1: 0.7368421052631579
Epoch:  475       12 Batch loss: 0.086659 Batch F1: 1.0
Train Avg Loss  475: 0.069359

Train Avg F1  475: 0.781439260057681

Val Avg Loss  475: 0.064029

Val Avg F1  475:  0.8340382205513784

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 476
--------------------------------------------------------------
Epoch:  476        1 Batch loss: 0.063424 Batch F1: 0.9333333333333333
Epoch:  476        2 Batch loss: 0.042386 Batch F1: 0.4
Epoch:  476        3 Batch loss: 0.067861 Batch F1: 0.0
Epoch:  476        4 Batch loss: 0.051459 Batch F1: 0.33333333333333337
Epoch:  476        5 Batch loss: 0.096890 Batch F1: 0.0
Epoch:  476        6 Batch loss: 0.086668 Batch F1: 0.8235294117647058
Epoch:  476        7 Batch loss: 0.088039 Batch F1: 0.888888888888889
Epoch:  476        8 Batch loss: 0.080402 Batch F1: 0.9600000000000001
Epoch:  476        9 Batch loss: 0.099671 Batch F1: 0.7368421052631579
Epoch:  476       10 Batch loss: 0.061948 Batch F1: 0.5454545454545454
Epoch:  476       11 Batch loss: 0.050765 Batch F1: 0.7272727272727273
Epoch:  476       12 Batch loss: 0.079733 Batch F1: 0.5454545454545454
Train Avg Loss  476: 0.072437

Train Avg F1  476: 0.5745090742304365

Val Avg Loss  476: 0.071983

Val Avg F1  476:  0.6891359414579229

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 477
--------------------------------------------------------------
Epoch:  477        1 Batch loss: 0.081948 Batch F1: 0.5714285714285714
Epoch:  477        2 Batch loss: 0.063216 Batch F1: 0.6666666666666666
Epoch:  477        3 Batch loss: 0.062910 Batch F1: 0.0
Epoch:  477        4 Batch loss: 0.105352 Batch F1: 0.15384615384615385
Epoch:  477        5 Batch loss: 0.067995 Batch F1: 0.9333333333333333
Epoch:  477        6 Batch loss: 0.082709 Batch F1: 0.9473684210526316
Epoch:  477        7 Batch loss: 0.071613 Batch F1: 0.5714285714285715
Epoch:  477        8 Batch loss: 0.040423 Batch F1: 0.7499999999999999
Epoch:  477        9 Batch loss: 0.063105 Batch F1: 0.19999999999999998
Epoch:  477       10 Batch loss: 0.103503 Batch F1: 0.5555555555555556
Epoch:  477       11 Batch loss: 0.078811 Batch F1: 0.9473684210526316
Epoch:  477       12 Batch loss: 0.089065 Batch F1: 0.9
Train Avg Loss  477: 0.075887

Train Avg F1  477: 0.5997496411970097

Val Avg Loss  477: 0.066142

Val Avg F1  477:  0.9266816774556712

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 478
--------------------------------------------------------------
Epoch:  478        1 Batch loss: 0.069778 Batch F1: 1.0
Epoch:  478        2 Batch loss: 0.049028 Batch F1: 0.6666666666666666
Epoch:  478        3 Batch loss: 0.054622 Batch F1: 0.5714285714285715
Epoch:  478        4 Batch loss: 0.048550 Batch F1: 0.5
Epoch:  478        5 Batch loss: 0.068350 Batch F1: 0.5454545454545454
Epoch:  478        6 Batch loss: 0.114146 Batch F1: 0.6666666666666666
Epoch:  478        7 Batch loss: 0.067355 Batch F1: 1.0
Epoch:  478        8 Batch loss: 0.064205 Batch F1: 0.9
Epoch:  478        9 Batch loss: 0.069963 Batch F1: 0.9166666666666666
Epoch:  478       10 Batch loss: 0.073826 Batch F1: 0.875
Epoch:  478       11 Batch loss: 0.070745 Batch F1: 0.8571428571428571
Epoch:  478       12 Batch loss: 0.096908 Batch F1: 0.9
Train Avg Loss  478: 0.070623

Train Avg F1  478: 0.7832521645021645

Val Avg Loss  478: 0.065112

Val Avg F1  478:  0.7627819548872181

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 479
--------------------------------------------------------------
Epoch:  479        1 Batch loss: 0.111451 Batch F1: 0.7272727272727273
Epoch:  479        2 Batch loss: 0.055857 Batch F1: 1.0
Epoch:  479        3 Batch loss: 0.071880 Batch F1: 0.8235294117647058
Epoch:  479        4 Batch loss: 0.086365 Batch F1: 0.782608695652174
Epoch:  479        5 Batch loss: 0.071269 Batch F1: 0.8
Epoch:  479        6 Batch loss: 0.058983 Batch F1: 0.923076923076923
Epoch:  479        7 Batch loss: 0.077690 Batch F1: 0.8
Epoch:  479        8 Batch loss: 0.071502 Batch F1: 0.7142857142857143
Epoch:  479        9 Batch loss: 0.079371 Batch F1: 0.5714285714285715
Epoch:  479       10 Batch loss: 0.069314 Batch F1: 0.4
Epoch:  479       11 Batch loss: 0.044502 Batch F1: 0.7499999999999999
Epoch:  479       12 Batch loss: 0.075829 Batch F1: 0.9333333333333333
Train Avg Loss  479: 0.072834

Train Avg F1  479: 0.7687946147345124

Val Avg Loss  479: 0.065713

Val Avg F1  479:  0.8857600732600732

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 480
--------------------------------------------------------------
Epoch:  480        1 Batch loss: 0.074776 Batch F1: 0.888888888888889
Epoch:  480        2 Batch loss: 0.054886 Batch F1: 0.888888888888889
Epoch:  480        3 Batch loss: 0.072087 Batch F1: 0.5454545454545454
Epoch:  480        4 Batch loss: 0.077309 Batch F1: 0.5
Epoch:  480        5 Batch loss: 0.049218 Batch F1: 0.4
Epoch:  480        6 Batch loss: 0.105927 Batch F1: 0.7586206896551725
Epoch:  480        7 Batch loss: 0.066703 Batch F1: 0.7142857142857143
Epoch:  480        8 Batch loss: 0.063652 Batch F1: 1.0
Epoch:  480        9 Batch loss: 0.081309 Batch F1: 0.8333333333333334
Epoch:  480       10 Batch loss: 0.072128 Batch F1: 0.9473684210526316
Epoch:  480       11 Batch loss: 0.063510 Batch F1: 0.5714285714285715
Epoch:  480       12 Batch loss: 0.092669 Batch F1: 0.6666666666666666
Train Avg Loss  480: 0.072848

Train Avg F1  480: 0.7262446433045344

Val Avg Loss  480: 0.066994

Val Avg F1  480:  0.5763888888888888

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 481
--------------------------------------------------------------
Epoch:  481        1 Batch loss: 0.071488 Batch F1: 0.6666666666666666
Epoch:  481        2 Batch loss: 0.072552 Batch F1: 0.8421052631578948
Epoch:  481        3 Batch loss: 0.058172 Batch F1: 0.888888888888889
Epoch:  481        4 Batch loss: 0.052569 Batch F1: 1.0
Epoch:  481        5 Batch loss: 0.047431 Batch F1: 0.9090909090909091
Epoch:  481        6 Batch loss: 0.072654 Batch F1: 0.5
Epoch:  481        7 Batch loss: 0.083520 Batch F1: 0.5
Epoch:  481        8 Batch loss: 0.079837 Batch F1: 0.6666666666666666
Epoch:  481        9 Batch loss: 0.059321 Batch F1: 0.2857142857142857
Epoch:  481       10 Batch loss: 0.084142 Batch F1: 0.9166666666666666
Epoch:  481       11 Batch loss: 0.061858 Batch F1: 1.0
Epoch:  481       12 Batch loss: 0.095560 Batch F1: 0.8421052631578948
Train Avg Loss  481: 0.069925

Train Avg F1  481: 0.7514920508341562

Val Avg Loss  481: 0.068776

Val Avg F1  481:  0.9097091422776007

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 482
--------------------------------------------------------------
Epoch:  482        1 Batch loss: 0.070933 Batch F1: 0.962962962962963
Epoch:  482        2 Batch loss: 0.093758 Batch F1: 0.962962962962963
Epoch:  482        3 Batch loss: 0.061429 Batch F1: 1.0
Epoch:  482        4 Batch loss: 0.038048 Batch F1: 1.0
Epoch:  482        5 Batch loss: 0.087744 Batch F1: 0.8421052631578948
Epoch:  482        6 Batch loss: 0.090597 Batch F1: 0.8235294117647058
Epoch:  482        7 Batch loss: 0.059987 Batch F1: 0.7692307692307693
Epoch:  482        8 Batch loss: 0.041658 Batch F1: 0.4
Epoch:  482        9 Batch loss: 0.074795 Batch F1: 0.6153846153846153
Epoch:  482       10 Batch loss: 0.081247 Batch F1: 0.7368421052631579
Epoch:  482       11 Batch loss: 0.071233 Batch F1: 0.25
Epoch:  482       12 Batch loss: 0.050496 Batch F1: 0.923076923076923
Train Avg Loss  482: 0.068494

Train Avg F1  482: 0.7738412511503326

Val Avg Loss  482: 0.063874

Val Avg F1  482:  0.9248917748917749

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 483
--------------------------------------------------------------
Epoch:  483        1 Batch loss: 0.081973 Batch F1: 0.8421052631578948
Epoch:  483        2 Batch loss: 0.074154 Batch F1: 0.8888888888888888
Epoch:  483        3 Batch loss: 0.072133 Batch F1: 0.888888888888889
Epoch:  483        4 Batch loss: 0.066633 Batch F1: 0.9411764705882353
Epoch:  483        5 Batch loss: 0.075502 Batch F1: 0.8235294117647058
Epoch:  483        6 Batch loss: 0.048532 Batch F1: 1.0
Epoch:  483        7 Batch loss: 0.067651 Batch F1: 0.8750000000000001
Epoch:  483        8 Batch loss: 0.057807 Batch F1: 0.9090909090909091
Epoch:  483        9 Batch loss: 0.078328 Batch F1: 0.7272727272727273
Epoch:  483       10 Batch loss: 0.062405 Batch F1: 0.7692307692307693
Epoch:  483       11 Batch loss: 0.064089 Batch F1: 0.8333333333333333
Epoch:  483       12 Batch loss: 0.075175 Batch F1: 0.8571428571428571
Train Avg Loss  483: 0.068699

Train Avg F1  483: 0.8629716266132675

Val Avg Loss  483: 0.063259

Val Avg F1  483:  0.6731715652768284

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 484
--------------------------------------------------------------
Epoch:  484        1 Batch loss: 0.057485 Batch F1: 0.6
Epoch:  484        2 Batch loss: 0.052209 Batch F1: 0.6666666666666666
Epoch:  484        3 Batch loss: 0.084392 Batch F1: 0.7000000000000001
Epoch:  484        4 Batch loss: 0.070565 Batch F1: 0.3636363636363636
Epoch:  484        5 Batch loss: 0.066134 Batch F1: 0.4
Epoch:  484        6 Batch loss: 0.062860 Batch F1: 0.6666666666666666
Epoch:  484        7 Batch loss: 0.048133 Batch F1: 0.888888888888889
Epoch:  484        8 Batch loss: 0.077184 Batch F1: 0.8421052631578948
Epoch:  484        9 Batch loss: 0.088667 Batch F1: 0.9285714285714286
Epoch:  484       10 Batch loss: 0.076267 Batch F1: 0.9
Epoch:  484       11 Batch loss: 0.073026 Batch F1: 1.0
Epoch:  484       12 Batch loss: 0.050980 Batch F1: 0.8571428571428571
Train Avg Loss  484: 0.067325

Train Avg F1  484: 0.7344731778942305

Val Avg Loss  484: 0.063548

Val Avg F1  484:  0.9392857142857143

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 485
--------------------------------------------------------------
Epoch:  485        1 Batch loss: 0.063382 Batch F1: 0.923076923076923
Epoch:  485        2 Batch loss: 0.085446 Batch F1: 0.7777777777777778
Epoch:  485        3 Batch loss: 0.064540 Batch F1: 0.5714285714285715
Epoch:  485        4 Batch loss: 0.061797 Batch F1: 0.5714285714285715
Epoch:  485        5 Batch loss: 0.073177 Batch F1: 0.7368421052631579
Epoch:  485        6 Batch loss: 0.056233 Batch F1: 0.5454545454545454
Epoch:  485        7 Batch loss: 0.051722 Batch F1: 0.7142857142857143
Epoch:  485        8 Batch loss: 0.078573 Batch F1: 0.761904761904762
Epoch:  485        9 Batch loss: 0.058077 Batch F1: 0.8333333333333334
Epoch:  485       10 Batch loss: 0.055268 Batch F1: 0.6666666666666666
Epoch:  485       11 Batch loss: 0.082021 Batch F1: 0.8181818181818181
Epoch:  485       12 Batch loss: 0.073286 Batch F1: 0.8333333333333333
Train Avg Loss  485: 0.066960

Train Avg F1  485: 0.729476176844598

Val Avg Loss  485: 0.062964

Val Avg F1  485:  0.8267156862745098

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 486
--------------------------------------------------------------
Epoch:  486        1 Batch loss: 0.054495 Batch F1: 1.0
Epoch:  486        2 Batch loss: 0.080559 Batch F1: 0.6666666666666666
Epoch:  486        3 Batch loss: 0.062666 Batch F1: 0.9
Epoch:  486        4 Batch loss: 0.084772 Batch F1: 0.8333333333333333
Epoch:  486        5 Batch loss: 0.105616 Batch F1: 0.6086956521739131
Epoch:  486        6 Batch loss: 0.078843 Batch F1: 0.875
Epoch:  486        7 Batch loss: 0.053084 Batch F1: 1.0
Epoch:  486        8 Batch loss: 0.062922 Batch F1: 0.9600000000000001
Epoch:  486        9 Batch loss: 0.067728 Batch F1: 0.8750000000000001
Epoch:  486       10 Batch loss: 0.040132 Batch F1: 0.8571428571428571
Epoch:  486       11 Batch loss: 0.039685 Batch F1: 0.8571428571428571
Epoch:  486       12 Batch loss: 0.081677 Batch F1: 0.2222222222222222
Train Avg Loss  486: 0.067682

Train Avg F1  486: 0.8046002990568207

Val Avg Loss  486: 0.066763

Val Avg F1  486:  0.5880681818181819

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 487
--------------------------------------------------------------
Epoch:  487        1 Batch loss: 0.059293 Batch F1: 0.6
Epoch:  487        2 Batch loss: 0.055415 Batch F1: 0.6666666666666666
Epoch:  487        3 Batch loss: 0.079131 Batch F1: 0.5333333333333333
Epoch:  487        4 Batch loss: 0.069031 Batch F1: 0.5454545454545454
Epoch:  487        5 Batch loss: 0.104252 Batch F1: 0.5833333333333334
Epoch:  487        6 Batch loss: 0.057988 Batch F1: 0.8
Epoch:  487        7 Batch loss: 0.090951 Batch F1: 0.8421052631578948
Epoch:  487        8 Batch loss: 0.076114 Batch F1: 0.9600000000000001
Epoch:  487        9 Batch loss: 0.073958 Batch F1: 0.6
Epoch:  487       10 Batch loss: 0.049793 Batch F1: 1.0
Epoch:  487       11 Batch loss: 0.063549 Batch F1: 0.923076923076923
Epoch:  487       12 Batch loss: 0.062460 Batch F1: 0.9333333333333333
Train Avg Loss  487: 0.070161

Train Avg F1  487: 0.7489419498630024

Val Avg Loss  487: 0.065367

Val Avg F1  487:  0.6812266573295985

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 488
--------------------------------------------------------------
Epoch:  488        1 Batch loss: 0.063605 Batch F1: 0.888888888888889
Epoch:  488        2 Batch loss: 0.057239 Batch F1: 0.6
Epoch:  488        3 Batch loss: 0.072298 Batch F1: 0.5
Epoch:  488        4 Batch loss: 0.087785 Batch F1: 0.7857142857142858
Epoch:  488        5 Batch loss: 0.072744 Batch F1: 0.923076923076923
Epoch:  488        6 Batch loss: 0.093867 Batch F1: 0.8235294117647058
Epoch:  488        7 Batch loss: 0.053866 Batch F1: 0.9090909090909091
Epoch:  488        8 Batch loss: 0.044451 Batch F1: 0.5714285714285715
Epoch:  488        9 Batch loss: 0.075006 Batch F1: 0.2222222222222222
Epoch:  488       10 Batch loss: 0.051045 Batch F1: 0.7272727272727273
Epoch:  488       11 Batch loss: 0.084075 Batch F1: 0.0
Epoch:  488       12 Batch loss: 0.080991 Batch F1: 0.0
Train Avg Loss  488: 0.069748

Train Avg F1  488: 0.5792686616216028

Val Avg Loss  488: 0.071404

Val Avg F1  488:  0.6095238095238096

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 489
--------------------------------------------------------------
Epoch:  489        1 Batch loss: 0.060728 Batch F1: 0.5
Epoch:  489        2 Batch loss: 0.053311 Batch F1: 0.8
Epoch:  489        3 Batch loss: 0.070516 Batch F1: 0.6666666666666666
Epoch:  489        4 Batch loss: 0.088118 Batch F1: 0.8181818181818181
Epoch:  489        5 Batch loss: 0.072913 Batch F1: 0.823529411764706
Epoch:  489        6 Batch loss: 0.050400 Batch F1: 0.8
Epoch:  489        7 Batch loss: 0.068399 Batch F1: 0.5454545454545454
Epoch:  489        8 Batch loss: 0.116518 Batch F1: 0.5
Epoch:  489        9 Batch loss: 0.061246 Batch F1: 0.8571428571428571
Epoch:  489       10 Batch loss: 0.074488 Batch F1: 0.888888888888889
Epoch:  489       11 Batch loss: 0.077891 Batch F1: 0.9565217391304348
Epoch:  489       12 Batch loss: 0.048260 Batch F1: 0.7499999999999999
Train Avg Loss  489: 0.070232

Train Avg F1  489: 0.7421988272691599

Val Avg Loss  489: 0.063882

Val Avg F1  489:  0.6177350427350428

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 490
--------------------------------------------------------------
Epoch:  490        1 Batch loss: 0.085464 Batch F1: 0.7200000000000001
Epoch:  490        2 Batch loss: 0.058540 Batch F1: 0.923076923076923
Epoch:  490        3 Batch loss: 0.053275 Batch F1: 0.9333333333333333
Epoch:  490        4 Batch loss: 0.077513 Batch F1: 0.19999999999999998
Epoch:  490        5 Batch loss: 0.079796 Batch F1: 0.4
Epoch:  490        6 Batch loss: 0.055505 Batch F1: 0.33333333333333337
Epoch:  490        7 Batch loss: 0.073392 Batch F1: 0.7058823529411764
Epoch:  490        8 Batch loss: 0.052734 Batch F1: 0.7272727272727273
Epoch:  490        9 Batch loss: 0.063574 Batch F1: 0.7499999999999999
Epoch:  490       10 Batch loss: 0.104427 Batch F1: 0.846153846153846
Epoch:  490       11 Batch loss: 0.101602 Batch F1: 0.6666666666666667
Epoch:  490       12 Batch loss: 0.058818 Batch F1: 0.888888888888889
Train Avg Loss  490: 0.072053

Train Avg F1  490: 0.674550672638908

Val Avg Loss  490: 0.074750

Val Avg F1  490:  0.375222816399287

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 491
--------------------------------------------------------------
Epoch:  491        1 Batch loss: 0.058622 Batch F1: 0.4444444444444445
Epoch:  491        2 Batch loss: 0.075736 Batch F1: 0.0
Epoch:  491        3 Batch loss: 0.093248 Batch F1: 0.0
Epoch:  491        4 Batch loss: 0.082691 Batch F1: 0.6666666666666666
Epoch:  491        5 Batch loss: 0.072155 Batch F1: 0.9473684210526316
Epoch:  491        6 Batch loss: 0.061176 Batch F1: 0.9473684210526316
Epoch:  491        7 Batch loss: 0.075491 Batch F1: 0.8571428571428571
Epoch:  491        8 Batch loss: 0.082762 Batch F1: 0.7142857142857143
Epoch:  491        9 Batch loss: 0.061451 Batch F1: 0.6666666666666666
Epoch:  491       10 Batch loss: 0.088154 Batch F1: 0.5555555555555556
Epoch:  491       11 Batch loss: 0.113829 Batch F1: 0.7499999999999999
Epoch:  491       12 Batch loss: 0.109590 Batch F1: 0.0
Train Avg Loss  491: 0.081242

Train Avg F1  491: 0.5457915622389307

Val Avg Loss  491: 0.090205

Val Avg F1  491:  0.0

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 492
--------------------------------------------------------------
Epoch:  492        1 Batch loss: 0.107232 Batch F1: 0.0
Epoch:  492        2 Batch loss: 0.094497 Batch F1: 0.16666666666666669
Epoch:  492        3 Batch loss: 0.071121 Batch F1: 0.9090909090909091
Epoch:  492        4 Batch loss: 0.067144 Batch F1: 0.7499999999999999
Epoch:  492        5 Batch loss: 0.091157 Batch F1: 0.16666666666666669
Epoch:  492        6 Batch loss: 0.072542 Batch F1: 0.0
Epoch:  492        7 Batch loss: 0.083255 Batch F1: 0.33333333333333337
Epoch:  492        8 Batch loss: 0.087408 Batch F1: 0.6666666666666666
Epoch:  492        9 Batch loss: 0.103514 Batch F1: 0.8235294117647058
Epoch:  492       10 Batch loss: 0.058792 Batch F1: 1.0
Epoch:  492       11 Batch loss: 0.073364 Batch F1: 0.9333333333333333
Epoch:  492       12 Batch loss: 0.114105 Batch F1: 0.5555555555555556
Train Avg Loss  492: 0.085344

Train Avg F1  492: 0.5254035452564864

Val Avg Loss  492: 0.067489

Val Avg F1  492:  0.7044400452488688

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 493
--------------------------------------------------------------
Epoch:  493        1 Batch loss: 0.083942 Batch F1: 0.5333333333333333
Epoch:  493        2 Batch loss: 0.067732 Batch F1: 0.9411764705882353
Epoch:  493        3 Batch loss: 0.080883 Batch F1: 0.888888888888889
Epoch:  493        4 Batch loss: 0.062603 Batch F1: 0.923076923076923
Epoch:  493        5 Batch loss: 0.063490 Batch F1: 0.9473684210526316
Epoch:  493        6 Batch loss: 0.073806 Batch F1: 0.9090909090909091
Epoch:  493        7 Batch loss: 0.075052 Batch F1: 0.9
Epoch:  493        8 Batch loss: 0.062309 Batch F1: 0.8571428571428571
Epoch:  493        9 Batch loss: 0.059530 Batch F1: 0.9090909090909091
Epoch:  493       10 Batch loss: 0.080080 Batch F1: 0.4615384615384615
Epoch:  493       11 Batch loss: 0.086189 Batch F1: 0.42857142857142855
Epoch:  493       12 Batch loss: 0.072067 Batch F1: 0.7692307692307693
Train Avg Loss  493: 0.072307

Train Avg F1  493: 0.7890424476337791

Val Avg Loss  493: 0.065595

Val Avg F1  493:  0.7414148351648352

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 494
--------------------------------------------------------------
Epoch:  494        1 Batch loss: 0.053495 Batch F1: 0.923076923076923
Epoch:  494        2 Batch loss: 0.058327 Batch F1: 0.8
Epoch:  494        3 Batch loss: 0.097075 Batch F1: 0.4444444444444445
Epoch:  494        4 Batch loss: 0.070844 Batch F1: 0.5454545454545454
Epoch:  494        5 Batch loss: 0.049285 Batch F1: 0.5714285714285715
Epoch:  494        6 Batch loss: 0.047874 Batch F1: 0.7499999999999999
Epoch:  494        7 Batch loss: 0.068737 Batch F1: 0.6666666666666666
Epoch:  494        8 Batch loss: 0.064874 Batch F1: 0.4615384615384615
Epoch:  494        9 Batch loss: 0.065027 Batch F1: 0.4
Epoch:  494       10 Batch loss: 0.085308 Batch F1: 0.7777777777777778
Epoch:  494       11 Batch loss: 0.078443 Batch F1: 0.9166666666666666
Epoch:  494       12 Batch loss: 0.114156 Batch F1: 0.7692307692307693
Train Avg Loss  494: 0.071120

Train Avg F1  494: 0.668857068857069

Val Avg Loss  494: 0.064902

Val Avg F1  494:  0.9373774509803923

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 495
--------------------------------------------------------------
Epoch:  495        1 Batch loss: 0.058558 Batch F1: 1.0
Epoch:  495        2 Batch loss: 0.061980 Batch F1: 1.0
Epoch:  495        3 Batch loss: 0.038891 Batch F1: 1.0
Epoch:  495        4 Batch loss: 0.063678 Batch F1: 0.8333333333333333
Epoch:  495        5 Batch loss: 0.083988 Batch F1: 0.5555555555555556
Epoch:  495        6 Batch loss: 0.042359 Batch F1: 0.7499999999999999
Epoch:  495        7 Batch loss: 0.067509 Batch F1: 0.4
Epoch:  495        8 Batch loss: 0.113674 Batch F1: 0.5
Epoch:  495        9 Batch loss: 0.078396 Batch F1: 0.823529411764706
Epoch:  495       10 Batch loss: 0.078080 Batch F1: 0.875
Epoch:  495       11 Batch loss: 0.132289 Batch F1: 0.64
Epoch:  495       12 Batch loss: 0.044553 Batch F1: 0.8333333333333333
Train Avg Loss  495: 0.071996

Train Avg F1  495: 0.7675626361655774

Val Avg Loss  495: 0.064330

Val Avg F1  495:  0.6268939393939393

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 496
--------------------------------------------------------------
Epoch:  496        1 Batch loss: 0.057257 Batch F1: 0.5454545454545454
Epoch:  496        2 Batch loss: 0.058084 Batch F1: 0.6666666666666666
Epoch:  496        3 Batch loss: 0.088013 Batch F1: 0.375
Epoch:  496        4 Batch loss: 0.077112 Batch F1: 0.8235294117647058
Epoch:  496        5 Batch loss: 0.084182 Batch F1: 0.9565217391304348
Epoch:  496        6 Batch loss: 0.085597 Batch F1: 0.8333333333333333
Epoch:  496        7 Batch loss: 0.075597 Batch F1: 0.8333333333333334
Epoch:  496        8 Batch loss: 0.063980 Batch F1: 0.923076923076923
Epoch:  496        9 Batch loss: 0.068218 Batch F1: 0.9411764705882353
Epoch:  496       10 Batch loss: 0.069602 Batch F1: 0.9090909090909091
Epoch:  496       11 Batch loss: 0.060100 Batch F1: 0.9473684210526316
Epoch:  496       12 Batch loss: 0.052187 Batch F1: 0.5714285714285715
Train Avg Loss  496: 0.069994

Train Avg F1  496: 0.7771650270766908

Val Avg Loss  496: 0.067563

Val Avg F1  496:  0.5851648351648352

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 497
--------------------------------------------------------------
Epoch:  497        1 Batch loss: 0.097999 Batch F1: 0.5263157894736842
Epoch:  497        2 Batch loss: 0.097272 Batch F1: 0.4444444444444445
Epoch:  497        3 Batch loss: 0.072972 Batch F1: 0.8235294117647058
Epoch:  497        4 Batch loss: 0.061924 Batch F1: 0.9090909090909091
Epoch:  497        5 Batch loss: 0.063038 Batch F1: 0.888888888888889
Epoch:  497        6 Batch loss: 0.068943 Batch F1: 0.9473684210526316
Epoch:  497        7 Batch loss: 0.041245 Batch F1: 0.8
Epoch:  497        8 Batch loss: 0.070848 Batch F1: 0.7777777777777778
Epoch:  497        9 Batch loss: 0.064449 Batch F1: 0.7692307692307693
Epoch:  497       10 Batch loss: 0.079538 Batch F1: 0.3636363636363636
Epoch:  497       11 Batch loss: 0.079170 Batch F1: 0.7368421052631579
Epoch:  497       12 Batch loss: 0.061210 Batch F1: 0.0
Train Avg Loss  497: 0.071551

Train Avg F1  497: 0.6655937400519443

Val Avg Loss  497: 0.067170

Val Avg F1  497:  0.758288770053476

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 498
--------------------------------------------------------------
Epoch:  498        1 Batch loss: 0.067859 Batch F1: 0.6
Epoch:  498        2 Batch loss: 0.059390 Batch F1: 1.0
Epoch:  498        3 Batch loss: 0.058707 Batch F1: 0.8
Epoch:  498        4 Batch loss: 0.068194 Batch F1: 0.8421052631578948
Epoch:  498        5 Batch loss: 0.046982 Batch F1: 0.9333333333333333
Epoch:  498        6 Batch loss: 0.072322 Batch F1: 0.7142857142857143
Epoch:  498        7 Batch loss: 0.107046 Batch F1: 0.4444444444444445
Epoch:  498        8 Batch loss: 0.102466 Batch F1: 0.2857142857142857
Epoch:  498        9 Batch loss: 0.072209 Batch F1: 0.8571428571428571
Epoch:  498       10 Batch loss: 0.066925 Batch F1: 0.9523809523809523
Epoch:  498       11 Batch loss: 0.088879 Batch F1: 0.8571428571428571
Epoch:  498       12 Batch loss: 0.044081 Batch F1: 1.0
Train Avg Loss  498: 0.071255

Train Avg F1  498: 0.773879142300195

Val Avg Loss  498: 0.065343

Val Avg F1  498:  0.9290441176470589

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 499
--------------------------------------------------------------
Epoch:  499        1 Batch loss: 0.080605 Batch F1: 0.7999999999999999
Epoch:  499        2 Batch loss: 0.075809 Batch F1: 0.9411764705882353
Epoch:  499        3 Batch loss: 0.054479 Batch F1: 0.888888888888889
Epoch:  499        4 Batch loss: 0.078526 Batch F1: 0.8235294117647058
Epoch:  499        5 Batch loss: 0.077979 Batch F1: 0.7777777777777778
Epoch:  499        6 Batch loss: 0.041383 Batch F1: 0.8571428571428571
Epoch:  499        7 Batch loss: 0.050105 Batch F1: 0.8333333333333333
Epoch:  499        8 Batch loss: 0.085857 Batch F1: 0.375
Epoch:  499        9 Batch loss: 0.085334 Batch F1: 0.42857142857142855
Epoch:  499       10 Batch loss: 0.092750 Batch F1: 0.5
Epoch:  499       11 Batch loss: 0.062144 Batch F1: 0.8333333333333333
Epoch:  499       12 Batch loss: 0.073335 Batch F1: 0.9333333333333333
Train Avg Loss  499: 0.071526

Train Avg F1  499: 0.7493405695611578

Val Avg Loss  499: 0.064579

Val Avg F1  499:  0.9506620830150241

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 500
--------------------------------------------------------------
Epoch:  500        1 Batch loss: 0.063009 Batch F1: 0.9473684210526316
Epoch:  500        2 Batch loss: 0.081324 Batch F1: 0.9090909090909091
Epoch:  500        3 Batch loss: 0.063041 Batch F1: 0.923076923076923
Epoch:  500        4 Batch loss: 0.069273 Batch F1: 0.9411764705882353
Epoch:  500        5 Batch loss: 0.072306 Batch F1: 0.4
Epoch:  500        6 Batch loss: 0.074665 Batch F1: 0.6153846153846153
Epoch:  500        7 Batch loss: 0.051051 Batch F1: 0.8750000000000001
Epoch:  500        8 Batch loss: 0.071870 Batch F1: 0.8
Epoch:  500        9 Batch loss: 0.074282 Batch F1: 0.5882352941176471
Epoch:  500       10 Batch loss: 0.066952 Batch F1: 0.8
Epoch:  500       11 Batch loss: 0.056037 Batch F1: 1.0
Epoch:  500       12 Batch loss: 0.070857 Batch F1: 0.8
Train Avg Loss  500: 0.067889

Train Avg F1  500: 0.7999443861092468

Val Avg Loss  500: 0.062611

Val Avg F1  500:  0.6307692307692307

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 501
--------------------------------------------------------------
Epoch:  501        1 Batch loss: 0.056141 Batch F1: 0.6666666666666666
Epoch:  501        2 Batch loss: 0.054055 Batch F1: 0.7142857142857143
Epoch:  501        3 Batch loss: 0.078518 Batch F1: 0.2222222222222222
Epoch:  501        4 Batch loss: 0.052697 Batch F1: 0.5714285714285715
Epoch:  501        5 Batch loss: 0.088702 Batch F1: 0.631578947368421
Epoch:  501        6 Batch loss: 0.088737 Batch F1: 0.5
Epoch:  501        7 Batch loss: 0.061698 Batch F1: 0.9333333333333333
Epoch:  501        8 Batch loss: 0.052425 Batch F1: 0.9411764705882353
Epoch:  501        9 Batch loss: 0.073822 Batch F1: 0.9166666666666666
Epoch:  501       10 Batch loss: 0.080815 Batch F1: 0.9090909090909091
Epoch:  501       11 Batch loss: 0.050654 Batch F1: 1.0
Epoch:  501       12 Batch loss: 0.075733 Batch F1: 0.7272727272727273
Train Avg Loss  501: 0.067833

Train Avg F1  501: 0.7278101857436224

Val Avg Loss  501: 0.062707

Val Avg F1  501:  0.6458333333333333

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 502
--------------------------------------------------------------
Epoch:  502        1 Batch loss: 0.047373 Batch F1: 0.8333333333333333
Epoch:  502        2 Batch loss: 0.064593 Batch F1: 0.2857142857142857
Epoch:  502        3 Batch loss: 0.066271 Batch F1: 0.6
Epoch:  502        4 Batch loss: 0.062707 Batch F1: 0.5454545454545454
Epoch:  502        5 Batch loss: 0.046902 Batch F1: 0.7272727272727273
Epoch:  502        6 Batch loss: 0.083166 Batch F1: 0.5714285714285715
Epoch:  502        7 Batch loss: 0.088559 Batch F1: 0.18181818181818182
Epoch:  502        8 Batch loss: 0.059827 Batch F1: 0.6153846153846153
Epoch:  502        9 Batch loss: 0.087171 Batch F1: 0.7368421052631579
Epoch:  502       10 Batch loss: 0.059253 Batch F1: 1.0
Epoch:  502       11 Batch loss: 0.081721 Batch F1: 0.962962962962963
Epoch:  502       12 Batch loss: 0.075155 Batch F1: 1.0
Train Avg Loss  502: 0.068558

Train Avg F1  502: 0.6716842773860318

Val Avg Loss  502: 0.065854

Val Avg F1  502:  0.9208333333333333

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 503
--------------------------------------------------------------
Epoch:  503        1 Batch loss: 0.083791 Batch F1: 0.9230769230769231
Epoch:  503        2 Batch loss: 0.079388 Batch F1: 0.9090909090909091
Epoch:  503        3 Batch loss: 0.055629 Batch F1: 0.9090909090909091
Epoch:  503        4 Batch loss: 0.058950 Batch F1: 0.9411764705882353
Epoch:  503        5 Batch loss: 0.066183 Batch F1: 0.888888888888889
Epoch:  503        6 Batch loss: 0.063266 Batch F1: 0.5714285714285715
Epoch:  503        7 Batch loss: 0.070937 Batch F1: 0.6666666666666666
Epoch:  503        8 Batch loss: 0.079063 Batch F1: 0.7368421052631579
Epoch:  503        9 Batch loss: 0.075324 Batch F1: 0.4615384615384615
Epoch:  503       10 Batch loss: 0.060988 Batch F1: 0.7272727272727273
Epoch:  503       11 Batch loss: 0.069369 Batch F1: 0.8750000000000001
Epoch:  503       12 Batch loss: 0.062199 Batch F1: 0.8000000000000002
Train Avg Loss  503: 0.068757

Train Avg F1  503: 0.7841727194087876

Val Avg Loss  503: 0.063765

Val Avg F1  503:  0.913888888888889

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 504
--------------------------------------------------------------
Epoch:  504        1 Batch loss: 0.082346 Batch F1: 0.8695652173913044
Epoch:  504        2 Batch loss: 0.050667 Batch F1: 1.0
Epoch:  504        3 Batch loss: 0.072177 Batch F1: 0.8421052631578948
Epoch:  504        4 Batch loss: 0.070140 Batch F1: 0.5454545454545454
Epoch:  504        5 Batch loss: 0.049261 Batch F1: 0.5714285714285715
Epoch:  504        6 Batch loss: 0.049933 Batch F1: 0.7692307692307693
Epoch:  504        7 Batch loss: 0.084360 Batch F1: 0.631578947368421
Epoch:  504        8 Batch loss: 0.075582 Batch F1: 0.5
Epoch:  504        9 Batch loss: 0.071571 Batch F1: 0.888888888888889
Epoch:  504       10 Batch loss: 0.065652 Batch F1: 0.8
Epoch:  504       11 Batch loss: 0.066944 Batch F1: 0.6
Epoch:  504       12 Batch loss: 0.086576 Batch F1: 0.3636363636363636
Train Avg Loss  504: 0.068767

Train Avg F1  504: 0.6984907138797299

Val Avg Loss  504: 0.064194

Val Avg F1  504:  0.6368686868686869

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 505
--------------------------------------------------------------
Epoch:  505        1 Batch loss: 0.072144 Batch F1: 0.5
Epoch:  505        2 Batch loss: 0.053973 Batch F1: 0.8571428571428571
Epoch:  505        3 Batch loss: 0.066621 Batch F1: 0.4
Epoch:  505        4 Batch loss: 0.054852 Batch F1: 0.6
Epoch:  505        5 Batch loss: 0.055313 Batch F1: 0.4444444444444445
Epoch:  505        6 Batch loss: 0.099909 Batch F1: 0.6956521739130436
Epoch:  505        7 Batch loss: 0.075041 Batch F1: 0.8
Epoch:  505        8 Batch loss: 0.046969 Batch F1: 1.0
Epoch:  505        9 Batch loss: 0.062607 Batch F1: 1.0
Epoch:  505       10 Batch loss: 0.081960 Batch F1: 0.8333333333333333
Epoch:  505       11 Batch loss: 0.051674 Batch F1: 1.0
Epoch:  505       12 Batch loss: 0.095412 Batch F1: 0.6666666666666666
Train Avg Loss  505: 0.068040

Train Avg F1  505: 0.7331032896250287

Val Avg Loss  505: 0.063793

Val Avg F1  505:  0.9481605351170568

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 506
--------------------------------------------------------------
Epoch:  506        1 Batch loss: 0.075102 Batch F1: 0.923076923076923
Epoch:  506        2 Batch loss: 0.041447 Batch F1: 0.5714285714285715
Epoch:  506        3 Batch loss: 0.075536 Batch F1: 0.3076923076923077
Epoch:  506        4 Batch loss: 0.083242 Batch F1: 0.18181818181818182
Epoch:  506        5 Batch loss: 0.065627 Batch F1: 0.6153846153846153
Epoch:  506        6 Batch loss: 0.085853 Batch F1: 0.8571428571428572
Epoch:  506        7 Batch loss: 0.071519 Batch F1: 0.875
Epoch:  506        8 Batch loss: 0.070683 Batch F1: 0.888888888888889
Epoch:  506        9 Batch loss: 0.047496 Batch F1: 0.8
Epoch:  506       10 Batch loss: 0.082317 Batch F1: 0.42857142857142855
Epoch:  506       11 Batch loss: 0.080195 Batch F1: 0.5333333333333333
Epoch:  506       12 Batch loss: 0.073300 Batch F1: 0.7142857142857143
Train Avg Loss  506: 0.071026

Train Avg F1  506: 0.6413852351352353

Val Avg Loss  506: 0.064044

Val Avg F1  506:  0.8318181818181818

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 507
--------------------------------------------------------------
Epoch:  507        1 Batch loss: 0.067715 Batch F1: 0.8750000000000001
Epoch:  507        2 Batch loss: 0.066793 Batch F1: 0.9411764705882353
Epoch:  507        3 Batch loss: 0.041243 Batch F1: 0.9090909090909091
Epoch:  507        4 Batch loss: 0.053862 Batch F1: 1.0
Epoch:  507        5 Batch loss: 0.066048 Batch F1: 0.8
Epoch:  507        6 Batch loss: 0.063009 Batch F1: 0.7272727272727273
Epoch:  507        7 Batch loss: 0.086437 Batch F1: 0.631578947368421
Epoch:  507        8 Batch loss: 0.092025 Batch F1: 0.5882352941176471
Epoch:  507        9 Batch loss: 0.076999 Batch F1: 0.5333333333333333
Epoch:  507       10 Batch loss: 0.072862 Batch F1: 0.9
Epoch:  507       11 Batch loss: 0.065143 Batch F1: 0.9411764705882353
Epoch:  507       12 Batch loss: 0.071842 Batch F1: 0.9411764705882353
Train Avg Loss  507: 0.068665

Train Avg F1  507: 0.815670051912312

Val Avg Loss  507: 0.063686

Val Avg F1  507:  0.9012860204810669

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 508
--------------------------------------------------------------
Epoch:  508        1 Batch loss: 0.067479 Batch F1: 0.8333333333333333
Epoch:  508        2 Batch loss: 0.083037 Batch F1: 0.8695652173913044
Epoch:  508        3 Batch loss: 0.060223 Batch F1: 0.7272727272727273
Epoch:  508        4 Batch loss: 0.088016 Batch F1: 0.375
Epoch:  508        5 Batch loss: 0.071452 Batch F1: 0.5454545454545454
Epoch:  508        6 Batch loss: 0.064456 Batch F1: 0.8
Epoch:  508        7 Batch loss: 0.071983 Batch F1: 0.888888888888889
Epoch:  508        8 Batch loss: 0.047221 Batch F1: 1.0
Epoch:  508        9 Batch loss: 0.062020 Batch F1: 0.9411764705882353
Epoch:  508       10 Batch loss: 0.051014 Batch F1: 0.6666666666666666
Epoch:  508       11 Batch loss: 0.079086 Batch F1: 0.5714285714285715
Epoch:  508       12 Batch loss: 0.068310 Batch F1: 0.8
Train Avg Loss  508: 0.067858

Train Avg F1  508: 0.7515655350853563

Val Avg Loss  508: 0.063117

Val Avg F1  508:  0.7540584415584415

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 509
--------------------------------------------------------------
Epoch:  509        1 Batch loss: 0.063633 Batch F1: 0.8
Epoch:  509        2 Batch loss: 0.054664 Batch F1: 0.8571428571428571
Epoch:  509        3 Batch loss: 0.075491 Batch F1: 0.5
Epoch:  509        4 Batch loss: 0.082272 Batch F1: 0.5714285714285715
Epoch:  509        5 Batch loss: 0.067586 Batch F1: 0.9
Epoch:  509        6 Batch loss: 0.058305 Batch F1: 0.9333333333333333
Epoch:  509        7 Batch loss: 0.058747 Batch F1: 1.0
Epoch:  509        8 Batch loss: 0.069656 Batch F1: 0.9411764705882353
Epoch:  509        9 Batch loss: 0.067379 Batch F1: 0.7692307692307693
Epoch:  509       10 Batch loss: 0.062716 Batch F1: 0.8235294117647058
Epoch:  509       11 Batch loss: 0.072162 Batch F1: 0.6153846153846153
Epoch:  509       12 Batch loss: 0.066183 Batch F1: 0.8333333333333333
Train Avg Loss  509: 0.066566

Train Avg F1  509: 0.795379946850535

Val Avg Loss  509: 0.062587

Val Avg F1  509:  0.8068181818181818

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 510
--------------------------------------------------------------
Epoch:  510        1 Batch loss: 0.081534 Batch F1: 0.5454545454545454
Epoch:  510        2 Batch loss: 0.049746 Batch F1: 0.9090909090909091
Epoch:  510        3 Batch loss: 0.074202 Batch F1: 0.7499999999999999
Epoch:  510        4 Batch loss: 0.056978 Batch F1: 0.9333333333333333
Epoch:  510        5 Batch loss: 0.063792 Batch F1: 0.7692307692307693
Epoch:  510        6 Batch loss: 0.076380 Batch F1: 0.7272727272727273
Epoch:  510        7 Batch loss: 0.089562 Batch F1: 0.4
Epoch:  510        8 Batch loss: 0.077057 Batch F1: 0.625
Epoch:  510        9 Batch loss: 0.059263 Batch F1: 0.9090909090909091
Epoch:  510       10 Batch loss: 0.059726 Batch F1: 1.0
Epoch:  510       11 Batch loss: 0.062460 Batch F1: 0.888888888888889
Epoch:  510       12 Batch loss: 0.068788 Batch F1: 0.8235294117647058
Train Avg Loss  510: 0.068291

Train Avg F1  510: 0.7734076245105658

Val Avg Loss  510: 0.062098

Val Avg F1  510:  0.9251276759016697

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 511
--------------------------------------------------------------
Epoch:  511        1 Batch loss: 0.058533 Batch F1: 0.8
Epoch:  511        2 Batch loss: 0.085641 Batch F1: 0.9166666666666666
Epoch:  511        3 Batch loss: 0.072745 Batch F1: 0.9523809523809523
Epoch:  511        4 Batch loss: 0.066436 Batch F1: 0.8333333333333333
Epoch:  511        5 Batch loss: 0.068826 Batch F1: 0.7499999999999999
Epoch:  511        6 Batch loss: 0.057568 Batch F1: 0.7692307692307693
Epoch:  511        7 Batch loss: 0.055978 Batch F1: 0.6666666666666666
Epoch:  511        8 Batch loss: 0.073787 Batch F1: 0.5714285714285715
Epoch:  511        9 Batch loss: 0.067196 Batch F1: 0.6666666666666666
Epoch:  511       10 Batch loss: 0.084487 Batch F1: 0.3076923076923077
Epoch:  511       11 Batch loss: 0.075325 Batch F1: 0.9
Epoch:  511       12 Batch loss: 0.054697 Batch F1: 1.0
Train Avg Loss  511: 0.068435

Train Avg F1  511: 0.7611721611721611

Val Avg Loss  511: 0.065001

Val Avg F1  511:  0.8971861471861471

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 512
--------------------------------------------------------------
Epoch:  512        1 Batch loss: 0.083278 Batch F1: 0.8695652173913044
Epoch:  512        2 Batch loss: 0.045442 Batch F1: 0.9090909090909091
Epoch:  512        3 Batch loss: 0.070556 Batch F1: 0.6666666666666666
Epoch:  512        4 Batch loss: 0.055466 Batch F1: 0.33333333333333337
Epoch:  512        5 Batch loss: 0.061001 Batch F1: 0.3636363636363636
Epoch:  512        6 Batch loss: 0.055792 Batch F1: 0.8571428571428571
Epoch:  512        7 Batch loss: 0.092034 Batch F1: 0.375
Epoch:  512        8 Batch loss: 0.060368 Batch F1: 0.6
Epoch:  512        9 Batch loss: 0.085164 Batch F1: 0.9166666666666666
Epoch:  512       10 Batch loss: 0.068937 Batch F1: 0.8421052631578948
Epoch:  512       11 Batch loss: 0.069857 Batch F1: 0.875
Epoch:  512       12 Batch loss: 0.067416 Batch F1: 0.9411764705882353
Train Avg Loss  512: 0.067943

Train Avg F1  512: 0.7124486456395193

Val Avg Loss  512: 0.061918

Val Avg F1  512:  0.8694331983805668

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 513
--------------------------------------------------------------
Epoch:  513        1 Batch loss: 0.057153 Batch F1: 0.9333333333333333
Epoch:  513        2 Batch loss: 0.097460 Batch F1: 0.7058823529411764
Epoch:  513        3 Batch loss: 0.046154 Batch F1: 1.0
Epoch:  513        4 Batch loss: 0.083724 Batch F1: 0.33333333333333337
Epoch:  513        5 Batch loss: 0.057887 Batch F1: 0.8
Epoch:  513        6 Batch loss: 0.050359 Batch F1: 1.0
Epoch:  513        7 Batch loss: 0.062276 Batch F1: 0.923076923076923
Epoch:  513        8 Batch loss: 0.091001 Batch F1: 0.6666666666666666
Epoch:  513        9 Batch loss: 0.075826 Batch F1: 0.7499999999999999
Epoch:  513       10 Batch loss: 0.075742 Batch F1: 0.7777777777777778
Epoch:  513       11 Batch loss: 0.062423 Batch F1: 0.888888888888889
Epoch:  513       12 Batch loss: 0.057422 Batch F1: 0.7499999999999999
Train Avg Loss  513: 0.068119

Train Avg F1  513: 0.7940799396681749

Val Avg Loss  513: 0.064087

Val Avg F1  513:  0.7859848484848484

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 514
--------------------------------------------------------------
Epoch:  514        1 Batch loss: 0.056387 Batch F1: 0.8333333333333333
Epoch:  514        2 Batch loss: 0.070506 Batch F1: 0.6666666666666666
Epoch:  514        3 Batch loss: 0.051683 Batch F1: 0.5714285714285715
Epoch:  514        4 Batch loss: 0.064287 Batch F1: 0.923076923076923
Epoch:  514        5 Batch loss: 0.097123 Batch F1: 0.8
Epoch:  514        6 Batch loss: 0.067027 Batch F1: 1.0
Epoch:  514        7 Batch loss: 0.074301 Batch F1: 0.6666666666666666
Epoch:  514        8 Batch loss: 0.077066 Batch F1: 0.3636363636363636
Epoch:  514        9 Batch loss: 0.067704 Batch F1: 0.7499999999999999
Epoch:  514       10 Batch loss: 0.068745 Batch F1: 0.5454545454545454
Epoch:  514       11 Batch loss: 0.068184 Batch F1: 0.5333333333333333
Epoch:  514       12 Batch loss: 0.063247 Batch F1: 0.8571428571428571
Train Avg Loss  514: 0.068855

Train Avg F1  514: 0.7092282717282717

Val Avg Loss  514: 0.063077

Val Avg F1  514:  0.9281045751633986

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 515
--------------------------------------------------------------
Epoch:  515        1 Batch loss: 0.060078 Batch F1: 0.8571428571428571
Epoch:  515        2 Batch loss: 0.069455 Batch F1: 0.9411764705882353
Epoch:  515        3 Batch loss: 0.072320 Batch F1: 0.4615384615384615
Epoch:  515        4 Batch loss: 0.058526 Batch F1: 0.6666666666666666
Epoch:  515        5 Batch loss: 0.066695 Batch F1: 0.8235294117647058
Epoch:  515        6 Batch loss: 0.070479 Batch F1: 0.5
Epoch:  515        7 Batch loss: 0.062468 Batch F1: 0.7499999999999999
Epoch:  515        8 Batch loss: 0.061749 Batch F1: 0.9473684210526316
Epoch:  515        9 Batch loss: 0.063014 Batch F1: 1.0
Epoch:  515       10 Batch loss: 0.077959 Batch F1: 0.88
Epoch:  515       11 Batch loss: 0.079452 Batch F1: 0.9166666666666666
Epoch:  515       12 Batch loss: 0.060345 Batch F1: 0.9090909090909091
Train Avg Loss  515: 0.066878

Train Avg F1  515: 0.8044316553759278

Val Avg Loss  515: 0.062523

Val Avg F1  515:  0.5880681818181819

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 516
--------------------------------------------------------------
Epoch:  516        1 Batch loss: 0.053858 Batch F1: 0.5
Epoch:  516        2 Batch loss: 0.061883 Batch F1: 0.7499999999999999
Epoch:  516        3 Batch loss: 0.043905 Batch F1: 0.8
Epoch:  516        4 Batch loss: 0.058211 Batch F1: 0.7692307692307693
Epoch:  516        5 Batch loss: 0.101235 Batch F1: 0.5263157894736842
Epoch:  516        6 Batch loss: 0.074996 Batch F1: 0.7777777777777778
Epoch:  516        7 Batch loss: 0.072687 Batch F1: 0.7692307692307693
Epoch:  516        8 Batch loss: 0.075969 Batch F1: 0.8235294117647058
Epoch:  516        9 Batch loss: 0.056359 Batch F1: 0.888888888888889
Epoch:  516       10 Batch loss: 0.058736 Batch F1: 0.8333333333333333
Epoch:  516       11 Batch loss: 0.089155 Batch F1: 0.7499999999999999
Epoch:  516       12 Batch loss: 0.063405 Batch F1: 0.9333333333333333
Train Avg Loss  516: 0.067533

Train Avg F1  516: 0.7601366727527717

Val Avg Loss  516: 0.063184

Val Avg F1  516:  0.9034161490683231

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 517
--------------------------------------------------------------
Epoch:  517        1 Batch loss: 0.064980 Batch F1: 0.8571428571428571
Epoch:  517        2 Batch loss: 0.070742 Batch F1: 0.8
Epoch:  517        3 Batch loss: 0.060914 Batch F1: 0.7499999999999999
Epoch:  517        4 Batch loss: 0.055876 Batch F1: 0.6
Epoch:  517        5 Batch loss: 0.061532 Batch F1: 0.5454545454545454
Epoch:  517        6 Batch loss: 0.073040 Batch F1: 0.5714285714285715
Epoch:  517        7 Batch loss: 0.070716 Batch F1: 0.8181818181818181
Epoch:  517        8 Batch loss: 0.079846 Batch F1: 0.5
Epoch:  517        9 Batch loss: 0.071372 Batch F1: 0.8571428571428571
Epoch:  517       10 Batch loss: 0.064619 Batch F1: 0.9411764705882353
Epoch:  517       11 Batch loss: 0.067369 Batch F1: 1.0
Epoch:  517       12 Batch loss: 0.085032 Batch F1: 0.8571428571428571
Train Avg Loss  517: 0.068836

Train Avg F1  517: 0.758139164756812

Val Avg Loss  517: 0.064559

Val Avg F1  517:  0.7621689026487788

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 518
--------------------------------------------------------------
Epoch:  518        1 Batch loss: 0.061305 Batch F1: 0.33333333333333337
Epoch:  518        2 Batch loss: 0.081578 Batch F1: 0.7000000000000001
Epoch:  518        3 Batch loss: 0.115297 Batch F1: 0.4210526315789474
Epoch:  518        4 Batch loss: 0.057546 Batch F1: 0.9333333333333333
Epoch:  518        5 Batch loss: 0.060311 Batch F1: 1.0
Epoch:  518        6 Batch loss: 0.068361 Batch F1: 0.9473684210526316
Epoch:  518        7 Batch loss: 0.060189 Batch F1: 0.923076923076923
Epoch:  518        8 Batch loss: 0.089657 Batch F1: 0.8421052631578948
Epoch:  518        9 Batch loss: 0.054467 Batch F1: 0.9333333333333333
Epoch:  518       10 Batch loss: 0.052710 Batch F1: 0.923076923076923
Epoch:  518       11 Batch loss: 0.066307 Batch F1: 0.5454545454545454
Epoch:  518       12 Batch loss: 0.057395 Batch F1: 0.7272727272727273
Train Avg Loss  518: 0.068760

Train Avg F1  518: 0.7691172862225494

Val Avg Loss  518: 0.064579

Val Avg F1  518:  0.6457417582417582

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 519
--------------------------------------------------------------
Epoch:  519        1 Batch loss: 0.052724 Batch F1: 0.0
Epoch:  519        2 Batch loss: 0.039507 Batch F1: 1.0
Epoch:  519        3 Batch loss: 0.080600 Batch F1: 0.6666666666666666
Epoch:  519        4 Batch loss: 0.062236 Batch F1: 1.0
Epoch:  519        5 Batch loss: 0.064270 Batch F1: 0.6666666666666666
Epoch:  519        6 Batch loss: 0.079484 Batch F1: 0.7058823529411764
Epoch:  519        7 Batch loss: 0.066161 Batch F1: 0.7499999999999999
Epoch:  519        8 Batch loss: 0.070891 Batch F1: 0.8571428571428571
Epoch:  519        9 Batch loss: 0.069561 Batch F1: 0.8235294117647058
Epoch:  519       10 Batch loss: 0.092589 Batch F1: 0.7058823529411764
Epoch:  519       11 Batch loss: 0.070038 Batch F1: 0.8799999999999999
Epoch:  519       12 Batch loss: 0.045054 Batch F1: 1.0
Train Avg Loss  519: 0.066093

Train Avg F1  519: 0.7546475256769374

Val Avg Loss  519: 0.062187

Val Avg F1  519:  0.9081501831501831

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 520
--------------------------------------------------------------
Epoch:  520        1 Batch loss: 0.072455 Batch F1: 0.8
Epoch:  520        2 Batch loss: 0.049093 Batch F1: 0.8571428571428571
Epoch:  520        3 Batch loss: 0.058038 Batch F1: 0.6153846153846153
Epoch:  520        4 Batch loss: 0.064123 Batch F1: 0.6153846153846153
Epoch:  520        5 Batch loss: 0.086476 Batch F1: 0.5333333333333333
Epoch:  520        6 Batch loss: 0.070471 Batch F1: 0.7058823529411764
Epoch:  520        7 Batch loss: 0.056814 Batch F1: 0.7142857142857143
Epoch:  520        8 Batch loss: 0.057548 Batch F1: 0.8333333333333333
Epoch:  520        9 Batch loss: 0.077500 Batch F1: 0.8421052631578948
Epoch:  520       10 Batch loss: 0.055543 Batch F1: 0.8333333333333333
Epoch:  520       11 Batch loss: 0.090704 Batch F1: 0.7000000000000001
Epoch:  520       12 Batch loss: 0.065807 Batch F1: 0.7272727272727273
Train Avg Loss  520: 0.067048

Train Avg F1  520: 0.7314548454641332

Val Avg Loss  520: 0.061598

Val Avg F1  520:  0.7938552188552188

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 521
--------------------------------------------------------------
Epoch:  521        1 Batch loss: 0.053838 Batch F1: 0.9333333333333333
Epoch:  521        2 Batch loss: 0.064697 Batch F1: 0.8750000000000001
Epoch:  521        3 Batch loss: 0.074145 Batch F1: 0.7499999999999999
Epoch:  521        4 Batch loss: 0.051515 Batch F1: 0.8333333333333333
Epoch:  521        5 Batch loss: 0.044475 Batch F1: 0.888888888888889
Epoch:  521        6 Batch loss: 0.103138 Batch F1: 0.5714285714285715
Epoch:  521        7 Batch loss: 0.065680 Batch F1: 0.8
Epoch:  521        8 Batch loss: 0.063404 Batch F1: 0.9333333333333333
Epoch:  521        9 Batch loss: 0.063753 Batch F1: 1.0
Epoch:  521       10 Batch loss: 0.076482 Batch F1: 0.7777777777777778
Epoch:  521       11 Batch loss: 0.059044 Batch F1: 0.9411764705882353
Epoch:  521       12 Batch loss: 0.070946 Batch F1: 0.8750000000000001
Train Avg Loss  521: 0.065926

Train Avg F1  521: 0.8482726423902895

Val Avg Loss  521: 0.062093

Val Avg F1  521:  0.7431457431457432

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 522
--------------------------------------------------------------
Epoch:  522        1 Batch loss: 0.061682 Batch F1: 0.8750000000000001
Epoch:  522        2 Batch loss: 0.056372 Batch F1: 0.8571428571428571
Epoch:  522        3 Batch loss: 0.065212 Batch F1: 0.6153846153846153
Epoch:  522        4 Batch loss: 0.064217 Batch F1: 0.5
Epoch:  522        5 Batch loss: 0.073145 Batch F1: 0.6666666666666666
Epoch:  522        6 Batch loss: 0.078857 Batch F1: 0.7058823529411764
Epoch:  522        7 Batch loss: 0.057915 Batch F1: 0.8
Epoch:  522        8 Batch loss: 0.072875 Batch F1: 0.7999999999999999
Epoch:  522        9 Batch loss: 0.067169 Batch F1: 0.875
Epoch:  522       10 Batch loss: 0.068627 Batch F1: 0.9090909090909091
Epoch:  522       11 Batch loss: 0.064440 Batch F1: 0.6
Epoch:  522       12 Batch loss: 0.064114 Batch F1: 0.6666666666666666
Train Avg Loss  522: 0.066219

Train Avg F1  522: 0.7392361723244075

Val Avg Loss  522: 0.063270

Val Avg F1  522:  0.7538461538461538

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 523
--------------------------------------------------------------
Epoch:  523        1 Batch loss: 0.072514 Batch F1: 0.7499999999999999
Epoch:  523        2 Batch loss: 0.059564 Batch F1: 0.7272727272727273
Epoch:  523        3 Batch loss: 0.067169 Batch F1: 0.625
Epoch:  523        4 Batch loss: 0.085194 Batch F1: 0.7058823529411764
Epoch:  523        5 Batch loss: 0.059306 Batch F1: 0.8
Epoch:  523        6 Batch loss: 0.065546 Batch F1: 0.9565217391304348
Epoch:  523        7 Batch loss: 0.068495 Batch F1: 0.8750000000000001
Epoch:  523        8 Batch loss: 0.063195 Batch F1: 0.923076923076923
Epoch:  523        9 Batch loss: 0.045287 Batch F1: 0.8571428571428571
Epoch:  523       10 Batch loss: 0.067333 Batch F1: 0.4
Epoch:  523       11 Batch loss: 0.077372 Batch F1: 0.42857142857142855
Epoch:  523       12 Batch loss: 0.071952 Batch F1: 0.5
Train Avg Loss  523: 0.066911

Train Avg F1  523: 0.7123723356779622

Val Avg Loss  523: 0.064389

Val Avg F1  523:  0.82525623885918

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 524
--------------------------------------------------------------
Epoch:  524        1 Batch loss: 0.076478 Batch F1: 0.6666666666666666
Epoch:  524        2 Batch loss: 0.076008 Batch F1: 0.8235294117647058
Epoch:  524        3 Batch loss: 0.064717 Batch F1: 0.7142857142857143
Epoch:  524        4 Batch loss: 0.053795 Batch F1: 0.7499999999999999
Epoch:  524        5 Batch loss: 0.084297 Batch F1: 0.5
Epoch:  524        6 Batch loss: 0.070480 Batch F1: 0.6153846153846153
Epoch:  524        7 Batch loss: 0.049564 Batch F1: 0.6666666666666666
Epoch:  524        8 Batch loss: 0.061062 Batch F1: 0.7777777777777778
Epoch:  524        9 Batch loss: 0.060493 Batch F1: 0.888888888888889
Epoch:  524       10 Batch loss: 0.070196 Batch F1: 0.875
Epoch:  524       11 Batch loss: 0.063697 Batch F1: 1.0
Epoch:  524       12 Batch loss: 0.075794 Batch F1: 0.8235294117647058
Train Avg Loss  524: 0.067215

Train Avg F1  524: 0.7584774294333118

Val Avg Loss  524: 0.061833

Val Avg F1  524:  0.9097890671420082

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 525
--------------------------------------------------------------
Epoch:  525        1 Batch loss: 0.062623 Batch F1: 0.9333333333333333
Epoch:  525        2 Batch loss: 0.058024 Batch F1: 0.8
Epoch:  525        3 Batch loss: 0.058975 Batch F1: 0.7692307692307693
Epoch:  525        4 Batch loss: 0.058363 Batch F1: 0.923076923076923
Epoch:  525        5 Batch loss: 0.086192 Batch F1: 0.625
Epoch:  525        6 Batch loss: 0.095626 Batch F1: 0.846153846153846
Epoch:  525        7 Batch loss: 0.065124 Batch F1: 0.9523809523809523
Epoch:  525        8 Batch loss: 0.067753 Batch F1: 1.0
Epoch:  525        9 Batch loss: 0.069798 Batch F1: 0.9473684210526316
Epoch:  525       10 Batch loss: 0.058132 Batch F1: 1.0
Epoch:  525       11 Batch loss: 0.064808 Batch F1: 0.8333333333333333
Epoch:  525       12 Batch loss: 0.082124 Batch F1: 0.7692307692307693
Train Avg Loss  525: 0.068962

Train Avg F1  525: 0.8665923623160467

Val Avg Loss  525: 0.062639

Val Avg F1  525:  0.8117216117216117

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 526
--------------------------------------------------------------
Epoch:  526        1 Batch loss: 0.047534 Batch F1: 0.923076923076923
Epoch:  526        2 Batch loss: 0.068906 Batch F1: 0.5714285714285715
Epoch:  526        3 Batch loss: 0.066213 Batch F1: 0.5454545454545454
Epoch:  526        4 Batch loss: 0.093495 Batch F1: 0.4
Epoch:  526        5 Batch loss: 0.051609 Batch F1: 0.888888888888889
Epoch:  526        6 Batch loss: 0.076785 Batch F1: 0.9600000000000001
Epoch:  526        7 Batch loss: 0.087119 Batch F1: 0.9166666666666666
Epoch:  526        8 Batch loss: 0.099123 Batch F1: 0.9090909090909091
Epoch:  526        9 Batch loss: 0.077243 Batch F1: 0.7058823529411764
Epoch:  526       10 Batch loss: 0.050557 Batch F1: 0.5714285714285715
Epoch:  526       11 Batch loss: 0.046982 Batch F1: 0.2857142857142857
Epoch:  526       12 Batch loss: 0.073444 Batch F1: 0.0
Train Avg Loss  526: 0.069917

Train Avg F1  526: 0.6398026428908782

Val Avg Loss  526: 0.073768

Val Avg F1  526:  0.4913461538461539

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 527
--------------------------------------------------------------
Epoch:  527        1 Batch loss: 0.072663 Batch F1: 0.4615384615384615
Epoch:  527        2 Batch loss: 0.074734 Batch F1: 0.8
Epoch:  527        3 Batch loss: 0.058597 Batch F1: 0.888888888888889
Epoch:  527        4 Batch loss: 0.089745 Batch F1: 0.8
Epoch:  527        5 Batch loss: 0.072734 Batch F1: 0.8421052631578948
Epoch:  527        6 Batch loss: 0.074004 Batch F1: 0.7058823529411764
Epoch:  527        7 Batch loss: 0.073069 Batch F1: 0.6250000000000001
Epoch:  527        8 Batch loss: 0.062643 Batch F1: 0.6666666666666666
Epoch:  527        9 Batch loss: 0.100885 Batch F1: 0.2857142857142857
Epoch:  527       10 Batch loss: 0.078953 Batch F1: 0.6666666666666666
Epoch:  527       11 Batch loss: 0.064584 Batch F1: 1.0
Epoch:  527       12 Batch loss: 0.071361 Batch F1: 0.0
Train Avg Loss  527: 0.074498

Train Avg F1  527: 0.6452052154645035

Val Avg Loss  527: 0.069570

Val Avg F1  527:  0.6319444444444444

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 528
--------------------------------------------------------------
Epoch:  528        1 Batch loss: 0.063544 Batch F1: 0.5454545454545454
Epoch:  528        2 Batch loss: 0.059179 Batch F1: 0.8
Epoch:  528        3 Batch loss: 0.079890 Batch F1: 0.6666666666666666
Epoch:  528        4 Batch loss: 0.063142 Batch F1: 0.6666666666666666
Epoch:  528        5 Batch loss: 0.084981 Batch F1: 0.846153846153846
Epoch:  528        6 Batch loss: 0.058605 Batch F1: 1.0
Epoch:  528        7 Batch loss: 0.091868 Batch F1: 0.7368421052631579
Epoch:  528        8 Batch loss: 0.070274 Batch F1: 0.6153846153846153
Epoch:  528        9 Batch loss: 0.060727 Batch F1: 0.5454545454545454
Epoch:  528       10 Batch loss: 0.074537 Batch F1: 0.4
Epoch:  528       11 Batch loss: 0.086448 Batch F1: 0.5
Epoch:  528       12 Batch loss: 0.052391 Batch F1: 0.888888888888889
Train Avg Loss  528: 0.070465

Train Avg F1  528: 0.6842926566610776

Val Avg Loss  528: 0.065297

Val Avg F1  528:  0.5735431235431235

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 529
--------------------------------------------------------------
Epoch:  529        1 Batch loss: 0.079715 Batch F1: 0.6153846153846153
Epoch:  529        2 Batch loss: 0.070883 Batch F1: 0.5714285714285715
Epoch:  529        3 Batch loss: 0.063707 Batch F1: 0.8571428571428571
Epoch:  529        4 Batch loss: 0.045139 Batch F1: 1.0
Epoch:  529        5 Batch loss: 0.080491 Batch F1: 0.8333333333333333
Epoch:  529        6 Batch loss: 0.081841 Batch F1: 0.923076923076923
Epoch:  529        7 Batch loss: 0.075429 Batch F1: 0.923076923076923
Epoch:  529        8 Batch loss: 0.041745 Batch F1: 0.7499999999999999
Epoch:  529        9 Batch loss: 0.092797 Batch F1: 0.5555555555555556
Epoch:  529       10 Batch loss: 0.050397 Batch F1: 0.33333333333333337
Epoch:  529       11 Batch loss: 0.093322 Batch F1: 0.5263157894736842
Epoch:  529       12 Batch loss: 0.061713 Batch F1: 0.8333333333333333
Train Avg Loss  529: 0.069765

Train Avg F1  529: 0.7268317695949275

Val Avg Loss  529: 0.063617

Val Avg F1  529:  0.9495798319327731

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 530
--------------------------------------------------------------
Epoch:  530        1 Batch loss: 0.060705 Batch F1: 1.0
Epoch:  530        2 Batch loss: 0.079412 Batch F1: 0.9090909090909091
Epoch:  530        3 Batch loss: 0.065096 Batch F1: 0.9411764705882353
Epoch:  530        4 Batch loss: 0.063737 Batch F1: 0.7999999999999999
Epoch:  530        5 Batch loss: 0.091184 Batch F1: 0.7368421052631579
Epoch:  530        6 Batch loss: 0.068360 Batch F1: 0.7692307692307693
Epoch:  530        7 Batch loss: 0.068970 Batch F1: 0.625
Epoch:  530        8 Batch loss: 0.062951 Batch F1: 0.625
Epoch:  530        9 Batch loss: 0.056393 Batch F1: 0.9333333333333333
Epoch:  530       10 Batch loss: 0.066468 Batch F1: 0.9411764705882353
Epoch:  530       11 Batch loss: 0.069303 Batch F1: 0.8235294117647058
Epoch:  530       12 Batch loss: 0.062797 Batch F1: 0.888888888888889
Train Avg Loss  530: 0.067948

Train Avg F1  530: 0.8327723632290196

Val Avg Loss  530: 0.063241

Val Avg F1  530:  0.8583333333333334

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 531
--------------------------------------------------------------
Epoch:  531        1 Batch loss: 0.087775 Batch F1: 0.8181818181818181
Epoch:  531        2 Batch loss: 0.054422 Batch F1: 0.923076923076923
Epoch:  531        3 Batch loss: 0.075968 Batch F1: 0.761904761904762
Epoch:  531        4 Batch loss: 0.070204 Batch F1: 0.8750000000000001
Epoch:  531        5 Batch loss: 0.079933 Batch F1: 0.9473684210526316
Epoch:  531        6 Batch loss: 0.063721 Batch F1: 0.7692307692307693
Epoch:  531        7 Batch loss: 0.050364 Batch F1: 0.6666666666666665
Epoch:  531        8 Batch loss: 0.075330 Batch F1: 0.7499999999999999
Epoch:  531        9 Batch loss: 0.058326 Batch F1: 0.6666666666666666
Epoch:  531       10 Batch loss: 0.091761 Batch F1: 0.3076923076923077
Epoch:  531       11 Batch loss: 0.049785 Batch F1: 0.9411764705882353
Epoch:  531       12 Batch loss: 0.045885 Batch F1: 1.0
Train Avg Loss  531: 0.066956

Train Avg F1  531: 0.7855804004217317

Val Avg Loss  531: 0.063602

Val Avg F1  531:  0.8068181818181818

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 532
--------------------------------------------------------------
Epoch:  532        1 Batch loss: 0.055752 Batch F1: 0.8571428571428571
Epoch:  532        2 Batch loss: 0.075145 Batch F1: 0.8181818181818181
Epoch:  532        3 Batch loss: 0.053487 Batch F1: 0.8
Epoch:  532        4 Batch loss: 0.075228 Batch F1: 0.7499999999999999
Epoch:  532        5 Batch loss: 0.055859 Batch F1: 0.7272727272727273
Epoch:  532        6 Batch loss: 0.064938 Batch F1: 0.8421052631578948
Epoch:  532        7 Batch loss: 0.074455 Batch F1: 0.888888888888889
Epoch:  532        8 Batch loss: 0.065357 Batch F1: 0.8571428571428571
Epoch:  532        9 Batch loss: 0.069790 Batch F1: 0.7272727272727273
Epoch:  532       10 Batch loss: 0.051421 Batch F1: 0.9333333333333333
Epoch:  532       11 Batch loss: 0.075039 Batch F1: 0.6666666666666666
Epoch:  532       12 Batch loss: 0.097617 Batch F1: 0.33333333333333337
Train Avg Loss  532: 0.067841

Train Avg F1  532: 0.7667783726994254

Val Avg Loss  532: 0.061643

Val Avg F1  532:  0.8339487310075545

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 533
--------------------------------------------------------------
Epoch:  533        1 Batch loss: 0.066805 Batch F1: 0.9090909090909091
Epoch:  533        2 Batch loss: 0.074317 Batch F1: 0.9333333333333333
Epoch:  533        3 Batch loss: 0.080567 Batch F1: 0.8
Epoch:  533        4 Batch loss: 0.059324 Batch F1: 0.9333333333333333
Epoch:  533        5 Batch loss: 0.041093 Batch F1: 1.0
Epoch:  533        6 Batch loss: 0.084102 Batch F1: 0.3076923076923077
Epoch:  533        7 Batch loss: 0.040666 Batch F1: 0.7499999999999999
Epoch:  533        8 Batch loss: 0.087712 Batch F1: 0.7000000000000001
Epoch:  533        9 Batch loss: 0.061663 Batch F1: 0.625
Epoch:  533       10 Batch loss: 0.075852 Batch F1: 0.9090909090909091
Epoch:  533       11 Batch loss: 0.069988 Batch F1: 0.888888888888889
Epoch:  533       12 Batch loss: 0.086527 Batch F1: 0.8888888888888888
Train Avg Loss  533: 0.069051

Train Avg F1  533: 0.8037765475265476

Val Avg Loss  533: 0.064891

Val Avg F1  533:  0.9017857142857143

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 534
--------------------------------------------------------------
Epoch:  534        1 Batch loss: 0.068414 Batch F1: 0.9565217391304348
Epoch:  534        2 Batch loss: 0.053438 Batch F1: 0.2857142857142857
Epoch:  534        3 Batch loss: 0.082386 Batch F1: 0.625
Epoch:  534        4 Batch loss: 0.096389 Batch F1: 0.3076923076923077
Epoch:  534        5 Batch loss: 0.049024 Batch F1: 1.0
Epoch:  534        6 Batch loss: 0.065571 Batch F1: 0.8
Epoch:  534        7 Batch loss: 0.084058 Batch F1: 0.7999999999999999
Epoch:  534        8 Batch loss: 0.079965 Batch F1: 0.7142857142857143
Epoch:  534        9 Batch loss: 0.054437 Batch F1: 0.5714285714285715
Epoch:  534       10 Batch loss: 0.100729 Batch F1: 0.6666666666666666
Epoch:  534       11 Batch loss: 0.060334 Batch F1: 0.6153846153846153
Epoch:  534       12 Batch loss: 0.058332 Batch F1: 0.8
Train Avg Loss  534: 0.071090

Train Avg F1  534: 0.6785578250252163

Val Avg Loss  534: 0.063173

Val Avg F1  534:  0.9156410256410257

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 535
--------------------------------------------------------------
Epoch:  535        1 Batch loss: 0.067764 Batch F1: 0.8421052631578948
Epoch:  535        2 Batch loss: 0.067495 Batch F1: 0.8421052631578948
Epoch:  535        3 Batch loss: 0.069533 Batch F1: 0.923076923076923
Epoch:  535        4 Batch loss: 0.047322 Batch F1: 0.7499999999999999
Epoch:  535        5 Batch loss: 0.058228 Batch F1: 0.6
Epoch:  535        6 Batch loss: 0.059224 Batch F1: 0.6666666666666666
Epoch:  535        7 Batch loss: 0.091261 Batch F1: 0.42857142857142855
Epoch:  535        8 Batch loss: 0.070398 Batch F1: 0.5
Epoch:  535        9 Batch loss: 0.065741 Batch F1: 0.8571428571428571
Epoch:  535       10 Batch loss: 0.078170 Batch F1: 0.8421052631578948
Epoch:  535       11 Batch loss: 0.079683 Batch F1: 0.9
Epoch:  535       12 Batch loss: 0.084766 Batch F1: 0.8235294117647058
Train Avg Loss  535: 0.069965

Train Avg F1  535: 0.7479419230580221

Val Avg Loss  535: 0.066064

Val Avg F1  535:  0.5908088235294118

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 536
--------------------------------------------------------------
Epoch:  536        1 Batch loss: 0.073607 Batch F1: 0.761904761904762
Epoch:  536        2 Batch loss: 0.063587 Batch F1: 0.7142857142857143
Epoch:  536        3 Batch loss: 0.047376 Batch F1: 0.6666666666666666
Epoch:  536        4 Batch loss: 0.054964 Batch F1: 0.5454545454545454
Epoch:  536        5 Batch loss: 0.103865 Batch F1: 0.4210526315789474
Epoch:  536        6 Batch loss: 0.063789 Batch F1: 0.7692307692307693
Epoch:  536        7 Batch loss: 0.084081 Batch F1: 0.9411764705882353
Epoch:  536        8 Batch loss: 0.082834 Batch F1: 0.7692307692307693
Epoch:  536        9 Batch loss: 0.058519 Batch F1: 0.9090909090909091
Epoch:  536       10 Batch loss: 0.051903 Batch F1: 0.8
Epoch:  536       11 Batch loss: 0.094182 Batch F1: 0.6956521739130436
Epoch:  536       12 Batch loss: 0.075488 Batch F1: 0.0
Train Avg Loss  536: 0.071183

Train Avg F1  536: 0.6661454509953635

Val Avg Loss  536: 0.065966

Val Avg F1  536:  0.8341774891774891

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 537
--------------------------------------------------------------
Epoch:  537        1 Batch loss: 0.050194 Batch F1: 0.8333333333333333
Epoch:  537        2 Batch loss: 0.088202 Batch F1: 0.9565217391304348
Epoch:  537        3 Batch loss: 0.064802 Batch F1: 0.923076923076923
Epoch:  537        4 Batch loss: 0.081028 Batch F1: 0.8235294117647058
Epoch:  537        5 Batch loss: 0.071728 Batch F1: 0.7499999999999999
Epoch:  537        6 Batch loss: 0.054602 Batch F1: 0.4444444444444445
Epoch:  537        7 Batch loss: 0.092839 Batch F1: 0.18181818181818182
Epoch:  537        8 Batch loss: 0.081139 Batch F1: 0.7058823529411764
Epoch:  537        9 Batch loss: 0.090624 Batch F1: 0.6086956521739131
Epoch:  537       10 Batch loss: 0.087004 Batch F1: 0.9090909090909091
Epoch:  537       11 Batch loss: 0.068491 Batch F1: 1.0
Epoch:  537       12 Batch loss: 0.057608 Batch F1: 0.9090909090909091
Train Avg Loss  537: 0.074022

Train Avg F1  537: 0.7537903214054108

Val Avg Loss  537: 0.064349

Val Avg F1  537:  0.6413419913419913

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 538
--------------------------------------------------------------
Epoch:  538        1 Batch loss: 0.089887 Batch F1: 0.631578947368421
Epoch:  538        2 Batch loss: 0.048782 Batch F1: 0.8
Epoch:  538        3 Batch loss: 0.070903 Batch F1: 0.625
Epoch:  538        4 Batch loss: 0.069213 Batch F1: 0.5454545454545454
Epoch:  538        5 Batch loss: 0.086782 Batch F1: 0.7499999999999999
Epoch:  538        6 Batch loss: 0.077050 Batch F1: 0.625
Epoch:  538        7 Batch loss: 0.052963 Batch F1: 0.6666666666666666
Epoch:  538        8 Batch loss: 0.060745 Batch F1: 0.4444444444444445
Epoch:  538        9 Batch loss: 0.066453 Batch F1: 0.4
Epoch:  538       10 Batch loss: 0.044108 Batch F1: 0.4
Epoch:  538       11 Batch loss: 0.077086 Batch F1: 0.18181818181818182
Epoch:  538       12 Batch loss: 0.099143 Batch F1: 0.7368421052631579
Train Avg Loss  538: 0.070260

Train Avg F1  538: 0.5672337409179514

Val Avg Loss  538: 0.065270

Val Avg F1  538:  0.9103084415584416

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 539
--------------------------------------------------------------
Epoch:  539        1 Batch loss: 0.078588 Batch F1: 0.962962962962963
Epoch:  539        2 Batch loss: 0.077457 Batch F1: 0.7999999999999999
Epoch:  539        3 Batch loss: 0.062659 Batch F1: 0.6666666666666666
Epoch:  539        4 Batch loss: 0.091646 Batch F1: 0.4444444444444445
Epoch:  539        5 Batch loss: 0.065450 Batch F1: 0.7142857142857143
Epoch:  539        6 Batch loss: 0.080694 Batch F1: 0.7058823529411764
Epoch:  539        7 Batch loss: 0.056384 Batch F1: 1.0
Epoch:  539        8 Batch loss: 0.049379 Batch F1: 0.888888888888889
Epoch:  539        9 Batch loss: 0.074421 Batch F1: 0.19999999999999998
Epoch:  539       10 Batch loss: 0.060402 Batch F1: 0.7272727272727273
Epoch:  539       11 Batch loss: 0.087885 Batch F1: 0.4615384615384615
Epoch:  539       12 Batch loss: 0.051202 Batch F1: 0.6666666666666666
Train Avg Loss  539: 0.069681

Train Avg F1  539: 0.6865507404723092

Val Avg Loss  539: 0.068022

Val Avg F1  539:  0.5880566801619433

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 540
--------------------------------------------------------------
Epoch:  540        1 Batch loss: 0.045354 Batch F1: 0.7499999999999999
Epoch:  540        2 Batch loss: 0.066235 Batch F1: 0.6666666666666666
Epoch:  540        3 Batch loss: 0.060279 Batch F1: 0.7272727272727273
Epoch:  540        4 Batch loss: 0.074074 Batch F1: 0.5
Epoch:  540        5 Batch loss: 0.086702 Batch F1: 0.7000000000000001
Epoch:  540        6 Batch loss: 0.074537 Batch F1: 0.5333333333333333
Epoch:  540        7 Batch loss: 0.071798 Batch F1: 1.0
Epoch:  540        8 Batch loss: 0.061029 Batch F1: 1.0
Epoch:  540        9 Batch loss: 0.074073 Batch F1: 0.923076923076923
Epoch:  540       10 Batch loss: 0.084417 Batch F1: 0.7058823529411764
Epoch:  540       11 Batch loss: 0.056712 Batch F1: 0.6153846153846153
Epoch:  540       12 Batch loss: 0.072350 Batch F1: 0.4
Train Avg Loss  540: 0.068963

Train Avg F1  540: 0.7101347182229536

Val Avg Loss  540: 0.064686

Val Avg F1  540:  0.6261904761904762

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 541
--------------------------------------------------------------
Epoch:  541        1 Batch loss: 0.072378 Batch F1: 0.6153846153846153
Epoch:  541        2 Batch loss: 0.065998 Batch F1: 0.6153846153846153
Epoch:  541        3 Batch loss: 0.076786 Batch F1: 0.9565217391304348
Epoch:  541        4 Batch loss: 0.075022 Batch F1: 0.8
Epoch:  541        5 Batch loss: 0.071817 Batch F1: 0.9411764705882353
Epoch:  541        6 Batch loss: 0.062221 Batch F1: 0.888888888888889
Epoch:  541        7 Batch loss: 0.070814 Batch F1: 0.888888888888889
Epoch:  541        8 Batch loss: 0.044786 Batch F1: 0.6666666666666666
Epoch:  541        9 Batch loss: 0.069669 Batch F1: 0.7142857142857143
Epoch:  541       10 Batch loss: 0.065898 Batch F1: 0.5714285714285715
Epoch:  541       11 Batch loss: 0.067217 Batch F1: 0.8571428571428571
Epoch:  541       12 Batch loss: 0.080954 Batch F1: 0.8
Train Avg Loss  541: 0.068630

Train Avg F1  541: 0.7763140856491241

Val Avg Loss  541: 0.062806

Val Avg F1  541:  0.9290674603174603

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 542
--------------------------------------------------------------
Epoch:  542        1 Batch loss: 0.061142 Batch F1: 0.8571428571428571
Epoch:  542        2 Batch loss: 0.064653 Batch F1: 0.8333333333333333
Epoch:  542        3 Batch loss: 0.054822 Batch F1: 0.7692307692307693
Epoch:  542        4 Batch loss: 0.070393 Batch F1: 0.4615384615384615
Epoch:  542        5 Batch loss: 0.053745 Batch F1: 0.5
Epoch:  542        6 Batch loss: 0.042070 Batch F1: 0.923076923076923
Epoch:  542        7 Batch loss: 0.089090 Batch F1: 0.5555555555555556
Epoch:  542        8 Batch loss: 0.068633 Batch F1: 0.888888888888889
Epoch:  542        9 Batch loss: 0.062231 Batch F1: 0.8571428571428571
Epoch:  542       10 Batch loss: 0.079528 Batch F1: 0.9
Epoch:  542       11 Batch loss: 0.078501 Batch F1: 0.9090909090909091
Epoch:  542       12 Batch loss: 0.072185 Batch F1: 0.8
Train Avg Loss  542: 0.066416

Train Avg F1  542: 0.7712500462500462

Val Avg Loss  542: 0.062520

Val Avg F1  542:  0.598611111111111

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 543
--------------------------------------------------------------
Epoch:  543        1 Batch loss: 0.052518 Batch F1: 0.7692307692307693
Epoch:  543        2 Batch loss: 0.074308 Batch F1: 0.4615384615384615
Epoch:  543        3 Batch loss: 0.080132 Batch F1: 0.33333333333333337
Epoch:  543        4 Batch loss: 0.065765 Batch F1: 0.5454545454545454
Epoch:  543        5 Batch loss: 0.073599 Batch F1: 0.8571428571428571
Epoch:  543        6 Batch loss: 0.079515 Batch F1: 0.9166666666666666
Epoch:  543        7 Batch loss: 0.047262 Batch F1: 1.0
Epoch:  543        8 Batch loss: 0.076699 Batch F1: 0.9090909090909091
Epoch:  543        9 Batch loss: 0.065806 Batch F1: 0.8
Epoch:  543       10 Batch loss: 0.058501 Batch F1: 0.9090909090909091
Epoch:  543       11 Batch loss: 0.053973 Batch F1: 0.8
Epoch:  543       12 Batch loss: 0.088659 Batch F1: 0.5555555555555556
Train Avg Loss  543: 0.068061

Train Avg F1  543: 0.7380920005920006

Val Avg Loss  543: 0.063281

Val Avg F1  543:  0.748976023976024

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 544
--------------------------------------------------------------
Epoch:  544        1 Batch loss: 0.075948 Batch F1: 0.8
Epoch:  544        2 Batch loss: 0.071354 Batch F1: 0.9090909090909091
Epoch:  544        3 Batch loss: 0.054451 Batch F1: 1.0
Epoch:  544        4 Batch loss: 0.047715 Batch F1: 0.9090909090909091
Epoch:  544        5 Batch loss: 0.060504 Batch F1: 0.9523809523809523
Epoch:  544        6 Batch loss: 0.089723 Batch F1: 0.6666666666666666
Epoch:  544        7 Batch loss: 0.072106 Batch F1: 0.8571428571428571
Epoch:  544        8 Batch loss: 0.057888 Batch F1: 0.8
Epoch:  544        9 Batch loss: 0.070222 Batch F1: 0.6153846153846153
Epoch:  544       10 Batch loss: 0.072501 Batch F1: 0.7777777777777777
Epoch:  544       11 Batch loss: 0.075387 Batch F1: 0.625
Epoch:  544       12 Batch loss: 0.060954 Batch F1: 0.8333333333333334
Train Avg Loss  544: 0.067396

Train Avg F1  544: 0.8121556684056684

Val Avg Loss  544: 0.062991

Val Avg F1  544:  0.8438311688311688

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 545
--------------------------------------------------------------
Epoch:  545        1 Batch loss: 0.052659 Batch F1: 1.0
Epoch:  545        2 Batch loss: 0.085319 Batch F1: 0.6666666666666666
Epoch:  545        3 Batch loss: 0.052098 Batch F1: 1.0
Epoch:  545        4 Batch loss: 0.076356 Batch F1: 0.7368421052631579
Epoch:  545        5 Batch loss: 0.085120 Batch F1: 0.8695652173913043
Epoch:  545        6 Batch loss: 0.041163 Batch F1: 1.0
Epoch:  545        7 Batch loss: 0.093506 Batch F1: 0.888888888888889
Epoch:  545        8 Batch loss: 0.056770 Batch F1: 0.9565217391304348
Epoch:  545        9 Batch loss: 0.065052 Batch F1: 0.8333333333333333
Epoch:  545       10 Batch loss: 0.052660 Batch F1: 0.7499999999999999
Epoch:  545       11 Batch loss: 0.068057 Batch F1: 0.6666666666666666
Epoch:  545       12 Batch loss: 0.063691 Batch F1: 0.6
Train Avg Loss  545: 0.066038

Train Avg F1  545: 0.8307070514450375

Val Avg Loss  545: 0.065864

Val Avg F1  545:  0.5927128427128427

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 546
--------------------------------------------------------------
Epoch:  546        1 Batch loss: 0.074114 Batch F1: 0.6666666666666666
Epoch:  546        2 Batch loss: 0.074898 Batch F1: 0.6666666666666666
Epoch:  546        3 Batch loss: 0.059783 Batch F1: 0.7272727272727273
Epoch:  546        4 Batch loss: 0.064835 Batch F1: 0.6666666666666666
Epoch:  546        5 Batch loss: 0.065624 Batch F1: 0.8
Epoch:  546        6 Batch loss: 0.066586 Batch F1: 0.923076923076923
Epoch:  546        7 Batch loss: 0.064822 Batch F1: 0.9
Epoch:  546        8 Batch loss: 0.071974 Batch F1: 0.9473684210526316
Epoch:  546        9 Batch loss: 0.062684 Batch F1: 1.0
Epoch:  546       10 Batch loss: 0.078663 Batch F1: 0.7142857142857143
Epoch:  546       11 Batch loss: 0.063710 Batch F1: 0.923076923076923
Epoch:  546       12 Batch loss: 0.072097 Batch F1: 0.8235294117647058
Train Avg Loss  546: 0.068316

Train Avg F1  546: 0.8132175100441356

Val Avg Loss  546: 0.062629

Val Avg F1  546:  0.7291042291042291

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 547
--------------------------------------------------------------
Epoch:  547        1 Batch loss: 0.062246 Batch F1: 0.7692307692307693
Epoch:  547        2 Batch loss: 0.040321 Batch F1: 0.6666666666666666
Epoch:  547        3 Batch loss: 0.055488 Batch F1: 0.6
Epoch:  547        4 Batch loss: 0.069305 Batch F1: 0.625
Epoch:  547        5 Batch loss: 0.064330 Batch F1: 0.5454545454545454
Epoch:  547        6 Batch loss: 0.106870 Batch F1: 0.33333333333333337
Epoch:  547        7 Batch loss: 0.050982 Batch F1: 0.8571428571428571
Epoch:  547        8 Batch loss: 0.074487 Batch F1: 0.8421052631578948
Epoch:  547        9 Batch loss: 0.086506 Batch F1: 0.75
Epoch:  547       10 Batch loss: 0.066671 Batch F1: 1.0
Epoch:  547       11 Batch loss: 0.054244 Batch F1: 1.0
Epoch:  547       12 Batch loss: 0.080034 Batch F1: 0.8750000000000001
Train Avg Loss  547: 0.067624

Train Avg F1  547: 0.7386611195821722

Val Avg Loss  547: 0.062378

Val Avg F1  547:  0.9183298319327731

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 548
--------------------------------------------------------------
Epoch:  548        1 Batch loss: 0.078780 Batch F1: 0.8421052631578948
Epoch:  548        2 Batch loss: 0.078557 Batch F1: 0.8421052631578948
Epoch:  548        3 Batch loss: 0.071717 Batch F1: 0.9411764705882353
Epoch:  548        4 Batch loss: 0.055854 Batch F1: 0.9411764705882353
Epoch:  548        5 Batch loss: 0.034684 Batch F1: 0.5
Epoch:  548        6 Batch loss: 0.056472 Batch F1: 0.7142857142857143
Epoch:  548        7 Batch loss: 0.071550 Batch F1: 0.5
Epoch:  548        8 Batch loss: 0.072497 Batch F1: 0.5
Epoch:  548        9 Batch loss: 0.084445 Batch F1: 0.7499999999999999
Epoch:  548       10 Batch loss: 0.069390 Batch F1: 0.9600000000000001
Epoch:  548       11 Batch loss: 0.065000 Batch F1: 0.9411764705882353
Epoch:  548       12 Batch loss: 0.069131 Batch F1: 0.7272727272727273
Train Avg Loss  548: 0.067340

Train Avg F1  548: 0.7632748649699114

Val Avg Loss  548: 0.061857

Val Avg F1  548:  0.78125

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 549
--------------------------------------------------------------
Epoch:  549        1 Batch loss: 0.041812 Batch F1: 0.8
Epoch:  549        2 Batch loss: 0.072637 Batch F1: 0.7777777777777778
Epoch:  549        3 Batch loss: 0.082521 Batch F1: 0.18181818181818182
Epoch:  549        4 Batch loss: 0.082662 Batch F1: 0.4615384615384615
Epoch:  549        5 Batch loss: 0.049853 Batch F1: 0.8333333333333333
Epoch:  549        6 Batch loss: 0.069565 Batch F1: 0.8750000000000001
Epoch:  549        7 Batch loss: 0.061375 Batch F1: 0.9
Epoch:  549        8 Batch loss: 0.053845 Batch F1: 0.8000000000000002
Epoch:  549        9 Batch loss: 0.059787 Batch F1: 0.5454545454545454
Epoch:  549       10 Batch loss: 0.082611 Batch F1: 0.5333333333333333
Epoch:  549       11 Batch loss: 0.068083 Batch F1: 0.5882352941176471
Epoch:  549       12 Batch loss: 0.078206 Batch F1: 0.6666666666666666
Train Avg Loss  549: 0.066913

Train Avg F1  549: 0.6635964661699957

Val Avg Loss  549: 0.063998

Val Avg F1  549:  0.8888888888888888

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 550
--------------------------------------------------------------
Epoch:  550        1 Batch loss: 0.051026 Batch F1: 1.0
Epoch:  550        2 Batch loss: 0.085363 Batch F1: 0.8695652173913044
Epoch:  550        3 Batch loss: 0.065581 Batch F1: 0.923076923076923
Epoch:  550        4 Batch loss: 0.066367 Batch F1: 0.6666666666666666
Epoch:  550        5 Batch loss: 0.043999 Batch F1: 0.8
Epoch:  550        6 Batch loss: 0.061316 Batch F1: 0.6666666666666666
Epoch:  550        7 Batch loss: 0.053667 Batch F1: 0.6666666666666666
Epoch:  550        8 Batch loss: 0.074148 Batch F1: 0.6666666666666666
Epoch:  550        9 Batch loss: 0.082491 Batch F1: 0.7058823529411764
Epoch:  550       10 Batch loss: 0.087633 Batch F1: 0.7368421052631579
Epoch:  550       11 Batch loss: 0.060698 Batch F1: 0.9473684210526316
Epoch:  550       12 Batch loss: 0.084795 Batch F1: 0.9523809523809523
Train Avg Loss  550: 0.068090

Train Avg F1  550: 0.8001485532310677

Val Avg Loss  550: 0.069203

Val Avg F1  550:  0.937566844919786

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 551
--------------------------------------------------------------
Epoch:  551        1 Batch loss: 0.083161 Batch F1: 0.8
Epoch:  551        2 Batch loss: 0.066194 Batch F1: 0.8571428571428571
Epoch:  551        3 Batch loss: 0.065232 Batch F1: 0.6666666666666666
Epoch:  551        4 Batch loss: 0.037121 Batch F1: 0.888888888888889
Epoch:  551        5 Batch loss: 0.067534 Batch F1: 0.5
Epoch:  551        6 Batch loss: 0.065137 Batch F1: 0.6666666666666666
Epoch:  551        7 Batch loss: 0.066176 Batch F1: 0.6666666666666666
Epoch:  551        8 Batch loss: 0.073226 Batch F1: 0.5
Epoch:  551        9 Batch loss: 0.079802 Batch F1: 0.5
Epoch:  551       10 Batch loss: 0.094807 Batch F1: 0.6666666666666666
Epoch:  551       11 Batch loss: 0.063482 Batch F1: 0.8
Epoch:  551       12 Batch loss: 0.060045 Batch F1: 1.0
Train Avg Loss  551: 0.068493

Train Avg F1  551: 0.7093915343915344

Val Avg Loss  551: 0.064135

Val Avg F1  551:  0.8698322510822512

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 552
--------------------------------------------------------------
Epoch:  552        1 Batch loss: 0.064804 Batch F1: 0.888888888888889
Epoch:  552        2 Batch loss: 0.064509 Batch F1: 0.7142857142857143
Epoch:  552        3 Batch loss: 0.059545 Batch F1: 0.8
Epoch:  552        4 Batch loss: 0.076139 Batch F1: 0.7499999999999999
Epoch:  552        5 Batch loss: 0.049886 Batch F1: 0.8333333333333333
Epoch:  552        6 Batch loss: 0.082965 Batch F1: 0.0
Epoch:  552        7 Batch loss: 0.065272 Batch F1: 0.8
Epoch:  552        8 Batch loss: 0.058802 Batch F1: 1.0
Epoch:  552        9 Batch loss: 0.075556 Batch F1: 0.6153846153846153
Epoch:  552       10 Batch loss: 0.074461 Batch F1: 0.4615384615384615
Epoch:  552       11 Batch loss: 0.057944 Batch F1: 0.4
Epoch:  552       12 Batch loss: 0.087314 Batch F1: 0.8695652173913044
Train Avg Loss  552: 0.068100

Train Avg F1  552: 0.6777496859018598

Val Avg Loss  552: 0.063059

Val Avg F1  552:  0.9365079365079365

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 553
--------------------------------------------------------------
Epoch:  553        1 Batch loss: 0.063505 Batch F1: 0.9473684210526316
Epoch:  553        2 Batch loss: 0.078251 Batch F1: 0.9565217391304348
Epoch:  553        3 Batch loss: 0.064995 Batch F1: 0.9090909090909091
Epoch:  553        4 Batch loss: 0.070226 Batch F1: 1.0
Epoch:  553        5 Batch loss: 0.071250 Batch F1: 0.7692307692307693
Epoch:  553        6 Batch loss: 0.083736 Batch F1: 0.7142857142857143
Epoch:  553        7 Batch loss: 0.057306 Batch F1: 0.7692307692307693
Epoch:  553        8 Batch loss: 0.062331 Batch F1: 0.8571428571428571
Epoch:  553        9 Batch loss: 0.055246 Batch F1: 0.7692307692307693
Epoch:  553       10 Batch loss: 0.059868 Batch F1: 0.5454545454545454
Epoch:  553       11 Batch loss: 0.077621 Batch F1: 0.625
Epoch:  553       12 Batch loss: 0.058392 Batch F1: 0.8
Train Avg Loss  553: 0.066894

Train Avg F1  553: 0.8052130411541167

Val Avg Loss  553: 0.062640

Val Avg F1  553:  0.8956025592055004

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 554
--------------------------------------------------------------
Epoch:  554        1 Batch loss: 0.091546 Batch F1: 0.7368421052631579
Epoch:  554        2 Batch loss: 0.066635 Batch F1: 0.9411764705882353
Epoch:  554        3 Batch loss: 0.070402 Batch F1: 0.8750000000000001
Epoch:  554        4 Batch loss: 0.056740 Batch F1: 1.0
Epoch:  554        5 Batch loss: 0.049155 Batch F1: 0.9090909090909091
Epoch:  554        6 Batch loss: 0.061513 Batch F1: 0.6153846153846153
Epoch:  554        7 Batch loss: 0.059803 Batch F1: 0.5454545454545454
Epoch:  554        8 Batch loss: 0.068353 Batch F1: 0.4615384615384615
Epoch:  554        9 Batch loss: 0.097283 Batch F1: 0.7000000000000001
Epoch:  554       10 Batch loss: 0.061630 Batch F1: 0.8235294117647058
Epoch:  554       11 Batch loss: 0.064845 Batch F1: 1.0
Epoch:  554       12 Batch loss: 0.069483 Batch F1: 0.7499999999999999
Train Avg Loss  554: 0.068116

Train Avg F1  554: 0.7798347099237192

Val Avg Loss  554: 0.064335

Val Avg F1  554:  0.7367216117216117

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 555
--------------------------------------------------------------
Epoch:  555        1 Batch loss: 0.079781 Batch F1: 0.8333333333333333
Epoch:  555        2 Batch loss: 0.073232 Batch F1: 0.8750000000000001
Epoch:  555        3 Batch loss: 0.068306 Batch F1: 0.4615384615384615
Epoch:  555        4 Batch loss: 0.043265 Batch F1: 0.8333333333333333
Epoch:  555        5 Batch loss: 0.063724 Batch F1: 0.7499999999999999
Epoch:  555        6 Batch loss: 0.077277 Batch F1: 0.7142857142857143
Epoch:  555        7 Batch loss: 0.074220 Batch F1: 1.0
Epoch:  555        8 Batch loss: 0.057914 Batch F1: 0.8333333333333333
Epoch:  555        9 Batch loss: 0.049366 Batch F1: 0.8
Epoch:  555       10 Batch loss: 0.082197 Batch F1: 0.7142857142857143
Epoch:  555       11 Batch loss: 0.070647 Batch F1: 0.7692307692307693
Epoch:  555       12 Batch loss: 0.058851 Batch F1: 0.7272727272727273
Train Avg Loss  555: 0.066565

Train Avg F1  555: 0.7759677822177822

Val Avg Loss  555: 0.064491

Val Avg F1  555:  0.6218614718614719

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 556
--------------------------------------------------------------
Epoch:  556        1 Batch loss: 0.069472 Batch F1: 0.6666666666666666
Epoch:  556        2 Batch loss: 0.050785 Batch F1: 0.2857142857142857
Epoch:  556        3 Batch loss: 0.064447 Batch F1: 0.6153846153846153
Epoch:  556        4 Batch loss: 0.077168 Batch F1: 0.6666666666666666
Epoch:  556        5 Batch loss: 0.057247 Batch F1: 0.7142857142857143
Epoch:  556        6 Batch loss: 0.049932 Batch F1: 0.9090909090909091
Epoch:  556        7 Batch loss: 0.091697 Batch F1: 0.8695652173913044
Epoch:  556        8 Batch loss: 0.079537 Batch F1: 0.9565217391304348
Epoch:  556        9 Batch loss: 0.062268 Batch F1: 1.0
Epoch:  556       10 Batch loss: 0.068138 Batch F1: 0.8333333333333333
Epoch:  556       11 Batch loss: 0.077292 Batch F1: 0.8421052631578948
Epoch:  556       12 Batch loss: 0.098077 Batch F1: 0.7142857142857143
Train Avg Loss  556: 0.070505

Train Avg F1  556: 0.7561350104256283

Val Avg Loss  556: 0.067359

Val Avg F1  556:  0.6500793650793651

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 557
--------------------------------------------------------------
Epoch:  557        1 Batch loss: 0.075769 Batch F1: 0.7058823529411764
Epoch:  557        2 Batch loss: 0.063434 Batch F1: 0.5454545454545454
Epoch:  557        3 Batch loss: 0.064103 Batch F1: 0.25
Epoch:  557        4 Batch loss: 0.076876 Batch F1: 0.33333333333333337
Epoch:  557        5 Batch loss: 0.074214 Batch F1: 0.3636363636363636
Epoch:  557        6 Batch loss: 0.084630 Batch F1: 0.8333333333333333
Epoch:  557        7 Batch loss: 0.066704 Batch F1: 0.9411764705882353
Epoch:  557        8 Batch loss: 0.089199 Batch F1: 0.9090909090909091
Epoch:  557        9 Batch loss: 0.083750 Batch F1: 0.9090909090909091
Epoch:  557       10 Batch loss: 0.048750 Batch F1: 0.7499999999999999
Epoch:  557       11 Batch loss: 0.070501 Batch F1: 0.4444444444444445
Epoch:  557       12 Batch loss: 0.050115 Batch F1: 0.0
Train Avg Loss  557: 0.070671

Train Avg F1  557: 0.5821202218261042

Val Avg Loss  557: 0.073112

Val Avg F1  557:  0.5450757575757575

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 558
--------------------------------------------------------------
Epoch:  558        1 Batch loss: 0.051351 Batch F1: 0.8571428571428571
Epoch:  558        2 Batch loss: 0.059854 Batch F1: 0.8
Epoch:  558        3 Batch loss: 0.059791 Batch F1: 0.8750000000000001
Epoch:  558        4 Batch loss: 0.064393 Batch F1: 0.6666666666666666
Epoch:  558        5 Batch loss: 0.074929 Batch F1: 0.6666666666666666
Epoch:  558        6 Batch loss: 0.105875 Batch F1: 0.42857142857142855
Epoch:  558        7 Batch loss: 0.091144 Batch F1: 0.42857142857142855
Epoch:  558        8 Batch loss: 0.057512 Batch F1: 0.923076923076923
Epoch:  558        9 Batch loss: 0.078239 Batch F1: 0.9565217391304348
Epoch:  558       10 Batch loss: 0.073563 Batch F1: 0.8571428571428571
Epoch:  558       11 Batch loss: 0.055168 Batch F1: 1.0
Epoch:  558       12 Batch loss: 0.080611 Batch F1: 0.2222222222222222
Train Avg Loss  558: 0.071036

Train Avg F1  558: 0.7234652324326237

Val Avg Loss  558: 0.067678

Val Avg F1  558:  0.5883228291316527

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 559
--------------------------------------------------------------
Epoch:  559        1 Batch loss: 0.056584 Batch F1: 0.5
Epoch:  559        2 Batch loss: 0.054421 Batch F1: 0.6666666666666666
Epoch:  559        3 Batch loss: 0.079162 Batch F1: 0.5714285714285715
Epoch:  559        4 Batch loss: 0.072425 Batch F1: 0.8750000000000001
Epoch:  559        5 Batch loss: 0.071511 Batch F1: 0.8571428571428571
Epoch:  559        6 Batch loss: 0.077908 Batch F1: 0.9
Epoch:  559        7 Batch loss: 0.073185 Batch F1: 0.9523809523809523
Epoch:  559        8 Batch loss: 0.082234 Batch F1: 0.8
Epoch:  559        9 Batch loss: 0.056011 Batch F1: 0.9090909090909091
Epoch:  559       10 Batch loss: 0.048313 Batch F1: 0.923076923076923
Epoch:  559       11 Batch loss: 0.087873 Batch F1: 0.5
Epoch:  559       12 Batch loss: 0.053468 Batch F1: 1.0
Train Avg Loss  559: 0.067758

Train Avg F1  559: 0.7878989066489067

Val Avg Loss  559: 0.063206

Val Avg F1  559:  0.8309355118565644

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 560
--------------------------------------------------------------
Epoch:  560        1 Batch loss: 0.059503 Batch F1: 0.5714285714285715
Epoch:  560        2 Batch loss: 0.079620 Batch F1: 0.33333333333333337
Epoch:  560        3 Batch loss: 0.084588 Batch F1: 0.5882352941176471
Epoch:  560        4 Batch loss: 0.063977 Batch F1: 0.5454545454545454
Epoch:  560        5 Batch loss: 0.045301 Batch F1: 1.0
Epoch:  560        6 Batch loss: 0.084862 Batch F1: 0.8695652173913044
Epoch:  560        7 Batch loss: 0.069153 Batch F1: 0.8750000000000001
Epoch:  560        8 Batch loss: 0.059396 Batch F1: 0.8571428571428571
Epoch:  560        9 Batch loss: 0.076413 Batch F1: 0.9166666666666666
Epoch:  560       10 Batch loss: 0.063470 Batch F1: 0.9411764705882353
Epoch:  560       11 Batch loss: 0.060065 Batch F1: 0.8750000000000001
Epoch:  560       12 Batch loss: 0.063242 Batch F1: 0.8
Train Avg Loss  560: 0.067466

Train Avg F1  560: 0.7644169130102635

Val Avg Loss  560: 0.062571

Val Avg F1  560:  0.9244322928533455

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 561
--------------------------------------------------------------
Epoch:  561        1 Batch loss: 0.082318 Batch F1: 0.888888888888889
Epoch:  561        2 Batch loss: 0.090166 Batch F1: 0.8799999999999999
Epoch:  561        3 Batch loss: 0.057637 Batch F1: 0.923076923076923
Epoch:  561        4 Batch loss: 0.079631 Batch F1: 0.625
Epoch:  561        5 Batch loss: 0.072786 Batch F1: 0.4615384615384615
Epoch:  561        6 Batch loss: 0.045378 Batch F1: 0.7499999999999999
Epoch:  561        7 Batch loss: 0.046040 Batch F1: 0.7272727272727273
Epoch:  561        8 Batch loss: 0.060560 Batch F1: 0.6666666666666666
Epoch:  561        9 Batch loss: 0.076625 Batch F1: 0.42857142857142855
Epoch:  561       10 Batch loss: 0.045958 Batch F1: 0.888888888888889
Epoch:  561       11 Batch loss: 0.074700 Batch F1: 0.42857142857142855
Epoch:  561       12 Batch loss: 0.073312 Batch F1: 0.5
Train Avg Loss  561: 0.067093

Train Avg F1  561: 0.6807062844562846

Val Avg Loss  561: 0.063120

Val Avg F1  561:  0.911458107110281

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 562
--------------------------------------------------------------
Epoch:  562        1 Batch loss: 0.062924 Batch F1: 0.9333333333333333
Epoch:  562        2 Batch loss: 0.086465 Batch F1: 0.888888888888889
Epoch:  562        3 Batch loss: 0.063619 Batch F1: 0.9523809523809523
Epoch:  562        4 Batch loss: 0.086270 Batch F1: 0.5
Epoch:  562        5 Batch loss: 0.080937 Batch F1: 0.8571428571428571
Epoch:  562        6 Batch loss: 0.069008 Batch F1: 0.8750000000000001
Epoch:  562        7 Batch loss: 0.057902 Batch F1: 0.8
Epoch:  562        8 Batch loss: 0.050050 Batch F1: 0.8333333333333333
Epoch:  562        9 Batch loss: 0.081808 Batch F1: 0.5882352941176471
Epoch:  562       10 Batch loss: 0.045028 Batch F1: 0.5714285714285715
Epoch:  562       11 Batch loss: 0.070756 Batch F1: 0.4615384615384615
Epoch:  562       12 Batch loss: 0.058547 Batch F1: 0.8571428571428571
Train Avg Loss  562: 0.067776

Train Avg F1  562: 0.7598687124422417

Val Avg Loss  562: 0.063390

Val Avg F1  562:  0.9195804195804196

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 563
--------------------------------------------------------------
Epoch:  563        1 Batch loss: 0.067054 Batch F1: 0.8235294117647058
Epoch:  563        2 Batch loss: 0.087419 Batch F1: 0.8
Epoch:  563        3 Batch loss: 0.093622 Batch F1: 0.9090909090909091
Epoch:  563        4 Batch loss: 0.079534 Batch F1: 0.8333333333333334
Epoch:  563        5 Batch loss: 0.069441 Batch F1: 0.3636363636363636
Epoch:  563        6 Batch loss: 0.069115 Batch F1: 0.7142857142857143
Epoch:  563        7 Batch loss: 0.069080 Batch F1: 0.0
Epoch:  563        8 Batch loss: 0.055078 Batch F1: 0.6666666666666666
Epoch:  563        9 Batch loss: 0.068492 Batch F1: 0.5
Epoch:  563       10 Batch loss: 0.087285 Batch F1: 0.7000000000000001
Epoch:  563       11 Batch loss: 0.063566 Batch F1: 0.8333333333333333
Epoch:  563       12 Batch loss: 0.081628 Batch F1: 0.5
Train Avg Loss  563: 0.074276

Train Avg F1  563: 0.6369896443425855

Val Avg Loss  563: 0.064018

Val Avg F1  563:  0.7351648351648352

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 564
--------------------------------------------------------------
Epoch:  564        1 Batch loss: 0.047028 Batch F1: 1.0
Epoch:  564        2 Batch loss: 0.064415 Batch F1: 0.6666666666666666
Epoch:  564        3 Batch loss: 0.065873 Batch F1: 0.4444444444444445
Epoch:  564        4 Batch loss: 0.078725 Batch F1: 0.5714285714285715
Epoch:  564        5 Batch loss: 0.090772 Batch F1: 0.16666666666666669
Epoch:  564        6 Batch loss: 0.084737 Batch F1: 0.846153846153846
Epoch:  564        7 Batch loss: 0.093293 Batch F1: 0.6666666666666666
Epoch:  564        8 Batch loss: 0.084478 Batch F1: 0.8
Epoch:  564        9 Batch loss: 0.090445 Batch F1: 0.5555555555555556
Epoch:  564       10 Batch loss: 0.058301 Batch F1: 0.5
Epoch:  564       11 Batch loss: 0.047811 Batch F1: 0.8571428571428571
Epoch:  564       12 Batch loss: 0.066279 Batch F1: 0.9090909090909091
Train Avg Loss  564: 0.072680

Train Avg F1  564: 0.6653180153180153

Val Avg Loss  564: 0.064431

Val Avg F1  564:  0.9246323529411764

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 565
--------------------------------------------------------------
Epoch:  565        1 Batch loss: 0.082601 Batch F1: 0.9565217391304348
Epoch:  565        2 Batch loss: 0.065754 Batch F1: 0.923076923076923
Epoch:  565        3 Batch loss: 0.073621 Batch F1: 0.9600000000000001
Epoch:  565        4 Batch loss: 0.078605 Batch F1: 0.625
Epoch:  565        5 Batch loss: 0.092441 Batch F1: 0.631578947368421
Epoch:  565        6 Batch loss: 0.078929 Batch F1: 0.6666666666666666
Epoch:  565        7 Batch loss: 0.063835 Batch F1: 0.7142857142857143
Epoch:  565        8 Batch loss: 0.082246 Batch F1: 0.47058823529411764
Epoch:  565        9 Batch loss: 0.053257 Batch F1: 0.7272727272727273
Epoch:  565       10 Batch loss: 0.057195 Batch F1: 0.7272727272727273
Epoch:  565       11 Batch loss: 0.038586 Batch F1: 0.4
Epoch:  565       12 Batch loss: 0.046045 Batch F1: 0.888888888888889
Train Avg Loss  565: 0.067760

Train Avg F1  565: 0.7242627141047185

Val Avg Loss  565: 0.065280

Val Avg F1  565:  0.5868131868131868

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 566
--------------------------------------------------------------
Epoch:  566        1 Batch loss: 0.067692 Batch F1: 0.5454545454545454
Epoch:  566        2 Batch loss: 0.068951 Batch F1: 0.4444444444444445
Epoch:  566        3 Batch loss: 0.057089 Batch F1: 0.7272727272727273
Epoch:  566        4 Batch loss: 0.066567 Batch F1: 0.25
Epoch:  566        5 Batch loss: 0.069523 Batch F1: 0.4615384615384615
Epoch:  566        6 Batch loss: 0.082881 Batch F1: 0.625
Epoch:  566        7 Batch loss: 0.055245 Batch F1: 0.888888888888889
Epoch:  566        8 Batch loss: 0.055998 Batch F1: 1.0
Epoch:  566        9 Batch loss: 0.089765 Batch F1: 0.6666666666666666
Epoch:  566       10 Batch loss: 0.065927 Batch F1: 0.7692307692307693
Epoch:  566       11 Batch loss: 0.074551 Batch F1: 0.9090909090909091
Epoch:  566       12 Batch loss: 0.055045 Batch F1: 1.0
Train Avg Loss  566: 0.067436

Train Avg F1  566: 0.6906322843822844

Val Avg Loss  566: 0.063232

Val Avg F1  566:  0.9412955465587044

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 567
--------------------------------------------------------------
Epoch:  567        1 Batch loss: 0.052382 Batch F1: 1.0
Epoch:  567        2 Batch loss: 0.070896 Batch F1: 0.888888888888889
Epoch:  567        3 Batch loss: 0.074038 Batch F1: 0.9
Epoch:  567        4 Batch loss: 0.065781 Batch F1: 0.888888888888889
Epoch:  567        5 Batch loss: 0.064411 Batch F1: 0.8333333333333334
Epoch:  567        6 Batch loss: 0.063021 Batch F1: 0.6666666666666666
Epoch:  567        7 Batch loss: 0.067572 Batch F1: 0.6666666666666666
Epoch:  567        8 Batch loss: 0.055691 Batch F1: 0.5454545454545454
Epoch:  567        9 Batch loss: 0.089756 Batch F1: 0.6363636363636364
Epoch:  567       10 Batch loss: 0.081835 Batch F1: 0.8421052631578948
Epoch:  567       11 Batch loss: 0.060450 Batch F1: 0.9090909090909091
Epoch:  567       12 Batch loss: 0.079367 Batch F1: 0.8
Train Avg Loss  567: 0.068767

Train Avg F1  567: 0.7981215665426192

Val Avg Loss  567: 0.063482

Val Avg F1  567:  0.8720833333333333

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 568
--------------------------------------------------------------
Epoch:  568        1 Batch loss: 0.071829 Batch F1: 0.8888888888888888
Epoch:  568        2 Batch loss: 0.065639 Batch F1: 0.7499999999999999
Epoch:  568        3 Batch loss: 0.098383 Batch F1: 0.0
Epoch:  568        4 Batch loss: 0.071649 Batch F1: 0.5714285714285715
Epoch:  568        5 Batch loss: 0.058720 Batch F1: 0.8
Epoch:  568        6 Batch loss: 0.065578 Batch F1: 0.888888888888889
Epoch:  568        7 Batch loss: 0.082115 Batch F1: 0.9600000000000001
Epoch:  568        8 Batch loss: 0.077248 Batch F1: 0.9090909090909091
Epoch:  568        9 Batch loss: 0.071894 Batch F1: 0.9411764705882353
Epoch:  568       10 Batch loss: 0.057453 Batch F1: 0.9333333333333333
Epoch:  568       11 Batch loss: 0.048567 Batch F1: 1.0
Epoch:  568       12 Batch loss: 0.061755 Batch F1: 0.8
Train Avg Loss  568: 0.069236

Train Avg F1  568: 0.7869005885182357

Val Avg Loss  568: 0.064462

Val Avg F1  568:  0.5964052287581699

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 569
--------------------------------------------------------------
Epoch:  569        1 Batch loss: 0.076667 Batch F1: 0.5333333333333333
Epoch:  569        2 Batch loss: 0.052503 Batch F1: 0.5714285714285715
Epoch:  569        3 Batch loss: 0.085623 Batch F1: 0.7058823529411764
Epoch:  569        4 Batch loss: 0.078868 Batch F1: 0.782608695652174
Epoch:  569        5 Batch loss: 0.072482 Batch F1: 0.888888888888889
Epoch:  569        6 Batch loss: 0.074738 Batch F1: 0.9
Epoch:  569        7 Batch loss: 0.059546 Batch F1: 0.9473684210526316
Epoch:  569        8 Batch loss: 0.079879 Batch F1: 0.9
Epoch:  569        9 Batch loss: 0.084413 Batch F1: 0.9
Epoch:  569       10 Batch loss: 0.046513 Batch F1: 1.0
Epoch:  569       11 Batch loss: 0.065474 Batch F1: 0.6
Epoch:  569       12 Batch loss: 0.033993 Batch F1: 0.8
Train Avg Loss  569: 0.067558

Train Avg F1  569: 0.7941258552747313

Val Avg Loss  569: 0.076756

Val Avg F1  569:  0.3275974025974026

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 570
--------------------------------------------------------------
Epoch:  570        1 Batch loss: 0.045429 Batch F1: 0.6666666666666666
Epoch:  570        2 Batch loss: 0.066694 Batch F1: 0.2222222222222222
Epoch:  570        3 Batch loss: 0.063781 Batch F1: 0.5454545454545454
Epoch:  570        4 Batch loss: 0.088450 Batch F1: 0.923076923076923
Epoch:  570        5 Batch loss: 0.068732 Batch F1: 0.8
Epoch:  570        6 Batch loss: 0.046049 Batch F1: 0.7272727272727273
Epoch:  570        7 Batch loss: 0.072456 Batch F1: 0.7499999999999999
Epoch:  570        8 Batch loss: 0.062341 Batch F1: 0.4444444444444445
Epoch:  570        9 Batch loss: 0.102569 Batch F1: 0.5263157894736842
Epoch:  570       10 Batch loss: 0.083987 Batch F1: 0.4615384615384615
Epoch:  570       11 Batch loss: 0.084033 Batch F1: 0.8421052631578948
Epoch:  570       12 Batch loss: 0.071460 Batch F1: 1.0
Train Avg Loss  570: 0.071332

Train Avg F1  570: 0.6590914202756308

Val Avg Loss  570: 0.070238

Val Avg F1  570:  0.9157407407407407

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 571
--------------------------------------------------------------
Epoch:  571        1 Batch loss: 0.079645 Batch F1: 0.8571428571428571
Epoch:  571        2 Batch loss: 0.057644 Batch F1: 0.5
Epoch:  571        3 Batch loss: 0.085667 Batch F1: 0.18181818181818182
Epoch:  571        4 Batch loss: 0.102417 Batch F1: 0.5555555555555556
Epoch:  571        5 Batch loss: 0.058414 Batch F1: 1.0
Epoch:  571        6 Batch loss: 0.074424 Batch F1: 0.9
Epoch:  571        7 Batch loss: 0.079723 Batch F1: 0.9
Epoch:  571        8 Batch loss: 0.069373 Batch F1: 0.8181818181818181
Epoch:  571        9 Batch loss: 0.062806 Batch F1: 0.6666666666666666
Epoch:  571       10 Batch loss: 0.074160 Batch F1: 0.5714285714285715
Epoch:  571       11 Batch loss: 0.062865 Batch F1: 1.0
Epoch:  571       12 Batch loss: 0.065419 Batch F1: 0.8
Train Avg Loss  571: 0.072713

Train Avg F1  571: 0.7292328042328043

Val Avg Loss  571: 0.066509

Val Avg F1  571:  0.7749766573295985

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 572
--------------------------------------------------------------
Epoch:  572        1 Batch loss: 0.071976 Batch F1: 0.8750000000000001
Epoch:  572        2 Batch loss: 0.055339 Batch F1: 0.7272727272727273
Epoch:  572        3 Batch loss: 0.068090 Batch F1: 0.5454545454545454
Epoch:  572        4 Batch loss: 0.089827 Batch F1: 0.6086956521739131
Epoch:  572        5 Batch loss: 0.071653 Batch F1: 0.8333333333333333
Epoch:  572        6 Batch loss: 0.082720 Batch F1: 0.8695652173913043
Epoch:  572        7 Batch loss: 0.072818 Batch F1: 0.8181818181818181
Epoch:  572        8 Batch loss: 0.074763 Batch F1: 0.8888888888888888
Epoch:  572        9 Batch loss: 0.062418 Batch F1: 0.9333333333333333
Epoch:  572       10 Batch loss: 0.043810 Batch F1: 1.0
Epoch:  572       11 Batch loss: 0.075032 Batch F1: 0.7692307692307693
Epoch:  572       12 Batch loss: 0.056884 Batch F1: 0.33333333333333337
Train Avg Loss  572: 0.068778

Train Avg F1  572: 0.7668574682161641

Val Avg Loss  572: 0.070867

Val Avg F1  572:  0.6191176470588236

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 573
--------------------------------------------------------------
Epoch:  573        1 Batch loss: 0.081120 Batch F1: 0.2222222222222222
Epoch:  573        2 Batch loss: 0.090630 Batch F1: 0.0
Epoch:  573        3 Batch loss: 0.080416 Batch F1: 0.3636363636363636
Epoch:  573        4 Batch loss: 0.069554 Batch F1: 0.8750000000000001
Epoch:  573        5 Batch loss: 0.078426 Batch F1: 0.962962962962963
Epoch:  573        6 Batch loss: 0.052451 Batch F1: 1.0
Epoch:  573        7 Batch loss: 0.064901 Batch F1: 0.9
Epoch:  573        8 Batch loss: 0.061071 Batch F1: 1.0
Epoch:  573        9 Batch loss: 0.056686 Batch F1: 0.7272727272727273
Epoch:  573       10 Batch loss: 0.105618 Batch F1: 0.4444444444444445
Epoch:  573       11 Batch loss: 0.059763 Batch F1: 0.6
Epoch:  573       12 Batch loss: 0.046792 Batch F1: 0.9090909090909091
Train Avg Loss  573: 0.070619

Train Avg F1  573: 0.6670524691358025

Val Avg Loss  573: 0.063574

Val Avg F1  573:  0.6416221033868093

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 574
--------------------------------------------------------------
Epoch:  574        1 Batch loss: 0.059206 Batch F1: 0.6666666666666666
Epoch:  574        2 Batch loss: 0.056965 Batch F1: 0.0
Epoch:  574        3 Batch loss: 0.069118 Batch F1: 0.3636363636363636
Epoch:  574        4 Batch loss: 0.062959 Batch F1: 0.4
Epoch:  574        5 Batch loss: 0.058176 Batch F1: 0.7692307692307693
Epoch:  574        6 Batch loss: 0.067501 Batch F1: 1.0
Epoch:  574        7 Batch loss: 0.077458 Batch F1: 0.9090909090909091
Epoch:  574        8 Batch loss: 0.078986 Batch F1: 0.8571428571428571
Epoch:  574        9 Batch loss: 0.056883 Batch F1: 0.7499999999999999
Epoch:  574       10 Batch loss: 0.067718 Batch F1: 0.8750000000000001
Epoch:  574       11 Batch loss: 0.071294 Batch F1: 0.7142857142857143
Epoch:  574       12 Batch loss: 0.092241 Batch F1: 0.4
Train Avg Loss  574: 0.068209

Train Avg F1  574: 0.6420877733377733

Val Avg Loss  574: 0.065097

Val Avg F1  574:  0.8108563263362025

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 575
--------------------------------------------------------------
Epoch:  575        1 Batch loss: 0.086852 Batch F1: 0.761904761904762
Epoch:  575        2 Batch loss: 0.054073 Batch F1: 1.0
Epoch:  575        3 Batch loss: 0.057759 Batch F1: 1.0
Epoch:  575        4 Batch loss: 0.059542 Batch F1: 0.923076923076923
Epoch:  575        5 Batch loss: 0.075686 Batch F1: 0.888888888888889
Epoch:  575        6 Batch loss: 0.088098 Batch F1: 0.7777777777777778
Epoch:  575        7 Batch loss: 0.050612 Batch F1: 0.7272727272727273
Epoch:  575        8 Batch loss: 0.048846 Batch F1: 0.5714285714285715
Epoch:  575        9 Batch loss: 0.114036 Batch F1: 0.5
Epoch:  575       10 Batch loss: 0.081680 Batch F1: 0.5882352941176471
Epoch:  575       11 Batch loss: 0.074546 Batch F1: 0.8235294117647058
Epoch:  575       12 Batch loss: 0.058075 Batch F1: 0.8
Train Avg Loss  575: 0.070817

Train Avg F1  575: 0.780176196352667

Val Avg Loss  575: 0.063405

Val Avg F1  575:  0.85492673992674

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 576
--------------------------------------------------------------
Epoch:  576        1 Batch loss: 0.046458 Batch F1: 0.9333333333333333
Epoch:  576        2 Batch loss: 0.096783 Batch F1: 0.8695652173913044
Epoch:  576        3 Batch loss: 0.040716 Batch F1: 0.9090909090909091
Epoch:  576        4 Batch loss: 0.069834 Batch F1: 0.9333333333333333
Epoch:  576        5 Batch loss: 0.057405 Batch F1: 0.7692307692307692
Epoch:  576        6 Batch loss: 0.079764 Batch F1: 0.36363636363636365
Epoch:  576        7 Batch loss: 0.106686 Batch F1: 0.0
Epoch:  576        8 Batch loss: 0.051269 Batch F1: 0.0
Epoch:  576        9 Batch loss: 0.087009 Batch F1: 0.823529411764706
Epoch:  576       10 Batch loss: 0.099140 Batch F1: 0.6666666666666666
Epoch:  576       11 Batch loss: 0.069453 Batch F1: 0.923076923076923
Epoch:  576       12 Batch loss: 0.073847 Batch F1: 0.8750000000000001
Train Avg Loss  576: 0.073197

Train Avg F1  576: 0.6722052439603591

Val Avg Loss  576: 0.063151

Val Avg F1  576:  0.9090643274853801

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 577
--------------------------------------------------------------
Epoch:  577        1 Batch loss: 0.074127 Batch F1: 0.8750000000000001
Epoch:  577        2 Batch loss: 0.078164 Batch F1: 0.3636363636363636
Epoch:  577        3 Batch loss: 0.057688 Batch F1: 0.7499999999999999
Epoch:  577        4 Batch loss: 0.063895 Batch F1: 0.6666666666666666
Epoch:  577        5 Batch loss: 0.064799 Batch F1: 0.8571428571428571
Epoch:  577        6 Batch loss: 0.061576 Batch F1: 0.9411764705882353
Epoch:  577        7 Batch loss: 0.065433 Batch F1: 0.8333333333333333
Epoch:  577        8 Batch loss: 0.069630 Batch F1: 0.7058823529411764
Epoch:  577        9 Batch loss: 0.057536 Batch F1: 0.6
Epoch:  577       10 Batch loss: 0.087417 Batch F1: 0.6666666666666666
Epoch:  577       11 Batch loss: 0.072931 Batch F1: 0.3636363636363636
Epoch:  577       12 Batch loss: 0.072710 Batch F1: 0.25
Train Avg Loss  577: 0.068825

Train Avg F1  577: 0.6560950895509718

Val Avg Loss  577: 0.063062

Val Avg F1  577:  0.7398567119155355

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 578
--------------------------------------------------------------
Epoch:  578        1 Batch loss: 0.100085 Batch F1: 0.6956521739130436
Epoch:  578        2 Batch loss: 0.062118 Batch F1: 0.9473684210526316
Epoch:  578        3 Batch loss: 0.073410 Batch F1: 0.8571428571428571
Epoch:  578        4 Batch loss: 0.062539 Batch F1: 0.9090909090909091
Epoch:  578        5 Batch loss: 0.054368 Batch F1: 1.0
Epoch:  578        6 Batch loss: 0.060798 Batch F1: 0.6666666666666666
Epoch:  578        7 Batch loss: 0.088831 Batch F1: 0.5882352941176471
Epoch:  578        8 Batch loss: 0.063099 Batch F1: 0.9333333333333333
Epoch:  578        9 Batch loss: 0.053486 Batch F1: 0.9411764705882353
Epoch:  578       10 Batch loss: 0.065352 Batch F1: 1.0
Epoch:  578       11 Batch loss: 0.060713 Batch F1: 0.888888888888889
Epoch:  578       12 Batch loss: 0.085096 Batch F1: 0.7777777777777778
Train Avg Loss  578: 0.069158

Train Avg F1  578: 0.8504443993809994

Val Avg Loss  578: 0.063845

Val Avg F1  578:  0.6351190476190476

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 579
--------------------------------------------------------------
Epoch:  579        1 Batch loss: 0.079317 Batch F1: 0.6
Epoch:  579        2 Batch loss: 0.058036 Batch F1: 0.888888888888889
Epoch:  579        3 Batch loss: 0.065572 Batch F1: 1.0
Epoch:  579        4 Batch loss: 0.059946 Batch F1: 0.7692307692307692
Epoch:  579        5 Batch loss: 0.074320 Batch F1: 0.4
Epoch:  579        6 Batch loss: 0.062865 Batch F1: 0.6666666666666666
Epoch:  579        7 Batch loss: 0.068788 Batch F1: 0.4444444444444445
Epoch:  579        8 Batch loss: 0.050605 Batch F1: 0.5714285714285715
Epoch:  579        9 Batch loss: 0.056710 Batch F1: 0.5454545454545454
Epoch:  579       10 Batch loss: 0.083842 Batch F1: 0.6666666666666666
Epoch:  579       11 Batch loss: 0.073586 Batch F1: 0.7142857142857143
Epoch:  579       12 Batch loss: 0.071322 Batch F1: 0.8181818181818181
Train Avg Loss  579: 0.067076

Train Avg F1  579: 0.6737706737706738

Val Avg Loss  579: 0.064826

Val Avg F1  579:  0.9233333333333333

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 580
--------------------------------------------------------------
Epoch:  580        1 Batch loss: 0.072391 Batch F1: 1.0
Epoch:  580        2 Batch loss: 0.073826 Batch F1: 0.9473684210526316
Epoch:  580        3 Batch loss: 0.080023 Batch F1: 0.7777777777777777
Epoch:  580        4 Batch loss: 0.065007 Batch F1: 0.9333333333333333
Epoch:  580        5 Batch loss: 0.067609 Batch F1: 0.8
Epoch:  580        6 Batch loss: 0.079887 Batch F1: 0.6666666666666666
Epoch:  580        7 Batch loss: 0.040389 Batch F1: 1.0
Epoch:  580        8 Batch loss: 0.069446 Batch F1: 0.5454545454545454
Epoch:  580        9 Batch loss: 0.048590 Batch F1: 0.7499999999999999
Epoch:  580       10 Batch loss: 0.074044 Batch F1: 0.4615384615384615
Epoch:  580       11 Batch loss: 0.072629 Batch F1: 0.5714285714285715
Epoch:  580       12 Batch loss: 0.082323 Batch F1: 0.7058823529411764
Train Avg Loss  580: 0.068847

Train Avg F1  580: 0.7632875108494304

Val Avg Loss  580: 0.064152

Val Avg F1  580:  0.8315601838821653

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 581
--------------------------------------------------------------
Epoch:  581        1 Batch loss: 0.076380 Batch F1: 0.7499999999999999
Epoch:  581        2 Batch loss: 0.074813 Batch F1: 0.8235294117647058
Epoch:  581        3 Batch loss: 0.062396 Batch F1: 0.8
Epoch:  581        4 Batch loss: 0.074307 Batch F1: 0.923076923076923
Epoch:  581        5 Batch loss: 0.066552 Batch F1: 0.8750000000000001
Epoch:  581        6 Batch loss: 0.080724 Batch F1: 0.625
Epoch:  581        7 Batch loss: 0.054828 Batch F1: 0.7142857142857143
Epoch:  581        8 Batch loss: 0.051066 Batch F1: 0.5714285714285715
Epoch:  581        9 Batch loss: 0.093811 Batch F1: 0.846153846153846
Epoch:  581       10 Batch loss: 0.051409 Batch F1: 1.0
Epoch:  581       11 Batch loss: 0.068682 Batch F1: 0.962962962962963
Epoch:  581       12 Batch loss: 0.096660 Batch F1: 0.6153846153846153
Train Avg Loss  581: 0.070969

Train Avg F1  581: 0.7922351704214449

Val Avg Loss  581: 0.062820

Val Avg F1  581:  0.8245341614906833

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 582
--------------------------------------------------------------
Epoch:  582        1 Batch loss: 0.061071 Batch F1: 0.7499999999999999
Epoch:  582        2 Batch loss: 0.056664 Batch F1: 0.9090909090909091
Epoch:  582        3 Batch loss: 0.046248 Batch F1: 0.9090909090909091
Epoch:  582        4 Batch loss: 0.083367 Batch F1: 0.7826086956521738
Epoch:  582        5 Batch loss: 0.058998 Batch F1: 0.4444444444444445
Epoch:  582        6 Batch loss: 0.075887 Batch F1: 0.6153846153846153
Epoch:  582        7 Batch loss: 0.050879 Batch F1: 0.6
Epoch:  582        8 Batch loss: 0.070397 Batch F1: 0.8571428571428571
Epoch:  582        9 Batch loss: 0.065646 Batch F1: 0.25
Epoch:  582       10 Batch loss: 0.087323 Batch F1: 0.6
Epoch:  582       11 Batch loss: 0.079468 Batch F1: 0.88
Epoch:  582       12 Batch loss: 0.089106 Batch F1: 0.923076923076923
Train Avg Loss  582: 0.068754

Train Avg F1  582: 0.7100699461569026

Val Avg Loss  582: 0.064005

Val Avg F1  582:  0.9047619047619048

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 583
--------------------------------------------------------------
Epoch:  583        1 Batch loss: 0.086765 Batch F1: 0.8571428571428571
Epoch:  583        2 Batch loss: 0.080016 Batch F1: 0.9090909090909091
Epoch:  583        3 Batch loss: 0.070791 Batch F1: 0.0
Epoch:  583        4 Batch loss: 0.103438 Batch F1: 0.5833333333333334
Epoch:  583        5 Batch loss: 0.062301 Batch F1: 0.6666666666666666
Epoch:  583        6 Batch loss: 0.059715 Batch F1: 1.0
Epoch:  583        7 Batch loss: 0.035964 Batch F1: 0.8
Epoch:  583        8 Batch loss: 0.066559 Batch F1: 0.6666666666666666
Epoch:  583        9 Batch loss: 0.074711 Batch F1: 0.42857142857142855
Epoch:  583       10 Batch loss: 0.054115 Batch F1: 0.6
Epoch:  583       11 Batch loss: 0.077427 Batch F1: 0.4615384615384615
Epoch:  583       12 Batch loss: 0.041924 Batch F1: 0.0
Train Avg Loss  583: 0.067810

Train Avg F1  583: 0.5810841935841936

Val Avg Loss  583: 0.068539

Val Avg F1  583:  0.6165393430099313

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 584
--------------------------------------------------------------
Epoch:  584        1 Batch loss: 0.067742 Batch F1: 0.7499999999999999
Epoch:  584        2 Batch loss: 0.055730 Batch F1: 0.4444444444444445
Epoch:  584        3 Batch loss: 0.046409 Batch F1: 0.9090909090909091
Epoch:  584        4 Batch loss: 0.055409 Batch F1: 1.0
Epoch:  584        5 Batch loss: 0.068911 Batch F1: 0.8
Epoch:  584        6 Batch loss: 0.095226 Batch F1: 0.846153846153846
Epoch:  584        7 Batch loss: 0.078382 Batch F1: 0.8750000000000001
Epoch:  584        8 Batch loss: 0.066183 Batch F1: 0.9473684210526316
Epoch:  584        9 Batch loss: 0.057110 Batch F1: 1.0
Epoch:  584       10 Batch loss: 0.082519 Batch F1: 0.3636363636363636
Epoch:  584       11 Batch loss: 0.085159 Batch F1: 0.42857142857142855
Epoch:  584       12 Batch loss: 0.088649 Batch F1: 0.2222222222222222
Train Avg Loss  584: 0.070619

Train Avg F1  584: 0.7155406362643203

Val Avg Loss  584: 0.065682

Val Avg F1  584:  0.7104700854700854

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 585
--------------------------------------------------------------
Epoch:  585        1 Batch loss: 0.077041 Batch F1: 0.5
Epoch:  585        2 Batch loss: 0.051406 Batch F1: 0.8333333333333334
Epoch:  585        3 Batch loss: 0.069743 Batch F1: 0.5333333333333333
Epoch:  585        4 Batch loss: 0.070396 Batch F1: 0.8571428571428571
Epoch:  585        5 Batch loss: 0.058850 Batch F1: 0.9411764705882353
Epoch:  585        6 Batch loss: 0.085292 Batch F1: 0.6666666666666665
Epoch:  585        7 Batch loss: 0.056173 Batch F1: 0.8333333333333333
Epoch:  585        8 Batch loss: 0.065859 Batch F1: 0.7272727272727273
Epoch:  585        9 Batch loss: 0.055279 Batch F1: 0.6666666666666666
Epoch:  585       10 Batch loss: 0.064371 Batch F1: 0.0
Epoch:  585       11 Batch loss: 0.086824 Batch F1: 0.7000000000000001
Epoch:  585       12 Batch loss: 0.075966 Batch F1: 0.2222222222222222
Train Avg Loss  585: 0.068100

Train Avg F1  585: 0.6234289675466147

Val Avg Loss  585: 0.062990

Val Avg F1  585:  0.755764411027569

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 586
--------------------------------------------------------------
Epoch:  586        1 Batch loss: 0.059558 Batch F1: 0.6666666666666666
Epoch:  586        2 Batch loss: 0.079652 Batch F1: 0.8
Epoch:  586        3 Batch loss: 0.069009 Batch F1: 0.9411764705882353
Epoch:  586        4 Batch loss: 0.058420 Batch F1: 0.8750000000000001
Epoch:  586        5 Batch loss: 0.060030 Batch F1: 1.0
Epoch:  586        6 Batch loss: 0.093191 Batch F1: 0.7499999999999999
Epoch:  586        7 Batch loss: 0.077669 Batch F1: 0.888888888888889
Epoch:  586        8 Batch loss: 0.072094 Batch F1: 0.9
Epoch:  586        9 Batch loss: 0.073673 Batch F1: 1.0
Epoch:  586       10 Batch loss: 0.068173 Batch F1: 0.9411764705882353
Epoch:  586       11 Batch loss: 0.067673 Batch F1: 0.9411764705882353
Epoch:  586       12 Batch loss: 0.044266 Batch F1: 0.8
Train Avg Loss  586: 0.068617

Train Avg F1  586: 0.8753404139433553

Val Avg Loss  586: 0.066838

Val Avg F1  586:  0.6204906204906205

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 587
--------------------------------------------------------------
Epoch:  587        1 Batch loss: 0.054414 Batch F1: 0.6666666666666666
Epoch:  587        2 Batch loss: 0.090917 Batch F1: 0.6
Epoch:  587        3 Batch loss: 0.092814 Batch F1: 0.923076923076923
Epoch:  587        4 Batch loss: 0.086846 Batch F1: 0.8
Epoch:  587        5 Batch loss: 0.083475 Batch F1: 1.0
Epoch:  587        6 Batch loss: 0.063128 Batch F1: 0.7272727272727273
Epoch:  587        7 Batch loss: 0.076163 Batch F1: 0.5454545454545454
Epoch:  587        8 Batch loss: 0.075164 Batch F1: 0.18181818181818182
Epoch:  587        9 Batch loss: 0.073332 Batch F1: 0.4
Epoch:  587       10 Batch loss: 0.064619 Batch F1: 0.8235294117647058
Epoch:  587       11 Batch loss: 0.061783 Batch F1: 1.0
Epoch:  587       12 Batch loss: 0.067779 Batch F1: 1.0
Train Avg Loss  587: 0.074203

Train Avg F1  587: 0.7223182046711459

Val Avg Loss  587: 0.068277

Val Avg F1  587:  0.8336038961038961

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 588
--------------------------------------------------------------
Epoch:  588        1 Batch loss: 0.069120 Batch F1: 0.9411764705882353
Epoch:  588        2 Batch loss: 0.066189 Batch F1: 0.6153846153846153
Epoch:  588        3 Batch loss: 0.059006 Batch F1: 0.4444444444444445
Epoch:  588        4 Batch loss: 0.110321 Batch F1: 0.47619047619047616
Epoch:  588        5 Batch loss: 0.071582 Batch F1: 0.5
Epoch:  588        6 Batch loss: 0.072293 Batch F1: 0.8
Epoch:  588        7 Batch loss: 0.095471 Batch F1: 0.7142857142857143
Epoch:  588        8 Batch loss: 0.053005 Batch F1: 1.0
Epoch:  588        9 Batch loss: 0.065214 Batch F1: 0.8421052631578948
Epoch:  588       10 Batch loss: 0.083066 Batch F1: 0.8181818181818181
Epoch:  588       11 Batch loss: 0.047983 Batch F1: 0.4
Epoch:  588       12 Batch loss: 0.054135 Batch F1: 0.7499999999999999
Train Avg Loss  588: 0.070615

Train Avg F1  588: 0.6918140668527665

Val Avg Loss  588: 0.064210

Val Avg F1  588:  0.59375

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 589
--------------------------------------------------------------
Epoch:  589        1 Batch loss: 0.058673 Batch F1: 0.5454545454545454
Epoch:  589        2 Batch loss: 0.059928 Batch F1: 0.6
Epoch:  589        3 Batch loss: 0.068760 Batch F1: 0.25
Epoch:  589        4 Batch loss: 0.071834 Batch F1: 0.625
Epoch:  589        5 Batch loss: 0.061667 Batch F1: 1.0
Epoch:  589        6 Batch loss: 0.091525 Batch F1: 0.9166666666666666
Epoch:  589        7 Batch loss: 0.072489 Batch F1: 0.9
Epoch:  589        8 Batch loss: 0.054645 Batch F1: 0.8750000000000001
Epoch:  589        9 Batch loss: 0.068592 Batch F1: 0.9
Epoch:  589       10 Batch loss: 0.063963 Batch F1: 0.923076923076923
Epoch:  589       11 Batch loss: 0.062512 Batch F1: 0.6153846153846153
Epoch:  589       12 Batch loss: 0.071933 Batch F1: 0.5454545454545454
Train Avg Loss  589: 0.067210

Train Avg F1  589: 0.7246697746697747

Val Avg Loss  589: 0.065063

Val Avg F1  589:  0.641025641025641

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 590
--------------------------------------------------------------
Epoch:  590        1 Batch loss: 0.051133 Batch F1: 0.8571428571428571
Epoch:  590        2 Batch loss: 0.057574 Batch F1: 0.7272727272727273
Epoch:  590        3 Batch loss: 0.081568 Batch F1: 0.4615384615384615
Epoch:  590        4 Batch loss: 0.060539 Batch F1: 0.4444444444444445
Epoch:  590        5 Batch loss: 0.078399 Batch F1: 0.33333333333333337
Epoch:  590        6 Batch loss: 0.063448 Batch F1: 0.8421052631578948
Epoch:  590        7 Batch loss: 0.087935 Batch F1: 0.8695652173913044
Epoch:  590        8 Batch loss: 0.056731 Batch F1: 1.0
Epoch:  590        9 Batch loss: 0.064584 Batch F1: 0.9090909090909091
Epoch:  590       10 Batch loss: 0.063913 Batch F1: 0.9411764705882353
Epoch:  590       11 Batch loss: 0.072810 Batch F1: 0.888888888888889
Epoch:  590       12 Batch loss: 0.062735 Batch F1: 0.8333333333333333
Train Avg Loss  590: 0.066781

Train Avg F1  590: 0.7589909921818658

Val Avg Loss  590: 0.064404

Val Avg F1  590:  0.7281746031746031

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 591
--------------------------------------------------------------
Epoch:  591        1 Batch loss: 0.090236 Batch F1: 0.8421052631578948
Epoch:  591        2 Batch loss: 0.058761 Batch F1: 0.9333333333333333
Epoch:  591        3 Batch loss: 0.066192 Batch F1: 0.9090909090909091
Epoch:  591        4 Batch loss: 0.056800 Batch F1: 0.7499999999999999
Epoch:  591        5 Batch loss: 0.037009 Batch F1: 0.888888888888889
Epoch:  591        6 Batch loss: 0.082563 Batch F1: 0.6666666666666666
Epoch:  591        7 Batch loss: 0.069445 Batch F1: 0.8
Epoch:  591        8 Batch loss: 0.076664 Batch F1: 0.5714285714285715
Epoch:  591        9 Batch loss: 0.078787 Batch F1: 0.761904761904762
Epoch:  591       10 Batch loss: 0.066851 Batch F1: 0.8571428571428571
Epoch:  591       11 Batch loss: 0.063278 Batch F1: 0.9333333333333333
Epoch:  591       12 Batch loss: 0.063352 Batch F1: 0.8333333333333333
Train Avg Loss  591: 0.067495

Train Avg F1  591: 0.8122689931900459

Val Avg Loss  591: 0.062206

Val Avg F1  591:  0.8973559120617943

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 592
--------------------------------------------------------------
Epoch:  592        1 Batch loss: 0.076128 Batch F1: 0.8750000000000001
Epoch:  592        2 Batch loss: 0.059470 Batch F1: 0.7692307692307693
Epoch:  592        3 Batch loss: 0.053896 Batch F1: 0.8
Epoch:  592        4 Batch loss: 0.047051 Batch F1: 0.8
Epoch:  592        5 Batch loss: 0.066771 Batch F1: 0.6
Epoch:  592        6 Batch loss: 0.059402 Batch F1: 0.7142857142857143
Epoch:  592        7 Batch loss: 0.087144 Batch F1: 0.42857142857142855
Epoch:  592        8 Batch loss: 0.053230 Batch F1: 0.7692307692307693
Epoch:  592        9 Batch loss: 0.047436 Batch F1: 0.6666666666666666
Epoch:  592       10 Batch loss: 0.071877 Batch F1: 0.3636363636363636
Epoch:  592       11 Batch loss: 0.106146 Batch F1: 0.38095238095238093
Epoch:  592       12 Batch loss: 0.067996 Batch F1: 0.9411764705882353
Train Avg Loss  592: 0.066379

Train Avg F1  592: 0.6757292135968607

Val Avg Loss  592: 0.065013

Val Avg F1  592:  0.9218181818181819

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 593
--------------------------------------------------------------
Epoch:  593        1 Batch loss: 0.048624 Batch F1: 0.8000000000000002
Epoch:  593        2 Batch loss: 0.078900 Batch F1: 0.8333333333333334
Epoch:  593        3 Batch loss: 0.054704 Batch F1: 0.923076923076923
Epoch:  593        4 Batch loss: 0.048309 Batch F1: 1.0
Epoch:  593        5 Batch loss: 0.101859 Batch F1: 0.7407407407407407
Epoch:  593        6 Batch loss: 0.060369 Batch F1: 0.7499999999999999
Epoch:  593        7 Batch loss: 0.075734 Batch F1: 1.0
Epoch:  593        8 Batch loss: 0.077535 Batch F1: 1.0
Epoch:  593        9 Batch loss: 0.092597 Batch F1: 0.75
Epoch:  593       10 Batch loss: 0.057226 Batch F1: 0.8571428571428571
Epoch:  593       11 Batch loss: 0.056730 Batch F1: 0.8571428571428571
Epoch:  593       12 Batch loss: 0.085962 Batch F1: 0.2222222222222222
Train Avg Loss  593: 0.069879

Train Avg F1  593: 0.8111382444715778

Val Avg Loss  593: 0.070110

Val Avg F1  593:  0.5538461538461539

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 594
--------------------------------------------------------------
Epoch:  594        1 Batch loss: 0.081288 Batch F1: 0.5333333333333333
Epoch:  594        2 Batch loss: 0.087452 Batch F1: 0.6666666666666666
Epoch:  594        3 Batch loss: 0.071957 Batch F1: 0.823529411764706
Epoch:  594        4 Batch loss: 0.071830 Batch F1: 0.9523809523809523
Epoch:  594        5 Batch loss: 0.067819 Batch F1: 0.8750000000000001
Epoch:  594        6 Batch loss: 0.049586 Batch F1: 0.8333333333333333
Epoch:  594        7 Batch loss: 0.052748 Batch F1: 0.8235294117647058
Epoch:  594        8 Batch loss: 0.070902 Batch F1: 0.5454545454545454
Epoch:  594        9 Batch loss: 0.042716 Batch F1: 0.4
Epoch:  594       10 Batch loss: 0.068287 Batch F1: 0.4444444444444445
Epoch:  594       11 Batch loss: 0.120538 Batch F1: 0.4210526315789474
Epoch:  594       12 Batch loss: 0.053421 Batch F1: 0.8333333333333333
Train Avg Loss  594: 0.069879

Train Avg F1  594: 0.6793381720045807

Val Avg Loss  594: 0.064920

Val Avg F1  594:  0.8253968253968255

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 595
--------------------------------------------------------------
Epoch:  595        1 Batch loss: 0.074839 Batch F1: 0.8
Epoch:  595        2 Batch loss: 0.073719 Batch F1: 1.0
Epoch:  595        3 Batch loss: 0.077207 Batch F1: 0.8750000000000001
Epoch:  595        4 Batch loss: 0.071508 Batch F1: 0.9333333333333333
Epoch:  595        5 Batch loss: 0.060484 Batch F1: 0.9411764705882353
Epoch:  595        6 Batch loss: 0.065700 Batch F1: 0.8571428571428571
Epoch:  595        7 Batch loss: 0.076360 Batch F1: 0.6666666666666666
Epoch:  595        8 Batch loss: 0.056630 Batch F1: 0.8
Epoch:  595        9 Batch loss: 0.040145 Batch F1: 1.0
Epoch:  595       10 Batch loss: 0.100315 Batch F1: 0.5555555555555556
Epoch:  595       11 Batch loss: 0.059391 Batch F1: 0.6666666666666666
Epoch:  595       12 Batch loss: 0.070460 Batch F1: 0.9
Train Avg Loss  595: 0.068896

Train Avg F1  595: 0.8329617958294429

Val Avg Loss  595: 0.065547

Val Avg F1  595:  0.907516339869281

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 596
--------------------------------------------------------------
Epoch:  596        1 Batch loss: 0.067448 Batch F1: 0.9411764705882353
Epoch:  596        2 Batch loss: 0.073553 Batch F1: 0.6153846153846154
Epoch:  596        3 Batch loss: 0.079052 Batch F1: 0.6666666666666666
Epoch:  596        4 Batch loss: 0.060933 Batch F1: 0.7777777777777778
Epoch:  596        5 Batch loss: 0.077775 Batch F1: 0.9411764705882353
Epoch:  596        6 Batch loss: 0.064869 Batch F1: 0.888888888888889
Epoch:  596        7 Batch loss: 0.070421 Batch F1: 0.9411764705882353
Epoch:  596        8 Batch loss: 0.062031 Batch F1: 0.7272727272727273
Epoch:  596        9 Batch loss: 0.050207 Batch F1: 0.8
Epoch:  596       10 Batch loss: 0.067252 Batch F1: 0.8
Epoch:  596       11 Batch loss: 0.064549 Batch F1: 0.7777777777777778
Epoch:  596       12 Batch loss: 0.078692 Batch F1: 0.3636363636363636
Train Avg Loss  596: 0.068065

Train Avg F1  596: 0.7700778524307937

Val Avg Loss  596: 0.063421

Val Avg F1  596:  0.599561403508772

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 597
--------------------------------------------------------------
Epoch:  597        1 Batch loss: 0.074106 Batch F1: 0.6666666666666666
Epoch:  597        2 Batch loss: 0.051680 Batch F1: 0.8
Epoch:  597        3 Batch loss: 0.056050 Batch F1: 0.888888888888889
Epoch:  597        4 Batch loss: 0.070770 Batch F1: 0.9411764705882353
Epoch:  597        5 Batch loss: 0.072556 Batch F1: 0.6666666666666666
Epoch:  597        6 Batch loss: 0.107053 Batch F1: 0.5333333333333333
Epoch:  597        7 Batch loss: 0.069914 Batch F1: 0.33333333333333337
Epoch:  597        8 Batch loss: 0.074455 Batch F1: 0.5333333333333333
Epoch:  597        9 Batch loss: 0.059050 Batch F1: 0.8750000000000001
Epoch:  597       10 Batch loss: 0.053950 Batch F1: 1.0
Epoch:  597       11 Batch loss: 0.062116 Batch F1: 0.9411764705882353
Epoch:  597       12 Batch loss: 0.081667 Batch F1: 0.7999999999999999
Train Avg Loss  597: 0.069447

Train Avg F1  597: 0.7482979302832243

Val Avg Loss  597: 0.062545

Val Avg F1  597:  0.7257575757575757

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 598
--------------------------------------------------------------
Epoch:  598        1 Batch loss: 0.066955 Batch F1: 0.6666666666666666
Epoch:  598        2 Batch loss: 0.075933 Batch F1: 0.5454545454545454
Epoch:  598        3 Batch loss: 0.065249 Batch F1: 0.4444444444444445
Epoch:  598        4 Batch loss: 0.091328 Batch F1: 0.7272727272727273
Epoch:  598        5 Batch loss: 0.073539 Batch F1: 0.5
Epoch:  598        6 Batch loss: 0.059924 Batch F1: 0.9090909090909091
Epoch:  598        7 Batch loss: 0.046030 Batch F1: 0.888888888888889
Epoch:  598        8 Batch loss: 0.091066 Batch F1: 0.5263157894736842
Epoch:  598        9 Batch loss: 0.071719 Batch F1: 0.4615384615384615
Epoch:  598       10 Batch loss: 0.084964 Batch F1: 0.761904761904762
Epoch:  598       11 Batch loss: 0.071884 Batch F1: 0.8750000000000001
Epoch:  598       12 Batch loss: 0.064446 Batch F1: 0.75
Train Avg Loss  598: 0.071920

Train Avg F1  598: 0.6713814328945907

Val Avg Loss  598: 0.064733

Val Avg F1  598:  0.9126662810873337

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 599
--------------------------------------------------------------
Epoch:  599        1 Batch loss: 0.063104 Batch F1: 0.8750000000000001
Epoch:  599        2 Batch loss: 0.068027 Batch F1: 0.7272727272727273
Epoch:  599        3 Batch loss: 0.072728 Batch F1: 0.9166666666666666
Epoch:  599        4 Batch loss: 0.048158 Batch F1: 1.0
Epoch:  599        5 Batch loss: 0.042789 Batch F1: 1.0
Epoch:  599        6 Batch loss: 0.135665 Batch F1: 0.4799999999999999
Epoch:  599        7 Batch loss: 0.070417 Batch F1: 0.888888888888889
Epoch:  599        8 Batch loss: 0.079071 Batch F1: 0.8571428571428571
Epoch:  599        9 Batch loss: 0.071505 Batch F1: 0.6666666666666666
Epoch:  599       10 Batch loss: 0.051828 Batch F1: 0.8571428571428571
Epoch:  599       11 Batch loss: 0.066313 Batch F1: 0.33333333333333337
Epoch:  599       12 Batch loss: 0.085502 Batch F1: 0.6
Train Avg Loss  599: 0.071259

Train Avg F1  599: 0.7668428330928331

Val Avg Loss  599: 0.077496

Val Avg F1  599:  0.1839285714285714

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 600
--------------------------------------------------------------
Epoch:  600        1 Batch loss: 0.072796 Batch F1: 0.25
Epoch:  600        2 Batch loss: 0.073568 Batch F1: 0.0
Epoch:  600        3 Batch loss: 0.082880 Batch F1: 0.625
Epoch:  600        4 Batch loss: 0.062841 Batch F1: 0.9166666666666666
Epoch:  600        5 Batch loss: 0.097524 Batch F1: 1.0
Epoch:  600        6 Batch loss: 0.068138 Batch F1: 0.888888888888889
Epoch:  600        7 Batch loss: 0.065600 Batch F1: 0.7142857142857143
Epoch:  600        8 Batch loss: 0.071657 Batch F1: 0.6153846153846153
Epoch:  600        9 Batch loss: 0.073814 Batch F1: 0.5
Epoch:  600       10 Batch loss: 0.091858 Batch F1: 0.5333333333333333
Epoch:  600       11 Batch loss: 0.066003 Batch F1: 0.7692307692307693
Epoch:  600       12 Batch loss: 0.064421 Batch F1: 0.5714285714285715
Train Avg Loss  600: 0.074258

Train Avg F1  600: 0.6153515466015466

Val Avg Loss  600: 0.063483

Val Avg F1  600:  0.897860962566845

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 601
--------------------------------------------------------------
Epoch:  601        1 Batch loss: 0.076990 Batch F1: 0.5
Epoch:  601        2 Batch loss: 0.053628 Batch F1: 0.7692307692307693
Epoch:  601        3 Batch loss: 0.066462 Batch F1: 0.7058823529411764
Epoch:  601        4 Batch loss: 0.077027 Batch F1: 0.5714285714285715
Epoch:  601        5 Batch loss: 0.079229 Batch F1: 0.7058823529411764
Epoch:  601        6 Batch loss: 0.082146 Batch F1: 1.0
Epoch:  601        7 Batch loss: 0.074799 Batch F1: 0.9090909090909091
Epoch:  601        8 Batch loss: 0.075945 Batch F1: 0.9411764705882353
Epoch:  601        9 Batch loss: 0.051148 Batch F1: 0.6666666666666666
Epoch:  601       10 Batch loss: 0.079419 Batch F1: 0.2222222222222222
Epoch:  601       11 Batch loss: 0.085352 Batch F1: 0.16666666666666669
Epoch:  601       12 Batch loss: 0.074904 Batch F1: 0.7272727272727273
Train Avg Loss  601: 0.073088

Train Avg F1  601: 0.6571266424207601

Val Avg Loss  601: 0.064081

Val Avg F1  601:  0.7827705627705628

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 602
--------------------------------------------------------------
Epoch:  602        1 Batch loss: 0.088906 Batch F1: 0.782608695652174
Epoch:  602        2 Batch loss: 0.076500 Batch F1: 1.0
Epoch:  602        3 Batch loss: 0.067344 Batch F1: 0.8333333333333333
Epoch:  602        4 Batch loss: 0.068504 Batch F1: 0.9333333333333333
Epoch:  602        5 Batch loss: 0.080862 Batch F1: 0.5333333333333333
Epoch:  602        6 Batch loss: 0.071644 Batch F1: 0.5454545454545454
Epoch:  602        7 Batch loss: 0.047012 Batch F1: 0.7499999999999999
Epoch:  602        8 Batch loss: 0.066752 Batch F1: 0.5454545454545454
Epoch:  602        9 Batch loss: 0.076852 Batch F1: 0.3636363636363636
Epoch:  602       10 Batch loss: 0.081633 Batch F1: 0.5333333333333333
Epoch:  602       11 Batch loss: 0.080372 Batch F1: 0.8421052631578948
Epoch:  602       12 Batch loss: 0.027387 Batch F1: 0.8
Train Avg Loss  602: 0.069481

Train Avg F1  602: 0.7052160622240713

Val Avg Loss  602: 0.071198

Val Avg F1  602:  0.47342995169082125

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 603
--------------------------------------------------------------
Epoch:  603        1 Batch loss: 0.079794 Batch F1: 0.25
Epoch:  603        2 Batch loss: 0.068828 Batch F1: 0.5454545454545454
Epoch:  603        3 Batch loss: 0.088843 Batch F1: 0.7272727272727273
Epoch:  603        4 Batch loss: 0.077467 Batch F1: 0.8750000000000001
Epoch:  603        5 Batch loss: 0.067724 Batch F1: 0.9411764705882353
Epoch:  603        6 Batch loss: 0.078377 Batch F1: 0.888888888888889
Epoch:  603        7 Batch loss: 0.057330 Batch F1: 0.6666666666666666
Epoch:  603        8 Batch loss: 0.034770 Batch F1: 0.8
Epoch:  603        9 Batch loss: 0.094430 Batch F1: 0.42857142857142855
Epoch:  603       10 Batch loss: 0.057008 Batch F1: 0.6
Epoch:  603       11 Batch loss: 0.116126 Batch F1: 0.38095238095238093
Epoch:  603       12 Batch loss: 0.068886 Batch F1: 0.9090909090909091
Train Avg Loss  603: 0.074132

Train Avg F1  603: 0.6677561681238151

Val Avg Loss  603: 0.065666

Val Avg F1  603:  0.9289215686274509

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 604
--------------------------------------------------------------
Epoch:  604        1 Batch loss: 0.058863 Batch F1: 1.0
Epoch:  604        2 Batch loss: 0.073971 Batch F1: 0.9523809523809523
Epoch:  604        3 Batch loss: 0.065668 Batch F1: 0.9090909090909091
Epoch:  604        4 Batch loss: 0.074836 Batch F1: 0.6666666666666665
Epoch:  604        5 Batch loss: 0.107461 Batch F1: 0.6
Epoch:  604        6 Batch loss: 0.082250 Batch F1: 0.823529411764706
Epoch:  604        7 Batch loss: 0.082185 Batch F1: 0.8235294117647058
Epoch:  604        8 Batch loss: 0.069569 Batch F1: 0.4
Epoch:  604        9 Batch loss: 0.054682 Batch F1: 0.8
Epoch:  604       10 Batch loss: 0.107683 Batch F1: 0.375
Epoch:  604       11 Batch loss: 0.050340 Batch F1: 0.9090909090909091
Epoch:  604       12 Batch loss: 0.068695 Batch F1: 0.7692307692307692
Train Avg Loss  604: 0.074684

Train Avg F1  604: 0.7523765858324681

Val Avg Loss  604: 0.064567

Val Avg F1  604:  0.7974081839213418

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 605
--------------------------------------------------------------
Epoch:  605        1 Batch loss: 0.070424 Batch F1: 0.8750000000000001
Epoch:  605        2 Batch loss: 0.077156 Batch F1: 0.7000000000000001
Epoch:  605        3 Batch loss: 0.091854 Batch F1: 0.6363636363636364
Epoch:  605        4 Batch loss: 0.048783 Batch F1: 0.9333333333333333
Epoch:  605        5 Batch loss: 0.097116 Batch F1: 0.7142857142857143
Epoch:  605        6 Batch loss: 0.060074 Batch F1: 1.0
Epoch:  605        7 Batch loss: 0.052655 Batch F1: 0.6666666666666666
Epoch:  605        8 Batch loss: 0.047699 Batch F1: 0.5
Epoch:  605        9 Batch loss: 0.073388 Batch F1: 0.5
Epoch:  605       10 Batch loss: 0.074787 Batch F1: 0.7499999999999999
Epoch:  605       11 Batch loss: 0.066136 Batch F1: 0.6666666666666666
Epoch:  605       12 Batch loss: 0.084803 Batch F1: 0.6666666666666666
Train Avg Loss  605: 0.070406

Train Avg F1  605: 0.7174152236652237

Val Avg Loss  605: 0.066852

Val Avg F1  605:  0.7931848852901484

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 606
--------------------------------------------------------------
Epoch:  606        1 Batch loss: 0.054689 Batch F1: 0.7499999999999999
Epoch:  606        2 Batch loss: 0.087603 Batch F1: 0.5882352941176471
Epoch:  606        3 Batch loss: 0.035395 Batch F1: 0.6666666666666666
Epoch:  606        4 Batch loss: 0.097198 Batch F1: 0.19999999999999998
Epoch:  606        5 Batch loss: 0.064327 Batch F1: 0.4444444444444445
Epoch:  606        6 Batch loss: 0.072074 Batch F1: 0.4615384615384615
Epoch:  606        7 Batch loss: 0.055462 Batch F1: 0.7692307692307693
Epoch:  606        8 Batch loss: 0.087575 Batch F1: 0.9166666666666666
Epoch:  606        9 Batch loss: 0.080216 Batch F1: 0.9523809523809523
Epoch:  606       10 Batch loss: 0.089764 Batch F1: 0.8333333333333333
Epoch:  606       11 Batch loss: 0.052513 Batch F1: 1.0
Epoch:  606       12 Batch loss: 0.084545 Batch F1: 0.9411764705882353
Train Avg Loss  606: 0.071780

Train Avg F1  606: 0.7103060882472647

Val Avg Loss  606: 0.069903

Val Avg F1  606:  0.8664086687306503

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 607
--------------------------------------------------------------
Epoch:  607        1 Batch loss: 0.071109 Batch F1: 0.823529411764706
Epoch:  607        2 Batch loss: 0.090332 Batch F1: 0.7000000000000001
Epoch:  607        3 Batch loss: 0.052040 Batch F1: 0.6
Epoch:  607        4 Batch loss: 0.064551 Batch F1: 0.4
Epoch:  607        5 Batch loss: 0.099059 Batch F1: 0.5714285714285715
Epoch:  607        6 Batch loss: 0.078457 Batch F1: 0.9090909090909091
Epoch:  607        7 Batch loss: 0.079647 Batch F1: 0.8235294117647058
Epoch:  607        8 Batch loss: 0.073363 Batch F1: 0.5
Epoch:  607        9 Batch loss: 0.057330 Batch F1: 0.6666666666666666
Epoch:  607       10 Batch loss: 0.065295 Batch F1: 0.6153846153846153
Epoch:  607       11 Batch loss: 0.056808 Batch F1: 0.2857142857142857
Epoch:  607       12 Batch loss: 0.086309 Batch F1: 0.5714285714285715
Train Avg Loss  607: 0.072858

Train Avg F1  607: 0.6222310369369192

Val Avg Loss  607: 0.063924

Val Avg F1  607:  0.6071969696969697

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 608
--------------------------------------------------------------
Epoch:  608        1 Batch loss: 0.077196 Batch F1: 0.5333333333333333
Epoch:  608        2 Batch loss: 0.067678 Batch F1: 0.9333333333333333
Epoch:  608        3 Batch loss: 0.069438 Batch F1: 1.0
Epoch:  608        4 Batch loss: 0.043560 Batch F1: 1.0
Epoch:  608        5 Batch loss: 0.054764 Batch F1: 0.888888888888889
Epoch:  608        6 Batch loss: 0.062369 Batch F1: 0.8750000000000001
Epoch:  608        7 Batch loss: 0.084423 Batch F1: 0.631578947368421
Epoch:  608        8 Batch loss: 0.079066 Batch F1: 0.5714285714285715
Epoch:  608        9 Batch loss: 0.086325 Batch F1: 0.8421052631578948
Epoch:  608       10 Batch loss: 0.070597 Batch F1: 0.9411764705882353
Epoch:  608       11 Batch loss: 0.062770 Batch F1: 0.9333333333333333
Epoch:  608       12 Batch loss: 0.083378 Batch F1: 0.8235294117647058
Train Avg Loss  608: 0.070130

Train Avg F1  608: 0.8311422960997265

Val Avg Loss  608: 0.063732

Val Avg F1  608:  0.7412990196078431

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 609
--------------------------------------------------------------
Epoch:  609        1 Batch loss: 0.056219 Batch F1: 0.8
Epoch:  609        2 Batch loss: 0.075530 Batch F1: 0.19999999999999998
Epoch:  609        3 Batch loss: 0.057013 Batch F1: 0.8235294117647058
Epoch:  609        4 Batch loss: 0.085400 Batch F1: 0.8181818181818181
Epoch:  609        5 Batch loss: 0.087091 Batch F1: 0.8
Epoch:  609        6 Batch loss: 0.077481 Batch F1: 0.7499999999999999
Epoch:  609        7 Batch loss: 0.065241 Batch F1: 0.4
Epoch:  609        8 Batch loss: 0.068112 Batch F1: 0.7499999999999999
Epoch:  609        9 Batch loss: 0.073912 Batch F1: 0.7058823529411764
Epoch:  609       10 Batch loss: 0.081842 Batch F1: 0.7499999999999999
Epoch:  609       11 Batch loss: 0.084749 Batch F1: 0.6
Epoch:  609       12 Batch loss: 0.072200 Batch F1: 0.9333333333333333
Train Avg Loss  609: 0.073733

Train Avg F1  609: 0.6942439096850861

Val Avg Loss  609: 0.066200

Val Avg F1  609:  0.7631868131868133

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 610
--------------------------------------------------------------
Epoch:  610        1 Batch loss: 0.064060 Batch F1: 0.6153846153846153
Epoch:  610        2 Batch loss: 0.097344 Batch F1: 0.6
Epoch:  610        3 Batch loss: 0.072629 Batch F1: 0.7058823529411764
Epoch:  610        4 Batch loss: 0.072155 Batch F1: 0.9411764705882353
Epoch:  610        5 Batch loss: 0.064648 Batch F1: 1.0
Epoch:  610        6 Batch loss: 0.070531 Batch F1: 0.9411764705882353
Epoch:  610        7 Batch loss: 0.075343 Batch F1: 1.0
Epoch:  610        8 Batch loss: 0.060749 Batch F1: 0.6666666666666666
Epoch:  610        9 Batch loss: 0.066322 Batch F1: 0.5
Epoch:  610       10 Batch loss: 0.080381 Batch F1: 0.5333333333333333
Epoch:  610       11 Batch loss: 0.090261 Batch F1: 0.33333333333333337
Epoch:  610       12 Batch loss: 0.048471 Batch F1: 0.8571428571428571
Train Avg Loss  610: 0.071908

Train Avg F1  610: 0.7245080083315377

Val Avg Loss  610: 0.064142

Val Avg F1  610:  0.5738930659983292

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 611
--------------------------------------------------------------
Epoch:  611        1 Batch loss: 0.055202 Batch F1: 0.7692307692307693
Epoch:  611        2 Batch loss: 0.053897 Batch F1: 0.6666666666666666
Epoch:  611        3 Batch loss: 0.065076 Batch F1: 0.6
Epoch:  611        4 Batch loss: 0.073649 Batch F1: 0.25
Epoch:  611        5 Batch loss: 0.063248 Batch F1: 0.2857142857142857
Epoch:  611        6 Batch loss: 0.045448 Batch F1: 0.7499999999999999
Epoch:  611        7 Batch loss: 0.088422 Batch F1: 0.5333333333333333
Epoch:  611        8 Batch loss: 0.087122 Batch F1: 0.782608695652174
Epoch:  611        9 Batch loss: 0.081293 Batch F1: 0.7368421052631579
Epoch:  611       10 Batch loss: 0.070651 Batch F1: 0.9090909090909091
Epoch:  611       11 Batch loss: 0.083289 Batch F1: 0.8421052631578948
Epoch:  611       12 Batch loss: 0.075636 Batch F1: 0.9
Train Avg Loss  611: 0.070244

Train Avg F1  611: 0.6687993356757658

Val Avg Loss  611: 0.070694

Val Avg F1  611:  0.9141148325358852

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 612
--------------------------------------------------------------
Epoch:  612        1 Batch loss: 0.076666 Batch F1: 0.8571428571428571
Epoch:  612        2 Batch loss: 0.075508 Batch F1: 0.7142857142857143
Epoch:  612        3 Batch loss: 0.098556 Batch F1: 0.3076923076923077
Epoch:  612        4 Batch loss: 0.053971 Batch F1: 0.6666666666666666
Epoch:  612        5 Batch loss: 0.062345 Batch F1: 0.4
Epoch:  612        6 Batch loss: 0.063156 Batch F1: 0.8
Epoch:  612        7 Batch loss: 0.081351 Batch F1: 0.9
Epoch:  612        8 Batch loss: 0.082020 Batch F1: 0.962962962962963
Epoch:  612        9 Batch loss: 0.058923 Batch F1: 1.0
Epoch:  612       10 Batch loss: 0.078686 Batch F1: 0.9600000000000001
Epoch:  612       11 Batch loss: 0.055650 Batch F1: 0.7272727272727273
Epoch:  612       12 Batch loss: 0.064355 Batch F1: 0.2857142857142857
Train Avg Loss  612: 0.070932

Train Avg F1  612: 0.7151447934781269

Val Avg Loss  612: 0.070122

Val Avg F1  612:  0.5894230769230768

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 613
--------------------------------------------------------------
Epoch:  613        1 Batch loss: 0.072756 Batch F1: 0.4
Epoch:  613        2 Batch loss: 0.086257 Batch F1: 0.631578947368421
Epoch:  613        3 Batch loss: 0.088303 Batch F1: 0.3636363636363636
Epoch:  613        4 Batch loss: 0.053049 Batch F1: 0.8333333333333333
Epoch:  613        5 Batch loss: 0.078574 Batch F1: 0.8571428571428571
Epoch:  613        6 Batch loss: 0.069110 Batch F1: 0.8750000000000001
Epoch:  613        7 Batch loss: 0.061046 Batch F1: 0.9523809523809523
Epoch:  613        8 Batch loss: 0.059323 Batch F1: 0.923076923076923
Epoch:  613        9 Batch loss: 0.064258 Batch F1: 0.923076923076923
Epoch:  613       10 Batch loss: 0.074460 Batch F1: 0.9
Epoch:  613       11 Batch loss: 0.051730 Batch F1: 0.7692307692307693
Epoch:  613       12 Batch loss: 0.068742 Batch F1: 0.2857142857142857
Train Avg Loss  613: 0.068967

Train Avg F1  613: 0.7261809462467359

Val Avg Loss  613: 0.065706

Val Avg F1  613:  0.6124084249084248

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 614
--------------------------------------------------------------
Epoch:  614        1 Batch loss: 0.028791 Batch F1: 1.0
Epoch:  614        2 Batch loss: 0.064211 Batch F1: 0.0
Epoch:  614        3 Batch loss: 0.084781 Batch F1: 0.6666666666666666
Epoch:  614        4 Batch loss: 0.073942 Batch F1: 0.5333333333333333
Epoch:  614        5 Batch loss: 0.067400 Batch F1: 0.6666666666666666
Epoch:  614        6 Batch loss: 0.061778 Batch F1: 0.9411764705882353
Epoch:  614        7 Batch loss: 0.077391 Batch F1: 0.8181818181818181
Epoch:  614        8 Batch loss: 0.063059 Batch F1: 0.9090909090909091
Epoch:  614        9 Batch loss: 0.072723 Batch F1: 0.8695652173913043
Epoch:  614       10 Batch loss: 0.077601 Batch F1: 0.7499999999999999
Epoch:  614       11 Batch loss: 0.077446 Batch F1: 0.7777777777777778
Epoch:  614       12 Batch loss: 0.072020 Batch F1: 0.923076923076923
Train Avg Loss  614: 0.068429

Train Avg F1  614: 0.7379613152311362

Val Avg Loss  614: 0.063826

Val Avg F1  614:  0.9376750700280112

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 615
--------------------------------------------------------------
Epoch:  615        1 Batch loss: 0.071262 Batch F1: 0.888888888888889
Epoch:  615        2 Batch loss: 0.064476 Batch F1: 1.0
Epoch:  615        3 Batch loss: 0.069774 Batch F1: 0.9333333333333333
Epoch:  615        4 Batch loss: 0.082723 Batch F1: 0.9090909090909091
Epoch:  615        5 Batch loss: 0.051096 Batch F1: 1.0
Epoch:  615        6 Batch loss: 0.052638 Batch F1: 0.7499999999999999
Epoch:  615        7 Batch loss: 0.083586 Batch F1: 0.7272727272727273
Epoch:  615        8 Batch loss: 0.067119 Batch F1: 0.4
Epoch:  615        9 Batch loss: 0.072863 Batch F1: 0.4
Epoch:  615       10 Batch loss: 0.073239 Batch F1: 0.5882352941176471
Epoch:  615       11 Batch loss: 0.062858 Batch F1: 0.6666666666666666
Epoch:  615       12 Batch loss: 0.074700 Batch F1: 1.0
Train Avg Loss  615: 0.068861

Train Avg F1  615: 0.7719573182808478

Val Avg Loss  615: 0.063580

Val Avg F1  615:  0.9467780026990553

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 616
--------------------------------------------------------------
Epoch:  616        1 Batch loss: 0.048645 Batch F1: 1.0
Epoch:  616        2 Batch loss: 0.063998 Batch F1: 1.0
Epoch:  616        3 Batch loss: 0.043866 Batch F1: 0.923076923076923
Epoch:  616        4 Batch loss: 0.076791 Batch F1: 0.8235294117647058
Epoch:  616        5 Batch loss: 0.070682 Batch F1: 0.7272727272727273
Epoch:  616        6 Batch loss: 0.069964 Batch F1: 0.8571428571428571
Epoch:  616        7 Batch loss: 0.078995 Batch F1: 0.8333333333333333
Epoch:  616        8 Batch loss: 0.067628 Batch F1: 0.8333333333333334
Epoch:  616        9 Batch loss: 0.084110 Batch F1: 0.761904761904762
Epoch:  616       10 Batch loss: 0.078830 Batch F1: 0.8421052631578948
Epoch:  616       11 Batch loss: 0.036652 Batch F1: 1.0
Epoch:  616       12 Batch loss: 0.090544 Batch F1: 0.36363636363636365
Train Avg Loss  616: 0.067559

Train Avg F1  616: 0.830444581218575

Val Avg Loss  616: 0.062443

Val Avg F1  616:  0.6488903253609136

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 617
--------------------------------------------------------------
Epoch:  617        1 Batch loss: 0.066333 Batch F1: 0.5454545454545454
Epoch:  617        2 Batch loss: 0.067498 Batch F1: 0.6666666666666666
Epoch:  617        3 Batch loss: 0.087269 Batch F1: 0.19999999999999998
Epoch:  617        4 Batch loss: 0.055434 Batch F1: 0.4444444444444445
Epoch:  617        5 Batch loss: 0.040945 Batch F1: 0.6666666666666666
Epoch:  617        6 Batch loss: 0.081170 Batch F1: 0.5714285714285715
Epoch:  617        7 Batch loss: 0.054835 Batch F1: 0.7272727272727273
Epoch:  617        8 Batch loss: 0.075809 Batch F1: 0.8421052631578948
Epoch:  617        9 Batch loss: 0.065636 Batch F1: 0.9473684210526316
Epoch:  617       10 Batch loss: 0.086413 Batch F1: 0.8235294117647058
Epoch:  617       11 Batch loss: 0.071280 Batch F1: 1.0
Epoch:  617       12 Batch loss: 0.059606 Batch F1: 1.0
Train Avg Loss  617: 0.067686

Train Avg F1  617: 0.7029113931590713

Val Avg Loss  617: 0.064189

Val Avg F1  617:  0.857638888888889

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 618
--------------------------------------------------------------
Epoch:  618        1 Batch loss: 0.076492 Batch F1: 0.9565217391304348
Epoch:  618        2 Batch loss: 0.069986 Batch F1: 0.8
Epoch:  618        3 Batch loss: 0.068657 Batch F1: 0.8333333333333333
Epoch:  618        4 Batch loss: 0.057601 Batch F1: 0.7499999999999999
Epoch:  618        5 Batch loss: 0.066248 Batch F1: 0.8
Epoch:  618        6 Batch loss: 0.058657 Batch F1: 0.4444444444444445
Epoch:  618        7 Batch loss: 0.062617 Batch F1: 0.7142857142857143
Epoch:  618        8 Batch loss: 0.061299 Batch F1: 0.7499999999999999
Epoch:  618        9 Batch loss: 0.073918 Batch F1: 0.9565217391304348
Epoch:  618       10 Batch loss: 0.047699 Batch F1: 0.923076923076923
Epoch:  618       11 Batch loss: 0.087162 Batch F1: 0.7777777777777778
Epoch:  618       12 Batch loss: 0.087822 Batch F1: 0.7499999999999999
Train Avg Loss  618: 0.068180

Train Avg F1  618: 0.7879968059315886

Val Avg Loss  618: 0.065039

Val Avg F1  618:  0.9252136752136751

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 619
--------------------------------------------------------------
Epoch:  619        1 Batch loss: 0.052533 Batch F1: 0.8571428571428571
Epoch:  619        2 Batch loss: 0.058788 Batch F1: 0.888888888888889
Epoch:  619        3 Batch loss: 0.070675 Batch F1: 0.7000000000000001
Epoch:  619        4 Batch loss: 0.081207 Batch F1: 0.2857142857142857
Epoch:  619        5 Batch loss: 0.075937 Batch F1: 0.7058823529411764
Epoch:  619        6 Batch loss: 0.087353 Batch F1: 0.9032258064516129
Epoch:  619        7 Batch loss: 0.062332 Batch F1: 1.0
Epoch:  619        8 Batch loss: 0.064544 Batch F1: 0.9411764705882353
Epoch:  619        9 Batch loss: 0.061454 Batch F1: 0.8571428571428571
Epoch:  619       10 Batch loss: 0.072372 Batch F1: 0.5333333333333333
Epoch:  619       11 Batch loss: 0.063302 Batch F1: 0.2857142857142857
Epoch:  619       12 Batch loss: 0.073534 Batch F1: 0.5
Train Avg Loss  619: 0.068669

Train Avg F1  619: 0.7048517614931278

Val Avg Loss  619: 0.072424

Val Avg F1  619:  0.2912581699346405

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 620
--------------------------------------------------------------
Epoch:  620        1 Batch loss: 0.051106 Batch F1: 0.5
Epoch:  620        2 Batch loss: 0.096411 Batch F1: 0.0
Epoch:  620        3 Batch loss: 0.088098 Batch F1: 0.5714285714285715
Epoch:  620        4 Batch loss: 0.069496 Batch F1: 0.7777777777777778
Epoch:  620        5 Batch loss: 0.071542 Batch F1: 0.9166666666666666
Epoch:  620        6 Batch loss: 0.065870 Batch F1: 0.8000000000000002
Epoch:  620        7 Batch loss: 0.057895 Batch F1: 0.9333333333333333
Epoch:  620        8 Batch loss: 0.079997 Batch F1: 0.8421052631578948
Epoch:  620        9 Batch loss: 0.058774 Batch F1: 0.8571428571428571
Epoch:  620       10 Batch loss: 0.066997 Batch F1: 0.7058823529411764
Epoch:  620       11 Batch loss: 0.062007 Batch F1: 0.6666666666666666
Epoch:  620       12 Batch loss: 0.088950 Batch F1: 0.5
Train Avg Loss  620: 0.071429

Train Avg F1  620: 0.672583624092912

Val Avg Loss  620: 0.065670

Val Avg F1  620:  0.7994505494505494

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 621
--------------------------------------------------------------
Epoch:  621        1 Batch loss: 0.078722 Batch F1: 0.6666666666666666
Epoch:  621        2 Batch loss: 0.067131 Batch F1: 0.9333333333333333
Epoch:  621        3 Batch loss: 0.061974 Batch F1: 0.7692307692307693
Epoch:  621        4 Batch loss: 0.074304 Batch F1: 0.4
Epoch:  621        5 Batch loss: 0.073580 Batch F1: 0.5333333333333333
Epoch:  621        6 Batch loss: 0.068019 Batch F1: 0.625
Epoch:  621        7 Batch loss: 0.080947 Batch F1: 0.9411764705882353
Epoch:  621        8 Batch loss: 0.070718 Batch F1: 0.7499999999999999
Epoch:  621        9 Batch loss: 0.059699 Batch F1: 0.7499999999999999
Epoch:  621       10 Batch loss: 0.062320 Batch F1: 0.4444444444444445
Epoch:  621       11 Batch loss: 0.059264 Batch F1: 0.8333333333333333
Epoch:  621       12 Batch loss: 0.074228 Batch F1: 0.8750000000000001
Train Avg Loss  621: 0.069242

Train Avg F1  621: 0.7101265292441763

Val Avg Loss  621: 0.064523

Val Avg F1  621:  0.7258771929824561

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 622
--------------------------------------------------------------
Epoch:  622        1 Batch loss: 0.057457 Batch F1: 0.6666666666666666
Epoch:  622        2 Batch loss: 0.062024 Batch F1: 0.5
Epoch:  622        3 Batch loss: 0.090746 Batch F1: 0.7272727272727273
Epoch:  622        4 Batch loss: 0.068961 Batch F1: 0.4444444444444445
Epoch:  622        5 Batch loss: 0.057814 Batch F1: 0.5454545454545454
Epoch:  622        6 Batch loss: 0.099956 Batch F1: 0.47058823529411764
Epoch:  622        7 Batch loss: 0.048704 Batch F1: 1.0
Epoch:  622        8 Batch loss: 0.066194 Batch F1: 1.0
Epoch:  622        9 Batch loss: 0.060302 Batch F1: 0.8571428571428571
Epoch:  622       10 Batch loss: 0.063840 Batch F1: 0.9
Epoch:  622       11 Batch loss: 0.067810 Batch F1: 0.6666666666666666
Epoch:  622       12 Batch loss: 0.076406 Batch F1: 0.8
Train Avg Loss  622: 0.068351

Train Avg F1  622: 0.7148530119118356

Val Avg Loss  622: 0.064031

Val Avg F1  622:  0.7854166666666667

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 623
--------------------------------------------------------------
Epoch:  623        1 Batch loss: 0.058354 Batch F1: 0.6666666666666666
Epoch:  623        2 Batch loss: 0.054356 Batch F1: 0.9090909090909091
Epoch:  623        3 Batch loss: 0.069085 Batch F1: 0.8571428571428571
Epoch:  623        4 Batch loss: 0.073740 Batch F1: 0.625
Epoch:  623        5 Batch loss: 0.057743 Batch F1: 0.9333333333333333
Epoch:  623        6 Batch loss: 0.060073 Batch F1: 0.8333333333333333
Epoch:  623        7 Batch loss: 0.104055 Batch F1: 0.631578947368421
Epoch:  623        8 Batch loss: 0.070703 Batch F1: 0.8
Epoch:  623        9 Batch loss: 0.071393 Batch F1: 0.8235294117647058
Epoch:  623       10 Batch loss: 0.058431 Batch F1: 0.8888888888888888
Epoch:  623       11 Batch loss: 0.069327 Batch F1: 0.888888888888889
Epoch:  623       12 Batch loss: 0.053650 Batch F1: 1.0
Train Avg Loss  623: 0.066742

Train Avg F1  623: 0.8214544363731671

Val Avg Loss  623: 0.061843

Val Avg F1  623:  0.8727941176470588

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 624
--------------------------------------------------------------
Epoch:  624        1 Batch loss: 0.068661 Batch F1: 0.6153846153846153
Epoch:  624        2 Batch loss: 0.084661 Batch F1: 0.7368421052631579
Epoch:  624        3 Batch loss: 0.066566 Batch F1: 0.8571428571428571
Epoch:  624        4 Batch loss: 0.051035 Batch F1: 0.923076923076923
Epoch:  624        5 Batch loss: 0.087846 Batch F1: 0.18181818181818182
Epoch:  624        6 Batch loss: 0.066329 Batch F1: 0.8235294117647058
Epoch:  624        7 Batch loss: 0.071577 Batch F1: 0.896551724137931
Epoch:  624        8 Batch loss: 0.049595 Batch F1: 1.0
Epoch:  624        9 Batch loss: 0.063352 Batch F1: 0.9411764705882353
Epoch:  624       10 Batch loss: 0.065506 Batch F1: 0.8
Epoch:  624       11 Batch loss: 0.078638 Batch F1: 0.8750000000000001
Epoch:  624       12 Batch loss: 0.062016 Batch F1: 0.9411764705882353
Train Avg Loss  624: 0.067982

Train Avg F1  624: 0.7993082299804036

Val Avg Loss  624: 0.062690

Val Avg F1  624:  0.7505718954248366

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 625
--------------------------------------------------------------
Epoch:  625        1 Batch loss: 0.061569 Batch F1: 0.6666666666666666
Epoch:  625        2 Batch loss: 0.063328 Batch F1: 0.7499999999999999
Epoch:  625        3 Batch loss: 0.061989 Batch F1: 0.4444444444444445
Epoch:  625        4 Batch loss: 0.075374 Batch F1: 0.5
Epoch:  625        5 Batch loss: 0.080034 Batch F1: 0.5333333333333333
Epoch:  625        6 Batch loss: 0.047520 Batch F1: 0.5714285714285715
Epoch:  625        7 Batch loss: 0.063347 Batch F1: 0.8
Epoch:  625        8 Batch loss: 0.072524 Batch F1: 0.7499999999999999
Epoch:  625        9 Batch loss: 0.083056 Batch F1: 0.9600000000000001
Epoch:  625       10 Batch loss: 0.070220 Batch F1: 0.8333333333333333
Epoch:  625       11 Batch loss: 0.084219 Batch F1: 0.88
Epoch:  625       12 Batch loss: 0.053493 Batch F1: 0.7272727272727273
Train Avg Loss  625: 0.068056

Train Avg F1  625: 0.7013732563732563

Val Avg Loss  625: 0.063155

Val Avg F1  625:  0.5770676691729324

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 626
--------------------------------------------------------------
Epoch:  626        1 Batch loss: 0.075719 Batch F1: 0.5882352941176471
Epoch:  626        2 Batch loss: 0.048818 Batch F1: 0.9090909090909091
Epoch:  626        3 Batch loss: 0.068299 Batch F1: 0.7692307692307693
Epoch:  626        4 Batch loss: 0.067362 Batch F1: 0.8571428571428571
Epoch:  626        5 Batch loss: 0.104322 Batch F1: 0.888888888888889
Epoch:  626        6 Batch loss: 0.059553 Batch F1: 0.7692307692307693
Epoch:  626        7 Batch loss: 0.068604 Batch F1: 0.9411764705882353
Epoch:  626        8 Batch loss: 0.070777 Batch F1: 0.9411764705882353
Epoch:  626        9 Batch loss: 0.075722 Batch F1: 0.8
Epoch:  626       10 Batch loss: 0.067701 Batch F1: 1.0
Epoch:  626       11 Batch loss: 0.071758 Batch F1: 0.7692307692307693
Epoch:  626       12 Batch loss: 0.065428 Batch F1: 0.5714285714285715
Train Avg Loss  626: 0.070339

Train Avg F1  626: 0.8170693141281378

Val Avg Loss  626: 0.062661

Val Avg F1  626:  0.6433823529411764

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 627
--------------------------------------------------------------
Epoch:  627        1 Batch loss: 0.055568 Batch F1: 0.7142857142857143
Epoch:  627        2 Batch loss: 0.080588 Batch F1: 0.7058823529411764
Epoch:  627        3 Batch loss: 0.067478 Batch F1: 0.8235294117647058
Epoch:  627        4 Batch loss: 0.052689 Batch F1: 0.33333333333333337
Epoch:  627        5 Batch loss: 0.115193 Batch F1: 0.33333333333333337
Epoch:  627        6 Batch loss: 0.070484 Batch F1: 0.8750000000000001
Epoch:  627        7 Batch loss: 0.082427 Batch F1: 0.823529411764706
Epoch:  627        8 Batch loss: 0.068052 Batch F1: 0.8571428571428571
Epoch:  627        9 Batch loss: 0.058217 Batch F1: 0.7692307692307693
Epoch:  627       10 Batch loss: 0.059619 Batch F1: 0.7142857142857143
Epoch:  627       11 Batch loss: 0.077450 Batch F1: 0.2222222222222222
Epoch:  627       12 Batch loss: 0.062219 Batch F1: 0.5454545454545454
Train Avg Loss  627: 0.070832

Train Avg F1  627: 0.6431024721465898

Val Avg Loss  627: 0.062593

Val Avg F1  627:  0.628968253968254

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 628
--------------------------------------------------------------
Epoch:  628        1 Batch loss: 0.093730 Batch F1: 0.6
Epoch:  628        2 Batch loss: 0.065447 Batch F1: 0.888888888888889
Epoch:  628        3 Batch loss: 0.083372 Batch F1: 0.9565217391304348
Epoch:  628        4 Batch loss: 0.070640 Batch F1: 0.9411764705882353
Epoch:  628        5 Batch loss: 0.058687 Batch F1: 0.923076923076923
Epoch:  628        6 Batch loss: 0.071868 Batch F1: 0.4444444444444445
Epoch:  628        7 Batch loss: 0.060727 Batch F1: 0.7142857142857143
Epoch:  628        8 Batch loss: 0.054366 Batch F1: 0.6666666666666666
Epoch:  628        9 Batch loss: 0.071900 Batch F1: 0.4
Epoch:  628       10 Batch loss: 0.050980 Batch F1: 0.7499999999999999
Epoch:  628       11 Batch loss: 0.076209 Batch F1: 0.4615384615384615
Epoch:  628       12 Batch loss: 0.086648 Batch F1: 0.5333333333333333
Train Avg Loss  628: 0.070381

Train Avg F1  628: 0.6899943868294254

Val Avg Loss  628: 0.064446

Val Avg F1  628:  0.9554865424430642

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 629
--------------------------------------------------------------
Epoch:  629        1 Batch loss: 0.061536 Batch F1: 0.923076923076923
Epoch:  629        2 Batch loss: 0.061360 Batch F1: 0.9473684210526316
Epoch:  629        3 Batch loss: 0.063091 Batch F1: 0.8333333333333333
Epoch:  629        4 Batch loss: 0.061185 Batch F1: 0.25
Epoch:  629        5 Batch loss: 0.118895 Batch F1: 0.0
Epoch:  629        6 Batch loss: 0.061463 Batch F1: 0.7692307692307693
Epoch:  629        7 Batch loss: 0.065043 Batch F1: 0.8333333333333333
Epoch:  629        8 Batch loss: 0.067537 Batch F1: 0.8571428571428571
Epoch:  629        9 Batch loss: 0.062405 Batch F1: 0.9523809523809523
Epoch:  629       10 Batch loss: 0.063937 Batch F1: 0.7499999999999999
Epoch:  629       11 Batch loss: 0.057439 Batch F1: 0.9411764705882353
Epoch:  629       12 Batch loss: 0.094989 Batch F1: 0.6666666666666665
Train Avg Loss  629: 0.069907

Train Avg F1  629: 0.7269758105671418

Val Avg Loss  629: 0.063702

Val Avg F1  629:  0.9080924235722998

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 630
--------------------------------------------------------------
Epoch:  630        1 Batch loss: 0.085168 Batch F1: 0.7058823529411764
Epoch:  630        2 Batch loss: 0.073518 Batch F1: 0.8235294117647058
Epoch:  630        3 Batch loss: 0.057344 Batch F1: 0.888888888888889
Epoch:  630        4 Batch loss: 0.054090 Batch F1: 0.9090909090909091
Epoch:  630        5 Batch loss: 0.080701 Batch F1: 0.625
Epoch:  630        6 Batch loss: 0.065412 Batch F1: 0.9333333333333333
Epoch:  630        7 Batch loss: 0.091555 Batch F1: 0.5555555555555556
Epoch:  630        8 Batch loss: 0.067107 Batch F1: 0.6666666666666666
Epoch:  630        9 Batch loss: 0.063273 Batch F1: 0.6153846153846153
Epoch:  630       10 Batch loss: 0.066866 Batch F1: 0.625
Epoch:  630       11 Batch loss: 0.048387 Batch F1: 1.0
Epoch:  630       12 Batch loss: 0.068983 Batch F1: 0.7142857142857143
Train Avg Loss  630: 0.068534

Train Avg F1  630: 0.755218120659297

Val Avg Loss  630: 0.063376

Val Avg F1  630:  0.6387674825174825

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 631
--------------------------------------------------------------
Epoch:  631        1 Batch loss: 0.057169 Batch F1: 0.6666666666666666
Epoch:  631        2 Batch loss: 0.071387 Batch F1: 0.6666666666666666
Epoch:  631        3 Batch loss: 0.065909 Batch F1: 0.9473684210526316
Epoch:  631        4 Batch loss: 0.044448 Batch F1: 1.0
Epoch:  631        5 Batch loss: 0.071250 Batch F1: 0.7142857142857143
Epoch:  631        6 Batch loss: 0.100369 Batch F1: 0.6666666666666666
Epoch:  631        7 Batch loss: 0.064292 Batch F1: 1.0
Epoch:  631        8 Batch loss: 0.076306 Batch F1: 0.7692307692307693
Epoch:  631        9 Batch loss: 0.067089 Batch F1: 1.0
Epoch:  631       10 Batch loss: 0.077920 Batch F1: 0.888888888888889
Epoch:  631       11 Batch loss: 0.061147 Batch F1: 0.8333333333333333
Epoch:  631       12 Batch loss: 0.044977 Batch F1: 1.0
Train Avg Loss  631: 0.066855

Train Avg F1  631: 0.8460922605659449

Val Avg Loss  631: 0.062845

Val Avg F1  631:  0.8360028860028861

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 632
--------------------------------------------------------------
Epoch:  632        1 Batch loss: 0.065264 Batch F1: 0.7999999999999999
Epoch:  632        2 Batch loss: 0.043489 Batch F1: 1.0
Epoch:  632        3 Batch loss: 0.071667 Batch F1: 0.6153846153846153
Epoch:  632        4 Batch loss: 0.062972 Batch F1: 0.8
Epoch:  632        5 Batch loss: 0.099759 Batch F1: 0.47058823529411764
Epoch:  632        6 Batch loss: 0.060197 Batch F1: 0.8000000000000002
Epoch:  632        7 Batch loss: 0.077567 Batch F1: 0.5454545454545454
Epoch:  632        8 Batch loss: 0.080886 Batch F1: 0.7058823529411764
Epoch:  632        9 Batch loss: 0.073708 Batch F1: 0.625
Epoch:  632       10 Batch loss: 0.064720 Batch F1: 0.9523809523809523
Epoch:  632       11 Batch loss: 0.097727 Batch F1: 0.7407407407407407
Epoch:  632       12 Batch loss: 0.075467 Batch F1: 0.8750000000000001
Train Avg Loss  632: 0.072785

Train Avg F1  632: 0.7442026201830124

Val Avg Loss  632: 0.068564

Val Avg F1  632:  0.6393939393939394

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 633
--------------------------------------------------------------
Epoch:  633        1 Batch loss: 0.070318 Batch F1: 0.4
Epoch:  633        2 Batch loss: 0.083551 Batch F1: 0.6666666666666666
Epoch:  633        3 Batch loss: 0.045587 Batch F1: 0.6666666666666666
Epoch:  633        4 Batch loss: 0.101191 Batch F1: 0.35294117647058826
Epoch:  633        5 Batch loss: 0.073947 Batch F1: 0.6666666666666666
Epoch:  633        6 Batch loss: 0.077606 Batch F1: 0.888888888888889
Epoch:  633        7 Batch loss: 0.064438 Batch F1: 0.9090909090909091
Epoch:  633        8 Batch loss: 0.065211 Batch F1: 0.888888888888889
Epoch:  633        9 Batch loss: 0.090354 Batch F1: 0.5714285714285715
Epoch:  633       10 Batch loss: 0.040147 Batch F1: 0.6666666666666666
Epoch:  633       11 Batch loss: 0.058814 Batch F1: 0.6666666666666666
Epoch:  633       12 Batch loss: 0.096624 Batch F1: 0.5
Train Avg Loss  633: 0.072316

Train Avg F1  633: 0.6537143140084317

Val Avg Loss  633: 0.066170

Val Avg F1  633:  0.8576680672268907

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 634
--------------------------------------------------------------
Epoch:  634        1 Batch loss: 0.078919 Batch F1: 0.7142857142857143
Epoch:  634        2 Batch loss: 0.066229 Batch F1: 0.888888888888889
Epoch:  634        3 Batch loss: 0.076273 Batch F1: 0.9473684210526316
Epoch:  634        4 Batch loss: 0.073647 Batch F1: 0.9333333333333333
Epoch:  634        5 Batch loss: 0.071107 Batch F1: 0.9565217391304348
Epoch:  634        6 Batch loss: 0.078936 Batch F1: 0.7142857142857143
Epoch:  634        7 Batch loss: 0.070059 Batch F1: 0.6666666666666666
Epoch:  634        8 Batch loss: 0.058133 Batch F1: 0.25
Epoch:  634        9 Batch loss: 0.065007 Batch F1: 0.8421052631578948
Epoch:  634       10 Batch loss: 0.060934 Batch F1: 0.8571428571428571
Epoch:  634       11 Batch loss: 0.047234 Batch F1: 1.0
Epoch:  634       12 Batch loss: 0.078587 Batch F1: 0.8235294117647058
Train Avg Loss  634: 0.068755

Train Avg F1  634: 0.799510667475737

Val Avg Loss  634: 0.063191

Val Avg F1  634:  0.7486111111111111

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 635
--------------------------------------------------------------
Epoch:  635        1 Batch loss: 0.072573 Batch F1: 0.7777777777777778
Epoch:  635        2 Batch loss: 0.065704 Batch F1: 0.9090909090909091
Epoch:  635        3 Batch loss: 0.065989 Batch F1: 0.8333333333333333
Epoch:  635        4 Batch loss: 0.048190 Batch F1: 0.888888888888889
Epoch:  635        5 Batch loss: 0.085720 Batch F1: 0.9090909090909091
Epoch:  635        6 Batch loss: 0.096746 Batch F1: 0.5882352941176471
Epoch:  635        7 Batch loss: 0.063962 Batch F1: 0.8421052631578948
Epoch:  635        8 Batch loss: 0.061095 Batch F1: 0.888888888888889
Epoch:  635        9 Batch loss: 0.055636 Batch F1: 0.9411764705882353
Epoch:  635       10 Batch loss: 0.068290 Batch F1: 0.8421052631578948
Epoch:  635       11 Batch loss: 0.058639 Batch F1: 0.8
Epoch:  635       12 Batch loss: 0.070633 Batch F1: 0.75
Train Avg Loss  635: 0.067765

Train Avg F1  635: 0.830891083174365

Val Avg Loss  635: 0.063194

Val Avg F1  635:  0.6181818181818182

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 636
--------------------------------------------------------------
Epoch:  636        1 Batch loss: 0.080748 Batch F1: 0.4444444444444445
Epoch:  636        2 Batch loss: 0.051580 Batch F1: 0.75
Epoch:  636        3 Batch loss: 0.063816 Batch F1: 0.7777777777777778
Epoch:  636        4 Batch loss: 0.059157 Batch F1: 0.9
Epoch:  636        5 Batch loss: 0.046974 Batch F1: 1.0
Epoch:  636        6 Batch loss: 0.072726 Batch F1: 0.8333333333333333
Epoch:  636        7 Batch loss: 0.074923 Batch F1: 0.8235294117647058
Epoch:  636        8 Batch loss: 0.061524 Batch F1: 0.6666666666666666
Epoch:  636        9 Batch loss: 0.078392 Batch F1: 0.7272727272727273
Epoch:  636       10 Batch loss: 0.076932 Batch F1: 0.7777777777777778
Epoch:  636       11 Batch loss: 0.065560 Batch F1: 0.6666666666666666
Epoch:  636       12 Batch loss: 0.070423 Batch F1: 0.7692307692307693
Train Avg Loss  636: 0.066896

Train Avg F1  636: 0.7613916312445724

Val Avg Loss  636: 0.063448

Val Avg F1  636:  0.8956152779682192

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 637
--------------------------------------------------------------
Epoch:  637        1 Batch loss: 0.072798 Batch F1: 1.0
Epoch:  637        2 Batch loss: 0.062541 Batch F1: 0.9333333333333333
Epoch:  637        3 Batch loss: 0.082089 Batch F1: 0.8235294117647058
Epoch:  637        4 Batch loss: 0.072344 Batch F1: 0.7692307692307693
Epoch:  637        5 Batch loss: 0.080558 Batch F1: 0.8571428571428571
Epoch:  637        6 Batch loss: 0.048963 Batch F1: 0.9411764705882353
Epoch:  637        7 Batch loss: 0.052976 Batch F1: 0.9411764705882353
Epoch:  637        8 Batch loss: 0.080974 Batch F1: 0.8421052631578948
Epoch:  637        9 Batch loss: 0.051262 Batch F1: 1.0
Epoch:  637       10 Batch loss: 0.069631 Batch F1: 0.6666666666666666
Epoch:  637       11 Batch loss: 0.065769 Batch F1: 0.7692307692307693
Epoch:  637       12 Batch loss: 0.065914 Batch F1: 0.4
Train Avg Loss  637: 0.067152

Train Avg F1  637: 0.8286326676419556

Val Avg Loss  637: 0.063254

Val Avg F1  637:  0.6458333333333333

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 638
--------------------------------------------------------------
Epoch:  638        1 Batch loss: 0.083615 Batch F1: 0.631578947368421
Epoch:  638        2 Batch loss: 0.049600 Batch F1: 0.7272727272727273
Epoch:  638        3 Batch loss: 0.062028 Batch F1: 0.9473684210526316
Epoch:  638        4 Batch loss: 0.050005 Batch F1: 0.888888888888889
Epoch:  638        5 Batch loss: 0.084200 Batch F1: 0.33333333333333337
Epoch:  638        6 Batch loss: 0.073957 Batch F1: 0.5882352941176471
Epoch:  638        7 Batch loss: 0.040015 Batch F1: 0.888888888888889
Epoch:  638        8 Batch loss: 0.074447 Batch F1: 0.4
Epoch:  638        9 Batch loss: 0.059732 Batch F1: 0.4444444444444445
Epoch:  638       10 Batch loss: 0.094479 Batch F1: 0.375
Epoch:  638       11 Batch loss: 0.067024 Batch F1: 0.33333333333333337
Epoch:  638       12 Batch loss: 0.061791 Batch F1: 1.0
Train Avg Loss  638: 0.066741

Train Avg F1  638: 0.6298620232250264

Val Avg Loss  638: 0.062122

Val Avg F1  638:  0.9166666666666666

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 639
--------------------------------------------------------------
Epoch:  639        1 Batch loss: 0.075405 Batch F1: 0.8
Epoch:  639        2 Batch loss: 0.074173 Batch F1: 0.8235294117647058
Epoch:  639        3 Batch loss: 0.049711 Batch F1: 0.9090909090909091
Epoch:  639        4 Batch loss: 0.062849 Batch F1: 0.8571428571428571
Epoch:  639        5 Batch loss: 0.059274 Batch F1: 1.0
Epoch:  639        6 Batch loss: 0.054592 Batch F1: 0.5454545454545454
Epoch:  639        7 Batch loss: 0.077619 Batch F1: 0.19999999999999998
Epoch:  639        8 Batch loss: 0.066006 Batch F1: 0.7142857142857143
Epoch:  639        9 Batch loss: 0.080534 Batch F1: 0.6666666666666666
Epoch:  639       10 Batch loss: 0.056465 Batch F1: 0.9411764705882353
Epoch:  639       11 Batch loss: 0.074771 Batch F1: 0.8421052631578948
Epoch:  639       12 Batch loss: 0.060475 Batch F1: 1.0
Train Avg Loss  639: 0.065989

Train Avg F1  639: 0.7749543198459609

Val Avg Loss  639: 0.063181

Val Avg F1  639:  0.9252941176470588

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 640
--------------------------------------------------------------
Epoch:  640        1 Batch loss: 0.061134 Batch F1: 0.9473684210526316
Epoch:  640        2 Batch loss: 0.063509 Batch F1: 0.7999999999999999
Epoch:  640        3 Batch loss: 0.079311 Batch F1: 0.8
Epoch:  640        4 Batch loss: 0.067713 Batch F1: 0.33333333333333337
Epoch:  640        5 Batch loss: 0.046532 Batch F1: 0.7272727272727273
Epoch:  640        6 Batch loss: 0.063039 Batch F1: 0.5454545454545454
Epoch:  640        7 Batch loss: 0.065512 Batch F1: 0.9
Epoch:  640        8 Batch loss: 0.050697 Batch F1: 0.9333333333333333
Epoch:  640        9 Batch loss: 0.067904 Batch F1: 0.9473684210526316
Epoch:  640       10 Batch loss: 0.057963 Batch F1: 1.0
Epoch:  640       11 Batch loss: 0.074861 Batch F1: 0.7272727272727273
Epoch:  640       12 Batch loss: 0.105984 Batch F1: 0.7499999999999999
Train Avg Loss  640: 0.067013

Train Avg F1  640: 0.7842836257309941

Val Avg Loss  640: 0.063994

Val Avg F1  640:  0.8839717046238785

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 641
--------------------------------------------------------------
Epoch:  641        1 Batch loss: 0.067551 Batch F1: 0.9411764705882353
Epoch:  641        2 Batch loss: 0.072566 Batch F1: 0.823529411764706
Epoch:  641        3 Batch loss: 0.068908 Batch F1: 0.4
Epoch:  641        4 Batch loss: 0.066077 Batch F1: 0.5454545454545454
Epoch:  641        5 Batch loss: 0.082987 Batch F1: 0.5882352941176471
Epoch:  641        6 Batch loss: 0.056545 Batch F1: 0.8750000000000001
Epoch:  641        7 Batch loss: 0.073059 Batch F1: 0.6
Epoch:  641        8 Batch loss: 0.064247 Batch F1: 0.923076923076923
Epoch:  641        9 Batch loss: 0.058080 Batch F1: 0.8333333333333333
Epoch:  641       10 Batch loss: 0.074234 Batch F1: 0.625
Epoch:  641       11 Batch loss: 0.061751 Batch F1: 0.7777777777777778
Epoch:  641       12 Batch loss: 0.071372 Batch F1: 0.5714285714285715
Train Avg Loss  641: 0.068115

Train Avg F1  641: 0.7086676939618116

Val Avg Loss  641: 0.062347

Val Avg F1  641:  0.9292763157894737

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 642
--------------------------------------------------------------
Epoch:  642        1 Batch loss: 0.063299 Batch F1: 0.9333333333333333
Epoch:  642        2 Batch loss: 0.049712 Batch F1: 0.888888888888889
Epoch:  642        3 Batch loss: 0.079182 Batch F1: 0.9411764705882353
Epoch:  642        4 Batch loss: 0.072365 Batch F1: 0.7692307692307693
Epoch:  642        5 Batch loss: 0.059271 Batch F1: 0.7272727272727273
Epoch:  642        6 Batch loss: 0.103104 Batch F1: 0.7407407407407407
Epoch:  642        7 Batch loss: 0.057014 Batch F1: 0.8571428571428571
Epoch:  642        8 Batch loss: 0.083582 Batch F1: 0.7368421052631579
Epoch:  642        9 Batch loss: 0.072400 Batch F1: 0.9565217391304348
Epoch:  642       10 Batch loss: 0.077832 Batch F1: 0.888888888888889
Epoch:  642       11 Batch loss: 0.054231 Batch F1: 1.0
Epoch:  642       12 Batch loss: 0.050913 Batch F1: 0.888888888888889
Train Avg Loss  642: 0.068575

Train Avg F1  642: 0.8607439507807434

Val Avg Loss  642: 0.064820

Val Avg F1  642:  0.7145676691729324

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 643
--------------------------------------------------------------
Epoch:  643        1 Batch loss: 0.083924 Batch F1: 0.5333333333333333
Epoch:  643        2 Batch loss: 0.072904 Batch F1: 0.5714285714285715
Epoch:  643        3 Batch loss: 0.081661 Batch F1: 0.6666666666666666
Epoch:  643        4 Batch loss: 0.063591 Batch F1: 0.923076923076923
Epoch:  643        5 Batch loss: 0.059694 Batch F1: 0.6666666666666666
Epoch:  643        6 Batch loss: 0.065640 Batch F1: 0.8750000000000001
Epoch:  643        7 Batch loss: 0.085794 Batch F1: 0.5882352941176471
Epoch:  643        8 Batch loss: 0.030956 Batch F1: 0.8571428571428571
Epoch:  643        9 Batch loss: 0.075840 Batch F1: 0.5714285714285715
Epoch:  643       10 Batch loss: 0.076933 Batch F1: 0.4615384615384615
Epoch:  643       11 Batch loss: 0.083464 Batch F1: 0.7368421052631579
Epoch:  643       12 Batch loss: 0.087471 Batch F1: 0.923076923076923
Train Avg Loss  643: 0.072323

Train Avg F1  643: 0.6978696978116482

Val Avg Loss  643: 0.068898

Val Avg F1  643:  0.9295454545454546

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 644
--------------------------------------------------------------
Epoch:  644        1 Batch loss: 0.063394 Batch F1: 1.0
Epoch:  644        2 Batch loss: 0.082244 Batch F1: 0.8750000000000001
Epoch:  644        3 Batch loss: 0.047729 Batch F1: 1.0
Epoch:  644        4 Batch loss: 0.060740 Batch F1: 0.8
Epoch:  644        5 Batch loss: 0.078932 Batch F1: 0.3636363636363636
Epoch:  644        6 Batch loss: 0.067830 Batch F1: 0.7692307692307693
Epoch:  644        7 Batch loss: 0.072343 Batch F1: 0.5
Epoch:  644        8 Batch loss: 0.064437 Batch F1: 0.5454545454545454
Epoch:  644        9 Batch loss: 0.077691 Batch F1: 0.9565217391304348
Epoch:  644       10 Batch loss: 0.080233 Batch F1: 0.8421052631578948
Epoch:  644       11 Batch loss: 0.058580 Batch F1: 0.5454545454545454
Epoch:  644       12 Batch loss: 0.079251 Batch F1: 0.33333333333333337
Train Avg Loss  644: 0.069450

Train Avg F1  644: 0.7108947132831571

Val Avg Loss  644: 0.070283

Val Avg F1  644:  0.9166666666666666

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 645
--------------------------------------------------------------
Epoch:  645        1 Batch loss: 0.078840 Batch F1: 0.962962962962963
Epoch:  645        2 Batch loss: 0.119901 Batch F1: 0.8181818181818182
Epoch:  645        3 Batch loss: 0.041870 Batch F1: 1.0
Epoch:  645        4 Batch loss: 0.086015 Batch F1: 0.0
Epoch:  645        5 Batch loss: 0.087246 Batch F1: 0.0
Epoch:  645        6 Batch loss: 0.088938 Batch F1: 0.3076923076923077
Epoch:  645        7 Batch loss: 0.065414 Batch F1: 0.8
Epoch:  645        8 Batch loss: 0.081747 Batch F1: 0.6666666666666666
Epoch:  645        9 Batch loss: 0.057417 Batch F1: 0.7272727272727273
Epoch:  645       10 Batch loss: 0.056014 Batch F1: 0.7272727272727273
Epoch:  645       11 Batch loss: 0.084744 Batch F1: 0.6666666666666666
Epoch:  645       12 Batch loss: 0.062835 Batch F1: 0.7272727272727273
Train Avg Loss  645: 0.075915

Train Avg F1  645: 0.6169990503323838

Val Avg Loss  645: 0.066562

Val Avg F1  645:  0.6333333333333333

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 646
--------------------------------------------------------------
Epoch:  646        1 Batch loss: 0.047878 Batch F1: 0.0
Epoch:  646        2 Batch loss: 0.058081 Batch F1: 0.6
Epoch:  646        3 Batch loss: 0.058579 Batch F1: 0.4
Epoch:  646        4 Batch loss: 0.053501 Batch F1: 0.8000000000000002
Epoch:  646        5 Batch loss: 0.074776 Batch F1: 0.6153846153846153
Epoch:  646        6 Batch loss: 0.071629 Batch F1: 0.8695652173913043
Epoch:  646        7 Batch loss: 0.068676 Batch F1: 0.9333333333333333
Epoch:  646        8 Batch loss: 0.039297 Batch F1: 0.888888888888889
Epoch:  646        9 Batch loss: 0.086938 Batch F1: 0.7272727272727273
Epoch:  646       10 Batch loss: 0.079259 Batch F1: 0.5882352941176471
Epoch:  646       11 Batch loss: 0.125995 Batch F1: 0.7499999999999999
Epoch:  646       12 Batch loss: 0.063724 Batch F1: 1.0
Train Avg Loss  646: 0.069028

Train Avg F1  646: 0.6810566730323764

Val Avg Loss  646: 0.067235

Val Avg F1  646:  0.9172771672771672

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 647
--------------------------------------------------------------
Epoch:  647        1 Batch loss: 0.088389 Batch F1: 0.8421052631578948
Epoch:  647        2 Batch loss: 0.057231 Batch F1: 1.0
Epoch:  647        3 Batch loss: 0.057562 Batch F1: 0.9090909090909091
Epoch:  647        4 Batch loss: 0.072827 Batch F1: 0.5
Epoch:  647        5 Batch loss: 0.071913 Batch F1: 0.33333333333333337
Epoch:  647        6 Batch loss: 0.082974 Batch F1: 0.6666666666666666
Epoch:  647        7 Batch loss: 0.065532 Batch F1: 0.9411764705882353
Epoch:  647        8 Batch loss: 0.054046 Batch F1: 0.923076923076923
Epoch:  647        9 Batch loss: 0.063375 Batch F1: 0.9523809523809523
Epoch:  647       10 Batch loss: 0.058677 Batch F1: 1.0
Epoch:  647       11 Batch loss: 0.057643 Batch F1: 0.9411764705882353
Epoch:  647       12 Batch loss: 0.085455 Batch F1: 0.2857142857142857
Train Avg Loss  647: 0.067969

Train Avg F1  647: 0.7745601062164531

Val Avg Loss  647: 0.066434

Val Avg F1  647:  0.6137254901960785

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 648
--------------------------------------------------------------
Epoch:  648        1 Batch loss: 0.043145 Batch F1: 0.7499999999999999
Epoch:  648        2 Batch loss: 0.062709 Batch F1: 0.6153846153846153
Epoch:  648        3 Batch loss: 0.083914 Batch F1: 0.4615384615384615
Epoch:  648        4 Batch loss: 0.088347 Batch F1: 0.5
Epoch:  648        5 Batch loss: 0.068793 Batch F1: 0.6666666666666666
Epoch:  648        6 Batch loss: 0.092925 Batch F1: 0.375
Epoch:  648        7 Batch loss: 0.073227 Batch F1: 0.9
Epoch:  648        8 Batch loss: 0.061423 Batch F1: 0.923076923076923
Epoch:  648        9 Batch loss: 0.073485 Batch F1: 0.8695652173913043
Epoch:  648       10 Batch loss: 0.064473 Batch F1: 0.8
Epoch:  648       11 Batch loss: 0.067728 Batch F1: 0.9411764705882353
Epoch:  648       12 Batch loss: 0.041975 Batch F1: 1.0
Train Avg Loss  648: 0.068512

Train Avg F1  648: 0.7335340295538506

Val Avg Loss  648: 0.063485

Val Avg F1  648:  0.838616975130133

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 649
--------------------------------------------------------------
Epoch:  649        1 Batch loss: 0.046282 Batch F1: 0.8
Epoch:  649        2 Batch loss: 0.060664 Batch F1: 1.0
Epoch:  649        3 Batch loss: 0.087824 Batch F1: 0.8333333333333333
Epoch:  649        4 Batch loss: 0.076970 Batch F1: 0.6
Epoch:  649        5 Batch loss: 0.066882 Batch F1: 0.9411764705882353
Epoch:  649        6 Batch loss: 0.096851 Batch F1: 0.5882352941176471
Epoch:  649        7 Batch loss: 0.089908 Batch F1: 0.7272727272727273
Epoch:  649        8 Batch loss: 0.072874 Batch F1: 0.9090909090909091
Epoch:  649        9 Batch loss: 0.043273 Batch F1: 1.0
Epoch:  649       10 Batch loss: 0.056718 Batch F1: 0.7272727272727273
Epoch:  649       11 Batch loss: 0.096734 Batch F1: 0.14285714285714288
Epoch:  649       12 Batch loss: 0.069154 Batch F1: 0.6
Train Avg Loss  649: 0.072011

Train Avg F1  649: 0.7391032170443935

Val Avg Loss  649: 0.069044

Val Avg F1  649:  0.9029605263157895

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 650
--------------------------------------------------------------
Epoch:  650        1 Batch loss: 0.063817 Batch F1: 0.8333333333333333
Epoch:  650        2 Batch loss: 0.072492 Batch F1: 1.0
Epoch:  650        3 Batch loss: 0.063251 Batch F1: 1.0
Epoch:  650        4 Batch loss: 0.074592 Batch F1: 0.2222222222222222
Epoch:  650        5 Batch loss: 0.058830 Batch F1: 0.7272727272727273
Epoch:  650        6 Batch loss: 0.064409 Batch F1: 0.7272727272727273
Epoch:  650        7 Batch loss: 0.061109 Batch F1: 0.7142857142857143
Epoch:  650        8 Batch loss: 0.062864 Batch F1: 0.4444444444444445
Epoch:  650        9 Batch loss: 0.073555 Batch F1: 0.3636363636363636
Epoch:  650       10 Batch loss: 0.113970 Batch F1: 0.5454545454545454
Epoch:  650       11 Batch loss: 0.067662 Batch F1: 0.8571428571428571
Epoch:  650       12 Batch loss: 0.085977 Batch F1: 0.9090909090909091
Train Avg Loss  650: 0.071877

Train Avg F1  650: 0.6953463203463204

Val Avg Loss  650: 0.074039

Val Avg F1  650:  0.9244322928533455

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 651
--------------------------------------------------------------
Epoch:  651        1 Batch loss: 0.092747 Batch F1: 0.88
Epoch:  651        2 Batch loss: 0.058875 Batch F1: 1.0
Epoch:  651        3 Batch loss: 0.064771 Batch F1: 0.7499999999999999
Epoch:  651        4 Batch loss: 0.053205 Batch F1: 0.6
Epoch:  651        5 Batch loss: 0.083609 Batch F1: 0.42857142857142855
Epoch:  651        6 Batch loss: 0.059662 Batch F1: 0.5
Epoch:  651        7 Batch loss: 0.071525 Batch F1: 0.6666666666666666
Epoch:  651        8 Batch loss: 0.047377 Batch F1: 0.3333333333333333
Epoch:  651        9 Batch loss: 0.069299 Batch F1: 0.0
Epoch:  651       10 Batch loss: 0.072043 Batch F1: 0.9411764705882353
Epoch:  651       11 Batch loss: 0.109044 Batch F1: 0.6956521739130436
Epoch:  651       12 Batch loss: 0.093159 Batch F1: 0.3076923076923077
Train Avg Loss  651: 0.072943

Train Avg F1  651: 0.5919243650637512

Val Avg Loss  651: 0.074627

Val Avg F1  651:  0.9217414529914529

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 652
--------------------------------------------------------------
Epoch:  652        1 Batch loss: 0.059985 Batch F1: 0.9333333333333333
Epoch:  652        2 Batch loss: 0.124853 Batch F1: 0.6666666666666666
Epoch:  652        3 Batch loss: 0.067820 Batch F1: 0.9333333333333333
Epoch:  652        4 Batch loss: 0.076344 Batch F1: 0.6666666666666666
Epoch:  652        5 Batch loss: 0.062859 Batch F1: 0.7058823529411764
Epoch:  652        6 Batch loss: 0.098556 Batch F1: 0.5555555555555556
Epoch:  652        7 Batch loss: 0.069123 Batch F1: 0.8695652173913044
Epoch:  652        8 Batch loss: 0.066490 Batch F1: 0.8
Epoch:  652        9 Batch loss: 0.067015 Batch F1: 0.7272727272727273
Epoch:  652       10 Batch loss: 0.064546 Batch F1: 0.7692307692307693
Epoch:  652       11 Batch loss: 0.071345 Batch F1: 0.5
Epoch:  652       12 Batch loss: 0.064372 Batch F1: 0.2857142857142857
Train Avg Loss  652: 0.074442

Train Avg F1  652: 0.7011017423421516

Val Avg Loss  652: 0.071433

Val Avg F1  652:  0.39663461538461536

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 653
--------------------------------------------------------------
Epoch:  653        1 Batch loss: 0.058120 Batch F1: 0.7272727272727273
Epoch:  653        2 Batch loss: 0.092825 Batch F1: 0.5714285714285715
Epoch:  653        3 Batch loss: 0.064252 Batch F1: 0.6153846153846153
Epoch:  653        4 Batch loss: 0.067275 Batch F1: 0.8571428571428571
Epoch:  653        5 Batch loss: 0.052722 Batch F1: 0.9090909090909091
Epoch:  653        6 Batch loss: 0.078581 Batch F1: 0.8571428571428571
Epoch:  653        7 Batch loss: 0.082530 Batch F1: 0.8421052631578948
Epoch:  653        8 Batch loss: 0.057821 Batch F1: 0.9090909090909091
Epoch:  653        9 Batch loss: 0.076355 Batch F1: 0.8
Epoch:  653       10 Batch loss: 0.067635 Batch F1: 0.5
Epoch:  653       11 Batch loss: 0.062970 Batch F1: 0.6153846153846153
Epoch:  653       12 Batch loss: 0.085480 Batch F1: 0.5882352941176471
Train Avg Loss  653: 0.070547

Train Avg F1  653: 0.7326898849344669

Val Avg Loss  653: 0.063128

Val Avg F1  653:  0.6469017094017094

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 654
--------------------------------------------------------------
Epoch:  654        1 Batch loss: 0.066225 Batch F1: 0.8
Epoch:  654        2 Batch loss: 0.066874 Batch F1: 0.8571428571428571
Epoch:  654        3 Batch loss: 0.064520 Batch F1: 1.0
Epoch:  654        4 Batch loss: 0.057546 Batch F1: 0.8333333333333334
Epoch:  654        5 Batch loss: 0.059925 Batch F1: 0.7272727272727273
Epoch:  654        6 Batch loss: 0.057279 Batch F1: 0.923076923076923
Epoch:  654        7 Batch loss: 0.027973 Batch F1: 1.0
Epoch:  654        8 Batch loss: 0.133746 Batch F1: 0.3157894736842105
Epoch:  654        9 Batch loss: 0.073898 Batch F1: 0.4
Epoch:  654       10 Batch loss: 0.123626 Batch F1: 0.3636363636363636
Epoch:  654       11 Batch loss: 0.074637 Batch F1: 0.9473684210526316
Epoch:  654       12 Batch loss: 0.061481 Batch F1: 1.0
Train Avg Loss  654: 0.072311

Train Avg F1  654: 0.7639683415999206

Val Avg Loss  654: 0.063467

Val Avg F1  654:  0.9173076923076923

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 655
--------------------------------------------------------------
Epoch:  655        1 Batch loss: 0.064008 Batch F1: 1.0
Epoch:  655        2 Batch loss: 0.052141 Batch F1: 0.9090909090909091
Epoch:  655        3 Batch loss: 0.048830 Batch F1: 0.5714285714285715
Epoch:  655        4 Batch loss: 0.156365 Batch F1: 0.1111111111111111
Epoch:  655        5 Batch loss: 0.072044 Batch F1: 0.7058823529411764
Epoch:  655        6 Batch loss: 0.101403 Batch F1: 0.7368421052631579
Epoch:  655        7 Batch loss: 0.081141 Batch F1: 0.8421052631578948
Epoch:  655        8 Batch loss: 0.055489 Batch F1: 1.0
Epoch:  655        9 Batch loss: 0.066122 Batch F1: 0.7142857142857143
Epoch:  655       10 Batch loss: 0.044745 Batch F1: 0.888888888888889
Epoch:  655       11 Batch loss: 0.097388 Batch F1: 0.5333333333333333
Epoch:  655       12 Batch loss: 0.076256 Batch F1: 0.4
Train Avg Loss  655: 0.076328

Train Avg F1  655: 0.7010806874583966

Val Avg Loss  655: 0.066507

Val Avg F1  655:  0.6008928571428571

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 656
--------------------------------------------------------------
Epoch:  656        1 Batch loss: 0.096757 Batch F1: 0.2857142857142857
Epoch:  656        2 Batch loss: 0.032629 Batch F1: 0.8
Epoch:  656        3 Batch loss: 0.058086 Batch F1: 0.8235294117647058
Epoch:  656        4 Batch loss: 0.069544 Batch F1: 0.6153846153846153
Epoch:  656        5 Batch loss: 0.065617 Batch F1: 0.6666666666666666
Epoch:  656        6 Batch loss: 0.041313 Batch F1: 0.7499999999999999
Epoch:  656        7 Batch loss: 0.079620 Batch F1: 0.4
Epoch:  656        8 Batch loss: 0.061368 Batch F1: 0.7142857142857143
Epoch:  656        9 Batch loss: 0.073103 Batch F1: 0.5714285714285715
Epoch:  656       10 Batch loss: 0.085308 Batch F1: 0.6
Epoch:  656       11 Batch loss: 0.087020 Batch F1: 0.88
Epoch:  656       12 Batch loss: 0.087478 Batch F1: 0.875
Train Avg Loss  656: 0.069820

Train Avg F1  656: 0.6651674387703799

Val Avg Loss  656: 0.071448

Val Avg F1  656:  0.9198412698412698

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 657
--------------------------------------------------------------
Epoch:  657        1 Batch loss: 0.077112 Batch F1: 0.9473684210526316
Epoch:  657        2 Batch loss: 0.071765 Batch F1: 0.9473684210526316
Epoch:  657        3 Batch loss: 0.055099 Batch F1: 0.6666666666666666
Epoch:  657        4 Batch loss: 0.067637 Batch F1: 0.6666666666666666
Epoch:  657        5 Batch loss: 0.078097 Batch F1: 0.33333333333333337
Epoch:  657        6 Batch loss: 0.077989 Batch F1: 0.0
Epoch:  657        7 Batch loss: 0.076307 Batch F1: 0.5714285714285715
Epoch:  657        8 Batch loss: 0.053744 Batch F1: 0.8571428571428571
Epoch:  657        9 Batch loss: 0.058269 Batch F1: 0.9333333333333333
Epoch:  657       10 Batch loss: 0.090881 Batch F1: 0.47058823529411764
Epoch:  657       11 Batch loss: 0.062422 Batch F1: 0.7142857142857143
Epoch:  657       12 Batch loss: 0.063984 Batch F1: 0.9333333333333333
Train Avg Loss  657: 0.069442

Train Avg F1  657: 0.6701262961324881

Val Avg Loss  657: 0.067743

Val Avg F1  657:  0.9083333333333334

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 658
--------------------------------------------------------------
Epoch:  658        1 Batch loss: 0.076133 Batch F1: 0.8750000000000001
Epoch:  658        2 Batch loss: 0.063378 Batch F1: 0.9090909090909091
Epoch:  658        3 Batch loss: 0.068038 Batch F1: 0.7142857142857143
Epoch:  658        4 Batch loss: 0.084591 Batch F1: 0.5555555555555556
Epoch:  658        5 Batch loss: 0.068076 Batch F1: 0.7692307692307693
Epoch:  658        6 Batch loss: 0.063413 Batch F1: 0.9523809523809523
Epoch:  658        7 Batch loss: 0.065103 Batch F1: 0.9333333333333333
Epoch:  658        8 Batch loss: 0.075011 Batch F1: 0.9166666666666666
Epoch:  658        9 Batch loss: 0.056686 Batch F1: 0.9333333333333333
Epoch:  658       10 Batch loss: 0.055075 Batch F1: 0.6
Epoch:  658       11 Batch loss: 0.053762 Batch F1: 0.4444444444444445
Epoch:  658       12 Batch loss: 0.093386 Batch F1: 0.4615384615384615
Train Avg Loss  658: 0.068554

Train Avg F1  658: 0.7554050116550117

Val Avg Loss  658: 0.066686

Val Avg F1  658:  0.5710088522588523

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 659
--------------------------------------------------------------
Epoch:  659        1 Batch loss: 0.066673 Batch F1: 0.7499999999999999
Epoch:  659        2 Batch loss: 0.071422 Batch F1: 0.5714285714285715
Epoch:  659        3 Batch loss: 0.056595 Batch F1: 0.7499999999999999
Epoch:  659        4 Batch loss: 0.065865 Batch F1: 0.8750000000000001
Epoch:  659        5 Batch loss: 0.087916 Batch F1: 0.8181818181818181
Epoch:  659        6 Batch loss: 0.076217 Batch F1: 0.8235294117647058
Epoch:  659        7 Batch loss: 0.077548 Batch F1: 0.823529411764706
Epoch:  659        8 Batch loss: 0.054596 Batch F1: 1.0
Epoch:  659        9 Batch loss: 0.052061 Batch F1: 1.0
Epoch:  659       10 Batch loss: 0.079292 Batch F1: 0.9473684210526316
Epoch:  659       11 Batch loss: 0.060277 Batch F1: 0.923076923076923
Epoch:  659       12 Batch loss: 0.057324 Batch F1: 1.0
Train Avg Loss  659: 0.067149

Train Avg F1  659: 0.8568428797724463

Val Avg Loss  659: 0.063356

Val Avg F1  659:  0.7824592074592074

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 660
--------------------------------------------------------------
Epoch:  660        1 Batch loss: 0.060931 Batch F1: 0.8
Epoch:  660        2 Batch loss: 0.082105 Batch F1: 0.3636363636363636
Epoch:  660        3 Batch loss: 0.068807 Batch F1: 0.6666666666666666
Epoch:  660        4 Batch loss: 0.078439 Batch F1: 0.3636363636363636
Epoch:  660        5 Batch loss: 0.063477 Batch F1: 0.6666666666666666
Epoch:  660        6 Batch loss: 0.049478 Batch F1: 0.923076923076923
Epoch:  660        7 Batch loss: 0.062528 Batch F1: 0.9333333333333333
Epoch:  660        8 Batch loss: 0.081321 Batch F1: 0.761904761904762
Epoch:  660        9 Batch loss: 0.044305 Batch F1: 0.9090909090909091
Epoch:  660       10 Batch loss: 0.058184 Batch F1: 1.0
Epoch:  660       11 Batch loss: 0.068111 Batch F1: 0.7142857142857143
Epoch:  660       12 Batch loss: 0.086752 Batch F1: 0.33333333333333337
Train Avg Loss  660: 0.067036

Train Avg F1  660: 0.702969252969253

Val Avg Loss  660: 0.063457

Val Avg F1  660:  0.7492647058823529

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 661
--------------------------------------------------------------
Epoch:  661        1 Batch loss: 0.053504 Batch F1: 0.8333333333333333
Epoch:  661        2 Batch loss: 0.061607 Batch F1: 0.8750000000000001
Epoch:  661        3 Batch loss: 0.092111 Batch F1: 0.631578947368421
Epoch:  661        4 Batch loss: 0.078189 Batch F1: 0.8
Epoch:  661        5 Batch loss: 0.081664 Batch F1: 0.761904761904762
Epoch:  661        6 Batch loss: 0.050460 Batch F1: 0.8000000000000002
Epoch:  661        7 Batch loss: 0.053288 Batch F1: 0.9333333333333333
Epoch:  661        8 Batch loss: 0.062465 Batch F1: 0.6666666666666666
Epoch:  661        9 Batch loss: 0.077865 Batch F1: 0.9166666666666666
Epoch:  661       10 Batch loss: 0.067353 Batch F1: 0.8421052631578948
Epoch:  661       11 Batch loss: 0.060639 Batch F1: 0.8571428571428571
Epoch:  661       12 Batch loss: 0.065184 Batch F1: 1.0
Train Avg Loss  661: 0.067027

Train Avg F1  661: 0.8264776524644947

Val Avg Loss  661: 0.062415

Val Avg F1  661:  0.773015873015873

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 662
--------------------------------------------------------------
Epoch:  662        1 Batch loss: 0.074527 Batch F1: 0.7777777777777778
Epoch:  662        2 Batch loss: 0.062010 Batch F1: 0.9
Epoch:  662        3 Batch loss: 0.059043 Batch F1: 0.8235294117647058
Epoch:  662        4 Batch loss: 0.078508 Batch F1: 0.4
Epoch:  662        5 Batch loss: 0.080090 Batch F1: 0.7777777777777778
Epoch:  662        6 Batch loss: 0.073619 Batch F1: 0.7368421052631579
Epoch:  662        7 Batch loss: 0.063754 Batch F1: 0.8571428571428571
Epoch:  662        8 Batch loss: 0.056561 Batch F1: 1.0
Epoch:  662        9 Batch loss: 0.062389 Batch F1: 0.923076923076923
Epoch:  662       10 Batch loss: 0.065680 Batch F1: 0.923076923076923
Epoch:  662       11 Batch loss: 0.070185 Batch F1: 0.7777777777777778
Epoch:  662       12 Batch loss: 0.047668 Batch F1: 0.888888888888889
Train Avg Loss  662: 0.066169

Train Avg F1  662: 0.8154908702122325

Val Avg Loss  662: 0.063708

Val Avg F1  662:  0.6207070707070708

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 663
--------------------------------------------------------------
Epoch:  663        1 Batch loss: 0.071838 Batch F1: 0.5333333333333333
Epoch:  663        2 Batch loss: 0.060097 Batch F1: 0.7272727272727273
Epoch:  663        3 Batch loss: 0.062301 Batch F1: 0.6
Epoch:  663        4 Batch loss: 0.062672 Batch F1: 0.7499999999999999
Epoch:  663        5 Batch loss: 0.067056 Batch F1: 0.625
Epoch:  663        6 Batch loss: 0.063249 Batch F1: 0.7692307692307693
Epoch:  663        7 Batch loss: 0.076779 Batch F1: 0.19999999999999998
Epoch:  663        8 Batch loss: 0.062103 Batch F1: 0.8
Epoch:  663        9 Batch loss: 0.090367 Batch F1: 0.761904761904762
Epoch:  663       10 Batch loss: 0.060467 Batch F1: 0.8333333333333333
Epoch:  663       11 Batch loss: 0.061588 Batch F1: 0.9411764705882353
Epoch:  663       12 Batch loss: 0.055923 Batch F1: 0.8333333333333333
Train Avg Loss  663: 0.066203

Train Avg F1  663: 0.6978820607497078

Val Avg Loss  663: 0.062292

Val Avg F1  663:  0.8395833333333333

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 664
--------------------------------------------------------------
Epoch:  664        1 Batch loss: 0.060015 Batch F1: 0.923076923076923
Epoch:  664        2 Batch loss: 0.083317 Batch F1: 0.8235294117647058
Epoch:  664        3 Batch loss: 0.080644 Batch F1: 0.9565217391304348
Epoch:  664        4 Batch loss: 0.051277 Batch F1: 0.8
Epoch:  664        5 Batch loss: 0.096579 Batch F1: 0.7272727272727273
Epoch:  664        6 Batch loss: 0.065185 Batch F1: 0.7058823529411764
Epoch:  664        7 Batch loss: 0.045200 Batch F1: 1.0
Epoch:  664        8 Batch loss: 0.074858 Batch F1: 0.9
Epoch:  664        9 Batch loss: 0.050788 Batch F1: 0.8
Epoch:  664       10 Batch loss: 0.062796 Batch F1: 0.9
Epoch:  664       11 Batch loss: 0.068317 Batch F1: 0.6
Epoch:  664       12 Batch loss: 0.053512 Batch F1: 0.9333333333333333
Train Avg Loss  664: 0.066041

Train Avg F1  664: 0.8391347072932751

Val Avg Loss  664: 0.062095

Val Avg F1  664:  0.7957251082251082

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 665
--------------------------------------------------------------
Epoch:  665        1 Batch loss: 0.083012 Batch F1: 0.5882352941176471
Epoch:  665        2 Batch loss: 0.062919 Batch F1: 0.8750000000000001
Epoch:  665        3 Batch loss: 0.077238 Batch F1: 0.8
Epoch:  665        4 Batch loss: 0.068402 Batch F1: 0.9090909090909091
Epoch:  665        5 Batch loss: 0.094319 Batch F1: 0.7777777777777777
Epoch:  665        6 Batch loss: 0.063388 Batch F1: 1.0
Epoch:  665        7 Batch loss: 0.046144 Batch F1: 1.0
Epoch:  665        8 Batch loss: 0.054535 Batch F1: 0.9333333333333333
Epoch:  665        9 Batch loss: 0.059557 Batch F1: 0.2857142857142857
Epoch:  665       10 Batch loss: 0.070494 Batch F1: 0.5
Epoch:  665       11 Batch loss: 0.081225 Batch F1: 0.5
Epoch:  665       12 Batch loss: 0.054361 Batch F1: 0.8333333333333333
Train Avg Loss  665: 0.067966

Train Avg F1  665: 0.7502070777806072

Val Avg Loss  665: 0.063976

Val Avg F1  665:  0.6068764568764569

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 666
--------------------------------------------------------------
Epoch:  666        1 Batch loss: 0.101049 Batch F1: 0.6923076923076924
Epoch:  666        2 Batch loss: 0.082741 Batch F1: 0.7142857142857143
Epoch:  666        3 Batch loss: 0.064968 Batch F1: 0.9411764705882353
Epoch:  666        4 Batch loss: 0.074129 Batch F1: 0.8750000000000001
Epoch:  666        5 Batch loss: 0.061510 Batch F1: 1.0
Epoch:  666        6 Batch loss: 0.046877 Batch F1: 1.0
Epoch:  666        7 Batch loss: 0.060494 Batch F1: 0.6666666666666666
Epoch:  666        8 Batch loss: 0.110027 Batch F1: 0.0
Epoch:  666        9 Batch loss: 0.083931 Batch F1: 0.33333333333333337
Epoch:  666       10 Batch loss: 0.052656 Batch F1: 1.0
Epoch:  666       11 Batch loss: 0.050752 Batch F1: 1.0
Epoch:  666       12 Batch loss: 0.067894 Batch F1: 0.9333333333333333
Train Avg Loss  666: 0.071419

Train Avg F1  666: 0.763008600876248

Val Avg Loss  666: 0.063565

Val Avg F1  666:  0.6083139083139084

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 667
--------------------------------------------------------------
Epoch:  667        1 Batch loss: 0.074376 Batch F1: 0.2222222222222222
Epoch:  667        2 Batch loss: 0.041870 Batch F1: 0.8571428571428571
Epoch:  667        3 Batch loss: 0.088988 Batch F1: 0.15384615384615385
Epoch:  667        4 Batch loss: 0.034210 Batch F1: 0.8571428571428571
Epoch:  667        5 Batch loss: 0.066596 Batch F1: 0.6153846153846153
Epoch:  667        6 Batch loss: 0.070965 Batch F1: 0.6
Epoch:  667        7 Batch loss: 0.085154 Batch F1: 0.6666666666666666
Epoch:  667        8 Batch loss: 0.076427 Batch F1: 0.8235294117647058
Epoch:  667        9 Batch loss: 0.059060 Batch F1: 0.9411764705882353
Epoch:  667       10 Batch loss: 0.090609 Batch F1: 0.7368421052631579
Epoch:  667       11 Batch loss: 0.063419 Batch F1: 0.8571428571428571
Epoch:  667       12 Batch loss: 0.076618 Batch F1: 0.9
Train Avg Loss  667: 0.069024

Train Avg F1  667: 0.6859246847636941

Val Avg Loss  667: 0.069503

Val Avg F1  667:  0.9291666666666667

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 668
--------------------------------------------------------------
Epoch:  668        1 Batch loss: 0.079380 Batch F1: 0.5714285714285715
Epoch:  668        2 Batch loss: 0.065155 Batch F1: 0.9523809523809523
Epoch:  668        3 Batch loss: 0.093678 Batch F1: 0.5882352941176471
Epoch:  668        4 Batch loss: 0.075629 Batch F1: 0.9523809523809523
Epoch:  668        5 Batch loss: 0.052563 Batch F1: 0.8571428571428571
Epoch:  668        6 Batch loss: 0.068073 Batch F1: 0.6153846153846153
Epoch:  668        7 Batch loss: 0.057342 Batch F1: 0.25
Epoch:  668        8 Batch loss: 0.085993 Batch F1: 0.5333333333333333
Epoch:  668        9 Batch loss: 0.075381 Batch F1: 0.625
Epoch:  668       10 Batch loss: 0.059289 Batch F1: 0.923076923076923
Epoch:  668       11 Batch loss: 0.066504 Batch F1: 0.8421052631578948
Epoch:  668       12 Batch loss: 0.061972 Batch F1: 1.0
Train Avg Loss  668: 0.070080

Train Avg F1  668: 0.7258723968669788

Val Avg Loss  668: 0.063716

Val Avg F1  668:  0.8424242424242425

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 669
--------------------------------------------------------------
Epoch:  669        1 Batch loss: 0.059246 Batch F1: 0.9411764705882353
Epoch:  669        2 Batch loss: 0.090113 Batch F1: 0.7777777777777778
Epoch:  669        3 Batch loss: 0.044485 Batch F1: 1.0
Epoch:  669        4 Batch loss: 0.043492 Batch F1: 1.0
Epoch:  669        5 Batch loss: 0.065241 Batch F1: 0.7499999999999999
Epoch:  669        6 Batch loss: 0.072810 Batch F1: 0.6666666666666666
Epoch:  669        7 Batch loss: 0.084325 Batch F1: 0.6666666666666666
Epoch:  669        8 Batch loss: 0.054704 Batch F1: 0.8235294117647058
Epoch:  669        9 Batch loss: 0.079640 Batch F1: 0.9
Epoch:  669       10 Batch loss: 0.067149 Batch F1: 0.9333333333333333
Epoch:  669       11 Batch loss: 0.079478 Batch F1: 0.8571428571428571
Epoch:  669       12 Batch loss: 0.071025 Batch F1: 0.6
Train Avg Loss  669: 0.067642

Train Avg F1  669: 0.8263577653283537

Val Avg Loss  669: 0.062670

Val Avg F1  669:  0.7600490196078431

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 670
--------------------------------------------------------------
Epoch:  670        1 Batch loss: 0.077659 Batch F1: 0.8181818181818181
Epoch:  670        2 Batch loss: 0.058083 Batch F1: 0.8235294117647058
Epoch:  670        3 Batch loss: 0.072158 Batch F1: 0.4
Epoch:  670        4 Batch loss: 0.092078 Batch F1: 0.5
Epoch:  670        5 Batch loss: 0.063718 Batch F1: 0.8750000000000001
Epoch:  670        6 Batch loss: 0.071391 Batch F1: 0.9333333333333333
Epoch:  670        7 Batch loss: 0.048248 Batch F1: 1.0
Epoch:  670        8 Batch loss: 0.051311 Batch F1: 1.0
Epoch:  670        9 Batch loss: 0.061229 Batch F1: 0.8571428571428571
Epoch:  670       10 Batch loss: 0.069398 Batch F1: 0.5333333333333333
Epoch:  670       11 Batch loss: 0.079948 Batch F1: 0.625
Epoch:  670       12 Batch loss: 0.058649 Batch F1: 0.6666666666666666
Train Avg Loss  670: 0.066989

Train Avg F1  670: 0.7526822850352262

Val Avg Loss  670: 0.062537

Val Avg F1  670:  0.7888888888888889

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 671
--------------------------------------------------------------
Epoch:  671        1 Batch loss: 0.047360 Batch F1: 0.5714285714285715
Epoch:  671        2 Batch loss: 0.069141 Batch F1: 0.42857142857142855
Epoch:  671        3 Batch loss: 0.108115 Batch F1: 0.4210526315789474
Epoch:  671        4 Batch loss: 0.063690 Batch F1: 0.8750000000000001
Epoch:  671        5 Batch loss: 0.070632 Batch F1: 0.8571428571428571
Epoch:  671        6 Batch loss: 0.089097 Batch F1: 0.8333333333333333
Epoch:  671        7 Batch loss: 0.045469 Batch F1: 1.0
Epoch:  671        8 Batch loss: 0.063292 Batch F1: 0.8750000000000001
Epoch:  671        9 Batch loss: 0.064787 Batch F1: 0.8
Epoch:  671       10 Batch loss: 0.052853 Batch F1: 0.8
Epoch:  671       11 Batch loss: 0.057083 Batch F1: 0.9333333333333333
Epoch:  671       12 Batch loss: 0.063134 Batch F1: 0.6666666666666666
Train Avg Loss  671: 0.066221

Train Avg F1  671: 0.755127401837928

Val Avg Loss  671: 0.062164

Val Avg F1  671:  0.7833333333333334

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 672
--------------------------------------------------------------
Epoch:  672        1 Batch loss: 0.067723 Batch F1: 0.7142857142857143
Epoch:  672        2 Batch loss: 0.053275 Batch F1: 0.8
Epoch:  672        3 Batch loss: 0.063782 Batch F1: 0.8
Epoch:  672        4 Batch loss: 0.076746 Batch F1: 0.7499999999999999
Epoch:  672        5 Batch loss: 0.072149 Batch F1: 0.9166666666666666
Epoch:  672        6 Batch loss: 0.057590 Batch F1: 0.7499999999999999
Epoch:  672        7 Batch loss: 0.066900 Batch F1: 0.7692307692307692
Epoch:  672        8 Batch loss: 0.079325 Batch F1: 0.5714285714285715
Epoch:  672        9 Batch loss: 0.070073 Batch F1: 0.6666666666666666
Epoch:  672       10 Batch loss: 0.070122 Batch F1: 0.9
Epoch:  672       11 Batch loss: 0.069391 Batch F1: 0.7777777777777778
Epoch:  672       12 Batch loss: 0.049215 Batch F1: 1.0
Train Avg Loss  672: 0.066358

Train Avg F1  672: 0.7846713471713471

Val Avg Loss  672: 0.062853

Val Avg F1  672:  0.7142857142857142

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 673
--------------------------------------------------------------
Epoch:  673        1 Batch loss: 0.053313 Batch F1: 0.6
Epoch:  673        2 Batch loss: 0.045655 Batch F1: 0.7272727272727273
Epoch:  673        3 Batch loss: 0.090157 Batch F1: 0.47058823529411764
Epoch:  673        4 Batch loss: 0.083573 Batch F1: 0.5714285714285715
Epoch:  673        5 Batch loss: 0.092682 Batch F1: 0.846153846153846
Epoch:  673        6 Batch loss: 0.056048 Batch F1: 0.8333333333333333
Epoch:  673        7 Batch loss: 0.061306 Batch F1: 0.6666666666666666
Epoch:  673        8 Batch loss: 0.058868 Batch F1: 0.923076923076923
Epoch:  673        9 Batch loss: 0.080206 Batch F1: 0.782608695652174
Epoch:  673       10 Batch loss: 0.069943 Batch F1: 0.75
Epoch:  673       11 Batch loss: 0.062559 Batch F1: 0.9333333333333333
Epoch:  673       12 Batch loss: 0.051763 Batch F1: 0.888888888888889
Train Avg Loss  673: 0.067173

Train Avg F1  673: 0.7494459350917152

Val Avg Loss  673: 0.064951

Val Avg F1  673:  0.8248120300751881

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 674
--------------------------------------------------------------
Epoch:  674        1 Batch loss: 0.076303 Batch F1: 0.7058823529411764
Epoch:  674        2 Batch loss: 0.054498 Batch F1: 0.8333333333333333
Epoch:  674        3 Batch loss: 0.057788 Batch F1: 1.0
Epoch:  674        4 Batch loss: 0.071974 Batch F1: 0.823529411764706
Epoch:  674        5 Batch loss: 0.058684 Batch F1: 0.9411764705882353
Epoch:  674        6 Batch loss: 0.077747 Batch F1: 0.3636363636363636
Epoch:  674        7 Batch loss: 0.088835 Batch F1: 0.4615384615384615
Epoch:  674        8 Batch loss: 0.057737 Batch F1: 0.25
Epoch:  674        9 Batch loss: 0.036534 Batch F1: 0.8
Epoch:  674       10 Batch loss: 0.078219 Batch F1: 0.6666666666666666
Epoch:  674       11 Batch loss: 0.085811 Batch F1: 0.7777777777777778
Epoch:  674       12 Batch loss: 0.073284 Batch F1: 0.8235294117647058
Train Avg Loss  674: 0.068118

Train Avg F1  674: 0.7039225208342855

Val Avg Loss  674: 0.064705

Val Avg F1  674:  0.9542334096109841

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 675
--------------------------------------------------------------
Epoch:  675        1 Batch loss: 0.076368 Batch F1: 0.9565217391304348
Epoch:  675        2 Batch loss: 0.069988 Batch F1: 0.9411764705882353
Epoch:  675        3 Batch loss: 0.062793 Batch F1: 0.9411764705882353
Epoch:  675        4 Batch loss: 0.085959 Batch F1: 0.9285714285714286
Epoch:  675        5 Batch loss: 0.063585 Batch F1: 1.0
Epoch:  675        6 Batch loss: 0.049538 Batch F1: 1.0
Epoch:  675        7 Batch loss: 0.067321 Batch F1: 0.8571428571428571
Epoch:  675        8 Batch loss: 0.062888 Batch F1: 0.923076923076923
Epoch:  675        9 Batch loss: 0.070264 Batch F1: 0.4
Epoch:  675       10 Batch loss: 0.034906 Batch F1: 1.0
Epoch:  675       11 Batch loss: 0.104064 Batch F1: 0.42857142857142855
Epoch:  675       12 Batch loss: 0.080150 Batch F1: 0.7499999999999999
Train Avg Loss  675: 0.068985

Train Avg F1  675: 0.8438531098057953

Val Avg Loss  675: 0.062616

Val Avg F1  675:  0.9080419580419581

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 676
--------------------------------------------------------------
Epoch:  676        1 Batch loss: 0.067668 Batch F1: 0.9333333333333333
Epoch:  676        2 Batch loss: 0.048730 Batch F1: 0.7499999999999999
Epoch:  676        3 Batch loss: 0.090323 Batch F1: 0.625
Epoch:  676        4 Batch loss: 0.101962 Batch F1: 0.5
Epoch:  676        5 Batch loss: 0.068925 Batch F1: 0.9523809523809523
Epoch:  676        6 Batch loss: 0.069908 Batch F1: 1.0
Epoch:  676        7 Batch loss: 0.063609 Batch F1: 1.0
Epoch:  676        8 Batch loss: 0.064122 Batch F1: 0.923076923076923
Epoch:  676        9 Batch loss: 0.075826 Batch F1: 0.888888888888889
Epoch:  676       10 Batch loss: 0.060627 Batch F1: 0.923076923076923
Epoch:  676       11 Batch loss: 0.055915 Batch F1: 0.6666666666666666
Epoch:  676       12 Batch loss: 0.102517 Batch F1: 0.0
Train Avg Loss  676: 0.072511

Train Avg F1  676: 0.7635353072853072

Val Avg Loss  676: 0.064880

Val Avg F1  676:  0.5824175824175823

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 677
--------------------------------------------------------------
Epoch:  677        1 Batch loss: 0.059132 Batch F1: 0.4
Epoch:  677        2 Batch loss: 0.062775 Batch F1: 0.9
Epoch:  677        3 Batch loss: 0.100569 Batch F1: 0.88
Epoch:  677        4 Batch loss: 0.080841 Batch F1: 0.9600000000000001
Epoch:  677        5 Batch loss: 0.085324 Batch F1: 0.923076923076923
Epoch:  677        6 Batch loss: 0.055774 Batch F1: 0.5
Epoch:  677        7 Batch loss: 0.082165 Batch F1: 0.42857142857142855
Epoch:  677        8 Batch loss: 0.056850 Batch F1: 0.5714285714285715
Epoch:  677        9 Batch loss: 0.062793 Batch F1: 0.6
Epoch:  677       10 Batch loss: 0.055653 Batch F1: 0.2857142857142857
Epoch:  677       11 Batch loss: 0.074146 Batch F1: 0.5
Epoch:  677       12 Batch loss: 0.087872 Batch F1: 0.7058823529411764
Train Avg Loss  677: 0.071991

Train Avg F1  677: 0.6378894634776987

Val Avg Loss  677: 0.067479

Val Avg F1  677:  0.9261278195488722

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 678
--------------------------------------------------------------
Epoch:  678        1 Batch loss: 0.076554 Batch F1: 0.888888888888889
Epoch:  678        2 Batch loss: 0.058873 Batch F1: 0.923076923076923
Epoch:  678        3 Batch loss: 0.071636 Batch F1: 0.0
Epoch:  678        4 Batch loss: 0.081556 Batch F1: 0.42857142857142855
Epoch:  678        5 Batch loss: 0.065097 Batch F1: 0.6666666666666666
Epoch:  678        6 Batch loss: 0.094557 Batch F1: 0.8695652173913044
Epoch:  678        7 Batch loss: 0.069401 Batch F1: 0.9333333333333333
Epoch:  678        8 Batch loss: 0.089368 Batch F1: 0.6956521739130436
Epoch:  678        9 Batch loss: 0.087247 Batch F1: 0.3076923076923077
Epoch:  678       10 Batch loss: 0.063669 Batch F1: 0.6
Epoch:  678       11 Batch loss: 0.060116 Batch F1: 0.6666666666666666
Epoch:  678       12 Batch loss: 0.057527 Batch F1: 0.2857142857142857
Train Avg Loss  678: 0.072967

Train Avg F1  678: 0.6054856576595707

Val Avg Loss  678: 0.066935

Val Avg F1  678:  0.6387674825174825

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 679
--------------------------------------------------------------
Epoch:  679        1 Batch loss: 0.108330 Batch F1: 0.6086956521739131
Epoch:  679        2 Batch loss: 0.053369 Batch F1: 1.0
Epoch:  679        3 Batch loss: 0.065467 Batch F1: 0.9473684210526316
Epoch:  679        4 Batch loss: 0.069169 Batch F1: 0.9473684210526316
Epoch:  679        5 Batch loss: 0.089818 Batch F1: 0.8571428571428571
Epoch:  679        6 Batch loss: 0.065133 Batch F1: 1.0
Epoch:  679        7 Batch loss: 0.048655 Batch F1: 0.9090909090909091
Epoch:  679        8 Batch loss: 0.061723 Batch F1: 0.5
Epoch:  679        9 Batch loss: 0.084104 Batch F1: 0.6666666666666666
Epoch:  679       10 Batch loss: 0.058300 Batch F1: 0.9090909090909091
Epoch:  679       11 Batch loss: 0.078176 Batch F1: 0.9411764705882353
Epoch:  679       12 Batch loss: 0.052689 Batch F1: 0.5714285714285715
Train Avg Loss  679: 0.069578

Train Avg F1  679: 0.8215024065239437

Val Avg Loss  679: 0.063228

Val Avg F1  679:  0.6298076923076923

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 680
--------------------------------------------------------------
Epoch:  680        1 Batch loss: 0.068094 Batch F1: 0.4
Epoch:  680        2 Batch loss: 0.057632 Batch F1: 0.7692307692307693
Epoch:  680        3 Batch loss: 0.068078 Batch F1: 0.6153846153846153
Epoch:  680        4 Batch loss: 0.056283 Batch F1: 0.6666666666666666
Epoch:  680        5 Batch loss: 0.080024 Batch F1: 0.6666666666666666
Epoch:  680        6 Batch loss: 0.087326 Batch F1: 0.42857142857142855
Epoch:  680        7 Batch loss: 0.062746 Batch F1: 0.5454545454545454
Epoch:  680        8 Batch loss: 0.070493 Batch F1: 0.8235294117647058
Epoch:  680        9 Batch loss: 0.058554 Batch F1: 0.9333333333333333
Epoch:  680       10 Batch loss: 0.061357 Batch F1: 0.962962962962963
Epoch:  680       11 Batch loss: 0.058839 Batch F1: 0.9411764705882353
Epoch:  680       12 Batch loss: 0.072561 Batch F1: 0.7499999999999999
Train Avg Loss  680: 0.066832

Train Avg F1  680: 0.7085814058853274

Val Avg Loss  680: 0.062537

Val Avg F1  680:  0.8382546439628482

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 681
--------------------------------------------------------------
Epoch:  681        1 Batch loss: 0.075539 Batch F1: 0.8571428571428571
Epoch:  681        2 Batch loss: 0.059134 Batch F1: 0.9473684210526316
Epoch:  681        3 Batch loss: 0.077029 Batch F1: 0.7142857142857143
Epoch:  681        4 Batch loss: 0.081030 Batch F1: 0.7499999999999999
Epoch:  681        5 Batch loss: 0.080373 Batch F1: 0.8421052631578948
Epoch:  681        6 Batch loss: 0.058825 Batch F1: 0.8333333333333333
Epoch:  681        7 Batch loss: 0.052570 Batch F1: 1.0
Epoch:  681        8 Batch loss: 0.053486 Batch F1: 1.0
Epoch:  681        9 Batch loss: 0.058721 Batch F1: 0.7272727272727273
Epoch:  681       10 Batch loss: 0.078857 Batch F1: 0.8181818181818181
Epoch:  681       11 Batch loss: 0.067781 Batch F1: 0.8750000000000001
Epoch:  681       12 Batch loss: 0.053713 Batch F1: 0.9333333333333333
Train Avg Loss  681: 0.066421

Train Avg F1  681: 0.8581686223133591

Val Avg Loss  681: 0.062310

Val Avg F1  681:  0.8320900824097756

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 682
--------------------------------------------------------------
Epoch:  682        1 Batch loss: 0.059320 Batch F1: 0.8571428571428571
Epoch:  682        2 Batch loss: 0.075079 Batch F1: 0.9523809523809523
Epoch:  682        3 Batch loss: 0.048878 Batch F1: 1.0
Epoch:  682        4 Batch loss: 0.080674 Batch F1: 0.8235294117647058
Epoch:  682        5 Batch loss: 0.069152 Batch F1: 0.7142857142857143
Epoch:  682        6 Batch loss: 0.049161 Batch F1: 0.8333333333333333
Epoch:  682        7 Batch loss: 0.056737 Batch F1: 0.2857142857142857
Epoch:  682        8 Batch loss: 0.081156 Batch F1: 0.7142857142857143
Epoch:  682        9 Batch loss: 0.056792 Batch F1: 0.9333333333333333
Epoch:  682       10 Batch loss: 0.076096 Batch F1: 0.8333333333333333
Epoch:  682       11 Batch loss: 0.053829 Batch F1: 0.9473684210526316
Epoch:  682       12 Batch loss: 0.090072 Batch F1: 0.7777777777777777
Train Avg Loss  682: 0.066412

Train Avg F1  682: 0.8060404278670532

Val Avg Loss  682: 0.063137

Val Avg F1  682:  0.8875

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 683
--------------------------------------------------------------
Epoch:  683        1 Batch loss: 0.057066 Batch F1: 1.0
Epoch:  683        2 Batch loss: 0.069024 Batch F1: 0.7499999999999999
Epoch:  683        3 Batch loss: 0.061608 Batch F1: 0.7499999999999999
Epoch:  683        4 Batch loss: 0.062377 Batch F1: 0.2857142857142857
Epoch:  683        5 Batch loss: 0.062923 Batch F1: 0.5454545454545454
Epoch:  683        6 Batch loss: 0.087451 Batch F1: 0.631578947368421
Epoch:  683        7 Batch loss: 0.065321 Batch F1: 0.5454545454545454
Epoch:  683        8 Batch loss: 0.054406 Batch F1: 0.923076923076923
Epoch:  683        9 Batch loss: 0.075736 Batch F1: 0.923076923076923
Epoch:  683       10 Batch loss: 0.077183 Batch F1: 0.888888888888889
Epoch:  683       11 Batch loss: 0.077055 Batch F1: 0.8421052631578948
Epoch:  683       12 Batch loss: 0.047356 Batch F1: 1.0
Train Avg Loss  683: 0.066459

Train Avg F1  683: 0.7571125268493691

Val Avg Loss  683: 0.062612

Val Avg F1  683:  0.9494949494949495

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 684
--------------------------------------------------------------
Epoch:  684        1 Batch loss: 0.073315 Batch F1: 0.8750000000000001
Epoch:  684        2 Batch loss: 0.050686 Batch F1: 1.0
Epoch:  684        3 Batch loss: 0.064119 Batch F1: 0.6666666666666666
Epoch:  684        4 Batch loss: 0.063836 Batch F1: 0.4444444444444445
Epoch:  684        5 Batch loss: 0.084976 Batch F1: 0.7000000000000001
Epoch:  684        6 Batch loss: 0.059429 Batch F1: 0.8
Epoch:  684        7 Batch loss: 0.058774 Batch F1: 1.0
Epoch:  684        8 Batch loss: 0.070754 Batch F1: 0.9090909090909091
Epoch:  684        9 Batch loss: 0.054366 Batch F1: 0.9090909090909091
Epoch:  684       10 Batch loss: 0.062553 Batch F1: 0.8
Epoch:  684       11 Batch loss: 0.079267 Batch F1: 0.7000000000000001
Epoch:  684       12 Batch loss: 0.100422 Batch F1: 0.5
Train Avg Loss  684: 0.068541

Train Avg F1  684: 0.775357744107744

Val Avg Loss  684: 0.063107

Val Avg F1  684:  0.8943966817496228

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 685
--------------------------------------------------------------
Epoch:  685        1 Batch loss: 0.076920 Batch F1: 0.8181818181818181
Epoch:  685        2 Batch loss: 0.091519 Batch F1: 0.8
Epoch:  685        3 Batch loss: 0.060954 Batch F1: 1.0
Epoch:  685        4 Batch loss: 0.069180 Batch F1: 0.9411764705882353
Epoch:  685        5 Batch loss: 0.076376 Batch F1: 0.8181818181818182
Epoch:  685        6 Batch loss: 0.063069 Batch F1: 1.0
Epoch:  685        7 Batch loss: 0.066882 Batch F1: 1.0
Epoch:  685        8 Batch loss: 0.070142 Batch F1: 0.4615384615384615
Epoch:  685        9 Batch loss: 0.061700 Batch F1: 0.4444444444444445
Epoch:  685       10 Batch loss: 0.079018 Batch F1: 0.33333333333333337
Epoch:  685       11 Batch loss: 0.054785 Batch F1: 0.6666666666666666
Epoch:  685       12 Batch loss: 0.056590 Batch F1: 0.5714285714285715
Train Avg Loss  685: 0.068928

Train Avg F1  685: 0.737912632030279

Val Avg Loss  685: 0.064495

Val Avg F1  685:  0.6072303921568627

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 686
--------------------------------------------------------------
Epoch:  686        1 Batch loss: 0.087605 Batch F1: 0.4210526315789474
Epoch:  686        2 Batch loss: 0.070578 Batch F1: 0.6666666666666666
Epoch:  686        3 Batch loss: 0.061610 Batch F1: 0.9411764705882353
Epoch:  686        4 Batch loss: 0.065337 Batch F1: 0.8333333333333333
Epoch:  686        5 Batch loss: 0.071106 Batch F1: 0.9090909090909091
Epoch:  686        6 Batch loss: 0.069382 Batch F1: 0.8333333333333333
Epoch:  686        7 Batch loss: 0.078992 Batch F1: 0.5882352941176471
Epoch:  686        8 Batch loss: 0.058171 Batch F1: 0.8333333333333333
Epoch:  686        9 Batch loss: 0.068063 Batch F1: 0.7692307692307693
Epoch:  686       10 Batch loss: 0.057171 Batch F1: 0.7692307692307693
Epoch:  686       11 Batch loss: 0.070742 Batch F1: 0.9166666666666666
Epoch:  686       12 Batch loss: 0.068155 Batch F1: 0.7692307692307693
Train Avg Loss  686: 0.068909

Train Avg F1  686: 0.7708817455334483

Val Avg Loss  686: 0.064044

Val Avg F1  686:  0.9172350099460074

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 687
--------------------------------------------------------------
Epoch:  687        1 Batch loss: 0.073195 Batch F1: 0.8888888888888888
Epoch:  687        2 Batch loss: 0.079392 Batch F1: 0.2222222222222222
Epoch:  687        3 Batch loss: 0.069446 Batch F1: 0.5714285714285715
Epoch:  687        4 Batch loss: 0.083670 Batch F1: 0.631578947368421
Epoch:  687        5 Batch loss: 0.070479 Batch F1: 0.7692307692307693
Epoch:  687        6 Batch loss: 0.075347 Batch F1: 0.9
Epoch:  687        7 Batch loss: 0.048674 Batch F1: 1.0
Epoch:  687        8 Batch loss: 0.056781 Batch F1: 0.6
Epoch:  687        9 Batch loss: 0.070653 Batch F1: 0.7368421052631579
Epoch:  687       10 Batch loss: 0.060947 Batch F1: 0.823529411764706
Epoch:  687       11 Batch loss: 0.061606 Batch F1: 0.2857142857142857
Epoch:  687       12 Batch loss: 0.094705 Batch F1: 0.625
Train Avg Loss  687: 0.070408

Train Avg F1  687: 0.6712029334900852

Val Avg Loss  687: 0.064627

Val Avg F1  687:  0.7105263157894737

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 688
--------------------------------------------------------------
Epoch:  688        1 Batch loss: 0.073101 Batch F1: 0.7777777777777778
Epoch:  688        2 Batch loss: 0.059572 Batch F1: 0.8
Epoch:  688        3 Batch loss: 0.041527 Batch F1: 1.0
Epoch:  688        4 Batch loss: 0.068779 Batch F1: 0.7692307692307692
Epoch:  688        5 Batch loss: 0.094785 Batch F1: 0.8275862068965517
Epoch:  688        6 Batch loss: 0.044267 Batch F1: 1.0
Epoch:  688        7 Batch loss: 0.091708 Batch F1: 0.625
Epoch:  688        8 Batch loss: 0.072082 Batch F1: 0.8235294117647058
Epoch:  688        9 Batch loss: 0.063620 Batch F1: 0.9333333333333333
Epoch:  688       10 Batch loss: 0.081695 Batch F1: 0.6153846153846153
Epoch:  688       11 Batch loss: 0.070378 Batch F1: 0.8571428571428571
Epoch:  688       12 Batch loss: 0.074996 Batch F1: 0.875
Train Avg Loss  688: 0.069709

Train Avg F1  688: 0.8253320809608843

Val Avg Loss  688: 0.066026

Val Avg F1  688:  0.8483766233766235

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 689
--------------------------------------------------------------
Epoch:  689        1 Batch loss: 0.065134 Batch F1: 0.9333333333333333
Epoch:  689        2 Batch loss: 0.063994 Batch F1: 0.8333333333333333
Epoch:  689        3 Batch loss: 0.065243 Batch F1: 0.6666666666666666
Epoch:  689        4 Batch loss: 0.062103 Batch F1: 0.6666666666666666
Epoch:  689        5 Batch loss: 0.046235 Batch F1: 0.8
Epoch:  689        6 Batch loss: 0.089631 Batch F1: 0.4210526315789474
Epoch:  689        7 Batch loss: 0.067305 Batch F1: 0.8750000000000001
Epoch:  689        8 Batch loss: 0.062568 Batch F1: 0.8571428571428571
Epoch:  689        9 Batch loss: 0.079398 Batch F1: 0.888888888888889
Epoch:  689       10 Batch loss: 0.076183 Batch F1: 0.8750000000000001
Epoch:  689       11 Batch loss: 0.065735 Batch F1: 0.9411764705882353
Epoch:  689       12 Batch loss: 0.087311 Batch F1: 0.5
Train Avg Loss  689: 0.069237

Train Avg F1  689: 0.7715217373499107

Val Avg Loss  689: 0.064076

Val Avg F1  689:  0.6015873015873016

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 690
--------------------------------------------------------------
Epoch:  690        1 Batch loss: 0.097385 Batch F1: 0.47058823529411764
Epoch:  690        2 Batch loss: 0.062987 Batch F1: 0.7272727272727273
Epoch:  690        3 Batch loss: 0.066970 Batch F1: 0.5714285714285715
Epoch:  690        4 Batch loss: 0.052123 Batch F1: 0.5714285714285715
Epoch:  690        5 Batch loss: 0.090447 Batch F1: 0.5263157894736842
Epoch:  690        6 Batch loss: 0.056467 Batch F1: 0.7272727272727273
Epoch:  690        7 Batch loss: 0.071422 Batch F1: 0.923076923076923
Epoch:  690        8 Batch loss: 0.056297 Batch F1: 1.0
Epoch:  690        9 Batch loss: 0.072809 Batch F1: 0.888888888888889
Epoch:  690       10 Batch loss: 0.060481 Batch F1: 1.0
Epoch:  690       11 Batch loss: 0.079133 Batch F1: 0.88
Epoch:  690       12 Batch loss: 0.054531 Batch F1: 0.888888888888889
Train Avg Loss  690: 0.068421

Train Avg F1  690: 0.7645967769187584

Val Avg Loss  690: 0.066703

Val Avg F1  690:  0.8131868131868132

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 691
--------------------------------------------------------------
Epoch:  691        1 Batch loss: 0.078632 Batch F1: 0.8
Epoch:  691        2 Batch loss: 0.061142 Batch F1: 0.9090909090909091
Epoch:  691        3 Batch loss: 0.052883 Batch F1: 0.9411764705882353
Epoch:  691        4 Batch loss: 0.066748 Batch F1: 0.6153846153846153
Epoch:  691        5 Batch loss: 0.049007 Batch F1: 0.5
Epoch:  691        6 Batch loss: 0.089463 Batch F1: 0.5333333333333333
Epoch:  691        7 Batch loss: 0.074755 Batch F1: 0.7368421052631579
Epoch:  691        8 Batch loss: 0.056967 Batch F1: 1.0
Epoch:  691        9 Batch loss: 0.080882 Batch F1: 0.8421052631578948
Epoch:  691       10 Batch loss: 0.093291 Batch F1: 0.6666666666666667
Epoch:  691       11 Batch loss: 0.070764 Batch F1: 0.8333333333333333
Epoch:  691       12 Batch loss: 0.051824 Batch F1: 0.7272727272727273
Train Avg Loss  691: 0.068863

Train Avg F1  691: 0.7587671186742394

Val Avg Loss  691: 0.064601

Val Avg F1  691:  0.8629332623897841

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 692
--------------------------------------------------------------
Epoch:  692        1 Batch loss: 0.053577 Batch F1: 0.923076923076923
Epoch:  692        2 Batch loss: 0.051730 Batch F1: 0.8571428571428571
Epoch:  692        3 Batch loss: 0.080192 Batch F1: 0.5714285714285715
Epoch:  692        4 Batch loss: 0.064613 Batch F1: 0.8
Epoch:  692        5 Batch loss: 0.046105 Batch F1: 0.8
Epoch:  692        6 Batch loss: 0.066662 Batch F1: 0.6153846153846153
Epoch:  692        7 Batch loss: 0.086082 Batch F1: 0.631578947368421
Epoch:  692        8 Batch loss: 0.097385 Batch F1: 0.8387096774193548
Epoch:  692        9 Batch loss: 0.091132 Batch F1: 0.9090909090909091
Epoch:  692       10 Batch loss: 0.072140 Batch F1: 0.7999999999999999
Epoch:  692       11 Batch loss: 0.081422 Batch F1: 0.0
Epoch:  692       12 Batch loss: 0.102938 Batch F1: 0.0
Train Avg Loss  692: 0.074498

Train Avg F1  692: 0.645534375075971

Val Avg Loss  692: 0.067064

Val Avg F1  692:  0.7764705882352942

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 693
--------------------------------------------------------------
Epoch:  693        1 Batch loss: 0.074731 Batch F1: 0.8571428571428571
Epoch:  693        2 Batch loss: 0.072986 Batch F1: 0.8
Epoch:  693        3 Batch loss: 0.062542 Batch F1: 0.9411764705882353
Epoch:  693        4 Batch loss: 0.081604 Batch F1: 0.9166666666666666
Epoch:  693        5 Batch loss: 0.066878 Batch F1: 0.923076923076923
Epoch:  693        6 Batch loss: 0.078945 Batch F1: 0.8421052631578948
Epoch:  693        7 Batch loss: 0.079944 Batch F1: 0.6153846153846153
Epoch:  693        8 Batch loss: 0.054180 Batch F1: 0.8
Epoch:  693        9 Batch loss: 0.080569 Batch F1: 0.7000000000000001
Epoch:  693       10 Batch loss: 0.052627 Batch F1: 0.9090909090909091
Epoch:  693       11 Batch loss: 0.066304 Batch F1: 0.9473684210526316
Epoch:  693       12 Batch loss: 0.062170 Batch F1: 0.888888888888889
Train Avg Loss  693: 0.069457

Train Avg F1  693: 0.8450750845874685

Val Avg Loss  693: 0.064571

Val Avg F1  693:  0.6434294871794872

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 694
--------------------------------------------------------------
Epoch:  694        1 Batch loss: 0.063884 Batch F1: 0.8
Epoch:  694        2 Batch loss: 0.091682 Batch F1: 0.4
Epoch:  694        3 Batch loss: 0.053944 Batch F1: 0.7272727272727273
Epoch:  694        4 Batch loss: 0.093535 Batch F1: 0.375
Epoch:  694        5 Batch loss: 0.058807 Batch F1: 0.8571428571428571
Epoch:  694        6 Batch loss: 0.067616 Batch F1: 0.25
Epoch:  694        7 Batch loss: 0.082152 Batch F1: 0.2222222222222222
Epoch:  694        8 Batch loss: 0.064259 Batch F1: 0.2222222222222222
Epoch:  694        9 Batch loss: 0.074743 Batch F1: 0.8235294117647058
Epoch:  694       10 Batch loss: 0.069213 Batch F1: 0.7142857142857143
Epoch:  694       11 Batch loss: 0.055227 Batch F1: 1.0
Epoch:  694       12 Batch loss: 0.084965 Batch F1: 0.9523809523809523
Train Avg Loss  694: 0.071669

Train Avg F1  694: 0.6120046756076168

Val Avg Loss  694: 0.064703

Val Avg F1  694:  0.8831453634085213

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 695
--------------------------------------------------------------
Epoch:  695        1 Batch loss: 0.072041 Batch F1: 0.888888888888889
Epoch:  695        2 Batch loss: 0.065746 Batch F1: 0.8750000000000001
Epoch:  695        3 Batch loss: 0.072335 Batch F1: 0.782608695652174
Epoch:  695        4 Batch loss: 0.068780 Batch F1: 0.4
Epoch:  695        5 Batch loss: 0.077699 Batch F1: 0.46153846153846156
Epoch:  695        6 Batch loss: 0.053926 Batch F1: 0.7499999999999999
Epoch:  695        7 Batch loss: 0.057562 Batch F1: 0.8571428571428571
Epoch:  695        8 Batch loss: 0.052109 Batch F1: 0.2857142857142857
Epoch:  695        9 Batch loss: 0.104398 Batch F1: 0.2857142857142857
Epoch:  695       10 Batch loss: 0.078932 Batch F1: 0.8333333333333333
Epoch:  695       11 Batch loss: 0.058940 Batch F1: 0.923076923076923
Epoch:  695       12 Batch loss: 0.135153 Batch F1: 0.4444444444444445
Train Avg Loss  695: 0.074802

Train Avg F1  695: 0.6489551812921378

Val Avg Loss  695: 0.068009

Val Avg F1  695:  0.9375110015842282

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 696
--------------------------------------------------------------
Epoch:  696        1 Batch loss: 0.089956 Batch F1: 0.967741935483871
Epoch:  696        2 Batch loss: 0.073089 Batch F1: 0.8571428571428571
Epoch:  696        3 Batch loss: 0.067816 Batch F1: 0.9090909090909091
Epoch:  696        4 Batch loss: 0.097894 Batch F1: 0.8695652173913043
Epoch:  696        5 Batch loss: 0.065162 Batch F1: 0.923076923076923
Epoch:  696        6 Batch loss: 0.068669 Batch F1: 0.7499999999999999
Epoch:  696        7 Batch loss: 0.058031 Batch F1: 0.9333333333333333
Epoch:  696        8 Batch loss: 0.088218 Batch F1: 0.6153846153846153
Epoch:  696        9 Batch loss: 0.081725 Batch F1: 0.6
Epoch:  696       10 Batch loss: 0.044573 Batch F1: 0.5
Epoch:  696       11 Batch loss: 0.070066 Batch F1: 0.8
Epoch:  696       12 Batch loss: 0.082543 Batch F1: 0.5714285714285715
Train Avg Loss  696: 0.073979

Train Avg F1  696: 0.7747303635276986

Val Avg Loss  696: 0.071692

Val Avg F1  696:  0.8439636752136752

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 697
--------------------------------------------------------------
Epoch:  697        1 Batch loss: 0.103279 Batch F1: 0.7499999999999999
Epoch:  697        2 Batch loss: 0.089677 Batch F1: 0.9655172413793104
Epoch:  697        3 Batch loss: 0.069816 Batch F1: 0.9
Epoch:  697        4 Batch loss: 0.059211 Batch F1: 0.4444444444444445
Epoch:  697        5 Batch loss: 0.058155 Batch F1: 0.33333333333333337
Epoch:  697        6 Batch loss: 0.043970 Batch F1: 0.0
Epoch:  697        7 Batch loss: 0.093715 Batch F1: 0.4615384615384615
Epoch:  697        8 Batch loss: 0.104818 Batch F1: 0.375
Epoch:  697        9 Batch loss: 0.070641 Batch F1: 0.7272727272727272
Epoch:  697       10 Batch loss: 0.061616 Batch F1: 0.9090909090909091
Epoch:  697       11 Batch loss: 0.077151 Batch F1: 0.9523809523809523
Epoch:  697       12 Batch loss: 0.046698 Batch F1: 1.0
Train Avg Loss  697: 0.073229

Train Avg F1  697: 0.651548172453345

Val Avg Loss  697: 0.067014

Val Avg F1  697:  0.7270676691729324

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 698
--------------------------------------------------------------
Epoch:  698        1 Batch loss: 0.094752 Batch F1: 0.8148148148148148
Epoch:  698        2 Batch loss: 0.074970 Batch F1: 0.6153846153846154
Epoch:  698        3 Batch loss: 0.067445 Batch F1: 0.8421052631578948
Epoch:  698        4 Batch loss: 0.060364 Batch F1: 0.7777777777777778
Epoch:  698        5 Batch loss: 0.077054 Batch F1: 0.3636363636363636
Epoch:  698        6 Batch loss: 0.071433 Batch F1: 0.6666666666666666
Epoch:  698        7 Batch loss: 0.047010 Batch F1: 0.8
Epoch:  698        8 Batch loss: 0.053618 Batch F1: 0.8750000000000001
Epoch:  698        9 Batch loss: 0.088329 Batch F1: 0.0
Epoch:  698       10 Batch loss: 0.048924 Batch F1: 0.5714285714285715
Epoch:  698       11 Batch loss: 0.075720 Batch F1: 0.33333333333333337
Epoch:  698       12 Batch loss: 0.061020 Batch F1: 0.7499999999999999
Train Avg Loss  698: 0.068387

Train Avg F1  698: 0.6175122838500031

Val Avg Loss  698: 0.063472

Val Avg F1  698:  0.7261029411764706

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 699
--------------------------------------------------------------
Epoch:  699        1 Batch loss: 0.061602 Batch F1: 0.75
Epoch:  699        2 Batch loss: 0.079402 Batch F1: 0.5
Epoch:  699        3 Batch loss: 0.085872 Batch F1: 0.7000000000000001
Epoch:  699        4 Batch loss: 0.062886 Batch F1: 0.8750000000000001
Epoch:  699        5 Batch loss: 0.077461 Batch F1: 0.9090909090909091
Epoch:  699        6 Batch loss: 0.064654 Batch F1: 0.9333333333333333
Epoch:  699        7 Batch loss: 0.063312 Batch F1: 0.7272727272727273
Epoch:  699        8 Batch loss: 0.040957 Batch F1: 0.8571428571428571
Epoch:  699        9 Batch loss: 0.065903 Batch F1: 0.5
Epoch:  699       10 Batch loss: 0.086055 Batch F1: 0.625
Epoch:  699       11 Batch loss: 0.057596 Batch F1: 0.25
Epoch:  699       12 Batch loss: 0.088667 Batch F1: 0.9473684210526316
Train Avg Loss  699: 0.069530

Train Avg F1  699: 0.7145173539910382

Val Avg Loss  699: 0.066927

Val Avg F1  699:  0.9244949494949495

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 700
--------------------------------------------------------------
Epoch:  700        1 Batch loss: 0.068933 Batch F1: 0.9411764705882353
Epoch:  700        2 Batch loss: 0.067535 Batch F1: 0.9523809523809523
Epoch:  700        3 Batch loss: 0.072475 Batch F1: 0.9523809523809523
Epoch:  700        4 Batch loss: 0.088286 Batch F1: 0.7499999999999999
Epoch:  700        5 Batch loss: 0.060867 Batch F1: 0.7499999999999999
Epoch:  700        6 Batch loss: 0.069091 Batch F1: 0.6153846153846153
Epoch:  700        7 Batch loss: 0.084776 Batch F1: 0.7368421052631579
Epoch:  700        8 Batch loss: 0.079106 Batch F1: 0.8
Epoch:  700        9 Batch loss: 0.060114 Batch F1: 0.5714285714285715
Epoch:  700       10 Batch loss: 0.082299 Batch F1: 0.8421052631578948
Epoch:  700       11 Batch loss: 0.058607 Batch F1: 0.9333333333333333
Epoch:  700       12 Batch loss: 0.045379 Batch F1: 0.9090909090909091
Train Avg Loss  700: 0.069789

Train Avg F1  700: 0.8128435977507182

Val Avg Loss  700: 0.065295

Val Avg F1  700:  0.7589285714285714

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 701
--------------------------------------------------------------
Epoch:  701        1 Batch loss: 0.047711 Batch F1: 0.8
Epoch:  701        2 Batch loss: 0.067429 Batch F1: 0.25
Epoch:  701        3 Batch loss: 0.065558 Batch F1: 0.888888888888889
Epoch:  701        4 Batch loss: 0.063345 Batch F1: 0.4
Epoch:  701        5 Batch loss: 0.078479 Batch F1: 0.625
Epoch:  701        6 Batch loss: 0.057201 Batch F1: 0.6666666666666666
Epoch:  701        7 Batch loss: 0.069971 Batch F1: 0.8333333333333333
Epoch:  701        8 Batch loss: 0.085903 Batch F1: 0.9375
Epoch:  701        9 Batch loss: 0.061331 Batch F1: 0.9411764705882353
Epoch:  701       10 Batch loss: 0.068488 Batch F1: 1.0
Epoch:  701       11 Batch loss: 0.076488 Batch F1: 0.6666666666666666
Epoch:  701       12 Batch loss: 0.077336 Batch F1: 0.8571428571428571
Train Avg Loss  701: 0.068270

Train Avg F1  701: 0.7388645736072207

Val Avg Loss  701: 0.065664

Val Avg F1  701:  0.882554945054945

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 702
--------------------------------------------------------------
Epoch:  702        1 Batch loss: 0.061348 Batch F1: 1.0
Epoch:  702        2 Batch loss: 0.076914 Batch F1: 0.9523809523809523
Epoch:  702        3 Batch loss: 0.057038 Batch F1: 0.7692307692307693
Epoch:  702        4 Batch loss: 0.071882 Batch F1: 0.4615384615384615
Epoch:  702        5 Batch loss: 0.061875 Batch F1: 0.4444444444444445
Epoch:  702        6 Batch loss: 0.059318 Batch F1: 0.4444444444444445
Epoch:  702        7 Batch loss: 0.103843 Batch F1: 0.4444444444444445
Epoch:  702        8 Batch loss: 0.049155 Batch F1: 0.8333333333333333
Epoch:  702        9 Batch loss: 0.103825 Batch F1: 0.846153846153846
Epoch:  702       10 Batch loss: 0.042310 Batch F1: 0.6666666666666666
Epoch:  702       11 Batch loss: 0.080923 Batch F1: 0.8571428571428571
Epoch:  702       12 Batch loss: 0.058625 Batch F1: 0.5
Train Avg Loss  702: 0.068921

Train Avg F1  702: 0.6849816849816849

Val Avg Loss  702: 0.063895

Val Avg F1  702:  0.7393439893439894

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 703
--------------------------------------------------------------
Epoch:  703        1 Batch loss: 0.073078 Batch F1: 0.88
Epoch:  703        2 Batch loss: 0.075376 Batch F1: 0.9473684210526316
Epoch:  703        3 Batch loss: 0.081426 Batch F1: 0.7142857142857143
Epoch:  703        4 Batch loss: 0.065433 Batch F1: 0.9333333333333333
Epoch:  703        5 Batch loss: 0.067244 Batch F1: 0.8750000000000001
Epoch:  703        6 Batch loss: 0.071536 Batch F1: 0.9090909090909091
Epoch:  703        7 Batch loss: 0.066155 Batch F1: 0.8
Epoch:  703        8 Batch loss: 0.054363 Batch F1: 0.8571428571428571
Epoch:  703        9 Batch loss: 0.055933 Batch F1: 0.7692307692307693
Epoch:  703       10 Batch loss: 0.055059 Batch F1: 0.33333333333333337
Epoch:  703       11 Batch loss: 0.078782 Batch F1: 0.5
Epoch:  703       12 Batch loss: 0.091566 Batch F1: 0.19999999999999998
Train Avg Loss  703: 0.069663

Train Avg F1  703: 0.726565444789129

Val Avg Loss  703: 0.066195

Val Avg F1  703:  0.6384803921568627

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 704
--------------------------------------------------------------
Epoch:  704        1 Batch loss: 0.086386 Batch F1: 0.3076923076923077
Epoch:  704        2 Batch loss: 0.077136 Batch F1: 0.8
Epoch:  704        3 Batch loss: 0.072700 Batch F1: 0.9523809523809523
Epoch:  704        4 Batch loss: 0.062517 Batch F1: 0.9090909090909091
Epoch:  704        5 Batch loss: 0.069967 Batch F1: 0.9333333333333333
Epoch:  704        6 Batch loss: 0.057469 Batch F1: 0.9411764705882353
Epoch:  704        7 Batch loss: 0.073233 Batch F1: 0.9473684210526316
Epoch:  704        8 Batch loss: 0.084618 Batch F1: 0.8181818181818182
Epoch:  704        9 Batch loss: 0.072413 Batch F1: 0.8750000000000001
Epoch:  704       10 Batch loss: 0.056399 Batch F1: 0.33333333333333337
Epoch:  704       11 Batch loss: 0.069012 Batch F1: 0.7777777777777778
Epoch:  704       12 Batch loss: 0.050895 Batch F1: 0.6666666666666666
Train Avg Loss  704: 0.069395

Train Avg F1  704: 0.7718334991748305

Val Avg Loss  704: 0.064570

Val Avg F1  704:  0.6363636363636365

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 705
--------------------------------------------------------------
Epoch:  705        1 Batch loss: 0.069676 Batch F1: 0.5
Epoch:  705        2 Batch loss: 0.049553 Batch F1: 0.4
Epoch:  705        3 Batch loss: 0.078851 Batch F1: 0.33333333333333337
Epoch:  705        4 Batch loss: 0.046681 Batch F1: 0.5
Epoch:  705        5 Batch loss: 0.060572 Batch F1: 0.7142857142857143
Epoch:  705        6 Batch loss: 0.079775 Batch F1: 0.6666666666666666
Epoch:  705        7 Batch loss: 0.068978 Batch F1: 0.8181818181818181
Epoch:  705        8 Batch loss: 0.075865 Batch F1: 0.8750000000000001
Epoch:  705        9 Batch loss: 0.082612 Batch F1: 0.9565217391304348
Epoch:  705       10 Batch loss: 0.077203 Batch F1: 0.8571428571428571
Epoch:  705       11 Batch loss: 0.079391 Batch F1: 0.9
Epoch:  705       12 Batch loss: 0.050612 Batch F1: 0.9333333333333333
Train Avg Loss  705: 0.068314

Train Avg F1  705: 0.7045387885061798

Val Avg Loss  705: 0.063334

Val Avg F1  705:  0.6268939393939393

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 706
--------------------------------------------------------------
Epoch:  706        1 Batch loss: 0.046540 Batch F1: 0.8333333333333333
Epoch:  706        2 Batch loss: 0.095274 Batch F1: 0.375
Epoch:  706        3 Batch loss: 0.059119 Batch F1: 0.7499999999999999
Epoch:  706        4 Batch loss: 0.064809 Batch F1: 0.8750000000000001
Epoch:  706        5 Batch loss: 0.064775 Batch F1: 0.9411764705882353
Epoch:  706        6 Batch loss: 0.066197 Batch F1: 0.923076923076923
Epoch:  706        7 Batch loss: 0.061044 Batch F1: 0.923076923076923
Epoch:  706        8 Batch loss: 0.064258 Batch F1: 0.6666666666666666
Epoch:  706        9 Batch loss: 0.097811 Batch F1: 0.2857142857142857
Epoch:  706       10 Batch loss: 0.074658 Batch F1: 0.6666666666666666
Epoch:  706       11 Batch loss: 0.060220 Batch F1: 0.8
Epoch:  706       12 Batch loss: 0.065127 Batch F1: 1.0
Train Avg Loss  706: 0.068319

Train Avg F1  706: 0.7533092724269196

Val Avg Loss  706: 0.064656

Val Avg F1  706:  0.9352941176470588

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 707
--------------------------------------------------------------
Epoch:  707        1 Batch loss: 0.085853 Batch F1: 0.8571428571428571
Epoch:  707        2 Batch loss: 0.078348 Batch F1: 0.8888888888888888
Epoch:  707        3 Batch loss: 0.047087 Batch F1: 1.0
Epoch:  707        4 Batch loss: 0.098384 Batch F1: 0.8484848484848484
Epoch:  707        5 Batch loss: 0.047331 Batch F1: 1.0
Epoch:  707        6 Batch loss: 0.066975 Batch F1: 0.9
Epoch:  707        7 Batch loss: 0.069115 Batch F1: 0.8
Epoch:  707        8 Batch loss: 0.058892 Batch F1: 0.7499999999999999
Epoch:  707        9 Batch loss: 0.088156 Batch F1: 0.5
Epoch:  707       10 Batch loss: 0.037486 Batch F1: 0.8
Epoch:  707       11 Batch loss: 0.090507 Batch F1: 0.5
Epoch:  707       12 Batch loss: 0.052064 Batch F1: 0.7272727272727273
Train Avg Loss  707: 0.068350

Train Avg F1  707: 0.7976491101491101

Val Avg Loss  707: 0.063528

Val Avg F1  707:  0.6301136363636364

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 708
--------------------------------------------------------------
Epoch:  708        1 Batch loss: 0.059081 Batch F1: 0.5
Epoch:  708        2 Batch loss: 0.069991 Batch F1: 0.761904761904762
Epoch:  708        3 Batch loss: 0.064698 Batch F1: 0.25
Epoch:  708        4 Batch loss: 0.077191 Batch F1: 0.46153846153846156
Epoch:  708        5 Batch loss: 0.101743 Batch F1: 0.75
Epoch:  708        6 Batch loss: 0.062775 Batch F1: 0.9090909090909091
Epoch:  708        7 Batch loss: 0.075050 Batch F1: 0.9
Epoch:  708        8 Batch loss: 0.070431 Batch F1: 1.0
Epoch:  708        9 Batch loss: 0.056312 Batch F1: 0.9333333333333333
Epoch:  708       10 Batch loss: 0.052671 Batch F1: 0.9333333333333333
Epoch:  708       11 Batch loss: 0.051172 Batch F1: 1.0
Epoch:  708       12 Batch loss: 0.071833 Batch F1: 0.9
Train Avg Loss  708: 0.067746

Train Avg F1  708: 0.7749333999334

Val Avg Loss  708: 0.063145

Val Avg F1  708:  0.6107226107226107

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 709
--------------------------------------------------------------
Epoch:  709        1 Batch loss: 0.071628 Batch F1: 0.7142857142857143
Epoch:  709        2 Batch loss: 0.109071 Batch F1: 0.5263157894736842
Epoch:  709        3 Batch loss: 0.056261 Batch F1: 0.4444444444444445
Epoch:  709        4 Batch loss: 0.069755 Batch F1: 0.625
Epoch:  709        5 Batch loss: 0.063883 Batch F1: 0.9090909090909091
Epoch:  709        6 Batch loss: 0.050128 Batch F1: 0.888888888888889
Epoch:  709        7 Batch loss: 0.065262 Batch F1: 0.8333333333333333
Epoch:  709        8 Batch loss: 0.064498 Batch F1: 0.6153846153846153
Epoch:  709        9 Batch loss: 0.086468 Batch F1: 0.4
Epoch:  709       10 Batch loss: 0.064254 Batch F1: 0.4
Epoch:  709       11 Batch loss: 0.030880 Batch F1: 0.8
Epoch:  709       12 Batch loss: 0.086972 Batch F1: 0.42857142857142855
Train Avg Loss  709: 0.068255

Train Avg F1  709: 0.6321095936227515

Val Avg Loss  709: 0.065434

Val Avg F1  709:  0.8319838056680162

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 710
--------------------------------------------------------------
Epoch:  710        1 Batch loss: 0.062993 Batch F1: 0.823529411764706
Epoch:  710        2 Batch loss: 0.075280 Batch F1: 0.8695652173913043
Epoch:  710        3 Batch loss: 0.085602 Batch F1: 0.9655172413793104
Epoch:  710        4 Batch loss: 0.065686 Batch F1: 0.8333333333333333
Epoch:  710        5 Batch loss: 0.061388 Batch F1: 0.9333333333333333
Epoch:  710        6 Batch loss: 0.067985 Batch F1: 0.7058823529411764
Epoch:  710        7 Batch loss: 0.062675 Batch F1: 0.7692307692307693
Epoch:  710        8 Batch loss: 0.077939 Batch F1: 0.5454545454545454
Epoch:  710        9 Batch loss: 0.046683 Batch F1: 0.5714285714285715
Epoch:  710       10 Batch loss: 0.092161 Batch F1: 0.5882352941176471
Epoch:  710       11 Batch loss: 0.045665 Batch F1: 0.5714285714285715
Epoch:  710       12 Batch loss: 0.082990 Batch F1: 0.6153846153846153
Train Avg Loss  710: 0.068921

Train Avg F1  710: 0.7326936047656569

Val Avg Loss  710: 0.063788

Val Avg F1  710:  0.9125668449197861

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 711
--------------------------------------------------------------
Epoch:  711        1 Batch loss: 0.083100 Batch F1: 0.888888888888889
Epoch:  711        2 Batch loss: 0.066852 Batch F1: 0.9600000000000001
Epoch:  711        3 Batch loss: 0.065933 Batch F1: 0.9090909090909091
Epoch:  711        4 Batch loss: 0.042646 Batch F1: 1.0
Epoch:  711        5 Batch loss: 0.046993 Batch F1: 0.5714285714285715
Epoch:  711        6 Batch loss: 0.070372 Batch F1: 0.6666666666666666
Epoch:  711        7 Batch loss: 0.087444 Batch F1: 0.42857142857142855
Epoch:  711        8 Batch loss: 0.063988 Batch F1: 0.6666666666666666
Epoch:  711        9 Batch loss: 0.082872 Batch F1: 0.9
Epoch:  711       10 Batch loss: 0.071924 Batch F1: 0.7999999999999999
Epoch:  711       11 Batch loss: 0.082182 Batch F1: 0.8235294117647058
Epoch:  711       12 Batch loss: 0.059251 Batch F1: 1.0
Train Avg Loss  711: 0.068630

Train Avg F1  711: 0.8012368785898198

Val Avg Loss  711: 0.063741

Val Avg F1  711:  0.708974358974359

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 712
--------------------------------------------------------------
Epoch:  712        1 Batch loss: 0.054082 Batch F1: 0.6
Epoch:  712        2 Batch loss: 0.057099 Batch F1: 0.6
Epoch:  712        3 Batch loss: 0.090440 Batch F1: 0.7368421052631579
Epoch:  712        4 Batch loss: 0.067863 Batch F1: 0.7368421052631579
Epoch:  712        5 Batch loss: 0.050615 Batch F1: 1.0
Epoch:  712        6 Batch loss: 0.056841 Batch F1: 0.4
Epoch:  712        7 Batch loss: 0.059109 Batch F1: 0.7692307692307692
Epoch:  712        8 Batch loss: 0.091016 Batch F1: 0.7499999999999999
Epoch:  712        9 Batch loss: 0.079886 Batch F1: 0.75
Epoch:  712       10 Batch loss: 0.064019 Batch F1: 0.8571428571428571
Epoch:  712       11 Batch loss: 0.054680 Batch F1: 0.7499999999999999
Epoch:  712       12 Batch loss: 0.105750 Batch F1: 0.2857142857142857
Train Avg Loss  712: 0.069284

Train Avg F1  712: 0.6863143435511856

Val Avg Loss  712: 0.065841

Val Avg F1  712:  0.6452380952380952

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 713
--------------------------------------------------------------
Epoch:  713        1 Batch loss: 0.060368 Batch F1: 0.6666666666666666
Epoch:  713        2 Batch loss: 0.055900 Batch F1: 0.8
Epoch:  713        3 Batch loss: 0.061717 Batch F1: 0.7499999999999999
Epoch:  713        4 Batch loss: 0.042729 Batch F1: 1.0
Epoch:  713        5 Batch loss: 0.065652 Batch F1: 0.9473684210526316
Epoch:  713        6 Batch loss: 0.064833 Batch F1: 0.888888888888889
Epoch:  713        7 Batch loss: 0.072591 Batch F1: 0.8
Epoch:  713        8 Batch loss: 0.068133 Batch F1: 0.9523809523809523
Epoch:  713        9 Batch loss: 0.081071 Batch F1: 0.7499999999999999
Epoch:  713       10 Batch loss: 0.085144 Batch F1: 0.5555555555555556
Epoch:  713       11 Batch loss: 0.048774 Batch F1: 0.7272727272727273
Epoch:  713       12 Batch loss: 0.096591 Batch F1: 0.6666666666666666
Train Avg Loss  713: 0.066959

Train Avg F1  713: 0.7920666565403408

Val Avg Loss  713: 0.063240

Val Avg F1  713:  0.8538752913752913

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 714
--------------------------------------------------------------
Epoch:  714        1 Batch loss: 0.070712 Batch F1: 0.8695652173913044
Epoch:  714        2 Batch loss: 0.062031 Batch F1: 0.9090909090909091
Epoch:  714        3 Batch loss: 0.084461 Batch F1: 0.7999999999999999
Epoch:  714        4 Batch loss: 0.083848 Batch F1: 0.9333333333333333
Epoch:  714        5 Batch loss: 0.065937 Batch F1: 1.0
Epoch:  714        6 Batch loss: 0.050486 Batch F1: 0.888888888888889
Epoch:  714        7 Batch loss: 0.053959 Batch F1: 0.8333333333333333
Epoch:  714        8 Batch loss: 0.071038 Batch F1: 0.7692307692307693
Epoch:  714        9 Batch loss: 0.078983 Batch F1: 0.16666666666666669
Epoch:  714       10 Batch loss: 0.046817 Batch F1: 0.6666666666666666
Epoch:  714       11 Batch loss: 0.094473 Batch F1: 0.631578947368421
Epoch:  714       12 Batch loss: 0.056955 Batch F1: 0.9090909090909091
Train Avg Loss  714: 0.068308

Train Avg F1  714: 0.7814538034217667

Val Avg Loss  714: 0.064555

Val Avg F1  714:  0.763375350140056

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 715
--------------------------------------------------------------
Epoch:  715        1 Batch loss: 0.063229 Batch F1: 0.8
Epoch:  715        2 Batch loss: 0.083930 Batch F1: 0.7368421052631579
Epoch:  715        3 Batch loss: 0.060630 Batch F1: 0.9333333333333333
Epoch:  715        4 Batch loss: 0.048270 Batch F1: 0.9411764705882353
Epoch:  715        5 Batch loss: 0.089146 Batch F1: 0.8571428571428571
Epoch:  715        6 Batch loss: 0.071177 Batch F1: 0.8750000000000001
Epoch:  715        7 Batch loss: 0.056610 Batch F1: 0.9090909090909091
Epoch:  715        8 Batch loss: 0.085990 Batch F1: 0.6666666666666666
Epoch:  715        9 Batch loss: 0.054786 Batch F1: 0.9333333333333333
Epoch:  715       10 Batch loss: 0.065565 Batch F1: 0.8333333333333333
Epoch:  715       11 Batch loss: 0.085327 Batch F1: 0.5000000000000001
Epoch:  715       12 Batch loss: 0.041562 Batch F1: 0.7499999999999999
Train Avg Loss  715: 0.067185

Train Avg F1  715: 0.8113265840626522

Val Avg Loss  715: 0.066231

Val Avg F1  715:  0.6190867955573838

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 716
--------------------------------------------------------------
Epoch:  716        1 Batch loss: 0.045369 Batch F1: 0.9090909090909091
Epoch:  716        2 Batch loss: 0.104920 Batch F1: 0.5
Epoch:  716        3 Batch loss: 0.091291 Batch F1: 0.5333333333333333
Epoch:  716        4 Batch loss: 0.050524 Batch F1: 0.888888888888889
Epoch:  716        5 Batch loss: 0.067172 Batch F1: 0.8333333333333333
Epoch:  716        6 Batch loss: 0.071868 Batch F1: 0.8421052631578948
Epoch:  716        7 Batch loss: 0.073487 Batch F1: 0.8750000000000001
Epoch:  716        8 Batch loss: 0.052836 Batch F1: 0.9333333333333333
Epoch:  716        9 Batch loss: 0.071935 Batch F1: 0.4615384615384615
Epoch:  716       10 Batch loss: 0.088556 Batch F1: 0.5333333333333333
Epoch:  716       11 Batch loss: 0.056708 Batch F1: 0.7692307692307693
Epoch:  716       12 Batch loss: 0.064593 Batch F1: 0.923076923076923
Train Avg Loss  716: 0.069938

Train Avg F1  716: 0.750188712359765

Val Avg Loss  716: 0.063033

Val Avg F1  716:  0.9212503183091418

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 717
--------------------------------------------------------------
Epoch:  717        1 Batch loss: 0.097893 Batch F1: 0.888888888888889
Epoch:  717        2 Batch loss: 0.054549 Batch F1: 0.923076923076923
Epoch:  717        3 Batch loss: 0.051413 Batch F1: 0.923076923076923
Epoch:  717        4 Batch loss: 0.070970 Batch F1: 0.7777777777777778
Epoch:  717        5 Batch loss: 0.065667 Batch F1: 0.8421052631578948
Epoch:  717        6 Batch loss: 0.048564 Batch F1: 0.8
Epoch:  717        7 Batch loss: 0.060933 Batch F1: 0.8750000000000001
Epoch:  717        8 Batch loss: 0.068777 Batch F1: 0.7692307692307693
Epoch:  717        9 Batch loss: 0.062266 Batch F1: 0.5
Epoch:  717       10 Batch loss: 0.069144 Batch F1: 0.8
Epoch:  717       11 Batch loss: 0.078621 Batch F1: 0.7368421052631579
Epoch:  717       12 Batch loss: 0.070780 Batch F1: 0.25
Train Avg Loss  717: 0.066631

Train Avg F1  717: 0.7571665542060279

Val Avg Loss  717: 0.062211

Val Avg F1  717:  0.6964285714285714

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 718
--------------------------------------------------------------
Epoch:  718        1 Batch loss: 0.064600 Batch F1: 0.5
Epoch:  718        2 Batch loss: 0.091255 Batch F1: 0.8275862068965517
Epoch:  718        3 Batch loss: 0.073874 Batch F1: 0.9565217391304348
Epoch:  718        4 Batch loss: 0.052135 Batch F1: 0.888888888888889
Epoch:  718        5 Batch loss: 0.053887 Batch F1: 1.0
Epoch:  718        6 Batch loss: 0.048319 Batch F1: 1.0
Epoch:  718        7 Batch loss: 0.068397 Batch F1: 0.7499999999999999
Epoch:  718        8 Batch loss: 0.065510 Batch F1: 0.7272727272727273
Epoch:  718        9 Batch loss: 0.082793 Batch F1: 0.4615384615384615
Epoch:  718       10 Batch loss: 0.064452 Batch F1: 0.6
Epoch:  718       11 Batch loss: 0.078037 Batch F1: 0.4
Epoch:  718       12 Batch loss: 0.057303 Batch F1: 0.6
Train Avg Loss  718: 0.066713

Train Avg F1  718: 0.7259840019772552

Val Avg Loss  718: 0.063280

Val Avg F1  718:  0.6424408924408925

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 719
--------------------------------------------------------------
Epoch:  719        1 Batch loss: 0.057344 Batch F1: 0.6
Epoch:  719        2 Batch loss: 0.055065 Batch F1: 0.6666666666666666
Epoch:  719        3 Batch loss: 0.057883 Batch F1: 0.8571428571428571
Epoch:  719        4 Batch loss: 0.052544 Batch F1: 0.6
Epoch:  719        5 Batch loss: 0.092968 Batch F1: 0.5
Epoch:  719        6 Batch loss: 0.083128 Batch F1: 0.6666666666666666
Epoch:  719        7 Batch loss: 0.070030 Batch F1: 0.888888888888889
Epoch:  719        8 Batch loss: 0.086946 Batch F1: 0.7777777777777777
Epoch:  719        9 Batch loss: 0.058325 Batch F1: 0.7692307692307693
Epoch:  719       10 Batch loss: 0.046337 Batch F1: 1.0
Epoch:  719       11 Batch loss: 0.078012 Batch F1: 0.5333333333333333
Epoch:  719       12 Batch loss: 0.069613 Batch F1: 0.6666666666666666
Train Avg Loss  719: 0.067350

Train Avg F1  719: 0.7105311355311356

Val Avg Loss  719: 0.063574

Val Avg F1  719:  0.7455357142857143

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 720
--------------------------------------------------------------
Epoch:  720        1 Batch loss: 0.077316 Batch F1: 0.7368421052631579
Epoch:  720        2 Batch loss: 0.055499 Batch F1: 0.9333333333333333
Epoch:  720        3 Batch loss: 0.048632 Batch F1: 1.0
Epoch:  720        4 Batch loss: 0.067953 Batch F1: 0.7142857142857143
Epoch:  720        5 Batch loss: 0.086946 Batch F1: 0.8695652173913044
Epoch:  720        6 Batch loss: 0.056035 Batch F1: 0.6666666666666666
Epoch:  720        7 Batch loss: 0.076353 Batch F1: 0.7777777777777778
Epoch:  720        8 Batch loss: 0.065787 Batch F1: 0.8333333333333333
Epoch:  720        9 Batch loss: 0.077512 Batch F1: 0.9
Epoch:  720       10 Batch loss: 0.054822 Batch F1: 0.8333333333333333
Epoch:  720       11 Batch loss: 0.072958 Batch F1: 0.9565217391304348
Epoch:  720       12 Batch loss: 0.066605 Batch F1: 0.9090909090909091
Train Avg Loss  720: 0.067202

Train Avg F1  720: 0.8442291774671639

Val Avg Loss  720: 0.062455

Val Avg F1  720:  0.8423913043478262

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 721
--------------------------------------------------------------
Epoch:  721        1 Batch loss: 0.053256 Batch F1: 0.7499999999999999
Epoch:  721        2 Batch loss: 0.041070 Batch F1: 1.0
Epoch:  721        3 Batch loss: 0.066033 Batch F1: 0.6666666666666666
Epoch:  721        4 Batch loss: 0.065246 Batch F1: 0.6153846153846153
Epoch:  721        5 Batch loss: 0.055771 Batch F1: 0.5714285714285715
Epoch:  721        6 Batch loss: 0.087555 Batch F1: 0.5882352941176471
Epoch:  721        7 Batch loss: 0.093812 Batch F1: 0.5263157894736842
Epoch:  721        8 Batch loss: 0.071184 Batch F1: 0.6666666666666666
Epoch:  721        9 Batch loss: 0.062002 Batch F1: 0.888888888888889
Epoch:  721       10 Batch loss: 0.071255 Batch F1: 0.8888888888888888
Epoch:  721       11 Batch loss: 0.069483 Batch F1: 0.9411764705882353
Epoch:  721       12 Batch loss: 0.088637 Batch F1: 0.9565217391304348
Train Avg Loss  721: 0.068775

Train Avg F1  721: 0.7550144659361918

Val Avg Loss  721: 0.061682

Val Avg F1  721:  0.8443181818181819

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 722
--------------------------------------------------------------
Epoch:  722        1 Batch loss: 0.060032 Batch F1: 0.8750000000000001
Epoch:  722        2 Batch loss: 0.061897 Batch F1: 0.888888888888889
Epoch:  722        3 Batch loss: 0.064014 Batch F1: 0.8333333333333333
Epoch:  722        4 Batch loss: 0.065263 Batch F1: 0.8
Epoch:  722        5 Batch loss: 0.055923 Batch F1: 0.6666666666666666
Epoch:  722        6 Batch loss: 0.083212 Batch F1: 0.19999999999999998
Epoch:  722        7 Batch loss: 0.059683 Batch F1: 0.8
Epoch:  722        8 Batch loss: 0.044681 Batch F1: 0.8
Epoch:  722        9 Batch loss: 0.081974 Batch F1: 0.5333333333333333
Epoch:  722       10 Batch loss: 0.077798 Batch F1: 0.42857142857142855
Epoch:  722       11 Batch loss: 0.091085 Batch F1: 0.8333333333333333
Epoch:  722       12 Batch loss: 0.064333 Batch F1: 1.0
Train Avg Loss  722: 0.067491

Train Avg F1  722: 0.7215939153439154

Val Avg Loss  722: 0.064475

Val Avg F1  722:  0.9144439152179091

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 723
--------------------------------------------------------------
Epoch:  723        1 Batch loss: 0.063500 Batch F1: 1.0
Epoch:  723        2 Batch loss: 0.068838 Batch F1: 0.9411764705882353
Epoch:  723        3 Batch loss: 0.060993 Batch F1: 0.7692307692307693
Epoch:  723        4 Batch loss: 0.082593 Batch F1: 0.6666666666666666
Epoch:  723        5 Batch loss: 0.065805 Batch F1: 0.8
Epoch:  723        6 Batch loss: 0.086381 Batch F1: 0.7058823529411764
Epoch:  723        7 Batch loss: 0.074349 Batch F1: 0.8235294117647058
Epoch:  723        8 Batch loss: 0.063516 Batch F1: 0.9473684210526316
Epoch:  723        9 Batch loss: 0.077002 Batch F1: 0.9411764705882353
Epoch:  723       10 Batch loss: 0.051453 Batch F1: 0.8
Epoch:  723       11 Batch loss: 0.085756 Batch F1: 0.631578947368421
Epoch:  723       12 Batch loss: 0.047608 Batch F1: 0.888888888888889
Train Avg Loss  723: 0.068983

Train Avg F1  723: 0.8262915332574776

Val Avg Loss  723: 0.064881

Val Avg F1  723:  0.6142857142857143

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 724
--------------------------------------------------------------
Epoch:  724        1 Batch loss: 0.063141 Batch F1: 0.8421052631578948
Epoch:  724        2 Batch loss: 0.053328 Batch F1: 0.7142857142857143
Epoch:  724        3 Batch loss: 0.062646 Batch F1: 0.7692307692307693
Epoch:  724        4 Batch loss: 0.058385 Batch F1: 0.923076923076923
Epoch:  724        5 Batch loss: 0.078536 Batch F1: 0.9600000000000001
Epoch:  724        6 Batch loss: 0.075930 Batch F1: 0.8571428571428571
Epoch:  724        7 Batch loss: 0.076526 Batch F1: 0.8888888888888888
Epoch:  724        8 Batch loss: 0.063762 Batch F1: 0.8421052631578948
Epoch:  724        9 Batch loss: 0.079273 Batch F1: 0.2222222222222222
Epoch:  724       10 Batch loss: 0.076870 Batch F1: 0.6153846153846153
Epoch:  724       11 Batch loss: 0.063156 Batch F1: 0.6153846153846153
Epoch:  724       12 Batch loss: 0.066975 Batch F1: 0.5
Train Avg Loss  724: 0.068211

Train Avg F1  724: 0.7291522609943661

Val Avg Loss  724: 0.064874

Val Avg F1  724:  0.7056818181818182

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 725
--------------------------------------------------------------
Epoch:  725        1 Batch loss: 0.046274 Batch F1: 0.5714285714285715
Epoch:  725        2 Batch loss: 0.069653 Batch F1: 0.5714285714285715
Epoch:  725        3 Batch loss: 0.094609 Batch F1: 0.33333333333333337
Epoch:  725        4 Batch loss: 0.060459 Batch F1: 0.8750000000000001
Epoch:  725        5 Batch loss: 0.080407 Batch F1: 0.8421052631578948
Epoch:  725        6 Batch loss: 0.064243 Batch F1: 0.8750000000000001
Epoch:  725        7 Batch loss: 0.092323 Batch F1: 0.5263157894736842
Epoch:  725        8 Batch loss: 0.063434 Batch F1: 0.9333333333333333
Epoch:  725        9 Batch loss: 0.051433 Batch F1: 1.0
Epoch:  725       10 Batch loss: 0.065785 Batch F1: 0.9333333333333333
Epoch:  725       11 Batch loss: 0.081165 Batch F1: 0.8181818181818181
Epoch:  725       12 Batch loss: 0.054030 Batch F1: 1.0
Train Avg Loss  725: 0.068651

Train Avg F1  725: 0.7732883344725451

Val Avg Loss  725: 0.062769

Val Avg F1  725:  0.9245192307692307

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 726
--------------------------------------------------------------
Epoch:  726        1 Batch loss: 0.056574 Batch F1: 1.0
Epoch:  726        2 Batch loss: 0.054202 Batch F1: 0.6666666666666666
Epoch:  726        3 Batch loss: 0.059384 Batch F1: 0.7142857142857143
Epoch:  726        4 Batch loss: 0.087188 Batch F1: 0.42857142857142855
Epoch:  726        5 Batch loss: 0.090578 Batch F1: 0.6086956521739131
Epoch:  726        6 Batch loss: 0.082638 Batch F1: 0.9411764705882353
Epoch:  726        7 Batch loss: 0.071244 Batch F1: 0.9565217391304348
Epoch:  726        8 Batch loss: 0.061336 Batch F1: 0.9411764705882353
Epoch:  726        9 Batch loss: 0.057733 Batch F1: 1.0
Epoch:  726       10 Batch loss: 0.088516 Batch F1: 0.6666666666666666
Epoch:  726       11 Batch loss: 0.075293 Batch F1: 0.0
Epoch:  726       12 Batch loss: 0.051374 Batch F1: 0.9090909090909091
Train Avg Loss  726: 0.069672

Train Avg F1  726: 0.7360709764801836

Val Avg Loss  726: 0.065144

Val Avg F1  726:  0.6452380952380953

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 727
--------------------------------------------------------------
Epoch:  727        1 Batch loss: 0.061590 Batch F1: 0.4444444444444445
Epoch:  727        2 Batch loss: 0.090967 Batch F1: 0.42857142857142855
Epoch:  727        3 Batch loss: 0.051459 Batch F1: 0.8
Epoch:  727        4 Batch loss: 0.062271 Batch F1: 0.7499999999999999
Epoch:  727        5 Batch loss: 0.062966 Batch F1: 0.6666666666666666
Epoch:  727        6 Batch loss: 0.056630 Batch F1: 0.8333333333333333
Epoch:  727        7 Batch loss: 0.063465 Batch F1: 0.6
Epoch:  727        8 Batch loss: 0.098766 Batch F1: 0.5555555555555556
Epoch:  727        9 Batch loss: 0.064035 Batch F1: 0.8571428571428571
Epoch:  727       10 Batch loss: 0.053469 Batch F1: 1.0
Epoch:  727       11 Batch loss: 0.087900 Batch F1: 0.9375
Epoch:  727       12 Batch loss: 0.076127 Batch F1: 0.923076923076923
Train Avg Loss  727: 0.069137

Train Avg F1  727: 0.7330242673992672

Val Avg Loss  727: 0.063900

Val Avg F1  727:  0.9247468218056453

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 728
--------------------------------------------------------------
Epoch:  728        1 Batch loss: 0.078449 Batch F1: 0.8750000000000001
Epoch:  728        2 Batch loss: 0.067996 Batch F1: 0.7272727272727273
Epoch:  728        3 Batch loss: 0.058039 Batch F1: 0.5
Epoch:  728        4 Batch loss: 0.067953 Batch F1: 0.7058823529411764
Epoch:  728        5 Batch loss: 0.040785 Batch F1: 0.8333333333333333
Epoch:  728        6 Batch loss: 0.064871 Batch F1: 0.8235294117647058
Epoch:  728        7 Batch loss: 0.092452 Batch F1: 0.375
Epoch:  728        8 Batch loss: 0.069026 Batch F1: 0.923076923076923
Epoch:  728        9 Batch loss: 0.064135 Batch F1: 0.9333333333333333
Epoch:  728       10 Batch loss: 0.080066 Batch F1: 0.8000000000000002
Epoch:  728       11 Batch loss: 0.074810 Batch F1: 0.7777777777777777
Epoch:  728       12 Batch loss: 0.073918 Batch F1: 0.7692307692307693
Train Avg Loss  728: 0.069375

Train Avg F1  728: 0.7536197190608956

Val Avg Loss  728: 0.068092

Val Avg F1  728:  0.6478521478521478

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 729
--------------------------------------------------------------
Epoch:  729        1 Batch loss: 0.058463 Batch F1: 0.6
Epoch:  729        2 Batch loss: 0.041209 Batch F1: 0.6666666666666666
Epoch:  729        3 Batch loss: 0.080593 Batch F1: 0.7777777777777778
Epoch:  729        4 Batch loss: 0.071214 Batch F1: 0.7499999999999999
Epoch:  729        5 Batch loss: 0.100230 Batch F1: 0.9032258064516129
Epoch:  729        6 Batch loss: 0.074506 Batch F1: 0.923076923076923
Epoch:  729        7 Batch loss: 0.078956 Batch F1: 0.8
Epoch:  729        8 Batch loss: 0.088495 Batch F1: 0.19999999999999998
Epoch:  729        9 Batch loss: 0.068666 Batch F1: 0.6153846153846153
Epoch:  729       10 Batch loss: 0.076393 Batch F1: 0.888888888888889
Epoch:  729       11 Batch loss: 0.048937 Batch F1: 1.0
Epoch:  729       12 Batch loss: 0.077815 Batch F1: 0.9411764705882353
Train Avg Loss  729: 0.072123

Train Avg F1  729: 0.7555164290695601

Val Avg Loss  729: 0.065269

Val Avg F1  729:  0.923389355742297

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 730
--------------------------------------------------------------
Epoch:  730        1 Batch loss: 0.059161 Batch F1: 0.8333333333333333
Epoch:  730        2 Batch loss: 0.047392 Batch F1: 1.0
Epoch:  730        3 Batch loss: 0.050723 Batch F1: 0.7499999999999999
Epoch:  730        4 Batch loss: 0.075398 Batch F1: 0.0
Epoch:  730        5 Batch loss: 0.084938 Batch F1: 0.19999999999999998
Epoch:  730        6 Batch loss: 0.108457 Batch F1: 0.47058823529411764
Epoch:  730        7 Batch loss: 0.053752 Batch F1: 0.7692307692307693
Epoch:  730        8 Batch loss: 0.092893 Batch F1: 0.888888888888889
Epoch:  730        9 Batch loss: 0.101257 Batch F1: 0.846153846153846
Epoch:  730       10 Batch loss: 0.048050 Batch F1: 0.8750000000000001
Epoch:  730       11 Batch loss: 0.061454 Batch F1: 0.923076923076923
Epoch:  730       12 Batch loss: 0.074189 Batch F1: 0.923076923076923
Train Avg Loss  730: 0.071472

Train Avg F1  730: 0.7066124099212335

Val Avg Loss  730: 0.063706

Val Avg F1  730:  0.676470588235294

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 731
--------------------------------------------------------------
Epoch:  731        1 Batch loss: 0.075339 Batch F1: 0.7058823529411764
Epoch:  731        2 Batch loss: 0.067567 Batch F1: 0.8750000000000001
Epoch:  731        3 Batch loss: 0.052283 Batch F1: 1.0
Epoch:  731        4 Batch loss: 0.080685 Batch F1: 0.7777777777777778
Epoch:  731        5 Batch loss: 0.082745 Batch F1: 0.3076923076923077
Epoch:  731        6 Batch loss: 0.064555 Batch F1: 0.8
Epoch:  731        7 Batch loss: 0.076233 Batch F1: 0.923076923076923
Epoch:  731        8 Batch loss: 0.059865 Batch F1: 0.9333333333333333
Epoch:  731        9 Batch loss: 0.059931 Batch F1: 0.9333333333333333
Epoch:  731       10 Batch loss: 0.054819 Batch F1: 0.5
Epoch:  731       11 Batch loss: 0.073200 Batch F1: 0.4
Epoch:  731       12 Batch loss: 0.072809 Batch F1: 0.2857142857142857
Train Avg Loss  731: 0.068336

Train Avg F1  731: 0.7034841928224282

Val Avg Loss  731: 0.065149

Val Avg F1  731:  0.6077200577200577

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 732
--------------------------------------------------------------
Epoch:  732        1 Batch loss: 0.062487 Batch F1: 0.7499999999999999
Epoch:  732        2 Batch loss: 0.067291 Batch F1: 0.7499999999999999
Epoch:  732        3 Batch loss: 0.070266 Batch F1: 0.9473684210526316
Epoch:  732        4 Batch loss: 0.090801 Batch F1: 0.8571428571428572
Epoch:  732        5 Batch loss: 0.073643 Batch F1: 0.7058823529411764
Epoch:  732        6 Batch loss: 0.036622 Batch F1: 0.8571428571428571
Epoch:  732        7 Batch loss: 0.063730 Batch F1: 0.6153846153846153
Epoch:  732        8 Batch loss: 0.054987 Batch F1: 0.2857142857142857
Epoch:  732        9 Batch loss: 0.105384 Batch F1: 0.2666666666666667
Epoch:  732       10 Batch loss: 0.070132 Batch F1: 0.5454545454545454
Epoch:  732       11 Batch loss: 0.074403 Batch F1: 0.8235294117647058
Epoch:  732       12 Batch loss: 0.071722 Batch F1: 0.7272727272727272
Train Avg Loss  732: 0.070122

Train Avg F1  732: 0.6776298950447557

Val Avg Loss  732: 0.065381

Val Avg F1  732:  0.9263808087337498

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 733
--------------------------------------------------------------
Epoch:  733        1 Batch loss: 0.053239 Batch F1: 1.0
Epoch:  733        2 Batch loss: 0.075193 Batch F1: 0.7999999999999999
Epoch:  733        3 Batch loss: 0.072553 Batch F1: 0.9166666666666666
Epoch:  733        4 Batch loss: 0.058368 Batch F1: 0.7142857142857143
Epoch:  733        5 Batch loss: 0.085265 Batch F1: 0.3636363636363636
Epoch:  733        6 Batch loss: 0.058035 Batch F1: 0.5
Epoch:  733        7 Batch loss: 0.109489 Batch F1: 0.5833333333333334
Epoch:  733        8 Batch loss: 0.048749 Batch F1: 0.9090909090909091
Epoch:  733        9 Batch loss: 0.095610 Batch F1: 0.7142857142857143
Epoch:  733       10 Batch loss: 0.061405 Batch F1: 0.923076923076923
Epoch:  733       11 Batch loss: 0.060202 Batch F1: 0.9
Epoch:  733       12 Batch loss: 0.057423 Batch F1: 0.7499999999999999
Train Avg Loss  733: 0.069628

Train Avg F1  733: 0.7561979686979687

Val Avg Loss  733: 0.066734

Val Avg F1  733:  0.5780042326094957

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 734
--------------------------------------------------------------
Epoch:  734        1 Batch loss: 0.062887 Batch F1: 0.6153846153846153
Epoch:  734        2 Batch loss: 0.038142 Batch F1: 0.8571428571428571
Epoch:  734        3 Batch loss: 0.074042 Batch F1: 0.5454545454545454
Epoch:  734        4 Batch loss: 0.054542 Batch F1: 0.6
Epoch:  734        5 Batch loss: 0.074965 Batch F1: 0.7499999999999999
Epoch:  734        6 Batch loss: 0.065853 Batch F1: 0.4
Epoch:  734        7 Batch loss: 0.048234 Batch F1: 0.9333333333333333
Epoch:  734        8 Batch loss: 0.076574 Batch F1: 0.625
Epoch:  734        9 Batch loss: 0.059279 Batch F1: 0.6666666666666666
Epoch:  734       10 Batch loss: 0.091644 Batch F1: 0.8148148148148148
Epoch:  734       11 Batch loss: 0.084266 Batch F1: 0.8421052631578948
Epoch:  734       12 Batch loss: 0.109934 Batch F1: 0.8421052631578948
Train Avg Loss  734: 0.070030

Train Avg F1  734: 0.7076672799260519

Val Avg Loss  734: 0.066143

Val Avg F1  734:  0.9105077928607341

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 735
--------------------------------------------------------------
Epoch:  735        1 Batch loss: 0.058132 Batch F1: 1.0
Epoch:  735        2 Batch loss: 0.092891 Batch F1: 0.7368421052631579
Epoch:  735        3 Batch loss: 0.044499 Batch F1: 0.9090909090909091
Epoch:  735        4 Batch loss: 0.055186 Batch F1: 0.6666666666666666
Epoch:  735        5 Batch loss: 0.078247 Batch F1: 0.625
Epoch:  735        6 Batch loss: 0.090607 Batch F1: 0.42857142857142855
Epoch:  735        7 Batch loss: 0.073350 Batch F1: 0.9090909090909091
Epoch:  735        8 Batch loss: 0.074463 Batch F1: 0.8333333333333333
Epoch:  735        9 Batch loss: 0.069117 Batch F1: 0.9411764705882353
Epoch:  735       10 Batch loss: 0.067747 Batch F1: 0.8
Epoch:  735       11 Batch loss: 0.086322 Batch F1: 0.5
Epoch:  735       12 Batch loss: 0.054073 Batch F1: 0.33333333333333337
Train Avg Loss  735: 0.070386

Train Avg F1  735: 0.7235920963281646

Val Avg Loss  735: 0.066757

Val Avg F1  735:  0.6140522875816994

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 736
--------------------------------------------------------------
Epoch:  736        1 Batch loss: 0.084737 Batch F1: 0.782608695652174
Epoch:  736        2 Batch loss: 0.059401 Batch F1: 0.75
Epoch:  736        3 Batch loss: 0.060798 Batch F1: 0.8750000000000001
Epoch:  736        4 Batch loss: 0.072976 Batch F1: 0.7272727272727273
Epoch:  736        5 Batch loss: 0.082819 Batch F1: 0.8181818181818181
Epoch:  736        6 Batch loss: 0.070792 Batch F1: 0.9600000000000001
Epoch:  736        7 Batch loss: 0.064522 Batch F1: 0.7272727272727272
Epoch:  736        8 Batch loss: 0.052288 Batch F1: 0.6
Epoch:  736        9 Batch loss: 0.071957 Batch F1: 0.5333333333333333
Epoch:  736       10 Batch loss: 0.064611 Batch F1: 0.5
Epoch:  736       11 Batch loss: 0.067945 Batch F1: 0.6
Epoch:  736       12 Batch loss: 0.080049 Batch F1: 0.5454545454545454
Train Avg Loss  736: 0.069408

Train Avg F1  736: 0.7015936539306105

Val Avg Loss  736: 0.066810

Val Avg F1  736:  0.7777777777777777

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 737
--------------------------------------------------------------
Epoch:  737        1 Batch loss: 0.071186 Batch F1: 0.6
Epoch:  737        2 Batch loss: 0.058247 Batch F1: 0.8333333333333333
Epoch:  737        3 Batch loss: 0.075142 Batch F1: 0.8
Epoch:  737        4 Batch loss: 0.068283 Batch F1: 0.9523809523809523
Epoch:  737        5 Batch loss: 0.069639 Batch F1: 0.9090909090909091
Epoch:  737        6 Batch loss: 0.059151 Batch F1: 1.0
Epoch:  737        7 Batch loss: 0.074438 Batch F1: 0.7777777777777778
Epoch:  737        8 Batch loss: 0.052559 Batch F1: 0.9333333333333333
Epoch:  737        9 Batch loss: 0.066196 Batch F1: 0.8235294117647058
Epoch:  737       10 Batch loss: 0.056487 Batch F1: 0.2857142857142857
Epoch:  737       11 Batch loss: 0.076879 Batch F1: 0.6666666666666667
Epoch:  737       12 Batch loss: 0.094175 Batch F1: 0.8571428571428572
Train Avg Loss  737: 0.068532

Train Avg F1  737: 0.7865807939337351

Val Avg Loss  737: 0.067402

Val Avg F1  737:  0.9047619047619048

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 738
--------------------------------------------------------------
Epoch:  738        1 Batch loss: 0.054108 Batch F1: 0.888888888888889
Epoch:  738        2 Batch loss: 0.069221 Batch F1: 0.6666666666666665
Epoch:  738        3 Batch loss: 0.079119 Batch F1: 0.7368421052631579
Epoch:  738        4 Batch loss: 0.098840 Batch F1: 0.8
Epoch:  738        5 Batch loss: 0.062981 Batch F1: 0.8
Epoch:  738        6 Batch loss: 0.095498 Batch F1: 0.8333333333333333
Epoch:  738        7 Batch loss: 0.048527 Batch F1: 0.5
Epoch:  738        8 Batch loss: 0.054448 Batch F1: 0.7272727272727273
Epoch:  738        9 Batch loss: 0.046602 Batch F1: 0.7499999999999999
Epoch:  738       10 Batch loss: 0.073725 Batch F1: 0.7058823529411764
Epoch:  738       11 Batch loss: 0.096121 Batch F1: 0.375
Epoch:  738       12 Batch loss: 0.069522 Batch F1: 0.7142857142857143
Train Avg Loss  738: 0.070726

Train Avg F1  738: 0.7081809823876387

Val Avg Loss  738: 0.065026

Val Avg F1  738:  0.8786507610037021

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 739
--------------------------------------------------------------
Epoch:  739        1 Batch loss: 0.089157 Batch F1: 0.8181818181818181
Epoch:  739        2 Batch loss: 0.065584 Batch F1: 0.923076923076923
Epoch:  739        3 Batch loss: 0.061641 Batch F1: 0.8571428571428571
Epoch:  739        4 Batch loss: 0.093124 Batch F1: 0.6
Epoch:  739        5 Batch loss: 0.051632 Batch F1: 0.5
Epoch:  739        6 Batch loss: 0.061246 Batch F1: 0.2857142857142857
Epoch:  739        7 Batch loss: 0.092550 Batch F1: 0.625
Epoch:  739        8 Batch loss: 0.059395 Batch F1: 0.5454545454545454
Epoch:  739        9 Batch loss: 0.068878 Batch F1: 0.7777777777777778
Epoch:  739       10 Batch loss: 0.064536 Batch F1: 0.7142857142857143
Epoch:  739       11 Batch loss: 0.068029 Batch F1: 0.9655172413793104
Epoch:  739       12 Batch loss: 0.071173 Batch F1: 1.0
Train Avg Loss  739: 0.070579

Train Avg F1  739: 0.7176792635844359

Val Avg Loss  739: 0.067235

Val Avg F1  739:  0.8648601398601399

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 740
--------------------------------------------------------------
Epoch:  740        1 Batch loss: 0.083370 Batch F1: 0.9090909090909091
Epoch:  740        2 Batch loss: 0.067026 Batch F1: 0.25
Epoch:  740        3 Batch loss: 0.099340 Batch F1: 0.2666666666666667
Epoch:  740        4 Batch loss: 0.067012 Batch F1: 0.9565217391304348
Epoch:  740        5 Batch loss: 0.093254 Batch F1: 0.7058823529411764
Epoch:  740        6 Batch loss: 0.057953 Batch F1: 1.0
Epoch:  740        7 Batch loss: 0.062290 Batch F1: 0.8333333333333333
Epoch:  740        8 Batch loss: 0.060287 Batch F1: 0.9090909090909091
Epoch:  740        9 Batch loss: 0.062194 Batch F1: 0.888888888888889
Epoch:  740       10 Batch loss: 0.055371 Batch F1: 0.6
Epoch:  740       11 Batch loss: 0.060486 Batch F1: 0.25
Epoch:  740       12 Batch loss: 0.076805 Batch F1: 0.6666666666666666
Train Avg Loss  740: 0.070449

Train Avg F1  740: 0.6863451221507487

Val Avg Loss  740: 0.066264

Val Avg F1  740:  0.6142857142857143

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 741
--------------------------------------------------------------
Epoch:  741        1 Batch loss: 0.077256 Batch F1: 0.625
Epoch:  741        2 Batch loss: 0.057428 Batch F1: 0.8
Epoch:  741        3 Batch loss: 0.063438 Batch F1: 1.0
Epoch:  741        4 Batch loss: 0.089286 Batch F1: 0.8421052631578948
Epoch:  741        5 Batch loss: 0.079454 Batch F1: 0.8235294117647058
Epoch:  741        6 Batch loss: 0.060071 Batch F1: 0.6666666666666666
Epoch:  741        7 Batch loss: 0.075120 Batch F1: 0.5
Epoch:  741        8 Batch loss: 0.079188 Batch F1: 0.5
Epoch:  741        9 Batch loss: 0.063440 Batch F1: 0.875
Epoch:  741       10 Batch loss: 0.071850 Batch F1: 0.888888888888889
Epoch:  741       11 Batch loss: 0.050889 Batch F1: 0.8
Epoch:  741       12 Batch loss: 0.082959 Batch F1: 0.5882352941176471
Train Avg Loss  741: 0.070865

Train Avg F1  741: 0.7424521270496504

Val Avg Loss  741: 0.063760

Val Avg F1  741:  0.7722222222222223

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 742
--------------------------------------------------------------
Epoch:  742        1 Batch loss: 0.061641 Batch F1: 0.7272727272727273
Epoch:  742        2 Batch loss: 0.091784 Batch F1: 0.16666666666666669
Epoch:  742        3 Batch loss: 0.049612 Batch F1: 0.923076923076923
Epoch:  742        4 Batch loss: 0.076487 Batch F1: 0.8148148148148148
Epoch:  742        5 Batch loss: 0.069586 Batch F1: 0.6666666666666666
Epoch:  742        6 Batch loss: 0.067261 Batch F1: 0.8
Epoch:  742        7 Batch loss: 0.091386 Batch F1: 0.782608695652174
Epoch:  742        8 Batch loss: 0.076453 Batch F1: 0.888888888888889
Epoch:  742        9 Batch loss: 0.065054 Batch F1: 0.9473684210526316
Epoch:  742       10 Batch loss: 0.060462 Batch F1: 0.8333333333333333
Epoch:  742       11 Batch loss: 0.067729 Batch F1: 1.0
Epoch:  742       12 Batch loss: 0.045840 Batch F1: 1.0
Train Avg Loss  742: 0.068608

Train Avg F1  742: 0.7958914281187356

Val Avg Loss  742: 0.063781

Val Avg F1  742:  0.859632509303562

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 743
--------------------------------------------------------------
Epoch:  743        1 Batch loss: 0.084893 Batch F1: 0.5454545454545454
Epoch:  743        2 Batch loss: 0.085100 Batch F1: 0.5
Epoch:  743        3 Batch loss: 0.086240 Batch F1: 0.5333333333333333
Epoch:  743        4 Batch loss: 0.074617 Batch F1: 0.5882352941176471
Epoch:  743        5 Batch loss: 0.065910 Batch F1: 0.9333333333333333
Epoch:  743        6 Batch loss: 0.053508 Batch F1: 1.0
Epoch:  743        7 Batch loss: 0.071816 Batch F1: 0.9090909090909091
Epoch:  743        8 Batch loss: 0.050625 Batch F1: 0.9090909090909091
Epoch:  743        9 Batch loss: 0.060132 Batch F1: 0.7142857142857143
Epoch:  743       10 Batch loss: 0.058217 Batch F1: 0.7499999999999999
Epoch:  743       11 Batch loss: 0.074890 Batch F1: 0.18181818181818182
Epoch:  743       12 Batch loss: 0.060057 Batch F1: 0.8333333333333333
Train Avg Loss  743: 0.068834

Train Avg F1  743: 0.6998312961548256

Val Avg Loss  743: 0.063546

Val Avg F1  743:  0.8264705882352941

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 744
--------------------------------------------------------------
Epoch:  744        1 Batch loss: 0.082928 Batch F1: 0.8181818181818181
Epoch:  744        2 Batch loss: 0.072958 Batch F1: 0.7692307692307693
Epoch:  744        3 Batch loss: 0.060460 Batch F1: 1.0
Epoch:  744        4 Batch loss: 0.062835 Batch F1: 0.9090909090909091
Epoch:  744        5 Batch loss: 0.080476 Batch F1: 0.6666666666666666
Epoch:  744        6 Batch loss: 0.042937 Batch F1: 0.9090909090909091
Epoch:  744        7 Batch loss: 0.044865 Batch F1: 0.6666666666666666
Epoch:  744        8 Batch loss: 0.075728 Batch F1: 0.7368421052631579
Epoch:  744        9 Batch loss: 0.074621 Batch F1: 0.6153846153846153
Epoch:  744       10 Batch loss: 0.057183 Batch F1: 0.8
Epoch:  744       11 Batch loss: 0.077027 Batch F1: 0.7058823529411764
Epoch:  744       12 Batch loss: 0.083896 Batch F1: 0.7499999999999999
Train Avg Loss  744: 0.067993

Train Avg F1  744: 0.7789197343763906

Val Avg Loss  744: 0.064175

Val Avg F1  744:  0.9315584415584416

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 745
--------------------------------------------------------------
Epoch:  745        1 Batch loss: 0.055924 Batch F1: 0.8333333333333333
Epoch:  745        2 Batch loss: 0.065789 Batch F1: 0.9473684210526316
Epoch:  745        3 Batch loss: 0.061976 Batch F1: 0.8
Epoch:  745        4 Batch loss: 0.052794 Batch F1: 0.888888888888889
Epoch:  745        5 Batch loss: 0.079891 Batch F1: 0.9600000000000001
Epoch:  745        6 Batch loss: 0.078821 Batch F1: 0.8
Epoch:  745        7 Batch loss: 0.074278 Batch F1: 0.7058823529411764
Epoch:  745        8 Batch loss: 0.057864 Batch F1: 0.7272727272727273
Epoch:  745        9 Batch loss: 0.070068 Batch F1: 1.0
Epoch:  745       10 Batch loss: 0.067423 Batch F1: 0.8421052631578948
Epoch:  745       11 Batch loss: 0.086540 Batch F1: 0.19999999999999998
Epoch:  745       12 Batch loss: 0.069765 Batch F1: 0.7058823529411764
Train Avg Loss  745: 0.068428

Train Avg F1  745: 0.7842277782989857

Val Avg Loss  745: 0.063001

Val Avg F1  745:  0.6526610644257702

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 746
--------------------------------------------------------------
Epoch:  746        1 Batch loss: 0.064367 Batch F1: 0.6
Epoch:  746        2 Batch loss: 0.039760 Batch F1: 1.0
Epoch:  746        3 Batch loss: 0.060830 Batch F1: 0.5454545454545454
Epoch:  746        4 Batch loss: 0.088132 Batch F1: 0.5882352941176471
Epoch:  746        5 Batch loss: 0.065649 Batch F1: 0.5
Epoch:  746        6 Batch loss: 0.061658 Batch F1: 0.8421052631578948
Epoch:  746        7 Batch loss: 0.071060 Batch F1: 0.6153846153846153
Epoch:  746        8 Batch loss: 0.066644 Batch F1: 0.7142857142857143
Epoch:  746        9 Batch loss: 0.076990 Batch F1: 0.9
Epoch:  746       10 Batch loss: 0.064768 Batch F1: 1.0
Epoch:  746       11 Batch loss: 0.067799 Batch F1: 0.8571428571428571
Epoch:  746       12 Batch loss: 0.082047 Batch F1: 0.9523809523809523
Train Avg Loss  746: 0.067475

Train Avg F1  746: 0.759582436827019

Val Avg Loss  746: 0.062913

Val Avg F1  746:  0.882748538011696

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 747
--------------------------------------------------------------
Epoch:  747        1 Batch loss: 0.045908 Batch F1: 0.9333333333333333
Epoch:  747        2 Batch loss: 0.078648 Batch F1: 0.8421052631578948
Epoch:  747        3 Batch loss: 0.065246 Batch F1: 0.8421052631578948
Epoch:  747        4 Batch loss: 0.057597 Batch F1: 0.888888888888889
Epoch:  747        5 Batch loss: 0.080041 Batch F1: 0.9166666666666666
Epoch:  747        6 Batch loss: 0.061489 Batch F1: 1.0
Epoch:  747        7 Batch loss: 0.056516 Batch F1: 0.9090909090909091
Epoch:  747        8 Batch loss: 0.060000 Batch F1: 0.6666666666666666
Epoch:  747        9 Batch loss: 0.087275 Batch F1: 0.42857142857142855
Epoch:  747       10 Batch loss: 0.074018 Batch F1: 0.6666666666666666
Epoch:  747       11 Batch loss: 0.075180 Batch F1: 0.4615384615384615
Epoch:  747       12 Batch loss: 0.080854 Batch F1: 0.6666666666666666
Train Avg Loss  747: 0.068564

Train Avg F1  747: 0.7685250178671231

Val Avg Loss  747: 0.064570

Val Avg F1  747:  0.8414134884723119

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 748
--------------------------------------------------------------
Epoch:  748        1 Batch loss: 0.067034 Batch F1: 1.0
Epoch:  748        2 Batch loss: 0.068802 Batch F1: 0.9473684210526316
Epoch:  748        3 Batch loss: 0.072558 Batch F1: 0.9473684210526316
Epoch:  748        4 Batch loss: 0.058184 Batch F1: 0.8
Epoch:  748        5 Batch loss: 0.084549 Batch F1: 0.3076923076923077
Epoch:  748        6 Batch loss: 0.062253 Batch F1: 0.5454545454545454
Epoch:  748        7 Batch loss: 0.072280 Batch F1: 0.9473684210526316
Epoch:  748        8 Batch loss: 0.064194 Batch F1: 1.0
Epoch:  748        9 Batch loss: 0.073569 Batch F1: 0.9090909090909091
Epoch:  748       10 Batch loss: 0.073096 Batch F1: 0.8421052631578948
Epoch:  748       11 Batch loss: 0.063807 Batch F1: 0.8
Epoch:  748       12 Batch loss: 0.069798 Batch F1: 0.7272727272727273
Train Avg Loss  748: 0.069177

Train Avg F1  748: 0.8144767513188566

Val Avg Loss  748: 0.066418

Val Avg F1  748:  0.5993872549019608

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 749
--------------------------------------------------------------
Epoch:  749        1 Batch loss: 0.071855 Batch F1: 0.6666666666666666
Epoch:  749        2 Batch loss: 0.065353 Batch F1: 0.8
Epoch:  749        3 Batch loss: 0.078866 Batch F1: 0.8235294117647058
Epoch:  749        4 Batch loss: 0.061874 Batch F1: 0.9090909090909091
Epoch:  749        5 Batch loss: 0.102374 Batch F1: 0.18181818181818182
Epoch:  749        6 Batch loss: 0.061499 Batch F1: 0.4444444444444445
Epoch:  749        7 Batch loss: 0.087043 Batch F1: 0.33333333333333337
Epoch:  749        8 Batch loss: 0.074760 Batch F1: 0.3636363636363636
Epoch:  749        9 Batch loss: 0.059101 Batch F1: 1.0
Epoch:  749       10 Batch loss: 0.054490 Batch F1: 0.7272727272727273
Epoch:  749       11 Batch loss: 0.082548 Batch F1: 0.8421052631578948
Epoch:  749       12 Batch loss: 0.061299 Batch F1: 1.0
Train Avg Loss  749: 0.071755

Train Avg F1  749: 0.674324775098769

Val Avg Loss  749: 0.065420

Val Avg F1  749:  0.8801039646627882

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 750
--------------------------------------------------------------
Epoch:  750        1 Batch loss: 0.081926 Batch F1: 0.7777777777777778
Epoch:  750        2 Batch loss: 0.052834 Batch F1: 0.8000000000000002
Epoch:  750        3 Batch loss: 0.054586 Batch F1: 0.6
Epoch:  750        4 Batch loss: 0.071267 Batch F1: 0.6666666666666666
Epoch:  750        5 Batch loss: 0.069976 Batch F1: 0.6153846153846153
Epoch:  750        6 Batch loss: 0.060965 Batch F1: 0.6
Epoch:  750        7 Batch loss: 0.077038 Batch F1: 0.625
Epoch:  750        8 Batch loss: 0.073475 Batch F1: 0.888888888888889
Epoch:  750        9 Batch loss: 0.079732 Batch F1: 1.0
Epoch:  750       10 Batch loss: 0.061340 Batch F1: 0.8750000000000001
Epoch:  750       11 Batch loss: 0.078322 Batch F1: 0.8235294117647058
Epoch:  750       12 Batch loss: 0.062375 Batch F1: 0.7272727272727273
Train Avg Loss  750: 0.068653

Train Avg F1  750: 0.7499600073129485

Val Avg Loss  750: 0.064227

Val Avg F1  750:  0.6349547511312217

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 751
--------------------------------------------------------------
Epoch:  751        1 Batch loss: 0.056693 Batch F1: 0.25
Epoch:  751        2 Batch loss: 0.067421 Batch F1: 0.7499999999999999
Epoch:  751        3 Batch loss: 0.057708 Batch F1: 0.9411764705882353
Epoch:  751        4 Batch loss: 0.087972 Batch F1: 0.8571428571428572
Epoch:  751        5 Batch loss: 0.079060 Batch F1: 0.8421052631578948
Epoch:  751        6 Batch loss: 0.071861 Batch F1: 0.9
Epoch:  751        7 Batch loss: 0.085999 Batch F1: 0.846153846153846
Epoch:  751        8 Batch loss: 0.081479 Batch F1: 0.888888888888889
Epoch:  751        9 Batch loss: 0.055290 Batch F1: 0.7272727272727273
Epoch:  751       10 Batch loss: 0.047891 Batch F1: 0.6
Epoch:  751       11 Batch loss: 0.067228 Batch F1: 0.6
Epoch:  751       12 Batch loss: 0.067761 Batch F1: 0.4444444444444445
Train Avg Loss  751: 0.068863

Train Avg F1  751: 0.7205987081374078

Val Avg Loss  751: 0.069860

Val Avg F1  751:  0.5944805194805195

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 752
--------------------------------------------------------------
Epoch:  752        1 Batch loss: 0.053635 Batch F1: 0.6666666666666666
Epoch:  752        2 Batch loss: 0.070449 Batch F1: 0.7272727272727273
Epoch:  752        3 Batch loss: 0.066134 Batch F1: 0.9333333333333333
Epoch:  752        4 Batch loss: 0.082314 Batch F1: 0.88
Epoch:  752        5 Batch loss: 0.081546 Batch F1: 0.888888888888889
Epoch:  752        6 Batch loss: 0.061530 Batch F1: 0.9411764705882353
Epoch:  752        7 Batch loss: 0.066463 Batch F1: 1.0
Epoch:  752        8 Batch loss: 0.079756 Batch F1: 0.4
Epoch:  752        9 Batch loss: 0.095813 Batch F1: 0.625
Epoch:  752       10 Batch loss: 0.078355 Batch F1: 0.923076923076923
Epoch:  752       11 Batch loss: 0.064029 Batch F1: 0.6666666666666665
Epoch:  752       12 Batch loss: 0.099950 Batch F1: 0.2222222222222222
Train Avg Loss  752: 0.074998

Train Avg F1  752: 0.739525324892972

Val Avg Loss  752: 0.095724

Val Avg F1  752:  0.0

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 753
--------------------------------------------------------------
Epoch:  753        1 Batch loss: 0.099264 Batch F1: 0.0
Epoch:  753        2 Batch loss: 0.049715 Batch F1: 0.4444444444444445
Epoch:  753        3 Batch loss: 0.081481 Batch F1: 0.5333333333333333
Epoch:  753        4 Batch loss: 0.096466 Batch F1: 0.782608695652174
Epoch:  753        5 Batch loss: 0.095791 Batch F1: 0.47058823529411764
Epoch:  753        6 Batch loss: 0.046958 Batch F1: 0.8
Epoch:  753        7 Batch loss: 0.061182 Batch F1: 0.7692307692307693
Epoch:  753        8 Batch loss: 0.105442 Batch F1: 0.3076923076923077
Epoch:  753        9 Batch loss: 0.064368 Batch F1: 0.5
Epoch:  753       10 Batch loss: 0.056771 Batch F1: 0.7142857142857143
Epoch:  753       11 Batch loss: 0.082670 Batch F1: 0.8181818181818181
Epoch:  753       12 Batch loss: 0.055030 Batch F1: 0.9090909090909091
Train Avg Loss  753: 0.074595

Train Avg F1  753: 0.5874546856004657

Val Avg Loss  753: 0.063357

Val Avg F1  753:  0.8138917004048584

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 754
--------------------------------------------------------------
Epoch:  754        1 Batch loss: 0.083251 Batch F1: 0.7499999999999999
Epoch:  754        2 Batch loss: 0.088310 Batch F1: 0.8
Epoch:  754        3 Batch loss: 0.062317 Batch F1: 0.7142857142857143
Epoch:  754        4 Batch loss: 0.077063 Batch F1: 0.625
Epoch:  754        5 Batch loss: 0.062003 Batch F1: 0.9473684210526316
Epoch:  754        6 Batch loss: 0.060849 Batch F1: 0.8
Epoch:  754        7 Batch loss: 0.061741 Batch F1: 0.9523809523809523
Epoch:  754        8 Batch loss: 0.065355 Batch F1: 1.0
Epoch:  754        9 Batch loss: 0.063798 Batch F1: 0.923076923076923
Epoch:  754       10 Batch loss: 0.070067 Batch F1: 0.7692307692307693
Epoch:  754       11 Batch loss: 0.052159 Batch F1: 0.8750000000000001
Epoch:  754       12 Batch loss: 0.081848 Batch F1: 0.4444444444444445
Train Avg Loss  754: 0.069063

Train Avg F1  754: 0.8000656020392863

Val Avg Loss  754: 0.067508

Val Avg F1  754:  0.61875

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 755
--------------------------------------------------------------
Epoch:  755        1 Batch loss: 0.059261 Batch F1: 0.6
Epoch:  755        2 Batch loss: 0.061306 Batch F1: 0.4
Epoch:  755        3 Batch loss: 0.073211 Batch F1: 0.4615384615384615
Epoch:  755        4 Batch loss: 0.071448 Batch F1: 0.5714285714285715
Epoch:  755        5 Batch loss: 0.060459 Batch F1: 0.8
Epoch:  755        6 Batch loss: 0.094465 Batch F1: 0.8695652173913044
Epoch:  755        7 Batch loss: 0.078071 Batch F1: 0.9523809523809523
Epoch:  755        8 Batch loss: 0.052378 Batch F1: 1.0
Epoch:  755        9 Batch loss: 0.060722 Batch F1: 0.923076923076923
Epoch:  755       10 Batch loss: 0.067022 Batch F1: 0.7499999999999999
Epoch:  755       11 Batch loss: 0.068115 Batch F1: 0.6666666666666666
Epoch:  755       12 Batch loss: 0.073611 Batch F1: 0.6153846153846153
Train Avg Loss  755: 0.068339

Train Avg F1  755: 0.7175034506556246

Val Avg Loss  755: 0.064894

Val Avg F1  755:  0.8232157097288676

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 756
--------------------------------------------------------------
Epoch:  756        1 Batch loss: 0.063601 Batch F1: 0.6666666666666666
Epoch:  756        2 Batch loss: 0.079767 Batch F1: 0.9565217391304348
Epoch:  756        3 Batch loss: 0.083189 Batch F1: 0.9565217391304348
Epoch:  756        4 Batch loss: 0.074001 Batch F1: 0.8571428571428571
Epoch:  756        5 Batch loss: 0.058584 Batch F1: 0.9473684210526316
Epoch:  756        6 Batch loss: 0.056887 Batch F1: 0.5
Epoch:  756        7 Batch loss: 0.085112 Batch F1: 0.5882352941176471
Epoch:  756        8 Batch loss: 0.070880 Batch F1: 0.5454545454545454
Epoch:  756        9 Batch loss: 0.064951 Batch F1: 0.5714285714285715
Epoch:  756       10 Batch loss: 0.090919 Batch F1: 0.4615384615384615
Epoch:  756       11 Batch loss: 0.065423 Batch F1: 0.7368421052631579
Epoch:  756       12 Batch loss: 0.049608 Batch F1: 0.8
Train Avg Loss  756: 0.070244

Train Avg F1  756: 0.7156433667437839

Val Avg Loss  756: 0.064607

Val Avg F1  756:  0.6243818681318681

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 757
--------------------------------------------------------------
Epoch:  757        1 Batch loss: 0.051005 Batch F1: 0.5
Epoch:  757        2 Batch loss: 0.040612 Batch F1: 0.9090909090909091
Epoch:  757        3 Batch loss: 0.046791 Batch F1: 0.6666666666666666
Epoch:  757        4 Batch loss: 0.097206 Batch F1: 0.375
Epoch:  757        5 Batch loss: 0.094111 Batch F1: 0.5
Epoch:  757        6 Batch loss: 0.062855 Batch F1: 0.8750000000000001
Epoch:  757        7 Batch loss: 0.083872 Batch F1: 0.9166666666666666
Epoch:  757        8 Batch loss: 0.071717 Batch F1: 0.923076923076923
Epoch:  757        9 Batch loss: 0.064818 Batch F1: 0.9333333333333333
Epoch:  757       10 Batch loss: 0.087870 Batch F1: 0.761904761904762
Epoch:  757       11 Batch loss: 0.072152 Batch F1: 0.8235294117647058
Epoch:  757       12 Batch loss: 0.057330 Batch F1: 1.0
Train Avg Loss  757: 0.069195

Train Avg F1  757: 0.7653557227086639

Val Avg Loss  757: 0.065644

Val Avg F1  757:  0.6010989010989011

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 758
--------------------------------------------------------------
Epoch:  758        1 Batch loss: 0.083503 Batch F1: 0.631578947368421
Epoch:  758        2 Batch loss: 0.065317 Batch F1: 0.6666666666666666
Epoch:  758        3 Batch loss: 0.098771 Batch F1: 0.18181818181818182
Epoch:  758        4 Batch loss: 0.057104 Batch F1: 0.6
Epoch:  758        5 Batch loss: 0.060350 Batch F1: 0.7142857142857143
Epoch:  758        6 Batch loss: 0.080982 Batch F1: 0.8421052631578948
Epoch:  758        7 Batch loss: 0.077839 Batch F1: 0.7142857142857143
Epoch:  758        8 Batch loss: 0.066900 Batch F1: 0.9090909090909091
Epoch:  758        9 Batch loss: 0.068217 Batch F1: 0.5
Epoch:  758       10 Batch loss: 0.055640 Batch F1: 0.6
Epoch:  758       11 Batch loss: 0.058186 Batch F1: 0.5454545454545454
Epoch:  758       12 Batch loss: 0.083359 Batch F1: 0.5
Train Avg Loss  758: 0.071347

Train Avg F1  758: 0.6171071618440039

Val Avg Loss  758: 0.064519

Val Avg F1  758:  0.6237179487179487

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 759
--------------------------------------------------------------
Epoch:  759        1 Batch loss: 0.078722 Batch F1: 0.4615384615384615
Epoch:  759        2 Batch loss: 0.062576 Batch F1: 0.6666666666666666
Epoch:  759        3 Batch loss: 0.077968 Batch F1: 0.8750000000000001
Epoch:  759        4 Batch loss: 0.051572 Batch F1: 1.0
Epoch:  759        5 Batch loss: 0.076435 Batch F1: 0.9565217391304348
Epoch:  759        6 Batch loss: 0.047698 Batch F1: 1.0
Epoch:  759        7 Batch loss: 0.082380 Batch F1: 0.631578947368421
Epoch:  759        8 Batch loss: 0.056367 Batch F1: 0.5
Epoch:  759        9 Batch loss: 0.050020 Batch F1: 0.6
Epoch:  759       10 Batch loss: 0.059093 Batch F1: 0.9
Epoch:  759       11 Batch loss: 0.100395 Batch F1: 0.7000000000000001
Epoch:  759       12 Batch loss: 0.075750 Batch F1: 0.9333333333333333
Train Avg Loss  759: 0.068248

Train Avg F1  759: 0.7687199290031098

Val Avg Loss  759: 0.062824

Val Avg F1  759:  0.7606060606060605

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 760
--------------------------------------------------------------
Epoch:  760        1 Batch loss: 0.076575 Batch F1: 0.88
Epoch:  760        2 Batch loss: 0.059389 Batch F1: 0.888888888888889
Epoch:  760        3 Batch loss: 0.046781 Batch F1: 0.33333333333333337
Epoch:  760        4 Batch loss: 0.071257 Batch F1: 0.6153846153846153
Epoch:  760        5 Batch loss: 0.076167 Batch F1: 0.631578947368421
Epoch:  760        6 Batch loss: 0.057307 Batch F1: 0.888888888888889
Epoch:  760        7 Batch loss: 0.067996 Batch F1: 0.6666666666666666
Epoch:  760        8 Batch loss: 0.058188 Batch F1: 0.888888888888889
Epoch:  760        9 Batch loss: 0.060882 Batch F1: 0.5454545454545454
Epoch:  760       10 Batch loss: 0.071757 Batch F1: 0.2222222222222222
Epoch:  760       11 Batch loss: 0.101972 Batch F1: 0.2666666666666667
Epoch:  760       12 Batch loss: 0.062502 Batch F1: 0.7272727272727273
Train Avg Loss  760: 0.067564

Train Avg F1  760: 0.6296038659196556

Val Avg Loss  760: 0.063739

Val Avg F1  760:  0.7834429824561404

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 761
--------------------------------------------------------------
Epoch:  761        1 Batch loss: 0.057441 Batch F1: 0.7272727272727273
Epoch:  761        2 Batch loss: 0.067551 Batch F1: 0.8750000000000001
Epoch:  761        3 Batch loss: 0.048249 Batch F1: 0.8333333333333333
Epoch:  761        4 Batch loss: 0.044681 Batch F1: 0.923076923076923
Epoch:  761        5 Batch loss: 0.093923 Batch F1: 0.8571428571428571
Epoch:  761        6 Batch loss: 0.087321 Batch F1: 0.8181818181818182
Epoch:  761        7 Batch loss: 0.048593 Batch F1: 1.0
Epoch:  761        8 Batch loss: 0.080107 Batch F1: 0.8695652173913044
Epoch:  761        9 Batch loss: 0.098660 Batch F1: 0.8181818181818182
Epoch:  761       10 Batch loss: 0.058230 Batch F1: 0.8333333333333333
Epoch:  761       11 Batch loss: 0.065854 Batch F1: 0.8571428571428571
Epoch:  761       12 Batch loss: 0.066965 Batch F1: 0.8571428571428571
Train Avg Loss  761: 0.068131

Train Avg F1  761: 0.8557811451833192

Val Avg Loss  761: 0.064583

Val Avg F1  761:  0.6181984681984681

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 762
--------------------------------------------------------------
Epoch:  762        1 Batch loss: 0.062696 Batch F1: 0.6153846153846153
Epoch:  762        2 Batch loss: 0.076399 Batch F1: 0.5333333333333333
Epoch:  762        3 Batch loss: 0.069626 Batch F1: 0.6153846153846153
Epoch:  762        4 Batch loss: 0.093806 Batch F1: 0.631578947368421
Epoch:  762        5 Batch loss: 0.065847 Batch F1: 0.9333333333333333
Epoch:  762        6 Batch loss: 0.064634 Batch F1: 1.0
Epoch:  762        7 Batch loss: 0.060888 Batch F1: 0.9
Epoch:  762        8 Batch loss: 0.069002 Batch F1: 0.888888888888889
Epoch:  762        9 Batch loss: 0.059146 Batch F1: 0.8571428571428571
Epoch:  762       10 Batch loss: 0.054832 Batch F1: 1.0
Epoch:  762       11 Batch loss: 0.068029 Batch F1: 0.8750000000000001
Epoch:  762       12 Batch loss: 0.064561 Batch F1: 0.8333333333333333
Train Avg Loss  762: 0.067455

Train Avg F1  762: 0.8069483270141166

Val Avg Loss  762: 0.063498

Val Avg F1  762:  0.6255681818181817

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 763
--------------------------------------------------------------
Epoch:  763        1 Batch loss: 0.078836 Batch F1: 0.5333333333333333
Epoch:  763        2 Batch loss: 0.068102 Batch F1: 0.7142857142857143
Epoch:  763        3 Batch loss: 0.056824 Batch F1: 0.6666666666666666
Epoch:  763        4 Batch loss: 0.061911 Batch F1: 0.7058823529411764
Epoch:  763        5 Batch loss: 0.059431 Batch F1: 0.7692307692307693
Epoch:  763        6 Batch loss: 0.062789 Batch F1: 0.875
Epoch:  763        7 Batch loss: 0.063641 Batch F1: 0.8750000000000001
Epoch:  763        8 Batch loss: 0.067850 Batch F1: 0.5714285714285715
Epoch:  763        9 Batch loss: 0.069485 Batch F1: 0.5454545454545454
Epoch:  763       10 Batch loss: 0.076669 Batch F1: 0.4615384615384615
Epoch:  763       11 Batch loss: 0.088801 Batch F1: 0.4
Epoch:  763       12 Batch loss: 0.037153 Batch F1: 1.0
Train Avg Loss  763: 0.065958

Train Avg F1  763: 0.6764850345732699

Val Avg Loss  763: 0.062614

Val Avg F1  763:  0.6149572649572649

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 764
--------------------------------------------------------------
Epoch:  764        1 Batch loss: 0.071200 Batch F1: 0.5714285714285715
Epoch:  764        2 Batch loss: 0.046475 Batch F1: 0.5714285714285715
Epoch:  764        3 Batch loss: 0.070455 Batch F1: 0.4
Epoch:  764        4 Batch loss: 0.057761 Batch F1: 0.7142857142857143
Epoch:  764        5 Batch loss: 0.083929 Batch F1: 0.6666666666666666
Epoch:  764        6 Batch loss: 0.067242 Batch F1: 0.8333333333333333
Epoch:  764        7 Batch loss: 0.060955 Batch F1: 0.7692307692307693
Epoch:  764        8 Batch loss: 0.077585 Batch F1: 0.8235294117647058
Epoch:  764        9 Batch loss: 0.056397 Batch F1: 0.8
Epoch:  764       10 Batch loss: 0.075239 Batch F1: 0.888888888888889
Epoch:  764       11 Batch loss: 0.082969 Batch F1: 0.846153846153846
Epoch:  764       12 Batch loss: 0.063973 Batch F1: 1.0
Train Avg Loss  764: 0.067848

Train Avg F1  764: 0.7404121477650888

Val Avg Loss  764: 0.065741

Val Avg F1  764:  0.9220436000487152

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 765
--------------------------------------------------------------
Epoch:  765        1 Batch loss: 0.048730 Batch F1: 1.0
Epoch:  765        2 Batch loss: 0.065060 Batch F1: 0.8750000000000001
Epoch:  765        3 Batch loss: 0.066846 Batch F1: 0.8421052631578948
Epoch:  765        4 Batch loss: 0.067906 Batch F1: 0.8235294117647058
Epoch:  765        5 Batch loss: 0.062519 Batch F1: 0.888888888888889
Epoch:  765        6 Batch loss: 0.067563 Batch F1: 0.8235294117647058
Epoch:  765        7 Batch loss: 0.069275 Batch F1: 0.7499999999999999
Epoch:  765        8 Batch loss: 0.062599 Batch F1: 0.9473684210526316
Epoch:  765        9 Batch loss: 0.100018 Batch F1: 0.4615384615384615
Epoch:  765       10 Batch loss: 0.074190 Batch F1: 0.8571428571428571
Epoch:  765       11 Batch loss: 0.087335 Batch F1: 0.8235294117647058
Epoch:  765       12 Batch loss: 0.046215 Batch F1: 1.0
Train Avg Loss  765: 0.068188

Train Avg F1  765: 0.8410526772562377

Val Avg Loss  765: 0.064233

Val Avg F1  765:  0.5567226890756303

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 766
--------------------------------------------------------------
Epoch:  766        1 Batch loss: 0.116888 Batch F1: 0.4
Epoch:  766        2 Batch loss: 0.062540 Batch F1: 1.0
Epoch:  766        3 Batch loss: 0.069496 Batch F1: 1.0
Epoch:  766        4 Batch loss: 0.052511 Batch F1: 1.0
Epoch:  766        5 Batch loss: 0.069995 Batch F1: 0.7142857142857143
Epoch:  766        6 Batch loss: 0.070620 Batch F1: 0.5714285714285715
Epoch:  766        7 Batch loss: 0.080838 Batch F1: 0.625
Epoch:  766        8 Batch loss: 0.048137 Batch F1: 0.888888888888889
Epoch:  766        9 Batch loss: 0.070042 Batch F1: 0.8888888888888888
Epoch:  766       10 Batch loss: 0.092631 Batch F1: 0.7058823529411764
Epoch:  766       11 Batch loss: 0.040221 Batch F1: 0.8000000000000002
Epoch:  766       12 Batch loss: 0.050271 Batch F1: 0.8
Train Avg Loss  766: 0.068682

Train Avg F1  766: 0.7828645347027701

Val Avg Loss  766: 0.064620

Val Avg F1  766:  0.624107142857143

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 767
--------------------------------------------------------------
Epoch:  767        1 Batch loss: 0.046510 Batch F1: 0.6666666666666666
Epoch:  767        2 Batch loss: 0.051847 Batch F1: 0.5
Epoch:  767        3 Batch loss: 0.089733 Batch F1: 0.3076923076923077
Epoch:  767        4 Batch loss: 0.069334 Batch F1: 0.4444444444444445
Epoch:  767        5 Batch loss: 0.064709 Batch F1: 0.8235294117647058
Epoch:  767        6 Batch loss: 0.065624 Batch F1: 0.5454545454545454
Epoch:  767        7 Batch loss: 0.080715 Batch F1: 0.88
Epoch:  767        8 Batch loss: 0.084068 Batch F1: 0.9090909090909091
Epoch:  767        9 Batch loss: 0.070123 Batch F1: 0.9411764705882353
Epoch:  767       10 Batch loss: 0.062731 Batch F1: 0.9523809523809523
Epoch:  767       11 Batch loss: 0.073951 Batch F1: 0.8421052631578948
Epoch:  767       12 Batch loss: 0.070355 Batch F1: 1.0
Train Avg Loss  767: 0.069142

Train Avg F1  767: 0.7343784142700551

Val Avg Loss  767: 0.065917

Val Avg F1  767:  0.7826417004048583

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 768
--------------------------------------------------------------
Epoch:  768        1 Batch loss: 0.052620 Batch F1: 0.9473684210526316
Epoch:  768        2 Batch loss: 0.076435 Batch F1: 0.9166666666666666
Epoch:  768        3 Batch loss: 0.076033 Batch F1: 0.761904761904762
Epoch:  768        4 Batch loss: 0.046309 Batch F1: 1.0
Epoch:  768        5 Batch loss: 0.060740 Batch F1: 0.8333333333333333
Epoch:  768        6 Batch loss: 0.067378 Batch F1: 0.8333333333333333
Epoch:  768        7 Batch loss: 0.054557 Batch F1: 0.8333333333333333
Epoch:  768        8 Batch loss: 0.064881 Batch F1: 0.5
Epoch:  768        9 Batch loss: 0.084085 Batch F1: 0.5333333333333333
Epoch:  768       10 Batch loss: 0.094486 Batch F1: 0.8
Epoch:  768       11 Batch loss: 0.074397 Batch F1: 0.9333333333333333
Epoch:  768       12 Batch loss: 0.063934 Batch F1: 0.5
Train Avg Loss  768: 0.067988

Train Avg F1  768: 0.7827172096908939

Val Avg Loss  768: 0.070056

Val Avg F1  768:  0.5757575757575757

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 769
--------------------------------------------------------------
Epoch:  769        1 Batch loss: 0.079850 Batch F1: 0.5714285714285715
Epoch:  769        2 Batch loss: 0.071443 Batch F1: 0.8181818181818181
Epoch:  769        3 Batch loss: 0.064966 Batch F1: 0.888888888888889
Epoch:  769        4 Batch loss: 0.067829 Batch F1: 0.8571428571428571
Epoch:  769        5 Batch loss: 0.088614 Batch F1: 0.8421052631578948
Epoch:  769        6 Batch loss: 0.070839 Batch F1: 0.9090909090909091
Epoch:  769        7 Batch loss: 0.068078 Batch F1: 0.9565217391304348
Epoch:  769        8 Batch loss: 0.067548 Batch F1: 0.8
Epoch:  769        9 Batch loss: 0.047836 Batch F1: 0.6666666666666666
Epoch:  769       10 Batch loss: 0.063449 Batch F1: 0.6666666666666666
Epoch:  769       11 Batch loss: 0.065429 Batch F1: 0.5454545454545454
Epoch:  769       12 Batch loss: 0.080019 Batch F1: 0.6153846153846153
Train Avg Loss  769: 0.069658

Train Avg F1  769: 0.7614610450994891

Val Avg Loss  769: 0.064148

Val Avg F1  769:  0.7855614973262033

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 770
--------------------------------------------------------------
Epoch:  770        1 Batch loss: 0.072388 Batch F1: 0.8235294117647058
Epoch:  770        2 Batch loss: 0.050367 Batch F1: 0.8
Epoch:  770        3 Batch loss: 0.065564 Batch F1: 0.9473684210526316
Epoch:  770        4 Batch loss: 0.060383 Batch F1: 0.7692307692307693
Epoch:  770        5 Batch loss: 0.058207 Batch F1: 0.8
Epoch:  770        6 Batch loss: 0.089006 Batch F1: 0.7368421052631579
Epoch:  770        7 Batch loss: 0.093257 Batch F1: 0.7777777777777778
Epoch:  770        8 Batch loss: 0.095239 Batch F1: 0.7200000000000001
Epoch:  770        9 Batch loss: 0.048800 Batch F1: 1.0
Epoch:  770       10 Batch loss: 0.057315 Batch F1: 0.5
Epoch:  770       11 Batch loss: 0.070341 Batch F1: 0.6153846153846153
Epoch:  770       12 Batch loss: 0.060402 Batch F1: 0.7272727272727273
Train Avg Loss  770: 0.068439

Train Avg F1  770: 0.7681171523121986

Val Avg Loss  770: 0.066356

Val Avg F1  770:  0.6410984848484849

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 771
--------------------------------------------------------------
Epoch:  771        1 Batch loss: 0.063494 Batch F1: 0.5454545454545454
Epoch:  771        2 Batch loss: 0.088649 Batch F1: 0.4
Epoch:  771        3 Batch loss: 0.057948 Batch F1: 0.8571428571428571
Epoch:  771        4 Batch loss: 0.071476 Batch F1: 0.9090909090909091
Epoch:  771        5 Batch loss: 0.046265 Batch F1: 0.8
Epoch:  771        6 Batch loss: 0.063733 Batch F1: 0.9523809523809523
Epoch:  771        7 Batch loss: 0.053755 Batch F1: 0.9411764705882353
Epoch:  771        8 Batch loss: 0.075294 Batch F1: 0.9166666666666666
Epoch:  771        9 Batch loss: 0.082827 Batch F1: 0.6666666666666666
Epoch:  771       10 Batch loss: 0.082459 Batch F1: 0.7777777777777778
Epoch:  771       11 Batch loss: 0.058097 Batch F1: 0.8750000000000001
Epoch:  771       12 Batch loss: 0.061681 Batch F1: 0.8
Train Avg Loss  771: 0.067140

Train Avg F1  771: 0.7867797371473845

Val Avg Loss  771: 0.063221

Val Avg F1  771:  0.6132227249874309

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 772
--------------------------------------------------------------
Epoch:  772        1 Batch loss: 0.089806 Batch F1: 0.5263157894736842
Epoch:  772        2 Batch loss: 0.063931 Batch F1: 0.9411764705882353
Epoch:  772        3 Batch loss: 0.069831 Batch F1: 0.8235294117647058
Epoch:  772        4 Batch loss: 0.048620 Batch F1: 0.888888888888889
Epoch:  772        5 Batch loss: 0.074082 Batch F1: 0.7368421052631579
Epoch:  772        6 Batch loss: 0.073724 Batch F1: 0.5
Epoch:  772        7 Batch loss: 0.049096 Batch F1: 0.7272727272727273
Epoch:  772        8 Batch loss: 0.073993 Batch F1: 0.7058823529411764
Epoch:  772        9 Batch loss: 0.071217 Batch F1: 0.5454545454545454
Epoch:  772       10 Batch loss: 0.044024 Batch F1: 0.6666666666666666
Epoch:  772       11 Batch loss: 0.077167 Batch F1: 0.8
Epoch:  772       12 Batch loss: 0.061988 Batch F1: 0.9333333333333333
Train Avg Loss  772: 0.066456

Train Avg F1  772: 0.7329468576372601

Val Avg Loss  772: 0.063453

Val Avg F1  772:  0.8595833333333334

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 773
--------------------------------------------------------------
Epoch:  773        1 Batch loss: 0.079639 Batch F1: 0.9
Epoch:  773        2 Batch loss: 0.072560 Batch F1: 0.8571428571428571
Epoch:  773        3 Batch loss: 0.069091 Batch F1: 0.9090909090909091
Epoch:  773        4 Batch loss: 0.053798 Batch F1: 0.7272727272727273
Epoch:  773        5 Batch loss: 0.063553 Batch F1: 0.9
Epoch:  773        6 Batch loss: 0.051681 Batch F1: 0.923076923076923
Epoch:  773        7 Batch loss: 0.060988 Batch F1: 0.8333333333333334
Epoch:  773        8 Batch loss: 0.074051 Batch F1: 0.625
Epoch:  773        9 Batch loss: 0.087824 Batch F1: 0.4615384615384615
Epoch:  773       10 Batch loss: 0.075640 Batch F1: 0.6666666666666666
Epoch:  773       11 Batch loss: 0.053676 Batch F1: 0.8235294117647058
Epoch:  773       12 Batch loss: 0.063041 Batch F1: 0.888888888888889
Train Avg Loss  773: 0.067129

Train Avg F1  773: 0.7929616815646229

Val Avg Loss  773: 0.062431

Val Avg F1  773:  0.8364845938375349

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 774
--------------------------------------------------------------
Epoch:  774        1 Batch loss: 0.076754 Batch F1: 0.8750000000000001
Epoch:  774        2 Batch loss: 0.068534 Batch F1: 0.8695652173913044
Epoch:  774        3 Batch loss: 0.046510 Batch F1: 1.0
Epoch:  774        4 Batch loss: 0.051986 Batch F1: 0.923076923076923
Epoch:  774        5 Batch loss: 0.063562 Batch F1: 0.8
Epoch:  774        6 Batch loss: 0.060409 Batch F1: 0.7272727272727273
Epoch:  774        7 Batch loss: 0.058047 Batch F1: 0.8421052631578948
Epoch:  774        8 Batch loss: 0.058128 Batch F1: 0.9473684210526316
Epoch:  774        9 Batch loss: 0.085722 Batch F1: 0.8571428571428571
Epoch:  774       10 Batch loss: 0.099941 Batch F1: 0.625
Epoch:  774       11 Batch loss: 0.062900 Batch F1: 0.8571428571428571
Epoch:  774       12 Batch loss: 0.065318 Batch F1: 0.7499999999999999
Train Avg Loss  774: 0.066484

Train Avg F1  774: 0.8394728555197664

Val Avg Loss  774: 0.063886

Val Avg F1  774:  0.6059149184149184

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 775
--------------------------------------------------------------
Epoch:  775        1 Batch loss: 0.068013 Batch F1: 0.5
Epoch:  775        2 Batch loss: 0.067700 Batch F1: 0.4444444444444445
Epoch:  775        3 Batch loss: 0.095259 Batch F1: 0.47058823529411764
Epoch:  775        4 Batch loss: 0.064566 Batch F1: 0.888888888888889
Epoch:  775        5 Batch loss: 0.078370 Batch F1: 0.75
Epoch:  775        6 Batch loss: 0.069518 Batch F1: 0.8571428571428571
Epoch:  775        7 Batch loss: 0.061763 Batch F1: 0.8
Epoch:  775        8 Batch loss: 0.069360 Batch F1: 0.7142857142857143
Epoch:  775        9 Batch loss: 0.085040 Batch F1: 0.3636363636363636
Epoch:  775       10 Batch loss: 0.090953 Batch F1: 0.3076923076923077
Epoch:  775       11 Batch loss: 0.062271 Batch F1: 0.7499999999999999
Epoch:  775       12 Batch loss: 0.058048 Batch F1: 0.9411764705882353
Train Avg Loss  775: 0.072572

Train Avg F1  775: 0.6489879401644107

Val Avg Loss  775: 0.069959

Val Avg F1  775:  0.9314393939393939

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 776
--------------------------------------------------------------
Epoch:  776        1 Batch loss: 0.078246 Batch F1: 0.888888888888889
Epoch:  776        2 Batch loss: 0.060417 Batch F1: 1.0
Epoch:  776        3 Batch loss: 0.061886 Batch F1: 0.8235294117647058
Epoch:  776        4 Batch loss: 0.074249 Batch F1: 0.5
Epoch:  776        5 Batch loss: 0.065106 Batch F1: 0.875
Epoch:  776        6 Batch loss: 0.092189 Batch F1: 0.5
Epoch:  776        7 Batch loss: 0.071275 Batch F1: 0.4
Epoch:  776        8 Batch loss: 0.068230 Batch F1: 0.8571428571428571
Epoch:  776        9 Batch loss: 0.082297 Batch F1: 0.5882352941176471
Epoch:  776       10 Batch loss: 0.056136 Batch F1: 0.25
Epoch:  776       11 Batch loss: 0.072973 Batch F1: 0.9600000000000001
Epoch:  776       12 Batch loss: 0.080041 Batch F1: 0.8333333333333333
Train Avg Loss  776: 0.071920

Train Avg F1  776: 0.7063441487706194

Val Avg Loss  776: 0.065202

Val Avg F1  776:  0.9271978021978022

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 777
--------------------------------------------------------------
Epoch:  777        1 Batch loss: 0.063030 Batch F1: 0.923076923076923
Epoch:  777        2 Batch loss: 0.076765 Batch F1: 0.7058823529411764
Epoch:  777        3 Batch loss: 0.046750 Batch F1: 0.7499999999999999
Epoch:  777        4 Batch loss: 0.076800 Batch F1: 0.3636363636363636
Epoch:  777        5 Batch loss: 0.086458 Batch F1: 0.4615384615384615
Epoch:  777        6 Batch loss: 0.070428 Batch F1: 0.9523809523809523
Epoch:  777        7 Batch loss: 0.074822 Batch F1: 1.0
Epoch:  777        8 Batch loss: 0.071661 Batch F1: 0.923076923076923
Epoch:  777        9 Batch loss: 0.053811 Batch F1: 0.9523809523809523
Epoch:  777       10 Batch loss: 0.049642 Batch F1: 0.4
Epoch:  777       11 Batch loss: 0.085945 Batch F1: 0.3076923076923077
Epoch:  777       12 Batch loss: 0.073202 Batch F1: 0.7142857142857143
Train Avg Loss  777: 0.069110

Train Avg F1  777: 0.7044959125841479

Val Avg Loss  777: 0.067256

Val Avg F1  777:  0.7416666666666667

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 778
--------------------------------------------------------------
Epoch:  778        1 Batch loss: 0.057308 Batch F1: 1.0
Epoch:  778        2 Batch loss: 0.049614 Batch F1: 0.888888888888889
Epoch:  778        3 Batch loss: 0.073209 Batch F1: 0.6153846153846153
Epoch:  778        4 Batch loss: 0.063706 Batch F1: 0.8571428571428571
Epoch:  778        5 Batch loss: 0.061080 Batch F1: 0.9473684210526316
Epoch:  778        6 Batch loss: 0.101826 Batch F1: 0.7692307692307692
Epoch:  778        7 Batch loss: 0.077396 Batch F1: 0.8571428571428571
Epoch:  778        8 Batch loss: 0.065214 Batch F1: 0.9333333333333333
Epoch:  778        9 Batch loss: 0.061790 Batch F1: 0.4
Epoch:  778       10 Batch loss: 0.059644 Batch F1: 0.6153846153846153
Epoch:  778       11 Batch loss: 0.062300 Batch F1: 0.5454545454545454
Epoch:  778       12 Batch loss: 0.076689 Batch F1: 0.2222222222222222
Train Avg Loss  778: 0.067481

Train Avg F1  778: 0.7209627604364446

Val Avg Loss  778: 0.063622

Val Avg F1  778:  0.8674242424242424

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 779
--------------------------------------------------------------
Epoch:  779        1 Batch loss: 0.082383 Batch F1: 0.8695652173913044
Epoch:  779        2 Batch loss: 0.068107 Batch F1: 1.0
Epoch:  779        3 Batch loss: 0.061856 Batch F1: 0.9411764705882353
Epoch:  779        4 Batch loss: 0.055178 Batch F1: 0.8750000000000001
Epoch:  779        5 Batch loss: 0.067380 Batch F1: 0.6153846153846153
Epoch:  779        6 Batch loss: 0.090039 Batch F1: 0.2857142857142857
Epoch:  779        7 Batch loss: 0.052776 Batch F1: 0.8
Epoch:  779        8 Batch loss: 0.076649 Batch F1: 0.6153846153846153
Epoch:  779        9 Batch loss: 0.067497 Batch F1: 0.7142857142857143
Epoch:  779       10 Batch loss: 0.058575 Batch F1: 0.8333333333333333
Epoch:  779       11 Batch loss: 0.040596 Batch F1: 1.0
Epoch:  779       12 Batch loss: 0.085342 Batch F1: 0.9090909090909091
Train Avg Loss  779: 0.067198

Train Avg F1  779: 0.7882445967644176

Val Avg Loss  779: 0.063692

Val Avg F1  779:  0.9125668449197861

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 780
--------------------------------------------------------------
Epoch:  780        1 Batch loss: 0.055376 Batch F1: 0.888888888888889
Epoch:  780        2 Batch loss: 0.065799 Batch F1: 1.0
Epoch:  780        3 Batch loss: 0.084265 Batch F1: 0.761904761904762
Epoch:  780        4 Batch loss: 0.059554 Batch F1: 0.6666666666666666
Epoch:  780        5 Batch loss: 0.063718 Batch F1: 0.5
Epoch:  780        6 Batch loss: 0.078922 Batch F1: 0.7368421052631579
Epoch:  780        7 Batch loss: 0.083694 Batch F1: 0.3076923076923077
Epoch:  780        8 Batch loss: 0.077869 Batch F1: 0.88
Epoch:  780        9 Batch loss: 0.063919 Batch F1: 0.9090909090909091
Epoch:  780       10 Batch loss: 0.056111 Batch F1: 1.0
Epoch:  780       11 Batch loss: 0.067680 Batch F1: 0.8421052631578948
Epoch:  780       12 Batch loss: 0.062390 Batch F1: 0.8750000000000001
Train Avg Loss  780: 0.068275

Train Avg F1  780: 0.7806825752220489

Val Avg Loss  780: 0.061852

Val Avg F1  780:  0.7770299145299145

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 781
--------------------------------------------------------------
Epoch:  781        1 Batch loss: 0.069280 Batch F1: 0.6666666666666666
Epoch:  781        2 Batch loss: 0.068442 Batch F1: 0.25
Epoch:  781        3 Batch loss: 0.029936 Batch F1: 0.8571428571428571
Epoch:  781        4 Batch loss: 0.079908 Batch F1: 0.4615384615384615
Epoch:  781        5 Batch loss: 0.060367 Batch F1: 0.6
Epoch:  781        6 Batch loss: 0.085488 Batch F1: 0.5
Epoch:  781        7 Batch loss: 0.046622 Batch F1: 1.0
Epoch:  781        8 Batch loss: 0.059607 Batch F1: 1.0
Epoch:  781        9 Batch loss: 0.077129 Batch F1: 0.9
Epoch:  781       10 Batch loss: 0.070004 Batch F1: 0.962962962962963
Epoch:  781       11 Batch loss: 0.074193 Batch F1: 0.8695652173913044
Epoch:  781       12 Batch loss: 0.083373 Batch F1: 0.8
Train Avg Loss  781: 0.067029

Train Avg F1  781: 0.7389896804751878

Val Avg Loss  781: 0.064244

Val Avg F1  781:  0.9022727272727273

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 782
--------------------------------------------------------------
Epoch:  782        1 Batch loss: 0.075414 Batch F1: 0.9411764705882353
Epoch:  782        2 Batch loss: 0.071775 Batch F1: 0.8571428571428571
Epoch:  782        3 Batch loss: 0.046814 Batch F1: 1.0
Epoch:  782        4 Batch loss: 0.076221 Batch F1: 0.7368421052631579
Epoch:  782        5 Batch loss: 0.067541 Batch F1: 0.6153846153846153
Epoch:  782        6 Batch loss: 0.071840 Batch F1: 0.4
Epoch:  782        7 Batch loss: 0.037830 Batch F1: 0.8571428571428571
Epoch:  782        8 Batch loss: 0.068954 Batch F1: 0.7272727272727273
Epoch:  782        9 Batch loss: 0.068160 Batch F1: 0.823529411764706
Epoch:  782       10 Batch loss: 0.081130 Batch F1: 0.9565217391304348
Epoch:  782       11 Batch loss: 0.086478 Batch F1: 0.8571428571428572
Epoch:  782       12 Batch loss: 0.056653 Batch F1: 0.8
Train Avg Loss  782: 0.067401

Train Avg F1  782: 0.7976796367360374

Val Avg Loss  782: 0.064025

Val Avg F1  782:  0.7686542443064182

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 783
--------------------------------------------------------------
Epoch:  783        1 Batch loss: 0.082074 Batch F1: 0.5714285714285715
Epoch:  783        2 Batch loss: 0.054615 Batch F1: 0.9411764705882353
Epoch:  783        3 Batch loss: 0.056992 Batch F1: 1.0
Epoch:  783        4 Batch loss: 0.056855 Batch F1: 0.6666666666666666
Epoch:  783        5 Batch loss: 0.088664 Batch F1: 0.47058823529411764
Epoch:  783        6 Batch loss: 0.057749 Batch F1: 0.923076923076923
Epoch:  783        7 Batch loss: 0.055425 Batch F1: 0.8
Epoch:  783        8 Batch loss: 0.073975 Batch F1: 0.7499999999999999
Epoch:  783        9 Batch loss: 0.091697 Batch F1: 0.8571428571428571
Epoch:  783       10 Batch loss: 0.057514 Batch F1: 1.0
Epoch:  783       11 Batch loss: 0.067548 Batch F1: 0.888888888888889
Epoch:  783       12 Batch loss: 0.075590 Batch F1: 0.5454545454545454
Train Avg Loss  783: 0.068225

Train Avg F1  783: 0.7845352632117337

Val Avg Loss  783: 0.063053

Val Avg F1  783:  0.617361111111111

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 784
--------------------------------------------------------------
Epoch:  784        1 Batch loss: 0.044092 Batch F1: 0.9090909090909091
Epoch:  784        2 Batch loss: 0.091843 Batch F1: 0.47058823529411764
Epoch:  784        3 Batch loss: 0.048650 Batch F1: 0.6
Epoch:  784        4 Batch loss: 0.064406 Batch F1: 0.7777777777777778
Epoch:  784        5 Batch loss: 0.054031 Batch F1: 1.0
Epoch:  784        6 Batch loss: 0.072509 Batch F1: 0.7142857142857143
Epoch:  784        7 Batch loss: 0.066526 Batch F1: 0.9333333333333333
Epoch:  784        8 Batch loss: 0.054782 Batch F1: 0.8
Epoch:  784        9 Batch loss: 0.067428 Batch F1: 0.4
Epoch:  784       10 Batch loss: 0.085346 Batch F1: 0.5
Epoch:  784       11 Batch loss: 0.076592 Batch F1: 0.5454545454545454
Epoch:  784       12 Batch loss: 0.083772 Batch F1: 0.7058823529411764
Train Avg Loss  784: 0.067498

Train Avg F1  784: 0.6963677390147978

Val Avg Loss  784: 0.062792

Val Avg F1  784:  0.9416666666666667

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 785
--------------------------------------------------------------
Epoch:  785        1 Batch loss: 0.081274 Batch F1: 0.8421052631578948
Epoch:  785        2 Batch loss: 0.058750 Batch F1: 0.8000000000000002
Epoch:  785        3 Batch loss: 0.060109 Batch F1: 1.0
Epoch:  785        4 Batch loss: 0.061928 Batch F1: 1.0
Epoch:  785        5 Batch loss: 0.066638 Batch F1: 0.8750000000000001
Epoch:  785        6 Batch loss: 0.090102 Batch F1: 0.2666666666666667
Epoch:  785        7 Batch loss: 0.068388 Batch F1: 0.8235294117647058
Epoch:  785        8 Batch loss: 0.062879 Batch F1: 0.8333333333333333
Epoch:  785        9 Batch loss: 0.052834 Batch F1: 0.8333333333333333
Epoch:  785       10 Batch loss: 0.072179 Batch F1: 0.5882352941176471
Epoch:  785       11 Batch loss: 0.099755 Batch F1: 0.35294117647058826
Epoch:  785       12 Batch loss: 0.065410 Batch F1: 0.6666666666666666
Train Avg Loss  785: 0.070020

Train Avg F1  785: 0.7401509287925695

Val Avg Loss  785: 0.064039

Val Avg F1  785:  0.9227941176470589

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 786
--------------------------------------------------------------
Epoch:  786        1 Batch loss: 0.064226 Batch F1: 0.9090909090909091
Epoch:  786        2 Batch loss: 0.066794 Batch F1: 0.8333333333333333
Epoch:  786        3 Batch loss: 0.073863 Batch F1: 0.7777777777777778
Epoch:  786        4 Batch loss: 0.044981 Batch F1: 0.6666666666666666
Epoch:  786        5 Batch loss: 0.087146 Batch F1: 0.6
Epoch:  786        6 Batch loss: 0.044770 Batch F1: 0.5714285714285715
Epoch:  786        7 Batch loss: 0.051540 Batch F1: 0.7692307692307693
Epoch:  786        8 Batch loss: 0.065823 Batch F1: 0.8
Epoch:  786        9 Batch loss: 0.076108 Batch F1: 0.7368421052631579
Epoch:  786       10 Batch loss: 0.105754 Batch F1: 0.761904761904762
Epoch:  786       11 Batch loss: 0.055161 Batch F1: 1.0
Epoch:  786       12 Batch loss: 0.100736 Batch F1: 0.782608695652174
Train Avg Loss  786: 0.069742

Train Avg F1  786: 0.7674069658623434

Val Avg Loss  786: 0.064395

Val Avg F1  786:  0.8867338801549327

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 787
--------------------------------------------------------------
Epoch:  787        1 Batch loss: 0.071051 Batch F1: 0.8
Epoch:  787        2 Batch loss: 0.050058 Batch F1: 0.9333333333333333
Epoch:  787        3 Batch loss: 0.074476 Batch F1: 0.8750000000000001
Epoch:  787        4 Batch loss: 0.066161 Batch F1: 0.7692307692307693
Epoch:  787        5 Batch loss: 0.104149 Batch F1: 0.888888888888889
Epoch:  787        6 Batch loss: 0.063391 Batch F1: 0.923076923076923
Epoch:  787        7 Batch loss: 0.046972 Batch F1: 0.9090909090909091
Epoch:  787        8 Batch loss: 0.062978 Batch F1: 0.9333333333333333
Epoch:  787        9 Batch loss: 0.080562 Batch F1: 0.7368421052631579
Epoch:  787       10 Batch loss: 0.059405 Batch F1: 0.8333333333333333
Epoch:  787       11 Batch loss: 0.069708 Batch F1: 0.8235294117647058
Epoch:  787       12 Batch loss: 0.054505 Batch F1: 0.7499999999999999
Train Avg Loss  787: 0.066951

Train Avg F1  787: 0.8479715839429462

Val Avg Loss  787: 0.063121

Val Avg F1  787:  0.6479353979353979

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 788
--------------------------------------------------------------
Epoch:  788        1 Batch loss: 0.060499 Batch F1: 0.6666666666666666
Epoch:  788        2 Batch loss: 0.058170 Batch F1: 0.7142857142857143
Epoch:  788        3 Batch loss: 0.072316 Batch F1: 0.3636363636363636
Epoch:  788        4 Batch loss: 0.060566 Batch F1: 0.7142857142857143
Epoch:  788        5 Batch loss: 0.068793 Batch F1: 0.2857142857142857
Epoch:  788        6 Batch loss: 0.062273 Batch F1: 0.5
Epoch:  788        7 Batch loss: 0.068228 Batch F1: 0.6666666666666666
Epoch:  788        8 Batch loss: 0.036425 Batch F1: 0.8571428571428571
Epoch:  788        9 Batch loss: 0.059017 Batch F1: 0.5454545454545454
Epoch:  788       10 Batch loss: 0.111487 Batch F1: 0.56
Epoch:  788       11 Batch loss: 0.078963 Batch F1: 0.7058823529411764
Epoch:  788       12 Batch loss: 0.081579 Batch F1: 0.9
Train Avg Loss  788: 0.068193

Train Avg F1  788: 0.6233112638994992

Val Avg Loss  788: 0.069966

Val Avg F1  788:  0.9276917784657723

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 789
--------------------------------------------------------------
Epoch:  789        1 Batch loss: 0.058778 Batch F1: 0.8571428571428571
Epoch:  789        2 Batch loss: 0.058981 Batch F1: 1.0
Epoch:  789        3 Batch loss: 0.085139 Batch F1: 0.9285714285714286
Epoch:  789        4 Batch loss: 0.068862 Batch F1: 0.9565217391304348
Epoch:  789        5 Batch loss: 0.066254 Batch F1: 1.0
Epoch:  789        6 Batch loss: 0.072307 Batch F1: 0.9411764705882353
Epoch:  789        7 Batch loss: 0.094338 Batch F1: 0.8333333333333333
Epoch:  789        8 Batch loss: 0.078873 Batch F1: 0.9473684210526316
Epoch:  789        9 Batch loss: 0.043941 Batch F1: 0.6666666666666666
Epoch:  789       10 Batch loss: 0.111849 Batch F1: 0.18181818181818182
Epoch:  789       11 Batch loss: 0.051748 Batch F1: 0.4
Epoch:  789       12 Batch loss: 0.064293 Batch F1: 0.6
Train Avg Loss  789: 0.071280

Train Avg F1  789: 0.7760499248586474

Val Avg Loss  789: 0.065666

Val Avg F1  789:  0.6121794871794871

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 790
--------------------------------------------------------------
Epoch:  790        1 Batch loss: 0.068072 Batch F1: 0.0
Epoch:  790        2 Batch loss: 0.060226 Batch F1: 0.9333333333333333
Epoch:  790        3 Batch loss: 0.050926 Batch F1: 0.8
Epoch:  790        4 Batch loss: 0.060340 Batch F1: 0.7272727272727273
Epoch:  790        5 Batch loss: 0.064538 Batch F1: 0.6153846153846153
Epoch:  790        6 Batch loss: 0.077280 Batch F1: 0.6666666666666666
Epoch:  790        7 Batch loss: 0.083787 Batch F1: 0.4615384615384615
Epoch:  790        8 Batch loss: 0.068993 Batch F1: 0.8571428571428571
Epoch:  790        9 Batch loss: 0.090904 Batch F1: 0.7857142857142858
Epoch:  790       10 Batch loss: 0.069447 Batch F1: 0.8333333333333333
Epoch:  790       11 Batch loss: 0.065524 Batch F1: 0.6666666666666666
Epoch:  790       12 Batch loss: 0.077121 Batch F1: 0.2222222222222222
Train Avg Loss  790: 0.069763

Train Avg F1  790: 0.6307729307729307

Val Avg Loss  790: 0.066560

Val Avg F1  790:  0.7422459893048128

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 791
--------------------------------------------------------------
Epoch:  791        1 Batch loss: 0.071188 Batch F1: 0.625
Epoch:  791        2 Batch loss: 0.072534 Batch F1: 0.9523809523809523
Epoch:  791        3 Batch loss: 0.063729 Batch F1: 0.9523809523809523
Epoch:  791        4 Batch loss: 0.053885 Batch F1: 0.923076923076923
Epoch:  791        5 Batch loss: 0.070063 Batch F1: 0.8333333333333333
Epoch:  791        6 Batch loss: 0.069953 Batch F1: 0.9473684210526316
Epoch:  791        7 Batch loss: 0.070088 Batch F1: 0.7499999999999999
Epoch:  791        8 Batch loss: 0.064769 Batch F1: 0.4444444444444445
Epoch:  791        9 Batch loss: 0.064915 Batch F1: 0.6
Epoch:  791       10 Batch loss: 0.102688 Batch F1: 0.47058823529411764
Epoch:  791       11 Batch loss: 0.051371 Batch F1: 0.8
Epoch:  791       12 Batch loss: 0.056208 Batch F1: 0.8
Train Avg Loss  791: 0.067616

Train Avg F1  791: 0.7582144384969464

Val Avg Loss  791: 0.062922

Val Avg F1  791:  0.9233333333333333

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 792
--------------------------------------------------------------
Epoch:  792        1 Batch loss: 0.076991 Batch F1: 0.9411764705882353
Epoch:  792        2 Batch loss: 0.090502 Batch F1: 0.896551724137931
Epoch:  792        3 Batch loss: 0.063836 Batch F1: 0.7142857142857143
Epoch:  792        4 Batch loss: 0.070611 Batch F1: 0.7272727272727273
Epoch:  792        5 Batch loss: 0.048096 Batch F1: 1.0
Epoch:  792        6 Batch loss: 0.069010 Batch F1: 0.9166666666666666
Epoch:  792        7 Batch loss: 0.065438 Batch F1: 0.923076923076923
Epoch:  792        8 Batch loss: 0.068358 Batch F1: 0.9473684210526316
Epoch:  792        9 Batch loss: 0.070968 Batch F1: 0.9473684210526316
Epoch:  792       10 Batch loss: 0.045549 Batch F1: 0.8571428571428571
Epoch:  792       11 Batch loss: 0.090068 Batch F1: 0.5882352941176471
Epoch:  792       12 Batch loss: 0.050761 Batch F1: 0.6666666666666666
Train Avg Loss  792: 0.067516

Train Avg F1  792: 0.8438176571717193

Val Avg Loss  792: 0.065484

Val Avg F1  792:  0.6421703296703296

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 793
--------------------------------------------------------------
Epoch:  793        1 Batch loss: 0.076736 Batch F1: 0.5714285714285715
Epoch:  793        2 Batch loss: 0.061827 Batch F1: 0.7692307692307693
Epoch:  793        3 Batch loss: 0.050088 Batch F1: 0.8
Epoch:  793        4 Batch loss: 0.059460 Batch F1: 0.7692307692307693
Epoch:  793        5 Batch loss: 0.073419 Batch F1: 0.8181818181818181
Epoch:  793        6 Batch loss: 0.060469 Batch F1: 0.7272727272727272
Epoch:  793        7 Batch loss: 0.090309 Batch F1: 0.7272727272727273
Epoch:  793        8 Batch loss: 0.049252 Batch F1: 1.0
Epoch:  793        9 Batch loss: 0.088971 Batch F1: 0.8421052631578948
Epoch:  793       10 Batch loss: 0.062690 Batch F1: 0.6
Epoch:  793       11 Batch loss: 0.067220 Batch F1: 0.6666666666666666
Epoch:  793       12 Batch loss: 0.085877 Batch F1: 0.5714285714285715
Train Avg Loss  793: 0.068860

Train Avg F1  793: 0.7385681569892096

Val Avg Loss  793: 0.064354

Val Avg F1  793:  0.6236471861471861

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 794
--------------------------------------------------------------
Epoch:  794        1 Batch loss: 0.057520 Batch F1: 0.6666666666666666
Epoch:  794        2 Batch loss: 0.061794 Batch F1: 0.6
Epoch:  794        3 Batch loss: 0.069025 Batch F1: 0.7368421052631579
Epoch:  794        4 Batch loss: 0.065107 Batch F1: 0.9333333333333333
Epoch:  794        5 Batch loss: 0.079224 Batch F1: 0.625
Epoch:  794        6 Batch loss: 0.075429 Batch F1: 0.8571428571428571
Epoch:  794        7 Batch loss: 0.062178 Batch F1: 0.9090909090909091
Epoch:  794        8 Batch loss: 0.063263 Batch F1: 1.0
Epoch:  794        9 Batch loss: 0.076651 Batch F1: 0.9
Epoch:  794       10 Batch loss: 0.067898 Batch F1: 0.9523809523809523
Epoch:  794       11 Batch loss: 0.080865 Batch F1: 0.8
Epoch:  794       12 Batch loss: 0.066502 Batch F1: 0.4444444444444445
Train Avg Loss  794: 0.068788

Train Avg F1  794: 0.7854084390268601

Val Avg Loss  794: 0.067910

Val Avg F1  794:  0.5881028693528695

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 795
--------------------------------------------------------------
Epoch:  795        1 Batch loss: 0.057804 Batch F1: 0.4444444444444445
Epoch:  795        2 Batch loss: 0.064850 Batch F1: 0.6
Epoch:  795        3 Batch loss: 0.094718 Batch F1: 0.6666666666666666
Epoch:  795        4 Batch loss: 0.081721 Batch F1: 0.888888888888889
Epoch:  795        5 Batch loss: 0.071679 Batch F1: 0.9090909090909091
Epoch:  795        6 Batch loss: 0.087645 Batch F1: 0.8571428571428572
Epoch:  795        7 Batch loss: 0.065098 Batch F1: 1.0
Epoch:  795        8 Batch loss: 0.060211 Batch F1: 0.5454545454545454
Epoch:  795        9 Batch loss: 0.058250 Batch F1: 0.5
Epoch:  795       10 Batch loss: 0.092296 Batch F1: 0.3076923076923077
Epoch:  795       11 Batch loss: 0.059273 Batch F1: 1.0
Epoch:  795       12 Batch loss: 0.059393 Batch F1: 1.0
Train Avg Loss  795: 0.071078

Train Avg F1  795: 0.7266150516150516

Val Avg Loss  795: 0.063791

Val Avg F1  795:  0.7256410256410256

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 796
--------------------------------------------------------------
Epoch:  796        1 Batch loss: 0.059423 Batch F1: 0.5714285714285715
Epoch:  796        2 Batch loss: 0.058169 Batch F1: 0.7272727272727272
Epoch:  796        3 Batch loss: 0.066836 Batch F1: 0.6666666666666666
Epoch:  796        4 Batch loss: 0.072267 Batch F1: 0.9523809523809523
Epoch:  796        5 Batch loss: 0.067432 Batch F1: 0.8571428571428571
Epoch:  796        6 Batch loss: 0.067768 Batch F1: 0.5454545454545454
Epoch:  796        7 Batch loss: 0.065292 Batch F1: 0.4444444444444445
Epoch:  796        8 Batch loss: 0.074279 Batch F1: 0.6153846153846153
Epoch:  796        9 Batch loss: 0.066175 Batch F1: 0.7499999999999999
Epoch:  796       10 Batch loss: 0.103060 Batch F1: 0.5333333333333333
Epoch:  796       11 Batch loss: 0.082956 Batch F1: 0.8750000000000001
Epoch:  796       12 Batch loss: 0.058464 Batch F1: 0.8571428571428571
Train Avg Loss  796: 0.070177

Train Avg F1  796: 0.6996376308876308

Val Avg Loss  796: 0.065344

Val Avg F1  796:  0.5964635854341737

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 797
--------------------------------------------------------------
Epoch:  797        1 Batch loss: 0.061976 Batch F1: 0.8421052631578948
Epoch:  797        2 Batch loss: 0.080319 Batch F1: 0.5333333333333333
Epoch:  797        3 Batch loss: 0.055679 Batch F1: 0.9411764705882353
Epoch:  797        4 Batch loss: 0.068725 Batch F1: 0.8571428571428571
Epoch:  797        5 Batch loss: 0.088203 Batch F1: 0.0
Epoch:  797        6 Batch loss: 0.074667 Batch F1: 0.1818181818181818
Epoch:  797        7 Batch loss: 0.049088 Batch F1: 0.5714285714285715
Epoch:  797        8 Batch loss: 0.095508 Batch F1: 0.3076923076923077
Epoch:  797        9 Batch loss: 0.073795 Batch F1: 1.0
Epoch:  797       10 Batch loss: 0.089343 Batch F1: 0.9565217391304348
Epoch:  797       11 Batch loss: 0.067432 Batch F1: 0.7272727272727273
Epoch:  797       12 Batch loss: 0.060178 Batch F1: 0.9090909090909091
Train Avg Loss  797: 0.072076

Train Avg F1  797: 0.652298530054621

Val Avg Loss  797: 0.067273

Val Avg F1  797:  0.5978084415584415

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 798
--------------------------------------------------------------
Epoch:  798        1 Batch loss: 0.082173 Batch F1: 0.625
Epoch:  798        2 Batch loss: 0.089845 Batch F1: 0.47058823529411764
Epoch:  798        3 Batch loss: 0.067597 Batch F1: 0.0
Epoch:  798        4 Batch loss: 0.069950 Batch F1: 0.6153846153846153
Epoch:  798        5 Batch loss: 0.063308 Batch F1: 0.6666666666666666
Epoch:  798        6 Batch loss: 0.064540 Batch F1: 0.7058823529411764
Epoch:  798        7 Batch loss: 0.061493 Batch F1: 0.5454545454545454
Epoch:  798        8 Batch loss: 0.064203 Batch F1: 0.7777777777777778
Epoch:  798        9 Batch loss: 0.077268 Batch F1: 0.5
Epoch:  798       10 Batch loss: 0.053762 Batch F1: 0.2857142857142857
Epoch:  798       11 Batch loss: 0.067011 Batch F1: 0.4
Epoch:  798       12 Batch loss: 0.063609 Batch F1: 0.8
Train Avg Loss  798: 0.068730

Train Avg F1  798: 0.5327057066027655

Val Avg Loss  798: 0.063639

Val Avg F1  798:  0.6095238095238096

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 799
--------------------------------------------------------------
Epoch:  799        1 Batch loss: 0.067303 Batch F1: 0.5
Epoch:  799        2 Batch loss: 0.065719 Batch F1: 0.8235294117647058
Epoch:  799        3 Batch loss: 0.050017 Batch F1: 0.923076923076923
Epoch:  799        4 Batch loss: 0.078686 Batch F1: 0.9090909090909091
Epoch:  799        5 Batch loss: 0.061941 Batch F1: 0.8888888888888888
Epoch:  799        6 Batch loss: 0.062138 Batch F1: 0.8
Epoch:  799        7 Batch loss: 0.067532 Batch F1: 0.7777777777777778
Epoch:  799        8 Batch loss: 0.067224 Batch F1: 0.3333333333333333
Epoch:  799        9 Batch loss: 0.057781 Batch F1: 0.5
Epoch:  799       10 Batch loss: 0.081099 Batch F1: 0.9090909090909091
Epoch:  799       11 Batch loss: 0.081169 Batch F1: 0.8333333333333333
Epoch:  799       12 Batch loss: 0.066811 Batch F1: 0.6666666666666666
Train Avg Loss  799: 0.067285

Train Avg F1  799: 0.7387323460852873

Val Avg Loss  799: 0.063897

Val Avg F1  799:  0.773313492063492

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 800
--------------------------------------------------------------
Epoch:  800        1 Batch loss: 0.076946 Batch F1: 0.8181818181818181
Epoch:  800        2 Batch loss: 0.067393 Batch F1: 0.6666666666666666
Epoch:  800        3 Batch loss: 0.068608 Batch F1: 0.8
Epoch:  800        4 Batch loss: 0.057596 Batch F1: 0.8
Epoch:  800        5 Batch loss: 0.033062 Batch F1: 0.0
Epoch:  800        6 Batch loss: 0.066520 Batch F1: 0.7499999999999999
Epoch:  800        7 Batch loss: 0.067164 Batch F1: 0.6666666666666666
Epoch:  800        8 Batch loss: 0.076781 Batch F1: 0.625
Epoch:  800        9 Batch loss: 0.062771 Batch F1: 0.7142857142857143
Epoch:  800       10 Batch loss: 0.068830 Batch F1: 0.8571428571428571
Epoch:  800       11 Batch loss: 0.077203 Batch F1: 0.9565217391304348
Epoch:  800       12 Batch loss: 0.107406 Batch F1: 0.761904761904762
Train Avg Loss  800: 0.069190

Train Avg F1  800: 0.7013641853315766

Val Avg Loss  800: 0.064837

Val Avg F1  800:  0.9341179653679653

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 801
--------------------------------------------------------------
Epoch:  801        1 Batch loss: 0.057609 Batch F1: 0.9333333333333333
Epoch:  801        2 Batch loss: 0.061779 Batch F1: 0.875
Epoch:  801        3 Batch loss: 0.068997 Batch F1: 0.8
Epoch:  801        4 Batch loss: 0.072882 Batch F1: 0.7499999999999999
Epoch:  801        5 Batch loss: 0.070494 Batch F1: 0.9
Epoch:  801        6 Batch loss: 0.061919 Batch F1: 0.9411764705882353
Epoch:  801        7 Batch loss: 0.047488 Batch F1: 1.0
Epoch:  801        8 Batch loss: 0.066111 Batch F1: 0.8571428571428571
Epoch:  801        9 Batch loss: 0.069770 Batch F1: 0.8235294117647058
Epoch:  801       10 Batch loss: 0.063870 Batch F1: 0.6666666666666666
Epoch:  801       11 Batch loss: 0.093755 Batch F1: 0.5263157894736842
Epoch:  801       12 Batch loss: 0.079752 Batch F1: 0.7272727272727273
Train Avg Loss  801: 0.067869

Train Avg F1  801: 0.8167031046868508

Val Avg Loss  801: 0.062282

Val Avg F1  801:  0.7941468253968255

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 802
--------------------------------------------------------------
Epoch:  802        1 Batch loss: 0.052251 Batch F1: 0.8
Epoch:  802        2 Batch loss: 0.078575 Batch F1: 0.923076923076923
Epoch:  802        3 Batch loss: 0.058839 Batch F1: 0.9
Epoch:  802        4 Batch loss: 0.056472 Batch F1: 1.0
Epoch:  802        5 Batch loss: 0.078000 Batch F1: 0.7777777777777778
Epoch:  802        6 Batch loss: 0.072606 Batch F1: 0.7692307692307693
Epoch:  802        7 Batch loss: 0.052840 Batch F1: 0.888888888888889
Epoch:  802        8 Batch loss: 0.071683 Batch F1: 0.7058823529411764
Epoch:  802        9 Batch loss: 0.078778 Batch F1: 0.19999999999999998
Epoch:  802       10 Batch loss: 0.091052 Batch F1: 0.625
Epoch:  802       11 Batch loss: 0.066304 Batch F1: 0.7142857142857143
Epoch:  802       12 Batch loss: 0.065553 Batch F1: 1.0
Train Avg Loss  802: 0.068579

Train Avg F1  802: 0.7753452021834376

Val Avg Loss  802: 0.065026

Val Avg F1  802:  0.9154135338345866

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 803
--------------------------------------------------------------
Epoch:  803        1 Batch loss: 0.060722 Batch F1: 0.8333333333333333
Epoch:  803        2 Batch loss: 0.060385 Batch F1: 0.9333333333333333
Epoch:  803        3 Batch loss: 0.075185 Batch F1: 0.8235294117647058
Epoch:  803        4 Batch loss: 0.068100 Batch F1: 0.33333333333333337
Epoch:  803        5 Batch loss: 0.074507 Batch F1: 0.6
Epoch:  803        6 Batch loss: 0.103796 Batch F1: 0.5
Epoch:  803        7 Batch loss: 0.081625 Batch F1: 0.4615384615384615
Epoch:  803        8 Batch loss: 0.067490 Batch F1: 0.7692307692307693
Epoch:  803        9 Batch loss: 0.066446 Batch F1: 0.8750000000000001
Epoch:  803       10 Batch loss: 0.051702 Batch F1: 0.923076923076923
Epoch:  803       11 Batch loss: 0.054919 Batch F1: 0.9333333333333333
Epoch:  803       12 Batch loss: 0.060421 Batch F1: 0.8750000000000001
Train Avg Loss  803: 0.068775

Train Avg F1  803: 0.7383924082453496

Val Avg Loss  803: 0.063159

Val Avg F1  803:  0.7914086687306501

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 804
--------------------------------------------------------------
Epoch:  804        1 Batch loss: 0.064087 Batch F1: 0.8333333333333333
Epoch:  804        2 Batch loss: 0.046136 Batch F1: 0.888888888888889
Epoch:  804        3 Batch loss: 0.057933 Batch F1: 1.0
Epoch:  804        4 Batch loss: 0.099360 Batch F1: 0.6666666666666667
Epoch:  804        5 Batch loss: 0.050589 Batch F1: 1.0
Epoch:  804        6 Batch loss: 0.072559 Batch F1: 0.6
Epoch:  804        7 Batch loss: 0.079487 Batch F1: 0.5714285714285715
Epoch:  804        8 Batch loss: 0.059063 Batch F1: 0.8571428571428571
Epoch:  804        9 Batch loss: 0.089861 Batch F1: 0.5
Epoch:  804       10 Batch loss: 0.075779 Batch F1: 0.2222222222222222
Epoch:  804       11 Batch loss: 0.057583 Batch F1: 0.9090909090909091
Epoch:  804       12 Batch loss: 0.073471 Batch F1: 0.9
Train Avg Loss  804: 0.068826

Train Avg F1  804: 0.7457311207311207

Val Avg Loss  804: 0.066357

Val Avg F1  804:  0.9177018633540373

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 805
--------------------------------------------------------------
Epoch:  805        1 Batch loss: 0.069685 Batch F1: 0.9333333333333333
Epoch:  805        2 Batch loss: 0.076373 Batch F1: 0.4
Epoch:  805        3 Batch loss: 0.090692 Batch F1: 0.761904761904762
Epoch:  805        4 Batch loss: 0.064724 Batch F1: 0.923076923076923
Epoch:  805        5 Batch loss: 0.075986 Batch F1: 0.5882352941176471
Epoch:  805        6 Batch loss: 0.069146 Batch F1: 0.5454545454545454
Epoch:  805        7 Batch loss: 0.055426 Batch F1: 1.0
Epoch:  805        8 Batch loss: 0.085885 Batch F1: 0.8571428571428571
Epoch:  805        9 Batch loss: 0.057881 Batch F1: 0.9333333333333333
Epoch:  805       10 Batch loss: 0.054788 Batch F1: 0.9333333333333333
Epoch:  805       11 Batch loss: 0.056378 Batch F1: 0.923076923076923
Epoch:  805       12 Batch loss: 0.063887 Batch F1: 0.7692307692307693
Train Avg Loss  805: 0.068404

Train Avg F1  805: 0.7973435061670356

Val Avg Loss  805: 0.063581

Val Avg F1  805:  0.6238095238095238

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 806
--------------------------------------------------------------
Epoch:  806        1 Batch loss: 0.091492 Batch F1: 0.5
Epoch:  806        2 Batch loss: 0.086202 Batch F1: 0.8571428571428571
Epoch:  806        3 Batch loss: 0.071726 Batch F1: 0.9
Epoch:  806        4 Batch loss: 0.070728 Batch F1: 1.0
Epoch:  806        5 Batch loss: 0.065270 Batch F1: 1.0
Epoch:  806        6 Batch loss: 0.060368 Batch F1: 0.9090909090909091
Epoch:  806        7 Batch loss: 0.053684 Batch F1: 1.0
Epoch:  806        8 Batch loss: 0.055534 Batch F1: 0.7692307692307693
Epoch:  806        9 Batch loss: 0.063262 Batch F1: 0.6
Epoch:  806       10 Batch loss: 0.048406 Batch F1: 0.6
Epoch:  806       11 Batch loss: 0.074781 Batch F1: 0.7142857142857143
Epoch:  806       12 Batch loss: 0.073259 Batch F1: 0.5454545454545454
Train Avg Loss  806: 0.067893

Train Avg F1  806: 0.7829337329337328

Val Avg Loss  806: 0.064673

Val Avg F1  806:  0.5969017094017094

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 807
--------------------------------------------------------------
Epoch:  807        1 Batch loss: 0.071025 Batch F1: 0.625
Epoch:  807        2 Batch loss: 0.052271 Batch F1: 0.8333333333333333
Epoch:  807        3 Batch loss: 0.079814 Batch F1: 0.9655172413793104
Epoch:  807        4 Batch loss: 0.098119 Batch F1: 0.8421052631578948
Epoch:  807        5 Batch loss: 0.066784 Batch F1: 0.8571428571428571
Epoch:  807        6 Batch loss: 0.075778 Batch F1: 0.5714285714285715
Epoch:  807        7 Batch loss: 0.053844 Batch F1: 0.8333333333333333
Epoch:  807        8 Batch loss: 0.082952 Batch F1: 0.6666666666666667
Epoch:  807        9 Batch loss: 0.053780 Batch F1: 0.25
Epoch:  807       10 Batch loss: 0.051413 Batch F1: 0.9333333333333333
Epoch:  807       11 Batch loss: 0.093035 Batch F1: 0.7058823529411764
Epoch:  807       12 Batch loss: 0.067255 Batch F1: 1.0
Train Avg Loss  807: 0.070506

Train Avg F1  807: 0.7569785793930396

Val Avg Loss  807: 0.066585

Val Avg F1  807:  0.8624586198115609

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 808
--------------------------------------------------------------
Epoch:  808        1 Batch loss: 0.075372 Batch F1: 0.7777777777777778
Epoch:  808        2 Batch loss: 0.063359 Batch F1: 0.5454545454545454
Epoch:  808        3 Batch loss: 0.087013 Batch F1: 0.631578947368421
Epoch:  808        4 Batch loss: 0.058212 Batch F1: 0.9333333333333333
Epoch:  808        5 Batch loss: 0.056372 Batch F1: 0.7692307692307693
Epoch:  808        6 Batch loss: 0.049284 Batch F1: 0.7499999999999999
Epoch:  808        7 Batch loss: 0.081173 Batch F1: 0.5
Epoch:  808        8 Batch loss: 0.105709 Batch F1: 0.2666666666666667
Epoch:  808        9 Batch loss: 0.064164 Batch F1: 0.6153846153846153
Epoch:  808       10 Batch loss: 0.077570 Batch F1: 0.9
Epoch:  808       11 Batch loss: 0.055669 Batch F1: 0.923076923076923
Epoch:  808       12 Batch loss: 0.069679 Batch F1: 0.8333333333333333
Train Avg Loss  808: 0.070298

Train Avg F1  808: 0.703819742635532

Val Avg Loss  808: 0.064380

Val Avg F1  808:  0.829059829059829

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 809
--------------------------------------------------------------
Epoch:  809        1 Batch loss: 0.052305 Batch F1: 1.0
Epoch:  809        2 Batch loss: 0.083515 Batch F1: 0.3076923076923077
Epoch:  809        3 Batch loss: 0.077823 Batch F1: 0.6666666666666666
Epoch:  809        4 Batch loss: 0.046468 Batch F1: 0.5
Epoch:  809        5 Batch loss: 0.073926 Batch F1: 0.2222222222222222
Epoch:  809        6 Batch loss: 0.067795 Batch F1: 0.7692307692307693
Epoch:  809        7 Batch loss: 0.086928 Batch F1: 0.896551724137931
Epoch:  809        8 Batch loss: 0.066041 Batch F1: 0.8
Epoch:  809        9 Batch loss: 0.076555 Batch F1: 0.9565217391304348
Epoch:  809       10 Batch loss: 0.087643 Batch F1: 0.8181818181818182
Epoch:  809       11 Batch loss: 0.061666 Batch F1: 1.0
Epoch:  809       12 Batch loss: 0.059721 Batch F1: 0.8333333333333333
Train Avg Loss  809: 0.070032

Train Avg F1  809: 0.7308667150496236

Val Avg Loss  809: 0.069412

Val Avg F1  809:  0.625

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 810
--------------------------------------------------------------
Epoch:  810        1 Batch loss: 0.068031 Batch F1: 0.8181818181818181
Epoch:  810        2 Batch loss: 0.083648 Batch F1: 0.8421052631578948
Epoch:  810        3 Batch loss: 0.072403 Batch F1: 0.8750000000000001
Epoch:  810        4 Batch loss: 0.075531 Batch F1: 0.888888888888889
Epoch:  810        5 Batch loss: 0.059495 Batch F1: 0.7499999999999999
Epoch:  810        6 Batch loss: 0.101696 Batch F1: 0.5555555555555556
Epoch:  810        7 Batch loss: 0.067768 Batch F1: 0.25
Epoch:  810        8 Batch loss: 0.048693 Batch F1: 0.6
Epoch:  810        9 Batch loss: 0.056970 Batch F1: 0.8571428571428571
Epoch:  810       10 Batch loss: 0.069889 Batch F1: 0.8571428571428571
Epoch:  810       11 Batch loss: 0.082002 Batch F1: 0.9473684210526316
Epoch:  810       12 Batch loss: 0.069156 Batch F1: 0.8333333333333333
Train Avg Loss  810: 0.071273

Train Avg F1  810: 0.7562265828713196

Val Avg Loss  810: 0.065279

Val Avg F1  810:  0.5922619047619047

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 811
--------------------------------------------------------------
Epoch:  811        1 Batch loss: 0.048616 Batch F1: 0.6666666666666666
Epoch:  811        2 Batch loss: 0.076676 Batch F1: 0.5
Epoch:  811        3 Batch loss: 0.056063 Batch F1: 0.6
Epoch:  811        4 Batch loss: 0.112364 Batch F1: 0.6666666666666666
Epoch:  811        5 Batch loss: 0.072437 Batch F1: 0.5
Epoch:  811        6 Batch loss: 0.072291 Batch F1: 0.9565217391304348
Epoch:  811        7 Batch loss: 0.073822 Batch F1: 0.8888888888888888
Epoch:  811        8 Batch loss: 0.072390 Batch F1: 0.888888888888889
Epoch:  811        9 Batch loss: 0.072373 Batch F1: 0.8235294117647058
Epoch:  811       10 Batch loss: 0.070745 Batch F1: 0.6666666666666666
Epoch:  811       11 Batch loss: 0.046163 Batch F1: 0.7499999999999999
Epoch:  811       12 Batch loss: 0.064959 Batch F1: 0.7272727272727273
Train Avg Loss  811: 0.069908

Train Avg F1  811: 0.7195918046621371

Val Avg Loss  811: 0.067699

Val Avg F1  811:  0.8220682503770739

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 812
--------------------------------------------------------------
Epoch:  812        1 Batch loss: 0.072034 Batch F1: 0.7272727272727273
Epoch:  812        2 Batch loss: 0.064141 Batch F1: 0.25
Epoch:  812        3 Batch loss: 0.067609 Batch F1: 0.6666666666666666
Epoch:  812        4 Batch loss: 0.084050 Batch F1: 0.761904761904762
Epoch:  812        5 Batch loss: 0.045073 Batch F1: 0.8
Epoch:  812        6 Batch loss: 0.074485 Batch F1: 0.9
Epoch:  812        7 Batch loss: 0.073566 Batch F1: 0.8421052631578948
Epoch:  812        8 Batch loss: 0.061135 Batch F1: 0.8
Epoch:  812        9 Batch loss: 0.076410 Batch F1: 0.631578947368421
Epoch:  812       10 Batch loss: 0.060865 Batch F1: 0.9090909090909091
Epoch:  812       11 Batch loss: 0.047276 Batch F1: 0.8571428571428571
Epoch:  812       12 Batch loss: 0.097869 Batch F1: 0.5
Train Avg Loss  812: 0.068709

Train Avg F1  812: 0.7204801777170199

Val Avg Loss  812: 0.063338

Val Avg F1  812:  0.5986111111111111

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 813
--------------------------------------------------------------
Epoch:  813        1 Batch loss: 0.086806 Batch F1: 0.5555555555555556
Epoch:  813        2 Batch loss: 0.058259 Batch F1: 0.4
Epoch:  813        3 Batch loss: 0.058556 Batch F1: 0.7499999999999999
Epoch:  813        4 Batch loss: 0.056984 Batch F1: 0.923076923076923
Epoch:  813        5 Batch loss: 0.039733 Batch F1: 0.5
Epoch:  813        6 Batch loss: 0.106371 Batch F1: 0.6086956521739131
Epoch:  813        7 Batch loss: 0.061061 Batch F1: 0.8235294117647058
Epoch:  813        8 Batch loss: 0.069958 Batch F1: 0.7058823529411764
Epoch:  813        9 Batch loss: 0.057984 Batch F1: 0.9411764705882353
Epoch:  813       10 Batch loss: 0.073417 Batch F1: 0.8750000000000001
Epoch:  813       11 Batch loss: 0.071215 Batch F1: 0.962962962962963
Epoch:  813       12 Batch loss: 0.070157 Batch F1: 0.8571428571428571
Train Avg Loss  813: 0.067542

Train Avg F1  813: 0.7419185155171942

Val Avg Loss  813: 0.064235

Val Avg F1  813:  0.9277777777777778

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 814
--------------------------------------------------------------
Epoch:  814        1 Batch loss: 0.054789 Batch F1: 1.0
Epoch:  814        2 Batch loss: 0.048118 Batch F1: 1.0
Epoch:  814        3 Batch loss: 0.050348 Batch F1: 0.888888888888889
Epoch:  814        4 Batch loss: 0.072229 Batch F1: 0.6666666666666666
Epoch:  814        5 Batch loss: 0.077059 Batch F1: 0.7142857142857143
Epoch:  814        6 Batch loss: 0.079168 Batch F1: 0.7499999999999999
Epoch:  814        7 Batch loss: 0.088659 Batch F1: 0.8695652173913044
Epoch:  814        8 Batch loss: 0.077009 Batch F1: 0.9473684210526316
Epoch:  814        9 Batch loss: 0.075544 Batch F1: 0.8421052631578948
Epoch:  814       10 Batch loss: 0.067969 Batch F1: 0.8333333333333333
Epoch:  814       11 Batch loss: 0.060384 Batch F1: 1.0
Epoch:  814       12 Batch loss: 0.078602 Batch F1: 0.4444444444444445
Train Avg Loss  814: 0.069157

Train Avg F1  814: 0.8297214957684066

Val Avg Loss  814: 0.068988

Val Avg F1  814:  0.5646367521367521

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 815
--------------------------------------------------------------
Epoch:  815        1 Batch loss: 0.077755 Batch F1: 0.4615384615384615
Epoch:  815        2 Batch loss: 0.051213 Batch F1: 0.5714285714285715
Epoch:  815        3 Batch loss: 0.069351 Batch F1: 0.6153846153846153
Epoch:  815        4 Batch loss: 0.104980 Batch F1: 0.5263157894736842
Epoch:  815        5 Batch loss: 0.070558 Batch F1: 0.7142857142857143
Epoch:  815        6 Batch loss: 0.055587 Batch F1: 0.923076923076923
Epoch:  815        7 Batch loss: 0.054483 Batch F1: 1.0
Epoch:  815        8 Batch loss: 0.075571 Batch F1: 0.5
Epoch:  815        9 Batch loss: 0.079828 Batch F1: 0.9411764705882353
Epoch:  815       10 Batch loss: 0.079772 Batch F1: 0.823529411764706
Epoch:  815       11 Batch loss: 0.066673 Batch F1: 0.7142857142857143
Epoch:  815       12 Batch loss: 0.090719 Batch F1: 0.3636363636363636
Train Avg Loss  815: 0.073041

Train Avg F1  815: 0.6795548362885824

Val Avg Loss  815: 0.065030

Val Avg F1  815:  0.7305555555555555

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 816
--------------------------------------------------------------
Epoch:  816        1 Batch loss: 0.071849 Batch F1: 0.33333333333333337
Epoch:  816        2 Batch loss: 0.060247 Batch F1: 0.923076923076923
Epoch:  816        3 Batch loss: 0.078606 Batch F1: 0.8421052631578948
Epoch:  816        4 Batch loss: 0.073475 Batch F1: 0.8333333333333333
Epoch:  816        5 Batch loss: 0.063756 Batch F1: 0.9523809523809523
Epoch:  816        6 Batch loss: 0.049088 Batch F1: 1.0
Epoch:  816        7 Batch loss: 0.078285 Batch F1: 0.7142857142857143
Epoch:  816        8 Batch loss: 0.057378 Batch F1: 0.6666666666666666
Epoch:  816        9 Batch loss: 0.078449 Batch F1: 0.7499999999999999
Epoch:  816       10 Batch loss: 0.073666 Batch F1: 0.7058823529411764
Epoch:  816       11 Batch loss: 0.052718 Batch F1: 0.8
Epoch:  816       12 Batch loss: 0.088304 Batch F1: 0.6666666666666666
Train Avg Loss  816: 0.068818

Train Avg F1  816: 0.7656442671535552

Val Avg Loss  816: 0.065484

Val Avg F1  816:  0.9065934065934065

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 817
--------------------------------------------------------------
Epoch:  817        1 Batch loss: 0.068784 Batch F1: 0.8333333333333333
Epoch:  817        2 Batch loss: 0.058658 Batch F1: 1.0
Epoch:  817        3 Batch loss: 0.080713 Batch F1: 0.8
Epoch:  817        4 Batch loss: 0.076481 Batch F1: 0.625
Epoch:  817        5 Batch loss: 0.076244 Batch F1: 0.6153846153846154
Epoch:  817        6 Batch loss: 0.059386 Batch F1: 1.0
Epoch:  817        7 Batch loss: 0.085734 Batch F1: 0.761904761904762
Epoch:  817        8 Batch loss: 0.051838 Batch F1: 1.0
Epoch:  817        9 Batch loss: 0.084294 Batch F1: 0.923076923076923
Epoch:  817       10 Batch loss: 0.065994 Batch F1: 0.7499999999999999
Epoch:  817       11 Batch loss: 0.041486 Batch F1: 0.923076923076923
Epoch:  817       12 Batch loss: 0.068702 Batch F1: 0.4444444444444445
Train Avg Loss  817: 0.068193

Train Avg F1  817: 0.8063517501017502

Val Avg Loss  817: 0.066741

Val Avg F1  817:  0.6070018796992481

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 818
--------------------------------------------------------------
Epoch:  818        1 Batch loss: 0.053571 Batch F1: 0.6
Epoch:  818        2 Batch loss: 0.079918 Batch F1: 0.6666666666666666
Epoch:  818        3 Batch loss: 0.055987 Batch F1: 0.6666666666666666
Epoch:  818        4 Batch loss: 0.082156 Batch F1: 0.75
Epoch:  818        5 Batch loss: 0.063144 Batch F1: 0.9473684210526316
Epoch:  818        6 Batch loss: 0.068732 Batch F1: 0.9333333333333333
Epoch:  818        7 Batch loss: 0.065648 Batch F1: 0.6153846153846153
Epoch:  818        8 Batch loss: 0.093235 Batch F1: 0.2857142857142857
Epoch:  818        9 Batch loss: 0.054926 Batch F1: 0.5
Epoch:  818       10 Batch loss: 0.076454 Batch F1: 0.7499999999999999
Epoch:  818       11 Batch loss: 0.081250 Batch F1: 0.8571428571428571
Epoch:  818       12 Batch loss: 0.039159 Batch F1: 1.0
Train Avg Loss  818: 0.067848

Train Avg F1  818: 0.714356403830088

Val Avg Loss  818: 0.063643

Val Avg F1  818:  0.9206088029617441

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 819
--------------------------------------------------------------
Epoch:  819        1 Batch loss: 0.052467 Batch F1: 0.9090909090909091
Epoch:  819        2 Batch loss: 0.075942 Batch F1: 0.8750000000000001
Epoch:  819        3 Batch loss: 0.085686 Batch F1: 0.6086956521739131
Epoch:  819        4 Batch loss: 0.067230 Batch F1: 0.6666666666666666
Epoch:  819        5 Batch loss: 0.062509 Batch F1: 0.9
Epoch:  819        6 Batch loss: 0.066904 Batch F1: 0.9411764705882353
Epoch:  819        7 Batch loss: 0.065571 Batch F1: 0.8
Epoch:  819        8 Batch loss: 0.074347 Batch F1: 0.5714285714285714
Epoch:  819        9 Batch loss: 0.080825 Batch F1: 0.8181818181818181
Epoch:  819       10 Batch loss: 0.059786 Batch F1: 0.9333333333333333
Epoch:  819       11 Batch loss: 0.055311 Batch F1: 0.8
Epoch:  819       12 Batch loss: 0.056071 Batch F1: 0.8333333333333333
Train Avg Loss  819: 0.066887

Train Avg F1  819: 0.8047422295663984

Val Avg Loss  819: 0.061918

Val Avg F1  819:  0.7928758741258741

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 820
--------------------------------------------------------------
Epoch:  820        1 Batch loss: 0.053149 Batch F1: 0.7499999999999999
Epoch:  820        2 Batch loss: 0.077012 Batch F1: 0.4615384615384615
Epoch:  820        3 Batch loss: 0.065486 Batch F1: 0.5714285714285715
Epoch:  820        4 Batch loss: 0.069122 Batch F1: 0.6153846153846153
Epoch:  820        5 Batch loss: 0.065482 Batch F1: 0.6666666666666666
Epoch:  820        6 Batch loss: 0.085240 Batch F1: 0.7058823529411764
Epoch:  820        7 Batch loss: 0.069291 Batch F1: 0.923076923076923
Epoch:  820        8 Batch loss: 0.060578 Batch F1: 0.8571428571428571
Epoch:  820        9 Batch loss: 0.082793 Batch F1: 0.6666666666666666
Epoch:  820       10 Batch loss: 0.069271 Batch F1: 1.0
Epoch:  820       11 Batch loss: 0.072678 Batch F1: 0.9090909090909091
Epoch:  820       12 Batch loss: 0.049445 Batch F1: 0.888888888888889
Train Avg Loss  820: 0.068296

Train Avg F1  820: 0.7513139094021447

Val Avg Loss  820: 0.064560

Val Avg F1  820:  0.9047727272727273

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 821
--------------------------------------------------------------
Epoch:  821        1 Batch loss: 0.068991 Batch F1: 1.0
Epoch:  821        2 Batch loss: 0.073642 Batch F1: 1.0
Epoch:  821        3 Batch loss: 0.068532 Batch F1: 1.0
Epoch:  821        4 Batch loss: 0.057259 Batch F1: 0.2857142857142857
Epoch:  821        5 Batch loss: 0.084150 Batch F1: 0.2222222222222222
Epoch:  821        6 Batch loss: 0.071202 Batch F1: 0.6666666666666666
Epoch:  821        7 Batch loss: 0.065739 Batch F1: 0.4
Epoch:  821        8 Batch loss: 0.068031 Batch F1: 0.761904761904762
Epoch:  821        9 Batch loss: 0.065576 Batch F1: 0.9523809523809523
Epoch:  821       10 Batch loss: 0.077501 Batch F1: 0.8421052631578948
Epoch:  821       11 Batch loss: 0.082619 Batch F1: 0.8571428571428572
Epoch:  821       12 Batch loss: 0.042673 Batch F1: 1.0
Train Avg Loss  821: 0.068826

Train Avg F1  821: 0.7490114174324701

Val Avg Loss  821: 0.063711

Val Avg F1  821:  0.6320728291316527

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 822
--------------------------------------------------------------
Epoch:  822        1 Batch loss: 0.059807 Batch F1: 0.7272727272727273
Epoch:  822        2 Batch loss: 0.052012 Batch F1: 0.6666666666666666
Epoch:  822        3 Batch loss: 0.074620 Batch F1: 0.7058823529411764
Epoch:  822        4 Batch loss: 0.090401 Batch F1: 0.5882352941176471
Epoch:  822        5 Batch loss: 0.083592 Batch F1: 0.8333333333333333
Epoch:  822        6 Batch loss: 0.081404 Batch F1: 0.7272727272727272
Epoch:  822        7 Batch loss: 0.084671 Batch F1: 0.761904761904762
Epoch:  822        8 Batch loss: 0.053829 Batch F1: 0.6666666666666666
Epoch:  822        9 Batch loss: 0.057379 Batch F1: 1.0
Epoch:  822       10 Batch loss: 0.065064 Batch F1: 0.6666666666666666
Epoch:  822       11 Batch loss: 0.061599 Batch F1: 0.8571428571428571
Epoch:  822       12 Batch loss: 0.084476 Batch F1: 0.9333333333333333
Train Avg Loss  822: 0.070738

Train Avg F1  822: 0.7611981156098805

Val Avg Loss  822: 0.061888

Val Avg F1  822:  0.9186507936507937

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 823
--------------------------------------------------------------
Epoch:  823        1 Batch loss: 0.073182 Batch F1: 0.7142857142857143
Epoch:  823        2 Batch loss: 0.048312 Batch F1: 0.8
Epoch:  823        3 Batch loss: 0.050431 Batch F1: 0.6
Epoch:  823        4 Batch loss: 0.085301 Batch F1: 0.5333333333333333
Epoch:  823        5 Batch loss: 0.060047 Batch F1: 0.888888888888889
Epoch:  823        6 Batch loss: 0.061997 Batch F1: 0.7499999999999999
Epoch:  823        7 Batch loss: 0.073342 Batch F1: 0.9333333333333333
Epoch:  823        8 Batch loss: 0.070449 Batch F1: 1.0
Epoch:  823        9 Batch loss: 0.076952 Batch F1: 0.7777777777777778
Epoch:  823       10 Batch loss: 0.061097 Batch F1: 0.8333333333333333
Epoch:  823       11 Batch loss: 0.089305 Batch F1: 0.42857142857142855
Epoch:  823       12 Batch loss: 0.106403 Batch F1: 0.5
Train Avg Loss  823: 0.071401

Train Avg F1  823: 0.7299603174603174

Val Avg Loss  823: 0.066415

Val Avg F1  823:  0.6087662337662337

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 824
--------------------------------------------------------------
Epoch:  824        1 Batch loss: 0.068492 Batch F1: 0.5454545454545454
Epoch:  824        2 Batch loss: 0.086227 Batch F1: 0.5
Epoch:  824        3 Batch loss: 0.039202 Batch F1: 1.0
Epoch:  824        4 Batch loss: 0.074147 Batch F1: 0.5333333333333333
Epoch:  824        5 Batch loss: 0.067968 Batch F1: 0.6666666666666666
Epoch:  824        6 Batch loss: 0.059324 Batch F1: 0.8750000000000001
Epoch:  824        7 Batch loss: 0.085801 Batch F1: 0.7000000000000001
Epoch:  824        8 Batch loss: 0.063794 Batch F1: 0.9411764705882353
Epoch:  824        9 Batch loss: 0.066112 Batch F1: 0.9565217391304348
Epoch:  824       10 Batch loss: 0.079200 Batch F1: 0.9
Epoch:  824       11 Batch loss: 0.048253 Batch F1: 1.0
Epoch:  824       12 Batch loss: 0.075233 Batch F1: 0.7272727272727273
Train Avg Loss  824: 0.067813

Train Avg F1  824: 0.7787854568704953

Val Avg Loss  824: 0.065610

Val Avg F1  824:  0.6363636363636364

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 825
--------------------------------------------------------------
Epoch:  825        1 Batch loss: 0.050282 Batch F1: 0.5714285714285715
Epoch:  825        2 Batch loss: 0.094105 Batch F1: 0.4
Epoch:  825        3 Batch loss: 0.071034 Batch F1: 0.7368421052631579
Epoch:  825        4 Batch loss: 0.072682 Batch F1: 0.9565217391304348
Epoch:  825        5 Batch loss: 0.053797 Batch F1: 0.888888888888889
Epoch:  825        6 Batch loss: 0.096033 Batch F1: 0.7272727272727274
Epoch:  825        7 Batch loss: 0.064200 Batch F1: 0.6666666666666666
Epoch:  825        8 Batch loss: 0.055599 Batch F1: 0.2857142857142857
Epoch:  825        9 Batch loss: 0.090353 Batch F1: 0.3076923076923077
Epoch:  825       10 Batch loss: 0.056364 Batch F1: 0.8
Epoch:  825       11 Batch loss: 0.064947 Batch F1: 0.6666666666666666
Epoch:  825       12 Batch loss: 0.057360 Batch F1: 0.7272727272727273
Train Avg Loss  825: 0.068896

Train Avg F1  825: 0.6445805571663695

Val Avg Loss  825: 0.063251

Val Avg F1  825:  0.6265182186234818

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 826
--------------------------------------------------------------
Epoch:  826        1 Batch loss: 0.047316 Batch F1: 0.5
Epoch:  826        2 Batch loss: 0.094160 Batch F1: 0.6666666666666666
Epoch:  826        3 Batch loss: 0.074811 Batch F1: 0.5714285714285715
Epoch:  826        4 Batch loss: 0.063558 Batch F1: 0.8750000000000001
Epoch:  826        5 Batch loss: 0.065512 Batch F1: 0.8
Epoch:  826        6 Batch loss: 0.045297 Batch F1: 0.7499999999999999
Epoch:  826        7 Batch loss: 0.043809 Batch F1: 1.0
Epoch:  826        8 Batch loss: 0.096262 Batch F1: 0.33333333333333337
Epoch:  826        9 Batch loss: 0.084676 Batch F1: 0.5555555555555556
Epoch:  826       10 Batch loss: 0.083510 Batch F1: 0.7368421052631579
Epoch:  826       11 Batch loss: 0.062596 Batch F1: 0.7272727272727273
Epoch:  826       12 Batch loss: 0.040620 Batch F1: 1.0
Train Avg Loss  826: 0.066844

Train Avg F1  826: 0.7096749132933343

Val Avg Loss  826: 0.064262

Val Avg F1  826:  0.9311145510835914

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 827
--------------------------------------------------------------
Epoch:  827        1 Batch loss: 0.054771 Batch F1: 1.0
Epoch:  827        2 Batch loss: 0.078480 Batch F1: 0.8571428571428572
Epoch:  827        3 Batch loss: 0.088137 Batch F1: 0.8181818181818182
Epoch:  827        4 Batch loss: 0.047937 Batch F1: 0.8333333333333333
Epoch:  827        5 Batch loss: 0.118415 Batch F1: 0.5217391304347826
Epoch:  827        6 Batch loss: 0.062773 Batch F1: 0.7272727272727273
Epoch:  827        7 Batch loss: 0.069423 Batch F1: 0.9333333333333333
Epoch:  827        8 Batch loss: 0.049624 Batch F1: 0.9333333333333333
Epoch:  827        9 Batch loss: 0.091140 Batch F1: 0.7777777777777778
Epoch:  827       10 Batch loss: 0.045070 Batch F1: 0.8571428571428571
Epoch:  827       11 Batch loss: 0.060807 Batch F1: 0.7499999999999999
Epoch:  827       12 Batch loss: 0.067853 Batch F1: 0.5454545454545454
Train Avg Loss  827: 0.069536

Train Avg F1  827: 0.7962259761172805

Val Avg Loss  827: 0.066449

Val Avg F1  827:  0.6428071928071928

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 828
--------------------------------------------------------------
Epoch:  828        1 Batch loss: 0.034383 Batch F1: 0.8
Epoch:  828        2 Batch loss: 0.086369 Batch F1: 0.4615384615384615
Epoch:  828        3 Batch loss: 0.065915 Batch F1: 0.4615384615384615
Epoch:  828        4 Batch loss: 0.067661 Batch F1: 0.6
Epoch:  828        5 Batch loss: 0.079934 Batch F1: 0.888888888888889
Epoch:  828        6 Batch loss: 0.048671 Batch F1: 1.0
Epoch:  828        7 Batch loss: 0.081419 Batch F1: 0.8333333333333333
Epoch:  828        8 Batch loss: 0.067915 Batch F1: 0.9333333333333333
Epoch:  828        9 Batch loss: 0.089527 Batch F1: 0.5
Epoch:  828       10 Batch loss: 0.047301 Batch F1: 1.0
Epoch:  828       11 Batch loss: 0.066433 Batch F1: 0.9411764705882353
Epoch:  828       12 Batch loss: 0.075874 Batch F1: 0.6666666666666666
Train Avg Loss  828: 0.067617

Train Avg F1  828: 0.7572063013239482

Val Avg Loss  828: 0.065621

Val Avg F1  828:  0.7957251082251081

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 829
--------------------------------------------------------------
Epoch:  829        1 Batch loss: 0.059381 Batch F1: 0.8
Epoch:  829        2 Batch loss: 0.051468 Batch F1: 0.9090909090909091
Epoch:  829        3 Batch loss: 0.071651 Batch F1: 0.625
Epoch:  829        4 Batch loss: 0.053744 Batch F1: 0.7499999999999999
Epoch:  829        5 Batch loss: 0.077253 Batch F1: 0.5714285714285715
Epoch:  829        6 Batch loss: 0.097209 Batch F1: 0.6363636363636364
Epoch:  829        7 Batch loss: 0.058090 Batch F1: 0.9473684210526316
Epoch:  829        8 Batch loss: 0.085731 Batch F1: 0.75
Epoch:  829        9 Batch loss: 0.069074 Batch F1: 0.9473684210526316
Epoch:  829       10 Batch loss: 0.084487 Batch F1: 0.8571428571428572
Epoch:  829       11 Batch loss: 0.063835 Batch F1: 0.5
Epoch:  829       12 Batch loss: 0.039679 Batch F1: 0.0
Train Avg Loss  829: 0.067633

Train Avg F1  829: 0.6911469013442698

Val Avg Loss  829: 0.072164

Val Avg F1  829:  0.5220588235294118

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 830
--------------------------------------------------------------
Epoch:  830        1 Batch loss: 0.097429 Batch F1: 0.5263157894736842
Epoch:  830        2 Batch loss: 0.092073 Batch F1: 0.88
Epoch:  830        3 Batch loss: 0.074742 Batch F1: 0.8
Epoch:  830        4 Batch loss: 0.058912 Batch F1: 0.923076923076923
Epoch:  830        5 Batch loss: 0.054921 Batch F1: 0.5
Epoch:  830        6 Batch loss: 0.064125 Batch F1: 0.0
Epoch:  830        7 Batch loss: 0.089060 Batch F1: 0.375
Epoch:  830        8 Batch loss: 0.049394 Batch F1: 0.8000000000000002
Epoch:  830        9 Batch loss: 0.095705 Batch F1: 0.46153846153846156
Epoch:  830       10 Batch loss: 0.063501 Batch F1: 0.5454545454545454
Epoch:  830       11 Batch loss: 0.069615 Batch F1: 0.5
Epoch:  830       12 Batch loss: 0.084900 Batch F1: 0.6666666666666666
Train Avg Loss  830: 0.074531

Train Avg F1  830: 0.5815043655175234

Val Avg Loss  830: 0.071894

Val Avg F1  830:  0.9380952380952381

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 831
--------------------------------------------------------------
Epoch:  831        1 Batch loss: 0.068299 Batch F1: 0.967741935483871
Epoch:  831        2 Batch loss: 0.089745 Batch F1: 0.8750000000000001
Epoch:  831        3 Batch loss: 0.060047 Batch F1: 0.9473684210526316
Epoch:  831        4 Batch loss: 0.102541 Batch F1: 0.5555555555555556
Epoch:  831        5 Batch loss: 0.052578 Batch F1: 0.7272727272727273
Epoch:  831        6 Batch loss: 0.041533 Batch F1: 0.7499999999999999
Epoch:  831        7 Batch loss: 0.065767 Batch F1: 0.6
Epoch:  831        8 Batch loss: 0.068523 Batch F1: 0.5
Epoch:  831        9 Batch loss: 0.089743 Batch F1: 0.4615384615384615
Epoch:  831       10 Batch loss: 0.061335 Batch F1: 0.8
Epoch:  831       11 Batch loss: 0.065510 Batch F1: 0.6666666666666666
Epoch:  831       12 Batch loss: 0.055883 Batch F1: 0.8000000000000002
Train Avg Loss  831: 0.068459

Train Avg F1  831: 0.7209286472974928

Val Avg Loss  831: 0.062448

Val Avg F1  831:  0.6887840420449116

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 832
--------------------------------------------------------------
Epoch:  832        1 Batch loss: 0.068809 Batch F1: 0.7692307692307693
Epoch:  832        2 Batch loss: 0.067795 Batch F1: 0.7499999999999999
Epoch:  832        3 Batch loss: 0.069637 Batch F1: 0.2857142857142857
Epoch:  832        4 Batch loss: 0.052970 Batch F1: 0.33333333333333337
Epoch:  832        5 Batch loss: 0.082983 Batch F1: 0.625
Epoch:  832        6 Batch loss: 0.056340 Batch F1: 0.6666666666666666
Epoch:  832        7 Batch loss: 0.050836 Batch F1: 0.8235294117647058
Epoch:  832        8 Batch loss: 0.073394 Batch F1: 0.5333333333333333
Epoch:  832        9 Batch loss: 0.081936 Batch F1: 0.9565217391304348
Epoch:  832       10 Batch loss: 0.079713 Batch F1: 0.8695652173913043
Epoch:  832       11 Batch loss: 0.069517 Batch F1: 0.9473684210526316
Epoch:  832       12 Batch loss: 0.060288 Batch F1: 1.0
Train Avg Loss  832: 0.067851

Train Avg F1  832: 0.7133552648014554

Val Avg Loss  832: 0.062000

Val Avg F1  832:  0.841001400560224

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 833
--------------------------------------------------------------
Epoch:  833        1 Batch loss: 0.058709 Batch F1: 0.7272727272727273
Epoch:  833        2 Batch loss: 0.061123 Batch F1: 0.5714285714285715
Epoch:  833        3 Batch loss: 0.059218 Batch F1: 0.2857142857142857
Epoch:  833        4 Batch loss: 0.081584 Batch F1: 0.0
Epoch:  833        5 Batch loss: 0.077533 Batch F1: 0.5
Epoch:  833        6 Batch loss: 0.053620 Batch F1: 0.33333333333333337
Epoch:  833        7 Batch loss: 0.062115 Batch F1: 0.8421052631578948
Epoch:  833        8 Batch loss: 0.087920 Batch F1: 0.88
Epoch:  833        9 Batch loss: 0.075696 Batch F1: 0.9600000000000001
Epoch:  833       10 Batch loss: 0.082809 Batch F1: 0.9523809523809523
Epoch:  833       11 Batch loss: 0.064611 Batch F1: 0.9333333333333333
Epoch:  833       12 Batch loss: 0.074647 Batch F1: 0.9523809523809523
Train Avg Loss  833: 0.069965

Train Avg F1  833: 0.6614957849168376

Val Avg Loss  833: 0.068169

Val Avg F1  833:  0.9212962962962963

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 834
--------------------------------------------------------------
Epoch:  834        1 Batch loss: 0.076916 Batch F1: 0.9473684210526316
Epoch:  834        2 Batch loss: 0.045334 Batch F1: 1.0
Epoch:  834        3 Batch loss: 0.057923 Batch F1: 0.7142857142857143
Epoch:  834        4 Batch loss: 0.063970 Batch F1: 0.4444444444444445
Epoch:  834        5 Batch loss: 0.058532 Batch F1: 0.6
Epoch:  834        6 Batch loss: 0.065352 Batch F1: 0.8235294117647058
Epoch:  834        7 Batch loss: 0.117078 Batch F1: 0.25
Epoch:  834        8 Batch loss: 0.079367 Batch F1: 0.875
Epoch:  834        9 Batch loss: 0.074557 Batch F1: 0.9
Epoch:  834       10 Batch loss: 0.063052 Batch F1: 0.9523809523809523
Epoch:  834       11 Batch loss: 0.078202 Batch F1: 0.7368421052631579
Epoch:  834       12 Batch loss: 0.069838 Batch F1: 0.888888888888889
Train Avg Loss  834: 0.070843

Train Avg F1  834: 0.761061661506708

Val Avg Loss  834: 0.064646

Val Avg F1  834:  0.7383771929824561

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 835
--------------------------------------------------------------
Epoch:  835        1 Batch loss: 0.070049 Batch F1: 0.7499999999999999
Epoch:  835        2 Batch loss: 0.079139 Batch F1: 0.5714285714285715
Epoch:  835        3 Batch loss: 0.067105 Batch F1: 0.5454545454545454
Epoch:  835        4 Batch loss: 0.053548 Batch F1: 0.2857142857142857
Epoch:  835        5 Batch loss: 0.069775 Batch F1: 0.6666666666666666
Epoch:  835        6 Batch loss: 0.052675 Batch F1: 0.8333333333333333
Epoch:  835        7 Batch loss: 0.087848 Batch F1: 0.7058823529411764
Epoch:  835        8 Batch loss: 0.051228 Batch F1: 0.7499999999999999
Epoch:  835        9 Batch loss: 0.066141 Batch F1: 1.0
Epoch:  835       10 Batch loss: 0.079268 Batch F1: 0.8571428571428571
Epoch:  835       11 Batch loss: 0.067534 Batch F1: 0.8750000000000001
Epoch:  835       12 Batch loss: 0.071783 Batch F1: 0.888888888888889
Train Avg Loss  835: 0.068008

Train Avg F1  835: 0.7274592917975271

Val Avg Loss  835: 0.064027

Val Avg F1  835:  0.9177018633540373

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 836
--------------------------------------------------------------
Epoch:  836        1 Batch loss: 0.049919 Batch F1: 1.0
Epoch:  836        2 Batch loss: 0.062194 Batch F1: 0.9473684210526316
Epoch:  836        3 Batch loss: 0.057685 Batch F1: 1.0
Epoch:  836        4 Batch loss: 0.067147 Batch F1: 0.6666666666666666
Epoch:  836        5 Batch loss: 0.077296 Batch F1: 0.8
Epoch:  836        6 Batch loss: 0.083138 Batch F1: 0.7058823529411764
Epoch:  836        7 Batch loss: 0.059340 Batch F1: 1.0
Epoch:  836        8 Batch loss: 0.083353 Batch F1: 0.7368421052631579
Epoch:  836        9 Batch loss: 0.078469 Batch F1: 0.8235294117647058
Epoch:  836       10 Batch loss: 0.075182 Batch F1: 0.8750000000000001
Epoch:  836       11 Batch loss: 0.068104 Batch F1: 1.0
Epoch:  836       12 Batch loss: 0.067620 Batch F1: 0.5714285714285715
Train Avg Loss  836: 0.069120

Train Avg F1  836: 0.8438931274264091

Val Avg Loss  836: 0.065849

Val Avg F1  836:  0.8341269841269843

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 837
--------------------------------------------------------------
Epoch:  837        1 Batch loss: 0.070009 Batch F1: 0.8181818181818181
Epoch:  837        2 Batch loss: 0.078225 Batch F1: 0.8571428571428571
Epoch:  837        3 Batch loss: 0.056209 Batch F1: 0.823529411764706
Epoch:  837        4 Batch loss: 0.057496 Batch F1: 0.4444444444444445
Epoch:  837        5 Batch loss: 0.068438 Batch F1: 0.4
Epoch:  837        6 Batch loss: 0.046278 Batch F1: 0.33333333333333337
Epoch:  837        7 Batch loss: 0.051976 Batch F1: 0.5714285714285715
Epoch:  837        8 Batch loss: 0.067941 Batch F1: 0.6
Epoch:  837        9 Batch loss: 0.085654 Batch F1: 0.625
Epoch:  837       10 Batch loss: 0.092136 Batch F1: 0.7272727272727273
Epoch:  837       11 Batch loss: 0.086963 Batch F1: 0.6666666666666666
Epoch:  837       12 Batch loss: 0.086615 Batch F1: 0.9411764705882353
Train Avg Loss  837: 0.070662

Train Avg F1  837: 0.6506813584019467

Val Avg Loss  837: 0.070909

Val Avg F1  837:  0.9224358974358975

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 838
--------------------------------------------------------------
Epoch:  838        1 Batch loss: 0.063735 Batch F1: 0.9090909090909091
Epoch:  838        2 Batch loss: 0.055961 Batch F1: 0.8235294117647058
Epoch:  838        3 Batch loss: 0.064560 Batch F1: 0.75
Epoch:  838        4 Batch loss: 0.085940 Batch F1: 0.6153846153846153
Epoch:  838        5 Batch loss: 0.052345 Batch F1: 1.0
Epoch:  838        6 Batch loss: 0.119190 Batch F1: 0.7000000000000001
Epoch:  838        7 Batch loss: 0.083627 Batch F1: 0.9600000000000001
Epoch:  838        8 Batch loss: 0.070185 Batch F1: 1.0
Epoch:  838        9 Batch loss: 0.063857 Batch F1: 1.0
Epoch:  838       10 Batch loss: 0.079999 Batch F1: 0.625
Epoch:  838       11 Batch loss: 0.075048 Batch F1: 0.6153846153846153
Epoch:  838       12 Batch loss: 0.042679 Batch F1: 1.0
Train Avg Loss  838: 0.071427

Train Avg F1  838: 0.8331991293020704

Val Avg Loss  838: 0.069624

Val Avg F1  838:  0.6124401913875598

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 839
--------------------------------------------------------------
Epoch:  839        1 Batch loss: 0.100222 Batch F1: 0.5714285714285715
Epoch:  839        2 Batch loss: 0.065046 Batch F1: 0.8
Epoch:  839        3 Batch loss: 0.067443 Batch F1: 0.7499999999999999
Epoch:  839        4 Batch loss: 0.082749 Batch F1: 0.7000000000000001
Epoch:  839        5 Batch loss: 0.059579 Batch F1: 0.7692307692307693
Epoch:  839        6 Batch loss: 0.071058 Batch F1: 0.8235294117647058
Epoch:  839        7 Batch loss: 0.050346 Batch F1: 0.8
Epoch:  839        8 Batch loss: 0.053123 Batch F1: 0.4
Epoch:  839        9 Batch loss: 0.081538 Batch F1: 0.5454545454545454
Epoch:  839       10 Batch loss: 0.101998 Batch F1: 0.2857142857142857
Epoch:  839       11 Batch loss: 0.062547 Batch F1: 0.9473684210526316
Epoch:  839       12 Batch loss: 0.084930 Batch F1: 0.8571428571428571
Train Avg Loss  839: 0.073382

Train Avg F1  839: 0.6874890718156972

Val Avg Loss  839: 0.066732

Val Avg F1  839:  0.9218789727943046

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 840
--------------------------------------------------------------
Epoch:  840        1 Batch loss: 0.073032 Batch F1: 0.9
Epoch:  840        2 Batch loss: 0.067854 Batch F1: 0.7692307692307693
Epoch:  840        3 Batch loss: 0.063870 Batch F1: 0.7777777777777778
Epoch:  840        4 Batch loss: 0.067886 Batch F1: 0.6666666666666666
Epoch:  840        5 Batch loss: 0.033967 Batch F1: 0.8
Epoch:  840        6 Batch loss: 0.081533 Batch F1: 0.33333333333333337
Epoch:  840        7 Batch loss: 0.064477 Batch F1: 0.7142857142857143
Epoch:  840        8 Batch loss: 0.078976 Batch F1: 0.3636363636363636
Epoch:  840        9 Batch loss: 0.064443 Batch F1: 0.8750000000000001
Epoch:  840       10 Batch loss: 0.080726 Batch F1: 0.9565217391304348
Epoch:  840       11 Batch loss: 0.090553 Batch F1: 0.9523809523809523
Epoch:  840       12 Batch loss: 0.061503 Batch F1: 1.0
Train Avg Loss  840: 0.069068

Train Avg F1  840: 0.7590694430368342

Val Avg Loss  840: 0.065256

Val Avg F1  840:  0.7059294871794872

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 841
--------------------------------------------------------------
Epoch:  841        1 Batch loss: 0.062316 Batch F1: 0.8235294117647058
Epoch:  841        2 Batch loss: 0.049076 Batch F1: 0.5714285714285715
Epoch:  841        3 Batch loss: 0.057305 Batch F1: 0.2857142857142857
Epoch:  841        4 Batch loss: 0.068964 Batch F1: 0.0
Epoch:  841        5 Batch loss: 0.080440 Batch F1: 0.5714285714285715
Epoch:  841        6 Batch loss: 0.076189 Batch F1: 0.7368421052631579
Epoch:  841        7 Batch loss: 0.065193 Batch F1: 0.923076923076923
Epoch:  841        8 Batch loss: 0.064250 Batch F1: 0.8
Epoch:  841        9 Batch loss: 0.083606 Batch F1: 0.8695652173913044
Epoch:  841       10 Batch loss: 0.053332 Batch F1: 0.8571428571428571
Epoch:  841       11 Batch loss: 0.083366 Batch F1: 0.5555555555555556
Epoch:  841       12 Batch loss: 0.109793 Batch F1: 0.631578947368421
Train Avg Loss  841: 0.071153

Train Avg F1  841: 0.6354885371778628

Val Avg Loss  841: 0.065367

Val Avg F1  841:  0.8869245524296675

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 842
--------------------------------------------------------------
Epoch:  842        1 Batch loss: 0.071471 Batch F1: 1.0
Epoch:  842        2 Batch loss: 0.067956 Batch F1: 0.923076923076923
Epoch:  842        3 Batch loss: 0.076164 Batch F1: 0.4
Epoch:  842        4 Batch loss: 0.064117 Batch F1: 0.5
Epoch:  842        5 Batch loss: 0.073960 Batch F1: 0.6666666666666666
Epoch:  842        6 Batch loss: 0.051106 Batch F1: 0.6666666666666666
Epoch:  842        7 Batch loss: 0.096984 Batch F1: 0.8
Epoch:  842        8 Batch loss: 0.076363 Batch F1: 0.75
Epoch:  842        9 Batch loss: 0.061189 Batch F1: 0.9473684210526316
Epoch:  842       10 Batch loss: 0.069054 Batch F1: 0.7058823529411764
Epoch:  842       11 Batch loss: 0.065559 Batch F1: 0.6666666666666666
Epoch:  842       12 Batch loss: 0.070727 Batch F1: 0.8
Train Avg Loss  842: 0.070387

Train Avg F1  842: 0.7355273080892276

Val Avg Loss  842: 0.064090

Val Avg F1  842:  0.7561965811965812

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 843
--------------------------------------------------------------
Epoch:  843        1 Batch loss: 0.074393 Batch F1: 0.8235294117647058
Epoch:  843        2 Batch loss: 0.065371 Batch F1: 0.9411764705882353
Epoch:  843        3 Batch loss: 0.063869 Batch F1: 0.9333333333333333
Epoch:  843        4 Batch loss: 0.049843 Batch F1: 0.8
Epoch:  843        5 Batch loss: 0.066977 Batch F1: 0.4444444444444445
Epoch:  843        6 Batch loss: 0.089846 Batch F1: 0.6956521739130436
Epoch:  843        7 Batch loss: 0.077374 Batch F1: 0.9
Epoch:  843        8 Batch loss: 0.068246 Batch F1: 0.9523809523809523
Epoch:  843        9 Batch loss: 0.094226 Batch F1: 0.16666666666666669
Epoch:  843       10 Batch loss: 0.060929 Batch F1: 0.9
Epoch:  843       11 Batch loss: 0.063273 Batch F1: 0.8333333333333333
Epoch:  843       12 Batch loss: 0.076991 Batch F1: 0.6666666666666666
Train Avg Loss  843: 0.070945

Train Avg F1  843: 0.7547652877576153

Val Avg Loss  843: 0.066026

Val Avg F1  843:  0.7781767252355487

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 844
--------------------------------------------------------------
Epoch:  844        1 Batch loss: 0.074210 Batch F1: 0.9473684210526316
Epoch:  844        2 Batch loss: 0.064130 Batch F1: 0.6153846153846153
Epoch:  844        3 Batch loss: 0.069557 Batch F1: 0.6153846153846153
Epoch:  844        4 Batch loss: 0.076114 Batch F1: 0.6666666666666666
Epoch:  844        5 Batch loss: 0.061928 Batch F1: 0.5454545454545454
Epoch:  844        6 Batch loss: 0.044790 Batch F1: 0.9473684210526316
Epoch:  844        7 Batch loss: 0.080032 Batch F1: 0.8421052631578948
Epoch:  844        8 Batch loss: 0.069180 Batch F1: 0.8421052631578948
Epoch:  844        9 Batch loss: 0.079711 Batch F1: 0.9
Epoch:  844       10 Batch loss: 0.066650 Batch F1: 0.8333333333333333
Epoch:  844       11 Batch loss: 0.053631 Batch F1: 0.33333333333333337
Epoch:  844       12 Batch loss: 0.074795 Batch F1: 0.5454545454545454
Train Avg Loss  844: 0.067894

Train Avg F1  844: 0.719496585286059

Val Avg Loss  844: 0.069564

Val Avg F1  844:  0.6428571428571428

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 845
--------------------------------------------------------------
Epoch:  845        1 Batch loss: 0.079737 Batch F1: 0.5714285714285715
Epoch:  845        2 Batch loss: 0.078892 Batch F1: 0.5
Epoch:  845        3 Batch loss: 0.067874 Batch F1: 0.8235294117647058
Epoch:  845        4 Batch loss: 0.054553 Batch F1: 0.6666666666666666
Epoch:  845        5 Batch loss: 0.066018 Batch F1: 0.7058823529411764
Epoch:  845        6 Batch loss: 0.079774 Batch F1: 0.375
Epoch:  845        7 Batch loss: 0.060105 Batch F1: 0.8750000000000001
Epoch:  845        8 Batch loss: 0.081731 Batch F1: 0.8421052631578948
Epoch:  845        9 Batch loss: 0.066480 Batch F1: 0.9333333333333333
Epoch:  845       10 Batch loss: 0.065724 Batch F1: 0.8750000000000001
Epoch:  845       11 Batch loss: 0.056650 Batch F1: 0.7272727272727273
Epoch:  845       12 Batch loss: 0.050606 Batch F1: 1.0
Train Avg Loss  845: 0.067345

Train Avg F1  845: 0.741268193880423

Val Avg Loss  845: 0.062437

Val Avg F1  845:  0.7236652236652237

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 846
--------------------------------------------------------------
Epoch:  846        1 Batch loss: 0.056687 Batch F1: 0.8
Epoch:  846        2 Batch loss: 0.056910 Batch F1: 0.7142857142857143
Epoch:  846        3 Batch loss: 0.071336 Batch F1: 0.6666666666666666
Epoch:  846        4 Batch loss: 0.048545 Batch F1: 0.8
Epoch:  846        5 Batch loss: 0.056887 Batch F1: 0.6
Epoch:  846        6 Batch loss: 0.087029 Batch F1: 0.5714285714285715
Epoch:  846        7 Batch loss: 0.077863 Batch F1: 0.5
Epoch:  846        8 Batch loss: 0.051733 Batch F1: 0.888888888888889
Epoch:  846        9 Batch loss: 0.061349 Batch F1: 0.6153846153846153
Epoch:  846       10 Batch loss: 0.084263 Batch F1: 0.35294117647058826
Epoch:  846       11 Batch loss: 0.075537 Batch F1: 0.923076923076923
Epoch:  846       12 Batch loss: 0.102685 Batch F1: 0.9
Train Avg Loss  846: 0.069235

Train Avg F1  846: 0.6943893796834973

Val Avg Loss  846: 0.065106

Val Avg F1  846:  0.9017857142857142

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 847
--------------------------------------------------------------
Epoch:  847        1 Batch loss: 0.055854 Batch F1: 0.9333333333333333
Epoch:  847        2 Batch loss: 0.081226 Batch F1: 0.8
Epoch:  847        3 Batch loss: 0.065146 Batch F1: 1.0
Epoch:  847        4 Batch loss: 0.064823 Batch F1: 0.9411764705882353
Epoch:  847        5 Batch loss: 0.063621 Batch F1: 0.9
Epoch:  847        6 Batch loss: 0.090792 Batch F1: 0.2857142857142857
Epoch:  847        7 Batch loss: 0.062155 Batch F1: 0.7692307692307693
Epoch:  847        8 Batch loss: 0.080079 Batch F1: 0.9565217391304348
Epoch:  847        9 Batch loss: 0.068404 Batch F1: 0.8571428571428571
Epoch:  847       10 Batch loss: 0.055304 Batch F1: 0.8
Epoch:  847       11 Batch loss: 0.051686 Batch F1: 0.7499999999999999
Epoch:  847       12 Batch loss: 0.093605 Batch F1: 0.0
Train Avg Loss  847: 0.069391

Train Avg F1  847: 0.7494266212616596

Val Avg Loss  847: 0.070144

Val Avg F1  847:  0.5931547619047619

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 848
--------------------------------------------------------------
Epoch:  848        1 Batch loss: 0.073777 Batch F1: 0.6153846153846153
Epoch:  848        2 Batch loss: 0.080969 Batch F1: 0.7499999999999999
Epoch:  848        3 Batch loss: 0.062759 Batch F1: 1.0
Epoch:  848        4 Batch loss: 0.058331 Batch F1: 0.9411764705882353
Epoch:  848        5 Batch loss: 0.066616 Batch F1: 1.0
Epoch:  848        6 Batch loss: 0.054816 Batch F1: 0.9473684210526316
Epoch:  848        7 Batch loss: 0.089393 Batch F1: 0.5882352941176471
Epoch:  848        8 Batch loss: 0.069767 Batch F1: 0.5
Epoch:  848        9 Batch loss: 0.084410 Batch F1: 0.6153846153846153
Epoch:  848       10 Batch loss: 0.056990 Batch F1: 0.7272727272727273
Epoch:  848       11 Batch loss: 0.067285 Batch F1: 0.2857142857142857
Epoch:  848       12 Batch loss: 0.064984 Batch F1: 0.8
Train Avg Loss  848: 0.069175

Train Avg F1  848: 0.7308780357928965

Val Avg Loss  848: 0.063273

Val Avg F1  848:  0.742816742081448

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 849
--------------------------------------------------------------
Epoch:  849        1 Batch loss: 0.079111 Batch F1: 0.9
Epoch:  849        2 Batch loss: 0.065253 Batch F1: 0.9473684210526316
Epoch:  849        3 Batch loss: 0.086300 Batch F1: 0.9411764705882353
Epoch:  849        4 Batch loss: 0.069218 Batch F1: 0.9473684210526316
Epoch:  849        5 Batch loss: 0.060244 Batch F1: 0.8571428571428571
Epoch:  849        6 Batch loss: 0.066357 Batch F1: 0.6153846153846153
Epoch:  849        7 Batch loss: 0.070837 Batch F1: 0.6153846153846153
Epoch:  849        8 Batch loss: 0.043417 Batch F1: 0.9333333333333333
Epoch:  849        9 Batch loss: 0.079339 Batch F1: 0.4615384615384615
Epoch:  849       10 Batch loss: 0.063763 Batch F1: 0.9333333333333333
Epoch:  849       11 Batch loss: 0.070814 Batch F1: 0.823529411764706
Epoch:  849       12 Batch loss: 0.080459 Batch F1: 0.7272727272727273
Train Avg Loss  849: 0.069593

Train Avg F1  849: 0.8085693889873456

Val Avg Loss  849: 0.064962

Val Avg F1  849:  0.6324484339190222

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 850
--------------------------------------------------------------
Epoch:  850        1 Batch loss: 0.081907 Batch F1: 0.5555555555555556
Epoch:  850        2 Batch loss: 0.080855 Batch F1: 0.625
Epoch:  850        3 Batch loss: 0.065734 Batch F1: 0.9
Epoch:  850        4 Batch loss: 0.060762 Batch F1: 0.8333333333333334
Epoch:  850        5 Batch loss: 0.045937 Batch F1: 1.0
Epoch:  850        6 Batch loss: 0.073194 Batch F1: 0.7142857142857143
Epoch:  850        7 Batch loss: 0.092678 Batch F1: 0.4210526315789474
Epoch:  850        8 Batch loss: 0.058297 Batch F1: 0.9333333333333333
Epoch:  850        9 Batch loss: 0.056878 Batch F1: 0.888888888888889
Epoch:  850       10 Batch loss: 0.080218 Batch F1: 0.6153846153846153
Epoch:  850       11 Batch loss: 0.067659 Batch F1: 0.2222222222222222
Epoch:  850       12 Batch loss: 0.064168 Batch F1: 0.8
Train Avg Loss  850: 0.069024

Train Avg F1  850: 0.709088024548551

Val Avg Loss  850: 0.065795

Val Avg F1  850:  0.5833333333333334

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 851
--------------------------------------------------------------
Epoch:  851        1 Batch loss: 0.048635 Batch F1: 0.5
Epoch:  851        2 Batch loss: 0.088034 Batch F1: 0.5555555555555556
Epoch:  851        3 Batch loss: 0.050081 Batch F1: 0.7272727272727273
Epoch:  851        4 Batch loss: 0.076602 Batch F1: 0.4615384615384615
Epoch:  851        5 Batch loss: 0.067088 Batch F1: 0.6666666666666666
Epoch:  851        6 Batch loss: 0.081913 Batch F1: 0.33333333333333337
Epoch:  851        7 Batch loss: 0.059111 Batch F1: 0.8235294117647058
Epoch:  851        8 Batch loss: 0.065785 Batch F1: 0.6666666666666666
Epoch:  851        9 Batch loss: 0.058229 Batch F1: 0.888888888888889
Epoch:  851       10 Batch loss: 0.072610 Batch F1: 0.8
Epoch:  851       11 Batch loss: 0.071687 Batch F1: 0.8571428571428571
Epoch:  851       12 Batch loss: 0.065554 Batch F1: 0.9411764705882353
Train Avg Loss  851: 0.067111

Train Avg F1  851: 0.6851475866181748

Val Avg Loss  851: 0.063228

Val Avg F1  851:  0.9304029304029304

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 852
--------------------------------------------------------------
Epoch:  852        1 Batch loss: 0.070464 Batch F1: 1.0
Epoch:  852        2 Batch loss: 0.078548 Batch F1: 0.88
Epoch:  852        3 Batch loss: 0.064426 Batch F1: 1.0
Epoch:  852        4 Batch loss: 0.057877 Batch F1: 0.9333333333333333
Epoch:  852        5 Batch loss: 0.073930 Batch F1: 0.9090909090909091
Epoch:  852        6 Batch loss: 0.060159 Batch F1: 1.0
Epoch:  852        7 Batch loss: 0.064295 Batch F1: 0.9090909090909091
Epoch:  852        8 Batch loss: 0.050896 Batch F1: 0.8333333333333333
Epoch:  852        9 Batch loss: 0.066090 Batch F1: 0.4
Epoch:  852       10 Batch loss: 0.064179 Batch F1: 0.7142857142857143
Epoch:  852       11 Batch loss: 0.078461 Batch F1: 0.5714285714285715
Epoch:  852       12 Batch loss: 0.103087 Batch F1: 0.2222222222222222
Train Avg Loss  852: 0.069368

Train Avg F1  852: 0.7810654160654159

Val Avg Loss  852: 0.063415

Val Avg F1  852:  0.8722910216718267

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 853
--------------------------------------------------------------
Epoch:  853        1 Batch loss: 0.063308 Batch F1: 0.9333333333333333
Epoch:  853        2 Batch loss: 0.057622 Batch F1: 0.8750000000000001
Epoch:  853        3 Batch loss: 0.073426 Batch F1: 0.9
Epoch:  853        4 Batch loss: 0.093962 Batch F1: 0.9285714285714286
Epoch:  853        5 Batch loss: 0.066860 Batch F1: 1.0
Epoch:  853        6 Batch loss: 0.060720 Batch F1: 0.6666666666666666
Epoch:  853        7 Batch loss: 0.063088 Batch F1: 0.8
Epoch:  853        8 Batch loss: 0.059157 Batch F1: 0.0
Epoch:  853        9 Batch loss: 0.087597 Batch F1: 0.0
Epoch:  853       10 Batch loss: 0.083323 Batch F1: 0.2857142857142857
Epoch:  853       11 Batch loss: 0.086396 Batch F1: 0.8695652173913044
Epoch:  853       12 Batch loss: 0.078331 Batch F1: 0.8888888888888888
Train Avg Loss  853: 0.072816

Train Avg F1  853: 0.6789783183804924

Val Avg Loss  853: 0.067653

Val Avg F1  853:  0.9107142857142857

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 854
--------------------------------------------------------------
Epoch:  854        1 Batch loss: 0.090012 Batch F1: 0.9166666666666666
Epoch:  854        2 Batch loss: 0.059536 Batch F1: 0.5454545454545454
Epoch:  854        3 Batch loss: 0.107131 Batch F1: 0.4
Epoch:  854        4 Batch loss: 0.077704 Batch F1: 0.5
Epoch:  854        5 Batch loss: 0.058697 Batch F1: 0.6666666666666666
Epoch:  854        6 Batch loss: 0.052136 Batch F1: 0.6
Epoch:  854        7 Batch loss: 0.065899 Batch F1: 0.6153846153846153
Epoch:  854        8 Batch loss: 0.076359 Batch F1: 0.5
Epoch:  854        9 Batch loss: 0.051708 Batch F1: 0.7272727272727273
Epoch:  854       10 Batch loss: 0.062714 Batch F1: 0.9411764705882353
Epoch:  854       11 Batch loss: 0.054868 Batch F1: 0.9411764705882353
Epoch:  854       12 Batch loss: 0.069747 Batch F1: 0.9411764705882353
Train Avg Loss  854: 0.068876

Train Avg F1  854: 0.6912478861008272

Val Avg Loss  854: 0.064136

Val Avg F1  854:  0.9123774509803921

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 855
--------------------------------------------------------------
Epoch:  855        1 Batch loss: 0.059012 Batch F1: 0.8333333333333333
Epoch:  855        2 Batch loss: 0.081791 Batch F1: 0.5714285714285715
Epoch:  855        3 Batch loss: 0.092858 Batch F1: 0.42857142857142855
Epoch:  855        4 Batch loss: 0.059298 Batch F1: 0.8333333333333333
Epoch:  855        5 Batch loss: 0.075171 Batch F1: 0.7142857142857143
Epoch:  855        6 Batch loss: 0.089100 Batch F1: 0.6666666666666666
Epoch:  855        7 Batch loss: 0.058778 Batch F1: 0.888888888888889
Epoch:  855        8 Batch loss: 0.076689 Batch F1: 0.8571428571428572
Epoch:  855        9 Batch loss: 0.051324 Batch F1: 0.9333333333333333
Epoch:  855       10 Batch loss: 0.060449 Batch F1: 0.923076923076923
Epoch:  855       11 Batch loss: 0.056578 Batch F1: 0.8571428571428571
Epoch:  855       12 Batch loss: 0.056608 Batch F1: 0.5
Train Avg Loss  855: 0.068138

Train Avg F1  855: 0.7506003256003257

Val Avg Loss  855: 0.062909

Val Avg F1  855:  0.614024864024864

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 856
--------------------------------------------------------------
Epoch:  856        1 Batch loss: 0.050105 Batch F1: 0.7692307692307693
Epoch:  856        2 Batch loss: 0.052023 Batch F1: 0.4444444444444445
Epoch:  856        3 Batch loss: 0.043569 Batch F1: 0.9333333333333333
Epoch:  856        4 Batch loss: 0.096609 Batch F1: 0.4
Epoch:  856        5 Batch loss: 0.065734 Batch F1: 0.8750000000000001
Epoch:  856        6 Batch loss: 0.052185 Batch F1: 0.923076923076923
Epoch:  856        7 Batch loss: 0.073134 Batch F1: 0.6666666666666667
Epoch:  856        8 Batch loss: 0.064358 Batch F1: 0.8235294117647058
Epoch:  856        9 Batch loss: 0.044946 Batch F1: 0.8333333333333333
Epoch:  856       10 Batch loss: 0.074975 Batch F1: 0.5
Epoch:  856       11 Batch loss: 0.084585 Batch F1: 0.8
Epoch:  856       12 Batch loss: 0.091129 Batch F1: 0.8235294117647058
Train Avg Loss  856: 0.066113

Train Avg F1  856: 0.7326786911345735

Val Avg Loss  856: 0.061749

Val Avg F1  856:  0.7745761183261184

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 857
--------------------------------------------------------------
Epoch:  857        1 Batch loss: 0.038959 Batch F1: 1.0
Epoch:  857        2 Batch loss: 0.088400 Batch F1: 0.5555555555555556
Epoch:  857        3 Batch loss: 0.056690 Batch F1: 0.5
Epoch:  857        4 Batch loss: 0.060286 Batch F1: 0.888888888888889
Epoch:  857        5 Batch loss: 0.086125 Batch F1: 0.8333333333333333
Epoch:  857        6 Batch loss: 0.078677 Batch F1: 0.8421052631578948
Epoch:  857        7 Batch loss: 0.085649 Batch F1: 0.6666666666666666
Epoch:  857        8 Batch loss: 0.064822 Batch F1: 1.0
Epoch:  857        9 Batch loss: 0.051889 Batch F1: 1.0
Epoch:  857       10 Batch loss: 0.071437 Batch F1: 0.888888888888889
Epoch:  857       11 Batch loss: 0.075498 Batch F1: 1.0
Epoch:  857       12 Batch loss: 0.046871 Batch F1: 1.0
Train Avg Loss  857: 0.067109

Train Avg F1  857: 0.847953216374269

Val Avg Loss  857: 0.064417

Val Avg F1  857:  0.6068764568764569

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 858
--------------------------------------------------------------
Epoch:  858        1 Batch loss: 0.082819 Batch F1: 0.5555555555555556
Epoch:  858        2 Batch loss: 0.059624 Batch F1: 0.6666666666666666
Epoch:  858        3 Batch loss: 0.074211 Batch F1: 0.7368421052631579
Epoch:  858        4 Batch loss: 0.042981 Batch F1: 0.5714285714285715
Epoch:  858        5 Batch loss: 0.068595 Batch F1: 0.8571428571428571
Epoch:  858        6 Batch loss: 0.080445 Batch F1: 0.75
Epoch:  858        7 Batch loss: 0.056932 Batch F1: 1.0
Epoch:  858        8 Batch loss: 0.041983 Batch F1: 0.5
Epoch:  858        9 Batch loss: 0.099940 Batch F1: 0.4
Epoch:  858       10 Batch loss: 0.075163 Batch F1: 0.7142857142857143
Epoch:  858       11 Batch loss: 0.077620 Batch F1: 0.6666666666666666
Epoch:  858       12 Batch loss: 0.065046 Batch F1: 0.4444444444444445
Train Avg Loss  858: 0.068780

Train Avg F1  858: 0.6552527151211364

Val Avg Loss  858: 0.063930

Val Avg F1  858:  0.7222222222222222

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 859
--------------------------------------------------------------
Epoch:  859        1 Batch loss: 0.062364 Batch F1: 0.8750000000000001
Epoch:  859        2 Batch loss: 0.065297 Batch F1: 0.9
Epoch:  859        3 Batch loss: 0.073068 Batch F1: 0.888888888888889
Epoch:  859        4 Batch loss: 0.082981 Batch F1: 0.9090909090909091
Epoch:  859        5 Batch loss: 0.067058 Batch F1: 1.0
Epoch:  859        6 Batch loss: 0.055950 Batch F1: 0.8750000000000001
Epoch:  859        7 Batch loss: 0.052840 Batch F1: 0.8
Epoch:  859        8 Batch loss: 0.075111 Batch F1: 0.4
Epoch:  859        9 Batch loss: 0.082519 Batch F1: 0.5333333333333333
Epoch:  859       10 Batch loss: 0.038765 Batch F1: 0.9090909090909091
Epoch:  859       11 Batch loss: 0.090669 Batch F1: 0.47058823529411764
Epoch:  859       12 Batch loss: 0.071277 Batch F1: 0.7272727272727273
Train Avg Loss  859: 0.068158

Train Avg F1  859: 0.7740220835809071

Val Avg Loss  859: 0.064218

Val Avg F1  859:  0.9122753676529419

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 860
--------------------------------------------------------------
Epoch:  860        1 Batch loss: 0.056374 Batch F1: 0.7499999999999999
Epoch:  860        2 Batch loss: 0.083913 Batch F1: 0.8181818181818181
Epoch:  860        3 Batch loss: 0.051139 Batch F1: 0.9411764705882353
Epoch:  860        4 Batch loss: 0.086511 Batch F1: 0.7142857142857143
Epoch:  860        5 Batch loss: 0.066461 Batch F1: 0.8571428571428571
Epoch:  860        6 Batch loss: 0.056930 Batch F1: 1.0
Epoch:  860        7 Batch loss: 0.087575 Batch F1: 0.4
Epoch:  860        8 Batch loss: 0.045880 Batch F1: 0.7272727272727273
Epoch:  860        9 Batch loss: 0.091209 Batch F1: 0.5
Epoch:  860       10 Batch loss: 0.074719 Batch F1: 0.6153846153846154
Epoch:  860       11 Batch loss: 0.048437 Batch F1: 0.8571428571428571
Epoch:  860       12 Batch loss: 0.065188 Batch F1: 0.6666666666666666
Train Avg Loss  860: 0.067861

Train Avg F1  860: 0.7372711438887909

Val Avg Loss  860: 0.063365

Val Avg F1  860:  0.6383971291866029

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 861
--------------------------------------------------------------
Epoch:  861        1 Batch loss: 0.043834 Batch F1: 0.8571428571428571
Epoch:  861        2 Batch loss: 0.088989 Batch F1: 0.6
Epoch:  861        3 Batch loss: 0.083810 Batch F1: 0.5263157894736842
Epoch:  861        4 Batch loss: 0.081844 Batch F1: 0.888888888888889
Epoch:  861        5 Batch loss: 0.068069 Batch F1: 0.7272727272727272
Epoch:  861        6 Batch loss: 0.075248 Batch F1: 0.8421052631578948
Epoch:  861        7 Batch loss: 0.064207 Batch F1: 0.9090909090909091
Epoch:  861        8 Batch loss: 0.057921 Batch F1: 1.0
Epoch:  861        9 Batch loss: 0.050649 Batch F1: 0.9333333333333333
Epoch:  861       10 Batch loss: 0.076052 Batch F1: 0.625
Epoch:  861       11 Batch loss: 0.067113 Batch F1: 0.8
Epoch:  861       12 Batch loss: 0.065761 Batch F1: 0.8333333333333333
Train Avg Loss  861: 0.068625

Train Avg F1  861: 0.7952069251411357

Val Avg Loss  861: 0.063297

Val Avg F1  861:  0.8690753690753691

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 862
--------------------------------------------------------------
Epoch:  862        1 Batch loss: 0.070286 Batch F1: 0.8571428571428571
Epoch:  862        2 Batch loss: 0.048239 Batch F1: 0.923076923076923
Epoch:  862        3 Batch loss: 0.045982 Batch F1: 0.8571428571428571
Epoch:  862        4 Batch loss: 0.088066 Batch F1: 0.4
Epoch:  862        5 Batch loss: 0.088364 Batch F1: 0.5882352941176471
Epoch:  862        6 Batch loss: 0.072223 Batch F1: 0.6666666666666666
Epoch:  862        7 Batch loss: 0.063246 Batch F1: 0.6153846153846153
Epoch:  862        8 Batch loss: 0.061937 Batch F1: 0.6153846153846153
Epoch:  862        9 Batch loss: 0.070696 Batch F1: 0.7142857142857143
Epoch:  862       10 Batch loss: 0.052252 Batch F1: 1.0
Epoch:  862       11 Batch loss: 0.071342 Batch F1: 0.8421052631578948
Epoch:  862       12 Batch loss: 0.068328 Batch F1: 0.8750000000000001
Train Avg Loss  862: 0.066747

Train Avg F1  862: 0.7462020671966493

Val Avg Loss  862: 0.062597

Val Avg F1  862:  0.8952205882352942

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 863
--------------------------------------------------------------
Epoch:  863        1 Batch loss: 0.073388 Batch F1: 0.8000000000000002
Epoch:  863        2 Batch loss: 0.059397 Batch F1: 0.8235294117647058
Epoch:  863        3 Batch loss: 0.055137 Batch F1: 0.8235294117647058
Epoch:  863        4 Batch loss: 0.063763 Batch F1: 0.7777777777777778
Epoch:  863        5 Batch loss: 0.063865 Batch F1: 0.6
Epoch:  863        6 Batch loss: 0.067639 Batch F1: 0.7058823529411764
Epoch:  863        7 Batch loss: 0.060008 Batch F1: 0.4
Epoch:  863        8 Batch loss: 0.076773 Batch F1: 0.9090909090909091
Epoch:  863        9 Batch loss: 0.055909 Batch F1: 0.888888888888889
Epoch:  863       10 Batch loss: 0.078266 Batch F1: 0.7058823529411764
Epoch:  863       11 Batch loss: 0.085606 Batch F1: 0.4
Epoch:  863       12 Batch loss: 0.065770 Batch F1: 0.7272727272727273
Train Avg Loss  863: 0.067127

Train Avg F1  863: 0.7134878193701724

Val Avg Loss  863: 0.062634

Val Avg F1  863:  0.8232600732600732

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 864
--------------------------------------------------------------
Epoch:  864        1 Batch loss: 0.075988 Batch F1: 0.88
Epoch:  864        2 Batch loss: 0.074118 Batch F1: 0.8695652173913043
Epoch:  864        3 Batch loss: 0.063393 Batch F1: 0.6666666666666666
Epoch:  864        4 Batch loss: 0.096402 Batch F1: 0.7058823529411764
Epoch:  864        5 Batch loss: 0.055580 Batch F1: 0.5454545454545454
Epoch:  864        6 Batch loss: 0.074479 Batch F1: 0.5714285714285715
Epoch:  864        7 Batch loss: 0.074075 Batch F1: 0.7142857142857143
Epoch:  864        8 Batch loss: 0.055856 Batch F1: 0.9090909090909091
Epoch:  864        9 Batch loss: 0.071434 Batch F1: 0.9565217391304348
Epoch:  864       10 Batch loss: 0.068806 Batch F1: 0.7272727272727273
Epoch:  864       11 Batch loss: 0.057423 Batch F1: 0.8
Epoch:  864       12 Batch loss: 0.087699 Batch F1: 0.2222222222222222
Train Avg Loss  864: 0.071271

Train Avg F1  864: 0.7140325554903559

Val Avg Loss  864: 0.068412

Val Avg F1  864:  0.6268939393939393

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 865
--------------------------------------------------------------
Epoch:  865        1 Batch loss: 0.047797 Batch F1: 0.6666666666666666
Epoch:  865        2 Batch loss: 0.072872 Batch F1: 0.6666666666666666
Epoch:  865        3 Batch loss: 0.086188 Batch F1: 0.7368421052631579
Epoch:  865        4 Batch loss: 0.074039 Batch F1: 0.9
Epoch:  865        5 Batch loss: 0.084120 Batch F1: 0.888888888888889
Epoch:  865        6 Batch loss: 0.064368 Batch F1: 0.9411764705882353
Epoch:  865        7 Batch loss: 0.063152 Batch F1: 0.9523809523809523
Epoch:  865        8 Batch loss: 0.062093 Batch F1: 0.6153846153846153
Epoch:  865        9 Batch loss: 0.054026 Batch F1: 0.8333333333333333
Epoch:  865       10 Batch loss: 0.075332 Batch F1: 0.4
Epoch:  865       11 Batch loss: 0.064512 Batch F1: 0.7142857142857143
Epoch:  865       12 Batch loss: 0.070193 Batch F1: 0.0
Train Avg Loss  865: 0.068224

Train Avg F1  865: 0.6929687844548525

Val Avg Loss  865: 0.064598

Val Avg F1  865:  0.5864527629233511

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 866
--------------------------------------------------------------
Epoch:  866        1 Batch loss: 0.071210 Batch F1: 0.5333333333333333
Epoch:  866        2 Batch loss: 0.085908 Batch F1: 0.7058823529411764
Epoch:  866        3 Batch loss: 0.064188 Batch F1: 1.0
Epoch:  866        4 Batch loss: 0.071548 Batch F1: 0.6666666666666666
Epoch:  866        5 Batch loss: 0.055803 Batch F1: 0.8
Epoch:  866        6 Batch loss: 0.060403 Batch F1: 0.5454545454545454
Epoch:  866        7 Batch loss: 0.069683 Batch F1: 0.7058823529411764
Epoch:  866        8 Batch loss: 0.060574 Batch F1: 0.2857142857142857
Epoch:  866        9 Batch loss: 0.085930 Batch F1: 0.8
Epoch:  866       10 Batch loss: 0.066003 Batch F1: 0.923076923076923
Epoch:  866       11 Batch loss: 0.070079 Batch F1: 1.0
Epoch:  866       12 Batch loss: 0.065480 Batch F1: 0.8333333333333333
Train Avg Loss  866: 0.068901

Train Avg F1  866: 0.7332786494551201

Val Avg Loss  866: 0.066226

Val Avg F1  866:  0.925455221107395

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 867
--------------------------------------------------------------
Epoch:  867        1 Batch loss: 0.063461 Batch F1: 0.8333333333333333
Epoch:  867        2 Batch loss: 0.071498 Batch F1: 0.8
Epoch:  867        3 Batch loss: 0.049765 Batch F1: 1.0
Epoch:  867        4 Batch loss: 0.058006 Batch F1: 1.0
Epoch:  867        5 Batch loss: 0.054810 Batch F1: 0.33333333333333337
Epoch:  867        6 Batch loss: 0.076231 Batch F1: 0.33333333333333337
Epoch:  867        7 Batch loss: 0.100299 Batch F1: 0.5555555555555556
Epoch:  867        8 Batch loss: 0.092149 Batch F1: 0.5555555555555556
Epoch:  867        9 Batch loss: 0.065977 Batch F1: 0.6666666666666666
Epoch:  867       10 Batch loss: 0.073231 Batch F1: 0.9333333333333333
Epoch:  867       11 Batch loss: 0.076932 Batch F1: 0.9
Epoch:  867       12 Batch loss: 0.057701 Batch F1: 0.888888888888889
Train Avg Loss  867: 0.070005

Train Avg F1  867: 0.7333333333333334

Val Avg Loss  867: 0.064603

Val Avg F1  867:  0.9415584415584416

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 868
--------------------------------------------------------------
Epoch:  868        1 Batch loss: 0.072823 Batch F1: 0.8571428571428571
Epoch:  868        2 Batch loss: 0.062363 Batch F1: 1.0
Epoch:  868        3 Batch loss: 0.055802 Batch F1: 0.6666666666666666
Epoch:  868        4 Batch loss: 0.055889 Batch F1: 0.6
Epoch:  868        5 Batch loss: 0.074300 Batch F1: 0.4615384615384615
Epoch:  868        6 Batch loss: 0.073987 Batch F1: 0.7272727272727273
Epoch:  868        7 Batch loss: 0.084191 Batch F1: 0.8571428571428571
Epoch:  868        8 Batch loss: 0.084807 Batch F1: 0.88
Epoch:  868        9 Batch loss: 0.066889 Batch F1: 0.8
Epoch:  868       10 Batch loss: 0.072241 Batch F1: 0.8421052631578948
Epoch:  868       11 Batch loss: 0.057301 Batch F1: 0.7142857142857143
Epoch:  868       12 Batch loss: 0.072728 Batch F1: 0.7142857142857143
Train Avg Loss  868: 0.069443

Train Avg F1  868: 0.760036688457741

Val Avg Loss  868: 0.063786

Val Avg F1  868:  0.7633928571428572

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 869
--------------------------------------------------------------
Epoch:  869        1 Batch loss: 0.054723 Batch F1: 0.9090909090909091
Epoch:  869        2 Batch loss: 0.060312 Batch F1: 0.7499999999999999
Epoch:  869        3 Batch loss: 0.088683 Batch F1: 0.4
Epoch:  869        4 Batch loss: 0.071051 Batch F1: 0.8750000000000001
Epoch:  869        5 Batch loss: 0.085500 Batch F1: 0.9
Epoch:  869        6 Batch loss: 0.070137 Batch F1: 0.7499999999999999
Epoch:  869        7 Batch loss: 0.076452 Batch F1: 0.625
Epoch:  869        8 Batch loss: 0.084119 Batch F1: 0.7368421052631579
Epoch:  869        9 Batch loss: 0.091423 Batch F1: 0.6086956521739131
Epoch:  869       10 Batch loss: 0.054110 Batch F1: 0.9333333333333333
Epoch:  869       11 Batch loss: 0.046734 Batch F1: 1.0
Epoch:  869       12 Batch loss: 0.083121 Batch F1: 0.7499999999999999
Train Avg Loss  869: 0.072197

Train Avg F1  869: 0.7698301666551094

Val Avg Loss  869: 0.064404

Val Avg F1  869:  0.7492784992784993

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 870
--------------------------------------------------------------
Epoch:  870        1 Batch loss: 0.091287 Batch F1: 0.625
Epoch:  870        2 Batch loss: 0.057310 Batch F1: 0.6
Epoch:  870        3 Batch loss: 0.059101 Batch F1: 0.5454545454545454
Epoch:  870        4 Batch loss: 0.075879 Batch F1: 0.7058823529411764
Epoch:  870        5 Batch loss: 0.058875 Batch F1: 0.9090909090909091
Epoch:  870        6 Batch loss: 0.074379 Batch F1: 0.888888888888889
Epoch:  870        7 Batch loss: 0.060450 Batch F1: 1.0
Epoch:  870        8 Batch loss: 0.075266 Batch F1: 1.0
Epoch:  870        9 Batch loss: 0.077966 Batch F1: 0.8421052631578948
Epoch:  870       10 Batch loss: 0.061192 Batch F1: 0.5454545454545454
Epoch:  870       11 Batch loss: 0.065696 Batch F1: 0.5454545454545454
Epoch:  870       12 Batch loss: 0.066629 Batch F1: 0.5
Train Avg Loss  870: 0.068669

Train Avg F1  870: 0.7256109208702087

Val Avg Loss  870: 0.063477

Val Avg F1  870:  0.607051282051282

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 871
--------------------------------------------------------------
Epoch:  871        1 Batch loss: 0.045723 Batch F1: 0.7272727272727273
Epoch:  871        2 Batch loss: 0.066072 Batch F1: 0.5714285714285715
Epoch:  871        3 Batch loss: 0.061701 Batch F1: 0.888888888888889
Epoch:  871        4 Batch loss: 0.060135 Batch F1: 0.7499999999999999
Epoch:  871        5 Batch loss: 0.086155 Batch F1: 0.4
Epoch:  871        6 Batch loss: 0.109748 Batch F1: 0.4210526315789474
Epoch:  871        7 Batch loss: 0.065323 Batch F1: 0.9473684210526316
Epoch:  871        8 Batch loss: 0.082462 Batch F1: 0.9655172413793104
Epoch:  871        9 Batch loss: 0.093678 Batch F1: 0.8571428571428571
Epoch:  871       10 Batch loss: 0.058418 Batch F1: 1.0
Epoch:  871       11 Batch loss: 0.072436 Batch F1: 0.7499999999999999
Epoch:  871       12 Batch loss: 0.062248 Batch F1: 0.2857142857142857
Train Avg Loss  871: 0.072008

Train Avg F1  871: 0.713698802038185

Val Avg Loss  871: 0.069279

Val Avg F1  871:  0.5978298017771702

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 872
--------------------------------------------------------------
Epoch:  872        1 Batch loss: 0.068226 Batch F1: 0.7142857142857143
Epoch:  872        2 Batch loss: 0.092635 Batch F1: 0.5555555555555556
Epoch:  872        3 Batch loss: 0.069735 Batch F1: 0.7499999999999999
Epoch:  872        4 Batch loss: 0.061797 Batch F1: 0.923076923076923
Epoch:  872        5 Batch loss: 0.061018 Batch F1: 0.6666666666666666
Epoch:  872        6 Batch loss: 0.072087 Batch F1: 0.7499999999999999
Epoch:  872        7 Batch loss: 0.085390 Batch F1: 0.3636363636363636
Epoch:  872        8 Batch loss: 0.064245 Batch F1: 0.5454545454545454
Epoch:  872        9 Batch loss: 0.068253 Batch F1: 0.8
Epoch:  872       10 Batch loss: 0.066176 Batch F1: 0.888888888888889
Epoch:  872       11 Batch loss: 0.091123 Batch F1: 0.923076923076923
Epoch:  872       12 Batch loss: 0.083508 Batch F1: 0.9090909090909091
Train Avg Loss  872: 0.073683

Train Avg F1  872: 0.7324777074777075

Val Avg Loss  872: 0.066603

Val Avg F1  872:  0.9262663398692811

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 873
--------------------------------------------------------------
Epoch:  873        1 Batch loss: 0.082366 Batch F1: 0.8571428571428571
Epoch:  873        2 Batch loss: 0.066715 Batch F1: 0.5454545454545454
Epoch:  873        3 Batch loss: 0.057178 Batch F1: 0.8235294117647058
Epoch:  873        4 Batch loss: 0.072803 Batch F1: 0.5454545454545454
Epoch:  873        5 Batch loss: 0.056366 Batch F1: 0.7272727272727273
Epoch:  873        6 Batch loss: 0.058417 Batch F1: 0.7692307692307693
Epoch:  873        7 Batch loss: 0.057483 Batch F1: 0.8571428571428571
Epoch:  873        8 Batch loss: 0.087094 Batch F1: 0.8571428571428572
Epoch:  873        9 Batch loss: 0.074802 Batch F1: 0.875
Epoch:  873       10 Batch loss: 0.053701 Batch F1: 0.8333333333333334
Epoch:  873       11 Batch loss: 0.087259 Batch F1: 0.7000000000000001
Epoch:  873       12 Batch loss: 0.083663 Batch F1: 0.3636363636363636
Train Avg Loss  873: 0.069821

Train Avg F1  873: 0.7295283556312967

Val Avg Loss  873: 0.064113

Val Avg F1  873:  0.6130952380952381

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 874
--------------------------------------------------------------
Epoch:  874        1 Batch loss: 0.050457 Batch F1: 0.5454545454545454
Epoch:  874        2 Batch loss: 0.079282 Batch F1: 0.5
Epoch:  874        3 Batch loss: 0.081457 Batch F1: 0.7000000000000001
Epoch:  874        4 Batch loss: 0.060431 Batch F1: 0.8333333333333333
Epoch:  874        5 Batch loss: 0.062736 Batch F1: 0.8571428571428571
Epoch:  874        6 Batch loss: 0.054099 Batch F1: 0.923076923076923
Epoch:  874        7 Batch loss: 0.051391 Batch F1: 0.7272727272727273
Epoch:  874        8 Batch loss: 0.077499 Batch F1: 0.5333333333333333
Epoch:  874        9 Batch loss: 0.058377 Batch F1: 0.8235294117647058
Epoch:  874       10 Batch loss: 0.071796 Batch F1: 0.6
Epoch:  874       11 Batch loss: 0.081499 Batch F1: 0.5882352941176471
Epoch:  874       12 Batch loss: 0.069244 Batch F1: 0.8
Train Avg Loss  874: 0.066522

Train Avg F1  874: 0.7026148687913394

Val Avg Loss  874: 0.062226

Val Avg F1  874:  0.8689393939393939

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 875
--------------------------------------------------------------
Epoch:  875        1 Batch loss: 0.070234 Batch F1: 0.8235294117647058
Epoch:  875        2 Batch loss: 0.083343 Batch F1: 0.8695652173913044
Epoch:  875        3 Batch loss: 0.081553 Batch F1: 0.8695652173913044
Epoch:  875        4 Batch loss: 0.070406 Batch F1: 0.8333333333333334
Epoch:  875        5 Batch loss: 0.060674 Batch F1: 0.923076923076923
Epoch:  875        6 Batch loss: 0.048429 Batch F1: 0.8571428571428571
Epoch:  875        7 Batch loss: 0.069073 Batch F1: 0.6153846153846153
Epoch:  875        8 Batch loss: 0.063970 Batch F1: 0.6153846153846153
Epoch:  875        9 Batch loss: 0.043371 Batch F1: 0.888888888888889
Epoch:  875       10 Batch loss: 0.073881 Batch F1: 0.5333333333333333
Epoch:  875       11 Batch loss: 0.090305 Batch F1: 0.14285714285714288
Epoch:  875       12 Batch loss: 0.048411 Batch F1: 0.8571428571428571
Train Avg Loss  875: 0.066971

Train Avg F1  875: 0.7357670344243235

Val Avg Loss  875: 0.063220

Val Avg F1  875:  0.8341269841269842

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 876
--------------------------------------------------------------
Epoch:  876        1 Batch loss: 0.061306 Batch F1: 0.9411764705882353
Epoch:  876        2 Batch loss: 0.073386 Batch F1: 0.888888888888889
Epoch:  876        3 Batch loss: 0.089904 Batch F1: 0.6666666666666666
Epoch:  876        4 Batch loss: 0.080137 Batch F1: 0.7058823529411764
Epoch:  876        5 Batch loss: 0.050785 Batch F1: 0.9411764705882353
Epoch:  876        6 Batch loss: 0.082769 Batch F1: 0.8181818181818181
Epoch:  876        7 Batch loss: 0.059414 Batch F1: 0.7999999999999999
Epoch:  876        8 Batch loss: 0.052584 Batch F1: 1.0
Epoch:  876        9 Batch loss: 0.071114 Batch F1: 0.8571428571428571
Epoch:  876       10 Batch loss: 0.066673 Batch F1: 0.8571428571428571
Epoch:  876       11 Batch loss: 0.071779 Batch F1: 0.625
Epoch:  876       12 Batch loss: 0.066354 Batch F1: 0.5
Train Avg Loss  876: 0.068850

Train Avg F1  876: 0.8001048651783945

Val Avg Loss  876: 0.068416

Val Avg F1  876:  0.47916666666666663

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 877
--------------------------------------------------------------
Epoch:  877        1 Batch loss: 0.080098 Batch F1: 0.4615384615384615
Epoch:  877        2 Batch loss: 0.063617 Batch F1: 0.6666666666666666
Epoch:  877        3 Batch loss: 0.056316 Batch F1: 1.0
Epoch:  877        4 Batch loss: 0.069768 Batch F1: 0.9411764705882353
Epoch:  877        5 Batch loss: 0.060062 Batch F1: 0.8750000000000001
Epoch:  877        6 Batch loss: 0.086831 Batch F1: 0.7142857142857143
Epoch:  877        7 Batch loss: 0.099257 Batch F1: 0.5882352941176471
Epoch:  877        8 Batch loss: 0.063425 Batch F1: 0.9333333333333333
Epoch:  877        9 Batch loss: 0.052957 Batch F1: 0.888888888888889
Epoch:  877       10 Batch loss: 0.090355 Batch F1: 0.6666666666666666
Epoch:  877       11 Batch loss: 0.061330 Batch F1: 0.9333333333333333
Epoch:  877       12 Batch loss: 0.052059 Batch F1: 1.0
Train Avg Loss  877: 0.069673

Train Avg F1  877: 0.805760402451579

Val Avg Loss  877: 0.064626

Val Avg F1  877:  0.8260131681184313

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 878
--------------------------------------------------------------
Epoch:  878        1 Batch loss: 0.096143 Batch F1: 0.7499999999999999
Epoch:  878        2 Batch loss: 0.065420 Batch F1: 0.888888888888889
Epoch:  878        3 Batch loss: 0.088311 Batch F1: 0.9090909090909091
Epoch:  878        4 Batch loss: 0.061351 Batch F1: 0.9473684210526316
Epoch:  878        5 Batch loss: 0.060144 Batch F1: 0.9411764705882353
Epoch:  878        6 Batch loss: 0.058709 Batch F1: 0.8571428571428571
Epoch:  878        7 Batch loss: 0.050375 Batch F1: 0.6666666666666666
Epoch:  878        8 Batch loss: 0.050626 Batch F1: 0.8
Epoch:  878        9 Batch loss: 0.076346 Batch F1: 0.25
Epoch:  878       10 Batch loss: 0.078559 Batch F1: 0.5
Epoch:  878       11 Batch loss: 0.060746 Batch F1: 0.6666666666666666
Epoch:  878       12 Batch loss: 0.061497 Batch F1: 0.5454545454545454
Train Avg Loss  878: 0.067352

Train Avg F1  878: 0.7268712854626167

Val Avg Loss  878: 0.063241

Val Avg F1  878:  0.7795771479982005

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 879
--------------------------------------------------------------
Epoch:  879        1 Batch loss: 0.065673 Batch F1: 0.7692307692307693
Epoch:  879        2 Batch loss: 0.061673 Batch F1: 1.0
Epoch:  879        3 Batch loss: 0.074911 Batch F1: 0.8750000000000001
Epoch:  879        4 Batch loss: 0.082906 Batch F1: 0.7142857142857143
Epoch:  879        5 Batch loss: 0.062477 Batch F1: 0.88
Epoch:  879        6 Batch loss: 0.055082 Batch F1: 0.8
Epoch:  879        7 Batch loss: 0.059443 Batch F1: 0.875
Epoch:  879        8 Batch loss: 0.089242 Batch F1: 0.7058823529411764
Epoch:  879        9 Batch loss: 0.070899 Batch F1: 0.7058823529411764
Epoch:  879       10 Batch loss: 0.068216 Batch F1: 0.6153846153846154
Epoch:  879       11 Batch loss: 0.059379 Batch F1: 0.5454545454545454
Epoch:  879       12 Batch loss: 0.052621 Batch F1: 0.33333333333333337
Train Avg Loss  879: 0.066877

Train Avg F1  879: 0.7349544736309442

Val Avg Loss  879: 0.062859

Val Avg F1  879:  0.5970779220779222

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 880
--------------------------------------------------------------
Epoch:  880        1 Batch loss: 0.085699 Batch F1: 0.3076923076923077
Epoch:  880        2 Batch loss: 0.059800 Batch F1: 0.6666666666666666
Epoch:  880        3 Batch loss: 0.059956 Batch F1: 0.8571428571428571
Epoch:  880        4 Batch loss: 0.047930 Batch F1: 0.923076923076923
Epoch:  880        5 Batch loss: 0.085966 Batch F1: 0.5333333333333333
Epoch:  880        6 Batch loss: 0.049956 Batch F1: 0.0
Epoch:  880        7 Batch loss: 0.084649 Batch F1: 0.6956521739130436
Epoch:  880        8 Batch loss: 0.068936 Batch F1: 0.9090909090909091
Epoch:  880        9 Batch loss: 0.058387 Batch F1: 0.9411764705882353
Epoch:  880       10 Batch loss: 0.092932 Batch F1: 0.8181818181818181
Epoch:  880       11 Batch loss: 0.080282 Batch F1: 0.9
Epoch:  880       12 Batch loss: 0.049775 Batch F1: 0.8571428571428571
Train Avg Loss  880: 0.068689

Train Avg F1  880: 0.7007630264024126

Val Avg Loss  880: 0.064139

Val Avg F1  880:  0.8763636363636363

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 881
--------------------------------------------------------------
Epoch:  881        1 Batch loss: 0.067112 Batch F1: 0.8750000000000001
Epoch:  881        2 Batch loss: 0.062251 Batch F1: 0.7272727272727273
Epoch:  881        3 Batch loss: 0.069238 Batch F1: 0.6666666666666666
Epoch:  881        4 Batch loss: 0.094106 Batch F1: 0.6666666666666666
Epoch:  881        5 Batch loss: 0.054421 Batch F1: 1.0
Epoch:  881        6 Batch loss: 0.051344 Batch F1: 0.6666666666666666
Epoch:  881        7 Batch loss: 0.068109 Batch F1: 0.5454545454545454
Epoch:  881        8 Batch loss: 0.065213 Batch F1: 0.4444444444444445
Epoch:  881        9 Batch loss: 0.094016 Batch F1: 0.5555555555555556
Epoch:  881       10 Batch loss: 0.050341 Batch F1: 0.8571428571428571
Epoch:  881       11 Batch loss: 0.069076 Batch F1: 0.5714285714285715
Epoch:  881       12 Batch loss: 0.075681 Batch F1: 0.8
Train Avg Loss  881: 0.068409

Train Avg F1  881: 0.6980248917748918

Val Avg Loss  881: 0.066394

Val Avg F1  881:  0.9375901875901875

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 882
--------------------------------------------------------------
Epoch:  882        1 Batch loss: 0.073389 Batch F1: 0.9
Epoch:  882        2 Batch loss: 0.069743 Batch F1: 0.7999999999999999
Epoch:  882        3 Batch loss: 0.091652 Batch F1: 0.9714285714285714
Epoch:  882        4 Batch loss: 0.069525 Batch F1: 0.8
Epoch:  882        5 Batch loss: 0.068835 Batch F1: 0.2222222222222222
Epoch:  882        6 Batch loss: 0.063769 Batch F1: 0.7499999999999999
Epoch:  882        7 Batch loss: 0.052570 Batch F1: 0.5714285714285715
Epoch:  882        8 Batch loss: 0.066506 Batch F1: 0.8571428571428571
Epoch:  882        9 Batch loss: 0.059257 Batch F1: 0.8333333333333333
Epoch:  882       10 Batch loss: 0.083391 Batch F1: 0.5882352941176471
Epoch:  882       11 Batch loss: 0.081322 Batch F1: 0.8571428571428571
Epoch:  882       12 Batch loss: 0.080392 Batch F1: 0.8333333333333333
Train Avg Loss  882: 0.071696

Train Avg F1  882: 0.7486889200124494

Val Avg Loss  882: 0.066892

Val Avg F1  882:  0.8916666666666666

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 883
--------------------------------------------------------------
Epoch:  883        1 Batch loss: 0.075542 Batch F1: 0.7142857142857143
Epoch:  883        2 Batch loss: 0.057911 Batch F1: 0.7692307692307693
Epoch:  883        3 Batch loss: 0.057164 Batch F1: 0.25
Epoch:  883        4 Batch loss: 0.069543 Batch F1: 0.5454545454545454
Epoch:  883        5 Batch loss: 0.099824 Batch F1: 0.5882352941176471
Epoch:  883        6 Batch loss: 0.060040 Batch F1: 0.8333333333333334
Epoch:  883        7 Batch loss: 0.066596 Batch F1: 0.8888888888888888
Epoch:  883        8 Batch loss: 0.066210 Batch F1: 0.4444444444444445
Epoch:  883        9 Batch loss: 0.072793 Batch F1: 0.782608695652174
Epoch:  883       10 Batch loss: 0.087055 Batch F1: 0.4615384615384615
Epoch:  883       11 Batch loss: 0.060958 Batch F1: 0.8750000000000001
Epoch:  883       12 Batch loss: 0.075331 Batch F1: 0.8750000000000001
Train Avg Loss  883: 0.070747

Train Avg F1  883: 0.6690016789121649

Val Avg Loss  883: 0.064764

Val Avg F1  883:  0.9103174603174604

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 884
--------------------------------------------------------------
Epoch:  884        1 Batch loss: 0.057660 Batch F1: 0.9411764705882353
Epoch:  884        2 Batch loss: 0.057930 Batch F1: 0.9333333333333333
Epoch:  884        3 Batch loss: 0.065421 Batch F1: 0.923076923076923
Epoch:  884        4 Batch loss: 0.079755 Batch F1: 0.8
Epoch:  884        5 Batch loss: 0.075694 Batch F1: 0.7058823529411764
Epoch:  884        6 Batch loss: 0.079262 Batch F1: 0.625
Epoch:  884        7 Batch loss: 0.083512 Batch F1: 0.16666666666666669
Epoch:  884        8 Batch loss: 0.068186 Batch F1: 0.7272727272727273
Epoch:  884        9 Batch loss: 0.076116 Batch F1: 0.962962962962963
Epoch:  884       10 Batch loss: 0.063486 Batch F1: 0.8750000000000001
Epoch:  884       11 Batch loss: 0.062685 Batch F1: 0.7272727272727272
Epoch:  884       12 Batch loss: 0.055275 Batch F1: 1.0
Train Avg Loss  884: 0.068749

Train Avg F1  884: 0.782303680342896

Val Avg Loss  884: 0.062664

Val Avg F1  884:  0.6410984848484849

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 885
--------------------------------------------------------------
Epoch:  885        1 Batch loss: 0.065221 Batch F1: 0.5454545454545454
Epoch:  885        2 Batch loss: 0.076301 Batch F1: 0.7000000000000001
Epoch:  885        3 Batch loss: 0.057335 Batch F1: 0.6
Epoch:  885        4 Batch loss: 0.093077 Batch F1: 0.6666666666666666
Epoch:  885        5 Batch loss: 0.087094 Batch F1: 0.782608695652174
Epoch:  885        6 Batch loss: 0.064449 Batch F1: 0.8571428571428571
Epoch:  885        7 Batch loss: 0.067849 Batch F1: 0.7499999999999999
Epoch:  885        8 Batch loss: 0.065286 Batch F1: 0.8235294117647058
Epoch:  885        9 Batch loss: 0.041812 Batch F1: 0.8571428571428571
Epoch:  885       10 Batch loss: 0.079508 Batch F1: 0.4615384615384615
Epoch:  885       11 Batch loss: 0.052498 Batch F1: 0.6
Epoch:  885       12 Batch loss: 0.101319 Batch F1: 0.4615384615384615
Train Avg Loss  885: 0.070979

Train Avg F1  885: 0.675468496408394

Val Avg Loss  885: 0.066422

Val Avg F1  885:  0.8611673414304993

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 886
--------------------------------------------------------------
Epoch:  886        1 Batch loss: 0.055530 Batch F1: 0.9333333333333333
Epoch:  886        2 Batch loss: 0.073994 Batch F1: 1.0
Epoch:  886        3 Batch loss: 0.078909 Batch F1: 0.8571428571428572
Epoch:  886        4 Batch loss: 0.053470 Batch F1: 0.8333333333333333
Epoch:  886        5 Batch loss: 0.058722 Batch F1: 0.6153846153846153
Epoch:  886        6 Batch loss: 0.121966 Batch F1: 0.5263157894736842
Epoch:  886        7 Batch loss: 0.066118 Batch F1: 0.2857142857142857
Epoch:  886        8 Batch loss: 0.068356 Batch F1: 0.7272727272727273
Epoch:  886        9 Batch loss: 0.067149 Batch F1: 0.8333333333333333
Epoch:  886       10 Batch loss: 0.056044 Batch F1: 0.9333333333333333
Epoch:  886       11 Batch loss: 0.049289 Batch F1: 0.923076923076923
Epoch:  886       12 Batch loss: 0.093790 Batch F1: 0.3636363636363636
Train Avg Loss  886: 0.070278

Train Avg F1  886: 0.7359897412528991

Val Avg Loss  886: 0.062306

Val Avg F1  886:  0.7205128205128205

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 887
--------------------------------------------------------------
Epoch:  887        1 Batch loss: 0.063889 Batch F1: 0.7368421052631579
Epoch:  887        2 Batch loss: 0.053248 Batch F1: 0.8571428571428571
Epoch:  887        3 Batch loss: 0.042504 Batch F1: 1.0
Epoch:  887        4 Batch loss: 0.088773 Batch F1: 0.4615384615384615
Epoch:  887        5 Batch loss: 0.061265 Batch F1: 0.5454545454545454
Epoch:  887        6 Batch loss: 0.036434 Batch F1: 0.8
Epoch:  887        7 Batch loss: 0.058295 Batch F1: 0.6666666666666666
Epoch:  887        8 Batch loss: 0.041105 Batch F1: 0.8
Epoch:  887        9 Batch loss: 0.080273 Batch F1: 0.4
Epoch:  887       10 Batch loss: 0.102923 Batch F1: 0.2857142857142857
Epoch:  887       11 Batch loss: 0.099491 Batch F1: 0.4444444444444445
Epoch:  887       12 Batch loss: 0.077860 Batch F1: 0.8750000000000001
Train Avg Loss  887: 0.067172

Train Avg F1  887: 0.6560669471853683

Val Avg Loss  887: 0.066795

Val Avg F1  887:  0.9329377519032692

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 888
--------------------------------------------------------------
Epoch:  888        1 Batch loss: 0.071117 Batch F1: 0.7692307692307693
Epoch:  888        2 Batch loss: 0.059306 Batch F1: 1.0
Epoch:  888        3 Batch loss: 0.087100 Batch F1: 0.8799999999999999
Epoch:  888        4 Batch loss: 0.075884 Batch F1: 0.7777777777777777
Epoch:  888        5 Batch loss: 0.075411 Batch F1: 0.7142857142857143
Epoch:  888        6 Batch loss: 0.074818 Batch F1: 0.2222222222222222
Epoch:  888        7 Batch loss: 0.090117 Batch F1: 0.761904761904762
Epoch:  888        8 Batch loss: 0.068047 Batch F1: 0.8235294117647058
Epoch:  888        9 Batch loss: 0.069354 Batch F1: 1.0
Epoch:  888       10 Batch loss: 0.074477 Batch F1: 1.0
Epoch:  888       11 Batch loss: 0.076060 Batch F1: 0.9473684210526316
Epoch:  888       12 Batch loss: 0.048538 Batch F1: 0.6666666666666666
Train Avg Loss  888: 0.072519

Train Avg F1  888: 0.796915478742104

Val Avg Loss  888: 0.078594

Val Avg F1  888:  0.0

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 889
--------------------------------------------------------------
Epoch:  889        1 Batch loss: 0.055781 Batch F1: 0.0
Epoch:  889        2 Batch loss: 0.097575 Batch F1: 0.16666666666666669
Epoch:  889        3 Batch loss: 0.054136 Batch F1: 0.25
Epoch:  889        4 Batch loss: 0.077125 Batch F1: 0.9523809523809523
Epoch:  889        5 Batch loss: 0.080875 Batch F1: 0.8421052631578948
Epoch:  889        6 Batch loss: 0.070012 Batch F1: 0.9473684210526316
Epoch:  889        7 Batch loss: 0.090520 Batch F1: 0.6666666666666666
Epoch:  889        8 Batch loss: 0.065696 Batch F1: 0.6
Epoch:  889        9 Batch loss: 0.070466 Batch F1: 0.4615384615384615
Epoch:  889       10 Batch loss: 0.048781 Batch F1: 0.888888888888889
Epoch:  889       11 Batch loss: 0.094939 Batch F1: 0.8750000000000001
Epoch:  889       12 Batch loss: 0.086353 Batch F1: 0.25
Train Avg Loss  889: 0.074355

Train Avg F1  889: 0.5750512766960135

Val Avg Loss  889: 0.067705

Val Avg F1  889:  0.7276997168638035

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 890
--------------------------------------------------------------
Epoch:  890        1 Batch loss: 0.086951 Batch F1: 0.7499999999999999
Epoch:  890        2 Batch loss: 0.076931 Batch F1: 0.6
Epoch:  890        3 Batch loss: 0.071154 Batch F1: 0.7499999999999999
Epoch:  890        4 Batch loss: 0.068179 Batch F1: 0.8235294117647058
Epoch:  890        5 Batch loss: 0.074442 Batch F1: 0.888888888888889
Epoch:  890        6 Batch loss: 0.065330 Batch F1: 0.7692307692307692
Epoch:  890        7 Batch loss: 0.061071 Batch F1: 0.25
Epoch:  890        8 Batch loss: 0.093477 Batch F1: 0.5333333333333333
Epoch:  890        9 Batch loss: 0.067665 Batch F1: 0.19999999999999998
Epoch:  890       10 Batch loss: 0.064051 Batch F1: 0.6
Epoch:  890       11 Batch loss: 0.045643 Batch F1: 0.8750000000000001
Epoch:  890       12 Batch loss: 0.065816 Batch F1: 0.923076923076923
Train Avg Loss  890: 0.070059

Train Avg F1  890: 0.6635882771912184

Val Avg Loss  890: 0.065538

Val Avg F1  890:  0.7267857142857143

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 891
--------------------------------------------------------------
Epoch:  891        1 Batch loss: 0.059735 Batch F1: 0.8571428571428571
Epoch:  891        2 Batch loss: 0.099935 Batch F1: 0.5714285714285715
Epoch:  891        3 Batch loss: 0.064980 Batch F1: 0.7777777777777778
Epoch:  891        4 Batch loss: 0.050569 Batch F1: 0.8333333333333333
Epoch:  891        5 Batch loss: 0.063450 Batch F1: 0.8333333333333333
Epoch:  891        6 Batch loss: 0.059158 Batch F1: 0.9473684210526316
Epoch:  891        7 Batch loss: 0.070112 Batch F1: 0.9411764705882353
Epoch:  891        8 Batch loss: 0.046459 Batch F1: 0.8571428571428571
Epoch:  891        9 Batch loss: 0.084484 Batch F1: 0.5
Epoch:  891       10 Batch loss: 0.076094 Batch F1: 0.7499999999999999
Epoch:  891       11 Batch loss: 0.076950 Batch F1: 0.8
Epoch:  891       12 Batch loss: 0.075867 Batch F1: 0.9411764705882353
Train Avg Loss  891: 0.068983

Train Avg F1  891: 0.8008233410323194

Val Avg Loss  891: 0.063895

Val Avg F1  891:  0.8378035718189172

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 892
--------------------------------------------------------------
Epoch:  892        1 Batch loss: 0.095174 Batch F1: 0.8
Epoch:  892        2 Batch loss: 0.085563 Batch F1: 0.9375
Epoch:  892        3 Batch loss: 0.047507 Batch F1: 1.0
Epoch:  892        4 Batch loss: 0.080175 Batch F1: 0.9333333333333333
Epoch:  892        5 Batch loss: 0.067590 Batch F1: 0.9333333333333333
Epoch:  892        6 Batch loss: 0.072163 Batch F1: 0.5
Epoch:  892        7 Batch loss: 0.056029 Batch F1: 0.5
Epoch:  892        8 Batch loss: 0.044010 Batch F1: 0.7499999999999999
Epoch:  892        9 Batch loss: 0.080331 Batch F1: 0.5333333333333333
Epoch:  892       10 Batch loss: 0.059816 Batch F1: 0.6666666666666666
Epoch:  892       11 Batch loss: 0.069390 Batch F1: 0.5714285714285715
Epoch:  892       12 Batch loss: 0.068544 Batch F1: 0.8750000000000001
Train Avg Loss  892: 0.068858

Train Avg F1  892: 0.7500496031746032

Val Avg Loss  892: 0.065821

Val Avg F1  892:  0.9230769230769231

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 893
--------------------------------------------------------------
Epoch:  893        1 Batch loss: 0.067006 Batch F1: 0.8
Epoch:  893        2 Batch loss: 0.089041 Batch F1: 0.888888888888889
Epoch:  893        3 Batch loss: 0.052742 Batch F1: 1.0
Epoch:  893        4 Batch loss: 0.063226 Batch F1: 1.0
Epoch:  893        5 Batch loss: 0.066441 Batch F1: 0.8235294117647058
Epoch:  893        6 Batch loss: 0.049594 Batch F1: 0.8333333333333333
Epoch:  893        7 Batch loss: 0.047720 Batch F1: 0.8333333333333333
Epoch:  893        8 Batch loss: 0.108391 Batch F1: 0.42857142857142855
Epoch:  893        9 Batch loss: 0.064423 Batch F1: 0.7058823529411764
Epoch:  893       10 Batch loss: 0.040362 Batch F1: 0.9090909090909091
Epoch:  893       11 Batch loss: 0.072554 Batch F1: 0.33333333333333337
Epoch:  893       12 Batch loss: 0.086303 Batch F1: 0.6666666666666666
Train Avg Loss  893: 0.067317

Train Avg F1  893: 0.7685524714936479

Val Avg Loss  893: 0.064253

Val Avg F1  893:  0.86492673992674

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 894
--------------------------------------------------------------
Epoch:  894        1 Batch loss: 0.061518 Batch F1: 0.8571428571428571
Epoch:  894        2 Batch loss: 0.089082 Batch F1: 0.7368421052631579
Epoch:  894        3 Batch loss: 0.046832 Batch F1: 1.0
Epoch:  894        4 Batch loss: 0.069537 Batch F1: 0.875
Epoch:  894        5 Batch loss: 0.078714 Batch F1: 0.8750000000000001
Epoch:  894        6 Batch loss: 0.052815 Batch F1: 0.9090909090909091
Epoch:  894        7 Batch loss: 0.093073 Batch F1: 0.7499999999999999
Epoch:  894        8 Batch loss: 0.050712 Batch F1: 0.923076923076923
Epoch:  894        9 Batch loss: 0.071517 Batch F1: 0.8
Epoch:  894       10 Batch loss: 0.062447 Batch F1: 0.7692307692307693
Epoch:  894       11 Batch loss: 0.063706 Batch F1: 0.7142857142857143
Epoch:  894       12 Batch loss: 0.076198 Batch F1: 0.4444444444444445
Train Avg Loss  894: 0.068013

Train Avg F1  894: 0.804509476877898

Val Avg Loss  894: 0.063705

Val Avg F1  894:  0.5946969696969697

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 895
--------------------------------------------------------------
Epoch:  895        1 Batch loss: 0.050673 Batch F1: 0.6666666666666666
Epoch:  895        2 Batch loss: 0.060590 Batch F1: 0.4
Epoch:  895        3 Batch loss: 0.082003 Batch F1: 0.5
Epoch:  895        4 Batch loss: 0.064139 Batch F1: 0.7142857142857143
Epoch:  895        5 Batch loss: 0.061167 Batch F1: 0.8421052631578948
Epoch:  895        6 Batch loss: 0.067922 Batch F1: 0.7777777777777778
Epoch:  895        7 Batch loss: 0.071127 Batch F1: 0.6153846153846153
Epoch:  895        8 Batch loss: 0.061461 Batch F1: 0.8571428571428571
Epoch:  895        9 Batch loss: 0.070188 Batch F1: 0.9
Epoch:  895       10 Batch loss: 0.092377 Batch F1: 0.7777777777777778
Epoch:  895       11 Batch loss: 0.061415 Batch F1: 0.8571428571428571
Epoch:  895       12 Batch loss: 0.076759 Batch F1: 0.25
Train Avg Loss  895: 0.068318

Train Avg F1  895: 0.6798569607780133

Val Avg Loss  895: 0.068549

Val Avg F1  895:  0.6529720279720279

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 896
--------------------------------------------------------------
Epoch:  896        1 Batch loss: 0.064995 Batch F1: 0.7692307692307693
Epoch:  896        2 Batch loss: 0.085780 Batch F1: 0.33333333333333337
Epoch:  896        3 Batch loss: 0.070125 Batch F1: 0.0
Epoch:  896        4 Batch loss: 0.071376 Batch F1: 0.33333333333333337
Epoch:  896        5 Batch loss: 0.072322 Batch F1: 0.8
Epoch:  896        6 Batch loss: 0.071527 Batch F1: 0.9523809523809523
Epoch:  896        7 Batch loss: 0.084750 Batch F1: 0.8
Epoch:  896        8 Batch loss: 0.063472 Batch F1: 1.0
Epoch:  896        9 Batch loss: 0.084676 Batch F1: 0.9473684210526316
Epoch:  896       10 Batch loss: 0.043004 Batch F1: 1.0
Epoch:  896       11 Batch loss: 0.050152 Batch F1: 0.9090909090909091
Epoch:  896       12 Batch loss: 0.094989 Batch F1: 0.5714285714285715
Train Avg Loss  896: 0.071430

Train Avg F1  896: 0.7013471908208752

Val Avg Loss  896: 0.067459

Val Avg F1  896:  0.7849264705882353

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 897
--------------------------------------------------------------
Epoch:  897        1 Batch loss: 0.061390 Batch F1: 0.8750000000000001
Epoch:  897        2 Batch loss: 0.079835 Batch F1: 0.6666666666666666
Epoch:  897        3 Batch loss: 0.071022 Batch F1: 0.7692307692307693
Epoch:  897        4 Batch loss: 0.065914 Batch F1: 0.888888888888889
Epoch:  897        5 Batch loss: 0.093260 Batch F1: 0.47058823529411764
Epoch:  897        6 Batch loss: 0.048446 Batch F1: 0.8
Epoch:  897        7 Batch loss: 0.039394 Batch F1: 0.8571428571428571
Epoch:  897        8 Batch loss: 0.074872 Batch F1: 0.4615384615384615
Epoch:  897        9 Batch loss: 0.085745 Batch F1: 0.5882352941176471
Epoch:  897       10 Batch loss: 0.069979 Batch F1: 0.4
Epoch:  897       11 Batch loss: 0.060860 Batch F1: 0.8750000000000001
Epoch:  897       12 Batch loss: 0.070450 Batch F1: 1.0
Train Avg Loss  897: 0.068431

Train Avg F1  897: 0.7210242644066174

Val Avg Loss  897: 0.063592

Val Avg F1  897:  0.8803508771929824

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 898
--------------------------------------------------------------
Epoch:  898        1 Batch loss: 0.057078 Batch F1: 0.923076923076923
Epoch:  898        2 Batch loss: 0.053658 Batch F1: 1.0
Epoch:  898        3 Batch loss: 0.083944 Batch F1: 0.6666666666666666
Epoch:  898        4 Batch loss: 0.053539 Batch F1: 0.8750000000000001
Epoch:  898        5 Batch loss: 0.073709 Batch F1: 0.7142857142857143
Epoch:  898        6 Batch loss: 0.055934 Batch F1: 1.0
Epoch:  898        7 Batch loss: 0.078926 Batch F1: 0.888888888888889
Epoch:  898        8 Batch loss: 0.065016 Batch F1: 0.9
Epoch:  898        9 Batch loss: 0.055189 Batch F1: 1.0
Epoch:  898       10 Batch loss: 0.075456 Batch F1: 0.7499999999999999
Epoch:  898       11 Batch loss: 0.064924 Batch F1: 0.7272727272727272
Epoch:  898       12 Batch loss: 0.094540 Batch F1: 0.7142857142857143
Train Avg Loss  898: 0.067659

Train Avg F1  898: 0.8466230528730527

Val Avg Loss  898: 0.063271

Val Avg F1  898:  0.8000894033502728

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 899
--------------------------------------------------------------
Epoch:  899        1 Batch loss: 0.072791 Batch F1: 0.9
Epoch:  899        2 Batch loss: 0.062570 Batch F1: 0.6153846153846153
Epoch:  899        3 Batch loss: 0.082715 Batch F1: 0.8
Epoch:  899        4 Batch loss: 0.062289 Batch F1: 0.8421052631578948
Epoch:  899        5 Batch loss: 0.065359 Batch F1: 0.8333333333333334
Epoch:  899        6 Batch loss: 0.079652 Batch F1: 0.8421052631578948
Epoch:  899        7 Batch loss: 0.061829 Batch F1: 0.9411764705882353
Epoch:  899        8 Batch loss: 0.060798 Batch F1: 0.923076923076923
Epoch:  899        9 Batch loss: 0.080733 Batch F1: 0.7999999999999999
Epoch:  899       10 Batch loss: 0.057764 Batch F1: 0.8571428571428571
Epoch:  899       11 Batch loss: 0.056975 Batch F1: 0.888888888888889
Epoch:  899       12 Batch loss: 0.076298 Batch F1: 0.7058823529411764
Train Avg Loss  899: 0.068314

Train Avg F1  899: 0.8290913306393183

Val Avg Loss  899: 0.065022

Val Avg F1  899:  0.6111471861471861

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 900
--------------------------------------------------------------
Epoch:  900        1 Batch loss: 0.076501 Batch F1: 0.33333333333333337
Epoch:  900        2 Batch loss: 0.056809 Batch F1: 0.7692307692307693
Epoch:  900        3 Batch loss: 0.059395 Batch F1: 0.4444444444444445
Epoch:  900        4 Batch loss: 0.064982 Batch F1: 0.5454545454545454
Epoch:  900        5 Batch loss: 0.084640 Batch F1: 0.7000000000000001
Epoch:  900        6 Batch loss: 0.049706 Batch F1: 0.923076923076923
Epoch:  900        7 Batch loss: 0.076642 Batch F1: 0.7499999999999999
Epoch:  900        8 Batch loss: 0.068505 Batch F1: 0.9411764705882353
Epoch:  900        9 Batch loss: 0.065685 Batch F1: 0.8333333333333333
Epoch:  900       10 Batch loss: 0.069105 Batch F1: 0.9090909090909091
Epoch:  900       11 Batch loss: 0.054943 Batch F1: 1.0
Epoch:  900       12 Batch loss: 0.079285 Batch F1: 0.8888888888888888
Train Avg Loss  900: 0.067183

Train Avg F1  900: 0.7531691347867818

Val Avg Loss  900: 0.063513

Val Avg F1  900:  0.930701754385965

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 901
--------------------------------------------------------------
Epoch:  901        1 Batch loss: 0.051865 Batch F1: 0.8
Epoch:  901        2 Batch loss: 0.081084 Batch F1: 0.9
Epoch:  901        3 Batch loss: 0.070135 Batch F1: 0.9
Epoch:  901        4 Batch loss: 0.099596 Batch F1: 0.7499999999999999
Epoch:  901        5 Batch loss: 0.058103 Batch F1: 0.7692307692307693
Epoch:  901        6 Batch loss: 0.077298 Batch F1: 0.7692307692307693
Epoch:  901        7 Batch loss: 0.052307 Batch F1: 0.9333333333333333
Epoch:  901        8 Batch loss: 0.045352 Batch F1: 0.8
Epoch:  901        9 Batch loss: 0.062545 Batch F1: 0.8235294117647058
Epoch:  901       10 Batch loss: 0.062177 Batch F1: 0.6666666666666666
Epoch:  901       11 Batch loss: 0.075776 Batch F1: 0.6666666666666666
Epoch:  901       12 Batch loss: 0.073097 Batch F1: 0.0
Train Avg Loss  901: 0.067445

Train Avg F1  901: 0.7315548014077425

Val Avg Loss  901: 0.063997

Val Avg F1  901:  0.6233766233766235

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 902
--------------------------------------------------------------
Epoch:  902        1 Batch loss: 0.066456 Batch F1: 0.4
Epoch:  902        2 Batch loss: 0.043776 Batch F1: 0.4
Epoch:  902        3 Batch loss: 0.091961 Batch F1: 0.47058823529411764
Epoch:  902        4 Batch loss: 0.056741 Batch F1: 0.7272727272727273
Epoch:  902        5 Batch loss: 0.062791 Batch F1: 0.6666666666666666
Epoch:  902        6 Batch loss: 0.073072 Batch F1: 0.7142857142857143
Epoch:  902        7 Batch loss: 0.078817 Batch F1: 0.6153846153846153
Epoch:  902        8 Batch loss: 0.065325 Batch F1: 0.9565217391304348
Epoch:  902        9 Batch loss: 0.077485 Batch F1: 0.8333333333333333
Epoch:  902       10 Batch loss: 0.056743 Batch F1: 1.0
Epoch:  902       11 Batch loss: 0.079245 Batch F1: 0.9285714285714286
Epoch:  902       12 Batch loss: 0.050348 Batch F1: 1.0
Train Avg Loss  902: 0.066897

Train Avg F1  902: 0.7260520383282532

Val Avg Loss  902: 0.063374

Val Avg F1  902:  0.9052579365079365

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 903
--------------------------------------------------------------
Epoch:  903        1 Batch loss: 0.059347 Batch F1: 0.75
Epoch:  903        2 Batch loss: 0.049365 Batch F1: 0.8571428571428571
Epoch:  903        3 Batch loss: 0.054757 Batch F1: 0.8571428571428571
Epoch:  903        4 Batch loss: 0.082127 Batch F1: 0.625
Epoch:  903        5 Batch loss: 0.076494 Batch F1: 0.42857142857142855
Epoch:  903        6 Batch loss: 0.053039 Batch F1: 0.923076923076923
Epoch:  903        7 Batch loss: 0.079720 Batch F1: 0.9
Epoch:  903        8 Batch loss: 0.071888 Batch F1: 0.9473684210526316
Epoch:  903        9 Batch loss: 0.063879 Batch F1: 0.5714285714285715
Epoch:  903       10 Batch loss: 0.082792 Batch F1: 0.6666666666666666
Epoch:  903       11 Batch loss: 0.078521 Batch F1: 0.5882352941176471
Epoch:  903       12 Batch loss: 0.088296 Batch F1: 0.42857142857142855
Train Avg Loss  903: 0.070019

Train Avg F1  903: 0.7119337039809177

Val Avg Loss  903: 0.064257

Val Avg F1  903:  0.9240507299717826

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 904
--------------------------------------------------------------
Epoch:  904        1 Batch loss: 0.069725 Batch F1: 0.9523809523809523
Epoch:  904        2 Batch loss: 0.074237 Batch F1: 0.7499999999999999
Epoch:  904        3 Batch loss: 0.068368 Batch F1: 1.0
Epoch:  904        4 Batch loss: 0.082676 Batch F1: 0.9655172413793104
Epoch:  904        5 Batch loss: 0.070687 Batch F1: 0.9523809523809523
Epoch:  904        6 Batch loss: 0.042957 Batch F1: 1.0
Epoch:  904        7 Batch loss: 0.058532 Batch F1: 0.9473684210526316
Epoch:  904        8 Batch loss: 0.084654 Batch F1: 0.8695652173913044
Epoch:  904        9 Batch loss: 0.060335 Batch F1: 1.0
Epoch:  904       10 Batch loss: 0.079183 Batch F1: 0.6666666666666666
Epoch:  904       11 Batch loss: 0.088561 Batch F1: 0.7058823529411764
Epoch:  904       12 Batch loss: 0.046768 Batch F1: 0.8
Train Avg Loss  904: 0.068890

Train Avg F1  904: 0.8841468170160828

Val Avg Loss  904: 0.065807

Val Avg F1  904:  0.6167582417582418

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 905
--------------------------------------------------------------
Epoch:  905        1 Batch loss: 0.083710 Batch F1: 0.4615384615384615
Epoch:  905        2 Batch loss: 0.074399 Batch F1: 0.5714285714285715
Epoch:  905        3 Batch loss: 0.053020 Batch F1: 0.7692307692307693
Epoch:  905        4 Batch loss: 0.045217 Batch F1: 0.9411764705882353
Epoch:  905        5 Batch loss: 0.081087 Batch F1: 0.5
Epoch:  905        6 Batch loss: 0.060612 Batch F1: 0.6
Epoch:  905        7 Batch loss: 0.055075 Batch F1: 0.6666666666666666
Epoch:  905        8 Batch loss: 0.081422 Batch F1: 0.6666666666666666
Epoch:  905        9 Batch loss: 0.048401 Batch F1: 0.8571428571428571
Epoch:  905       10 Batch loss: 0.087300 Batch F1: 0.6
Epoch:  905       11 Batch loss: 0.074477 Batch F1: 0.6666666666666666
Epoch:  905       12 Batch loss: 0.060644 Batch F1: 0.8571428571428571
Train Avg Loss  905: 0.067114

Train Avg F1  905: 0.6798049989226459

Val Avg Loss  905: 0.063468

Val Avg F1  905:  0.8841853798375536

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 906
--------------------------------------------------------------
Epoch:  906        1 Batch loss: 0.065564 Batch F1: 0.8571428571428571
Epoch:  906        2 Batch loss: 0.076797 Batch F1: 0.888888888888889
Epoch:  906        3 Batch loss: 0.081837 Batch F1: 0.888888888888889
Epoch:  906        4 Batch loss: 0.075455 Batch F1: 0.8888888888888888
Epoch:  906        5 Batch loss: 0.072525 Batch F1: 0.6666666666666666
Epoch:  906        6 Batch loss: 0.045807 Batch F1: 1.0
Epoch:  906        7 Batch loss: 0.050795 Batch F1: 0.5714285714285715
Epoch:  906        8 Batch loss: 0.073683 Batch F1: 0.6666666666666666
Epoch:  906        9 Batch loss: 0.059796 Batch F1: 0.4444444444444445
Epoch:  906       10 Batch loss: 0.064959 Batch F1: 0.4
Epoch:  906       11 Batch loss: 0.066160 Batch F1: 0.5454545454545454
Epoch:  906       12 Batch loss: 0.084695 Batch F1: 0.6666666666666666
Train Avg Loss  906: 0.068173

Train Avg F1  906: 0.7070947570947571

Val Avg Loss  906: 0.062115

Val Avg F1  906:  0.7253787878787878

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 907
--------------------------------------------------------------
Epoch:  907        1 Batch loss: 0.067781 Batch F1: 0.7777777777777778
Epoch:  907        2 Batch loss: 0.062383 Batch F1: 0.9411764705882353
Epoch:  907        3 Batch loss: 0.072633 Batch F1: 0.8235294117647058
Epoch:  907        4 Batch loss: 0.060305 Batch F1: 0.923076923076923
Epoch:  907        5 Batch loss: 0.062827 Batch F1: 1.0
Epoch:  907        6 Batch loss: 0.081013 Batch F1: 0.923076923076923
Epoch:  907        7 Batch loss: 0.060222 Batch F1: 0.9090909090909091
Epoch:  907        8 Batch loss: 0.049284 Batch F1: 1.0
Epoch:  907        9 Batch loss: 0.073616 Batch F1: 0.5714285714285715
Epoch:  907       10 Batch loss: 0.080508 Batch F1: 0.33333333333333337
Epoch:  907       11 Batch loss: 0.069127 Batch F1: 0.5
Epoch:  907       12 Batch loss: 0.080842 Batch F1: 0.7272727272727273
Train Avg Loss  907: 0.068379

Train Avg F1  907: 0.7858135872841755

Val Avg Loss  907: 0.064046

Val Avg F1  907:  0.7919657097288676

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 908
--------------------------------------------------------------
Epoch:  908        1 Batch loss: 0.076820 Batch F1: 0.7499999999999999
Epoch:  908        2 Batch loss: 0.059415 Batch F1: 0.7272727272727273
Epoch:  908        3 Batch loss: 0.073210 Batch F1: 0.8
Epoch:  908        4 Batch loss: 0.087032 Batch F1: 0.8571428571428571
Epoch:  908        5 Batch loss: 0.061783 Batch F1: 0.9333333333333333
Epoch:  908        6 Batch loss: 0.062730 Batch F1: 1.0
Epoch:  908        7 Batch loss: 0.059818 Batch F1: 1.0
Epoch:  908        8 Batch loss: 0.076878 Batch F1: 0.4615384615384615
Epoch:  908        9 Batch loss: 0.083166 Batch F1: 0.42857142857142855
Epoch:  908       10 Batch loss: 0.069500 Batch F1: 0.6666666666666666
Epoch:  908       11 Batch loss: 0.051795 Batch F1: 0.8
Epoch:  908       12 Batch loss: 0.054800 Batch F1: 0.888888888888889
Train Avg Loss  908: 0.068079

Train Avg F1  908: 0.7761178636178637

Val Avg Loss  908: 0.062259

Val Avg F1  908:  0.7907925407925407

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 909
--------------------------------------------------------------
Epoch:  909        1 Batch loss: 0.060084 Batch F1: 0.7499999999999999
Epoch:  909        2 Batch loss: 0.068008 Batch F1: 0.5454545454545454
Epoch:  909        3 Batch loss: 0.095017 Batch F1: 0.6956521739130436
Epoch:  909        4 Batch loss: 0.067797 Batch F1: 0.8333333333333333
Epoch:  909        5 Batch loss: 0.063009 Batch F1: 0.9333333333333333
Epoch:  909        6 Batch loss: 0.060812 Batch F1: 0.9090909090909091
Epoch:  909        7 Batch loss: 0.047622 Batch F1: 0.7272727272727273
Epoch:  909        8 Batch loss: 0.056467 Batch F1: 0.0
Epoch:  909        9 Batch loss: 0.068251 Batch F1: 0.5714285714285715
Epoch:  909       10 Batch loss: 0.060581 Batch F1: 0.33333333333333337
Epoch:  909       11 Batch loss: 0.086283 Batch F1: 0.4615384615384615
Epoch:  909       12 Batch loss: 0.088832 Batch F1: 0.631578947368421
Train Avg Loss  909: 0.068564

Train Avg F1  909: 0.6160013613388899

Val Avg Loss  909: 0.063096

Val Avg F1  909:  0.95

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 910
--------------------------------------------------------------
Epoch:  910        1 Batch loss: 0.063524 Batch F1: 1.0
Epoch:  910        2 Batch loss: 0.068556 Batch F1: 1.0
Epoch:  910        3 Batch loss: 0.087428 Batch F1: 0.7777777777777778
Epoch:  910        4 Batch loss: 0.070134 Batch F1: 0.8
Epoch:  910        5 Batch loss: 0.076523 Batch F1: 0.6666666666666666
Epoch:  910        6 Batch loss: 0.057204 Batch F1: 0.8750000000000001
Epoch:  910        7 Batch loss: 0.076015 Batch F1: 0.75
Epoch:  910        8 Batch loss: 0.080492 Batch F1: 0.8695652173913043
Epoch:  910        9 Batch loss: 0.067724 Batch F1: 0.923076923076923
Epoch:  910       10 Batch loss: 0.070084 Batch F1: 0.923076923076923
Epoch:  910       11 Batch loss: 0.074919 Batch F1: 0.7058823529411764
Epoch:  910       12 Batch loss: 0.050631 Batch F1: 0.7499999999999999
Train Avg Loss  910: 0.070270

Train Avg F1  910: 0.8367538217442309

Val Avg Loss  910: 0.067747

Val Avg F1  910:  0.6202380952380953

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 911
--------------------------------------------------------------
Epoch:  911        1 Batch loss: 0.056451 Batch F1: 0.2857142857142857
Epoch:  911        2 Batch loss: 0.063995 Batch F1: 0.25
Epoch:  911        3 Batch loss: 0.072596 Batch F1: 0.4
Epoch:  911        4 Batch loss: 0.085381 Batch F1: 0.625
Epoch:  911        5 Batch loss: 0.050438 Batch F1: 1.0
Epoch:  911        6 Batch loss: 0.077232 Batch F1: 0.9090909090909091
Epoch:  911        7 Batch loss: 0.077500 Batch F1: 0.9090909090909091
Epoch:  911        8 Batch loss: 0.057833 Batch F1: 0.9411764705882353
Epoch:  911        9 Batch loss: 0.086523 Batch F1: 0.7058823529411764
Epoch:  911       10 Batch loss: 0.072789 Batch F1: 0.5
Epoch:  911       11 Batch loss: 0.063324 Batch F1: 0.9333333333333333
Epoch:  911       12 Batch loss: 0.071792 Batch F1: 0.6666666666666666
Train Avg Loss  911: 0.069654

Train Avg F1  911: 0.677162910618793

Val Avg Loss  911: 0.064193

Val Avg F1  911:  0.5928571428571429

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 912
--------------------------------------------------------------
Epoch:  912        1 Batch loss: 0.056865 Batch F1: 0.5714285714285715
Epoch:  912        2 Batch loss: 0.092502 Batch F1: 0.3076923076923077
Epoch:  912        3 Batch loss: 0.070994 Batch F1: 0.5454545454545454
Epoch:  912        4 Batch loss: 0.085558 Batch F1: 0.5882352941176471
Epoch:  912        5 Batch loss: 0.083347 Batch F1: 0.5
Epoch:  912        6 Batch loss: 0.063161 Batch F1: 1.0
Epoch:  912        7 Batch loss: 0.082591 Batch F1: 0.888888888888889
Epoch:  912        8 Batch loss: 0.062810 Batch F1: 0.8750000000000001
Epoch:  912        9 Batch loss: 0.070572 Batch F1: 0.3636363636363636
Epoch:  912       10 Batch loss: 0.058137 Batch F1: 0.8750000000000001
Epoch:  912       11 Batch loss: 0.048337 Batch F1: 0.5714285714285715
Epoch:  912       12 Batch loss: 0.064003 Batch F1: 1.0
Train Avg Loss  912: 0.069906

Train Avg F1  912: 0.6738970452205746

Val Avg Loss  912: 0.063999

Val Avg F1  912:  0.635989010989011

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 913
--------------------------------------------------------------
Epoch:  913        1 Batch loss: 0.088645 Batch F1: 0.6956521739130436
Epoch:  913        2 Batch loss: 0.064423 Batch F1: 0.8571428571428571
Epoch:  913        3 Batch loss: 0.052081 Batch F1: 0.8333333333333333
Epoch:  913        4 Batch loss: 0.070008 Batch F1: 0.8421052631578948
Epoch:  913        5 Batch loss: 0.052430 Batch F1: 0.8
Epoch:  913        6 Batch loss: 0.061235 Batch F1: 0.8571428571428571
Epoch:  913        7 Batch loss: 0.061969 Batch F1: 0.7692307692307693
Epoch:  913        8 Batch loss: 0.066938 Batch F1: 0.7777777777777778
Epoch:  913        9 Batch loss: 0.069237 Batch F1: 0.6666666666666666
Epoch:  913       10 Batch loss: 0.076404 Batch F1: 0.5
Epoch:  913       11 Batch loss: 0.068629 Batch F1: 0.4444444444444444
Epoch:  913       12 Batch loss: 0.086194 Batch F1: 0.3636363636363636
Train Avg Loss  913: 0.068183

Train Avg F1  913: 0.7005943755371672

Val Avg Loss  913: 0.065026

Val Avg F1  913:  0.746031746031746

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 914
--------------------------------------------------------------
Epoch:  914        1 Batch loss: 0.060173 Batch F1: 0.6666666666666666
Epoch:  914        2 Batch loss: 0.062806 Batch F1: 0.9473684210526316
Epoch:  914        3 Batch loss: 0.073530 Batch F1: 0.7368421052631579
Epoch:  914        4 Batch loss: 0.071165 Batch F1: 0.823529411764706
Epoch:  914        5 Batch loss: 0.080800 Batch F1: 0.8333333333333333
Epoch:  914        6 Batch loss: 0.065246 Batch F1: 0.5454545454545454
Epoch:  914        7 Batch loss: 0.089525 Batch F1: 0.0
Epoch:  914        8 Batch loss: 0.069201 Batch F1: 0.8181818181818181
Epoch:  914        9 Batch loss: 0.049802 Batch F1: 0.923076923076923
Epoch:  914       10 Batch loss: 0.075656 Batch F1: 0.8235294117647058
Epoch:  914       11 Batch loss: 0.068093 Batch F1: 0.9411764705882353
Epoch:  914       12 Batch loss: 0.054051 Batch F1: 1.0
Train Avg Loss  914: 0.068337

Train Avg F1  914: 0.7549299255955603

Val Avg Loss  914: 0.062937

Val Avg F1  914:  0.8820626934984521

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 915
--------------------------------------------------------------
Epoch:  915        1 Batch loss: 0.076989 Batch F1: 0.8
Epoch:  915        2 Batch loss: 0.070060 Batch F1: 0.9473684210526316
Epoch:  915        3 Batch loss: 0.070399 Batch F1: 0.9523809523809523
Epoch:  915        4 Batch loss: 0.063423 Batch F1: 0.7692307692307693
Epoch:  915        5 Batch loss: 0.046182 Batch F1: 0.8571428571428571
Epoch:  915        6 Batch loss: 0.068119 Batch F1: 0.4
Epoch:  915        7 Batch loss: 0.072451 Batch F1: 0.3636363636363636
Epoch:  915        8 Batch loss: 0.057863 Batch F1: 0.6
Epoch:  915        9 Batch loss: 0.068408 Batch F1: 0.3636363636363636
Epoch:  915       10 Batch loss: 0.066294 Batch F1: 0.8
Epoch:  915       11 Batch loss: 0.084289 Batch F1: 0.8333333333333333
Epoch:  915       12 Batch loss: 0.054705 Batch F1: 1.0
Train Avg Loss  915: 0.066598

Train Avg F1  915: 0.7238940883677726

Val Avg Loss  915: 0.062583

Val Avg F1  915:  0.8976190476190476

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 916
--------------------------------------------------------------
Epoch:  916        1 Batch loss: 0.062557 Batch F1: 0.9523809523809523
Epoch:  916        2 Batch loss: 0.058988 Batch F1: 0.8333333333333333
Epoch:  916        3 Batch loss: 0.080482 Batch F1: 0.5882352941176471
Epoch:  916        4 Batch loss: 0.039422 Batch F1: 0.8
Epoch:  916        5 Batch loss: 0.049374 Batch F1: 0.7692307692307693
Epoch:  916        6 Batch loss: 0.067200 Batch F1: 0.6666666666666666
Epoch:  916        7 Batch loss: 0.062360 Batch F1: 0.4444444444444445
Epoch:  916        8 Batch loss: 0.085475 Batch F1: 0.7142857142857143
Epoch:  916        9 Batch loss: 0.078099 Batch F1: 0.9565217391304348
Epoch:  916       10 Batch loss: 0.072103 Batch F1: 0.9473684210526316
Epoch:  916       11 Batch loss: 0.079826 Batch F1: 0.7499999999999999
Epoch:  916       12 Batch loss: 0.060492 Batch F1: 1.0
Train Avg Loss  916: 0.066365

Train Avg F1  916: 0.7852056112202161

Val Avg Loss  916: 0.064295

Val Avg F1  916:  0.913888888888889

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 917
--------------------------------------------------------------
Epoch:  917        1 Batch loss: 0.075530 Batch F1: 0.9523809523809523
Epoch:  917        2 Batch loss: 0.079757 Batch F1: 0.7999999999999999
Epoch:  917        3 Batch loss: 0.059787 Batch F1: 0.8
Epoch:  917        4 Batch loss: 0.085811 Batch F1: 0.6
Epoch:  917        5 Batch loss: 0.052178 Batch F1: 0.8
Epoch:  917        6 Batch loss: 0.070547 Batch F1: 0.7777777777777778
Epoch:  917        7 Batch loss: 0.069362 Batch F1: 0.8571428571428571
Epoch:  917        8 Batch loss: 0.059484 Batch F1: 0.8571428571428571
Epoch:  917        9 Batch loss: 0.070052 Batch F1: 0.7692307692307693
Epoch:  917       10 Batch loss: 0.063297 Batch F1: 0.8750000000000001
Epoch:  917       11 Batch loss: 0.048565 Batch F1: 0.8
Epoch:  917       12 Batch loss: 0.070975 Batch F1: 0.8235294117647058
Train Avg Loss  917: 0.067112

Train Avg F1  917: 0.8093503854533267

Val Avg Loss  917: 0.063700

Val Avg F1  917:  0.6386946386946387

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 918
--------------------------------------------------------------
Epoch:  918        1 Batch loss: 0.065448 Batch F1: 0.7777777777777778
Epoch:  918        2 Batch loss: 0.101873 Batch F1: 0.4444444444444445
Epoch:  918        3 Batch loss: 0.062702 Batch F1: 0.7142857142857143
Epoch:  918        4 Batch loss: 0.063468 Batch F1: 0.9523809523809523
Epoch:  918        5 Batch loss: 0.065751 Batch F1: 0.8750000000000001
Epoch:  918        6 Batch loss: 0.073148 Batch F1: 0.888888888888889
Epoch:  918        7 Batch loss: 0.063158 Batch F1: 0.9090909090909091
Epoch:  918        8 Batch loss: 0.050801 Batch F1: 0.923076923076923
Epoch:  918        9 Batch loss: 0.060430 Batch F1: 0.8333333333333333
Epoch:  918       10 Batch loss: 0.064983 Batch F1: 0.6153846153846153
Epoch:  918       11 Batch loss: 0.067247 Batch F1: 0.6153846153846153
Epoch:  918       12 Batch loss: 0.070946 Batch F1: 0.4444444444444445
Train Avg Loss  918: 0.067496

Train Avg F1  918: 0.7494577182077182

Val Avg Loss  918: 0.066715

Val Avg F1  918:  0.5778081567555251

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 919
--------------------------------------------------------------
Epoch:  919        1 Batch loss: 0.092517 Batch F1: 0.5555555555555556
Epoch:  919        2 Batch loss: 0.060871 Batch F1: 0.6153846153846153
Epoch:  919        3 Batch loss: 0.059029 Batch F1: 0.8333333333333333
Epoch:  919        4 Batch loss: 0.060280 Batch F1: 0.6153846153846153
Epoch:  919        5 Batch loss: 0.071814 Batch F1: 0.9166666666666666
Epoch:  919        6 Batch loss: 0.084015 Batch F1: 0.9166666666666666
Epoch:  919        7 Batch loss: 0.072703 Batch F1: 0.888888888888889
Epoch:  919        8 Batch loss: 0.063036 Batch F1: 0.8
Epoch:  919        9 Batch loss: 0.059791 Batch F1: 1.0
Epoch:  919       10 Batch loss: 0.044949 Batch F1: 1.0
Epoch:  919       11 Batch loss: 0.086395 Batch F1: 0.6666666666666666
Epoch:  919       12 Batch loss: 0.057334 Batch F1: 0.5714285714285715
Train Avg Loss  919: 0.067728

Train Avg F1  919: 0.7816646316646315

Val Avg Loss  919: 0.072490

Val Avg F1  919:  0.37777777777777777

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 920
--------------------------------------------------------------
Epoch:  920        1 Batch loss: 0.072130 Batch F1: 0.6666666666666666
Epoch:  920        2 Batch loss: 0.075909 Batch F1: 0.5
Epoch:  920        3 Batch loss: 0.064549 Batch F1: 0.6666666666666665
Epoch:  920        4 Batch loss: 0.071193 Batch F1: 0.5714285714285715
Epoch:  920        5 Batch loss: 0.076046 Batch F1: 0.8571428571428571
Epoch:  920        6 Batch loss: 0.080537 Batch F1: 0.9
Epoch:  920        7 Batch loss: 0.062189 Batch F1: 1.0
Epoch:  920        8 Batch loss: 0.061355 Batch F1: 0.888888888888889
Epoch:  920        9 Batch loss: 0.065094 Batch F1: 0.8750000000000001
Epoch:  920       10 Batch loss: 0.050884 Batch F1: 0.923076923076923
Epoch:  920       11 Batch loss: 0.062545 Batch F1: 0.2222222222222222
Epoch:  920       12 Batch loss: 0.073726 Batch F1: 0.5
Train Avg Loss  920: 0.068013

Train Avg F1  920: 0.7142577330077331

Val Avg Loss  920: 0.063324

Val Avg F1  920:  0.7442557442557443

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 921
--------------------------------------------------------------
Epoch:  921        1 Batch loss: 0.047888 Batch F1: 0.9090909090909091
Epoch:  921        2 Batch loss: 0.089254 Batch F1: 0.7368421052631579
Epoch:  921        3 Batch loss: 0.064157 Batch F1: 0.9
Epoch:  921        4 Batch loss: 0.057743 Batch F1: 0.9411764705882353
Epoch:  921        5 Batch loss: 0.064995 Batch F1: 0.9333333333333333
Epoch:  921        6 Batch loss: 0.056742 Batch F1: 0.6666666666666666
Epoch:  921        7 Batch loss: 0.073145 Batch F1: 0.5
Epoch:  921        8 Batch loss: 0.056037 Batch F1: 0.8
Epoch:  921        9 Batch loss: 0.104166 Batch F1: 0.4
Epoch:  921       10 Batch loss: 0.055555 Batch F1: 0.888888888888889
Epoch:  921       11 Batch loss: 0.073994 Batch F1: 0.9166666666666666
Epoch:  921       12 Batch loss: 0.052644 Batch F1: 0.888888888888889
Train Avg Loss  921: 0.066360

Train Avg F1  921: 0.7901294941155624

Val Avg Loss  921: 0.062842

Val Avg F1  921:  0.9195906432748538

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 922
--------------------------------------------------------------
Epoch:  922        1 Batch loss: 0.067005 Batch F1: 0.7142857142857143
Epoch:  922        2 Batch loss: 0.076533 Batch F1: 0.8235294117647058
Epoch:  922        3 Batch loss: 0.064901 Batch F1: 0.888888888888889
Epoch:  922        4 Batch loss: 0.058059 Batch F1: 0.923076923076923
Epoch:  922        5 Batch loss: 0.056982 Batch F1: 0.6666666666666666
Epoch:  922        6 Batch loss: 0.064067 Batch F1: 0.6666666666666666
Epoch:  922        7 Batch loss: 0.061481 Batch F1: 0.8
Epoch:  922        8 Batch loss: 0.074427 Batch F1: 0.0
Epoch:  922        9 Batch loss: 0.085236 Batch F1: 0.782608695652174
Epoch:  922       10 Batch loss: 0.061448 Batch F1: 1.0
Epoch:  922       11 Batch loss: 0.083701 Batch F1: 0.6
Epoch:  922       12 Batch loss: 0.069626 Batch F1: 0.9411764705882353
Train Avg Loss  922: 0.068622

Train Avg F1  922: 0.7339082864658312

Val Avg Loss  922: 0.062850

Val Avg F1  922:  0.8807741278329514

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 923
--------------------------------------------------------------
Epoch:  923        1 Batch loss: 0.058859 Batch F1: 1.0
Epoch:  923        2 Batch loss: 0.061617 Batch F1: 0.9411764705882353
Epoch:  923        3 Batch loss: 0.097965 Batch F1: 0.782608695652174
Epoch:  923        4 Batch loss: 0.072971 Batch F1: 0.8235294117647058
Epoch:  923        5 Batch loss: 0.099966 Batch F1: 0.9166666666666666
Epoch:  923        6 Batch loss: 0.060678 Batch F1: 0.888888888888889
Epoch:  923        7 Batch loss: 0.054417 Batch F1: 0.8
Epoch:  923        8 Batch loss: 0.073380 Batch F1: 0.9333333333333333
Epoch:  923        9 Batch loss: 0.057605 Batch F1: 0.5454545454545454
Epoch:  923       10 Batch loss: 0.067524 Batch F1: 0.0
Epoch:  923       11 Batch loss: 0.054332 Batch F1: 0.2857142857142857
Epoch:  923       12 Batch loss: 0.076858 Batch F1: 0.7692307692307693
Train Avg Loss  923: 0.069681

Train Avg F1  923: 0.7238835889411338

Val Avg Loss  923: 0.063822

Val Avg F1  923:  0.7748217468805705

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 924
--------------------------------------------------------------
Epoch:  924        1 Batch loss: 0.096836 Batch F1: 0.6363636363636364
Epoch:  924        2 Batch loss: 0.054300 Batch F1: 0.8571428571428571
Epoch:  924        3 Batch loss: 0.076536 Batch F1: 0.9090909090909091
Epoch:  924        4 Batch loss: 0.077324 Batch F1: 0.8571428571428571
Epoch:  924        5 Batch loss: 0.059319 Batch F1: 1.0
Epoch:  924        6 Batch loss: 0.032994 Batch F1: 1.0
Epoch:  924        7 Batch loss: 0.076560 Batch F1: 0.7499999999999999
Epoch:  924        8 Batch loss: 0.064111 Batch F1: 0.6
Epoch:  924        9 Batch loss: 0.122673 Batch F1: 0.6153846153846153
Epoch:  924       10 Batch loss: 0.077116 Batch F1: 0.9565217391304348
Epoch:  924       11 Batch loss: 0.072502 Batch F1: 0.888888888888889
Epoch:  924       12 Batch loss: 0.052799 Batch F1: 0.8333333333333333
Train Avg Loss  924: 0.071923

Train Avg F1  924: 0.8253224030397944

Val Avg Loss  924: 0.070964

Val Avg F1  924:  0.6102564102564103

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 925
--------------------------------------------------------------
Epoch:  925        1 Batch loss: 0.060532 Batch F1: 0.0
Epoch:  925        2 Batch loss: 0.121642 Batch F1: 0.0
Epoch:  925        3 Batch loss: 0.049439 Batch F1: 0.2857142857142857
Epoch:  925        4 Batch loss: 0.102834 Batch F1: 0.631578947368421
Epoch:  925        5 Batch loss: 0.107489 Batch F1: 0.375
Epoch:  925        6 Batch loss: 0.065437 Batch F1: 0.7499999999999999
Epoch:  925        7 Batch loss: 0.118990 Batch F1: 0.7500000000000001
Epoch:  925        8 Batch loss: 0.064893 Batch F1: 0.6
Epoch:  925        9 Batch loss: 0.086128 Batch F1: 0.3636363636363636
Epoch:  925       10 Batch loss: 0.069370 Batch F1: 0.4444444444444445
Epoch:  925       11 Batch loss: 0.056759 Batch F1: 0.6
Epoch:  925       12 Batch loss: 0.074005 Batch F1: 0.888888888888889
Train Avg Loss  925: 0.081460

Train Avg F1  925: 0.47410524417103367

Val Avg Loss  925: 0.080826

Val Avg F1  925:  0.8888028895768834

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 926
--------------------------------------------------------------
Epoch:  926        1 Batch loss: 0.081211 Batch F1: 0.888888888888889
Epoch:  926        2 Batch loss: 0.095963 Batch F1: 0.0
Epoch:  926        3 Batch loss: 0.064908 Batch F1: 0.5454545454545454
Epoch:  926        4 Batch loss: 0.092312 Batch F1: 0.5714285714285715
Epoch:  926        5 Batch loss: 0.069279 Batch F1: 0.9411764705882353
Epoch:  926        6 Batch loss: 0.068382 Batch F1: 1.0
Epoch:  926        7 Batch loss: 0.077818 Batch F1: 0.9090909090909091
Epoch:  926        8 Batch loss: 0.068112 Batch F1: 0.7058823529411764
Epoch:  926        9 Batch loss: 0.087354 Batch F1: 0.4615384615384615
Epoch:  926       10 Batch loss: 0.066167 Batch F1: 0.5714285714285715
Epoch:  926       11 Batch loss: 0.065971 Batch F1: 0.25
Epoch:  926       12 Batch loss: 0.058959 Batch F1: 0.5
Train Avg Loss  926: 0.074703

Train Avg F1  926: 0.6120740642799466

Val Avg Loss  926: 0.068444

Val Avg F1  926:  0.5955357142857143

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 927
--------------------------------------------------------------
Epoch:  927        1 Batch loss: 0.078025 Batch F1: 0.3636363636363636
Epoch:  927        2 Batch loss: 0.080607 Batch F1: 0.7058823529411764
Epoch:  927        3 Batch loss: 0.073293 Batch F1: 0.5
Epoch:  927        4 Batch loss: 0.079845 Batch F1: 0.761904761904762
Epoch:  927        5 Batch loss: 0.079855 Batch F1: 0.8421052631578948
Epoch:  927        6 Batch loss: 0.081441 Batch F1: 0.9523809523809523
Epoch:  927        7 Batch loss: 0.051293 Batch F1: 1.0
Epoch:  927        8 Batch loss: 0.060356 Batch F1: 0.7499999999999999
Epoch:  927        9 Batch loss: 0.054555 Batch F1: 0.0
Epoch:  927       10 Batch loss: 0.100927 Batch F1: 0.18181818181818182
Epoch:  927       11 Batch loss: 0.073888 Batch F1: 0.5
Epoch:  927       12 Batch loss: 0.055647 Batch F1: 0.923076923076923
Train Avg Loss  927: 0.072478

Train Avg F1  927: 0.6234003999096879

Val Avg Loss  927: 0.065621

Val Avg F1  927:  0.918939393939394

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 928
--------------------------------------------------------------
Epoch:  928        1 Batch loss: 0.085838 Batch F1: 0.923076923076923
Epoch:  928        2 Batch loss: 0.086891 Batch F1: 0.9090909090909091
Epoch:  928        3 Batch loss: 0.105928 Batch F1: 0.9032258064516129
Epoch:  928        4 Batch loss: 0.059337 Batch F1: 0.8888888888888888
Epoch:  928        5 Batch loss: 0.071337 Batch F1: 0.7058823529411764
Epoch:  928        6 Batch loss: 0.055746 Batch F1: 0.5714285714285715
Epoch:  928        7 Batch loss: 0.046582 Batch F1: 0.5
Epoch:  928        8 Batch loss: 0.051210 Batch F1: 0.25
Epoch:  928        9 Batch loss: 0.061150 Batch F1: 0.6
Epoch:  928       10 Batch loss: 0.064800 Batch F1: 0.2857142857142857
Epoch:  928       11 Batch loss: 0.076138 Batch F1: 0.4
Epoch:  928       12 Batch loss: 0.058965 Batch F1: 0.6666666666666666
Train Avg Loss  928: 0.068660

Train Avg F1  928: 0.6336645336882528

Val Avg Loss  928: 0.063984

Val Avg F1  928:  0.8535014005602239

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 929
--------------------------------------------------------------
Epoch:  929        1 Batch loss: 0.066179 Batch F1: 0.8235294117647058
Epoch:  929        2 Batch loss: 0.078574 Batch F1: 0.7058823529411764
Epoch:  929        3 Batch loss: 0.057662 Batch F1: 0.9411764705882353
Epoch:  929        4 Batch loss: 0.096430 Batch F1: 0.8571428571428571
Epoch:  929        5 Batch loss: 0.073563 Batch F1: 0.8750000000000001
Epoch:  929        6 Batch loss: 0.078493 Batch F1: 0.9
Epoch:  929        7 Batch loss: 0.048018 Batch F1: 1.0
Epoch:  929        8 Batch loss: 0.054171 Batch F1: 0.7272727272727273
Epoch:  929        9 Batch loss: 0.066419 Batch F1: 0.25
Epoch:  929       10 Batch loss: 0.055835 Batch F1: 0.6666666666666666
Epoch:  929       11 Batch loss: 0.053057 Batch F1: 0.5
Epoch:  929       12 Batch loss: 0.081135 Batch F1: 0.4
Train Avg Loss  929: 0.067461

Train Avg F1  929: 0.7205558738646975

Val Avg Loss  929: 0.069402

Val Avg F1  929:  0.5481913919413919

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 930
--------------------------------------------------------------
Epoch:  930        1 Batch loss: 0.075108 Batch F1: 0.5
Epoch:  930        2 Batch loss: 0.082163 Batch F1: 0.7777777777777778
Epoch:  930        3 Batch loss: 0.081932 Batch F1: 0.7499999999999999
Epoch:  930        4 Batch loss: 0.077733 Batch F1: 0.9
Epoch:  930        5 Batch loss: 0.088581 Batch F1: 0.9523809523809523
Epoch:  930        6 Batch loss: 0.061332 Batch F1: 1.0
Epoch:  930        7 Batch loss: 0.067198 Batch F1: 0.7692307692307693
Epoch:  930        8 Batch loss: 0.088933 Batch F1: 0.923076923076923
Epoch:  930        9 Batch loss: 0.058134 Batch F1: 0.6
Epoch:  930       10 Batch loss: 0.071920 Batch F1: 0.5
Epoch:  930       11 Batch loss: 0.074245 Batch F1: 0.9090909090909091
Epoch:  930       12 Batch loss: 0.057397 Batch F1: 1.0
Train Avg Loss  930: 0.073723

Train Avg F1  930: 0.798463110963111

Val Avg Loss  930: 0.068112

Val Avg F1  930:  0.6121794871794871

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 931
--------------------------------------------------------------
Epoch:  931        1 Batch loss: 0.070896 Batch F1: 0.4444444444444445
Epoch:  931        2 Batch loss: 0.107956 Batch F1: 0.6666666666666666
Epoch:  931        3 Batch loss: 0.044475 Batch F1: 0.4
Epoch:  931        4 Batch loss: 0.072929 Batch F1: 0.4
Epoch:  931        5 Batch loss: 0.072185 Batch F1: 0.5714285714285715
Epoch:  931        6 Batch loss: 0.077918 Batch F1: 0.9090909090909091
Epoch:  931        7 Batch loss: 0.079074 Batch F1: 0.923076923076923
Epoch:  931        8 Batch loss: 0.059869 Batch F1: 0.6153846153846153
Epoch:  931        9 Batch loss: 0.063399 Batch F1: 0.8421052631578948
Epoch:  931       10 Batch loss: 0.068607 Batch F1: 0.6153846153846153
Epoch:  931       11 Batch loss: 0.061655 Batch F1: 0.6
Epoch:  931       12 Batch loss: 0.093737 Batch F1: 0.3076923076923077
Train Avg Loss  931: 0.072725

Train Avg F1  931: 0.6079395263605789

Val Avg Loss  931: 0.064669

Val Avg F1  931:  0.8976190476190475

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 932
--------------------------------------------------------------
Epoch:  932        1 Batch loss: 0.049842 Batch F1: 1.0
Epoch:  932        2 Batch loss: 0.061070 Batch F1: 0.9333333333333333
Epoch:  932        3 Batch loss: 0.069177 Batch F1: 0.9166666666666666
Epoch:  932        4 Batch loss: 0.072300 Batch F1: 0.7499999999999999
Epoch:  932        5 Batch loss: 0.082919 Batch F1: 0.8
Epoch:  932        6 Batch loss: 0.067040 Batch F1: 0.8421052631578948
Epoch:  932        7 Batch loss: 0.063257 Batch F1: 1.0
Epoch:  932        8 Batch loss: 0.075835 Batch F1: 0.7692307692307693
Epoch:  932        9 Batch loss: 0.081671 Batch F1: 0.88
Epoch:  932       10 Batch loss: 0.052606 Batch F1: 0.8571428571428571
Epoch:  932       11 Batch loss: 0.069674 Batch F1: 0.8888888888888888
Epoch:  932       12 Batch loss: 0.075708 Batch F1: 0.9411764705882353
Train Avg Loss  932: 0.068425

Train Avg F1  932: 0.8815453540840538

Val Avg Loss  932: 0.066598

Val Avg F1  932:  0.5708333333333333

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 933
--------------------------------------------------------------
Epoch:  933        1 Batch loss: 0.071327 Batch F1: 0.6
Epoch:  933        2 Batch loss: 0.049871 Batch F1: 0.8
Epoch:  933        3 Batch loss: 0.082692 Batch F1: 0.5882352941176471
Epoch:  933        4 Batch loss: 0.067363 Batch F1: 0.5454545454545454
Epoch:  933        5 Batch loss: 0.080703 Batch F1: 0.5
Epoch:  933        6 Batch loss: 0.080338 Batch F1: 0.9565217391304348
Epoch:  933        7 Batch loss: 0.075227 Batch F1: 0.7272727272727272
Epoch:  933        8 Batch loss: 0.093801 Batch F1: 0.8888888888888888
Epoch:  933        9 Batch loss: 0.109676 Batch F1: 0.923076923076923
Epoch:  933       10 Batch loss: 0.053348 Batch F1: 0.6666666666666666
Epoch:  933       11 Batch loss: 0.085376 Batch F1: 0.6666666666666666
Epoch:  933       12 Batch loss: 0.065301 Batch F1: 0.2857142857142857
Train Avg Loss  933: 0.076252

Train Avg F1  933: 0.6790414780823989

Val Avg Loss  933: 0.074695

Val Avg F1  933:  0.5709401709401709

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 934
--------------------------------------------------------------
Epoch:  934        1 Batch loss: 0.108723 Batch F1: 0.6
Epoch:  934        2 Batch loss: 0.073662 Batch F1: 0.8
Epoch:  934        3 Batch loss: 0.052672 Batch F1: 0.7499999999999999
Epoch:  934        4 Batch loss: 0.078145 Batch F1: 0.7142857142857143
Epoch:  934        5 Batch loss: 0.066578 Batch F1: 0.9
Epoch:  934        6 Batch loss: 0.071037 Batch F1: 0.9411764705882353
Epoch:  934        7 Batch loss: 0.070937 Batch F1: 0.9090909090909091
Epoch:  934        8 Batch loss: 0.076206 Batch F1: 0.9
Epoch:  934        9 Batch loss: 0.066105 Batch F1: 0.7272727272727273
Epoch:  934       10 Batch loss: 0.066280 Batch F1: 0.8
Epoch:  934       11 Batch loss: 0.062700 Batch F1: 0.8571428571428571
Epoch:  934       12 Batch loss: 0.053063 Batch F1: 0.7499999999999999
Train Avg Loss  934: 0.070509

Train Avg F1  934: 0.8040807231983704

Val Avg Loss  934: 0.063686

Val Avg F1  934:  0.6274350649350648

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 935
--------------------------------------------------------------
Epoch:  935        1 Batch loss: 0.058479 Batch F1: 0.5454545454545454
Epoch:  935        2 Batch loss: 0.066776 Batch F1: 0.6666666666666666
Epoch:  935        3 Batch loss: 0.066898 Batch F1: 0.7692307692307693
Epoch:  935        4 Batch loss: 0.061726 Batch F1: 0.8571428571428571
Epoch:  935        5 Batch loss: 0.048124 Batch F1: 0.9333333333333333
Epoch:  935        6 Batch loss: 0.062698 Batch F1: 0.8
Epoch:  935        7 Batch loss: 0.094058 Batch F1: 0.7499999999999999
Epoch:  935        8 Batch loss: 0.094543 Batch F1: 0.7000000000000001
Epoch:  935        9 Batch loss: 0.071575 Batch F1: 0.4444444444444444
Epoch:  935       10 Batch loss: 0.054141 Batch F1: 0.8333333333333333
Epoch:  935       11 Batch loss: 0.058735 Batch F1: 0.6153846153846154
Epoch:  935       12 Batch loss: 0.069499 Batch F1: 0.5454545454545454
Train Avg Loss  935: 0.067271

Train Avg F1  935: 0.7050370925370925

Val Avg Loss  935: 0.064664

Val Avg F1  935:  0.63125

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 936
--------------------------------------------------------------
Epoch:  936        1 Batch loss: 0.074413 Batch F1: 0.7058823529411764
Epoch:  936        2 Batch loss: 0.060862 Batch F1: 0.6153846153846153
Epoch:  936        3 Batch loss: 0.073814 Batch F1: 0.5714285714285715
Epoch:  936        4 Batch loss: 0.073065 Batch F1: 0.5
Epoch:  936        5 Batch loss: 0.076031 Batch F1: 0.6153846153846153
Epoch:  936        6 Batch loss: 0.075095 Batch F1: 0.9565217391304348
Epoch:  936        7 Batch loss: 0.066068 Batch F1: 0.7692307692307693
Epoch:  936        8 Batch loss: 0.048732 Batch F1: 0.9090909090909091
Epoch:  936        9 Batch loss: 0.062938 Batch F1: 0.8333333333333333
Epoch:  936       10 Batch loss: 0.041855 Batch F1: 0.888888888888889
Epoch:  936       11 Batch loss: 0.079475 Batch F1: 0.5333333333333333
Epoch:  936       12 Batch loss: 0.079046 Batch F1: 0.5454545454545454
Train Avg Loss  936: 0.067616

Train Avg F1  936: 0.703661139466766

Val Avg Loss  936: 0.063394

Val Avg F1  936:  0.6315559440559441

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 937
--------------------------------------------------------------
Epoch:  937        1 Batch loss: 0.067339 Batch F1: 0.7058823529411764
Epoch:  937        2 Batch loss: 0.066391 Batch F1: 0.7272727272727273
Epoch:  937        3 Batch loss: 0.078286 Batch F1: 0.7142857142857143
Epoch:  937        4 Batch loss: 0.057052 Batch F1: 0.5454545454545454
Epoch:  937        5 Batch loss: 0.080038 Batch F1: 0.8
Epoch:  937        6 Batch loss: 0.068470 Batch F1: 0.8571428571428571
Epoch:  937        7 Batch loss: 0.062119 Batch F1: 0.7692307692307692
Epoch:  937        8 Batch loss: 0.054748 Batch F1: 0.9473684210526316
Epoch:  937        9 Batch loss: 0.073756 Batch F1: 0.7499999999999999
Epoch:  937       10 Batch loss: 0.064931 Batch F1: 0.8571428571428571
Epoch:  937       11 Batch loss: 0.064993 Batch F1: 0.888888888888889
Epoch:  937       12 Batch loss: 0.059125 Batch F1: 0.8
Train Avg Loss  937: 0.066438

Train Avg F1  937: 0.7802224277843472

Val Avg Loss  937: 0.063654

Val Avg F1  937:  0.6205128205128204

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 938
--------------------------------------------------------------
Epoch:  938        1 Batch loss: 0.088483 Batch F1: 0.19999999999999998
Epoch:  938        2 Batch loss: 0.064403 Batch F1: 0.5454545454545454
Epoch:  938        3 Batch loss: 0.060260 Batch F1: 0.6666666666666666
Epoch:  938        4 Batch loss: 0.052482 Batch F1: 0.8
Epoch:  938        5 Batch loss: 0.078220 Batch F1: 0.2222222222222222
Epoch:  938        6 Batch loss: 0.072708 Batch F1: 0.625
Epoch:  938        7 Batch loss: 0.076875 Batch F1: 0.888888888888889
Epoch:  938        8 Batch loss: 0.082884 Batch F1: 0.8
Epoch:  938        9 Batch loss: 0.067545 Batch F1: 0.8235294117647058
Epoch:  938       10 Batch loss: 0.050087 Batch F1: 1.0
Epoch:  938       11 Batch loss: 0.052237 Batch F1: 0.9333333333333333
Epoch:  938       12 Batch loss: 0.058433 Batch F1: 1.0
Train Avg Loss  938: 0.067052

Train Avg F1  938: 0.7087579223608635

Val Avg Loss  938: 0.063524

Val Avg F1  938:  0.8917335115864529

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 939
--------------------------------------------------------------
Epoch:  939        1 Batch loss: 0.062085 Batch F1: 1.0
Epoch:  939        2 Batch loss: 0.085424 Batch F1: 0.761904761904762
Epoch:  939        3 Batch loss: 0.053745 Batch F1: 0.8571428571428571
Epoch:  939        4 Batch loss: 0.057830 Batch F1: 0.8750000000000001
Epoch:  939        5 Batch loss: 0.074959 Batch F1: 0.6153846153846153
Epoch:  939        6 Batch loss: 0.083776 Batch F1: 0.6666666666666666
Epoch:  939        7 Batch loss: 0.054617 Batch F1: 0.8
Epoch:  939        8 Batch loss: 0.070920 Batch F1: 0.6666666666666666
Epoch:  939        9 Batch loss: 0.079310 Batch F1: 0.5333333333333333
Epoch:  939       10 Batch loss: 0.046749 Batch F1: 0.8333333333333333
Epoch:  939       11 Batch loss: 0.086244 Batch F1: 0.42857142857142855
Epoch:  939       12 Batch loss: 0.052991 Batch F1: 1.0
Train Avg Loss  939: 0.067388

Train Avg F1  939: 0.7531669719169719

Val Avg Loss  939: 0.063791

Val Avg F1  939:  0.7863247863247863

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 940
--------------------------------------------------------------
Epoch:  940        1 Batch loss: 0.075084 Batch F1: 0.8
Epoch:  940        2 Batch loss: 0.063814 Batch F1: 0.9473684210526316
Epoch:  940        3 Batch loss: 0.047160 Batch F1: 0.8571428571428571
Epoch:  940        4 Batch loss: 0.068300 Batch F1: 0.4
Epoch:  940        5 Batch loss: 0.075466 Batch F1: 0.5714285714285715
Epoch:  940        6 Batch loss: 0.074650 Batch F1: 0.5
Epoch:  940        7 Batch loss: 0.055712 Batch F1: 0.7272727272727273
Epoch:  940        8 Batch loss: 0.078057 Batch F1: 0.5000000000000001
Epoch:  940        9 Batch loss: 0.083856 Batch F1: 0.6153846153846153
Epoch:  940       10 Batch loss: 0.078049 Batch F1: 0.8421052631578948
Epoch:  940       11 Batch loss: 0.046782 Batch F1: 0.8333333333333333
Epoch:  940       12 Batch loss: 0.067608 Batch F1: 0.8235294117647058
Train Avg Loss  940: 0.067878

Train Avg F1  940: 0.7014637667114446

Val Avg Loss  940: 0.062472

Val Avg F1  940:  0.7848515519568151

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 941
--------------------------------------------------------------
Epoch:  941        1 Batch loss: 0.076454 Batch F1: 0.4444444444444445
Epoch:  941        2 Batch loss: 0.075189 Batch F1: 0.2222222222222222
Epoch:  941        3 Batch loss: 0.063360 Batch F1: 0.5
Epoch:  941        4 Batch loss: 0.079542 Batch F1: 0.5882352941176471
Epoch:  941        5 Batch loss: 0.049766 Batch F1: 0.7692307692307693
Epoch:  941        6 Batch loss: 0.072533 Batch F1: 0.5
Epoch:  941        7 Batch loss: 0.057971 Batch F1: 0.9411764705882353
Epoch:  941        8 Batch loss: 0.050221 Batch F1: 1.0
Epoch:  941        9 Batch loss: 0.064773 Batch F1: 0.6666666666666666
Epoch:  941       10 Batch loss: 0.068862 Batch F1: 0.7368421052631579
Epoch:  941       11 Batch loss: 0.066690 Batch F1: 0.8421052631578948
Epoch:  941       12 Batch loss: 0.071495 Batch F1: 0.823529411764706
Train Avg Loss  941: 0.066405

Train Avg F1  941: 0.669537720621312

Val Avg Loss  941: 0.062678

Val Avg F1  941:  0.8954958795112249

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 942
--------------------------------------------------------------
Epoch:  942        1 Batch loss: 0.073394 Batch F1: 0.8
Epoch:  942        2 Batch loss: 0.076602 Batch F1: 0.8
Epoch:  942        3 Batch loss: 0.043355 Batch F1: 1.0
Epoch:  942        4 Batch loss: 0.053558 Batch F1: 1.0
Epoch:  942        5 Batch loss: 0.065091 Batch F1: 0.5454545454545454
Epoch:  942        6 Batch loss: 0.064418 Batch F1: 0.6153846153846153
Epoch:  942        7 Batch loss: 0.093378 Batch F1: 0.5263157894736842
Epoch:  942        8 Batch loss: 0.059798 Batch F1: 0.6666666666666666
Epoch:  942        9 Batch loss: 0.069386 Batch F1: 0.7142857142857143
Epoch:  942       10 Batch loss: 0.083128 Batch F1: 0.7368421052631579
Epoch:  942       11 Batch loss: 0.061369 Batch F1: 1.0
Epoch:  942       12 Batch loss: 0.053889 Batch F1: 0.8
Train Avg Loss  942: 0.066447

Train Avg F1  942: 0.7670791197106986

Val Avg Loss  942: 0.062633

Val Avg F1  942:  0.7927881297446515

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 943
--------------------------------------------------------------
Epoch:  943        1 Batch loss: 0.080070 Batch F1: 0.5
Epoch:  943        2 Batch loss: 0.050831 Batch F1: 0.923076923076923
Epoch:  943        3 Batch loss: 0.080070 Batch F1: 0.8
Epoch:  943        4 Batch loss: 0.076705 Batch F1: 0.9655172413793104
Epoch:  943        5 Batch loss: 0.081485 Batch F1: 0.9
Epoch:  943        6 Batch loss: 0.050585 Batch F1: 1.0
Epoch:  943        7 Batch loss: 0.071448 Batch F1: 0.923076923076923
Epoch:  943        8 Batch loss: 0.046783 Batch F1: 0.923076923076923
Epoch:  943        9 Batch loss: 0.072173 Batch F1: 0.7058823529411764
Epoch:  943       10 Batch loss: 0.069458 Batch F1: 0.6153846153846153
Epoch:  943       11 Batch loss: 0.057494 Batch F1: 0.923076923076923
Epoch:  943       12 Batch loss: 0.060068 Batch F1: 0.7272727272727273
Train Avg Loss  943: 0.066431

Train Avg F1  943: 0.8255303857737936

Val Avg Loss  943: 0.062972

Val Avg F1  943:  0.808974358974359

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 944
--------------------------------------------------------------
Epoch:  944        1 Batch loss: 0.045316 Batch F1: 1.0
Epoch:  944        2 Batch loss: 0.067749 Batch F1: 0.6666666666666666
Epoch:  944        3 Batch loss: 0.053108 Batch F1: 0.7272727272727273
Epoch:  944        4 Batch loss: 0.070730 Batch F1: 0.6666666666666666
Epoch:  944        5 Batch loss: 0.090328 Batch F1: 0.47058823529411764
Epoch:  944        6 Batch loss: 0.068263 Batch F1: 0.8571428571428571
Epoch:  944        7 Batch loss: 0.044847 Batch F1: 0.9090909090909091
Epoch:  944        8 Batch loss: 0.073136 Batch F1: 0.7142857142857143
Epoch:  944        9 Batch loss: 0.085332 Batch F1: 0.7999999999999999
Epoch:  944       10 Batch loss: 0.064013 Batch F1: 0.9600000000000001
Epoch:  944       11 Batch loss: 0.064721 Batch F1: 0.7272727272727273
Epoch:  944       12 Batch loss: 0.072533 Batch F1: 0.8571428571428571
Train Avg Loss  944: 0.066673

Train Avg F1  944: 0.7796774467362703

Val Avg Loss  944: 0.062459

Val Avg F1  944:  0.7839015151515152

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 945
--------------------------------------------------------------
Epoch:  945        1 Batch loss: 0.070614 Batch F1: 0.8695652173913044
Epoch:  945        2 Batch loss: 0.051143 Batch F1: 0.8571428571428571
Epoch:  945        3 Batch loss: 0.053003 Batch F1: 0.6
Epoch:  945        4 Batch loss: 0.041189 Batch F1: 0.8571428571428571
Epoch:  945        5 Batch loss: 0.043130 Batch F1: 0.8571428571428571
Epoch:  945        6 Batch loss: 0.092005 Batch F1: 0.42857142857142855
Epoch:  945        7 Batch loss: 0.076343 Batch F1: 0.5882352941176471
Epoch:  945        8 Batch loss: 0.065154 Batch F1: 0.9
Epoch:  945        9 Batch loss: 0.081986 Batch F1: 0.8421052631578948
Epoch:  945       10 Batch loss: 0.076061 Batch F1: 0.888888888888889
Epoch:  945       11 Batch loss: 0.081119 Batch F1: 0.9
Epoch:  945       12 Batch loss: 0.089763 Batch F1: 0.875
Train Avg Loss  945: 0.068459

Train Avg F1  945: 0.7886495552963112

Val Avg Loss  945: 0.065747

Val Avg F1  945:  0.8712121212121212

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 946
--------------------------------------------------------------
Epoch:  946        1 Batch loss: 0.071677 Batch F1: 0.8750000000000001
Epoch:  946        2 Batch loss: 0.057395 Batch F1: 0.8
Epoch:  946        3 Batch loss: 0.078167 Batch F1: 0.4
Epoch:  946        4 Batch loss: 0.079781 Batch F1: 0.0
Epoch:  946        5 Batch loss: 0.070325 Batch F1: 0.7142857142857143
Epoch:  946        6 Batch loss: 0.059333 Batch F1: 0.6153846153846153
Epoch:  946        7 Batch loss: 0.084622 Batch F1: 0.8
Epoch:  946        8 Batch loss: 0.090558 Batch F1: 0.2857142857142857
Epoch:  946        9 Batch loss: 0.061500 Batch F1: 0.4444444444444445
Epoch:  946       10 Batch loss: 0.081897 Batch F1: 0.5
Epoch:  946       11 Batch loss: 0.084577 Batch F1: 0.846153846153846
Epoch:  946       12 Batch loss: 0.056562 Batch F1: 0.9090909090909091
Train Avg Loss  946: 0.073033

Train Avg F1  946: 0.599172817922818

Val Avg Loss  946: 0.064819

Val Avg F1  946:  0.5971590909090909

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 947
--------------------------------------------------------------
Epoch:  947        1 Batch loss: 0.061842 Batch F1: 0.6153846153846153
Epoch:  947        2 Batch loss: 0.032572 Batch F1: 0.5
Epoch:  947        3 Batch loss: 0.099217 Batch F1: 0.15384615384615385
Epoch:  947        4 Batch loss: 0.051410 Batch F1: 0.25
Epoch:  947        5 Batch loss: 0.083581 Batch F1: 0.6666666666666666
Epoch:  947        6 Batch loss: 0.083386 Batch F1: 0.923076923076923
Epoch:  947        7 Batch loss: 0.087560 Batch F1: 0.8695652173913044
Epoch:  947        8 Batch loss: 0.070680 Batch F1: 1.0
Epoch:  947        9 Batch loss: 0.076340 Batch F1: 0.888888888888889
Epoch:  947       10 Batch loss: 0.079485 Batch F1: 0.6666666666666667
Epoch:  947       11 Batch loss: 0.050442 Batch F1: 0.5714285714285715
Epoch:  947       12 Batch loss: 0.096852 Batch F1: 0.0
Train Avg Loss  947: 0.072781

Train Avg F1  947: 0.5921269752791493

Val Avg Loss  947: 0.077147

Val Avg F1  947:  0.43076923076923074

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 948
--------------------------------------------------------------
Epoch:  948        1 Batch loss: 0.069476 Batch F1: 0.4
Epoch:  948        2 Batch loss: 0.079583 Batch F1: 0.9333333333333333
Epoch:  948        3 Batch loss: 0.083089 Batch F1: 0.6153846153846153
Epoch:  948        4 Batch loss: 0.055335 Batch F1: 0.5
Epoch:  948        5 Batch loss: 0.073150 Batch F1: 0.5
Epoch:  948        6 Batch loss: 0.056048 Batch F1: 0.8571428571428571
Epoch:  948        7 Batch loss: 0.080686 Batch F1: 0.46153846153846156
Epoch:  948        8 Batch loss: 0.090704 Batch F1: 0.782608695652174
Epoch:  948        9 Batch loss: 0.061886 Batch F1: 0.9523809523809523
Epoch:  948       10 Batch loss: 0.055821 Batch F1: 1.0
Epoch:  948       11 Batch loss: 0.076935 Batch F1: 0.7368421052631579
Epoch:  948       12 Batch loss: 0.055759 Batch F1: 0.7272727272727273
Train Avg Loss  948: 0.069873

Train Avg F1  948: 0.7055419789973566

Val Avg Loss  948: 0.064102

Val Avg F1  948:  0.7178758741258741

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 949
--------------------------------------------------------------
Epoch:  949        1 Batch loss: 0.072540 Batch F1: 0.33333333333333337
Epoch:  949        2 Batch loss: 0.085464 Batch F1: 0.625
Epoch:  949        3 Batch loss: 0.063322 Batch F1: 0.8571428571428571
Epoch:  949        4 Batch loss: 0.041695 Batch F1: 1.0
Epoch:  949        5 Batch loss: 0.060844 Batch F1: 0.6666666666666666
Epoch:  949        6 Batch loss: 0.069858 Batch F1: 0.5454545454545454
Epoch:  949        7 Batch loss: 0.069916 Batch F1: 0.6666666666666666
Epoch:  949        8 Batch loss: 0.071284 Batch F1: 0.6153846153846153
Epoch:  949        9 Batch loss: 0.052531 Batch F1: 0.8
Epoch:  949       10 Batch loss: 0.080943 Batch F1: 0.8571428571428571
Epoch:  949       11 Batch loss: 0.061214 Batch F1: 0.9333333333333333
Epoch:  949       12 Batch loss: 0.086542 Batch F1: 0.75
Train Avg Loss  949: 0.068013

Train Avg F1  949: 0.7208437395937395

Val Avg Loss  949: 0.065085

Val Avg F1  949:  0.926984126984127

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 950
--------------------------------------------------------------
Epoch:  950        1 Batch loss: 0.080059 Batch F1: 0.8571428571428571
Epoch:  950        2 Batch loss: 0.079280 Batch F1: 0.8421052631578948
Epoch:  950        3 Batch loss: 0.072716 Batch F1: 0.6666666666666666
Epoch:  950        4 Batch loss: 0.061851 Batch F1: 0.9
Epoch:  950        5 Batch loss: 0.059590 Batch F1: 0.8571428571428571
Epoch:  950        6 Batch loss: 0.078712 Batch F1: 0.7499999999999999
Epoch:  950        7 Batch loss: 0.066476 Batch F1: 0.2857142857142857
Epoch:  950        8 Batch loss: 0.066151 Batch F1: 0.6153846153846153
Epoch:  950        9 Batch loss: 0.055433 Batch F1: 0.7692307692307693
Epoch:  950       10 Batch loss: 0.060858 Batch F1: 0.8235294117647058
Epoch:  950       11 Batch loss: 0.063832 Batch F1: 0.8235294117647058
Epoch:  950       12 Batch loss: 0.065943 Batch F1: 0.7142857142857143
Train Avg Loss  950: 0.067575

Train Avg F1  950: 0.7420609876879225

Val Avg Loss  950: 0.063351

Val Avg F1  950:  0.8730319499341239

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 951
--------------------------------------------------------------
Epoch:  951        1 Batch loss: 0.056110 Batch F1: 0.9473684210526316
Epoch:  951        2 Batch loss: 0.069993 Batch F1: 0.8
Epoch:  951        3 Batch loss: 0.072685 Batch F1: 0.9090909090909091
Epoch:  951        4 Batch loss: 0.072058 Batch F1: 0.7999999999999999
Epoch:  951        5 Batch loss: 0.056075 Batch F1: 0.9090909090909091
Epoch:  951        6 Batch loss: 0.054427 Batch F1: 0.6
Epoch:  951        7 Batch loss: 0.101168 Batch F1: 0.6666666666666666
Epoch:  951        8 Batch loss: 0.073052 Batch F1: 0.8571428571428571
Epoch:  951        9 Batch loss: 0.048956 Batch F1: 1.0
Epoch:  951       10 Batch loss: 0.057932 Batch F1: 0.6666666666666666
Epoch:  951       11 Batch loss: 0.092079 Batch F1: 0.5454545454545454
Epoch:  951       12 Batch loss: 0.065865 Batch F1: 0.6666666666666666
Train Avg Loss  951: 0.068367

Train Avg F1  951: 0.7806789701526542

Val Avg Loss  951: 0.062888

Val Avg F1  951:  0.8017156862745098

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 952
--------------------------------------------------------------
Epoch:  952        1 Batch loss: 0.075613 Batch F1: 0.9090909090909091
Epoch:  952        2 Batch loss: 0.052036 Batch F1: 0.9090909090909091
Epoch:  952        3 Batch loss: 0.069460 Batch F1: 0.9
Epoch:  952        4 Batch loss: 0.068756 Batch F1: 0.8750000000000001
Epoch:  952        5 Batch loss: 0.068450 Batch F1: 0.8571428571428571
Epoch:  952        6 Batch loss: 0.057398 Batch F1: 0.8
Epoch:  952        7 Batch loss: 0.046597 Batch F1: 0.8571428571428571
Epoch:  952        8 Batch loss: 0.054192 Batch F1: 0.888888888888889
Epoch:  952        9 Batch loss: 0.078511 Batch F1: 0.9
Epoch:  952       10 Batch loss: 0.073663 Batch F1: 0.7692307692307693
Epoch:  952       11 Batch loss: 0.091539 Batch F1: 0.631578947368421
Epoch:  952       12 Batch loss: 0.059451 Batch F1: 0.6
Train Avg Loss  952: 0.066305

Train Avg F1  952: 0.8247638448296343

Val Avg Loss  952: 0.062780

Val Avg F1  952:  0.5938949938949939

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 953
--------------------------------------------------------------
Epoch:  953        1 Batch loss: 0.095469 Batch F1: 0.5263157894736842
Epoch:  953        2 Batch loss: 0.066402 Batch F1: 0.8571428571428571
Epoch:  953        3 Batch loss: 0.066465 Batch F1: 0.75
Epoch:  953        4 Batch loss: 0.063712 Batch F1: 0.8333333333333333
Epoch:  953        5 Batch loss: 0.055850 Batch F1: 0.9090909090909091
Epoch:  953        6 Batch loss: 0.078035 Batch F1: 0.8333333333333333
Epoch:  953        7 Batch loss: 0.050532 Batch F1: 0.5
Epoch:  953        8 Batch loss: 0.073732 Batch F1: 0.4615384615384615
Epoch:  953        9 Batch loss: 0.055197 Batch F1: 0.5
Epoch:  953       10 Batch loss: 0.051699 Batch F1: 0.5
Epoch:  953       11 Batch loss: 0.074872 Batch F1: 0.7000000000000001
Epoch:  953       12 Batch loss: 0.065672 Batch F1: 0.5
Train Avg Loss  953: 0.066470

Train Avg F1  953: 0.6558962236593816

Val Avg Loss  953: 0.062165

Val Avg F1  953:  0.6466374269005848

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 954
--------------------------------------------------------------
Epoch:  954        1 Batch loss: 0.055399 Batch F1: 0.4444444444444445
Epoch:  954        2 Batch loss: 0.065146 Batch F1: 0.7499999999999999
Epoch:  954        3 Batch loss: 0.078341 Batch F1: 0.9166666666666666
Epoch:  954        4 Batch loss: 0.085394 Batch F1: 0.8333333333333334
Epoch:  954        5 Batch loss: 0.067420 Batch F1: 0.9473684210526316
Epoch:  954        6 Batch loss: 0.066970 Batch F1: 0.8235294117647058
Epoch:  954        7 Batch loss: 0.074124 Batch F1: 0.888888888888889
Epoch:  954        8 Batch loss: 0.072372 Batch F1: 0.5
Epoch:  954        9 Batch loss: 0.055599 Batch F1: 0.4444444444444445
Epoch:  954       10 Batch loss: 0.074496 Batch F1: 0.5
Epoch:  954       11 Batch loss: 0.068356 Batch F1: 0.9333333333333333
Epoch:  954       12 Batch loss: 0.037763 Batch F1: 1.0
Train Avg Loss  954: 0.066782

Train Avg F1  954: 0.7485007453273708

Val Avg Loss  954: 0.063725

Val Avg F1  954:  0.6438120702826585

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 955
--------------------------------------------------------------
Epoch:  955        1 Batch loss: 0.071866 Batch F1: 0.7368421052631579
Epoch:  955        2 Batch loss: 0.078397 Batch F1: 0.7000000000000001
Epoch:  955        3 Batch loss: 0.056572 Batch F1: 0.7692307692307693
Epoch:  955        4 Batch loss: 0.049584 Batch F1: 0.888888888888889
Epoch:  955        5 Batch loss: 0.078817 Batch F1: 0.9090909090909091
Epoch:  955        6 Batch loss: 0.065928 Batch F1: 0.5454545454545454
Epoch:  955        7 Batch loss: 0.071345 Batch F1: 0.888888888888889
Epoch:  955        8 Batch loss: 0.070718 Batch F1: 0.7499999999999999
Epoch:  955        9 Batch loss: 0.049983 Batch F1: 1.0
Epoch:  955       10 Batch loss: 0.084847 Batch F1: 0.18181818181818182
Epoch:  955       11 Batch loss: 0.063337 Batch F1: 0.5
Epoch:  955       12 Batch loss: 0.072105 Batch F1: 0.6666666666666666
Train Avg Loss  955: 0.067792

Train Avg F1  955: 0.7114067462751673

Val Avg Loss  955: 0.063024

Val Avg F1  955:  0.8100961538461539

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 956
--------------------------------------------------------------
Epoch:  956        1 Batch loss: 0.070707 Batch F1: 0.8
Epoch:  956        2 Batch loss: 0.089072 Batch F1: 0.5454545454545454
Epoch:  956        3 Batch loss: 0.079936 Batch F1: 0.8571428571428571
Epoch:  956        4 Batch loss: 0.068769 Batch F1: 0.9600000000000001
Epoch:  956        5 Batch loss: 0.072359 Batch F1: 0.9
Epoch:  956        6 Batch loss: 0.044132 Batch F1: 1.0
Epoch:  956        7 Batch loss: 0.054537 Batch F1: 0.923076923076923
Epoch:  956        8 Batch loss: 0.059130 Batch F1: 0.6666666666666666
Epoch:  956        9 Batch loss: 0.058444 Batch F1: 0.5454545454545454
Epoch:  956       10 Batch loss: 0.064850 Batch F1: 0.4
Epoch:  956       11 Batch loss: 0.068252 Batch F1: 0.6153846153846153
Epoch:  956       12 Batch loss: 0.061942 Batch F1: 0.4444444444444445
Train Avg Loss  956: 0.066011

Train Avg F1  956: 0.7214687164687166

Val Avg Loss  956: 0.064449

Val Avg F1  956:  0.5888278388278388

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 957
--------------------------------------------------------------
Epoch:  957        1 Batch loss: 0.070493 Batch F1: 0.5
Epoch:  957        2 Batch loss: 0.065311 Batch F1: 0.9411764705882353
Epoch:  957        3 Batch loss: 0.066867 Batch F1: 0.923076923076923
Epoch:  957        4 Batch loss: 0.079709 Batch F1: 0.9333333333333333
Epoch:  957        5 Batch loss: 0.083927 Batch F1: 0.823529411764706
Epoch:  957        6 Batch loss: 0.054883 Batch F1: 1.0
Epoch:  957        7 Batch loss: 0.092065 Batch F1: 0.7777777777777777
Epoch:  957        8 Batch loss: 0.046428 Batch F1: 1.0
Epoch:  957        9 Batch loss: 0.068842 Batch F1: 0.5
Epoch:  957       10 Batch loss: 0.099638 Batch F1: 0.0
Epoch:  957       11 Batch loss: 0.057165 Batch F1: 0.6153846153846153
Epoch:  957       12 Batch loss: 0.060195 Batch F1: 0.7499999999999999
Train Avg Loss  957: 0.070460

Train Avg F1  957: 0.7303565443271326

Val Avg Loss  957: 0.064000

Val Avg F1  957:  0.6666666666666666

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 958
--------------------------------------------------------------
Epoch:  958        1 Batch loss: 0.038743 Batch F1: 0.0
Epoch:  958        2 Batch loss: 0.092477 Batch F1: 0.5
Epoch:  958        3 Batch loss: 0.066364 Batch F1: 0.7777777777777778
Epoch:  958        4 Batch loss: 0.073148 Batch F1: 0.9
Epoch:  958        5 Batch loss: 0.079127 Batch F1: 0.9166666666666666
Epoch:  958        6 Batch loss: 0.087142 Batch F1: 0.8571428571428571
Epoch:  958        7 Batch loss: 0.077422 Batch F1: 0.8333333333333333
Epoch:  958        8 Batch loss: 0.077429 Batch F1: 0.7272727272727272
Epoch:  958        9 Batch loss: 0.062296 Batch F1: 1.0
Epoch:  958       10 Batch loss: 0.060866 Batch F1: 0.25
Epoch:  958       11 Batch loss: 0.105305 Batch F1: 0.14285714285714288
Epoch:  958       12 Batch loss: 0.053984 Batch F1: 0.6666666666666666
Train Avg Loss  958: 0.072859

Train Avg F1  958: 0.6309764309764311

Val Avg Loss  958: 0.064167

Val Avg F1  958:  0.7796451914098972

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 959
--------------------------------------------------------------
Epoch:  959        1 Batch loss: 0.052588 Batch F1: 0.8
Epoch:  959        2 Batch loss: 0.066997 Batch F1: 0.9411764705882353
Epoch:  959        3 Batch loss: 0.074354 Batch F1: 0.8235294117647058
Epoch:  959        4 Batch loss: 0.057812 Batch F1: 0.7272727272727273
Epoch:  959        5 Batch loss: 0.087714 Batch F1: 0.3076923076923077
Epoch:  959        6 Batch loss: 0.061039 Batch F1: 0.8
Epoch:  959        7 Batch loss: 0.088148 Batch F1: 0.923076923076923
Epoch:  959        8 Batch loss: 0.053949 Batch F1: 1.0
Epoch:  959        9 Batch loss: 0.082310 Batch F1: 0.8421052631578948
Epoch:  959       10 Batch loss: 0.081386 Batch F1: 0.8235294117647058
Epoch:  959       11 Batch loss: 0.059672 Batch F1: 0.888888888888889
Epoch:  959       12 Batch loss: 0.054288 Batch F1: 0.888888888888889
Train Avg Loss  959: 0.068355

Train Avg F1  959: 0.8138466910912731

Val Avg Loss  959: 0.064881

Val Avg F1  959:  0.6443181818181818

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 960
--------------------------------------------------------------
Epoch:  960        1 Batch loss: 0.055635 Batch F1: 0.4444444444444445
Epoch:  960        2 Batch loss: 0.085928 Batch F1: 0.5
Epoch:  960        3 Batch loss: 0.059493 Batch F1: 0.7499999999999999
Epoch:  960        4 Batch loss: 0.048971 Batch F1: 0.5714285714285715
Epoch:  960        5 Batch loss: 0.082639 Batch F1: 0.7000000000000001
Epoch:  960        6 Batch loss: 0.083409 Batch F1: 0.6666666666666665
Epoch:  960        7 Batch loss: 0.079312 Batch F1: 0.8695652173913044
Epoch:  960        8 Batch loss: 0.079222 Batch F1: 0.7272727272727273
Epoch:  960        9 Batch loss: 0.054820 Batch F1: 1.0
Epoch:  960       10 Batch loss: 0.051492 Batch F1: 0.9090909090909091
Epoch:  960       11 Batch loss: 0.068707 Batch F1: 0.7142857142857143
Epoch:  960       12 Batch loss: 0.079368 Batch F1: 0.2222222222222222
Train Avg Loss  960: 0.069083

Train Avg F1  960: 0.67291470606688

Val Avg Loss  960: 0.065589

Val Avg F1  960:  0.6085218702865762

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 961
--------------------------------------------------------------
Epoch:  961        1 Batch loss: 0.083028 Batch F1: 0.8
Epoch:  961        2 Batch loss: 0.032487 Batch F1: 1.0
Epoch:  961        3 Batch loss: 0.079421 Batch F1: 0.6666666666666666
Epoch:  961        4 Batch loss: 0.060411 Batch F1: 0.7692307692307693
Epoch:  961        5 Batch loss: 0.060878 Batch F1: 0.5454545454545454
Epoch:  961        6 Batch loss: 0.070461 Batch F1: 0.6666666666666666
Epoch:  961        7 Batch loss: 0.052049 Batch F1: 0.6
Epoch:  961        8 Batch loss: 0.071752 Batch F1: 0.6153846153846153
Epoch:  961        9 Batch loss: 0.044602 Batch F1: 0.5714285714285715
Epoch:  961       10 Batch loss: 0.086408 Batch F1: 0.42857142857142855
Epoch:  961       11 Batch loss: 0.086170 Batch F1: 0.5882352941176471
Epoch:  961       12 Batch loss: 0.090054 Batch F1: 0.7499999999999999
Train Avg Loss  961: 0.068143

Train Avg F1  961: 0.6668032131267424

Val Avg Loss  961: 0.064340

Val Avg F1  961:  0.9312865497076023

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 962
--------------------------------------------------------------
Epoch:  962        1 Batch loss: 0.059545 Batch F1: 0.8333333333333334
Epoch:  962        2 Batch loss: 0.080271 Batch F1: 0.5454545454545454
Epoch:  962        3 Batch loss: 0.060245 Batch F1: 0.7692307692307693
Epoch:  962        4 Batch loss: 0.069065 Batch F1: 0.8571428571428571
Epoch:  962        5 Batch loss: 0.027153 Batch F1: 1.0
Epoch:  962        6 Batch loss: 0.060379 Batch F1: 0.6666666666666666
Epoch:  962        7 Batch loss: 0.048497 Batch F1: 0.5
Epoch:  962        8 Batch loss: 0.101951 Batch F1: 0.47058823529411764
Epoch:  962        9 Batch loss: 0.068354 Batch F1: 0.4
Epoch:  962       10 Batch loss: 0.095098 Batch F1: 0.6666666666666666
Epoch:  962       11 Batch loss: 0.066890 Batch F1: 1.0
Epoch:  962       12 Batch loss: 0.079573 Batch F1: 0.9523809523809523
Train Avg Loss  962: 0.068085

Train Avg F1  962: 0.7217886688474925

Val Avg Loss  962: 0.069747

Val Avg F1  962:  0.9245098039215687

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 963
--------------------------------------------------------------
Epoch:  963        1 Batch loss: 0.069877 Batch F1: 1.0
Epoch:  963        2 Batch loss: 0.059006 Batch F1: 0.9333333333333333
Epoch:  963        3 Batch loss: 0.085175 Batch F1: 0.8421052631578948
Epoch:  963        4 Batch loss: 0.067090 Batch F1: 0.9411764705882353
Epoch:  963        5 Batch loss: 0.050509 Batch F1: 0.9090909090909091
Epoch:  963        6 Batch loss: 0.072085 Batch F1: 0.4615384615384615
Epoch:  963        7 Batch loss: 0.077709 Batch F1: 0.7692307692307693
Epoch:  963        8 Batch loss: 0.054389 Batch F1: 0.8571428571428571
Epoch:  963        9 Batch loss: 0.088739 Batch F1: 0.6666666666666666
Epoch:  963       10 Batch loss: 0.080190 Batch F1: 0.8571428571428571
Epoch:  963       11 Batch loss: 0.068916 Batch F1: 0.8750000000000001
Epoch:  963       12 Batch loss: 0.062852 Batch F1: 1.0
Train Avg Loss  963: 0.069711

Train Avg F1  963: 0.8427022989909987

Val Avg Loss  963: 0.065977

Val Avg F1  963:  0.9142857142857144

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 964
--------------------------------------------------------------
Epoch:  964        1 Batch loss: 0.093838 Batch F1: 0.9411764705882353
Epoch:  964        2 Batch loss: 0.058783 Batch F1: 1.0
Epoch:  964        3 Batch loss: 0.074118 Batch F1: 0.962962962962963
Epoch:  964        4 Batch loss: 0.057701 Batch F1: 1.0
Epoch:  964        5 Batch loss: 0.102330 Batch F1: 0.3076923076923077
Epoch:  964        6 Batch loss: 0.059216 Batch F1: 0.33333333333333337
Epoch:  964        7 Batch loss: 0.084945 Batch F1: 0.3636363636363636
Epoch:  964        8 Batch loss: 0.050371 Batch F1: 0.5
Epoch:  964        9 Batch loss: 0.066963 Batch F1: 0.6153846153846153
Epoch:  964       10 Batch loss: 0.058485 Batch F1: 0.5
Epoch:  964       11 Batch loss: 0.053808 Batch F1: 0.8571428571428571
Epoch:  964       12 Batch loss: 0.058777 Batch F1: 0.9333333333333333
Train Avg Loss  964: 0.068278

Train Avg F1  964: 0.6928885203395007

Val Avg Loss  964: 0.062953

Val Avg F1  964:  0.9388644688644687

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 965
--------------------------------------------------------------
Epoch:  965        1 Batch loss: 0.070340 Batch F1: 0.8750000000000001
Epoch:  965        2 Batch loss: 0.057894 Batch F1: 0.9333333333333333
Epoch:  965        3 Batch loss: 0.064351 Batch F1: 0.7058823529411764
Epoch:  965        4 Batch loss: 0.078857 Batch F1: 0.3636363636363636
Epoch:  965        5 Batch loss: 0.076635 Batch F1: 0.5333333333333333
Epoch:  965        6 Batch loss: 0.054922 Batch F1: 0.4444444444444445
Epoch:  965        7 Batch loss: 0.057999 Batch F1: 0.8750000000000001
Epoch:  965        8 Batch loss: 0.053522 Batch F1: 0.7272727272727273
Epoch:  965        9 Batch loss: 0.085549 Batch F1: 0.8571428571428571
Epoch:  965       10 Batch loss: 0.072775 Batch F1: 0.8333333333333333
Epoch:  965       11 Batch loss: 0.066362 Batch F1: 0.7272727272727273
Epoch:  965       12 Batch loss: 0.052112 Batch F1: 1.0
Train Avg Loss  965: 0.065943

Train Avg F1  965: 0.7396376227258581

Val Avg Loss  965: 0.066668

Val Avg F1  965:  0.9146198830409358

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 966
--------------------------------------------------------------
Epoch:  966        1 Batch loss: 0.062463 Batch F1: 0.9333333333333333
Epoch:  966        2 Batch loss: 0.058303 Batch F1: 0.7272727272727273
Epoch:  966        3 Batch loss: 0.079601 Batch F1: 0.4
Epoch:  966        4 Batch loss: 0.045651 Batch F1: 0.5714285714285715
Epoch:  966        5 Batch loss: 0.062521 Batch F1: 0.8
Epoch:  966        6 Batch loss: 0.084319 Batch F1: 0.3636363636363636
Epoch:  966        7 Batch loss: 0.085829 Batch F1: 0.5333333333333333
Epoch:  966        8 Batch loss: 0.070251 Batch F1: 0.6666666666666666
Epoch:  966        9 Batch loss: 0.063150 Batch F1: 0.6153846153846153
Epoch:  966       10 Batch loss: 0.078788 Batch F1: 0.88
Epoch:  966       11 Batch loss: 0.083504 Batch F1: 0.9600000000000001
Epoch:  966       12 Batch loss: 0.048419 Batch F1: 1.0
Train Avg Loss  966: 0.068567

Train Avg F1  966: 0.7042546342546343

Val Avg Loss  966: 0.067226

Val Avg F1  966:  0.9305555555555556

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 967
--------------------------------------------------------------
Epoch:  967        1 Batch loss: 0.080217 Batch F1: 0.8571428571428572
Epoch:  967        2 Batch loss: 0.063856 Batch F1: 1.0
Epoch:  967        3 Batch loss: 0.074740 Batch F1: 0.9333333333333333
Epoch:  967        4 Batch loss: 0.078921 Batch F1: 0.6666666666666666
Epoch:  967        5 Batch loss: 0.082954 Batch F1: 0.7058823529411764
Epoch:  967        6 Batch loss: 0.067285 Batch F1: 0.9333333333333333
Epoch:  967        7 Batch loss: 0.054592 Batch F1: 0.7692307692307693
Epoch:  967        8 Batch loss: 0.049212 Batch F1: 0.8
Epoch:  967        9 Batch loss: 0.060820 Batch F1: 0.6153846153846153
Epoch:  967       10 Batch loss: 0.070799 Batch F1: 0.625
Epoch:  967       11 Batch loss: 0.077649 Batch F1: 0.5714285714285715
Epoch:  967       12 Batch loss: 0.059217 Batch F1: 0.7272727272727273
Train Avg Loss  967: 0.068355

Train Avg F1  967: 0.7670562688945041

Val Avg Loss  967: 0.064378

Val Avg F1  967:  0.8844470480499893

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 968
--------------------------------------------------------------
Epoch:  968        1 Batch loss: 0.056302 Batch F1: 0.923076923076923
Epoch:  968        2 Batch loss: 0.086739 Batch F1: 0.8
Epoch:  968        3 Batch loss: 0.068794 Batch F1: 0.8
Epoch:  968        4 Batch loss: 0.060425 Batch F1: 0.6666666666666666
Epoch:  968        5 Batch loss: 0.089283 Batch F1: 0.5333333333333333
Epoch:  968        6 Batch loss: 0.077766 Batch F1: 0.8333333333333333
Epoch:  968        7 Batch loss: 0.079598 Batch F1: 0.923076923076923
Epoch:  968        8 Batch loss: 0.041076 Batch F1: 1.0
Epoch:  968        9 Batch loss: 0.056272 Batch F1: 1.0
Epoch:  968       10 Batch loss: 0.061566 Batch F1: 0.9090909090909091
Epoch:  968       11 Batch loss: 0.070961 Batch F1: 0.7777777777777778
Epoch:  968       12 Batch loss: 0.053931 Batch F1: 0.7272727272727273
Train Avg Loss  968: 0.066893

Train Avg F1  968: 0.8244690494690494

Val Avg Loss  968: 0.063804

Val Avg F1  968:  0.6025917065390749

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 969
--------------------------------------------------------------
Epoch:  969        1 Batch loss: 0.048135 Batch F1: 0.9333333333333333
Epoch:  969        2 Batch loss: 0.089553 Batch F1: 0.3076923076923077
Epoch:  969        3 Batch loss: 0.085861 Batch F1: 0.7058823529411764
Epoch:  969        4 Batch loss: 0.077140 Batch F1: 0.6153846153846153
Epoch:  969        5 Batch loss: 0.053319 Batch F1: 0.9473684210526316
Epoch:  969        6 Batch loss: 0.060702 Batch F1: 1.0
Epoch:  969        7 Batch loss: 0.061533 Batch F1: 0.8571428571428571
Epoch:  969        8 Batch loss: 0.066971 Batch F1: 0.7142857142857143
Epoch:  969        9 Batch loss: 0.060035 Batch F1: 0.6
Epoch:  969       10 Batch loss: 0.091096 Batch F1: 0.5
Epoch:  969       11 Batch loss: 0.066142 Batch F1: 0.8
Epoch:  969       12 Batch loss: 0.070241 Batch F1: 0.9090909090909091
Train Avg Loss  969: 0.069227

Train Avg F1  969: 0.7408483759102954

Val Avg Loss  969: 0.063573

Val Avg F1  969:  0.8716517400727928

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 970
--------------------------------------------------------------
Epoch:  970        1 Batch loss: 0.077944 Batch F1: 0.7499999999999999
Epoch:  970        2 Batch loss: 0.076117 Batch F1: 0.8695652173913044
Epoch:  970        3 Batch loss: 0.060253 Batch F1: 0.9333333333333333
Epoch:  970        4 Batch loss: 0.072509 Batch F1: 0.4
Epoch:  970        5 Batch loss: 0.059472 Batch F1: 0.2857142857142857
Epoch:  970        6 Batch loss: 0.042320 Batch F1: 0.923076923076923
Epoch:  970        7 Batch loss: 0.064424 Batch F1: 0.6153846153846153
Epoch:  970        8 Batch loss: 0.064694 Batch F1: 0.5
Epoch:  970        9 Batch loss: 0.069510 Batch F1: 0.7058823529411764
Epoch:  970       10 Batch loss: 0.066806 Batch F1: 0.9523809523809523
Epoch:  970       11 Batch loss: 0.055547 Batch F1: 1.0
Epoch:  970       12 Batch loss: 0.106393 Batch F1: 0.5
Train Avg Loss  970: 0.067999

Train Avg F1  970: 0.7029448066852159

Val Avg Loss  970: 0.064421

Val Avg F1  970:  0.7289986329460014

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 971
--------------------------------------------------------------
Epoch:  971        1 Batch loss: 0.083763 Batch F1: 0.42857142857142855
Epoch:  971        2 Batch loss: 0.044080 Batch F1: 0.9090909090909091
Epoch:  971        3 Batch loss: 0.070831 Batch F1: 0.9090909090909091
Epoch:  971        4 Batch loss: 0.058659 Batch F1: 1.0
Epoch:  971        5 Batch loss: 0.069789 Batch F1: 0.8888888888888888
Epoch:  971        6 Batch loss: 0.078436 Batch F1: 0.4615384615384615
Epoch:  971        7 Batch loss: 0.079787 Batch F1: 0.9
Epoch:  971        8 Batch loss: 0.070578 Batch F1: 0.7692307692307693
Epoch:  971        9 Batch loss: 0.063234 Batch F1: 0.8750000000000001
Epoch:  971       10 Batch loss: 0.048246 Batch F1: 0.8750000000000001
Epoch:  971       11 Batch loss: 0.076740 Batch F1: 0.8571428571428571
Epoch:  971       12 Batch loss: 0.072602 Batch F1: 0.5
Train Avg Loss  971: 0.068062

Train Avg F1  971: 0.7811295186295187

Val Avg Loss  971: 0.064112

Val Avg F1  971:  0.7478632478632479

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 972
--------------------------------------------------------------
Epoch:  972        1 Batch loss: 0.076350 Batch F1: 0.7499999999999999
Epoch:  972        2 Batch loss: 0.062552 Batch F1: 0.6
Epoch:  972        3 Batch loss: 0.069298 Batch F1: 0.7499999999999999
Epoch:  972        4 Batch loss: 0.057388 Batch F1: 0.8421052631578948
Epoch:  972        5 Batch loss: 0.055934 Batch F1: 0.9411764705882353
Epoch:  972        6 Batch loss: 0.072725 Batch F1: 0.7142857142857143
Epoch:  972        7 Batch loss: 0.076367 Batch F1: 0.5454545454545454
Epoch:  972        8 Batch loss: 0.081443 Batch F1: 0.6153846153846153
Epoch:  972        9 Batch loss: 0.084900 Batch F1: 0.8333333333333333
Epoch:  972       10 Batch loss: 0.066810 Batch F1: 0.888888888888889
Epoch:  972       11 Batch loss: 0.070542 Batch F1: 0.9411764705882353
Epoch:  972       12 Batch loss: 0.040802 Batch F1: 1.0
Train Avg Loss  972: 0.067926

Train Avg F1  972: 0.7851504418067884

Val Avg Loss  972: 0.061684

Val Avg F1  972:  0.7736928104575164

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 973
--------------------------------------------------------------
Epoch:  973        1 Batch loss: 0.050951 Batch F1: 0.4444444444444445
Epoch:  973        2 Batch loss: 0.045754 Batch F1: 0.7272727272727273
Epoch:  973        3 Batch loss: 0.085266 Batch F1: 0.5
Epoch:  973        4 Batch loss: 0.050902 Batch F1: 0.2857142857142857
Epoch:  973        5 Batch loss: 0.076127 Batch F1: 0.6153846153846153
Epoch:  973        6 Batch loss: 0.103319 Batch F1: 0.7272727272727273
Epoch:  973        7 Batch loss: 0.052126 Batch F1: 1.0
Epoch:  973        8 Batch loss: 0.055196 Batch F1: 0.9411764705882353
Epoch:  973        9 Batch loss: 0.095336 Batch F1: 0.8695652173913044
Epoch:  973       10 Batch loss: 0.075107 Batch F1: 0.8235294117647058
Epoch:  973       11 Batch loss: 0.060966 Batch F1: 0.8571428571428571
Epoch:  973       12 Batch loss: 0.070346 Batch F1: 0.923076923076923
Train Avg Loss  973: 0.068450

Train Avg F1  973: 0.7262149733377354

Val Avg Loss  973: 0.065700

Val Avg F1  973:  0.6475490196078431

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 974
--------------------------------------------------------------
Epoch:  974        1 Batch loss: 0.050812 Batch F1: 0.6666666666666666
Epoch:  974        2 Batch loss: 0.094844 Batch F1: 0.5555555555555556
Epoch:  974        3 Batch loss: 0.051381 Batch F1: 0.8571428571428571
Epoch:  974        4 Batch loss: 0.069094 Batch F1: 0.8571428571428571
Epoch:  974        5 Batch loss: 0.069790 Batch F1: 0.7499999999999999
Epoch:  974        6 Batch loss: 0.065750 Batch F1: 0.6
Epoch:  974        7 Batch loss: 0.065883 Batch F1: 0.5714285714285715
Epoch:  974        8 Batch loss: 0.096127 Batch F1: 0.42857142857142855
Epoch:  974        9 Batch loss: 0.061596 Batch F1: 1.0
Epoch:  974       10 Batch loss: 0.081684 Batch F1: 0.9090909090909091
Epoch:  974       11 Batch loss: 0.059494 Batch F1: 0.9411764705882353
Epoch:  974       12 Batch loss: 0.049167 Batch F1: 1.0
Train Avg Loss  974: 0.067969

Train Avg F1  974: 0.76139794301559

Val Avg Loss  974: 0.065713

Val Avg F1  974:  0.653177704648293

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 975
--------------------------------------------------------------
Epoch:  975        1 Batch loss: 0.083571 Batch F1: 0.6666666666666666
Epoch:  975        2 Batch loss: 0.054851 Batch F1: 0.8750000000000001
Epoch:  975        3 Batch loss: 0.106821 Batch F1: 0.8
Epoch:  975        4 Batch loss: 0.066830 Batch F1: 0.8333333333333333
Epoch:  975        5 Batch loss: 0.065232 Batch F1: 1.0
Epoch:  975        6 Batch loss: 0.058484 Batch F1: 0.923076923076923
Epoch:  975        7 Batch loss: 0.076256 Batch F1: 0.625
Epoch:  975        8 Batch loss: 0.070821 Batch F1: 0.4
Epoch:  975        9 Batch loss: 0.074779 Batch F1: 0.0
Epoch:  975       10 Batch loss: 0.052919 Batch F1: 0.33333333333333337
Epoch:  975       11 Batch loss: 0.068890 Batch F1: 0.5454545454545454
Epoch:  975       12 Batch loss: 0.057470 Batch F1: 0.4444444444444445
Train Avg Loss  975: 0.069744

Train Avg F1  975: 0.6205257705257705

Val Avg Loss  975: 0.065226

Val Avg F1  975:  0.6133699633699634

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 976
--------------------------------------------------------------
Epoch:  976        1 Batch loss: 0.079266 Batch F1: 0.6666666666666666
Epoch:  976        2 Batch loss: 0.078115 Batch F1: 0.9
Epoch:  976        3 Batch loss: 0.070673 Batch F1: 0.9333333333333333
Epoch:  976        4 Batch loss: 0.054889 Batch F1: 0.7142857142857143
Epoch:  976        5 Batch loss: 0.065691 Batch F1: 0.625
Epoch:  976        6 Batch loss: 0.062968 Batch F1: 1.0
Epoch:  976        7 Batch loss: 0.057068 Batch F1: 0.9411764705882353
Epoch:  976        8 Batch loss: 0.052716 Batch F1: 0.5714285714285715
Epoch:  976        9 Batch loss: 0.072687 Batch F1: 0.5333333333333333
Epoch:  976       10 Batch loss: 0.089286 Batch F1: 0.5
Epoch:  976       11 Batch loss: 0.068455 Batch F1: 0.7272727272727273
Epoch:  976       12 Batch loss: 0.063764 Batch F1: 0.8333333333333333
Train Avg Loss  976: 0.067965

Train Avg F1  976: 0.745485845853493

Val Avg Loss  976: 0.066520

Val Avg F1  976:  0.9032467532467532

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 977
--------------------------------------------------------------
Epoch:  977        1 Batch loss: 0.061894 Batch F1: 0.9411764705882353
Epoch:  977        2 Batch loss: 0.063165 Batch F1: 1.0
Epoch:  977        3 Batch loss: 0.074127 Batch F1: 0.9
Epoch:  977        4 Batch loss: 0.066421 Batch F1: 0.823529411764706
Epoch:  977        5 Batch loss: 0.069742 Batch F1: 0.5454545454545454
Epoch:  977        6 Batch loss: 0.057149 Batch F1: 0.2857142857142857
Epoch:  977        7 Batch loss: 0.079132 Batch F1: 0.18181818181818182
Epoch:  977        8 Batch loss: 0.090289 Batch F1: 0.7368421052631579
Epoch:  977        9 Batch loss: 0.077340 Batch F1: 0.7692307692307693
Epoch:  977       10 Batch loss: 0.064326 Batch F1: 1.0
Epoch:  977       11 Batch loss: 0.065294 Batch F1: 0.888888888888889
Epoch:  977       12 Batch loss: 0.077612 Batch F1: 0.9090909090909091
Train Avg Loss  977: 0.070541

Train Avg F1  977: 0.7484787973178065

Val Avg Loss  977: 0.064509

Val Avg F1  977:  0.9013526570048309

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 978
--------------------------------------------------------------
Epoch:  978        1 Batch loss: 0.056471 Batch F1: 1.0
Epoch:  978        2 Batch loss: 0.061576 Batch F1: 0.6666666666666666
Epoch:  978        3 Batch loss: 0.065404 Batch F1: 0.2857142857142857
Epoch:  978        4 Batch loss: 0.068317 Batch F1: 0.7142857142857143
Epoch:  978        5 Batch loss: 0.089609 Batch F1: 0.5882352941176471
Epoch:  978        6 Batch loss: 0.072427 Batch F1: 0.3636363636363636
Epoch:  978        7 Batch loss: 0.069006 Batch F1: 1.0
Epoch:  978        8 Batch loss: 0.075074 Batch F1: 0.6666666666666666
Epoch:  978        9 Batch loss: 0.119654 Batch F1: 0.4210526315789474
Epoch:  978       10 Batch loss: 0.035570 Batch F1: 0.8571428571428571
Epoch:  978       11 Batch loss: 0.060796 Batch F1: 0.5454545454545454
Epoch:  978       12 Batch loss: 0.079160 Batch F1: 0.8
Train Avg Loss  978: 0.071089

Train Avg F1  978: 0.6590712521053079

Val Avg Loss  978: 0.062968

Val Avg F1  978:  0.7840579710144927

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 979
--------------------------------------------------------------
Epoch:  979        1 Batch loss: 0.070977 Batch F1: 0.9411764705882353
Epoch:  979        2 Batch loss: 0.067394 Batch F1: 0.9166666666666666
Epoch:  979        3 Batch loss: 0.072682 Batch F1: 0.8750000000000001
Epoch:  979        4 Batch loss: 0.044064 Batch F1: 1.0
Epoch:  979        5 Batch loss: 0.071560 Batch F1: 0.6
Epoch:  979        6 Batch loss: 0.079482 Batch F1: 0.8421052631578948
Epoch:  979        7 Batch loss: 0.056692 Batch F1: 0.8571428571428571
Epoch:  979        8 Batch loss: 0.062059 Batch F1: 0.8571428571428571
Epoch:  979        9 Batch loss: 0.072753 Batch F1: 0.888888888888889
Epoch:  979       10 Batch loss: 0.061203 Batch F1: 0.8750000000000001
Epoch:  979       11 Batch loss: 0.075492 Batch F1: 0.8750000000000001
Epoch:  979       12 Batch loss: 0.086107 Batch F1: 0.888888888888889
Train Avg Loss  979: 0.068372

Train Avg F1  979: 0.8680843243730241

Val Avg Loss  979: 0.062349

Val Avg F1  979:  0.9081320450885668

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 980
--------------------------------------------------------------
Epoch:  980        1 Batch loss: 0.058393 Batch F1: 0.9411764705882353
Epoch:  980        2 Batch loss: 0.057453 Batch F1: 0.6666666666666666
Epoch:  980        3 Batch loss: 0.059343 Batch F1: 0.4
Epoch:  980        4 Batch loss: 0.063393 Batch F1: 0.6666666666666666
Epoch:  980        5 Batch loss: 0.113361 Batch F1: 0.631578947368421
Epoch:  980        6 Batch loss: 0.074266 Batch F1: 0.0
Epoch:  980        7 Batch loss: 0.112143 Batch F1: 0.0
Epoch:  980        8 Batch loss: 0.099970 Batch F1: 0.0
Epoch:  980        9 Batch loss: 0.077727 Batch F1: 0.9166666666666666
Epoch:  980       10 Batch loss: 0.086425 Batch F1: 0.9473684210526316
Epoch:  980       11 Batch loss: 0.084679 Batch F1: 0.875
Epoch:  980       12 Batch loss: 0.096120 Batch F1: 0.8
Train Avg Loss  980: 0.081939

Train Avg F1  980: 0.5704269865841073

Val Avg Loss  980: 0.072241

Val Avg F1  980:  0.5720238095238095

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 981
--------------------------------------------------------------
Epoch:  981        1 Batch loss: 0.104704 Batch F1: 0.6399999999999999
Epoch:  981        2 Batch loss: 0.099133 Batch F1: 0.5555555555555556
Epoch:  981        3 Batch loss: 0.065385 Batch F1: 0.923076923076923
Epoch:  981        4 Batch loss: 0.071530 Batch F1: 0.6666666666666666
Epoch:  981        5 Batch loss: 0.052390 Batch F1: 0.7272727272727273
Epoch:  981        6 Batch loss: 0.046579 Batch F1: 0.7499999999999999
Epoch:  981        7 Batch loss: 0.093709 Batch F1: 0.42857142857142855
Epoch:  981        8 Batch loss: 0.075548 Batch F1: 0.7058823529411764
Epoch:  981        9 Batch loss: 0.067730 Batch F1: 0.9090909090909091
Epoch:  981       10 Batch loss: 0.061153 Batch F1: 1.0
Epoch:  981       11 Batch loss: 0.062080 Batch F1: 0.8
Epoch:  981       12 Batch loss: 0.080693 Batch F1: 0.5454545454545454
Train Avg Loss  981: 0.073386

Train Avg F1  981: 0.7209642590524944

Val Avg Loss  981: 0.063357

Val Avg F1  981:  0.6468131112093961

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 982
--------------------------------------------------------------
Epoch:  982        1 Batch loss: 0.066122 Batch F1: 0.7058823529411764
Epoch:  982        2 Batch loss: 0.074679 Batch F1: 0.3636363636363636
Epoch:  982        3 Batch loss: 0.076135 Batch F1: 0.6153846153846153
Epoch:  982        4 Batch loss: 0.082205 Batch F1: 0.6666666666666666
Epoch:  982        5 Batch loss: 0.095021 Batch F1: 0.8
Epoch:  982        6 Batch loss: 0.064073 Batch F1: 1.0
Epoch:  982        7 Batch loss: 0.075937 Batch F1: 0.7692307692307692
Epoch:  982        8 Batch loss: 0.062061 Batch F1: 0.9090909090909091
Epoch:  982        9 Batch loss: 0.046742 Batch F1: 0.4
Epoch:  982       10 Batch loss: 0.031958 Batch F1: 0.5
Epoch:  982       11 Batch loss: 0.103027 Batch F1: 0.0
Epoch:  982       12 Batch loss: 0.098563 Batch F1: 0.0
Train Avg Loss  982: 0.073044

Train Avg F1  982: 0.5608243064125417

Val Avg Loss  982: 0.071729

Val Avg F1  982:  0.4030075187969925

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 983
--------------------------------------------------------------
Epoch:  983        1 Batch loss: 0.069683 Batch F1: 0.6666666666666666
Epoch:  983        2 Batch loss: 0.063884 Batch F1: 0.4444444444444445
Epoch:  983        3 Batch loss: 0.073568 Batch F1: 0.9411764705882353
Epoch:  983        4 Batch loss: 0.088089 Batch F1: 0.7777777777777778
Epoch:  983        5 Batch loss: 0.059690 Batch F1: 0.5
Epoch:  983        6 Batch loss: 0.073808 Batch F1: 0.4
Epoch:  983        7 Batch loss: 0.073581 Batch F1: 0.6666666666666666
Epoch:  983        8 Batch loss: 0.079655 Batch F1: 0.5882352941176471
Epoch:  983        9 Batch loss: 0.039555 Batch F1: 0.9090909090909091
Epoch:  983       10 Batch loss: 0.065776 Batch F1: 0.4444444444444445
Epoch:  983       11 Batch loss: 0.070525 Batch F1: 0.5714285714285715
Epoch:  983       12 Batch loss: 0.095137 Batch F1: 0.9090909090909091
Train Avg Loss  983: 0.071079

Train Avg F1  983: 0.651585179526356

Val Avg Loss  983: 0.066734

Val Avg F1  983:  0.9222855149965125

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 984
--------------------------------------------------------------
Epoch:  984        1 Batch loss: 0.056602 Batch F1: 1.0
Epoch:  984        2 Batch loss: 0.077424 Batch F1: 0.8750000000000001
Epoch:  984        3 Batch loss: 0.063730 Batch F1: 0.7272727272727273
Epoch:  984        4 Batch loss: 0.090713 Batch F1: 0.47058823529411764
Epoch:  984        5 Batch loss: 0.067087 Batch F1: 0.4444444444444445
Epoch:  984        6 Batch loss: 0.044326 Batch F1: 0.7499999999999999
Epoch:  984        7 Batch loss: 0.069381 Batch F1: 0.6
Epoch:  984        8 Batch loss: 0.086923 Batch F1: 0.5882352941176471
Epoch:  984        9 Batch loss: 0.064561 Batch F1: 0.7058823529411764
Epoch:  984       10 Batch loss: 0.070469 Batch F1: 0.8421052631578948
Epoch:  984       11 Batch loss: 0.069732 Batch F1: 0.9565217391304348
Epoch:  984       12 Batch loss: 0.083975 Batch F1: 0.8571428571428571
Train Avg Loss  984: 0.070410

Train Avg F1  984: 0.7347660761251084

Val Avg Loss  984: 0.069117

Val Avg F1  984:  0.9221661490683231

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 985
--------------------------------------------------------------
Epoch:  985        1 Batch loss: 0.063719 Batch F1: 0.9090909090909091
Epoch:  985        2 Batch loss: 0.068286 Batch F1: 0.888888888888889
Epoch:  985        3 Batch loss: 0.045915 Batch F1: 0.7499999999999999
Epoch:  985        4 Batch loss: 0.077828 Batch F1: 0.5714285714285715
Epoch:  985        5 Batch loss: 0.066383 Batch F1: 0.6153846153846153
Epoch:  985        6 Batch loss: 0.063684 Batch F1: 0.6
Epoch:  985        7 Batch loss: 0.067176 Batch F1: 0.9
Epoch:  985        8 Batch loss: 0.071085 Batch F1: 0.8333333333333333
Epoch:  985        9 Batch loss: 0.070133 Batch F1: 0.9090909090909091
Epoch:  985       10 Batch loss: 0.081345 Batch F1: 0.6153846153846153
Epoch:  985       11 Batch loss: 0.066975 Batch F1: 0.4
Epoch:  985       12 Batch loss: 0.118360 Batch F1: 0.5263157894736842
Train Avg Loss  985: 0.071741

Train Avg F1  985: 0.7099098026729607

Val Avg Loss  985: 0.065949

Val Avg F1  985:  0.9347890671420084

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 986
--------------------------------------------------------------
Epoch:  986        1 Batch loss: 0.055741 Batch F1: 1.0
Epoch:  986        2 Batch loss: 0.082354 Batch F1: 0.823529411764706
Epoch:  986        3 Batch loss: 0.068550 Batch F1: 1.0
Epoch:  986        4 Batch loss: 0.074246 Batch F1: 0.7692307692307692
Epoch:  986        5 Batch loss: 0.059961 Batch F1: 0.8750000000000001
Epoch:  986        6 Batch loss: 0.105735 Batch F1: 0.5555555555555556
Epoch:  986        7 Batch loss: 0.069410 Batch F1: 0.7272727272727273
Epoch:  986        8 Batch loss: 0.064585 Batch F1: 0.8333333333333333
Epoch:  986        9 Batch loss: 0.077988 Batch F1: 0.0
Epoch:  986       10 Batch loss: 0.075070 Batch F1: 0.7499999999999999
Epoch:  986       11 Batch loss: 0.050577 Batch F1: 0.9333333333333333
Epoch:  986       12 Batch loss: 0.058297 Batch F1: 1.0
Train Avg Loss  986: 0.070210

Train Avg F1  986: 0.7722712608742021

Val Avg Loss  986: 0.064295

Val Avg F1  986:  0.6109592162223741

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 987
--------------------------------------------------------------
Epoch:  987        1 Batch loss: 0.079965 Batch F1: 0.3076923076923077
Epoch:  987        2 Batch loss: 0.060594 Batch F1: 0.4444444444444445
Epoch:  987        3 Batch loss: 0.085585 Batch F1: 0.7368421052631579
Epoch:  987        4 Batch loss: 0.055724 Batch F1: 0.8
Epoch:  987        5 Batch loss: 0.049718 Batch F1: 0.888888888888889
Epoch:  987        6 Batch loss: 0.073160 Batch F1: 0.9600000000000001
Epoch:  987        7 Batch loss: 0.062086 Batch F1: 0.8571428571428571
Epoch:  987        8 Batch loss: 0.079979 Batch F1: 0.6153846153846153
Epoch:  987        9 Batch loss: 0.063190 Batch F1: 0.9523809523809523
Epoch:  987       10 Batch loss: 0.076021 Batch F1: 0.888888888888889
Epoch:  987       11 Batch loss: 0.060809 Batch F1: 0.9411764705882353
Epoch:  987       12 Batch loss: 0.071865 Batch F1: 0.8333333333333333
Train Avg Loss  987: 0.068225

Train Avg F1  987: 0.7688479053339735

Val Avg Loss  987: 0.063605

Val Avg F1  987:  0.796011396011396

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 988
--------------------------------------------------------------
Epoch:  988        1 Batch loss: 0.072295 Batch F1: 0.8750000000000001
Epoch:  988        2 Batch loss: 0.056185 Batch F1: 0.923076923076923
Epoch:  988        3 Batch loss: 0.069578 Batch F1: 0.6666666666666666
Epoch:  988        4 Batch loss: 0.057623 Batch F1: 0.8750000000000001
Epoch:  988        5 Batch loss: 0.061993 Batch F1: 0.6666666666666666
Epoch:  988        6 Batch loss: 0.075241 Batch F1: 0.5
Epoch:  988        7 Batch loss: 0.063351 Batch F1: 0.6666666666666666
Epoch:  988        8 Batch loss: 0.074906 Batch F1: 0.5714285714285715
Epoch:  988        9 Batch loss: 0.080901 Batch F1: 0.888888888888889
Epoch:  988       10 Batch loss: 0.063268 Batch F1: 0.923076923076923
Epoch:  988       11 Batch loss: 0.076305 Batch F1: 0.9
Epoch:  988       12 Batch loss: 0.061752 Batch F1: 0.8
Train Avg Loss  988: 0.067783

Train Avg F1  988: 0.7713726088726091

Val Avg Loss  988: 0.065353

Val Avg F1  988:  0.7652380952380953

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 989
--------------------------------------------------------------
Epoch:  989        1 Batch loss: 0.075065 Batch F1: 0.7499999999999999
Epoch:  989        2 Batch loss: 0.065334 Batch F1: 0.7999999999999999
Epoch:  989        3 Batch loss: 0.060956 Batch F1: 0.8750000000000001
Epoch:  989        4 Batch loss: 0.057259 Batch F1: 0.8333333333333333
Epoch:  989        5 Batch loss: 0.061298 Batch F1: 0.6666666666666666
Epoch:  989        6 Batch loss: 0.074483 Batch F1: 0.7777777777777778
Epoch:  989        7 Batch loss: 0.085398 Batch F1: 0.8
Epoch:  989        8 Batch loss: 0.048679 Batch F1: 0.9090909090909091
Epoch:  989        9 Batch loss: 0.114374 Batch F1: 0.72
Epoch:  989       10 Batch loss: 0.070834 Batch F1: 0.9565217391304348
Epoch:  989       11 Batch loss: 0.071027 Batch F1: 0.8333333333333333
Epoch:  989       12 Batch loss: 0.056574 Batch F1: 1.0
Train Avg Loss  989: 0.070107

Train Avg F1  989: 0.8268103132777046

Val Avg Loss  989: 0.063927

Val Avg F1  989:  0.9083333333333334

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 990
--------------------------------------------------------------
Epoch:  990        1 Batch loss: 0.058276 Batch F1: 0.9090909090909091
Epoch:  990        2 Batch loss: 0.059664 Batch F1: 0.7692307692307693
Epoch:  990        3 Batch loss: 0.071108 Batch F1: 0.5333333333333333
Epoch:  990        4 Batch loss: 0.064758 Batch F1: 0.6666666666666666
Epoch:  990        5 Batch loss: 0.070530 Batch F1: 0.5454545454545454
Epoch:  990        6 Batch loss: 0.064720 Batch F1: 0.8
Epoch:  990        7 Batch loss: 0.064400 Batch F1: 0.5
Epoch:  990        8 Batch loss: 0.061849 Batch F1: 0.6
Epoch:  990        9 Batch loss: 0.094973 Batch F1: 0.6666666666666666
Epoch:  990       10 Batch loss: 0.066171 Batch F1: 0.6153846153846154
Epoch:  990       11 Batch loss: 0.093216 Batch F1: 0.4
Epoch:  990       12 Batch loss: 0.068789 Batch F1: 0.9411764705882353
Train Avg Loss  990: 0.069871

Train Avg F1  990: 0.6622503313679785

Val Avg Loss  990: 0.067329

Val Avg F1  990:  0.9315584415584416

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 991
--------------------------------------------------------------
Epoch:  991        1 Batch loss: 0.068011 Batch F1: 0.8571428571428571
Epoch:  991        2 Batch loss: 0.066529 Batch F1: 0.888888888888889
Epoch:  991        3 Batch loss: 0.076720 Batch F1: 0.9090909090909091
Epoch:  991        4 Batch loss: 0.074072 Batch F1: 0.9523809523809523
Epoch:  991        5 Batch loss: 0.084630 Batch F1: 0.9
Epoch:  991        6 Batch loss: 0.066192 Batch F1: 0.9333333333333333
Epoch:  991        7 Batch loss: 0.052143 Batch F1: 0.7272727272727273
Epoch:  991        8 Batch loss: 0.056483 Batch F1: 0.7272727272727273
Epoch:  991        9 Batch loss: 0.058122 Batch F1: 0.6666666666666666
Epoch:  991       10 Batch loss: 0.076651 Batch F1: 0.4615384615384615
Epoch:  991       11 Batch loss: 0.081930 Batch F1: 0.6666666666666666
Epoch:  991       12 Batch loss: 0.056929 Batch F1: 0.7499999999999999
Train Avg Loss  991: 0.068201

Train Avg F1  991: 0.7866878491878492

Val Avg Loss  991: 0.063698

Val Avg F1  991:  0.8741278483565235

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 992
--------------------------------------------------------------
Epoch:  992        1 Batch loss: 0.062392 Batch F1: 0.923076923076923
Epoch:  992        2 Batch loss: 0.069456 Batch F1: 0.7142857142857143
Epoch:  992        3 Batch loss: 0.055364 Batch F1: 0.5714285714285715
Epoch:  992        4 Batch loss: 0.088046 Batch F1: 0.3636363636363636
Epoch:  992        5 Batch loss: 0.051343 Batch F1: 0.6
Epoch:  992        6 Batch loss: 0.100702 Batch F1: 0.6666666666666666
Epoch:  992        7 Batch loss: 0.080099 Batch F1: 0.625
Epoch:  992        8 Batch loss: 0.089952 Batch F1: 0.18181818181818182
Epoch:  992        9 Batch loss: 0.043236 Batch F1: 0.9090909090909091
Epoch:  992       10 Batch loss: 0.065325 Batch F1: 1.0
Epoch:  992       11 Batch loss: 0.050643 Batch F1: 0.9565217391304348
Epoch:  992       12 Batch loss: 0.062454 Batch F1: 0.8750000000000001
Train Avg Loss  992: 0.068251

Train Avg F1  992: 0.6988770890944803

Val Avg Loss  992: 0.062757

Val Avg F1  992:  0.8576680672268908

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 993
--------------------------------------------------------------
Epoch:  993        1 Batch loss: 0.081483 Batch F1: 0.7499999999999999
Epoch:  993        2 Batch loss: 0.073018 Batch F1: 0.9166666666666666
Epoch:  993        3 Batch loss: 0.066820 Batch F1: 0.9523809523809523
Epoch:  993        4 Batch loss: 0.057442 Batch F1: 1.0
Epoch:  993        5 Batch loss: 0.068691 Batch F1: 0.9600000000000001
Epoch:  993        6 Batch loss: 0.048194 Batch F1: 1.0
Epoch:  993        7 Batch loss: 0.058803 Batch F1: 0.9333333333333333
Epoch:  993        8 Batch loss: 0.061928 Batch F1: 0.8333333333333333
Epoch:  993        9 Batch loss: 0.071241 Batch F1: 0.5
Epoch:  993       10 Batch loss: 0.089878 Batch F1: 0.19999999999999998
Epoch:  993       11 Batch loss: 0.086539 Batch F1: 0.5333333333333333
Epoch:  993       12 Batch loss: 0.073233 Batch F1: 0.25
Train Avg Loss  993: 0.069773

Train Avg F1  993: 0.7357539682539681

Val Avg Loss  993: 0.064118

Val Avg F1  993:  0.7791424262012497

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 994
--------------------------------------------------------------
Epoch:  994        1 Batch loss: 0.059731 Batch F1: 0.4
Epoch:  994        2 Batch loss: 0.065469 Batch F1: 0.6666666666666666
Epoch:  994        3 Batch loss: 0.063224 Batch F1: 0.7499999999999999
Epoch:  994        4 Batch loss: 0.058950 Batch F1: 0.7499999999999999
Epoch:  994        5 Batch loss: 0.081734 Batch F1: 0.8666666666666666
Epoch:  994        6 Batch loss: 0.062035 Batch F1: 0.9411764705882353
Epoch:  994        7 Batch loss: 0.089886 Batch F1: 0.8235294117647058
Epoch:  994        8 Batch loss: 0.056391 Batch F1: 1.0
Epoch:  994        9 Batch loss: 0.073378 Batch F1: 0.8750000000000001
Epoch:  994       10 Batch loss: 0.049232 Batch F1: 1.0
Epoch:  994       11 Batch loss: 0.083795 Batch F1: 1.0
Epoch:  994       12 Batch loss: 0.072506 Batch F1: 0.9333333333333333
Train Avg Loss  994: 0.068028

Train Avg F1  994: 0.8338643790849672

Val Avg Loss  994: 0.064661

Val Avg F1  994:  0.7086802086802086

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 995
--------------------------------------------------------------
Epoch:  995        1 Batch loss: 0.054077 Batch F1: 0.7272727272727273
Epoch:  995        2 Batch loss: 0.085114 Batch F1: 0.5333333333333333
Epoch:  995        3 Batch loss: 0.082803 Batch F1: 0.5714285714285715
Epoch:  995        4 Batch loss: 0.066111 Batch F1: 0.4615384615384615
Epoch:  995        5 Batch loss: 0.108112 Batch F1: 0.6363636363636364
Epoch:  995        6 Batch loss: 0.072335 Batch F1: 0.9473684210526316
Epoch:  995        7 Batch loss: 0.068344 Batch F1: 0.9565217391304348
Epoch:  995        8 Batch loss: 0.045775 Batch F1: 1.0
Epoch:  995        9 Batch loss: 0.042906 Batch F1: 0.8571428571428571
Epoch:  995       10 Batch loss: 0.105315 Batch F1: 0.6666666666666666
Epoch:  995       11 Batch loss: 0.065164 Batch F1: 0.7142857142857143
Epoch:  995       12 Batch loss: 0.055892 Batch F1: 0.8571428571428571
Train Avg Loss  995: 0.070996

Train Avg F1  995: 0.7440887487798243

Val Avg Loss  995: 0.064679

Val Avg F1  995:  0.6043233082706767

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 996
--------------------------------------------------------------
Epoch:  996        1 Batch loss: 0.059964 Batch F1: 0.5
Epoch:  996        2 Batch loss: 0.095903 Batch F1: 0.2857142857142857
Epoch:  996        3 Batch loss: 0.079388 Batch F1: 0.5882352941176471
Epoch:  996        4 Batch loss: 0.077043 Batch F1: 0.9090909090909091
Epoch:  996        5 Batch loss: 0.083003 Batch F1: 0.9166666666666666
Epoch:  996        6 Batch loss: 0.054917 Batch F1: 1.0
Epoch:  996        7 Batch loss: 0.071785 Batch F1: 0.7058823529411764
Epoch:  996        8 Batch loss: 0.050152 Batch F1: 0.6666666666666666
Epoch:  996        9 Batch loss: 0.070408 Batch F1: 0.2222222222222222
Epoch:  996       10 Batch loss: 0.076386 Batch F1: 0.7777777777777778
Epoch:  996       11 Batch loss: 0.055269 Batch F1: 0.5
Epoch:  996       12 Batch loss: 0.071937 Batch F1: 0.33333333333333337
Train Avg Loss  996: 0.070513

Train Avg F1  996: 0.6171324590442238

Val Avg Loss  996: 0.065832

Val Avg F1  996:  0.5809523809523809

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 997
--------------------------------------------------------------
Epoch:  997        1 Batch loss: 0.045207 Batch F1: 0.6666666666666666
Epoch:  997        2 Batch loss: 0.090507 Batch F1: 0.2857142857142857
Epoch:  997        3 Batch loss: 0.095556 Batch F1: 0.4444444444444445
Epoch:  997        4 Batch loss: 0.067136 Batch F1: 0.8571428571428571
Epoch:  997        5 Batch loss: 0.072733 Batch F1: 0.8750000000000001
Epoch:  997        6 Batch loss: 0.070461 Batch F1: 0.8571428571428571
Epoch:  997        7 Batch loss: 0.076592 Batch F1: 0.7692307692307693
Epoch:  997        8 Batch loss: 0.066730 Batch F1: 0.7058823529411764
Epoch:  997        9 Batch loss: 0.080999 Batch F1: 0.6666666666666666
Epoch:  997       10 Batch loss: 0.052174 Batch F1: 0.5
Epoch:  997       11 Batch loss: 0.064692 Batch F1: 0.9
Epoch:  997       12 Batch loss: 0.065978 Batch F1: 0.923076923076923
Train Avg Loss  997: 0.070730

Train Avg F1  997: 0.704247318585554

Val Avg Loss  997: 0.063743

Val Avg F1  997:  0.8356060606060607

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 998
--------------------------------------------------------------
Epoch:  998        1 Batch loss: 0.056764 Batch F1: 0.923076923076923
Epoch:  998        2 Batch loss: 0.075955 Batch F1: 0.4444444444444445
Epoch:  998        3 Batch loss: 0.066643 Batch F1: 0.6666666666666666
Epoch:  998        4 Batch loss: 0.084573 Batch F1: 0.6153846153846153
Epoch:  998        5 Batch loss: 0.053846 Batch F1: 0.8571428571428571
Epoch:  998        6 Batch loss: 0.062147 Batch F1: 0.7142857142857143
Epoch:  998        7 Batch loss: 0.070567 Batch F1: 0.4444444444444445
Epoch:  998        8 Batch loss: 0.049886 Batch F1: 0.5
Epoch:  998        9 Batch loss: 0.091920 Batch F1: 0.4
Epoch:  998       10 Batch loss: 0.077879 Batch F1: 0.6666666666666666
Epoch:  998       11 Batch loss: 0.064494 Batch F1: 0.8235294117647058
Epoch:  998       12 Batch loss: 0.063516 Batch F1: 1.0
Train Avg Loss  998: 0.068183

Train Avg F1  998: 0.6713034786564199

Val Avg Loss  998: 0.066769

Val Avg F1  998:  0.9375668449197861

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 999
--------------------------------------------------------------
Epoch:  999        1 Batch loss: 0.074517 Batch F1: 0.8333333333333334
Epoch:  999        2 Batch loss: 0.056270 Batch F1: 0.923076923076923
Epoch:  999        3 Batch loss: 0.043776 Batch F1: 1.0
Epoch:  999        4 Batch loss: 0.062172 Batch F1: 0.9411764705882353
Epoch:  999        5 Batch loss: 0.068628 Batch F1: 0.8235294117647058
Epoch:  999        6 Batch loss: 0.065686 Batch F1: 0.6666666666666666
Epoch:  999        7 Batch loss: 0.067077 Batch F1: 0.6153846153846153
Epoch:  999        8 Batch loss: 0.064958 Batch F1: 0.7142857142857143
Epoch:  999        9 Batch loss: 0.059787 Batch F1: 0.7692307692307693
Epoch:  999       10 Batch loss: 0.106916 Batch F1: 0.6956521739130436
Epoch:  999       11 Batch loss: 0.092521 Batch F1: 0.8
Epoch:  999       12 Batch loss: 0.074424 Batch F1: 0.8750000000000001
Train Avg Loss  999: 0.069728

Train Avg F1  999: 0.8047780065203339

Val Avg Loss  999: 0.066415

Val Avg F1  999:  0.9319548872180452

Optimal Val loss (Epoch 461): 0.061337235383689404

Epoch 1000
--------------------------------------------------------------
Epoch: 1000        1 Batch loss: 0.059801 Batch F1: 0.9090909090909091
Epoch: 1000        2 Batch loss: 0.076055 Batch F1: 0.631578947368421
Epoch: 1000        3 Batch loss: 0.058849 Batch F1: 0.8571428571428571
Epoch: 1000        4 Batch loss: 0.079982 Batch F1: 0.5333333333333333
Epoch: 1000        5 Batch loss: 0.038726 Batch F1: 0.8
Epoch: 1000        6 Batch loss: 0.070660 Batch F1: 0.2857142857142857
Epoch: 1000        7 Batch loss: 0.065892 Batch F1: 0.6666666666666666
Epoch: 1000        8 Batch loss: 0.082142 Batch F1: 0.42857142857142855
Epoch: 1000        9 Batch loss: 0.084547 Batch F1: 0.42857142857142855
Epoch: 1000       10 Batch loss: 0.066480 Batch F1: 0.9473684210526316
Epoch: 1000       11 Batch loss: 0.084914 Batch F1: 0.962962962962963
Epoch: 1000       12 Batch loss: 0.068765 Batch F1: 1.0
Train Avg Loss 1000: 0.069734

Train Avg F1 1000: 0.7042501033729104

Val Avg Loss 1000: 0.065971

Val Avg F1 1000:  0.9446640316205533

Optimal Val loss (Epoch 461): 0.061337235383689404

Done!
