Removed 3 of 595
Removed 0 of 198
Removed 0 of 198
Model with variable positions in join nodes
Loss function: MSELoss
Optimizer: LR [0.01] weight decay [0.0005]
Epoch 1
--------------------------------------------------------------
Epoch:    1        1 Batch loss: 0.259976 Batch F1: 0.3050847457627119
Epoch:    1        2 Batch loss: 0.184105 Batch F1: 0.0
Epoch:    1        3 Batch loss: 0.195672 Batch F1: 0.0
Epoch:    1        4 Batch loss: 0.177418 Batch F1: 0.0
Epoch:    1        5 Batch loss: 0.172031 Batch F1: 0.0
Epoch:    1        6 Batch loss: 0.133720 Batch F1: 0.0
Epoch:    1        7 Batch loss: 0.116983 Batch F1: 0.0
Epoch:    1        8 Batch loss: 0.161727 Batch F1: 0.0
Epoch:    1        9 Batch loss: 0.115618 Batch F1: 0.0
Epoch:    1       10 Batch loss: 0.219855 Batch F1: 0.0
Epoch:    1       11 Batch loss: 0.147666 Batch F1: 0.0
Epoch:    1       12 Batch loss: 0.169789 Batch F1: 0.0
Train Avg Loss    1: 0.171213

Train Avg F1    1: 0.025423728813559324

Val Avg Loss    1: 0.148717

Val Avg F1    1:  0.0

Optimal Val loss (Epoch 1): 0.14871688559651375

Epoch 2
--------------------------------------------------------------
Epoch:    2        1 Batch loss: 0.134488 Batch F1: 0.0
Epoch:    2        2 Batch loss: 0.229207 Batch F1: 0.0
Epoch:    2        3 Batch loss: 0.093424 Batch F1: 0.0
Epoch:    2        4 Batch loss: 0.134448 Batch F1: 0.0
Epoch:    2        5 Batch loss: 0.231816 Batch F1: 0.0
Epoch:    2        6 Batch loss: 0.134443 Batch F1: 0.0
Epoch:    2        7 Batch loss: 0.120716 Batch F1: 0.0
Epoch:    2        8 Batch loss: 0.120864 Batch F1: 0.0
Epoch:    2        9 Batch loss: 0.174934 Batch F1: 0.0
Epoch:    2       10 Batch loss: 0.134469 Batch F1: 0.0
Epoch:    2       11 Batch loss: 0.121587 Batch F1: 0.0
Epoch:    2       12 Batch loss: 0.169632 Batch F1: 0.0
Train Avg Loss    2: 0.150002

Train Avg F1    2: 0.0

Val Avg Loss    2: 0.148223

Val Avg F1    2:  0.0

Optimal Val loss (Epoch 2): 0.14822250790894032

Epoch 3
--------------------------------------------------------------
Epoch:    3        1 Batch loss: 0.134589 Batch F1: 0.0
Epoch:    3        2 Batch loss: 0.097085 Batch F1: 0.0
Epoch:    3        3 Batch loss: 0.186480 Batch F1: 0.0
Epoch:    3        4 Batch loss: 0.121122 Batch F1: 0.0
Epoch:    3        5 Batch loss: 0.160425 Batch F1: 0.0
Epoch:    3        6 Batch loss: 0.173408 Batch F1: 0.0
Epoch:    3        7 Batch loss: 0.145567 Batch F1: 0.0
Epoch:    3        8 Batch loss: 0.134606 Batch F1: 0.0
Epoch:    3        9 Batch loss: 0.123114 Batch F1: 0.0
Epoch:    3       10 Batch loss: 0.144343 Batch F1: 0.0
Epoch:    3       11 Batch loss: 0.196905 Batch F1: 0.0
Epoch:    3       12 Batch loss: 0.167290 Batch F1: 0.0
Train Avg Loss    3: 0.148744

Train Avg F1    3: 0.0

Val Avg Loss    3: 0.143356

Val Avg F1    3:  0.0

Optimal Val loss (Epoch 3): 0.1433562021702528

Epoch 4
--------------------------------------------------------------
Epoch:    4        1 Batch loss: 0.129056 Batch F1: 0.0
Epoch:    4        2 Batch loss: 0.130679 Batch F1: 0.0
Epoch:    4        3 Batch loss: 0.093878 Batch F1: 0.0
Epoch:    4        4 Batch loss: 0.159437 Batch F1: 0.0
Epoch:    4        5 Batch loss: 0.128994 Batch F1: 0.0
Epoch:    4        6 Batch loss: 0.167351 Batch F1: 0.0
Epoch:    4        7 Batch loss: 0.187160 Batch F1: 0.0
Epoch:    4        8 Batch loss: 0.180588 Batch F1: 0.0
Epoch:    4        9 Batch loss: 0.129420 Batch F1: 0.0
Epoch:    4       10 Batch loss: 0.146716 Batch F1: 0.0
Epoch:    4       11 Batch loss: 0.156932 Batch F1: 0.0
Epoch:    4       12 Batch loss: 0.126734 Batch F1: 0.0
Train Avg Loss    4: 0.144746

Train Avg F1    4: 0.0

Val Avg Loss    4: 0.143889

Val Avg F1    4:  0.0

Optimal Val loss (Epoch 3): 0.1433562021702528

Epoch 5
--------------------------------------------------------------
Epoch:    5        1 Batch loss: 0.167964 Batch F1: 0.0
Epoch:    5        2 Batch loss: 0.156719 Batch F1: 0.0
Epoch:    5        3 Batch loss: 0.079402 Batch F1: 0.0
Epoch:    5        4 Batch loss: 0.128666 Batch F1: 0.0
Epoch:    5        5 Batch loss: 0.091740 Batch F1: 0.0
Epoch:    5        6 Batch loss: 0.120155 Batch F1: 0.0
Epoch:    5        7 Batch loss: 0.183088 Batch F1: 0.0
Epoch:    5        8 Batch loss: 0.166320 Batch F1: 0.0
Epoch:    5        9 Batch loss: 0.103131 Batch F1: 0.0
Epoch:    5       10 Batch loss: 0.177283 Batch F1: 0.0
Epoch:    5       11 Batch loss: 0.160688 Batch F1: 0.0
Epoch:    5       12 Batch loss: 0.181135 Batch F1: 0.0
Train Avg Loss    5: 0.143024

Train Avg F1    5: 0.0

Val Avg Loss    5: 0.144270

Val Avg F1    5:  0.0

Optimal Val loss (Epoch 3): 0.1433562021702528

Epoch 6
--------------------------------------------------------------
Epoch:    6        1 Batch loss: 0.170647 Batch F1: 0.0
Epoch:    6        2 Batch loss: 0.151337 Batch F1: 0.0
Epoch:    6        3 Batch loss: 0.119114 Batch F1: 0.0
Epoch:    6        4 Batch loss: 0.152937 Batch F1: 0.0
Epoch:    6        5 Batch loss: 0.141277 Batch F1: 0.0
Epoch:    6        6 Batch loss: 0.169736 Batch F1: 0.0
Epoch:    6        7 Batch loss: 0.152830 Batch F1: 0.0
Epoch:    6        8 Batch loss: 0.146399 Batch F1: 0.0
Epoch:    6        9 Batch loss: 0.107488 Batch F1: 0.0
Epoch:    6       10 Batch loss: 0.132306 Batch F1: 0.0
Epoch:    6       11 Batch loss: 0.133421 Batch F1: 0.0
Epoch:    6       12 Batch loss: 0.133472 Batch F1: 0.0
Train Avg Loss    6: 0.142580

Train Avg F1    6: 0.0

Val Avg Loss    6: 0.142388

Val Avg F1    6:  0.0

Optimal Val loss (Epoch 6): 0.14238783903419971

Epoch 7
--------------------------------------------------------------
Epoch:    7        1 Batch loss: 0.126645 Batch F1: 0.0
Epoch:    7        2 Batch loss: 0.117993 Batch F1: 0.0
Epoch:    7        3 Batch loss: 0.204875 Batch F1: 0.0
Epoch:    7        4 Batch loss: 0.126826 Batch F1: 0.0
Epoch:    7        5 Batch loss: 0.146870 Batch F1: 0.0
Epoch:    7        6 Batch loss: 0.084069 Batch F1: 0.0
Epoch:    7        7 Batch loss: 0.128717 Batch F1: 0.0
Epoch:    7        8 Batch loss: 0.160399 Batch F1: 0.0
Epoch:    7        9 Batch loss: 0.166795 Batch F1: 0.0
Epoch:    7       10 Batch loss: 0.108403 Batch F1: 0.0
Epoch:    7       11 Batch loss: 0.202676 Batch F1: 0.0
Epoch:    7       12 Batch loss: 0.121111 Batch F1: 0.0
Train Avg Loss    7: 0.141282

Train Avg F1    7: 0.0

Val Avg Loss    7: 0.138389

Val Avg F1    7:  0.0

Optimal Val loss (Epoch 7): 0.1383891310542822

Epoch 8
--------------------------------------------------------------
Epoch:    8        1 Batch loss: 0.105395 Batch F1: 0.0
Epoch:    8        2 Batch loss: 0.131818 Batch F1: 0.0
Epoch:    8        3 Batch loss: 0.126230 Batch F1: 0.0
Epoch:    8        4 Batch loss: 0.120606 Batch F1: 0.0
Epoch:    8        5 Batch loss: 0.132482 Batch F1: 0.0
Epoch:    8        6 Batch loss: 0.205396 Batch F1: 0.0
Epoch:    8        7 Batch loss: 0.171883 Batch F1: 0.0
Epoch:    8        8 Batch loss: 0.085301 Batch F1: 0.0
Epoch:    8        9 Batch loss: 0.121362 Batch F1: 0.0
Epoch:    8       10 Batch loss: 0.156588 Batch F1: 0.0
Epoch:    8       11 Batch loss: 0.162200 Batch F1: 0.0
Epoch:    8       12 Batch loss: 0.205650 Batch F1: 0.0
Train Avg Loss    8: 0.143743

Train Avg F1    8: 0.0

Val Avg Loss    8: 0.140069

Val Avg F1    8:  0.0

Optimal Val loss (Epoch 7): 0.1383891310542822

Epoch 9
--------------------------------------------------------------
Epoch:    9        1 Batch loss: 0.130719 Batch F1: 0.0
Epoch:    9        2 Batch loss: 0.153530 Batch F1: 0.0
Epoch:    9        3 Batch loss: 0.170507 Batch F1: 0.0
Epoch:    9        4 Batch loss: 0.167446 Batch F1: 0.0
Epoch:    9        5 Batch loss: 0.179148 Batch F1: 0.0
Epoch:    9        6 Batch loss: 0.140059 Batch F1: 0.0
Epoch:    9        7 Batch loss: 0.190404 Batch F1: 0.0
Epoch:    9        8 Batch loss: 0.088669 Batch F1: 0.0
Epoch:    9        9 Batch loss: 0.108159 Batch F1: 0.0
Epoch:    9       10 Batch loss: 0.120934 Batch F1: 0.0
Epoch:    9       11 Batch loss: 0.113768 Batch F1: 0.0
Epoch:    9       12 Batch loss: 0.108682 Batch F1: 0.0
Train Avg Loss    9: 0.139335

Train Avg F1    9: 0.0

Val Avg Loss    9: 0.142599

Val Avg F1    9:  0.0

Optimal Val loss (Epoch 7): 0.1383891310542822

Epoch 10
--------------------------------------------------------------
Epoch:   10        1 Batch loss: 0.142810 Batch F1: 0.0
Epoch:   10        2 Batch loss: 0.158039 Batch F1: 0.0
Epoch:   10        3 Batch loss: 0.104505 Batch F1: 0.0
Epoch:   10        4 Batch loss: 0.101406 Batch F1: 0.0
Epoch:   10        5 Batch loss: 0.139282 Batch F1: 0.0
Epoch:   10        6 Batch loss: 0.104374 Batch F1: 0.0
Epoch:   10        7 Batch loss: 0.115226 Batch F1: 0.0
Epoch:   10        8 Batch loss: 0.140559 Batch F1: 0.0
Epoch:   10        9 Batch loss: 0.180920 Batch F1: 0.0
Epoch:   10       10 Batch loss: 0.176249 Batch F1: 0.0
Epoch:   10       11 Batch loss: 0.183012 Batch F1: 0.0
Epoch:   10       12 Batch loss: 0.143635 Batch F1: 0.0
Train Avg Loss   10: 0.140835

Train Avg F1   10: 0.0

Val Avg Loss   10: 0.144039

Val Avg F1   10:  0.0

Optimal Val loss (Epoch 7): 0.1383891310542822

Epoch 11
--------------------------------------------------------------
Epoch:   11        1 Batch loss: 0.130621 Batch F1: 0.0
Epoch:   11        2 Batch loss: 0.152472 Batch F1: 0.0
Epoch:   11        3 Batch loss: 0.152654 Batch F1: 0.0
Epoch:   11        4 Batch loss: 0.122039 Batch F1: 0.0
Epoch:   11        5 Batch loss: 0.165887 Batch F1: 0.0
Epoch:   11        6 Batch loss: 0.157576 Batch F1: 0.0
Epoch:   11        7 Batch loss: 0.115338 Batch F1: 0.0
Epoch:   11        8 Batch loss: 0.127749 Batch F1: 0.0
Epoch:   11        9 Batch loss: 0.176937 Batch F1: 0.0
Epoch:   11       10 Batch loss: 0.129812 Batch F1: 0.0
Epoch:   11       11 Batch loss: 0.135377 Batch F1: 0.0
Epoch:   11       12 Batch loss: 0.115899 Batch F1: 0.0
Train Avg Loss   11: 0.140197

Train Avg F1   11: 0.0

Val Avg Loss   11: 0.137204

Val Avg F1   11:  0.0

Optimal Val loss (Epoch 11): 0.13720444031059742

Epoch 12
--------------------------------------------------------------
Epoch:   12        1 Batch loss: 0.162775 Batch F1: 0.0
Epoch:   12        2 Batch loss: 0.118043 Batch F1: 0.0
Epoch:   12        3 Batch loss: 0.128323 Batch F1: 0.0
Epoch:   12        4 Batch loss: 0.099942 Batch F1: 0.0
Epoch:   12        5 Batch loss: 0.120440 Batch F1: 0.0
Epoch:   12        6 Batch loss: 0.124366 Batch F1: 0.0
Epoch:   12        7 Batch loss: 0.110895 Batch F1: 0.0
Epoch:   12        8 Batch loss: 0.170228 Batch F1: 0.0
Epoch:   12        9 Batch loss: 0.167976 Batch F1: 0.0
Epoch:   12       10 Batch loss: 0.156601 Batch F1: 0.0
Epoch:   12       11 Batch loss: 0.158189 Batch F1: 0.0
Epoch:   12       12 Batch loss: 0.135196 Batch F1: 0.0
Train Avg Loss   12: 0.137748

Train Avg F1   12: 0.0

Val Avg Loss   12: 0.133422

Val Avg F1   12:  0.0

Optimal Val loss (Epoch 12): 0.13342227041721344

Epoch 13
--------------------------------------------------------------
Epoch:   13        1 Batch loss: 0.160080 Batch F1: 0.0
Epoch:   13        2 Batch loss: 0.138260 Batch F1: 0.0
Epoch:   13        3 Batch loss: 0.185852 Batch F1: 0.0
Epoch:   13        4 Batch loss: 0.146528 Batch F1: 0.0
Epoch:   13        5 Batch loss: 0.123963 Batch F1: 0.0
Epoch:   13        6 Batch loss: 0.134784 Batch F1: 0.0
Epoch:   13        7 Batch loss: 0.111145 Batch F1: 0.0
Epoch:   13        8 Batch loss: 0.139282 Batch F1: 0.0
Epoch:   13        9 Batch loss: 0.121903 Batch F1: 0.0
Epoch:   13       10 Batch loss: 0.109351 Batch F1: 0.0
Epoch:   13       11 Batch loss: 0.119306 Batch F1: 0.0
Epoch:   13       12 Batch loss: 0.122739 Batch F1: 0.0
Train Avg Loss   13: 0.134433

Train Avg F1   13: 0.0

Val Avg Loss   13: 0.129941

Val Avg F1   13:  0.0

Optimal Val loss (Epoch 13): 0.1299413349479437

Epoch 14
--------------------------------------------------------------
Epoch:   14        1 Batch loss: 0.111480 Batch F1: 0.0
Epoch:   14        2 Batch loss: 0.134105 Batch F1: 0.0
Epoch:   14        3 Batch loss: 0.153718 Batch F1: 0.0
Epoch:   14        4 Batch loss: 0.153986 Batch F1: 0.0
Epoch:   14        5 Batch loss: 0.107664 Batch F1: 0.0
Epoch:   14        6 Batch loss: 0.134918 Batch F1: 0.0
Epoch:   14        7 Batch loss: 0.116782 Batch F1: 0.0
Epoch:   14        8 Batch loss: 0.122949 Batch F1: 0.0
Epoch:   14        9 Batch loss: 0.138257 Batch F1: 0.0
Epoch:   14       10 Batch loss: 0.135351 Batch F1: 0.0
Epoch:   14       11 Batch loss: 0.115186 Batch F1: 0.0
Epoch:   14       12 Batch loss: 0.084718 Batch F1: 0.0
Train Avg Loss   14: 0.125759

Train Avg F1   14: 0.0

Val Avg Loss   14: 0.122311

Val Avg F1   14:  0.0

Optimal Val loss (Epoch 14): 0.12231072969734669

Epoch 15
--------------------------------------------------------------
Epoch:   15        1 Batch loss: 0.140889 Batch F1: 0.0
Epoch:   15        2 Batch loss: 0.100929 Batch F1: 0.0
Epoch:   15        3 Batch loss: 0.100771 Batch F1: 0.0
Epoch:   15        4 Batch loss: 0.173907 Batch F1: 0.0
Epoch:   15        5 Batch loss: 0.127394 Batch F1: 0.0
Epoch:   15        6 Batch loss: 0.084163 Batch F1: 0.0
Epoch:   15        7 Batch loss: 0.131027 Batch F1: 0.0
Epoch:   15        8 Batch loss: 0.121117 Batch F1: 0.0
Epoch:   15        9 Batch loss: 0.091094 Batch F1: 0.0
Epoch:   15       10 Batch loss: 0.149427 Batch F1: 0.0
Epoch:   15       11 Batch loss: 0.128787 Batch F1: 0.0
Epoch:   15       12 Batch loss: 0.113002 Batch F1: 0.0
Train Avg Loss   15: 0.121876

Train Avg F1   15: 0.0

Val Avg Loss   15: 0.114759

Val Avg F1   15:  0.0

Optimal Val loss (Epoch 15): 0.11475932784378529

Epoch 16
--------------------------------------------------------------
Epoch:   16        1 Batch loss: 0.089092 Batch F1: 0.0
Epoch:   16        2 Batch loss: 0.150883 Batch F1: 0.0
Epoch:   16        3 Batch loss: 0.140331 Batch F1: 0.0
Epoch:   16        4 Batch loss: 0.150949 Batch F1: 0.0
Epoch:   16        5 Batch loss: 0.149237 Batch F1: 0.0
Epoch:   16        6 Batch loss: 0.114414 Batch F1: 0.0
Epoch:   16        7 Batch loss: 0.071432 Batch F1: 0.0
Epoch:   16        8 Batch loss: 0.128512 Batch F1: 0.0
Epoch:   16        9 Batch loss: 0.082813 Batch F1: 0.0
Epoch:   16       10 Batch loss: 0.108238 Batch F1: 0.0
Epoch:   16       11 Batch loss: 0.147751 Batch F1: 0.0
Epoch:   16       12 Batch loss: 0.214520 Batch F1: 0.0
Train Avg Loss   16: 0.129014

Train Avg F1   16: 0.0

Val Avg Loss   16: 0.118873

Val Avg F1   16:  0.0

Optimal Val loss (Epoch 15): 0.11475932784378529

Epoch 17
--------------------------------------------------------------
Epoch:   17        1 Batch loss: 0.114823 Batch F1: 0.0
Epoch:   17        2 Batch loss: 0.120297 Batch F1: 0.8333333333333333
Epoch:   17        3 Batch loss: 0.135845 Batch F1: 0.0
Epoch:   17        4 Batch loss: 0.130675 Batch F1: 0.0
Epoch:   17        5 Batch loss: 0.086018 Batch F1: 0.0
Epoch:   17        6 Batch loss: 0.138466 Batch F1: 0.0
Epoch:   17        7 Batch loss: 0.164563 Batch F1: 0.0
Epoch:   17        8 Batch loss: 0.142744 Batch F1: 0.0
Epoch:   17        9 Batch loss: 0.099210 Batch F1: 0.0
Epoch:   17       10 Batch loss: 0.118072 Batch F1: 0.0
Epoch:   17       11 Batch loss: 0.103614 Batch F1: 0.0
Epoch:   17       12 Batch loss: 0.084753 Batch F1: 0.0
Train Avg Loss   17: 0.119924

Train Avg F1   17: 0.06944444444444443

Val Avg Loss   17: 0.113765

Val Avg F1   17:  0.0

Optimal Val loss (Epoch 17): 0.11376523040235043

Epoch 18
--------------------------------------------------------------
Epoch:   18        1 Batch loss: 0.100511 Batch F1: 0.0
Epoch:   18        2 Batch loss: 0.129221 Batch F1: 0.0
Epoch:   18        3 Batch loss: 0.113059 Batch F1: 0.0
Epoch:   18        4 Batch loss: 0.135129 Batch F1: 0.0
Epoch:   18        5 Batch loss: 0.095026 Batch F1: 0.0
Epoch:   18        6 Batch loss: 0.096205 Batch F1: 0.0
Epoch:   18        7 Batch loss: 0.107513 Batch F1: 0.0
Epoch:   18        8 Batch loss: 0.095086 Batch F1: 0.0
Epoch:   18        9 Batch loss: 0.118698 Batch F1: 0.0
Epoch:   18       10 Batch loss: 0.123493 Batch F1: 0.0
Epoch:   18       11 Batch loss: 0.125934 Batch F1: 0.0
Epoch:   18       12 Batch loss: 0.121855 Batch F1: 0.6153846153846153
Train Avg Loss   18: 0.113478

Train Avg F1   18: 0.05128205128205127

Val Avg Loss   18: 0.114843

Val Avg F1   18:  0.5780797101449275

Optimal Val loss (Epoch 17): 0.11376523040235043

Epoch 19
--------------------------------------------------------------
Epoch:   19        1 Batch loss: 0.124198 Batch F1: 0.5333333333333333
Epoch:   19        2 Batch loss: 0.098239 Batch F1: 0.0
Epoch:   19        3 Batch loss: 0.107595 Batch F1: 0.0
Epoch:   19        4 Batch loss: 0.116336 Batch F1: 0.0
Epoch:   19        5 Batch loss: 0.102404 Batch F1: 0.0
Epoch:   19        6 Batch loss: 0.126055 Batch F1: 0.0
Epoch:   19        7 Batch loss: 0.163365 Batch F1: 0.0
Epoch:   19        8 Batch loss: 0.099399 Batch F1: 0.0
Epoch:   19        9 Batch loss: 0.081369 Batch F1: 0.0
Epoch:   19       10 Batch loss: 0.115059 Batch F1: 0.0
Epoch:   19       11 Batch loss: 0.112756 Batch F1: 0.0
Epoch:   19       12 Batch loss: 0.101432 Batch F1: 0.0
Train Avg Loss   19: 0.112351

Train Avg F1   19: 0.044444444444444446

Val Avg Loss   19: 0.114760

Val Avg F1   19:  0.0

Optimal Val loss (Epoch 17): 0.11376523040235043

Epoch 20
--------------------------------------------------------------
Epoch:   20        1 Batch loss: 0.115396 Batch F1: 0.0
Epoch:   20        2 Batch loss: 0.093547 Batch F1: 0.0
Epoch:   20        3 Batch loss: 0.128064 Batch F1: 0.0
Epoch:   20        4 Batch loss: 0.104705 Batch F1: 0.0
Epoch:   20        5 Batch loss: 0.137119 Batch F1: 0.0
Epoch:   20        6 Batch loss: 0.108799 Batch F1: 0.0
Epoch:   20        7 Batch loss: 0.112418 Batch F1: 0.6666666666666666
Epoch:   20        8 Batch loss: 0.107822 Batch F1: 0.0
Epoch:   20        9 Batch loss: 0.130377 Batch F1: 0.0
Epoch:   20       10 Batch loss: 0.112666 Batch F1: 0.0
Epoch:   20       11 Batch loss: 0.105670 Batch F1: 0.0
Epoch:   20       12 Batch loss: 0.097092 Batch F1: 0.0
Train Avg Loss   20: 0.112806

Train Avg F1   20: 0.05555555555555555

Val Avg Loss   20: 0.104282

Val Avg F1   20:  0.0

Optimal Val loss (Epoch 20): 0.10428210720419884

Epoch 21
--------------------------------------------------------------
Epoch:   21        1 Batch loss: 0.132249 Batch F1: 0.0
Epoch:   21        2 Batch loss: 0.140149 Batch F1: 0.0
Epoch:   21        3 Batch loss: 0.113760 Batch F1: 0.0
Epoch:   21        4 Batch loss: 0.120583 Batch F1: 0.0
Epoch:   21        5 Batch loss: 0.112331 Batch F1: 0.0
Epoch:   21        6 Batch loss: 0.105348 Batch F1: 0.0
Epoch:   21        7 Batch loss: 0.086038 Batch F1: 0.0
Epoch:   21        8 Batch loss: 0.090157 Batch F1: 0.0
Epoch:   21        9 Batch loss: 0.097353 Batch F1: 0.0
Epoch:   21       10 Batch loss: 0.079183 Batch F1: 0.0
Epoch:   21       11 Batch loss: 0.119872 Batch F1: 0.0
Epoch:   21       12 Batch loss: 0.087686 Batch F1: 0.0
Train Avg Loss   21: 0.107059

Train Avg F1   21: 0.0

Val Avg Loss   21: 0.100566

Val Avg F1   21:  0.0

Optimal Val loss (Epoch 21): 0.10056648217141628

Epoch 22
--------------------------------------------------------------
Epoch:   22        1 Batch loss: 0.113096 Batch F1: 0.0
Epoch:   22        2 Batch loss: 0.115512 Batch F1: 0.0
Epoch:   22        3 Batch loss: 0.098837 Batch F1: 0.6666666666666666
Epoch:   22        4 Batch loss: 0.105333 Batch F1: 0.5714285714285715
Epoch:   22        5 Batch loss: 0.109158 Batch F1: 0.0
Epoch:   22        6 Batch loss: 0.093483 Batch F1: 0.0
Epoch:   22        7 Batch loss: 0.069292 Batch F1: 0.0
Epoch:   22        8 Batch loss: 0.098178 Batch F1: 0.0
Epoch:   22        9 Batch loss: 0.093609 Batch F1: 0.0
Epoch:   22       10 Batch loss: 0.112417 Batch F1: 0.0
Epoch:   22       11 Batch loss: 0.105341 Batch F1: 0.0
Epoch:   22       12 Batch loss: 0.121712 Batch F1: 0.8421052631578948
Train Avg Loss   22: 0.102997

Train Avg F1   22: 0.1733500417710944

Val Avg Loss   22: 0.097824

Val Avg F1   22:  0.9021803714898343

Optimal Val loss (Epoch 22): 0.0978242289274931

Epoch 23
--------------------------------------------------------------
Epoch:   23        1 Batch loss: 0.073360 Batch F1: 1.0
Epoch:   23        2 Batch loss: 0.123293 Batch F1: 0.0
Epoch:   23        3 Batch loss: 0.153774 Batch F1: 0.0
Epoch:   23        4 Batch loss: 0.086978 Batch F1: 0.7272727272727273
Epoch:   23        5 Batch loss: 0.093372 Batch F1: 0.33333333333333337
Epoch:   23        6 Batch loss: 0.086955 Batch F1: 0.0
Epoch:   23        7 Batch loss: 0.094549 Batch F1: 0.0
Epoch:   23        8 Batch loss: 0.096432 Batch F1: 0.0
Epoch:   23        9 Batch loss: 0.122973 Batch F1: 0.0
Epoch:   23       10 Batch loss: 0.116269 Batch F1: 0.0
Epoch:   23       11 Batch loss: 0.122707 Batch F1: 0.0
Epoch:   23       12 Batch loss: 0.114360 Batch F1: 0.0
Train Avg Loss   23: 0.107085

Train Avg F1   23: 0.1717171717171717

Val Avg Loss   23: 0.116230

Val Avg F1   23:  0.8129142300194933

Optimal Val loss (Epoch 22): 0.0978242289274931

Epoch 24
--------------------------------------------------------------
Epoch:   24        1 Batch loss: 0.122753 Batch F1: 0.9600000000000001
Epoch:   24        2 Batch loss: 0.119399 Batch F1: 0.8695652173913044
Epoch:   24        3 Batch loss: 0.107468 Batch F1: 0.4615384615384615
Epoch:   24        4 Batch loss: 0.114892 Batch F1: 0.0
Epoch:   24        5 Batch loss: 0.104262 Batch F1: 0.0
Epoch:   24        6 Batch loss: 0.062401 Batch F1: 0.0
Epoch:   24        7 Batch loss: 0.070524 Batch F1: 0.0
Epoch:   24        8 Batch loss: 0.061243 Batch F1: 0.0
Epoch:   24        9 Batch loss: 0.146867 Batch F1: 0.0
Epoch:   24       10 Batch loss: 0.123720 Batch F1: 0.0
Epoch:   24       11 Batch loss: 0.144287 Batch F1: 0.0
Epoch:   24       12 Batch loss: 0.085589 Batch F1: 0.5714285714285715
Train Avg Loss   24: 0.105284

Train Avg F1   24: 0.23854435419652817

Val Avg Loss   24: 0.098486

Val Avg F1   24:  0.0

Optimal Val loss (Epoch 22): 0.0978242289274931

Epoch 25
--------------------------------------------------------------
Epoch:   25        1 Batch loss: 0.076765 Batch F1: 0.0
Epoch:   25        2 Batch loss: 0.087251 Batch F1: 0.0
Epoch:   25        3 Batch loss: 0.129025 Batch F1: 0.0
Epoch:   25        4 Batch loss: 0.110436 Batch F1: 0.0
Epoch:   25        5 Batch loss: 0.091355 Batch F1: 0.0
Epoch:   25        6 Batch loss: 0.147531 Batch F1: 0.0
Epoch:   25        7 Batch loss: 0.067646 Batch F1: 0.0
Epoch:   25        8 Batch loss: 0.089163 Batch F1: 0.2222222222222222
Epoch:   25        9 Batch loss: 0.085786 Batch F1: 0.0
Epoch:   25       10 Batch loss: 0.093405 Batch F1: 0.0
Epoch:   25       11 Batch loss: 0.120475 Batch F1: 0.0
Epoch:   25       12 Batch loss: 0.133351 Batch F1: 0.0
Train Avg Loss   25: 0.102682

Train Avg F1   25: 0.018518518518518517

Val Avg Loss   25: 0.093685

Val Avg F1   25:  0.0

Optimal Val loss (Epoch 25): 0.0936854612082243

Epoch 26
--------------------------------------------------------------
Epoch:   26        1 Batch loss: 0.123253 Batch F1: 0.0
Epoch:   26        2 Batch loss: 0.064723 Batch F1: 0.8571428571428571
Epoch:   26        3 Batch loss: 0.057180 Batch F1: 0.0
Epoch:   26        4 Batch loss: 0.100240 Batch F1: 0.0
Epoch:   26        5 Batch loss: 0.119523 Batch F1: 0.0
Epoch:   26        6 Batch loss: 0.094251 Batch F1: 0.0
Epoch:   26        7 Batch loss: 0.106710 Batch F1: 0.0
Epoch:   26        8 Batch loss: 0.093717 Batch F1: 0.8235294117647058
Epoch:   26        9 Batch loss: 0.103250 Batch F1: 1.0
Epoch:   26       10 Batch loss: 0.100671 Batch F1: 0.42857142857142855
Epoch:   26       11 Batch loss: 0.109943 Batch F1: 0.0
Epoch:   26       12 Batch loss: 0.105149 Batch F1: 0.0
Train Avg Loss   26: 0.098218

Train Avg F1   26: 0.2591036414565826

Val Avg Loss   26: 0.088413

Val Avg F1   26:  0.0

Optimal Val loss (Epoch 26): 0.08841328136622906

Epoch 27
--------------------------------------------------------------
Epoch:   27        1 Batch loss: 0.071877 Batch F1: 0.0
Epoch:   27        2 Batch loss: 0.088257 Batch F1: 0.0
Epoch:   27        3 Batch loss: 0.107425 Batch F1: 0.0
Epoch:   27        4 Batch loss: 0.088857 Batch F1: 0.0
Epoch:   27        5 Batch loss: 0.104497 Batch F1: 0.5
Epoch:   27        6 Batch loss: 0.091211 Batch F1: 0.8571428571428571
Epoch:   27        7 Batch loss: 0.106122 Batch F1: 0.0
Epoch:   27        8 Batch loss: 0.117975 Batch F1: 0.0
Epoch:   27        9 Batch loss: 0.103955 Batch F1: 0.0
Epoch:   27       10 Batch loss: 0.136088 Batch F1: 0.0
Epoch:   27       11 Batch loss: 0.073088 Batch F1: 0.0
Epoch:   27       12 Batch loss: 0.081470 Batch F1: 0.0
Train Avg Loss   27: 0.097569

Train Avg F1   27: 0.1130952380952381

Val Avg Loss   27: 0.092831

Val Avg F1   27:  0.5843137254901961

Optimal Val loss (Epoch 26): 0.08841328136622906

Epoch 28
--------------------------------------------------------------
Epoch:   28        1 Batch loss: 0.086920 Batch F1: 0.6
Epoch:   28        2 Batch loss: 0.133943 Batch F1: 0.5714285714285715
Epoch:   28        3 Batch loss: 0.074208 Batch F1: 0.8
Epoch:   28        4 Batch loss: 0.091686 Batch F1: 0.7499999999999999
Epoch:   28        5 Batch loss: 0.076140 Batch F1: 0.6
Epoch:   28        6 Batch loss: 0.109554 Batch F1: 0.7058823529411764
Epoch:   28        7 Batch loss: 0.108675 Batch F1: 0.0
Epoch:   28        8 Batch loss: 0.080377 Batch F1: 0.0
Epoch:   28        9 Batch loss: 0.100096 Batch F1: 0.0
Epoch:   28       10 Batch loss: 0.087092 Batch F1: 0.0
Epoch:   28       11 Batch loss: 0.103873 Batch F1: 0.0
Epoch:   28       12 Batch loss: 0.075584 Batch F1: 0.5
Train Avg Loss   28: 0.094012

Train Avg F1   28: 0.37727591036414565

Val Avg Loss   28: 0.093761

Val Avg F1   28:  0.0

Optimal Val loss (Epoch 26): 0.08841328136622906

Epoch 29
--------------------------------------------------------------
Epoch:   29        1 Batch loss: 0.065266 Batch F1: 0.0
Epoch:   29        2 Batch loss: 0.193853 Batch F1: 0.0
Epoch:   29        3 Batch loss: 0.086603 Batch F1: 0.0
Epoch:   29        4 Batch loss: 0.091054 Batch F1: 0.0
Epoch:   29        5 Batch loss: 0.086285 Batch F1: 0.6666666666666666
Epoch:   29        6 Batch loss: 0.092316 Batch F1: 0.5
Epoch:   29        7 Batch loss: 0.089151 Batch F1: 0.8750000000000001
Epoch:   29        8 Batch loss: 0.085312 Batch F1: 0.5
Epoch:   29        9 Batch loss: 0.099214 Batch F1: 0.4
Epoch:   29       10 Batch loss: 0.093826 Batch F1: 0.0
Epoch:   29       11 Batch loss: 0.083000 Batch F1: 0.8571428571428571
Epoch:   29       12 Batch loss: 0.074760 Batch F1: 0.9090909090909091
Train Avg Loss   29: 0.095053

Train Avg F1   29: 0.39232503607503605

Val Avg Loss   29: 0.088246

Val Avg F1   29:  0.0

Optimal Val loss (Epoch 29): 0.08824588917195797

Epoch 30
--------------------------------------------------------------
Epoch:   30        1 Batch loss: 0.088517 Batch F1: 0.0
Epoch:   30        2 Batch loss: 0.091038 Batch F1: 0.7499999999999999
Epoch:   30        3 Batch loss: 0.094745 Batch F1: 0.8235294117647058
Epoch:   30        4 Batch loss: 0.088812 Batch F1: 0.9411764705882353
Epoch:   30        5 Batch loss: 0.068845 Batch F1: 0.923076923076923
Epoch:   30        6 Batch loss: 0.092823 Batch F1: 0.0
Epoch:   30        7 Batch loss: 0.091020 Batch F1: 0.0
Epoch:   30        8 Batch loss: 0.088105 Batch F1: 0.0
Epoch:   30        9 Batch loss: 0.089919 Batch F1: 0.0
Epoch:   30       10 Batch loss: 0.100581 Batch F1: 0.0
Epoch:   30       11 Batch loss: 0.100124 Batch F1: 0.4
Epoch:   30       12 Batch loss: 0.068326 Batch F1: 1.0
Train Avg Loss   30: 0.088571

Train Avg F1   30: 0.4031485671191553

Val Avg Loss   30: 0.081520

Val Avg F1   30:  0.9375901875901876

Optimal Val loss (Epoch 30): 0.08151977695524693

Epoch 31
--------------------------------------------------------------
Epoch:   31        1 Batch loss: 0.096325 Batch F1: 0.888888888888889
Epoch:   31        2 Batch loss: 0.081018 Batch F1: 0.4615384615384615
Epoch:   31        3 Batch loss: 0.071233 Batch F1: 0.5
Epoch:   31        4 Batch loss: 0.093255 Batch F1: 0.0
Epoch:   31        5 Batch loss: 0.108141 Batch F1: 0.2666666666666667
Epoch:   31        6 Batch loss: 0.079190 Batch F1: 0.9333333333333333
Epoch:   31        7 Batch loss: 0.094320 Batch F1: 0.8571428571428571
Epoch:   31        8 Batch loss: 0.080728 Batch F1: 0.5
Epoch:   31        9 Batch loss: 0.067156 Batch F1: 0.7142857142857143
Epoch:   31       10 Batch loss: 0.089412 Batch F1: 0.5454545454545454
Epoch:   31       11 Batch loss: 0.098606 Batch F1: 0.0
Epoch:   31       12 Batch loss: 0.072626 Batch F1: 0.4444444444444445
Train Avg Loss   31: 0.086001

Train Avg F1   31: 0.5093129093129094

Val Avg Loss   31: 0.077559

Val Avg F1   31:  0.6124023035787741

Optimal Val loss (Epoch 31): 0.07755929697304964

Epoch 32
--------------------------------------------------------------
Epoch:   32        1 Batch loss: 0.085629 Batch F1: 0.7058823529411764
Epoch:   32        2 Batch loss: 0.097134 Batch F1: 0.4615384615384615
Epoch:   32        3 Batch loss: 0.095482 Batch F1: 0.7692307692307693
Epoch:   32        4 Batch loss: 0.086719 Batch F1: 0.42857142857142855
Epoch:   32        5 Batch loss: 0.076928 Batch F1: 0.25
Epoch:   32        6 Batch loss: 0.048122 Batch F1: 0.8
Epoch:   32        7 Batch loss: 0.090574 Batch F1: 0.0
Epoch:   32        8 Batch loss: 0.117234 Batch F1: 0.0
Epoch:   32        9 Batch loss: 0.072811 Batch F1: 0.6153846153846153
Epoch:   32       10 Batch loss: 0.099469 Batch F1: 0.7058823529411764
Epoch:   32       11 Batch loss: 0.121367 Batch F1: 0.7200000000000001
Epoch:   32       12 Batch loss: 0.085771 Batch F1: 0.4
Train Avg Loss   32: 0.089770

Train Avg F1   32: 0.4880408317173022

Val Avg Loss   32: 0.101343

Val Avg F1   32:  0.0

Optimal Val loss (Epoch 31): 0.07755929697304964

Epoch 33
--------------------------------------------------------------
Epoch:   33        1 Batch loss: 0.112019 Batch F1: 0.0
Epoch:   33        2 Batch loss: 0.191886 Batch F1: 0.0
Epoch:   33        3 Batch loss: 0.106450 Batch F1: 0.4444444444444445
Epoch:   33        4 Batch loss: 0.094182 Batch F1: 0.8333333333333334
Epoch:   33        5 Batch loss: 0.115987 Batch F1: 0.7272727272727273
Epoch:   33        6 Batch loss: 0.094353 Batch F1: 0.8750000000000001
Epoch:   33        7 Batch loss: 0.098542 Batch F1: 0.0
Epoch:   33        8 Batch loss: 0.071151 Batch F1: 0.0
Epoch:   33        9 Batch loss: 0.091609 Batch F1: 0.0
Epoch:   33       10 Batch loss: 0.064466 Batch F1: 0.6666666666666666
Epoch:   33       11 Batch loss: 0.099384 Batch F1: 0.0
Epoch:   33       12 Batch loss: 0.074038 Batch F1: 0.0
Train Avg Loss   33: 0.101172

Train Avg F1   33: 0.29555976430976433

Val Avg Loss   33: 0.084088

Val Avg F1   33:  0.0

Optimal Val loss (Epoch 31): 0.07755929697304964

Epoch 34
--------------------------------------------------------------
Epoch:   34        1 Batch loss: 0.110371 Batch F1: 0.0
Epoch:   34        2 Batch loss: 0.106438 Batch F1: 0.0
Epoch:   34        3 Batch loss: 0.108725 Batch F1: 0.6363636363636364
Epoch:   34        4 Batch loss: 0.103209 Batch F1: 0.9565217391304348
Epoch:   34        5 Batch loss: 0.072487 Batch F1: 0.6666666666666666
Epoch:   34        6 Batch loss: 0.070225 Batch F1: 0.6666666666666666
Epoch:   34        7 Batch loss: 0.075892 Batch F1: 0.0
Epoch:   34        8 Batch loss: 0.060659 Batch F1: 0.0
Epoch:   34        9 Batch loss: 0.130823 Batch F1: 0.0
Epoch:   34       10 Batch loss: 0.097179 Batch F1: 0.42857142857142855
Epoch:   34       11 Batch loss: 0.074640 Batch F1: 0.6153846153846153
Epoch:   34       12 Batch loss: 0.064942 Batch F1: 1.0
Train Avg Loss   34: 0.089633

Train Avg F1   34: 0.4141812293986207

Val Avg Loss   34: 0.077867

Val Avg F1   34:  0.9307692307692308

Optimal Val loss (Epoch 31): 0.07755929697304964

Epoch 35
--------------------------------------------------------------
Epoch:   35        1 Batch loss: 0.091138 Batch F1: 0.9
Epoch:   35        2 Batch loss: 0.095538 Batch F1: 0.9
Epoch:   35        3 Batch loss: 0.073000 Batch F1: 0.5
Epoch:   35        4 Batch loss: 0.082972 Batch F1: 0.6153846153846153
Epoch:   35        5 Batch loss: 0.094127 Batch F1: 0.0
Epoch:   35        6 Batch loss: 0.073237 Batch F1: 0.8235294117647058
Epoch:   35        7 Batch loss: 0.067790 Batch F1: 0.2857142857142857
Epoch:   35        8 Batch loss: 0.061621 Batch F1: 0.6
Epoch:   35        9 Batch loss: 0.067380 Batch F1: 0.5454545454545454
Epoch:   35       10 Batch loss: 0.073739 Batch F1: 0.5454545454545454
Epoch:   35       11 Batch loss: 0.101069 Batch F1: 0.5714285714285715
Epoch:   35       12 Batch loss: 0.114472 Batch F1: 0.19999999999999998
Train Avg Loss   35: 0.083007

Train Avg F1   35: 0.540580497933439

Val Avg Loss   35: 0.074392

Val Avg F1   35:  0.9123774509803921

Optimal Val loss (Epoch 35): 0.07439183630049229

Epoch 36
--------------------------------------------------------------
Epoch:   36        1 Batch loss: 0.069633 Batch F1: 0.923076923076923
Epoch:   36        2 Batch loss: 0.064710 Batch F1: 0.9090909090909091
Epoch:   36        3 Batch loss: 0.062255 Batch F1: 0.8
Epoch:   36        4 Batch loss: 0.115355 Batch F1: 0.3157894736842105
Epoch:   36        5 Batch loss: 0.071935 Batch F1: 0.888888888888889
Epoch:   36        6 Batch loss: 0.072552 Batch F1: 0.7692307692307693
Epoch:   36        7 Batch loss: 0.081677 Batch F1: 0.7142857142857143
Epoch:   36        8 Batch loss: 0.122569 Batch F1: 0.2857142857142857
Epoch:   36        9 Batch loss: 0.083008 Batch F1: 0.6153846153846153
Epoch:   36       10 Batch loss: 0.074457 Batch F1: 0.8
Epoch:   36       11 Batch loss: 0.058701 Batch F1: 0.0
Epoch:   36       12 Batch loss: 0.090117 Batch F1: 0.6666666666666666
Train Avg Loss   36: 0.080581

Train Avg F1   36: 0.6406773538352486

Val Avg Loss   36: 0.073670

Val Avg F1   36:  0.5520833333333333

Optimal Val loss (Epoch 36): 0.0736698666587472

Epoch 37
--------------------------------------------------------------
Epoch:   37        1 Batch loss: 0.070190 Batch F1: 0.5454545454545454
Epoch:   37        2 Batch loss: 0.094578 Batch F1: 0.5333333333333333
Epoch:   37        3 Batch loss: 0.079165 Batch F1: 0.8235294117647058
Epoch:   37        4 Batch loss: 0.064353 Batch F1: 0.888888888888889
Epoch:   37        5 Batch loss: 0.079471 Batch F1: 0.8
Epoch:   37        6 Batch loss: 0.058604 Batch F1: 0.5
Epoch:   37        7 Batch loss: 0.067224 Batch F1: 0.7692307692307693
Epoch:   37        8 Batch loss: 0.113313 Batch F1: 0.25
Epoch:   37        9 Batch loss: 0.067443 Batch F1: 0.6153846153846153
Epoch:   37       10 Batch loss: 0.083942 Batch F1: 0.4
Epoch:   37       11 Batch loss: 0.087657 Batch F1: 0.7368421052631579
Epoch:   37       12 Batch loss: 0.078293 Batch F1: 0.8571428571428571
Train Avg Loss   37: 0.078686

Train Avg F1   37: 0.6433172105385727

Val Avg Loss   37: 0.070994

Val Avg F1   37:  0.9257309941520468

Optimal Val loss (Epoch 37): 0.0709940642118454

Epoch 38
--------------------------------------------------------------
Epoch:   38        1 Batch loss: 0.082591 Batch F1: 0.9565217391304348
Epoch:   38        2 Batch loss: 0.073993 Batch F1: 1.0
Epoch:   38        3 Batch loss: 0.069701 Batch F1: 0.6666666666666666
Epoch:   38        4 Batch loss: 0.085040 Batch F1: 0.42857142857142855
Epoch:   38        5 Batch loss: 0.091505 Batch F1: 0.33333333333333337
Epoch:   38        6 Batch loss: 0.075412 Batch F1: 0.6153846153846153
Epoch:   38        7 Batch loss: 0.071071 Batch F1: 0.4
Epoch:   38        8 Batch loss: 0.067350 Batch F1: 0.6
Epoch:   38        9 Batch loss: 0.083326 Batch F1: 0.8571428571428571
Epoch:   38       10 Batch loss: 0.073652 Batch F1: 0.7058823529411764
Epoch:   38       11 Batch loss: 0.061649 Batch F1: 0.5454545454545454
Epoch:   38       12 Batch loss: 0.090010 Batch F1: 0.18181818181818182
Train Avg Loss   38: 0.077108

Train Avg F1   38: 0.6075646433702699

Val Avg Loss   38: 0.069056

Val Avg F1   38:  0.5887723387723387

Optimal Val loss (Epoch 38): 0.06905621290206909

Epoch 39
--------------------------------------------------------------
Epoch:   39        1 Batch loss: 0.075053 Batch F1: 0.4444444444444445
Epoch:   39        2 Batch loss: 0.072926 Batch F1: 0.5454545454545454
Epoch:   39        3 Batch loss: 0.076624 Batch F1: 0.5333333333333333
Epoch:   39        4 Batch loss: 0.070267 Batch F1: 0.25
Epoch:   39        5 Batch loss: 0.059564 Batch F1: 0.25
Epoch:   39        6 Batch loss: 0.072740 Batch F1: 0.5454545454545454
Epoch:   39        7 Batch loss: 0.079110 Batch F1: 0.4615384615384615
Epoch:   39        8 Batch loss: 0.079434 Batch F1: 0.6666666666666666
Epoch:   39        9 Batch loss: 0.084732 Batch F1: 0.9600000000000001
Epoch:   39       10 Batch loss: 0.056603 Batch F1: 1.0
Epoch:   39       11 Batch loss: 0.085360 Batch F1: 0.8421052631578948
Epoch:   39       12 Batch loss: 0.096987 Batch F1: 0.8695652173913044
Train Avg Loss   39: 0.075783

Train Avg F1   39: 0.6140468731200998

Val Avg Loss   39: 0.068171

Val Avg F1   39:  0.9361413043478262

Optimal Val loss (Epoch 39): 0.06817093398422003

Epoch 40
--------------------------------------------------------------
Epoch:   40        1 Batch loss: 0.075812 Batch F1: 0.8750000000000001
Epoch:   40        2 Batch loss: 0.072163 Batch F1: 1.0
Epoch:   40        3 Batch loss: 0.063205 Batch F1: 1.0
Epoch:   40        4 Batch loss: 0.069101 Batch F1: 0.9411764705882353
Epoch:   40        5 Batch loss: 0.070218 Batch F1: 0.6666666666666666
Epoch:   40        6 Batch loss: 0.068800 Batch F1: 0.4
Epoch:   40        7 Batch loss: 0.061953 Batch F1: 0.6
Epoch:   40        8 Batch loss: 0.062133 Batch F1: 0.0
Epoch:   40        9 Batch loss: 0.099638 Batch F1: 0.6666666666666666
Epoch:   40       10 Batch loss: 0.082468 Batch F1: 0.4615384615384615
Epoch:   40       11 Batch loss: 0.080713 Batch F1: 0.8333333333333333
Epoch:   40       12 Batch loss: 0.100200 Batch F1: 0.8
Train Avg Loss   40: 0.075534

Train Avg F1   40: 0.687031799899447

Val Avg Loss   40: 0.075442

Val Avg F1   40:  0.9245798319327732

Optimal Val loss (Epoch 39): 0.06817093398422003

Epoch 41
--------------------------------------------------------------
Epoch:   41        1 Batch loss: 0.077750 Batch F1: 0.8333333333333333
Epoch:   41        2 Batch loss: 0.076001 Batch F1: 0.888888888888889
Epoch:   41        3 Batch loss: 0.085987 Batch F1: 0.5882352941176471
Epoch:   41        4 Batch loss: 0.088085 Batch F1: 0.5333333333333333
Epoch:   41        5 Batch loss: 0.058422 Batch F1: 0.6
Epoch:   41        6 Batch loss: 0.060792 Batch F1: 0.5
Epoch:   41        7 Batch loss: 0.093744 Batch F1: 0.18181818181818182
Epoch:   41        8 Batch loss: 0.078978 Batch F1: 0.42857142857142855
Epoch:   41        9 Batch loss: 0.066378 Batch F1: 1.0
Epoch:   41       10 Batch loss: 0.080004 Batch F1: 1.0
Epoch:   41       11 Batch loss: 0.081066 Batch F1: 0.9565217391304348
Epoch:   41       12 Batch loss: 0.071482 Batch F1: 0.9333333333333333
Train Avg Loss   41: 0.076557

Train Avg F1   41: 0.7036696277105484

Val Avg Loss   41: 0.066681

Val Avg F1   41:  0.9177018633540373

Optimal Val loss (Epoch 41): 0.06668126303702593

Epoch 42
--------------------------------------------------------------
Epoch:   42        1 Batch loss: 0.044502 Batch F1: 1.0
Epoch:   42        2 Batch loss: 0.071991 Batch F1: 0.4
Epoch:   42        3 Batch loss: 0.080201 Batch F1: 0.6153846153846153
Epoch:   42        4 Batch loss: 0.070061 Batch F1: 0.5454545454545454
Epoch:   42        5 Batch loss: 0.102682 Batch F1: 0.2857142857142857
Epoch:   42        6 Batch loss: 0.067428 Batch F1: 0.4444444444444445
Epoch:   42        7 Batch loss: 0.071555 Batch F1: 0.9473684210526316
Epoch:   42        8 Batch loss: 0.084338 Batch F1: 0.888888888888889
Epoch:   42        9 Batch loss: 0.062376 Batch F1: 0.9411764705882353
Epoch:   42       10 Batch loss: 0.078051 Batch F1: 0.625
Epoch:   42       11 Batch loss: 0.073062 Batch F1: 0.3636363636363636
Epoch:   42       12 Batch loss: 0.113923 Batch F1: 0.2857142857142857
Train Avg Loss   42: 0.076681

Train Avg F1   42: 0.611898526739858

Val Avg Loss   42: 0.068860

Val Avg F1   42:  0.9256410256410256

Optimal Val loss (Epoch 41): 0.06668126303702593

Epoch 43
--------------------------------------------------------------
Epoch:   43        1 Batch loss: 0.096374 Batch F1: 0.888888888888889
Epoch:   43        2 Batch loss: 0.079575 Batch F1: 0.9166666666666666
Epoch:   43        3 Batch loss: 0.094672 Batch F1: 0.8888888888888888
Epoch:   43        4 Batch loss: 0.082553 Batch F1: 0.9523809523809523
Epoch:   43        5 Batch loss: 0.059665 Batch F1: 0.4
Epoch:   43        6 Batch loss: 0.093208 Batch F1: 0.0
Epoch:   43        7 Batch loss: 0.079396 Batch F1: 0.4444444444444445
Epoch:   43        8 Batch loss: 0.075188 Batch F1: 0.33333333333333337
Epoch:   43        9 Batch loss: 0.095855 Batch F1: 0.0
Epoch:   43       10 Batch loss: 0.064394 Batch F1: 0.25
Epoch:   43       11 Batch loss: 0.067339 Batch F1: 0.5454545454545454
Epoch:   43       12 Batch loss: 0.050433 Batch F1: 0.8
Train Avg Loss   43: 0.078221

Train Avg F1   43: 0.53500481000481

Val Avg Loss   43: 0.066595

Val Avg F1   43:  0.6212121212121212

Optimal Val loss (Epoch 43): 0.06659510172903538

Epoch 44
--------------------------------------------------------------
Epoch:   44        1 Batch loss: 0.076600 Batch F1: 0.4
Epoch:   44        2 Batch loss: 0.053890 Batch F1: 0.7499999999999999
Epoch:   44        3 Batch loss: 0.071173 Batch F1: 0.7368421052631579
Epoch:   44        4 Batch loss: 0.044062 Batch F1: 0.8571428571428571
Epoch:   44        5 Batch loss: 0.066284 Batch F1: 0.5454545454545454
Epoch:   44        6 Batch loss: 0.115612 Batch F1: 0.0
Epoch:   44        7 Batch loss: 0.099037 Batch F1: 0.42857142857142855
Epoch:   44        8 Batch loss: 0.068182 Batch F1: 1.0
Epoch:   44        9 Batch loss: 0.088376 Batch F1: 0.9090909090909091
Epoch:   44       10 Batch loss: 0.084395 Batch F1: 0.8333333333333333
Epoch:   44       11 Batch loss: 0.075607 Batch F1: 0.7368421052631579
Epoch:   44       12 Batch loss: 0.078930 Batch F1: 0.5454545454545454
Train Avg Loss   44: 0.076846

Train Avg F1   44: 0.6452276524644945

Val Avg Loss   44: 0.068995

Val Avg F1   44:  0.5887445887445887

Optimal Val loss (Epoch 43): 0.06659510172903538

Epoch 45
--------------------------------------------------------------
Epoch:   45        1 Batch loss: 0.055420 Batch F1: 0.5714285714285715
Epoch:   45        2 Batch loss: 0.078277 Batch F1: 0.6153846153846153
Epoch:   45        3 Batch loss: 0.080079 Batch F1: 0.3076923076923077
Epoch:   45        4 Batch loss: 0.078049 Batch F1: 0.7499999999999999
Epoch:   45        5 Batch loss: 0.069686 Batch F1: 0.8750000000000001
Epoch:   45        6 Batch loss: 0.068759 Batch F1: 0.923076923076923
Epoch:   45        7 Batch loss: 0.073493 Batch F1: 0.888888888888889
Epoch:   45        8 Batch loss: 0.073225 Batch F1: 0.6666666666666666
Epoch:   45        9 Batch loss: 0.076318 Batch F1: 0.33333333333333337
Epoch:   45       10 Batch loss: 0.087543 Batch F1: 0.6666666666666666
Epoch:   45       11 Batch loss: 0.084088 Batch F1: 0.3076923076923077
Epoch:   45       12 Batch loss: 0.073234 Batch F1: 1.0
Train Avg Loss   45: 0.074848

Train Avg F1   45: 0.6588191900691901

Val Avg Loss   45: 0.068552

Val Avg F1   45:  0.914443915217909

Optimal Val loss (Epoch 43): 0.06659510172903538

Epoch 46
--------------------------------------------------------------
Epoch:   46        1 Batch loss: 0.066515 Batch F1: 0.9333333333333333
Epoch:   46        2 Batch loss: 0.073665 Batch F1: 0.9523809523809523
Epoch:   46        3 Batch loss: 0.064884 Batch F1: 1.0
Epoch:   46        4 Batch loss: 0.053812 Batch F1: 0.4
Epoch:   46        5 Batch loss: 0.131171 Batch F1: 0.0
Epoch:   46        6 Batch loss: 0.081171 Batch F1: 0.3636363636363636
Epoch:   46        7 Batch loss: 0.083158 Batch F1: 0.7272727272727273
Epoch:   46        8 Batch loss: 0.073427 Batch F1: 1.0
Epoch:   46        9 Batch loss: 0.076406 Batch F1: 0.8750000000000001
Epoch:   46       10 Batch loss: 0.070150 Batch F1: 0.9411764705882353
Epoch:   46       11 Batch loss: 0.059740 Batch F1: 0.4444444444444445
Epoch:   46       12 Batch loss: 0.117049 Batch F1: 0.4
Train Avg Loss   46: 0.079262

Train Avg F1   46: 0.6697703576380047

Val Avg Loss   46: 0.068704

Val Avg F1   46:  0.5844017094017093

Optimal Val loss (Epoch 43): 0.06659510172903538

Epoch 47
--------------------------------------------------------------
Epoch:   47        1 Batch loss: 0.069175 Batch F1: 0.25
Epoch:   47        2 Batch loss: 0.095396 Batch F1: 0.9166666666666666
Epoch:   47        3 Batch loss: 0.045030 Batch F1: 1.0
Epoch:   47        4 Batch loss: 0.101801 Batch F1: 0.9565217391304348
Epoch:   47        5 Batch loss: 0.079577 Batch F1: 0.7058823529411764
Epoch:   47        6 Batch loss: 0.115269 Batch F1: 0.25
Epoch:   47        7 Batch loss: 0.046419 Batch F1: 0.0
Epoch:   47        8 Batch loss: 0.089952 Batch F1: 0.5
Epoch:   47        9 Batch loss: 0.056518 Batch F1: 0.6666666666666666
Epoch:   47       10 Batch loss: 0.093233 Batch F1: 0.18181818181818182
Epoch:   47       11 Batch loss: 0.065173 Batch F1: 0.6153846153846153
Epoch:   47       12 Batch loss: 0.051614 Batch F1: 1.0
Train Avg Loss   47: 0.075763

Train Avg F1   47: 0.5869116852173119

Val Avg Loss   47: 0.065671

Val Avg F1   47:  0.7170388091440724

Optimal Val loss (Epoch 47): 0.06567056197673082

Epoch 48
--------------------------------------------------------------
Epoch:   48        1 Batch loss: 0.080441 Batch F1: 0.7272727272727273
Epoch:   48        2 Batch loss: 0.072515 Batch F1: 0.9411764705882353
Epoch:   48        3 Batch loss: 0.066828 Batch F1: 1.0
Epoch:   48        4 Batch loss: 0.056769 Batch F1: 1.0
Epoch:   48        5 Batch loss: 0.075981 Batch F1: 0.6
Epoch:   48        6 Batch loss: 0.046068 Batch F1: 0.0
Epoch:   48        7 Batch loss: 0.096041 Batch F1: 0.0
Epoch:   48        8 Batch loss: 0.073997 Batch F1: 0.4
Epoch:   48        9 Batch loss: 0.064960 Batch F1: 0.5454545454545454
Epoch:   48       10 Batch loss: 0.102400 Batch F1: 0.7368421052631579
Epoch:   48       11 Batch loss: 0.057634 Batch F1: 0.9411764705882353
Epoch:   48       12 Batch loss: 0.072036 Batch F1: 1.0
Train Avg Loss   48: 0.072139

Train Avg F1   48: 0.6576601932639085

Val Avg Loss   48: 0.065379

Val Avg F1   48:  0.9183298319327732

Optimal Val loss (Epoch 48): 0.06537938956171274

Epoch 49
--------------------------------------------------------------
Epoch:   49        1 Batch loss: 0.071849 Batch F1: 0.9333333333333333
Epoch:   49        2 Batch loss: 0.053183 Batch F1: 0.8571428571428571
Epoch:   49        3 Batch loss: 0.052217 Batch F1: 0.2857142857142857
Epoch:   49        4 Batch loss: 0.074692 Batch F1: 0.0
Epoch:   49        5 Batch loss: 0.065402 Batch F1: 0.7692307692307693
Epoch:   49        6 Batch loss: 0.075717 Batch F1: 0.33333333333333337
Epoch:   49        7 Batch loss: 0.103959 Batch F1: 0.2857142857142857
Epoch:   49        8 Batch loss: 0.069482 Batch F1: 0.9333333333333333
Epoch:   49        9 Batch loss: 0.060112 Batch F1: 0.9411764705882353
Epoch:   49       10 Batch loss: 0.083190 Batch F1: 0.9523809523809523
Epoch:   49       11 Batch loss: 0.067492 Batch F1: 1.0
Epoch:   49       12 Batch loss: 0.103427 Batch F1: 0.47058823529411764
Train Avg Loss   49: 0.073394

Train Avg F1   49: 0.6468289880054586

Val Avg Loss   49: 0.064380

Val Avg F1   49:  0.5613636363636363

Optimal Val loss (Epoch 49): 0.0643799090757966

Epoch 50
--------------------------------------------------------------
Epoch:   50        1 Batch loss: 0.079959 Batch F1: 0.5333333333333333
Epoch:   50        2 Batch loss: 0.050922 Batch F1: 0.5
Epoch:   50        3 Batch loss: 0.063194 Batch F1: 0.9333333333333333
Epoch:   50        4 Batch loss: 0.064240 Batch F1: 0.2857142857142857
Epoch:   50        5 Batch loss: 0.067113 Batch F1: 0.6153846153846153
Epoch:   50        6 Batch loss: 0.092538 Batch F1: 0.47058823529411764
Epoch:   50        7 Batch loss: 0.054181 Batch F1: 1.0
Epoch:   50        8 Batch loss: 0.071446 Batch F1: 0.33333333333333337
Epoch:   50        9 Batch loss: 0.079982 Batch F1: 0.5333333333333333
Epoch:   50       10 Batch loss: 0.054860 Batch F1: 1.0
Epoch:   50       11 Batch loss: 0.082182 Batch F1: 0.4
Epoch:   50       12 Batch loss: 0.106805 Batch F1: 0.47058823529411764
Train Avg Loss   50: 0.072285

Train Avg F1   50: 0.5896340587517058

Val Avg Loss   50: 0.064243

Val Avg F1   50:  0.9392857142857143

Optimal Val loss (Epoch 50): 0.06424316763877869

Epoch 51
--------------------------------------------------------------
Epoch:   51        1 Batch loss: 0.074771 Batch F1: 0.9565217391304348
Epoch:   51        2 Batch loss: 0.079888 Batch F1: 0.923076923076923
Epoch:   51        3 Batch loss: 0.086331 Batch F1: 0.7692307692307693
Epoch:   51        4 Batch loss: 0.065746 Batch F1: 0.8571428571428571
Epoch:   51        5 Batch loss: 0.054457 Batch F1: 0.4444444444444445
Epoch:   51        6 Batch loss: 0.076957 Batch F1: 0.5
Epoch:   51        7 Batch loss: 0.066012 Batch F1: 0.6153846153846153
Epoch:   51        8 Batch loss: 0.071517 Batch F1: 0.9411764705882353
Epoch:   51        9 Batch loss: 0.057756 Batch F1: 0.888888888888889
Epoch:   51       10 Batch loss: 0.078995 Batch F1: 0.962962962962963
Epoch:   51       11 Batch loss: 0.075527 Batch F1: 0.9565217391304348
Epoch:   51       12 Batch loss: 0.073882 Batch F1: 0.9333333333333333
Train Avg Loss   51: 0.071820

Train Avg F1   51: 0.8123903952761583

Val Avg Loss   51: 0.063541

Val Avg F1   51:  0.9227941176470589

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 52
--------------------------------------------------------------
Epoch:   52        1 Batch loss: 0.073738 Batch F1: 0.8235294117647058
Epoch:   52        2 Batch loss: 0.079017 Batch F1: 1.0
Epoch:   52        3 Batch loss: 0.065553 Batch F1: 0.9090909090909091
Epoch:   52        4 Batch loss: 0.061677 Batch F1: 0.6
Epoch:   52        5 Batch loss: 0.070669 Batch F1: 0.2222222222222222
Epoch:   52        6 Batch loss: 0.062492 Batch F1: 0.4444444444444445
Epoch:   52        7 Batch loss: 0.093087 Batch F1: 0.3076923076923077
Epoch:   52        8 Batch loss: 0.061738 Batch F1: 0.4444444444444445
Epoch:   52        9 Batch loss: 0.070765 Batch F1: 0.9411764705882353
Epoch:   52       10 Batch loss: 0.071023 Batch F1: 0.9565217391304348
Epoch:   52       11 Batch loss: 0.074344 Batch F1: 0.9565217391304348
Epoch:   52       12 Batch loss: 0.072782 Batch F1: 0.9090909090909091
Train Avg Loss   52: 0.071407

Train Avg F1   52: 0.7095612164665873

Val Avg Loss   52: 0.063647

Val Avg F1   52:  0.8976754385964911

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 53
--------------------------------------------------------------
Epoch:   53        1 Batch loss: 0.064801 Batch F1: 0.9411764705882353
Epoch:   53        2 Batch loss: 0.086556 Batch F1: 0.42857142857142855
Epoch:   53        3 Batch loss: 0.068758 Batch F1: 0.6153846153846153
Epoch:   53        4 Batch loss: 0.070376 Batch F1: 0.5
Epoch:   53        5 Batch loss: 0.063681 Batch F1: 0.5454545454545454
Epoch:   53        6 Batch loss: 0.098570 Batch F1: 0.47619047619047616
Epoch:   53        7 Batch loss: 0.083609 Batch F1: 0.888888888888889
Epoch:   53        8 Batch loss: 0.097685 Batch F1: 0.631578947368421
Epoch:   53        9 Batch loss: 0.046494 Batch F1: 0.5714285714285715
Epoch:   53       10 Batch loss: 0.077443 Batch F1: 0.4615384615384615
Epoch:   53       11 Batch loss: 0.065576 Batch F1: 0.2222222222222222
Epoch:   53       12 Batch loss: 0.058531 Batch F1: 0.33333333333333337
Train Avg Loss   53: 0.073506

Train Avg F1   53: 0.5513139967474333

Val Avg Loss   53: 0.067228

Val Avg F1   53:  0.9226190476190476

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 54
--------------------------------------------------------------
Epoch:   54        1 Batch loss: 0.071869 Batch F1: 0.9333333333333333
Epoch:   54        2 Batch loss: 0.075356 Batch F1: 0.9523809523809523
Epoch:   54        3 Batch loss: 0.078909 Batch F1: 0.962962962962963
Epoch:   54        4 Batch loss: 0.069542 Batch F1: 0.923076923076923
Epoch:   54        5 Batch loss: 0.070898 Batch F1: 0.9090909090909091
Epoch:   54        6 Batch loss: 0.055743 Batch F1: 0.7499999999999999
Epoch:   54        7 Batch loss: 0.105333 Batch F1: 0.0
Epoch:   54        8 Batch loss: 0.091129 Batch F1: 0.0
Epoch:   54        9 Batch loss: 0.054009 Batch F1: 0.8333333333333333
Epoch:   54       10 Batch loss: 0.061424 Batch F1: 0.9333333333333333
Epoch:   54       11 Batch loss: 0.081710 Batch F1: 0.8750000000000001
Epoch:   54       12 Batch loss: 0.083051 Batch F1: 0.9600000000000001
Train Avg Loss   54: 0.074915

Train Avg F1   54: 0.7527093122926457

Val Avg Loss   54: 0.068878

Val Avg F1   54:  0.8740079365079365

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 55
--------------------------------------------------------------
Epoch:   55        1 Batch loss: 0.094204 Batch F1: 0.8571428571428572
Epoch:   55        2 Batch loss: 0.073312 Batch F1: 0.9473684210526316
Epoch:   55        3 Batch loss: 0.070043 Batch F1: 0.5714285714285715
Epoch:   55        4 Batch loss: 0.080086 Batch F1: 0.4615384615384615
Epoch:   55        5 Batch loss: 0.068115 Batch F1: 0.4
Epoch:   55        6 Batch loss: 0.078003 Batch F1: 0.4615384615384615
Epoch:   55        7 Batch loss: 0.070883 Batch F1: 0.5714285714285715
Epoch:   55        8 Batch loss: 0.058690 Batch F1: 0.9473684210526316
Epoch:   55        9 Batch loss: 0.058171 Batch F1: 0.888888888888889
Epoch:   55       10 Batch loss: 0.080034 Batch F1: 0.3636363636363636
Epoch:   55       11 Batch loss: 0.065289 Batch F1: 0.25
Epoch:   55       12 Batch loss: 0.071299 Batch F1: 0.5454545454545454
Train Avg Loss   55: 0.072344

Train Avg F1   55: 0.6054827969301654

Val Avg Loss   55: 0.066502

Val Avg F1   55:  0.5802756067461949

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 56
--------------------------------------------------------------
Epoch:   56        1 Batch loss: 0.068738 Batch F1: 0.5714285714285715
Epoch:   56        2 Batch loss: 0.063679 Batch F1: 0.4444444444444445
Epoch:   56        3 Batch loss: 0.054812 Batch F1: 0.6666666666666666
Epoch:   56        4 Batch loss: 0.072257 Batch F1: 0.3636363636363636
Epoch:   56        5 Batch loss: 0.083790 Batch F1: 0.631578947368421
Epoch:   56        6 Batch loss: 0.069288 Batch F1: 0.9
Epoch:   56        7 Batch loss: 0.066122 Batch F1: 1.0
Epoch:   56        8 Batch loss: 0.097273 Batch F1: 0.8333333333333333
Epoch:   56        9 Batch loss: 0.079977 Batch F1: 0.9
Epoch:   56       10 Batch loss: 0.082791 Batch F1: 0.9090909090909091
Epoch:   56       11 Batch loss: 0.071729 Batch F1: 0.8571428571428571
Epoch:   56       12 Batch loss: 0.055436 Batch F1: 0.33333333333333337
Train Avg Loss   56: 0.072158

Train Avg F1   56: 0.7008879522037418

Val Avg Loss   56: 0.070113

Val Avg F1   56:  0.5931372549019607

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 57
--------------------------------------------------------------
Epoch:   57        1 Batch loss: 0.095507 Batch F1: 0.7272727272727273
Epoch:   57        2 Batch loss: 0.078644 Batch F1: 0.4615384615384615
Epoch:   57        3 Batch loss: 0.080161 Batch F1: 0.4615384615384615
Epoch:   57        4 Batch loss: 0.052000 Batch F1: 0.7499999999999999
Epoch:   57        5 Batch loss: 0.073764 Batch F1: 0.5
Epoch:   57        6 Batch loss: 0.080116 Batch F1: 0.0
Epoch:   57        7 Batch loss: 0.075647 Batch F1: 0.9090909090909091
Epoch:   57        8 Batch loss: 0.065878 Batch F1: 1.0
Epoch:   57        9 Batch loss: 0.079731 Batch F1: 0.9411764705882353
Epoch:   57       10 Batch loss: 0.076530 Batch F1: 0.923076923076923
Epoch:   57       11 Batch loss: 0.032485 Batch F1: 0.0
Epoch:   57       12 Batch loss: 0.155446 Batch F1: 0.0
Train Avg Loss   57: 0.078826

Train Avg F1   57: 0.5561411627588099

Val Avg Loss   57: 0.096480

Val Avg F1   57:  0.0

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 58
--------------------------------------------------------------
Epoch:   58        1 Batch loss: 0.079057 Batch F1: 0.0
Epoch:   58        2 Batch loss: 0.085276 Batch F1: 0.0
Epoch:   58        3 Batch loss: 0.083231 Batch F1: 0.5333333333333333
Epoch:   58        4 Batch loss: 0.079844 Batch F1: 0.9411764705882353
Epoch:   58        5 Batch loss: 0.085050 Batch F1: 0.8571428571428571
Epoch:   58        6 Batch loss: 0.086998 Batch F1: 0.5
Epoch:   58        7 Batch loss: 0.070429 Batch F1: 0.6153846153846153
Epoch:   58        8 Batch loss: 0.063319 Batch F1: 0.6666666666666666
Epoch:   58        9 Batch loss: 0.068895 Batch F1: 0.4444444444444445
Epoch:   58       10 Batch loss: 0.069255 Batch F1: 0.4444444444444445
Epoch:   58       11 Batch loss: 0.074640 Batch F1: 0.19999999999999998
Epoch:   58       12 Batch loss: 0.088253 Batch F1: 0.8
Train Avg Loss   58: 0.077854

Train Avg F1   58: 0.5002160693337164

Val Avg Loss   58: 0.072876

Val Avg F1   58:  0.9076388888888889

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 59
--------------------------------------------------------------
Epoch:   59        1 Batch loss: 0.107534 Batch F1: 0.7000000000000001
Epoch:   59        2 Batch loss: 0.065175 Batch F1: 0.9411764705882353
Epoch:   59        3 Batch loss: 0.064398 Batch F1: 1.0
Epoch:   59        4 Batch loss: 0.064746 Batch F1: 0.923076923076923
Epoch:   59        5 Batch loss: 0.125244 Batch F1: 0.1111111111111111
Epoch:   59        6 Batch loss: 0.081913 Batch F1: 0.8421052631578948
Epoch:   59        7 Batch loss: 0.070542 Batch F1: 0.888888888888889
Epoch:   59        8 Batch loss: 0.057879 Batch F1: 1.0
Epoch:   59        9 Batch loss: 0.069715 Batch F1: 1.0
Epoch:   59       10 Batch loss: 0.069936 Batch F1: 0.4
Epoch:   59       11 Batch loss: 0.071054 Batch F1: 0.6153846153846153
Epoch:   59       12 Batch loss: 0.069101 Batch F1: 0.4444444444444445
Train Avg Loss   59: 0.076436

Train Avg F1   59: 0.7388489763876761

Val Avg Loss   59: 0.066476

Val Avg F1   59:  0.625

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 60
--------------------------------------------------------------
Epoch:   60        1 Batch loss: 0.101269 Batch F1: 0.25
Epoch:   60        2 Batch loss: 0.062782 Batch F1: 0.9090909090909091
Epoch:   60        3 Batch loss: 0.070071 Batch F1: 0.9333333333333333
Epoch:   60        4 Batch loss: 0.082455 Batch F1: 1.0
Epoch:   60        5 Batch loss: 0.068765 Batch F1: 0.25
Epoch:   60        6 Batch loss: 0.079481 Batch F1: 0.4615384615384615
Epoch:   60        7 Batch loss: 0.095023 Batch F1: 0.4
Epoch:   60        8 Batch loss: 0.055768 Batch F1: 1.0
Epoch:   60        9 Batch loss: 0.066468 Batch F1: 0.9411764705882353
Epoch:   60       10 Batch loss: 0.076367 Batch F1: 0.9
Epoch:   60       11 Batch loss: 0.067203 Batch F1: 0.8750000000000001
Epoch:   60       12 Batch loss: 0.054143 Batch F1: 1.0
Train Avg Loss   60: 0.073316

Train Avg F1   60: 0.7433449312125783

Val Avg Loss   60: 0.064971

Val Avg F1   60:  0.53125

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 61
--------------------------------------------------------------
Epoch:   61        1 Batch loss: 0.089266 Batch F1: 0.4
Epoch:   61        2 Batch loss: 0.062193 Batch F1: 0.4444444444444445
Epoch:   61        3 Batch loss: 0.053044 Batch F1: 0.8
Epoch:   61        4 Batch loss: 0.069988 Batch F1: 0.4
Epoch:   61        5 Batch loss: 0.051764 Batch F1: 0.6666666666666666
Epoch:   61        6 Batch loss: 0.074226 Batch F1: 0.5714285714285715
Epoch:   61        7 Batch loss: 0.075624 Batch F1: 0.625
Epoch:   61        8 Batch loss: 0.084602 Batch F1: 0.33333333333333337
Epoch:   61        9 Batch loss: 0.080316 Batch F1: 0.4
Epoch:   61       10 Batch loss: 0.069330 Batch F1: 0.8421052631578948
Epoch:   61       11 Batch loss: 0.082703 Batch F1: 0.8333333333333333
Epoch:   61       12 Batch loss: 0.089501 Batch F1: 0.9333333333333333
Train Avg Loss   61: 0.073547

Train Avg F1   61: 0.6041370788081315

Val Avg Loss   61: 0.065831

Val Avg F1   61:  0.9198778195488722

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 62
--------------------------------------------------------------
Epoch:   62        1 Batch loss: 0.080235 Batch F1: 1.0
Epoch:   62        2 Batch loss: 0.076264 Batch F1: 1.0
Epoch:   62        3 Batch loss: 0.084893 Batch F1: 0.33333333333333337
Epoch:   62        4 Batch loss: 0.079074 Batch F1: 0.7142857142857143
Epoch:   62        5 Batch loss: 0.068338 Batch F1: 0.25
Epoch:   62        6 Batch loss: 0.073342 Batch F1: 0.7058823529411764
Epoch:   62        7 Batch loss: 0.059127 Batch F1: 0.4444444444444445
Epoch:   62        8 Batch loss: 0.054776 Batch F1: 0.8571428571428571
Epoch:   62        9 Batch loss: 0.068743 Batch F1: 1.0
Epoch:   62       10 Batch loss: 0.069693 Batch F1: 0.7272727272727273
Epoch:   62       11 Batch loss: 0.074949 Batch F1: 0.8571428571428571
Epoch:   62       12 Batch loss: 0.083397 Batch F1: 0.8571428571428571
Train Avg Loss   62: 0.072736

Train Avg F1   62: 0.7288872619754972

Val Avg Loss   62: 0.065581

Val Avg F1   62:  0.8833333333333333

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 63
--------------------------------------------------------------
Epoch:   63        1 Batch loss: 0.074009 Batch F1: 0.7692307692307693
Epoch:   63        2 Batch loss: 0.052080 Batch F1: 1.0
Epoch:   63        3 Batch loss: 0.069700 Batch F1: 0.5714285714285715
Epoch:   63        4 Batch loss: 0.076381 Batch F1: 0.6666666666666666
Epoch:   63        5 Batch loss: 0.064189 Batch F1: 0.7777777777777778
Epoch:   63        6 Batch loss: 0.063512 Batch F1: 0.5
Epoch:   63        7 Batch loss: 0.066509 Batch F1: 0.2222222222222222
Epoch:   63        8 Batch loss: 0.097940 Batch F1: 0.5
Epoch:   63        9 Batch loss: 0.060934 Batch F1: 1.0
Epoch:   63       10 Batch loss: 0.097653 Batch F1: 0.8695652173913044
Epoch:   63       11 Batch loss: 0.067921 Batch F1: 1.0
Epoch:   63       12 Batch loss: 0.067318 Batch F1: 0.9090909090909091
Train Avg Loss   63: 0.071512

Train Avg F1   63: 0.7321651778173517

Val Avg Loss   63: 0.063971

Val Avg F1   63:  0.7377705627705627

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 64
--------------------------------------------------------------
Epoch:   64        1 Batch loss: 0.055135 Batch F1: 0.7272727272727273
Epoch:   64        2 Batch loss: 0.075122 Batch F1: 0.5882352941176471
Epoch:   64        3 Batch loss: 0.083840 Batch F1: 0.42857142857142855
Epoch:   64        4 Batch loss: 0.076959 Batch F1: 0.5333333333333333
Epoch:   64        5 Batch loss: 0.079027 Batch F1: 0.33333333333333337
Epoch:   64        6 Batch loss: 0.096791 Batch F1: 0.9090909090909091
Epoch:   64        7 Batch loss: 0.063730 Batch F1: 0.9090909090909091
Epoch:   64        8 Batch loss: 0.065671 Batch F1: 0.9333333333333333
Epoch:   64        9 Batch loss: 0.086930 Batch F1: 0.9090909090909091
Epoch:   64       10 Batch loss: 0.048092 Batch F1: 1.0
Epoch:   64       11 Batch loss: 0.057756 Batch F1: 0.5
Epoch:   64       12 Batch loss: 0.069220 Batch F1: 0.6
Train Avg Loss   64: 0.071523

Train Avg F1   64: 0.6976126814362109

Val Avg Loss   64: 0.067628

Val Avg F1   64:  0.5520833333333333

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 65
--------------------------------------------------------------
Epoch:   65        1 Batch loss: 0.083619 Batch F1: 0.19999999999999998
Epoch:   65        2 Batch loss: 0.064154 Batch F1: 0.5454545454545454
Epoch:   65        3 Batch loss: 0.076036 Batch F1: 0.18181818181818182
Epoch:   65        4 Batch loss: 0.070422 Batch F1: 0.5
Epoch:   65        5 Batch loss: 0.077418 Batch F1: 0.7499999999999999
Epoch:   65        6 Batch loss: 0.055728 Batch F1: 1.0
Epoch:   65        7 Batch loss: 0.071461 Batch F1: 0.888888888888889
Epoch:   65        8 Batch loss: 0.088006 Batch F1: 0.9333333333333333
Epoch:   65        9 Batch loss: 0.067973 Batch F1: 0.9333333333333333
Epoch:   65       10 Batch loss: 0.060559 Batch F1: 0.923076923076923
Epoch:   65       11 Batch loss: 0.066191 Batch F1: 1.0
Epoch:   65       12 Batch loss: 0.060105 Batch F1: 0.7272727272727273
Train Avg Loss   65: 0.070139

Train Avg F1   65: 0.7152648277648278

Val Avg Loss   65: 0.064172

Val Avg F1   65:  0.5756302521008403

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 66
--------------------------------------------------------------
Epoch:   66        1 Batch loss: 0.062500 Batch F1: 0.7142857142857143
Epoch:   66        2 Batch loss: 0.062947 Batch F1: 0.8
Epoch:   66        3 Batch loss: 0.070299 Batch F1: 0.5714285714285715
Epoch:   66        4 Batch loss: 0.065638 Batch F1: 0.0
Epoch:   66        5 Batch loss: 0.069760 Batch F1: 0.4
Epoch:   66        6 Batch loss: 0.074666 Batch F1: 0.5882352941176471
Epoch:   66        7 Batch loss: 0.073415 Batch F1: 0.5
Epoch:   66        8 Batch loss: 0.069236 Batch F1: 0.8571428571428571
Epoch:   66        9 Batch loss: 0.084060 Batch F1: 0.9090909090909091
Epoch:   66       10 Batch loss: 0.071024 Batch F1: 0.8571428571428571
Epoch:   66       11 Batch loss: 0.070967 Batch F1: 0.923076923076923
Epoch:   66       12 Batch loss: 0.061755 Batch F1: 1.0
Train Avg Loss   66: 0.069689

Train Avg F1   66: 0.67670026052379

Val Avg Loss   66: 0.064338

Val Avg F1   66:  0.7357142857142858

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 67
--------------------------------------------------------------
Epoch:   67        1 Batch loss: 0.067048 Batch F1: 0.6666666666666666
Epoch:   67        2 Batch loss: 0.096098 Batch F1: 0.47058823529411764
Epoch:   67        3 Batch loss: 0.055232 Batch F1: 0.25
Epoch:   67        4 Batch loss: 0.069536 Batch F1: 0.8750000000000001
Epoch:   67        5 Batch loss: 0.066947 Batch F1: 0.9411764705882353
Epoch:   67        6 Batch loss: 0.083713 Batch F1: 0.846153846153846
Epoch:   67        7 Batch loss: 0.057817 Batch F1: 1.0
Epoch:   67        8 Batch loss: 0.075378 Batch F1: 1.0
Epoch:   67        9 Batch loss: 0.069264 Batch F1: 0.9411764705882353
Epoch:   67       10 Batch loss: 0.079814 Batch F1: 0.5333333333333333
Epoch:   67       11 Batch loss: 0.051256 Batch F1: 0.6666666666666666
Epoch:   67       12 Batch loss: 0.081644 Batch F1: 0.5
Train Avg Loss   67: 0.071146

Train Avg F1   67: 0.7242301407742584

Val Avg Loss   67: 0.064678

Val Avg F1   67:  0.5475490196078431

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 68
--------------------------------------------------------------
Epoch:   68        1 Batch loss: 0.076978 Batch F1: 0.7000000000000001
Epoch:   68        2 Batch loss: 0.092028 Batch F1: 0.375
Epoch:   68        3 Batch loss: 0.068999 Batch F1: 0.923076923076923
Epoch:   68        4 Batch loss: 0.054169 Batch F1: 1.0
Epoch:   68        5 Batch loss: 0.080962 Batch F1: 0.8
Epoch:   68        6 Batch loss: 0.069814 Batch F1: 0.7499999999999999
Epoch:   68        7 Batch loss: 0.079013 Batch F1: 0.7499999999999999
Epoch:   68        8 Batch loss: 0.059313 Batch F1: 0.0
Epoch:   68        9 Batch loss: 0.066126 Batch F1: 0.0
Epoch:   68       10 Batch loss: 0.060252 Batch F1: 0.6666666666666666
Epoch:   68       11 Batch loss: 0.089633 Batch F1: 0.42857142857142855
Epoch:   68       12 Batch loss: 0.074288 Batch F1: 0.8750000000000001
Train Avg Loss   68: 0.072631

Train Avg F1   68: 0.6056929181929183

Val Avg Loss   68: 0.064452

Val Avg F1   68:  0.9242216117216117

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 69
--------------------------------------------------------------
Epoch:   69        1 Batch loss: 0.072004 Batch F1: 0.923076923076923
Epoch:   69        2 Batch loss: 0.071414 Batch F1: 1.0
Epoch:   69        3 Batch loss: 0.065004 Batch F1: 0.6666666666666666
Epoch:   69        4 Batch loss: 0.057742 Batch F1: 0.4444444444444445
Epoch:   69        5 Batch loss: 0.068530 Batch F1: 0.6153846153846153
Epoch:   69        6 Batch loss: 0.070212 Batch F1: 0.6153846153846153
Epoch:   69        7 Batch loss: 0.080972 Batch F1: 0.25
Epoch:   69        8 Batch loss: 0.081192 Batch F1: 0.5714285714285715
Epoch:   69        9 Batch loss: 0.062717 Batch F1: 0.9333333333333333
Epoch:   69       10 Batch loss: 0.080223 Batch F1: 0.5454545454545454
Epoch:   69       11 Batch loss: 0.067708 Batch F1: 1.0
Epoch:   69       12 Batch loss: 0.079147 Batch F1: 0.9565217391304348
Train Avg Loss   69: 0.071405

Train Avg F1   69: 0.7101412878586792

Val Avg Loss   69: 0.064893

Val Avg F1   69:  0.9375667429443173

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 70
--------------------------------------------------------------
Epoch:   70        1 Batch loss: 0.059851 Batch F1: 1.0
Epoch:   70        2 Batch loss: 0.059053 Batch F1: 0.7142857142857143
Epoch:   70        3 Batch loss: 0.090232 Batch F1: 0.5
Epoch:   70        4 Batch loss: 0.042342 Batch F1: 0.7499999999999999
Epoch:   70        5 Batch loss: 0.063972 Batch F1: 0.7058823529411764
Epoch:   70        6 Batch loss: 0.052957 Batch F1: 0.5
Epoch:   70        7 Batch loss: 0.109243 Batch F1: 0.16666666666666669
Epoch:   70        8 Batch loss: 0.071498 Batch F1: 0.25
Epoch:   70        9 Batch loss: 0.084880 Batch F1: 0.8421052631578948
Epoch:   70       10 Batch loss: 0.076301 Batch F1: 0.8750000000000001
Epoch:   70       11 Batch loss: 0.059636 Batch F1: 0.9090909090909091
Epoch:   70       12 Batch loss: 0.127377 Batch F1: 0.47619047619047616
Train Avg Loss   70: 0.074779

Train Avg F1   70: 0.6407684485277365

Val Avg Loss   70: 0.064725

Val Avg F1   70:  0.9201754385964912

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 71
--------------------------------------------------------------
Epoch:   71        1 Batch loss: 0.070790 Batch F1: 0.923076923076923
Epoch:   71        2 Batch loss: 0.073029 Batch F1: 1.0
Epoch:   71        3 Batch loss: 0.093809 Batch F1: 0.9166666666666666
Epoch:   71        4 Batch loss: 0.080094 Batch F1: 0.7692307692307693
Epoch:   71        5 Batch loss: 0.056399 Batch F1: 0.923076923076923
Epoch:   71        6 Batch loss: 0.055821 Batch F1: 1.0
Epoch:   71        7 Batch loss: 0.068002 Batch F1: 0.9473684210526316
Epoch:   71        8 Batch loss: 0.078937 Batch F1: 0.9565217391304348
Epoch:   71        9 Batch loss: 0.066738 Batch F1: 0.7499999999999999
Epoch:   71       10 Batch loss: 0.062132 Batch F1: 0.8
Epoch:   71       11 Batch loss: 0.082522 Batch F1: 0.5882352941176471
Epoch:   71       12 Batch loss: 0.078519 Batch F1: 0.5714285714285715
Train Avg Loss   71: 0.072233

Train Avg F1   71: 0.845467108981714

Val Avg Loss   71: 0.064110

Val Avg F1   71:  0.5718635531135532

Optimal Val loss (Epoch 51): 0.06354095228016376

Epoch 72
--------------------------------------------------------------
Epoch:   72        1 Batch loss: 0.052037 Batch F1: 0.6666666666666666
Epoch:   72        2 Batch loss: 0.078923 Batch F1: 0.5882352941176471
Epoch:   72        3 Batch loss: 0.090132 Batch F1: 0.0
Epoch:   72        4 Batch loss: 0.073297 Batch F1: 0.7692307692307693
Epoch:   72        5 Batch loss: 0.083248 Batch F1: 0.9090909090909091
Epoch:   72        6 Batch loss: 0.066527 Batch F1: 1.0
Epoch:   72        7 Batch loss: 0.054318 Batch F1: 0.888888888888889
Epoch:   72        8 Batch loss: 0.065222 Batch F1: 0.9090909090909091
Epoch:   72        9 Batch loss: 0.092113 Batch F1: 0.5555555555555556
Epoch:   72       10 Batch loss: 0.047655 Batch F1: 0.5
Epoch:   72       11 Batch loss: 0.076533 Batch F1: 0.42857142857142855
Epoch:   72       12 Batch loss: 0.074493 Batch F1: 0.7142857142857143
Train Avg Loss   72: 0.071208

Train Avg F1   72: 0.660801344624874

Val Avg Loss   72: 0.062427

Val Avg F1   72:  0.9259992458521871

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 73
--------------------------------------------------------------
Epoch:   73        1 Batch loss: 0.047397 Batch F1: 1.0
Epoch:   73        2 Batch loss: 0.066863 Batch F1: 0.8
Epoch:   73        3 Batch loss: 0.086347 Batch F1: 0.6666666666666666
Epoch:   73        4 Batch loss: 0.055841 Batch F1: 0.2857142857142857
Epoch:   73        5 Batch loss: 0.057783 Batch F1: 0.7499999999999999
Epoch:   73        6 Batch loss: 0.071306 Batch F1: 0.0
Epoch:   73        7 Batch loss: 0.067123 Batch F1: 0.6666666666666666
Epoch:   73        8 Batch loss: 0.071519 Batch F1: 1.0
Epoch:   73        9 Batch loss: 0.068873 Batch F1: 0.9333333333333333
Epoch:   73       10 Batch loss: 0.101510 Batch F1: 0.896551724137931
Epoch:   73       11 Batch loss: 0.064757 Batch F1: 0.9090909090909091
Epoch:   73       12 Batch loss: 0.076008 Batch F1: 0.888888888888889
Train Avg Loss   73: 0.069611

Train Avg F1   73: 0.7330760395415568

Val Avg Loss   73: 0.064032

Val Avg F1   73:  0.91289592760181

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 74
--------------------------------------------------------------
Epoch:   74        1 Batch loss: 0.064180 Batch F1: 1.0
Epoch:   74        2 Batch loss: 0.056854 Batch F1: 1.0
Epoch:   74        3 Batch loss: 0.068536 Batch F1: 0.5714285714285715
Epoch:   74        4 Batch loss: 0.104985 Batch F1: 0.5
Epoch:   74        5 Batch loss: 0.049386 Batch F1: 0.5
Epoch:   74        6 Batch loss: 0.096458 Batch F1: 0.375
Epoch:   74        7 Batch loss: 0.054909 Batch F1: 0.923076923076923
Epoch:   74        8 Batch loss: 0.094471 Batch F1: 0.8571428571428571
Epoch:   74        9 Batch loss: 0.068000 Batch F1: 0.9473684210526316
Epoch:   74       10 Batch loss: 0.066934 Batch F1: 0.9333333333333333
Epoch:   74       11 Batch loss: 0.072750 Batch F1: 0.9523809523809523
Epoch:   74       12 Batch loss: 0.060361 Batch F1: 1.0
Train Avg Loss   74: 0.071485

Train Avg F1   74: 0.796644254867939

Val Avg Loss   74: 0.065042

Val Avg F1   74:  0.5509049773755657

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 75
--------------------------------------------------------------
Epoch:   75        1 Batch loss: 0.072880 Batch F1: 0.33333333333333337
Epoch:   75        2 Batch loss: 0.077479 Batch F1: 0.4615384615384615
Epoch:   75        3 Batch loss: 0.075033 Batch F1: 0.888888888888889
Epoch:   75        4 Batch loss: 0.087871 Batch F1: 0.888888888888889
Epoch:   75        5 Batch loss: 0.080285 Batch F1: 0.888888888888889
Epoch:   75        6 Batch loss: 0.063428 Batch F1: 0.8571428571428571
Epoch:   75        7 Batch loss: 0.048910 Batch F1: 0.8
Epoch:   75        8 Batch loss: 0.072658 Batch F1: 0.5714285714285715
Epoch:   75        9 Batch loss: 0.078184 Batch F1: 0.4615384615384615
Epoch:   75       10 Batch loss: 0.045482 Batch F1: 0.5714285714285715
Epoch:   75       11 Batch loss: 0.068802 Batch F1: 0.4615384615384615
Epoch:   75       12 Batch loss: 0.068877 Batch F1: 0.7142857142857143
Train Avg Loss   75: 0.069991

Train Avg F1   75: 0.6582417582417582

Val Avg Loss   75: 0.062767

Val Avg F1   75:  0.9261278195488722

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 76
--------------------------------------------------------------
Epoch:   76        1 Batch loss: 0.084933 Batch F1: 0.88
Epoch:   76        2 Batch loss: 0.071817 Batch F1: 1.0
Epoch:   76        3 Batch loss: 0.055006 Batch F1: 1.0
Epoch:   76        4 Batch loss: 0.058798 Batch F1: 0.5454545454545454
Epoch:   76        5 Batch loss: 0.069324 Batch F1: 0.5714285714285715
Epoch:   76        6 Batch loss: 0.078328 Batch F1: 0.18181818181818182
Epoch:   76        7 Batch loss: 0.074110 Batch F1: 0.625
Epoch:   76        8 Batch loss: 0.077008 Batch F1: 0.8421052631578948
Epoch:   76        9 Batch loss: 0.085585 Batch F1: 0.9090909090909091
Epoch:   76       10 Batch loss: 0.076428 Batch F1: 0.8333333333333333
Epoch:   76       11 Batch loss: 0.057774 Batch F1: 1.0
Epoch:   76       12 Batch loss: 0.056951 Batch F1: 0.6666666666666666
Train Avg Loss   76: 0.070505

Train Avg F1   76: 0.7545747892458418

Val Avg Loss   76: 0.068772

Val Avg F1   76:  0.5509049773755655

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 77
--------------------------------------------------------------
Epoch:   77        1 Batch loss: 0.099030 Batch F1: 0.6
Epoch:   77        2 Batch loss: 0.089705 Batch F1: 0.18181818181818182
Epoch:   77        3 Batch loss: 0.060507 Batch F1: 0.9333333333333333
Epoch:   77        4 Batch loss: 0.061548 Batch F1: 0.9333333333333333
Epoch:   77        5 Batch loss: 0.092141 Batch F1: 0.8181818181818181
Epoch:   77        6 Batch loss: 0.055635 Batch F1: 1.0
Epoch:   77        7 Batch loss: 0.083597 Batch F1: 0.9090909090909091
Epoch:   77        8 Batch loss: 0.057476 Batch F1: 1.0
Epoch:   77        9 Batch loss: 0.083015 Batch F1: 0.9090909090909091
Epoch:   77       10 Batch loss: 0.052428 Batch F1: 0.9090909090909091
Epoch:   77       11 Batch loss: 0.048054 Batch F1: 1.0
Epoch:   77       12 Batch loss: 0.054683 Batch F1: 0.4
Train Avg Loss   77: 0.069818

Train Avg F1   77: 0.7994949494949495

Val Avg Loss   77: 0.069949

Val Avg F1   77:  0.5893665158371041

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 78
--------------------------------------------------------------
Epoch:   78        1 Batch loss: 0.066473 Batch F1: 0.6666666666666666
Epoch:   78        2 Batch loss: 0.044723 Batch F1: 0.4
Epoch:   78        3 Batch loss: 0.038656 Batch F1: 0.7499999999999999
Epoch:   78        4 Batch loss: 0.069155 Batch F1: 0.3636363636363636
Epoch:   78        5 Batch loss: 0.084724 Batch F1: 0.4615384615384615
Epoch:   78        6 Batch loss: 0.077974 Batch F1: 0.9600000000000001
Epoch:   78        7 Batch loss: 0.070400 Batch F1: 1.0
Epoch:   78        8 Batch loss: 0.094297 Batch F1: 0.7368421052631579
Epoch:   78        9 Batch loss: 0.068708 Batch F1: 0.9473684210526316
Epoch:   78       10 Batch loss: 0.084279 Batch F1: 0.888888888888889
Epoch:   78       11 Batch loss: 0.093026 Batch F1: 0.9166666666666666
Epoch:   78       12 Batch loss: 0.061847 Batch F1: 0.8571428571428571
Train Avg Loss   78: 0.071188

Train Avg F1   78: 0.7457292025713079

Val Avg Loss   78: 0.063838

Val Avg F1   78:  0.9305555555555556

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 79
--------------------------------------------------------------
Epoch:   79        1 Batch loss: 0.088419 Batch F1: 0.8
Epoch:   79        2 Batch loss: 0.086285 Batch F1: 0.8
Epoch:   79        3 Batch loss: 0.064236 Batch F1: 1.0
Epoch:   79        4 Batch loss: 0.077263 Batch F1: 0.9473684210526316
Epoch:   79        5 Batch loss: 0.057537 Batch F1: 0.7272727272727273
Epoch:   79        6 Batch loss: 0.061768 Batch F1: 0.7692307692307693
Epoch:   79        7 Batch loss: 0.108069 Batch F1: 0.375
Epoch:   79        8 Batch loss: 0.065556 Batch F1: 0.3636363636363636
Epoch:   79        9 Batch loss: 0.068702 Batch F1: 0.9090909090909091
Epoch:   79       10 Batch loss: 0.060160 Batch F1: 1.0
Epoch:   79       11 Batch loss: 0.076820 Batch F1: 0.3636363636363636
Epoch:   79       12 Batch loss: 0.068898 Batch F1: 0.4444444444444445
Train Avg Loss   79: 0.073643

Train Avg F1   79: 0.7083066665303508

Val Avg Loss   79: 0.064551

Val Avg F1   79:  0.5809523809523809

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 80
--------------------------------------------------------------
Epoch:   80        1 Batch loss: 0.043767 Batch F1: 0.6666666666666666
Epoch:   80        2 Batch loss: 0.055168 Batch F1: 0.33333333333333337
Epoch:   80        3 Batch loss: 0.102340 Batch F1: 0.3076923076923077
Epoch:   80        4 Batch loss: 0.083454 Batch F1: 0.42857142857142855
Epoch:   80        5 Batch loss: 0.072424 Batch F1: 0.5454545454545454
Epoch:   80        6 Batch loss: 0.067498 Batch F1: 1.0
Epoch:   80        7 Batch loss: 0.089851 Batch F1: 0.9285714285714286
Epoch:   80        8 Batch loss: 0.074431 Batch F1: 0.888888888888889
Epoch:   80        9 Batch loss: 0.073145 Batch F1: 0.8
Epoch:   80       10 Batch loss: 0.067147 Batch F1: 0.6666666666666666
Epoch:   80       11 Batch loss: 0.092653 Batch F1: 0.47058823529411764
Epoch:   80       12 Batch loss: 0.063700 Batch F1: 0.9090909090909091
Train Avg Loss   80: 0.073798

Train Avg F1   80: 0.6621270341858577

Val Avg Loss   80: 0.064985

Val Avg F1   80:  0.924579831932773

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 81
--------------------------------------------------------------
Epoch:   81        1 Batch loss: 0.061751 Batch F1: 0.9411764705882353
Epoch:   81        2 Batch loss: 0.067285 Batch F1: 0.9090909090909091
Epoch:   81        3 Batch loss: 0.083974 Batch F1: 0.9565217391304348
Epoch:   81        4 Batch loss: 0.067999 Batch F1: 0.8333333333333333
Epoch:   81        5 Batch loss: 0.055687 Batch F1: 0.33333333333333337
Epoch:   81        6 Batch loss: 0.074094 Batch F1: 0.5714285714285715
Epoch:   81        7 Batch loss: 0.080629 Batch F1: 0.33333333333333337
Epoch:   81        8 Batch loss: 0.079169 Batch F1: 0.4615384615384615
Epoch:   81        9 Batch loss: 0.081167 Batch F1: 0.631578947368421
Epoch:   81       10 Batch loss: 0.063390 Batch F1: 0.9411764705882353
Epoch:   81       11 Batch loss: 0.078505 Batch F1: 0.9473684210526316
Epoch:   81       12 Batch loss: 0.074281 Batch F1: 0.8333333333333333
Train Avg Loss   81: 0.072327

Train Avg F1   81: 0.7244344436766029

Val Avg Loss   81: 0.064425

Val Avg F1   81:  0.9368421052631579

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 82
--------------------------------------------------------------
Epoch:   82        1 Batch loss: 0.063246 Batch F1: 1.0
Epoch:   82        2 Batch loss: 0.101732 Batch F1: 0.7777777777777778
Epoch:   82        3 Batch loss: 0.044901 Batch F1: 1.0
Epoch:   82        4 Batch loss: 0.066963 Batch F1: 0.7499999999999999
Epoch:   82        5 Batch loss: 0.052889 Batch F1: 0.5
Epoch:   82        6 Batch loss: 0.041890 Batch F1: 0.7499999999999999
Epoch:   82        7 Batch loss: 0.054308 Batch F1: 0.5
Epoch:   82        8 Batch loss: 0.108467 Batch F1: 0.4444444444444445
Epoch:   82        9 Batch loss: 0.063357 Batch F1: 0.5
Epoch:   82       10 Batch loss: 0.096203 Batch F1: 0.7368421052631579
Epoch:   82       11 Batch loss: 0.082573 Batch F1: 0.9565217391304348
Epoch:   82       12 Batch loss: 0.085188 Batch F1: 0.9473684210526316
Train Avg Loss   82: 0.071810

Train Avg F1   82: 0.7385795406390372

Val Avg Loss   82: 0.067643

Val Avg F1   82:  0.924408950182944

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 83
--------------------------------------------------------------
Epoch:   83        1 Batch loss: 0.082332 Batch F1: 0.9
Epoch:   83        2 Batch loss: 0.068552 Batch F1: 0.8750000000000001
Epoch:   83        3 Batch loss: 0.055574 Batch F1: 1.0
Epoch:   83        4 Batch loss: 0.054482 Batch F1: 0.5714285714285715
Epoch:   83        5 Batch loss: 0.073158 Batch F1: 0.0
Epoch:   83        6 Batch loss: 0.087719 Batch F1: 0.0
Epoch:   83        7 Batch loss: 0.053062 Batch F1: 0.6666666666666666
Epoch:   83        8 Batch loss: 0.076564 Batch F1: 0.9
Epoch:   83        9 Batch loss: 0.086605 Batch F1: 0.7499999999999999
Epoch:   83       10 Batch loss: 0.077177 Batch F1: 0.9473684210526316
Epoch:   83       11 Batch loss: 0.094236 Batch F1: 0.9166666666666666
Epoch:   83       12 Batch loss: 0.072703 Batch F1: 0.6153846153846153
Train Avg Loss   83: 0.073514

Train Avg F1   83: 0.6785429117665961

Val Avg Loss   83: 0.065811

Val Avg F1   83:  0.7270676691729323

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 84
--------------------------------------------------------------
Epoch:   84        1 Batch loss: 0.085485 Batch F1: 0.42857142857142855
Epoch:   84        2 Batch loss: 0.064597 Batch F1: 0.7142857142857143
Epoch:   84        3 Batch loss: 0.073157 Batch F1: 0.9090909090909091
Epoch:   84        4 Batch loss: 0.078497 Batch F1: 0.8
Epoch:   84        5 Batch loss: 0.059221 Batch F1: 0.7272727272727273
Epoch:   84        6 Batch loss: 0.062329 Batch F1: 0.4
Epoch:   84        7 Batch loss: 0.077830 Batch F1: 0.625
Epoch:   84        8 Batch loss: 0.064923 Batch F1: 0.5454545454545454
Epoch:   84        9 Batch loss: 0.075066 Batch F1: 0.8571428571428571
Epoch:   84       10 Batch loss: 0.071771 Batch F1: 0.9411764705882353
Epoch:   84       11 Batch loss: 0.071204 Batch F1: 1.0
Epoch:   84       12 Batch loss: 0.072515 Batch F1: 0.5
Train Avg Loss   84: 0.071383

Train Avg F1   84: 0.7039995543672015

Val Avg Loss   84: 0.064885

Val Avg F1   84:  0.5752060439560439

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 85
--------------------------------------------------------------
Epoch:   85        1 Batch loss: 0.051716 Batch F1: 0.7499999999999999
Epoch:   85        2 Batch loss: 0.099538 Batch F1: 0.5
Epoch:   85        3 Batch loss: 0.066756 Batch F1: 0.625
Epoch:   85        4 Batch loss: 0.093563 Batch F1: 0.42857142857142855
Epoch:   85        5 Batch loss: 0.062787 Batch F1: 1.0
Epoch:   85        6 Batch loss: 0.090980 Batch F1: 0.9473684210526316
Epoch:   85        7 Batch loss: 0.060414 Batch F1: 0.6
Epoch:   85        8 Batch loss: 0.118468 Batch F1: 0.14285714285714288
Epoch:   85        9 Batch loss: 0.046564 Batch F1: 0.7499999999999999
Epoch:   85       10 Batch loss: 0.068075 Batch F1: 0.2222222222222222
Epoch:   85       11 Batch loss: 0.074911 Batch F1: 0.7058823529411764
Epoch:   85       12 Batch loss: 0.061402 Batch F1: 1.0
Train Avg Loss   85: 0.074598

Train Avg F1   85: 0.6393251306370501

Val Avg Loss   85: 0.066459

Val Avg F1   85:  0.9196859903381642

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 86
--------------------------------------------------------------
Epoch:   86        1 Batch loss: 0.074543 Batch F1: 0.9411764705882353
Epoch:   86        2 Batch loss: 0.081926 Batch F1: 0.9090909090909091
Epoch:   86        3 Batch loss: 0.065323 Batch F1: 0.9333333333333333
Epoch:   86        4 Batch loss: 0.061902 Batch F1: 0.0
Epoch:   86        5 Batch loss: 0.113842 Batch F1: 0.2857142857142857
Epoch:   86        6 Batch loss: 0.067230 Batch F1: 0.6666666666666666
Epoch:   86        7 Batch loss: 0.074896 Batch F1: 0.42857142857142855
Epoch:   86        8 Batch loss: 0.069444 Batch F1: 1.0
Epoch:   86        9 Batch loss: 0.077552 Batch F1: 0.8750000000000001
Epoch:   86       10 Batch loss: 0.057311 Batch F1: 0.9411764705882353
Epoch:   86       11 Batch loss: 0.069205 Batch F1: 0.7058823529411764
Epoch:   86       12 Batch loss: 0.080553 Batch F1: 0.888888888888889
Train Avg Loss   86: 0.074477

Train Avg F1   86: 0.7146250671985966

Val Avg Loss   86: 0.069089

Val Avg F1   86:  0.5903318903318904

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 87
--------------------------------------------------------------
Epoch:   87        1 Batch loss: 0.057913 Batch F1: 0.4444444444444445
Epoch:   87        2 Batch loss: 0.107481 Batch F1: 0.0
Epoch:   87        3 Batch loss: 0.083601 Batch F1: 0.5714285714285715
Epoch:   87        4 Batch loss: 0.064594 Batch F1: 0.5
Epoch:   87        5 Batch loss: 0.058528 Batch F1: 0.923076923076923
Epoch:   87        6 Batch loss: 0.082131 Batch F1: 0.4
Epoch:   87        7 Batch loss: 0.073494 Batch F1: 0.6666666666666666
Epoch:   87        8 Batch loss: 0.068851 Batch F1: 0.923076923076923
Epoch:   87        9 Batch loss: 0.073633 Batch F1: 0.8571428571428571
Epoch:   87       10 Batch loss: 0.070891 Batch F1: 0.6153846153846153
Epoch:   87       11 Batch loss: 0.056418 Batch F1: 0.7692307692307693
Epoch:   87       12 Batch loss: 0.098577 Batch F1: 0.16666666666666669
Train Avg Loss   87: 0.074676

Train Avg F1   87: 0.5697598697598697

Val Avg Loss   87: 0.064492

Val Avg F1   87:  0.9233500417710944

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 88
--------------------------------------------------------------
Epoch:   88        1 Batch loss: 0.063335 Batch F1: 1.0
Epoch:   88        2 Batch loss: 0.056608 Batch F1: 1.0
Epoch:   88        3 Batch loss: 0.068893 Batch F1: 0.9411764705882353
Epoch:   88        4 Batch loss: 0.064037 Batch F1: 0.9523809523809523
Epoch:   88        5 Batch loss: 0.084299 Batch F1: 0.9
Epoch:   88        6 Batch loss: 0.077001 Batch F1: 0.8571428571428571
Epoch:   88        7 Batch loss: 0.048547 Batch F1: 1.0
Epoch:   88        8 Batch loss: 0.058539 Batch F1: 0.7692307692307693
Epoch:   88        9 Batch loss: 0.098879 Batch F1: 0.0
Epoch:   88       10 Batch loss: 0.075034 Batch F1: 0.5714285714285715
Epoch:   88       11 Batch loss: 0.069785 Batch F1: 0.6666666666666666
Epoch:   88       12 Batch loss: 0.096739 Batch F1: 0.19999999999999998
Train Avg Loss   88: 0.071808

Train Avg F1   88: 0.7381688572865043

Val Avg Loss   88: 0.063315

Val Avg F1   88:  0.940780660090123

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 89
--------------------------------------------------------------
Epoch:   89        1 Batch loss: 0.044636 Batch F1: 1.0
Epoch:   89        2 Batch loss: 0.078967 Batch F1: 0.9090909090909091
Epoch:   89        3 Batch loss: 0.045009 Batch F1: 0.8571428571428571
Epoch:   89        4 Batch loss: 0.078709 Batch F1: 0.9565217391304348
Epoch:   89        5 Batch loss: 0.085036 Batch F1: 0.9285714285714286
Epoch:   89        6 Batch loss: 0.071652 Batch F1: 0.8333333333333333
Epoch:   89        7 Batch loss: 0.072295 Batch F1: 0.888888888888889
Epoch:   89        8 Batch loss: 0.075290 Batch F1: 0.9
Epoch:   89        9 Batch loss: 0.072081 Batch F1: 0.8750000000000001
Epoch:   89       10 Batch loss: 0.067124 Batch F1: 0.9090909090909091
Epoch:   89       11 Batch loss: 0.077352 Batch F1: 0.9565217391304348
Epoch:   89       12 Batch loss: 0.067456 Batch F1: 1.0
Train Avg Loss   89: 0.069634

Train Avg F1   89: 0.9178468170315998

Val Avg Loss   89: 0.064165

Val Avg F1   89:  0.580392156862745

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 90
--------------------------------------------------------------
Epoch:   90        1 Batch loss: 0.067504 Batch F1: 0.0
Epoch:   90        2 Batch loss: 0.079894 Batch F1: 0.19999999999999998
Epoch:   90        3 Batch loss: 0.079473 Batch F1: 0.42857142857142855
Epoch:   90        4 Batch loss: 0.059625 Batch F1: 0.7692307692307693
Epoch:   90        5 Batch loss: 0.063977 Batch F1: 0.2222222222222222
Epoch:   90        6 Batch loss: 0.073221 Batch F1: 0.9090909090909091
Epoch:   90        7 Batch loss: 0.078208 Batch F1: 0.8
Epoch:   90        8 Batch loss: 0.058132 Batch F1: 1.0
Epoch:   90        9 Batch loss: 0.071902 Batch F1: 0.8571428571428571
Epoch:   90       10 Batch loss: 0.081935 Batch F1: 1.0
Epoch:   90       11 Batch loss: 0.081263 Batch F1: 0.5
Epoch:   90       12 Batch loss: 0.059245 Batch F1: 0.7692307692307693
Train Avg Loss   90: 0.071198

Train Avg F1   90: 0.6212907462907463

Val Avg Loss   90: 0.063742

Val Avg F1   90:  0.5729166666666666

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 91
--------------------------------------------------------------
Epoch:   91        1 Batch loss: 0.063019 Batch F1: 0.5454545454545454
Epoch:   91        2 Batch loss: 0.045225 Batch F1: 0.0
Epoch:   91        3 Batch loss: 0.063723 Batch F1: 0.6153846153846153
Epoch:   91        4 Batch loss: 0.067121 Batch F1: 0.3636363636363636
Epoch:   91        5 Batch loss: 0.085709 Batch F1: 0.5714285714285715
Epoch:   91        6 Batch loss: 0.086144 Batch F1: 0.6956521739130436
Epoch:   91        7 Batch loss: 0.085174 Batch F1: 0.9473684210526316
Epoch:   91        8 Batch loss: 0.048231 Batch F1: 1.0
Epoch:   91        9 Batch loss: 0.094419 Batch F1: 0.88
Epoch:   91       10 Batch loss: 0.074503 Batch F1: 0.9166666666666666
Epoch:   91       11 Batch loss: 0.059569 Batch F1: 1.0
Epoch:   91       12 Batch loss: 0.072261 Batch F1: 0.8
Train Avg Loss   91: 0.070425

Train Avg F1   91: 0.6946326131280366

Val Avg Loss   91: 0.063709

Val Avg F1   91:  0.9199922884133409

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 92
--------------------------------------------------------------
Epoch:   92        1 Batch loss: 0.072218 Batch F1: 0.7499999999999999
Epoch:   92        2 Batch loss: 0.058947 Batch F1: 0.0
Epoch:   92        3 Batch loss: 0.063878 Batch F1: 0.0
Epoch:   92        4 Batch loss: 0.091779 Batch F1: 0.4
Epoch:   92        5 Batch loss: 0.086403 Batch F1: 0.6
Epoch:   92        6 Batch loss: 0.085616 Batch F1: 0.8695652173913044
Epoch:   92        7 Batch loss: 0.086349 Batch F1: 0.9090909090909091
Epoch:   92        8 Batch loss: 0.066361 Batch F1: 1.0
Epoch:   92        9 Batch loss: 0.090852 Batch F1: 0.631578947368421
Epoch:   92       10 Batch loss: 0.054805 Batch F1: 0.6666666666666666
Epoch:   92       11 Batch loss: 0.065032 Batch F1: 0.6
Epoch:   92       12 Batch loss: 0.067914 Batch F1: 0.4444444444444445
Train Avg Loss   92: 0.074179

Train Avg F1   92: 0.5726121820801455

Val Avg Loss   92: 0.064764

Val Avg F1   92:  0.593956043956044

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 93
--------------------------------------------------------------
Epoch:   93        1 Batch loss: 0.071596 Batch F1: 0.4615384615384615
Epoch:   93        2 Batch loss: 0.070656 Batch F1: 0.6666666666666666
Epoch:   93        3 Batch loss: 0.074918 Batch F1: 0.962962962962963
Epoch:   93        4 Batch loss: 0.086517 Batch F1: 0.9090909090909091
Epoch:   93        5 Batch loss: 0.069452 Batch F1: 1.0
Epoch:   93        6 Batch loss: 0.062141 Batch F1: 1.0
Epoch:   93        7 Batch loss: 0.101333 Batch F1: 0.0
Epoch:   93        8 Batch loss: 0.111599 Batch F1: 0.4
Epoch:   93        9 Batch loss: 0.061279 Batch F1: 0.9333333333333333
Epoch:   93       10 Batch loss: 0.065748 Batch F1: 0.8000000000000002
Epoch:   93       11 Batch loss: 0.071264 Batch F1: 0.9333333333333333
Epoch:   93       12 Batch loss: 0.079684 Batch F1: 0.2222222222222222
Train Avg Loss   93: 0.077182

Train Avg F1   93: 0.6907623240956574

Val Avg Loss   93: 0.068020

Val Avg F1   93:  0.5676937441643325

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 94
--------------------------------------------------------------
Epoch:   94        1 Batch loss: 0.080301 Batch F1: 0.42857142857142855
Epoch:   94        2 Batch loss: 0.035898 Batch F1: 0.7499999999999999
Epoch:   94        3 Batch loss: 0.090504 Batch F1: 0.7368421052631579
Epoch:   94        4 Batch loss: 0.074354 Batch F1: 1.0
Epoch:   94        5 Batch loss: 0.084784 Batch F1: 0.9166666666666666
Epoch:   94        6 Batch loss: 0.090119 Batch F1: 0.7272727272727273
Epoch:   94        7 Batch loss: 0.065486 Batch F1: 1.0
Epoch:   94        8 Batch loss: 0.077540 Batch F1: 0.25
Epoch:   94        9 Batch loss: 0.105702 Batch F1: 0.4
Epoch:   94       10 Batch loss: 0.060862 Batch F1: 0.6666666666666666
Epoch:   94       11 Batch loss: 0.084856 Batch F1: 0.9090909090909091
Epoch:   94       12 Batch loss: 0.055339 Batch F1: 0.8
Train Avg Loss   94: 0.075479

Train Avg F1   94: 0.7154258752942964

Val Avg Loss   94: 0.064926

Val Avg F1   94:  0.9023809523809525

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 95
--------------------------------------------------------------
Epoch:   95        1 Batch loss: 0.064145 Batch F1: 0.923076923076923
Epoch:   95        2 Batch loss: 0.044463 Batch F1: 0.5
Epoch:   95        3 Batch loss: 0.117229 Batch F1: 0.47619047619047616
Epoch:   95        4 Batch loss: 0.060119 Batch F1: 0.6666666666666666
Epoch:   95        5 Batch loss: 0.074112 Batch F1: 0.8750000000000001
Epoch:   95        6 Batch loss: 0.067939 Batch F1: 1.0
Epoch:   95        7 Batch loss: 0.088309 Batch F1: 0.8571428571428571
Epoch:   95        8 Batch loss: 0.075989 Batch F1: 0.8
Epoch:   95        9 Batch loss: 0.071935 Batch F1: 0.888888888888889
Epoch:   95       10 Batch loss: 0.067271 Batch F1: 0.9411764705882353
Epoch:   95       11 Batch loss: 0.078366 Batch F1: 0.625
Epoch:   95       12 Batch loss: 0.065538 Batch F1: 0.4444444444444445
Train Avg Loss   95: 0.072951

Train Avg F1   95: 0.749798893916541

Val Avg Loss   95: 0.066558

Val Avg F1   95:  0.603030303030303

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 96
--------------------------------------------------------------
Epoch:   96        1 Batch loss: 0.082797 Batch F1: 0.5333333333333333
Epoch:   96        2 Batch loss: 0.070050 Batch F1: 0.25
Epoch:   96        3 Batch loss: 0.077982 Batch F1: 0.42857142857142855
Epoch:   96        4 Batch loss: 0.065011 Batch F1: 0.8
Epoch:   96        5 Batch loss: 0.083754 Batch F1: 0.6153846153846153
Epoch:   96        6 Batch loss: 0.078481 Batch F1: 0.5
Epoch:   96        7 Batch loss: 0.068331 Batch F1: 0.5714285714285715
Epoch:   96        8 Batch loss: 0.078921 Batch F1: 0.47058823529411764
Epoch:   96        9 Batch loss: 0.069891 Batch F1: 0.9333333333333333
Epoch:   96       10 Batch loss: 0.059769 Batch F1: 1.0
Epoch:   96       11 Batch loss: 0.065958 Batch F1: 0.9333333333333333
Epoch:   96       12 Batch loss: 0.057996 Batch F1: 0.5
Train Avg Loss   96: 0.071578

Train Avg F1   96: 0.6279977375565612

Val Avg Loss   96: 0.064566

Val Avg F1   96:  0.5849358974358974

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 97
--------------------------------------------------------------
Epoch:   97        1 Batch loss: 0.060269 Batch F1: 0.4444444444444445
Epoch:   97        2 Batch loss: 0.092804 Batch F1: 0.2857142857142857
Epoch:   97        3 Batch loss: 0.085511 Batch F1: 0.3076923076923077
Epoch:   97        4 Batch loss: 0.062438 Batch F1: 0.9333333333333333
Epoch:   97        5 Batch loss: 0.078579 Batch F1: 0.9565217391304348
Epoch:   97        6 Batch loss: 0.061151 Batch F1: 0.888888888888889
Epoch:   97        7 Batch loss: 0.075677 Batch F1: 0.9090909090909091
Epoch:   97        8 Batch loss: 0.070598 Batch F1: 0.9333333333333333
Epoch:   97        9 Batch loss: 0.067586 Batch F1: 0.923076923076923
Epoch:   97       10 Batch loss: 0.057616 Batch F1: 1.0
Epoch:   97       11 Batch loss: 0.088571 Batch F1: 0.42857142857142855
Epoch:   97       12 Batch loss: 0.059911 Batch F1: 0.33333333333333337
Train Avg Loss   97: 0.071726

Train Avg F1   97: 0.6953334105508019

Val Avg Loss   97: 0.073136

Val Avg F1   97:  0.5734848484848485

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 98
--------------------------------------------------------------
Epoch:   98        1 Batch loss: 0.090417 Batch F1: 0.42857142857142855
Epoch:   98        2 Batch loss: 0.045327 Batch F1: 0.8
Epoch:   98        3 Batch loss: 0.099931 Batch F1: 0.4444444444444445
Epoch:   98        4 Batch loss: 0.084060 Batch F1: 1.0
Epoch:   98        5 Batch loss: 0.067009 Batch F1: 0.8571428571428571
Epoch:   98        6 Batch loss: 0.066764 Batch F1: 0.9333333333333333
Epoch:   98        7 Batch loss: 0.060895 Batch F1: 1.0
Epoch:   98        8 Batch loss: 0.050983 Batch F1: 1.0
Epoch:   98        9 Batch loss: 0.062941 Batch F1: 0.0
Epoch:   98       10 Batch loss: 0.098926 Batch F1: 0.3076923076923077
Epoch:   98       11 Batch loss: 0.105145 Batch F1: 0.631578947368421
Epoch:   98       12 Batch loss: 0.115160 Batch F1: 0.3076923076923077
Train Avg Loss   98: 0.078963

Train Avg F1   98: 0.6425379688537584

Val Avg Loss   98: 0.065448

Val Avg F1   98:  0.6003342245989305

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 99
--------------------------------------------------------------
Epoch:   99        1 Batch loss: 0.056295 Batch F1: 0.6666666666666666
Epoch:   99        2 Batch loss: 0.065235 Batch F1: 0.6666666666666666
Epoch:   99        3 Batch loss: 0.069643 Batch F1: 0.9333333333333333
Epoch:   99        4 Batch loss: 0.054033 Batch F1: 0.8333333333333333
Epoch:   99        5 Batch loss: 0.091622 Batch F1: 0.6666666666666666
Epoch:   99        6 Batch loss: 0.084983 Batch F1: 0.8
Epoch:   99        7 Batch loss: 0.074400 Batch F1: 0.5454545454545454
Epoch:   99        8 Batch loss: 0.085004 Batch F1: 0.5333333333333333
Epoch:   99        9 Batch loss: 0.071174 Batch F1: 0.9090909090909091
Epoch:   99       10 Batch loss: 0.073061 Batch F1: 0.9
Epoch:   99       11 Batch loss: 0.066434 Batch F1: 0.8333333333333333
Epoch:   99       12 Batch loss: 0.081989 Batch F1: 0.888888888888889
Train Avg Loss   99: 0.072823

Train Avg F1   99: 0.7647306397306397

Val Avg Loss   99: 0.064231

Val Avg F1   99:  0.9237012987012987

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 100
--------------------------------------------------------------
Epoch:  100        1 Batch loss: 0.067452 Batch F1: 0.9333333333333333
Epoch:  100        2 Batch loss: 0.080771 Batch F1: 0.9565217391304348
Epoch:  100        3 Batch loss: 0.040997 Batch F1: 1.0
Epoch:  100        4 Batch loss: 0.072478 Batch F1: 0.8333333333333333
Epoch:  100        5 Batch loss: 0.084976 Batch F1: 0.3076923076923077
Epoch:  100        6 Batch loss: 0.097071 Batch F1: 0.0
Epoch:  100        7 Batch loss: 0.074264 Batch F1: 0.6666666666666666
Epoch:  100        8 Batch loss: 0.055116 Batch F1: 0.8571428571428571
Epoch:  100        9 Batch loss: 0.097414 Batch F1: 0.9166666666666666
Epoch:  100       10 Batch loss: 0.047633 Batch F1: 1.0
Epoch:  100       11 Batch loss: 0.070881 Batch F1: 0.8333333333333333
Epoch:  100       12 Batch loss: 0.073226 Batch F1: 0.9565217391304348
Train Avg Loss  100: 0.071856

Train Avg F1  100: 0.7717676647024474

Val Avg Loss  100: 0.064979

Val Avg F1  100:  0.9222222222222223

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 101
--------------------------------------------------------------
Epoch:  101        1 Batch loss: 0.089053 Batch F1: 0.6666666666666666
Epoch:  101        2 Batch loss: 0.073990 Batch F1: 0.9473684210526316
Epoch:  101        3 Batch loss: 0.081297 Batch F1: 0.962962962962963
Epoch:  101        4 Batch loss: 0.076605 Batch F1: 0.8750000000000001
Epoch:  101        5 Batch loss: 0.062521 Batch F1: 0.923076923076923
Epoch:  101        6 Batch loss: 0.073197 Batch F1: 0.5555555555555556
Epoch:  101        7 Batch loss: 0.057519 Batch F1: 0.6666666666666666
Epoch:  101        8 Batch loss: 0.090735 Batch F1: 0.33333333333333337
Epoch:  101        9 Batch loss: 0.053478 Batch F1: 0.5
Epoch:  101       10 Batch loss: 0.046918 Batch F1: 0.7272727272727273
Epoch:  101       11 Batch loss: 0.055647 Batch F1: 0.5
Epoch:  101       12 Batch loss: 0.086503 Batch F1: 0.33333333333333337
Train Avg Loss  101: 0.070622

Train Avg F1  101: 0.6659363824934

Val Avg Loss  101: 0.065108

Val Avg F1  101:  0.5840852130325814

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 102
--------------------------------------------------------------
Epoch:  102        1 Batch loss: 0.078621 Batch F1: 0.33333333333333337
Epoch:  102        2 Batch loss: 0.096130 Batch F1: 0.2666666666666667
Epoch:  102        3 Batch loss: 0.054253 Batch F1: 0.8571428571428571
Epoch:  102        4 Batch loss: 0.082436 Batch F1: 0.8
Epoch:  102        5 Batch loss: 0.060134 Batch F1: 0.9090909090909091
Epoch:  102        6 Batch loss: 0.070484 Batch F1: 0.9523809523809523
Epoch:  102        7 Batch loss: 0.068454 Batch F1: 0.7692307692307693
Epoch:  102        8 Batch loss: 0.052728 Batch F1: 0.5
Epoch:  102        9 Batch loss: 0.076099 Batch F1: 0.4
Epoch:  102       10 Batch loss: 0.076358 Batch F1: 0.6666666666666666
Epoch:  102       11 Batch loss: 0.069114 Batch F1: 1.0
Epoch:  102       12 Batch loss: 0.070027 Batch F1: 0.9411764705882353
Train Avg Loss  102: 0.071236

Train Avg F1  102: 0.6996407187583659

Val Avg Loss  102: 0.063343

Val Avg F1  102:  0.9205291079156779

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 103
--------------------------------------------------------------
Epoch:  103        1 Batch loss: 0.069532 Batch F1: 0.888888888888889
Epoch:  103        2 Batch loss: 0.077143 Batch F1: 0.8
Epoch:  103        3 Batch loss: 0.058353 Batch F1: 1.0
Epoch:  103        4 Batch loss: 0.070425 Batch F1: 1.0
Epoch:  103        5 Batch loss: 0.091424 Batch F1: 0.5263157894736842
Epoch:  103        6 Batch loss: 0.068163 Batch F1: 0.4615384615384615
Epoch:  103        7 Batch loss: 0.067621 Batch F1: 1.0
Epoch:  103        8 Batch loss: 0.058723 Batch F1: 1.0
Epoch:  103        9 Batch loss: 0.089032 Batch F1: 0.8181818181818181
Epoch:  103       10 Batch loss: 0.061806 Batch F1: 0.8571428571428571
Epoch:  103       11 Batch loss: 0.061474 Batch F1: 0.8750000000000001
Epoch:  103       12 Batch loss: 0.060141 Batch F1: 0.9090909090909091
Train Avg Loss  103: 0.069486

Train Avg F1  103: 0.8446798936930516

Val Avg Loss  103: 0.063201

Val Avg F1  103:  0.5756118881118881

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 104
--------------------------------------------------------------
Epoch:  104        1 Batch loss: 0.085191 Batch F1: 0.5333333333333333
Epoch:  104        2 Batch loss: 0.073188 Batch F1: 0.7058823529411764
Epoch:  104        3 Batch loss: 0.067984 Batch F1: 0.5333333333333333
Epoch:  104        4 Batch loss: 0.078661 Batch F1: 0.9
Epoch:  104        5 Batch loss: 0.081208 Batch F1: 0.9166666666666666
Epoch:  104        6 Batch loss: 0.066492 Batch F1: 0.9333333333333333
Epoch:  104        7 Batch loss: 0.065653 Batch F1: 0.923076923076923
Epoch:  104        8 Batch loss: 0.067895 Batch F1: 0.8333333333333333
Epoch:  104        9 Batch loss: 0.040434 Batch F1: 0.4
Epoch:  104       10 Batch loss: 0.048324 Batch F1: 0.5714285714285715
Epoch:  104       11 Batch loss: 0.095685 Batch F1: 0.0
Epoch:  104       12 Batch loss: 0.098878 Batch F1: 0.33333333333333337
Train Avg Loss  104: 0.072466

Train Avg F1  104: 0.6319767650650003

Val Avg Loss  104: 0.066167

Val Avg F1  104:  0.5968094405594406

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 105
--------------------------------------------------------------
Epoch:  105        1 Batch loss: 0.071198 Batch F1: 0.6153846153846153
Epoch:  105        2 Batch loss: 0.075107 Batch F1: 0.9523809523809523
Epoch:  105        3 Batch loss: 0.083764 Batch F1: 0.8750000000000001
Epoch:  105        4 Batch loss: 0.069722 Batch F1: 0.8571428571428571
Epoch:  105        5 Batch loss: 0.071590 Batch F1: 0.9
Epoch:  105        6 Batch loss: 0.065768 Batch F1: 0.9523809523809523
Epoch:  105        7 Batch loss: 0.066011 Batch F1: 0.9090909090909091
Epoch:  105        8 Batch loss: 0.060497 Batch F1: 0.6666666666666666
Epoch:  105        9 Batch loss: 0.064485 Batch F1: 0.6666666666666666
Epoch:  105       10 Batch loss: 0.105870 Batch F1: 0.375
Epoch:  105       11 Batch loss: 0.050891 Batch F1: 0.6666666666666666
Epoch:  105       12 Batch loss: 0.075065 Batch F1: 0.888888888888889
Train Avg Loss  105: 0.071664

Train Avg F1  105: 0.7771057646057646

Val Avg Loss  105: 0.069501

Val Avg F1  105:  0.9261437908496732

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 106
--------------------------------------------------------------
Epoch:  106        1 Batch loss: 0.084055 Batch F1: 0.8235294117647058
Epoch:  106        2 Batch loss: 0.081475 Batch F1: 0.923076923076923
Epoch:  106        3 Batch loss: 0.055370 Batch F1: 1.0
Epoch:  106        4 Batch loss: 0.094703 Batch F1: 0.2857142857142857
Epoch:  106        5 Batch loss: 0.070457 Batch F1: 0.5454545454545454
Epoch:  106        6 Batch loss: 0.030010 Batch F1: 1.0
Epoch:  106        7 Batch loss: 0.076021 Batch F1: 0.7058823529411764
Epoch:  106        8 Batch loss: 0.091639 Batch F1: 0.19999999999999998
Epoch:  106        9 Batch loss: 0.079991 Batch F1: 0.4615384615384615
Epoch:  106       10 Batch loss: 0.069451 Batch F1: 0.7368421052631579
Epoch:  106       11 Batch loss: 0.067317 Batch F1: 1.0
Epoch:  106       12 Batch loss: 0.069596 Batch F1: 0.9333333333333333
Train Avg Loss  106: 0.072507

Train Avg F1  106: 0.7179476182572158

Val Avg Loss  106: 0.068252

Val Avg F1  106:  0.8826754385964911

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 107
--------------------------------------------------------------
Epoch:  107        1 Batch loss: 0.087832 Batch F1: 0.8235294117647058
Epoch:  107        2 Batch loss: 0.064880 Batch F1: 0.888888888888889
Epoch:  107        3 Batch loss: 0.068918 Batch F1: 0.9411764705882353
Epoch:  107        4 Batch loss: 0.066141 Batch F1: 0.8333333333333333
Epoch:  107        5 Batch loss: 0.054428 Batch F1: 0.7272727272727273
Epoch:  107        6 Batch loss: 0.058165 Batch F1: 0.6666666666666666
Epoch:  107        7 Batch loss: 0.068978 Batch F1: 0.6153846153846153
Epoch:  107        8 Batch loss: 0.086834 Batch F1: 0.5
Epoch:  107        9 Batch loss: 0.059833 Batch F1: 0.2857142857142857
Epoch:  107       10 Batch loss: 0.093486 Batch F1: 0.3076923076923077
Epoch:  107       11 Batch loss: 0.086924 Batch F1: 0.9090909090909091
Epoch:  107       12 Batch loss: 0.080046 Batch F1: 0.9565217391304348
Train Avg Loss  107: 0.073039

Train Avg F1  107: 0.7046059462939258

Val Avg Loss  107: 0.082736

Val Avg F1  107:  0.8191484145145472

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 108
--------------------------------------------------------------
Epoch:  108        1 Batch loss: 0.085929 Batch F1: 1.0
Epoch:  108        2 Batch loss: 0.083982 Batch F1: 0.8421052631578948
Epoch:  108        3 Batch loss: 0.064365 Batch F1: 0.4444444444444445
Epoch:  108        4 Batch loss: 0.040815 Batch F1: 0.0
Epoch:  108        5 Batch loss: 0.103130 Batch F1: 0.5882352941176471
Epoch:  108        6 Batch loss: 0.072341 Batch F1: 0.625
Epoch:  108        7 Batch loss: 0.047397 Batch F1: 0.7499999999999999
Epoch:  108        8 Batch loss: 0.086945 Batch F1: 0.42857142857142855
Epoch:  108        9 Batch loss: 0.066645 Batch F1: 0.0
Epoch:  108       10 Batch loss: 0.089084 Batch F1: 0.9
Epoch:  108       11 Batch loss: 0.084061 Batch F1: 0.7272727272727273
Epoch:  108       12 Batch loss: 0.103573 Batch F1: 0.962962962962963
Train Avg Loss  108: 0.077356

Train Avg F1  108: 0.6057160100439255

Val Avg Loss  108: 0.067711

Val Avg F1  108:  0.92421955624355

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 109
--------------------------------------------------------------
Epoch:  109        1 Batch loss: 0.083412 Batch F1: 0.888888888888889
Epoch:  109        2 Batch loss: 0.079068 Batch F1: 0.6666666666666666
Epoch:  109        3 Batch loss: 0.068411 Batch F1: 0.8
Epoch:  109        4 Batch loss: 0.066902 Batch F1: 0.5454545454545454
Epoch:  109        5 Batch loss: 0.100639 Batch F1: 0.375
Epoch:  109        6 Batch loss: 0.064875 Batch F1: 0.6153846153846153
Epoch:  109        7 Batch loss: 0.059473 Batch F1: 0.9411764705882353
Epoch:  109        8 Batch loss: 0.069913 Batch F1: 0.6666666666666666
Epoch:  109        9 Batch loss: 0.083259 Batch F1: 0.9523809523809523
Epoch:  109       10 Batch loss: 0.057716 Batch F1: 0.7272727272727273
Epoch:  109       11 Batch loss: 0.069618 Batch F1: 0.5333333333333333
Epoch:  109       12 Batch loss: 0.081301 Batch F1: 0.3636363636363636
Train Avg Loss  109: 0.073716

Train Avg F1  109: 0.6729884358560829

Val Avg Loss  109: 0.064401

Val Avg F1  109:  0.4716666666666667

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 110
--------------------------------------------------------------
Epoch:  110        1 Batch loss: 0.061907 Batch F1: 0.4444444444444445
Epoch:  110        2 Batch loss: 0.064147 Batch F1: 0.5454545454545454
Epoch:  110        3 Batch loss: 0.049580 Batch F1: 0.4444444444444445
Epoch:  110        4 Batch loss: 0.071399 Batch F1: 0.4
Epoch:  110        5 Batch loss: 0.068037 Batch F1: 0.6153846153846153
Epoch:  110        6 Batch loss: 0.103377 Batch F1: 0.14285714285714288
Epoch:  110        7 Batch loss: 0.079197 Batch F1: 0.9565217391304348
Epoch:  110        8 Batch loss: 0.077158 Batch F1: 0.8
Epoch:  110        9 Batch loss: 0.063058 Batch F1: 1.0
Epoch:  110       10 Batch loss: 0.089563 Batch F1: 0.8235294117647058
Epoch:  110       11 Batch loss: 0.065408 Batch F1: 1.0
Epoch:  110       12 Batch loss: 0.056740 Batch F1: 0.923076923076923
Train Avg Loss  110: 0.070798

Train Avg F1  110: 0.6746427722131046

Val Avg Loss  110: 0.064101

Val Avg F1  110:  0.7395833333333333

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 111
--------------------------------------------------------------
Epoch:  111        1 Batch loss: 0.071184 Batch F1: 0.6666666666666666
Epoch:  111        2 Batch loss: 0.060646 Batch F1: 0.7692307692307693
Epoch:  111        3 Batch loss: 0.069266 Batch F1: 0.4
Epoch:  111        4 Batch loss: 0.069411 Batch F1: 0.4615384615384615
Epoch:  111        5 Batch loss: 0.085443 Batch F1: 0.0
Epoch:  111        6 Batch loss: 0.073318 Batch F1: 0.7058823529411764
Epoch:  111        7 Batch loss: 0.107843 Batch F1: 0.8750000000000001
Epoch:  111        8 Batch loss: 0.065165 Batch F1: 0.8333333333333333
Epoch:  111        9 Batch loss: 0.063157 Batch F1: 1.0
Epoch:  111       10 Batch loss: 0.051581 Batch F1: 1.0
Epoch:  111       11 Batch loss: 0.064762 Batch F1: 0.9411764705882353
Epoch:  111       12 Batch loss: 0.070880 Batch F1: 0.2857142857142857
Train Avg Loss  111: 0.071055

Train Avg F1  111: 0.6615451950010773

Val Avg Loss  111: 0.063962

Val Avg F1  111:  0.5868131868131868

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 112
--------------------------------------------------------------
Epoch:  112        1 Batch loss: 0.057281 Batch F1: 0.8421052631578948
Epoch:  112        2 Batch loss: 0.044084 Batch F1: 0.0
Epoch:  112        3 Batch loss: 0.075301 Batch F1: 0.6666666666666666
Epoch:  112        4 Batch loss: 0.083147 Batch F1: 0.2222222222222222
Epoch:  112        5 Batch loss: 0.091626 Batch F1: 0.4444444444444445
Epoch:  112        6 Batch loss: 0.105660 Batch F1: 0.2666666666666667
Epoch:  112        7 Batch loss: 0.080809 Batch F1: 0.8235294117647058
Epoch:  112        8 Batch loss: 0.077233 Batch F1: 0.9333333333333333
Epoch:  112        9 Batch loss: 0.065596 Batch F1: 1.0
Epoch:  112       10 Batch loss: 0.076378 Batch F1: 0.888888888888889
Epoch:  112       11 Batch loss: 0.069329 Batch F1: 0.888888888888889
Epoch:  112       12 Batch loss: 0.043875 Batch F1: 1.0
Train Avg Loss  112: 0.072527

Train Avg F1  112: 0.6647288155028094

Val Avg Loss  112: 0.067883

Val Avg F1  112:  0.5850961538461539

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 113
--------------------------------------------------------------
Epoch:  113        1 Batch loss: 0.056445 Batch F1: 0.7272727272727273
Epoch:  113        2 Batch loss: 0.095495 Batch F1: 0.0
Epoch:  113        3 Batch loss: 0.096497 Batch F1: 0.42857142857142855
Epoch:  113        4 Batch loss: 0.080126 Batch F1: 0.8421052631578948
Epoch:  113        5 Batch loss: 0.069220 Batch F1: 0.923076923076923
Epoch:  113        6 Batch loss: 0.067807 Batch F1: 0.9333333333333333
Epoch:  113        7 Batch loss: 0.102003 Batch F1: 0.8695652173913044
Epoch:  113        8 Batch loss: 0.058273 Batch F1: 0.8333333333333333
Epoch:  113        9 Batch loss: 0.071931 Batch F1: 0.625
Epoch:  113       10 Batch loss: 0.073909 Batch F1: 0.3636363636363636
Epoch:  113       11 Batch loss: 0.050407 Batch F1: 0.33333333333333337
Epoch:  113       12 Batch loss: 0.065962 Batch F1: 0.7272727272727273
Train Avg Loss  113: 0.074006

Train Avg F1  113: 0.6338750541982807

Val Avg Loss  113: 0.065785

Val Avg F1  113:  0.617929292929293

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 114
--------------------------------------------------------------
Epoch:  114        1 Batch loss: 0.076630 Batch F1: 0.5714285714285715
Epoch:  114        2 Batch loss: 0.071129 Batch F1: 0.3636363636363636
Epoch:  114        3 Batch loss: 0.079269 Batch F1: 0.42857142857142855
Epoch:  114        4 Batch loss: 0.062039 Batch F1: 0.923076923076923
Epoch:  114        5 Batch loss: 0.075642 Batch F1: 0.19999999999999998
Epoch:  114        6 Batch loss: 0.077747 Batch F1: 0.4615384615384615
Epoch:  114        7 Batch loss: 0.057029 Batch F1: 0.6666666666666666
Epoch:  114        8 Batch loss: 0.075340 Batch F1: 0.7058823529411764
Epoch:  114        9 Batch loss: 0.073630 Batch F1: 0.5
Epoch:  114       10 Batch loss: 0.062887 Batch F1: 0.4
Epoch:  114       11 Batch loss: 0.053601 Batch F1: 0.0
Epoch:  114       12 Batch loss: 0.092972 Batch F1: 0.5
Train Avg Loss  114: 0.071493

Train Avg F1  114: 0.4767333973216326

Val Avg Loss  114: 0.063523

Val Avg F1  114:  0.5783088235294118

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 115
--------------------------------------------------------------
Epoch:  115        1 Batch loss: 0.049888 Batch F1: 0.5
Epoch:  115        2 Batch loss: 0.079345 Batch F1: 0.33333333333333337
Epoch:  115        3 Batch loss: 0.061874 Batch F1: 0.9523809523809523
Epoch:  115        4 Batch loss: 0.069915 Batch F1: 0.888888888888889
Epoch:  115        5 Batch loss: 0.076515 Batch F1: 0.888888888888889
Epoch:  115        6 Batch loss: 0.070865 Batch F1: 0.7058823529411764
Epoch:  115        7 Batch loss: 0.076824 Batch F1: 0.5
Epoch:  115        8 Batch loss: 0.045134 Batch F1: 0.5
Epoch:  115        9 Batch loss: 0.073965 Batch F1: 0.5
Epoch:  115       10 Batch loss: 0.085487 Batch F1: 0.15384615384615385
Epoch:  115       11 Batch loss: 0.087615 Batch F1: 0.5263157894736842
Epoch:  115       12 Batch loss: 0.059909 Batch F1: 0.888888888888889
Train Avg Loss  115: 0.069778

Train Avg F1  115: 0.6115354373868306

Val Avg Loss  115: 0.063533

Val Avg F1  115:  0.9325163398692811

Optimal Val loss (Epoch 72): 0.062427153810858727

Epoch 116
--------------------------------------------------------------
Epoch:  116        1 Batch loss: 0.060111 Batch F1: 0.7499999999999999
Epoch:  116        2 Batch loss: 0.079767 Batch F1: 0.9473684210526316
Epoch:  116        3 Batch loss: 0.081097 Batch F1: 0.9
Epoch:  116        4 Batch loss: 0.065464 Batch F1: 0.9473684210526316
Epoch:  116        5 Batch loss: 0.057797 Batch F1: 0.9333333333333333
Epoch:  116        6 Batch loss: 0.074022 Batch F1: 1.0
Epoch:  116        7 Batch loss: 0.094480 Batch F1: 0.8148148148148148
Epoch:  116        8 Batch loss: 0.051970 Batch F1: 1.0
Epoch:  116        9 Batch loss: 0.085055 Batch F1: 0.7499999999999999
Epoch:  116       10 Batch loss: 0.060626 Batch F1: 0.8571428571428571
Epoch:  116       11 Batch loss: 0.046704 Batch F1: 1.0
Epoch:  116       12 Batch loss: 0.077355 Batch F1: 0.923076923076923
Train Avg Loss  116: 0.069538

Train Avg F1  116: 0.9019253975394327

Val Avg Loss  116: 0.061997

Val Avg F1  116:  0.7327380952380952

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 117
--------------------------------------------------------------
Epoch:  117        1 Batch loss: 0.057055 Batch F1: 0.7272727272727273
Epoch:  117        2 Batch loss: 0.055213 Batch F1: 0.0
Epoch:  117        3 Batch loss: 0.079795 Batch F1: 0.5714285714285715
Epoch:  117        4 Batch loss: 0.071936 Batch F1: 0.5454545454545454
Epoch:  117        5 Batch loss: 0.055205 Batch F1: 0.6666666666666666
Epoch:  117        6 Batch loss: 0.102618 Batch F1: 0.35294117647058826
Epoch:  117        7 Batch loss: 0.074891 Batch F1: 0.5714285714285715
Epoch:  117        8 Batch loss: 0.069867 Batch F1: 0.9523809523809523
Epoch:  117        9 Batch loss: 0.072966 Batch F1: 0.888888888888889
Epoch:  117       10 Batch loss: 0.063165 Batch F1: 1.0
Epoch:  117       11 Batch loss: 0.069440 Batch F1: 0.9333333333333333
Epoch:  117       12 Batch loss: 0.078544 Batch F1: 0.8333333333333333
Train Avg Loss  117: 0.070891

Train Avg F1  117: 0.6702607305548484

Val Avg Loss  117: 0.062630

Val Avg F1  117:  0.9163752913752914

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 118
--------------------------------------------------------------
Epoch:  118        1 Batch loss: 0.056122 Batch F1: 0.9090909090909091
Epoch:  118        2 Batch loss: 0.068697 Batch F1: 0.0
Epoch:  118        3 Batch loss: 0.091327 Batch F1: 0.5555555555555556
Epoch:  118        4 Batch loss: 0.069841 Batch F1: 0.6153846153846153
Epoch:  118        5 Batch loss: 0.066774 Batch F1: 0.2222222222222222
Epoch:  118        6 Batch loss: 0.052279 Batch F1: 1.0
Epoch:  118        7 Batch loss: 0.071974 Batch F1: 1.0
Epoch:  118        8 Batch loss: 0.084648 Batch F1: 0.8235294117647058
Epoch:  118        9 Batch loss: 0.065547 Batch F1: 0.8333333333333333
Epoch:  118       10 Batch loss: 0.072381 Batch F1: 1.0
Epoch:  118       11 Batch loss: 0.076707 Batch F1: 0.0
Epoch:  118       12 Batch loss: 0.068796 Batch F1: 0.8750000000000001
Train Avg Loss  118: 0.070424

Train Avg F1  118: 0.6528430039459451

Val Avg Loss  118: 0.062575

Val Avg F1  118:  0.9133986928104576

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 119
--------------------------------------------------------------
Epoch:  119        1 Batch loss: 0.075809 Batch F1: 0.888888888888889
Epoch:  119        2 Batch loss: 0.075671 Batch F1: 0.8
Epoch:  119        3 Batch loss: 0.062414 Batch F1: 0.8571428571428571
Epoch:  119        4 Batch loss: 0.078925 Batch F1: 0.9473684210526316
Epoch:  119        5 Batch loss: 0.064297 Batch F1: 0.9333333333333333
Epoch:  119        6 Batch loss: 0.071687 Batch F1: 1.0
Epoch:  119        7 Batch loss: 0.071575 Batch F1: 0.5454545454545454
Epoch:  119        8 Batch loss: 0.070795 Batch F1: 0.625
Epoch:  119        9 Batch loss: 0.054691 Batch F1: 0.6
Epoch:  119       10 Batch loss: 0.061693 Batch F1: 0.6666666666666666
Epoch:  119       11 Batch loss: 0.073467 Batch F1: 0.4615384615384615
Epoch:  119       12 Batch loss: 0.070185 Batch F1: 0.8333333333333333
Train Avg Loss  119: 0.069267

Train Avg F1  119: 0.7632272089508931

Val Avg Loss  119: 0.062310

Val Avg F1  119:  0.6092171717171717

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 120
--------------------------------------------------------------
Epoch:  120        1 Batch loss: 0.050367 Batch F1: 0.6666666666666666
Epoch:  120        2 Batch loss: 0.086409 Batch F1: 0.42857142857142855
Epoch:  120        3 Batch loss: 0.074301 Batch F1: 0.19999999999999998
Epoch:  120        4 Batch loss: 0.092441 Batch F1: 0.375
Epoch:  120        5 Batch loss: 0.062549 Batch F1: 0.7499999999999999
Epoch:  120        6 Batch loss: 0.058008 Batch F1: 0.923076923076923
Epoch:  120        7 Batch loss: 0.070018 Batch F1: 0.9333333333333333
Epoch:  120        8 Batch loss: 0.040355 Batch F1: 0.888888888888889
Epoch:  120        9 Batch loss: 0.081931 Batch F1: 0.631578947368421
Epoch:  120       10 Batch loss: 0.062424 Batch F1: 0.5714285714285715
Epoch:  120       11 Batch loss: 0.072238 Batch F1: 0.3636363636363636
Epoch:  120       12 Batch loss: 0.093532 Batch F1: 0.8571428571428571
Train Avg Loss  120: 0.070381

Train Avg F1  120: 0.6324436650094544

Val Avg Loss  120: 0.064929

Val Avg F1  120:  0.9269294778448096

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 121
--------------------------------------------------------------
Epoch:  121        1 Batch loss: 0.072583 Batch F1: 0.7692307692307693
Epoch:  121        2 Batch loss: 0.089288 Batch F1: 0.9600000000000001
Epoch:  121        3 Batch loss: 0.082394 Batch F1: 0.962962962962963
Epoch:  121        4 Batch loss: 0.075001 Batch F1: 0.888888888888889
Epoch:  121        5 Batch loss: 0.074620 Batch F1: 0.9473684210526316
Epoch:  121        6 Batch loss: 0.054907 Batch F1: 0.6666666666666666
Epoch:  121        7 Batch loss: 0.067157 Batch F1: 0.8235294117647058
Epoch:  121        8 Batch loss: 0.050262 Batch F1: 0.8333333333333333
Epoch:  121        9 Batch loss: 0.052265 Batch F1: 0.33333333333333337
Epoch:  121       10 Batch loss: 0.082825 Batch F1: 0.3636363636363636
Epoch:  121       11 Batch loss: 0.061192 Batch F1: 0.4444444444444445
Epoch:  121       12 Batch loss: 0.094371 Batch F1: 0.3076923076923077
Train Avg Loss  121: 0.071406

Train Avg F1  121: 0.6917572419172006

Val Avg Loss  121: 0.064435

Val Avg F1  121:  0.9325163398692811

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 122
--------------------------------------------------------------
Epoch:  122        1 Batch loss: 0.081995 Batch F1: 1.0
Epoch:  122        2 Batch loss: 0.093168 Batch F1: 0.8235294117647058
Epoch:  122        3 Batch loss: 0.067925 Batch F1: 1.0
Epoch:  122        4 Batch loss: 0.080174 Batch F1: 0.5
Epoch:  122        5 Batch loss: 0.046409 Batch F1: 0.8333333333333333
Epoch:  122        6 Batch loss: 0.110094 Batch F1: 0.18181818181818182
Epoch:  122        7 Batch loss: 0.056652 Batch F1: 0.25
Epoch:  122        8 Batch loss: 0.042024 Batch F1: 0.4
Epoch:  122        9 Batch loss: 0.073134 Batch F1: 0.25
Epoch:  122       10 Batch loss: 0.064671 Batch F1: 0.5714285714285715
Epoch:  122       11 Batch loss: 0.132015 Batch F1: 0.5217391304347826
Epoch:  122       12 Batch loss: 0.083982 Batch F1: 0.8571428571428572
Train Avg Loss  122: 0.077687

Train Avg F1  122: 0.5990826238268693

Val Avg Loss  122: 0.067735

Val Avg F1  122:  0.9076756576756576

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 123
--------------------------------------------------------------
Epoch:  123        1 Batch loss: 0.060469 Batch F1: 0.9333333333333333
Epoch:  123        2 Batch loss: 0.066488 Batch F1: 1.0
Epoch:  123        3 Batch loss: 0.083151 Batch F1: 0.5555555555555556
Epoch:  123        4 Batch loss: 0.071821 Batch F1: 0.6153846153846153
Epoch:  123        5 Batch loss: 0.057386 Batch F1: 0.25
Epoch:  123        6 Batch loss: 0.080332 Batch F1: 0.631578947368421
Epoch:  123        7 Batch loss: 0.083431 Batch F1: 0.888888888888889
Epoch:  123        8 Batch loss: 0.079295 Batch F1: 0.8750000000000001
Epoch:  123        9 Batch loss: 0.055643 Batch F1: 0.7499999999999999
Epoch:  123       10 Batch loss: 0.065254 Batch F1: 0.2857142857142857
Epoch:  123       11 Batch loss: 0.101132 Batch F1: 0.4
Epoch:  123       12 Batch loss: 0.092100 Batch F1: 0.5714285714285715
Train Avg Loss  123: 0.074708

Train Avg F1  123: 0.646407016472806

Val Avg Loss  123: 0.066074

Val Avg F1  123:  0.7431457431457431

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 124
--------------------------------------------------------------
Epoch:  124        1 Batch loss: 0.077947 Batch F1: 0.7058823529411764
Epoch:  124        2 Batch loss: 0.076008 Batch F1: 0.9473684210526316
Epoch:  124        3 Batch loss: 0.081592 Batch F1: 0.8
Epoch:  124        4 Batch loss: 0.066634 Batch F1: 0.7368421052631579
Epoch:  124        5 Batch loss: 0.072973 Batch F1: 0.5333333333333333
Epoch:  124        6 Batch loss: 0.086438 Batch F1: 0.33333333333333337
Epoch:  124        7 Batch loss: 0.058513 Batch F1: 0.9090909090909091
Epoch:  124        8 Batch loss: 0.076954 Batch F1: 0.7777777777777778
Epoch:  124        9 Batch loss: 0.063409 Batch F1: 0.8333333333333333
Epoch:  124       10 Batch loss: 0.060044 Batch F1: 0.33333333333333337
Epoch:  124       11 Batch loss: 0.069129 Batch F1: 0.4
Epoch:  124       12 Batch loss: 0.086626 Batch F1: 0.3636363636363636
Train Avg Loss  124: 0.073022

Train Avg F1  124: 0.6394942719246125

Val Avg Loss  124: 0.063632

Val Avg F1  124:  0.7317460317460318

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 125
--------------------------------------------------------------
Epoch:  125        1 Batch loss: 0.071479 Batch F1: 0.846153846153846
Epoch:  125        2 Batch loss: 0.093798 Batch F1: 0.7777777777777778
Epoch:  125        3 Batch loss: 0.062795 Batch F1: 0.8333333333333333
Epoch:  125        4 Batch loss: 0.067989 Batch F1: 1.0
Epoch:  125        5 Batch loss: 0.058979 Batch F1: 1.0
Epoch:  125        6 Batch loss: 0.050598 Batch F1: 0.5
Epoch:  125        7 Batch loss: 0.105059 Batch F1: 0.0
Epoch:  125        8 Batch loss: 0.103653 Batch F1: 0.14285714285714288
Epoch:  125        9 Batch loss: 0.067143 Batch F1: 0.2857142857142857
Epoch:  125       10 Batch loss: 0.065969 Batch F1: 1.0
Epoch:  125       11 Batch loss: 0.053680 Batch F1: 0.8333333333333333
Epoch:  125       12 Batch loss: 0.079901 Batch F1: 0.9411764705882353
Train Avg Loss  125: 0.073420

Train Avg F1  125: 0.6800288491464962

Val Avg Loss  125: 0.064493

Val Avg F1  125:  0.9279914529914529

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 126
--------------------------------------------------------------
Epoch:  126        1 Batch loss: 0.056727 Batch F1: 0.9411764705882353
Epoch:  126        2 Batch loss: 0.048113 Batch F1: 1.0
Epoch:  126        3 Batch loss: 0.072123 Batch F1: 0.9565217391304348
Epoch:  126        4 Batch loss: 0.067820 Batch F1: 0.0
Epoch:  126        5 Batch loss: 0.113312 Batch F1: 0.5925925925925926
Epoch:  126        6 Batch loss: 0.064791 Batch F1: 1.0
Epoch:  126        7 Batch loss: 0.088045 Batch F1: 0.8571428571428571
Epoch:  126        8 Batch loss: 0.063601 Batch F1: 0.8333333333333333
Epoch:  126        9 Batch loss: 0.081602 Batch F1: 0.7692307692307693
Epoch:  126       10 Batch loss: 0.052642 Batch F1: 1.0
Epoch:  126       11 Batch loss: 0.075927 Batch F1: 0.9333333333333333
Epoch:  126       12 Batch loss: 0.078034 Batch F1: 0.4
Train Avg Loss  126: 0.071895

Train Avg F1  126: 0.7736109246126296

Val Avg Loss  126: 0.066861

Val Avg F1  126:  0.5

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 127
--------------------------------------------------------------
Epoch:  127        1 Batch loss: 0.053339 Batch F1: 0.7272727272727273
Epoch:  127        2 Batch loss: 0.074834 Batch F1: 0.5
Epoch:  127        3 Batch loss: 0.071480 Batch F1: 0.25
Epoch:  127        4 Batch loss: 0.104945 Batch F1: 0.2857142857142857
Epoch:  127        5 Batch loss: 0.051776 Batch F1: 0.6
Epoch:  127        6 Batch loss: 0.098934 Batch F1: 0.88
Epoch:  127        7 Batch loss: 0.084173 Batch F1: 0.9600000000000001
Epoch:  127        8 Batch loss: 0.077286 Batch F1: 0.9090909090909091
Epoch:  127        9 Batch loss: 0.077445 Batch F1: 0.9523809523809523
Epoch:  127       10 Batch loss: 0.040211 Batch F1: 0.888888888888889
Epoch:  127       11 Batch loss: 0.070709 Batch F1: 0.625
Epoch:  127       12 Batch loss: 0.057413 Batch F1: 0.2857142857142857
Train Avg Loss  127: 0.071879

Train Avg F1  127: 0.6553385040885041

Val Avg Loss  127: 0.065573

Val Avg F1  127:  0.5899122807017544

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 128
--------------------------------------------------------------
Epoch:  128        1 Batch loss: 0.049938 Batch F1: 0.8333333333333333
Epoch:  128        2 Batch loss: 0.082217 Batch F1: 0.5333333333333333
Epoch:  128        3 Batch loss: 0.072072 Batch F1: 0.625
Epoch:  128        4 Batch loss: 0.068079 Batch F1: 0.8333333333333333
Epoch:  128        5 Batch loss: 0.058482 Batch F1: 1.0
Epoch:  128        6 Batch loss: 0.062642 Batch F1: 0.923076923076923
Epoch:  128        7 Batch loss: 0.076848 Batch F1: 0.4
Epoch:  128        8 Batch loss: 0.068418 Batch F1: 0.5714285714285715
Epoch:  128        9 Batch loss: 0.052133 Batch F1: 0.2857142857142857
Epoch:  128       10 Batch loss: 0.063134 Batch F1: 0.25
Epoch:  128       11 Batch loss: 0.092430 Batch F1: 0.5555555555555556
Epoch:  128       12 Batch loss: 0.102184 Batch F1: 0.7499999999999999
Train Avg Loss  128: 0.070715

Train Avg F1  128: 0.6300646113146113

Val Avg Loss  128: 0.063109

Val Avg F1  128:  0.9144439152179091

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 129
--------------------------------------------------------------
Epoch:  129        1 Batch loss: 0.060033 Batch F1: 0.9090909090909091
Epoch:  129        2 Batch loss: 0.075571 Batch F1: 0.9600000000000001
Epoch:  129        3 Batch loss: 0.061870 Batch F1: 0.6666666666666666
Epoch:  129        4 Batch loss: 0.070524 Batch F1: 0.9411764705882353
Epoch:  129        5 Batch loss: 0.071311 Batch F1: 0.9473684210526316
Epoch:  129        6 Batch loss: 0.067452 Batch F1: 0.9411764705882353
Epoch:  129        7 Batch loss: 0.099771 Batch F1: 0.8571428571428571
Epoch:  129        8 Batch loss: 0.056313 Batch F1: 0.888888888888889
Epoch:  129        9 Batch loss: 0.060062 Batch F1: 1.0
Epoch:  129       10 Batch loss: 0.062838 Batch F1: 1.0
Epoch:  129       11 Batch loss: 0.064277 Batch F1: 0.4
Epoch:  129       12 Batch loss: 0.079623 Batch F1: 0.5454545454545454
Train Avg Loss  129: 0.069137

Train Avg F1  129: 0.838080435789414

Val Avg Loss  129: 0.063387

Val Avg F1  129:  0.5967447585094644

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 130
--------------------------------------------------------------
Epoch:  130        1 Batch loss: 0.055297 Batch F1: 0.5714285714285715
Epoch:  130        2 Batch loss: 0.099825 Batch F1: 0.4444444444444445
Epoch:  130        3 Batch loss: 0.081084 Batch F1: 0.33333333333333337
Epoch:  130        4 Batch loss: 0.076580 Batch F1: 0.9523809523809523
Epoch:  130        5 Batch loss: 0.088976 Batch F1: 0.9166666666666666
Epoch:  130        6 Batch loss: 0.065772 Batch F1: 0.9411764705882353
Epoch:  130        7 Batch loss: 0.079559 Batch F1: 0.8
Epoch:  130        8 Batch loss: 0.043294 Batch F1: 1.0
Epoch:  130        9 Batch loss: 0.049215 Batch F1: 1.0
Epoch:  130       10 Batch loss: 0.074890 Batch F1: 0.4615384615384615
Epoch:  130       11 Batch loss: 0.080953 Batch F1: 0.625
Epoch:  130       12 Batch loss: 0.065498 Batch F1: 0.8
Train Avg Loss  130: 0.071745

Train Avg F1  130: 0.7371640750317221

Val Avg Loss  130: 0.063800

Val Avg F1  130:  0.5744810744810744

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 131
--------------------------------------------------------------
Epoch:  131        1 Batch loss: 0.076070 Batch F1: 0.0
Epoch:  131        2 Batch loss: 0.037714 Batch F1: 0.6666666666666666
Epoch:  131        3 Batch loss: 0.055508 Batch F1: 0.8
Epoch:  131        4 Batch loss: 0.077186 Batch F1: 0.0
Epoch:  131        5 Batch loss: 0.054203 Batch F1: 0.6
Epoch:  131        6 Batch loss: 0.080203 Batch F1: 0.5882352941176471
Epoch:  131        7 Batch loss: 0.080538 Batch F1: 0.5714285714285715
Epoch:  131        8 Batch loss: 0.082959 Batch F1: 0.375
Epoch:  131        9 Batch loss: 0.065672 Batch F1: 0.9333333333333333
Epoch:  131       10 Batch loss: 0.081083 Batch F1: 0.8421052631578948
Epoch:  131       11 Batch loss: 0.074352 Batch F1: 1.0
Epoch:  131       12 Batch loss: 0.067140 Batch F1: 0.8571428571428571
Train Avg Loss  131: 0.069386

Train Avg F1  131: 0.6028259988205809

Val Avg Loss  131: 0.063541

Val Avg F1  131:  0.9196859903381643

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 132
--------------------------------------------------------------
Epoch:  132        1 Batch loss: 0.049858 Batch F1: 0.9090909090909091
Epoch:  132        2 Batch loss: 0.069636 Batch F1: 0.9333333333333333
Epoch:  132        3 Batch loss: 0.093497 Batch F1: 0.375
Epoch:  132        4 Batch loss: 0.100236 Batch F1: 0.4
Epoch:  132        5 Batch loss: 0.063472 Batch F1: 0.923076923076923
Epoch:  132        6 Batch loss: 0.059841 Batch F1: 0.9090909090909091
Epoch:  132        7 Batch loss: 0.057583 Batch F1: 1.0
Epoch:  132        8 Batch loss: 0.072737 Batch F1: 0.9473684210526316
Epoch:  132        9 Batch loss: 0.062973 Batch F1: 0.8333333333333333
Epoch:  132       10 Batch loss: 0.054341 Batch F1: 0.9411764705882353
Epoch:  132       11 Batch loss: 0.082543 Batch F1: 0.9
Epoch:  132       12 Batch loss: 0.067990 Batch F1: 0.9473684210526316
Train Avg Loss  132: 0.069559

Train Avg F1  132: 0.8349032267182421

Val Avg Loss  132: 0.062448

Val Avg F1  132:  0.9287464985994397

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 133
--------------------------------------------------------------
Epoch:  133        1 Batch loss: 0.057096 Batch F1: 0.923076923076923
Epoch:  133        2 Batch loss: 0.047158 Batch F1: 0.9090909090909091
Epoch:  133        3 Batch loss: 0.068193 Batch F1: 0.9411764705882353
Epoch:  133        4 Batch loss: 0.065059 Batch F1: 1.0
Epoch:  133        5 Batch loss: 0.073825 Batch F1: 0.5714285714285715
Epoch:  133        6 Batch loss: 0.059624 Batch F1: 0.5714285714285715
Epoch:  133        7 Batch loss: 0.078652 Batch F1: 0.7499999999999999
Epoch:  133        8 Batch loss: 0.086636 Batch F1: 0.7499999999999999
Epoch:  133        9 Batch loss: 0.074552 Batch F1: 1.0
Epoch:  133       10 Batch loss: 0.075623 Batch F1: 0.9523809523809523
Epoch:  133       11 Batch loss: 0.082449 Batch F1: 0.8750000000000001
Epoch:  133       12 Batch loss: 0.060696 Batch F1: 1.0
Train Avg Loss  133: 0.069130

Train Avg F1  133: 0.8536318664995135

Val Avg Loss  133: 0.062015

Val Avg F1  133:  0.9226190476190476

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 134
--------------------------------------------------------------
Epoch:  134        1 Batch loss: 0.085933 Batch F1: 0.7368421052631579
Epoch:  134        2 Batch loss: 0.070783 Batch F1: 0.9473684210526316
Epoch:  134        3 Batch loss: 0.061724 Batch F1: 0.6153846153846153
Epoch:  134        4 Batch loss: 0.073472 Batch F1: 0.5
Epoch:  134        5 Batch loss: 0.065715 Batch F1: 0.5
Epoch:  134        6 Batch loss: 0.064723 Batch F1: 0.5714285714285715
Epoch:  134        7 Batch loss: 0.057758 Batch F1: 0.5454545454545454
Epoch:  134        8 Batch loss: 0.059832 Batch F1: 0.33333333333333337
Epoch:  134        9 Batch loss: 0.049211 Batch F1: 0.8
Epoch:  134       10 Batch loss: 0.069177 Batch F1: 0.4
Epoch:  134       11 Batch loss: 0.063191 Batch F1: 0.6153846153846153
Epoch:  134       12 Batch loss: 0.105980 Batch F1: 0.47058823529411764
Train Avg Loss  134: 0.068958

Train Avg F1  134: 0.586315370216299

Val Avg Loss  134: 0.062096

Val Avg F1  134:  0.5395658263305322

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 135
--------------------------------------------------------------
Epoch:  135        1 Batch loss: 0.080541 Batch F1: 0.18181818181818182
Epoch:  135        2 Batch loss: 0.063099 Batch F1: 0.8333333333333333
Epoch:  135        3 Batch loss: 0.061505 Batch F1: 0.8571428571428571
Epoch:  135        4 Batch loss: 0.077783 Batch F1: 0.888888888888889
Epoch:  135        5 Batch loss: 0.052315 Batch F1: 1.0
Epoch:  135        6 Batch loss: 0.103498 Batch F1: 0.25
Epoch:  135        7 Batch loss: 0.056286 Batch F1: 1.0
Epoch:  135        8 Batch loss: 0.045213 Batch F1: 1.0
Epoch:  135        9 Batch loss: 0.097226 Batch F1: 0.35294117647058826
Epoch:  135       10 Batch loss: 0.054526 Batch F1: 1.0
Epoch:  135       11 Batch loss: 0.063265 Batch F1: 0.9333333333333333
Epoch:  135       12 Batch loss: 0.088684 Batch F1: 0.7000000000000001
Train Avg Loss  135: 0.070328

Train Avg F1  135: 0.7497881475822651

Val Avg Loss  135: 0.062160

Val Avg F1  135:  0.7110576923076923

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 136
--------------------------------------------------------------
Epoch:  136        1 Batch loss: 0.057509 Batch F1: 0.5
Epoch:  136        2 Batch loss: 0.059309 Batch F1: 0.5454545454545454
Epoch:  136        3 Batch loss: 0.071959 Batch F1: 0.625
Epoch:  136        4 Batch loss: 0.111502 Batch F1: 0.13333333333333333
Epoch:  136        5 Batch loss: 0.057545 Batch F1: 0.9333333333333333
Epoch:  136        6 Batch loss: 0.077142 Batch F1: 0.7692307692307693
Epoch:  136        7 Batch loss: 0.081728 Batch F1: 0.9090909090909091
Epoch:  136        8 Batch loss: 0.052605 Batch F1: 0.9090909090909091
Epoch:  136        9 Batch loss: 0.078241 Batch F1: 0.8571428571428571
Epoch:  136       10 Batch loss: 0.087162 Batch F1: 0.9285714285714286
Epoch:  136       11 Batch loss: 0.042635 Batch F1: 1.0
Epoch:  136       12 Batch loss: 0.066819 Batch F1: 0.25
Train Avg Loss  136: 0.070346

Train Avg F1  136: 0.6966873404373404

Val Avg Loss  136: 0.065663

Val Avg F1  136:  0.5499999999999999

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 137
--------------------------------------------------------------
Epoch:  137        1 Batch loss: 0.058088 Batch F1: 0.6666666666666666
Epoch:  137        2 Batch loss: 0.054455 Batch F1: 0.8750000000000001
Epoch:  137        3 Batch loss: 0.104135 Batch F1: 0.6
Epoch:  137        4 Batch loss: 0.049321 Batch F1: 0.7272727272727273
Epoch:  137        5 Batch loss: 0.041842 Batch F1: 0.5714285714285715
Epoch:  137        6 Batch loss: 0.069040 Batch F1: 0.5714285714285715
Epoch:  137        7 Batch loss: 0.089715 Batch F1: 0.16666666666666669
Epoch:  137        8 Batch loss: 0.071504 Batch F1: 0.5
Epoch:  137        9 Batch loss: 0.073012 Batch F1: 0.9333333333333333
Epoch:  137       10 Batch loss: 0.086919 Batch F1: 1.0
Epoch:  137       11 Batch loss: 0.053872 Batch F1: 1.0
Epoch:  137       12 Batch loss: 0.078326 Batch F1: 0.6666666666666666
Train Avg Loss  137: 0.069185

Train Avg F1  137: 0.6898719336219337

Val Avg Loss  137: 0.062890

Val Avg F1  137:  0.9422222222222222

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 138
--------------------------------------------------------------
Epoch:  138        1 Batch loss: 0.071720 Batch F1: 0.6666666666666666
Epoch:  138        2 Batch loss: 0.074465 Batch F1: 0.8333333333333333
Epoch:  138        3 Batch loss: 0.060292 Batch F1: 1.0
Epoch:  138        4 Batch loss: 0.077084 Batch F1: 0.9
Epoch:  138        5 Batch loss: 0.081743 Batch F1: 0.9565217391304348
Epoch:  138        6 Batch loss: 0.063408 Batch F1: 1.0
Epoch:  138        7 Batch loss: 0.054321 Batch F1: 0.9090909090909091
Epoch:  138        8 Batch loss: 0.080333 Batch F1: 0.9
Epoch:  138        9 Batch loss: 0.072105 Batch F1: 0.923076923076923
Epoch:  138       10 Batch loss: 0.066533 Batch F1: 0.9473684210526316
Epoch:  138       11 Batch loss: 0.066191 Batch F1: 0.5
Epoch:  138       12 Batch loss: 0.081703 Batch F1: 0.6153846153846153
Train Avg Loss  138: 0.070825

Train Avg F1  138: 0.8459535506446262

Val Avg Loss  138: 0.063074

Val Avg F1  138:  0.5524350649350649

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 139
--------------------------------------------------------------
Epoch:  139        1 Batch loss: 0.077408 Batch F1: 0.5
Epoch:  139        2 Batch loss: 0.084531 Batch F1: 0.18181818181818182
Epoch:  139        3 Batch loss: 0.053710 Batch F1: 0.7272727272727273
Epoch:  139        4 Batch loss: 0.069831 Batch F1: 0.5454545454545454
Epoch:  139        5 Batch loss: 0.064113 Batch F1: 0.6666666666666666
Epoch:  139        6 Batch loss: 0.076553 Batch F1: 0.33333333333333337
Epoch:  139        7 Batch loss: 0.085225 Batch F1: 0.16666666666666669
Epoch:  139        8 Batch loss: 0.060153 Batch F1: 0.5454545454545454
Epoch:  139        9 Batch loss: 0.072039 Batch F1: 0.9090909090909091
Epoch:  139       10 Batch loss: 0.073085 Batch F1: 0.9333333333333333
Epoch:  139       11 Batch loss: 0.051818 Batch F1: 1.0
Epoch:  139       12 Batch loss: 0.068722 Batch F1: 0.9411764705882353
Train Avg Loss  139: 0.069766

Train Avg F1  139: 0.620855614973262

Val Avg Loss  139: 0.062191

Val Avg F1  139:  0.502266081871345

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 140
--------------------------------------------------------------
Epoch:  140        1 Batch loss: 0.068042 Batch F1: 0.4
Epoch:  140        2 Batch loss: 0.058071 Batch F1: 0.4
Epoch:  140        3 Batch loss: 0.054485 Batch F1: 0.4444444444444445
Epoch:  140        4 Batch loss: 0.069003 Batch F1: 0.5714285714285715
Epoch:  140        5 Batch loss: 0.050444 Batch F1: 0.4
Epoch:  140        6 Batch loss: 0.090935 Batch F1: 0.3076923076923077
Epoch:  140        7 Batch loss: 0.064432 Batch F1: 0.6666666666666666
Epoch:  140        8 Batch loss: 0.069276 Batch F1: 0.4615384615384615
Epoch:  140        9 Batch loss: 0.073615 Batch F1: 0.9473684210526316
Epoch:  140       10 Batch loss: 0.087137 Batch F1: 0.8695652173913044
Epoch:  140       11 Batch loss: 0.064672 Batch F1: 0.9333333333333333
Epoch:  140       12 Batch loss: 0.077006 Batch F1: 0.9411764705882353
Train Avg Loss  140: 0.068926

Train Avg F1  140: 0.6119344911779964

Val Avg Loss  140: 0.063241

Val Avg F1  140:  0.931897050318103

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 141
--------------------------------------------------------------
Epoch:  141        1 Batch loss: 0.077607 Batch F1: 0.7692307692307693
Epoch:  141        2 Batch loss: 0.063781 Batch F1: 1.0
Epoch:  141        3 Batch loss: 0.066438 Batch F1: 0.8333333333333333
Epoch:  141        4 Batch loss: 0.080522 Batch F1: 0.631578947368421
Epoch:  141        5 Batch loss: 0.073506 Batch F1: 0.888888888888889
Epoch:  141        6 Batch loss: 0.064769 Batch F1: 0.9523809523809523
Epoch:  141        7 Batch loss: 0.053531 Batch F1: 1.0
Epoch:  141        8 Batch loss: 0.065132 Batch F1: 0.923076923076923
Epoch:  141        9 Batch loss: 0.074068 Batch F1: 0.33333333333333337
Epoch:  141       10 Batch loss: 0.051018 Batch F1: 0.6
Epoch:  141       11 Batch loss: 0.078306 Batch F1: 0.5454545454545454
Epoch:  141       12 Batch loss: 0.098405 Batch F1: 0.4
Train Avg Loss  141: 0.070590

Train Avg F1  141: 0.7397731410889307

Val Avg Loss  141: 0.062724

Val Avg F1  141:  0.5680555555555555

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 142
--------------------------------------------------------------
Epoch:  142        1 Batch loss: 0.101974 Batch F1: 0.4444444444444445
Epoch:  142        2 Batch loss: 0.073939 Batch F1: 0.8750000000000001
Epoch:  142        3 Batch loss: 0.071207 Batch F1: 0.888888888888889
Epoch:  142        4 Batch loss: 0.071132 Batch F1: 0.923076923076923
Epoch:  142        5 Batch loss: 0.064787 Batch F1: 0.9411764705882353
Epoch:  142        6 Batch loss: 0.096926 Batch F1: 0.2857142857142857
Epoch:  142        7 Batch loss: 0.070327 Batch F1: 0.7142857142857143
Epoch:  142        8 Batch loss: 0.061238 Batch F1: 1.0
Epoch:  142        9 Batch loss: 0.059070 Batch F1: 0.9090909090909091
Epoch:  142       10 Batch loss: 0.066597 Batch F1: 0.9411764705882353
Epoch:  142       11 Batch loss: 0.054701 Batch F1: 0.6
Epoch:  142       12 Batch loss: 0.076591 Batch F1: 0.4
Train Avg Loss  142: 0.072374

Train Avg F1  142: 0.7435711755564697

Val Avg Loss  142: 0.066613

Val Avg F1  142:  0.5731049995755878

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 143
--------------------------------------------------------------
Epoch:  143        1 Batch loss: 0.077895 Batch F1: 0.0
Epoch:  143        2 Batch loss: 0.060928 Batch F1: 0.4444444444444445
Epoch:  143        3 Batch loss: 0.054092 Batch F1: 0.2857142857142857
Epoch:  143        4 Batch loss: 0.070021 Batch F1: 0.2222222222222222
Epoch:  143        5 Batch loss: 0.057733 Batch F1: 0.6153846153846153
Epoch:  143        6 Batch loss: 0.066170 Batch F1: 0.923076923076923
Epoch:  143        7 Batch loss: 0.090521 Batch F1: 0.8181818181818181
Epoch:  143        8 Batch loss: 0.051637 Batch F1: 0.9411764705882353
Epoch:  143        9 Batch loss: 0.078836 Batch F1: 0.962962962962963
Epoch:  143       10 Batch loss: 0.066948 Batch F1: 1.0
Epoch:  143       11 Batch loss: 0.080488 Batch F1: 0.9
Epoch:  143       12 Batch loss: 0.066083 Batch F1: 0.923076923076923
Train Avg Loss  143: 0.068446

Train Avg F1  143: 0.6696867221377025

Val Avg Loss  143: 0.062690

Val Avg F1  143:  0.9278143274853802

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 144
--------------------------------------------------------------
Epoch:  144        1 Batch loss: 0.094417 Batch F1: 0.88
Epoch:  144        2 Batch loss: 0.075713 Batch F1: 0.9600000000000001
Epoch:  144        3 Batch loss: 0.043599 Batch F1: 1.0
Epoch:  144        4 Batch loss: 0.044938 Batch F1: 1.0
Epoch:  144        5 Batch loss: 0.065303 Batch F1: 1.0
Epoch:  144        6 Batch loss: 0.057794 Batch F1: 0.0
Epoch:  144        7 Batch loss: 0.059355 Batch F1: 0.5454545454545454
Epoch:  144        8 Batch loss: 0.088294 Batch F1: 0.19999999999999998
Epoch:  144        9 Batch loss: 0.067407 Batch F1: 0.6
Epoch:  144       10 Batch loss: 0.079403 Batch F1: 0.5
Epoch:  144       11 Batch loss: 0.074916 Batch F1: 0.5882352941176471
Epoch:  144       12 Batch loss: 0.087317 Batch F1: 0.5
Train Avg Loss  144: 0.069871

Train Avg F1  144: 0.647807486631016

Val Avg Loss  144: 0.062389

Val Avg F1  144:  0.9090643274853802

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 145
--------------------------------------------------------------
Epoch:  145        1 Batch loss: 0.072659 Batch F1: 0.8333333333333333
Epoch:  145        2 Batch loss: 0.061001 Batch F1: 1.0
Epoch:  145        3 Batch loss: 0.060413 Batch F1: 0.9411764705882353
Epoch:  145        4 Batch loss: 0.092948 Batch F1: 0.8421052631578948
Epoch:  145        5 Batch loss: 0.083241 Batch F1: 1.0
Epoch:  145        6 Batch loss: 0.047670 Batch F1: 1.0
Epoch:  145        7 Batch loss: 0.075277 Batch F1: 0.9473684210526316
Epoch:  145        8 Batch loss: 0.065958 Batch F1: 0.5454545454545454
Epoch:  145        9 Batch loss: 0.107311 Batch F1: 0.2666666666666667
Epoch:  145       10 Batch loss: 0.070857 Batch F1: 0.9411764705882353
Epoch:  145       11 Batch loss: 0.061737 Batch F1: 0.888888888888889
Epoch:  145       12 Batch loss: 0.048723 Batch F1: 1.0
Train Avg Loss  145: 0.070650

Train Avg F1  145: 0.8505141716442025

Val Avg Loss  145: 0.064364

Val Avg F1  145:  0.9228843052372464

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 146
--------------------------------------------------------------
Epoch:  146        1 Batch loss: 0.043247 Batch F1: 1.0
Epoch:  146        2 Batch loss: 0.069801 Batch F1: 0.5454545454545454
Epoch:  146        3 Batch loss: 0.099179 Batch F1: 0.375
Epoch:  146        4 Batch loss: 0.082523 Batch F1: 0.5
Epoch:  146        5 Batch loss: 0.073174 Batch F1: 0.5714285714285715
Epoch:  146        6 Batch loss: 0.062905 Batch F1: 0.8571428571428571
Epoch:  146        7 Batch loss: 0.074255 Batch F1: 1.0
Epoch:  146        8 Batch loss: 0.077869 Batch F1: 0.8421052631578948
Epoch:  146        9 Batch loss: 0.082477 Batch F1: 0.8571428571428571
Epoch:  146       10 Batch loss: 0.060146 Batch F1: 0.9090909090909091
Epoch:  146       11 Batch loss: 0.072344 Batch F1: 1.0
Epoch:  146       12 Batch loss: 0.081303 Batch F1: 0.4
Train Avg Loss  146: 0.073269

Train Avg F1  146: 0.738113750284803

Val Avg Loss  146: 0.065780

Val Avg F1  146:  0.5765427383074442

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 147
--------------------------------------------------------------
Epoch:  147        1 Batch loss: 0.059171 Batch F1: 0.6
Epoch:  147        2 Batch loss: 0.073741 Batch F1: 0.4615384615384615
Epoch:  147        3 Batch loss: 0.089203 Batch F1: 0.47058823529411764
Epoch:  147        4 Batch loss: 0.084242 Batch F1: 0.2222222222222222
Epoch:  147        5 Batch loss: 0.091013 Batch F1: 0.7499999999999999
Epoch:  147        6 Batch loss: 0.068004 Batch F1: 0.9473684210526316
Epoch:  147        7 Batch loss: 0.067178 Batch F1: 0.8333333333333333
Epoch:  147        8 Batch loss: 0.068371 Batch F1: 0.8571428571428571
Epoch:  147        9 Batch loss: 0.053898 Batch F1: 0.888888888888889
Epoch:  147       10 Batch loss: 0.080670 Batch F1: 0.4615384615384615
Epoch:  147       11 Batch loss: 0.059778 Batch F1: 0.5
Epoch:  147       12 Batch loss: 0.082656 Batch F1: 0.5
Train Avg Loss  147: 0.073160

Train Avg F1  147: 0.6243850734175812

Val Avg Loss  147: 0.063903

Val Avg F1  147:  0.5780219780219781

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 148
--------------------------------------------------------------
Epoch:  148        1 Batch loss: 0.088488 Batch F1: 0.6
Epoch:  148        2 Batch loss: 0.065692 Batch F1: 1.0
Epoch:  148        3 Batch loss: 0.068694 Batch F1: 0.923076923076923
Epoch:  148        4 Batch loss: 0.074914 Batch F1: 0.5454545454545454
Epoch:  148        5 Batch loss: 0.079199 Batch F1: 0.782608695652174
Epoch:  148        6 Batch loss: 0.063308 Batch F1: 1.0
Epoch:  148        7 Batch loss: 0.067304 Batch F1: 0.8333333333333333
Epoch:  148        8 Batch loss: 0.084725 Batch F1: 0.19999999999999998
Epoch:  148        9 Batch loss: 0.080861 Batch F1: 0.42857142857142855
Epoch:  148       10 Batch loss: 0.074742 Batch F1: 0.19999999999999998
Epoch:  148       11 Batch loss: 0.047957 Batch F1: 0.923076923076923
Epoch:  148       12 Batch loss: 0.065429 Batch F1: 0.33333333333333337
Train Avg Loss  148: 0.071776

Train Avg F1  148: 0.6474545985415551

Val Avg Loss  148: 0.064954

Val Avg F1  148:  0.724223602484472

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 149
--------------------------------------------------------------
Epoch:  149        1 Batch loss: 0.067598 Batch F1: 0.6666666666666666
Epoch:  149        2 Batch loss: 0.040324 Batch F1: 0.6666666666666666
Epoch:  149        3 Batch loss: 0.049746 Batch F1: 0.0
Epoch:  149        4 Batch loss: 0.107720 Batch F1: 0.4444444444444445
Epoch:  149        5 Batch loss: 0.078127 Batch F1: 0.625
Epoch:  149        6 Batch loss: 0.069446 Batch F1: 0.5714285714285715
Epoch:  149        7 Batch loss: 0.060171 Batch F1: 0.9
Epoch:  149        8 Batch loss: 0.073281 Batch F1: 1.0
Epoch:  149        9 Batch loss: 0.076997 Batch F1: 0.8333333333333333
Epoch:  149       10 Batch loss: 0.069895 Batch F1: 1.0
Epoch:  149       11 Batch loss: 0.103354 Batch F1: 0.8333333333333333
Epoch:  149       12 Batch loss: 0.076249 Batch F1: 0.8571428571428571
Train Avg Loss  149: 0.072742

Train Avg F1  149: 0.699834656084656

Val Avg Loss  149: 0.063756

Val Avg F1  149:  0.9318452380952381

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 150
--------------------------------------------------------------
Epoch:  150        1 Batch loss: 0.062524 Batch F1: 0.9333333333333333
Epoch:  150        2 Batch loss: 0.085566 Batch F1: 0.9600000000000001
Epoch:  150        3 Batch loss: 0.051730 Batch F1: 0.888888888888889
Epoch:  150        4 Batch loss: 0.080593 Batch F1: 0.9
Epoch:  150        5 Batch loss: 0.073455 Batch F1: 0.3636363636363636
Epoch:  150        6 Batch loss: 0.067667 Batch F1: 0.5882352941176471
Epoch:  150        7 Batch loss: 0.079516 Batch F1: 0.5714285714285715
Epoch:  150        8 Batch loss: 0.065860 Batch F1: 0.7272727272727273
Epoch:  150        9 Batch loss: 0.077341 Batch F1: 0.8421052631578948
Epoch:  150       10 Batch loss: 0.067087 Batch F1: 0.9411764705882353
Epoch:  150       11 Batch loss: 0.051872 Batch F1: 0.8
Epoch:  150       12 Batch loss: 0.078106 Batch F1: 0.7272727272727273
Train Avg Loss  150: 0.070110

Train Avg F1  150: 0.7702791366413657

Val Avg Loss  150: 0.062834

Val Avg F1  150:  0.5865384615384616

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 151
--------------------------------------------------------------
Epoch:  151        1 Batch loss: 0.077931 Batch F1: 0.5882352941176471
Epoch:  151        2 Batch loss: 0.070398 Batch F1: 0.19999999999999998
Epoch:  151        3 Batch loss: 0.066476 Batch F1: 0.9473684210526316
Epoch:  151        4 Batch loss: 0.053400 Batch F1: 1.0
Epoch:  151        5 Batch loss: 0.057135 Batch F1: 0.923076923076923
Epoch:  151        6 Batch loss: 0.071383 Batch F1: 0.9411764705882353
Epoch:  151        7 Batch loss: 0.075755 Batch F1: 0.5
Epoch:  151        8 Batch loss: 0.055414 Batch F1: 0.33333333333333337
Epoch:  151        9 Batch loss: 0.063421 Batch F1: 0.7142857142857143
Epoch:  151       10 Batch loss: 0.088906 Batch F1: 0.5555555555555556
Epoch:  151       11 Batch loss: 0.048654 Batch F1: 0.6666666666666666
Epoch:  151       12 Batch loss: 0.108475 Batch F1: 0.2857142857142857
Train Avg Loss  151: 0.069779

Train Avg F1  151: 0.637951055365916

Val Avg Loss  151: 0.062790

Val Avg F1  151:  0.8677944862155389

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 152
--------------------------------------------------------------
Epoch:  152        1 Batch loss: 0.047383 Batch F1: 1.0
Epoch:  152        2 Batch loss: 0.062021 Batch F1: 0.8333333333333333
Epoch:  152        3 Batch loss: 0.062057 Batch F1: 1.0
Epoch:  152        4 Batch loss: 0.068624 Batch F1: 0.9333333333333333
Epoch:  152        5 Batch loss: 0.065412 Batch F1: 0.2857142857142857
Epoch:  152        6 Batch loss: 0.097722 Batch F1: 0.6666666666666666
Epoch:  152        7 Batch loss: 0.076370 Batch F1: 0.4615384615384615
Epoch:  152        8 Batch loss: 0.077812 Batch F1: 0.5555555555555556
Epoch:  152        9 Batch loss: 0.056114 Batch F1: 1.0
Epoch:  152       10 Batch loss: 0.077463 Batch F1: 0.888888888888889
Epoch:  152       11 Batch loss: 0.094492 Batch F1: 0.888888888888889
Epoch:  152       12 Batch loss: 0.066578 Batch F1: 1.0
Train Avg Loss  152: 0.071004

Train Avg F1  152: 0.7928266178266178

Val Avg Loss  152: 0.065462

Val Avg F1  152:  0.9243421052631579

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 153
--------------------------------------------------------------
Epoch:  153        1 Batch loss: 0.068061 Batch F1: 0.923076923076923
Epoch:  153        2 Batch loss: 0.065226 Batch F1: 1.0
Epoch:  153        3 Batch loss: 0.109817 Batch F1: 0.45454545454545453
Epoch:  153        4 Batch loss: 0.056097 Batch F1: 0.8333333333333333
Epoch:  153        5 Batch loss: 0.076071 Batch F1: 0.2222222222222222
Epoch:  153        6 Batch loss: 0.070505 Batch F1: 0.6666666666666666
Epoch:  153        7 Batch loss: 0.062341 Batch F1: 0.0
Epoch:  153        8 Batch loss: 0.073629 Batch F1: 0.3636363636363636
Epoch:  153        9 Batch loss: 0.072104 Batch F1: 0.3636363636363636
Epoch:  153       10 Batch loss: 0.069185 Batch F1: 0.5
Epoch:  153       11 Batch loss: 0.070291 Batch F1: 0.3636363636363636
Epoch:  153       12 Batch loss: 0.056401 Batch F1: 0.7692307692307693
Train Avg Loss  153: 0.070810

Train Avg F1  153: 0.5383320383320382

Val Avg Loss  153: 0.062768

Val Avg F1  153:  0.7978896103896104

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 154
--------------------------------------------------------------
Epoch:  154        1 Batch loss: 0.061371 Batch F1: 0.8
Epoch:  154        2 Batch loss: 0.081699 Batch F1: 0.16666666666666669
Epoch:  154        3 Batch loss: 0.082395 Batch F1: 0.5
Epoch:  154        4 Batch loss: 0.052985 Batch F1: 0.9411764705882353
Epoch:  154        5 Batch loss: 0.063315 Batch F1: 1.0
Epoch:  154        6 Batch loss: 0.056710 Batch F1: 0.9411764705882353
Epoch:  154        7 Batch loss: 0.064044 Batch F1: 0.923076923076923
Epoch:  154        8 Batch loss: 0.077707 Batch F1: 0.18181818181818182
Epoch:  154        9 Batch loss: 0.068444 Batch F1: 0.6153846153846153
Epoch:  154       10 Batch loss: 0.078791 Batch F1: 0.5
Epoch:  154       11 Batch loss: 0.083299 Batch F1: 0.5
Epoch:  154       12 Batch loss: 0.062595 Batch F1: 0.9090909090909091
Train Avg Loss  154: 0.069446

Train Avg F1  154: 0.6648658531011472

Val Avg Loss  154: 0.062014

Val Avg F1  154:  0.9222222222222223

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 155
--------------------------------------------------------------
Epoch:  155        1 Batch loss: 0.074565 Batch F1: 0.9565217391304348
Epoch:  155        2 Batch loss: 0.055848 Batch F1: 1.0
Epoch:  155        3 Batch loss: 0.061170 Batch F1: 0.9411764705882353
Epoch:  155        4 Batch loss: 0.066579 Batch F1: 0.8750000000000001
Epoch:  155        5 Batch loss: 0.078271 Batch F1: 0.5333333333333333
Epoch:  155        6 Batch loss: 0.076247 Batch F1: 0.625
Epoch:  155        7 Batch loss: 0.065734 Batch F1: 0.9411764705882353
Epoch:  155        8 Batch loss: 0.072971 Batch F1: 0.8
Epoch:  155        9 Batch loss: 0.059543 Batch F1: 0.9333333333333333
Epoch:  155       10 Batch loss: 0.078429 Batch F1: 0.9090909090909091
Epoch:  155       11 Batch loss: 0.071399 Batch F1: 0.2222222222222222
Epoch:  155       12 Batch loss: 0.069316 Batch F1: 0.7142857142857143
Train Avg Loss  155: 0.069173

Train Avg F1  155: 0.7875950160477013

Val Avg Loss  155: 0.062323

Val Avg F1  155:  0.5863636363636363

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 156
--------------------------------------------------------------
Epoch:  156        1 Batch loss: 0.070428 Batch F1: 0.3636363636363636
Epoch:  156        2 Batch loss: 0.060572 Batch F1: 0.6666666666666666
Epoch:  156        3 Batch loss: 0.067806 Batch F1: 0.4615384615384615
Epoch:  156        4 Batch loss: 0.094222 Batch F1: 0.896551724137931
Epoch:  156        5 Batch loss: 0.059755 Batch F1: 0.9333333333333333
Epoch:  156        6 Batch loss: 0.068874 Batch F1: 0.9090909090909091
Epoch:  156        7 Batch loss: 0.051532 Batch F1: 1.0
Epoch:  156        8 Batch loss: 0.056491 Batch F1: 1.0
Epoch:  156        9 Batch loss: 0.088857 Batch F1: 0.3076923076923077
Epoch:  156       10 Batch loss: 0.059741 Batch F1: 0.4444444444444445
Epoch:  156       11 Batch loss: 0.093531 Batch F1: 0.16666666666666669
Epoch:  156       12 Batch loss: 0.072728 Batch F1: 0.7272727272727273
Train Avg Loss  156: 0.070378

Train Avg F1  156: 0.6564078003733177

Val Avg Loss  156: 0.063594

Val Avg F1  156:  0.5883012820512821

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 157
--------------------------------------------------------------
Epoch:  157        1 Batch loss: 0.042400 Batch F1: 0.9090909090909091
Epoch:  157        2 Batch loss: 0.089453 Batch F1: 0.47058823529411764
Epoch:  157        3 Batch loss: 0.080029 Batch F1: 0.19999999999999998
Epoch:  157        4 Batch loss: 0.060468 Batch F1: 1.0
Epoch:  157        5 Batch loss: 0.071577 Batch F1: 0.9411764705882353
Epoch:  157        6 Batch loss: 0.058341 Batch F1: 1.0
Epoch:  157        7 Batch loss: 0.090325 Batch F1: 0.8
Epoch:  157        8 Batch loss: 0.069287 Batch F1: 0.9
Epoch:  157        9 Batch loss: 0.085824 Batch F1: 0.9
Epoch:  157       10 Batch loss: 0.058074 Batch F1: 0.923076923076923
Epoch:  157       11 Batch loss: 0.056051 Batch F1: 1.0
Epoch:  157       12 Batch loss: 0.069094 Batch F1: 0.6666666666666666
Train Avg Loss  157: 0.069244

Train Avg F1  157: 0.809216600393071

Val Avg Loss  157: 0.062533

Val Avg F1  157:  0.5630252100840336

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 158
--------------------------------------------------------------
Epoch:  158        1 Batch loss: 0.071388 Batch F1: 0.19999999999999998
Epoch:  158        2 Batch loss: 0.075297 Batch F1: 0.5333333333333333
Epoch:  158        3 Batch loss: 0.049672 Batch F1: 0.2857142857142857
Epoch:  158        4 Batch loss: 0.051315 Batch F1: 0.6666666666666666
Epoch:  158        5 Batch loss: 0.074608 Batch F1: 0.5
Epoch:  158        6 Batch loss: 0.072876 Batch F1: 0.5333333333333333
Epoch:  158        7 Batch loss: 0.094840 Batch F1: 0.4
Epoch:  158        8 Batch loss: 0.054443 Batch F1: 0.6666666666666666
Epoch:  158        9 Batch loss: 0.072683 Batch F1: 0.9523809523809523
Epoch:  158       10 Batch loss: 0.050677 Batch F1: 1.0
Epoch:  158       11 Batch loss: 0.071191 Batch F1: 0.888888888888889
Epoch:  158       12 Batch loss: 0.087208 Batch F1: 0.9523809523809523
Train Avg Loss  158: 0.068850

Train Avg F1  158: 0.6316137566137566

Val Avg Loss  158: 0.062092

Val Avg F1  158:  0.9079377519032692

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 159
--------------------------------------------------------------
Epoch:  159        1 Batch loss: 0.080662 Batch F1: 0.8421052631578948
Epoch:  159        2 Batch loss: 0.075545 Batch F1: 0.9600000000000001
Epoch:  159        3 Batch loss: 0.072645 Batch F1: 1.0
Epoch:  159        4 Batch loss: 0.058771 Batch F1: 0.8333333333333333
Epoch:  159        5 Batch loss: 0.070862 Batch F1: 0.9523809523809523
Epoch:  159        6 Batch loss: 0.066633 Batch F1: 0.9473684210526316
Epoch:  159        7 Batch loss: 0.064203 Batch F1: 0.9411764705882353
Epoch:  159        8 Batch loss: 0.067158 Batch F1: 0.9333333333333333
Epoch:  159        9 Batch loss: 0.059325 Batch F1: 0.8333333333333333
Epoch:  159       10 Batch loss: 0.084362 Batch F1: 0.631578947368421
Epoch:  159       11 Batch loss: 0.054149 Batch F1: 0.5714285714285715
Epoch:  159       12 Batch loss: 0.054434 Batch F1: 0.0
Train Avg Loss  159: 0.067396

Train Avg F1  159: 0.7871698854980589

Val Avg Loss  159: 0.064668

Val Avg F1  159:  0.586038961038961

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 160
--------------------------------------------------------------
Epoch:  160        1 Batch loss: 0.067273 Batch F1: 0.8235294117647058
Epoch:  160        2 Batch loss: 0.067854 Batch F1: 0.4
Epoch:  160        3 Batch loss: 0.051416 Batch F1: 0.6
Epoch:  160        4 Batch loss: 0.074398 Batch F1: 0.2222222222222222
Epoch:  160        5 Batch loss: 0.066461 Batch F1: 0.3636363636363636
Epoch:  160        6 Batch loss: 0.075797 Batch F1: 1.0
Epoch:  160        7 Batch loss: 0.082782 Batch F1: 0.9333333333333333
Epoch:  160        8 Batch loss: 0.082756 Batch F1: 0.8695652173913044
Epoch:  160        9 Batch loss: 0.080387 Batch F1: 0.33333333333333337
Epoch:  160       10 Batch loss: 0.074913 Batch F1: 0.6153846153846153
Epoch:  160       11 Batch loss: 0.064313 Batch F1: 0.8
Epoch:  160       12 Batch loss: 0.052224 Batch F1: 0.9333333333333333
Train Avg Loss  160: 0.070048

Train Avg F1  160: 0.657861485866601

Val Avg Loss  160: 0.062271

Val Avg F1  160:  0.9233333333333333

Optimal Val loss (Epoch 116): 0.061996571719646454

Epoch 161
--------------------------------------------------------------
Epoch:  161        1 Batch loss: 0.052459 Batch F1: 1.0
Epoch:  161        2 Batch loss: 0.068890 Batch F1: 0.9333333333333333
Epoch:  161        3 Batch loss: 0.069394 Batch F1: 0.5714285714285715
Epoch:  161        4 Batch loss: 0.061576 Batch F1: 0.2857142857142857
Epoch:  161        5 Batch loss: 0.065790 Batch F1: 0.5454545454545454
Epoch:  161        6 Batch loss: 0.090798 Batch F1: 0.5
Epoch:  161        7 Batch loss: 0.051776 Batch F1: 0.6
Epoch:  161        8 Batch loss: 0.087827 Batch F1: 0.923076923076923
Epoch:  161        9 Batch loss: 0.060285 Batch F1: 0.9473684210526316
Epoch:  161       10 Batch loss: 0.073881 Batch F1: 0.9333333333333333
Epoch:  161       11 Batch loss: 0.087697 Batch F1: 0.8695652173913044
Epoch:  161       12 Batch loss: 0.061760 Batch F1: 0.6666666666666666
Train Avg Loss  161: 0.069344

Train Avg F1  161: 0.7313284414542996

Val Avg Loss  161: 0.061656

Val Avg F1  161:  0.9266304347826086

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 162
--------------------------------------------------------------
Epoch:  162        1 Batch loss: 0.088800 Batch F1: 0.9166666666666666
Epoch:  162        2 Batch loss: 0.064201 Batch F1: 1.0
Epoch:  162        3 Batch loss: 0.039157 Batch F1: 1.0
Epoch:  162        4 Batch loss: 0.063662 Batch F1: 0.8333333333333333
Epoch:  162        5 Batch loss: 0.096624 Batch F1: 0.8421052631578948
Epoch:  162        6 Batch loss: 0.067297 Batch F1: 0.9411764705882353
Epoch:  162        7 Batch loss: 0.069457 Batch F1: 0.5714285714285715
Epoch:  162        8 Batch loss: 0.052282 Batch F1: 0.6
Epoch:  162        9 Batch loss: 0.058478 Batch F1: 0.4444444444444445
Epoch:  162       10 Batch loss: 0.059664 Batch F1: 0.6
Epoch:  162       11 Batch loss: 0.087183 Batch F1: 0.3076923076923077
Epoch:  162       12 Batch loss: 0.082531 Batch F1: 0.9523809523809523
Train Avg Loss  162: 0.069111

Train Avg F1  162: 0.7507690008077005

Val Avg Loss  162: 0.064595

Val Avg F1  162:  0.9331550802139037

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 163
--------------------------------------------------------------
Epoch:  163        1 Batch loss: 0.094675 Batch F1: 0.9411764705882353
Epoch:  163        2 Batch loss: 0.079046 Batch F1: 1.0
Epoch:  163        3 Batch loss: 0.074147 Batch F1: 0.9166666666666666
Epoch:  163        4 Batch loss: 0.054142 Batch F1: 1.0
Epoch:  163        5 Batch loss: 0.068215 Batch F1: 0.0
Epoch:  163        6 Batch loss: 0.089413 Batch F1: 0.0
Epoch:  163        7 Batch loss: 0.064383 Batch F1: 0.7272727272727273
Epoch:  163        8 Batch loss: 0.085036 Batch F1: 0.8235294117647058
Epoch:  163        9 Batch loss: 0.059522 Batch F1: 0.923076923076923
Epoch:  163       10 Batch loss: 0.077544 Batch F1: 0.8750000000000001
Epoch:  163       11 Batch loss: 0.052256 Batch F1: 0.7499999999999999
Epoch:  163       12 Batch loss: 0.090000 Batch F1: 0.5
Train Avg Loss  163: 0.074031

Train Avg F1  163: 0.7047268499474382

Val Avg Loss  163: 0.068715

Val Avg F1  163:  0.5750534188034188

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 164
--------------------------------------------------------------
Epoch:  164        1 Batch loss: 0.055842 Batch F1: 0.6
Epoch:  164        2 Batch loss: 0.096880 Batch F1: 0.16666666666666669
Epoch:  164        3 Batch loss: 0.058634 Batch F1: 1.0
Epoch:  164        4 Batch loss: 0.061551 Batch F1: 0.888888888888889
Epoch:  164        5 Batch loss: 0.062006 Batch F1: 0.6666666666666666
Epoch:  164        6 Batch loss: 0.066033 Batch F1: 0.4
Epoch:  164        7 Batch loss: 0.097047 Batch F1: 0.5263157894736842
Epoch:  164        8 Batch loss: 0.045355 Batch F1: 0.888888888888889
Epoch:  164        9 Batch loss: 0.087424 Batch F1: 0.7142857142857143
Epoch:  164       10 Batch loss: 0.076442 Batch F1: 0.9600000000000001
Epoch:  164       11 Batch loss: 0.070626 Batch F1: 0.9523809523809523
Epoch:  164       12 Batch loss: 0.083275 Batch F1: 0.8
Train Avg Loss  164: 0.071760

Train Avg F1  164: 0.7136744639376219

Val Avg Loss  164: 0.064090

Val Avg F1  164:  0.9057971014492754

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 165
--------------------------------------------------------------
Epoch:  165        1 Batch loss: 0.057286 Batch F1: 0.923076923076923
Epoch:  165        2 Batch loss: 0.062569 Batch F1: 0.9411764705882353
Epoch:  165        3 Batch loss: 0.065184 Batch F1: 0.25
Epoch:  165        4 Batch loss: 0.090378 Batch F1: 0.47058823529411764
Epoch:  165        5 Batch loss: 0.094489 Batch F1: 0.8333333333333333
Epoch:  165        6 Batch loss: 0.074275 Batch F1: 1.0
Epoch:  165        7 Batch loss: 0.081587 Batch F1: 1.0
Epoch:  165        8 Batch loss: 0.062847 Batch F1: 0.8333333333333333
Epoch:  165        9 Batch loss: 0.071542 Batch F1: 0.6153846153846153
Epoch:  165       10 Batch loss: 0.087374 Batch F1: 0.4615384615384615
Epoch:  165       11 Batch loss: 0.059097 Batch F1: 0.2857142857142857
Epoch:  165       12 Batch loss: 0.060432 Batch F1: 0.5454545454545454
Train Avg Loss  165: 0.072255

Train Avg F1  165: 0.6799666836431543

Val Avg Loss  165: 0.063864

Val Avg F1  165:  0.5555555555555556

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 166
--------------------------------------------------------------
Epoch:  166        1 Batch loss: 0.040832 Batch F1: 0.8571428571428571
Epoch:  166        2 Batch loss: 0.076000 Batch F1: 0.5333333333333333
Epoch:  166        3 Batch loss: 0.073605 Batch F1: 0.3636363636363636
Epoch:  166        4 Batch loss: 0.074207 Batch F1: 0.8181818181818181
Epoch:  166        5 Batch loss: 0.076278 Batch F1: 0.9473684210526316
Epoch:  166        6 Batch loss: 0.076624 Batch F1: 0.9473684210526316
Epoch:  166        7 Batch loss: 0.069779 Batch F1: 0.25
Epoch:  166        8 Batch loss: 0.082638 Batch F1: 0.4615384615384615
Epoch:  166        9 Batch loss: 0.058305 Batch F1: 0.6
Epoch:  166       10 Batch loss: 0.072050 Batch F1: 0.6153846153846153
Epoch:  166       11 Batch loss: 0.089813 Batch F1: 0.4
Epoch:  166       12 Batch loss: 0.071630 Batch F1: 0.9090909090909091
Train Avg Loss  166: 0.071813

Train Avg F1  166: 0.6419204333678018

Val Avg Loss  166: 0.063196

Val Avg F1  166:  0.9246411483253588

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 167
--------------------------------------------------------------
Epoch:  167        1 Batch loss: 0.076036 Batch F1: 0.8750000000000001
Epoch:  167        2 Batch loss: 0.066691 Batch F1: 0.9411764705882353
Epoch:  167        3 Batch loss: 0.071820 Batch F1: 0.9411764705882353
Epoch:  167        4 Batch loss: 0.095501 Batch F1: 0.9333333333333333
Epoch:  167        5 Batch loss: 0.070281 Batch F1: 0.8
Epoch:  167        6 Batch loss: 0.065447 Batch F1: 0.9333333333333333
Epoch:  167        7 Batch loss: 0.069408 Batch F1: 1.0
Epoch:  167        8 Batch loss: 0.076795 Batch F1: 0.9411764705882353
Epoch:  167        9 Batch loss: 0.057597 Batch F1: 0.888888888888889
Epoch:  167       10 Batch loss: 0.077234 Batch F1: 0.5333333333333333
Epoch:  167       11 Batch loss: 0.070018 Batch F1: 0.3636363636363636
Epoch:  167       12 Batch loss: 0.048440 Batch F1: 0.4
Train Avg Loss  167: 0.070439

Train Avg F1  167: 0.7959212220241633

Val Avg Loss  167: 0.064633

Val Avg F1  167:  0.5799533799533799

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 168
--------------------------------------------------------------
Epoch:  168        1 Batch loss: 0.064543 Batch F1: 0.4
Epoch:  168        2 Batch loss: 0.058463 Batch F1: 0.4444444444444445
Epoch:  168        3 Batch loss: 0.067792 Batch F1: 0.5454545454545454
Epoch:  168        4 Batch loss: 0.076315 Batch F1: 0.5333333333333333
Epoch:  168        5 Batch loss: 0.063367 Batch F1: 0.6666666666666666
Epoch:  168        6 Batch loss: 0.074481 Batch F1: 0.9565217391304348
Epoch:  168        7 Batch loss: 0.065982 Batch F1: 0.8750000000000001
Epoch:  168        8 Batch loss: 0.067654 Batch F1: 1.0
Epoch:  168        9 Batch loss: 0.059011 Batch F1: 1.0
Epoch:  168       10 Batch loss: 0.064713 Batch F1: 0.5454545454545454
Epoch:  168       11 Batch loss: 0.085005 Batch F1: 0.42857142857142855
Epoch:  168       12 Batch loss: 0.099105 Batch F1: 0.33333333333333337
Train Avg Loss  168: 0.070536

Train Avg F1  168: 0.6440650030323943

Val Avg Loss  168: 0.062138

Val Avg F1  168:  0.9172619047619046

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 169
--------------------------------------------------------------
Epoch:  169        1 Batch loss: 0.089025 Batch F1: 0.9333333333333333
Epoch:  169        2 Batch loss: 0.054723 Batch F1: 0.888888888888889
Epoch:  169        3 Batch loss: 0.068213 Batch F1: 1.0
Epoch:  169        4 Batch loss: 0.061021 Batch F1: 0.8333333333333333
Epoch:  169        5 Batch loss: 0.067034 Batch F1: 0.888888888888889
Epoch:  169        6 Batch loss: 0.067078 Batch F1: 0.8333333333333333
Epoch:  169        7 Batch loss: 0.061553 Batch F1: 0.5
Epoch:  169        8 Batch loss: 0.135766 Batch F1: 0.4166666666666667
Epoch:  169        9 Batch loss: 0.067024 Batch F1: 0.5454545454545454
Epoch:  169       10 Batch loss: 0.088990 Batch F1: 0.761904761904762
Epoch:  169       11 Batch loss: 0.051020 Batch F1: 1.0
Epoch:  169       12 Batch loss: 0.078920 Batch F1: 1.0
Train Avg Loss  169: 0.074197

Train Avg F1  169: 0.8001503126503128

Val Avg Loss  169: 0.065568

Val Avg F1  169:  0.7392411510058567

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 170
--------------------------------------------------------------
Epoch:  170        1 Batch loss: 0.078961 Batch F1: 0.5714285714285715
Epoch:  170        2 Batch loss: 0.091549 Batch F1: 0.2857142857142857
Epoch:  170        3 Batch loss: 0.067105 Batch F1: 0.6666666666666666
Epoch:  170        4 Batch loss: 0.072876 Batch F1: 0.6666666666666666
Epoch:  170        5 Batch loss: 0.072080 Batch F1: 0.9523809523809523
Epoch:  170        6 Batch loss: 0.072030 Batch F1: 0.9473684210526316
Epoch:  170        7 Batch loss: 0.060420 Batch F1: 0.7499999999999999
Epoch:  170        8 Batch loss: 0.057218 Batch F1: 0.5454545454545454
Epoch:  170        9 Batch loss: 0.071213 Batch F1: 0.5
Epoch:  170       10 Batch loss: 0.099611 Batch F1: 0.47058823529411764
Epoch:  170       11 Batch loss: 0.055642 Batch F1: 0.923076923076923
Epoch:  170       12 Batch loss: 0.064573 Batch F1: 0.7499999999999999
Train Avg Loss  170: 0.071940

Train Avg F1  170: 0.6691121056446133

Val Avg Loss  170: 0.063097

Val Avg F1  170:  0.742948717948718

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 171
--------------------------------------------------------------
Epoch:  171        1 Batch loss: 0.082670 Batch F1: 0.5714285714285715
Epoch:  171        2 Batch loss: 0.040059 Batch F1: 0.4
Epoch:  171        3 Batch loss: 0.099405 Batch F1: 0.5263157894736842
Epoch:  171        4 Batch loss: 0.050359 Batch F1: 0.8333333333333333
Epoch:  171        5 Batch loss: 0.064639 Batch F1: 0.4
Epoch:  171        6 Batch loss: 0.060545 Batch F1: 0.0
Epoch:  171        7 Batch loss: 0.093069 Batch F1: 0.5
Epoch:  171        8 Batch loss: 0.063128 Batch F1: 1.0
Epoch:  171        9 Batch loss: 0.083639 Batch F1: 0.9
Epoch:  171       10 Batch loss: 0.074617 Batch F1: 0.9473684210526316
Epoch:  171       11 Batch loss: 0.055529 Batch F1: 1.0
Epoch:  171       12 Batch loss: 0.074289 Batch F1: 0.8333333333333333
Train Avg Loss  171: 0.070162

Train Avg F1  171: 0.6593149540517962

Val Avg Loss  171: 0.063091

Val Avg F1  171:  0.5806220095693779

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 172
--------------------------------------------------------------
Epoch:  172        1 Batch loss: 0.064315 Batch F1: 0.6
Epoch:  172        2 Batch loss: 0.077432 Batch F1: 0.5333333333333333
Epoch:  172        3 Batch loss: 0.125087 Batch F1: 0.45454545454545453
Epoch:  172        4 Batch loss: 0.062224 Batch F1: 0.2222222222222222
Epoch:  172        5 Batch loss: 0.071472 Batch F1: 0.8571428571428571
Epoch:  172        6 Batch loss: 0.053766 Batch F1: 1.0
Epoch:  172        7 Batch loss: 0.057025 Batch F1: 1.0
Epoch:  172        8 Batch loss: 0.064296 Batch F1: 1.0
Epoch:  172        9 Batch loss: 0.075629 Batch F1: 0.8571428571428571
Epoch:  172       10 Batch loss: 0.071874 Batch F1: 0.888888888888889
Epoch:  172       11 Batch loss: 0.049314 Batch F1: 0.8
Epoch:  172       12 Batch loss: 0.073597 Batch F1: 0.4
Train Avg Loss  172: 0.070503

Train Avg F1  172: 0.7177729677729677

Val Avg Loss  172: 0.063795

Val Avg F1  172:  0.5637254901960784

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 173
--------------------------------------------------------------
Epoch:  173        1 Batch loss: 0.054141 Batch F1: 0.25
Epoch:  173        2 Batch loss: 0.076185 Batch F1: 0.4615384615384615
Epoch:  173        3 Batch loss: 0.069752 Batch F1: 0.5333333333333333
Epoch:  173        4 Batch loss: 0.056185 Batch F1: 1.0
Epoch:  173        5 Batch loss: 0.070503 Batch F1: 0.8571428571428571
Epoch:  173        6 Batch loss: 0.081886 Batch F1: 0.8421052631578948
Epoch:  173        7 Batch loss: 0.063279 Batch F1: 1.0
Epoch:  173        8 Batch loss: 0.072386 Batch F1: 0.9565217391304348
Epoch:  173        9 Batch loss: 0.085959 Batch F1: 0.923076923076923
Epoch:  173       10 Batch loss: 0.066110 Batch F1: 0.7272727272727273
Epoch:  173       11 Batch loss: 0.074432 Batch F1: 0.8571428571428571
Epoch:  173       12 Batch loss: 0.051106 Batch F1: 0.888888888888889
Train Avg Loss  173: 0.068494

Train Avg F1  173: 0.7747519208903649

Val Avg Loss  173: 0.063861

Val Avg F1  173:  0.5487179487179487

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 174
--------------------------------------------------------------
Epoch:  174        1 Batch loss: 0.067110 Batch F1: 0.3636363636363636
Epoch:  174        2 Batch loss: 0.083920 Batch F1: 0.782608695652174
Epoch:  174        3 Batch loss: 0.078203 Batch F1: 0.19999999999999998
Epoch:  174        4 Batch loss: 0.073101 Batch F1: 0.8750000000000001
Epoch:  174        5 Batch loss: 0.086050 Batch F1: 1.0
Epoch:  174        6 Batch loss: 0.065703 Batch F1: 0.9333333333333333
Epoch:  174        7 Batch loss: 0.089904 Batch F1: 0.7058823529411764
Epoch:  174        8 Batch loss: 0.062186 Batch F1: 1.0
Epoch:  174        9 Batch loss: 0.085203 Batch F1: 0.4
Epoch:  174       10 Batch loss: 0.051788 Batch F1: 0.6
Epoch:  174       11 Batch loss: 0.049339 Batch F1: 0.5714285714285715
Epoch:  174       12 Batch loss: 0.035374 Batch F1: 0.6666666666666666
Train Avg Loss  174: 0.068990

Train Avg F1  174: 0.6748796653048571

Val Avg Loss  174: 0.065798

Val Avg F1  174:  0.5670995670995671

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 175
--------------------------------------------------------------
Epoch:  175        1 Batch loss: 0.089764 Batch F1: 0.5263157894736842
Epoch:  175        2 Batch loss: 0.053057 Batch F1: 0.0
Epoch:  175        3 Batch loss: 0.086742 Batch F1: 0.5555555555555556
Epoch:  175        4 Batch loss: 0.069922 Batch F1: 0.3636363636363636
Epoch:  175        5 Batch loss: 0.052597 Batch F1: 0.9333333333333333
Epoch:  175        6 Batch loss: 0.067838 Batch F1: 0.7142857142857143
Epoch:  175        7 Batch loss: 0.066124 Batch F1: 0.923076923076923
Epoch:  175        8 Batch loss: 0.084036 Batch F1: 0.9166666666666666
Epoch:  175        9 Batch loss: 0.072185 Batch F1: 0.8750000000000001
Epoch:  175       10 Batch loss: 0.091978 Batch F1: 0.962962962962963
Epoch:  175       11 Batch loss: 0.058468 Batch F1: 1.0
Epoch:  175       12 Batch loss: 0.051567 Batch F1: 1.0
Train Avg Loss  175: 0.070357

Train Avg F1  175: 0.730902775749267

Val Avg Loss  175: 0.064177

Val Avg F1  175:  0.5276610644257702

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 176
--------------------------------------------------------------
Epoch:  176        1 Batch loss: 0.061810 Batch F1: 0.7272727272727273
Epoch:  176        2 Batch loss: 0.064134 Batch F1: 0.4444444444444445
Epoch:  176        3 Batch loss: 0.084531 Batch F1: 0.3636363636363636
Epoch:  176        4 Batch loss: 0.069943 Batch F1: 0.7058823529411764
Epoch:  176        5 Batch loss: 0.049679 Batch F1: 0.5714285714285715
Epoch:  176        6 Batch loss: 0.085219 Batch F1: 0.5333333333333333
Epoch:  176        7 Batch loss: 0.062770 Batch F1: 1.0
Epoch:  176        8 Batch loss: 0.080682 Batch F1: 0.888888888888889
Epoch:  176        9 Batch loss: 0.105235 Batch F1: 0.9714285714285714
Epoch:  176       10 Batch loss: 0.070107 Batch F1: 0.9333333333333333
Epoch:  176       11 Batch loss: 0.058275 Batch F1: 0.923076923076923
Epoch:  176       12 Batch loss: 0.081340 Batch F1: 0.7692307692307693
Train Avg Loss  176: 0.072810

Train Avg F1  176: 0.7359963565845921

Val Avg Loss  176: 0.062520

Val Avg F1  176:  0.6048265460030166

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 177
--------------------------------------------------------------
Epoch:  177        1 Batch loss: 0.057700 Batch F1: 0.6666666666666666
Epoch:  177        2 Batch loss: 0.063216 Batch F1: 0.6153846153846153
Epoch:  177        3 Batch loss: 0.074593 Batch F1: 0.5333333333333333
Epoch:  177        4 Batch loss: 0.089907 Batch F1: 0.42857142857142855
Epoch:  177        5 Batch loss: 0.069706 Batch F1: 1.0
Epoch:  177        6 Batch loss: 0.104073 Batch F1: 0.5714285714285715
Epoch:  177        7 Batch loss: 0.072749 Batch F1: 1.0
Epoch:  177        8 Batch loss: 0.061620 Batch F1: 0.5454545454545454
Epoch:  177        9 Batch loss: 0.092610 Batch F1: 0.3636363636363636
Epoch:  177       10 Batch loss: 0.107891 Batch F1: 0.3076923076923077
Epoch:  177       11 Batch loss: 0.035956 Batch F1: 0.5
Epoch:  177       12 Batch loss: 0.090033 Batch F1: 0.7058823529411764
Train Avg Loss  177: 0.076671

Train Avg F1  177: 0.603170848759084

Val Avg Loss  177: 0.066358

Val Avg F1  177:  0.9223276723276723

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 178
--------------------------------------------------------------
Epoch:  178        1 Batch loss: 0.082822 Batch F1: 0.9090909090909091
Epoch:  178        2 Batch loss: 0.107756 Batch F1: 1.0
Epoch:  178        3 Batch loss: 0.078828 Batch F1: 0.9473684210526316
Epoch:  178        4 Batch loss: 0.079744 Batch F1: 0.9565217391304348
Epoch:  178        5 Batch loss: 0.050814 Batch F1: 1.0
Epoch:  178        6 Batch loss: 0.088488 Batch F1: 0.0
Epoch:  178        7 Batch loss: 0.056451 Batch F1: 1.0
Epoch:  178        8 Batch loss: 0.058957 Batch F1: 0.888888888888889
Epoch:  178        9 Batch loss: 0.066377 Batch F1: 0.923076923076923
Epoch:  178       10 Batch loss: 0.084213 Batch F1: 0.625
Epoch:  178       11 Batch loss: 0.094167 Batch F1: 0.5333333333333333
Epoch:  178       12 Batch loss: 0.066507 Batch F1: 0.5
Train Avg Loss  178: 0.076260

Train Avg F1  178: 0.7736066845477602

Val Avg Loss  178: 0.066456

Val Avg F1  178:  0.5712258329905389

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 179
--------------------------------------------------------------
Epoch:  179        1 Batch loss: 0.069015 Batch F1: 0.5714285714285715
Epoch:  179        2 Batch loss: 0.066327 Batch F1: 0.6666666666666666
Epoch:  179        3 Batch loss: 0.092450 Batch F1: 0.5555555555555556
Epoch:  179        4 Batch loss: 0.048919 Batch F1: 1.0
Epoch:  179        5 Batch loss: 0.082373 Batch F1: 0.7499999999999999
Epoch:  179        6 Batch loss: 0.089527 Batch F1: 0.8421052631578948
Epoch:  179        7 Batch loss: 0.066414 Batch F1: 0.7499999999999999
Epoch:  179        8 Batch loss: 0.076201 Batch F1: 0.2222222222222222
Epoch:  179        9 Batch loss: 0.062070 Batch F1: 0.7499999999999999
Epoch:  179       10 Batch loss: 0.062013 Batch F1: 0.0
Epoch:  179       11 Batch loss: 0.083441 Batch F1: 0.4615384615384615
Epoch:  179       12 Batch loss: 0.057664 Batch F1: 0.923076923076923
Train Avg Loss  179: 0.071368

Train Avg F1  179: 0.6243828053038579

Val Avg Loss  179: 0.065442

Val Avg F1  179:  0.7455357142857142

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 180
--------------------------------------------------------------
Epoch:  180        1 Batch loss: 0.062721 Batch F1: 0.5
Epoch:  180        2 Batch loss: 0.064408 Batch F1: 0.25
Epoch:  180        3 Batch loss: 0.079530 Batch F1: 0.33333333333333337
Epoch:  180        4 Batch loss: 0.085023 Batch F1: 0.47058823529411764
Epoch:  180        5 Batch loss: 0.057484 Batch F1: 0.923076923076923
Epoch:  180        6 Batch loss: 0.092243 Batch F1: 0.7499999999999999
Epoch:  180        7 Batch loss: 0.056192 Batch F1: 1.0
Epoch:  180        8 Batch loss: 0.078637 Batch F1: 0.9090909090909091
Epoch:  180        9 Batch loss: 0.090778 Batch F1: 0.9166666666666666
Epoch:  180       10 Batch loss: 0.075194 Batch F1: 0.9600000000000001
Epoch:  180       11 Batch loss: 0.059239 Batch F1: 0.888888888888889
Epoch:  180       12 Batch loss: 0.061732 Batch F1: 0.923076923076923
Train Avg Loss  180: 0.071932

Train Avg F1  180: 0.7353934899523136

Val Avg Loss  180: 0.063991

Val Avg F1  180:  0.9142857142857144

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 181
--------------------------------------------------------------
Epoch:  181        1 Batch loss: 0.065255 Batch F1: 0.9473684210526316
Epoch:  181        2 Batch loss: 0.078838 Batch F1: 0.8
Epoch:  181        3 Batch loss: 0.076736 Batch F1: 0.6153846153846153
Epoch:  181        4 Batch loss: 0.065482 Batch F1: 0.5714285714285715
Epoch:  181        5 Batch loss: 0.067744 Batch F1: 0.6666666666666666
Epoch:  181        6 Batch loss: 0.065215 Batch F1: 0.9411764705882353
Epoch:  181        7 Batch loss: 0.048374 Batch F1: 1.0
Epoch:  181        8 Batch loss: 0.066232 Batch F1: 0.5714285714285715
Epoch:  181        9 Batch loss: 0.076400 Batch F1: 0.4615384615384615
Epoch:  181       10 Batch loss: 0.066115 Batch F1: 0.6153846153846153
Epoch:  181       11 Batch loss: 0.082927 Batch F1: 0.18181818181818182
Epoch:  181       12 Batch loss: 0.072104 Batch F1: 0.25
Train Avg Loss  181: 0.069285

Train Avg F1  181: 0.6351828812742125

Val Avg Loss  181: 0.062969

Val Avg F1  181:  0.5979166666666667

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 182
--------------------------------------------------------------
Epoch:  182        1 Batch loss: 0.062669 Batch F1: 0.6666666666666666
Epoch:  182        2 Batch loss: 0.085955 Batch F1: 0.9166666666666666
Epoch:  182        3 Batch loss: 0.079921 Batch F1: 0.9473684210526316
Epoch:  182        4 Batch loss: 0.073969 Batch F1: 0.8571428571428571
Epoch:  182        5 Batch loss: 0.048025 Batch F1: 1.0
Epoch:  182        6 Batch loss: 0.066013 Batch F1: 0.9333333333333333
Epoch:  182        7 Batch loss: 0.031708 Batch F1: 0.8571428571428571
Epoch:  182        8 Batch loss: 0.079135 Batch F1: 0.4615384615384615
Epoch:  182        9 Batch loss: 0.084551 Batch F1: 0.6153846153846153
Epoch:  182       10 Batch loss: 0.086294 Batch F1: 0.5
Epoch:  182       11 Batch loss: 0.080254 Batch F1: 0.5555555555555556
Epoch:  182       12 Batch loss: 0.089285 Batch F1: 0.8571428571428571
Train Avg Loss  182: 0.072315

Train Avg F1  182: 0.7639951909688752

Val Avg Loss  182: 0.066977

Val Avg F1  182:  0.9139254385964912

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 183
--------------------------------------------------------------
Epoch:  183        1 Batch loss: 0.085757 Batch F1: 0.9285714285714286
Epoch:  183        2 Batch loss: 0.080439 Batch F1: 0.8571428571428571
Epoch:  183        3 Batch loss: 0.068565 Batch F1: 0.888888888888889
Epoch:  183        4 Batch loss: 0.064847 Batch F1: 0.8333333333333333
Epoch:  183        5 Batch loss: 0.078979 Batch F1: 0.9523809523809523
Epoch:  183        6 Batch loss: 0.084724 Batch F1: 0.0
Epoch:  183        7 Batch loss: 0.091521 Batch F1: 0.4615384615384615
Epoch:  183        8 Batch loss: 0.083331 Batch F1: 0.6666666666666666
Epoch:  183        9 Batch loss: 0.056352 Batch F1: 1.0
Epoch:  183       10 Batch loss: 0.056696 Batch F1: 0.923076923076923
Epoch:  183       11 Batch loss: 0.071138 Batch F1: 1.0
Epoch:  183       12 Batch loss: 0.061169 Batch F1: 0.923076923076923
Train Avg Loss  183: 0.073627

Train Avg F1  183: 0.7862230362230364

Val Avg Loss  183: 0.068958

Val Avg F1  183:  0.7394033211370673

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 184
--------------------------------------------------------------
Epoch:  184        1 Batch loss: 0.058734 Batch F1: 0.8
Epoch:  184        2 Batch loss: 0.072272 Batch F1: 0.4444444444444445
Epoch:  184        3 Batch loss: 0.087253 Batch F1: 0.7058823529411764
Epoch:  184        4 Batch loss: 0.089047 Batch F1: 0.5
Epoch:  184        5 Batch loss: 0.087640 Batch F1: 0.3076923076923077
Epoch:  184        6 Batch loss: 0.062328 Batch F1: 0.923076923076923
Epoch:  184        7 Batch loss: 0.073955 Batch F1: 0.9411764705882353
Epoch:  184        8 Batch loss: 0.066832 Batch F1: 1.0
Epoch:  184        9 Batch loss: 0.051886 Batch F1: 0.6
Epoch:  184       10 Batch loss: 0.074756 Batch F1: 0.5
Epoch:  184       11 Batch loss: 0.088647 Batch F1: 0.5333333333333333
Epoch:  184       12 Batch loss: 0.062643 Batch F1: 0.5714285714285715
Train Avg Loss  184: 0.072999

Train Avg F1  184: 0.6522528669587492

Val Avg Loss  184: 0.065536

Val Avg F1  184:  0.5957767722473605

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 185
--------------------------------------------------------------
Epoch:  185        1 Batch loss: 0.098639 Batch F1: 0.5263157894736842
Epoch:  185        2 Batch loss: 0.065459 Batch F1: 0.25
Epoch:  185        3 Batch loss: 0.083781 Batch F1: 0.9565217391304348
Epoch:  185        4 Batch loss: 0.079859 Batch F1: 0.888888888888889
Epoch:  185        5 Batch loss: 0.050346 Batch F1: 1.0
Epoch:  185        6 Batch loss: 0.064121 Batch F1: 0.9090909090909091
Epoch:  185        7 Batch loss: 0.068387 Batch F1: 0.9473684210526316
Epoch:  185        8 Batch loss: 0.060624 Batch F1: 0.8421052631578948
Epoch:  185        9 Batch loss: 0.062393 Batch F1: 0.4
Epoch:  185       10 Batch loss: 0.052517 Batch F1: 0.5
Epoch:  185       11 Batch loss: 0.102231 Batch F1: 0.18181818181818182
Epoch:  185       12 Batch loss: 0.070793 Batch F1: 0.0
Train Avg Loss  185: 0.071596

Train Avg F1  185: 0.6168424327177188

Val Avg Loss  185: 0.063279

Val Avg F1  185:  0.7779605263157895

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 186
--------------------------------------------------------------
Epoch:  186        1 Batch loss: 0.075320 Batch F1: 0.8
Epoch:  186        2 Batch loss: 0.056762 Batch F1: 1.0
Epoch:  186        3 Batch loss: 0.089756 Batch F1: 0.7058823529411764
Epoch:  186        4 Batch loss: 0.072705 Batch F1: 1.0
Epoch:  186        5 Batch loss: 0.074851 Batch F1: 1.0
Epoch:  186        6 Batch loss: 0.060760 Batch F1: 0.923076923076923
Epoch:  186        7 Batch loss: 0.064185 Batch F1: 1.0
Epoch:  186        8 Batch loss: 0.090967 Batch F1: 0.5263157894736842
Epoch:  186        9 Batch loss: 0.054819 Batch F1: 0.6666666666666666
Epoch:  186       10 Batch loss: 0.050899 Batch F1: 0.7499999999999999
Epoch:  186       11 Batch loss: 0.070862 Batch F1: 0.2222222222222222
Epoch:  186       12 Batch loss: 0.091310 Batch F1: 0.0
Train Avg Loss  186: 0.071100

Train Avg F1  186: 0.7161803295317227

Val Avg Loss  186: 0.063398

Val Avg F1  186:  0.5865384615384615

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 187
--------------------------------------------------------------
Epoch:  187        1 Batch loss: 0.062433 Batch F1: 0.6666666666666666
Epoch:  187        2 Batch loss: 0.049733 Batch F1: 0.9090909090909091
Epoch:  187        3 Batch loss: 0.061105 Batch F1: 0.8571428571428571
Epoch:  187        4 Batch loss: 0.100785 Batch F1: 0.9285714285714286
Epoch:  187        5 Batch loss: 0.074711 Batch F1: 1.0
Epoch:  187        6 Batch loss: 0.069992 Batch F1: 0.9411764705882353
Epoch:  187        7 Batch loss: 0.077287 Batch F1: 0.888888888888889
Epoch:  187        8 Batch loss: 0.065386 Batch F1: 1.0
Epoch:  187        9 Batch loss: 0.069959 Batch F1: 0.6666666666666666
Epoch:  187       10 Batch loss: 0.062692 Batch F1: 0.5454545454545454
Epoch:  187       11 Batch loss: 0.098288 Batch F1: 0.18181818181818182
Epoch:  187       12 Batch loss: 0.043416 Batch F1: 0.7499999999999999
Train Avg Loss  187: 0.069649

Train Avg F1  187: 0.7779563845740317

Val Avg Loss  187: 0.063613

Val Avg F1  187:  0.5833333333333333

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 188
--------------------------------------------------------------
Epoch:  188        1 Batch loss: 0.067377 Batch F1: 0.4615384615384615
Epoch:  188        2 Batch loss: 0.073850 Batch F1: 0.5714285714285715
Epoch:  188        3 Batch loss: 0.049962 Batch F1: 1.0
Epoch:  188        4 Batch loss: 0.093847 Batch F1: 0.8571428571428571
Epoch:  188        5 Batch loss: 0.068678 Batch F1: 0.9523809523809523
Epoch:  188        6 Batch loss: 0.056304 Batch F1: 0.923076923076923
Epoch:  188        7 Batch loss: 0.059489 Batch F1: 0.888888888888889
Epoch:  188        8 Batch loss: 0.065740 Batch F1: 0.5
Epoch:  188        9 Batch loss: 0.058466 Batch F1: 0.5
Epoch:  188       10 Batch loss: 0.080893 Batch F1: 0.6153846153846153
Epoch:  188       11 Batch loss: 0.107943 Batch F1: 0.2666666666666667
Epoch:  188       12 Batch loss: 0.085699 Batch F1: 0.3636363636363636
Train Avg Loss  188: 0.072354

Train Avg F1  188: 0.6583453583453583

Val Avg Loss  188: 0.063238

Val Avg F1  188:  0.9106854838709678

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 189
--------------------------------------------------------------
Epoch:  189        1 Batch loss: 0.055353 Batch F1: 0.923076923076923
Epoch:  189        2 Batch loss: 0.067330 Batch F1: 0.923076923076923
Epoch:  189        3 Batch loss: 0.071312 Batch F1: 0.8571428571428571
Epoch:  189        4 Batch loss: 0.078844 Batch F1: 0.7692307692307693
Epoch:  189        5 Batch loss: 0.082716 Batch F1: 0.5
Epoch:  189        6 Batch loss: 0.083580 Batch F1: 0.3076923076923077
Epoch:  189        7 Batch loss: 0.069345 Batch F1: 0.6666666666666666
Epoch:  189        8 Batch loss: 0.089016 Batch F1: 0.5555555555555556
Epoch:  189        9 Batch loss: 0.073556 Batch F1: 0.9565217391304348
Epoch:  189       10 Batch loss: 0.067899 Batch F1: 1.0
Epoch:  189       11 Batch loss: 0.064899 Batch F1: 1.0
Epoch:  189       12 Batch loss: 0.064786 Batch F1: 0.6153846153846153
Train Avg Loss  189: 0.072386

Train Avg F1  189: 0.7561956964130876

Val Avg Loss  189: 0.066139

Val Avg F1  189:  0.5987076648841354

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 190
--------------------------------------------------------------
Epoch:  190        1 Batch loss: 0.062405 Batch F1: 0.25
Epoch:  190        2 Batch loss: 0.080287 Batch F1: 0.33333333333333337
Epoch:  190        3 Batch loss: 0.086065 Batch F1: 0.631578947368421
Epoch:  190        4 Batch loss: 0.068745 Batch F1: 0.9565217391304348
Epoch:  190        5 Batch loss: 0.063385 Batch F1: 1.0
Epoch:  190        6 Batch loss: 0.077496 Batch F1: 0.8333333333333333
Epoch:  190        7 Batch loss: 0.086679 Batch F1: 0.8571428571428571
Epoch:  190        8 Batch loss: 0.085153 Batch F1: 0.8
Epoch:  190        9 Batch loss: 0.054332 Batch F1: 0.923076923076923
Epoch:  190       10 Batch loss: 0.058630 Batch F1: 0.5
Epoch:  190       11 Batch loss: 0.060287 Batch F1: 0.25
Epoch:  190       12 Batch loss: 0.102923 Batch F1: 0.33333333333333337
Train Avg Loss  190: 0.073866

Train Avg F1  190: 0.6390267055598863

Val Avg Loss  190: 0.065600

Val Avg F1  190:  0.5611111111111111

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 191
--------------------------------------------------------------
Epoch:  191        1 Batch loss: 0.076912 Batch F1: 0.631578947368421
Epoch:  191        2 Batch loss: 0.067441 Batch F1: 1.0
Epoch:  191        3 Batch loss: 0.092471 Batch F1: 0.7142857142857143
Epoch:  191        4 Batch loss: 0.092639 Batch F1: 0.8421052631578948
Epoch:  191        5 Batch loss: 0.082744 Batch F1: 0.8750000000000001
Epoch:  191        6 Batch loss: 0.085110 Batch F1: 0.8695652173913044
Epoch:  191        7 Batch loss: 0.067507 Batch F1: 0.9473684210526316
Epoch:  191        8 Batch loss: 0.061001 Batch F1: 0.9090909090909091
Epoch:  191        9 Batch loss: 0.052758 Batch F1: 1.0
Epoch:  191       10 Batch loss: 0.064850 Batch F1: 0.5454545454545454
Epoch:  191       11 Batch loss: 0.062956 Batch F1: 0.5
Epoch:  191       12 Batch loss: 0.066686 Batch F1: 0.6
Train Avg Loss  191: 0.072756

Train Avg F1  191: 0.7862040848167852

Val Avg Loss  191: 0.066750

Val Avg F1  191:  0.5904761904761904

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 192
--------------------------------------------------------------
Epoch:  192        1 Batch loss: 0.071612 Batch F1: 0.4615384615384615
Epoch:  192        2 Batch loss: 0.063056 Batch F1: 0.5
Epoch:  192        3 Batch loss: 0.072104 Batch F1: 0.3636363636363636
Epoch:  192        4 Batch loss: 0.077971 Batch F1: 0.625
Epoch:  192        5 Batch loss: 0.070792 Batch F1: 0.9473684210526316
Epoch:  192        6 Batch loss: 0.062722 Batch F1: 0.9333333333333333
Epoch:  192        7 Batch loss: 0.065362 Batch F1: 0.9333333333333333
Epoch:  192        8 Batch loss: 0.097176 Batch F1: 0.47058823529411764
Epoch:  192        9 Batch loss: 0.077729 Batch F1: 0.3636363636363636
Epoch:  192       10 Batch loss: 0.068008 Batch F1: 0.923076923076923
Epoch:  192       11 Batch loss: 0.063730 Batch F1: 1.0
Epoch:  192       12 Batch loss: 0.061313 Batch F1: 1.0
Train Avg Loss  192: 0.070964

Train Avg F1  192: 0.7101259529084607

Val Avg Loss  192: 0.063273

Val Avg F1  192:  0.7123015873015873

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 193
--------------------------------------------------------------
Epoch:  193        1 Batch loss: 0.069800 Batch F1: 0.7142857142857143
Epoch:  193        2 Batch loss: 0.066487 Batch F1: 0.25
Epoch:  193        3 Batch loss: 0.074730 Batch F1: 0.4
Epoch:  193        4 Batch loss: 0.077453 Batch F1: 0.7058823529411764
Epoch:  193        5 Batch loss: 0.066702 Batch F1: 0.9411764705882353
Epoch:  193        6 Batch loss: 0.070467 Batch F1: 1.0
Epoch:  193        7 Batch loss: 0.063309 Batch F1: 0.9
Epoch:  193        8 Batch loss: 0.064477 Batch F1: 0.8571428571428571
Epoch:  193        9 Batch loss: 0.085310 Batch F1: 0.8333333333333333
Epoch:  193       10 Batch loss: 0.068143 Batch F1: 0.9523809523809523
Epoch:  193       11 Batch loss: 0.079109 Batch F1: 0.9600000000000001
Epoch:  193       12 Batch loss: 0.047501 Batch F1: 0.0
Train Avg Loss  193: 0.069457

Train Avg F1  193: 0.709516806722689

Val Avg Loss  193: 0.063982

Val Avg F1  193:  0.5954715219421102

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 194
--------------------------------------------------------------
Epoch:  194        1 Batch loss: 0.061838 Batch F1: 0.6666666666666666
Epoch:  194        2 Batch loss: 0.067479 Batch F1: 0.5714285714285715
Epoch:  194        3 Batch loss: 0.058845 Batch F1: 0.7692307692307693
Epoch:  194        4 Batch loss: 0.064568 Batch F1: 0.4
Epoch:  194        5 Batch loss: 0.055676 Batch F1: 0.6
Epoch:  194        6 Batch loss: 0.072991 Batch F1: 0.3636363636363636
Epoch:  194        7 Batch loss: 0.047824 Batch F1: 0.6666666666666666
Epoch:  194        8 Batch loss: 0.064609 Batch F1: 0.888888888888889
Epoch:  194        9 Batch loss: 0.073128 Batch F1: 0.9411764705882353
Epoch:  194       10 Batch loss: 0.103568 Batch F1: 0.7272727272727273
Epoch:  194       11 Batch loss: 0.078357 Batch F1: 0.8750000000000001
Epoch:  194       12 Batch loss: 0.084293 Batch F1: 0.9333333333333333
Train Avg Loss  194: 0.069431

Train Avg F1  194: 0.7002750381426853

Val Avg Loss  194: 0.064614

Val Avg F1  194:  0.9383732965326894

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 195
--------------------------------------------------------------
Epoch:  195        1 Batch loss: 0.069378 Batch F1: 0.8750000000000001
Epoch:  195        2 Batch loss: 0.078196 Batch F1: 0.8
Epoch:  195        3 Batch loss: 0.075997 Batch F1: 0.7142857142857143
Epoch:  195        4 Batch loss: 0.073748 Batch F1: 0.6153846153846153
Epoch:  195        5 Batch loss: 0.048387 Batch F1: 0.5
Epoch:  195        6 Batch loss: 0.075441 Batch F1: 0.5714285714285715
Epoch:  195        7 Batch loss: 0.069314 Batch F1: 0.5
Epoch:  195        8 Batch loss: 0.081841 Batch F1: 0.5555555555555556
Epoch:  195        9 Batch loss: 0.099241 Batch F1: 0.846153846153846
Epoch:  195       10 Batch loss: 0.076944 Batch F1: 0.9473684210526316
Epoch:  195       11 Batch loss: 0.079576 Batch F1: 1.0
Epoch:  195       12 Batch loss: 0.067345 Batch F1: 1.0
Train Avg Loss  195: 0.074617

Train Avg F1  195: 0.7437647269884112

Val Avg Loss  195: 0.065472

Val Avg F1  195:  0.9209064327485381

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 196
--------------------------------------------------------------
Epoch:  196        1 Batch loss: 0.061224 Batch F1: 0.9411764705882353
Epoch:  196        2 Batch loss: 0.066819 Batch F1: 0.7692307692307693
Epoch:  196        3 Batch loss: 0.099003 Batch F1: 0.0
Epoch:  196        4 Batch loss: 0.069065 Batch F1: 0.9
Epoch:  196        5 Batch loss: 0.066549 Batch F1: 1.0
Epoch:  196        6 Batch loss: 0.077179 Batch F1: 0.9090909090909091
Epoch:  196        7 Batch loss: 0.084916 Batch F1: 0.2222222222222222
Epoch:  196        8 Batch loss: 0.110583 Batch F1: 0.0
Epoch:  196        9 Batch loss: 0.087562 Batch F1: 0.4615384615384615
Epoch:  196       10 Batch loss: 0.092778 Batch F1: 0.7499999999999999
Epoch:  196       11 Batch loss: 0.066725 Batch F1: 1.0
Epoch:  196       12 Batch loss: 0.060033 Batch F1: 0.6666666666666666
Train Avg Loss  196: 0.078536

Train Avg F1  196: 0.6349937916114387

Val Avg Loss  196: 0.069710

Val Avg F1  196:  0.5887445887445888

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 197
--------------------------------------------------------------
Epoch:  197        1 Batch loss: 0.084347 Batch F1: 0.6666666666666666
Epoch:  197        2 Batch loss: 0.081390 Batch F1: 0.33333333333333337
Epoch:  197        3 Batch loss: 0.055241 Batch F1: 0.33333333333333337
Epoch:  197        4 Batch loss: 0.076832 Batch F1: 0.42857142857142855
Epoch:  197        5 Batch loss: 0.073836 Batch F1: 0.7142857142857143
Epoch:  197        6 Batch loss: 0.071514 Batch F1: 0.7142857142857143
Epoch:  197        7 Batch loss: 0.080272 Batch F1: 0.7368421052631579
Epoch:  197        8 Batch loss: 0.069187 Batch F1: 0.9333333333333333
Epoch:  197        9 Batch loss: 0.062011 Batch F1: 0.8333333333333333
Epoch:  197       10 Batch loss: 0.070716 Batch F1: 0.4444444444444445
Epoch:  197       11 Batch loss: 0.061326 Batch F1: 0.5
Epoch:  197       12 Batch loss: 0.072584 Batch F1: 0.6153846153846153
Train Avg Loss  197: 0.071605

Train Avg F1  197: 0.6044845018529229

Val Avg Loss  197: 0.063774

Val Avg F1  197:  0.5619047619047619

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 198
--------------------------------------------------------------
Epoch:  198        1 Batch loss: 0.065051 Batch F1: 0.5714285714285715
Epoch:  198        2 Batch loss: 0.077636 Batch F1: 0.8
Epoch:  198        3 Batch loss: 0.084838 Batch F1: 0.8571428571428571
Epoch:  198        4 Batch loss: 0.060922 Batch F1: 1.0
Epoch:  198        5 Batch loss: 0.066864 Batch F1: 0.9411764705882353
Epoch:  198        6 Batch loss: 0.064287 Batch F1: 1.0
Epoch:  198        7 Batch loss: 0.045051 Batch F1: 1.0
Epoch:  198        8 Batch loss: 0.069748 Batch F1: 0.5714285714285715
Epoch:  198        9 Batch loss: 0.054386 Batch F1: 0.6666666666666666
Epoch:  198       10 Batch loss: 0.073170 Batch F1: 0.625
Epoch:  198       11 Batch loss: 0.095421 Batch F1: 0.2857142857142857
Epoch:  198       12 Batch loss: 0.081832 Batch F1: 0.0
Train Avg Loss  198: 0.069934

Train Avg F1  198: 0.6932131185807657

Val Avg Loss  198: 0.062767

Val Avg F1  198:  0.9214285714285715

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 199
--------------------------------------------------------------
Epoch:  199        1 Batch loss: 0.041460 Batch F1: 1.0
Epoch:  199        2 Batch loss: 0.089101 Batch F1: 0.88
Epoch:  199        3 Batch loss: 0.094804 Batch F1: 0.8333333333333333
Epoch:  199        4 Batch loss: 0.082702 Batch F1: 0.8421052631578948
Epoch:  199        5 Batch loss: 0.064505 Batch F1: 0.9090909090909091
Epoch:  199        6 Batch loss: 0.068506 Batch F1: 1.0
Epoch:  199        7 Batch loss: 0.065059 Batch F1: 0.923076923076923
Epoch:  199        8 Batch loss: 0.082079 Batch F1: 0.888888888888889
Epoch:  199        9 Batch loss: 0.068438 Batch F1: 1.0
Epoch:  199       10 Batch loss: 0.076139 Batch F1: 0.33333333333333337
Epoch:  199       11 Batch loss: 0.061999 Batch F1: 0.2857142857142857
Epoch:  199       12 Batch loss: 0.051809 Batch F1: 0.33333333333333337
Train Avg Loss  199: 0.070550

Train Avg F1  199: 0.7690730224940753

Val Avg Loss  199: 0.064121

Val Avg F1  199:  0.5824175824175823

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 200
--------------------------------------------------------------
Epoch:  200        1 Batch loss: 0.131846 Batch F1: 0.11764705882352941
Epoch:  200        2 Batch loss: 0.049443 Batch F1: 0.5
Epoch:  200        3 Batch loss: 0.068245 Batch F1: 0.9411764705882353
Epoch:  200        4 Batch loss: 0.063214 Batch F1: 0.9411764705882353
Epoch:  200        5 Batch loss: 0.079667 Batch F1: 0.7272727272727273
Epoch:  200        6 Batch loss: 0.064953 Batch F1: 0.9411764705882353
Epoch:  200        7 Batch loss: 0.076281 Batch F1: 0.9166666666666666
Epoch:  200        8 Batch loss: 0.064288 Batch F1: 1.0
Epoch:  200        9 Batch loss: 0.063676 Batch F1: 0.4444444444444445
Epoch:  200       10 Batch loss: 0.067592 Batch F1: 0.5
Epoch:  200       11 Batch loss: 0.048952 Batch F1: 0.5714285714285715
Epoch:  200       12 Batch loss: 0.061298 Batch F1: 0.8
Train Avg Loss  200: 0.069955

Train Avg F1  200: 0.7000824067000538

Val Avg Loss  200: 0.066798

Val Avg F1  200:  0.56875

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 201
--------------------------------------------------------------
Epoch:  201        1 Batch loss: 0.038086 Batch F1: 0.6666666666666666
Epoch:  201        2 Batch loss: 0.065446 Batch F1: 0.6666666666666666
Epoch:  201        3 Batch loss: 0.099286 Batch F1: 0.5454545454545454
Epoch:  201        4 Batch loss: 0.075172 Batch F1: 0.9
Epoch:  201        5 Batch loss: 0.088086 Batch F1: 0.9090909090909091
Epoch:  201        6 Batch loss: 0.079220 Batch F1: 0.9523809523809523
Epoch:  201        7 Batch loss: 0.055978 Batch F1: 0.5
Epoch:  201        8 Batch loss: 0.078047 Batch F1: 0.9473684210526316
Epoch:  201        9 Batch loss: 0.068010 Batch F1: 0.2222222222222222
Epoch:  201       10 Batch loss: 0.070193 Batch F1: 0.5
Epoch:  201       11 Batch loss: 0.072697 Batch F1: 0.8750000000000001
Epoch:  201       12 Batch loss: 0.066095 Batch F1: 1.0
Train Avg Loss  201: 0.071360

Train Avg F1  201: 0.7237375319612163

Val Avg Loss  201: 0.064386

Val Avg F1  201:  0.5757020757020757

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 202
--------------------------------------------------------------
Epoch:  202        1 Batch loss: 0.044710 Batch F1: 0.5
Epoch:  202        2 Batch loss: 0.071056 Batch F1: 0.6666666666666666
Epoch:  202        3 Batch loss: 0.069815 Batch F1: 0.5
Epoch:  202        4 Batch loss: 0.089128 Batch F1: 0.0
Epoch:  202        5 Batch loss: 0.078075 Batch F1: 0.9166666666666666
Epoch:  202        6 Batch loss: 0.094087 Batch F1: 0.7499999999999999
Epoch:  202        7 Batch loss: 0.083144 Batch F1: 0.9090909090909091
Epoch:  202        8 Batch loss: 0.079551 Batch F1: 0.9411764705882353
Epoch:  202        9 Batch loss: 0.056654 Batch F1: 1.0
Epoch:  202       10 Batch loss: 0.067098 Batch F1: 0.6153846153846153
Epoch:  202       11 Batch loss: 0.064193 Batch F1: 0.6666666666666666
Epoch:  202       12 Batch loss: 0.074077 Batch F1: 0.5
Train Avg Loss  202: 0.072632

Train Avg F1  202: 0.6638043329219799

Val Avg Loss  202: 0.068745

Val Avg F1  202:  0.5992445054945055

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 203
--------------------------------------------------------------
Epoch:  203        1 Batch loss: 0.063106 Batch F1: 0.25
Epoch:  203        2 Batch loss: 0.065194 Batch F1: 0.3636363636363636
Epoch:  203        3 Batch loss: 0.073848 Batch F1: 0.9473684210526316
Epoch:  203        4 Batch loss: 0.062149 Batch F1: 0.8571428571428571
Epoch:  203        5 Batch loss: 0.077544 Batch F1: 0.888888888888889
Epoch:  203        6 Batch loss: 0.051911 Batch F1: 1.0
Epoch:  203        7 Batch loss: 0.110219 Batch F1: 0.33333333333333337
Epoch:  203        8 Batch loss: 0.077401 Batch F1: 0.6666666666666666
Epoch:  203        9 Batch loss: 0.057923 Batch F1: 0.9333333333333333
Epoch:  203       10 Batch loss: 0.054712 Batch F1: 0.8
Epoch:  203       11 Batch loss: 0.077008 Batch F1: 0.3636363636363636
Epoch:  203       12 Batch loss: 0.073808 Batch F1: 0.4444444444444445
Train Avg Loss  203: 0.070402

Train Avg F1  203: 0.6540375560112403

Val Avg Loss  203: 0.063732

Val Avg F1  203:  0.623249299719888

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 204
--------------------------------------------------------------
Epoch:  204        1 Batch loss: 0.062358 Batch F1: 0.4
Epoch:  204        2 Batch loss: 0.072214 Batch F1: 0.5
Epoch:  204        3 Batch loss: 0.060408 Batch F1: 0.8750000000000001
Epoch:  204        4 Batch loss: 0.049976 Batch F1: 0.888888888888889
Epoch:  204        5 Batch loss: 0.072164 Batch F1: 0.19999999999999998
Epoch:  204        6 Batch loss: 0.100044 Batch F1: 0.4
Epoch:  204        7 Batch loss: 0.085826 Batch F1: 0.8421052631578948
Epoch:  204        8 Batch loss: 0.059995 Batch F1: 0.9090909090909091
Epoch:  204        9 Batch loss: 0.059046 Batch F1: 1.0
Epoch:  204       10 Batch loss: 0.078211 Batch F1: 0.9473684210526316
Epoch:  204       11 Batch loss: 0.057043 Batch F1: 1.0
Epoch:  204       12 Batch loss: 0.087275 Batch F1: 0.6153846153846153
Train Avg Loss  204: 0.070380

Train Avg F1  204: 0.7148198414645783

Val Avg Loss  204: 0.065991

Val Avg F1  204:  0.578088578088578

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 205
--------------------------------------------------------------
Epoch:  205        1 Batch loss: 0.075207 Batch F1: 0.625
Epoch:  205        2 Batch loss: 0.049957 Batch F1: 0.5
Epoch:  205        3 Batch loss: 0.108095 Batch F1: 0.5217391304347826
Epoch:  205        4 Batch loss: 0.075014 Batch F1: 0.888888888888889
Epoch:  205        5 Batch loss: 0.042138 Batch F1: 1.0
Epoch:  205        6 Batch loss: 0.064430 Batch F1: 1.0
Epoch:  205        7 Batch loss: 0.073755 Batch F1: 0.9411764705882353
Epoch:  205        8 Batch loss: 0.083383 Batch F1: 0.7777777777777778
Epoch:  205        9 Batch loss: 0.060514 Batch F1: 0.9090909090909091
Epoch:  205       10 Batch loss: 0.080166 Batch F1: 0.9565217391304348
Epoch:  205       11 Batch loss: 0.051601 Batch F1: 1.0
Epoch:  205       12 Batch loss: 0.075060 Batch F1: 0.4
Train Avg Loss  205: 0.069943

Train Avg F1  205: 0.7933495763259191

Val Avg Loss  205: 0.062621

Val Avg F1  205:  0.5938375350140056

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 206
--------------------------------------------------------------
Epoch:  206        1 Batch loss: 0.068728 Batch F1: 0.4615384615384615
Epoch:  206        2 Batch loss: 0.065315 Batch F1: 1.0
Epoch:  206        3 Batch loss: 0.070830 Batch F1: 0.9473684210526316
Epoch:  206        4 Batch loss: 0.063337 Batch F1: 0.8750000000000001
Epoch:  206        5 Batch loss: 0.046459 Batch F1: 0.5
Epoch:  206        6 Batch loss: 0.053955 Batch F1: 0.6666666666666666
Epoch:  206        7 Batch loss: 0.101524 Batch F1: 0.5
Epoch:  206        8 Batch loss: 0.078222 Batch F1: 0.5
Epoch:  206        9 Batch loss: 0.073202 Batch F1: 0.888888888888889
Epoch:  206       10 Batch loss: 0.061090 Batch F1: 0.9090909090909091
Epoch:  206       11 Batch loss: 0.069853 Batch F1: 0.9333333333333333
Epoch:  206       12 Batch loss: 0.085955 Batch F1: 0.7692307692307693
Train Avg Loss  206: 0.069872

Train Avg F1  206: 0.7459264541501384

Val Avg Loss  206: 0.062041

Val Avg F1  206:  0.9201754385964913

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 207
--------------------------------------------------------------
Epoch:  207        1 Batch loss: 0.078663 Batch F1: 0.8750000000000001
Epoch:  207        2 Batch loss: 0.075083 Batch F1: 0.9090909090909091
Epoch:  207        3 Batch loss: 0.066434 Batch F1: 0.9565217391304348
Epoch:  207        4 Batch loss: 0.056946 Batch F1: 1.0
Epoch:  207        5 Batch loss: 0.056552 Batch F1: 0.8571428571428571
Epoch:  207        6 Batch loss: 0.065183 Batch F1: 0.5714285714285715
Epoch:  207        7 Batch loss: 0.049292 Batch F1: 0.6666666666666666
Epoch:  207        8 Batch loss: 0.094608 Batch F1: 0.3076923076923077
Epoch:  207        9 Batch loss: 0.071922 Batch F1: 0.3636363636363636
Epoch:  207       10 Batch loss: 0.064455 Batch F1: 0.625
Epoch:  207       11 Batch loss: 0.062843 Batch F1: 1.0
Epoch:  207       12 Batch loss: 0.082258 Batch F1: 0.8
Train Avg Loss  207: 0.068686

Train Avg F1  207: 0.7443482845656758

Val Avg Loss  207: 0.062084

Val Avg F1  207:  0.9257309941520468

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 208
--------------------------------------------------------------
Epoch:  208        1 Batch loss: 0.076897 Batch F1: 0.9
Epoch:  208        2 Batch loss: 0.052365 Batch F1: 1.0
Epoch:  208        3 Batch loss: 0.049329 Batch F1: 1.0
Epoch:  208        4 Batch loss: 0.088458 Batch F1: 0.8571428571428571
Epoch:  208        5 Batch loss: 0.093131 Batch F1: 0.8
Epoch:  208        6 Batch loss: 0.055998 Batch F1: 1.0
Epoch:  208        7 Batch loss: 0.078532 Batch F1: 0.5882352941176471
Epoch:  208        8 Batch loss: 0.058785 Batch F1: 0.5454545454545454
Epoch:  208        9 Batch loss: 0.068268 Batch F1: 0.4615384615384615
Epoch:  208       10 Batch loss: 0.069306 Batch F1: 0.8571428571428571
Epoch:  208       11 Batch loss: 0.058846 Batch F1: 0.9333333333333333
Epoch:  208       12 Batch loss: 0.070767 Batch F1: 1.0
Train Avg Loss  208: 0.068390

Train Avg F1  208: 0.8285706123941418

Val Avg Loss  208: 0.061902

Val Avg F1  208:  0.9251276759016697

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 209
--------------------------------------------------------------
Epoch:  209        1 Batch loss: 0.058445 Batch F1: 1.0
Epoch:  209        2 Batch loss: 0.066729 Batch F1: 0.8571428571428571
Epoch:  209        3 Batch loss: 0.074041 Batch F1: 0.8571428571428571
Epoch:  209        4 Batch loss: 0.057712 Batch F1: 0.9333333333333333
Epoch:  209        5 Batch loss: 0.055391 Batch F1: 0.7272727272727273
Epoch:  209        6 Batch loss: 0.061828 Batch F1: 0.6666666666666666
Epoch:  209        7 Batch loss: 0.057824 Batch F1: 0.5
Epoch:  209        8 Batch loss: 0.099795 Batch F1: 0.35294117647058826
Epoch:  209        9 Batch loss: 0.069608 Batch F1: 0.19999999999999998
Epoch:  209       10 Batch loss: 0.062150 Batch F1: 1.0
Epoch:  209       11 Batch loss: 0.083054 Batch F1: 0.6153846153846153
Epoch:  209       12 Batch loss: 0.072981 Batch F1: 0.888888888888889
Train Avg Loss  209: 0.068296

Train Avg F1  209: 0.7165644268585445

Val Avg Loss  209: 0.065243

Val Avg F1  209:  0.9150751041483307

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 210
--------------------------------------------------------------
Epoch:  210        1 Batch loss: 0.075837 Batch F1: 0.9473684210526316
Epoch:  210        2 Batch loss: 0.074294 Batch F1: 0.888888888888889
Epoch:  210        3 Batch loss: 0.078456 Batch F1: 0.9
Epoch:  210        4 Batch loss: 0.066201 Batch F1: 0.9565217391304348
Epoch:  210        5 Batch loss: 0.083348 Batch F1: 0.8571428571428571
Epoch:  210        6 Batch loss: 0.074322 Batch F1: 0.7272727272727273
Epoch:  210        7 Batch loss: 0.064473 Batch F1: 0.923076923076923
Epoch:  210        8 Batch loss: 0.069408 Batch F1: 0.4
Epoch:  210        9 Batch loss: 0.053792 Batch F1: 0.2857142857142857
Epoch:  210       10 Batch loss: 0.091340 Batch F1: 0.5333333333333333
Epoch:  210       11 Batch loss: 0.060819 Batch F1: 0.5
Epoch:  210       12 Batch loss: 0.058132 Batch F1: 1.0
Train Avg Loss  210: 0.070869

Train Avg F1  210: 0.7432765979676734

Val Avg Loss  210: 0.064811

Val Avg F1  210:  0.9227485380116959

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 211
--------------------------------------------------------------
Epoch:  211        1 Batch loss: 0.088271 Batch F1: 0.9600000000000001
Epoch:  211        2 Batch loss: 0.071939 Batch F1: 0.9333333333333333
Epoch:  211        3 Batch loss: 0.063552 Batch F1: 0.5454545454545454
Epoch:  211        4 Batch loss: 0.063690 Batch F1: 0.4444444444444445
Epoch:  211        5 Batch loss: 0.057466 Batch F1: 0.7272727272727273
Epoch:  211        6 Batch loss: 0.064546 Batch F1: 0.7142857142857143
Epoch:  211        7 Batch loss: 0.075494 Batch F1: 0.4615384615384615
Epoch:  211        8 Batch loss: 0.080295 Batch F1: 0.9600000000000001
Epoch:  211        9 Batch loss: 0.058515 Batch F1: 1.0
Epoch:  211       10 Batch loss: 0.088080 Batch F1: 0.9090909090909091
Epoch:  211       11 Batch loss: 0.059049 Batch F1: 0.6666666666666666
Epoch:  211       12 Batch loss: 0.098972 Batch F1: 0.33333333333333337
Train Avg Loss  211: 0.072489

Train Avg F1  211: 0.7212850112850114

Val Avg Loss  211: 0.065526

Val Avg F1  211:  0.5469612087259146

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 212
--------------------------------------------------------------
Epoch:  212        1 Batch loss: 0.084827 Batch F1: 0.2857142857142857
Epoch:  212        2 Batch loss: 0.071638 Batch F1: 0.9411764705882353
Epoch:  212        3 Batch loss: 0.087076 Batch F1: 0.8
Epoch:  212        4 Batch loss: 0.051813 Batch F1: 1.0
Epoch:  212        5 Batch loss: 0.082309 Batch F1: 0.8695652173913044
Epoch:  212        6 Batch loss: 0.064242 Batch F1: 0.9565217391304348
Epoch:  212        7 Batch loss: 0.075012 Batch F1: 0.9090909090909091
Epoch:  212        8 Batch loss: 0.068678 Batch F1: 0.8333333333333333
Epoch:  212        9 Batch loss: 0.073641 Batch F1: 0.9090909090909091
Epoch:  212       10 Batch loss: 0.081915 Batch F1: 1.0
Epoch:  212       11 Batch loss: 0.063541 Batch F1: 0.5454545454545454
Epoch:  212       12 Batch loss: 0.050985 Batch F1: 0.6666666666666666
Train Avg Loss  212: 0.071306

Train Avg F1  212: 0.8097178397050518

Val Avg Loss  212: 0.064039

Val Avg F1  212:  0.6065705128205128

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 213
--------------------------------------------------------------
Epoch:  213        1 Batch loss: 0.072441 Batch F1: 0.6153846153846153
Epoch:  213        2 Batch loss: 0.082150 Batch F1: 0.33333333333333337
Epoch:  213        3 Batch loss: 0.087427 Batch F1: 0.6
Epoch:  213        4 Batch loss: 0.068674 Batch F1: 0.5714285714285715
Epoch:  213        5 Batch loss: 0.065751 Batch F1: 0.9090909090909091
Epoch:  213        6 Batch loss: 0.070217 Batch F1: 0.9
Epoch:  213        7 Batch loss: 0.057585 Batch F1: 1.0
Epoch:  213        8 Batch loss: 0.061933 Batch F1: 0.9411764705882353
Epoch:  213        9 Batch loss: 0.076880 Batch F1: 0.9523809523809523
Epoch:  213       10 Batch loss: 0.078854 Batch F1: 0.2222222222222222
Epoch:  213       11 Batch loss: 0.048625 Batch F1: 0.8
Epoch:  213       12 Batch loss: 0.066812 Batch F1: 0.6153846153846153
Train Avg Loss  213: 0.069779

Train Avg F1  213: 0.7050334741511213

Val Avg Loss  213: 0.062821

Val Avg F1  213:  0.49151371074745687

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 214
--------------------------------------------------------------
Epoch:  214        1 Batch loss: 0.074604 Batch F1: 0.19999999999999998
Epoch:  214        2 Batch loss: 0.078120 Batch F1: 0.5
Epoch:  214        3 Batch loss: 0.052804 Batch F1: 0.6
Epoch:  214        4 Batch loss: 0.090637 Batch F1: 0.47058823529411764
Epoch:  214        5 Batch loss: 0.041429 Batch F1: 1.0
Epoch:  214        6 Batch loss: 0.069071 Batch F1: 0.9411764705882353
Epoch:  214        7 Batch loss: 0.072996 Batch F1: 0.888888888888889
Epoch:  214        8 Batch loss: 0.054171 Batch F1: 1.0
Epoch:  214        9 Batch loss: 0.084860 Batch F1: 0.15384615384615385
Epoch:  214       10 Batch loss: 0.060958 Batch F1: 0.8
Epoch:  214       11 Batch loss: 0.083876 Batch F1: 0.9090909090909091
Epoch:  214       12 Batch loss: 0.054570 Batch F1: 1.0
Train Avg Loss  214: 0.068175

Train Avg F1  214: 0.7052992214756921

Val Avg Loss  214: 0.062074

Val Avg F1  214:  0.9173116615067081

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 215
--------------------------------------------------------------
Epoch:  215        1 Batch loss: 0.079271 Batch F1: 0.8235294117647058
Epoch:  215        2 Batch loss: 0.064983 Batch F1: 0.9090909090909091
Epoch:  215        3 Batch loss: 0.050428 Batch F1: 1.0
Epoch:  215        4 Batch loss: 0.067411 Batch F1: 0.8750000000000001
Epoch:  215        5 Batch loss: 0.063804 Batch F1: 0.9473684210526316
Epoch:  215        6 Batch loss: 0.079842 Batch F1: 0.8571428571428571
Epoch:  215        7 Batch loss: 0.069955 Batch F1: 0.8
Epoch:  215        8 Batch loss: 0.049927 Batch F1: 0.923076923076923
Epoch:  215        9 Batch loss: 0.079405 Batch F1: 0.9
Epoch:  215       10 Batch loss: 0.071879 Batch F1: 0.9523809523809523
Epoch:  215       11 Batch loss: 0.073623 Batch F1: 0.9565217391304348
Epoch:  215       12 Batch loss: 0.071334 Batch F1: 0.9333333333333333
Train Avg Loss  215: 0.068489

Train Avg F1  215: 0.9064537122477291

Val Avg Loss  215: 0.061771

Val Avg F1  215:  0.9328282828282829

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 216
--------------------------------------------------------------
Epoch:  216        1 Batch loss: 0.071707 Batch F1: 0.7692307692307693
Epoch:  216        2 Batch loss: 0.071493 Batch F1: 0.8571428571428571
Epoch:  216        3 Batch loss: 0.068705 Batch F1: 0.8571428571428571
Epoch:  216        4 Batch loss: 0.044204 Batch F1: 1.0
Epoch:  216        5 Batch loss: 0.075818 Batch F1: 0.4615384615384615
Epoch:  216        6 Batch loss: 0.068123 Batch F1: 0.6666666666666666
Epoch:  216        7 Batch loss: 0.052085 Batch F1: 0.6666666666666666
Epoch:  216        8 Batch loss: 0.078357 Batch F1: 0.5
Epoch:  216        9 Batch loss: 0.072447 Batch F1: 0.5333333333333333
Epoch:  216       10 Batch loss: 0.084820 Batch F1: 0.5882352941176471
Epoch:  216       11 Batch loss: 0.078681 Batch F1: 0.9
Epoch:  216       12 Batch loss: 0.055284 Batch F1: 1.0
Train Avg Loss  216: 0.068477

Train Avg F1  216: 0.7333297421532716

Val Avg Loss  216: 0.062349

Val Avg F1  216:  0.9099190283400809

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 217
--------------------------------------------------------------
Epoch:  217        1 Batch loss: 0.059832 Batch F1: 0.9333333333333333
Epoch:  217        2 Batch loss: 0.072093 Batch F1: 0.9473684210526316
Epoch:  217        3 Batch loss: 0.052777 Batch F1: 0.923076923076923
Epoch:  217        4 Batch loss: 0.061092 Batch F1: 0.9333333333333333
Epoch:  217        5 Batch loss: 0.066666 Batch F1: 0.5
Epoch:  217        6 Batch loss: 0.055049 Batch F1: 0.6666666666666666
Epoch:  217        7 Batch loss: 0.074934 Batch F1: 0.3636363636363636
Epoch:  217        8 Batch loss: 0.087084 Batch F1: 0.42857142857142855
Epoch:  217        9 Batch loss: 0.077485 Batch F1: 0.42857142857142855
Epoch:  217       10 Batch loss: 0.069335 Batch F1: 0.8235294117647058
Epoch:  217       11 Batch loss: 0.086892 Batch F1: 0.8421052631578948
Epoch:  217       12 Batch loss: 0.064156 Batch F1: 0.9090909090909091
Train Avg Loss  217: 0.068950

Train Avg F1  217: 0.7249402901879681

Val Avg Loss  217: 0.066380

Val Avg F1  217:  0.8888028895768834

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 218
--------------------------------------------------------------
Epoch:  218        1 Batch loss: 0.067980 Batch F1: 0.8333333333333333
Epoch:  218        2 Batch loss: 0.076047 Batch F1: 1.0
Epoch:  218        3 Batch loss: 0.072796 Batch F1: 0.7692307692307693
Epoch:  218        4 Batch loss: 0.074764 Batch F1: 0.9600000000000001
Epoch:  218        5 Batch loss: 0.048753 Batch F1: 1.0
Epoch:  218        6 Batch loss: 0.082562 Batch F1: 0.7777777777777778
Epoch:  218        7 Batch loss: 0.082899 Batch F1: 0.9090909090909091
Epoch:  218        8 Batch loss: 0.079916 Batch F1: 0.8421052631578948
Epoch:  218        9 Batch loss: 0.069226 Batch F1: 1.0
Epoch:  218       10 Batch loss: 0.084699 Batch F1: 0.9523809523809523
Epoch:  218       11 Batch loss: 0.068376 Batch F1: 0.6666666666666666
Epoch:  218       12 Batch loss: 0.063951 Batch F1: 0.7272727272727273
Train Avg Loss  218: 0.072664

Train Avg F1  218: 0.8698215332425859

Val Avg Loss  218: 0.068320

Val Avg F1  218:  0.5952380952380952

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 219
--------------------------------------------------------------
Epoch:  219        1 Batch loss: 0.077690 Batch F1: 0.2222222222222222
Epoch:  219        2 Batch loss: 0.066142 Batch F1: 0.0
Epoch:  219        3 Batch loss: 0.060775 Batch F1: 0.6
Epoch:  219        4 Batch loss: 0.063405 Batch F1: 0.7692307692307693
Epoch:  219        5 Batch loss: 0.083024 Batch F1: 0.8235294117647058
Epoch:  219        6 Batch loss: 0.071509 Batch F1: 0.4
Epoch:  219        7 Batch loss: 0.073292 Batch F1: 0.6153846153846153
Epoch:  219        8 Batch loss: 0.080360 Batch F1: 0.5882352941176471
Epoch:  219        9 Batch loss: 0.077990 Batch F1: 0.3636363636363636
Epoch:  219       10 Batch loss: 0.080610 Batch F1: 0.9473684210526316
Epoch:  219       11 Batch loss: 0.078302 Batch F1: 1.0
Epoch:  219       12 Batch loss: 0.079942 Batch F1: 0.8571428571428571
Train Avg Loss  219: 0.074420

Train Avg F1  219: 0.5988958295459843

Val Avg Loss  219: 0.066643

Val Avg F1  219:  0.9204472797023948

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 220
--------------------------------------------------------------
Epoch:  220        1 Batch loss: 0.084681 Batch F1: 0.9523809523809523
Epoch:  220        2 Batch loss: 0.080163 Batch F1: 0.9
Epoch:  220        3 Batch loss: 0.079699 Batch F1: 0.3636363636363636
Epoch:  220        4 Batch loss: 0.073890 Batch F1: 0.7142857142857143
Epoch:  220        5 Batch loss: 0.054148 Batch F1: 0.8
Epoch:  220        6 Batch loss: 0.092327 Batch F1: 0.8695652173913044
Epoch:  220        7 Batch loss: 0.076333 Batch F1: 0.9333333333333333
Epoch:  220        8 Batch loss: 0.064907 Batch F1: 0.9
Epoch:  220        9 Batch loss: 0.060260 Batch F1: 1.0
Epoch:  220       10 Batch loss: 0.055350 Batch F1: 0.923076923076923
Epoch:  220       11 Batch loss: 0.049601 Batch F1: 0.6
Epoch:  220       12 Batch loss: 0.073553 Batch F1: 0.6666666666666666
Train Avg Loss  220: 0.070409

Train Avg F1  220: 0.8019120975642715

Val Avg Loss  220: 0.065059

Val Avg F1  220:  0.48840497737556554

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 221
--------------------------------------------------------------
Epoch:  221        1 Batch loss: 0.066038 Batch F1: 0.0
Epoch:  221        2 Batch loss: 0.083712 Batch F1: 0.4
Epoch:  221        3 Batch loss: 0.063440 Batch F1: 0.9333333333333333
Epoch:  221        4 Batch loss: 0.070311 Batch F1: 0.9473684210526316
Epoch:  221        5 Batch loss: 0.066510 Batch F1: 0.8750000000000001
Epoch:  221        6 Batch loss: 0.066520 Batch F1: 1.0
Epoch:  221        7 Batch loss: 0.055616 Batch F1: 0.9473684210526316
Epoch:  221        8 Batch loss: 0.062413 Batch F1: 0.9473684210526316
Epoch:  221        9 Batch loss: 0.070497 Batch F1: 0.8750000000000001
Epoch:  221       10 Batch loss: 0.068265 Batch F1: 1.0
Epoch:  221       11 Batch loss: 0.077666 Batch F1: 0.7692307692307693
Epoch:  221       12 Batch loss: 0.077335 Batch F1: 0.5454545454545454
Train Avg Loss  221: 0.069027

Train Avg F1  221: 0.7700103259313785

Val Avg Loss  221: 0.064208

Val Avg F1  221:  0.5446969696969697

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 222
--------------------------------------------------------------
Epoch:  222        1 Batch loss: 0.047900 Batch F1: 0.33333333333333337
Epoch:  222        2 Batch loss: 0.067632 Batch F1: 0.6153846153846153
Epoch:  222        3 Batch loss: 0.078003 Batch F1: 0.5882352941176471
Epoch:  222        4 Batch loss: 0.104420 Batch F1: 0.9032258064516129
Epoch:  222        5 Batch loss: 0.070633 Batch F1: 0.8
Epoch:  222        6 Batch loss: 0.070803 Batch F1: 0.923076923076923
Epoch:  222        7 Batch loss: 0.067083 Batch F1: 0.7142857142857143
Epoch:  222        8 Batch loss: 0.072802 Batch F1: 0.5
Epoch:  222        9 Batch loss: 0.081488 Batch F1: 0.9090909090909091
Epoch:  222       10 Batch loss: 0.061651 Batch F1: 1.0
Epoch:  222       11 Batch loss: 0.069315 Batch F1: 0.9333333333333333
Epoch:  222       12 Batch loss: 0.062327 Batch F1: 0.4444444444444445
Train Avg Loss  222: 0.071171

Train Avg F1  222: 0.7220341977932111

Val Avg Loss  222: 0.066389

Val Avg F1  222:  0.5403091060985798

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 223
--------------------------------------------------------------
Epoch:  223        1 Batch loss: 0.073711 Batch F1: 0.625
Epoch:  223        2 Batch loss: 0.108649 Batch F1: 0.13333333333333333
Epoch:  223        3 Batch loss: 0.061729 Batch F1: 1.0
Epoch:  223        4 Batch loss: 0.065220 Batch F1: 0.8333333333333333
Epoch:  223        5 Batch loss: 0.073927 Batch F1: 0.9333333333333333
Epoch:  223        6 Batch loss: 0.078773 Batch F1: 0.5714285714285715
Epoch:  223        7 Batch loss: 0.095498 Batch F1: 0.47058823529411764
Epoch:  223        8 Batch loss: 0.070706 Batch F1: 0.7777777777777778
Epoch:  223        9 Batch loss: 0.063997 Batch F1: 0.923076923076923
Epoch:  223       10 Batch loss: 0.067513 Batch F1: 0.9333333333333333
Epoch:  223       11 Batch loss: 0.060015 Batch F1: 0.9473684210526316
Epoch:  223       12 Batch loss: 0.038681 Batch F1: 1.0
Train Avg Loss  223: 0.071535

Train Avg F1  223: 0.7623811051636129

Val Avg Loss  223: 0.066396

Val Avg F1  223:  0.6010989010989011

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 224
--------------------------------------------------------------
Epoch:  224        1 Batch loss: 0.046110 Batch F1: 0.0
Epoch:  224        2 Batch loss: 0.118337 Batch F1: 0.0
Epoch:  224        3 Batch loss: 0.071657 Batch F1: 0.5714285714285715
Epoch:  224        4 Batch loss: 0.078971 Batch F1: 0.5882352941176471
Epoch:  224        5 Batch loss: 0.058420 Batch F1: 1.0
Epoch:  224        6 Batch loss: 0.058665 Batch F1: 0.9411764705882353
Epoch:  224        7 Batch loss: 0.071610 Batch F1: 0.9473684210526316
Epoch:  224        8 Batch loss: 0.079768 Batch F1: 0.9411764705882353
Epoch:  224        9 Batch loss: 0.059870 Batch F1: 0.6666666666666666
Epoch:  224       10 Batch loss: 0.056782 Batch F1: 0.6666666666666666
Epoch:  224       11 Batch loss: 0.096593 Batch F1: 0.0
Epoch:  224       12 Batch loss: 0.104627 Batch F1: 0.33333333333333337
Train Avg Loss  224: 0.075117

Train Avg F1  224: 0.554670991203499

Val Avg Loss  224: 0.064258

Val Avg F1  224:  0.9259446693657221

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 225
--------------------------------------------------------------
Epoch:  225        1 Batch loss: 0.071768 Batch F1: 0.9411764705882353
Epoch:  225        2 Batch loss: 0.091788 Batch F1: 0.9166666666666666
Epoch:  225        3 Batch loss: 0.065606 Batch F1: 0.9090909090909091
Epoch:  225        4 Batch loss: 0.058053 Batch F1: 0.9333333333333333
Epoch:  225        5 Batch loss: 0.080302 Batch F1: 0.9565217391304348
Epoch:  225        6 Batch loss: 0.053889 Batch F1: 0.9333333333333333
Epoch:  225        7 Batch loss: 0.067364 Batch F1: 0.8
Epoch:  225        8 Batch loss: 0.050978 Batch F1: 0.5
Epoch:  225        9 Batch loss: 0.066836 Batch F1: 0.4444444444444445
Epoch:  225       10 Batch loss: 0.071390 Batch F1: 0.25
Epoch:  225       11 Batch loss: 0.083000 Batch F1: 0.33333333333333337
Epoch:  225       12 Batch loss: 0.084624 Batch F1: 0.18181818181818182
Train Avg Loss  225: 0.070466

Train Avg F1  225: 0.6749765343115727

Val Avg Loss  225: 0.063745

Val Avg F1  225:  0.9232954545454546

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 226
--------------------------------------------------------------
Epoch:  226        1 Batch loss: 0.074100 Batch F1: 0.9473684210526316
Epoch:  226        2 Batch loss: 0.066576 Batch F1: 0.9473684210526316
Epoch:  226        3 Batch loss: 0.066861 Batch F1: 0.9411764705882353
Epoch:  226        4 Batch loss: 0.065075 Batch F1: 0.923076923076923
Epoch:  226        5 Batch loss: 0.063617 Batch F1: 0.8750000000000001
Epoch:  226        6 Batch loss: 0.053562 Batch F1: 1.0
Epoch:  226        7 Batch loss: 0.077394 Batch F1: 0.8750000000000001
Epoch:  226        8 Batch loss: 0.090291 Batch F1: 0.18181818181818182
Epoch:  226        9 Batch loss: 0.079893 Batch F1: 0.9600000000000001
Epoch:  226       10 Batch loss: 0.061357 Batch F1: 0.8571428571428571
Epoch:  226       11 Batch loss: 0.078070 Batch F1: 0.9473684210526316
Epoch:  226       12 Batch loss: 0.072834 Batch F1: 0.9473684210526316
Train Avg Loss  226: 0.070803

Train Avg F1  226: 0.8668906764030604

Val Avg Loss  226: 0.063194

Val Avg F1  226:  0.92421955624355

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 227
--------------------------------------------------------------
Epoch:  227        1 Batch loss: 0.070661 Batch F1: 0.9473684210526316
Epoch:  227        2 Batch loss: 0.056695 Batch F1: 1.0
Epoch:  227        3 Batch loss: 0.061508 Batch F1: 0.4444444444444445
Epoch:  227        4 Batch loss: 0.061706 Batch F1: 0.4
Epoch:  227        5 Batch loss: 0.092554 Batch F1: 0.6
Epoch:  227        6 Batch loss: 0.085579 Batch F1: 0.6363636363636364
Epoch:  227        7 Batch loss: 0.068909 Batch F1: 0.923076923076923
Epoch:  227        8 Batch loss: 0.102520 Batch F1: 0.7499999999999999
Epoch:  227        9 Batch loss: 0.074488 Batch F1: 0.9473684210526316
Epoch:  227       10 Batch loss: 0.063079 Batch F1: 0.888888888888889
Epoch:  227       11 Batch loss: 0.075280 Batch F1: 0.8333333333333333
Epoch:  227       12 Batch loss: 0.057915 Batch F1: 0.888888888888889
Train Avg Loss  227: 0.072575

Train Avg F1  227: 0.7716444130917816

Val Avg Loss  227: 0.063392

Val Avg F1  227:  0.9305555555555555

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 228
--------------------------------------------------------------
Epoch:  228        1 Batch loss: 0.050245 Batch F1: 1.0
Epoch:  228        2 Batch loss: 0.100689 Batch F1: 0.14285714285714288
Epoch:  228        3 Batch loss: 0.083577 Batch F1: 0.8
Epoch:  228        4 Batch loss: 0.058398 Batch F1: 1.0
Epoch:  228        5 Batch loss: 0.079469 Batch F1: 1.0
Epoch:  228        6 Batch loss: 0.062413 Batch F1: 0.9333333333333333
Epoch:  228        7 Batch loss: 0.077595 Batch F1: 0.5333333333333333
Epoch:  228        8 Batch loss: 0.071799 Batch F1: 0.5882352941176471
Epoch:  228        9 Batch loss: 0.059981 Batch F1: 0.923076923076923
Epoch:  228       10 Batch loss: 0.058390 Batch F1: 0.7499999999999999
Epoch:  228       11 Batch loss: 0.070052 Batch F1: 0.8333333333333333
Epoch:  228       12 Batch loss: 0.069689 Batch F1: 0.6153846153846153
Train Avg Loss  228: 0.070192

Train Avg F1  228: 0.7599628312863608

Val Avg Loss  228: 0.064260

Val Avg F1  228:  0.5383771929824561

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 229
--------------------------------------------------------------
Epoch:  229        1 Batch loss: 0.084588 Batch F1: 0.4615384615384615
Epoch:  229        2 Batch loss: 0.080355 Batch F1: 1.0
Epoch:  229        3 Batch loss: 0.077249 Batch F1: 0.8571428571428571
Epoch:  229        4 Batch loss: 0.066860 Batch F1: 0.8750000000000001
Epoch:  229        5 Batch loss: 0.086798 Batch F1: 0.9090909090909091
Epoch:  229        6 Batch loss: 0.072053 Batch F1: 1.0
Epoch:  229        7 Batch loss: 0.068829 Batch F1: 0.8333333333333333
Epoch:  229        8 Batch loss: 0.042783 Batch F1: 0.0
Epoch:  229        9 Batch loss: 0.096980 Batch F1: 0.0
Epoch:  229       10 Batch loss: 0.047641 Batch F1: 0.6666666666666666
Epoch:  229       11 Batch loss: 0.071671 Batch F1: 0.6666666666666666
Epoch:  229       12 Batch loss: 0.060940 Batch F1: 0.25
Train Avg Loss  229: 0.071395

Train Avg F1  229: 0.6266199078699078

Val Avg Loss  229: 0.064417

Val Avg F1  229:  0.919992288413341

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 230
--------------------------------------------------------------
Epoch:  230        1 Batch loss: 0.069846 Batch F1: 0.9473684210526316
Epoch:  230        2 Batch loss: 0.083575 Batch F1: 0.8695652173913043
Epoch:  230        3 Batch loss: 0.090760 Batch F1: 0.0
Epoch:  230        4 Batch loss: 0.072326 Batch F1: 0.5333333333333333
Epoch:  230        5 Batch loss: 0.089005 Batch F1: 0.7000000000000001
Epoch:  230        6 Batch loss: 0.065493 Batch F1: 0.4
Epoch:  230        7 Batch loss: 0.072531 Batch F1: 0.8
Epoch:  230        8 Batch loss: 0.061894 Batch F1: 1.0
Epoch:  230        9 Batch loss: 0.063072 Batch F1: 0.6666666666666666
Epoch:  230       10 Batch loss: 0.055546 Batch F1: 0.5
Epoch:  230       11 Batch loss: 0.058758 Batch F1: 0.33333333333333337
Epoch:  230       12 Batch loss: 0.091771 Batch F1: 0.33333333333333337
Train Avg Loss  230: 0.072881

Train Avg F1  230: 0.5903000254258836

Val Avg Loss  230: 0.064694

Val Avg F1  230:  0.5750534188034188

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 231
--------------------------------------------------------------
Epoch:  231        1 Batch loss: 0.066333 Batch F1: 0.7142857142857143
Epoch:  231        2 Batch loss: 0.061280 Batch F1: 0.888888888888889
Epoch:  231        3 Batch loss: 0.073238 Batch F1: 0.7692307692307693
Epoch:  231        4 Batch loss: 0.053032 Batch F1: 1.0
Epoch:  231        5 Batch loss: 0.055833 Batch F1: 0.7272727272727273
Epoch:  231        6 Batch loss: 0.075365 Batch F1: 0.3636363636363636
Epoch:  231        7 Batch loss: 0.068536 Batch F1: 0.5454545454545454
Epoch:  231        8 Batch loss: 0.102404 Batch F1: 0.2666666666666667
Epoch:  231        9 Batch loss: 0.053933 Batch F1: 0.5
Epoch:  231       10 Batch loss: 0.086374 Batch F1: 0.3076923076923077
Epoch:  231       11 Batch loss: 0.081475 Batch F1: 0.15384615384615385
Epoch:  231       12 Batch loss: 0.061622 Batch F1: 0.9411764705882353
Train Avg Loss  231: 0.069952

Train Avg F1  231: 0.5981792172968643

Val Avg Loss  231: 0.070333

Val Avg F1  231:  0.9221661490683231

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 232
--------------------------------------------------------------
Epoch:  232        1 Batch loss: 0.078367 Batch F1: 1.0
Epoch:  232        2 Batch loss: 0.063434 Batch F1: 0.9333333333333333
Epoch:  232        3 Batch loss: 0.064217 Batch F1: 0.9473684210526316
Epoch:  232        4 Batch loss: 0.050038 Batch F1: 0.9090909090909091
Epoch:  232        5 Batch loss: 0.056651 Batch F1: 0.9090909090909091
Epoch:  232        6 Batch loss: 0.099584 Batch F1: 0.33333333333333337
Epoch:  232        7 Batch loss: 0.099772 Batch F1: 0.42857142857142855
Epoch:  232        8 Batch loss: 0.067687 Batch F1: 0.9333333333333333
Epoch:  232        9 Batch loss: 0.072874 Batch F1: 0.9411764705882353
Epoch:  232       10 Batch loss: 0.076829 Batch F1: 0.8571428571428571
Epoch:  232       11 Batch loss: 0.051623 Batch F1: 1.0
Epoch:  232       12 Batch loss: 0.080246 Batch F1: 0.888888888888889
Train Avg Loss  232: 0.071777

Train Avg F1  232: 0.8401108237021551

Val Avg Loss  232: 0.063534

Val Avg F1  232:  0.9268525592055004

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 233
--------------------------------------------------------------
Epoch:  233        1 Batch loss: 0.083337 Batch F1: 0.9090909090909091
Epoch:  233        2 Batch loss: 0.046432 Batch F1: 1.0
Epoch:  233        3 Batch loss: 0.078219 Batch F1: 0.8421052631578948
Epoch:  233        4 Batch loss: 0.058315 Batch F1: 1.0
Epoch:  233        5 Batch loss: 0.043107 Batch F1: 1.0
Epoch:  233        6 Batch loss: 0.089676 Batch F1: 0.47058823529411764
Epoch:  233        7 Batch loss: 0.076833 Batch F1: 0.6666666666666666
Epoch:  233        8 Batch loss: 0.065466 Batch F1: 0.8333333333333333
Epoch:  233        9 Batch loss: 0.075519 Batch F1: 0.8750000000000001
Epoch:  233       10 Batch loss: 0.063614 Batch F1: 0.9473684210526316
Epoch:  233       11 Batch loss: 0.082618 Batch F1: 0.8750000000000001
Epoch:  233       12 Batch loss: 0.084292 Batch F1: 0.9473684210526316
Train Avg Loss  233: 0.070619

Train Avg F1  233: 0.8638767708040155

Val Avg Loss  233: 0.064056

Val Avg F1  233:  0.9291537667698659

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 234
--------------------------------------------------------------
Epoch:  234        1 Batch loss: 0.079486 Batch F1: 0.9565217391304348
Epoch:  234        2 Batch loss: 0.049093 Batch F1: 1.0
Epoch:  234        3 Batch loss: 0.070467 Batch F1: 0.9411764705882353
Epoch:  234        4 Batch loss: 0.054664 Batch F1: 0.8333333333333333
Epoch:  234        5 Batch loss: 0.036297 Batch F1: 0.888888888888889
Epoch:  234        6 Batch loss: 0.053818 Batch F1: 0.6666666666666666
Epoch:  234        7 Batch loss: 0.111323 Batch F1: 0.2857142857142857
Epoch:  234        8 Batch loss: 0.085642 Batch F1: 0.5882352941176471
Epoch:  234        9 Batch loss: 0.079567 Batch F1: 0.625
Epoch:  234       10 Batch loss: 0.073518 Batch F1: 0.9565217391304348
Epoch:  234       11 Batch loss: 0.072012 Batch F1: 0.923076923076923
Epoch:  234       12 Batch loss: 0.077808 Batch F1: 0.888888888888889
Train Avg Loss  234: 0.070308

Train Avg F1  234: 0.7961686857946448

Val Avg Loss  234: 0.063984

Val Avg F1  234:  0.9268525592055004

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 235
--------------------------------------------------------------
Epoch:  235        1 Batch loss: 0.072195 Batch F1: 0.9600000000000001
Epoch:  235        2 Batch loss: 0.068456 Batch F1: 1.0
Epoch:  235        3 Batch loss: 0.073667 Batch F1: 0.7692307692307693
Epoch:  235        4 Batch loss: 0.071282 Batch F1: 0.9473684210526316
Epoch:  235        5 Batch loss: 0.089040 Batch F1: 0.7142857142857143
Epoch:  235        6 Batch loss: 0.058566 Batch F1: 0.923076923076923
Epoch:  235        7 Batch loss: 0.078134 Batch F1: 0.33333333333333337
Epoch:  235        8 Batch loss: 0.054841 Batch F1: 0.33333333333333337
Epoch:  235        9 Batch loss: 0.080059 Batch F1: 0.42857142857142855
Epoch:  235       10 Batch loss: 0.059282 Batch F1: 0.4
Epoch:  235       11 Batch loss: 0.067411 Batch F1: 0.625
Epoch:  235       12 Batch loss: 0.056144 Batch F1: 0.9090909090909091
Train Avg Loss  235: 0.069090

Train Avg F1  235: 0.6952742359979203

Val Avg Loss  235: 0.063252

Val Avg F1  235:  0.9246336996336996

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 236
--------------------------------------------------------------
Epoch:  236        1 Batch loss: 0.040918 Batch F1: 1.0
Epoch:  236        2 Batch loss: 0.062394 Batch F1: 0.888888888888889
Epoch:  236        3 Batch loss: 0.096772 Batch F1: 0.4210526315789474
Epoch:  236        4 Batch loss: 0.075922 Batch F1: 0.9600000000000001
Epoch:  236        5 Batch loss: 0.067621 Batch F1: 0.9333333333333333
Epoch:  236        6 Batch loss: 0.056036 Batch F1: 1.0
Epoch:  236        7 Batch loss: 0.077051 Batch F1: 0.7692307692307693
Epoch:  236        8 Batch loss: 0.078759 Batch F1: 0.8421052631578948
Epoch:  236        9 Batch loss: 0.080325 Batch F1: 0.9090909090909091
Epoch:  236       10 Batch loss: 0.062159 Batch F1: 0.923076923076923
Epoch:  236       11 Batch loss: 0.064811 Batch F1: 0.8571428571428571
Epoch:  236       12 Batch loss: 0.066779 Batch F1: 1.0
Train Avg Loss  236: 0.069129

Train Avg F1  236: 0.875326797958377

Val Avg Loss  236: 0.061924

Val Avg F1  236:  0.9052075375604787

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 237
--------------------------------------------------------------
Epoch:  237        1 Batch loss: 0.073664 Batch F1: 0.9473684210526316
Epoch:  237        2 Batch loss: 0.054972 Batch F1: 0.923076923076923
Epoch:  237        3 Batch loss: 0.077353 Batch F1: 0.8421052631578948
Epoch:  237        4 Batch loss: 0.054127 Batch F1: 0.33333333333333337
Epoch:  237        5 Batch loss: 0.060563 Batch F1: 0.6153846153846153
Epoch:  237        6 Batch loss: 0.060443 Batch F1: 0.6666666666666666
Epoch:  237        7 Batch loss: 0.104733 Batch F1: 0.375
Epoch:  237        8 Batch loss: 0.033490 Batch F1: 0.888888888888889
Epoch:  237        9 Batch loss: 0.075401 Batch F1: 0.42857142857142855
Epoch:  237       10 Batch loss: 0.064709 Batch F1: 0.5
Epoch:  237       11 Batch loss: 0.072711 Batch F1: 0.9
Epoch:  237       12 Batch loss: 0.096059 Batch F1: 0.7142857142857143
Train Avg Loss  237: 0.069019

Train Avg F1  237: 0.6778901045348414

Val Avg Loss  237: 0.062783

Val Avg F1  237:  0.9039544047283985

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 238
--------------------------------------------------------------
Epoch:  238        1 Batch loss: 0.071553 Batch F1: 0.9090909090909091
Epoch:  238        2 Batch loss: 0.062014 Batch F1: 0.888888888888889
Epoch:  238        3 Batch loss: 0.060617 Batch F1: 1.0
Epoch:  238        4 Batch loss: 0.051486 Batch F1: 0.8571428571428571
Epoch:  238        5 Batch loss: 0.080854 Batch F1: 0.8235294117647058
Epoch:  238        6 Batch loss: 0.081383 Batch F1: 0.5333333333333333
Epoch:  238        7 Batch loss: 0.062188 Batch F1: 0.25
Epoch:  238        8 Batch loss: 0.082206 Batch F1: 0.761904761904762
Epoch:  238        9 Batch loss: 0.078365 Batch F1: 0.18181818181818182
Epoch:  238       10 Batch loss: 0.059959 Batch F1: 0.6666666666666666
Epoch:  238       11 Batch loss: 0.082412 Batch F1: 0.9090909090909091
Epoch:  238       12 Batch loss: 0.075943 Batch F1: 0.9523809523809523
Train Avg Loss  238: 0.070748

Train Avg F1  238: 0.7278205726735139

Val Avg Loss  238: 0.063689

Val Avg F1  238:  0.933041958041958

Optimal Val loss (Epoch 161): 0.061655597761273384

Epoch 239
--------------------------------------------------------------
Epoch:  239        1 Batch loss: 0.066725 Batch F1: 0.9411764705882353
Epoch:  239        2 Batch loss: 0.056632 Batch F1: 0.923076923076923
Epoch:  239        3 Batch loss: 0.060010 Batch F1: 0.923076923076923
Epoch:  239        4 Batch loss: 0.073371 Batch F1: 0.9411764705882353
Epoch:  239        5 Batch loss: 0.081645 Batch F1: 0.8
Epoch:  239        6 Batch loss: 0.067439 Batch F1: 1.0
Epoch:  239        7 Batch loss: 0.069073 Batch F1: 1.0
Epoch:  239        8 Batch loss: 0.079263 Batch F1: 0.9411764705882353
Epoch:  239        9 Batch loss: 0.068317 Batch F1: 0.8750000000000001
Epoch:  239       10 Batch loss: 0.047621 Batch F1: 0.888888888888889
Epoch:  239       11 Batch loss: 0.085096 Batch F1: 0.631578947368421
Epoch:  239       12 Batch loss: 0.074324 Batch F1: 0.9333333333333333
Train Avg Loss  239: 0.069126

Train Avg F1  239: 0.899873702292433

Val Avg Loss  239: 0.061586

Val Avg F1  239:  0.9166040100250625

Optimal Val loss (Epoch 239): 0.061585841700434685

Epoch 240
--------------------------------------------------------------
Epoch:  240        1 Batch loss: 0.060561 Batch F1: 0.7499999999999999
Epoch:  240        2 Batch loss: 0.080170 Batch F1: 0.9166666666666666
Epoch:  240        3 Batch loss: 0.067398 Batch F1: 1.0
Epoch:  240        4 Batch loss: 0.088838 Batch F1: 0.9655172413793104
Epoch:  240        5 Batch loss: 0.075292 Batch F1: 0.8571428571428571
Epoch:  240        6 Batch loss: 0.067377 Batch F1: 0.5714285714285715
Epoch:  240        7 Batch loss: 0.060929 Batch F1: 0.9333333333333333
Epoch:  240        8 Batch loss: 0.060339 Batch F1: 0.9411764705882353
Epoch:  240        9 Batch loss: 0.064839 Batch F1: 0.6153846153846153
Epoch:  240       10 Batch loss: 0.051079 Batch F1: 0.6
Epoch:  240       11 Batch loss: 0.083072 Batch F1: 0.3076923076923077
Epoch:  240       12 Batch loss: 0.068989 Batch F1: 0.0
Train Avg Loss  240: 0.069074

Train Avg F1  240: 0.7048618386346582

Val Avg Loss  240: 0.062203

Val Avg F1  240:  0.587004662004662

Optimal Val loss (Epoch 239): 0.061585841700434685

Epoch 241
--------------------------------------------------------------
Epoch:  241        1 Batch loss: 0.080686 Batch F1: 0.47058823529411764
Epoch:  241        2 Batch loss: 0.047177 Batch F1: 1.0
Epoch:  241        3 Batch loss: 0.058096 Batch F1: 1.0
Epoch:  241        4 Batch loss: 0.092407 Batch F1: 0.8
Epoch:  241        5 Batch loss: 0.063179 Batch F1: 0.7499999999999999
Epoch:  241        6 Batch loss: 0.056949 Batch F1: 0.923076923076923
Epoch:  241        7 Batch loss: 0.073099 Batch F1: 0.888888888888889
Epoch:  241        8 Batch loss: 0.074748 Batch F1: 0.9411764705882353
Epoch:  241        9 Batch loss: 0.078632 Batch F1: 0.9
Epoch:  241       10 Batch loss: 0.068082 Batch F1: 0.9411764705882353
Epoch:  241       11 Batch loss: 0.063367 Batch F1: 0.9333333333333333
Epoch:  241       12 Batch loss: 0.063009 Batch F1: 0.25
Train Avg Loss  241: 0.068286

Train Avg F1  241: 0.8165200268141445

Val Avg Loss  241: 0.061570

Val Avg F1  241:  0.5758240297713982

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 242
--------------------------------------------------------------
Epoch:  242        1 Batch loss: 0.095058 Batch F1: 0.375
Epoch:  242        2 Batch loss: 0.062128 Batch F1: 0.7692307692307693
Epoch:  242        3 Batch loss: 0.065363 Batch F1: 0.888888888888889
Epoch:  242        4 Batch loss: 0.072514 Batch F1: 1.0
Epoch:  242        5 Batch loss: 0.077790 Batch F1: 0.923076923076923
Epoch:  242        6 Batch loss: 0.070555 Batch F1: 1.0
Epoch:  242        7 Batch loss: 0.053987 Batch F1: 0.9090909090909091
Epoch:  242        8 Batch loss: 0.066774 Batch F1: 0.5454545454545454
Epoch:  242        9 Batch loss: 0.075213 Batch F1: 0.625
Epoch:  242       10 Batch loss: 0.068554 Batch F1: 0.5714285714285715
Epoch:  242       11 Batch loss: 0.048877 Batch F1: 0.5714285714285715
Epoch:  242       12 Batch loss: 0.059983 Batch F1: 0.6
Train Avg Loss  242: 0.068066

Train Avg F1  242: 0.7315499315499315

Val Avg Loss  242: 0.062908

Val Avg F1  242:  0.5348598769651401

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 243
--------------------------------------------------------------
Epoch:  243        1 Batch loss: 0.073404 Batch F1: 0.5714285714285715
Epoch:  243        2 Batch loss: 0.078698 Batch F1: 0.19999999999999998
Epoch:  243        3 Batch loss: 0.061177 Batch F1: 0.9473684210526316
Epoch:  243        4 Batch loss: 0.076359 Batch F1: 0.8750000000000001
Epoch:  243        5 Batch loss: 0.067104 Batch F1: 1.0
Epoch:  243        6 Batch loss: 0.075109 Batch F1: 0.9090909090909091
Epoch:  243        7 Batch loss: 0.058864 Batch F1: 0.923076923076923
Epoch:  243        8 Batch loss: 0.064756 Batch F1: 0.8
Epoch:  243        9 Batch loss: 0.073070 Batch F1: 0.962962962962963
Epoch:  243       10 Batch loss: 0.070731 Batch F1: 0.9473684210526316
Epoch:  243       11 Batch loss: 0.065132 Batch F1: 0.9473684210526316
Epoch:  243       12 Batch loss: 0.044544 Batch F1: 1.0
Train Avg Loss  243: 0.067412

Train Avg F1  243: 0.8403053858097719

Val Avg Loss  243: 0.062290

Val Avg F1  243:  0.5966533466533466

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 244
--------------------------------------------------------------
Epoch:  244        1 Batch loss: 0.071245 Batch F1: 0.5714285714285715
Epoch:  244        2 Batch loss: 0.064136 Batch F1: 0.5333333333333333
Epoch:  244        3 Batch loss: 0.058007 Batch F1: 0.2857142857142857
Epoch:  244        4 Batch loss: 0.058402 Batch F1: 0.25
Epoch:  244        5 Batch loss: 0.067915 Batch F1: 0.3636363636363636
Epoch:  244        6 Batch loss: 0.070836 Batch F1: 0.5714285714285715
Epoch:  244        7 Batch loss: 0.089570 Batch F1: 0.88
Epoch:  244        8 Batch loss: 0.059682 Batch F1: 1.0
Epoch:  244        9 Batch loss: 0.065943 Batch F1: 0.8571428571428571
Epoch:  244       10 Batch loss: 0.076411 Batch F1: 0.8333333333333333
Epoch:  244       11 Batch loss: 0.084558 Batch F1: 0.9285714285714286
Epoch:  244       12 Batch loss: 0.058551 Batch F1: 0.8333333333333333
Train Avg Loss  244: 0.068771

Train Avg F1  244: 0.6589935064935065

Val Avg Loss  244: 0.062403

Val Avg F1  244:  0.8963644688644689

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 245
--------------------------------------------------------------
Epoch:  245        1 Batch loss: 0.079959 Batch F1: 0.9
Epoch:  245        2 Batch loss: 0.061153 Batch F1: 0.9523809523809523
Epoch:  245        3 Batch loss: 0.070029 Batch F1: 0.7692307692307693
Epoch:  245        4 Batch loss: 0.051756 Batch F1: 1.0
Epoch:  245        5 Batch loss: 0.062226 Batch F1: 0.7499999999999999
Epoch:  245        6 Batch loss: 0.079543 Batch F1: 0.47058823529411764
Epoch:  245        7 Batch loss: 0.074468 Batch F1: 0.625
Epoch:  245        8 Batch loss: 0.083334 Batch F1: 0.19999999999999998
Epoch:  245        9 Batch loss: 0.077459 Batch F1: 0.3636363636363636
Epoch:  245       10 Batch loss: 0.069158 Batch F1: 0.4444444444444445
Epoch:  245       11 Batch loss: 0.054433 Batch F1: 0.2857142857142857
Epoch:  245       12 Batch loss: 0.074072 Batch F1: 0.5882352941176471
Train Avg Loss  245: 0.069799

Train Avg F1  245: 0.612435862068215

Val Avg Loss  245: 0.062550

Val Avg F1  245:  0.7324862637362638

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 246
--------------------------------------------------------------
Epoch:  246        1 Batch loss: 0.063557 Batch F1: 0.7142857142857143
Epoch:  246        2 Batch loss: 0.077212 Batch F1: 0.8695652173913044
Epoch:  246        3 Batch loss: 0.069487 Batch F1: 0.8333333333333333
Epoch:  246        4 Batch loss: 0.063227 Batch F1: 0.923076923076923
Epoch:  246        5 Batch loss: 0.059549 Batch F1: 0.9411764705882353
Epoch:  246        6 Batch loss: 0.082316 Batch F1: 0.8421052631578948
Epoch:  246        7 Batch loss: 0.063365 Batch F1: 1.0
Epoch:  246        8 Batch loss: 0.087574 Batch F1: 0.9166666666666666
Epoch:  246        9 Batch loss: 0.066790 Batch F1: 0.8750000000000001
Epoch:  246       10 Batch loss: 0.061384 Batch F1: 1.0
Epoch:  246       11 Batch loss: 0.058796 Batch F1: 1.0
Epoch:  246       12 Batch loss: 0.065704 Batch F1: 0.923076923076923
Train Avg Loss  246: 0.068247

Train Avg F1  246: 0.9031905426314163

Val Avg Loss  246: 0.062959

Val Avg F1  246:  0.49017857142857146

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 247
--------------------------------------------------------------
Epoch:  247        1 Batch loss: 0.070547 Batch F1: 0.4615384615384615
Epoch:  247        2 Batch loss: 0.080251 Batch F1: 0.6666666666666666
Epoch:  247        3 Batch loss: 0.050059 Batch F1: 1.0
Epoch:  247        4 Batch loss: 0.078466 Batch F1: 0.9473684210526316
Epoch:  247        5 Batch loss: 0.050803 Batch F1: 1.0
Epoch:  247        6 Batch loss: 0.064722 Batch F1: 0.9411764705882353
Epoch:  247        7 Batch loss: 0.071330 Batch F1: 0.9473684210526316
Epoch:  247        8 Batch loss: 0.067196 Batch F1: 0.8333333333333333
Epoch:  247        9 Batch loss: 0.056111 Batch F1: 0.923076923076923
Epoch:  247       10 Batch loss: 0.084987 Batch F1: 0.8571428571428571
Epoch:  247       11 Batch loss: 0.060243 Batch F1: 0.8
Epoch:  247       12 Batch loss: 0.082955 Batch F1: 0.9523809523809523
Train Avg Loss  247: 0.068139

Train Avg F1  247: 0.8608377089027245

Val Avg Loss  247: 0.061747

Val Avg F1  247:  0.9281655844155845

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 248
--------------------------------------------------------------
Epoch:  248        1 Batch loss: 0.074557 Batch F1: 0.9523809523809523
Epoch:  248        2 Batch loss: 0.061255 Batch F1: 0.9523809523809523
Epoch:  248        3 Batch loss: 0.065895 Batch F1: 1.0
Epoch:  248        4 Batch loss: 0.082689 Batch F1: 0.8235294117647058
Epoch:  248        5 Batch loss: 0.071101 Batch F1: 0.8750000000000001
Epoch:  248        6 Batch loss: 0.084670 Batch F1: 0.8
Epoch:  248        7 Batch loss: 0.062770 Batch F1: 1.0
Epoch:  248        8 Batch loss: 0.059013 Batch F1: 0.923076923076923
Epoch:  248        9 Batch loss: 0.074398 Batch F1: 0.9565217391304348
Epoch:  248       10 Batch loss: 0.065288 Batch F1: 0.6666666666666666
Epoch:  248       11 Batch loss: 0.062853 Batch F1: 0.4
Epoch:  248       12 Batch loss: 0.039949 Batch F1: 0.8
Train Avg Loss  248: 0.067036

Train Avg F1  248: 0.8457963871167197

Val Avg Loss  248: 0.065965

Val Avg F1  248:  0.590034965034965

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 249
--------------------------------------------------------------
Epoch:  249        1 Batch loss: 0.089136 Batch F1: 0.3076923076923077
Epoch:  249        2 Batch loss: 0.031680 Batch F1: 1.0
Epoch:  249        3 Batch loss: 0.064262 Batch F1: 0.5
Epoch:  249        4 Batch loss: 0.061966 Batch F1: 0.6153846153846153
Epoch:  249        5 Batch loss: 0.056266 Batch F1: 0.25
Epoch:  249        6 Batch loss: 0.082477 Batch F1: 0.8181818181818181
Epoch:  249        7 Batch loss: 0.063465 Batch F1: 0.8
Epoch:  249        8 Batch loss: 0.096951 Batch F1: 0.7000000000000001
Epoch:  249        9 Batch loss: 0.048741 Batch F1: 1.0
Epoch:  249       10 Batch loss: 0.084845 Batch F1: 0.9166666666666666
Epoch:  249       11 Batch loss: 0.075488 Batch F1: 0.9473684210526316
Epoch:  249       12 Batch loss: 0.070986 Batch F1: 1.0
Train Avg Loss  249: 0.068855

Train Avg F1  249: 0.7379411524148366

Val Avg Loss  249: 0.061593

Val Avg F1  249:  0.93875

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 250
--------------------------------------------------------------
Epoch:  250        1 Batch loss: 0.076565 Batch F1: 0.9166666666666666
Epoch:  250        2 Batch loss: 0.057906 Batch F1: 0.9333333333333333
Epoch:  250        3 Batch loss: 0.071077 Batch F1: 0.8750000000000001
Epoch:  250        4 Batch loss: 0.068183 Batch F1: 0.5882352941176471
Epoch:  250        5 Batch loss: 0.041786 Batch F1: 0.0
Epoch:  250        6 Batch loss: 0.059478 Batch F1: 0.4444444444444445
Epoch:  250        7 Batch loss: 0.064120 Batch F1: 0.4
Epoch:  250        8 Batch loss: 0.076585 Batch F1: 0.6666666666666666
Epoch:  250        9 Batch loss: 0.060699 Batch F1: 0.5
Epoch:  250       10 Batch loss: 0.096471 Batch F1: 0.25
Epoch:  250       11 Batch loss: 0.077077 Batch F1: 0.8
Epoch:  250       12 Batch loss: 0.073167 Batch F1: 1.0
Train Avg Loss  250: 0.068593

Train Avg F1  250: 0.6145288671023966

Val Avg Loss  250: 0.064469

Val Avg F1  250:  0.9219587176108915

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 251
--------------------------------------------------------------
Epoch:  251        1 Batch loss: 0.071977 Batch F1: 1.0
Epoch:  251        2 Batch loss: 0.059356 Batch F1: 0.7692307692307693
Epoch:  251        3 Batch loss: 0.072495 Batch F1: 0.5
Epoch:  251        4 Batch loss: 0.078265 Batch F1: 0.3636363636363636
Epoch:  251        5 Batch loss: 0.083354 Batch F1: 0.3076923076923077
Epoch:  251        6 Batch loss: 0.091979 Batch F1: 0.8
Epoch:  251        7 Batch loss: 0.121610 Batch F1: 0.7272727272727274
Epoch:  251        8 Batch loss: 0.081399 Batch F1: 0.5333333333333333
Epoch:  251        9 Batch loss: 0.091111 Batch F1: 0.0
Epoch:  251       10 Batch loss: 0.060260 Batch F1: 0.6
Epoch:  251       11 Batch loss: 0.067844 Batch F1: 0.3636363636363636
Epoch:  251       12 Batch loss: 0.084492 Batch F1: 0.8750000000000001
Train Avg Loss  251: 0.080345

Train Avg F1  251: 0.5699834887334887

Val Avg Loss  251: 0.083819

Val Avg F1  251:  0.7961906514538094

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 252
--------------------------------------------------------------
Epoch:  252        1 Batch loss: 0.111291 Batch F1: 0.5
Epoch:  252        2 Batch loss: 0.086377 Batch F1: 0.0
Epoch:  252        3 Batch loss: 0.115408 Batch F1: 0.0
Epoch:  252        4 Batch loss: 0.142094 Batch F1: 0.0
Epoch:  252        5 Batch loss: 0.062279 Batch F1: 0.0
Epoch:  252        6 Batch loss: 0.078997 Batch F1: 0.9411764705882353
Epoch:  252        7 Batch loss: 0.075608 Batch F1: 0.9411764705882353
Epoch:  252        8 Batch loss: 0.088521 Batch F1: 0.9090909090909091
Epoch:  252        9 Batch loss: 0.081841 Batch F1: 0.7058823529411764
Epoch:  252       10 Batch loss: 0.088854 Batch F1: 0.47058823529411764
Epoch:  252       11 Batch loss: 0.053118 Batch F1: 0.6
Epoch:  252       12 Batch loss: 0.083204 Batch F1: 0.5714285714285715
Train Avg Loss  252: 0.088966

Train Avg F1  252: 0.4699452508276037

Val Avg Loss  252: 0.066781

Val Avg F1  252:  0.9218020541549953

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 253
--------------------------------------------------------------
Epoch:  253        1 Batch loss: 0.071854 Batch F1: 0.9411764705882353
Epoch:  253        2 Batch loss: 0.050257 Batch F1: 1.0
Epoch:  253        3 Batch loss: 0.060034 Batch F1: 0.0
Epoch:  253        4 Batch loss: 0.105172 Batch F1: 0.0
Epoch:  253        5 Batch loss: 0.087808 Batch F1: 0.8
Epoch:  253        6 Batch loss: 0.095966 Batch F1: 0.7499999999999999
Epoch:  253        7 Batch loss: 0.072651 Batch F1: 1.0
Epoch:  253        8 Batch loss: 0.086258 Batch F1: 0.9600000000000001
Epoch:  253        9 Batch loss: 0.081251 Batch F1: 0.8333333333333333
Epoch:  253       10 Batch loss: 0.070580 Batch F1: 0.9473684210526316
Epoch:  253       11 Batch loss: 0.061985 Batch F1: 0.9333333333333333
Epoch:  253       12 Batch loss: 0.053060 Batch F1: 0.5
Train Avg Loss  253: 0.074740

Train Avg F1  253: 0.7221009631922944

Val Avg Loss  253: 0.069486

Val Avg F1  253:  0.549066065513434

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 254
--------------------------------------------------------------
Epoch:  254        1 Batch loss: 0.055905 Batch F1: 0.4
Epoch:  254        2 Batch loss: 0.071085 Batch F1: 0.0
Epoch:  254        3 Batch loss: 0.069311 Batch F1: 0.0
Epoch:  254        4 Batch loss: 0.130490 Batch F1: 0.45454545454545453
Epoch:  254        5 Batch loss: 0.103912 Batch F1: 0.2857142857142857
Epoch:  254        6 Batch loss: 0.068641 Batch F1: 1.0
Epoch:  254        7 Batch loss: 0.064625 Batch F1: 0.8
Epoch:  254        8 Batch loss: 0.067081 Batch F1: 1.0
Epoch:  254        9 Batch loss: 0.065300 Batch F1: 1.0
Epoch:  254       10 Batch loss: 0.061948 Batch F1: 0.8333333333333333
Epoch:  254       11 Batch loss: 0.109913 Batch F1: 0.0
Epoch:  254       12 Batch loss: 0.088779 Batch F1: 0.888888888888889
Train Avg Loss  254: 0.079749

Train Avg F1  254: 0.5552068302068301

Val Avg Loss  254: 0.066493

Val Avg F1  254:  0.9233500417710945

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 255
--------------------------------------------------------------
Epoch:  255        1 Batch loss: 0.073887 Batch F1: 0.8571428571428571
Epoch:  255        2 Batch loss: 0.088457 Batch F1: 0.9565217391304348
Epoch:  255        3 Batch loss: 0.059913 Batch F1: 0.8333333333333333
Epoch:  255        4 Batch loss: 0.072219 Batch F1: 0.8571428571428571
Epoch:  255        5 Batch loss: 0.074814 Batch F1: 0.25
Epoch:  255        6 Batch loss: 0.091038 Batch F1: 0.0
Epoch:  255        7 Batch loss: 0.103159 Batch F1: 0.5714285714285715
Epoch:  255        8 Batch loss: 0.078226 Batch F1: 0.2222222222222222
Epoch:  255        9 Batch loss: 0.067888 Batch F1: 0.9333333333333333
Epoch:  255       10 Batch loss: 0.061713 Batch F1: 1.0
Epoch:  255       11 Batch loss: 0.062748 Batch F1: 0.9090909090909091
Epoch:  255       12 Batch loss: 0.090123 Batch F1: 0.625
Train Avg Loss  255: 0.077016

Train Avg F1  255: 0.6679346519020433

Val Avg Loss  255: 0.065887

Val Avg F1  255:  0.9355263157894737

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 256
--------------------------------------------------------------
Epoch:  256        1 Batch loss: 0.076605 Batch F1: 0.888888888888889
Epoch:  256        2 Batch loss: 0.060709 Batch F1: 0.8333333333333333
Epoch:  256        3 Batch loss: 0.061411 Batch F1: 1.0
Epoch:  256        4 Batch loss: 0.103572 Batch F1: 0.9696969696969697
Epoch:  256        5 Batch loss: 0.053698 Batch F1: 1.0
Epoch:  256        6 Batch loss: 0.088394 Batch F1: 0.8235294117647058
Epoch:  256        7 Batch loss: 0.072150 Batch F1: 0.9411764705882353
Epoch:  256        8 Batch loss: 0.060051 Batch F1: 1.0
Epoch:  256        9 Batch loss: 0.063422 Batch F1: 0.8571428571428571
Epoch:  256       10 Batch loss: 0.060205 Batch F1: 1.0
Epoch:  256       11 Batch loss: 0.065789 Batch F1: 0.8750000000000001
Epoch:  256       12 Batch loss: 0.098657 Batch F1: 0.8421052631578948
Train Avg Loss  256: 0.072055

Train Avg F1  256: 0.9192394328810738

Val Avg Loss  256: 0.064132

Val Avg F1  256:  0.9215643274853801

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 257
--------------------------------------------------------------
Epoch:  257        1 Batch loss: 0.076030 Batch F1: 0.8750000000000001
Epoch:  257        2 Batch loss: 0.060709 Batch F1: 0.8571428571428571
Epoch:  257        3 Batch loss: 0.065288 Batch F1: 0.8571428571428571
Epoch:  257        4 Batch loss: 0.071787 Batch F1: 0.8750000000000001
Epoch:  257        5 Batch loss: 0.056636 Batch F1: 1.0
Epoch:  257        6 Batch loss: 0.072643 Batch F1: 0.5333333333333333
Epoch:  257        7 Batch loss: 0.079333 Batch F1: 0.33333333333333337
Epoch:  257        8 Batch loss: 0.068602 Batch F1: 0.5333333333333333
Epoch:  257        9 Batch loss: 0.066081 Batch F1: 0.7142857142857143
Epoch:  257       10 Batch loss: 0.062952 Batch F1: 0.9411764705882353
Epoch:  257       11 Batch loss: 0.078507 Batch F1: 0.9473684210526316
Epoch:  257       12 Batch loss: 0.081953 Batch F1: 0.9473684210526316
Train Avg Loss  257: 0.070044

Train Avg F1  257: 0.7845403951054105

Val Avg Loss  257: 0.062888

Val Avg F1  257:  0.9251276759016697

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 258
--------------------------------------------------------------
Epoch:  258        1 Batch loss: 0.068430 Batch F1: 1.0
Epoch:  258        2 Batch loss: 0.054263 Batch F1: 0.888888888888889
Epoch:  258        3 Batch loss: 0.105816 Batch F1: 0.782608695652174
Epoch:  258        4 Batch loss: 0.075529 Batch F1: 1.0
Epoch:  258        5 Batch loss: 0.070867 Batch F1: 0.9
Epoch:  258        6 Batch loss: 0.070088 Batch F1: 1.0
Epoch:  258        7 Batch loss: 0.063796 Batch F1: 0.923076923076923
Epoch:  258        8 Batch loss: 0.068843 Batch F1: 0.888888888888889
Epoch:  258        9 Batch loss: 0.057159 Batch F1: 0.7499999999999999
Epoch:  258       10 Batch loss: 0.057245 Batch F1: 0.888888888888889
Epoch:  258       11 Batch loss: 0.065588 Batch F1: 0.6153846153846153
Epoch:  258       12 Batch loss: 0.067554 Batch F1: 0.5454545454545454
Train Avg Loss  258: 0.068765

Train Avg F1  258: 0.8485992871862437

Val Avg Loss  258: 0.064447

Val Avg F1  258:  0.587012987012987

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 259
--------------------------------------------------------------
Epoch:  259        1 Batch loss: 0.052472 Batch F1: 0.6
Epoch:  259        2 Batch loss: 0.074231 Batch F1: 0.0
Epoch:  259        3 Batch loss: 0.087797 Batch F1: 0.47058823529411764
Epoch:  259        4 Batch loss: 0.073316 Batch F1: 0.5882352941176471
Epoch:  259        5 Batch loss: 0.058129 Batch F1: 0.9090909090909091
Epoch:  259        6 Batch loss: 0.067622 Batch F1: 0.8
Epoch:  259        7 Batch loss: 0.072249 Batch F1: 0.9333333333333333
Epoch:  259        8 Batch loss: 0.066659 Batch F1: 0.7692307692307693
Epoch:  259        9 Batch loss: 0.076031 Batch F1: 0.9565217391304348
Epoch:  259       10 Batch loss: 0.060668 Batch F1: 0.9333333333333333
Epoch:  259       11 Batch loss: 0.069200 Batch F1: 0.9411764705882353
Epoch:  259       12 Batch loss: 0.070869 Batch F1: 1.0
Train Avg Loss  259: 0.069104

Train Avg F1  259: 0.7417925070098983

Val Avg Loss  259: 0.062113

Val Avg F1  259:  0.9228911185432924

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 260
--------------------------------------------------------------
Epoch:  260        1 Batch loss: 0.061321 Batch F1: 0.9333333333333333
Epoch:  260        2 Batch loss: 0.054958 Batch F1: 0.7692307692307693
Epoch:  260        3 Batch loss: 0.068598 Batch F1: 0.25
Epoch:  260        4 Batch loss: 0.080362 Batch F1: 0.5
Epoch:  260        5 Batch loss: 0.079788 Batch F1: 0.625
Epoch:  260        6 Batch loss: 0.074502 Batch F1: 0.9333333333333333
Epoch:  260        7 Batch loss: 0.077062 Batch F1: 0.888888888888889
Epoch:  260        8 Batch loss: 0.070986 Batch F1: 0.8750000000000001
Epoch:  260        9 Batch loss: 0.064858 Batch F1: 0.9523809523809523
Epoch:  260       10 Batch loss: 0.058803 Batch F1: 0.888888888888889
Epoch:  260       11 Batch loss: 0.088738 Batch F1: 0.0
Epoch:  260       12 Batch loss: 0.055756 Batch F1: 0.7692307692307693
Train Avg Loss  260: 0.069644

Train Avg F1  260: 0.6987739112739114

Val Avg Loss  260: 0.063125

Val Avg F1  260:  0.5539986329460014

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 261
--------------------------------------------------------------
Epoch:  261        1 Batch loss: 0.082698 Batch F1: 0.72
Epoch:  261        2 Batch loss: 0.038787 Batch F1: 1.0
Epoch:  261        3 Batch loss: 0.040530 Batch F1: 1.0
Epoch:  261        4 Batch loss: 0.082145 Batch F1: 0.9090909090909091
Epoch:  261        5 Batch loss: 0.052531 Batch F1: 1.0
Epoch:  261        6 Batch loss: 0.077519 Batch F1: 0.9523809523809523
Epoch:  261        7 Batch loss: 0.075810 Batch F1: 0.2222222222222222
Epoch:  261        8 Batch loss: 0.058208 Batch F1: 0.5454545454545454
Epoch:  261        9 Batch loss: 0.075046 Batch F1: 0.3636363636363636
Epoch:  261       10 Batch loss: 0.083117 Batch F1: 0.9090909090909091
Epoch:  261       11 Batch loss: 0.081518 Batch F1: 0.9
Epoch:  261       12 Batch loss: 0.073457 Batch F1: 0.7272727272727273
Train Avg Loss  261: 0.068447

Train Avg F1  261: 0.7707623857623856

Val Avg Loss  261: 0.062203

Val Avg F1  261:  0.9257309941520467

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 262
--------------------------------------------------------------
Epoch:  262        1 Batch loss: 0.062132 Batch F1: 1.0
Epoch:  262        2 Batch loss: 0.055819 Batch F1: 1.0
Epoch:  262        3 Batch loss: 0.073574 Batch F1: 0.9
Epoch:  262        4 Batch loss: 0.072666 Batch F1: 0.8571428571428571
Epoch:  262        5 Batch loss: 0.062168 Batch F1: 0.5
Epoch:  262        6 Batch loss: 0.054726 Batch F1: 0.4444444444444445
Epoch:  262        7 Batch loss: 0.080512 Batch F1: 0.42857142857142855
Epoch:  262        8 Batch loss: 0.078290 Batch F1: 0.5
Epoch:  262        9 Batch loss: 0.083823 Batch F1: 0.8421052631578948
Epoch:  262       10 Batch loss: 0.062807 Batch F1: 0.9473684210526316
Epoch:  262       11 Batch loss: 0.063607 Batch F1: 0.9411764705882353
Epoch:  262       12 Batch loss: 0.081993 Batch F1: 0.9523809523809523
Train Avg Loss  262: 0.069343

Train Avg F1  262: 0.7760991531115371

Val Avg Loss  262: 0.063331

Val Avg F1  262:  0.9265079365079365

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 263
--------------------------------------------------------------
Epoch:  263        1 Batch loss: 0.070509 Batch F1: 0.9411764705882353
Epoch:  263        2 Batch loss: 0.104863 Batch F1: 0.8181818181818181
Epoch:  263        3 Batch loss: 0.063586 Batch F1: 1.0
Epoch:  263        4 Batch loss: 0.054392 Batch F1: 1.0
Epoch:  263        5 Batch loss: 0.049931 Batch F1: 0.923076923076923
Epoch:  263        6 Batch loss: 0.065887 Batch F1: 0.5454545454545454
Epoch:  263        7 Batch loss: 0.063849 Batch F1: 0.5
Epoch:  263        8 Batch loss: 0.057226 Batch F1: 0.8
Epoch:  263        9 Batch loss: 0.098382 Batch F1: 0.375
Epoch:  263       10 Batch loss: 0.070657 Batch F1: 0.6666666666666666
Epoch:  263       11 Batch loss: 0.066817 Batch F1: 0.9473684210526316
Epoch:  263       12 Batch loss: 0.064714 Batch F1: 0.9090909090909091
Train Avg Loss  263: 0.069234

Train Avg F1  263: 0.7855013128426441

Val Avg Loss  263: 0.062643

Val Avg F1  263:  0.9211309523809523

Optimal Val loss (Epoch 241): 0.061569975689053535

Epoch 264
--------------------------------------------------------------
Epoch:  264        1 Batch loss: 0.081739 Batch F1: 0.8235294117647058
Epoch:  264        2 Batch loss: 0.058171 Batch F1: 0.8
Epoch:  264        3 Batch loss: 0.074915 Batch F1: 0.9523809523809523
Epoch:  264        4 Batch loss: 0.067978 Batch F1: 0.9523809523809523
Epoch:  264        5 Batch loss: 0.074891 Batch F1: 0.9473684210526316
Epoch:  264        6 Batch loss: 0.057259 Batch F1: 0.9333333333333333
Epoch:  264        7 Batch loss: 0.059228 Batch F1: 0.9333333333333333
Epoch:  264        8 Batch loss: 0.074969 Batch F1: 0.9523809523809523
Epoch:  264        9 Batch loss: 0.049155 Batch F1: 1.0
Epoch:  264       10 Batch loss: 0.056108 Batch F1: 0.9333333333333333
Epoch:  264       11 Batch loss: 0.073125 Batch F1: 0.9
Epoch:  264       12 Batch loss: 0.098102 Batch F1: 0.8421052631578948
Train Avg Loss  264: 0.068803

Train Avg F1  264: 0.9141788294265076

Val Avg Loss  264: 0.061442

Val Avg F1  264:  0.9232034412955465

Optimal Val loss (Epoch 264): 0.06144154630601406

Epoch 265
--------------------------------------------------------------
Epoch:  265        1 Batch loss: 0.065204 Batch F1: 0.923076923076923
Epoch:  265        2 Batch loss: 0.074175 Batch F1: 0.9090909090909091
Epoch:  265        3 Batch loss: 0.060953 Batch F1: 0.923076923076923
Epoch:  265        4 Batch loss: 0.060773 Batch F1: 0.7499999999999999
Epoch:  265        5 Batch loss: 0.091760 Batch F1: 0.23529411764705882
Epoch:  265        6 Batch loss: 0.079183 Batch F1: 0.9523809523809523
Epoch:  265        7 Batch loss: 0.072700 Batch F1: 1.0
Epoch:  265        8 Batch loss: 0.058015 Batch F1: 0.7499999999999999
Epoch:  265        9 Batch loss: 0.053764 Batch F1: 0.923076923076923
Epoch:  265       10 Batch loss: 0.070672 Batch F1: 0.9565217391304348
Epoch:  265       11 Batch loss: 0.065010 Batch F1: 0.8750000000000001
Epoch:  265       12 Batch loss: 0.063103 Batch F1: 0.9333333333333333
Train Avg Loss  265: 0.067943

Train Avg F1  265: 0.8442376517344549

Val Avg Loss  265: 0.061115

Val Avg F1  265:  0.9209600706311234

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 266
--------------------------------------------------------------
Epoch:  266        1 Batch loss: 0.052208 Batch F1: 1.0
Epoch:  266        2 Batch loss: 0.067725 Batch F1: 0.5333333333333333
Epoch:  266        3 Batch loss: 0.046600 Batch F1: 0.7272727272727273
Epoch:  266        4 Batch loss: 0.088962 Batch F1: 0.2857142857142857
Epoch:  266        5 Batch loss: 0.077714 Batch F1: 0.6153846153846153
Epoch:  266        6 Batch loss: 0.100104 Batch F1: 0.8181818181818181
Epoch:  266        7 Batch loss: 0.056885 Batch F1: 0.9411764705882353
Epoch:  266        8 Batch loss: 0.072592 Batch F1: 0.888888888888889
Epoch:  266        9 Batch loss: 0.065316 Batch F1: 0.8571428571428571
Epoch:  266       10 Batch loss: 0.070815 Batch F1: 1.0
Epoch:  266       11 Batch loss: 0.066337 Batch F1: 0.9333333333333333
Epoch:  266       12 Batch loss: 0.060462 Batch F1: 0.9333333333333333
Train Avg Loss  266: 0.068810

Train Avg F1  266: 0.7944801385977857

Val Avg Loss  266: 0.061515

Val Avg F1  266:  0.9116409189938601

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 267
--------------------------------------------------------------
Epoch:  267        1 Batch loss: 0.060040 Batch F1: 0.8333333333333333
Epoch:  267        2 Batch loss: 0.068625 Batch F1: 1.0
Epoch:  267        3 Batch loss: 0.069222 Batch F1: 0.4615384615384615
Epoch:  267        4 Batch loss: 0.045756 Batch F1: 0.5714285714285715
Epoch:  267        5 Batch loss: 0.050520 Batch F1: 0.6666666666666666
Epoch:  267        6 Batch loss: 0.080587 Batch F1: 0.5882352941176471
Epoch:  267        7 Batch loss: 0.078266 Batch F1: 0.18181818181818182
Epoch:  267        8 Batch loss: 0.063650 Batch F1: 0.4444444444444445
Epoch:  267        9 Batch loss: 0.075967 Batch F1: 0.42857142857142855
Epoch:  267       10 Batch loss: 0.066331 Batch F1: 0.8571428571428571
Epoch:  267       11 Batch loss: 0.073839 Batch F1: 0.9565217391304348
Epoch:  267       12 Batch loss: 0.079624 Batch F1: 0.8
Train Avg Loss  267: 0.067702

Train Avg F1  267: 0.6491417481826688

Val Avg Loss  267: 0.061676

Val Avg F1  267:  0.9048913043478262

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 268
--------------------------------------------------------------
Epoch:  268        1 Batch loss: 0.050669 Batch F1: 0.888888888888889
Epoch:  268        2 Batch loss: 0.062930 Batch F1: 0.9090909090909091
Epoch:  268        3 Batch loss: 0.074095 Batch F1: 0.9166666666666666
Epoch:  268        4 Batch loss: 0.061690 Batch F1: 0.8750000000000001
Epoch:  268        5 Batch loss: 0.054888 Batch F1: 0.9090909090909091
Epoch:  268        6 Batch loss: 0.086474 Batch F1: 0.8695652173913044
Epoch:  268        7 Batch loss: 0.060758 Batch F1: 1.0
Epoch:  268        8 Batch loss: 0.069881 Batch F1: 0.962962962962963
Epoch:  268        9 Batch loss: 0.074558 Batch F1: 0.9473684210526316
Epoch:  268       10 Batch loss: 0.059675 Batch F1: 1.0
Epoch:  268       11 Batch loss: 0.079806 Batch F1: 0.9
Epoch:  268       12 Batch loss: 0.082029 Batch F1: 0.8333333333333333
Train Avg Loss  268: 0.068121

Train Avg F1  268: 0.9176639423731339

Val Avg Loss  268: 0.061357

Val Avg F1  268:  0.9228843052372463

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 269
--------------------------------------------------------------
Epoch:  269        1 Batch loss: 0.062099 Batch F1: 0.9090909090909091
Epoch:  269        2 Batch loss: 0.059681 Batch F1: 0.4444444444444445
Epoch:  269        3 Batch loss: 0.059059 Batch F1: 0.5454545454545454
Epoch:  269        4 Batch loss: 0.106190 Batch F1: 0.4210526315789474
Epoch:  269        5 Batch loss: 0.062626 Batch F1: 0.7368421052631579
Epoch:  269        6 Batch loss: 0.091973 Batch F1: 0.846153846153846
Epoch:  269        7 Batch loss: 0.055505 Batch F1: 1.0
Epoch:  269        8 Batch loss: 0.077572 Batch F1: 0.9523809523809523
Epoch:  269        9 Batch loss: 0.063936 Batch F1: 0.7692307692307693
Epoch:  269       10 Batch loss: 0.066214 Batch F1: 1.0
Epoch:  269       11 Batch loss: 0.057628 Batch F1: 0.9090909090909091
Epoch:  269       12 Batch loss: 0.067489 Batch F1: 0.9333333333333333
Train Avg Loss  269: 0.069164

Train Avg F1  269: 0.788922870501818

Val Avg Loss  269: 0.062126

Val Avg F1  269:  0.9468325791855203

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 270
--------------------------------------------------------------
Epoch:  270        1 Batch loss: 0.100453 Batch F1: 0.9375
Epoch:  270        2 Batch loss: 0.049016 Batch F1: 0.8
Epoch:  270        3 Batch loss: 0.061718 Batch F1: 0.923076923076923
Epoch:  270        4 Batch loss: 0.077950 Batch F1: 1.0
Epoch:  270        5 Batch loss: 0.050618 Batch F1: 1.0
Epoch:  270        6 Batch loss: 0.086829 Batch F1: 0.5333333333333333
Epoch:  270        7 Batch loss: 0.065417 Batch F1: 0.2857142857142857
Epoch:  270        8 Batch loss: 0.064743 Batch F1: 0.5714285714285715
Epoch:  270        9 Batch loss: 0.083198 Batch F1: 0.5555555555555556
Epoch:  270       10 Batch loss: 0.053888 Batch F1: 0.6666666666666666
Epoch:  270       11 Batch loss: 0.058309 Batch F1: 0.7499999999999999
Epoch:  270       12 Batch loss: 0.074487 Batch F1: 0.8333333333333333
Train Avg Loss  270: 0.068886

Train Avg F1  270: 0.7380507224257223

Val Avg Loss  270: 0.061511

Val Avg F1  270:  0.9175309816042081

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 271
--------------------------------------------------------------
Epoch:  271        1 Batch loss: 0.056126 Batch F1: 1.0
Epoch:  271        2 Batch loss: 0.067790 Batch F1: 0.888888888888889
Epoch:  271        3 Batch loss: 0.076085 Batch F1: 0.7692307692307693
Epoch:  271        4 Batch loss: 0.080717 Batch F1: 0.8421052631578948
Epoch:  271        5 Batch loss: 0.070560 Batch F1: 0.9411764705882353
Epoch:  271        6 Batch loss: 0.083658 Batch F1: 0.9565217391304348
Epoch:  271        7 Batch loss: 0.069062 Batch F1: 0.9600000000000001
Epoch:  271        8 Batch loss: 0.061706 Batch F1: 0.923076923076923
Epoch:  271        9 Batch loss: 0.063683 Batch F1: 0.8333333333333333
Epoch:  271       10 Batch loss: 0.059100 Batch F1: 0.9333333333333333
Epoch:  271       11 Batch loss: 0.066287 Batch F1: 0.5714285714285715
Epoch:  271       12 Batch loss: 0.046076 Batch F1: 0.4
Train Avg Loss  271: 0.066737

Train Avg F1  271: 0.8349246076806986

Val Avg Loss  271: 0.063114

Val Avg F1  271:  0.5966346153846154

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 272
--------------------------------------------------------------
Epoch:  272        1 Batch loss: 0.061249 Batch F1: 0.4
Epoch:  272        2 Batch loss: 0.080172 Batch F1: 0.5882352941176471
Epoch:  272        3 Batch loss: 0.067803 Batch F1: 0.625
Epoch:  272        4 Batch loss: 0.059747 Batch F1: 0.6666666666666666
Epoch:  272        5 Batch loss: 0.055745 Batch F1: 0.6666666666666666
Epoch:  272        6 Batch loss: 0.086779 Batch F1: 0.8571428571428571
Epoch:  272        7 Batch loss: 0.070525 Batch F1: 0.8333333333333333
Epoch:  272        8 Batch loss: 0.066287 Batch F1: 1.0
Epoch:  272        9 Batch loss: 0.061663 Batch F1: 0.8571428571428571
Epoch:  272       10 Batch loss: 0.062655 Batch F1: 0.8333333333333333
Epoch:  272       11 Batch loss: 0.078745 Batch F1: 0.7692307692307693
Epoch:  272       12 Batch loss: 0.063357 Batch F1: 0.923076923076923
Train Avg Loss  272: 0.067894

Train Avg F1  272: 0.7516523917259211

Val Avg Loss  272: 0.061739

Val Avg F1  272:  0.9172771672771672

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 273
--------------------------------------------------------------
Epoch:  273        1 Batch loss: 0.091046 Batch F1: 0.888888888888889
Epoch:  273        2 Batch loss: 0.059336 Batch F1: 0.9411764705882353
Epoch:  273        3 Batch loss: 0.074131 Batch F1: 0.9523809523809523
Epoch:  273        4 Batch loss: 0.062127 Batch F1: 0.9090909090909091
Epoch:  273        5 Batch loss: 0.068694 Batch F1: 0.9473684210526316
Epoch:  273        6 Batch loss: 0.064683 Batch F1: 0.5
Epoch:  273        7 Batch loss: 0.056548 Batch F1: 0.4444444444444445
Epoch:  273        8 Batch loss: 0.073678 Batch F1: 0.3636363636363636
Epoch:  273        9 Batch loss: 0.058762 Batch F1: 0.4444444444444445
Epoch:  273       10 Batch loss: 0.046529 Batch F1: 0.5
Epoch:  273       11 Batch loss: 0.070614 Batch F1: 0.4615384615384615
Epoch:  273       12 Batch loss: 0.086395 Batch F1: 0.5
Train Avg Loss  273: 0.067712

Train Avg F1  273: 0.6544141130054443

Val Avg Loss  273: 0.061669

Val Avg F1  273:  0.515727931488801

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 274
--------------------------------------------------------------
Epoch:  274        1 Batch loss: 0.089678 Batch F1: 0.2857142857142857
Epoch:  274        2 Batch loss: 0.073414 Batch F1: 0.9565217391304348
Epoch:  274        3 Batch loss: 0.062300 Batch F1: 0.8750000000000001
Epoch:  274        4 Batch loss: 0.062160 Batch F1: 0.9473684210526316
Epoch:  274        5 Batch loss: 0.066170 Batch F1: 1.0
Epoch:  274        6 Batch loss: 0.069732 Batch F1: 0.923076923076923
Epoch:  274        7 Batch loss: 0.069050 Batch F1: 0.9473684210526316
Epoch:  274        8 Batch loss: 0.067240 Batch F1: 0.625
Epoch:  274        9 Batch loss: 0.107552 Batch F1: 0.25
Epoch:  274       10 Batch loss: 0.041484 Batch F1: 0.888888888888889
Epoch:  274       11 Batch loss: 0.064436 Batch F1: 0.923076923076923
Epoch:  274       12 Batch loss: 0.064974 Batch F1: 1.0
Train Avg Loss  274: 0.069849

Train Avg F1  274: 0.8018346334993933

Val Avg Loss  274: 0.061664

Val Avg F1  274:  0.5355699855699856

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 275
--------------------------------------------------------------
Epoch:  275        1 Batch loss: 0.059020 Batch F1: 0.6153846153846153
Epoch:  275        2 Batch loss: 0.081866 Batch F1: 0.5714285714285715
Epoch:  275        3 Batch loss: 0.078238 Batch F1: 0.5333333333333333
Epoch:  275        4 Batch loss: 0.060787 Batch F1: 0.6153846153846153
Epoch:  275        5 Batch loss: 0.054435 Batch F1: 0.5
Epoch:  275        6 Batch loss: 0.085485 Batch F1: 0.4
Epoch:  275        7 Batch loss: 0.073566 Batch F1: 0.9090909090909091
Epoch:  275        8 Batch loss: 0.084186 Batch F1: 0.88
Epoch:  275        9 Batch loss: 0.072622 Batch F1: 1.0
Epoch:  275       10 Batch loss: 0.057929 Batch F1: 1.0
Epoch:  275       11 Batch loss: 0.057460 Batch F1: 0.5
Epoch:  275       12 Batch loss: 0.079838 Batch F1: 0.2222222222222222
Train Avg Loss  275: 0.070453

Train Avg F1  275: 0.6455703555703556

Val Avg Loss  275: 0.069796

Val Avg F1  275:  0.5812937062937062

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 276
--------------------------------------------------------------
Epoch:  276        1 Batch loss: 0.055056 Batch F1: 0.4444444444444445
Epoch:  276        2 Batch loss: 0.098836 Batch F1: 0.631578947368421
Epoch:  276        3 Batch loss: 0.080607 Batch F1: 0.9
Epoch:  276        4 Batch loss: 0.085707 Batch F1: 1.0
Epoch:  276        5 Batch loss: 0.065552 Batch F1: 1.0
Epoch:  276        6 Batch loss: 0.081660 Batch F1: 0.5333333333333333
Epoch:  276        7 Batch loss: 0.057759 Batch F1: 0.7272727272727273
Epoch:  276        8 Batch loss: 0.077653 Batch F1: 0.33333333333333337
Epoch:  276        9 Batch loss: 0.099347 Batch F1: 0.5263157894736842
Epoch:  276       10 Batch loss: 0.048615 Batch F1: 0.923076923076923
Epoch:  276       11 Batch loss: 0.062490 Batch F1: 0.6666666666666666
Epoch:  276       12 Batch loss: 0.077471 Batch F1: 0.19999999999999998
Train Avg Loss  276: 0.074229

Train Avg F1  276: 0.6571685137474611

Val Avg Loss  276: 0.066065

Val Avg F1  276:  0.9210084033613446

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 277
--------------------------------------------------------------
Epoch:  277        1 Batch loss: 0.080892 Batch F1: 0.7692307692307693
Epoch:  277        2 Batch loss: 0.089276 Batch F1: 0.9333333333333333
Epoch:  277        3 Batch loss: 0.073464 Batch F1: 0.9333333333333333
Epoch:  277        4 Batch loss: 0.059419 Batch F1: 1.0
Epoch:  277        5 Batch loss: 0.092247 Batch F1: 0.5
Epoch:  277        6 Batch loss: 0.061319 Batch F1: 0.6
Epoch:  277        7 Batch loss: 0.067777 Batch F1: 0.5
Epoch:  277        8 Batch loss: 0.050865 Batch F1: 1.0
Epoch:  277        9 Batch loss: 0.093130 Batch F1: 0.7777777777777778
Epoch:  277       10 Batch loss: 0.069462 Batch F1: 0.8571428571428571
Epoch:  277       11 Batch loss: 0.065207 Batch F1: 0.9473684210526316
Epoch:  277       12 Batch loss: 0.067129 Batch F1: 1.0
Train Avg Loss  277: 0.072516

Train Avg F1  277: 0.8181822076558918

Val Avg Loss  277: 0.064601

Val Avg F1  277:  0.731060606060606

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 278
--------------------------------------------------------------
Epoch:  278        1 Batch loss: 0.077431 Batch F1: 0.6153846153846153
Epoch:  278        2 Batch loss: 0.068910 Batch F1: 0.8
Epoch:  278        3 Batch loss: 0.079418 Batch F1: 0.19999999999999998
Epoch:  278        4 Batch loss: 0.072198 Batch F1: 0.9
Epoch:  278        5 Batch loss: 0.093056 Batch F1: 0.8
Epoch:  278        6 Batch loss: 0.054114 Batch F1: 1.0
Epoch:  278        7 Batch loss: 0.074442 Batch F1: 0.8571428571428571
Epoch:  278        8 Batch loss: 0.060785 Batch F1: 0.7499999999999999
Epoch:  278        9 Batch loss: 0.065871 Batch F1: 0.5454545454545454
Epoch:  278       10 Batch loss: 0.061005 Batch F1: 0.5
Epoch:  278       11 Batch loss: 0.075905 Batch F1: 0.33333333333333337
Epoch:  278       12 Batch loss: 0.059123 Batch F1: 0.7142857142857143
Train Avg Loss  278: 0.070188

Train Avg F1  278: 0.6679667554667553

Val Avg Loss  278: 0.063092

Val Avg F1  278:  0.9198778195488723

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 279
--------------------------------------------------------------
Epoch:  279        1 Batch loss: 0.086353 Batch F1: 0.9
Epoch:  279        2 Batch loss: 0.078732 Batch F1: 0.9523809523809523
Epoch:  279        3 Batch loss: 0.069195 Batch F1: 0.888888888888889
Epoch:  279        4 Batch loss: 0.091893 Batch F1: 0.896551724137931
Epoch:  279        5 Batch loss: 0.061834 Batch F1: 1.0
Epoch:  279        6 Batch loss: 0.068184 Batch F1: 1.0
Epoch:  279        7 Batch loss: 0.066613 Batch F1: 1.0
Epoch:  279        8 Batch loss: 0.067809 Batch F1: 0.8
Epoch:  279        9 Batch loss: 0.057054 Batch F1: 0.8571428571428571
Epoch:  279       10 Batch loss: 0.062397 Batch F1: 0.5454545454545454
Epoch:  279       11 Batch loss: 0.077320 Batch F1: 0.5333333333333333
Epoch:  279       12 Batch loss: 0.042068 Batch F1: 1.0
Train Avg Loss  279: 0.069121

Train Avg F1  279: 0.8644793584448757

Val Avg Loss  279: 0.062531

Val Avg F1  279:  0.7387820512820512

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 280
--------------------------------------------------------------
Epoch:  280        1 Batch loss: 0.036495 Batch F1: 0.6666666666666666
Epoch:  280        2 Batch loss: 0.066991 Batch F1: 0.4
Epoch:  280        3 Batch loss: 0.059640 Batch F1: 0.2857142857142857
Epoch:  280        4 Batch loss: 0.074042 Batch F1: 0.5
Epoch:  280        5 Batch loss: 0.066346 Batch F1: 0.5714285714285715
Epoch:  280        6 Batch loss: 0.057094 Batch F1: 0.6666666666666666
Epoch:  280        7 Batch loss: 0.045543 Batch F1: 0.6666666666666666
Epoch:  280        8 Batch loss: 0.085090 Batch F1: 0.5714285714285715
Epoch:  280        9 Batch loss: 0.084380 Batch F1: 0.42857142857142855
Epoch:  280       10 Batch loss: 0.087495 Batch F1: 0.88
Epoch:  280       11 Batch loss: 0.064513 Batch F1: 0.7692307692307693
Epoch:  280       12 Batch loss: 0.093866 Batch F1: 0.9166666666666666
Train Avg Loss  280: 0.068458

Train Avg F1  280: 0.6102533577533578

Val Avg Loss  280: 0.067100

Val Avg F1  280:  0.9158496732026143

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 281
--------------------------------------------------------------
Epoch:  281        1 Batch loss: 0.080261 Batch F1: 0.9473684210526316
Epoch:  281        2 Batch loss: 0.064791 Batch F1: 1.0
Epoch:  281        3 Batch loss: 0.072786 Batch F1: 1.0
Epoch:  281        4 Batch loss: 0.080233 Batch F1: 0.8421052631578948
Epoch:  281        5 Batch loss: 0.068581 Batch F1: 0.9473684210526316
Epoch:  281        6 Batch loss: 0.067401 Batch F1: 0.888888888888889
Epoch:  281        7 Batch loss: 0.065525 Batch F1: 0.888888888888889
Epoch:  281        8 Batch loss: 0.080492 Batch F1: 0.9523809523809523
Epoch:  281        9 Batch loss: 0.044860 Batch F1: 1.0
Epoch:  281       10 Batch loss: 0.054639 Batch F1: 0.9090909090909091
Epoch:  281       11 Batch loss: 0.081661 Batch F1: 0.42857142857142855
Epoch:  281       12 Batch loss: 0.072614 Batch F1: 0.5
Train Avg Loss  281: 0.069487

Train Avg F1  281: 0.8587219310903521

Val Avg Loss  281: 0.064774

Val Avg F1  281:  0.5823565323565324

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 282
--------------------------------------------------------------
Epoch:  282        1 Batch loss: 0.055637 Batch F1: 0.5714285714285715
Epoch:  282        2 Batch loss: 0.072990 Batch F1: 0.3636363636363636
Epoch:  282        3 Batch loss: 0.079640 Batch F1: 0.6666666666666666
Epoch:  282        4 Batch loss: 0.077222 Batch F1: 0.4615384615384615
Epoch:  282        5 Batch loss: 0.060632 Batch F1: 0.4444444444444445
Epoch:  282        6 Batch loss: 0.047848 Batch F1: 1.0
Epoch:  282        7 Batch loss: 0.076709 Batch F1: 1.0
Epoch:  282        8 Batch loss: 0.073075 Batch F1: 0.8421052631578948
Epoch:  282        9 Batch loss: 0.061952 Batch F1: 0.9333333333333333
Epoch:  282       10 Batch loss: 0.079417 Batch F1: 0.7272727272727273
Epoch:  282       11 Batch loss: 0.071250 Batch F1: 1.0
Epoch:  282       12 Batch loss: 0.073857 Batch F1: 0.888888888888889
Train Avg Loss  282: 0.069186

Train Avg F1  282: 0.7416095600306128

Val Avg Loss  282: 0.062638

Val Avg F1  282:  0.9290441176470589

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 283
--------------------------------------------------------------
Epoch:  283        1 Batch loss: 0.073547 Batch F1: 0.9090909090909091
Epoch:  283        2 Batch loss: 0.059290 Batch F1: 0.9090909090909091
Epoch:  283        3 Batch loss: 0.085183 Batch F1: 0.9
Epoch:  283        4 Batch loss: 0.078370 Batch F1: 0.9090909090909091
Epoch:  283        5 Batch loss: 0.064789 Batch F1: 0.923076923076923
Epoch:  283        6 Batch loss: 0.059419 Batch F1: 0.9090909090909091
Epoch:  283        7 Batch loss: 0.077985 Batch F1: 0.888888888888889
Epoch:  283        8 Batch loss: 0.070075 Batch F1: 0.5
Epoch:  283        9 Batch loss: 0.063449 Batch F1: 0.9333333333333333
Epoch:  283       10 Batch loss: 0.051360 Batch F1: 1.0
Epoch:  283       11 Batch loss: 0.068533 Batch F1: 0.8571428571428571
Epoch:  283       12 Batch loss: 0.064490 Batch F1: 0.7692307692307693
Train Avg Loss  283: 0.068041

Train Avg F1  283: 0.8673363673363674

Val Avg Loss  283: 0.061810

Val Avg F1  283:  0.9151785714285714

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 284
--------------------------------------------------------------
Epoch:  284        1 Batch loss: 0.067725 Batch F1: 0.8571428571428571
Epoch:  284        2 Batch loss: 0.078459 Batch F1: 0.7368421052631579
Epoch:  284        3 Batch loss: 0.045195 Batch F1: 0.9090909090909091
Epoch:  284        4 Batch loss: 0.063302 Batch F1: 1.0
Epoch:  284        5 Batch loss: 0.038399 Batch F1: 1.0
Epoch:  284        6 Batch loss: 0.073656 Batch F1: 0.6153846153846153
Epoch:  284        7 Batch loss: 0.085824 Batch F1: 0.375
Epoch:  284        8 Batch loss: 0.066110 Batch F1: 0.25
Epoch:  284        9 Batch loss: 0.076288 Batch F1: 0.42857142857142855
Epoch:  284       10 Batch loss: 0.074080 Batch F1: 0.7000000000000001
Epoch:  284       11 Batch loss: 0.084106 Batch F1: 0.5555555555555556
Epoch:  284       12 Batch loss: 0.066201 Batch F1: 0.9090909090909091
Train Avg Loss  284: 0.068279

Train Avg F1  284: 0.6947231983416193

Val Avg Loss  284: 0.061624

Val Avg F1  284:  0.9079949036470775

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 285
--------------------------------------------------------------
Epoch:  285        1 Batch loss: 0.065218 Batch F1: 0.9333333333333333
Epoch:  285        2 Batch loss: 0.064836 Batch F1: 0.9333333333333333
Epoch:  285        3 Batch loss: 0.053608 Batch F1: 1.0
Epoch:  285        4 Batch loss: 0.067276 Batch F1: 0.8750000000000001
Epoch:  285        5 Batch loss: 0.045340 Batch F1: 0.888888888888889
Epoch:  285        6 Batch loss: 0.058110 Batch F1: 0.923076923076923
Epoch:  285        7 Batch loss: 0.076498 Batch F1: 0.33333333333333337
Epoch:  285        8 Batch loss: 0.091456 Batch F1: 0.5263157894736842
Epoch:  285        9 Batch loss: 0.078709 Batch F1: 0.888888888888889
Epoch:  285       10 Batch loss: 0.083442 Batch F1: 1.0
Epoch:  285       11 Batch loss: 0.065952 Batch F1: 0.9333333333333333
Epoch:  285       12 Batch loss: 0.075192 Batch F1: 0.8
Train Avg Loss  285: 0.068803

Train Avg F1  285: 0.8362919853051434

Val Avg Loss  285: 0.062136

Val Avg F1  285:  0.9006060606060606

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 286
--------------------------------------------------------------
Epoch:  286        1 Batch loss: 0.070858 Batch F1: 0.923076923076923
Epoch:  286        2 Batch loss: 0.081194 Batch F1: 0.962962962962963
Epoch:  286        3 Batch loss: 0.075041 Batch F1: 0.888888888888889
Epoch:  286        4 Batch loss: 0.049323 Batch F1: 1.0
Epoch:  286        5 Batch loss: 0.069117 Batch F1: 1.0
Epoch:  286        6 Batch loss: 0.069928 Batch F1: 0.7272727272727273
Epoch:  286        7 Batch loss: 0.074536 Batch F1: 0.33333333333333337
Epoch:  286        8 Batch loss: 0.057728 Batch F1: 0.7499999999999999
Epoch:  286        9 Batch loss: 0.059754 Batch F1: 0.6
Epoch:  286       10 Batch loss: 0.066758 Batch F1: 0.5714285714285715
Epoch:  286       11 Batch loss: 0.072094 Batch F1: 0.4615384615384615
Epoch:  286       12 Batch loss: 0.074284 Batch F1: 0.5
Train Avg Loss  286: 0.068385

Train Avg F1  286: 0.7265418223751556

Val Avg Loss  286: 0.061512

Val Avg F1  286:  0.9261278195488722

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 287
--------------------------------------------------------------
Epoch:  287        1 Batch loss: 0.064693 Batch F1: 0.9411764705882353
Epoch:  287        2 Batch loss: 0.074468 Batch F1: 0.9523809523809523
Epoch:  287        3 Batch loss: 0.100319 Batch F1: 0.896551724137931
Epoch:  287        4 Batch loss: 0.067690 Batch F1: 0.9565217391304348
Epoch:  287        5 Batch loss: 0.068089 Batch F1: 0.9411764705882353
Epoch:  287        6 Batch loss: 0.065935 Batch F1: 0.9600000000000001
Epoch:  287        7 Batch loss: 0.066777 Batch F1: 0.888888888888889
Epoch:  287        8 Batch loss: 0.057410 Batch F1: 0.888888888888889
Epoch:  287        9 Batch loss: 0.069854 Batch F1: 0.7692307692307693
Epoch:  287       10 Batch loss: 0.062077 Batch F1: 0.5
Epoch:  287       11 Batch loss: 0.056631 Batch F1: 0.4
Epoch:  287       12 Batch loss: 0.066442 Batch F1: 0.2857142857142857
Train Avg Loss  287: 0.068366

Train Avg F1  287: 0.781710849129052

Val Avg Loss  287: 0.064890

Val Avg F1  287:  0.4633699633699634

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 288
--------------------------------------------------------------
Epoch:  288        1 Batch loss: 0.058484 Batch F1: 0.6
Epoch:  288        2 Batch loss: 0.078369 Batch F1: 0.4615384615384615
Epoch:  288        3 Batch loss: 0.054393 Batch F1: 0.5
Epoch:  288        4 Batch loss: 0.082110 Batch F1: 0.3636363636363636
Epoch:  288        5 Batch loss: 0.050781 Batch F1: 0.7272727272727273
Epoch:  288        6 Batch loss: 0.055702 Batch F1: 0.2857142857142857
Epoch:  288        7 Batch loss: 0.088905 Batch F1: 0.2857142857142857
Epoch:  288        8 Batch loss: 0.059201 Batch F1: 0.8
Epoch:  288        9 Batch loss: 0.068676 Batch F1: 1.0
Epoch:  288       10 Batch loss: 0.067072 Batch F1: 1.0
Epoch:  288       11 Batch loss: 0.074151 Batch F1: 0.9600000000000001
Epoch:  288       12 Batch loss: 0.087987 Batch F1: 0.9
Train Avg Loss  288: 0.068819

Train Avg F1  288: 0.6569896769896769

Val Avg Loss  288: 0.062241

Val Avg F1  288:  0.9232954545454546

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 289
--------------------------------------------------------------
Epoch:  289        1 Batch loss: 0.071161 Batch F1: 0.8
Epoch:  289        2 Batch loss: 0.087590 Batch F1: 0.5263157894736842
Epoch:  289        3 Batch loss: 0.067749 Batch F1: 0.7142857142857143
Epoch:  289        4 Batch loss: 0.079312 Batch F1: 0.4615384615384615
Epoch:  289        5 Batch loss: 0.079001 Batch F1: 0.8571428571428571
Epoch:  289        6 Batch loss: 0.059615 Batch F1: 1.0
Epoch:  289        7 Batch loss: 0.056795 Batch F1: 0.923076923076923
Epoch:  289        8 Batch loss: 0.072495 Batch F1: 0.9523809523809523
Epoch:  289        9 Batch loss: 0.073224 Batch F1: 0.7499999999999999
Epoch:  289       10 Batch loss: 0.066194 Batch F1: 0.3636363636363636
Epoch:  289       11 Batch loss: 0.056056 Batch F1: 1.0
Epoch:  289       12 Batch loss: 0.065296 Batch F1: 0.7272727272727273
Train Avg Loss  289: 0.069540

Train Avg F1  289: 0.756304149067307

Val Avg Loss  289: 0.062582

Val Avg F1  289:  0.6724025974025973

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 290
--------------------------------------------------------------
Epoch:  290        1 Batch loss: 0.067371 Batch F1: 0.5454545454545454
Epoch:  290        2 Batch loss: 0.061436 Batch F1: 0.2857142857142857
Epoch:  290        3 Batch loss: 0.074174 Batch F1: 0.3636363636363636
Epoch:  290        4 Batch loss: 0.060152 Batch F1: 0.6153846153846153
Epoch:  290        5 Batch loss: 0.059043 Batch F1: 0.6666666666666666
Epoch:  290        6 Batch loss: 0.102496 Batch F1: 0.5263157894736842
Epoch:  290        7 Batch loss: 0.069570 Batch F1: 0.5333333333333333
Epoch:  290        8 Batch loss: 0.054511 Batch F1: 0.9090909090909091
Epoch:  290        9 Batch loss: 0.084834 Batch F1: 0.8571428571428571
Epoch:  290       10 Batch loss: 0.069067 Batch F1: 0.923076923076923
Epoch:  290       11 Batch loss: 0.068070 Batch F1: 0.9523809523809523
Epoch:  290       12 Batch loss: 0.054813 Batch F1: 1.0
Train Avg Loss  290: 0.068795

Train Avg F1  290: 0.6815164367795946

Val Avg Loss  290: 0.063028

Val Avg F1  290:  0.9182449494949495

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 291
--------------------------------------------------------------
Epoch:  291        1 Batch loss: 0.076070 Batch F1: 0.8421052631578948
Epoch:  291        2 Batch loss: 0.072856 Batch F1: 0.8750000000000001
Epoch:  291        3 Batch loss: 0.066855 Batch F1: 0.888888888888889
Epoch:  291        4 Batch loss: 0.069352 Batch F1: 0.6666666666666666
Epoch:  291        5 Batch loss: 0.053814 Batch F1: 1.0
Epoch:  291        6 Batch loss: 0.066878 Batch F1: 1.0
Epoch:  291        7 Batch loss: 0.076446 Batch F1: 0.4615384615384615
Epoch:  291        8 Batch loss: 0.058954 Batch F1: 0.6153846153846153
Epoch:  291        9 Batch loss: 0.054831 Batch F1: 0.4
Epoch:  291       10 Batch loss: 0.071724 Batch F1: 0.5
Epoch:  291       11 Batch loss: 0.078809 Batch F1: 0.3636363636363636
Epoch:  291       12 Batch loss: 0.073800 Batch F1: 0.4615384615384615
Train Avg Loss  291: 0.068366

Train Avg F1  291: 0.6728965600676128

Val Avg Loss  291: 0.061962

Val Avg F1  291:  0.9175309816042082

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 292
--------------------------------------------------------------
Epoch:  292        1 Batch loss: 0.047103 Batch F1: 1.0
Epoch:  292        2 Batch loss: 0.074008 Batch F1: 0.47058823529411764
Epoch:  292        3 Batch loss: 0.089333 Batch F1: 0.88
Epoch:  292        4 Batch loss: 0.063800 Batch F1: 0.9411764705882353
Epoch:  292        5 Batch loss: 0.067858 Batch F1: 0.923076923076923
Epoch:  292        6 Batch loss: 0.073333 Batch F1: 0.8235294117647058
Epoch:  292        7 Batch loss: 0.073090 Batch F1: 0.9333333333333333
Epoch:  292        8 Batch loss: 0.050839 Batch F1: 0.923076923076923
Epoch:  292        9 Batch loss: 0.058949 Batch F1: 1.0
Epoch:  292       10 Batch loss: 0.086066 Batch F1: 0.33333333333333337
Epoch:  292       11 Batch loss: 0.062398 Batch F1: 0.9411764705882353
Epoch:  292       12 Batch loss: 0.087728 Batch F1: 0.9
Train Avg Loss  292: 0.069542

Train Avg F1  292: 0.8391075917546508

Val Avg Loss  292: 0.063595

Val Avg F1  292:  0.9095238095238096

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 293
--------------------------------------------------------------
Epoch:  293        1 Batch loss: 0.047308 Batch F1: 0.8
Epoch:  293        2 Batch loss: 0.082197 Batch F1: 0.888888888888889
Epoch:  293        3 Batch loss: 0.066823 Batch F1: 0.8235294117647058
Epoch:  293        4 Batch loss: 0.070340 Batch F1: 0.9473684210526316
Epoch:  293        5 Batch loss: 0.093989 Batch F1: 0.8571428571428571
Epoch:  293        6 Batch loss: 0.078631 Batch F1: 0.8
Epoch:  293        7 Batch loss: 0.079495 Batch F1: 0.9600000000000001
Epoch:  293        8 Batch loss: 0.063167 Batch F1: 1.0
Epoch:  293        9 Batch loss: 0.053566 Batch F1: 1.0
Epoch:  293       10 Batch loss: 0.041330 Batch F1: 1.0
Epoch:  293       11 Batch loss: 0.082981 Batch F1: 0.4615384615384615
Epoch:  293       12 Batch loss: 0.079968 Batch F1: 0.625
Train Avg Loss  293: 0.069983

Train Avg F1  293: 0.8469556700322953

Val Avg Loss  293: 0.062106

Val Avg F1  293:  0.5705128205128205

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 294
--------------------------------------------------------------
Epoch:  294        1 Batch loss: 0.055514 Batch F1: 0.0
Epoch:  294        2 Batch loss: 0.055454 Batch F1: 0.6
Epoch:  294        3 Batch loss: 0.078510 Batch F1: 0.6666666666666666
Epoch:  294        4 Batch loss: 0.072481 Batch F1: 0.5714285714285715
Epoch:  294        5 Batch loss: 0.073229 Batch F1: 0.6153846153846153
Epoch:  294        6 Batch loss: 0.074968 Batch F1: 0.9411764705882353
Epoch:  294        7 Batch loss: 0.063997 Batch F1: 0.5454545454545454
Epoch:  294        8 Batch loss: 0.104860 Batch F1: 0.4444444444444445
Epoch:  294        9 Batch loss: 0.079988 Batch F1: 0.9166666666666666
Epoch:  294       10 Batch loss: 0.076149 Batch F1: 0.9333333333333333
Epoch:  294       11 Batch loss: 0.078662 Batch F1: 0.9411764705882353
Epoch:  294       12 Batch loss: 0.072116 Batch F1: 0.0
Train Avg Loss  294: 0.073827

Train Avg F1  294: 0.5979776487129429

Val Avg Loss  294: 0.069117

Val Avg F1  294:  0.5743589743589743

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 295
--------------------------------------------------------------
Epoch:  295        1 Batch loss: 0.055655 Batch F1: 0.5
Epoch:  295        2 Batch loss: 0.075966 Batch F1: 0.5714285714285715
Epoch:  295        3 Batch loss: 0.081941 Batch F1: 0.5
Epoch:  295        4 Batch loss: 0.071499 Batch F1: 0.888888888888889
Epoch:  295        5 Batch loss: 0.060376 Batch F1: 0.9090909090909091
Epoch:  295        6 Batch loss: 0.076019 Batch F1: 0.6666666666666666
Epoch:  295        7 Batch loss: 0.061263 Batch F1: 0.4444444444444445
Epoch:  295        8 Batch loss: 0.064027 Batch F1: 0.4
Epoch:  295        9 Batch loss: 0.100923 Batch F1: 0.4210526315789474
Epoch:  295       10 Batch loss: 0.061321 Batch F1: 0.9411764705882353
Epoch:  295       11 Batch loss: 0.076415 Batch F1: 0.9
Epoch:  295       12 Batch loss: 0.065031 Batch F1: 1.0
Train Avg Loss  295: 0.070870

Train Avg F1  295: 0.6785623818905554

Val Avg Loss  295: 0.064635

Val Avg F1  295:  0.9219587176108917

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 296
--------------------------------------------------------------
Epoch:  296        1 Batch loss: 0.062912 Batch F1: 0.8333333333333333
Epoch:  296        2 Batch loss: 0.055727 Batch F1: 1.0
Epoch:  296        3 Batch loss: 0.107756 Batch F1: 0.782608695652174
Epoch:  296        4 Batch loss: 0.072062 Batch F1: 0.8750000000000001
Epoch:  296        5 Batch loss: 0.074027 Batch F1: 0.9090909090909091
Epoch:  296        6 Batch loss: 0.071274 Batch F1: 1.0
Epoch:  296        7 Batch loss: 0.075968 Batch F1: 0.8235294117647058
Epoch:  296        8 Batch loss: 0.105236 Batch F1: 0.23529411764705882
Epoch:  296        9 Batch loss: 0.044971 Batch F1: 0.888888888888889
Epoch:  296       10 Batch loss: 0.065082 Batch F1: 0.5454545454545454
Epoch:  296       11 Batch loss: 0.057456 Batch F1: 0.6
Epoch:  296       12 Batch loss: 0.074619 Batch F1: 0.6153846153846153
Train Avg Loss  296: 0.072257

Train Avg F1  296: 0.7590487097680191

Val Avg Loss  296: 0.063479

Val Avg F1  296:  0.9216311724051661

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 297
--------------------------------------------------------------
Epoch:  297        1 Batch loss: 0.098062 Batch F1: 0.9090909090909091
Epoch:  297        2 Batch loss: 0.051570 Batch F1: 0.888888888888889
Epoch:  297        3 Batch loss: 0.070561 Batch F1: 0.6666666666666666
Epoch:  297        4 Batch loss: 0.059648 Batch F1: 0.4
Epoch:  297        5 Batch loss: 0.060407 Batch F1: 0.2222222222222222
Epoch:  297        6 Batch loss: 0.076316 Batch F1: 0.6666666666666666
Epoch:  297        7 Batch loss: 0.072007 Batch F1: 0.8333333333333333
Epoch:  297        8 Batch loss: 0.057277 Batch F1: 0.8571428571428571
Epoch:  297        9 Batch loss: 0.071609 Batch F1: 1.0
Epoch:  297       10 Batch loss: 0.062440 Batch F1: 0.9473684210526316
Epoch:  297       11 Batch loss: 0.057726 Batch F1: 0.7499999999999999
Epoch:  297       12 Batch loss: 0.084633 Batch F1: 0.9
Train Avg Loss  297: 0.068521

Train Avg F1  297: 0.7534483304220146

Val Avg Loss  297: 0.061934

Val Avg F1  297:  0.9284161490683229

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 298
--------------------------------------------------------------
Epoch:  298        1 Batch loss: 0.072063 Batch F1: 0.8750000000000001
Epoch:  298        2 Batch loss: 0.090441 Batch F1: 0.88
Epoch:  298        3 Batch loss: 0.041394 Batch F1: 0.8
Epoch:  298        4 Batch loss: 0.063248 Batch F1: 1.0
Epoch:  298        5 Batch loss: 0.063604 Batch F1: 1.0
Epoch:  298        6 Batch loss: 0.068401 Batch F1: 0.9473684210526316
Epoch:  298        7 Batch loss: 0.083914 Batch F1: 0.9090909090909091
Epoch:  298        8 Batch loss: 0.062756 Batch F1: 0.8
Epoch:  298        9 Batch loss: 0.082955 Batch F1: 0.9600000000000001
Epoch:  298       10 Batch loss: 0.074728 Batch F1: 0.8421052631578948
Epoch:  298       11 Batch loss: 0.060776 Batch F1: 0.9411764705882353
Epoch:  298       12 Batch loss: 0.050021 Batch F1: 1.0
Train Avg Loss  298: 0.067859

Train Avg F1  298: 0.9128950886574727

Val Avg Loss  298: 0.061640

Val Avg F1  298:  0.9142857142857144

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 299
--------------------------------------------------------------
Epoch:  299        1 Batch loss: 0.060176 Batch F1: 0.9333333333333333
Epoch:  299        2 Batch loss: 0.064972 Batch F1: 1.0
Epoch:  299        3 Batch loss: 0.083153 Batch F1: 0.5
Epoch:  299        4 Batch loss: 0.059880 Batch F1: 0.5714285714285715
Epoch:  299        5 Batch loss: 0.077989 Batch F1: 0.8235294117647058
Epoch:  299        6 Batch loss: 0.071460 Batch F1: 0.8750000000000001
Epoch:  299        7 Batch loss: 0.053646 Batch F1: 0.923076923076923
Epoch:  299        8 Batch loss: 0.056467 Batch F1: 0.923076923076923
Epoch:  299        9 Batch loss: 0.071213 Batch F1: 0.8
Epoch:  299       10 Batch loss: 0.078409 Batch F1: 0.9090909090909091
Epoch:  299       11 Batch loss: 0.075955 Batch F1: 0.9473684210526316
Epoch:  299       12 Batch loss: 0.059856 Batch F1: 1.0
Train Avg Loss  299: 0.067765

Train Avg F1  299: 0.8504920410686666

Val Avg Loss  299: 0.061568

Val Avg F1  299:  0.9396135265700484

Optimal Val loss (Epoch 265): 0.061114504002034664

Epoch 300
--------------------------------------------------------------
Epoch:  300        1 Batch loss: 0.069261 Batch F1: 0.9
Epoch:  300        2 Batch loss: 0.066299 Batch F1: 1.0
Epoch:  300        3 Batch loss: 0.088954 Batch F1: 0.8695652173913044
Epoch:  300        4 Batch loss: 0.063462 Batch F1: 0.8571428571428571
Epoch:  300        5 Batch loss: 0.049860 Batch F1: 0.9090909090909091
Epoch:  300        6 Batch loss: 0.057804 Batch F1: 0.9333333333333333
Epoch:  300        7 Batch loss: 0.058043 Batch F1: 0.923076923076923
Epoch:  300        8 Batch loss: 0.073927 Batch F1: 0.33333333333333337
Epoch:  300        9 Batch loss: 0.067761 Batch F1: 0.5
Epoch:  300       10 Batch loss: 0.072998 Batch F1: 0.42857142857142855
Epoch:  300       11 Batch loss: 0.076309 Batch F1: 0.42857142857142855
Epoch:  300       12 Batch loss: 0.061052 Batch F1: 0.8571428571428571
Train Avg Loss  300: 0.067144

Train Avg F1  300: 0.7449856906378646

Val Avg Loss  300: 0.061043

Val Avg F1  300:  0.936421937195931

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 301
--------------------------------------------------------------
Epoch:  301        1 Batch loss: 0.049142 Batch F1: 1.0
Epoch:  301        2 Batch loss: 0.090096 Batch F1: 0.5555555555555556
Epoch:  301        3 Batch loss: 0.062928 Batch F1: 0.4
Epoch:  301        4 Batch loss: 0.064238 Batch F1: 0.25
Epoch:  301        5 Batch loss: 0.057191 Batch F1: 0.5454545454545454
Epoch:  301        6 Batch loss: 0.076732 Batch F1: 0.18181818181818182
Epoch:  301        7 Batch loss: 0.057216 Batch F1: 0.6
Epoch:  301        8 Batch loss: 0.062069 Batch F1: 0.9523809523809523
Epoch:  301        9 Batch loss: 0.083772 Batch F1: 0.9
Epoch:  301       10 Batch loss: 0.069615 Batch F1: 0.8421052631578948
Epoch:  301       11 Batch loss: 0.073104 Batch F1: 0.8750000000000001
Epoch:  301       12 Batch loss: 0.058267 Batch F1: 1.0
Train Avg Loss  301: 0.067031

Train Avg F1  301: 0.6751928748639275

Val Avg Loss  301: 0.062586

Val Avg F1  301:  0.8948412698412698

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 302
--------------------------------------------------------------
Epoch:  302        1 Batch loss: 0.071565 Batch F1: 0.923076923076923
Epoch:  302        2 Batch loss: 0.085060 Batch F1: 0.8
Epoch:  302        3 Batch loss: 0.051545 Batch F1: 0.9333333333333333
Epoch:  302        4 Batch loss: 0.053961 Batch F1: 1.0
Epoch:  302        5 Batch loss: 0.077447 Batch F1: 0.9565217391304348
Epoch:  302        6 Batch loss: 0.068725 Batch F1: 0.9333333333333333
Epoch:  302        7 Batch loss: 0.044340 Batch F1: 1.0
Epoch:  302        8 Batch loss: 0.080904 Batch F1: 0.3076923076923077
Epoch:  302        9 Batch loss: 0.072472 Batch F1: 0.6666666666666666
Epoch:  302       10 Batch loss: 0.074228 Batch F1: 0.8333333333333333
Epoch:  302       11 Batch loss: 0.067681 Batch F1: 0.9565217391304348
Epoch:  302       12 Batch loss: 0.065763 Batch F1: 0.8
Train Avg Loss  302: 0.067808

Train Avg F1  302: 0.8425399479747308

Val Avg Loss  302: 0.061360

Val Avg F1  302:  0.9246411483253589

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 303
--------------------------------------------------------------
Epoch:  303        1 Batch loss: 0.079328 Batch F1: 0.8750000000000001
Epoch:  303        2 Batch loss: 0.067794 Batch F1: 0.9090909090909091
Epoch:  303        3 Batch loss: 0.065232 Batch F1: 1.0
Epoch:  303        4 Batch loss: 0.071529 Batch F1: 0.8
Epoch:  303        5 Batch loss: 0.065234 Batch F1: 0.9090909090909091
Epoch:  303        6 Batch loss: 0.069649 Batch F1: 1.0
Epoch:  303        7 Batch loss: 0.078862 Batch F1: 0.962962962962963
Epoch:  303        8 Batch loss: 0.076200 Batch F1: 0.7142857142857143
Epoch:  303        9 Batch loss: 0.054046 Batch F1: 0.888888888888889
Epoch:  303       10 Batch loss: 0.055022 Batch F1: 0.923076923076923
Epoch:  303       11 Batch loss: 0.062412 Batch F1: 0.9411764705882353
Epoch:  303       12 Batch loss: 0.056383 Batch F1: 1.0
Train Avg Loss  303: 0.066808

Train Avg F1  303: 0.9102977314987118

Val Avg Loss  303: 0.061569

Val Avg F1  303:  0.6023310023310023

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 304
--------------------------------------------------------------
Epoch:  304        1 Batch loss: 0.056459 Batch F1: 0.6
Epoch:  304        2 Batch loss: 0.085459 Batch F1: 0.33333333333333337
Epoch:  304        3 Batch loss: 0.060378 Batch F1: 0.5
Epoch:  304        4 Batch loss: 0.069052 Batch F1: 0.6153846153846153
Epoch:  304        5 Batch loss: 0.058352 Batch F1: 0.4444444444444445
Epoch:  304        6 Batch loss: 0.088521 Batch F1: 0.16666666666666669
Epoch:  304        7 Batch loss: 0.076691 Batch F1: 0.6
Epoch:  304        8 Batch loss: 0.050399 Batch F1: 0.888888888888889
Epoch:  304        9 Batch loss: 0.077897 Batch F1: 0.8235294117647058
Epoch:  304       10 Batch loss: 0.067270 Batch F1: 1.0
Epoch:  304       11 Batch loss: 0.058833 Batch F1: 0.9565217391304348
Epoch:  304       12 Batch loss: 0.056497 Batch F1: 0.7499999999999999
Train Avg Loss  304: 0.067151

Train Avg F1  304: 0.6398974249677575

Val Avg Loss  304: 0.062090

Val Avg F1  304:  0.9166666666666666

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 305
--------------------------------------------------------------
Epoch:  305        1 Batch loss: 0.079016 Batch F1: 0.8235294117647058
Epoch:  305        2 Batch loss: 0.078116 Batch F1: 0.923076923076923
Epoch:  305        3 Batch loss: 0.065086 Batch F1: 0.8750000000000001
Epoch:  305        4 Batch loss: 0.072118 Batch F1: 0.9090909090909091
Epoch:  305        5 Batch loss: 0.067626 Batch F1: 1.0
Epoch:  305        6 Batch loss: 0.059751 Batch F1: 1.0
Epoch:  305        7 Batch loss: 0.064483 Batch F1: 0.2222222222222222
Epoch:  305        8 Batch loss: 0.057068 Batch F1: 0.5454545454545454
Epoch:  305        9 Batch loss: 0.080030 Batch F1: 0.33333333333333337
Epoch:  305       10 Batch loss: 0.051612 Batch F1: 0.6
Epoch:  305       11 Batch loss: 0.062045 Batch F1: 0.9411764705882353
Epoch:  305       12 Batch loss: 0.075146 Batch F1: 0.8571428571428571
Train Avg Loss  305: 0.067675

Train Avg F1  305: 0.752502222722811

Val Avg Loss  305: 0.061067

Val Avg F1  305:  0.9212503183091418

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 306
--------------------------------------------------------------
Epoch:  306        1 Batch loss: 0.072270 Batch F1: 0.9523809523809523
Epoch:  306        2 Batch loss: 0.061279 Batch F1: 0.923076923076923
Epoch:  306        3 Batch loss: 0.071756 Batch F1: 0.9565217391304348
Epoch:  306        4 Batch loss: 0.061571 Batch F1: 0.8571428571428571
Epoch:  306        5 Batch loss: 0.064310 Batch F1: 1.0
Epoch:  306        6 Batch loss: 0.057608 Batch F1: 0.8333333333333333
Epoch:  306        7 Batch loss: 0.073169 Batch F1: 0.6666666666666666
Epoch:  306        8 Batch loss: 0.074951 Batch F1: 0.4615384615384615
Epoch:  306        9 Batch loss: 0.069925 Batch F1: 0.7368421052631579
Epoch:  306       10 Batch loss: 0.077825 Batch F1: 0.9523809523809523
Epoch:  306       11 Batch loss: 0.062494 Batch F1: 0.8
Epoch:  306       12 Batch loss: 0.079556 Batch F1: 0.7272727272727273
Train Avg Loss  306: 0.068893

Train Avg F1  306: 0.8222630598488722

Val Avg Loss  306: 0.062663

Val Avg F1  306:  0.9268525592055004

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 307
--------------------------------------------------------------
Epoch:  307        1 Batch loss: 0.058760 Batch F1: 0.888888888888889
Epoch:  307        2 Batch loss: 0.049839 Batch F1: 1.0
Epoch:  307        3 Batch loss: 0.054190 Batch F1: 0.6
Epoch:  307        4 Batch loss: 0.096334 Batch F1: 0.5555555555555556
Epoch:  307        5 Batch loss: 0.050727 Batch F1: 0.6
Epoch:  307        6 Batch loss: 0.061768 Batch F1: 0.8235294117647058
Epoch:  307        7 Batch loss: 0.049449 Batch F1: 0.8571428571428571
Epoch:  307        8 Batch loss: 0.058924 Batch F1: 0.6666666666666666
Epoch:  307        9 Batch loss: 0.098153 Batch F1: 0.2857142857142857
Epoch:  307       10 Batch loss: 0.112550 Batch F1: 0.14285714285714288
Epoch:  307       11 Batch loss: 0.078528 Batch F1: 0.888888888888889
Epoch:  307       12 Batch loss: 0.088613 Batch F1: 0.8235294117647058
Train Avg Loss  307: 0.071486

Train Avg F1  307: 0.6777310924369749

Val Avg Loss  307: 0.072429

Val Avg F1  307:  0.9028282828282828

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 308
--------------------------------------------------------------
Epoch:  308        1 Batch loss: 0.088091 Batch F1: 0.8333333333333333
Epoch:  308        2 Batch loss: 0.070948 Batch F1: 0.9333333333333333
Epoch:  308        3 Batch loss: 0.037566 Batch F1: 1.0
Epoch:  308        4 Batch loss: 0.062684 Batch F1: 0.0
Epoch:  308        5 Batch loss: 0.079485 Batch F1: 0.0
Epoch:  308        6 Batch loss: 0.053534 Batch F1: 0.2857142857142857
Epoch:  308        7 Batch loss: 0.083898 Batch F1: 0.7499999999999999
Epoch:  308        8 Batch loss: 0.095513 Batch F1: 0.8181818181818182
Epoch:  308        9 Batch loss: 0.092254 Batch F1: 0.9
Epoch:  308       10 Batch loss: 0.083502 Batch F1: 0.7058823529411764
Epoch:  308       11 Batch loss: 0.111879 Batch F1: 0.35294117647058826
Epoch:  308       12 Batch loss: 0.075144 Batch F1: 0.8
Train Avg Loss  308: 0.077875

Train Avg F1  308: 0.6149488583312113

Val Avg Loss  308: 0.069943

Val Avg F1  308:  0.5510683760683761

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 309
--------------------------------------------------------------
Epoch:  309        1 Batch loss: 0.064836 Batch F1: 0.6153846153846153
Epoch:  309        2 Batch loss: 0.049977 Batch F1: 0.4
Epoch:  309        3 Batch loss: 0.078150 Batch F1: 0.5
Epoch:  309        4 Batch loss: 0.077754 Batch F1: 0.4615384615384615
Epoch:  309        5 Batch loss: 0.056756 Batch F1: 0.6666666666666666
Epoch:  309        6 Batch loss: 0.069959 Batch F1: 0.5454545454545454
Epoch:  309        7 Batch loss: 0.096689 Batch F1: 0.0
Epoch:  309        8 Batch loss: 0.077310 Batch F1: 1.0
Epoch:  309        9 Batch loss: 0.069024 Batch F1: 0.9523809523809523
Epoch:  309       10 Batch loss: 0.081748 Batch F1: 0.8235294117647058
Epoch:  309       11 Batch loss: 0.058652 Batch F1: 0.9333333333333333
Epoch:  309       12 Batch loss: 0.081714 Batch F1: 0.9411764705882353
Train Avg Loss  309: 0.071881

Train Avg F1  309: 0.653288704759293

Val Avg Loss  309: 0.065835

Val Avg F1  309:  0.7069444444444444

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 310
--------------------------------------------------------------
Epoch:  310        1 Batch loss: 0.074140 Batch F1: 0.5714285714285715
Epoch:  310        2 Batch loss: 0.074751 Batch F1: 0.8235294117647058
Epoch:  310        3 Batch loss: 0.063356 Batch F1: 0.7499999999999999
Epoch:  310        4 Batch loss: 0.064578 Batch F1: 1.0
Epoch:  310        5 Batch loss: 0.074140 Batch F1: 0.888888888888889
Epoch:  310        6 Batch loss: 0.062742 Batch F1: 1.0
Epoch:  310        7 Batch loss: 0.070689 Batch F1: 0.8750000000000001
Epoch:  310        8 Batch loss: 0.077743 Batch F1: 0.9565217391304348
Epoch:  310        9 Batch loss: 0.065623 Batch F1: 0.8333333333333333
Epoch:  310       10 Batch loss: 0.066662 Batch F1: 0.9333333333333333
Epoch:  310       11 Batch loss: 0.066124 Batch F1: 1.0
Epoch:  310       12 Batch loss: 0.069621 Batch F1: 0.7272727272727273
Train Avg Loss  310: 0.069181

Train Avg F1  310: 0.8632756670959995

Val Avg Loss  310: 0.062615

Val Avg F1  310:  0.9194794974846126

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 311
--------------------------------------------------------------
Epoch:  311        1 Batch loss: 0.067858 Batch F1: 0.8750000000000001
Epoch:  311        2 Batch loss: 0.065691 Batch F1: 0.9411764705882353
Epoch:  311        3 Batch loss: 0.043325 Batch F1: 1.0
Epoch:  311        4 Batch loss: 0.067591 Batch F1: 1.0
Epoch:  311        5 Batch loss: 0.066770 Batch F1: 0.3636363636363636
Epoch:  311        6 Batch loss: 0.086622 Batch F1: 0.5
Epoch:  311        7 Batch loss: 0.067867 Batch F1: 1.0
Epoch:  311        8 Batch loss: 0.086391 Batch F1: 0.7777777777777778
Epoch:  311        9 Batch loss: 0.062754 Batch F1: 1.0
Epoch:  311       10 Batch loss: 0.071126 Batch F1: 0.8571428571428571
Epoch:  311       11 Batch loss: 0.078610 Batch F1: 0.888888888888889
Epoch:  311       12 Batch loss: 0.045628 Batch F1: 1.0
Train Avg Loss  311: 0.067519

Train Avg F1  311: 0.8503018631695102

Val Avg Loss  311: 0.061456

Val Avg F1  311:  0.9151785714285714

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 312
--------------------------------------------------------------
Epoch:  312        1 Batch loss: 0.080325 Batch F1: 0.9090909090909091
Epoch:  312        2 Batch loss: 0.061021 Batch F1: 1.0
Epoch:  312        3 Batch loss: 0.062374 Batch F1: 1.0
Epoch:  312        4 Batch loss: 0.057392 Batch F1: 0.923076923076923
Epoch:  312        5 Batch loss: 0.054895 Batch F1: 0.5
Epoch:  312        6 Batch loss: 0.094667 Batch F1: 0.33333333333333337
Epoch:  312        7 Batch loss: 0.070001 Batch F1: 0.5333333333333333
Epoch:  312        8 Batch loss: 0.060228 Batch F1: 0.7142857142857143
Epoch:  312        9 Batch loss: 0.062427 Batch F1: 0.0
Epoch:  312       10 Batch loss: 0.058426 Batch F1: 0.8571428571428571
Epoch:  312       11 Batch loss: 0.083971 Batch F1: 0.9090909090909091
Epoch:  312       12 Batch loss: 0.070050 Batch F1: 0.9333333333333333
Train Avg Loss  312: 0.067981

Train Avg F1  312: 0.7177239427239427

Val Avg Loss  312: 0.061554

Val Avg F1  312:  0.9388644688644688

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 313
--------------------------------------------------------------
Epoch:  313        1 Batch loss: 0.057685 Batch F1: 0.9090909090909091
Epoch:  313        2 Batch loss: 0.067894 Batch F1: 1.0
Epoch:  313        3 Batch loss: 0.045243 Batch F1: 1.0
Epoch:  313        4 Batch loss: 0.066621 Batch F1: 0.9523809523809523
Epoch:  313        5 Batch loss: 0.093415 Batch F1: 0.9655172413793104
Epoch:  313        6 Batch loss: 0.089299 Batch F1: 0.9090909090909091
Epoch:  313        7 Batch loss: 0.075619 Batch F1: 0.2857142857142857
Epoch:  313        8 Batch loss: 0.081099 Batch F1: 0.8571428571428571
Epoch:  313        9 Batch loss: 0.050288 Batch F1: 1.0
Epoch:  313       10 Batch loss: 0.064294 Batch F1: 0.923076923076923
Epoch:  313       11 Batch loss: 0.059146 Batch F1: 0.8333333333333333
Epoch:  313       12 Batch loss: 0.071234 Batch F1: 1.0
Train Avg Loss  313: 0.068486

Train Avg F1  313: 0.8862789509341233

Val Avg Loss  313: 0.061252

Val Avg F1  313:  0.9281376518218624

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 314
--------------------------------------------------------------
Epoch:  314        1 Batch loss: 0.075185 Batch F1: 0.9565217391304348
Epoch:  314        2 Batch loss: 0.047861 Batch F1: 0.8
Epoch:  314        3 Batch loss: 0.065088 Batch F1: 0.9411764705882353
Epoch:  314        4 Batch loss: 0.074652 Batch F1: 0.18181818181818182
Epoch:  314        5 Batch loss: 0.070239 Batch F1: 0.4615384615384615
Epoch:  314        6 Batch loss: 0.053470 Batch F1: 0.7272727272727273
Epoch:  314        7 Batch loss: 0.096545 Batch F1: 0.9714285714285714
Epoch:  314        8 Batch loss: 0.072255 Batch F1: 0.9333333333333333
Epoch:  314        9 Batch loss: 0.073234 Batch F1: 0.888888888888889
Epoch:  314       10 Batch loss: 0.053144 Batch F1: 0.888888888888889
Epoch:  314       11 Batch loss: 0.070812 Batch F1: 0.9411764705882353
Epoch:  314       12 Batch loss: 0.056671 Batch F1: 0.8333333333333333
Train Avg Loss  314: 0.067430

Train Avg F1  314: 0.7937814222341077

Val Avg Loss  314: 0.063368

Val Avg F1  314:  0.5520833333333334

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 315
--------------------------------------------------------------
Epoch:  315        1 Batch loss: 0.070147 Batch F1: 0.3636363636363636
Epoch:  315        2 Batch loss: 0.061246 Batch F1: 0.923076923076923
Epoch:  315        3 Batch loss: 0.056090 Batch F1: 1.0
Epoch:  315        4 Batch loss: 0.060939 Batch F1: 0.888888888888889
Epoch:  315        5 Batch loss: 0.059621 Batch F1: 1.0
Epoch:  315        6 Batch loss: 0.069893 Batch F1: 0.5714285714285715
Epoch:  315        7 Batch loss: 0.081100 Batch F1: 0.4615384615384615
Epoch:  315        8 Batch loss: 0.064045 Batch F1: 0.2222222222222222
Epoch:  315        9 Batch loss: 0.056800 Batch F1: 0.7272727272727273
Epoch:  315       10 Batch loss: 0.076904 Batch F1: 0.631578947368421
Epoch:  315       11 Batch loss: 0.094712 Batch F1: 0.5454545454545454
Epoch:  315       12 Batch loss: 0.078100 Batch F1: 0.8750000000000001
Train Avg Loss  315: 0.069133

Train Avg F1  315: 0.6841748042405937

Val Avg Loss  315: 0.062833

Val Avg F1  315:  0.9256410256410256

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 316
--------------------------------------------------------------
Epoch:  316        1 Batch loss: 0.067007 Batch F1: 0.923076923076923
Epoch:  316        2 Batch loss: 0.066975 Batch F1: 0.8333333333333333
Epoch:  316        3 Batch loss: 0.076606 Batch F1: 1.0
Epoch:  316        4 Batch loss: 0.071646 Batch F1: 1.0
Epoch:  316        5 Batch loss: 0.077155 Batch F1: 0.7499999999999999
Epoch:  316        6 Batch loss: 0.072249 Batch F1: 0.9411764705882353
Epoch:  316        7 Batch loss: 0.058291 Batch F1: 1.0
Epoch:  316        8 Batch loss: 0.080850 Batch F1: 0.8235294117647058
Epoch:  316        9 Batch loss: 0.046136 Batch F1: 1.0
Epoch:  316       10 Batch loss: 0.082177 Batch F1: 0.33333333333333337
Epoch:  316       11 Batch loss: 0.066864 Batch F1: 0.5
Epoch:  316       12 Batch loss: 0.072889 Batch F1: 0.5
Train Avg Loss  316: 0.069904

Train Avg F1  316: 0.8003707893413776

Val Avg Loss  316: 0.062274

Val Avg F1  316:  0.5236111111111111

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 317
--------------------------------------------------------------
Epoch:  317        1 Batch loss: 0.066437 Batch F1: 0.25
Epoch:  317        2 Batch loss: 0.050864 Batch F1: 0.5714285714285715
Epoch:  317        3 Batch loss: 0.063654 Batch F1: 0.6153846153846153
Epoch:  317        4 Batch loss: 0.086799 Batch F1: 0.47058823529411764
Epoch:  317        5 Batch loss: 0.068905 Batch F1: 1.0
Epoch:  317        6 Batch loss: 0.073828 Batch F1: 0.8421052631578948
Epoch:  317        7 Batch loss: 0.056755 Batch F1: 1.0
Epoch:  317        8 Batch loss: 0.083999 Batch F1: 0.8695652173913044
Epoch:  317        9 Batch loss: 0.058881 Batch F1: 0.9411764705882353
Epoch:  317       10 Batch loss: 0.067907 Batch F1: 0.923076923076923
Epoch:  317       11 Batch loss: 0.073380 Batch F1: 0.9090909090909091
Epoch:  317       12 Batch loss: 0.079461 Batch F1: 0.8750000000000001
Train Avg Loss  317: 0.069239

Train Avg F1  317: 0.772284683784381

Val Avg Loss  317: 0.061813

Val Avg F1  317:  0.9214285714285715

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 318
--------------------------------------------------------------
Epoch:  318        1 Batch loss: 0.053162 Batch F1: 0.888888888888889
Epoch:  318        2 Batch loss: 0.055181 Batch F1: 1.0
Epoch:  318        3 Batch loss: 0.051998 Batch F1: 0.33333333333333337
Epoch:  318        4 Batch loss: 0.062233 Batch F1: 0.5454545454545454
Epoch:  318        5 Batch loss: 0.073999 Batch F1: 0.6666666666666666
Epoch:  318        6 Batch loss: 0.062492 Batch F1: 0.6
Epoch:  318        7 Batch loss: 0.113809 Batch F1: 0.2666666666666667
Epoch:  318        8 Batch loss: 0.085816 Batch F1: 0.5
Epoch:  318        9 Batch loss: 0.092991 Batch F1: 0.88
Epoch:  318       10 Batch loss: 0.098204 Batch F1: 0.9
Epoch:  318       11 Batch loss: 0.065640 Batch F1: 0.9333333333333333
Epoch:  318       12 Batch loss: 0.087556 Batch F1: 0.0
Train Avg Loss  318: 0.075257

Train Avg F1  318: 0.6261952861952862

Val Avg Loss  318: 0.064697

Val Avg F1  318:  0.727056277056277

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 319
--------------------------------------------------------------
Epoch:  319        1 Batch loss: 0.072842 Batch F1: 0.7058823529411764
Epoch:  319        2 Batch loss: 0.077533 Batch F1: 0.9090909090909091
Epoch:  319        3 Batch loss: 0.069453 Batch F1: 0.9333333333333333
Epoch:  319        4 Batch loss: 0.091130 Batch F1: 0.2857142857142857
Epoch:  319        5 Batch loss: 0.051886 Batch F1: 0.6666666666666666
Epoch:  319        6 Batch loss: 0.048947 Batch F1: 0.8333333333333333
Epoch:  319        7 Batch loss: 0.111415 Batch F1: 0.16666666666666669
Epoch:  319        8 Batch loss: 0.076620 Batch F1: 0.9523809523809523
Epoch:  319        9 Batch loss: 0.061618 Batch F1: 0.9411764705882353
Epoch:  319       10 Batch loss: 0.072600 Batch F1: 0.6153846153846153
Epoch:  319       11 Batch loss: 0.081120 Batch F1: 0.5
Epoch:  319       12 Batch loss: 0.076171 Batch F1: 0.6153846153846153
Train Avg Loss  319: 0.074278

Train Avg F1  319: 0.6770845167903992

Val Avg Loss  319: 0.065530

Val Avg F1  319:  0.9428104575163399

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 320
--------------------------------------------------------------
Epoch:  320        1 Batch loss: 0.069212 Batch F1: 0.9411764705882353
Epoch:  320        2 Batch loss: 0.047509 Batch F1: 1.0
Epoch:  320        3 Batch loss: 0.100374 Batch F1: 0.761904761904762
Epoch:  320        4 Batch loss: 0.053220 Batch F1: 1.0
Epoch:  320        5 Batch loss: 0.077393 Batch F1: 0.5714285714285715
Epoch:  320        6 Batch loss: 0.071920 Batch F1: 0.5714285714285715
Epoch:  320        7 Batch loss: 0.074266 Batch F1: 0.5
Epoch:  320        8 Batch loss: 0.068845 Batch F1: 0.5714285714285715
Epoch:  320        9 Batch loss: 0.058487 Batch F1: 1.0
Epoch:  320       10 Batch loss: 0.094840 Batch F1: 0.967741935483871
Epoch:  320       11 Batch loss: 0.081667 Batch F1: 0.8235294117647058
Epoch:  320       12 Batch loss: 0.069562 Batch F1: 0.8571428571428571
Train Avg Loss  320: 0.072275

Train Avg F1  320: 0.7971484292641788

Val Avg Loss  320: 0.062505

Val Avg F1  320:  0.9209600706311232

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 321
--------------------------------------------------------------
Epoch:  321        1 Batch loss: 0.060392 Batch F1: 0.923076923076923
Epoch:  321        2 Batch loss: 0.067587 Batch F1: 0.4444444444444445
Epoch:  321        3 Batch loss: 0.086935 Batch F1: 0.4615384615384615
Epoch:  321        4 Batch loss: 0.049262 Batch F1: 0.6666666666666666
Epoch:  321        5 Batch loss: 0.077389 Batch F1: 0.6153846153846153
Epoch:  321        6 Batch loss: 0.084023 Batch F1: 0.47058823529411764
Epoch:  321        7 Batch loss: 0.070854 Batch F1: 0.9411764705882353
Epoch:  321        8 Batch loss: 0.089155 Batch F1: 0.9285714285714286
Epoch:  321        9 Batch loss: 0.055271 Batch F1: 0.923076923076923
Epoch:  321       10 Batch loss: 0.064305 Batch F1: 1.0
Epoch:  321       11 Batch loss: 0.064649 Batch F1: 0.923076923076923
Epoch:  321       12 Batch loss: 0.067952 Batch F1: 1.0
Train Avg Loss  321: 0.069814

Train Avg F1  321: 0.7748000909765617

Val Avg Loss  321: 0.062394

Val Avg F1  321:  0.9295665634674923

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 322
--------------------------------------------------------------
Epoch:  322        1 Batch loss: 0.082343 Batch F1: 0.8571428571428571
Epoch:  322        2 Batch loss: 0.064409 Batch F1: 0.9333333333333333
Epoch:  322        3 Batch loss: 0.070649 Batch F1: 0.9411764705882353
Epoch:  322        4 Batch loss: 0.069587 Batch F1: 0.4615384615384615
Epoch:  322        5 Batch loss: 0.056182 Batch F1: 0.5714285714285715
Epoch:  322        6 Batch loss: 0.080721 Batch F1: 0.47058823529411764
Epoch:  322        7 Batch loss: 0.071456 Batch F1: 0.5714285714285715
Epoch:  322        8 Batch loss: 0.062319 Batch F1: 0.9411764705882353
Epoch:  322        9 Batch loss: 0.063316 Batch F1: 0.9333333333333333
Epoch:  322       10 Batch loss: 0.079680 Batch F1: 0.8421052631578948
Epoch:  322       11 Batch loss: 0.053332 Batch F1: 1.0
Epoch:  322       12 Batch loss: 0.065195 Batch F1: 1.0
Train Avg Loss  322: 0.068266

Train Avg F1  322: 0.7936042973194676

Val Avg Loss  322: 0.061772

Val Avg F1  322:  0.9256383712905452

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 323
--------------------------------------------------------------
Epoch:  323        1 Batch loss: 0.073326 Batch F1: 0.8
Epoch:  323        2 Batch loss: 0.071026 Batch F1: 1.0
Epoch:  323        3 Batch loss: 0.055826 Batch F1: 1.0
Epoch:  323        4 Batch loss: 0.061671 Batch F1: 0.923076923076923
Epoch:  323        5 Batch loss: 0.068589 Batch F1: 0.7272727272727273
Epoch:  323        6 Batch loss: 0.053345 Batch F1: 0.2857142857142857
Epoch:  323        7 Batch loss: 0.058663 Batch F1: 0.3636363636363636
Epoch:  323        8 Batch loss: 0.060243 Batch F1: 0.5454545454545454
Epoch:  323        9 Batch loss: 0.064746 Batch F1: 0.7499999999999999
Epoch:  323       10 Batch loss: 0.098449 Batch F1: 0.375
Epoch:  323       11 Batch loss: 0.090856 Batch F1: 0.8571428571428571
Epoch:  323       12 Batch loss: 0.058717 Batch F1: 1.0
Train Avg Loss  323: 0.067955

Train Avg F1  323: 0.718941475191475

Val Avg Loss  323: 0.062033

Val Avg F1  323:  0.9247208931419458

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 324
--------------------------------------------------------------
Epoch:  324        1 Batch loss: 0.074686 Batch F1: 0.9
Epoch:  324        2 Batch loss: 0.072971 Batch F1: 0.9411764705882353
Epoch:  324        3 Batch loss: 0.063203 Batch F1: 0.888888888888889
Epoch:  324        4 Batch loss: 0.071041 Batch F1: 0.7692307692307693
Epoch:  324        5 Batch loss: 0.058812 Batch F1: 1.0
Epoch:  324        6 Batch loss: 0.065277 Batch F1: 0.923076923076923
Epoch:  324        7 Batch loss: 0.079916 Batch F1: 1.0
Epoch:  324        8 Batch loss: 0.089029 Batch F1: 0.5555555555555556
Epoch:  324        9 Batch loss: 0.063823 Batch F1: 0.9411764705882353
Epoch:  324       10 Batch loss: 0.059333 Batch F1: 0.923076923076923
Epoch:  324       11 Batch loss: 0.057485 Batch F1: 0.923076923076923
Epoch:  324       12 Batch loss: 0.072056 Batch F1: 0.923076923076923
Train Avg Loss  324: 0.068969

Train Avg F1  324: 0.8906946539299482

Val Avg Loss  324: 0.063779

Val Avg F1  324:  0.7044934640522875

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 325
--------------------------------------------------------------
Epoch:  325        1 Batch loss: 0.064081 Batch F1: 0.6666666666666666
Epoch:  325        2 Batch loss: 0.058068 Batch F1: 0.4
Epoch:  325        3 Batch loss: 0.045305 Batch F1: 0.0
Epoch:  325        4 Batch loss: 0.080928 Batch F1: 0.5333333333333333
Epoch:  325        5 Batch loss: 0.055840 Batch F1: 0.6666666666666666
Epoch:  325        6 Batch loss: 0.089988 Batch F1: 0.375
Epoch:  325        7 Batch loss: 0.046033 Batch F1: 0.5
Epoch:  325        8 Batch loss: 0.066990 Batch F1: 0.9523809523809523
Epoch:  325        9 Batch loss: 0.087040 Batch F1: 0.923076923076923
Epoch:  325       10 Batch loss: 0.086421 Batch F1: 0.8235294117647058
Epoch:  325       11 Batch loss: 0.081730 Batch F1: 0.7692307692307693
Epoch:  325       12 Batch loss: 0.073336 Batch F1: 0.9411764705882353
Train Avg Loss  325: 0.069647

Train Avg F1  325: 0.6292550994756877

Val Avg Loss  325: 0.064845

Val Avg F1  325:  0.9263574660633483

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 326
--------------------------------------------------------------
Epoch:  326        1 Batch loss: 0.086428 Batch F1: 0.9473684210526316
Epoch:  326        2 Batch loss: 0.068032 Batch F1: 0.6
Epoch:  326        3 Batch loss: 0.077161 Batch F1: 0.5714285714285715
Epoch:  326        4 Batch loss: 0.048392 Batch F1: 0.5714285714285715
Epoch:  326        5 Batch loss: 0.087526 Batch F1: 0.47058823529411764
Epoch:  326        6 Batch loss: 0.070423 Batch F1: 0.5454545454545454
Epoch:  326        7 Batch loss: 0.077906 Batch F1: 0.6
Epoch:  326        8 Batch loss: 0.066161 Batch F1: 0.8333333333333333
Epoch:  326        9 Batch loss: 0.057345 Batch F1: 0.9090909090909091
Epoch:  326       10 Batch loss: 0.053772 Batch F1: 1.0
Epoch:  326       11 Batch loss: 0.085857 Batch F1: 0.4
Epoch:  326       12 Batch loss: 0.091334 Batch F1: 0.5333333333333333
Train Avg Loss  326: 0.072528

Train Avg F1  326: 0.6651688267013345

Val Avg Loss  326: 0.063424

Val Avg F1  326:  0.7563492063492063

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 327
--------------------------------------------------------------
Epoch:  327        1 Batch loss: 0.059692 Batch F1: 0.7272727272727273
Epoch:  327        2 Batch loss: 0.096277 Batch F1: 0.4444444444444445
Epoch:  327        3 Batch loss: 0.054257 Batch F1: 1.0
Epoch:  327        4 Batch loss: 0.043613 Batch F1: 1.0
Epoch:  327        5 Batch loss: 0.061703 Batch F1: 0.0
Epoch:  327        6 Batch loss: 0.086154 Batch F1: 0.47058823529411764
Epoch:  327        7 Batch loss: 0.074325 Batch F1: 0.7142857142857143
Epoch:  327        8 Batch loss: 0.076687 Batch F1: 0.888888888888889
Epoch:  327        9 Batch loss: 0.080724 Batch F1: 0.9285714285714286
Epoch:  327       10 Batch loss: 0.079225 Batch F1: 0.9523809523809523
Epoch:  327       11 Batch loss: 0.070001 Batch F1: 0.923076923076923
Epoch:  327       12 Batch loss: 0.046754 Batch F1: 1.0
Train Avg Loss  327: 0.069118

Train Avg F1  327: 0.7541257761845997

Val Avg Loss  327: 0.062974

Val Avg F1  327:  0.9223276723276723

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 328
--------------------------------------------------------------
Epoch:  328        1 Batch loss: 0.055857 Batch F1: 1.0
Epoch:  328        2 Batch loss: 0.073162 Batch F1: 0.25
Epoch:  328        3 Batch loss: 0.094721 Batch F1: 0.0
Epoch:  328        4 Batch loss: 0.075401 Batch F1: 0.2222222222222222
Epoch:  328        5 Batch loss: 0.068674 Batch F1: 0.761904761904762
Epoch:  328        6 Batch loss: 0.090167 Batch F1: 0.7142857142857143
Epoch:  328        7 Batch loss: 0.079118 Batch F1: 0.8235294117647058
Epoch:  328        8 Batch loss: 0.068036 Batch F1: 1.0
Epoch:  328        9 Batch loss: 0.063901 Batch F1: 1.0
Epoch:  328       10 Batch loss: 0.064108 Batch F1: 0.9523809523809523
Epoch:  328       11 Batch loss: 0.065054 Batch F1: 0.9333333333333333
Epoch:  328       12 Batch loss: 0.067712 Batch F1: 0.9090909090909091
Train Avg Loss  328: 0.072159

Train Avg F1  328: 0.7138956087485498

Val Avg Loss  328: 0.065441

Val Avg F1  328:  0.5604731525784158

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 329
--------------------------------------------------------------
Epoch:  329        1 Batch loss: 0.062107 Batch F1: 0.6666666666666666
Epoch:  329        2 Batch loss: 0.049236 Batch F1: 0.8571428571428571
Epoch:  329        3 Batch loss: 0.074027 Batch F1: 0.4
Epoch:  329        4 Batch loss: 0.071011 Batch F1: 0.4
Epoch:  329        5 Batch loss: 0.083229 Batch F1: 0.6666666666666666
Epoch:  329        6 Batch loss: 0.057703 Batch F1: 0.25
Epoch:  329        7 Batch loss: 0.081367 Batch F1: 0.888888888888889
Epoch:  329        8 Batch loss: 0.060024 Batch F1: 0.8
Epoch:  329        9 Batch loss: 0.079673 Batch F1: 0.888888888888889
Epoch:  329       10 Batch loss: 0.062262 Batch F1: 0.0
Epoch:  329       11 Batch loss: 0.100215 Batch F1: 0.23529411764705882
Epoch:  329       12 Batch loss: 0.075328 Batch F1: 0.5454545454545454
Train Avg Loss  329: 0.071348

Train Avg F1  329: 0.5499168859462977

Val Avg Loss  329: 0.064694

Val Avg F1  329:  0.9078804347826088

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 330
--------------------------------------------------------------
Epoch:  330        1 Batch loss: 0.073873 Batch F1: 0.888888888888889
Epoch:  330        2 Batch loss: 0.085012 Batch F1: 0.8
Epoch:  330        3 Batch loss: 0.072104 Batch F1: 0.9333333333333333
Epoch:  330        4 Batch loss: 0.056652 Batch F1: 1.0
Epoch:  330        5 Batch loss: 0.064511 Batch F1: 0.9333333333333333
Epoch:  330        6 Batch loss: 0.081357 Batch F1: 0.8695652173913044
Epoch:  330        7 Batch loss: 0.081843 Batch F1: 0.9166666666666666
Epoch:  330        8 Batch loss: 0.071933 Batch F1: 0.8750000000000001
Epoch:  330        9 Batch loss: 0.080993 Batch F1: 1.0
Epoch:  330       10 Batch loss: 0.064056 Batch F1: 1.0
Epoch:  330       11 Batch loss: 0.054144 Batch F1: 0.9090909090909091
Epoch:  330       12 Batch loss: 0.044166 Batch F1: 1.0
Train Avg Loss  330: 0.069220

Train Avg F1  330: 0.927156529058703

Val Avg Loss  330: 0.064120

Val Avg F1  330:  0.5818764568764568

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 331
--------------------------------------------------------------
Epoch:  331        1 Batch loss: 0.060708 Batch F1: 0.5714285714285715
Epoch:  331        2 Batch loss: 0.084975 Batch F1: 0.5333333333333333
Epoch:  331        3 Batch loss: 0.071720 Batch F1: 0.3636363636363636
Epoch:  331        4 Batch loss: 0.065751 Batch F1: 0.7777777777777778
Epoch:  331        5 Batch loss: 0.081876 Batch F1: 0.888888888888889
Epoch:  331        6 Batch loss: 0.060961 Batch F1: 0.8571428571428571
Epoch:  331        7 Batch loss: 0.041757 Batch F1: 1.0
Epoch:  331        8 Batch loss: 0.066025 Batch F1: 1.0
Epoch:  331        9 Batch loss: 0.079211 Batch F1: 0.8235294117647058
Epoch:  331       10 Batch loss: 0.077258 Batch F1: 0.5
Epoch:  331       11 Batch loss: 0.061668 Batch F1: 1.0
Epoch:  331       12 Batch loss: 0.081471 Batch F1: 1.0
Train Avg Loss  331: 0.069449

Train Avg F1  331: 0.7763114336643748

Val Avg Loss  331: 0.062198

Val Avg F1  331:  0.8988526570048309

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 332
--------------------------------------------------------------
Epoch:  332        1 Batch loss: 0.058899 Batch F1: 0.9333333333333333
Epoch:  332        2 Batch loss: 0.056547 Batch F1: 1.0
Epoch:  332        3 Batch loss: 0.085525 Batch F1: 0.8421052631578948
Epoch:  332        4 Batch loss: 0.082586 Batch F1: 0.9
Epoch:  332        5 Batch loss: 0.046943 Batch F1: 1.0
Epoch:  332        6 Batch loss: 0.055347 Batch F1: 0.888888888888889
Epoch:  332        7 Batch loss: 0.080088 Batch F1: 0.9565217391304348
Epoch:  332        8 Batch loss: 0.063177 Batch F1: 0.6666666666666666
Epoch:  332        9 Batch loss: 0.080699 Batch F1: 0.3076923076923077
Epoch:  332       10 Batch loss: 0.072635 Batch F1: 0.6153846153846153
Epoch:  332       11 Batch loss: 0.067384 Batch F1: 0.8235294117647058
Epoch:  332       12 Batch loss: 0.070393 Batch F1: 0.9473684210526316
Train Avg Loss  332: 0.068352

Train Avg F1  332: 0.8234575539226233

Val Avg Loss  332: 0.062222

Val Avg F1  332:  0.9229085865115277

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 333
--------------------------------------------------------------
Epoch:  333        1 Batch loss: 0.054571 Batch F1: 1.0
Epoch:  333        2 Batch loss: 0.069958 Batch F1: 0.9411764705882353
Epoch:  333        3 Batch loss: 0.077524 Batch F1: 1.0
Epoch:  333        4 Batch loss: 0.045249 Batch F1: 1.0
Epoch:  333        5 Batch loss: 0.070569 Batch F1: 0.9333333333333333
Epoch:  333        6 Batch loss: 0.061934 Batch F1: 0.6666666666666666
Epoch:  333        7 Batch loss: 0.077171 Batch F1: 0.3636363636363636
Epoch:  333        8 Batch loss: 0.073714 Batch F1: 0.5333333333333333
Epoch:  333        9 Batch loss: 0.074894 Batch F1: 0.9
Epoch:  333       10 Batch loss: 0.073631 Batch F1: 0.9090909090909091
Epoch:  333       11 Batch loss: 0.074654 Batch F1: 0.8571428571428571
Epoch:  333       12 Batch loss: 0.073247 Batch F1: 0.8571428571428571
Train Avg Loss  333: 0.068926

Train Avg F1  333: 0.8301268992445464

Val Avg Loss  333: 0.062138

Val Avg F1  333:  0.9229085865115276

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 334
--------------------------------------------------------------
Epoch:  334        1 Batch loss: 0.063527 Batch F1: 0.923076923076923
Epoch:  334        2 Batch loss: 0.064606 Batch F1: 0.6153846153846153
Epoch:  334        3 Batch loss: 0.072623 Batch F1: 0.5
Epoch:  334        4 Batch loss: 0.056046 Batch F1: 0.5454545454545454
Epoch:  334        5 Batch loss: 0.092940 Batch F1: 0.2666666666666667
Epoch:  334        6 Batch loss: 0.069704 Batch F1: 0.4
Epoch:  334        7 Batch loss: 0.056646 Batch F1: 0.9090909090909091
Epoch:  334        8 Batch loss: 0.060110 Batch F1: 0.7499999999999999
Epoch:  334        9 Batch loss: 0.069466 Batch F1: 1.0
Epoch:  334       10 Batch loss: 0.058619 Batch F1: 1.0
Epoch:  334       11 Batch loss: 0.079153 Batch F1: 0.7368421052631579
Epoch:  334       12 Batch loss: 0.095726 Batch F1: 0.5333333333333333
Train Avg Loss  334: 0.069931

Train Avg F1  334: 0.6816540915225126

Val Avg Loss  334: 0.062069

Val Avg F1  334:  0.9107142857142856

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 335
--------------------------------------------------------------
Epoch:  335        1 Batch loss: 0.083944 Batch F1: 0.8695652173913044
Epoch:  335        2 Batch loss: 0.057303 Batch F1: 1.0
Epoch:  335        3 Batch loss: 0.065095 Batch F1: 0.8750000000000001
Epoch:  335        4 Batch loss: 0.076378 Batch F1: 0.9
Epoch:  335        5 Batch loss: 0.066850 Batch F1: 1.0
Epoch:  335        6 Batch loss: 0.078399 Batch F1: 0.888888888888889
Epoch:  335        7 Batch loss: 0.064933 Batch F1: 1.0
Epoch:  335        8 Batch loss: 0.051393 Batch F1: 0.33333333333333337
Epoch:  335        9 Batch loss: 0.045512 Batch F1: 0.0
Epoch:  335       10 Batch loss: 0.096322 Batch F1: 0.0
Epoch:  335       11 Batch loss: 0.061802 Batch F1: 0.7499999999999999
Epoch:  335       12 Batch loss: 0.096491 Batch F1: 0.631578947368421
Train Avg Loss  335: 0.070368

Train Avg F1  335: 0.6873638655818289

Val Avg Loss  335: 0.063139

Val Avg F1  335:  0.9158496732026143

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 336
--------------------------------------------------------------
Epoch:  336        1 Batch loss: 0.073023 Batch F1: 0.9565217391304348
Epoch:  336        2 Batch loss: 0.083334 Batch F1: 0.8571428571428571
Epoch:  336        3 Batch loss: 0.075315 Batch F1: 0.8
Epoch:  336        4 Batch loss: 0.073114 Batch F1: 1.0
Epoch:  336        5 Batch loss: 0.070920 Batch F1: 0.5
Epoch:  336        6 Batch loss: 0.100118 Batch F1: 0.0
Epoch:  336        7 Batch loss: 0.064339 Batch F1: 0.9411764705882353
Epoch:  336        8 Batch loss: 0.075786 Batch F1: 0.8571428571428571
Epoch:  336        9 Batch loss: 0.068317 Batch F1: 0.7499999999999999
Epoch:  336       10 Batch loss: 0.086723 Batch F1: 0.6666666666666666
Epoch:  336       11 Batch loss: 0.073507 Batch F1: 0.5454545454545454
Epoch:  336       12 Batch loss: 0.080107 Batch F1: 0.4
Train Avg Loss  336: 0.077050

Train Avg F1  336: 0.6895087613437997

Val Avg Loss  336: 0.063746

Val Avg F1  336:  0.7203302373581011

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 337
--------------------------------------------------------------
Epoch:  337        1 Batch loss: 0.060288 Batch F1: 0.7272727272727273
Epoch:  337        2 Batch loss: 0.085385 Batch F1: 0.33333333333333337
Epoch:  337        3 Batch loss: 0.070515 Batch F1: 0.7692307692307693
Epoch:  337        4 Batch loss: 0.070513 Batch F1: 0.25
Epoch:  337        5 Batch loss: 0.065919 Batch F1: 0.5454545454545454
Epoch:  337        6 Batch loss: 0.083891 Batch F1: 0.42857142857142855
Epoch:  337        7 Batch loss: 0.062100 Batch F1: 0.7058823529411764
Epoch:  337        8 Batch loss: 0.061376 Batch F1: 0.9411764705882353
Epoch:  337        9 Batch loss: 0.092513 Batch F1: 0.8333333333333333
Epoch:  337       10 Batch loss: 0.091874 Batch F1: 0.7272727272727273
Epoch:  337       11 Batch loss: 0.061960 Batch F1: 1.0
Epoch:  337       12 Batch loss: 0.059019 Batch F1: 0.7272727272727273
Train Avg Loss  337: 0.072113

Train Avg F1  337: 0.6657333679392503

Val Avg Loss  337: 0.066966

Val Avg F1  337:  0.5868131868131868

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 338
--------------------------------------------------------------
Epoch:  338        1 Batch loss: 0.069291 Batch F1: 0.3636363636363636
Epoch:  338        2 Batch loss: 0.070694 Batch F1: 0.4615384615384615
Epoch:  338        3 Batch loss: 0.043172 Batch F1: 0.5
Epoch:  338        4 Batch loss: 0.079768 Batch F1: 0.625
Epoch:  338        5 Batch loss: 0.090747 Batch F1: 0.9655172413793104
Epoch:  338        6 Batch loss: 0.095727 Batch F1: 0.6666666666666666
Epoch:  338        7 Batch loss: 0.061884 Batch F1: 0.923076923076923
Epoch:  338        8 Batch loss: 0.061266 Batch F1: 0.6666666666666666
Epoch:  338        9 Batch loss: 0.084913 Batch F1: 0.8
Epoch:  338       10 Batch loss: 0.054543 Batch F1: 1.0
Epoch:  338       11 Batch loss: 0.075184 Batch F1: 0.42857142857142855
Epoch:  338       12 Batch loss: 0.062478 Batch F1: 1.0
Train Avg Loss  338: 0.070806

Train Avg F1  338: 0.7000561459613183

Val Avg Loss  338: 0.062288

Val Avg F1  338:  0.9426406926406926

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 339
--------------------------------------------------------------
Epoch:  339        1 Batch loss: 0.071844 Batch F1: 0.9523809523809523
Epoch:  339        2 Batch loss: 0.054369 Batch F1: 1.0
Epoch:  339        3 Batch loss: 0.073985 Batch F1: 0.8571428571428571
Epoch:  339        4 Batch loss: 0.065209 Batch F1: 0.9411764705882353
Epoch:  339        5 Batch loss: 0.067397 Batch F1: 0.7499999999999999
Epoch:  339        6 Batch loss: 0.055412 Batch F1: 0.8571428571428571
Epoch:  339        7 Batch loss: 0.065091 Batch F1: 0.6153846153846153
Epoch:  339        8 Batch loss: 0.067644 Batch F1: 0.25
Epoch:  339        9 Batch loss: 0.057253 Batch F1: 0.7272727272727273
Epoch:  339       10 Batch loss: 0.077411 Batch F1: 0.42857142857142855
Epoch:  339       11 Batch loss: 0.085693 Batch F1: 0.42857142857142855
Epoch:  339       12 Batch loss: 0.089420 Batch F1: 0.9523809523809523
Train Avg Loss  339: 0.069227

Train Avg F1  339: 0.7300020241196711

Val Avg Loss  339: 0.062139

Val Avg F1  339:  0.9386274509803922

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 340
--------------------------------------------------------------
Epoch:  340        1 Batch loss: 0.071557 Batch F1: 1.0
Epoch:  340        2 Batch loss: 0.089829 Batch F1: 0.7777777777777778
Epoch:  340        3 Batch loss: 0.081413 Batch F1: 0.8235294117647058
Epoch:  340        4 Batch loss: 0.057908 Batch F1: 0.888888888888889
Epoch:  340        5 Batch loss: 0.062579 Batch F1: 0.888888888888889
Epoch:  340        6 Batch loss: 0.071289 Batch F1: 0.5714285714285715
Epoch:  340        7 Batch loss: 0.073182 Batch F1: 0.33333333333333337
Epoch:  340        8 Batch loss: 0.046950 Batch F1: 1.0
Epoch:  340        9 Batch loss: 0.073085 Batch F1: 0.888888888888889
Epoch:  340       10 Batch loss: 0.057884 Batch F1: 0.9333333333333333
Epoch:  340       11 Batch loss: 0.080377 Batch F1: 0.9090909090909091
Epoch:  340       12 Batch loss: 0.065216 Batch F1: 0.7499999999999999
Train Avg Loss  340: 0.069272

Train Avg F1  340: 0.8137633336162747

Val Avg Loss  340: 0.062236

Val Avg F1  340:  0.9028679653679653

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 341
--------------------------------------------------------------
Epoch:  341        1 Batch loss: 0.074650 Batch F1: 0.9411764705882353
Epoch:  341        2 Batch loss: 0.063991 Batch F1: 0.8571428571428571
Epoch:  341        3 Batch loss: 0.078995 Batch F1: 0.962962962962963
Epoch:  341        4 Batch loss: 0.055701 Batch F1: 0.9411764705882353
Epoch:  341        5 Batch loss: 0.083230 Batch F1: 0.8571428571428571
Epoch:  341        6 Batch loss: 0.085111 Batch F1: 0.8571428571428571
Epoch:  341        7 Batch loss: 0.060856 Batch F1: 1.0
Epoch:  341        8 Batch loss: 0.054407 Batch F1: 0.888888888888889
Epoch:  341        9 Batch loss: 0.059769 Batch F1: 0.9090909090909091
Epoch:  341       10 Batch loss: 0.065934 Batch F1: 0.6153846153846153
Epoch:  341       11 Batch loss: 0.078955 Batch F1: 0.631578947368421
Epoch:  341       12 Batch loss: 0.064181 Batch F1: 0.5454545454545454
Train Avg Loss  341: 0.068815

Train Avg F1  341: 0.8339285318129486

Val Avg Loss  341: 0.063006

Val Avg F1  341:  0.5857142857142857

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 342
--------------------------------------------------------------
Epoch:  342        1 Batch loss: 0.044203 Batch F1: 0.5
Epoch:  342        2 Batch loss: 0.084583 Batch F1: 0.375
Epoch:  342        3 Batch loss: 0.072964 Batch F1: 0.9
Epoch:  342        4 Batch loss: 0.070941 Batch F1: 0.8750000000000001
Epoch:  342        5 Batch loss: 0.078301 Batch F1: 0.8750000000000001
Epoch:  342        6 Batch loss: 0.062654 Batch F1: 1.0
Epoch:  342        7 Batch loss: 0.068709 Batch F1: 0.7692307692307693
Epoch:  342        8 Batch loss: 0.075323 Batch F1: 0.9523809523809523
Epoch:  342        9 Batch loss: 0.065553 Batch F1: 0.9333333333333333
Epoch:  342       10 Batch loss: 0.079923 Batch F1: 0.923076923076923
Epoch:  342       11 Batch loss: 0.058667 Batch F1: 1.0
Epoch:  342       12 Batch loss: 0.057820 Batch F1: 0.6666666666666666
Train Avg Loss  342: 0.068303

Train Avg F1  342: 0.8141407203907204

Val Avg Loss  342: 0.065116

Val Avg F1  342:  0.5596590909090909

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 343
--------------------------------------------------------------
Epoch:  343        1 Batch loss: 0.068174 Batch F1: 0.2222222222222222
Epoch:  343        2 Batch loss: 0.092027 Batch F1: 0.4
Epoch:  343        3 Batch loss: 0.070965 Batch F1: 0.4
Epoch:  343        4 Batch loss: 0.047698 Batch F1: 1.0
Epoch:  343        5 Batch loss: 0.062857 Batch F1: 0.4444444444444445
Epoch:  343        6 Batch loss: 0.068347 Batch F1: 0.5714285714285715
Epoch:  343        7 Batch loss: 0.059770 Batch F1: 0.7499999999999999
Epoch:  343        8 Batch loss: 0.059639 Batch F1: 0.8235294117647058
Epoch:  343        9 Batch loss: 0.048803 Batch F1: 0.5
Epoch:  343       10 Batch loss: 0.083268 Batch F1: 0.0
Epoch:  343       11 Batch loss: 0.077642 Batch F1: 0.33333333333333337
Epoch:  343       12 Batch loss: 0.086022 Batch F1: 0.9
Train Avg Loss  343: 0.068768

Train Avg F1  343: 0.5287464985994398

Val Avg Loss  343: 0.062432

Val Avg F1  343:  0.9333333333333333

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 344
--------------------------------------------------------------
Epoch:  344        1 Batch loss: 0.074102 Batch F1: 0.8750000000000001
Epoch:  344        2 Batch loss: 0.054006 Batch F1: 1.0
Epoch:  344        3 Batch loss: 0.101067 Batch F1: 0.7368421052631579
Epoch:  344        4 Batch loss: 0.083144 Batch F1: 0.9600000000000001
Epoch:  344        5 Batch loss: 0.065391 Batch F1: 0.8421052631578948
Epoch:  344        6 Batch loss: 0.058114 Batch F1: 1.0
Epoch:  344        7 Batch loss: 0.063539 Batch F1: 1.0
Epoch:  344        8 Batch loss: 0.069980 Batch F1: 0.8333333333333333
Epoch:  344        9 Batch loss: 0.060454 Batch F1: 1.0
Epoch:  344       10 Batch loss: 0.046645 Batch F1: 0.7499999999999999
Epoch:  344       11 Batch loss: 0.086714 Batch F1: 0.5
Epoch:  344       12 Batch loss: 0.061477 Batch F1: 0.4444444444444445
Train Avg Loss  344: 0.068720

Train Avg F1  344: 0.8284770955165692

Val Avg Loss  344: 0.062691

Val Avg F1  344:  0.6110500610500611

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 345
--------------------------------------------------------------
Epoch:  345        1 Batch loss: 0.053036 Batch F1: 0.33333333333333337
Epoch:  345        2 Batch loss: 0.082763 Batch F1: 0.8
Epoch:  345        3 Batch loss: 0.067098 Batch F1: 0.888888888888889
Epoch:  345        4 Batch loss: 0.058438 Batch F1: 1.0
Epoch:  345        5 Batch loss: 0.059965 Batch F1: 1.0
Epoch:  345        6 Batch loss: 0.072822 Batch F1: 0.9523809523809523
Epoch:  345        7 Batch loss: 0.060191 Batch F1: 0.8750000000000001
Epoch:  345        8 Batch loss: 0.068008 Batch F1: 0.8571428571428571
Epoch:  345        9 Batch loss: 0.062055 Batch F1: 0.923076923076923
Epoch:  345       10 Batch loss: 0.080496 Batch F1: 0.18181818181818182
Epoch:  345       11 Batch loss: 0.089450 Batch F1: 0.47058823529411764
Epoch:  345       12 Batch loss: 0.070008 Batch F1: 0.9333333333333333
Train Avg Loss  345: 0.068694

Train Avg F1  345: 0.7679635587723822

Val Avg Loss  345: 0.061854

Val Avg F1  345:  0.9263574660633483

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 346
--------------------------------------------------------------
Epoch:  346        1 Batch loss: 0.069736 Batch F1: 1.0
Epoch:  346        2 Batch loss: 0.033430 Batch F1: 1.0
Epoch:  346        3 Batch loss: 0.061557 Batch F1: 0.9411764705882353
Epoch:  346        4 Batch loss: 0.054079 Batch F1: 1.0
Epoch:  346        5 Batch loss: 0.055583 Batch F1: 0.923076923076923
Epoch:  346        6 Batch loss: 0.081731 Batch F1: 0.625
Epoch:  346        7 Batch loss: 0.074552 Batch F1: 0.7499999999999999
Epoch:  346        8 Batch loss: 0.060637 Batch F1: 0.4444444444444445
Epoch:  346        9 Batch loss: 0.090317 Batch F1: 0.2857142857142857
Epoch:  346       10 Batch loss: 0.112948 Batch F1: 0.761904761904762
Epoch:  346       11 Batch loss: 0.075415 Batch F1: 0.9
Epoch:  346       12 Batch loss: 0.074140 Batch F1: 1.0
Train Avg Loss  346: 0.070344

Train Avg F1  346: 0.8026097404773876

Val Avg Loss  346: 0.065267

Val Avg F1  346:  0.924408950182944

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 347
--------------------------------------------------------------
Epoch:  347        1 Batch loss: 0.049536 Batch F1: 1.0
Epoch:  347        2 Batch loss: 0.058082 Batch F1: 0.9333333333333333
Epoch:  347        3 Batch loss: 0.076031 Batch F1: 0.9090909090909091
Epoch:  347        4 Batch loss: 0.078766 Batch F1: 0.7499999999999999
Epoch:  347        5 Batch loss: 0.077589 Batch F1: 0.625
Epoch:  347        6 Batch loss: 0.070068 Batch F1: 0.4
Epoch:  347        7 Batch loss: 0.062099 Batch F1: 0.5714285714285715
Epoch:  347        8 Batch loss: 0.070228 Batch F1: 0.0
Epoch:  347        9 Batch loss: 0.075790 Batch F1: 0.4
Epoch:  347       10 Batch loss: 0.076261 Batch F1: 0.6666666666666666
Epoch:  347       11 Batch loss: 0.067605 Batch F1: 0.923076923076923
Epoch:  347       12 Batch loss: 0.070036 Batch F1: 0.8333333333333333
Train Avg Loss  347: 0.069341

Train Avg F1  347: 0.6676608114108115

Val Avg Loss  347: 0.062536

Val Avg F1  347:  0.9160912190963342

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 348
--------------------------------------------------------------
Epoch:  348        1 Batch loss: 0.071673 Batch F1: 0.8
Epoch:  348        2 Batch loss: 0.060873 Batch F1: 0.8333333333333333
Epoch:  348        3 Batch loss: 0.072962 Batch F1: 0.9090909090909091
Epoch:  348        4 Batch loss: 0.064018 Batch F1: 0.9473684210526316
Epoch:  348        5 Batch loss: 0.068692 Batch F1: 0.9411764705882353
Epoch:  348        6 Batch loss: 0.075447 Batch F1: 0.9
Epoch:  348        7 Batch loss: 0.057448 Batch F1: 1.0
Epoch:  348        8 Batch loss: 0.067680 Batch F1: 1.0
Epoch:  348        9 Batch loss: 0.071242 Batch F1: 0.19999999999999998
Epoch:  348       10 Batch loss: 0.065098 Batch F1: 0.5
Epoch:  348       11 Batch loss: 0.063941 Batch F1: 0.3636363636363636
Epoch:  348       12 Batch loss: 0.076134 Batch F1: 0.6153846153846153
Train Avg Loss  348: 0.067934

Train Avg F1  348: 0.7508325094238407

Val Avg Loss  348: 0.062296

Val Avg F1  348:  0.5833333333333334

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 349
--------------------------------------------------------------
Epoch:  349        1 Batch loss: 0.064445 Batch F1: 0.6666666666666666
Epoch:  349        2 Batch loss: 0.100502 Batch F1: 0.5454545454545454
Epoch:  349        3 Batch loss: 0.055183 Batch F1: 0.7499999999999999
Epoch:  349        4 Batch loss: 0.064330 Batch F1: 0.8333333333333333
Epoch:  349        5 Batch loss: 0.080931 Batch F1: 0.8571428571428571
Epoch:  349        6 Batch loss: 0.063153 Batch F1: 0.9333333333333333
Epoch:  349        7 Batch loss: 0.053941 Batch F1: 0.888888888888889
Epoch:  349        8 Batch loss: 0.057135 Batch F1: 0.9411764705882353
Epoch:  349        9 Batch loss: 0.063726 Batch F1: 1.0
Epoch:  349       10 Batch loss: 0.089247 Batch F1: 0.9600000000000001
Epoch:  349       11 Batch loss: 0.053664 Batch F1: 1.0
Epoch:  349       12 Batch loss: 0.071786 Batch F1: 0.8571428571428571
Train Avg Loss  349: 0.068170

Train Avg F1  349: 0.8527615793792265

Val Avg Loss  349: 0.062209

Val Avg F1  349:  0.9052579365079365

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 350
--------------------------------------------------------------
Epoch:  350        1 Batch loss: 0.057542 Batch F1: 1.0
Epoch:  350        2 Batch loss: 0.062614 Batch F1: 0.8
Epoch:  350        3 Batch loss: 0.109629 Batch F1: 0.8333333333333333
Epoch:  350        4 Batch loss: 0.048946 Batch F1: 1.0
Epoch:  350        5 Batch loss: 0.056553 Batch F1: 1.0
Epoch:  350        6 Batch loss: 0.062198 Batch F1: 0.5714285714285715
Epoch:  350        7 Batch loss: 0.057703 Batch F1: 0.6666666666666666
Epoch:  350        8 Batch loss: 0.068062 Batch F1: 0.4
Epoch:  350        9 Batch loss: 0.070282 Batch F1: 0.4615384615384615
Epoch:  350       10 Batch loss: 0.073471 Batch F1: 0.888888888888889
Epoch:  350       11 Batch loss: 0.065137 Batch F1: 0.9473684210526316
Epoch:  350       12 Batch loss: 0.079093 Batch F1: 0.9411764705882353
Train Avg Loss  350: 0.067602

Train Avg F1  350: 0.7925334011247324

Val Avg Loss  350: 0.061735

Val Avg F1  350:  0.9164031620553359

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 351
--------------------------------------------------------------
Epoch:  351        1 Batch loss: 0.075412 Batch F1: 0.8235294117647058
Epoch:  351        2 Batch loss: 0.059698 Batch F1: 1.0
Epoch:  351        3 Batch loss: 0.063334 Batch F1: 1.0
Epoch:  351        4 Batch loss: 0.056626 Batch F1: 0.0
Epoch:  351        5 Batch loss: 0.070921 Batch F1: 0.0
Epoch:  351        6 Batch loss: 0.063628 Batch F1: 0.8571428571428571
Epoch:  351        7 Batch loss: 0.060623 Batch F1: 0.8333333333333333
Epoch:  351        8 Batch loss: 0.088376 Batch F1: 0.88
Epoch:  351        9 Batch loss: 0.068706 Batch F1: 1.0
Epoch:  351       10 Batch loss: 0.068362 Batch F1: 0.9411764705882353
Epoch:  351       11 Batch loss: 0.065887 Batch F1: 0.9473684210526316
Epoch:  351       12 Batch loss: 0.080231 Batch F1: 0.8
Train Avg Loss  351: 0.068484

Train Avg F1  351: 0.7568792078234803

Val Avg Loss  351: 0.061314

Val Avg F1  351:  0.9151785714285714

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 352
--------------------------------------------------------------
Epoch:  352        1 Batch loss: 0.073499 Batch F1: 1.0
Epoch:  352        2 Batch loss: 0.048825 Batch F1: 1.0
Epoch:  352        3 Batch loss: 0.050369 Batch F1: 0.9090909090909091
Epoch:  352        4 Batch loss: 0.075034 Batch F1: 0.888888888888889
Epoch:  352        5 Batch loss: 0.069731 Batch F1: 0.8750000000000001
Epoch:  352        6 Batch loss: 0.073109 Batch F1: 0.0
Epoch:  352        7 Batch loss: 0.060227 Batch F1: 0.5454545454545454
Epoch:  352        8 Batch loss: 0.096095 Batch F1: 0.15384615384615385
Epoch:  352        9 Batch loss: 0.058539 Batch F1: 0.7499999999999999
Epoch:  352       10 Batch loss: 0.053217 Batch F1: 0.6666666666666666
Epoch:  352       11 Batch loss: 0.087547 Batch F1: 0.3076923076923077
Epoch:  352       12 Batch loss: 0.062665 Batch F1: 0.9090909090909091
Train Avg Loss  352: 0.067405

Train Avg F1  352: 0.6671441983941985

Val Avg Loss  352: 0.061361

Val Avg F1  352:  0.9236111111111112

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 353
--------------------------------------------------------------
Epoch:  353        1 Batch loss: 0.065360 Batch F1: 0.8
Epoch:  353        2 Batch loss: 0.066512 Batch F1: 0.625
Epoch:  353        3 Batch loss: 0.081802 Batch F1: 0.5333333333333333
Epoch:  353        4 Batch loss: 0.069857 Batch F1: 0.3636363636363636
Epoch:  353        5 Batch loss: 0.068554 Batch F1: 0.625
Epoch:  353        6 Batch loss: 0.052654 Batch F1: 0.888888888888889
Epoch:  353        7 Batch loss: 0.065984 Batch F1: 0.9473684210526316
Epoch:  353        8 Batch loss: 0.059594 Batch F1: 0.9090909090909091
Epoch:  353        9 Batch loss: 0.074120 Batch F1: 0.42857142857142855
Epoch:  353       10 Batch loss: 0.060059 Batch F1: 0.0
Epoch:  353       11 Batch loss: 0.067054 Batch F1: 0.7368421052631579
Epoch:  353       12 Batch loss: 0.080586 Batch F1: 0.33333333333333337
Train Avg Loss  353: 0.067678

Train Avg F1  353: 0.5992553985975039

Val Avg Loss  353: 0.061674

Val Avg F1  353:  0.9

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 354
--------------------------------------------------------------
Epoch:  354        1 Batch loss: 0.067542 Batch F1: 0.9473684210526316
Epoch:  354        2 Batch loss: 0.059871 Batch F1: 0.8750000000000001
Epoch:  354        3 Batch loss: 0.060220 Batch F1: 0.8750000000000001
Epoch:  354        4 Batch loss: 0.051449 Batch F1: 1.0
Epoch:  354        5 Batch loss: 0.068067 Batch F1: 0.7692307692307693
Epoch:  354        6 Batch loss: 0.074275 Batch F1: 0.9473684210526316
Epoch:  354        7 Batch loss: 0.068552 Batch F1: 0.9090909090909091
Epoch:  354        8 Batch loss: 0.067352 Batch F1: 1.0
Epoch:  354        9 Batch loss: 0.073717 Batch F1: 0.9473684210526316
Epoch:  354       10 Batch loss: 0.100658 Batch F1: 0.47619047619047616
Epoch:  354       11 Batch loss: 0.061124 Batch F1: 0.7499999999999999
Epoch:  354       12 Batch loss: 0.064582 Batch F1: 0.9411764705882353
Train Avg Loss  354: 0.068117

Train Avg F1  354: 0.8698161573548572

Val Avg Loss  354: 0.061943

Val Avg F1  354:  0.9235119047619049

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 355
--------------------------------------------------------------
Epoch:  355        1 Batch loss: 0.056839 Batch F1: 0.923076923076923
Epoch:  355        2 Batch loss: 0.081463 Batch F1: 0.8571428571428571
Epoch:  355        3 Batch loss: 0.057663 Batch F1: 1.0
Epoch:  355        4 Batch loss: 0.070271 Batch F1: 0.888888888888889
Epoch:  355        5 Batch loss: 0.064874 Batch F1: 0.9473684210526316
Epoch:  355        6 Batch loss: 0.066097 Batch F1: 0.9411764705882353
Epoch:  355        7 Batch loss: 0.070261 Batch F1: 0.9523809523809523
Epoch:  355        8 Batch loss: 0.060892 Batch F1: 0.8750000000000001
Epoch:  355        9 Batch loss: 0.072859 Batch F1: 0.9333333333333333
Epoch:  355       10 Batch loss: 0.074720 Batch F1: 0.9565217391304348
Epoch:  355       11 Batch loss: 0.058029 Batch F1: 0.7499999999999999
Epoch:  355       12 Batch loss: 0.072600 Batch F1: 0.923076923076923
Train Avg Loss  355: 0.067214

Train Avg F1  355: 0.912330542389265

Val Avg Loss  355: 0.062152

Val Avg F1  355:  0.5015182186234818

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 356
--------------------------------------------------------------
Epoch:  356        1 Batch loss: 0.047174 Batch F1: 0.6
Epoch:  356        2 Batch loss: 0.099770 Batch F1: 0.14285714285714288
Epoch:  356        3 Batch loss: 0.086202 Batch F1: 0.5882352941176471
Epoch:  356        4 Batch loss: 0.071225 Batch F1: 0.6666666666666666
Epoch:  356        5 Batch loss: 0.066847 Batch F1: 0.9
Epoch:  356        6 Batch loss: 0.057164 Batch F1: 1.0
Epoch:  356        7 Batch loss: 0.052958 Batch F1: 1.0
Epoch:  356        8 Batch loss: 0.059410 Batch F1: 0.7272727272727273
Epoch:  356        9 Batch loss: 0.082064 Batch F1: 0.2222222222222222
Epoch:  356       10 Batch loss: 0.081847 Batch F1: 0.47058823529411764
Epoch:  356       11 Batch loss: 0.056251 Batch F1: 1.0
Epoch:  356       12 Batch loss: 0.065875 Batch F1: 0.8750000000000001
Train Avg Loss  356: 0.068899

Train Avg F1  356: 0.6827368573692104

Val Avg Loss  356: 0.065556

Val Avg F1  356:  0.9246411483253589

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 357
--------------------------------------------------------------
Epoch:  357        1 Batch loss: 0.085765 Batch F1: 0.7142857142857143
Epoch:  357        2 Batch loss: 0.066477 Batch F1: 1.0
Epoch:  357        3 Batch loss: 0.057541 Batch F1: 0.5
Epoch:  357        4 Batch loss: 0.048223 Batch F1: 0.4
Epoch:  357        5 Batch loss: 0.111032 Batch F1: 0.0
Epoch:  357        6 Batch loss: 0.081745 Batch F1: 0.4615384615384615
Epoch:  357        7 Batch loss: 0.086650 Batch F1: 0.8695652173913044
Epoch:  357        8 Batch loss: 0.060060 Batch F1: 0.9523809523809523
Epoch:  357        9 Batch loss: 0.051870 Batch F1: 0.8333333333333333
Epoch:  357       10 Batch loss: 0.088758 Batch F1: 0.5333333333333333
Epoch:  357       11 Batch loss: 0.081107 Batch F1: 0.6153846153846153
Epoch:  357       12 Batch loss: 0.082321 Batch F1: 1.0
Train Avg Loss  357: 0.075129

Train Avg F1  357: 0.6566518023039761

Val Avg Loss  357: 0.070320

Val Avg F1  357:  0.9224481658692185

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 358
--------------------------------------------------------------
Epoch:  358        1 Batch loss: 0.081278 Batch F1: 0.9473684210526316
Epoch:  358        2 Batch loss: 0.086184 Batch F1: 0.8571428571428571
Epoch:  358        3 Batch loss: 0.070957 Batch F1: 1.0
Epoch:  358        4 Batch loss: 0.064085 Batch F1: 0.5
Epoch:  358        5 Batch loss: 0.075963 Batch F1: 0.4615384615384615
Epoch:  358        6 Batch loss: 0.075773 Batch F1: 0.2222222222222222
Epoch:  358        7 Batch loss: 0.098221 Batch F1: 0.5
Epoch:  358        8 Batch loss: 0.079947 Batch F1: 0.9
Epoch:  358        9 Batch loss: 0.071406 Batch F1: 1.0
Epoch:  358       10 Batch loss: 0.060941 Batch F1: 0.8750000000000001
Epoch:  358       11 Batch loss: 0.082493 Batch F1: 0.7999999999999999
Epoch:  358       12 Batch loss: 0.052227 Batch F1: 0.5714285714285715
Train Avg Loss  358: 0.074956

Train Avg F1  358: 0.7195583777820621

Val Avg Loss  358: 0.069451

Val Avg F1  358:  0.5604166666666667

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 359
--------------------------------------------------------------
Epoch:  359        1 Batch loss: 0.085982 Batch F1: 0.19999999999999998
Epoch:  359        2 Batch loss: 0.077189 Batch F1: 0.4615384615384615
Epoch:  359        3 Batch loss: 0.045918 Batch F1: 0.8333333333333333
Epoch:  359        4 Batch loss: 0.078088 Batch F1: 0.47058823529411764
Epoch:  359        5 Batch loss: 0.069727 Batch F1: 0.888888888888889
Epoch:  359        6 Batch loss: 0.072720 Batch F1: 0.9411764705882353
Epoch:  359        7 Batch loss: 0.070299 Batch F1: 0.8
Epoch:  359        8 Batch loss: 0.062697 Batch F1: 0.4444444444444445
Epoch:  359        9 Batch loss: 0.065472 Batch F1: 0.5
Epoch:  359       10 Batch loss: 0.076062 Batch F1: 0.5714285714285715
Epoch:  359       11 Batch loss: 0.083001 Batch F1: 0.9
Epoch:  359       12 Batch loss: 0.065875 Batch F1: 0.8333333333333333
Train Avg Loss  359: 0.071086

Train Avg F1  359: 0.6537276449041155

Val Avg Loss  359: 0.063409

Val Avg F1  359:  0.9162663398692812

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 360
--------------------------------------------------------------
Epoch:  360        1 Batch loss: 0.076054 Batch F1: 0.8
Epoch:  360        2 Batch loss: 0.081867 Batch F1: 0.9565217391304348
Epoch:  360        3 Batch loss: 0.070795 Batch F1: 0.8750000000000001
Epoch:  360        4 Batch loss: 0.075443 Batch F1: 0.888888888888889
Epoch:  360        5 Batch loss: 0.075425 Batch F1: 1.0
Epoch:  360        6 Batch loss: 0.069718 Batch F1: 0.8235294117647058
Epoch:  360        7 Batch loss: 0.073283 Batch F1: 0.9333333333333333
Epoch:  360        8 Batch loss: 0.056603 Batch F1: 1.0
Epoch:  360        9 Batch loss: 0.075429 Batch F1: 0.9473684210526316
Epoch:  360       10 Batch loss: 0.053689 Batch F1: 1.0
Epoch:  360       11 Batch loss: 0.050192 Batch F1: 0.6666666666666666
Epoch:  360       12 Batch loss: 0.057818 Batch F1: 0.5714285714285715
Train Avg Loss  360: 0.068027

Train Avg F1  360: 0.8718947526887693

Val Avg Loss  360: 0.067396

Val Avg F1  360:  0.5866192630898514

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 361
--------------------------------------------------------------
Epoch:  361        1 Batch loss: 0.056416 Batch F1: 0.0
Epoch:  361        2 Batch loss: 0.099104 Batch F1: 0.5555555555555556
Epoch:  361        3 Batch loss: 0.052596 Batch F1: 0.8
Epoch:  361        4 Batch loss: 0.056113 Batch F1: 0.9090909090909091
Epoch:  361        5 Batch loss: 0.067091 Batch F1: 0.7692307692307693
Epoch:  361        6 Batch loss: 0.085448 Batch F1: 0.9655172413793104
Epoch:  361        7 Batch loss: 0.066842 Batch F1: 0.9090909090909091
Epoch:  361        8 Batch loss: 0.075237 Batch F1: 0.888888888888889
Epoch:  361        9 Batch loss: 0.079215 Batch F1: 0.9166666666666666
Epoch:  361       10 Batch loss: 0.045719 Batch F1: 1.0
Epoch:  361       11 Batch loss: 0.070717 Batch F1: 0.888888888888889
Epoch:  361       12 Batch loss: 0.077556 Batch F1: 0.9333333333333333
Train Avg Loss  361: 0.069338

Train Avg F1  361: 0.7946885968437694

Val Avg Loss  361: 0.062358

Val Avg F1  361:  0.9216311724051662

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 362
--------------------------------------------------------------
Epoch:  362        1 Batch loss: 0.065035 Batch F1: 0.8333333333333333
Epoch:  362        2 Batch loss: 0.076877 Batch F1: 0.782608695652174
Epoch:  362        3 Batch loss: 0.051954 Batch F1: 1.0
Epoch:  362        4 Batch loss: 0.070211 Batch F1: 0.9333333333333333
Epoch:  362        5 Batch loss: 0.057012 Batch F1: 1.0
Epoch:  362        6 Batch loss: 0.060255 Batch F1: 0.923076923076923
Epoch:  362        7 Batch loss: 0.086523 Batch F1: 0.8571428571428571
Epoch:  362        8 Batch loss: 0.095152 Batch F1: 0.7777777777777778
Epoch:  362        9 Batch loss: 0.068229 Batch F1: 1.0
Epoch:  362       10 Batch loss: 0.076407 Batch F1: 1.0
Epoch:  362       11 Batch loss: 0.056383 Batch F1: 0.7272727272727273
Epoch:  362       12 Batch loss: 0.062621 Batch F1: 0.9090909090909091
Train Avg Loss  362: 0.068888

Train Avg F1  362: 0.8953030463900027

Val Avg Loss  362: 0.061563

Val Avg F1  362:  0.9255952380952381

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 363
--------------------------------------------------------------
Epoch:  363        1 Batch loss: 0.077449 Batch F1: 0.9090909090909091
Epoch:  363        2 Batch loss: 0.057262 Batch F1: 0.923076923076923
Epoch:  363        3 Batch loss: 0.058527 Batch F1: 1.0
Epoch:  363        4 Batch loss: 0.061497 Batch F1: 0.8571428571428571
Epoch:  363        5 Batch loss: 0.066545 Batch F1: 0.888888888888889
Epoch:  363        6 Batch loss: 0.085723 Batch F1: 0.88
Epoch:  363        7 Batch loss: 0.057005 Batch F1: 1.0
Epoch:  363        8 Batch loss: 0.075905 Batch F1: 0.9473684210526316
Epoch:  363        9 Batch loss: 0.058675 Batch F1: 0.923076923076923
Epoch:  363       10 Batch loss: 0.040012 Batch F1: 0.7499999999999999
Epoch:  363       11 Batch loss: 0.115014 Batch F1: 0.23529411764705882
Epoch:  363       12 Batch loss: 0.055483 Batch F1: 0.0
Train Avg Loss  363: 0.067425

Train Avg F1  363: 0.7761615866646826

Val Avg Loss  363: 0.062599

Val Avg F1  363:  0.5854707792207793

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 364
--------------------------------------------------------------
Epoch:  364        1 Batch loss: 0.046951 Batch F1: 0.9090909090909091
Epoch:  364        2 Batch loss: 0.072785 Batch F1: 0.33333333333333337
Epoch:  364        3 Batch loss: 0.055504 Batch F1: 0.5454545454545454
Epoch:  364        4 Batch loss: 0.084126 Batch F1: 0.5263157894736842
Epoch:  364        5 Batch loss: 0.071534 Batch F1: 0.5
Epoch:  364        6 Batch loss: 0.093115 Batch F1: 0.888888888888889
Epoch:  364        7 Batch loss: 0.070394 Batch F1: 0.8
Epoch:  364        8 Batch loss: 0.053312 Batch F1: 1.0
Epoch:  364        9 Batch loss: 0.072548 Batch F1: 0.9523809523809523
Epoch:  364       10 Batch loss: 0.082765 Batch F1: 0.8571428571428571
Epoch:  364       11 Batch loss: 0.064408 Batch F1: 0.8
Epoch:  364       12 Batch loss: 0.052002 Batch F1: 0.9090909090909091
Train Avg Loss  364: 0.068287

Train Avg F1  364: 0.7518081820713399

Val Avg Loss  364: 0.061518

Val Avg F1  364:  0.9303490627020039

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 365
--------------------------------------------------------------
Epoch:  365        1 Batch loss: 0.066721 Batch F1: 1.0
Epoch:  365        2 Batch loss: 0.057657 Batch F1: 1.0
Epoch:  365        3 Batch loss: 0.097387 Batch F1: 0.923076923076923
Epoch:  365        4 Batch loss: 0.079648 Batch F1: 0.9090909090909091
Epoch:  365        5 Batch loss: 0.079602 Batch F1: 0.9
Epoch:  365        6 Batch loss: 0.048144 Batch F1: 0.888888888888889
Epoch:  365        7 Batch loss: 0.072734 Batch F1: 0.8333333333333333
Epoch:  365        8 Batch loss: 0.059130 Batch F1: 1.0
Epoch:  365        9 Batch loss: 0.061066 Batch F1: 0.8333333333333333
Epoch:  365       10 Batch loss: 0.067820 Batch F1: 0.9411764705882353
Epoch:  365       11 Batch loss: 0.066160 Batch F1: 0.888888888888889
Epoch:  365       12 Batch loss: 0.057357 Batch F1: 0.4
Train Avg Loss  365: 0.067786

Train Avg F1  365: 0.8764823956000427

Val Avg Loss  365: 0.062833

Val Avg F1  365:  0.5777777777777778

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 366
--------------------------------------------------------------
Epoch:  366        1 Batch loss: 0.072225 Batch F1: 0.2222222222222222
Epoch:  366        2 Batch loss: 0.067459 Batch F1: 0.0
Epoch:  366        3 Batch loss: 0.053715 Batch F1: 0.6
Epoch:  366        4 Batch loss: 0.100541 Batch F1: 0.4210526315789474
Epoch:  366        5 Batch loss: 0.087178 Batch F1: 0.5
Epoch:  366        6 Batch loss: 0.084647 Batch F1: 1.0
Epoch:  366        7 Batch loss: 0.069468 Batch F1: 1.0
Epoch:  366        8 Batch loss: 0.060369 Batch F1: 1.0
Epoch:  366        9 Batch loss: 0.071315 Batch F1: 1.0
Epoch:  366       10 Batch loss: 0.059276 Batch F1: 0.8571428571428571
Epoch:  366       11 Batch loss: 0.054942 Batch F1: 0.0
Epoch:  366       12 Batch loss: 0.075825 Batch F1: 0.0
Train Avg Loss  366: 0.071413

Train Avg F1  366: 0.5500348092453355

Val Avg Loss  366: 0.078109

Val Avg F1  366:  0.0

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 367
--------------------------------------------------------------
Epoch:  367        1 Batch loss: 0.090115 Batch F1: 0.0
Epoch:  367        2 Batch loss: 0.080719 Batch F1: 0.7058823529411764
Epoch:  367        3 Batch loss: 0.079114 Batch F1: 0.8695652173913044
Epoch:  367        4 Batch loss: 0.116266 Batch F1: 0.7142857142857143
Epoch:  367        5 Batch loss: 0.078526 Batch F1: 0.5
Epoch:  367        6 Batch loss: 0.045538 Batch F1: 0.0
Epoch:  367        7 Batch loss: 0.170759 Batch F1: 0.0
Epoch:  367        8 Batch loss: 0.087279 Batch F1: 0.0
Epoch:  367        9 Batch loss: 0.078327 Batch F1: 0.5
Epoch:  367       10 Batch loss: 0.087002 Batch F1: 1.0
Epoch:  367       11 Batch loss: 0.050487 Batch F1: 0.7499999999999999
Epoch:  367       12 Batch loss: 0.067072 Batch F1: 0.5
Train Avg Loss  367: 0.085934

Train Avg F1  367: 0.46164444038484964

Val Avg Loss  367: 0.091446

Val Avg F1  367:  0.0

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 368
--------------------------------------------------------------
Epoch:  368        1 Batch loss: 0.125890 Batch F1: 0.0
Epoch:  368        2 Batch loss: 0.095369 Batch F1: 0.42857142857142855
Epoch:  368        3 Batch loss: 0.065111 Batch F1: 0.4
Epoch:  368        4 Batch loss: 0.079229 Batch F1: 0.9333333333333333
Epoch:  368        5 Batch loss: 0.059257 Batch F1: 0.6
Epoch:  368        6 Batch loss: 0.065848 Batch F1: 0.7272727272727273
Epoch:  368        7 Batch loss: 0.056461 Batch F1: 0.6666666666666666
Epoch:  368        8 Batch loss: 0.090497 Batch F1: 0.2857142857142857
Epoch:  368        9 Batch loss: 0.071192 Batch F1: 0.0
Epoch:  368       10 Batch loss: 0.080526 Batch F1: 0.9166666666666666
Epoch:  368       11 Batch loss: 0.062325 Batch F1: 0.9523809523809523
Epoch:  368       12 Batch loss: 0.071864 Batch F1: 0.923076923076923
Train Avg Loss  368: 0.076964

Train Avg F1  368: 0.569473581973582

Val Avg Loss  368: 0.070034

Val Avg F1  368:  0.902685421994885

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 369
--------------------------------------------------------------
Epoch:  369        1 Batch loss: 0.067416 Batch F1: 0.923076923076923
Epoch:  369        2 Batch loss: 0.087370 Batch F1: 0.8235294117647058
Epoch:  369        3 Batch loss: 0.061457 Batch F1: 0.9333333333333333
Epoch:  369        4 Batch loss: 0.054600 Batch F1: 0.7499999999999999
Epoch:  369        5 Batch loss: 0.046238 Batch F1: 0.6666666666666666
Epoch:  369        6 Batch loss: 0.072691 Batch F1: 0.5
Epoch:  369        7 Batch loss: 0.106181 Batch F1: 0.16666666666666669
Epoch:  369        8 Batch loss: 0.044641 Batch F1: 0.5714285714285715
Epoch:  369        9 Batch loss: 0.085331 Batch F1: 0.5714285714285715
Epoch:  369       10 Batch loss: 0.099685 Batch F1: 0.4444444444444445
Epoch:  369       11 Batch loss: 0.078627 Batch F1: 0.9565217391304348
Epoch:  369       12 Batch loss: 0.076158 Batch F1: 0.9523809523809523
Train Avg Loss  369: 0.073366

Train Avg F1  369: 0.6882897733601059

Val Avg Loss  369: 0.067700

Val Avg F1  369:  0.9256410256410257

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 370
--------------------------------------------------------------
Epoch:  370        1 Batch loss: 0.075446 Batch F1: 0.9473684210526316
Epoch:  370        2 Batch loss: 0.075440 Batch F1: 0.8750000000000001
Epoch:  370        3 Batch loss: 0.072383 Batch F1: 0.9333333333333333
Epoch:  370        4 Batch loss: 0.074733 Batch F1: 0.888888888888889
Epoch:  370        5 Batch loss: 0.065106 Batch F1: 0.9523809523809523
Epoch:  370        6 Batch loss: 0.067335 Batch F1: 0.7499999999999999
Epoch:  370        7 Batch loss: 0.062045 Batch F1: 1.0
Epoch:  370        8 Batch loss: 0.058870 Batch F1: 0.4
Epoch:  370        9 Batch loss: 0.077154 Batch F1: 0.5454545454545454
Epoch:  370       10 Batch loss: 0.081479 Batch F1: 0.5333333333333333
Epoch:  370       11 Batch loss: 0.088945 Batch F1: 0.2857142857142857
Epoch:  370       12 Batch loss: 0.085727 Batch F1: 0.9411764705882353
Train Avg Loss  370: 0.073722

Train Avg F1  370: 0.7543875192288506

Val Avg Loss  370: 0.066989

Val Avg F1  370:  0.9137806637806638

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 371
--------------------------------------------------------------
Epoch:  371        1 Batch loss: 0.066069 Batch F1: 0.9333333333333333
Epoch:  371        2 Batch loss: 0.055913 Batch F1: 0.7499999999999999
Epoch:  371        3 Batch loss: 0.061804 Batch F1: 1.0
Epoch:  371        4 Batch loss: 0.070430 Batch F1: 0.9333333333333333
Epoch:  371        5 Batch loss: 0.060729 Batch F1: 0.9333333333333333
Epoch:  371        6 Batch loss: 0.075951 Batch F1: 0.9473684210526316
Epoch:  371        7 Batch loss: 0.069371 Batch F1: 0.8571428571428571
Epoch:  371        8 Batch loss: 0.065967 Batch F1: 0.6153846153846153
Epoch:  371        9 Batch loss: 0.115984 Batch F1: 0.25
Epoch:  371       10 Batch loss: 0.078252 Batch F1: 0.6666666666666666
Epoch:  371       11 Batch loss: 0.068773 Batch F1: 0.9333333333333333
Epoch:  371       12 Batch loss: 0.066437 Batch F1: 0.8333333333333333
Train Avg Loss  371: 0.071307

Train Avg F1  371: 0.8044357689094531

Val Avg Loss  371: 0.065797

Val Avg F1  371:  0.9209600706311232

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 372
--------------------------------------------------------------
Epoch:  372        1 Batch loss: 0.056407 Batch F1: 1.0
Epoch:  372        2 Batch loss: 0.070420 Batch F1: 1.0
Epoch:  372        3 Batch loss: 0.063087 Batch F1: 1.0
Epoch:  372        4 Batch loss: 0.096808 Batch F1: 0.5555555555555556
Epoch:  372        5 Batch loss: 0.066875 Batch F1: 0.5454545454545454
Epoch:  372        6 Batch loss: 0.059326 Batch F1: 0.0
Epoch:  372        7 Batch loss: 0.089326 Batch F1: 0.5882352941176471
Epoch:  372        8 Batch loss: 0.061642 Batch F1: 0.4
Epoch:  372        9 Batch loss: 0.054131 Batch F1: 0.0
Epoch:  372       10 Batch loss: 0.080567 Batch F1: 0.5333333333333333
Epoch:  372       11 Batch loss: 0.065747 Batch F1: 0.9565217391304348
Epoch:  372       12 Batch loss: 0.087190 Batch F1: 0.9
Train Avg Loss  372: 0.070960

Train Avg F1  372: 0.6232583722992929

Val Avg Loss  372: 0.063326

Val Avg F1  372:  0.9278143274853803

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 373
--------------------------------------------------------------
Epoch:  373        1 Batch loss: 0.053747 Batch F1: 1.0
Epoch:  373        2 Batch loss: 0.081028 Batch F1: 0.7142857142857143
Epoch:  373        3 Batch loss: 0.060198 Batch F1: 0.8333333333333333
Epoch:  373        4 Batch loss: 0.091520 Batch F1: 0.8421052631578948
Epoch:  373        5 Batch loss: 0.075352 Batch F1: 0.9473684210526316
Epoch:  373        6 Batch loss: 0.082710 Batch F1: 0.923076923076923
Epoch:  373        7 Batch loss: 0.044287 Batch F1: 1.0
Epoch:  373        8 Batch loss: 0.065069 Batch F1: 0.923076923076923
Epoch:  373        9 Batch loss: 0.084521 Batch F1: 0.9600000000000001
Epoch:  373       10 Batch loss: 0.061430 Batch F1: 0.9333333333333333
Epoch:  373       11 Batch loss: 0.050864 Batch F1: 1.0
Epoch:  373       12 Batch loss: 0.082478 Batch F1: 0.5882352941176471
Train Avg Loss  373: 0.069434

Train Avg F1  373: 0.8887346004528668

Val Avg Loss  373: 0.063216

Val Avg F1  373:  0.5966346153846154

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 374
--------------------------------------------------------------
Epoch:  374        1 Batch loss: 0.061070 Batch F1: 0.5
Epoch:  374        2 Batch loss: 0.079832 Batch F1: 0.5
Epoch:  374        3 Batch loss: 0.074024 Batch F1: 0.5714285714285715
Epoch:  374        4 Batch loss: 0.040488 Batch F1: 0.4
Epoch:  374        5 Batch loss: 0.081533 Batch F1: 0.6666666666666666
Epoch:  374        6 Batch loss: 0.082965 Batch F1: 0.9600000000000001
Epoch:  374        7 Batch loss: 0.055722 Batch F1: 0.9333333333333333
Epoch:  374        8 Batch loss: 0.067443 Batch F1: 0.9333333333333333
Epoch:  374        9 Batch loss: 0.062410 Batch F1: 0.8750000000000001
Epoch:  374       10 Batch loss: 0.087683 Batch F1: 0.9523809523809523
Epoch:  374       11 Batch loss: 0.060734 Batch F1: 1.0
Epoch:  374       12 Batch loss: 0.064303 Batch F1: 0.888888888888889
Train Avg Loss  374: 0.068184

Train Avg F1  374: 0.7650859788359788

Val Avg Loss  374: 0.061561

Val Avg F1  374:  0.9211309523809523

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 375
--------------------------------------------------------------
Epoch:  375        1 Batch loss: 0.068100 Batch F1: 0.8571428571428571
Epoch:  375        2 Batch loss: 0.050976 Batch F1: 0.9090909090909091
Epoch:  375        3 Batch loss: 0.061192 Batch F1: 0.4444444444444445
Epoch:  375        4 Batch loss: 0.058900 Batch F1: 0.7142857142857143
Epoch:  375        5 Batch loss: 0.061767 Batch F1: 0.5454545454545454
Epoch:  375        6 Batch loss: 0.094862 Batch F1: 0.47058823529411764
Epoch:  375        7 Batch loss: 0.078339 Batch F1: 0.19999999999999998
Epoch:  375        8 Batch loss: 0.055868 Batch F1: 0.6666666666666666
Epoch:  375        9 Batch loss: 0.100799 Batch F1: 0.38095238095238093
Epoch:  375       10 Batch loss: 0.067435 Batch F1: 0.7692307692307693
Epoch:  375       11 Batch loss: 0.058904 Batch F1: 0.923076923076923
Epoch:  375       12 Batch loss: 0.064580 Batch F1: 0.9333333333333333
Train Avg Loss  375: 0.068477

Train Avg F1  375: 0.6511888982477217

Val Avg Loss  375: 0.063667

Val Avg F1  375:  0.9251276759016697

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 376
--------------------------------------------------------------
Epoch:  376        1 Batch loss: 0.083915 Batch F1: 0.9090909090909091
Epoch:  376        2 Batch loss: 0.070122 Batch F1: 0.888888888888889
Epoch:  376        3 Batch loss: 0.066293 Batch F1: 0.9523809523809523
Epoch:  376        4 Batch loss: 0.062912 Batch F1: 0.923076923076923
Epoch:  376        5 Batch loss: 0.066102 Batch F1: 0.8750000000000001
Epoch:  376        6 Batch loss: 0.062389 Batch F1: 0.9333333333333333
Epoch:  376        7 Batch loss: 0.067140 Batch F1: 0.8750000000000001
Epoch:  376        8 Batch loss: 0.066369 Batch F1: 0.9411764705882353
Epoch:  376        9 Batch loss: 0.067574 Batch F1: 0.9333333333333333
Epoch:  376       10 Batch loss: 0.064859 Batch F1: 0.6153846153846153
Epoch:  376       11 Batch loss: 0.079118 Batch F1: 0.19999999999999998
Epoch:  376       12 Batch loss: 0.058998 Batch F1: 0.8333333333333333
Train Avg Loss  376: 0.067983

Train Avg F1  376: 0.823333229950877

Val Avg Loss  376: 0.063003

Val Avg F1  376:  0.5824175824175823

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 377
--------------------------------------------------------------
Epoch:  377        1 Batch loss: 0.062457 Batch F1: 0.7142857142857143
Epoch:  377        2 Batch loss: 0.064116 Batch F1: 0.4
Epoch:  377        3 Batch loss: 0.081884 Batch F1: 0.42857142857142855
Epoch:  377        4 Batch loss: 0.068489 Batch F1: 0.8
Epoch:  377        5 Batch loss: 0.043905 Batch F1: 1.0
Epoch:  377        6 Batch loss: 0.059621 Batch F1: 0.923076923076923
Epoch:  377        7 Batch loss: 0.082757 Batch F1: 0.962962962962963
Epoch:  377        8 Batch loss: 0.063500 Batch F1: 0.923076923076923
Epoch:  377        9 Batch loss: 0.092636 Batch F1: 0.8
Epoch:  377       10 Batch loss: 0.065442 Batch F1: 0.8750000000000001
Epoch:  377       11 Batch loss: 0.058233 Batch F1: 0.923076923076923
Epoch:  377       12 Batch loss: 0.070573 Batch F1: 0.8333333333333333
Train Avg Loss  377: 0.067801

Train Avg F1  377: 0.7986153506986841

Val Avg Loss  377: 0.061416

Val Avg F1  377:  0.9304259813413132

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 378
--------------------------------------------------------------
Epoch:  378        1 Batch loss: 0.050815 Batch F1: 0.6666666666666666
Epoch:  378        2 Batch loss: 0.074231 Batch F1: 0.9565217391304348
Epoch:  378        3 Batch loss: 0.075317 Batch F1: 0.9411764705882353
Epoch:  378        4 Batch loss: 0.069344 Batch F1: 0.9565217391304348
Epoch:  378        5 Batch loss: 0.065166 Batch F1: 0.8571428571428571
Epoch:  378        6 Batch loss: 0.076027 Batch F1: 0.9166666666666666
Epoch:  378        7 Batch loss: 0.057039 Batch F1: 0.9090909090909091
Epoch:  378        8 Batch loss: 0.073232 Batch F1: 0.9473684210526316
Epoch:  378        9 Batch loss: 0.065247 Batch F1: 0.923076923076923
Epoch:  378       10 Batch loss: 0.076035 Batch F1: 0.9090909090909091
Epoch:  378       11 Batch loss: 0.057610 Batch F1: 0.9333333333333333
Epoch:  378       12 Batch loss: 0.070329 Batch F1: 0.923076923076923
Train Avg Loss  378: 0.067533

Train Avg F1  378: 0.9033111298372437

Val Avg Loss  378: 0.061440

Val Avg F1  378:  0.9295454545454546

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 379
--------------------------------------------------------------
Epoch:  379        1 Batch loss: 0.058143 Batch F1: 1.0
Epoch:  379        2 Batch loss: 0.049934 Batch F1: 0.7272727272727273
Epoch:  379        3 Batch loss: 0.078775 Batch F1: 0.6666666666666666
Epoch:  379        4 Batch loss: 0.073275 Batch F1: 0.0
Epoch:  379        5 Batch loss: 0.066353 Batch F1: 0.6666666666666666
Epoch:  379        6 Batch loss: 0.070747 Batch F1: 0.5
Epoch:  379        7 Batch loss: 0.075654 Batch F1: 0.8750000000000001
Epoch:  379        8 Batch loss: 0.057270 Batch F1: 1.0
Epoch:  379        9 Batch loss: 0.049853 Batch F1: 0.923076923076923
Epoch:  379       10 Batch loss: 0.087952 Batch F1: 0.88
Epoch:  379       11 Batch loss: 0.064632 Batch F1: 1.0
Epoch:  379       12 Batch loss: 0.077216 Batch F1: 0.888888888888889
Train Avg Loss  379: 0.067484

Train Avg F1  379: 0.7606309893809895

Val Avg Loss  379: 0.061315

Val Avg F1  379:  0.9272727272727272

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 380
--------------------------------------------------------------
Epoch:  380        1 Batch loss: 0.052131 Batch F1: 0.8
Epoch:  380        2 Batch loss: 0.058765 Batch F1: 1.0
Epoch:  380        3 Batch loss: 0.059270 Batch F1: 1.0
Epoch:  380        4 Batch loss: 0.070479 Batch F1: 0.8750000000000001
Epoch:  380        5 Batch loss: 0.065774 Batch F1: 0.5454545454545454
Epoch:  380        6 Batch loss: 0.086129 Batch F1: 0.7000000000000001
Epoch:  380        7 Batch loss: 0.068594 Batch F1: 0.5714285714285715
Epoch:  380        8 Batch loss: 0.071003 Batch F1: 0.4615384615384615
Epoch:  380        9 Batch loss: 0.070714 Batch F1: 0.3076923076923077
Epoch:  380       10 Batch loss: 0.082306 Batch F1: 0.8571428571428571
Epoch:  380       11 Batch loss: 0.058231 Batch F1: 0.9090909090909091
Epoch:  380       12 Batch loss: 0.076956 Batch F1: 0.9
Train Avg Loss  380: 0.068363

Train Avg F1  380: 0.7439456376956377

Val Avg Loss  380: 0.063146

Val Avg F1  380:  0.9160633484162897

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 381
--------------------------------------------------------------
Epoch:  381        1 Batch loss: 0.073380 Batch F1: 0.9473684210526316
Epoch:  381        2 Batch loss: 0.055031 Batch F1: 1.0
Epoch:  381        3 Batch loss: 0.063981 Batch F1: 0.9333333333333333
Epoch:  381        4 Batch loss: 0.086527 Batch F1: 0.8571428571428571
Epoch:  381        5 Batch loss: 0.056777 Batch F1: 0.7499999999999999
Epoch:  381        6 Batch loss: 0.075744 Batch F1: 0.8750000000000001
Epoch:  381        7 Batch loss: 0.087734 Batch F1: 0.8695652173913044
Epoch:  381        8 Batch loss: 0.080381 Batch F1: 0.9090909090909091
Epoch:  381        9 Batch loss: 0.049168 Batch F1: 1.0
Epoch:  381       10 Batch loss: 0.050796 Batch F1: 0.6666666666666666
Epoch:  381       11 Batch loss: 0.084733 Batch F1: 0.4444444444444445
Epoch:  381       12 Batch loss: 0.054223 Batch F1: 0.6666666666666666
Train Avg Loss  381: 0.068206

Train Avg F1  381: 0.8266065429824011

Val Avg Loss  381: 0.062388

Val Avg F1  381:  0.5503108003108003

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 382
--------------------------------------------------------------
Epoch:  382        1 Batch loss: 0.078617 Batch F1: 0.5
Epoch:  382        2 Batch loss: 0.085483 Batch F1: 0.9
Epoch:  382        3 Batch loss: 0.059416 Batch F1: 0.9411764705882353
Epoch:  382        4 Batch loss: 0.071286 Batch F1: 0.9411764705882353
Epoch:  382        5 Batch loss: 0.058304 Batch F1: 0.923076923076923
Epoch:  382        6 Batch loss: 0.074135 Batch F1: 0.7272727272727273
Epoch:  382        7 Batch loss: 0.072634 Batch F1: 1.0
Epoch:  382        8 Batch loss: 0.078307 Batch F1: 0.8333333333333333
Epoch:  382        9 Batch loss: 0.049718 Batch F1: 0.9333333333333333
Epoch:  382       10 Batch loss: 0.071440 Batch F1: 0.888888888888889
Epoch:  382       11 Batch loss: 0.061733 Batch F1: 0.9473684210526316
Epoch:  382       12 Batch loss: 0.053890 Batch F1: 1.0
Train Avg Loss  382: 0.067914

Train Avg F1  382: 0.877968880677859

Val Avg Loss  382: 0.061286

Val Avg F1  382:  0.9145299145299145

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 383
--------------------------------------------------------------
Epoch:  383        1 Batch loss: 0.058411 Batch F1: 0.9090909090909091
Epoch:  383        2 Batch loss: 0.067254 Batch F1: 0.0
Epoch:  383        3 Batch loss: 0.064022 Batch F1: 0.7777777777777778
Epoch:  383        4 Batch loss: 0.124039 Batch F1: 0.38095238095238093
Epoch:  383        5 Batch loss: 0.071269 Batch F1: 0.8750000000000001
Epoch:  383        6 Batch loss: 0.060175 Batch F1: 0.9333333333333333
Epoch:  383        7 Batch loss: 0.076458 Batch F1: 1.0
Epoch:  383        8 Batch loss: 0.072716 Batch F1: 0.9090909090909091
Epoch:  383        9 Batch loss: 0.057604 Batch F1: 0.8571428571428571
Epoch:  383       10 Batch loss: 0.071241 Batch F1: 0.5714285714285715
Epoch:  383       11 Batch loss: 0.074175 Batch F1: 0.4615384615384615
Epoch:  383       12 Batch loss: 0.068694 Batch F1: 0.4444444444444445
Train Avg Loss  383: 0.072172

Train Avg F1  383: 0.6766499703999703

Val Avg Loss  383: 0.066389

Val Avg F1  383:  0.5955128205128205

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 384
--------------------------------------------------------------
Epoch:  384        1 Batch loss: 0.067171 Batch F1: 0.4615384615384615
Epoch:  384        2 Batch loss: 0.082933 Batch F1: 0.7777777777777778
Epoch:  384        3 Batch loss: 0.063813 Batch F1: 0.8
Epoch:  384        4 Batch loss: 0.078838 Batch F1: 0.7499999999999999
Epoch:  384        5 Batch loss: 0.065910 Batch F1: 0.6666666666666666
Epoch:  384        6 Batch loss: 0.069742 Batch F1: 0.25
Epoch:  384        7 Batch loss: 0.081644 Batch F1: 0.5333333333333333
Epoch:  384        8 Batch loss: 0.061793 Batch F1: 0.6666666666666666
Epoch:  384        9 Batch loss: 0.067372 Batch F1: 0.4
Epoch:  384       10 Batch loss: 0.070399 Batch F1: 0.9333333333333333
Epoch:  384       11 Batch loss: 0.063840 Batch F1: 0.5714285714285715
Epoch:  384       12 Batch loss: 0.070731 Batch F1: 0.5
Train Avg Loss  384: 0.070349

Train Avg F1  384: 0.6092287342287342

Val Avg Loss  384: 0.062658

Val Avg F1  384:  0.9363526570048308

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 385
--------------------------------------------------------------
Epoch:  385        1 Batch loss: 0.068554 Batch F1: 0.9411764705882353
Epoch:  385        2 Batch loss: 0.089243 Batch F1: 0.9
Epoch:  385        3 Batch loss: 0.054600 Batch F1: 0.9090909090909091
Epoch:  385        4 Batch loss: 0.105015 Batch F1: 0.8333333333333333
Epoch:  385        5 Batch loss: 0.051190 Batch F1: 0.9090909090909091
Epoch:  385        6 Batch loss: 0.076292 Batch F1: 0.888888888888889
Epoch:  385        7 Batch loss: 0.080590 Batch F1: 0.9
Epoch:  385        8 Batch loss: 0.064778 Batch F1: 0.9473684210526316
Epoch:  385        9 Batch loss: 0.053951 Batch F1: 1.0
Epoch:  385       10 Batch loss: 0.058824 Batch F1: 0.5454545454545454
Epoch:  385       11 Batch loss: 0.075001 Batch F1: 0.5333333333333333
Epoch:  385       12 Batch loss: 0.041618 Batch F1: 0.7499999999999999
Train Avg Loss  385: 0.068305

Train Avg F1  385: 0.8381447342360655

Val Avg Loss  385: 0.061727

Val Avg F1  385:  0.4845238095238096

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 386
--------------------------------------------------------------
Epoch:  386        1 Batch loss: 0.086537 Batch F1: 0.375
Epoch:  386        2 Batch loss: 0.054010 Batch F1: 1.0
Epoch:  386        3 Batch loss: 0.057340 Batch F1: 0.8750000000000001
Epoch:  386        4 Batch loss: 0.063322 Batch F1: 1.0
Epoch:  386        5 Batch loss: 0.060806 Batch F1: 0.8571428571428571
Epoch:  386        6 Batch loss: 0.061105 Batch F1: 1.0
Epoch:  386        7 Batch loss: 0.060348 Batch F1: 0.923076923076923
Epoch:  386        8 Batch loss: 0.095863 Batch F1: 0.8571428571428571
Epoch:  386        9 Batch loss: 0.060778 Batch F1: 0.9333333333333333
Epoch:  386       10 Batch loss: 0.069559 Batch F1: 0.8571428571428571
Epoch:  386       11 Batch loss: 0.062084 Batch F1: 0.9333333333333333
Epoch:  386       12 Batch loss: 0.085775 Batch F1: 0.8571428571428571
Train Avg Loss  386: 0.068127

Train Avg F1  386: 0.872359584859585

Val Avg Loss  386: 0.061576

Val Avg F1  386:  0.9201680672268907

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 387
--------------------------------------------------------------
Epoch:  387        1 Batch loss: 0.091628 Batch F1: 0.923076923076923
Epoch:  387        2 Batch loss: 0.065683 Batch F1: 0.8571428571428571
Epoch:  387        3 Batch loss: 0.073817 Batch F1: 0.8421052631578948
Epoch:  387        4 Batch loss: 0.055728 Batch F1: 0.923076923076923
Epoch:  387        5 Batch loss: 0.065919 Batch F1: 0.8333333333333333
Epoch:  387        6 Batch loss: 0.060743 Batch F1: 0.9411764705882353
Epoch:  387        7 Batch loss: 0.078201 Batch F1: 0.9
Epoch:  387        8 Batch loss: 0.073789 Batch F1: 0.9600000000000001
Epoch:  387        9 Batch loss: 0.056242 Batch F1: 1.0
Epoch:  387       10 Batch loss: 0.058364 Batch F1: 0.5
Epoch:  387       11 Batch loss: 0.074608 Batch F1: 0.33333333333333337
Epoch:  387       12 Batch loss: 0.052437 Batch F1: 0.5
Train Avg Loss  387: 0.067263

Train Avg F1  387: 0.7927704253091251

Val Avg Loss  387: 0.063847

Val Avg F1  387:  0.597027972027972

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 388
--------------------------------------------------------------
Epoch:  388        1 Batch loss: 0.069481 Batch F1: 0.6666666666666666
Epoch:  388        2 Batch loss: 0.068842 Batch F1: 0.7142857142857143
Epoch:  388        3 Batch loss: 0.052001 Batch F1: 0.5
Epoch:  388        4 Batch loss: 0.100868 Batch F1: 0.35294117647058826
Epoch:  388        5 Batch loss: 0.046275 Batch F1: 1.0
Epoch:  388        6 Batch loss: 0.078974 Batch F1: 0.888888888888889
Epoch:  388        7 Batch loss: 0.072640 Batch F1: 1.0
Epoch:  388        8 Batch loss: 0.072995 Batch F1: 0.8571428571428571
Epoch:  388        9 Batch loss: 0.072111 Batch F1: 1.0
Epoch:  388       10 Batch loss: 0.047949 Batch F1: 0.8571428571428571
Epoch:  388       11 Batch loss: 0.073516 Batch F1: 0.9090909090909091
Epoch:  388       12 Batch loss: 0.063790 Batch F1: 1.0
Train Avg Loss  388: 0.068287

Train Avg F1  388: 0.8121799224740401

Val Avg Loss  388: 0.061283

Val Avg F1  388:  0.9392857142857143

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 389
--------------------------------------------------------------
Epoch:  389        1 Batch loss: 0.055704 Batch F1: 0.8
Epoch:  389        2 Batch loss: 0.065456 Batch F1: 0.9473684210526316
Epoch:  389        3 Batch loss: 0.076850 Batch F1: 0.9565217391304348
Epoch:  389        4 Batch loss: 0.081313 Batch F1: 0.7499999999999999
Epoch:  389        5 Batch loss: 0.074279 Batch F1: 0.7272727272727273
Epoch:  389        6 Batch loss: 0.070322 Batch F1: 0.8421052631578948
Epoch:  389        7 Batch loss: 0.059388 Batch F1: 1.0
Epoch:  389        8 Batch loss: 0.051650 Batch F1: 1.0
Epoch:  389        9 Batch loss: 0.048178 Batch F1: 0.9090909090909091
Epoch:  389       10 Batch loss: 0.063382 Batch F1: 0.7499999999999999
Epoch:  389       11 Batch loss: 0.094678 Batch F1: 0.14285714285714288
Epoch:  389       12 Batch loss: 0.079800 Batch F1: 0.33333333333333337
Train Avg Loss  389: 0.068417

Train Avg F1  389: 0.7632124613245894

Val Avg Loss  389: 0.061698

Val Avg F1  389:  0.5550420168067226

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 390
--------------------------------------------------------------
Epoch:  390        1 Batch loss: 0.071460 Batch F1: 0.5714285714285715
Epoch:  390        2 Batch loss: 0.062743 Batch F1: 0.4
Epoch:  390        3 Batch loss: 0.072658 Batch F1: 0.9523809523809523
Epoch:  390        4 Batch loss: 0.079431 Batch F1: 0.9655172413793104
Epoch:  390        5 Batch loss: 0.035302 Batch F1: 1.0
Epoch:  390        6 Batch loss: 0.081444 Batch F1: 0.7692307692307693
Epoch:  390        7 Batch loss: 0.064718 Batch F1: 0.9411764705882353
Epoch:  390        8 Batch loss: 0.083022 Batch F1: 0.888888888888889
Epoch:  390        9 Batch loss: 0.072703 Batch F1: 0.8
Epoch:  390       10 Batch loss: 0.045972 Batch F1: 0.9090909090909091
Epoch:  390       11 Batch loss: 0.069133 Batch F1: 1.0
Epoch:  390       12 Batch loss: 0.072800 Batch F1: 0.8571428571428571
Train Avg Loss  390: 0.067616

Train Avg F1  390: 0.8379047216775413

Val Avg Loss  390: 0.061329

Val Avg F1  390:  0.9017494824016563

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 391
--------------------------------------------------------------
Epoch:  391        1 Batch loss: 0.078053 Batch F1: 0.8235294117647058
Epoch:  391        2 Batch loss: 0.070557 Batch F1: 0.9411764705882353
Epoch:  391        3 Batch loss: 0.058827 Batch F1: 0.923076923076923
Epoch:  391        4 Batch loss: 0.037037 Batch F1: 0.6666666666666666
Epoch:  391        5 Batch loss: 0.073813 Batch F1: 0.19999999999999998
Epoch:  391        6 Batch loss: 0.063145 Batch F1: 0.6153846153846153
Epoch:  391        7 Batch loss: 0.071001 Batch F1: 0.33333333333333337
Epoch:  391        8 Batch loss: 0.094889 Batch F1: 0.6363636363636364
Epoch:  391        9 Batch loss: 0.062528 Batch F1: 1.0
Epoch:  391       10 Batch loss: 0.072066 Batch F1: 0.9
Epoch:  391       11 Batch loss: 0.086094 Batch F1: 0.8750000000000001
Epoch:  391       12 Batch loss: 0.066530 Batch F1: 1.0
Train Avg Loss  391: 0.069545

Train Avg F1  391: 0.7428775880981764

Val Avg Loss  391: 0.064551

Val Avg F1  391:  0.6893939393939393

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 392
--------------------------------------------------------------
Epoch:  392        1 Batch loss: 0.069179 Batch F1: 0.7142857142857143
Epoch:  392        2 Batch loss: 0.055133 Batch F1: 0.6
Epoch:  392        3 Batch loss: 0.057305 Batch F1: 0.8333333333333333
Epoch:  392        4 Batch loss: 0.063770 Batch F1: 0.5454545454545454
Epoch:  392        5 Batch loss: 0.056320 Batch F1: 0.6
Epoch:  392        6 Batch loss: 0.104467 Batch F1: 0.4210526315789474
Epoch:  392        7 Batch loss: 0.093324 Batch F1: 0.42857142857142855
Epoch:  392        8 Batch loss: 0.099308 Batch F1: 0.888888888888889
Epoch:  392        9 Batch loss: 0.079048 Batch F1: 0.9600000000000001
Epoch:  392       10 Batch loss: 0.080758 Batch F1: 0.9090909090909091
Epoch:  392       11 Batch loss: 0.057164 Batch F1: 1.0
Epoch:  392       12 Batch loss: 0.072490 Batch F1: 0.7272727272727273
Train Avg Loss  392: 0.074022

Train Avg F1  392: 0.7189958482063745

Val Avg Loss  392: 0.082474

Val Avg F1  392:  0.0

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 393
--------------------------------------------------------------
Epoch:  393        1 Batch loss: 0.120073 Batch F1: 0.0
Epoch:  393        2 Batch loss: 0.058040 Batch F1: 0.923076923076923
Epoch:  393        3 Batch loss: 0.082784 Batch F1: 0.9523809523809523
Epoch:  393        4 Batch loss: 0.072937 Batch F1: 1.0
Epoch:  393        5 Batch loss: 0.062582 Batch F1: 0.8235294117647058
Epoch:  393        6 Batch loss: 0.111376 Batch F1: 0.16666666666666669
Epoch:  393        7 Batch loss: 0.063372 Batch F1: 0.6
Epoch:  393        8 Batch loss: 0.074298 Batch F1: 0.6666666666666666
Epoch:  393        9 Batch loss: 0.078718 Batch F1: 0.8750000000000001
Epoch:  393       10 Batch loss: 0.061043 Batch F1: 0.8
Epoch:  393       11 Batch loss: 0.062814 Batch F1: 0.5454545454545454
Epoch:  393       12 Batch loss: 0.058044 Batch F1: 0.5454545454545454
Train Avg Loss  393: 0.075507

Train Avg F1  393: 0.6581858092887504

Val Avg Loss  393: 0.064270

Val Avg F1  393:  0.5709325396825398

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 394
--------------------------------------------------------------
Epoch:  394        1 Batch loss: 0.067146 Batch F1: 0.3636363636363636
Epoch:  394        2 Batch loss: 0.065727 Batch F1: 0.5714285714285715
Epoch:  394        3 Batch loss: 0.064090 Batch F1: 0.8333333333333333
Epoch:  394        4 Batch loss: 0.070634 Batch F1: 0.7692307692307693
Epoch:  394        5 Batch loss: 0.059009 Batch F1: 0.8333333333333333
Epoch:  394        6 Batch loss: 0.055614 Batch F1: 1.0
Epoch:  394        7 Batch loss: 0.082323 Batch F1: 0.9090909090909091
Epoch:  394        8 Batch loss: 0.075692 Batch F1: 0.8750000000000001
Epoch:  394        9 Batch loss: 0.071507 Batch F1: 0.8
Epoch:  394       10 Batch loss: 0.086610 Batch F1: 0.6363636363636364
Epoch:  394       11 Batch loss: 0.060951 Batch F1: 1.0
Epoch:  394       12 Batch loss: 0.077064 Batch F1: 0.8750000000000001
Train Avg Loss  394: 0.069697

Train Avg F1  394: 0.7888680763680763

Val Avg Loss  394: 0.062939

Val Avg F1  394:  0.9137102667153818

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 395
--------------------------------------------------------------
Epoch:  395        1 Batch loss: 0.081268 Batch F1: 1.0
Epoch:  395        2 Batch loss: 0.070588 Batch F1: 0.8571428571428571
Epoch:  395        3 Batch loss: 0.056245 Batch F1: 0.8
Epoch:  395        4 Batch loss: 0.073633 Batch F1: 0.9
Epoch:  395        5 Batch loss: 0.072168 Batch F1: 0.9
Epoch:  395        6 Batch loss: 0.069784 Batch F1: 0.8750000000000001
Epoch:  395        7 Batch loss: 0.047575 Batch F1: 0.7499999999999999
Epoch:  395        8 Batch loss: 0.076801 Batch F1: 0.888888888888889
Epoch:  395        9 Batch loss: 0.070718 Batch F1: 0.9523809523809523
Epoch:  395       10 Batch loss: 0.066872 Batch F1: 1.0
Epoch:  395       11 Batch loss: 0.084283 Batch F1: 0.962962962962963
Epoch:  395       12 Batch loss: 0.045591 Batch F1: 1.0
Train Avg Loss  395: 0.067961

Train Avg F1  395: 0.9071979717813052

Val Avg Loss  395: 0.061779

Val Avg F1  395:  0.9354636591478698

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 396
--------------------------------------------------------------
Epoch:  396        1 Batch loss: 0.055748 Batch F1: 1.0
Epoch:  396        2 Batch loss: 0.058909 Batch F1: 1.0
Epoch:  396        3 Batch loss: 0.064001 Batch F1: 0.8750000000000001
Epoch:  396        4 Batch loss: 0.060903 Batch F1: 1.0
Epoch:  396        5 Batch loss: 0.066010 Batch F1: 0.9333333333333333
Epoch:  396        6 Batch loss: 0.072970 Batch F1: 0.8571428571428571
Epoch:  396        7 Batch loss: 0.067145 Batch F1: 0.8333333333333333
Epoch:  396        8 Batch loss: 0.081283 Batch F1: 0.8
Epoch:  396        9 Batch loss: 0.049942 Batch F1: 1.0
Epoch:  396       10 Batch loss: 0.070371 Batch F1: 0.8571428571428571
Epoch:  396       11 Batch loss: 0.074518 Batch F1: 0.9523809523809523
Epoch:  396       12 Batch loss: 0.096163 Batch F1: 0.8421052631578948
Train Avg Loss  396: 0.068163

Train Avg F1  396: 0.9125365497076025

Val Avg Loss  396: 0.061259

Val Avg F1  396:  0.9263574660633485

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 397
--------------------------------------------------------------
Epoch:  397        1 Batch loss: 0.067361 Batch F1: 0.8571428571428571
Epoch:  397        2 Batch loss: 0.077354 Batch F1: 0.888888888888889
Epoch:  397        3 Batch loss: 0.063630 Batch F1: 0.8571428571428571
Epoch:  397        4 Batch loss: 0.083399 Batch F1: 0.9166666666666666
Epoch:  397        5 Batch loss: 0.062145 Batch F1: 0.9333333333333333
Epoch:  397        6 Batch loss: 0.069341 Batch F1: 0.9473684210526316
Epoch:  397        7 Batch loss: 0.049912 Batch F1: 1.0
Epoch:  397        8 Batch loss: 0.061888 Batch F1: 1.0
Epoch:  397        9 Batch loss: 0.087062 Batch F1: 0.0
Epoch:  397       10 Batch loss: 0.063154 Batch F1: 0.7142857142857143
Epoch:  397       11 Batch loss: 0.049103 Batch F1: 0.6
Epoch:  397       12 Batch loss: 0.088257 Batch F1: 0.3076923076923077
Train Avg Loss  397: 0.068550

Train Avg F1  397: 0.7518767538504382

Val Avg Loss  397: 0.062339

Val Avg F1  397:  0.5709150326797385

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 398
--------------------------------------------------------------
Epoch:  398        1 Batch loss: 0.055290 Batch F1: 0.33333333333333337
Epoch:  398        2 Batch loss: 0.082829 Batch F1: 0.47058823529411764
Epoch:  398        3 Batch loss: 0.051342 Batch F1: 0.7692307692307693
Epoch:  398        4 Batch loss: 0.071271 Batch F1: 0.5333333333333333
Epoch:  398        5 Batch loss: 0.085393 Batch F1: 0.9166666666666666
Epoch:  398        6 Batch loss: 0.076008 Batch F1: 0.9473684210526316
Epoch:  398        7 Batch loss: 0.066449 Batch F1: 0.923076923076923
Epoch:  398        8 Batch loss: 0.071468 Batch F1: 0.888888888888889
Epoch:  398        9 Batch loss: 0.054904 Batch F1: 0.8571428571428571
Epoch:  398       10 Batch loss: 0.069775 Batch F1: 0.8750000000000001
Epoch:  398       11 Batch loss: 0.061924 Batch F1: 1.0
Epoch:  398       12 Batch loss: 0.062920 Batch F1: 0.888888888888889
Train Avg Loss  398: 0.067464

Train Avg F1  398: 0.7836265264090342

Val Avg Loss  398: 0.061087

Val Avg F1  398:  0.8839285714285714

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 399
--------------------------------------------------------------
Epoch:  399        1 Batch loss: 0.046584 Batch F1: 1.0
Epoch:  399        2 Batch loss: 0.050612 Batch F1: 1.0
Epoch:  399        3 Batch loss: 0.058658 Batch F1: 0.6153846153846153
Epoch:  399        4 Batch loss: 0.099001 Batch F1: 0.2857142857142857
Epoch:  399        5 Batch loss: 0.076583 Batch F1: 0.4615384615384615
Epoch:  399        6 Batch loss: 0.092075 Batch F1: 0.42857142857142855
Epoch:  399        7 Batch loss: 0.084095 Batch F1: 0.625
Epoch:  399        8 Batch loss: 0.064745 Batch F1: 0.9473684210526316
Epoch:  399        9 Batch loss: 0.081487 Batch F1: 0.9166666666666666
Epoch:  399       10 Batch loss: 0.077932 Batch F1: 1.0
Epoch:  399       11 Batch loss: 0.052435 Batch F1: 1.0
Epoch:  399       12 Batch loss: 0.069472 Batch F1: 1.0
Train Avg Loss  399: 0.071140

Train Avg F1  399: 0.7733536565773408

Val Avg Loss  399: 0.063722

Val Avg F1  399:  0.935054945054945

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 400
--------------------------------------------------------------
Epoch:  400        1 Batch loss: 0.094474 Batch F1: 0.7368421052631579
Epoch:  400        2 Batch loss: 0.064481 Batch F1: 1.0
Epoch:  400        3 Batch loss: 0.074745 Batch F1: 0.888888888888889
Epoch:  400        4 Batch loss: 0.077451 Batch F1: 0.631578947368421
Epoch:  400        5 Batch loss: 0.067329 Batch F1: 0.5714285714285715
Epoch:  400        6 Batch loss: 0.055215 Batch F1: 1.0
Epoch:  400        7 Batch loss: 0.073190 Batch F1: 0.5
Epoch:  400        8 Batch loss: 0.063507 Batch F1: 0.6153846153846153
Epoch:  400        9 Batch loss: 0.065257 Batch F1: 0.3636363636363636
Epoch:  400       10 Batch loss: 0.069032 Batch F1: 0.5
Epoch:  400       11 Batch loss: 0.057421 Batch F1: 0.5
Epoch:  400       12 Batch loss: 0.062017 Batch F1: 0.6
Train Avg Loss  400: 0.068677

Train Avg F1  400: 0.6589799576641681

Val Avg Loss  400: 0.063374

Val Avg F1  400:  0.6095779220779222

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 401
--------------------------------------------------------------
Epoch:  401        1 Batch loss: 0.053642 Batch F1: 0.5
Epoch:  401        2 Batch loss: 0.094043 Batch F1: 0.0
Epoch:  401        3 Batch loss: 0.079213 Batch F1: 0.5882352941176471
Epoch:  401        4 Batch loss: 0.061960 Batch F1: 0.5454545454545454
Epoch:  401        5 Batch loss: 0.078852 Batch F1: 0.888888888888889
Epoch:  401        6 Batch loss: 0.077463 Batch F1: 0.9
Epoch:  401        7 Batch loss: 0.050543 Batch F1: 0.9090909090909091
Epoch:  401        8 Batch loss: 0.069506 Batch F1: 0.8
Epoch:  401        9 Batch loss: 0.072940 Batch F1: 0.888888888888889
Epoch:  401       10 Batch loss: 0.072155 Batch F1: 0.888888888888889
Epoch:  401       11 Batch loss: 0.048223 Batch F1: 1.0
Epoch:  401       12 Batch loss: 0.060599 Batch F1: 1.0
Train Avg Loss  401: 0.068262

Train Avg F1  401: 0.7424539512774807

Val Avg Loss  401: 0.061148

Val Avg F1  401:  0.9204472797023948

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 402
--------------------------------------------------------------
Epoch:  402        1 Batch loss: 0.066879 Batch F1: 0.6666666666666666
Epoch:  402        2 Batch loss: 0.067487 Batch F1: 0.5
Epoch:  402        3 Batch loss: 0.051425 Batch F1: 0.6
Epoch:  402        4 Batch loss: 0.047984 Batch F1: 0.6
Epoch:  402        5 Batch loss: 0.075030 Batch F1: 0.3636363636363636
Epoch:  402        6 Batch loss: 0.068384 Batch F1: 0.3636363636363636
Epoch:  402        7 Batch loss: 0.055116 Batch F1: 0.33333333333333337
Epoch:  402        8 Batch loss: 0.080386 Batch F1: 0.5
Epoch:  402        9 Batch loss: 0.069181 Batch F1: 0.5
Epoch:  402       10 Batch loss: 0.072117 Batch F1: 0.9090909090909091
Epoch:  402       11 Batch loss: 0.092320 Batch F1: 0.9696969696969697
Epoch:  402       12 Batch loss: 0.062296 Batch F1: 1.0
Train Avg Loss  402: 0.067384

Train Avg F1  402: 0.6088383838383838

Val Avg Loss  402: 0.061773

Val Avg F1  402:  0.9219829988851728

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 403
--------------------------------------------------------------
Epoch:  403        1 Batch loss: 0.068282 Batch F1: 0.9
Epoch:  403        2 Batch loss: 0.055474 Batch F1: 1.0
Epoch:  403        3 Batch loss: 0.077173 Batch F1: 0.8
Epoch:  403        4 Batch loss: 0.075404 Batch F1: 0.8235294117647058
Epoch:  403        5 Batch loss: 0.057089 Batch F1: 0.9333333333333333
Epoch:  403        6 Batch loss: 0.072474 Batch F1: 0.888888888888889
Epoch:  403        7 Batch loss: 0.071523 Batch F1: 0.9411764705882353
Epoch:  403        8 Batch loss: 0.063798 Batch F1: 0.9473684210526316
Epoch:  403        9 Batch loss: 0.085574 Batch F1: 0.9166666666666666
Epoch:  403       10 Batch loss: 0.060815 Batch F1: 1.0
Epoch:  403       11 Batch loss: 0.049358 Batch F1: 1.0
Epoch:  403       12 Batch loss: 0.074284 Batch F1: 0.625
Train Avg Loss  403: 0.067604

Train Avg F1  403: 0.8979969326912052

Val Avg Loss  403: 0.062147

Val Avg F1  403:  0.7238095238095238

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 404
--------------------------------------------------------------
Epoch:  404        1 Batch loss: 0.051983 Batch F1: 0.7692307692307693
Epoch:  404        2 Batch loss: 0.085294 Batch F1: 0.0
Epoch:  404        3 Batch loss: 0.087659 Batch F1: 0.9333333333333333
Epoch:  404        4 Batch loss: 0.082488 Batch F1: 0.8571428571428571
Epoch:  404        5 Batch loss: 0.058091 Batch F1: 1.0
Epoch:  404        6 Batch loss: 0.070767 Batch F1: 1.0
Epoch:  404        7 Batch loss: 0.075267 Batch F1: 0.888888888888889
Epoch:  404        8 Batch loss: 0.074914 Batch F1: 0.9473684210526316
Epoch:  404        9 Batch loss: 0.059314 Batch F1: 1.0
Epoch:  404       10 Batch loss: 0.090098 Batch F1: 0.761904761904762
Epoch:  404       11 Batch loss: 0.066774 Batch F1: 0.8571428571428571
Epoch:  404       12 Batch loss: 0.054567 Batch F1: 0.888888888888889
Train Avg Loss  404: 0.071435

Train Avg F1  404: 0.8253250647987492

Val Avg Loss  404: 0.064789

Val Avg F1  404:  0.7383771929824561

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 405
--------------------------------------------------------------
Epoch:  405        1 Batch loss: 0.081981 Batch F1: 0.7058823529411764
Epoch:  405        2 Batch loss: 0.075819 Batch F1: 0.5333333333333333
Epoch:  405        3 Batch loss: 0.077751 Batch F1: 0.0
Epoch:  405        4 Batch loss: 0.103079 Batch F1: 0.5263157894736842
Epoch:  405        5 Batch loss: 0.074704 Batch F1: 0.7058823529411764
Epoch:  405        6 Batch loss: 0.083018 Batch F1: 0.5333333333333333
Epoch:  405        7 Batch loss: 0.069801 Batch F1: 0.5454545454545454
Epoch:  405        8 Batch loss: 0.054159 Batch F1: 0.8
Epoch:  405        9 Batch loss: 0.076592 Batch F1: 0.4615384615384615
Epoch:  405       10 Batch loss: 0.054442 Batch F1: 0.33333333333333337
Epoch:  405       11 Batch loss: 0.076687 Batch F1: 0.42857142857142855
Epoch:  405       12 Batch loss: 0.052086 Batch F1: 0.0
Train Avg Loss  405: 0.073343

Train Avg F1  405: 0.46447041091003943

Val Avg Loss  405: 0.063785

Val Avg F1  405:  0.5840659340659341

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 406
--------------------------------------------------------------
Epoch:  406        1 Batch loss: 0.076113 Batch F1: 0.7368421052631579
Epoch:  406        2 Batch loss: 0.073849 Batch F1: 0.6666666666666666
Epoch:  406        3 Batch loss: 0.065281 Batch F1: 0.6666666666666666
Epoch:  406        4 Batch loss: 0.061158 Batch F1: 0.8
Epoch:  406        5 Batch loss: 0.066571 Batch F1: 0.4
Epoch:  406        6 Batch loss: 0.083650 Batch F1: 0.8
Epoch:  406        7 Batch loss: 0.048683 Batch F1: 1.0
Epoch:  406        8 Batch loss: 0.078026 Batch F1: 0.9166666666666666
Epoch:  406        9 Batch loss: 0.069627 Batch F1: 0.888888888888889
Epoch:  406       10 Batch loss: 0.080675 Batch F1: 0.9565217391304348
Epoch:  406       11 Batch loss: 0.064466 Batch F1: 0.923076923076923
Epoch:  406       12 Batch loss: 0.051211 Batch F1: 0.888888888888889
Train Avg Loss  406: 0.068276

Train Avg F1  406: 0.8036848787706913

Val Avg Loss  406: 0.062501

Val Avg F1  406:  0.9144607843137256

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 407
--------------------------------------------------------------
Epoch:  407        1 Batch loss: 0.057477 Batch F1: 1.0
Epoch:  407        2 Batch loss: 0.084436 Batch F1: 0.9090909090909091
Epoch:  407        3 Batch loss: 0.107040 Batch F1: 0.9411764705882353
Epoch:  407        4 Batch loss: 0.056444 Batch F1: 1.0
Epoch:  407        5 Batch loss: 0.073290 Batch F1: 0.888888888888889
Epoch:  407        6 Batch loss: 0.091214 Batch F1: 0.7142857142857143
Epoch:  407        7 Batch loss: 0.076053 Batch F1: 0.923076923076923
Epoch:  407        8 Batch loss: 0.039597 Batch F1: 1.0
Epoch:  407        9 Batch loss: 0.055211 Batch F1: 1.0
Epoch:  407       10 Batch loss: 0.057671 Batch F1: 0.888888888888889
Epoch:  407       11 Batch loss: 0.047850 Batch F1: 0.8571428571428571
Epoch:  407       12 Batch loss: 0.091086 Batch F1: 0.4615384615384615
Train Avg Loss  407: 0.069781

Train Avg F1  407: 0.8820074261250733

Val Avg Loss  407: 0.062967

Val Avg F1  407:  0.5952380952380952

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 408
--------------------------------------------------------------
Epoch:  408        1 Batch loss: 0.076070 Batch F1: 0.6153846153846153
Epoch:  408        2 Batch loss: 0.066893 Batch F1: 0.5714285714285715
Epoch:  408        3 Batch loss: 0.041556 Batch F1: 0.6666666666666666
Epoch:  408        4 Batch loss: 0.076898 Batch F1: 0.7058823529411764
Epoch:  408        5 Batch loss: 0.096087 Batch F1: 0.47058823529411764
Epoch:  408        6 Batch loss: 0.053789 Batch F1: 1.0
Epoch:  408        7 Batch loss: 0.063250 Batch F1: 0.9333333333333333
Epoch:  408        8 Batch loss: 0.068272 Batch F1: 0.5714285714285715
Epoch:  408        9 Batch loss: 0.083054 Batch F1: 0.42857142857142855
Epoch:  408       10 Batch loss: 0.062939 Batch F1: 0.5
Epoch:  408       11 Batch loss: 0.076975 Batch F1: 0.7368421052631579
Epoch:  408       12 Batch loss: 0.060228 Batch F1: 0.7272727272727273
Train Avg Loss  408: 0.068834

Train Avg F1  408: 0.6606165506320305

Val Avg Loss  408: 0.062077

Val Avg F1  408:  0.9066666666666667

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 409
--------------------------------------------------------------
Epoch:  409        1 Batch loss: 0.092223 Batch F1: 0.8571428571428571
Epoch:  409        2 Batch loss: 0.081504 Batch F1: 0.9600000000000001
Epoch:  409        3 Batch loss: 0.067325 Batch F1: 0.9565217391304348
Epoch:  409        4 Batch loss: 0.061186 Batch F1: 1.0
Epoch:  409        5 Batch loss: 0.061226 Batch F1: 0.923076923076923
Epoch:  409        6 Batch loss: 0.068853 Batch F1: 0.5714285714285715
Epoch:  409        7 Batch loss: 0.075897 Batch F1: 0.8
Epoch:  409        8 Batch loss: 0.045905 Batch F1: 1.0
Epoch:  409        9 Batch loss: 0.071868 Batch F1: 0.42857142857142855
Epoch:  409       10 Batch loss: 0.077045 Batch F1: 0.5
Epoch:  409       11 Batch loss: 0.054454 Batch F1: 0.9333333333333333
Epoch:  409       12 Batch loss: 0.076132 Batch F1: 0.5714285714285715
Train Avg Loss  409: 0.069468

Train Avg F1  409: 0.7917919520093433

Val Avg Loss  409: 0.062781

Val Avg F1  409:  0.9266694090223502

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 410
--------------------------------------------------------------
Epoch:  410        1 Batch loss: 0.076684 Batch F1: 0.9
Epoch:  410        2 Batch loss: 0.068848 Batch F1: 0.923076923076923
Epoch:  410        3 Batch loss: 0.073370 Batch F1: 0.7000000000000001
Epoch:  410        4 Batch loss: 0.055310 Batch F1: 0.8333333333333333
Epoch:  410        5 Batch loss: 0.071245 Batch F1: 0.5
Epoch:  410        6 Batch loss: 0.052910 Batch F1: 1.0
Epoch:  410        7 Batch loss: 0.085363 Batch F1: 0.6666666666666666
Epoch:  410        8 Batch loss: 0.058176 Batch F1: 1.0
Epoch:  410        9 Batch loss: 0.095597 Batch F1: 0.8571428571428571
Epoch:  410       10 Batch loss: 0.064260 Batch F1: 0.9411764705882353
Epoch:  410       11 Batch loss: 0.057184 Batch F1: 0.5
Epoch:  410       12 Batch loss: 0.071708 Batch F1: 0.6666666666666666
Train Avg Loss  410: 0.069221

Train Avg F1  410: 0.7906719097895567

Val Avg Loss  410: 0.064342

Val Avg F1  410:  0.5725108225108224

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 411
--------------------------------------------------------------
Epoch:  411        1 Batch loss: 0.076988 Batch F1: 0.4615384615384615
Epoch:  411        2 Batch loss: 0.069537 Batch F1: 0.4444444444444445
Epoch:  411        3 Batch loss: 0.073185 Batch F1: 0.5454545454545454
Epoch:  411        4 Batch loss: 0.062723 Batch F1: 0.3636363636363636
Epoch:  411        5 Batch loss: 0.068146 Batch F1: 0.2222222222222222
Epoch:  411        6 Batch loss: 0.061797 Batch F1: 0.8333333333333333
Epoch:  411        7 Batch loss: 0.062537 Batch F1: 0.9333333333333333
Epoch:  411        8 Batch loss: 0.068798 Batch F1: 0.9
Epoch:  411        9 Batch loss: 0.081958 Batch F1: 0.5333333333333333
Epoch:  411       10 Batch loss: 0.070531 Batch F1: 0.6666666666666666
Epoch:  411       11 Batch loss: 0.048934 Batch F1: 0.5714285714285715
Epoch:  411       12 Batch loss: 0.092302 Batch F1: 0.4
Train Avg Loss  411: 0.069786

Train Avg F1  411: 0.572949272949273

Val Avg Loss  411: 0.062434

Val Avg F1  411:  0.7296918767507002

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 412
--------------------------------------------------------------
Epoch:  412        1 Batch loss: 0.069588 Batch F1: 0.2222222222222222
Epoch:  412        2 Batch loss: 0.059344 Batch F1: 0.9090909090909091
Epoch:  412        3 Batch loss: 0.055277 Batch F1: 0.5454545454545454
Epoch:  412        4 Batch loss: 0.075880 Batch F1: 0.19999999999999998
Epoch:  412        5 Batch loss: 0.060150 Batch F1: 0.25
Epoch:  412        6 Batch loss: 0.070579 Batch F1: 0.4615384615384615
Epoch:  412        7 Batch loss: 0.077524 Batch F1: 0.5882352941176471
Epoch:  412        8 Batch loss: 0.071517 Batch F1: 0.625
Epoch:  412        9 Batch loss: 0.083271 Batch F1: 0.7777777777777778
Epoch:  412       10 Batch loss: 0.056697 Batch F1: 1.0
Epoch:  412       11 Batch loss: 0.067064 Batch F1: 0.9411764705882353
Epoch:  412       12 Batch loss: 0.064350 Batch F1: 1.0
Train Avg Loss  412: 0.067603

Train Avg F1  412: 0.62670797339915

Val Avg Loss  412: 0.061117

Val Avg F1  412:  0.9202533577533577

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 413
--------------------------------------------------------------
Epoch:  413        1 Batch loss: 0.081427 Batch F1: 0.9166666666666666
Epoch:  413        2 Batch loss: 0.066880 Batch F1: 0.8571428571428571
Epoch:  413        3 Batch loss: 0.072524 Batch F1: 0.9473684210526316
Epoch:  413        4 Batch loss: 0.056054 Batch F1: 1.0
Epoch:  413        5 Batch loss: 0.072980 Batch F1: 0.888888888888889
Epoch:  413        6 Batch loss: 0.059507 Batch F1: 1.0
Epoch:  413        7 Batch loss: 0.075396 Batch F1: 0.9166666666666666
Epoch:  413        8 Batch loss: 0.057403 Batch F1: 0.9090909090909091
Epoch:  413        9 Batch loss: 0.057318 Batch F1: 0.6666666666666666
Epoch:  413       10 Batch loss: 0.058304 Batch F1: 0.9090909090909091
Epoch:  413       11 Batch loss: 0.091799 Batch F1: 0.2857142857142857
Epoch:  413       12 Batch loss: 0.056159 Batch F1: 0.5454545454545454
Train Avg Loss  413: 0.067146

Train Avg F1  413: 0.8202292347029189

Val Avg Loss  413: 0.061075

Val Avg F1  413:  0.573051948051948

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 414
--------------------------------------------------------------
Epoch:  414        1 Batch loss: 0.071791 Batch F1: 0.5454545454545454
Epoch:  414        2 Batch loss: 0.068370 Batch F1: 0.8333333333333333
Epoch:  414        3 Batch loss: 0.049355 Batch F1: 1.0
Epoch:  414        4 Batch loss: 0.066998 Batch F1: 0.9
Epoch:  414        5 Batch loss: 0.068406 Batch F1: 0.888888888888889
Epoch:  414        6 Batch loss: 0.075407 Batch F1: 0.9600000000000001
Epoch:  414        7 Batch loss: 0.077693 Batch F1: 0.8235294117647058
Epoch:  414        8 Batch loss: 0.062132 Batch F1: 1.0
Epoch:  414        9 Batch loss: 0.074167 Batch F1: 0.9523809523809523
Epoch:  414       10 Batch loss: 0.060116 Batch F1: 1.0
Epoch:  414       11 Batch loss: 0.055662 Batch F1: 1.0
Epoch:  414       12 Batch loss: 0.083349 Batch F1: 0.4615384615384615
Train Avg Loss  414: 0.067787

Train Avg F1  414: 0.8637604661134074

Val Avg Loss  414: 0.062263

Val Avg F1  414:  0.743311403508772

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 415
--------------------------------------------------------------
Epoch:  415        1 Batch loss: 0.059335 Batch F1: 0.7692307692307693
Epoch:  415        2 Batch loss: 0.049893 Batch F1: 0.6666666666666666
Epoch:  415        3 Batch loss: 0.066611 Batch F1: 0.5714285714285715
Epoch:  415        4 Batch loss: 0.060454 Batch F1: 0.625
Epoch:  415        5 Batch loss: 0.079235 Batch F1: 0.2857142857142857
Epoch:  415        6 Batch loss: 0.077997 Batch F1: 0.9090909090909091
Epoch:  415        7 Batch loss: 0.069421 Batch F1: 0.9473684210526316
Epoch:  415        8 Batch loss: 0.065238 Batch F1: 0.888888888888889
Epoch:  415        9 Batch loss: 0.051595 Batch F1: 0.888888888888889
Epoch:  415       10 Batch loss: 0.076250 Batch F1: 0.9411764705882353
Epoch:  415       11 Batch loss: 0.087541 Batch F1: 0.8421052631578948
Epoch:  415       12 Batch loss: 0.069436 Batch F1: 0.8
Train Avg Loss  415: 0.067750

Train Avg F1  415: 0.7612965945589787

Val Avg Loss  415: 0.061325

Val Avg F1  415:  0.920138888888889

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 416
--------------------------------------------------------------
Epoch:  416        1 Batch loss: 0.050724 Batch F1: 1.0
Epoch:  416        2 Batch loss: 0.058908 Batch F1: 0.9411764705882353
Epoch:  416        3 Batch loss: 0.068147 Batch F1: 0.5
Epoch:  416        4 Batch loss: 0.074969 Batch F1: 0.42857142857142855
Epoch:  416        5 Batch loss: 0.060928 Batch F1: 0.5454545454545454
Epoch:  416        6 Batch loss: 0.059308 Batch F1: 0.5454545454545454
Epoch:  416        7 Batch loss: 0.067650 Batch F1: 0.5454545454545454
Epoch:  416        8 Batch loss: 0.070235 Batch F1: 0.33333333333333337
Epoch:  416        9 Batch loss: 0.058624 Batch F1: 0.2857142857142857
Epoch:  416       10 Batch loss: 0.091706 Batch F1: 0.47058823529411764
Epoch:  416       11 Batch loss: 0.065027 Batch F1: 0.6666666666666666
Epoch:  416       12 Batch loss: 0.097332 Batch F1: 0.9090909090909091
Train Avg Loss  416: 0.068630

Train Avg F1  416: 0.5976254138018844

Val Avg Loss  416: 0.063080

Val Avg F1  416:  0.9080952380952381

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 417
--------------------------------------------------------------
Epoch:  417        1 Batch loss: 0.066402 Batch F1: 0.888888888888889
Epoch:  417        2 Batch loss: 0.064511 Batch F1: 0.7272727272727273
Epoch:  417        3 Batch loss: 0.068889 Batch F1: 0.7692307692307693
Epoch:  417        4 Batch loss: 0.066215 Batch F1: 0.9333333333333333
Epoch:  417        5 Batch loss: 0.077751 Batch F1: 0.888888888888889
Epoch:  417        6 Batch loss: 0.085306 Batch F1: 0.9166666666666666
Epoch:  417        7 Batch loss: 0.077026 Batch F1: 0.8750000000000001
Epoch:  417        8 Batch loss: 0.055187 Batch F1: 1.0
Epoch:  417        9 Batch loss: 0.050110 Batch F1: 1.0
Epoch:  417       10 Batch loss: 0.060627 Batch F1: 0.6
Epoch:  417       11 Batch loss: 0.068678 Batch F1: 0.625
Epoch:  417       12 Batch loss: 0.093098 Batch F1: 0.47058823529411764
Train Avg Loss  417: 0.069483

Train Avg F1  417: 0.807905792464616

Val Avg Loss  417: 0.062236

Val Avg F1  417:  0.9246323529411765

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 418
--------------------------------------------------------------
Epoch:  418        1 Batch loss: 0.071010 Batch F1: 0.888888888888889
Epoch:  418        2 Batch loss: 0.090700 Batch F1: 0.8181818181818182
Epoch:  418        3 Batch loss: 0.071509 Batch F1: 0.625
Epoch:  418        4 Batch loss: 0.064901 Batch F1: 0.9090909090909091
Epoch:  418        5 Batch loss: 0.075920 Batch F1: 0.8571428571428571
Epoch:  418        6 Batch loss: 0.085350 Batch F1: 0.16666666666666669
Epoch:  418        7 Batch loss: 0.080205 Batch F1: 0.9
Epoch:  418        8 Batch loss: 0.053803 Batch F1: 0.888888888888889
Epoch:  418        9 Batch loss: 0.048276 Batch F1: 1.0
Epoch:  418       10 Batch loss: 0.085595 Batch F1: 0.0
Epoch:  418       11 Batch loss: 0.085563 Batch F1: 0.16666666666666669
Epoch:  418       12 Batch loss: 0.077022 Batch F1: 0.888888888888889
Train Avg Loss  418: 0.074155

Train Avg F1  418: 0.6757846320346322

Val Avg Loss  418: 0.067157

Val Avg F1  418:  0.9251276759016697

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 419
--------------------------------------------------------------
Epoch:  419        1 Batch loss: 0.080072 Batch F1: 0.9411764705882353
Epoch:  419        2 Batch loss: 0.061711 Batch F1: 1.0
Epoch:  419        3 Batch loss: 0.078271 Batch F1: 0.5714285714285715
Epoch:  419        4 Batch loss: 0.075182 Batch F1: 0.4
Epoch:  419        5 Batch loss: 0.064314 Batch F1: 0.6153846153846153
Epoch:  419        6 Batch loss: 0.086452 Batch F1: 0.3076923076923077
Epoch:  419        7 Batch loss: 0.084667 Batch F1: 0.18181818181818182
Epoch:  419        8 Batch loss: 0.048821 Batch F1: 1.0
Epoch:  419        9 Batch loss: 0.079738 Batch F1: 0.9090909090909091
Epoch:  419       10 Batch loss: 0.065803 Batch F1: 0.8750000000000001
Epoch:  419       11 Batch loss: 0.067676 Batch F1: 0.9523809523809523
Epoch:  419       12 Batch loss: 0.069921 Batch F1: 0.9333333333333333
Train Avg Loss  419: 0.071886

Train Avg F1  419: 0.7239421118097589

Val Avg Loss  419: 0.064363

Val Avg F1  419:  0.9214285714285715

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 420
--------------------------------------------------------------
Epoch:  420        1 Batch loss: 0.079379 Batch F1: 1.0
Epoch:  420        2 Batch loss: 0.057260 Batch F1: 0.9473684210526316
Epoch:  420        3 Batch loss: 0.076609 Batch F1: 0.8750000000000001
Epoch:  420        4 Batch loss: 0.054310 Batch F1: 1.0
Epoch:  420        5 Batch loss: 0.087773 Batch F1: 0.7499999999999999
Epoch:  420        6 Batch loss: 0.104983 Batch F1: 0.33333333333333337
Epoch:  420        7 Batch loss: 0.076329 Batch F1: 0.3076923076923077
Epoch:  420        8 Batch loss: 0.064228 Batch F1: 0.9411764705882353
Epoch:  420        9 Batch loss: 0.055493 Batch F1: 1.0
Epoch:  420       10 Batch loss: 0.046735 Batch F1: 0.888888888888889
Epoch:  420       11 Batch loss: 0.081982 Batch F1: 0.7000000000000001
Epoch:  420       12 Batch loss: 0.060091 Batch F1: 0.6666666666666666
Train Avg Loss  420: 0.070431

Train Avg F1  420: 0.7841771740185052

Val Avg Loss  420: 0.062072

Val Avg F1  420:  0.5963480963480964

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 421
--------------------------------------------------------------
Epoch:  421        1 Batch loss: 0.069648 Batch F1: 0.5
Epoch:  421        2 Batch loss: 0.064811 Batch F1: 0.6666666666666666
Epoch:  421        3 Batch loss: 0.050710 Batch F1: 0.7692307692307693
Epoch:  421        4 Batch loss: 0.058048 Batch F1: 0.7142857142857143
Epoch:  421        5 Batch loss: 0.069663 Batch F1: 0.5
Epoch:  421        6 Batch loss: 0.054549 Batch F1: 0.6666666666666666
Epoch:  421        7 Batch loss: 0.064397 Batch F1: 0.25
Epoch:  421        8 Batch loss: 0.077435 Batch F1: 0.4615384615384615
Epoch:  421        9 Batch loss: 0.086381 Batch F1: 0.3636363636363636
Epoch:  421       10 Batch loss: 0.083590 Batch F1: 0.19999999999999998
Epoch:  421       11 Batch loss: 0.079593 Batch F1: 0.0
Epoch:  421       12 Batch loss: 0.069126 Batch F1: 0.8750000000000001
Train Avg Loss  421: 0.068996

Train Avg F1  421: 0.4972520535020535

Val Avg Loss  421: 0.062742

Val Avg F1  421:  0.9247208931419457

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 422
--------------------------------------------------------------
Epoch:  422        1 Batch loss: 0.072043 Batch F1: 0.7272727272727273
Epoch:  422        2 Batch loss: 0.062870 Batch F1: 0.9523809523809523
Epoch:  422        3 Batch loss: 0.063248 Batch F1: 0.9473684210526316
Epoch:  422        4 Batch loss: 0.075459 Batch F1: 0.9333333333333333
Epoch:  422        5 Batch loss: 0.061011 Batch F1: 0.923076923076923
Epoch:  422        6 Batch loss: 0.075891 Batch F1: 0.9473684210526316
Epoch:  422        7 Batch loss: 0.055502 Batch F1: 0.9090909090909091
Epoch:  422        8 Batch loss: 0.118853 Batch F1: 0.0
Epoch:  422        9 Batch loss: 0.072919 Batch F1: 0.7272727272727273
Epoch:  422       10 Batch loss: 0.078155 Batch F1: 0.8333333333333333
Epoch:  422       11 Batch loss: 0.069344 Batch F1: 1.0
Epoch:  422       12 Batch loss: 0.084521 Batch F1: 0.9411764705882353
Train Avg Loss  422: 0.074151

Train Avg F1  422: 0.8201395182045337

Val Avg Loss  422: 0.067808

Val Avg F1  422:  0.7082166199813259

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 423
--------------------------------------------------------------
Epoch:  423        1 Batch loss: 0.066793 Batch F1: 0.7142857142857143
Epoch:  423        2 Batch loss: 0.075629 Batch F1: 0.888888888888889
Epoch:  423        3 Batch loss: 0.074696 Batch F1: 0.8750000000000001
Epoch:  423        4 Batch loss: 0.064415 Batch F1: 1.0
Epoch:  423        5 Batch loss: 0.043531 Batch F1: 1.0
Epoch:  423        6 Batch loss: 0.073420 Batch F1: 0.4444444444444445
Epoch:  423        7 Batch loss: 0.108087 Batch F1: 0.15384615384615385
Epoch:  423        8 Batch loss: 0.057347 Batch F1: 0.5
Epoch:  423        9 Batch loss: 0.077456 Batch F1: 0.5882352941176471
Epoch:  423       10 Batch loss: 0.082517 Batch F1: 0.6250000000000001
Epoch:  423       11 Batch loss: 0.071491 Batch F1: 0.7777777777777778
Epoch:  423       12 Batch loss: 0.118909 Batch F1: 0.5
Train Avg Loss  423: 0.076191

Train Avg F1  423: 0.6722898561133855

Val Avg Loss  423: 0.066402

Val Avg F1  423:  0.742929292929293

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 424
--------------------------------------------------------------
Epoch:  424        1 Batch loss: 0.087004 Batch F1: 0.5333333333333333
Epoch:  424        2 Batch loss: 0.055797 Batch F1: 1.0
Epoch:  424        3 Batch loss: 0.077621 Batch F1: 0.9
Epoch:  424        4 Batch loss: 0.076481 Batch F1: 0.8
Epoch:  424        5 Batch loss: 0.093990 Batch F1: 0.8421052631578948
Epoch:  424        6 Batch loss: 0.068734 Batch F1: 0.8571428571428571
Epoch:  424        7 Batch loss: 0.048065 Batch F1: 0.6666666666666666
Epoch:  424        8 Batch loss: 0.109852 Batch F1: 0.0
Epoch:  424        9 Batch loss: 0.065908 Batch F1: 0.9473684210526316
Epoch:  424       10 Batch loss: 0.052196 Batch F1: 1.0
Epoch:  424       11 Batch loss: 0.059053 Batch F1: 0.9090909090909091
Epoch:  424       12 Batch loss: 0.073689 Batch F1: 0.923076923076923
Train Avg Loss  424: 0.072366

Train Avg F1  424: 0.7815653644601013

Val Avg Loss  424: 0.065620

Val Avg F1  424:  0.7378779308926369

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 425
--------------------------------------------------------------
Epoch:  425        1 Batch loss: 0.080662 Batch F1: 0.6153846153846153
Epoch:  425        2 Batch loss: 0.065034 Batch F1: 0.8421052631578948
Epoch:  425        3 Batch loss: 0.085225 Batch F1: 0.8695652173913044
Epoch:  425        4 Batch loss: 0.046207 Batch F1: 1.0
Epoch:  425        5 Batch loss: 0.080647 Batch F1: 0.8181818181818181
Epoch:  425        6 Batch loss: 0.052524 Batch F1: 1.0
Epoch:  425        7 Batch loss: 0.073883 Batch F1: 1.0
Epoch:  425        8 Batch loss: 0.066613 Batch F1: 0.8333333333333333
Epoch:  425        9 Batch loss: 0.091426 Batch F1: 0.9523809523809523
Epoch:  425       10 Batch loss: 0.067002 Batch F1: 0.7692307692307693
Epoch:  425       11 Batch loss: 0.070225 Batch F1: 0.0
Epoch:  425       12 Batch loss: 0.060779 Batch F1: 0.4
Train Avg Loss  425: 0.070019

Train Avg F1  425: 0.758348497421724

Val Avg Loss  425: 0.068103

Val Avg F1  425:  0.4652777777777778

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 426
--------------------------------------------------------------
Epoch:  426        1 Batch loss: 0.090937 Batch F1: 0.5
Epoch:  426        2 Batch loss: 0.096195 Batch F1: 0.2666666666666667
Epoch:  426        3 Batch loss: 0.064712 Batch F1: 0.9333333333333333
Epoch:  426        4 Batch loss: 0.070298 Batch F1: 1.0
Epoch:  426        5 Batch loss: 0.062731 Batch F1: 0.9411764705882353
Epoch:  426        6 Batch loss: 0.068512 Batch F1: 1.0
Epoch:  426        7 Batch loss: 0.069240 Batch F1: 0.8571428571428571
Epoch:  426        8 Batch loss: 0.048567 Batch F1: 0.8
Epoch:  426        9 Batch loss: 0.059526 Batch F1: 0.8571428571428571
Epoch:  426       10 Batch loss: 0.073360 Batch F1: 0.5882352941176471
Epoch:  426       11 Batch loss: 0.090603 Batch F1: 0.18181818181818182
Epoch:  426       12 Batch loss: 0.071237 Batch F1: 0.7058823529411764
Train Avg Loss  426: 0.072160

Train Avg F1  426: 0.7192831678125794

Val Avg Loss  426: 0.063322

Val Avg F1  426:  0.5040404040404041

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 427
--------------------------------------------------------------
Epoch:  427        1 Batch loss: 0.081403 Batch F1: 0.3636363636363636
Epoch:  427        2 Batch loss: 0.070218 Batch F1: 0.6666666666666666
Epoch:  427        3 Batch loss: 0.077089 Batch F1: 0.6153846153846153
Epoch:  427        4 Batch loss: 0.065984 Batch F1: 0.8
Epoch:  427        5 Batch loss: 0.073417 Batch F1: 1.0
Epoch:  427        6 Batch loss: 0.078361 Batch F1: 0.888888888888889
Epoch:  427        7 Batch loss: 0.057530 Batch F1: 0.8571428571428571
Epoch:  427        8 Batch loss: 0.054370 Batch F1: 1.0
Epoch:  427        9 Batch loss: 0.058166 Batch F1: 0.6666666666666666
Epoch:  427       10 Batch loss: 0.069425 Batch F1: 0.4615384615384615
Epoch:  427       11 Batch loss: 0.084313 Batch F1: 0.42857142857142855
Epoch:  427       12 Batch loss: 0.065961 Batch F1: 0.5714285714285715
Train Avg Loss  427: 0.069687

Train Avg F1  427: 0.6933270433270434

Val Avg Loss  427: 0.063097

Val Avg F1  427:  0.9139254385964912

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 428
--------------------------------------------------------------
Epoch:  428        1 Batch loss: 0.076779 Batch F1: 0.888888888888889
Epoch:  428        2 Batch loss: 0.079653 Batch F1: 0.962962962962963
Epoch:  428        3 Batch loss: 0.057063 Batch F1: 1.0
Epoch:  428        4 Batch loss: 0.080041 Batch F1: 0.8
Epoch:  428        5 Batch loss: 0.074158 Batch F1: 0.8571428571428571
Epoch:  428        6 Batch loss: 0.072713 Batch F1: 0.9473684210526316
Epoch:  428        7 Batch loss: 0.051109 Batch F1: 1.0
Epoch:  428        8 Batch loss: 0.077517 Batch F1: 0.8421052631578948
Epoch:  428        9 Batch loss: 0.050439 Batch F1: 1.0
Epoch:  428       10 Batch loss: 0.047530 Batch F1: 0.8571428571428571
Epoch:  428       11 Batch loss: 0.075718 Batch F1: 0.7499999999999999
Epoch:  428       12 Batch loss: 0.074940 Batch F1: 0.5
Train Avg Loss  428: 0.068138

Train Avg F1  428: 0.8671342708623411

Val Avg Loss  428: 0.062659

Val Avg F1  428:  0.5021929824561404

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 429
--------------------------------------------------------------
Epoch:  429        1 Batch loss: 0.079402 Batch F1: 0.4615384615384615
Epoch:  429        2 Batch loss: 0.054294 Batch F1: 0.5714285714285715
Epoch:  429        3 Batch loss: 0.067116 Batch F1: 0.7142857142857143
Epoch:  429        4 Batch loss: 0.070253 Batch F1: 0.19999999999999998
Epoch:  429        5 Batch loss: 0.071324 Batch F1: 0.5333333333333333
Epoch:  429        6 Batch loss: 0.056646 Batch F1: 0.9333333333333333
Epoch:  429        7 Batch loss: 0.068322 Batch F1: 1.0
Epoch:  429        8 Batch loss: 0.060275 Batch F1: 1.0
Epoch:  429        9 Batch loss: 0.065073 Batch F1: 0.9333333333333333
Epoch:  429       10 Batch loss: 0.087119 Batch F1: 0.8695652173913044
Epoch:  429       11 Batch loss: 0.063609 Batch F1: 0.9333333333333333
Epoch:  429       12 Batch loss: 0.070496 Batch F1: 0.9090909090909091
Train Avg Loss  429: 0.067827

Train Avg F1  429: 0.7549368505890245

Val Avg Loss  429: 0.061155

Val Avg F1  429:  0.918939393939394

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 430
--------------------------------------------------------------
Epoch:  430        1 Batch loss: 0.067112 Batch F1: 1.0
Epoch:  430        2 Batch loss: 0.067202 Batch F1: 0.8750000000000001
Epoch:  430        3 Batch loss: 0.072964 Batch F1: 0.888888888888889
Epoch:  430        4 Batch loss: 0.057307 Batch F1: 0.923076923076923
Epoch:  430        5 Batch loss: 0.063464 Batch F1: 0.8750000000000001
Epoch:  430        6 Batch loss: 0.087406 Batch F1: 0.8695652173913044
Epoch:  430        7 Batch loss: 0.049168 Batch F1: 1.0
Epoch:  430        8 Batch loss: 0.077667 Batch F1: 0.9090909090909091
Epoch:  430        9 Batch loss: 0.070715 Batch F1: 1.0
Epoch:  430       10 Batch loss: 0.066191 Batch F1: 0.6666666666666666
Epoch:  430       11 Batch loss: 0.061564 Batch F1: 0.9090909090909091
Epoch:  430       12 Batch loss: 0.063045 Batch F1: 1.0
Train Avg Loss  430: 0.066984

Train Avg F1  430: 0.9096982928504667

Val Avg Loss  430: 0.061317

Val Avg F1  430:  0.9052579365079365

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 431
--------------------------------------------------------------
Epoch:  431        1 Batch loss: 0.071370 Batch F1: 0.9333333333333333
Epoch:  431        2 Batch loss: 0.053614 Batch F1: 0.6
Epoch:  431        3 Batch loss: 0.055217 Batch F1: 0.6666666666666666
Epoch:  431        4 Batch loss: 0.098954 Batch F1: 0.47058823529411764
Epoch:  431        5 Batch loss: 0.053843 Batch F1: 0.6153846153846153
Epoch:  431        6 Batch loss: 0.087915 Batch F1: 0.2857142857142857
Epoch:  431        7 Batch loss: 0.061733 Batch F1: 0.6
Epoch:  431        8 Batch loss: 0.084325 Batch F1: 0.7368421052631579
Epoch:  431        9 Batch loss: 0.073937 Batch F1: 0.8750000000000001
Epoch:  431       10 Batch loss: 0.073068 Batch F1: 1.0
Epoch:  431       11 Batch loss: 0.052407 Batch F1: 1.0
Epoch:  431       12 Batch loss: 0.074337 Batch F1: 1.0
Train Avg Loss  431: 0.070060

Train Avg F1  431: 0.7319607701380146

Val Avg Loss  431: 0.063122

Val Avg F1  431:  0.9279914529914529

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 432
--------------------------------------------------------------
Epoch:  432        1 Batch loss: 0.056092 Batch F1: 1.0
Epoch:  432        2 Batch loss: 0.061461 Batch F1: 1.0
Epoch:  432        3 Batch loss: 0.074055 Batch F1: 0.7692307692307693
Epoch:  432        4 Batch loss: 0.075037 Batch F1: 1.0
Epoch:  432        5 Batch loss: 0.058662 Batch F1: 0.4
Epoch:  432        6 Batch loss: 0.074953 Batch F1: 0.2222222222222222
Epoch:  432        7 Batch loss: 0.073014 Batch F1: 0.42857142857142855
Epoch:  432        8 Batch loss: 0.057818 Batch F1: 0.5
Epoch:  432        9 Batch loss: 0.070692 Batch F1: 0.5714285714285715
Epoch:  432       10 Batch loss: 0.084858 Batch F1: 0.5
Epoch:  432       11 Batch loss: 0.077789 Batch F1: 0.33333333333333337
Epoch:  432       12 Batch loss: 0.057451 Batch F1: 0.7499999999999999
Train Avg Loss  432: 0.068490

Train Avg F1  432: 0.6228988603988604

Val Avg Loss  432: 0.061786

Val Avg F1  432:  0.916213768115942

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 433
--------------------------------------------------------------
Epoch:  433        1 Batch loss: 0.078670 Batch F1: 1.0
Epoch:  433        2 Batch loss: 0.068839 Batch F1: 0.9523809523809523
Epoch:  433        3 Batch loss: 0.078372 Batch F1: 0.7499999999999999
Epoch:  433        4 Batch loss: 0.067808 Batch F1: 1.0
Epoch:  433        5 Batch loss: 0.065442 Batch F1: 0.9411764705882353
Epoch:  433        6 Batch loss: 0.079149 Batch F1: 0.9565217391304348
Epoch:  433        7 Batch loss: 0.055750 Batch F1: 0.923076923076923
Epoch:  433        8 Batch loss: 0.055799 Batch F1: 0.8571428571428571
Epoch:  433        9 Batch loss: 0.067242 Batch F1: 0.8333333333333333
Epoch:  433       10 Batch loss: 0.062199 Batch F1: 0.9411764705882353
Epoch:  433       11 Batch loss: 0.077407 Batch F1: 0.8750000000000001
Epoch:  433       12 Batch loss: 0.057625 Batch F1: 0.9090909090909091
Train Avg Loss  433: 0.067858

Train Avg F1  433: 0.9115749712776565

Val Avg Loss  433: 0.062476

Val Avg F1  433:  0.5404040404040404

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 434
--------------------------------------------------------------
Epoch:  434        1 Batch loss: 0.052733 Batch F1: 0.6666666666666666
Epoch:  434        2 Batch loss: 0.067374 Batch F1: 0.6666666666666666
Epoch:  434        3 Batch loss: 0.058881 Batch F1: 0.6666666666666666
Epoch:  434        4 Batch loss: 0.051468 Batch F1: 0.6666666666666666
Epoch:  434        5 Batch loss: 0.081485 Batch F1: 0.4615384615384615
Epoch:  434        6 Batch loss: 0.065331 Batch F1: 0.4
Epoch:  434        7 Batch loss: 0.073858 Batch F1: 0.19999999999999998
Epoch:  434        8 Batch loss: 0.069819 Batch F1: 0.5
Epoch:  434        9 Batch loss: 0.082963 Batch F1: 0.47058823529411764
Epoch:  434       10 Batch loss: 0.080323 Batch F1: 0.8
Epoch:  434       11 Batch loss: 0.069062 Batch F1: 0.8750000000000001
Epoch:  434       12 Batch loss: 0.077391 Batch F1: 0.9333333333333333
Train Avg Loss  434: 0.069224

Train Avg F1  434: 0.6089272247360483

Val Avg Loss  434: 0.063980

Val Avg F1  434:  0.9138888888888889

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 435
--------------------------------------------------------------
Epoch:  435        1 Batch loss: 0.091793 Batch F1: 1.0
Epoch:  435        2 Batch loss: 0.058549 Batch F1: 0.8
Epoch:  435        3 Batch loss: 0.080274 Batch F1: 0.7058823529411764
Epoch:  435        4 Batch loss: 0.064606 Batch F1: 1.0
Epoch:  435        5 Batch loss: 0.061531 Batch F1: 0.9333333333333333
Epoch:  435        6 Batch loss: 0.060626 Batch F1: 0.8750000000000001
Epoch:  435        7 Batch loss: 0.071737 Batch F1: 0.9
Epoch:  435        8 Batch loss: 0.066194 Batch F1: 1.0
Epoch:  435        9 Batch loss: 0.064282 Batch F1: 0.923076923076923
Epoch:  435       10 Batch loss: 0.061481 Batch F1: 0.5
Epoch:  435       11 Batch loss: 0.065169 Batch F1: 0.6666666666666666
Epoch:  435       12 Batch loss: 0.085436 Batch F1: 0.25
Train Avg Loss  435: 0.069307

Train Avg F1  435: 0.7961632730015084

Val Avg Loss  435: 0.062636

Val Avg F1  435:  0.5459899749373434

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 436
--------------------------------------------------------------
Epoch:  436        1 Batch loss: 0.106730 Batch F1: 0.33333333333333337
Epoch:  436        2 Batch loss: 0.077582 Batch F1: 0.8235294117647058
Epoch:  436        3 Batch loss: 0.052892 Batch F1: 1.0
Epoch:  436        4 Batch loss: 0.050571 Batch F1: 1.0
Epoch:  436        5 Batch loss: 0.067585 Batch F1: 0.7692307692307693
Epoch:  436        6 Batch loss: 0.067558 Batch F1: 0.9411764705882353
Epoch:  436        7 Batch loss: 0.067649 Batch F1: 0.8571428571428571
Epoch:  436        8 Batch loss: 0.072372 Batch F1: 0.9473684210526316
Epoch:  436        9 Batch loss: 0.053437 Batch F1: 1.0
Epoch:  436       10 Batch loss: 0.085885 Batch F1: 0.88
Epoch:  436       11 Batch loss: 0.062480 Batch F1: 1.0
Epoch:  436       12 Batch loss: 0.058118 Batch F1: 0.9090909090909091
Train Avg Loss  436: 0.068572

Train Avg F1  436: 0.87173934768362

Val Avg Loss  436: 0.061862

Val Avg F1  436:  0.662878787878788

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 437
--------------------------------------------------------------
Epoch:  437        1 Batch loss: 0.086392 Batch F1: 0.7058823529411764
Epoch:  437        2 Batch loss: 0.074322 Batch F1: 0.4615384615384615
Epoch:  437        3 Batch loss: 0.082388 Batch F1: 0.5
Epoch:  437        4 Batch loss: 0.054419 Batch F1: 0.7692307692307693
Epoch:  437        5 Batch loss: 0.064848 Batch F1: 0.4
Epoch:  437        6 Batch loss: 0.057165 Batch F1: 0.6
Epoch:  437        7 Batch loss: 0.072102 Batch F1: 0.42857142857142855
Epoch:  437        8 Batch loss: 0.062174 Batch F1: 0.923076923076923
Epoch:  437        9 Batch loss: 0.068416 Batch F1: 0.9473684210526316
Epoch:  437       10 Batch loss: 0.070466 Batch F1: 0.9411764705882353
Epoch:  437       11 Batch loss: 0.071042 Batch F1: 0.9565217391304348
Epoch:  437       12 Batch loss: 0.045603 Batch F1: 1.0
Train Avg Loss  437: 0.067445

Train Avg F1  437: 0.7194472138441718

Val Avg Loss  437: 0.061495

Val Avg F1  437:  0.9170168067226889

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 438
--------------------------------------------------------------
Epoch:  438        1 Batch loss: 0.048518 Batch F1: 1.0
Epoch:  438        2 Batch loss: 0.053331 Batch F1: 0.6666666666666666
Epoch:  438        3 Batch loss: 0.068996 Batch F1: 0.3636363636363636
Epoch:  438        4 Batch loss: 0.069298 Batch F1: 0.25
Epoch:  438        5 Batch loss: 0.066594 Batch F1: 0.6666666666666666
Epoch:  438        6 Batch loss: 0.059630 Batch F1: 0.6666666666666666
Epoch:  438        7 Batch loss: 0.076196 Batch F1: 0.625
Epoch:  438        8 Batch loss: 0.086407 Batch F1: 0.42857142857142855
Epoch:  438        9 Batch loss: 0.080694 Batch F1: 0.3076923076923077
Epoch:  438       10 Batch loss: 0.057318 Batch F1: 1.0
Epoch:  438       11 Batch loss: 0.082149 Batch F1: 0.923076923076923
Epoch:  438       12 Batch loss: 0.068447 Batch F1: 0.9333333333333333
Train Avg Loss  438: 0.068131

Train Avg F1  438: 0.6526091963591963

Val Avg Loss  438: 0.062944

Val Avg F1  438:  0.9166040100250628

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 439
--------------------------------------------------------------
Epoch:  439        1 Batch loss: 0.050934 Batch F1: 1.0
Epoch:  439        2 Batch loss: 0.058666 Batch F1: 1.0
Epoch:  439        3 Batch loss: 0.086870 Batch F1: 0.7777777777777778
Epoch:  439        4 Batch loss: 0.067164 Batch F1: 1.0
Epoch:  439        5 Batch loss: 0.076225 Batch F1: 0.5333333333333333
Epoch:  439        6 Batch loss: 0.074982 Batch F1: 0.3636363636363636
Epoch:  439        7 Batch loss: 0.088155 Batch F1: 0.5882352941176471
Epoch:  439        8 Batch loss: 0.072314 Batch F1: 0.9473684210526316
Epoch:  439        9 Batch loss: 0.064942 Batch F1: 0.9473684210526316
Epoch:  439       10 Batch loss: 0.055557 Batch F1: 0.8333333333333333
Epoch:  439       11 Batch loss: 0.071494 Batch F1: 0.9565217391304348
Epoch:  439       12 Batch loss: 0.063194 Batch F1: 0.8571428571428571
Train Avg Loss  439: 0.069208

Train Avg F1  439: 0.8170597950480842

Val Avg Loss  439: 0.061685

Val Avg F1  439:  0.9265873015873015

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 440
--------------------------------------------------------------
Epoch:  440        1 Batch loss: 0.073385 Batch F1: 0.8571428571428571
Epoch:  440        2 Batch loss: 0.063382 Batch F1: 0.9090909090909091
Epoch:  440        3 Batch loss: 0.068930 Batch F1: 0.7142857142857143
Epoch:  440        4 Batch loss: 0.089679 Batch F1: 0.5882352941176471
Epoch:  440        5 Batch loss: 0.063360 Batch F1: 0.9333333333333333
Epoch:  440        6 Batch loss: 0.036462 Batch F1: 1.0
Epoch:  440        7 Batch loss: 0.078867 Batch F1: 0.9473684210526316
Epoch:  440        8 Batch loss: 0.112785 Batch F1: 0.6923076923076924
Epoch:  440        9 Batch loss: 0.060905 Batch F1: 0.9333333333333333
Epoch:  440       10 Batch loss: 0.083583 Batch F1: 0.9
Epoch:  440       11 Batch loss: 0.064385 Batch F1: 1.0
Epoch:  440       12 Batch loss: 0.056018 Batch F1: 0.888888888888889
Train Avg Loss  440: 0.070979

Train Avg F1  440: 0.8636655369627507

Val Avg Loss  440: 0.064110

Val Avg F1  440:  0.6779029793735676

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 441
--------------------------------------------------------------
Epoch:  441        1 Batch loss: 0.091500 Batch F1: 0.72
Epoch:  441        2 Batch loss: 0.061941 Batch F1: 1.0
Epoch:  441        3 Batch loss: 0.068638 Batch F1: 0.923076923076923
Epoch:  441        4 Batch loss: 0.088705 Batch F1: 0.33333333333333337
Epoch:  441        5 Batch loss: 0.081271 Batch F1: 0.7058823529411764
Epoch:  441        6 Batch loss: 0.048118 Batch F1: 0.9090909090909091
Epoch:  441        7 Batch loss: 0.041045 Batch F1: 1.0
Epoch:  441        8 Batch loss: 0.069423 Batch F1: 0.8235294117647058
Epoch:  441        9 Batch loss: 0.090255 Batch F1: 0.5333333333333333
Epoch:  441       10 Batch loss: 0.065623 Batch F1: 0.9473684210526316
Epoch:  441       11 Batch loss: 0.075543 Batch F1: 0.8333333333333333
Epoch:  441       12 Batch loss: 0.065842 Batch F1: 0.25
Train Avg Loss  441: 0.070659

Train Avg F1  441: 0.7482456681605288

Val Avg Loss  441: 0.063522

Val Avg F1  441:  0.6330128205128205

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 442
--------------------------------------------------------------
Epoch:  442        1 Batch loss: 0.069564 Batch F1: 0.3636363636363636
Epoch:  442        2 Batch loss: 0.051069 Batch F1: 0.8
Epoch:  442        3 Batch loss: 0.089876 Batch F1: 0.47058823529411764
Epoch:  442        4 Batch loss: 0.069099 Batch F1: 1.0
Epoch:  442        5 Batch loss: 0.066011 Batch F1: 0.923076923076923
Epoch:  442        6 Batch loss: 0.056122 Batch F1: 0.8333333333333333
Epoch:  442        7 Batch loss: 0.075721 Batch F1: 0.888888888888889
Epoch:  442        8 Batch loss: 0.058252 Batch F1: 1.0
Epoch:  442        9 Batch loss: 0.050374 Batch F1: 1.0
Epoch:  442       10 Batch loss: 0.080243 Batch F1: 0.5714285714285715
Epoch:  442       11 Batch loss: 0.080518 Batch F1: 0.6666666666666666
Epoch:  442       12 Batch loss: 0.083440 Batch F1: 0.9411764705882353
Train Avg Loss  442: 0.069191

Train Avg F1  442: 0.788232954409425

Val Avg Loss  442: 0.061178

Val Avg F1  442:  0.9244200244200245

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 443
--------------------------------------------------------------
Epoch:  443        1 Batch loss: 0.069841 Batch F1: 0.8571428571428571
Epoch:  443        2 Batch loss: 0.063783 Batch F1: 0.9090909090909091
Epoch:  443        3 Batch loss: 0.068679 Batch F1: 0.9473684210526316
Epoch:  443        4 Batch loss: 0.084668 Batch F1: 0.9600000000000001
Epoch:  443        5 Batch loss: 0.061538 Batch F1: 0.7692307692307693
Epoch:  443        6 Batch loss: 0.065372 Batch F1: 0.888888888888889
Epoch:  443        7 Batch loss: 0.071013 Batch F1: 0.8750000000000001
Epoch:  443        8 Batch loss: 0.055923 Batch F1: 0.8571428571428571
Epoch:  443        9 Batch loss: 0.048882 Batch F1: 0.8571428571428571
Epoch:  443       10 Batch loss: 0.079386 Batch F1: 0.42857142857142855
Epoch:  443       11 Batch loss: 0.094654 Batch F1: 0.56
Epoch:  443       12 Batch loss: 0.059079 Batch F1: 0.7272727272727273
Train Avg Loss  443: 0.068568

Train Avg F1  443: 0.8030709762946605

Val Avg Loss  443: 0.061156

Val Avg F1  443:  0.9198778195488722

Optimal Val loss (Epoch 300): 0.061042639426887035

Epoch 444
--------------------------------------------------------------
Epoch:  444        1 Batch loss: 0.063616 Batch F1: 1.0
Epoch:  444        2 Batch loss: 0.070042 Batch F1: 0.9523809523809523
Epoch:  444        3 Batch loss: 0.068333 Batch F1: 0.8750000000000001
Epoch:  444        4 Batch loss: 0.049292 Batch F1: 0.888888888888889
Epoch:  444        5 Batch loss: 0.059277 Batch F1: 0.9333333333333333
Epoch:  444        6 Batch loss: 0.087500 Batch F1: 0.8695652173913044
Epoch:  444        7 Batch loss: 0.061384 Batch F1: 1.0
Epoch:  444        8 Batch loss: 0.086369 Batch F1: 0.8421052631578948
Epoch:  444        9 Batch loss: 0.059512 Batch F1: 1.0
Epoch:  444       10 Batch loss: 0.062347 Batch F1: 0.9411764705882353
Epoch:  444       11 Batch loss: 0.060183 Batch F1: 0.8
Epoch:  444       12 Batch loss: 0.081291 Batch F1: 0.8750000000000001
Train Avg Loss  444: 0.067429

Train Avg F1  444: 0.9147875104783841

Val Avg Loss  444: 0.061000

Val Avg F1  444:  0.9226190476190477

Optimal Val loss (Epoch 444): 0.06099982187151909

Epoch 445
--------------------------------------------------------------
Epoch:  445        1 Batch loss: 0.071110 Batch F1: 0.8
Epoch:  445        2 Batch loss: 0.055797 Batch F1: 0.923076923076923
Epoch:  445        3 Batch loss: 0.084986 Batch F1: 0.8571428571428571
Epoch:  445        4 Batch loss: 0.075086 Batch F1: 0.8750000000000001
Epoch:  445        5 Batch loss: 0.061711 Batch F1: 1.0
Epoch:  445        6 Batch loss: 0.054397 Batch F1: 1.0
Epoch:  445        7 Batch loss: 0.068465 Batch F1: 0.8333333333333333
Epoch:  445        8 Batch loss: 0.073143 Batch F1: 0.7368421052631579
Epoch:  445        9 Batch loss: 0.058945 Batch F1: 0.6666666666666666
Epoch:  445       10 Batch loss: 0.059978 Batch F1: 0.6153846153846153
Epoch:  445       11 Batch loss: 0.066594 Batch F1: 0.7058823529411764
Epoch:  445       12 Batch loss: 0.078880 Batch F1: 0.3636363636363636
Train Avg Loss  445: 0.067424

Train Avg F1  445: 0.7814137681204243

Val Avg Loss  445: 0.061353

Val Avg F1  445:  0.5891941391941392

Optimal Val loss (Epoch 444): 0.06099982187151909

Epoch 446
--------------------------------------------------------------
Epoch:  446        1 Batch loss: 0.071813 Batch F1: 0.4
Epoch:  446        2 Batch loss: 0.059174 Batch F1: 0.6666666666666666
Epoch:  446        3 Batch loss: 0.086202 Batch F1: 0.923076923076923
Epoch:  446        4 Batch loss: 0.079497 Batch F1: 0.8571428571428571
Epoch:  446        5 Batch loss: 0.069862 Batch F1: 1.0
Epoch:  446        6 Batch loss: 0.061892 Batch F1: 0.9090909090909091
Epoch:  446        7 Batch loss: 0.057964 Batch F1: 0.9333333333333333
Epoch:  446        8 Batch loss: 0.064603 Batch F1: 0.8750000000000001
Epoch:  446        9 Batch loss: 0.073241 Batch F1: 1.0
Epoch:  446       10 Batch loss: 0.053135 Batch F1: 0.9411764705882353
Epoch:  446       11 Batch loss: 0.072152 Batch F1: 0.8571428571428571
Epoch:  446       12 Batch loss: 0.056916 Batch F1: 0.8
Train Avg Loss  446: 0.067204

Train Avg F1  446: 0.8468858347534819

Val Avg Loss  446: 0.061342

Val Avg F1  446:  0.93875

Optimal Val loss (Epoch 444): 0.06099982187151909

Epoch 447
--------------------------------------------------------------
Epoch:  447        1 Batch loss: 0.071083 Batch F1: 0.888888888888889
Epoch:  447        2 Batch loss: 0.062898 Batch F1: 0.9333333333333333
Epoch:  447        3 Batch loss: 0.070511 Batch F1: 0.7272727272727273
Epoch:  447        4 Batch loss: 0.059902 Batch F1: 1.0
Epoch:  447        5 Batch loss: 0.075963 Batch F1: 0.888888888888889
Epoch:  447        6 Batch loss: 0.057022 Batch F1: 1.0
Epoch:  447        7 Batch loss: 0.088330 Batch F1: 0.42857142857142855
Epoch:  447        8 Batch loss: 0.072605 Batch F1: 0.6666666666666666
Epoch:  447        9 Batch loss: 0.059443 Batch F1: 1.0
Epoch:  447       10 Batch loss: 0.066506 Batch F1: 1.0
Epoch:  447       11 Batch loss: 0.072995 Batch F1: 0.9
Epoch:  447       12 Batch loss: 0.056422 Batch F1: 1.0
Train Avg Loss  447: 0.067807

Train Avg F1  447: 0.8694684944684945

Val Avg Loss  447: 0.061237

Val Avg F1  447:  0.748844537815126

Optimal Val loss (Epoch 444): 0.06099982187151909

Epoch 448
--------------------------------------------------------------
Epoch:  448        1 Batch loss: 0.060278 Batch F1: 0.5
Epoch:  448        2 Batch loss: 0.064638 Batch F1: 0.5714285714285715
Epoch:  448        3 Batch loss: 0.068783 Batch F1: 0.5
Epoch:  448        4 Batch loss: 0.078482 Batch F1: 0.5882352941176471
Epoch:  448        5 Batch loss: 0.067117 Batch F1: 0.9523809523809523
Epoch:  448        6 Batch loss: 0.070427 Batch F1: 0.8
Epoch:  448        7 Batch loss: 0.057813 Batch F1: 0.9333333333333333
Epoch:  448        8 Batch loss: 0.071132 Batch F1: 0.9523809523809523
Epoch:  448        9 Batch loss: 0.078655 Batch F1: 0.8421052631578948
Epoch:  448       10 Batch loss: 0.073292 Batch F1: 0.8333333333333333
Epoch:  448       11 Batch loss: 0.077192 Batch F1: 0.9
Epoch:  448       12 Batch loss: 0.039159 Batch F1: 1.0
Train Avg Loss  448: 0.067247

Train Avg F1  448: 0.7810998083443904

Val Avg Loss  448: 0.060577

Val Avg F1  448:  0.9024064171122994

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 449
--------------------------------------------------------------
Epoch:  449        1 Batch loss: 0.053938 Batch F1: 1.0
Epoch:  449        2 Batch loss: 0.049324 Batch F1: 1.0
Epoch:  449        3 Batch loss: 0.060876 Batch F1: 0.6153846153846153
Epoch:  449        4 Batch loss: 0.088649 Batch F1: 0.7000000000000001
Epoch:  449        5 Batch loss: 0.067268 Batch F1: 0.3636363636363636
Epoch:  449        6 Batch loss: 0.094460 Batch F1: 0.25
Epoch:  449        7 Batch loss: 0.070805 Batch F1: 0.9333333333333333
Epoch:  449        8 Batch loss: 0.072738 Batch F1: 0.8750000000000001
Epoch:  449        9 Batch loss: 0.075750 Batch F1: 0.8571428571428571
Epoch:  449       10 Batch loss: 0.075043 Batch F1: 0.8235294117647058
Epoch:  449       11 Batch loss: 0.062432 Batch F1: 0.923076923076923
Epoch:  449       12 Batch loss: 0.065602 Batch F1: 0.8333333333333333
Train Avg Loss  449: 0.069741

Train Avg F1  449: 0.7645364031393443

Val Avg Loss  449: 0.064501

Val Avg F1  449:  0.9234936889735651

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 450
--------------------------------------------------------------
Epoch:  450        1 Batch loss: 0.071487 Batch F1: 0.8750000000000001
Epoch:  450        2 Batch loss: 0.057471 Batch F1: 1.0
Epoch:  450        3 Batch loss: 0.080620 Batch F1: 0.19999999999999998
Epoch:  450        4 Batch loss: 0.084368 Batch F1: 0.16666666666666669
Epoch:  450        5 Batch loss: 0.057899 Batch F1: 0.6666666666666666
Epoch:  450        6 Batch loss: 0.066581 Batch F1: 0.2222222222222222
Epoch:  450        7 Batch loss: 0.045343 Batch F1: 0.7499999999999999
Epoch:  450        8 Batch loss: 0.088466 Batch F1: 0.6666666666666666
Epoch:  450        9 Batch loss: 0.074599 Batch F1: 0.4615384615384615
Epoch:  450       10 Batch loss: 0.052438 Batch F1: 0.6
Epoch:  450       11 Batch loss: 0.075996 Batch F1: 0.5
Epoch:  450       12 Batch loss: 0.069774 Batch F1: 0.8333333333333333
Train Avg Loss  450: 0.068753

Train Avg F1  450: 0.5785078347578347

Val Avg Loss  450: 0.062444

Val Avg F1  450:  0.9285714285714286

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 451
--------------------------------------------------------------
Epoch:  451        1 Batch loss: 0.074451 Batch F1: 0.9473684210526316
Epoch:  451        2 Batch loss: 0.060795 Batch F1: 0.8333333333333333
Epoch:  451        3 Batch loss: 0.062061 Batch F1: 1.0
Epoch:  451        4 Batch loss: 0.044667 Batch F1: 1.0
Epoch:  451        5 Batch loss: 0.060672 Batch F1: 0.9473684210526316
Epoch:  451        6 Batch loss: 0.072446 Batch F1: 0.6666666666666666
Epoch:  451        7 Batch loss: 0.068235 Batch F1: 0.888888888888889
Epoch:  451        8 Batch loss: 0.094741 Batch F1: 0.88
Epoch:  451        9 Batch loss: 0.073769 Batch F1: 1.0
Epoch:  451       10 Batch loss: 0.062361 Batch F1: 0.8750000000000001
Epoch:  451       11 Batch loss: 0.070033 Batch F1: 0.9523809523809523
Epoch:  451       12 Batch loss: 0.080447 Batch F1: 0.9473684210526316
Train Avg Loss  451: 0.068723

Train Avg F1  451: 0.9115312587023113

Val Avg Loss  451: 0.061465

Val Avg F1  451:  0.9291666666666667

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 452
--------------------------------------------------------------
Epoch:  452        1 Batch loss: 0.063835 Batch F1: 1.0
Epoch:  452        2 Batch loss: 0.054711 Batch F1: 0.9333333333333333
Epoch:  452        3 Batch loss: 0.093773 Batch F1: 0.5714285714285715
Epoch:  452        4 Batch loss: 0.069340 Batch F1: 0.8750000000000001
Epoch:  452        5 Batch loss: 0.080418 Batch F1: 0.888888888888889
Epoch:  452        6 Batch loss: 0.066202 Batch F1: 1.0
Epoch:  452        7 Batch loss: 0.048602 Batch F1: 1.0
Epoch:  452        8 Batch loss: 0.053618 Batch F1: 0.6666666666666666
Epoch:  452        9 Batch loss: 0.043814 Batch F1: 0.5714285714285715
Epoch:  452       10 Batch loss: 0.100534 Batch F1: 0.5
Epoch:  452       11 Batch loss: 0.089517 Batch F1: 0.5
Epoch:  452       12 Batch loss: 0.061584 Batch F1: 0.6
Train Avg Loss  452: 0.068829

Train Avg F1  452: 0.7588955026455028

Val Avg Loss  452: 0.061855

Val Avg F1  452:  0.9210084033613446

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 453
--------------------------------------------------------------
Epoch:  453        1 Batch loss: 0.066410 Batch F1: 0.8235294117647058
Epoch:  453        2 Batch loss: 0.076746 Batch F1: 0.9166666666666666
Epoch:  453        3 Batch loss: 0.069683 Batch F1: 0.8
Epoch:  453        4 Batch loss: 0.056324 Batch F1: 1.0
Epoch:  453        5 Batch loss: 0.061788 Batch F1: 1.0
Epoch:  453        6 Batch loss: 0.082912 Batch F1: 0.9523809523809523
Epoch:  453        7 Batch loss: 0.081043 Batch F1: 0.888888888888889
Epoch:  453        8 Batch loss: 0.063125 Batch F1: 0.9333333333333333
Epoch:  453        9 Batch loss: 0.063413 Batch F1: 1.0
Epoch:  453       10 Batch loss: 0.068807 Batch F1: 0.9565217391304348
Epoch:  453       11 Batch loss: 0.082858 Batch F1: 0.8750000000000001
Epoch:  453       12 Batch loss: 0.077658 Batch F1: 0.8333333333333333
Train Avg Loss  453: 0.070897

Train Avg F1  453: 0.9149711937915264

Val Avg Loss  453: 0.061963

Val Avg F1  453:  0.8990909090909092

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 454
--------------------------------------------------------------
Epoch:  454        1 Batch loss: 0.063348 Batch F1: 0.888888888888889
Epoch:  454        2 Batch loss: 0.059136 Batch F1: 0.8571428571428571
Epoch:  454        3 Batch loss: 0.084837 Batch F1: 0.9166666666666666
Epoch:  454        4 Batch loss: 0.065003 Batch F1: 0.888888888888889
Epoch:  454        5 Batch loss: 0.067788 Batch F1: 1.0
Epoch:  454        6 Batch loss: 0.050583 Batch F1: 0.9090909090909091
Epoch:  454        7 Batch loss: 0.059694 Batch F1: 0.0
Epoch:  454        8 Batch loss: 0.060490 Batch F1: 0.6153846153846153
Epoch:  454        9 Batch loss: 0.098224 Batch F1: 0.2857142857142857
Epoch:  454       10 Batch loss: 0.056200 Batch F1: 0.5454545454545454
Epoch:  454       11 Batch loss: 0.082195 Batch F1: 0.42857142857142855
Epoch:  454       12 Batch loss: 0.076619 Batch F1: 0.7692307692307693
Train Avg Loss  454: 0.068676

Train Avg F1  454: 0.675419487919488

Val Avg Loss  454: 0.064632

Val Avg F1  454:  0.777056277056277

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 455
--------------------------------------------------------------
Epoch:  455        1 Batch loss: 0.064556 Batch F1: 0.6666666666666666
Epoch:  455        2 Batch loss: 0.076190 Batch F1: 0.5714285714285715
Epoch:  455        3 Batch loss: 0.094315 Batch F1: 0.42857142857142855
Epoch:  455        4 Batch loss: 0.052217 Batch F1: 0.923076923076923
Epoch:  455        5 Batch loss: 0.063398 Batch F1: 0.9333333333333333
Epoch:  455        6 Batch loss: 0.077858 Batch F1: 0.5882352941176471
Epoch:  455        7 Batch loss: 0.078059 Batch F1: 0.9523809523809523
Epoch:  455        8 Batch loss: 0.052116 Batch F1: 0.888888888888889
Epoch:  455        9 Batch loss: 0.085182 Batch F1: 0.9166666666666666
Epoch:  455       10 Batch loss: 0.050548 Batch F1: 1.0
Epoch:  455       11 Batch loss: 0.081885 Batch F1: 0.9285714285714286
Epoch:  455       12 Batch loss: 0.053835 Batch F1: 1.0
Train Avg Loss  455: 0.069180

Train Avg F1  455: 0.8164850128085422

Val Avg Loss  455: 0.061602

Val Avg F1  455:  0.9229085865115276

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 456
--------------------------------------------------------------
Epoch:  456        1 Batch loss: 0.065599 Batch F1: 0.8750000000000001
Epoch:  456        2 Batch loss: 0.056558 Batch F1: 0.8571428571428571
Epoch:  456        3 Batch loss: 0.087961 Batch F1: 0.9166666666666666
Epoch:  456        4 Batch loss: 0.066458 Batch F1: 0.9333333333333333
Epoch:  456        5 Batch loss: 0.057865 Batch F1: 0.8333333333333333
Epoch:  456        6 Batch loss: 0.063344 Batch F1: 1.0
Epoch:  456        7 Batch loss: 0.066416 Batch F1: 1.0
Epoch:  456        8 Batch loss: 0.071286 Batch F1: 0.7777777777777778
Epoch:  456        9 Batch loss: 0.057788 Batch F1: 0.8333333333333333
Epoch:  456       10 Batch loss: 0.066707 Batch F1: 0.3636363636363636
Epoch:  456       11 Batch loss: 0.072593 Batch F1: 0.5333333333333333
Epoch:  456       12 Batch loss: 0.087934 Batch F1: 0.3636363636363636
Train Avg Loss  456: 0.068376

Train Avg F1  456: 0.7739327801827801

Val Avg Loss  456: 0.061436

Val Avg F1  456:  0.9224481658692185

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 457
--------------------------------------------------------------
Epoch:  457        1 Batch loss: 0.064354 Batch F1: 0.923076923076923
Epoch:  457        2 Batch loss: 0.065349 Batch F1: 0.9411764705882353
Epoch:  457        3 Batch loss: 0.064752 Batch F1: 0.9333333333333333
Epoch:  457        4 Batch loss: 0.068293 Batch F1: 0.9411764705882353
Epoch:  457        5 Batch loss: 0.076916 Batch F1: 0.6666666666666666
Epoch:  457        6 Batch loss: 0.066691 Batch F1: 0.0
Epoch:  457        7 Batch loss: 0.070696 Batch F1: 0.9473684210526316
Epoch:  457        8 Batch loss: 0.034358 Batch F1: 1.0
Epoch:  457        9 Batch loss: 0.071647 Batch F1: 0.9
Epoch:  457       10 Batch loss: 0.083231 Batch F1: 0.8571428571428571
Epoch:  457       11 Batch loss: 0.062704 Batch F1: 0.8333333333333333
Epoch:  457       12 Batch loss: 0.081470 Batch F1: 1.0
Train Avg Loss  457: 0.067538

Train Avg F1  457: 0.8286062063151848

Val Avg Loss  457: 0.061171

Val Avg F1  457:  0.9278143274853802

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 458
--------------------------------------------------------------
Epoch:  458        1 Batch loss: 0.070563 Batch F1: 0.9411764705882353
Epoch:  458        2 Batch loss: 0.077381 Batch F1: 0.9090909090909091
Epoch:  458        3 Batch loss: 0.058176 Batch F1: 0.9333333333333333
Epoch:  458        4 Batch loss: 0.052134 Batch F1: 0.8
Epoch:  458        5 Batch loss: 0.070392 Batch F1: 0.8235294117647058
Epoch:  458        6 Batch loss: 0.066139 Batch F1: 1.0
Epoch:  458        7 Batch loss: 0.076179 Batch F1: 0.9090909090909091
Epoch:  458        8 Batch loss: 0.056862 Batch F1: 1.0
Epoch:  458        9 Batch loss: 0.054531 Batch F1: 1.0
Epoch:  458       10 Batch loss: 0.081705 Batch F1: 0.7692307692307693
Epoch:  458       11 Batch loss: 0.091978 Batch F1: 0.47058823529411764
Epoch:  458       12 Batch loss: 0.066258 Batch F1: 0.9333333333333333
Train Avg Loss  458: 0.068525

Train Avg F1  458: 0.8741144476438595

Val Avg Loss  458: 0.061659

Val Avg F1  458:  0.9232034412955467

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 459
--------------------------------------------------------------
Epoch:  459        1 Batch loss: 0.068709 Batch F1: 0.9523809523809523
Epoch:  459        2 Batch loss: 0.068626 Batch F1: 0.8750000000000001
Epoch:  459        3 Batch loss: 0.059498 Batch F1: 0.9333333333333333
Epoch:  459        4 Batch loss: 0.054230 Batch F1: 0.923076923076923
Epoch:  459        5 Batch loss: 0.069435 Batch F1: 0.9473684210526316
Epoch:  459        6 Batch loss: 0.081743 Batch F1: 0.8
Epoch:  459        7 Batch loss: 0.071656 Batch F1: 0.9411764705882353
Epoch:  459        8 Batch loss: 0.081296 Batch F1: 0.9166666666666666
Epoch:  459        9 Batch loss: 0.069478 Batch F1: 0.9473684210526316
Epoch:  459       10 Batch loss: 0.065088 Batch F1: 0.9090909090909091
Epoch:  459       11 Batch loss: 0.056563 Batch F1: 1.0
Epoch:  459       12 Batch loss: 0.065795 Batch F1: 0.4
Train Avg Loss  459: 0.067676

Train Avg F1  459: 0.8787885081035235

Val Avg Loss  459: 0.063395

Val Avg F1  459:  0.6083333333333333

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 460
--------------------------------------------------------------
Epoch:  460        1 Batch loss: 0.056291 Batch F1: 0.5
Epoch:  460        2 Batch loss: 0.063713 Batch F1: 0.0
Epoch:  460        3 Batch loss: 0.048693 Batch F1: 0.33333333333333337
Epoch:  460        4 Batch loss: 0.084901 Batch F1: 0.3636363636363636
Epoch:  460        5 Batch loss: 0.083511 Batch F1: 0.3076923076923077
Epoch:  460        6 Batch loss: 0.055389 Batch F1: 0.7142857142857143
Epoch:  460        7 Batch loss: 0.068935 Batch F1: 0.9333333333333333
Epoch:  460        8 Batch loss: 0.064904 Batch F1: 0.888888888888889
Epoch:  460        9 Batch loss: 0.078379 Batch F1: 0.962962962962963
Epoch:  460       10 Batch loss: 0.080856 Batch F1: 0.88
Epoch:  460       11 Batch loss: 0.077916 Batch F1: 1.0
Epoch:  460       12 Batch loss: 0.062157 Batch F1: 1.0
Train Avg Loss  460: 0.068804

Train Avg F1  460: 0.6570110753444087

Val Avg Loss  460: 0.062541

Val Avg F1  460:  0.9326625386996905

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 461
--------------------------------------------------------------
Epoch:  461        1 Batch loss: 0.068029 Batch F1: 1.0
Epoch:  461        2 Batch loss: 0.060772 Batch F1: 0.923076923076923
Epoch:  461        3 Batch loss: 0.101308 Batch F1: 0.6363636363636364
Epoch:  461        4 Batch loss: 0.072411 Batch F1: 0.9411764705882353
Epoch:  461        5 Batch loss: 0.068973 Batch F1: 0.9333333333333333
Epoch:  461        6 Batch loss: 0.076336 Batch F1: 0.2857142857142857
Epoch:  461        7 Batch loss: 0.066876 Batch F1: 0.4
Epoch:  461        8 Batch loss: 0.082333 Batch F1: 0.5
Epoch:  461        9 Batch loss: 0.054956 Batch F1: 1.0
Epoch:  461       10 Batch loss: 0.065083 Batch F1: 1.0
Epoch:  461       11 Batch loss: 0.064909 Batch F1: 1.0
Epoch:  461       12 Batch loss: 0.056938 Batch F1: 0.5714285714285715
Train Avg Loss  461: 0.069910

Train Avg F1  461: 0.7659244350420821

Val Avg Loss  461: 0.064139

Val Avg F1  461:  0.5857142857142857

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 462
--------------------------------------------------------------
Epoch:  462        1 Batch loss: 0.036871 Batch F1: 0.8
Epoch:  462        2 Batch loss: 0.070075 Batch F1: 0.5454545454545454
Epoch:  462        3 Batch loss: 0.090793 Batch F1: 0.625
Epoch:  462        4 Batch loss: 0.065787 Batch F1: 0.5714285714285715
Epoch:  462        5 Batch loss: 0.072759 Batch F1: 0.6
Epoch:  462        6 Batch loss: 0.065313 Batch F1: 0.5
Epoch:  462        7 Batch loss: 0.093961 Batch F1: 0.5555555555555556
Epoch:  462        8 Batch loss: 0.065398 Batch F1: 0.923076923076923
Epoch:  462        9 Batch loss: 0.075421 Batch F1: 0.9090909090909091
Epoch:  462       10 Batch loss: 0.066112 Batch F1: 0.9473684210526316
Epoch:  462       11 Batch loss: 0.084974 Batch F1: 0.9
Epoch:  462       12 Batch loss: 0.062094 Batch F1: 0.923076923076923
Train Avg Loss  462: 0.070796

Train Avg F1  462: 0.7333376540613384

Val Avg Loss  462: 0.062991

Val Avg F1  462:  0.8852941176470588

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 463
--------------------------------------------------------------
Epoch:  463        1 Batch loss: 0.103280 Batch F1: 0.8666666666666666
Epoch:  463        2 Batch loss: 0.050919 Batch F1: 1.0
Epoch:  463        3 Batch loss: 0.063305 Batch F1: 0.9473684210526316
Epoch:  463        4 Batch loss: 0.074311 Batch F1: 0.9565217391304348
Epoch:  463        5 Batch loss: 0.059765 Batch F1: 1.0
Epoch:  463        6 Batch loss: 0.061297 Batch F1: 0.8333333333333333
Epoch:  463        7 Batch loss: 0.062363 Batch F1: 0.6
Epoch:  463        8 Batch loss: 0.062477 Batch F1: 0.5454545454545454
Epoch:  463        9 Batch loss: 0.070346 Batch F1: 0.19999999999999998
Epoch:  463       10 Batch loss: 0.052064 Batch F1: 0.0
Epoch:  463       11 Batch loss: 0.083799 Batch F1: 0.6666666666666666
Epoch:  463       12 Batch loss: 0.069961 Batch F1: 0.6666666666666666
Train Avg Loss  463: 0.067824

Train Avg F1  463: 0.6902231699142454

Val Avg Loss  463: 0.061568

Val Avg F1  463:  0.9246336996336996

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 464
--------------------------------------------------------------
Epoch:  464        1 Batch loss: 0.083756 Batch F1: 0.9600000000000001
Epoch:  464        2 Batch loss: 0.069940 Batch F1: 0.8
Epoch:  464        3 Batch loss: 0.053554 Batch F1: 1.0
Epoch:  464        4 Batch loss: 0.058811 Batch F1: 0.9473684210526316
Epoch:  464        5 Batch loss: 0.069863 Batch F1: 0.888888888888889
Epoch:  464        6 Batch loss: 0.077798 Batch F1: 0.888888888888889
Epoch:  464        7 Batch loss: 0.048953 Batch F1: 1.0
Epoch:  464        8 Batch loss: 0.080522 Batch F1: 0.6
Epoch:  464        9 Batch loss: 0.070149 Batch F1: 0.888888888888889
Epoch:  464       10 Batch loss: 0.068353 Batch F1: 0.9333333333333333
Epoch:  464       11 Batch loss: 0.075324 Batch F1: 0.8
Epoch:  464       12 Batch loss: 0.069359 Batch F1: 0.8
Train Avg Loss  464: 0.068865

Train Avg F1  464: 0.8756140350877195

Val Avg Loss  464: 0.061942

Val Avg F1  464:  0.9119047619047619

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 465
--------------------------------------------------------------
Epoch:  465        1 Batch loss: 0.056544 Batch F1: 1.0
Epoch:  465        2 Batch loss: 0.067003 Batch F1: 0.3636363636363636
Epoch:  465        3 Batch loss: 0.076724 Batch F1: 0.625
Epoch:  465        4 Batch loss: 0.075577 Batch F1: 0.5882352941176471
Epoch:  465        5 Batch loss: 0.070356 Batch F1: 0.25
Epoch:  465        6 Batch loss: 0.083864 Batch F1: 0.6
Epoch:  465        7 Batch loss: 0.066234 Batch F1: 0.8750000000000001
Epoch:  465        8 Batch loss: 0.057296 Batch F1: 0.9333333333333333
Epoch:  465        9 Batch loss: 0.054732 Batch F1: 1.0
Epoch:  465       10 Batch loss: 0.095867 Batch F1: 0.9090909090909091
Epoch:  465       11 Batch loss: 0.065947 Batch F1: 1.0
Epoch:  465       12 Batch loss: 0.070235 Batch F1: 0.5714285714285715
Train Avg Loss  465: 0.070032

Train Avg F1  465: 0.7263103726339021

Val Avg Loss  465: 0.063264

Val Avg F1  465:  0.9305555555555556

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 466
--------------------------------------------------------------
Epoch:  466        1 Batch loss: 0.078814 Batch F1: 0.888888888888889
Epoch:  466        2 Batch loss: 0.084848 Batch F1: 0.5882352941176471
Epoch:  466        3 Batch loss: 0.067436 Batch F1: 0.8
Epoch:  466        4 Batch loss: 0.056982 Batch F1: 0.923076923076923
Epoch:  466        5 Batch loss: 0.061468 Batch F1: 0.923076923076923
Epoch:  466        6 Batch loss: 0.052723 Batch F1: 1.0
Epoch:  466        7 Batch loss: 0.086583 Batch F1: 0.6153846153846153
Epoch:  466        8 Batch loss: 0.083973 Batch F1: 0.5
Epoch:  466        9 Batch loss: 0.073288 Batch F1: 0.8333333333333333
Epoch:  466       10 Batch loss: 0.067611 Batch F1: 0.9523809523809523
Epoch:  466       11 Batch loss: 0.058368 Batch F1: 1.0
Epoch:  466       12 Batch loss: 0.057772 Batch F1: 1.0
Train Avg Loss  466: 0.069155

Train Avg F1  466: 0.8353647441882734

Val Avg Loss  466: 0.064958

Val Avg F1  466:  0.5787878787878789

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 467
--------------------------------------------------------------
Epoch:  467        1 Batch loss: 0.068553 Batch F1: 0.5
Epoch:  467        2 Batch loss: 0.046148 Batch F1: 0.8
Epoch:  467        3 Batch loss: 0.080040 Batch F1: 0.4615384615384615
Epoch:  467        4 Batch loss: 0.079873 Batch F1: 0.3636363636363636
Epoch:  467        5 Batch loss: 0.084760 Batch F1: 0.3076923076923077
Epoch:  467        6 Batch loss: 0.077556 Batch F1: 0.42857142857142855
Epoch:  467        7 Batch loss: 0.062423 Batch F1: 0.9473684210526316
Epoch:  467        8 Batch loss: 0.055448 Batch F1: 1.0
Epoch:  467        9 Batch loss: 0.057653 Batch F1: 0.9333333333333333
Epoch:  467       10 Batch loss: 0.065885 Batch F1: 0.8750000000000001
Epoch:  467       11 Batch loss: 0.084093 Batch F1: 0.8695652173913044
Epoch:  467       12 Batch loss: 0.068204 Batch F1: 0.9090909090909091
Train Avg Loss  467: 0.069220

Train Avg F1  467: 0.6996497035255617

Val Avg Loss  467: 0.061939

Val Avg F1  467:  0.8802681992337165

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 468
--------------------------------------------------------------
Epoch:  468        1 Batch loss: 0.077786 Batch F1: 0.9
Epoch:  468        2 Batch loss: 0.068534 Batch F1: 0.9473684210526316
Epoch:  468        3 Batch loss: 0.081427 Batch F1: 0.923076923076923
Epoch:  468        4 Batch loss: 0.049630 Batch F1: 1.0
Epoch:  468        5 Batch loss: 0.047041 Batch F1: 1.0
Epoch:  468        6 Batch loss: 0.071399 Batch F1: 0.9411764705882353
Epoch:  468        7 Batch loss: 0.061869 Batch F1: 0.9333333333333333
Epoch:  468        8 Batch loss: 0.081431 Batch F1: 0.7692307692307693
Epoch:  468        9 Batch loss: 0.062131 Batch F1: 1.0
Epoch:  468       10 Batch loss: 0.056901 Batch F1: 0.6666666666666666
Epoch:  468       11 Batch loss: 0.070870 Batch F1: 0.4
Epoch:  468       12 Batch loss: 0.103962 Batch F1: 0.375
Train Avg Loss  468: 0.069415

Train Avg F1  468: 0.82132104866238

Val Avg Loss  468: 0.062695

Val Avg F1  468:  0.7202221797810033

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 469
--------------------------------------------------------------
Epoch:  469        1 Batch loss: 0.078029 Batch F1: 0.5
Epoch:  469        2 Batch loss: 0.055868 Batch F1: 0.9411764705882353
Epoch:  469        3 Batch loss: 0.058948 Batch F1: 1.0
Epoch:  469        4 Batch loss: 0.078925 Batch F1: 0.888888888888889
Epoch:  469        5 Batch loss: 0.084080 Batch F1: 0.9523809523809523
Epoch:  469        6 Batch loss: 0.057861 Batch F1: 1.0
Epoch:  469        7 Batch loss: 0.059549 Batch F1: 0.25
Epoch:  469        8 Batch loss: 0.103318 Batch F1: 0.0
Epoch:  469        9 Batch loss: 0.082817 Batch F1: 0.7058823529411764
Epoch:  469       10 Batch loss: 0.057654 Batch F1: 0.7499999999999999
Epoch:  469       11 Batch loss: 0.075598 Batch F1: 0.8571428571428572
Epoch:  469       12 Batch loss: 0.093070 Batch F1: 0.761904761904762
Train Avg Loss  469: 0.073810

Train Avg F1  469: 0.7172813569872395

Val Avg Loss  469: 0.063605

Val Avg F1  469:  0.7452380952380953

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 470
--------------------------------------------------------------
Epoch:  470        1 Batch loss: 0.087135 Batch F1: 0.5555555555555556
Epoch:  470        2 Batch loss: 0.079711 Batch F1: 0.8571428571428571
Epoch:  470        3 Batch loss: 0.082684 Batch F1: 1.0
Epoch:  470        4 Batch loss: 0.065544 Batch F1: 0.9411764705882353
Epoch:  470        5 Batch loss: 0.068082 Batch F1: 0.7368421052631579
Epoch:  470        6 Batch loss: 0.065740 Batch F1: 0.4
Epoch:  470        7 Batch loss: 0.043369 Batch F1: 0.6666666666666666
Epoch:  470        8 Batch loss: 0.067547 Batch F1: 0.5
Epoch:  470        9 Batch loss: 0.097433 Batch F1: 0.2666666666666667
Epoch:  470       10 Batch loss: 0.053097 Batch F1: 0.5714285714285715
Epoch:  470       11 Batch loss: 0.051345 Batch F1: 0.6
Epoch:  470       12 Batch loss: 0.073932 Batch F1: 0.25
Train Avg Loss  470: 0.069635

Train Avg F1  470: 0.6121232411093092

Val Avg Loss  470: 0.062644

Val Avg F1  470:  0.5736111111111111

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 471
--------------------------------------------------------------
Epoch:  471        1 Batch loss: 0.066336 Batch F1: 0.7058823529411764
Epoch:  471        2 Batch loss: 0.072593 Batch F1: 0.5714285714285715
Epoch:  471        3 Batch loss: 0.069363 Batch F1: 0.33333333333333337
Epoch:  471        4 Batch loss: 0.047548 Batch F1: 1.0
Epoch:  471        5 Batch loss: 0.051804 Batch F1: 1.0
Epoch:  471        6 Batch loss: 0.063960 Batch F1: 1.0
Epoch:  471        7 Batch loss: 0.087739 Batch F1: 0.4615384615384615
Epoch:  471        8 Batch loss: 0.069884 Batch F1: 0.9333333333333333
Epoch:  471        9 Batch loss: 0.060745 Batch F1: 1.0
Epoch:  471       10 Batch loss: 0.061909 Batch F1: 0.9411764705882353
Epoch:  471       11 Batch loss: 0.060602 Batch F1: 0.8750000000000001
Epoch:  471       12 Batch loss: 0.102747 Batch F1: 0.5714285714285715
Train Avg Loss  471: 0.067936

Train Avg F1  471: 0.7827600912159736

Val Avg Loss  471: 0.068141

Val Avg F1  471:  0.9093406593406593

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 472
--------------------------------------------------------------
Epoch:  472        1 Batch loss: 0.072181 Batch F1: 1.0
Epoch:  472        2 Batch loss: 0.072365 Batch F1: 0.8571428571428571
Epoch:  472        3 Batch loss: 0.089283 Batch F1: 0.967741935483871
Epoch:  472        4 Batch loss: 0.061485 Batch F1: 0.923076923076923
Epoch:  472        5 Batch loss: 0.075905 Batch F1: 0.8750000000000001
Epoch:  472        6 Batch loss: 0.054500 Batch F1: 0.8
Epoch:  472        7 Batch loss: 0.055348 Batch F1: 0.0
Epoch:  472        8 Batch loss: 0.111615 Batch F1: 0.0
Epoch:  472        9 Batch loss: 0.061597 Batch F1: 0.6153846153846153
Epoch:  472       10 Batch loss: 0.083507 Batch F1: 0.8421052631578948
Epoch:  472       11 Batch loss: 0.086954 Batch F1: 0.9523809523809523
Epoch:  472       12 Batch loss: 0.070339 Batch F1: 1.0
Train Avg Loss  472: 0.074590

Train Avg F1  472: 0.7360693788855928

Val Avg Loss  472: 0.071826

Val Avg F1  472:  0.5655637254901962

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 473
--------------------------------------------------------------
Epoch:  473        1 Batch loss: 0.047751 Batch F1: 0.33333333333333337
Epoch:  473        2 Batch loss: 0.141415 Batch F1: 0.0
Epoch:  473        3 Batch loss: 0.061367 Batch F1: 0.5454545454545454
Epoch:  473        4 Batch loss: 0.081936 Batch F1: 0.6153846153846154
Epoch:  473        5 Batch loss: 0.078535 Batch F1: 0.42857142857142855
Epoch:  473        6 Batch loss: 0.073496 Batch F1: 0.6666666666666666
Epoch:  473        7 Batch loss: 0.088299 Batch F1: 0.7142857142857143
Epoch:  473        8 Batch loss: 0.082244 Batch F1: 0.962962962962963
Epoch:  473        9 Batch loss: 0.071483 Batch F1: 1.0
Epoch:  473       10 Batch loss: 0.074712 Batch F1: 0.7499999999999999
Epoch:  473       11 Batch loss: 0.107038 Batch F1: 0.15384615384615385
Epoch:  473       12 Batch loss: 0.063410 Batch F1: 0.2857142857142857
Train Avg Loss  473: 0.080974

Train Avg F1  473: 0.5380183088516423

Val Avg Loss  473: 0.066425

Val Avg F1  473:  0.725

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 474
--------------------------------------------------------------
Epoch:  474        1 Batch loss: 0.077496 Batch F1: 0.6666666666666666
Epoch:  474        2 Batch loss: 0.085737 Batch F1: 0.19999999999999998
Epoch:  474        3 Batch loss: 0.083935 Batch F1: 0.0
Epoch:  474        4 Batch loss: 0.047863 Batch F1: 0.7499999999999999
Epoch:  474        5 Batch loss: 0.078454 Batch F1: 0.5
Epoch:  474        6 Batch loss: 0.091962 Batch F1: 0.631578947368421
Epoch:  474        7 Batch loss: 0.044386 Batch F1: 0.6666666666666666
Epoch:  474        8 Batch loss: 0.045877 Batch F1: 0.7499999999999999
Epoch:  474        9 Batch loss: 0.074028 Batch F1: 0.6666666666666666
Epoch:  474       10 Batch loss: 0.083686 Batch F1: 0.2857142857142857
Epoch:  474       11 Batch loss: 0.069391 Batch F1: 0.888888888888889
Epoch:  474       12 Batch loss: 0.075859 Batch F1: 0.9411764705882353
Train Avg Loss  474: 0.071556

Train Avg F1  474: 0.5789465493799859

Val Avg Loss  474: 0.065181

Val Avg F1  474:  0.9246031746031746

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 475
--------------------------------------------------------------
Epoch:  475        1 Batch loss: 0.078953 Batch F1: 0.9
Epoch:  475        2 Batch loss: 0.064288 Batch F1: 1.0
Epoch:  475        3 Batch loss: 0.054600 Batch F1: 1.0
Epoch:  475        4 Batch loss: 0.079146 Batch F1: 0.9090909090909091
Epoch:  475        5 Batch loss: 0.065127 Batch F1: 0.9411764705882353
Epoch:  475        6 Batch loss: 0.084202 Batch F1: 0.9090909090909091
Epoch:  475        7 Batch loss: 0.066183 Batch F1: 0.9473684210526316
Epoch:  475        8 Batch loss: 0.056011 Batch F1: 0.9090909090909091
Epoch:  475        9 Batch loss: 0.072948 Batch F1: 0.8571428571428571
Epoch:  475       10 Batch loss: 0.074773 Batch F1: 0.8750000000000001
Epoch:  475       11 Batch loss: 0.076533 Batch F1: 0.8571428571428571
Epoch:  475       12 Batch loss: 0.062182 Batch F1: 0.9333333333333333
Train Avg Loss  475: 0.069579

Train Avg F1  475: 0.9198697222110536

Val Avg Loss  475: 0.062363

Val Avg F1  475:  0.9244200244200245

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 476
--------------------------------------------------------------
Epoch:  476        1 Batch loss: 0.072590 Batch F1: 0.8571428571428571
Epoch:  476        2 Batch loss: 0.051771 Batch F1: 0.9090909090909091
Epoch:  476        3 Batch loss: 0.064108 Batch F1: 0.6153846153846153
Epoch:  476        4 Batch loss: 0.062104 Batch F1: 0.6153846153846153
Epoch:  476        5 Batch loss: 0.062139 Batch F1: 0.7058823529411764
Epoch:  476        6 Batch loss: 0.070164 Batch F1: 0.5
Epoch:  476        7 Batch loss: 0.072782 Batch F1: 0.4
Epoch:  476        8 Batch loss: 0.076543 Batch F1: 0.33333333333333337
Epoch:  476        9 Batch loss: 0.060823 Batch F1: 0.25
Epoch:  476       10 Batch loss: 0.064806 Batch F1: 0.2857142857142857
Epoch:  476       11 Batch loss: 0.069276 Batch F1: 0.5333333333333333
Epoch:  476       12 Batch loss: 0.098745 Batch F1: 0.4444444444444445
Train Avg Loss  476: 0.068821

Train Avg F1  476: 0.5374758955641309

Val Avg Loss  476: 0.062035

Val Avg F1  476:  0.9285714285714286

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 477
--------------------------------------------------------------
Epoch:  477        1 Batch loss: 0.054603 Batch F1: 0.888888888888889
Epoch:  477        2 Batch loss: 0.063761 Batch F1: 0.9411764705882353
Epoch:  477        3 Batch loss: 0.076997 Batch F1: 0.8235294117647058
Epoch:  477        4 Batch loss: 0.053766 Batch F1: 1.0
Epoch:  477        5 Batch loss: 0.073975 Batch F1: 0.9473684210526316
Epoch:  477        6 Batch loss: 0.094858 Batch F1: 0.9655172413793104
Epoch:  477        7 Batch loss: 0.050693 Batch F1: 0.9333333333333333
Epoch:  477        8 Batch loss: 0.058913 Batch F1: 0.923076923076923
Epoch:  477        9 Batch loss: 0.079389 Batch F1: 0.9090909090909091
Epoch:  477       10 Batch loss: 0.078503 Batch F1: 0.7777777777777778
Epoch:  477       11 Batch loss: 0.062079 Batch F1: 1.0
Epoch:  477       12 Batch loss: 0.067850 Batch F1: 0.9411764705882353
Train Avg Loss  477: 0.067949

Train Avg F1  477: 0.9209113206284126

Val Avg Loss  477: 0.061633

Val Avg F1  477:  0.932674856903532

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 478
--------------------------------------------------------------
Epoch:  478        1 Batch loss: 0.086064 Batch F1: 0.9
Epoch:  478        2 Batch loss: 0.082931 Batch F1: 0.7499999999999999
Epoch:  478        3 Batch loss: 0.058337 Batch F1: 1.0
Epoch:  478        4 Batch loss: 0.054005 Batch F1: 1.0
Epoch:  478        5 Batch loss: 0.058005 Batch F1: 0.8
Epoch:  478        6 Batch loss: 0.073901 Batch F1: 0.8750000000000001
Epoch:  478        7 Batch loss: 0.051206 Batch F1: 0.9473684210526316
Epoch:  478        8 Batch loss: 0.060925 Batch F1: 0.9333333333333333
Epoch:  478        9 Batch loss: 0.064982 Batch F1: 0.6153846153846153
Epoch:  478       10 Batch loss: 0.069734 Batch F1: 0.5882352941176471
Epoch:  478       11 Batch loss: 0.073633 Batch F1: 0.19999999999999998
Epoch:  478       12 Batch loss: 0.081289 Batch F1: 0.888888888888889
Train Avg Loss  478: 0.067918

Train Avg F1  478: 0.7915175460647598

Val Avg Loss  478: 0.062350

Val Avg F1  478:  0.924579831932773

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 479
--------------------------------------------------------------
Epoch:  479        1 Batch loss: 0.038982 Batch F1: 1.0
Epoch:  479        2 Batch loss: 0.056887 Batch F1: 1.0
Epoch:  479        3 Batch loss: 0.086283 Batch F1: 0.8
Epoch:  479        4 Batch loss: 0.060421 Batch F1: 0.9411764705882353
Epoch:  479        5 Batch loss: 0.088760 Batch F1: 0.888888888888889
Epoch:  479        6 Batch loss: 0.046594 Batch F1: 1.0
Epoch:  479        7 Batch loss: 0.078438 Batch F1: 1.0
Epoch:  479        8 Batch loss: 0.082645 Batch F1: 0.8
Epoch:  479        9 Batch loss: 0.062933 Batch F1: 0.9333333333333333
Epoch:  479       10 Batch loss: 0.079774 Batch F1: 0.9565217391304348
Epoch:  479       11 Batch loss: 0.068514 Batch F1: 0.9333333333333333
Epoch:  479       12 Batch loss: 0.067176 Batch F1: 0.8
Train Avg Loss  479: 0.068117

Train Avg F1  479: 0.921104480439519

Val Avg Loss  479: 0.063450

Val Avg F1  479:  0.5828452593158475

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 480
--------------------------------------------------------------
Epoch:  480        1 Batch loss: 0.070081 Batch F1: 0.6666666666666666
Epoch:  480        2 Batch loss: 0.061553 Batch F1: 0.5454545454545454
Epoch:  480        3 Batch loss: 0.076863 Batch F1: 0.5333333333333333
Epoch:  480        4 Batch loss: 0.079646 Batch F1: 0.2222222222222222
Epoch:  480        5 Batch loss: 0.067600 Batch F1: 0.5714285714285715
Epoch:  480        6 Batch loss: 0.050564 Batch F1: 0.5
Epoch:  480        7 Batch loss: 0.062682 Batch F1: 0.2222222222222222
Epoch:  480        8 Batch loss: 0.079416 Batch F1: 0.8421052631578948
Epoch:  480        9 Batch loss: 0.048472 Batch F1: 1.0
Epoch:  480       10 Batch loss: 0.079557 Batch F1: 0.9565217391304348
Epoch:  480       11 Batch loss: 0.081566 Batch F1: 0.8
Epoch:  480       12 Batch loss: 0.048280 Batch F1: 0.888888888888889
Train Avg Loss  480: 0.067190

Train Avg F1  480: 0.6457369543753984

Val Avg Loss  480: 0.062039

Val Avg F1  480:  0.9212454212454213

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 481
--------------------------------------------------------------
Epoch:  481        1 Batch loss: 0.075303 Batch F1: 0.8750000000000001
Epoch:  481        2 Batch loss: 0.067738 Batch F1: 0.9333333333333333
Epoch:  481        3 Batch loss: 0.081673 Batch F1: 1.0
Epoch:  481        4 Batch loss: 0.079046 Batch F1: 0.88
Epoch:  481        5 Batch loss: 0.065796 Batch F1: 0.923076923076923
Epoch:  481        6 Batch loss: 0.065424 Batch F1: 1.0
Epoch:  481        7 Batch loss: 0.075982 Batch F1: 0.8421052631578948
Epoch:  481        8 Batch loss: 0.065225 Batch F1: 0.8750000000000001
Epoch:  481        9 Batch loss: 0.068773 Batch F1: 0.7692307692307693
Epoch:  481       10 Batch loss: 0.071290 Batch F1: 0.4615384615384615
Epoch:  481       11 Batch loss: 0.047911 Batch F1: 0.4444444444444445
Epoch:  481       12 Batch loss: 0.047597 Batch F1: 0.6666666666666666
Train Avg Loss  481: 0.067647

Train Avg F1  481: 0.8058663217873745

Val Avg Loss  481: 0.062831

Val Avg F1  481:  0.5592105263157895

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 482
--------------------------------------------------------------
Epoch:  482        1 Batch loss: 0.096003 Batch F1: 0.2666666666666667
Epoch:  482        2 Batch loss: 0.061063 Batch F1: 0.25
Epoch:  482        3 Batch loss: 0.058169 Batch F1: 1.0
Epoch:  482        4 Batch loss: 0.063333 Batch F1: 0.9333333333333333
Epoch:  482        5 Batch loss: 0.055319 Batch F1: 0.923076923076923
Epoch:  482        6 Batch loss: 0.048301 Batch F1: 0.7499999999999999
Epoch:  482        7 Batch loss: 0.045383 Batch F1: 0.6666666666666666
Epoch:  482        8 Batch loss: 0.097723 Batch F1: 0.5263157894736842
Epoch:  482        9 Batch loss: 0.081981 Batch F1: 0.42857142857142855
Epoch:  482       10 Batch loss: 0.071081 Batch F1: 0.625
Epoch:  482       11 Batch loss: 0.075459 Batch F1: 0.9473684210526316
Epoch:  482       12 Batch loss: 0.089720 Batch F1: 0.923076923076923
Train Avg Loss  482: 0.070295

Train Avg F1  482: 0.6866730126598548

Val Avg Loss  482: 0.064870

Val Avg F1  482:  0.9230357142857143

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 483
--------------------------------------------------------------
Epoch:  483        1 Batch loss: 0.068686 Batch F1: 0.8571428571428571
Epoch:  483        2 Batch loss: 0.078282 Batch F1: 0.9523809523809523
Epoch:  483        3 Batch loss: 0.062232 Batch F1: 0.9090909090909091
Epoch:  483        4 Batch loss: 0.077635 Batch F1: 0.8421052631578948
Epoch:  483        5 Batch loss: 0.063468 Batch F1: 1.0
Epoch:  483        6 Batch loss: 0.081956 Batch F1: 0.888888888888889
Epoch:  483        7 Batch loss: 0.058847 Batch F1: 0.9090909090909091
Epoch:  483        8 Batch loss: 0.067307 Batch F1: 0.9473684210526316
Epoch:  483        9 Batch loss: 0.076789 Batch F1: 0.9523809523809523
Epoch:  483       10 Batch loss: 0.051420 Batch F1: 0.33333333333333337
Epoch:  483       11 Batch loss: 0.088613 Batch F1: 0.3076923076923077
Epoch:  483       12 Batch loss: 0.068010 Batch F1: 0.7142857142857143
Train Avg Loss  483: 0.070270

Train Avg F1  483: 0.801146709041446

Val Avg Loss  483: 0.063070

Val Avg F1  483:  0.9265873015873016

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 484
--------------------------------------------------------------
Epoch:  484        1 Batch loss: 0.081920 Batch F1: 0.9565217391304348
Epoch:  484        2 Batch loss: 0.065510 Batch F1: 1.0
Epoch:  484        3 Batch loss: 0.045375 Batch F1: 0.8
Epoch:  484        4 Batch loss: 0.065984 Batch F1: 0.9333333333333333
Epoch:  484        5 Batch loss: 0.071229 Batch F1: 0.9411764705882353
Epoch:  484        6 Batch loss: 0.062834 Batch F1: 0.6666666666666666
Epoch:  484        7 Batch loss: 0.062627 Batch F1: 0.6153846153846153
Epoch:  484        8 Batch loss: 0.053129 Batch F1: 0.6666666666666666
Epoch:  484        9 Batch loss: 0.083757 Batch F1: 0.42857142857142855
Epoch:  484       10 Batch loss: 0.120611 Batch F1: 0.5454545454545454
Epoch:  484       11 Batch loss: 0.069586 Batch F1: 1.0
Epoch:  484       12 Batch loss: 0.070567 Batch F1: 0.8571428571428571
Train Avg Loss  484: 0.071094

Train Avg F1  484: 0.784243193578232

Val Avg Loss  484: 0.064420

Val Avg F1  484:  0.9166666666666667

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 485
--------------------------------------------------------------
Epoch:  485        1 Batch loss: 0.067908 Batch F1: 0.8333333333333333
Epoch:  485        2 Batch loss: 0.079476 Batch F1: 0.9090909090909091
Epoch:  485        3 Batch loss: 0.084164 Batch F1: 0.6666666666666666
Epoch:  485        4 Batch loss: 0.069135 Batch F1: 0.6666666666666666
Epoch:  485        5 Batch loss: 0.075115 Batch F1: 0.8750000000000001
Epoch:  485        6 Batch loss: 0.087095 Batch F1: 0.9090909090909091
Epoch:  485        7 Batch loss: 0.082422 Batch F1: 0.9565217391304348
Epoch:  485        8 Batch loss: 0.068075 Batch F1: 0.888888888888889
Epoch:  485        9 Batch loss: 0.045189 Batch F1: 1.0
Epoch:  485       10 Batch loss: 0.074969 Batch F1: 0.3636363636363636
Epoch:  485       11 Batch loss: 0.058890 Batch F1: 0.6153846153846153
Epoch:  485       12 Batch loss: 0.057038 Batch F1: 0.5714285714285715
Train Avg Loss  485: 0.070790

Train Avg F1  485: 0.7713090552764466

Val Avg Loss  485: 0.066043

Val Avg F1  485:  0.5811965811965814

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 486
--------------------------------------------------------------
Epoch:  486        1 Batch loss: 0.073904 Batch F1: 0.5714285714285715
Epoch:  486        2 Batch loss: 0.067581 Batch F1: 0.0
Epoch:  486        3 Batch loss: 0.076523 Batch F1: 0.33333333333333337
Epoch:  486        4 Batch loss: 0.048587 Batch F1: 0.888888888888889
Epoch:  486        5 Batch loss: 0.081106 Batch F1: 0.6363636363636364
Epoch:  486        6 Batch loss: 0.072994 Batch F1: 0.888888888888889
Epoch:  486        7 Batch loss: 0.084912 Batch F1: 0.8235294117647058
Epoch:  486        8 Batch loss: 0.060952 Batch F1: 1.0
Epoch:  486        9 Batch loss: 0.079335 Batch F1: 0.9523809523809523
Epoch:  486       10 Batch loss: 0.065882 Batch F1: 0.8750000000000001
Epoch:  486       11 Batch loss: 0.069228 Batch F1: 0.9565217391304348
Epoch:  486       12 Batch loss: 0.050350 Batch F1: 1.0
Train Avg Loss  486: 0.069279

Train Avg F1  486: 0.7438612851816178

Val Avg Loss  486: 0.062022

Val Avg F1  486:  0.9160087719298247

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 487
--------------------------------------------------------------
Epoch:  487        1 Batch loss: 0.066563 Batch F1: 0.9523809523809523
Epoch:  487        2 Batch loss: 0.057020 Batch F1: 0.2857142857142857
Epoch:  487        3 Batch loss: 0.078353 Batch F1: 0.5333333333333333
Epoch:  487        4 Batch loss: 0.059800 Batch F1: 0.0
Epoch:  487        5 Batch loss: 0.060903 Batch F1: 0.2222222222222222
Epoch:  487        6 Batch loss: 0.054317 Batch F1: 0.7272727272727273
Epoch:  487        7 Batch loss: 0.057018 Batch F1: 0.7692307692307693
Epoch:  487        8 Batch loss: 0.085593 Batch F1: 0.25
Epoch:  487        9 Batch loss: 0.080743 Batch F1: 0.3076923076923077
Epoch:  487       10 Batch loss: 0.072335 Batch F1: 0.5333333333333333
Epoch:  487       11 Batch loss: 0.078755 Batch F1: 0.375
Epoch:  487       12 Batch loss: 0.072347 Batch F1: 0.8750000000000001
Train Avg Loss  487: 0.068646

Train Avg F1  487: 0.4859316609316609

Val Avg Loss  487: 0.062630

Val Avg F1  487:  0.9249373433583961

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 488
--------------------------------------------------------------
Epoch:  488        1 Batch loss: 0.074412 Batch F1: 0.8235294117647058
Epoch:  488        2 Batch loss: 0.059466 Batch F1: 0.923076923076923
Epoch:  488        3 Batch loss: 0.077871 Batch F1: 0.9333333333333333
Epoch:  488        4 Batch loss: 0.080392 Batch F1: 0.9166666666666666
Epoch:  488        5 Batch loss: 0.064332 Batch F1: 0.9333333333333333
Epoch:  488        6 Batch loss: 0.071019 Batch F1: 0.923076923076923
Epoch:  488        7 Batch loss: 0.073716 Batch F1: 0.9473684210526316
Epoch:  488        8 Batch loss: 0.062058 Batch F1: 1.0
Epoch:  488        9 Batch loss: 0.074314 Batch F1: 0.8571428571428571
Epoch:  488       10 Batch loss: 0.071844 Batch F1: 0.6666666666666666
Epoch:  488       11 Batch loss: 0.072952 Batch F1: 0.888888888888889
Epoch:  488       12 Batch loss: 0.048150 Batch F1: 1.0
Train Avg Loss  488: 0.069210

Train Avg F1  488: 0.9010902854169108

Val Avg Loss  488: 0.062637

Val Avg F1  488:  0.919394615046789

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 489
--------------------------------------------------------------
Epoch:  489        1 Batch loss: 0.054358 Batch F1: 0.888888888888889
Epoch:  489        2 Batch loss: 0.078669 Batch F1: 0.6666666666666666
Epoch:  489        3 Batch loss: 0.089366 Batch F1: 0.18181818181818182
Epoch:  489        4 Batch loss: 0.056527 Batch F1: 0.6666666666666666
Epoch:  489        5 Batch loss: 0.067573 Batch F1: 0.3636363636363636
Epoch:  489        6 Batch loss: 0.060382 Batch F1: 0.4
Epoch:  489        7 Batch loss: 0.060794 Batch F1: 0.5454545454545454
Epoch:  489        8 Batch loss: 0.078509 Batch F1: 0.7368421052631579
Epoch:  489        9 Batch loss: 0.059918 Batch F1: 1.0
Epoch:  489       10 Batch loss: 0.073857 Batch F1: 0.9090909090909091
Epoch:  489       11 Batch loss: 0.073068 Batch F1: 0.9090909090909091
Epoch:  489       12 Batch loss: 0.068319 Batch F1: 0.923076923076923
Train Avg Loss  489: 0.068445

Train Avg F1  489: 0.682602679971101

Val Avg Loss  489: 0.061820

Val Avg F1  489:  0.92421955624355

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 490
--------------------------------------------------------------
Epoch:  490        1 Batch loss: 0.083118 Batch F1: 0.7142857142857143
Epoch:  490        2 Batch loss: 0.070678 Batch F1: 1.0
Epoch:  490        3 Batch loss: 0.058114 Batch F1: 0.8571428571428571
Epoch:  490        4 Batch loss: 0.064912 Batch F1: 0.9473684210526316
Epoch:  490        5 Batch loss: 0.037158 Batch F1: 1.0
Epoch:  490        6 Batch loss: 0.089953 Batch F1: 0.18181818181818182
Epoch:  490        7 Batch loss: 0.068001 Batch F1: 0.5882352941176471
Epoch:  490        8 Batch loss: 0.073424 Batch F1: 0.5454545454545454
Epoch:  490        9 Batch loss: 0.078381 Batch F1: 0.47058823529411764
Epoch:  490       10 Batch loss: 0.064179 Batch F1: 0.888888888888889
Epoch:  490       11 Batch loss: 0.062210 Batch F1: 0.9333333333333333
Epoch:  490       12 Batch loss: 0.069746 Batch F1: 0.9411764705882353
Train Avg Loss  490: 0.068323

Train Avg F1  490: 0.7556909951646794

Val Avg Loss  490: 0.062055

Val Avg F1  490:  0.9183298319327731

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 491
--------------------------------------------------------------
Epoch:  491        1 Batch loss: 0.068328 Batch F1: 0.8571428571428571
Epoch:  491        2 Batch loss: 0.055821 Batch F1: 0.923076923076923
Epoch:  491        3 Batch loss: 0.067539 Batch F1: 0.9411764705882353
Epoch:  491        4 Batch loss: 0.090216 Batch F1: 0.7777777777777778
Epoch:  491        5 Batch loss: 0.075556 Batch F1: 0.888888888888889
Epoch:  491        6 Batch loss: 0.064743 Batch F1: 1.0
Epoch:  491        7 Batch loss: 0.054514 Batch F1: 0.8571428571428571
Epoch:  491        8 Batch loss: 0.063506 Batch F1: 0.9333333333333333
Epoch:  491        9 Batch loss: 0.067836 Batch F1: 0.9565217391304348
Epoch:  491       10 Batch loss: 0.057167 Batch F1: 0.923076923076923
Epoch:  491       11 Batch loss: 0.056986 Batch F1: 1.0
Epoch:  491       12 Batch loss: 0.096672 Batch F1: 0.47058823529411764
Train Avg Loss  491: 0.068240

Train Avg F1  491: 0.8773938337876958

Val Avg Loss  491: 0.061512

Val Avg F1  491:  0.9196859903381642

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 492
--------------------------------------------------------------
Epoch:  492        1 Batch loss: 0.062462 Batch F1: 0.9523809523809523
Epoch:  492        2 Batch loss: 0.058071 Batch F1: 0.888888888888889
Epoch:  492        3 Batch loss: 0.065322 Batch F1: 0.923076923076923
Epoch:  492        4 Batch loss: 0.079626 Batch F1: 1.0
Epoch:  492        5 Batch loss: 0.073343 Batch F1: 0.9473684210526316
Epoch:  492        6 Batch loss: 0.076351 Batch F1: 0.962962962962963
Epoch:  492        7 Batch loss: 0.070634 Batch F1: 0.9600000000000001
Epoch:  492        8 Batch loss: 0.068998 Batch F1: 0.9
Epoch:  492        9 Batch loss: 0.081521 Batch F1: 0.8421052631578948
Epoch:  492       10 Batch loss: 0.062608 Batch F1: 0.8571428571428571
Epoch:  492       11 Batch loss: 0.059239 Batch F1: 0.8571428571428571
Epoch:  492       12 Batch loss: 0.057394 Batch F1: 0.5
Train Avg Loss  492: 0.067964

Train Avg F1  492: 0.8825890938171641

Val Avg Loss  492: 0.062157

Val Avg F1  492:  0.9247468218056454

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 493
--------------------------------------------------------------
Epoch:  493        1 Batch loss: 0.076607 Batch F1: 0.6666666666666666
Epoch:  493        2 Batch loss: 0.054389 Batch F1: 1.0
Epoch:  493        3 Batch loss: 0.072578 Batch F1: 0.888888888888889
Epoch:  493        4 Batch loss: 0.087320 Batch F1: 0.923076923076923
Epoch:  493        5 Batch loss: 0.074926 Batch F1: 0.9523809523809523
Epoch:  493        6 Batch loss: 0.072494 Batch F1: 0.7692307692307693
Epoch:  493        7 Batch loss: 0.076767 Batch F1: 0.9473684210526316
Epoch:  493        8 Batch loss: 0.062120 Batch F1: 1.0
Epoch:  493        9 Batch loss: 0.062122 Batch F1: 0.9090909090909091
Epoch:  493       10 Batch loss: 0.056083 Batch F1: 0.7272727272727273
Epoch:  493       11 Batch loss: 0.081067 Batch F1: 0.5
Epoch:  493       12 Batch loss: 0.058799 Batch F1: 0.7692307692307693
Train Avg Loss  493: 0.069606

Train Avg F1  493: 0.8377672522409364

Val Avg Loss  493: 0.062650

Val Avg F1  493:  0.5489661654135338

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 494
--------------------------------------------------------------
Epoch:  494        1 Batch loss: 0.056256 Batch F1: 0.5714285714285715
Epoch:  494        2 Batch loss: 0.069537 Batch F1: 0.3636363636363636
Epoch:  494        3 Batch loss: 0.091558 Batch F1: 0.3076923076923077
Epoch:  494        4 Batch loss: 0.060387 Batch F1: 0.4
Epoch:  494        5 Batch loss: 0.071243 Batch F1: 0.6666666666666666
Epoch:  494        6 Batch loss: 0.064300 Batch F1: 0.42857142857142855
Epoch:  494        7 Batch loss: 0.082569 Batch F1: 0.8571428571428571
Epoch:  494        8 Batch loss: 0.059281 Batch F1: 0.7499999999999999
Epoch:  494        9 Batch loss: 0.064370 Batch F1: 1.0
Epoch:  494       10 Batch loss: 0.065848 Batch F1: 0.7142857142857143
Epoch:  494       11 Batch loss: 0.068812 Batch F1: 0.8750000000000001
Epoch:  494       12 Batch loss: 0.076727 Batch F1: 0.6666666666666666
Train Avg Loss  494: 0.069241

Train Avg F1  494: 0.6334242146742147

Val Avg Loss  494: 0.062313

Val Avg F1  494:  0.7461352657004832

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 495
--------------------------------------------------------------
Epoch:  495        1 Batch loss: 0.070339 Batch F1: 0.8421052631578948
Epoch:  495        2 Batch loss: 0.059605 Batch F1: 1.0
Epoch:  495        3 Batch loss: 0.072131 Batch F1: 0.923076923076923
Epoch:  495        4 Batch loss: 0.067315 Batch F1: 0.9411764705882353
Epoch:  495        5 Batch loss: 0.059985 Batch F1: 0.5
Epoch:  495        6 Batch loss: 0.086443 Batch F1: 0.5
Epoch:  495        7 Batch loss: 0.045468 Batch F1: 0.5714285714285715
Epoch:  495        8 Batch loss: 0.070574 Batch F1: 0.33333333333333337
Epoch:  495        9 Batch loss: 0.097203 Batch F1: 0.6956521739130436
Epoch:  495       10 Batch loss: 0.068983 Batch F1: 1.0
Epoch:  495       11 Batch loss: 0.066478 Batch F1: 0.888888888888889
Epoch:  495       12 Batch loss: 0.073544 Batch F1: 0.923076923076923
Train Avg Loss  495: 0.069839

Train Avg F1  495: 0.7598948789553178

Val Avg Loss  495: 0.063853

Val Avg F1  495:  0.7389705882352939

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 496
--------------------------------------------------------------
Epoch:  496        1 Batch loss: 0.049339 Batch F1: 0.9090909090909091
Epoch:  496        2 Batch loss: 0.071759 Batch F1: 0.5
Epoch:  496        3 Batch loss: 0.070847 Batch F1: 0.6666666666666666
Epoch:  496        4 Batch loss: 0.050855 Batch F1: 1.0
Epoch:  496        5 Batch loss: 0.071983 Batch F1: 0.8333333333333333
Epoch:  496        6 Batch loss: 0.062486 Batch F1: 1.0
Epoch:  496        7 Batch loss: 0.068907 Batch F1: 0.9523809523809523
Epoch:  496        8 Batch loss: 0.083760 Batch F1: 0.8571428571428571
Epoch:  496        9 Batch loss: 0.087935 Batch F1: 0.9166666666666666
Epoch:  496       10 Batch loss: 0.052234 Batch F1: 0.923076923076923
Epoch:  496       11 Batch loss: 0.070161 Batch F1: 0.9473684210526316
Epoch:  496       12 Batch loss: 0.095032 Batch F1: 0.7142857142857143
Train Avg Loss  496: 0.069608

Train Avg F1  496: 0.8516677036413878

Val Avg Loss  496: 0.061695

Val Avg F1  496:  0.91875

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 497
--------------------------------------------------------------
Epoch:  497        1 Batch loss: 0.059948 Batch F1: 0.9333333333333333
Epoch:  497        2 Batch loss: 0.073258 Batch F1: 0.8
Epoch:  497        3 Batch loss: 0.059272 Batch F1: 0.8571428571428571
Epoch:  497        4 Batch loss: 0.070612 Batch F1: 0.9333333333333333
Epoch:  497        5 Batch loss: 0.053269 Batch F1: 0.2857142857142857
Epoch:  497        6 Batch loss: 0.088204 Batch F1: 0.5263157894736842
Epoch:  497        7 Batch loss: 0.073440 Batch F1: 0.42857142857142855
Epoch:  497        8 Batch loss: 0.059784 Batch F1: 0.8750000000000001
Epoch:  497        9 Batch loss: 0.089956 Batch F1: 0.962962962962963
Epoch:  497       10 Batch loss: 0.086177 Batch F1: 0.8
Epoch:  497       11 Batch loss: 0.069058 Batch F1: 1.0
Epoch:  497       12 Batch loss: 0.058820 Batch F1: 1.0
Train Avg Loss  497: 0.070150

Train Avg F1  497: 0.783531165877657

Val Avg Loss  497: 0.064717

Val Avg F1  497:  0.557378079436903

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 498
--------------------------------------------------------------
Epoch:  498        1 Batch loss: 0.092530 Batch F1: 0.47058823529411764
Epoch:  498        2 Batch loss: 0.075456 Batch F1: 0.4615384615384615
Epoch:  498        3 Batch loss: 0.073735 Batch F1: 0.5454545454545454
Epoch:  498        4 Batch loss: 0.047983 Batch F1: 1.0
Epoch:  498        5 Batch loss: 0.053962 Batch F1: 1.0
Epoch:  498        6 Batch loss: 0.090853 Batch F1: 0.7272727272727273
Epoch:  498        7 Batch loss: 0.074423 Batch F1: 0.9473684210526316
Epoch:  498        8 Batch loss: 0.081086 Batch F1: 0.7692307692307693
Epoch:  498        9 Batch loss: 0.068635 Batch F1: 0.9523809523809523
Epoch:  498       10 Batch loss: 0.041458 Batch F1: 1.0
Epoch:  498       11 Batch loss: 0.055940 Batch F1: 0.8571428571428571
Epoch:  498       12 Batch loss: 0.079329 Batch F1: 0.6666666666666666
Train Avg Loss  498: 0.069616

Train Avg F1  498: 0.7831369696694774

Val Avg Loss  498: 0.063327

Val Avg F1  498:  0.4676329862088376

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 499
--------------------------------------------------------------
Epoch:  499        1 Batch loss: 0.067422 Batch F1: 0.5454545454545454
Epoch:  499        2 Batch loss: 0.078321 Batch F1: 0.4615384615384615
Epoch:  499        3 Batch loss: 0.074126 Batch F1: 0.9
Epoch:  499        4 Batch loss: 0.068042 Batch F1: 0.923076923076923
Epoch:  499        5 Batch loss: 0.070251 Batch F1: 0.888888888888889
Epoch:  499        6 Batch loss: 0.087065 Batch F1: 0.8571428571428571
Epoch:  499        7 Batch loss: 0.053548 Batch F1: 0.923076923076923
Epoch:  499        8 Batch loss: 0.050779 Batch F1: 0.8
Epoch:  499        9 Batch loss: 0.098431 Batch F1: 0.4210526315789474
Epoch:  499       10 Batch loss: 0.055387 Batch F1: 0.4444444444444445
Epoch:  499       11 Batch loss: 0.067837 Batch F1: 0.3636363636363636
Epoch:  499       12 Batch loss: 0.057474 Batch F1: 0.9090909090909091
Train Avg Loss  499: 0.069057

Train Avg F1  499: 0.7031169123274386

Val Avg Loss  499: 0.062351

Val Avg F1  499:  0.7036713286713286

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 500
--------------------------------------------------------------
Epoch:  500        1 Batch loss: 0.058185 Batch F1: 0.2857142857142857
Epoch:  500        2 Batch loss: 0.052428 Batch F1: 0.6666666666666666
Epoch:  500        3 Batch loss: 0.071479 Batch F1: 0.5714285714285715
Epoch:  500        4 Batch loss: 0.103665 Batch F1: 0.9333333333333333
Epoch:  500        5 Batch loss: 0.060576 Batch F1: 0.923076923076923
Epoch:  500        6 Batch loss: 0.059247 Batch F1: 0.9473684210526316
Epoch:  500        7 Batch loss: 0.067342 Batch F1: 0.9411764705882353
Epoch:  500        8 Batch loss: 0.073267 Batch F1: 0.9523809523809523
Epoch:  500        9 Batch loss: 0.091751 Batch F1: 0.8181818181818181
Epoch:  500       10 Batch loss: 0.072689 Batch F1: 0.9411764705882353
Epoch:  500       11 Batch loss: 0.054335 Batch F1: 0.888888888888889
Epoch:  500       12 Batch loss: 0.062668 Batch F1: 1.0
Train Avg Loss  500: 0.068969

Train Avg F1  500: 0.8224494001583785

Val Avg Loss  500: 0.061377

Val Avg F1  500:  0.9398395721925134

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 501
--------------------------------------------------------------
Epoch:  501        1 Batch loss: 0.060845 Batch F1: 0.923076923076923
Epoch:  501        2 Batch loss: 0.076030 Batch F1: 0.9523809523809523
Epoch:  501        3 Batch loss: 0.072329 Batch F1: 0.5454545454545454
Epoch:  501        4 Batch loss: 0.049189 Batch F1: 0.5
Epoch:  501        5 Batch loss: 0.077806 Batch F1: 0.3636363636363636
Epoch:  501        6 Batch loss: 0.053425 Batch F1: 0.6666666666666666
Epoch:  501        7 Batch loss: 0.071548 Batch F1: 0.42857142857142855
Epoch:  501        8 Batch loss: 0.077604 Batch F1: 0.42857142857142855
Epoch:  501        9 Batch loss: 0.060155 Batch F1: 0.6666666666666666
Epoch:  501       10 Batch loss: 0.094276 Batch F1: 0.8333333333333333
Epoch:  501       11 Batch loss: 0.069365 Batch F1: 0.9473684210526316
Epoch:  501       12 Batch loss: 0.056514 Batch F1: 1.0
Train Avg Loss  501: 0.068257

Train Avg F1  501: 0.6879772274509118

Val Avg Loss  501: 0.063082

Val Avg F1  501:  0.9171626984126985

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 502
--------------------------------------------------------------
Epoch:  502        1 Batch loss: 0.052482 Batch F1: 1.0
Epoch:  502        2 Batch loss: 0.062511 Batch F1: 1.0
Epoch:  502        3 Batch loss: 0.076658 Batch F1: 0.8750000000000001
Epoch:  502        4 Batch loss: 0.061402 Batch F1: 1.0
Epoch:  502        5 Batch loss: 0.088403 Batch F1: 0.761904761904762
Epoch:  502        6 Batch loss: 0.066445 Batch F1: 0.4
Epoch:  502        7 Batch loss: 0.074351 Batch F1: 0.7368421052631579
Epoch:  502        8 Batch loss: 0.067496 Batch F1: 0.8333333333333333
Epoch:  502        9 Batch loss: 0.075089 Batch F1: 0.888888888888889
Epoch:  502       10 Batch loss: 0.046739 Batch F1: 0.6666666666666666
Epoch:  502       11 Batch loss: 0.105993 Batch F1: 0.33333333333333337
Epoch:  502       12 Batch loss: 0.055302 Batch F1: 0.33333333333333337
Train Avg Loss  502: 0.069406

Train Avg F1  502: 0.735775201893623

Val Avg Loss  502: 0.061867

Val Avg F1  502:  0.6771395636527215

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 503
--------------------------------------------------------------
Epoch:  503        1 Batch loss: 0.062680 Batch F1: 0.5
Epoch:  503        2 Batch loss: 0.057310 Batch F1: 0.6153846153846153
Epoch:  503        3 Batch loss: 0.082523 Batch F1: 0.631578947368421
Epoch:  503        4 Batch loss: 0.056564 Batch F1: 0.0
Epoch:  503        5 Batch loss: 0.086177 Batch F1: 0.5
Epoch:  503        6 Batch loss: 0.061007 Batch F1: 0.5
Epoch:  503        7 Batch loss: 0.081623 Batch F1: 0.5
Epoch:  503        8 Batch loss: 0.081150 Batch F1: 0.9
Epoch:  503        9 Batch loss: 0.054308 Batch F1: 1.0
Epoch:  503       10 Batch loss: 0.065880 Batch F1: 0.9473684210526316
Epoch:  503       11 Batch loss: 0.050630 Batch F1: 1.0
Epoch:  503       12 Batch loss: 0.070842 Batch F1: 0.9565217391304348
Train Avg Loss  503: 0.067558

Train Avg F1  503: 0.670904476911342

Val Avg Loss  503: 0.060983

Val Avg F1  503:  0.9042857142857142

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 504
--------------------------------------------------------------
Epoch:  504        1 Batch loss: 0.068510 Batch F1: 1.0
Epoch:  504        2 Batch loss: 0.066073 Batch F1: 0.9473684210526316
Epoch:  504        3 Batch loss: 0.060398 Batch F1: 0.923076923076923
Epoch:  504        4 Batch loss: 0.067415 Batch F1: 0.888888888888889
Epoch:  504        5 Batch loss: 0.079319 Batch F1: 0.8571428571428571
Epoch:  504        6 Batch loss: 0.057380 Batch F1: 0.8571428571428571
Epoch:  504        7 Batch loss: 0.069355 Batch F1: 0.9411764705882353
Epoch:  504        8 Batch loss: 0.071436 Batch F1: 0.8571428571428571
Epoch:  504        9 Batch loss: 0.065566 Batch F1: 1.0
Epoch:  504       10 Batch loss: 0.060397 Batch F1: 0.9411764705882353
Epoch:  504       11 Batch loss: 0.082075 Batch F1: 0.8
Epoch:  504       12 Batch loss: 0.052065 Batch F1: 0.9090909090909091
Train Avg Loss  504: 0.066666

Train Avg F1  504: 0.9101838878928662

Val Avg Loss  504: 0.060847

Val Avg F1  504:  0.9152930402930404

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 505
--------------------------------------------------------------
Epoch:  505        1 Batch loss: 0.085349 Batch F1: 0.6153846153846153
Epoch:  505        2 Batch loss: 0.052601 Batch F1: 1.0
Epoch:  505        3 Batch loss: 0.073598 Batch F1: 0.8
Epoch:  505        4 Batch loss: 0.056946 Batch F1: 1.0
Epoch:  505        5 Batch loss: 0.056171 Batch F1: 1.0
Epoch:  505        6 Batch loss: 0.071984 Batch F1: 0.9473684210526316
Epoch:  505        7 Batch loss: 0.067489 Batch F1: 0.6666666666666666
Epoch:  505        8 Batch loss: 0.074409 Batch F1: 0.9090909090909091
Epoch:  505        9 Batch loss: 0.055096 Batch F1: 0.6
Epoch:  505       10 Batch loss: 0.066940 Batch F1: 0.625
Epoch:  505       11 Batch loss: 0.068457 Batch F1: 0.4615384615384615
Epoch:  505       12 Batch loss: 0.077818 Batch F1: 0.3636363636363636
Train Avg Loss  505: 0.067238

Train Avg F1  505: 0.749057119780804

Val Avg Loss  505: 0.061114

Val Avg F1  505:  0.5852007469654528

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 506
--------------------------------------------------------------
Epoch:  506        1 Batch loss: 0.064169 Batch F1: 0.6153846153846153
Epoch:  506        2 Batch loss: 0.083403 Batch F1: 0.9090909090909091
Epoch:  506        3 Batch loss: 0.066957 Batch F1: 0.9523809523809523
Epoch:  506        4 Batch loss: 0.069859 Batch F1: 0.9411764705882353
Epoch:  506        5 Batch loss: 0.064272 Batch F1: 0.9411764705882353
Epoch:  506        6 Batch loss: 0.064731 Batch F1: 0.8333333333333333
Epoch:  506        7 Batch loss: 0.080726 Batch F1: 0.9565217391304348
Epoch:  506        8 Batch loss: 0.072123 Batch F1: 0.888888888888889
Epoch:  506        9 Batch loss: 0.051668 Batch F1: 1.0
Epoch:  506       10 Batch loss: 0.068958 Batch F1: 0.888888888888889
Epoch:  506       11 Batch loss: 0.056728 Batch F1: 0.9333333333333333
Epoch:  506       12 Batch loss: 0.056630 Batch F1: 0.923076923076923
Train Avg Loss  506: 0.066685

Train Avg F1  506: 0.8986043770570626

Val Avg Loss  506: 0.062031

Val Avg F1  506:  0.5717338217338217

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 507
--------------------------------------------------------------
Epoch:  507        1 Batch loss: 0.058320 Batch F1: 0.6
Epoch:  507        2 Batch loss: 0.062456 Batch F1: 0.5454545454545454
Epoch:  507        3 Batch loss: 0.045046 Batch F1: 0.7272727272727273
Epoch:  507        4 Batch loss: 0.075852 Batch F1: 0.625
Epoch:  507        5 Batch loss: 0.065439 Batch F1: 0.625
Epoch:  507        6 Batch loss: 0.077489 Batch F1: 0.2857142857142857
Epoch:  507        7 Batch loss: 0.084667 Batch F1: 0.8
Epoch:  507        8 Batch loss: 0.058476 Batch F1: 0.923076923076923
Epoch:  507        9 Batch loss: 0.079236 Batch F1: 0.8571428571428571
Epoch:  507       10 Batch loss: 0.056683 Batch F1: 1.0
Epoch:  507       11 Batch loss: 0.084985 Batch F1: 0.7142857142857143
Epoch:  507       12 Batch loss: 0.076603 Batch F1: 0.923076923076923
Train Avg Loss  507: 0.068771

Train Avg F1  507: 0.7188353313353314

Val Avg Loss  507: 0.061990

Val Avg F1  507:  0.9149466804265565

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 508
--------------------------------------------------------------
Epoch:  508        1 Batch loss: 0.098428 Batch F1: 0.888888888888889
Epoch:  508        2 Batch loss: 0.075054 Batch F1: 0.888888888888889
Epoch:  508        3 Batch loss: 0.075922 Batch F1: 0.7692307692307693
Epoch:  508        4 Batch loss: 0.053121 Batch F1: 0.7499999999999999
Epoch:  508        5 Batch loss: 0.066581 Batch F1: 0.6153846153846153
Epoch:  508        6 Batch loss: 0.076869 Batch F1: 0.6666666666666666
Epoch:  508        7 Batch loss: 0.057633 Batch F1: 0.5454545454545454
Epoch:  508        8 Batch loss: 0.075214 Batch F1: 0.761904761904762
Epoch:  508        9 Batch loss: 0.067848 Batch F1: 0.8333333333333333
Epoch:  508       10 Batch loss: 0.068391 Batch F1: 1.0
Epoch:  508       11 Batch loss: 0.069382 Batch F1: 0.4
Epoch:  508       12 Batch loss: 0.055391 Batch F1: 0.8
Train Avg Loss  508: 0.069986

Train Avg F1  508: 0.7433127058127059

Val Avg Loss  508: 0.067200

Val Avg F1  508:  0.5561497326203209

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 509
--------------------------------------------------------------
Epoch:  509        1 Batch loss: 0.059415 Batch F1: 0.8
Epoch:  509        2 Batch loss: 0.067362 Batch F1: 0.5
Epoch:  509        3 Batch loss: 0.082277 Batch F1: 0.42857142857142855
Epoch:  509        4 Batch loss: 0.078333 Batch F1: 0.8571428571428571
Epoch:  509        5 Batch loss: 0.066218 Batch F1: 0.9333333333333333
Epoch:  509        6 Batch loss: 0.074992 Batch F1: 0.3636363636363636
Epoch:  509        7 Batch loss: 0.068428 Batch F1: 0.33333333333333337
Epoch:  509        8 Batch loss: 0.092138 Batch F1: 0.7777777777777778
Epoch:  509        9 Batch loss: 0.078322 Batch F1: 1.0
Epoch:  509       10 Batch loss: 0.067524 Batch F1: 0.9090909090909091
Epoch:  509       11 Batch loss: 0.077305 Batch F1: 0.8750000000000001
Epoch:  509       12 Batch loss: 0.063918 Batch F1: 0.7499999999999999
Train Avg Loss  509: 0.073019

Train Avg F1  509: 0.710657166907167

Val Avg Loss  509: 0.075380

Val Avg F1  509:  0.0

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 510
--------------------------------------------------------------
Epoch:  510        1 Batch loss: 0.074089 Batch F1: 0.0
Epoch:  510        2 Batch loss: 0.095588 Batch F1: 0.375
Epoch:  510        3 Batch loss: 0.077645 Batch F1: 0.9166666666666666
Epoch:  510        4 Batch loss: 0.091827 Batch F1: 0.9090909090909091
Epoch:  510        5 Batch loss: 0.077438 Batch F1: 0.9411764705882353
Epoch:  510        6 Batch loss: 0.040828 Batch F1: 0.8
Epoch:  510        7 Batch loss: 0.082063 Batch F1: 0.33333333333333337
Epoch:  510        8 Batch loss: 0.066546 Batch F1: 0.6153846153846153
Epoch:  510        9 Batch loss: 0.052285 Batch F1: 0.5
Epoch:  510       10 Batch loss: 0.089512 Batch F1: 0.33333333333333337
Epoch:  510       11 Batch loss: 0.058496 Batch F1: 0.6
Epoch:  510       12 Batch loss: 0.071641 Batch F1: 0.25
Train Avg Loss  510: 0.073163

Train Avg F1  510: 0.5478321106997576

Val Avg Loss  510: 0.064594

Val Avg F1  510:  0.4865667420814479

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 511
--------------------------------------------------------------
Epoch:  511        1 Batch loss: 0.063451 Batch F1: 0.0
Epoch:  511        2 Batch loss: 0.063772 Batch F1: 0.7368421052631579
Epoch:  511        3 Batch loss: 0.080712 Batch F1: 1.0
Epoch:  511        4 Batch loss: 0.081166 Batch F1: 0.9333333333333333
Epoch:  511        5 Batch loss: 0.060608 Batch F1: 0.9090909090909091
Epoch:  511        6 Batch loss: 0.063114 Batch F1: 0.4444444444444445
Epoch:  511        7 Batch loss: 0.091527 Batch F1: 0.0
Epoch:  511        8 Batch loss: 0.077863 Batch F1: 0.5714285714285715
Epoch:  511        9 Batch loss: 0.068812 Batch F1: 1.0
Epoch:  511       10 Batch loss: 0.084539 Batch F1: 0.5
Epoch:  511       11 Batch loss: 0.078200 Batch F1: 0.9523809523809523
Epoch:  511       12 Batch loss: 0.065088 Batch F1: 0.8
Train Avg Loss  511: 0.073238

Train Avg F1  511: 0.6539600263284474

Val Avg Loss  511: 0.064629

Val Avg F1  511:  0.5848214285714286

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 512
--------------------------------------------------------------
Epoch:  512        1 Batch loss: 0.072528 Batch F1: 0.0
Epoch:  512        2 Batch loss: 0.055337 Batch F1: 0.6
Epoch:  512        3 Batch loss: 0.065866 Batch F1: 0.7499999999999999
Epoch:  512        4 Batch loss: 0.068908 Batch F1: 0.5454545454545454
Epoch:  512        5 Batch loss: 0.067662 Batch F1: 0.3636363636363636
Epoch:  512        6 Batch loss: 0.071025 Batch F1: 0.0
Epoch:  512        7 Batch loss: 0.062945 Batch F1: 0.6666666666666666
Epoch:  512        8 Batch loss: 0.088502 Batch F1: 0.923076923076923
Epoch:  512        9 Batch loss: 0.077618 Batch F1: 0.9523809523809523
Epoch:  512       10 Batch loss: 0.062651 Batch F1: 0.7499999999999999
Epoch:  512       11 Batch loss: 0.068034 Batch F1: 0.9523809523809523
Epoch:  512       12 Batch loss: 0.077104 Batch F1: 0.8333333333333333
Train Avg Loss  512: 0.069848

Train Avg F1  512: 0.6114108114108113

Val Avg Loss  512: 0.062977

Val Avg F1  512:  0.9262663398692811

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 513
--------------------------------------------------------------
Epoch:  513        1 Batch loss: 0.061017 Batch F1: 0.9411764705882353
Epoch:  513        2 Batch loss: 0.070499 Batch F1: 0.4
Epoch:  513        3 Batch loss: 0.070436 Batch F1: 0.2222222222222222
Epoch:  513        4 Batch loss: 0.057295 Batch F1: 0.4444444444444445
Epoch:  513        5 Batch loss: 0.075220 Batch F1: 0.9523809523809523
Epoch:  513        6 Batch loss: 0.071160 Batch F1: 0.9565217391304348
Epoch:  513        7 Batch loss: 0.076359 Batch F1: 0.888888888888889
Epoch:  513        8 Batch loss: 0.039290 Batch F1: 1.0
Epoch:  513        9 Batch loss: 0.071330 Batch F1: 0.7692307692307693
Epoch:  513       10 Batch loss: 0.064120 Batch F1: 1.0
Epoch:  513       11 Batch loss: 0.078008 Batch F1: 0.9473684210526316
Epoch:  513       12 Batch loss: 0.082265 Batch F1: 0.9
Train Avg Loss  513: 0.068083

Train Avg F1  513: 0.7851861589948816

Val Avg Loss  513: 0.061518

Val Avg F1  513:  0.9137336093857833

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 514
--------------------------------------------------------------
Epoch:  514        1 Batch loss: 0.076262 Batch F1: 0.9565217391304348
Epoch:  514        2 Batch loss: 0.075031 Batch F1: 0.8571428571428571
Epoch:  514        3 Batch loss: 0.072378 Batch F1: 0.9411764705882353
Epoch:  514        4 Batch loss: 0.075990 Batch F1: 0.7499999999999999
Epoch:  514        5 Batch loss: 0.065387 Batch F1: 0.8750000000000001
Epoch:  514        6 Batch loss: 0.060540 Batch F1: 1.0
Epoch:  514        7 Batch loss: 0.078836 Batch F1: 0.9565217391304348
Epoch:  514        8 Batch loss: 0.064401 Batch F1: 1.0
Epoch:  514        9 Batch loss: 0.057693 Batch F1: 0.923076923076923
Epoch:  514       10 Batch loss: 0.078088 Batch F1: 0.18181818181818182
Epoch:  514       11 Batch loss: 0.055004 Batch F1: 0.6666666666666666
Epoch:  514       12 Batch loss: 0.049655 Batch F1: 0.6666666666666666
Train Avg Loss  514: 0.067439

Train Avg F1  514: 0.8145492703516998

Val Avg Loss  514: 0.062083

Val Avg F1  514:  0.5845238095238096

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 515
--------------------------------------------------------------
Epoch:  515        1 Batch loss: 0.058224 Batch F1: 0.6
Epoch:  515        2 Batch loss: 0.121465 Batch F1: 0.2727272727272727
Epoch:  515        3 Batch loss: 0.072651 Batch F1: 0.888888888888889
Epoch:  515        4 Batch loss: 0.059782 Batch F1: 1.0
Epoch:  515        5 Batch loss: 0.059400 Batch F1: 0.9411764705882353
Epoch:  515        6 Batch loss: 0.079374 Batch F1: 0.8333333333333333
Epoch:  515        7 Batch loss: 0.050232 Batch F1: 1.0
Epoch:  515        8 Batch loss: 0.069216 Batch F1: 0.6666666666666666
Epoch:  515        9 Batch loss: 0.101810 Batch F1: 0.0
Epoch:  515       10 Batch loss: 0.068098 Batch F1: 0.9565217391304348
Epoch:  515       11 Batch loss: 0.075150 Batch F1: 0.9411764705882353
Epoch:  515       12 Batch loss: 0.058160 Batch F1: 1.0
Train Avg Loss  515: 0.072797

Train Avg F1  515: 0.7583742368269223

Val Avg Loss  515: 0.064969

Val Avg F1  515:  0.9328804347826086

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 516
--------------------------------------------------------------
Epoch:  516        1 Batch loss: 0.063106 Batch F1: 1.0
Epoch:  516        2 Batch loss: 0.044248 Batch F1: 1.0
Epoch:  516        3 Batch loss: 0.053133 Batch F1: 0.888888888888889
Epoch:  516        4 Batch loss: 0.100933 Batch F1: 0.375
Epoch:  516        5 Batch loss: 0.117523 Batch F1: 0.45454545454545453
Epoch:  516        6 Batch loss: 0.064452 Batch F1: 0.9411764705882353
Epoch:  516        7 Batch loss: 0.061182 Batch F1: 0.8333333333333333
Epoch:  516        8 Batch loss: 0.091843 Batch F1: 0.9166666666666666
Epoch:  516        9 Batch loss: 0.070887 Batch F1: 0.9333333333333333
Epoch:  516       10 Batch loss: 0.057751 Batch F1: 1.0
Epoch:  516       11 Batch loss: 0.062017 Batch F1: 0.9333333333333333
Epoch:  516       12 Batch loss: 0.067943 Batch F1: 0.8
Train Avg Loss  516: 0.071251

Train Avg F1  516: 0.8396897900574372

Val Avg Loss  516: 0.068655

Val Avg F1  516:  0.6664855072463768

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 517
--------------------------------------------------------------
Epoch:  517        1 Batch loss: 0.072468 Batch F1: 0.6153846153846153
Epoch:  517        2 Batch loss: 0.050627 Batch F1: 0.8
Epoch:  517        3 Batch loss: 0.092644 Batch F1: 0.761904761904762
Epoch:  517        4 Batch loss: 0.070480 Batch F1: 0.5714285714285715
Epoch:  517        5 Batch loss: 0.053955 Batch F1: 0.888888888888889
Epoch:  517        6 Batch loss: 0.069080 Batch F1: 1.0
Epoch:  517        7 Batch loss: 0.049435 Batch F1: 1.0
Epoch:  517        8 Batch loss: 0.065481 Batch F1: 0.6666666666666666
Epoch:  517        9 Batch loss: 0.077191 Batch F1: 0.4615384615384615
Epoch:  517       10 Batch loss: 0.101574 Batch F1: 0.4210526315789474
Epoch:  517       11 Batch loss: 0.103667 Batch F1: 0.5
Epoch:  517       12 Batch loss: 0.068646 Batch F1: 0.9090909090909091
Train Avg Loss  517: 0.072937

Train Avg F1  517: 0.7163296255401518

Val Avg Loss  517: 0.063338

Val Avg F1  517:  0.9272727272727272

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 518
--------------------------------------------------------------
Epoch:  518        1 Batch loss: 0.060731 Batch F1: 0.9090909090909091
Epoch:  518        2 Batch loss: 0.079600 Batch F1: 0.9473684210526316
Epoch:  518        3 Batch loss: 0.065791 Batch F1: 0.9090909090909091
Epoch:  518        4 Batch loss: 0.068883 Batch F1: 0.5714285714285715
Epoch:  518        5 Batch loss: 0.066944 Batch F1: 0.5
Epoch:  518        6 Batch loss: 0.052257 Batch F1: 0.8333333333333333
Epoch:  518        7 Batch loss: 0.054026 Batch F1: 0.8
Epoch:  518        8 Batch loss: 0.066164 Batch F1: 0.4444444444444445
Epoch:  518        9 Batch loss: 0.087181 Batch F1: 0.47058823529411764
Epoch:  518       10 Batch loss: 0.084202 Batch F1: 0.47058823529411764
Epoch:  518       11 Batch loss: 0.082515 Batch F1: 0.3076923076923077
Epoch:  518       12 Batch loss: 0.081615 Batch F1: 0.6666666666666666
Train Avg Loss  518: 0.070826

Train Avg F1  518: 0.6525243361156674

Val Avg Loss  518: 0.063587

Val Avg F1  518:  0.911904761904762

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 519
--------------------------------------------------------------
Epoch:  519        1 Batch loss: 0.063306 Batch F1: 1.0
Epoch:  519        2 Batch loss: 0.068348 Batch F1: 0.8571428571428571
Epoch:  519        3 Batch loss: 0.071168 Batch F1: 0.6666666666666666
Epoch:  519        4 Batch loss: 0.083084 Batch F1: 0.5
Epoch:  519        5 Batch loss: 0.082601 Batch F1: 0.7000000000000001
Epoch:  519        6 Batch loss: 0.053387 Batch F1: 0.888888888888889
Epoch:  519        7 Batch loss: 0.077761 Batch F1: 0.9285714285714286
Epoch:  519        8 Batch loss: 0.053596 Batch F1: 0.888888888888889
Epoch:  519        9 Batch loss: 0.064942 Batch F1: 1.0
Epoch:  519       10 Batch loss: 0.064362 Batch F1: 0.9333333333333333
Epoch:  519       11 Batch loss: 0.077430 Batch F1: 0.9565217391304348
Epoch:  519       12 Batch loss: 0.070009 Batch F1: 0.8333333333333333
Train Avg Loss  519: 0.069166

Train Avg F1  519: 0.8461122613296528

Val Avg Loss  519: 0.061472

Val Avg F1  519:  0.9196859903381643

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 520
--------------------------------------------------------------
Epoch:  520        1 Batch loss: 0.075442 Batch F1: 0.9
Epoch:  520        2 Batch loss: 0.069183 Batch F1: 0.9523809523809523
Epoch:  520        3 Batch loss: 0.061981 Batch F1: 0.923076923076923
Epoch:  520        4 Batch loss: 0.062897 Batch F1: 0.888888888888889
Epoch:  520        5 Batch loss: 0.061905 Batch F1: 0.8
Epoch:  520        6 Batch loss: 0.060558 Batch F1: 0.9411764705882353
Epoch:  520        7 Batch loss: 0.071079 Batch F1: 0.8
Epoch:  520        8 Batch loss: 0.068696 Batch F1: 0.9333333333333333
Epoch:  520        9 Batch loss: 0.067099 Batch F1: 1.0
Epoch:  520       10 Batch loss: 0.063043 Batch F1: 1.0
Epoch:  520       11 Batch loss: 0.074210 Batch F1: 0.8750000000000001
Epoch:  520       12 Batch loss: 0.065627 Batch F1: 0.9090909090909091
Train Avg Loss  520: 0.066810

Train Avg F1  520: 0.9102456231132702

Val Avg Loss  520: 0.060808

Val Avg F1  520:  0.9160912190963342

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 521
--------------------------------------------------------------
Epoch:  521        1 Batch loss: 0.083060 Batch F1: 0.8571428571428571
Epoch:  521        2 Batch loss: 0.064474 Batch F1: 0.9333333333333333
Epoch:  521        3 Batch loss: 0.062300 Batch F1: 0.8
Epoch:  521        4 Batch loss: 0.048428 Batch F1: 0.8
Epoch:  521        5 Batch loss: 0.069628 Batch F1: 0.19999999999999998
Epoch:  521        6 Batch loss: 0.090913 Batch F1: 0.5555555555555556
Epoch:  521        7 Batch loss: 0.063284 Batch F1: 0.5454545454545454
Epoch:  521        8 Batch loss: 0.063588 Batch F1: 0.625
Epoch:  521        9 Batch loss: 0.058609 Batch F1: 0.888888888888889
Epoch:  521       10 Batch loss: 0.057212 Batch F1: 1.0
Epoch:  521       11 Batch loss: 0.078301 Batch F1: 0.9
Epoch:  521       12 Batch loss: 0.066606 Batch F1: 0.9333333333333333
Train Avg Loss  521: 0.067200

Train Avg F1  521: 0.7532257094757094

Val Avg Loss  521: 0.060883

Val Avg F1  521:  0.9325163398692811

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 522
--------------------------------------------------------------
Epoch:  522        1 Batch loss: 0.058746 Batch F1: 0.9473684210526316
Epoch:  522        2 Batch loss: 0.085096 Batch F1: 0.9523809523809523
Epoch:  522        3 Batch loss: 0.054253 Batch F1: 1.0
Epoch:  522        4 Batch loss: 0.042212 Batch F1: 1.0
Epoch:  522        5 Batch loss: 0.044515 Batch F1: 0.4
Epoch:  522        6 Batch loss: 0.099633 Batch F1: 0.2857142857142857
Epoch:  522        7 Batch loss: 0.060111 Batch F1: 0.5714285714285715
Epoch:  522        8 Batch loss: 0.085587 Batch F1: 0.5555555555555556
Epoch:  522        9 Batch loss: 0.063895 Batch F1: 0.8571428571428571
Epoch:  522       10 Batch loss: 0.084539 Batch F1: 0.9166666666666666
Epoch:  522       11 Batch loss: 0.078855 Batch F1: 0.9411764705882353
Epoch:  522       12 Batch loss: 0.068897 Batch F1: 0.8333333333333333
Train Avg Loss  522: 0.068861

Train Avg F1  522: 0.7717305928219241

Val Avg Loss  522: 0.061365

Val Avg F1  522:  0.9292717086834734

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 523
--------------------------------------------------------------
Epoch:  523        1 Batch loss: 0.058850 Batch F1: 0.9473684210526316
Epoch:  523        2 Batch loss: 0.066984 Batch F1: 0.9333333333333333
Epoch:  523        3 Batch loss: 0.070467 Batch F1: 0.9523809523809523
Epoch:  523        4 Batch loss: 0.087512 Batch F1: 0.9523809523809523
Epoch:  523        5 Batch loss: 0.047884 Batch F1: 1.0
Epoch:  523        6 Batch loss: 0.093380 Batch F1: 0.7058823529411764
Epoch:  523        7 Batch loss: 0.077103 Batch F1: 0.9090909090909091
Epoch:  523        8 Batch loss: 0.070649 Batch F1: 0.9565217391304348
Epoch:  523        9 Batch loss: 0.093065 Batch F1: 0.8
Epoch:  523       10 Batch loss: 0.053764 Batch F1: 1.0
Epoch:  523       11 Batch loss: 0.060375 Batch F1: 0.7499999999999999
Epoch:  523       12 Batch loss: 0.055826 Batch F1: 0.7272727272727273
Train Avg Loss  523: 0.069655

Train Avg F1  523: 0.8861859489652598

Val Avg Loss  523: 0.061797

Val Avg F1  523:  0.7196969696969696

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 524
--------------------------------------------------------------
Epoch:  524        1 Batch loss: 0.077574 Batch F1: 0.3636363636363636
Epoch:  524        2 Batch loss: 0.076312 Batch F1: 0.8750000000000001
Epoch:  524        3 Batch loss: 0.099466 Batch F1: 0.5833333333333334
Epoch:  524        4 Batch loss: 0.067669 Batch F1: 1.0
Epoch:  524        5 Batch loss: 0.086025 Batch F1: 0.9166666666666666
Epoch:  524        6 Batch loss: 0.078167 Batch F1: 0.9523809523809523
Epoch:  524        7 Batch loss: 0.060518 Batch F1: 1.0
Epoch:  524        8 Batch loss: 0.053073 Batch F1: 0.5
Epoch:  524        9 Batch loss: 0.055744 Batch F1: 0.4444444444444445
Epoch:  524       10 Batch loss: 0.062410 Batch F1: 0.4444444444444445
Epoch:  524       11 Batch loss: 0.057890 Batch F1: 0.2857142857142857
Epoch:  524       12 Batch loss: 0.048173 Batch F1: 0.5714285714285715
Train Avg Loss  524: 0.068585

Train Avg F1  524: 0.6614207551707552

Val Avg Loss  524: 0.064031

Val Avg F1  524:  0.578030303030303

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 525
--------------------------------------------------------------
Epoch:  525        1 Batch loss: 0.065861 Batch F1: 0.5
Epoch:  525        2 Batch loss: 0.064178 Batch F1: 0.5
Epoch:  525        3 Batch loss: 0.062435 Batch F1: 0.888888888888889
Epoch:  525        4 Batch loss: 0.049597 Batch F1: 1.0
Epoch:  525        5 Batch loss: 0.085889 Batch F1: 0.88
Epoch:  525        6 Batch loss: 0.045858 Batch F1: 1.0
Epoch:  525        7 Batch loss: 0.087201 Batch F1: 0.6956521739130436
Epoch:  525        8 Batch loss: 0.051691 Batch F1: 0.9333333333333333
Epoch:  525        9 Batch loss: 0.086368 Batch F1: 0.8
Epoch:  525       10 Batch loss: 0.086713 Batch F1: 0.8421052631578948
Epoch:  525       11 Batch loss: 0.070729 Batch F1: 0.9333333333333333
Epoch:  525       12 Batch loss: 0.063195 Batch F1: 1.0
Train Avg Loss  525: 0.068310

Train Avg F1  525: 0.8311094160522079

Val Avg Loss  525: 0.061599

Val Avg F1  525:  0.9224481658692185

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 526
--------------------------------------------------------------
Epoch:  526        1 Batch loss: 0.081658 Batch F1: 0.888888888888889
Epoch:  526        2 Batch loss: 0.065546 Batch F1: 0.9411764705882353
Epoch:  526        3 Batch loss: 0.051557 Batch F1: 1.0
Epoch:  526        4 Batch loss: 0.055222 Batch F1: 0.9090909090909091
Epoch:  526        5 Batch loss: 0.060922 Batch F1: 0.9473684210526316
Epoch:  526        6 Batch loss: 0.069427 Batch F1: 0.8571428571428571
Epoch:  526        7 Batch loss: 0.069407 Batch F1: 0.9411764705882353
Epoch:  526        8 Batch loss: 0.076756 Batch F1: 0.9090909090909091
Epoch:  526        9 Batch loss: 0.055215 Batch F1: 1.0
Epoch:  526       10 Batch loss: 0.069849 Batch F1: 0.8750000000000001
Epoch:  526       11 Batch loss: 0.082655 Batch F1: 0.8571428571428571
Epoch:  526       12 Batch loss: 0.075801 Batch F1: 0.9411764705882353
Train Avg Loss  526: 0.067835

Train Avg F1  526: 0.9222711878478133

Val Avg Loss  526: 0.061297

Val Avg F1  526:  0.9275

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 527
--------------------------------------------------------------
Epoch:  527        1 Batch loss: 0.058475 Batch F1: 1.0
Epoch:  527        2 Batch loss: 0.075338 Batch F1: 0.888888888888889
Epoch:  527        3 Batch loss: 0.064336 Batch F1: 1.0
Epoch:  527        4 Batch loss: 0.086216 Batch F1: 0.8695652173913044
Epoch:  527        5 Batch loss: 0.064167 Batch F1: 0.9333333333333333
Epoch:  527        6 Batch loss: 0.073834 Batch F1: 0.888888888888889
Epoch:  527        7 Batch loss: 0.055534 Batch F1: 0.9333333333333333
Epoch:  527        8 Batch loss: 0.083350 Batch F1: 0.7499999999999999
Epoch:  527        9 Batch loss: 0.061742 Batch F1: 0.9333333333333333
Epoch:  527       10 Batch loss: 0.049733 Batch F1: 1.0
Epoch:  527       11 Batch loss: 0.075229 Batch F1: 0.8750000000000001
Epoch:  527       12 Batch loss: 0.059150 Batch F1: 1.0
Train Avg Loss  527: 0.067259

Train Avg F1  527: 0.9226952495974236

Val Avg Loss  527: 0.061552

Val Avg F1  527:  0.5674522845575477

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 528
--------------------------------------------------------------
Epoch:  528        1 Batch loss: 0.075176 Batch F1: 0.5882352941176471
Epoch:  528        2 Batch loss: 0.063012 Batch F1: 0.6153846153846153
Epoch:  528        3 Batch loss: 0.061498 Batch F1: 0.0
Epoch:  528        4 Batch loss: 0.054103 Batch F1: 0.6666666666666666
Epoch:  528        5 Batch loss: 0.036928 Batch F1: 1.0
Epoch:  528        6 Batch loss: 0.049621 Batch F1: 0.6
Epoch:  528        7 Batch loss: 0.060928 Batch F1: 0.6666666666666666
Epoch:  528        8 Batch loss: 0.105775 Batch F1: 0.15384615384615385
Epoch:  528        9 Batch loss: 0.081913 Batch F1: 0.3076923076923077
Epoch:  528       10 Batch loss: 0.079674 Batch F1: 0.33333333333333337
Epoch:  528       11 Batch loss: 0.072859 Batch F1: 0.9565217391304348
Epoch:  528       12 Batch loss: 0.075057 Batch F1: 0.9
Train Avg Loss  528: 0.068045

Train Avg F1  528: 0.5656955647364855

Val Avg Loss  528: 0.064013

Val Avg F1  528:  0.9283461210571184

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 529
--------------------------------------------------------------
Epoch:  529        1 Batch loss: 0.078192 Batch F1: 0.7272727272727273
Epoch:  529        2 Batch loss: 0.069033 Batch F1: 1.0
Epoch:  529        3 Batch loss: 0.065204 Batch F1: 0.9090909090909091
Epoch:  529        4 Batch loss: 0.057058 Batch F1: 1.0
Epoch:  529        5 Batch loss: 0.073548 Batch F1: 0.9
Epoch:  529        6 Batch loss: 0.068760 Batch F1: 0.2222222222222222
Epoch:  529        7 Batch loss: 0.077527 Batch F1: 0.33333333333333337
Epoch:  529        8 Batch loss: 0.090259 Batch F1: 0.5555555555555556
Epoch:  529        9 Batch loss: 0.054321 Batch F1: 0.5
Epoch:  529       10 Batch loss: 0.094047 Batch F1: 0.6363636363636364
Epoch:  529       11 Batch loss: 0.056756 Batch F1: 1.0
Epoch:  529       12 Batch loss: 0.077450 Batch F1: 0.8
Train Avg Loss  529: 0.071846

Train Avg F1  529: 0.7153198653198652

Val Avg Loss  529: 0.066866

Val Avg F1  529:  0.8978174603174603

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 530
--------------------------------------------------------------
Epoch:  530        1 Batch loss: 0.084827 Batch F1: 0.8888888888888888
Epoch:  530        2 Batch loss: 0.062789 Batch F1: 1.0
Epoch:  530        3 Batch loss: 0.068120 Batch F1: 0.9411764705882353
Epoch:  530        4 Batch loss: 0.086758 Batch F1: 0.0
Epoch:  530        5 Batch loss: 0.075233 Batch F1: 0.9523809523809523
Epoch:  530        6 Batch loss: 0.067425 Batch F1: 0.7777777777777778
Epoch:  530        7 Batch loss: 0.064603 Batch F1: 0.6
Epoch:  530        8 Batch loss: 0.108029 Batch F1: 0.6086956521739131
Epoch:  530        9 Batch loss: 0.070001 Batch F1: 0.8333333333333333
Epoch:  530       10 Batch loss: 0.054366 Batch F1: 1.0
Epoch:  530       11 Batch loss: 0.072078 Batch F1: 1.0
Epoch:  530       12 Batch loss: 0.056892 Batch F1: 0.9090909090909091
Train Avg Loss  530: 0.072593

Train Avg F1  530: 0.7926119986861674

Val Avg Loss  530: 0.062924

Val Avg F1  530:  0.9340579710144927

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 531
--------------------------------------------------------------
Epoch:  531        1 Batch loss: 0.084621 Batch F1: 0.8695652173913044
Epoch:  531        2 Batch loss: 0.054968 Batch F1: 1.0
Epoch:  531        3 Batch loss: 0.078806 Batch F1: 0.9411764705882353
Epoch:  531        4 Batch loss: 0.051678 Batch F1: 0.5
Epoch:  531        5 Batch loss: 0.050016 Batch F1: 0.0
Epoch:  531        6 Batch loss: 0.067372 Batch F1: 0.5
Epoch:  531        7 Batch loss: 0.096054 Batch F1: 0.5882352941176471
Epoch:  531        8 Batch loss: 0.068528 Batch F1: 0.5714285714285715
Epoch:  531        9 Batch loss: 0.056360 Batch F1: 0.6
Epoch:  531       10 Batch loss: 0.086670 Batch F1: 0.7272727272727273
Epoch:  531       11 Batch loss: 0.065278 Batch F1: 1.0
Epoch:  531       12 Batch loss: 0.077688 Batch F1: 0.8421052631578948
Train Avg Loss  531: 0.069837

Train Avg F1  531: 0.6783152953296984

Val Avg Loss  531: 0.066907

Val Avg F1  531:  0.9244200244200244

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 532
--------------------------------------------------------------
Epoch:  532        1 Batch loss: 0.070649 Batch F1: 0.8
Epoch:  532        2 Batch loss: 0.059439 Batch F1: 1.0
Epoch:  532        3 Batch loss: 0.067831 Batch F1: 1.0
Epoch:  532        4 Batch loss: 0.072969 Batch F1: 0.5454545454545454
Epoch:  532        5 Batch loss: 0.074853 Batch F1: 0.5333333333333333
Epoch:  532        6 Batch loss: 0.059885 Batch F1: 0.9411764705882353
Epoch:  532        7 Batch loss: 0.093153 Batch F1: 0.9090909090909091
Epoch:  532        8 Batch loss: 0.059376 Batch F1: 0.9411764705882353
Epoch:  532        9 Batch loss: 0.062012 Batch F1: 0.9333333333333333
Epoch:  532       10 Batch loss: 0.068236 Batch F1: 1.0
Epoch:  532       11 Batch loss: 0.065428 Batch F1: 0.9523809523809523
Epoch:  532       12 Batch loss: 0.100205 Batch F1: 0.6666666666666666
Train Avg Loss  532: 0.071170

Train Avg F1  532: 0.8518843901196842

Val Avg Loss  532: 0.062528

Val Avg F1  532:  0.9217160548429899

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 533
--------------------------------------------------------------
Epoch:  533        1 Batch loss: 0.056709 Batch F1: 1.0
Epoch:  533        2 Batch loss: 0.071651 Batch F1: 0.8750000000000001
Epoch:  533        3 Batch loss: 0.076127 Batch F1: 0.962962962962963
Epoch:  533        4 Batch loss: 0.071269 Batch F1: 0.9565217391304348
Epoch:  533        5 Batch loss: 0.064788 Batch F1: 0.9473684210526316
Epoch:  533        6 Batch loss: 0.069807 Batch F1: 0.8571428571428571
Epoch:  533        7 Batch loss: 0.056386 Batch F1: 0.8750000000000001
Epoch:  533        8 Batch loss: 0.072428 Batch F1: 0.8750000000000001
Epoch:  533        9 Batch loss: 0.072449 Batch F1: 1.0
Epoch:  533       10 Batch loss: 0.084280 Batch F1: 0.7142857142857143
Epoch:  533       11 Batch loss: 0.059451 Batch F1: 0.9411764705882353
Epoch:  533       12 Batch loss: 0.064536 Batch F1: 1.0
Train Avg Loss  533: 0.068323

Train Avg F1  533: 0.9170381804302363

Val Avg Loss  533: 0.061632

Val Avg F1  533:  0.8974637681159421

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 534
--------------------------------------------------------------
Epoch:  534        1 Batch loss: 0.054154 Batch F1: 0.9090909090909091
Epoch:  534        2 Batch loss: 0.075786 Batch F1: 0.33333333333333337
Epoch:  534        3 Batch loss: 0.086523 Batch F1: 0.7000000000000001
Epoch:  534        4 Batch loss: 0.064581 Batch F1: 0.5
Epoch:  534        5 Batch loss: 0.052211 Batch F1: 0.6
Epoch:  534        6 Batch loss: 0.084977 Batch F1: 0.9090909090909091
Epoch:  534        7 Batch loss: 0.067950 Batch F1: 0.9523809523809523
Epoch:  534        8 Batch loss: 0.065601 Batch F1: 0.9411764705882353
Epoch:  534        9 Batch loss: 0.087357 Batch F1: 0.9090909090909091
Epoch:  534       10 Batch loss: 0.068647 Batch F1: 0.8750000000000001
Epoch:  534       11 Batch loss: 0.063685 Batch F1: 0.9333333333333333
Epoch:  534       12 Batch loss: 0.042778 Batch F1: 1.0
Train Avg Loss  534: 0.067854

Train Avg F1  534: 0.7968747347423818

Val Avg Loss  534: 0.061312

Val Avg F1  534:  0.9137336093857833

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 535
--------------------------------------------------------------
Epoch:  535        1 Batch loss: 0.068667 Batch F1: 0.9523809523809523
Epoch:  535        2 Batch loss: 0.064729 Batch F1: 0.7272727272727273
Epoch:  535        3 Batch loss: 0.061025 Batch F1: 0.9090909090909091
Epoch:  535        4 Batch loss: 0.077353 Batch F1: 0.5
Epoch:  535        5 Batch loss: 0.076369 Batch F1: 0.5882352941176471
Epoch:  535        6 Batch loss: 0.062444 Batch F1: 0.9333333333333333
Epoch:  535        7 Batch loss: 0.080590 Batch F1: 0.9565217391304348
Epoch:  535        8 Batch loss: 0.048260 Batch F1: 1.0
Epoch:  535        9 Batch loss: 0.053360 Batch F1: 1.0
Epoch:  535       10 Batch loss: 0.067715 Batch F1: 0.8571428571428571
Epoch:  535       11 Batch loss: 0.074625 Batch F1: 0.4615384615384615
Epoch:  535       12 Batch loss: 0.080377 Batch F1: 0.18181818181818182
Train Avg Loss  535: 0.067959

Train Avg F1  535: 0.7556112046521254

Val Avg Loss  535: 0.061693

Val Avg F1  535:  0.9286858974358974

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 536
--------------------------------------------------------------
Epoch:  536        1 Batch loss: 0.079896 Batch F1: 1.0
Epoch:  536        2 Batch loss: 0.073818 Batch F1: 0.9
Epoch:  536        3 Batch loss: 0.060103 Batch F1: 0.9333333333333333
Epoch:  536        4 Batch loss: 0.062381 Batch F1: 1.0
Epoch:  536        5 Batch loss: 0.061800 Batch F1: 0.8333333333333333
Epoch:  536        6 Batch loss: 0.064859 Batch F1: 0.888888888888889
Epoch:  536        7 Batch loss: 0.062044 Batch F1: 0.9411764705882353
Epoch:  536        8 Batch loss: 0.077578 Batch F1: 0.8
Epoch:  536        9 Batch loss: 0.082188 Batch F1: 0.8235294117647058
Epoch:  536       10 Batch loss: 0.039056 Batch F1: 0.6666666666666666
Epoch:  536       11 Batch loss: 0.068071 Batch F1: 0.5454545454545454
Epoch:  536       12 Batch loss: 0.099397 Batch F1: 0.5555555555555556
Train Avg Loss  536: 0.069266

Train Avg F1  536: 0.8239948504654385

Val Avg Loss  536: 0.063089

Val Avg F1  536:  0.526470588235294

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 537
--------------------------------------------------------------
Epoch:  537        1 Batch loss: 0.055613 Batch F1: 0.6666666666666666
Epoch:  537        2 Batch loss: 0.079183 Batch F1: 0.18181818181818182
Epoch:  537        3 Batch loss: 0.056986 Batch F1: 0.5
Epoch:  537        4 Batch loss: 0.088063 Batch F1: 0.8571428571428571
Epoch:  537        5 Batch loss: 0.062980 Batch F1: 1.0
Epoch:  537        6 Batch loss: 0.066522 Batch F1: 0.5714285714285715
Epoch:  537        7 Batch loss: 0.053634 Batch F1: 0.8333333333333333
Epoch:  537        8 Batch loss: 0.080782 Batch F1: 0.33333333333333337
Epoch:  537        9 Batch loss: 0.073651 Batch F1: 0.6666666666666666
Epoch:  537       10 Batch loss: 0.076736 Batch F1: 0.7368421052631579
Epoch:  537       11 Batch loss: 0.075753 Batch F1: 0.9166666666666666
Epoch:  537       12 Batch loss: 0.073478 Batch F1: 0.8571428571428571
Train Avg Loss  537: 0.070282

Train Avg F1  537: 0.6767534366218576

Val Avg Loss  537: 0.063380

Val Avg F1  537:  0.925944669365722

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 538
--------------------------------------------------------------
Epoch:  538        1 Batch loss: 0.083552 Batch F1: 0.8571428571428571
Epoch:  538        2 Batch loss: 0.058645 Batch F1: 1.0
Epoch:  538        3 Batch loss: 0.069367 Batch F1: 0.923076923076923
Epoch:  538        4 Batch loss: 0.057961 Batch F1: 1.0
Epoch:  538        5 Batch loss: 0.082004 Batch F1: 0.6153846153846153
Epoch:  538        6 Batch loss: 0.082814 Batch F1: 0.7058823529411764
Epoch:  538        7 Batch loss: 0.069552 Batch F1: 0.888888888888889
Epoch:  538        8 Batch loss: 0.058634 Batch F1: 1.0
Epoch:  538        9 Batch loss: 0.070595 Batch F1: 0.9333333333333333
Epoch:  538       10 Batch loss: 0.068513 Batch F1: 0.4615384615384615
Epoch:  538       11 Batch loss: 0.081524 Batch F1: 0.33333333333333337
Epoch:  538       12 Batch loss: 0.075348 Batch F1: 0.5
Train Avg Loss  538: 0.071542

Train Avg F1  538: 0.7682150638032992

Val Avg Loss  538: 0.063828

Val Avg F1  538:  0.6034188034188035

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 539
--------------------------------------------------------------
Epoch:  539        1 Batch loss: 0.076408 Batch F1: 0.42857142857142855
Epoch:  539        2 Batch loss: 0.043759 Batch F1: 0.5714285714285715
Epoch:  539        3 Batch loss: 0.056425 Batch F1: 0.7499999999999999
Epoch:  539        4 Batch loss: 0.060009 Batch F1: 0.8
Epoch:  539        5 Batch loss: 0.065390 Batch F1: 0.6666666666666666
Epoch:  539        6 Batch loss: 0.100057 Batch F1: 0.8
Epoch:  539        7 Batch loss: 0.085564 Batch F1: 0.9
Epoch:  539        8 Batch loss: 0.064035 Batch F1: 0.9411764705882353
Epoch:  539        9 Batch loss: 0.078747 Batch F1: 0.5
Epoch:  539       10 Batch loss: 0.069207 Batch F1: 0.9523809523809523
Epoch:  539       11 Batch loss: 0.063028 Batch F1: 1.0
Epoch:  539       12 Batch loss: 0.059114 Batch F1: 1.0
Train Avg Loss  539: 0.068478

Train Avg F1  539: 0.7758520074696547

Val Avg Loss  539: 0.061548

Val Avg F1  539:  0.9240507299717826

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 540
--------------------------------------------------------------
Epoch:  540        1 Batch loss: 0.077909 Batch F1: 1.0
Epoch:  540        2 Batch loss: 0.045072 Batch F1: 0.888888888888889
Epoch:  540        3 Batch loss: 0.081196 Batch F1: 0.5714285714285715
Epoch:  540        4 Batch loss: 0.069345 Batch F1: 0.5714285714285715
Epoch:  540        5 Batch loss: 0.062263 Batch F1: 0.4444444444444445
Epoch:  540        6 Batch loss: 0.099111 Batch F1: 0.47619047619047616
Epoch:  540        7 Batch loss: 0.068576 Batch F1: 0.5454545454545454
Epoch:  540        8 Batch loss: 0.066216 Batch F1: 1.0
Epoch:  540        9 Batch loss: 0.054481 Batch F1: 0.8333333333333333
Epoch:  540       10 Batch loss: 0.057074 Batch F1: 0.9090909090909091
Epoch:  540       11 Batch loss: 0.091191 Batch F1: 0.5555555555555556
Epoch:  540       12 Batch loss: 0.052040 Batch F1: 0.6666666666666666
Train Avg Loss  540: 0.068706

Train Avg F1  540: 0.7052068302068303

Val Avg Loss  540: 0.061606

Val Avg F1  540:  0.5849567099567099

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 541
--------------------------------------------------------------
Epoch:  541        1 Batch loss: 0.086350 Batch F1: 0.6363636363636364
Epoch:  541        2 Batch loss: 0.055445 Batch F1: 0.9090909090909091
Epoch:  541        3 Batch loss: 0.046652 Batch F1: 1.0
Epoch:  541        4 Batch loss: 0.058997 Batch F1: 0.6153846153846153
Epoch:  541        5 Batch loss: 0.069629 Batch F1: 0.3636363636363636
Epoch:  541        6 Batch loss: 0.051808 Batch F1: 0.33333333333333337
Epoch:  541        7 Batch loss: 0.071162 Batch F1: 0.3636363636363636
Epoch:  541        8 Batch loss: 0.058983 Batch F1: 0.6153846153846153
Epoch:  541        9 Batch loss: 0.088223 Batch F1: 0.4615384615384615
Epoch:  541       10 Batch loss: 0.090373 Batch F1: 0.375
Epoch:  541       11 Batch loss: 0.092513 Batch F1: 0.88
Epoch:  541       12 Batch loss: 0.042244 Batch F1: 0.8
Train Avg Loss  541: 0.067698

Train Avg F1  541: 0.6127806915306915

Val Avg Loss  541: 0.061627

Val Avg F1  541:  0.9147727272727273

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 542
--------------------------------------------------------------
Epoch:  542        1 Batch loss: 0.059903 Batch F1: 0.8750000000000001
Epoch:  542        2 Batch loss: 0.067323 Batch F1: 0.923076923076923
Epoch:  542        3 Batch loss: 0.066500 Batch F1: 0.7272727272727273
Epoch:  542        4 Batch loss: 0.077128 Batch F1: 0.9600000000000001
Epoch:  542        5 Batch loss: 0.074511 Batch F1: 1.0
Epoch:  542        6 Batch loss: 0.067796 Batch F1: 0.8571428571428571
Epoch:  542        7 Batch loss: 0.084799 Batch F1: 0.9090909090909091
Epoch:  542        8 Batch loss: 0.070306 Batch F1: 0.9523809523809523
Epoch:  542        9 Batch loss: 0.069848 Batch F1: 0.9
Epoch:  542       10 Batch loss: 0.062165 Batch F1: 1.0
Epoch:  542       11 Batch loss: 0.057385 Batch F1: 0.9333333333333333
Epoch:  542       12 Batch loss: 0.051336 Batch F1: 0.8571428571428571
Train Avg Loss  542: 0.067417

Train Avg F1  542: 0.9078700466200468

Val Avg Loss  542: 0.062209

Val Avg F1  542:  0.5887254901960784

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 543
--------------------------------------------------------------
Epoch:  543        1 Batch loss: 0.073987 Batch F1: 0.5
Epoch:  543        2 Batch loss: 0.045333 Batch F1: 0.7272727272727273
Epoch:  543        3 Batch loss: 0.073899 Batch F1: 0.625
Epoch:  543        4 Batch loss: 0.097232 Batch F1: 0.4210526315789474
Epoch:  543        5 Batch loss: 0.067671 Batch F1: 0.8333333333333333
Epoch:  543        6 Batch loss: 0.057820 Batch F1: 0.923076923076923
Epoch:  543        7 Batch loss: 0.065837 Batch F1: 0.7272727272727273
Epoch:  543        8 Batch loss: 0.059208 Batch F1: 1.0
Epoch:  543        9 Batch loss: 0.060251 Batch F1: 0.923076923076923
Epoch:  543       10 Batch loss: 0.045899 Batch F1: 0.5714285714285715
Epoch:  543       11 Batch loss: 0.107920 Batch F1: 0.15384615384615385
Epoch:  543       12 Batch loss: 0.075645 Batch F1: 0.6666666666666666
Train Avg Loss  543: 0.069225

Train Avg F1  543: 0.6726688881294146

Val Avg Loss  543: 0.061158

Val Avg F1  543:  0.9376750700280112

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 544
--------------------------------------------------------------
Epoch:  544        1 Batch loss: 0.075832 Batch F1: 0.888888888888889
Epoch:  544        2 Batch loss: 0.075105 Batch F1: 0.9
Epoch:  544        3 Batch loss: 0.075645 Batch F1: 0.9600000000000001
Epoch:  544        4 Batch loss: 0.069322 Batch F1: 0.9473684210526316
Epoch:  544        5 Batch loss: 0.064389 Batch F1: 0.9333333333333333
Epoch:  544        6 Batch loss: 0.059873 Batch F1: 0.888888888888889
Epoch:  544        7 Batch loss: 0.067020 Batch F1: 0.8750000000000001
Epoch:  544        8 Batch loss: 0.083500 Batch F1: 0.8421052631578948
Epoch:  544        9 Batch loss: 0.077206 Batch F1: 0.9523809523809523
Epoch:  544       10 Batch loss: 0.060792 Batch F1: 0.9333333333333333
Epoch:  544       11 Batch loss: 0.051695 Batch F1: 0.4444444444444445
Epoch:  544       12 Batch loss: 0.055109 Batch F1: 0.5714285714285715
Train Avg Loss  544: 0.067957

Train Avg F1  544: 0.8447643414090783

Val Avg Loss  544: 0.064349

Val Avg F1  544:  0.553654970760234

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 545
--------------------------------------------------------------
Epoch:  545        1 Batch loss: 0.047661 Batch F1: 0.5714285714285715
Epoch:  545        2 Batch loss: 0.062591 Batch F1: 0.4
Epoch:  545        3 Batch loss: 0.089184 Batch F1: 0.5882352941176471
Epoch:  545        4 Batch loss: 0.055859 Batch F1: 0.6
Epoch:  545        5 Batch loss: 0.104011 Batch F1: 0.4444444444444445
Epoch:  545        6 Batch loss: 0.061222 Batch F1: 0.9333333333333333
Epoch:  545        7 Batch loss: 0.061392 Batch F1: 1.0
Epoch:  545        8 Batch loss: 0.079958 Batch F1: 0.9
Epoch:  545        9 Batch loss: 0.068905 Batch F1: 0.8750000000000001
Epoch:  545       10 Batch loss: 0.066292 Batch F1: 0.9473684210526316
Epoch:  545       11 Batch loss: 0.075125 Batch F1: 0.9411764705882353
Epoch:  545       12 Batch loss: 0.066526 Batch F1: 0.9333333333333333
Train Avg Loss  545: 0.069894

Train Avg F1  545: 0.7611933223581832

Val Avg Loss  545: 0.061599

Val Avg F1  545:  0.9266515837104072

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 546
--------------------------------------------------------------
Epoch:  546        1 Batch loss: 0.056069 Batch F1: 0.8
Epoch:  546        2 Batch loss: 0.064790 Batch F1: 0.7499999999999999
Epoch:  546        3 Batch loss: 0.092986 Batch F1: 0.6086956521739131
Epoch:  546        4 Batch loss: 0.061946 Batch F1: 0.6666666666666666
Epoch:  546        5 Batch loss: 0.044067 Batch F1: 0.923076923076923
Epoch:  546        6 Batch loss: 0.071831 Batch F1: 0.19999999999999998
Epoch:  546        7 Batch loss: 0.050808 Batch F1: 0.5
Epoch:  546        8 Batch loss: 0.074879 Batch F1: 0.625
Epoch:  546        9 Batch loss: 0.082871 Batch F1: 0.631578947368421
Epoch:  546       10 Batch loss: 0.083659 Batch F1: 0.33333333333333337
Epoch:  546       11 Batch loss: 0.070155 Batch F1: 0.2222222222222222
Epoch:  546       12 Batch loss: 0.085599 Batch F1: 0.19999999999999998
Train Avg Loss  546: 0.069972

Train Avg F1  546: 0.5383811454034566

Val Avg Loss  546: 0.062626

Val Avg F1  546:  0.7176691729323309

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 547
--------------------------------------------------------------
Epoch:  547        1 Batch loss: 0.076030 Batch F1: 0.625
Epoch:  547        2 Batch loss: 0.065382 Batch F1: 1.0
Epoch:  547        3 Batch loss: 0.080709 Batch F1: 0.8421052631578948
Epoch:  547        4 Batch loss: 0.072037 Batch F1: 0.9333333333333333
Epoch:  547        5 Batch loss: 0.047458 Batch F1: 1.0
Epoch:  547        6 Batch loss: 0.072099 Batch F1: 0.9523809523809523
Epoch:  547        7 Batch loss: 0.058195 Batch F1: 0.8750000000000001
Epoch:  547        8 Batch loss: 0.071836 Batch F1: 0.8750000000000001
Epoch:  547        9 Batch loss: 0.064987 Batch F1: 0.8
Epoch:  547       10 Batch loss: 0.057941 Batch F1: 0.9333333333333333
Epoch:  547       11 Batch loss: 0.057297 Batch F1: 0.9090909090909091
Epoch:  547       12 Batch loss: 0.115211 Batch F1: 0.35294117647058826
Train Avg Loss  547: 0.069932

Train Avg F1  547: 0.8415154139805843

Val Avg Loss  547: 0.061293

Val Avg F1  547:  0.9285714285714286

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 548
--------------------------------------------------------------
Epoch:  548        1 Batch loss: 0.082922 Batch F1: 0.8750000000000001
Epoch:  548        2 Batch loss: 0.073771 Batch F1: 0.7777777777777778
Epoch:  548        3 Batch loss: 0.067152 Batch F1: 0.8750000000000001
Epoch:  548        4 Batch loss: 0.068524 Batch F1: 1.0
Epoch:  548        5 Batch loss: 0.088268 Batch F1: 0.8571428571428571
Epoch:  548        6 Batch loss: 0.070045 Batch F1: 1.0
Epoch:  548        7 Batch loss: 0.053779 Batch F1: 0.9090909090909091
Epoch:  548        8 Batch loss: 0.064791 Batch F1: 1.0
Epoch:  548        9 Batch loss: 0.092164 Batch F1: 0.9285714285714286
Epoch:  548       10 Batch loss: 0.064450 Batch F1: 0.9090909090909091
Epoch:  548       11 Batch loss: 0.053174 Batch F1: 0.8333333333333333
Epoch:  548       12 Batch loss: 0.056606 Batch F1: 0.6666666666666666
Train Avg Loss  548: 0.069637

Train Avg F1  548: 0.8859728234728235

Val Avg Loss  548: 0.064532

Val Avg F1  548:  0.4653409090909091

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 549
--------------------------------------------------------------
Epoch:  549        1 Batch loss: 0.057139 Batch F1: 0.0
Epoch:  549        2 Batch loss: 0.046831 Batch F1: 0.8
Epoch:  549        3 Batch loss: 0.102099 Batch F1: 0.5
Epoch:  549        4 Batch loss: 0.080116 Batch F1: 0.42857142857142855
Epoch:  549        5 Batch loss: 0.060999 Batch F1: 0.5454545454545454
Epoch:  549        6 Batch loss: 0.083623 Batch F1: 0.625
Epoch:  549        7 Batch loss: 0.073281 Batch F1: 0.8750000000000001
Epoch:  549        8 Batch loss: 0.078107 Batch F1: 0.9600000000000001
Epoch:  549        9 Batch loss: 0.069738 Batch F1: 0.8235294117647058
Epoch:  549       10 Batch loss: 0.079384 Batch F1: 0.9411764705882353
Epoch:  549       11 Batch loss: 0.065119 Batch F1: 0.8333333333333333
Epoch:  549       12 Batch loss: 0.068693 Batch F1: 0.4444444444444445
Train Avg Loss  549: 0.072094

Train Avg F1  549: 0.6480424695130578

Val Avg Loss  549: 0.067812

Val Avg F1  549:  0.5444444444444445

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 550
--------------------------------------------------------------
Epoch:  550        1 Batch loss: 0.085589 Batch F1: 0.3076923076923077
Epoch:  550        2 Batch loss: 0.044431 Batch F1: 0.7499999999999999
Epoch:  550        3 Batch loss: 0.080464 Batch F1: 0.3076923076923077
Epoch:  550        4 Batch loss: 0.068476 Batch F1: 0.923076923076923
Epoch:  550        5 Batch loss: 0.069604 Batch F1: 0.8750000000000001
Epoch:  550        6 Batch loss: 0.053894 Batch F1: 0.9090909090909091
Epoch:  550        7 Batch loss: 0.075813 Batch F1: 0.8421052631578948
Epoch:  550        8 Batch loss: 0.068297 Batch F1: 0.888888888888889
Epoch:  550        9 Batch loss: 0.076312 Batch F1: 0.888888888888889
Epoch:  550       10 Batch loss: 0.078991 Batch F1: 0.9
Epoch:  550       11 Batch loss: 0.062447 Batch F1: 1.0
Epoch:  550       12 Batch loss: 0.061293 Batch F1: 0.923076923076923
Train Avg Loss  550: 0.068801

Train Avg F1  550: 0.7929593676304204

Val Avg Loss  550: 0.062483

Val Avg F1  550:  0.9291537667698658

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 551
--------------------------------------------------------------
Epoch:  551        1 Batch loss: 0.061610 Batch F1: 1.0
Epoch:  551        2 Batch loss: 0.078658 Batch F1: 0.888888888888889
Epoch:  551        3 Batch loss: 0.081809 Batch F1: 0.8421052631578948
Epoch:  551        4 Batch loss: 0.058260 Batch F1: 0.8333333333333333
Epoch:  551        5 Batch loss: 0.066493 Batch F1: 0.8571428571428571
Epoch:  551        6 Batch loss: 0.060931 Batch F1: 0.9411764705882353
Epoch:  551        7 Batch loss: 0.056395 Batch F1: 1.0
Epoch:  551        8 Batch loss: 0.069261 Batch F1: 0.888888888888889
Epoch:  551        9 Batch loss: 0.069728 Batch F1: 0.8235294117647058
Epoch:  551       10 Batch loss: 0.045393 Batch F1: 1.0
Epoch:  551       11 Batch loss: 0.085572 Batch F1: 0.9565217391304348
Epoch:  551       12 Batch loss: 0.077439 Batch F1: 0.3636363636363636
Train Avg Loss  551: 0.067629

Train Avg F1  551: 0.8662686013776336

Val Avg Loss  551: 0.061338

Val Avg F1  551:  0.597027972027972

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 552
--------------------------------------------------------------
Epoch:  552        1 Batch loss: 0.091297 Batch F1: 0.4444444444444445
Epoch:  552        2 Batch loss: 0.067124 Batch F1: 1.0
Epoch:  552        3 Batch loss: 0.061651 Batch F1: 1.0
Epoch:  552        4 Batch loss: 0.073741 Batch F1: 0.7272727272727273
Epoch:  552        5 Batch loss: 0.063603 Batch F1: 1.0
Epoch:  552        6 Batch loss: 0.083937 Batch F1: 0.7142857142857143
Epoch:  552        7 Batch loss: 0.052180 Batch F1: 1.0
Epoch:  552        8 Batch loss: 0.039091 Batch F1: 1.0
Epoch:  552        9 Batch loss: 0.065837 Batch F1: 1.0
Epoch:  552       10 Batch loss: 0.059039 Batch F1: 0.9333333333333333
Epoch:  552       11 Batch loss: 0.084275 Batch F1: 0.8235294117647058
Epoch:  552       12 Batch loss: 0.070477 Batch F1: 0.8571428571428571
Train Avg Loss  552: 0.067688

Train Avg F1  552: 0.8750007073536487

Val Avg Loss  552: 0.060815

Val Avg F1  552:  0.9223276723276723

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 553
--------------------------------------------------------------
Epoch:  553        1 Batch loss: 0.084672 Batch F1: 0.8695652173913044
Epoch:  553        2 Batch loss: 0.042856 Batch F1: 0.9090909090909091
Epoch:  553        3 Batch loss: 0.056283 Batch F1: 0.9090909090909091
Epoch:  553        4 Batch loss: 0.073304 Batch F1: 0.9
Epoch:  553        5 Batch loss: 0.070442 Batch F1: 1.0
Epoch:  553        6 Batch loss: 0.081430 Batch F1: 0.8571428571428571
Epoch:  553        7 Batch loss: 0.068163 Batch F1: 0.9473684210526316
Epoch:  553        8 Batch loss: 0.064802 Batch F1: 0.8333333333333333
Epoch:  553        9 Batch loss: 0.067520 Batch F1: 0.8571428571428571
Epoch:  553       10 Batch loss: 0.066578 Batch F1: 0.923076923076923
Epoch:  553       11 Batch loss: 0.068430 Batch F1: 0.625
Epoch:  553       12 Batch loss: 0.063219 Batch F1: 0.0
Train Avg Loss  553: 0.067308

Train Avg F1  553: 0.8025676189434771

Val Avg Loss  553: 0.061963

Val Avg F1  553:  0.4756944444444444

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 554
--------------------------------------------------------------
Epoch:  554        1 Batch loss: 0.063546 Batch F1: 0.625
Epoch:  554        2 Batch loss: 0.056981 Batch F1: 0.5714285714285715
Epoch:  554        3 Batch loss: 0.073279 Batch F1: 0.3636363636363636
Epoch:  554        4 Batch loss: 0.063006 Batch F1: 0.6
Epoch:  554        5 Batch loss: 0.071777 Batch F1: 0.5
Epoch:  554        6 Batch loss: 0.088080 Batch F1: 0.0
Epoch:  554        7 Batch loss: 0.047304 Batch F1: 0.7499999999999999
Epoch:  554        8 Batch loss: 0.076476 Batch F1: 0.5882352941176471
Epoch:  554        9 Batch loss: 0.057310 Batch F1: 1.0
Epoch:  554       10 Batch loss: 0.073123 Batch F1: 0.9523809523809523
Epoch:  554       11 Batch loss: 0.075260 Batch F1: 0.9523809523809523
Epoch:  554       12 Batch loss: 0.071789 Batch F1: 1.0
Train Avg Loss  554: 0.068161

Train Avg F1  554: 0.6585885111620406

Val Avg Loss  554: 0.061993

Val Avg F1  554:  0.9334546527641157

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 555
--------------------------------------------------------------
Epoch:  555        1 Batch loss: 0.051900 Batch F1: 0.923076923076923
Epoch:  555        2 Batch loss: 0.057874 Batch F1: 0.888888888888889
Epoch:  555        3 Batch loss: 0.058129 Batch F1: 0.9090909090909091
Epoch:  555        4 Batch loss: 0.087790 Batch F1: 0.2857142857142857
Epoch:  555        5 Batch loss: 0.070164 Batch F1: 0.6666666666666666
Epoch:  555        6 Batch loss: 0.059569 Batch F1: 1.0
Epoch:  555        7 Batch loss: 0.069859 Batch F1: 0.9523809523809523
Epoch:  555        8 Batch loss: 0.068901 Batch F1: 0.9333333333333333
Epoch:  555        9 Batch loss: 0.071348 Batch F1: 0.888888888888889
Epoch:  555       10 Batch loss: 0.079475 Batch F1: 0.8235294117647058
Epoch:  555       11 Batch loss: 0.063615 Batch F1: 1.0
Epoch:  555       12 Batch loss: 0.076116 Batch F1: 1.0
Train Avg Loss  555: 0.067895

Train Avg F1  555: 0.8559641883171296

Val Avg Loss  555: 0.061041

Val Avg F1  555:  0.9436274509803921

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 556
--------------------------------------------------------------
Epoch:  556        1 Batch loss: 0.063824 Batch F1: 0.9523809523809523
Epoch:  556        2 Batch loss: 0.069728 Batch F1: 1.0
Epoch:  556        3 Batch loss: 0.055469 Batch F1: 0.9333333333333333
Epoch:  556        4 Batch loss: 0.079889 Batch F1: 0.962962962962963
Epoch:  556        5 Batch loss: 0.089222 Batch F1: 0.7777777777777778
Epoch:  556        6 Batch loss: 0.074138 Batch F1: 0.9411764705882353
Epoch:  556        7 Batch loss: 0.060322 Batch F1: 1.0
Epoch:  556        8 Batch loss: 0.052211 Batch F1: 0.923076923076923
Epoch:  556        9 Batch loss: 0.066111 Batch F1: 0.8333333333333333
Epoch:  556       10 Batch loss: 0.064815 Batch F1: 0.8571428571428571
Epoch:  556       11 Batch loss: 0.084154 Batch F1: 0.9166666666666666
Epoch:  556       12 Batch loss: 0.063461 Batch F1: 0.9090909090909091
Train Avg Loss  556: 0.068612

Train Avg F1  556: 0.9172451821961626

Val Avg Loss  556: 0.063900

Val Avg F1  556:  0.6755952380952381

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 557
--------------------------------------------------------------
Epoch:  557        1 Batch loss: 0.087714 Batch F1: 0.7058823529411764
Epoch:  557        2 Batch loss: 0.068074 Batch F1: 0.6666666666666666
Epoch:  557        3 Batch loss: 0.063726 Batch F1: 0.9333333333333333
Epoch:  557        4 Batch loss: 0.081696 Batch F1: 0.9565217391304348
Epoch:  557        5 Batch loss: 0.078417 Batch F1: 0.5333333333333333
Epoch:  557        6 Batch loss: 0.078605 Batch F1: 0.5
Epoch:  557        7 Batch loss: 0.066846 Batch F1: 0.9473684210526316
Epoch:  557        8 Batch loss: 0.046103 Batch F1: 1.0
Epoch:  557        9 Batch loss: 0.081730 Batch F1: 0.18181818181818182
Epoch:  557       10 Batch loss: 0.053053 Batch F1: 0.6
Epoch:  557       11 Batch loss: 0.058105 Batch F1: 0.4444444444444445
Epoch:  557       12 Batch loss: 0.063884 Batch F1: 0.8
Train Avg Loss  557: 0.068996

Train Avg F1  557: 0.6891140393933503

Val Avg Loss  557: 0.063008

Val Avg F1  557:  0.4969834087481146

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 558
--------------------------------------------------------------
Epoch:  558        1 Batch loss: 0.089056 Batch F1: 0.16666666666666669
Epoch:  558        2 Batch loss: 0.083593 Batch F1: 0.5263157894736842
Epoch:  558        3 Batch loss: 0.047545 Batch F1: 1.0
Epoch:  558        4 Batch loss: 0.073086 Batch F1: 0.7692307692307693
Epoch:  558        5 Batch loss: 0.064551 Batch F1: 1.0
Epoch:  558        6 Batch loss: 0.081538 Batch F1: 1.0
Epoch:  558        7 Batch loss: 0.058142 Batch F1: 1.0
Epoch:  558        8 Batch loss: 0.076649 Batch F1: 0.7499999999999999
Epoch:  558        9 Batch loss: 0.047154 Batch F1: 1.0
Epoch:  558       10 Batch loss: 0.075771 Batch F1: 0.8750000000000001
Epoch:  558       11 Batch loss: 0.062210 Batch F1: 0.8750000000000001
Epoch:  558       12 Batch loss: 0.065659 Batch F1: 0.9411764705882353
Train Avg Loss  558: 0.068746

Train Avg F1  558: 0.8252824746632798

Val Avg Loss  558: 0.061336

Val Avg F1  558:  0.906415343915344

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 559
--------------------------------------------------------------
Epoch:  559        1 Batch loss: 0.069153 Batch F1: 0.8333333333333333
Epoch:  559        2 Batch loss: 0.060584 Batch F1: 1.0
Epoch:  559        3 Batch loss: 0.079513 Batch F1: 0.9090909090909091
Epoch:  559        4 Batch loss: 0.084540 Batch F1: 0.9285714285714286
Epoch:  559        5 Batch loss: 0.051735 Batch F1: 1.0
Epoch:  559        6 Batch loss: 0.089786 Batch F1: 0.8333333333333333
Epoch:  559        7 Batch loss: 0.067953 Batch F1: 0.8333333333333333
Epoch:  559        8 Batch loss: 0.061111 Batch F1: 0.923076923076923
Epoch:  559        9 Batch loss: 0.057603 Batch F1: 0.9411764705882353
Epoch:  559       10 Batch loss: 0.070498 Batch F1: 0.5714285714285715
Epoch:  559       11 Batch loss: 0.056548 Batch F1: 1.0
Epoch:  559       12 Batch loss: 0.056838 Batch F1: 0.6
Train Avg Loss  559: 0.067155

Train Avg F1  559: 0.8644453585630055

Val Avg Loss  559: 0.062686

Val Avg F1  559:  0.5833333333333334

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 560
--------------------------------------------------------------
Epoch:  560        1 Batch loss: 0.065586 Batch F1: 0.8235294117647058
Epoch:  560        2 Batch loss: 0.078806 Batch F1: 0.19999999999999998
Epoch:  560        3 Batch loss: 0.055583 Batch F1: 0.9090909090909091
Epoch:  560        4 Batch loss: 0.074682 Batch F1: 0.9523809523809523
Epoch:  560        5 Batch loss: 0.062514 Batch F1: 0.8571428571428571
Epoch:  560        6 Batch loss: 0.062243 Batch F1: 1.0
Epoch:  560        7 Batch loss: 0.064714 Batch F1: 0.9411764705882353
Epoch:  560        8 Batch loss: 0.066112 Batch F1: 0.923076923076923
Epoch:  560        9 Batch loss: 0.080386 Batch F1: 0.9285714285714286
Epoch:  560       10 Batch loss: 0.060046 Batch F1: 1.0
Epoch:  560       11 Batch loss: 0.067736 Batch F1: 0.8750000000000001
Epoch:  560       12 Batch loss: 0.067974 Batch F1: 0.923076923076923
Train Avg Loss  560: 0.067199

Train Avg F1  560: 0.8610871563077446

Val Avg Loss  560: 0.061434

Val Avg F1  560:  0.9209600706311234

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 561
--------------------------------------------------------------
Epoch:  561        1 Batch loss: 0.059660 Batch F1: 1.0
Epoch:  561        2 Batch loss: 0.053948 Batch F1: 0.6666666666666666
Epoch:  561        3 Batch loss: 0.099988 Batch F1: 0.25
Epoch:  561        4 Batch loss: 0.054123 Batch F1: 1.0
Epoch:  561        5 Batch loss: 0.067092 Batch F1: 0.6666666666666666
Epoch:  561        6 Batch loss: 0.075787 Batch F1: 0.9090909090909091
Epoch:  561        7 Batch loss: 0.063283 Batch F1: 1.0
Epoch:  561        8 Batch loss: 0.057699 Batch F1: 0.8
Epoch:  561        9 Batch loss: 0.066779 Batch F1: 1.0
Epoch:  561       10 Batch loss: 0.092412 Batch F1: 0.8181818181818181
Epoch:  561       11 Batch loss: 0.064309 Batch F1: 1.0
Epoch:  561       12 Batch loss: 0.057899 Batch F1: 1.0
Train Avg Loss  561: 0.067748

Train Avg F1  561: 0.842550505050505

Val Avg Loss  561: 0.061056

Val Avg F1  561:  0.9309722222222222

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 562
--------------------------------------------------------------
Epoch:  562        1 Batch loss: 0.062898 Batch F1: 0.7272727272727273
Epoch:  562        2 Batch loss: 0.064508 Batch F1: 0.923076923076923
Epoch:  562        3 Batch loss: 0.066819 Batch F1: 1.0
Epoch:  562        4 Batch loss: 0.085113 Batch F1: 0.9090909090909091
Epoch:  562        5 Batch loss: 0.070551 Batch F1: 0.8333333333333333
Epoch:  562        6 Batch loss: 0.064256 Batch F1: 0.888888888888889
Epoch:  562        7 Batch loss: 0.063074 Batch F1: 0.923076923076923
Epoch:  562        8 Batch loss: 0.066668 Batch F1: 0.9523809523809523
Epoch:  562        9 Batch loss: 0.071993 Batch F1: 0.9411764705882353
Epoch:  562       10 Batch loss: 0.073321 Batch F1: 0.9
Epoch:  562       11 Batch loss: 0.052748 Batch F1: 1.0
Epoch:  562       12 Batch loss: 0.060270 Batch F1: 0.9333333333333333
Train Avg Loss  562: 0.066852

Train Avg F1  562: 0.9109692050868522

Val Avg Loss  562: 0.060811

Val Avg F1  562:  0.9166666666666666

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 563
--------------------------------------------------------------
Epoch:  563        1 Batch loss: 0.080902 Batch F1: 0.9
Epoch:  563        2 Batch loss: 0.053135 Batch F1: 1.0
Epoch:  563        3 Batch loss: 0.060221 Batch F1: 0.5
Epoch:  563        4 Batch loss: 0.069089 Batch F1: 0.5333333333333333
Epoch:  563        5 Batch loss: 0.074101 Batch F1: 0.42857142857142855
Epoch:  563        6 Batch loss: 0.062364 Batch F1: 0.4444444444444445
Epoch:  563        7 Batch loss: 0.069951 Batch F1: 0.5454545454545454
Epoch:  563        8 Batch loss: 0.043431 Batch F1: 0.7499999999999999
Epoch:  563        9 Batch loss: 0.080043 Batch F1: 0.6666666666666666
Epoch:  563       10 Batch loss: 0.077041 Batch F1: 0.9565217391304348
Epoch:  563       11 Batch loss: 0.075722 Batch F1: 0.9
Epoch:  563       12 Batch loss: 0.057296 Batch F1: 0.7499999999999999
Train Avg Loss  563: 0.066941

Train Avg F1  563: 0.6979160131334045

Val Avg Loss  563: 0.061326

Val Avg F1  563:  0.9293907846539425

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 564
--------------------------------------------------------------
Epoch:  564        1 Batch loss: 0.060349 Batch F1: 0.9090909090909091
Epoch:  564        2 Batch loss: 0.066949 Batch F1: 0.8750000000000001
Epoch:  564        3 Batch loss: 0.080605 Batch F1: 0.9166666666666666
Epoch:  564        4 Batch loss: 0.068323 Batch F1: 0.9473684210526316
Epoch:  564        5 Batch loss: 0.067060 Batch F1: 0.9333333333333333
Epoch:  564        6 Batch loss: 0.058061 Batch F1: 1.0
Epoch:  564        7 Batch loss: 0.072023 Batch F1: 0.8235294117647058
Epoch:  564        8 Batch loss: 0.061779 Batch F1: 0.9523809523809523
Epoch:  564        9 Batch loss: 0.059622 Batch F1: 0.923076923076923
Epoch:  564       10 Batch loss: 0.073279 Batch F1: 0.19999999999999998
Epoch:  564       11 Batch loss: 0.068612 Batch F1: 0.2222222222222222
Epoch:  564       12 Batch loss: 0.074454 Batch F1: 0.3636363636363636
Train Avg Loss  564: 0.067593

Train Avg F1  564: 0.7555254336020588

Val Avg Loss  564: 0.063618

Val Avg F1  564:  0.9229085865115276

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 565
--------------------------------------------------------------
Epoch:  565        1 Batch loss: 0.060883 Batch F1: 1.0
Epoch:  565        2 Batch loss: 0.088036 Batch F1: 0.9166666666666666
Epoch:  565        3 Batch loss: 0.063730 Batch F1: 1.0
Epoch:  565        4 Batch loss: 0.062009 Batch F1: 0.9333333333333333
Epoch:  565        5 Batch loss: 0.078354 Batch F1: 0.7777777777777778
Epoch:  565        6 Batch loss: 0.070488 Batch F1: 1.0
Epoch:  565        7 Batch loss: 0.059511 Batch F1: 1.0
Epoch:  565        8 Batch loss: 0.069331 Batch F1: 0.888888888888889
Epoch:  565        9 Batch loss: 0.068859 Batch F1: 0.9473684210526316
Epoch:  565       10 Batch loss: 0.063104 Batch F1: 0.8333333333333333
Epoch:  565       11 Batch loss: 0.072698 Batch F1: 0.7692307692307693
Epoch:  565       12 Batch loss: 0.057965 Batch F1: 0.923076923076923
Train Avg Loss  565: 0.067914

Train Avg F1  565: 0.915806342780027

Val Avg Loss  565: 0.061760

Val Avg F1  565:  0.9075757575757576

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 566
--------------------------------------------------------------
Epoch:  566        1 Batch loss: 0.064051 Batch F1: 0.9333333333333333
Epoch:  566        2 Batch loss: 0.064401 Batch F1: 0.5714285714285715
Epoch:  566        3 Batch loss: 0.057292 Batch F1: 0.8750000000000001
Epoch:  566        4 Batch loss: 0.078242 Batch F1: 0.7272727272727273
Epoch:  566        5 Batch loss: 0.074686 Batch F1: 0.9
Epoch:  566        6 Batch loss: 0.069876 Batch F1: 0.9411764705882353
Epoch:  566        7 Batch loss: 0.079860 Batch F1: 0.9166666666666666
Epoch:  566        8 Batch loss: 0.054677 Batch F1: 1.0
Epoch:  566        9 Batch loss: 0.072783 Batch F1: 0.9473684210526316
Epoch:  566       10 Batch loss: 0.063448 Batch F1: 0.8750000000000001
Epoch:  566       11 Batch loss: 0.064892 Batch F1: 0.888888888888889
Epoch:  566       12 Batch loss: 0.067247 Batch F1: 1.0
Train Avg Loss  566: 0.067621

Train Avg F1  566: 0.8813445899359214

Val Avg Loss  566: 0.063111

Val Avg F1  566:  0.5866977225672878

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 567
--------------------------------------------------------------
Epoch:  567        1 Batch loss: 0.069987 Batch F1: 0.7142857142857143
Epoch:  567        2 Batch loss: 0.078662 Batch F1: 0.18181818181818182
Epoch:  567        3 Batch loss: 0.054082 Batch F1: 0.7272727272727273
Epoch:  567        4 Batch loss: 0.073939 Batch F1: 0.8750000000000001
Epoch:  567        5 Batch loss: 0.069589 Batch F1: 0.8571428571428571
Epoch:  567        6 Batch loss: 0.077562 Batch F1: 0.631578947368421
Epoch:  567        7 Batch loss: 0.062856 Batch F1: 0.4444444444444445
Epoch:  567        8 Batch loss: 0.066736 Batch F1: 0.2222222222222222
Epoch:  567        9 Batch loss: 0.077002 Batch F1: 0.18181818181818182
Epoch:  567       10 Batch loss: 0.066326 Batch F1: 0.9411764705882353
Epoch:  567       11 Batch loss: 0.049801 Batch F1: 0.9333333333333333
Epoch:  567       12 Batch loss: 0.067331 Batch F1: 1.0
Train Avg Loss  567: 0.067823

Train Avg F1  567: 0.6425077566911933

Val Avg Loss  567: 0.061248

Val Avg F1  567:  0.9213032581453635

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 568
--------------------------------------------------------------
Epoch:  568        1 Batch loss: 0.063946 Batch F1: 0.9333333333333333
Epoch:  568        2 Batch loss: 0.044706 Batch F1: 1.0
Epoch:  568        3 Batch loss: 0.073498 Batch F1: 0.4
Epoch:  568        4 Batch loss: 0.044724 Batch F1: 0.7272727272727273
Epoch:  568        5 Batch loss: 0.066136 Batch F1: 0.5454545454545454
Epoch:  568        6 Batch loss: 0.065631 Batch F1: 0.6153846153846153
Epoch:  568        7 Batch loss: 0.104564 Batch F1: 0.14285714285714288
Epoch:  568        8 Batch loss: 0.087166 Batch F1: 0.8695652173913044
Epoch:  568        9 Batch loss: 0.082649 Batch F1: 0.9473684210526316
Epoch:  568       10 Batch loss: 0.070890 Batch F1: 1.0
Epoch:  568       11 Batch loss: 0.063923 Batch F1: 1.0
Epoch:  568       12 Batch loss: 0.068041 Batch F1: 1.0
Train Avg Loss  568: 0.069656

Train Avg F1  568: 0.7651030002288585

Val Avg Loss  568: 0.065953

Val Avg F1  568:  0.9251336898395721

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 569
--------------------------------------------------------------
Epoch:  569        1 Batch loss: 0.056317 Batch F1: 0.888888888888889
Epoch:  569        2 Batch loss: 0.083354 Batch F1: 0.0
Epoch:  569        3 Batch loss: 0.061158 Batch F1: 1.0
Epoch:  569        4 Batch loss: 0.077397 Batch F1: 0.9600000000000001
Epoch:  569        5 Batch loss: 0.072352 Batch F1: 0.9090909090909091
Epoch:  569        6 Batch loss: 0.063234 Batch F1: 0.8571428571428571
Epoch:  569        7 Batch loss: 0.122101 Batch F1: 0.0
Epoch:  569        8 Batch loss: 0.063625 Batch F1: 1.0
Epoch:  569        9 Batch loss: 0.062327 Batch F1: 0.8333333333333333
Epoch:  569       10 Batch loss: 0.095294 Batch F1: 0.7000000000000001
Epoch:  569       11 Batch loss: 0.074302 Batch F1: 0.8333333333333333
Epoch:  569       12 Batch loss: 0.090183 Batch F1: 0.2222222222222222
Train Avg Loss  569: 0.076804

Train Avg F1  569: 0.6836676286676285

Val Avg Loss  569: 0.069183

Val Avg F1  569:  0.9247208931419457

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 570
--------------------------------------------------------------
Epoch:  570        1 Batch loss: 0.063093 Batch F1: 1.0
Epoch:  570        2 Batch loss: 0.113363 Batch F1: 0.0
Epoch:  570        3 Batch loss: 0.062575 Batch F1: 0.6
Epoch:  570        4 Batch loss: 0.071793 Batch F1: 0.8235294117647058
Epoch:  570        5 Batch loss: 0.086008 Batch F1: 0.9411764705882353
Epoch:  570        6 Batch loss: 0.048591 Batch F1: 0.7499999999999999
Epoch:  570        7 Batch loss: 0.092528 Batch F1: 0.625
Epoch:  570        8 Batch loss: 0.066502 Batch F1: 0.4444444444444445
Epoch:  570        9 Batch loss: 0.103558 Batch F1: 0.25
Epoch:  570       10 Batch loss: 0.090827 Batch F1: 1.0
Epoch:  570       11 Batch loss: 0.088376 Batch F1: 0.8571428571428571
Epoch:  570       12 Batch loss: 0.112041 Batch F1: 0.0
Train Avg Loss  570: 0.083271

Train Avg F1  570: 0.6076077653283536

Val Avg Loss  570: 0.094285

Val Avg F1  570:  0.0

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 571
--------------------------------------------------------------
Epoch:  571        1 Batch loss: 0.097839 Batch F1: 0.0
Epoch:  571        2 Batch loss: 0.048770 Batch F1: 1.0
Epoch:  571        3 Batch loss: 0.102311 Batch F1: 0.8
Epoch:  571        4 Batch loss: 0.067401 Batch F1: 0.888888888888889
Epoch:  571        5 Batch loss: 0.057280 Batch F1: 0.2857142857142857
Epoch:  571        6 Batch loss: 0.084074 Batch F1: 0.5
Epoch:  571        7 Batch loss: 0.071312 Batch F1: 0.7499999999999999
Epoch:  571        8 Batch loss: 0.073440 Batch F1: 0.5
Epoch:  571        9 Batch loss: 0.082339 Batch F1: 0.962962962962963
Epoch:  571       10 Batch loss: 0.071613 Batch F1: 0.923076923076923
Epoch:  571       11 Batch loss: 0.066164 Batch F1: 0.8333333333333333
Epoch:  571       12 Batch loss: 0.071068 Batch F1: 0.5714285714285715
Train Avg Loss  571: 0.074468

Train Avg F1  571: 0.6679504137837471

Val Avg Loss  571: 0.064659

Val Avg F1  571:  0.5625

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 572
--------------------------------------------------------------
Epoch:  572        1 Batch loss: 0.045118 Batch F1: 0.8571428571428571
Epoch:  572        2 Batch loss: 0.071963 Batch F1: 0.5
Epoch:  572        3 Batch loss: 0.040325 Batch F1: 0.6666666666666666
Epoch:  572        4 Batch loss: 0.069112 Batch F1: 0.25
Epoch:  572        5 Batch loss: 0.080803 Batch F1: 0.7000000000000001
Epoch:  572        6 Batch loss: 0.092459 Batch F1: 0.4
Epoch:  572        7 Batch loss: 0.087823 Batch F1: 0.888888888888889
Epoch:  572        8 Batch loss: 0.077688 Batch F1: 1.0
Epoch:  572        9 Batch loss: 0.078866 Batch F1: 0.9411764705882353
Epoch:  572       10 Batch loss: 0.075197 Batch F1: 0.9473684210526316
Epoch:  572       11 Batch loss: 0.060952 Batch F1: 0.8333333333333333
Epoch:  572       12 Batch loss: 0.081811 Batch F1: 0.9473684210526316
Train Avg Loss  572: 0.071843

Train Avg F1  572: 0.7443287548937704

Val Avg Loss  572: 0.063277

Val Avg F1  572:  0.9102941176470589

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 573
--------------------------------------------------------------
Epoch:  573        1 Batch loss: 0.067877 Batch F1: 1.0
Epoch:  573        2 Batch loss: 0.057318 Batch F1: 0.888888888888889
Epoch:  573        3 Batch loss: 0.075013 Batch F1: 0.888888888888889
Epoch:  573        4 Batch loss: 0.062501 Batch F1: 0.8333333333333333
Epoch:  573        5 Batch loss: 0.061353 Batch F1: 0.923076923076923
Epoch:  573        6 Batch loss: 0.072041 Batch F1: 0.5714285714285715
Epoch:  573        7 Batch loss: 0.062723 Batch F1: 0.5454545454545454
Epoch:  573        8 Batch loss: 0.110312 Batch F1: 0.375
Epoch:  573        9 Batch loss: 0.064229 Batch F1: 0.2222222222222222
Epoch:  573       10 Batch loss: 0.076600 Batch F1: 0.5
Epoch:  573       11 Batch loss: 0.059859 Batch F1: 1.0
Epoch:  573       12 Batch loss: 0.069739 Batch F1: 0.9411764705882353
Train Avg Loss  573: 0.069964

Train Avg F1  573: 0.7241224869901339

Val Avg Loss  573: 0.062901

Val Avg F1  573:  0.9168525592055004

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 574
--------------------------------------------------------------
Epoch:  574        1 Batch loss: 0.088704 Batch F1: 0.9600000000000001
Epoch:  574        2 Batch loss: 0.059142 Batch F1: 0.9090909090909091
Epoch:  574        3 Batch loss: 0.066606 Batch F1: 0.9
Epoch:  574        4 Batch loss: 0.041917 Batch F1: 1.0
Epoch:  574        5 Batch loss: 0.049302 Batch F1: 0.8
Epoch:  574        6 Batch loss: 0.097115 Batch F1: 0.888888888888889
Epoch:  574        7 Batch loss: 0.055646 Batch F1: 0.9090909090909091
Epoch:  574        8 Batch loss: 0.077184 Batch F1: 0.6666666666666666
Epoch:  574        9 Batch loss: 0.061316 Batch F1: 0.4
Epoch:  574       10 Batch loss: 0.099953 Batch F1: 0.47058823529411764
Epoch:  574       11 Batch loss: 0.064084 Batch F1: 0.5333333333333333
Epoch:  574       12 Batch loss: 0.067125 Batch F1: 1.0
Train Avg Loss  574: 0.069008

Train Avg F1  574: 0.7864715785304023

Val Avg Loss  574: 0.061903

Val Avg F1  574:  0.9216311724051662

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 575
--------------------------------------------------------------
Epoch:  575        1 Batch loss: 0.088251 Batch F1: 0.7777777777777778
Epoch:  575        2 Batch loss: 0.077475 Batch F1: 0.8235294117647058
Epoch:  575        3 Batch loss: 0.075552 Batch F1: 0.9166666666666666
Epoch:  575        4 Batch loss: 0.046794 Batch F1: 1.0
Epoch:  575        5 Batch loss: 0.056370 Batch F1: 1.0
Epoch:  575        6 Batch loss: 0.071798 Batch F1: 0.9411764705882353
Epoch:  575        7 Batch loss: 0.073937 Batch F1: 0.9523809523809523
Epoch:  575        8 Batch loss: 0.070486 Batch F1: 0.923076923076923
Epoch:  575        9 Batch loss: 0.072116 Batch F1: 0.7368421052631579
Epoch:  575       10 Batch loss: 0.082240 Batch F1: 0.9600000000000001
Epoch:  575       11 Batch loss: 0.065419 Batch F1: 0.8571428571428571
Epoch:  575       12 Batch loss: 0.049493 Batch F1: 0.8571428571428571
Train Avg Loss  575: 0.069161

Train Avg F1  575: 0.8954780018170113

Val Avg Loss  575: 0.063206

Val Avg F1  575:  0.914396681749623

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 576
--------------------------------------------------------------
Epoch:  576        1 Batch loss: 0.055147 Batch F1: 0.888888888888889
Epoch:  576        2 Batch loss: 0.081781 Batch F1: 0.5882352941176471
Epoch:  576        3 Batch loss: 0.059793 Batch F1: 0.8333333333333333
Epoch:  576        4 Batch loss: 0.060704 Batch F1: 0.6
Epoch:  576        5 Batch loss: 0.086188 Batch F1: 0.42857142857142855
Epoch:  576        6 Batch loss: 0.064155 Batch F1: 0.6153846153846153
Epoch:  576        7 Batch loss: 0.091068 Batch F1: 0.6666666666666666
Epoch:  576        8 Batch loss: 0.065067 Batch F1: 0.8571428571428571
Epoch:  576        9 Batch loss: 0.073926 Batch F1: 0.888888888888889
Epoch:  576       10 Batch loss: 0.053006 Batch F1: 1.0
Epoch:  576       11 Batch loss: 0.091944 Batch F1: 0.967741935483871
Epoch:  576       12 Batch loss: 0.049318 Batch F1: 0.8571428571428571
Train Avg Loss  576: 0.069342

Train Avg F1  576: 0.7659997304684212

Val Avg Loss  576: 0.061990

Val Avg F1  576:  0.9360633484162897

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 577
--------------------------------------------------------------
Epoch:  577        1 Batch loss: 0.082395 Batch F1: 0.8421052631578948
Epoch:  577        2 Batch loss: 0.079476 Batch F1: 0.9090909090909091
Epoch:  577        3 Batch loss: 0.061709 Batch F1: 0.9090909090909091
Epoch:  577        4 Batch loss: 0.062801 Batch F1: 0.8333333333333333
Epoch:  577        5 Batch loss: 0.072037 Batch F1: 0.9473684210526316
Epoch:  577        6 Batch loss: 0.057239 Batch F1: 1.0
Epoch:  577        7 Batch loss: 0.039887 Batch F1: 0.6666666666666666
Epoch:  577        8 Batch loss: 0.086619 Batch F1: 0.3076923076923077
Epoch:  577        9 Batch loss: 0.080173 Batch F1: 0.5714285714285715
Epoch:  577       10 Batch loss: 0.066109 Batch F1: 0.5714285714285715
Epoch:  577       11 Batch loss: 0.073295 Batch F1: 0.5555555555555556
Epoch:  577       12 Batch loss: 0.066134 Batch F1: 0.9411764705882353
Train Avg Loss  577: 0.068990

Train Avg F1  577: 0.7545780815904655

Val Avg Loss  577: 0.062134

Val Avg F1  577:  0.9254332623897841

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 578
--------------------------------------------------------------
Epoch:  578        1 Batch loss: 0.074058 Batch F1: 0.9473684210526316
Epoch:  578        2 Batch loss: 0.073187 Batch F1: 0.9473684210526316
Epoch:  578        3 Batch loss: 0.062666 Batch F1: 1.0
Epoch:  578        4 Batch loss: 0.062401 Batch F1: 0.9411764705882353
Epoch:  578        5 Batch loss: 0.074753 Batch F1: 0.9565217391304348
Epoch:  578        6 Batch loss: 0.091912 Batch F1: 0.8181818181818181
Epoch:  578        7 Batch loss: 0.047077 Batch F1: 0.888888888888889
Epoch:  578        8 Batch loss: 0.064013 Batch F1: 1.0
Epoch:  578        9 Batch loss: 0.082624 Batch F1: 0.7142857142857143
Epoch:  578       10 Batch loss: 0.072038 Batch F1: 0.9600000000000001
Epoch:  578       11 Batch loss: 0.065847 Batch F1: 0.9411764705882353
Epoch:  578       12 Batch loss: 0.055946 Batch F1: 0.8571428571428571
Train Avg Loss  578: 0.068877

Train Avg F1  578: 0.9143425667426207

Val Avg Loss  578: 0.061438

Val Avg F1  578:  0.9145299145299145

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 579
--------------------------------------------------------------
Epoch:  579        1 Batch loss: 0.059000 Batch F1: 0.9333333333333333
Epoch:  579        2 Batch loss: 0.068758 Batch F1: 0.4444444444444445
Epoch:  579        3 Batch loss: 0.086050 Batch F1: 0.4
Epoch:  579        4 Batch loss: 0.049622 Batch F1: 0.5714285714285715
Epoch:  579        5 Batch loss: 0.064430 Batch F1: 0.7058823529411764
Epoch:  579        6 Batch loss: 0.089668 Batch F1: 0.5263157894736842
Epoch:  579        7 Batch loss: 0.063026 Batch F1: 0.25
Epoch:  579        8 Batch loss: 0.059266 Batch F1: 1.0
Epoch:  579        9 Batch loss: 0.075195 Batch F1: 0.9565217391304348
Epoch:  579       10 Batch loss: 0.062710 Batch F1: 1.0
Epoch:  579       11 Batch loss: 0.063331 Batch F1: 0.9473684210526316
Epoch:  579       12 Batch loss: 0.078564 Batch F1: 0.7272727272727273
Train Avg Loss  579: 0.068302

Train Avg F1  579: 0.7052139482564169

Val Avg Loss  579: 0.061652

Val Avg F1  579:  0.9065934065934066

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 580
--------------------------------------------------------------
Epoch:  580        1 Batch loss: 0.070002 Batch F1: 0.888888888888889
Epoch:  580        2 Batch loss: 0.068360 Batch F1: 1.0
Epoch:  580        3 Batch loss: 0.054498 Batch F1: 0.9411764705882353
Epoch:  580        4 Batch loss: 0.069462 Batch F1: 0.9333333333333333
Epoch:  580        5 Batch loss: 0.065674 Batch F1: 1.0
Epoch:  580        6 Batch loss: 0.087487 Batch F1: 0.7368421052631579
Epoch:  580        7 Batch loss: 0.043147 Batch F1: 1.0
Epoch:  580        8 Batch loss: 0.079878 Batch F1: 0.9523809523809523
Epoch:  580        9 Batch loss: 0.082908 Batch F1: 0.8235294117647058
Epoch:  580       10 Batch loss: 0.060078 Batch F1: 0.923076923076923
Epoch:  580       11 Batch loss: 0.061416 Batch F1: 0.8750000000000001
Epoch:  580       12 Batch loss: 0.064739 Batch F1: 1.0
Train Avg Loss  580: 0.067304

Train Avg F1  580: 0.9228523404413497

Val Avg Loss  580: 0.061917

Val Avg F1  580:  0.4816239316239316

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 581
--------------------------------------------------------------
Epoch:  581        1 Batch loss: 0.080311 Batch F1: 0.5263157894736842
Epoch:  581        2 Batch loss: 0.074500 Batch F1: 0.9523809523809523
Epoch:  581        3 Batch loss: 0.061368 Batch F1: 0.9333333333333333
Epoch:  581        4 Batch loss: 0.064537 Batch F1: 1.0
Epoch:  581        5 Batch loss: 0.083210 Batch F1: 0.8421052631578948
Epoch:  581        6 Batch loss: 0.076955 Batch F1: 0.9090909090909091
Epoch:  581        7 Batch loss: 0.054921 Batch F1: 1.0
Epoch:  581        8 Batch loss: 0.064886 Batch F1: 0.9333333333333333
Epoch:  581        9 Batch loss: 0.057119 Batch F1: 0.8333333333333333
Epoch:  581       10 Batch loss: 0.068357 Batch F1: 0.8333333333333333
Epoch:  581       11 Batch loss: 0.059350 Batch F1: 1.0
Epoch:  581       12 Batch loss: 0.070000 Batch F1: 0.8333333333333333
Train Avg Loss  581: 0.067960

Train Avg F1  581: 0.8830466317308424

Val Avg Loss  581: 0.061860

Val Avg F1  581:  0.5845959595959596

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 582
--------------------------------------------------------------
Epoch:  582        1 Batch loss: 0.047718 Batch F1: 0.6666666666666666
Epoch:  582        2 Batch loss: 0.082116 Batch F1: 0.3076923076923077
Epoch:  582        3 Batch loss: 0.069980 Batch F1: 0.7058823529411764
Epoch:  582        4 Batch loss: 0.072760 Batch F1: 0.5714285714285715
Epoch:  582        5 Batch loss: 0.077649 Batch F1: 0.5
Epoch:  582        6 Batch loss: 0.058470 Batch F1: 0.5
Epoch:  582        7 Batch loss: 0.079272 Batch F1: 0.8421052631578948
Epoch:  582        8 Batch loss: 0.081603 Batch F1: 0.8571428571428571
Epoch:  582        9 Batch loss: 0.065418 Batch F1: 0.8333333333333333
Epoch:  582       10 Batch loss: 0.066893 Batch F1: 1.0
Epoch:  582       11 Batch loss: 0.054617 Batch F1: 0.8571428571428571
Epoch:  582       12 Batch loss: 0.075549 Batch F1: 0.8235294117647058
Train Avg Loss  582: 0.069337

Train Avg F1  582: 0.7054103017725307

Val Avg Loss  582: 0.067101

Val Avg F1  582:  0.6868347338935574

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 583
--------------------------------------------------------------
Epoch:  583        1 Batch loss: 0.073203 Batch F1: 0.7777777777777778
Epoch:  583        2 Batch loss: 0.054770 Batch F1: 0.6666666666666666
Epoch:  583        3 Batch loss: 0.078584 Batch F1: 0.761904761904762
Epoch:  583        4 Batch loss: 0.066943 Batch F1: 0.8571428571428571
Epoch:  583        5 Batch loss: 0.069324 Batch F1: 0.923076923076923
Epoch:  583        6 Batch loss: 0.066549 Batch F1: 0.6666666666666666
Epoch:  583        7 Batch loss: 0.075175 Batch F1: 0.7499999999999999
Epoch:  583        8 Batch loss: 0.080787 Batch F1: 0.6666666666666666
Epoch:  583        9 Batch loss: 0.065374 Batch F1: 0.5454545454545454
Epoch:  583       10 Batch loss: 0.046942 Batch F1: 0.5714285714285715
Epoch:  583       11 Batch loss: 0.105143 Batch F1: 0.23529411764705882
Epoch:  583       12 Batch loss: 0.060453 Batch F1: 0.4444444444444445
Train Avg Loss  583: 0.070271

Train Avg F1  583: 0.6555436665730784

Val Avg Loss  583: 0.061958

Val Avg F1  583:  0.933041958041958

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 584
--------------------------------------------------------------
Epoch:  584        1 Batch loss: 0.070109 Batch F1: 1.0
Epoch:  584        2 Batch loss: 0.063080 Batch F1: 0.8571428571428571
Epoch:  584        3 Batch loss: 0.055689 Batch F1: 1.0
Epoch:  584        4 Batch loss: 0.056371 Batch F1: 1.0
Epoch:  584        5 Batch loss: 0.084364 Batch F1: 0.19999999999999998
Epoch:  584        6 Batch loss: 0.062467 Batch F1: 0.7058823529411764
Epoch:  584        7 Batch loss: 0.068710 Batch F1: 0.7272727272727273
Epoch:  584        8 Batch loss: 0.060828 Batch F1: 0.9411764705882353
Epoch:  584        9 Batch loss: 0.072085 Batch F1: 0.9090909090909091
Epoch:  584       10 Batch loss: 0.066890 Batch F1: 0.888888888888889
Epoch:  584       11 Batch loss: 0.073122 Batch F1: 1.0
Epoch:  584       12 Batch loss: 0.084284 Batch F1: 0.7272727272727273
Train Avg Loss  584: 0.068167

Train Avg F1  584: 0.8297272444331267

Val Avg Loss  584: 0.062253

Val Avg F1  584:  0.9293560606060606

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 585
--------------------------------------------------------------
Epoch:  585        1 Batch loss: 0.085820 Batch F1: 0.8235294117647058
Epoch:  585        2 Batch loss: 0.074477 Batch F1: 0.8235294117647058
Epoch:  585        3 Batch loss: 0.067327 Batch F1: 0.7692307692307693
Epoch:  585        4 Batch loss: 0.054157 Batch F1: 1.0
Epoch:  585        5 Batch loss: 0.054468 Batch F1: 0.5
Epoch:  585        6 Batch loss: 0.082636 Batch F1: 0.0
Epoch:  585        7 Batch loss: 0.080378 Batch F1: 0.4
Epoch:  585        8 Batch loss: 0.053215 Batch F1: 1.0
Epoch:  585        9 Batch loss: 0.082519 Batch F1: 0.9565217391304348
Epoch:  585       10 Batch loss: 0.066952 Batch F1: 0.9333333333333333
Epoch:  585       11 Batch loss: 0.075330 Batch F1: 0.9523809523809523
Epoch:  585       12 Batch loss: 0.060892 Batch F1: 0.8571428571428571
Train Avg Loss  585: 0.069848

Train Avg F1  585: 0.75130570622898

Val Avg Loss  585: 0.061888

Val Avg F1  585:  0.537950937950938

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 586
--------------------------------------------------------------
Epoch:  586        1 Batch loss: 0.059462 Batch F1: 0.4
Epoch:  586        2 Batch loss: 0.063698 Batch F1: 0.7499999999999999
Epoch:  586        3 Batch loss: 0.072344 Batch F1: 0.3636363636363636
Epoch:  586        4 Batch loss: 0.074076 Batch F1: 0.9523809523809523
Epoch:  586        5 Batch loss: 0.054743 Batch F1: 0.888888888888889
Epoch:  586        6 Batch loss: 0.073560 Batch F1: 0.8
Epoch:  586        7 Batch loss: 0.067596 Batch F1: 0.9523809523809523
Epoch:  586        8 Batch loss: 0.055861 Batch F1: 1.0
Epoch:  586        9 Batch loss: 0.069889 Batch F1: 0.9473684210526316
Epoch:  586       10 Batch loss: 0.074118 Batch F1: 0.8235294117647058
Epoch:  586       11 Batch loss: 0.079229 Batch F1: 0.9523809523809523
Epoch:  586       12 Batch loss: 0.067443 Batch F1: 0.888888888888889
Train Avg Loss  586: 0.067668

Train Avg F1  586: 0.8099545692811946

Val Avg Loss  586: 0.061293

Val Avg F1  586:  0.9229085865115276

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 587
--------------------------------------------------------------
Epoch:  587        1 Batch loss: 0.083862 Batch F1: 0.9655172413793104
Epoch:  587        2 Batch loss: 0.072598 Batch F1: 0.8750000000000001
Epoch:  587        3 Batch loss: 0.057866 Batch F1: 0.8333333333333333
Epoch:  587        4 Batch loss: 0.073553 Batch F1: 0.9565217391304348
Epoch:  587        5 Batch loss: 0.064647 Batch F1: 0.923076923076923
Epoch:  587        6 Batch loss: 0.066724 Batch F1: 0.9411764705882353
Epoch:  587        7 Batch loss: 0.066370 Batch F1: 0.9473684210526316
Epoch:  587        8 Batch loss: 0.045278 Batch F1: 0.923076923076923
Epoch:  587        9 Batch loss: 0.070223 Batch F1: 0.8571428571428571
Epoch:  587       10 Batch loss: 0.061849 Batch F1: 0.8333333333333333
Epoch:  587       11 Batch loss: 0.056782 Batch F1: 0.25
Epoch:  587       12 Batch loss: 0.084319 Batch F1: 0.4615384615384615
Train Avg Loss  587: 0.067006

Train Avg F1  587: 0.8139238086377037

Val Avg Loss  587: 0.061389

Val Avg F1  587:  0.5629960317460317

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 588
--------------------------------------------------------------
Epoch:  588        1 Batch loss: 0.060806 Batch F1: 0.6153846153846153
Epoch:  588        2 Batch loss: 0.071258 Batch F1: 0.9565217391304348
Epoch:  588        3 Batch loss: 0.058568 Batch F1: 0.888888888888889
Epoch:  588        4 Batch loss: 0.070449 Batch F1: 0.8235294117647058
Epoch:  588        5 Batch loss: 0.055380 Batch F1: 1.0
Epoch:  588        6 Batch loss: 0.089750 Batch F1: 0.888888888888889
Epoch:  588        7 Batch loss: 0.054879 Batch F1: 1.0
Epoch:  588        8 Batch loss: 0.063062 Batch F1: 0.9333333333333333
Epoch:  588        9 Batch loss: 0.090553 Batch F1: 0.9
Epoch:  588       10 Batch loss: 0.058393 Batch F1: 0.8571428571428571
Epoch:  588       11 Batch loss: 0.082963 Batch F1: 0.9565217391304348
Epoch:  588       12 Batch loss: 0.044512 Batch F1: 1.0
Train Avg Loss  588: 0.066714

Train Avg F1  588: 0.9016842894720134

Val Avg Loss  588: 0.061428

Val Avg F1  588:  0.5812499999999999

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 589
--------------------------------------------------------------
Epoch:  589        1 Batch loss: 0.061454 Batch F1: 0.4
Epoch:  589        2 Batch loss: 0.052464 Batch F1: 0.6
Epoch:  589        3 Batch loss: 0.061402 Batch F1: 0.4
Epoch:  589        4 Batch loss: 0.090740 Batch F1: 0.16666666666666669
Epoch:  589        5 Batch loss: 0.053398 Batch F1: 0.2857142857142857
Epoch:  589        6 Batch loss: 0.092761 Batch F1: 0.5714285714285715
Epoch:  589        7 Batch loss: 0.079598 Batch F1: 0.8235294117647058
Epoch:  589        8 Batch loss: 0.066126 Batch F1: 0.9333333333333333
Epoch:  589        9 Batch loss: 0.072363 Batch F1: 0.8750000000000001
Epoch:  589       10 Batch loss: 0.059436 Batch F1: 1.0
Epoch:  589       11 Batch loss: 0.074212 Batch F1: 0.888888888888889
Epoch:  589       12 Batch loss: 0.055417 Batch F1: 0.923076923076923
Train Avg Loss  589: 0.068281

Train Avg F1  589: 0.655636506739448

Val Avg Loss  589: 0.062752

Val Avg F1  589:  0.9131766381766382

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 590
--------------------------------------------------------------
Epoch:  590        1 Batch loss: 0.074367 Batch F1: 0.9411764705882353
Epoch:  590        2 Batch loss: 0.076345 Batch F1: 0.9523809523809523
Epoch:  590        3 Batch loss: 0.086882 Batch F1: 0.8695652173913044
Epoch:  590        4 Batch loss: 0.059171 Batch F1: 0.8750000000000001
Epoch:  590        5 Batch loss: 0.075563 Batch F1: 0.9090909090909091
Epoch:  590        6 Batch loss: 0.055032 Batch F1: 0.923076923076923
Epoch:  590        7 Batch loss: 0.073882 Batch F1: 0.888888888888889
Epoch:  590        8 Batch loss: 0.062243 Batch F1: 0.8333333333333333
Epoch:  590        9 Batch loss: 0.062779 Batch F1: 0.6666666666666666
Epoch:  590       10 Batch loss: 0.064585 Batch F1: 0.5454545454545454
Epoch:  590       11 Batch loss: 0.071946 Batch F1: 0.5333333333333333
Epoch:  590       12 Batch loss: 0.043774 Batch F1: 0.0
Train Avg Loss  590: 0.067214

Train Avg F1  590: 0.7448306033504243

Val Avg Loss  590: 0.062854

Val Avg F1  590:  0.5812499999999999

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 591
--------------------------------------------------------------
Epoch:  591        1 Batch loss: 0.085524 Batch F1: 0.5
Epoch:  591        2 Batch loss: 0.093174 Batch F1: 0.5454545454545454
Epoch:  591        3 Batch loss: 0.070030 Batch F1: 0.9523809523809523
Epoch:  591        4 Batch loss: 0.075411 Batch F1: 0.9090909090909091
Epoch:  591        5 Batch loss: 0.069479 Batch F1: 0.9411764705882353
Epoch:  591        6 Batch loss: 0.052278 Batch F1: 1.0
Epoch:  591        7 Batch loss: 0.070080 Batch F1: 0.6666666666666666
Epoch:  591        8 Batch loss: 0.067916 Batch F1: 0.5714285714285715
Epoch:  591        9 Batch loss: 0.082151 Batch F1: 0.5333333333333333
Epoch:  591       10 Batch loss: 0.075679 Batch F1: 0.7142857142857143
Epoch:  591       11 Batch loss: 0.054659 Batch F1: 0.923076923076923
Epoch:  591       12 Batch loss: 0.052653 Batch F1: 1.0
Train Avg Loss  591: 0.070753

Train Avg F1  591: 0.7714078405254875

Val Avg Loss  591: 0.065918

Val Avg F1  591:  0.7121794871794871

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 592
--------------------------------------------------------------
Epoch:  592        1 Batch loss: 0.078252 Batch F1: 0.4
Epoch:  592        2 Batch loss: 0.079780 Batch F1: 0.8421052631578948
Epoch:  592        3 Batch loss: 0.060462 Batch F1: 0.6666666666666666
Epoch:  592        4 Batch loss: 0.085552 Batch F1: 0.5
Epoch:  592        5 Batch loss: 0.071185 Batch F1: 0.9473684210526316
Epoch:  592        6 Batch loss: 0.075945 Batch F1: 0.9
Epoch:  592        7 Batch loss: 0.076874 Batch F1: 0.8571428571428571
Epoch:  592        8 Batch loss: 0.057889 Batch F1: 0.6666666666666666
Epoch:  592        9 Batch loss: 0.106974 Batch F1: 0.0
Epoch:  592       10 Batch loss: 0.045345 Batch F1: 0.7499999999999999
Epoch:  592       11 Batch loss: 0.100759 Batch F1: 0.4
Epoch:  592       12 Batch loss: 0.066462 Batch F1: 0.8571428571428571
Train Avg Loss  592: 0.075457

Train Avg F1  592: 0.6489243943191312

Val Avg Loss  592: 0.066375

Val Avg F1  592:  0.9331501831501832

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 593
--------------------------------------------------------------
Epoch:  593        1 Batch loss: 0.075278 Batch F1: 0.8750000000000001
Epoch:  593        2 Batch loss: 0.067074 Batch F1: 1.0
Epoch:  593        3 Batch loss: 0.074149 Batch F1: 0.9
Epoch:  593        4 Batch loss: 0.092732 Batch F1: 0.6363636363636364
Epoch:  593        5 Batch loss: 0.072219 Batch F1: 0.6666666666666666
Epoch:  593        6 Batch loss: 0.044941 Batch F1: 0.7499999999999999
Epoch:  593        7 Batch loss: 0.060666 Batch F1: 0.4444444444444445
Epoch:  593        8 Batch loss: 0.049624 Batch F1: 0.5
Epoch:  593        9 Batch loss: 0.089276 Batch F1: 0.0
Epoch:  593       10 Batch loss: 0.076853 Batch F1: 0.18181818181818182
Epoch:  593       11 Batch loss: 0.082735 Batch F1: 0.8
Epoch:  593       12 Batch loss: 0.089182 Batch F1: 0.8
Train Avg Loss  593: 0.072894

Train Avg F1  593: 0.6295244107744108

Val Avg Loss  593: 0.066181

Val Avg F1  593:  0.9312955465587044

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 594
--------------------------------------------------------------
Epoch:  594        1 Batch loss: 0.068943 Batch F1: 0.7499999999999999
Epoch:  594        2 Batch loss: 0.072792 Batch F1: 0.9
Epoch:  594        3 Batch loss: 0.072614 Batch F1: 0.888888888888889
Epoch:  594        4 Batch loss: 0.055881 Batch F1: 0.7692307692307693
Epoch:  594        5 Batch loss: 0.100023 Batch F1: 0.4444444444444445
Epoch:  594        6 Batch loss: 0.094759 Batch F1: 0.47058823529411764
Epoch:  594        7 Batch loss: 0.062379 Batch F1: 0.8333333333333333
Epoch:  594        8 Batch loss: 0.063439 Batch F1: 1.0
Epoch:  594        9 Batch loss: 0.069673 Batch F1: 1.0
Epoch:  594       10 Batch loss: 0.067292 Batch F1: 0.5882352941176471
Epoch:  594       11 Batch loss: 0.063127 Batch F1: 0.4
Epoch:  594       12 Batch loss: 0.062878 Batch F1: 0.7692307692307693
Train Avg Loss  594: 0.071150

Train Avg F1  594: 0.7344959778783308

Val Avg Loss  594: 0.062719

Val Avg F1  594:  0.9328648325358853

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 595
--------------------------------------------------------------
Epoch:  595        1 Batch loss: 0.057461 Batch F1: 1.0
Epoch:  595        2 Batch loss: 0.067463 Batch F1: 0.4
Epoch:  595        3 Batch loss: 0.079014 Batch F1: 0.3636363636363636
Epoch:  595        4 Batch loss: 0.060372 Batch F1: 0.7692307692307693
Epoch:  595        5 Batch loss: 0.088203 Batch F1: 0.7499999999999999
Epoch:  595        6 Batch loss: 0.067819 Batch F1: 0.9565217391304348
Epoch:  595        7 Batch loss: 0.065152 Batch F1: 1.0
Epoch:  595        8 Batch loss: 0.075606 Batch F1: 0.888888888888889
Epoch:  595        9 Batch loss: 0.063964 Batch F1: 1.0
Epoch:  595       10 Batch loss: 0.076061 Batch F1: 0.9333333333333333
Epoch:  595       11 Batch loss: 0.065011 Batch F1: 0.5
Epoch:  595       12 Batch loss: 0.061815 Batch F1: 0.2857142857142857
Train Avg Loss  595: 0.068995

Train Avg F1  595: 0.7372771149945064

Val Avg Loss  595: 0.063900

Val Avg F1  595:  0.5828234265734266

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 596
--------------------------------------------------------------
Epoch:  596        1 Batch loss: 0.061369 Batch F1: 0.7777777777777778
Epoch:  596        2 Batch loss: 0.083546 Batch F1: 0.16666666666666669
Epoch:  596        3 Batch loss: 0.051251 Batch F1: 0.9090909090909091
Epoch:  596        4 Batch loss: 0.061634 Batch F1: 0.9090909090909091
Epoch:  596        5 Batch loss: 0.074938 Batch F1: 0.9
Epoch:  596        6 Batch loss: 0.050144 Batch F1: 0.888888888888889
Epoch:  596        7 Batch loss: 0.086665 Batch F1: 0.923076923076923
Epoch:  596        8 Batch loss: 0.054392 Batch F1: 0.888888888888889
Epoch:  596        9 Batch loss: 0.059731 Batch F1: 0.8571428571428571
Epoch:  596       10 Batch loss: 0.073659 Batch F1: 1.0
Epoch:  596       11 Batch loss: 0.091501 Batch F1: 0.888888888888889
Epoch:  596       12 Batch loss: 0.075374 Batch F1: 0.7692307692307693
Train Avg Loss  596: 0.068684

Train Avg F1  596: 0.8232286232286233

Val Avg Loss  596: 0.062158

Val Avg F1  596:  0.9110576923076923

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 597
--------------------------------------------------------------
Epoch:  597        1 Batch loss: 0.079027 Batch F1: 0.962962962962963
Epoch:  597        2 Batch loss: 0.047912 Batch F1: 0.923076923076923
Epoch:  597        3 Batch loss: 0.058012 Batch F1: 0.8571428571428571
Epoch:  597        4 Batch loss: 0.046641 Batch F1: 1.0
Epoch:  597        5 Batch loss: 0.061344 Batch F1: 0.9090909090909091
Epoch:  597        6 Batch loss: 0.040336 Batch F1: 1.0
Epoch:  597        7 Batch loss: 0.083452 Batch F1: 0.4615384615384615
Epoch:  597        8 Batch loss: 0.082910 Batch F1: 0.3636363636363636
Epoch:  597        9 Batch loss: 0.108101 Batch F1: 0.4
Epoch:  597       10 Batch loss: 0.071891 Batch F1: 0.6666666666666666
Epoch:  597       11 Batch loss: 0.076000 Batch F1: 0.42857142857142855
Epoch:  597       12 Batch loss: 0.101071 Batch F1: 0.962962962962963
Train Avg Loss  597: 0.071391

Train Avg F1  597: 0.7446374613041281

Val Avg Loss  597: 0.063469

Val Avg F1  597:  0.8896464646464647

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 598
--------------------------------------------------------------
Epoch:  598        1 Batch loss: 0.081808 Batch F1: 0.9565217391304348
Epoch:  598        2 Batch loss: 0.063712 Batch F1: 0.9411764705882353
Epoch:  598        3 Batch loss: 0.086915 Batch F1: 0.9090909090909091
Epoch:  598        4 Batch loss: 0.077233 Batch F1: 0.9
Epoch:  598        5 Batch loss: 0.066988 Batch F1: 0.923076923076923
Epoch:  598        6 Batch loss: 0.070164 Batch F1: 0.8
Epoch:  598        7 Batch loss: 0.080301 Batch F1: 0.9
Epoch:  598        8 Batch loss: 0.044919 Batch F1: 0.9090909090909091
Epoch:  598        9 Batch loss: 0.048306 Batch F1: 0.9090909090909091
Epoch:  598       10 Batch loss: 0.072378 Batch F1: 1.0
Epoch:  598       11 Batch loss: 0.061034 Batch F1: 1.0
Epoch:  598       12 Batch loss: 0.078947 Batch F1: 0.4
Train Avg Loss  598: 0.069392

Train Avg F1  598: 0.8790039883390267

Val Avg Loss  598: 0.064526

Val Avg F1  598:  0.5886363636363636

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 599
--------------------------------------------------------------
Epoch:  599        1 Batch loss: 0.106573 Batch F1: 0.33333333333333337
Epoch:  599        2 Batch loss: 0.079470 Batch F1: 0.8
Epoch:  599        3 Batch loss: 0.059055 Batch F1: 0.9411764705882353
Epoch:  599        4 Batch loss: 0.054601 Batch F1: 0.923076923076923
Epoch:  599        5 Batch loss: 0.064395 Batch F1: 1.0
Epoch:  599        6 Batch loss: 0.070806 Batch F1: 0.8571428571428571
Epoch:  599        7 Batch loss: 0.080722 Batch F1: 0.33333333333333337
Epoch:  599        8 Batch loss: 0.061796 Batch F1: 0.9411764705882353
Epoch:  599        9 Batch loss: 0.065937 Batch F1: 1.0
Epoch:  599       10 Batch loss: 0.065962 Batch F1: 1.0
Epoch:  599       11 Batch loss: 0.073595 Batch F1: 0.888888888888889
Epoch:  599       12 Batch loss: 0.044343 Batch F1: 1.0
Train Avg Loss  599: 0.068938

Train Avg F1  599: 0.8348440230793172

Val Avg Loss  599: 0.062695

Val Avg F1  599:  0.9305921052631579

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 600
--------------------------------------------------------------
Epoch:  600        1 Batch loss: 0.077673 Batch F1: 0.9
Epoch:  600        2 Batch loss: 0.062394 Batch F1: 0.4
Epoch:  600        3 Batch loss: 0.030053 Batch F1: 1.0
Epoch:  600        4 Batch loss: 0.040750 Batch F1: 0.5714285714285715
Epoch:  600        5 Batch loss: 0.082574 Batch F1: 0.5333333333333333
Epoch:  600        6 Batch loss: 0.075082 Batch F1: 0.4615384615384615
Epoch:  600        7 Batch loss: 0.088618 Batch F1: 0.5263157894736842
Epoch:  600        8 Batch loss: 0.071909 Batch F1: 0.8750000000000001
Epoch:  600        9 Batch loss: 0.077850 Batch F1: 0.7692307692307693
Epoch:  600       10 Batch loss: 0.087801 Batch F1: 0.9166666666666666
Epoch:  600       11 Batch loss: 0.073305 Batch F1: 0.9411764705882353
Epoch:  600       12 Batch loss: 0.070149 Batch F1: 0.9090909090909091
Train Avg Loss  600: 0.069847

Train Avg F1  600: 0.7336484142792193

Val Avg Loss  600: 0.062831

Val Avg F1  600:  0.9138655462184874

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 601
--------------------------------------------------------------
Epoch:  601        1 Batch loss: 0.071685 Batch F1: 1.0
Epoch:  601        2 Batch loss: 0.066904 Batch F1: 0.6666666666666666
Epoch:  601        3 Batch loss: 0.087645 Batch F1: 0.923076923076923
Epoch:  601        4 Batch loss: 0.080455 Batch F1: 0.8750000000000001
Epoch:  601        5 Batch loss: 0.059360 Batch F1: 0.9411764705882353
Epoch:  601        6 Batch loss: 0.051066 Batch F1: 1.0
Epoch:  601        7 Batch loss: 0.070808 Batch F1: 0.9523809523809523
Epoch:  601        8 Batch loss: 0.065041 Batch F1: 0.9411764705882353
Epoch:  601        9 Batch loss: 0.068584 Batch F1: 0.4
Epoch:  601       10 Batch loss: 0.059173 Batch F1: 0.25
Epoch:  601       11 Batch loss: 0.081656 Batch F1: 0.3076923076923077
Epoch:  601       12 Batch loss: 0.077530 Batch F1: 0.9411764705882353
Train Avg Loss  601: 0.069992

Train Avg F1  601: 0.7665288551317965

Val Avg Loss  601: 0.062621

Val Avg F1  601:  0.9246336996336997

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 602
--------------------------------------------------------------
Epoch:  602        1 Batch loss: 0.047951 Batch F1: 0.888888888888889
Epoch:  602        2 Batch loss: 0.071108 Batch F1: 0.8
Epoch:  602        3 Batch loss: 0.068409 Batch F1: 0.9473684210526316
Epoch:  602        4 Batch loss: 0.053561 Batch F1: 1.0
Epoch:  602        5 Batch loss: 0.067777 Batch F1: 1.0
Epoch:  602        6 Batch loss: 0.096680 Batch F1: 0.8695652173913044
Epoch:  602        7 Batch loss: 0.059472 Batch F1: 0.923076923076923
Epoch:  602        8 Batch loss: 0.066549 Batch F1: 0.9473684210526316
Epoch:  602        9 Batch loss: 0.067474 Batch F1: 0.923076923076923
Epoch:  602       10 Batch loss: 0.078372 Batch F1: 0.8750000000000001
Epoch:  602       11 Batch loss: 0.068511 Batch F1: 0.9523809523809523
Epoch:  602       12 Batch loss: 0.078090 Batch F1: 0.8750000000000001
Train Avg Loss  602: 0.068663

Train Avg F1  602: 0.9168104789100213

Val Avg Loss  602: 0.061837

Val Avg F1  602:  0.9219587176108917

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 603
--------------------------------------------------------------
Epoch:  603        1 Batch loss: 0.076951 Batch F1: 1.0
Epoch:  603        2 Batch loss: 0.060486 Batch F1: 0.8
Epoch:  603        3 Batch loss: 0.056684 Batch F1: 0.2857142857142857
Epoch:  603        4 Batch loss: 0.054013 Batch F1: 0.5
Epoch:  603        5 Batch loss: 0.077501 Batch F1: 0.625
Epoch:  603        6 Batch loss: 0.070019 Batch F1: 0.6666666666666666
Epoch:  603        7 Batch loss: 0.075710 Batch F1: 0.33333333333333337
Epoch:  603        8 Batch loss: 0.072412 Batch F1: 0.9565217391304348
Epoch:  603        9 Batch loss: 0.063723 Batch F1: 0.923076923076923
Epoch:  603       10 Batch loss: 0.073852 Batch F1: 0.8
Epoch:  603       11 Batch loss: 0.065598 Batch F1: 0.9473684210526316
Epoch:  603       12 Batch loss: 0.070010 Batch F1: 1.0
Train Avg Loss  603: 0.068080

Train Avg F1  603: 0.7364734474145229

Val Avg Loss  603: 0.061780

Val Avg F1  603:  0.9115079365079365

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 604
--------------------------------------------------------------
Epoch:  604        1 Batch loss: 0.061818 Batch F1: 0.9333333333333333
Epoch:  604        2 Batch loss: 0.073699 Batch F1: 0.9523809523809523
Epoch:  604        3 Batch loss: 0.070670 Batch F1: 1.0
Epoch:  604        4 Batch loss: 0.062972 Batch F1: 0.8571428571428571
Epoch:  604        5 Batch loss: 0.058940 Batch F1: 0.8
Epoch:  604        6 Batch loss: 0.074310 Batch F1: 0.5333333333333333
Epoch:  604        7 Batch loss: 0.078279 Batch F1: 0.4615384615384615
Epoch:  604        8 Batch loss: 0.062941 Batch F1: 0.4
Epoch:  604        9 Batch loss: 0.044446 Batch F1: 0.0
Epoch:  604       10 Batch loss: 0.085734 Batch F1: 0.375
Epoch:  604       11 Batch loss: 0.073640 Batch F1: 0.625
Epoch:  604       12 Batch loss: 0.069827 Batch F1: 0.9411764705882353
Train Avg Loss  604: 0.068106

Train Avg F1  604: 0.6565754506930978

Val Avg Loss  604: 0.061387

Val Avg F1  604:  0.9305555555555555

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 605
--------------------------------------------------------------
Epoch:  605        1 Batch loss: 0.072193 Batch F1: 1.0
Epoch:  605        2 Batch loss: 0.058980 Batch F1: 0.9473684210526316
Epoch:  605        3 Batch loss: 0.080788 Batch F1: 0.8
Epoch:  605        4 Batch loss: 0.071563 Batch F1: 0.9411764705882353
Epoch:  605        5 Batch loss: 0.049863 Batch F1: 1.0
Epoch:  605        6 Batch loss: 0.066928 Batch F1: 0.8
Epoch:  605        7 Batch loss: 0.085268 Batch F1: 0.7499999999999999
Epoch:  605        8 Batch loss: 0.075103 Batch F1: 0.8571428571428571
Epoch:  605        9 Batch loss: 0.080446 Batch F1: 1.0
Epoch:  605       10 Batch loss: 0.060434 Batch F1: 1.0
Epoch:  605       11 Batch loss: 0.060764 Batch F1: 0.9090909090909091
Epoch:  605       12 Batch loss: 0.075911 Batch F1: 0.9333333333333333
Train Avg Loss  605: 0.069854

Train Avg F1  605: 0.9115093326006639

Val Avg Loss  605: 0.063900

Val Avg F1  605:  0.5568181818181818

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 606
--------------------------------------------------------------
Epoch:  606        1 Batch loss: 0.070088 Batch F1: 0.5454545454545454
Epoch:  606        2 Batch loss: 0.061429 Batch F1: 0.6153846153846153
Epoch:  606        3 Batch loss: 0.067518 Batch F1: 0.4
Epoch:  606        4 Batch loss: 0.080487 Batch F1: 0.16666666666666669
Epoch:  606        5 Batch loss: 0.083272 Batch F1: 0.5333333333333333
Epoch:  606        6 Batch loss: 0.054733 Batch F1: 0.9333333333333333
Epoch:  606        7 Batch loss: 0.080559 Batch F1: 0.9565217391304348
Epoch:  606        8 Batch loss: 0.075351 Batch F1: 0.9473684210526316
Epoch:  606        9 Batch loss: 0.062054 Batch F1: 0.8750000000000001
Epoch:  606       10 Batch loss: 0.062543 Batch F1: 1.0
Epoch:  606       11 Batch loss: 0.070792 Batch F1: 0.8750000000000001
Epoch:  606       12 Batch loss: 0.058158 Batch F1: 1.0
Train Avg Loss  606: 0.068915

Train Avg F1  606: 0.73733855452963

Val Avg Loss  606: 0.062110

Val Avg F1  606:  0.9272727272727272

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 607
--------------------------------------------------------------
Epoch:  607        1 Batch loss: 0.075920 Batch F1: 0.9523809523809523
Epoch:  607        2 Batch loss: 0.070257 Batch F1: 0.888888888888889
Epoch:  607        3 Batch loss: 0.066778 Batch F1: 0.9411764705882353
Epoch:  607        4 Batch loss: 0.074774 Batch F1: 0.8
Epoch:  607        5 Batch loss: 0.061299 Batch F1: 0.9411764705882353
Epoch:  607        6 Batch loss: 0.057545 Batch F1: 0.6666666666666666
Epoch:  607        7 Batch loss: 0.084876 Batch F1: 0.18181818181818182
Epoch:  607        8 Batch loss: 0.059456 Batch F1: 0.5454545454545454
Epoch:  607        9 Batch loss: 0.061979 Batch F1: 0.6153846153846153
Epoch:  607       10 Batch loss: 0.076278 Batch F1: 0.5333333333333333
Epoch:  607       11 Batch loss: 0.045923 Batch F1: 0.5714285714285715
Epoch:  607       12 Batch loss: 0.086861 Batch F1: 0.631578947368421
Train Avg Loss  607: 0.068495

Train Avg F1  607: 0.6891073036583872

Val Avg Loss  607: 0.062221

Val Avg F1  607:  0.9102941176470588

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 608
--------------------------------------------------------------
Epoch:  608        1 Batch loss: 0.046372 Batch F1: 1.0
Epoch:  608        2 Batch loss: 0.082105 Batch F1: 0.9600000000000001
Epoch:  608        3 Batch loss: 0.057267 Batch F1: 0.8333333333333333
Epoch:  608        4 Batch loss: 0.070472 Batch F1: 0.888888888888889
Epoch:  608        5 Batch loss: 0.067544 Batch F1: 0.9
Epoch:  608        6 Batch loss: 0.078341 Batch F1: 0.9523809523809523
Epoch:  608        7 Batch loss: 0.065365 Batch F1: 0.9411764705882353
Epoch:  608        8 Batch loss: 0.066005 Batch F1: 0.5714285714285715
Epoch:  608        9 Batch loss: 0.068584 Batch F1: 1.0
Epoch:  608       10 Batch loss: 0.064497 Batch F1: 0.9333333333333333
Epoch:  608       11 Batch loss: 0.064485 Batch F1: 0.625
Epoch:  608       12 Batch loss: 0.097058 Batch F1: 0.42857142857142855
Train Avg Loss  608: 0.069008

Train Avg F1  608: 0.8361760815437287

Val Avg Loss  608: 0.061500

Val Avg F1  608:  0.9125874125874125

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 609
--------------------------------------------------------------
Epoch:  609        1 Batch loss: 0.075988 Batch F1: 0.8
Epoch:  609        2 Batch loss: 0.060705 Batch F1: 0.9333333333333333
Epoch:  609        3 Batch loss: 0.071548 Batch F1: 0.9411764705882353
Epoch:  609        4 Batch loss: 0.080917 Batch F1: 0.9090909090909091
Epoch:  609        5 Batch loss: 0.066360 Batch F1: 1.0
Epoch:  609        6 Batch loss: 0.050818 Batch F1: 1.0
Epoch:  609        7 Batch loss: 0.059814 Batch F1: 0.9090909090909091
Epoch:  609        8 Batch loss: 0.068981 Batch F1: 0.8333333333333333
Epoch:  609        9 Batch loss: 0.065834 Batch F1: 0.9473684210526316
Epoch:  609       10 Batch loss: 0.082331 Batch F1: 0.8571428571428571
Epoch:  609       11 Batch loss: 0.068236 Batch F1: 1.0
Epoch:  609       12 Batch loss: 0.077292 Batch F1: 0.8750000000000001
Train Avg Loss  609: 0.069069

Train Avg F1  609: 0.9171280194693509

Val Avg Loss  609: 0.063327

Val Avg F1  609:  0.9329131652661065

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 610
--------------------------------------------------------------
Epoch:  610        1 Batch loss: 0.072960 Batch F1: 0.888888888888889
Epoch:  610        2 Batch loss: 0.081403 Batch F1: 0.9090909090909091
Epoch:  610        3 Batch loss: 0.064061 Batch F1: 0.9090909090909091
Epoch:  610        4 Batch loss: 0.060732 Batch F1: 0.9333333333333333
Epoch:  610        5 Batch loss: 0.059542 Batch F1: 0.5
Epoch:  610        6 Batch loss: 0.087062 Batch F1: 0.42857142857142855
Epoch:  610        7 Batch loss: 0.064577 Batch F1: 0.4
Epoch:  610        8 Batch loss: 0.078113 Batch F1: 0.2222222222222222
Epoch:  610        9 Batch loss: 0.084057 Batch F1: 0.9333333333333333
Epoch:  610       10 Batch loss: 0.065140 Batch F1: 1.0
Epoch:  610       11 Batch loss: 0.068651 Batch F1: 0.9473684210526316
Epoch:  610       12 Batch loss: 0.054630 Batch F1: 0.888888888888889
Train Avg Loss  610: 0.070078

Train Avg F1  610: 0.7467323612060456

Val Avg Loss  610: 0.061861

Val Avg F1  610:  0.9047619047619048

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 611
--------------------------------------------------------------
Epoch:  611        1 Batch loss: 0.087054 Batch F1: 0.8181818181818181
Epoch:  611        2 Batch loss: 0.035141 Batch F1: 1.0
Epoch:  611        3 Batch loss: 0.068176 Batch F1: 0.9473684210526316
Epoch:  611        4 Batch loss: 0.059530 Batch F1: 1.0
Epoch:  611        5 Batch loss: 0.084474 Batch F1: 0.5555555555555556
Epoch:  611        6 Batch loss: 0.076608 Batch F1: 0.8
Epoch:  611        7 Batch loss: 0.086917 Batch F1: 0.7058823529411764
Epoch:  611        8 Batch loss: 0.064988 Batch F1: 1.0
Epoch:  611        9 Batch loss: 0.043584 Batch F1: 0.6666666666666666
Epoch:  611       10 Batch loss: 0.070707 Batch F1: 0.5
Epoch:  611       11 Batch loss: 0.113094 Batch F1: 0.0
Epoch:  611       12 Batch loss: 0.067489 Batch F1: 0.6666666666666666
Train Avg Loss  611: 0.071480

Train Avg F1  611: 0.7216934567553763

Val Avg Loss  611: 0.061905

Val Avg F1  611:  0.7264423076923077

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 612
--------------------------------------------------------------
Epoch:  612        1 Batch loss: 0.072167 Batch F1: 0.6666666666666666
Epoch:  612        2 Batch loss: 0.087541 Batch F1: 0.8
Epoch:  612        3 Batch loss: 0.080634 Batch F1: 0.888888888888889
Epoch:  612        4 Batch loss: 0.069166 Batch F1: 1.0
Epoch:  612        5 Batch loss: 0.058478 Batch F1: 0.7499999999999999
Epoch:  612        6 Batch loss: 0.047610 Batch F1: 0.0
Epoch:  612        7 Batch loss: 0.064263 Batch F1: 0.0
Epoch:  612        8 Batch loss: 0.065939 Batch F1: 0.6153846153846153
Epoch:  612        9 Batch loss: 0.074127 Batch F1: 0.4
Epoch:  612       10 Batch loss: 0.084824 Batch F1: 0.8421052631578948
Epoch:  612       11 Batch loss: 0.080349 Batch F1: 0.88
Epoch:  612       12 Batch loss: 0.108036 Batch F1: 0.8571428571428571
Train Avg Loss  612: 0.074428

Train Avg F1  612: 0.6416823576034102

Val Avg Loss  612: 0.063351

Val Avg F1  612:  0.586679292929293

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 613
--------------------------------------------------------------
Epoch:  613        1 Batch loss: 0.081278 Batch F1: 0.5555555555555556
Epoch:  613        2 Batch loss: 0.062296 Batch F1: 0.0
Epoch:  613        3 Batch loss: 0.100156 Batch F1: 0.0
Epoch:  613        4 Batch loss: 0.056861 Batch F1: 0.4
Epoch:  613        5 Batch loss: 0.053098 Batch F1: 0.923076923076923
Epoch:  613        6 Batch loss: 0.061305 Batch F1: 0.8571428571428571
Epoch:  613        7 Batch loss: 0.058802 Batch F1: 0.6666666666666666
Epoch:  613        8 Batch loss: 0.065699 Batch F1: 0.2857142857142857
Epoch:  613        9 Batch loss: 0.106502 Batch F1: 0.0
Epoch:  613       10 Batch loss: 0.084311 Batch F1: 0.625
Epoch:  613       11 Batch loss: 0.093375 Batch F1: 0.761904761904762
Epoch:  613       12 Batch loss: 0.087995 Batch F1: 0.9
Train Avg Loss  613: 0.075973

Train Avg F1  613: 0.49792175417175416

Val Avg Loss  613: 0.067223

Val Avg F1  613:  0.9292717086834734

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 614
--------------------------------------------------------------
Epoch:  614        1 Batch loss: 0.067090 Batch F1: 0.8
Epoch:  614        2 Batch loss: 0.095319 Batch F1: 0.0
Epoch:  614        3 Batch loss: 0.073359 Batch F1: 0.7499999999999999
Epoch:  614        4 Batch loss: 0.079521 Batch F1: 0.9600000000000001
Epoch:  614        5 Batch loss: 0.062066 Batch F1: 1.0
Epoch:  614        6 Batch loss: 0.084342 Batch F1: 0.42857142857142855
Epoch:  614        7 Batch loss: 0.088899 Batch F1: 0.5714285714285715
Epoch:  614        8 Batch loss: 0.059032 Batch F1: 0.33333333333333337
Epoch:  614        9 Batch loss: 0.071841 Batch F1: 0.8
Epoch:  614       10 Batch loss: 0.080002 Batch F1: 0.5333333333333333
Epoch:  614       11 Batch loss: 0.075178 Batch F1: 0.7499999999999999
Epoch:  614       12 Batch loss: 0.071114 Batch F1: 1.0
Train Avg Loss  614: 0.075647

Train Avg F1  614: 0.6605555555555555

Val Avg Loss  614: 0.064201

Val Avg F1  614:  0.9292763157894737

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 615
--------------------------------------------------------------
Epoch:  615        1 Batch loss: 0.060494 Batch F1: 0.888888888888889
Epoch:  615        2 Batch loss: 0.081917 Batch F1: 0.8750000000000001
Epoch:  615        3 Batch loss: 0.083730 Batch F1: 0.3636363636363636
Epoch:  615        4 Batch loss: 0.077668 Batch F1: 0.5
Epoch:  615        5 Batch loss: 0.058566 Batch F1: 0.6153846153846153
Epoch:  615        6 Batch loss: 0.051393 Batch F1: 1.0
Epoch:  615        7 Batch loss: 0.068167 Batch F1: 0.9333333333333333
Epoch:  615        8 Batch loss: 0.086186 Batch F1: 0.9090909090909091
Epoch:  615        9 Batch loss: 0.072018 Batch F1: 0.9565217391304348
Epoch:  615       10 Batch loss: 0.066928 Batch F1: 1.0
Epoch:  615       11 Batch loss: 0.071671 Batch F1: 1.0
Epoch:  615       12 Batch loss: 0.054723 Batch F1: 0.7499999999999999
Train Avg Loss  615: 0.069455

Train Avg F1  615: 0.8159879874553787

Val Avg Loss  615: 0.062813

Val Avg F1  615:  0.9307692307692308

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 616
--------------------------------------------------------------
Epoch:  616        1 Batch loss: 0.061170 Batch F1: 1.0
Epoch:  616        2 Batch loss: 0.084099 Batch F1: 0.9166666666666666
Epoch:  616        3 Batch loss: 0.062139 Batch F1: 1.0
Epoch:  616        4 Batch loss: 0.054272 Batch F1: 0.888888888888889
Epoch:  616        5 Batch loss: 0.058799 Batch F1: 1.0
Epoch:  616        6 Batch loss: 0.064255 Batch F1: 0.9523809523809523
Epoch:  616        7 Batch loss: 0.070768 Batch F1: 0.7272727272727273
Epoch:  616        8 Batch loss: 0.074252 Batch F1: 0.8571428571428571
Epoch:  616        9 Batch loss: 0.105460 Batch F1: 0.8181818181818181
Epoch:  616       10 Batch loss: 0.086025 Batch F1: 0.8
Epoch:  616       11 Batch loss: 0.065624 Batch F1: 1.0
Epoch:  616       12 Batch loss: 0.049540 Batch F1: 1.0
Train Avg Loss  616: 0.069700

Train Avg F1  616: 0.9133778258778259

Val Avg Loss  616: 0.061857

Val Avg F1  616:  0.9344444444444445

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 617
--------------------------------------------------------------
Epoch:  617        1 Batch loss: 0.056022 Batch F1: 0.923076923076923
Epoch:  617        2 Batch loss: 0.058139 Batch F1: 0.8
Epoch:  617        3 Batch loss: 0.073448 Batch F1: 0.9523809523809523
Epoch:  617        4 Batch loss: 0.077222 Batch F1: 0.6666666666666666
Epoch:  617        5 Batch loss: 0.073936 Batch F1: 0.7058823529411764
Epoch:  617        6 Batch loss: 0.056725 Batch F1: 1.0
Epoch:  617        7 Batch loss: 0.068407 Batch F1: 0.9
Epoch:  617        8 Batch loss: 0.062117 Batch F1: 0.7272727272727273
Epoch:  617        9 Batch loss: 0.081125 Batch F1: 0.8571428571428571
Epoch:  617       10 Batch loss: 0.073611 Batch F1: 0.9411764705882353
Epoch:  617       11 Batch loss: 0.063222 Batch F1: 0.9090909090909091
Epoch:  617       12 Batch loss: 0.075851 Batch F1: 1.0
Train Avg Loss  617: 0.068319

Train Avg F1  617: 0.8652241549300372

Val Avg Loss  617: 0.062652

Val Avg F1  617:  0.7021929824561403

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 618
--------------------------------------------------------------
Epoch:  618        1 Batch loss: 0.061733 Batch F1: 0.7272727272727273
Epoch:  618        2 Batch loss: 0.093031 Batch F1: 0.16666666666666669
Epoch:  618        3 Batch loss: 0.063473 Batch F1: 0.6666666666666666
Epoch:  618        4 Batch loss: 0.070078 Batch F1: 0.6153846153846153
Epoch:  618        5 Batch loss: 0.060645 Batch F1: 1.0
Epoch:  618        6 Batch loss: 0.056095 Batch F1: 0.9333333333333333
Epoch:  618        7 Batch loss: 0.071890 Batch F1: 0.7692307692307693
Epoch:  618        8 Batch loss: 0.073207 Batch F1: 0.9
Epoch:  618        9 Batch loss: 0.060087 Batch F1: 0.888888888888889
Epoch:  618       10 Batch loss: 0.064349 Batch F1: 0.888888888888889
Epoch:  618       11 Batch loss: 0.077682 Batch F1: 1.0
Epoch:  618       12 Batch loss: 0.065826 Batch F1: 0.9411764705882353
Train Avg Loss  618: 0.068175

Train Avg F1  618: 0.7914590855767326

Val Avg Loss  618: 0.061524

Val Avg F1  618:  0.9244949494949495

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 619
--------------------------------------------------------------
Epoch:  619        1 Batch loss: 0.072499 Batch F1: 0.8750000000000001
Epoch:  619        2 Batch loss: 0.079785 Batch F1: 0.7777777777777778
Epoch:  619        3 Batch loss: 0.065028 Batch F1: 0.9411764705882353
Epoch:  619        4 Batch loss: 0.060210 Batch F1: 1.0
Epoch:  619        5 Batch loss: 0.082652 Batch F1: 0.9
Epoch:  619        6 Batch loss: 0.050652 Batch F1: 0.9090909090909091
Epoch:  619        7 Batch loss: 0.078028 Batch F1: 0.9166666666666666
Epoch:  619        8 Batch loss: 0.064062 Batch F1: 0.9333333333333333
Epoch:  619        9 Batch loss: 0.070446 Batch F1: 0.9565217391304348
Epoch:  619       10 Batch loss: 0.058479 Batch F1: 1.0
Epoch:  619       11 Batch loss: 0.054713 Batch F1: 0.923076923076923
Epoch:  619       12 Batch loss: 0.072516 Batch F1: 0.9333333333333333
Train Avg Loss  619: 0.067423

Train Avg F1  619: 0.9221647627498012

Val Avg Loss  619: 0.061495

Val Avg F1  619:  0.5900162337662338

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 620
--------------------------------------------------------------
Epoch:  620        1 Batch loss: 0.061523 Batch F1: 0.6666666666666666
Epoch:  620        2 Batch loss: 0.075234 Batch F1: 0.3076923076923077
Epoch:  620        3 Batch loss: 0.076465 Batch F1: 0.625
Epoch:  620        4 Batch loss: 0.062465 Batch F1: 0.5714285714285715
Epoch:  620        5 Batch loss: 0.082714 Batch F1: 0.8
Epoch:  620        6 Batch loss: 0.077350 Batch F1: 1.0
Epoch:  620        7 Batch loss: 0.065877 Batch F1: 0.8
Epoch:  620        8 Batch loss: 0.065897 Batch F1: 0.8750000000000001
Epoch:  620        9 Batch loss: 0.066027 Batch F1: 0.5714285714285715
Epoch:  620       10 Batch loss: 0.059178 Batch F1: 0.923076923076923
Epoch:  620       11 Batch loss: 0.075999 Batch F1: 0.962962962962963
Epoch:  620       12 Batch loss: 0.048597 Batch F1: 1.0
Train Avg Loss  620: 0.068110

Train Avg F1  620: 0.7586046669380003

Val Avg Loss  620: 0.061305

Val Avg F1  620:  0.9125668449197861

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 621
--------------------------------------------------------------
Epoch:  621        1 Batch loss: 0.068764 Batch F1: 0.9523809523809523
Epoch:  621        2 Batch loss: 0.052440 Batch F1: 1.0
Epoch:  621        3 Batch loss: 0.066520 Batch F1: 0.8333333333333333
Epoch:  621        4 Batch loss: 0.064755 Batch F1: 0.4
Epoch:  621        5 Batch loss: 0.107024 Batch F1: 0.25
Epoch:  621        6 Batch loss: 0.065888 Batch F1: 0.4615384615384615
Epoch:  621        7 Batch loss: 0.076601 Batch F1: 0.9
Epoch:  621        8 Batch loss: 0.053866 Batch F1: 1.0
Epoch:  621        9 Batch loss: 0.066803 Batch F1: 0.9523809523809523
Epoch:  621       10 Batch loss: 0.085235 Batch F1: 0.923076923076923
Epoch:  621       11 Batch loss: 0.057934 Batch F1: 0.8333333333333333
Epoch:  621       12 Batch loss: 0.051801 Batch F1: 1.0
Train Avg Loss  621: 0.068136

Train Avg F1  621: 0.7921703296703297

Val Avg Loss  621: 0.061275

Val Avg F1  621:  0.9173116615067081

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 622
--------------------------------------------------------------
Epoch:  622        1 Batch loss: 0.089600 Batch F1: 0.8695652173913044
Epoch:  622        2 Batch loss: 0.072981 Batch F1: 0.8
Epoch:  622        3 Batch loss: 0.065872 Batch F1: 0.8571428571428571
Epoch:  622        4 Batch loss: 0.072404 Batch F1: 0.9473684210526316
Epoch:  622        5 Batch loss: 0.068600 Batch F1: 0.9411764705882353
Epoch:  622        6 Batch loss: 0.064025 Batch F1: 0.9523809523809523
Epoch:  622        7 Batch loss: 0.075465 Batch F1: 0.19999999999999998
Epoch:  622        8 Batch loss: 0.071684 Batch F1: 0.5
Epoch:  622        9 Batch loss: 0.062045 Batch F1: 0.9523809523809523
Epoch:  622       10 Batch loss: 0.051263 Batch F1: 1.0
Epoch:  622       11 Batch loss: 0.067741 Batch F1: 0.9411764705882353
Epoch:  622       12 Batch loss: 0.037571 Batch F1: 1.0
Train Avg Loss  622: 0.066604

Train Avg F1  622: 0.8300992784604307

Val Avg Loss  622: 0.061219

Val Avg F1  622:  0.7271398192450824

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 623
--------------------------------------------------------------
Epoch:  623        1 Batch loss: 0.066283 Batch F1: 0.4
Epoch:  623        2 Batch loss: 0.086773 Batch F1: 0.3076923076923077
Epoch:  623        3 Batch loss: 0.081899 Batch F1: 0.5555555555555556
Epoch:  623        4 Batch loss: 0.076845 Batch F1: 0.9655172413793104
Epoch:  623        5 Batch loss: 0.068599 Batch F1: 0.9473684210526316
Epoch:  623        6 Batch loss: 0.052151 Batch F1: 0.888888888888889
Epoch:  623        7 Batch loss: 0.066240 Batch F1: 0.9565217391304348
Epoch:  623        8 Batch loss: 0.077750 Batch F1: 0.9333333333333333
Epoch:  623        9 Batch loss: 0.050851 Batch F1: 0.888888888888889
Epoch:  623       10 Batch loss: 0.071627 Batch F1: 0.8571428571428571
Epoch:  623       11 Batch loss: 0.060510 Batch F1: 0.8333333333333333
Epoch:  623       12 Batch loss: 0.056240 Batch F1: 0.8
Train Avg Loss  623: 0.067981

Train Avg F1  623: 0.7778535471997953

Val Avg Loss  623: 0.062925

Val Avg F1  623:  0.6058000822706705

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 624
--------------------------------------------------------------
Epoch:  624        1 Batch loss: 0.027031 Batch F1: 1.0
Epoch:  624        2 Batch loss: 0.030118 Batch F1: 0.8
Epoch:  624        3 Batch loss: 0.080758 Batch F1: 0.5454545454545454
Epoch:  624        4 Batch loss: 0.098822 Batch F1: 0.3636363636363636
Epoch:  624        5 Batch loss: 0.116978 Batch F1: 0.5714285714285715
Epoch:  624        6 Batch loss: 0.092914 Batch F1: 0.42857142857142855
Epoch:  624        7 Batch loss: 0.085094 Batch F1: 0.5882352941176471
Epoch:  624        8 Batch loss: 0.077043 Batch F1: 0.9523809523809523
Epoch:  624        9 Batch loss: 0.077680 Batch F1: 0.9090909090909091
Epoch:  624       10 Batch loss: 0.075061 Batch F1: 0.9
Epoch:  624       11 Batch loss: 0.094775 Batch F1: 0.6363636363636364
Epoch:  624       12 Batch loss: 0.067958 Batch F1: 1.0
Train Avg Loss  624: 0.077019

Train Avg F1  624: 0.7245968084203379

Val Avg Loss  624: 0.065529

Val Avg F1  624:  0.8939393939393939

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 625
--------------------------------------------------------------
Epoch:  625        1 Batch loss: 0.065022 Batch F1: 0.923076923076923
Epoch:  625        2 Batch loss: 0.060667 Batch F1: 0.8
Epoch:  625        3 Batch loss: 0.057692 Batch F1: 0.9090909090909091
Epoch:  625        4 Batch loss: 0.112850 Batch F1: 0.47058823529411764
Epoch:  625        5 Batch loss: 0.057055 Batch F1: 0.8
Epoch:  625        6 Batch loss: 0.076366 Batch F1: 0.5333333333333333
Epoch:  625        7 Batch loss: 0.096180 Batch F1: 0.3333333333333333
Epoch:  625        8 Batch loss: 0.083856 Batch F1: 0.8
Epoch:  625        9 Batch loss: 0.098483 Batch F1: 0.761904761904762
Epoch:  625       10 Batch loss: 0.077053 Batch F1: 0.5
Epoch:  625       11 Batch loss: 0.082602 Batch F1: 0.9166666666666666
Epoch:  625       12 Batch loss: 0.069120 Batch F1: 1.0
Train Avg Loss  625: 0.078079

Train Avg F1  625: 0.7289995135583371

Val Avg Loss  625: 0.143805

Val Avg F1  625:  0.0

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 626
--------------------------------------------------------------
Epoch:  626        1 Batch loss: 0.107857 Batch F1: 0.0
Epoch:  626        2 Batch loss: 0.113811 Batch F1: 0.0
Epoch:  626        3 Batch loss: 0.115181 Batch F1: 0.18181818181818182
Epoch:  626        4 Batch loss: 0.120163 Batch F1: 0.5
Epoch:  626        5 Batch loss: 0.107349 Batch F1: 0.6666666666666666
Epoch:  626        6 Batch loss: 0.081962 Batch F1: 0.4
Epoch:  626        7 Batch loss: 0.047039 Batch F1: 0.888888888888889
Epoch:  626        8 Batch loss: 0.076873 Batch F1: 0.4
Epoch:  626        9 Batch loss: 0.084708 Batch F1: 0.5882352941176471
Epoch:  626       10 Batch loss: 0.076561 Batch F1: 0.5714285714285715
Epoch:  626       11 Batch loss: 0.077642 Batch F1: 0.5714285714285715
Epoch:  626       12 Batch loss: 0.066347 Batch F1: 0.6666666666666666
Train Avg Loss  626: 0.089624

Train Avg F1  626: 0.45292773675126613

Val Avg Loss  626: 0.065496

Val Avg F1  626:  0.5790106951871657

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 627
--------------------------------------------------------------
Epoch:  627        1 Batch loss: 0.071865 Batch F1: 0.6
Epoch:  627        2 Batch loss: 0.068991 Batch F1: 0.3636363636363636
Epoch:  627        3 Batch loss: 0.087815 Batch F1: 0.5
Epoch:  627        4 Batch loss: 0.074718 Batch F1: 0.5
Epoch:  627        5 Batch loss: 0.062711 Batch F1: 1.0
Epoch:  627        6 Batch loss: 0.075933 Batch F1: 0.7499999999999999
Epoch:  627        7 Batch loss: 0.085858 Batch F1: 0.8
Epoch:  627        8 Batch loss: 0.072755 Batch F1: 0.7058823529411764
Epoch:  627        9 Batch loss: 0.056667 Batch F1: 0.6666666666666666
Epoch:  627       10 Batch loss: 0.064273 Batch F1: 0.6666666666666666
Epoch:  627       11 Batch loss: 0.093217 Batch F1: 0.4
Epoch:  627       12 Batch loss: 0.065846 Batch F1: 0.7272727272727273
Train Avg Loss  627: 0.073387

Train Avg F1  627: 0.6400103980986335

Val Avg Loss  627: 0.065466

Val Avg F1  627:  0.7373928316265778

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 628
--------------------------------------------------------------
Epoch:  628        1 Batch loss: 0.094386 Batch F1: 0.33333333333333337
Epoch:  628        2 Batch loss: 0.071257 Batch F1: 0.7058823529411764
Epoch:  628        3 Batch loss: 0.060891 Batch F1: 0.8
Epoch:  628        4 Batch loss: 0.064063 Batch F1: 0.9523809523809523
Epoch:  628        5 Batch loss: 0.080902 Batch F1: 0.9
Epoch:  628        6 Batch loss: 0.080754 Batch F1: 0.9473684210526316
Epoch:  628        7 Batch loss: 0.072677 Batch F1: 1.0
Epoch:  628        8 Batch loss: 0.071820 Batch F1: 0.888888888888889
Epoch:  628        9 Batch loss: 0.069527 Batch F1: 1.0
Epoch:  628       10 Batch loss: 0.056859 Batch F1: 1.0
Epoch:  628       11 Batch loss: 0.065539 Batch F1: 0.6666666666666666
Epoch:  628       12 Batch loss: 0.068363 Batch F1: 0.3636363636363636
Train Avg Loss  628: 0.071420

Train Avg F1  628: 0.796513081575001

Val Avg Loss  628: 0.065347

Val Avg F1  628:  0.5913419913419913

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 629
--------------------------------------------------------------
Epoch:  629        1 Batch loss: 0.073906 Batch F1: 0.33333333333333337
Epoch:  629        2 Batch loss: 0.073485 Batch F1: 0.4615384615384615
Epoch:  629        3 Batch loss: 0.044156 Batch F1: 0.6666666666666666
Epoch:  629        4 Batch loss: 0.072737 Batch F1: 0.19999999999999998
Epoch:  629        5 Batch loss: 0.063460 Batch F1: 0.5454545454545454
Epoch:  629        6 Batch loss: 0.072371 Batch F1: 0.6666666666666666
Epoch:  629        7 Batch loss: 0.073700 Batch F1: 0.5
Epoch:  629        8 Batch loss: 0.087429 Batch F1: 0.5
Epoch:  629        9 Batch loss: 0.070345 Batch F1: 0.9565217391304348
Epoch:  629       10 Batch loss: 0.073271 Batch F1: 0.9523809523809523
Epoch:  629       11 Batch loss: 0.065109 Batch F1: 0.9333333333333333
Epoch:  629       12 Batch loss: 0.077312 Batch F1: 0.8333333333333333
Train Avg Loss  629: 0.070607

Train Avg F1  629: 0.6291024193198106

Val Avg Loss  629: 0.064880

Val Avg F1  629:  0.9299581492676121

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 630
--------------------------------------------------------------
Epoch:  630        1 Batch loss: 0.073874 Batch F1: 0.9565217391304348
Epoch:  630        2 Batch loss: 0.076386 Batch F1: 0.8750000000000001
Epoch:  630        3 Batch loss: 0.057291 Batch F1: 0.7499999999999999
Epoch:  630        4 Batch loss: 0.079936 Batch F1: 0.18181818181818182
Epoch:  630        5 Batch loss: 0.056702 Batch F1: 0.0
Epoch:  630        6 Batch loss: 0.059902 Batch F1: 0.6
Epoch:  630        7 Batch loss: 0.088296 Batch F1: 0.6666666666666666
Epoch:  630        8 Batch loss: 0.057514 Batch F1: 0.923076923076923
Epoch:  630        9 Batch loss: 0.088207 Batch F1: 0.962962962962963
Epoch:  630       10 Batch loss: 0.066195 Batch F1: 1.0
Epoch:  630       11 Batch loss: 0.075568 Batch F1: 0.7499999999999999
Epoch:  630       12 Batch loss: 0.070409 Batch F1: 1.0
Train Avg Loss  630: 0.070857

Train Avg F1  630: 0.7221705394712642

Val Avg Loss  630: 0.063738

Val Avg F1  630:  0.9186274509803922

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 631
--------------------------------------------------------------
Epoch:  631        1 Batch loss: 0.074950 Batch F1: 0.9565217391304348
Epoch:  631        2 Batch loss: 0.066857 Batch F1: 0.9333333333333333
Epoch:  631        3 Batch loss: 0.066839 Batch F1: 0.9411764705882353
Epoch:  631        4 Batch loss: 0.047566 Batch F1: 0.8
Epoch:  631        5 Batch loss: 0.083218 Batch F1: 0.5
Epoch:  631        6 Batch loss: 0.072009 Batch F1: 0.6666666666666666
Epoch:  631        7 Batch loss: 0.077351 Batch F1: 0.9090909090909091
Epoch:  631        8 Batch loss: 0.070128 Batch F1: 1.0
Epoch:  631        9 Batch loss: 0.091409 Batch F1: 0.8695652173913044
Epoch:  631       10 Batch loss: 0.064605 Batch F1: 1.0
Epoch:  631       11 Batch loss: 0.062781 Batch F1: 0.7692307692307693
Epoch:  631       12 Batch loss: 0.067777 Batch F1: 0.9411764705882353
Train Avg Loss  631: 0.070457

Train Avg F1  631: 0.8572301313349908

Val Avg Loss  631: 0.066083

Val Avg F1  631:  0.7145104895104896

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 632
--------------------------------------------------------------
Epoch:  632        1 Batch loss: 0.063800 Batch F1: 0.7272727272727273
Epoch:  632        2 Batch loss: 0.065845 Batch F1: 0.8333333333333333
Epoch:  632        3 Batch loss: 0.060480 Batch F1: 0.7499999999999999
Epoch:  632        4 Batch loss: 0.064602 Batch F1: 0.4
Epoch:  632        5 Batch loss: 0.078533 Batch F1: 0.33333333333333337
Epoch:  632        6 Batch loss: 0.056708 Batch F1: 1.0
Epoch:  632        7 Batch loss: 0.087672 Batch F1: 0.8
Epoch:  632        8 Batch loss: 0.081043 Batch F1: 0.888888888888889
Epoch:  632        9 Batch loss: 0.059940 Batch F1: 0.9090909090909091
Epoch:  632       10 Batch loss: 0.102468 Batch F1: 0.8148148148148148
Epoch:  632       11 Batch loss: 0.067078 Batch F1: 0.9411764705882353
Epoch:  632       12 Batch loss: 0.072077 Batch F1: 0.923076923076923
Train Avg Loss  632: 0.071687

Train Avg F1  632: 0.7767489500332637

Val Avg Loss  632: 0.062813

Val Avg F1  632:  0.5939060939060938

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 633
--------------------------------------------------------------
Epoch:  633        1 Batch loss: 0.066590 Batch F1: 0.25
Epoch:  633        2 Batch loss: 0.076940 Batch F1: 0.625
Epoch:  633        3 Batch loss: 0.062301 Batch F1: 0.6
Epoch:  633        4 Batch loss: 0.061457 Batch F1: 0.6666666666666666
Epoch:  633        5 Batch loss: 0.070830 Batch F1: 0.2222222222222222
Epoch:  633        6 Batch loss: 0.079863 Batch F1: 0.5714285714285715
Epoch:  633        7 Batch loss: 0.085741 Batch F1: 0.8181818181818181
Epoch:  633        8 Batch loss: 0.072461 Batch F1: 1.0
Epoch:  633        9 Batch loss: 0.090312 Batch F1: 0.962962962962963
Epoch:  633       10 Batch loss: 0.054052 Batch F1: 1.0
Epoch:  633       11 Batch loss: 0.062860 Batch F1: 0.8333333333333333
Epoch:  633       12 Batch loss: 0.062675 Batch F1: 1.0
Train Avg Loss  633: 0.070507

Train Avg F1  633: 0.7124829645662979

Val Avg Loss  633: 0.062303

Val Avg F1  633:  0.7159090909090908

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 634
--------------------------------------------------------------
Epoch:  634        1 Batch loss: 0.079835 Batch F1: 0.5
Epoch:  634        2 Batch loss: 0.068025 Batch F1: 0.5714285714285715
Epoch:  634        3 Batch loss: 0.057292 Batch F1: 1.0
Epoch:  634        4 Batch loss: 0.053940 Batch F1: 0.7272727272727273
Epoch:  634        5 Batch loss: 0.063068 Batch F1: 0.4615384615384615
Epoch:  634        6 Batch loss: 0.072404 Batch F1: 0.4
Epoch:  634        7 Batch loss: 0.084923 Batch F1: 0.5
Epoch:  634        8 Batch loss: 0.070445 Batch F1: 0.8571428571428571
Epoch:  634        9 Batch loss: 0.048799 Batch F1: 0.8571428571428571
Epoch:  634       10 Batch loss: 0.073043 Batch F1: 0.4
Epoch:  634       11 Batch loss: 0.089455 Batch F1: 0.5555555555555556
Epoch:  634       12 Batch loss: 0.074201 Batch F1: 0.25
Train Avg Loss  634: 0.069619

Train Avg F1  634: 0.5900067525067524

Val Avg Loss  634: 0.063404

Val Avg F1  634:  0.9243055555555555

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 635
--------------------------------------------------------------
Epoch:  635        1 Batch loss: 0.074591 Batch F1: 0.7499999999999999
Epoch:  635        2 Batch loss: 0.082759 Batch F1: 0.9090909090909091
Epoch:  635        3 Batch loss: 0.075913 Batch F1: 1.0
Epoch:  635        4 Batch loss: 0.074169 Batch F1: 0.9565217391304348
Epoch:  635        5 Batch loss: 0.054122 Batch F1: 1.0
Epoch:  635        6 Batch loss: 0.059530 Batch F1: 0.5
Epoch:  635        7 Batch loss: 0.056532 Batch F1: 0.33333333333333337
Epoch:  635        8 Batch loss: 0.043759 Batch F1: 0.5714285714285715
Epoch:  635        9 Batch loss: 0.112282 Batch F1: 0.47058823529411764
Epoch:  635       10 Batch loss: 0.085581 Batch F1: 0.4615384615384615
Epoch:  635       11 Batch loss: 0.056646 Batch F1: 0.6666666666666666
Epoch:  635       12 Batch loss: 0.082418 Batch F1: 0.42857142857142855
Train Avg Loss  635: 0.071525

Train Avg F1  635: 0.6706449454211603

Val Avg Loss  635: 0.062863

Val Avg F1  635:  0.9269294778448096

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 636
--------------------------------------------------------------
Epoch:  636        1 Batch loss: 0.070635 Batch F1: 0.8571428571428571
Epoch:  636        2 Batch loss: 0.068595 Batch F1: 0.9411764705882353
Epoch:  636        3 Batch loss: 0.089232 Batch F1: 0.8571428571428571
Epoch:  636        4 Batch loss: 0.081646 Batch F1: 0.9565217391304348
Epoch:  636        5 Batch loss: 0.062474 Batch F1: 0.8750000000000001
Epoch:  636        6 Batch loss: 0.088893 Batch F1: 0.9090909090909091
Epoch:  636        7 Batch loss: 0.065297 Batch F1: 0.9333333333333333
Epoch:  636        8 Batch loss: 0.056715 Batch F1: 0.25
Epoch:  636        9 Batch loss: 0.064980 Batch F1: 0.25
Epoch:  636       10 Batch loss: 0.061525 Batch F1: 0.8
Epoch:  636       11 Batch loss: 0.061980 Batch F1: 0.6153846153846153
Epoch:  636       12 Batch loss: 0.072628 Batch F1: 0.9090909090909091
Train Avg Loss  636: 0.070383

Train Avg F1  636: 0.7628236409086792

Val Avg Loss  636: 0.062845

Val Avg F1  636:  0.8961038961038961

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 637
--------------------------------------------------------------
Epoch:  637        1 Batch loss: 0.063276 Batch F1: 0.9565217391304348
Epoch:  637        2 Batch loss: 0.050757 Batch F1: 0.9090909090909091
Epoch:  637        3 Batch loss: 0.065440 Batch F1: 0.4615384615384615
Epoch:  637        4 Batch loss: 0.079426 Batch F1: 0.9
Epoch:  637        5 Batch loss: 0.080227 Batch F1: 0.9565217391304348
Epoch:  637        6 Batch loss: 0.068766 Batch F1: 0.8333333333333333
Epoch:  637        7 Batch loss: 0.060931 Batch F1: 1.0
Epoch:  637        8 Batch loss: 0.079597 Batch F1: 0.7272727272727273
Epoch:  637        9 Batch loss: 0.082456 Batch F1: 0.3076923076923077
Epoch:  637       10 Batch loss: 0.063664 Batch F1: 1.0
Epoch:  637       11 Batch loss: 0.059211 Batch F1: 0.5454545454545454
Epoch:  637       12 Batch loss: 0.073048 Batch F1: 0.5454545454545454
Train Avg Loss  637: 0.068900

Train Avg F1  637: 0.7619066923414749

Val Avg Loss  637: 0.062511

Val Avg F1  637:  0.8854166666666666

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 638
--------------------------------------------------------------
Epoch:  638        1 Batch loss: 0.064299 Batch F1: 0.9523809523809523
Epoch:  638        2 Batch loss: 0.052639 Batch F1: 1.0
Epoch:  638        3 Batch loss: 0.075558 Batch F1: 0.6
Epoch:  638        4 Batch loss: 0.105375 Batch F1: 0.5555555555555556
Epoch:  638        5 Batch loss: 0.054123 Batch F1: 0.8
Epoch:  638        6 Batch loss: 0.062434 Batch F1: 0.6666666666666666
Epoch:  638        7 Batch loss: 0.063385 Batch F1: 0.25
Epoch:  638        8 Batch loss: 0.078072 Batch F1: 0.33333333333333337
Epoch:  638        9 Batch loss: 0.067509 Batch F1: 0.5333333333333333
Epoch:  638       10 Batch loss: 0.066345 Batch F1: 0.3636363636363636
Epoch:  638       11 Batch loss: 0.062759 Batch F1: 1.0
Epoch:  638       12 Batch loss: 0.076752 Batch F1: 0.9523809523809523
Train Avg Loss  638: 0.069104

Train Avg F1  638: 0.6672739297739296

Val Avg Loss  638: 0.062046

Val Avg F1  638:  0.927991452991453

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 639
--------------------------------------------------------------
Epoch:  639        1 Batch loss: 0.072494 Batch F1: 0.9565217391304348
Epoch:  639        2 Batch loss: 0.075973 Batch F1: 0.6666666666666666
Epoch:  639        3 Batch loss: 0.053403 Batch F1: 1.0
Epoch:  639        4 Batch loss: 0.068001 Batch F1: 0.9333333333333333
Epoch:  639        5 Batch loss: 0.069482 Batch F1: 0.8
Epoch:  639        6 Batch loss: 0.067423 Batch F1: 1.0
Epoch:  639        7 Batch loss: 0.066414 Batch F1: 0.9473684210526316
Epoch:  639        8 Batch loss: 0.081187 Batch F1: 1.0
Epoch:  639        9 Batch loss: 0.055123 Batch F1: 0.5714285714285715
Epoch:  639       10 Batch loss: 0.070336 Batch F1: 0.9
Epoch:  639       11 Batch loss: 0.074824 Batch F1: 0.9523809523809523
Epoch:  639       12 Batch loss: 0.061099 Batch F1: 1.0
Train Avg Loss  639: 0.067980

Train Avg F1  639: 0.8939749736660492

Val Avg Loss  639: 0.064091

Val Avg F1  639:  0.9158496732026145

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 640
--------------------------------------------------------------
Epoch:  640        1 Batch loss: 0.049495 Batch F1: 0.7499999999999999
Epoch:  640        2 Batch loss: 0.069808 Batch F1: 0.7499999999999999
Epoch:  640        3 Batch loss: 0.065882 Batch F1: 0.6
Epoch:  640        4 Batch loss: 0.077260 Batch F1: 0.5333333333333333
Epoch:  640        5 Batch loss: 0.085618 Batch F1: 0.5555555555555556
Epoch:  640        6 Batch loss: 0.068318 Batch F1: 0.3636363636363636
Epoch:  640        7 Batch loss: 0.076271 Batch F1: 0.888888888888889
Epoch:  640        8 Batch loss: 0.055567 Batch F1: 1.0
Epoch:  640        9 Batch loss: 0.066101 Batch F1: 0.9333333333333333
Epoch:  640       10 Batch loss: 0.083756 Batch F1: 0.9600000000000001
Epoch:  640       11 Batch loss: 0.076574 Batch F1: 0.9090909090909091
Epoch:  640       12 Batch loss: 0.064937 Batch F1: 0.923076923076923
Train Avg Loss  640: 0.069966

Train Avg F1  640: 0.7639096089096089

Val Avg Loss  640: 0.061525

Val Avg F1  640:  0.8985460191981931

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 641
--------------------------------------------------------------
Epoch:  641        1 Batch loss: 0.070568 Batch F1: 1.0
Epoch:  641        2 Batch loss: 0.083878 Batch F1: 0.6666666666666666
Epoch:  641        3 Batch loss: 0.058684 Batch F1: 1.0
Epoch:  641        4 Batch loss: 0.062339 Batch F1: 0.923076923076923
Epoch:  641        5 Batch loss: 0.066466 Batch F1: 0.625
Epoch:  641        6 Batch loss: 0.064175 Batch F1: 0.5714285714285715
Epoch:  641        7 Batch loss: 0.058770 Batch F1: 1.0
Epoch:  641        8 Batch loss: 0.076924 Batch F1: 0.888888888888889
Epoch:  641        9 Batch loss: 0.080543 Batch F1: 0.8
Epoch:  641       10 Batch loss: 0.086877 Batch F1: 0.5
Epoch:  641       11 Batch loss: 0.060779 Batch F1: 0.8571428571428571
Epoch:  641       12 Batch loss: 0.059922 Batch F1: 1.0
Train Avg Loss  641: 0.069160

Train Avg F1  641: 0.8193503256003255

Val Avg Loss  641: 0.061497

Val Avg F1  641:  0.9240507299717826

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 642
--------------------------------------------------------------
Epoch:  642        1 Batch loss: 0.076380 Batch F1: 0.9
Epoch:  642        2 Batch loss: 0.061195 Batch F1: 0.9473684210526316
Epoch:  642        3 Batch loss: 0.055944 Batch F1: 0.923076923076923
Epoch:  642        4 Batch loss: 0.077463 Batch F1: 1.0
Epoch:  642        5 Batch loss: 0.083918 Batch F1: 0.8333333333333333
Epoch:  642        6 Batch loss: 0.076642 Batch F1: 0.9523809523809523
Epoch:  642        7 Batch loss: 0.070322 Batch F1: 0.8750000000000001
Epoch:  642        8 Batch loss: 0.055584 Batch F1: 0.8333333333333333
Epoch:  642        9 Batch loss: 0.070789 Batch F1: 0.9333333333333333
Epoch:  642       10 Batch loss: 0.047754 Batch F1: 1.0
Epoch:  642       11 Batch loss: 0.076378 Batch F1: 0.33333333333333337
Epoch:  642       12 Batch loss: 0.063082 Batch F1: 0.4444444444444445
Train Avg Loss  642: 0.067954

Train Avg F1  642: 0.8313003395240237

Val Avg Loss  642: 0.067212

Val Avg F1  642:  0.5915750915750916

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 643
--------------------------------------------------------------
Epoch:  643        1 Batch loss: 0.052346 Batch F1: 0.6666666666666666
Epoch:  643        2 Batch loss: 0.078619 Batch F1: 0.42857142857142855
Epoch:  643        3 Batch loss: 0.065803 Batch F1: 0.5
Epoch:  643        4 Batch loss: 0.074520 Batch F1: 0.6153846153846153
Epoch:  643        5 Batch loss: 0.077180 Batch F1: 0.8235294117647058
Epoch:  643        6 Batch loss: 0.057786 Batch F1: 0.9473684210526316
Epoch:  643        7 Batch loss: 0.089200 Batch F1: 0.9090909090909091
Epoch:  643        8 Batch loss: 0.060038 Batch F1: 0.6666666666666666
Epoch:  643        9 Batch loss: 0.073411 Batch F1: 0.9
Epoch:  643       10 Batch loss: 0.053364 Batch F1: 1.0
Epoch:  643       11 Batch loss: 0.063420 Batch F1: 0.8
Epoch:  643       12 Batch loss: 0.081721 Batch F1: 0.9411764705882353
Train Avg Loss  643: 0.068951

Train Avg F1  643: 0.766537882482155

Val Avg Loss  643: 0.063986

Val Avg F1  643:  0.9219771241830065

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 644
--------------------------------------------------------------
Epoch:  644        1 Batch loss: 0.065749 Batch F1: 1.0
Epoch:  644        2 Batch loss: 0.053011 Batch F1: 0.9090909090909091
Epoch:  644        3 Batch loss: 0.060416 Batch F1: 0.5714285714285715
Epoch:  644        4 Batch loss: 0.051681 Batch F1: 0.8
Epoch:  644        5 Batch loss: 0.104015 Batch F1: 0.5
Epoch:  644        6 Batch loss: 0.058319 Batch F1: 0.6
Epoch:  644        7 Batch loss: 0.068679 Batch F1: 0.9411764705882353
Epoch:  644        8 Batch loss: 0.074370 Batch F1: 0.9411764705882353
Epoch:  644        9 Batch loss: 0.079529 Batch F1: 0.5
Epoch:  644       10 Batch loss: 0.088221 Batch F1: 0.8148148148148148
Epoch:  644       11 Batch loss: 0.064148 Batch F1: 0.8571428571428571
Epoch:  644       12 Batch loss: 0.068498 Batch F1: 0.2222222222222222
Train Avg Loss  644: 0.069720

Train Avg F1  644: 0.7214210263229871

Val Avg Loss  644: 0.062247

Val Avg F1  644:  0.578030303030303

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 645
--------------------------------------------------------------
Epoch:  645        1 Batch loss: 0.055418 Batch F1: 0.5
Epoch:  645        2 Batch loss: 0.072029 Batch F1: 0.5882352941176471
Epoch:  645        3 Batch loss: 0.054421 Batch F1: 0.5
Epoch:  645        4 Batch loss: 0.089663 Batch F1: 0.5882352941176471
Epoch:  645        5 Batch loss: 0.077845 Batch F1: 0.5
Epoch:  645        6 Batch loss: 0.047398 Batch F1: 0.888888888888889
Epoch:  645        7 Batch loss: 0.051348 Batch F1: 1.0
Epoch:  645        8 Batch loss: 0.074855 Batch F1: 0.9473684210526316
Epoch:  645        9 Batch loss: 0.078283 Batch F1: 0.923076923076923
Epoch:  645       10 Batch loss: 0.085752 Batch F1: 0.888888888888889
Epoch:  645       11 Batch loss: 0.068379 Batch F1: 1.0
Epoch:  645       12 Batch loss: 0.062125 Batch F1: 0.923076923076923
Train Avg Loss  645: 0.068126

Train Avg F1  645: 0.7706475527682959

Val Avg Loss  645: 0.061670

Val Avg F1  645:  0.5598290598290598

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 646
--------------------------------------------------------------
Epoch:  646        1 Batch loss: 0.073548 Batch F1: 0.625
Epoch:  646        2 Batch loss: 0.060226 Batch F1: 0.4444444444444445
Epoch:  646        3 Batch loss: 0.069328 Batch F1: 0.6666666666666666
Epoch:  646        4 Batch loss: 0.055743 Batch F1: 0.7692307692307693
Epoch:  646        5 Batch loss: 0.087543 Batch F1: 0.42857142857142855
Epoch:  646        6 Batch loss: 0.069784 Batch F1: 0.2222222222222222
Epoch:  646        7 Batch loss: 0.068951 Batch F1: 0.5333333333333333
Epoch:  646        8 Batch loss: 0.067598 Batch F1: 0.25
Epoch:  646        9 Batch loss: 0.070611 Batch F1: 0.8750000000000001
Epoch:  646       10 Batch loss: 0.063224 Batch F1: 0.9473684210526316
Epoch:  646       11 Batch loss: 0.052639 Batch F1: 1.0
Epoch:  646       12 Batch loss: 0.065508 Batch F1: 0.9411764705882353
Train Avg Loss  646: 0.067058

Train Avg F1  646: 0.6419178130091443

Val Avg Loss  646: 0.061331

Val Avg F1  646:  0.9260577915376678

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 647
--------------------------------------------------------------
Epoch:  647        1 Batch loss: 0.056423 Batch F1: 0.923076923076923
Epoch:  647        2 Batch loss: 0.060356 Batch F1: 1.0
Epoch:  647        3 Batch loss: 0.075078 Batch F1: 0.7777777777777778
Epoch:  647        4 Batch loss: 0.074735 Batch F1: 0.9
Epoch:  647        5 Batch loss: 0.051619 Batch F1: 1.0
Epoch:  647        6 Batch loss: 0.056292 Batch F1: 1.0
Epoch:  647        7 Batch loss: 0.089163 Batch F1: 0.8695652173913044
Epoch:  647        8 Batch loss: 0.063656 Batch F1: 0.9090909090909091
Epoch:  647        9 Batch loss: 0.070981 Batch F1: 0.9473684210526316
Epoch:  647       10 Batch loss: 0.079992 Batch F1: 0.9090909090909091
Epoch:  647       11 Batch loss: 0.058084 Batch F1: 1.0
Epoch:  647       12 Batch loss: 0.065714 Batch F1: 0.7499999999999999
Train Avg Loss  647: 0.066841

Train Avg F1  647: 0.9154975131233711

Val Avg Loss  647: 0.061424

Val Avg F1  647:  0.9290674603174605

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 648
--------------------------------------------------------------
Epoch:  648        1 Batch loss: 0.070643 Batch F1: 0.888888888888889
Epoch:  648        2 Batch loss: 0.064141 Batch F1: 0.4615384615384615
Epoch:  648        3 Batch loss: 0.075929 Batch F1: 0.5
Epoch:  648        4 Batch loss: 0.049018 Batch F1: 0.8571428571428571
Epoch:  648        5 Batch loss: 0.069130 Batch F1: 0.9523809523809523
Epoch:  648        6 Batch loss: 0.060465 Batch F1: 0.923076923076923
Epoch:  648        7 Batch loss: 0.078354 Batch F1: 0.8
Epoch:  648        8 Batch loss: 0.065638 Batch F1: 0.8571428571428571
Epoch:  648        9 Batch loss: 0.074791 Batch F1: 0.9166666666666666
Epoch:  648       10 Batch loss: 0.062423 Batch F1: 1.0
Epoch:  648       11 Batch loss: 0.064775 Batch F1: 1.0
Epoch:  648       12 Batch loss: 0.068852 Batch F1: 0.923076923076923
Train Avg Loss  648: 0.067013

Train Avg F1  648: 0.8399928774928775

Val Avg Loss  648: 0.061255

Val Avg F1  648:  0.9210084033613446

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 649
--------------------------------------------------------------
Epoch:  649        1 Batch loss: 0.058355 Batch F1: 0.923076923076923
Epoch:  649        2 Batch loss: 0.060706 Batch F1: 0.8
Epoch:  649        3 Batch loss: 0.048102 Batch F1: 0.8
Epoch:  649        4 Batch loss: 0.081755 Batch F1: 0.5555555555555556
Epoch:  649        5 Batch loss: 0.065678 Batch F1: 0.5714285714285715
Epoch:  649        6 Batch loss: 0.063672 Batch F1: 0.6153846153846153
Epoch:  649        7 Batch loss: 0.062658 Batch F1: 0.0
Epoch:  649        8 Batch loss: 0.101065 Batch F1: 0.4210526315789474
Epoch:  649        9 Batch loss: 0.058647 Batch F1: 0.5
Epoch:  649       10 Batch loss: 0.075328 Batch F1: 0.9166666666666666
Epoch:  649       11 Batch loss: 0.070664 Batch F1: 0.8333333333333333
Epoch:  649       12 Batch loss: 0.069370 Batch F1: 1.0
Train Avg Loss  649: 0.068000

Train Avg F1  649: 0.6613748580853844

Val Avg Loss  649: 0.061657

Val Avg F1  649:  0.9360633484162896

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 650
--------------------------------------------------------------
Epoch:  650        1 Batch loss: 0.069109 Batch F1: 0.9473684210526316
Epoch:  650        2 Batch loss: 0.054171 Batch F1: 1.0
Epoch:  650        3 Batch loss: 0.054727 Batch F1: 0.7499999999999999
Epoch:  650        4 Batch loss: 0.074473 Batch F1: 0.7142857142857143
Epoch:  650        5 Batch loss: 0.073183 Batch F1: 0.4615384615384615
Epoch:  650        6 Batch loss: 0.089858 Batch F1: 0.4
Epoch:  650        7 Batch loss: 0.064152 Batch F1: 0.8
Epoch:  650        8 Batch loss: 0.056132 Batch F1: 0.923076923076923
Epoch:  650        9 Batch loss: 0.071465 Batch F1: 0.888888888888889
Epoch:  650       10 Batch loss: 0.079877 Batch F1: 0.9
Epoch:  650       11 Batch loss: 0.067893 Batch F1: 0.9523809523809523
Epoch:  650       12 Batch loss: 0.071580 Batch F1: 0.9473684210526316
Train Avg Loss  650: 0.068885

Train Avg F1  650: 0.8070756485230169

Val Avg Loss  650: 0.061491

Val Avg F1  650:  0.9156746031746031

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 651
--------------------------------------------------------------
Epoch:  651        1 Batch loss: 0.066592 Batch F1: 0.923076923076923
Epoch:  651        2 Batch loss: 0.065282 Batch F1: 0.9090909090909091
Epoch:  651        3 Batch loss: 0.084908 Batch F1: 0.9655172413793104
Epoch:  651        4 Batch loss: 0.061249 Batch F1: 0.923076923076923
Epoch:  651        5 Batch loss: 0.061509 Batch F1: 0.9090909090909091
Epoch:  651        6 Batch loss: 0.081617 Batch F1: 0.8235294117647058
Epoch:  651        7 Batch loss: 0.080691 Batch F1: 0.8
Epoch:  651        8 Batch loss: 0.054883 Batch F1: 1.0
Epoch:  651        9 Batch loss: 0.068199 Batch F1: 0.888888888888889
Epoch:  651       10 Batch loss: 0.055438 Batch F1: 0.9411764705882353
Epoch:  651       11 Batch loss: 0.065359 Batch F1: 0.9473684210526316
Epoch:  651       12 Batch loss: 0.081338 Batch F1: 0.9523809523809523
Train Avg Loss  651: 0.068922

Train Avg F1  651: 0.9152664208658657

Val Avg Loss  651: 0.061082

Val Avg F1  651:  0.8999358974358974

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 652
--------------------------------------------------------------
Epoch:  652        1 Batch loss: 0.051837 Batch F1: 0.888888888888889
Epoch:  652        2 Batch loss: 0.074727 Batch F1: 0.5714285714285715
Epoch:  652        3 Batch loss: 0.058169 Batch F1: 0.2857142857142857
Epoch:  652        4 Batch loss: 0.047987 Batch F1: 0.7499999999999999
Epoch:  652        5 Batch loss: 0.076927 Batch F1: 0.5882352941176471
Epoch:  652        6 Batch loss: 0.077492 Batch F1: 0.5555555555555556
Epoch:  652        7 Batch loss: 0.074223 Batch F1: 0.9473684210526316
Epoch:  652        8 Batch loss: 0.063804 Batch F1: 0.9473684210526316
Epoch:  652        9 Batch loss: 0.065808 Batch F1: 1.0
Epoch:  652       10 Batch loss: 0.064003 Batch F1: 1.0
Epoch:  652       11 Batch loss: 0.094932 Batch F1: 0.8
Epoch:  652       12 Batch loss: 0.072775 Batch F1: 0.8750000000000001
Train Avg Loss  652: 0.068557

Train Avg F1  652: 0.7674632864841845

Val Avg Loss  652: 0.061320

Val Avg F1  652:  0.9152930402930404

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 653
--------------------------------------------------------------
Epoch:  653        1 Batch loss: 0.077063 Batch F1: 0.9473684210526316
Epoch:  653        2 Batch loss: 0.064523 Batch F1: 0.9333333333333333
Epoch:  653        3 Batch loss: 0.058102 Batch F1: 0.9411764705882353
Epoch:  653        4 Batch loss: 0.058246 Batch F1: 1.0
Epoch:  653        5 Batch loss: 0.069507 Batch F1: 0.7499999999999999
Epoch:  653        6 Batch loss: 0.075663 Batch F1: 0.3636363636363636
Epoch:  653        7 Batch loss: 0.088369 Batch F1: 0.6
Epoch:  653        8 Batch loss: 0.067438 Batch F1: 0.625
Epoch:  653        9 Batch loss: 0.073924 Batch F1: 0.8571428571428571
Epoch:  653       10 Batch loss: 0.068976 Batch F1: 0.8571428571428571
Epoch:  653       11 Batch loss: 0.083217 Batch F1: 0.9090909090909091
Epoch:  653       12 Batch loss: 0.068027 Batch F1: 1.0
Train Avg Loss  653: 0.071088

Train Avg F1  653: 0.8153242676655988

Val Avg Loss  653: 0.064551

Val Avg F1  653:  0.9219587176108914

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 654
--------------------------------------------------------------
Epoch:  654        1 Batch loss: 0.066111 Batch F1: 1.0
Epoch:  654        2 Batch loss: 0.079948 Batch F1: 0.9166666666666666
Epoch:  654        3 Batch loss: 0.060822 Batch F1: 0.888888888888889
Epoch:  654        4 Batch loss: 0.077709 Batch F1: 0.9
Epoch:  654        5 Batch loss: 0.075953 Batch F1: 0.8421052631578948
Epoch:  654        6 Batch loss: 0.059932 Batch F1: 0.7499999999999999
Epoch:  654        7 Batch loss: 0.055768 Batch F1: 0.8571428571428571
Epoch:  654        8 Batch loss: 0.078443 Batch F1: 0.42857142857142855
Epoch:  654        9 Batch loss: 0.064200 Batch F1: 0.4
Epoch:  654       10 Batch loss: 0.066725 Batch F1: 0.4
Epoch:  654       11 Batch loss: 0.075686 Batch F1: 0.3636363636363636
Epoch:  654       12 Batch loss: 0.068669 Batch F1: 0.4
Train Avg Loss  654: 0.069164

Train Avg F1  654: 0.678917622338675

Val Avg Loss  654: 0.061872

Val Avg F1  654:  0.6111111111111112

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 655
--------------------------------------------------------------
Epoch:  655        1 Batch loss: 0.062930 Batch F1: 0.5454545454545454
Epoch:  655        2 Batch loss: 0.055674 Batch F1: 0.5454545454545454
Epoch:  655        3 Batch loss: 0.046274 Batch F1: 0.7272727272727273
Epoch:  655        4 Batch loss: 0.059657 Batch F1: 0.6
Epoch:  655        5 Batch loss: 0.098205 Batch F1: 0.4
Epoch:  655        6 Batch loss: 0.061520 Batch F1: 1.0
Epoch:  655        7 Batch loss: 0.081532 Batch F1: 0.9090909090909091
Epoch:  655        8 Batch loss: 0.086801 Batch F1: 0.7499999999999999
Epoch:  655        9 Batch loss: 0.087955 Batch F1: 0.9333333333333333
Epoch:  655       10 Batch loss: 0.059781 Batch F1: 1.0
Epoch:  655       11 Batch loss: 0.066538 Batch F1: 0.8333333333333333
Epoch:  655       12 Batch loss: 0.075809 Batch F1: 0.923076923076923
Train Avg Loss  655: 0.070223

Train Avg F1  655: 0.7639180264180264

Val Avg Loss  655: 0.063833

Val Avg F1  655:  0.9261437908496732

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 656
--------------------------------------------------------------
Epoch:  656        1 Batch loss: 0.071494 Batch F1: 0.9333333333333333
Epoch:  656        2 Batch loss: 0.082977 Batch F1: 0.761904761904762
Epoch:  656        3 Batch loss: 0.073107 Batch F1: 0.2222222222222222
Epoch:  656        4 Batch loss: 0.058604 Batch F1: 0.33333333333333337
Epoch:  656        5 Batch loss: 0.087473 Batch F1: 0.42857142857142855
Epoch:  656        6 Batch loss: 0.082167 Batch F1: 0.42857142857142855
Epoch:  656        7 Batch loss: 0.082723 Batch F1: 0.631578947368421
Epoch:  656        8 Batch loss: 0.072633 Batch F1: 0.4615384615384615
Epoch:  656        9 Batch loss: 0.052856 Batch F1: 0.5
Epoch:  656       10 Batch loss: 0.072036 Batch F1: 0.9473684210526316
Epoch:  656       11 Batch loss: 0.060752 Batch F1: 1.0
Epoch:  656       12 Batch loss: 0.044223 Batch F1: 1.0
Train Avg Loss  656: 0.070087

Train Avg F1  656: 0.6373685281580018

Val Avg Loss  656: 0.062671

Val Avg F1  656:  0.9141025641025641

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 657
--------------------------------------------------------------
Epoch:  657        1 Batch loss: 0.082445 Batch F1: 0.9565217391304348
Epoch:  657        2 Batch loss: 0.063266 Batch F1: 1.0
Epoch:  657        3 Batch loss: 0.043920 Batch F1: 1.0
Epoch:  657        4 Batch loss: 0.078945 Batch F1: 0.3076923076923077
Epoch:  657        5 Batch loss: 0.089595 Batch F1: 0.15384615384615385
Epoch:  657        6 Batch loss: 0.056228 Batch F1: 0.9333333333333333
Epoch:  657        7 Batch loss: 0.053783 Batch F1: 0.7499999999999999
Epoch:  657        8 Batch loss: 0.071787 Batch F1: 0.8333333333333333
Epoch:  657        9 Batch loss: 0.068697 Batch F1: 0.9523809523809523
Epoch:  657       10 Batch loss: 0.077941 Batch F1: 0.8750000000000001
Epoch:  657       11 Batch loss: 0.060031 Batch F1: 1.0
Epoch:  657       12 Batch loss: 0.083426 Batch F1: 0.8
Train Avg Loss  657: 0.069172

Train Avg F1  657: 0.7968423183097096

Val Avg Loss  657: 0.061694

Val Avg F1  657:  0.9246031746031746

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 658
--------------------------------------------------------------
Epoch:  658        1 Batch loss: 0.082238 Batch F1: 0.9166666666666666
Epoch:  658        2 Batch loss: 0.057610 Batch F1: 0.9090909090909091
Epoch:  658        3 Batch loss: 0.059878 Batch F1: 0.9333333333333333
Epoch:  658        4 Batch loss: 0.072587 Batch F1: 0.9333333333333333
Epoch:  658        5 Batch loss: 0.069799 Batch F1: 0.9411764705882353
Epoch:  658        6 Batch loss: 0.042762 Batch F1: 1.0
Epoch:  658        7 Batch loss: 0.066298 Batch F1: 0.6666666666666666
Epoch:  658        8 Batch loss: 0.065467 Batch F1: 0.9473684210526316
Epoch:  658        9 Batch loss: 0.071913 Batch F1: 0.8750000000000001
Epoch:  658       10 Batch loss: 0.095855 Batch F1: 0.782608695652174
Epoch:  658       11 Batch loss: 0.074440 Batch F1: 0.9411764705882353
Epoch:  658       12 Batch loss: 0.065133 Batch F1: 0.888888888888889
Train Avg Loss  658: 0.068665

Train Avg F1  658: 0.8946091546550896

Val Avg Loss  658: 0.061835

Val Avg F1  658:  0.9240507299717826

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 659
--------------------------------------------------------------
Epoch:  659        1 Batch loss: 0.082261 Batch F1: 0.9
Epoch:  659        2 Batch loss: 0.058781 Batch F1: 0.6666666666666666
Epoch:  659        3 Batch loss: 0.068726 Batch F1: 1.0
Epoch:  659        4 Batch loss: 0.081517 Batch F1: 0.9166666666666666
Epoch:  659        5 Batch loss: 0.063625 Batch F1: 0.9333333333333333
Epoch:  659        6 Batch loss: 0.079882 Batch F1: 0.9565217391304348
Epoch:  659        7 Batch loss: 0.074871 Batch F1: 0.9411764705882353
Epoch:  659        8 Batch loss: 0.058770 Batch F1: 0.9090909090909091
Epoch:  659        9 Batch loss: 0.069250 Batch F1: 0.8571428571428571
Epoch:  659       10 Batch loss: 0.047195 Batch F1: 0.0
Epoch:  659       11 Batch loss: 0.058295 Batch F1: 0.5454545454545454
Epoch:  659       12 Batch loss: 0.067781 Batch F1: 0.7499999999999999
Train Avg Loss  659: 0.067580

Train Avg F1  659: 0.781337765672804

Val Avg Loss  659: 0.061843

Val Avg F1  659:  0.5466628959276018

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 660
--------------------------------------------------------------
Epoch:  660        1 Batch loss: 0.068975 Batch F1: 0.25
Epoch:  660        2 Batch loss: 0.076170 Batch F1: 0.6666666666666666
Epoch:  660        3 Batch loss: 0.073957 Batch F1: 0.4615384615384615
Epoch:  660        4 Batch loss: 0.057884 Batch F1: 0.33333333333333337
Epoch:  660        5 Batch loss: 0.074801 Batch F1: 0.42857142857142855
Epoch:  660        6 Batch loss: 0.053510 Batch F1: 1.0
Epoch:  660        7 Batch loss: 0.059296 Batch F1: 0.9333333333333333
Epoch:  660        8 Batch loss: 0.068146 Batch F1: 0.9
Epoch:  660        9 Batch loss: 0.076869 Batch F1: 0.7499999999999999
Epoch:  660       10 Batch loss: 0.079009 Batch F1: 0.923076923076923
Epoch:  660       11 Batch loss: 0.068666 Batch F1: 0.8750000000000001
Epoch:  660       12 Batch loss: 0.052897 Batch F1: 1.0
Train Avg Loss  660: 0.067515

Train Avg F1  660: 0.7101266788766788

Val Avg Loss  660: 0.062737

Val Avg F1  660:  0.9246323529411764

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 661
--------------------------------------------------------------
Epoch:  661        1 Batch loss: 0.076828 Batch F1: 0.9523809523809523
Epoch:  661        2 Batch loss: 0.071810 Batch F1: 0.8750000000000001
Epoch:  661        3 Batch loss: 0.071417 Batch F1: 0.7499999999999999
Epoch:  661        4 Batch loss: 0.066067 Batch F1: 1.0
Epoch:  661        5 Batch loss: 0.060076 Batch F1: 0.9090909090909091
Epoch:  661        6 Batch loss: 0.058751 Batch F1: 0.9333333333333333
Epoch:  661        7 Batch loss: 0.068116 Batch F1: 0.6666666666666666
Epoch:  661        8 Batch loss: 0.087639 Batch F1: 0.2857142857142857
Epoch:  661        9 Batch loss: 0.066675 Batch F1: 0.4
Epoch:  661       10 Batch loss: 0.080966 Batch F1: 0.4
Epoch:  661       11 Batch loss: 0.064645 Batch F1: 0.5714285714285715
Epoch:  661       12 Batch loss: 0.049347 Batch F1: 0.0
Train Avg Loss  661: 0.068528

Train Avg F1  661: 0.6453012265512267

Val Avg Loss  661: 0.062320

Val Avg F1  661:  0.9217171717171717

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 662
--------------------------------------------------------------
Epoch:  662        1 Batch loss: 0.069716 Batch F1: 0.9473684210526316
Epoch:  662        2 Batch loss: 0.060295 Batch F1: 0.923076923076923
Epoch:  662        3 Batch loss: 0.062368 Batch F1: 0.8
Epoch:  662        4 Batch loss: 0.058657 Batch F1: 0.8333333333333333
Epoch:  662        5 Batch loss: 0.069431 Batch F1: 0.888888888888889
Epoch:  662        6 Batch loss: 0.057270 Batch F1: 1.0
Epoch:  662        7 Batch loss: 0.085149 Batch F1: 0.375
Epoch:  662        8 Batch loss: 0.068624 Batch F1: 1.0
Epoch:  662        9 Batch loss: 0.076363 Batch F1: 0.9565217391304348
Epoch:  662       10 Batch loss: 0.047551 Batch F1: 1.0
Epoch:  662       11 Batch loss: 0.076194 Batch F1: 0.8
Epoch:  662       12 Batch loss: 0.083854 Batch F1: 0.8750000000000001
Train Avg Loss  662: 0.067956

Train Avg F1  662: 0.8665991087901844

Val Avg Loss  662: 0.061617

Val Avg F1  662:  0.921945701357466

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 663
--------------------------------------------------------------
Epoch:  663        1 Batch loss: 0.062418 Batch F1: 1.0
Epoch:  663        2 Batch loss: 0.055733 Batch F1: 0.923076923076923
Epoch:  663        3 Batch loss: 0.055838 Batch F1: 1.0
Epoch:  663        4 Batch loss: 0.078333 Batch F1: 0.7499999999999999
Epoch:  663        5 Batch loss: 0.055818 Batch F1: 1.0
Epoch:  663        6 Batch loss: 0.060374 Batch F1: 0.9090909090909091
Epoch:  663        7 Batch loss: 0.060754 Batch F1: 0.9411764705882353
Epoch:  663        8 Batch loss: 0.087398 Batch F1: 0.5333333333333333
Epoch:  663        9 Batch loss: 0.061851 Batch F1: 0.923076923076923
Epoch:  663       10 Batch loss: 0.077583 Batch F1: 0.962962962962963
Epoch:  663       11 Batch loss: 0.072643 Batch F1: 0.9473684210526316
Epoch:  663       12 Batch loss: 0.090280 Batch F1: 0.8750000000000001
Train Avg Loss  663: 0.068252

Train Avg F1  663: 0.8970904952651599

Val Avg Loss  663: 0.061273

Val Avg F1  663:  0.9237012987012987

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 664
--------------------------------------------------------------
Epoch:  664        1 Batch loss: 0.052204 Batch F1: 0.9473684210526316
Epoch:  664        2 Batch loss: 0.063571 Batch F1: 0.9473684210526316
Epoch:  664        3 Batch loss: 0.077261 Batch F1: 1.0
Epoch:  664        4 Batch loss: 0.066598 Batch F1: 0.9411764705882353
Epoch:  664        5 Batch loss: 0.083130 Batch F1: 0.7499999999999999
Epoch:  664        6 Batch loss: 0.054143 Batch F1: 0.8571428571428571
Epoch:  664        7 Batch loss: 0.075413 Batch F1: 0.8
Epoch:  664        8 Batch loss: 0.089360 Batch F1: 0.9090909090909091
Epoch:  664        9 Batch loss: 0.065084 Batch F1: 0.9411764705882353
Epoch:  664       10 Batch loss: 0.067260 Batch F1: 0.9473684210526316
Epoch:  664       11 Batch loss: 0.050223 Batch F1: 0.9090909090909091
Epoch:  664       12 Batch loss: 0.055993 Batch F1: 0.5
Train Avg Loss  664: 0.066687

Train Avg F1  664: 0.8708152399715866

Val Avg Loss  664: 0.062229

Val Avg F1  664:  0.6051101072840204

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 665
--------------------------------------------------------------
Epoch:  665        1 Batch loss: 0.034376 Batch F1: 0.0
Epoch:  665        2 Batch loss: 0.065650 Batch F1: 0.7142857142857143
Epoch:  665        3 Batch loss: 0.067553 Batch F1: 0.6153846153846153
Epoch:  665        4 Batch loss: 0.077116 Batch F1: 0.5333333333333333
Epoch:  665        5 Batch loss: 0.077834 Batch F1: 0.7368421052631579
Epoch:  665        6 Batch loss: 0.072571 Batch F1: 0.2222222222222222
Epoch:  665        7 Batch loss: 0.074458 Batch F1: 1.0
Epoch:  665        8 Batch loss: 0.084346 Batch F1: 0.8
Epoch:  665        9 Batch loss: 0.071000 Batch F1: 0.9333333333333333
Epoch:  665       10 Batch loss: 0.057829 Batch F1: 1.0
Epoch:  665       11 Batch loss: 0.069178 Batch F1: 0.8750000000000001
Epoch:  665       12 Batch loss: 0.062669 Batch F1: 0.8571428571428571
Train Avg Loss  665: 0.067882

Train Avg F1  665: 0.6906286817471029

Val Avg Loss  665: 0.062670

Val Avg F1  665:  0.9196859903381643

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 666
--------------------------------------------------------------
Epoch:  666        1 Batch loss: 0.065780 Batch F1: 0.9523809523809523
Epoch:  666        2 Batch loss: 0.054089 Batch F1: 0.923076923076923
Epoch:  666        3 Batch loss: 0.070445 Batch F1: 0.9473684210526316
Epoch:  666        4 Batch loss: 0.085951 Batch F1: 0.9
Epoch:  666        5 Batch loss: 0.072058 Batch F1: 0.8750000000000001
Epoch:  666        6 Batch loss: 0.059287 Batch F1: 0.923076923076923
Epoch:  666        7 Batch loss: 0.072498 Batch F1: 0.5882352941176471
Epoch:  666        8 Batch loss: 0.049891 Batch F1: 0.5714285714285715
Epoch:  666        9 Batch loss: 0.063234 Batch F1: 0.5
Epoch:  666       10 Batch loss: 0.090308 Batch F1: 0.5555555555555556
Epoch:  666       11 Batch loss: 0.073199 Batch F1: 0.19999999999999998
Epoch:  666       12 Batch loss: 0.059601 Batch F1: 0.7499999999999999
Train Avg Loss  666: 0.068028

Train Avg F1  666: 0.723843553390767

Val Avg Loss  666: 0.062128

Val Avg F1  666:  0.9292763157894737

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 667
--------------------------------------------------------------
Epoch:  667        1 Batch loss: 0.083253 Batch F1: 0.9166666666666666
Epoch:  667        2 Batch loss: 0.056126 Batch F1: 0.923076923076923
Epoch:  667        3 Batch loss: 0.066097 Batch F1: 0.923076923076923
Epoch:  667        4 Batch loss: 0.076856 Batch F1: 0.9565217391304348
Epoch:  667        5 Batch loss: 0.085981 Batch F1: 0.7777777777777778
Epoch:  667        6 Batch loss: 0.076210 Batch F1: 0.9411764705882353
Epoch:  667        7 Batch loss: 0.056916 Batch F1: 0.923076923076923
Epoch:  667        8 Batch loss: 0.061125 Batch F1: 0.9333333333333333
Epoch:  667        9 Batch loss: 0.065200 Batch F1: 0.8750000000000001
Epoch:  667       10 Batch loss: 0.046189 Batch F1: 0.6666666666666666
Epoch:  667       11 Batch loss: 0.083911 Batch F1: 0.16666666666666669
Epoch:  667       12 Batch loss: 0.061150 Batch F1: 0.7499999999999999
Train Avg Loss  667: 0.068251

Train Avg F1  667: 0.8127533408383791

Val Avg Loss  667: 0.061428

Val Avg F1  667:  0.9237012987012987

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 668
--------------------------------------------------------------
Epoch:  668        1 Batch loss: 0.052456 Batch F1: 0.923076923076923
Epoch:  668        2 Batch loss: 0.064556 Batch F1: 0.6666666666666666
Epoch:  668        3 Batch loss: 0.076704 Batch F1: 0.8750000000000001
Epoch:  668        4 Batch loss: 0.077456 Batch F1: 0.888888888888889
Epoch:  668        5 Batch loss: 0.077506 Batch F1: 0.9523809523809523
Epoch:  668        6 Batch loss: 0.052560 Batch F1: 0.9333333333333333
Epoch:  668        7 Batch loss: 0.067866 Batch F1: 1.0
Epoch:  668        8 Batch loss: 0.062344 Batch F1: 1.0
Epoch:  668        9 Batch loss: 0.067031 Batch F1: 0.5714285714285715
Epoch:  668       10 Batch loss: 0.095067 Batch F1: 0.6
Epoch:  668       11 Batch loss: 0.058644 Batch F1: 0.9411764705882353
Epoch:  668       12 Batch loss: 0.076565 Batch F1: 0.8333333333333333
Train Avg Loss  668: 0.069063

Train Avg F1  668: 0.8487737616414087

Val Avg Loss  668: 0.062784

Val Avg F1  668:  0.9224481658692185

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 669
--------------------------------------------------------------
Epoch:  669        1 Batch loss: 0.073243 Batch F1: 0.923076923076923
Epoch:  669        2 Batch loss: 0.047502 Batch F1: 1.0
Epoch:  669        3 Batch loss: 0.071282 Batch F1: 0.4615384615384615
Epoch:  669        4 Batch loss: 0.061152 Batch F1: 0.2857142857142857
Epoch:  669        5 Batch loss: 0.071770 Batch F1: 0.625
Epoch:  669        6 Batch loss: 0.062714 Batch F1: 0.7499999999999999
Epoch:  669        7 Batch loss: 0.070303 Batch F1: 0.3636363636363636
Epoch:  669        8 Batch loss: 0.074106 Batch F1: 0.3636363636363636
Epoch:  669        9 Batch loss: 0.093254 Batch F1: 0.5454545454545454
Epoch:  669       10 Batch loss: 0.089463 Batch F1: 0.923076923076923
Epoch:  669       11 Batch loss: 0.066193 Batch F1: 1.0
Epoch:  669       12 Batch loss: 0.061179 Batch F1: 1.0
Train Avg Loss  669: 0.070180

Train Avg F1  669: 0.6867611555111554

Val Avg Loss  669: 0.064913

Val Avg F1  669:  0.6951754385964912

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 670
--------------------------------------------------------------
Epoch:  670        1 Batch loss: 0.091319 Batch F1: 0.5882352941176471
Epoch:  670        2 Batch loss: 0.043662 Batch F1: 0.7499999999999999
Epoch:  670        3 Batch loss: 0.061450 Batch F1: 0.6666666666666666
Epoch:  670        4 Batch loss: 0.057028 Batch F1: 0.6666666666666666
Epoch:  670        5 Batch loss: 0.068925 Batch F1: 0.6666666666666666
Epoch:  670        6 Batch loss: 0.085496 Batch F1: 0.5263157894736842
Epoch:  670        7 Batch loss: 0.042210 Batch F1: 0.5714285714285715
Epoch:  670        8 Batch loss: 0.076250 Batch F1: 0.4
Epoch:  670        9 Batch loss: 0.107554 Batch F1: 0.6956521739130436
Epoch:  670       10 Batch loss: 0.078528 Batch F1: 0.8
Epoch:  670       11 Batch loss: 0.070746 Batch F1: 1.0
Epoch:  670       12 Batch loss: 0.087908 Batch F1: 0.9090909090909091
Train Avg Loss  670: 0.072590

Train Avg F1  670: 0.6867268948353212

Val Avg Loss  670: 0.065419

Val Avg F1  670:  0.9202533577533577

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 671
--------------------------------------------------------------
Epoch:  671        1 Batch loss: 0.068475 Batch F1: 0.7272727272727273
Epoch:  671        2 Batch loss: 0.076589 Batch F1: 0.9411764705882353
Epoch:  671        3 Batch loss: 0.057540 Batch F1: 0.7499999999999999
Epoch:  671        4 Batch loss: 0.070725 Batch F1: 0.8750000000000001
Epoch:  671        5 Batch loss: 0.078112 Batch F1: 0.9523809523809523
Epoch:  671        6 Batch loss: 0.061549 Batch F1: 0.5454545454545454
Epoch:  671        7 Batch loss: 0.085827 Batch F1: 0.47058823529411764
Epoch:  671        8 Batch loss: 0.072903 Batch F1: 0.5333333333333333
Epoch:  671        9 Batch loss: 0.054691 Batch F1: 1.0
Epoch:  671       10 Batch loss: 0.074775 Batch F1: 0.5333333333333333
Epoch:  671       11 Batch loss: 0.063882 Batch F1: 0.6666666666666666
Epoch:  671       12 Batch loss: 0.086396 Batch F1: 0.19999999999999998
Train Avg Loss  671: 0.070956

Train Avg F1  671: 0.6829338553603259

Val Avg Loss  671: 0.063638

Val Avg F1  671:  0.5736652236652237

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 672
--------------------------------------------------------------
Epoch:  672        1 Batch loss: 0.079508 Batch F1: 0.5333333333333333
Epoch:  672        2 Batch loss: 0.072077 Batch F1: 0.4444444444444445
Epoch:  672        3 Batch loss: 0.069031 Batch F1: 0.6153846153846153
Epoch:  672        4 Batch loss: 0.064111 Batch F1: 0.4
Epoch:  672        5 Batch loss: 0.064626 Batch F1: 0.2222222222222222
Epoch:  672        6 Batch loss: 0.080834 Batch F1: 0.5882352941176471
Epoch:  672        7 Batch loss: 0.053349 Batch F1: 0.9473684210526316
Epoch:  672        8 Batch loss: 0.054341 Batch F1: 1.0
Epoch:  672        9 Batch loss: 0.086966 Batch F1: 0.9600000000000001
Epoch:  672       10 Batch loss: 0.070949 Batch F1: 0.33333333333333337
Epoch:  672       11 Batch loss: 0.057604 Batch F1: 0.923076923076923
Epoch:  672       12 Batch loss: 0.063309 Batch F1: 1.0
Train Avg Loss  672: 0.068059

Train Avg F1  672: 0.6639498822470958

Val Avg Loss  672: 0.061931

Val Avg F1  672:  0.9212503183091418

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 673
--------------------------------------------------------------
Epoch:  673        1 Batch loss: 0.076539 Batch F1: 0.8
Epoch:  673        2 Batch loss: 0.056038 Batch F1: 0.9090909090909091
Epoch:  673        3 Batch loss: 0.059183 Batch F1: 0.5
Epoch:  673        4 Batch loss: 0.066801 Batch F1: 0.3636363636363636
Epoch:  673        5 Batch loss: 0.089481 Batch F1: 0.4
Epoch:  673        6 Batch loss: 0.093651 Batch F1: 0.33333333333333337
Epoch:  673        7 Batch loss: 0.058537 Batch F1: 0.923076923076923
Epoch:  673        8 Batch loss: 0.049322 Batch F1: 1.0
Epoch:  673        9 Batch loss: 0.073293 Batch F1: 0.88
Epoch:  673       10 Batch loss: 0.062245 Batch F1: 0.888888888888889
Epoch:  673       11 Batch loss: 0.063663 Batch F1: 0.9523809523809523
Epoch:  673       12 Batch loss: 0.074900 Batch F1: 0.9333333333333333
Train Avg Loss  673: 0.068638

Train Avg F1  673: 0.7403117253117254

Val Avg Loss  673: 0.061795

Val Avg F1  673:  0.9221723928245668

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 674
--------------------------------------------------------------
Epoch:  674        1 Batch loss: 0.075356 Batch F1: 0.9333333333333333
Epoch:  674        2 Batch loss: 0.078129 Batch F1: 0.8235294117647058
Epoch:  674        3 Batch loss: 0.070917 Batch F1: 0.8750000000000001
Epoch:  674        4 Batch loss: 0.081216 Batch F1: 0.47058823529411764
Epoch:  674        5 Batch loss: 0.046869 Batch F1: 1.0
Epoch:  674        6 Batch loss: 0.050038 Batch F1: 1.0
Epoch:  674        7 Batch loss: 0.073549 Batch F1: 0.9473684210526316
Epoch:  674        8 Batch loss: 0.069231 Batch F1: 0.8
Epoch:  674        9 Batch loss: 0.076956 Batch F1: 0.9090909090909091
Epoch:  674       10 Batch loss: 0.063909 Batch F1: 0.923076923076923
Epoch:  674       11 Batch loss: 0.070145 Batch F1: 0.6153846153846153
Epoch:  674       12 Batch loss: 0.062024 Batch F1: 0.7272727272727273
Train Avg Loss  674: 0.068195

Train Avg F1  674: 0.8353870480224969

Val Avg Loss  674: 0.062370

Val Avg F1  674:  0.7398567119155355

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 675
--------------------------------------------------------------
Epoch:  675        1 Batch loss: 0.070963 Batch F1: 0.5454545454545454
Epoch:  675        2 Batch loss: 0.089712 Batch F1: 0.42857142857142855
Epoch:  675        3 Batch loss: 0.043509 Batch F1: 0.6666666666666666
Epoch:  675        4 Batch loss: 0.064115 Batch F1: 0.5
Epoch:  675        5 Batch loss: 0.078751 Batch F1: 0.42857142857142855
Epoch:  675        6 Batch loss: 0.061409 Batch F1: 0.5454545454545454
Epoch:  675        7 Batch loss: 0.083653 Batch F1: 0.5
Epoch:  675        8 Batch loss: 0.057985 Batch F1: 1.0
Epoch:  675        9 Batch loss: 0.086695 Batch F1: 0.9166666666666666
Epoch:  675       10 Batch loss: 0.055536 Batch F1: 0.923076923076923
Epoch:  675       11 Batch loss: 0.078690 Batch F1: 0.9655172413793104
Epoch:  675       12 Batch loss: 0.053443 Batch F1: 0.8
Train Avg Loss  675: 0.068705

Train Avg F1  675: 0.6849982871534596

Val Avg Loss  675: 0.063483

Val Avg F1  675:  0.9210084033613445

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 676
--------------------------------------------------------------
Epoch:  676        1 Batch loss: 0.072775 Batch F1: 0.6666666666666666
Epoch:  676        2 Batch loss: 0.080630 Batch F1: 0.8
Epoch:  676        3 Batch loss: 0.051250 Batch F1: 0.9090909090909091
Epoch:  676        4 Batch loss: 0.075772 Batch F1: 0.4615384615384615
Epoch:  676        5 Batch loss: 0.072801 Batch F1: 0.2222222222222222
Epoch:  676        6 Batch loss: 0.049163 Batch F1: 0.4
Epoch:  676        7 Batch loss: 0.076985 Batch F1: 0.3076923076923077
Epoch:  676        8 Batch loss: 0.064270 Batch F1: 0.5
Epoch:  676        9 Batch loss: 0.065606 Batch F1: 0.5
Epoch:  676       10 Batch loss: 0.084381 Batch F1: 0.8695652173913044
Epoch:  676       11 Batch loss: 0.078144 Batch F1: 1.0
Epoch:  676       12 Batch loss: 0.055359 Batch F1: 1.0
Train Avg Loss  676: 0.068928

Train Avg F1  676: 0.6363979820501561

Val Avg Loss  676: 0.062926

Val Avg F1  676:  0.9219587176108915

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 677
--------------------------------------------------------------
Epoch:  677        1 Batch loss: 0.056258 Batch F1: 0.8333333333333333
Epoch:  677        2 Batch loss: 0.063261 Batch F1: 1.0
Epoch:  677        3 Batch loss: 0.069253 Batch F1: 0.9333333333333333
Epoch:  677        4 Batch loss: 0.058406 Batch F1: 1.0
Epoch:  677        5 Batch loss: 0.087626 Batch F1: 0.8235294117647058
Epoch:  677        6 Batch loss: 0.066201 Batch F1: 0.9411764705882353
Epoch:  677        7 Batch loss: 0.072575 Batch F1: 0.9473684210526316
Epoch:  677        8 Batch loss: 0.054955 Batch F1: 1.0
Epoch:  677        9 Batch loss: 0.065563 Batch F1: 0.9473684210526316
Epoch:  677       10 Batch loss: 0.070803 Batch F1: 0.3636363636363636
Epoch:  677       11 Batch loss: 0.070893 Batch F1: 0.4615384615384615
Epoch:  677       12 Batch loss: 0.094897 Batch F1: 0.7142857142857143
Train Avg Loss  677: 0.069224

Train Avg F1  677: 0.8304641608821175

Val Avg Loss  677: 0.061452

Val Avg F1  677:  0.930701754385965

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 678
--------------------------------------------------------------
Epoch:  678        1 Batch loss: 0.062746 Batch F1: 0.6666666666666666
Epoch:  678        2 Batch loss: 0.054691 Batch F1: 0.9090909090909091
Epoch:  678        3 Batch loss: 0.073246 Batch F1: 0.8421052631578948
Epoch:  678        4 Batch loss: 0.066033 Batch F1: 0.9411764705882353
Epoch:  678        5 Batch loss: 0.067416 Batch F1: 0.888888888888889
Epoch:  678        6 Batch loss: 0.073141 Batch F1: 0.7499999999999999
Epoch:  678        7 Batch loss: 0.082817 Batch F1: 0.9565217391304348
Epoch:  678        8 Batch loss: 0.077058 Batch F1: 1.0
Epoch:  678        9 Batch loss: 0.057472 Batch F1: 1.0
Epoch:  678       10 Batch loss: 0.082512 Batch F1: 0.9565217391304348
Epoch:  678       11 Batch loss: 0.066439 Batch F1: 0.6666666666666666
Epoch:  678       12 Batch loss: 0.053829 Batch F1: 0.6666666666666666
Train Avg Loss  678: 0.068117

Train Avg F1  678: 0.8536920841655663

Val Avg Loss  678: 0.062568

Val Avg F1  678:  0.581990231990232

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 679
--------------------------------------------------------------
Epoch:  679        1 Batch loss: 0.063033 Batch F1: 0.6666666666666666
Epoch:  679        2 Batch loss: 0.064258 Batch F1: 0.6153846153846153
Epoch:  679        3 Batch loss: 0.046282 Batch F1: 0.6666666666666666
Epoch:  679        4 Batch loss: 0.075824 Batch F1: 0.33333333333333337
Epoch:  679        5 Batch loss: 0.083919 Batch F1: 0.7368421052631579
Epoch:  679        6 Batch loss: 0.063777 Batch F1: 0.7499999999999999
Epoch:  679        7 Batch loss: 0.064333 Batch F1: 0.8571428571428571
Epoch:  679        8 Batch loss: 0.068031 Batch F1: 0.9333333333333333
Epoch:  679        9 Batch loss: 0.083997 Batch F1: 0.888888888888889
Epoch:  679       10 Batch loss: 0.080488 Batch F1: 0.923076923076923
Epoch:  679       11 Batch loss: 0.058860 Batch F1: 1.0
Epoch:  679       12 Batch loss: 0.072840 Batch F1: 0.9411764705882353
Train Avg Loss  679: 0.068803

Train Avg F1  679: 0.7760426550287232

Val Avg Loss  679: 0.061969

Val Avg F1  679:  0.9284161490683229

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 680
--------------------------------------------------------------
Epoch:  680        1 Batch loss: 0.057282 Batch F1: 0.9411764705882353
Epoch:  680        2 Batch loss: 0.044357 Batch F1: 1.0
Epoch:  680        3 Batch loss: 0.063933 Batch F1: 1.0
Epoch:  680        4 Batch loss: 0.066219 Batch F1: 0.4
Epoch:  680        5 Batch loss: 0.081182 Batch F1: 0.19999999999999998
Epoch:  680        6 Batch loss: 0.062501 Batch F1: 0.4444444444444445
Epoch:  680        7 Batch loss: 0.069819 Batch F1: 0.6666666666666666
Epoch:  680        8 Batch loss: 0.081925 Batch F1: 0.4
Epoch:  680        9 Batch loss: 0.071888 Batch F1: 0.5882352941176471
Epoch:  680       10 Batch loss: 0.082587 Batch F1: 0.8235294117647058
Epoch:  680       11 Batch loss: 0.077845 Batch F1: 0.8235294117647058
Epoch:  680       12 Batch loss: 0.057147 Batch F1: 0.888888888888889
Train Avg Loss  680: 0.068057

Train Avg F1  680: 0.6813725490196078

Val Avg Loss  680: 0.061830

Val Avg F1  680:  0.9325163398692811

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 681
--------------------------------------------------------------
Epoch:  681        1 Batch loss: 0.071072 Batch F1: 0.9565217391304348
Epoch:  681        2 Batch loss: 0.074434 Batch F1: 1.0
Epoch:  681        3 Batch loss: 0.050907 Batch F1: 0.888888888888889
Epoch:  681        4 Batch loss: 0.077454 Batch F1: 0.9600000000000001
Epoch:  681        5 Batch loss: 0.054423 Batch F1: 0.923076923076923
Epoch:  681        6 Batch loss: 0.044868 Batch F1: 1.0
Epoch:  681        7 Batch loss: 0.057944 Batch F1: 0.5
Epoch:  681        8 Batch loss: 0.047746 Batch F1: 0.7499999999999999
Epoch:  681        9 Batch loss: 0.107305 Batch F1: 0.2666666666666667
Epoch:  681       10 Batch loss: 0.079602 Batch F1: 0.5882352941176471
Epoch:  681       11 Batch loss: 0.095827 Batch F1: 0.2666666666666667
Epoch:  681       12 Batch loss: 0.074674 Batch F1: 0.6
Train Avg Loss  681: 0.069688

Train Avg F1  681: 0.7250046815456023

Val Avg Loss  681: 0.063894

Val Avg F1  681:  0.9245098039215687

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 682
--------------------------------------------------------------
Epoch:  682        1 Batch loss: 0.061921 Batch F1: 0.9411764705882353
Epoch:  682        2 Batch loss: 0.060585 Batch F1: 0.8
Epoch:  682        3 Batch loss: 0.075700 Batch F1: 0.888888888888889
Epoch:  682        4 Batch loss: 0.087925 Batch F1: 0.9600000000000001
Epoch:  682        5 Batch loss: 0.058603 Batch F1: 0.8571428571428571
Epoch:  682        6 Batch loss: 0.068857 Batch F1: 1.0
Epoch:  682        7 Batch loss: 0.066059 Batch F1: 1.0
Epoch:  682        8 Batch loss: 0.077232 Batch F1: 0.3636363636363636
Epoch:  682        9 Batch loss: 0.071537 Batch F1: 0.5714285714285715
Epoch:  682       10 Batch loss: 0.077527 Batch F1: 0.19999999999999998
Epoch:  682       11 Batch loss: 0.063053 Batch F1: 0.4444444444444445
Epoch:  682       12 Batch loss: 0.078289 Batch F1: 0.7368421052631579
Train Avg Loss  682: 0.070607

Train Avg F1  682: 0.7302966417827098

Val Avg Loss  682: 0.062146

Val Avg F1  682:  0.7277777777777779

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 683
--------------------------------------------------------------
Epoch:  683        1 Batch loss: 0.061833 Batch F1: 0.8333333333333333
Epoch:  683        2 Batch loss: 0.059976 Batch F1: 0.8571428571428571
Epoch:  683        3 Batch loss: 0.047442 Batch F1: 0.8
Epoch:  683        4 Batch loss: 0.069883 Batch F1: 0.2857142857142857
Epoch:  683        5 Batch loss: 0.085304 Batch F1: 0.4615384615384615
Epoch:  683        6 Batch loss: 0.085645 Batch F1: 0.5
Epoch:  683        7 Batch loss: 0.070323 Batch F1: 0.7777777777777778
Epoch:  683        8 Batch loss: 0.070580 Batch F1: 0.9411764705882353
Epoch:  683        9 Batch loss: 0.075698 Batch F1: 0.8750000000000001
Epoch:  683       10 Batch loss: 0.055352 Batch F1: 0.9090909090909091
Epoch:  683       11 Batch loss: 0.079597 Batch F1: 0.88
Epoch:  683       12 Batch loss: 0.077948 Batch F1: 0.9600000000000001
Train Avg Loss  683: 0.069965

Train Avg F1  683: 0.7567311745988218

Val Avg Loss  683: 0.063462

Val Avg F1  683:  0.9207251082251082

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 684
--------------------------------------------------------------
Epoch:  684        1 Batch loss: 0.080778 Batch F1: 0.9090909090909091
Epoch:  684        2 Batch loss: 0.075802 Batch F1: 1.0
Epoch:  684        3 Batch loss: 0.060358 Batch F1: 0.6666666666666666
Epoch:  684        4 Batch loss: 0.065297 Batch F1: 0.8333333333333333
Epoch:  684        5 Batch loss: 0.073463 Batch F1: 0.888888888888889
Epoch:  684        6 Batch loss: 0.077339 Batch F1: 0.9
Epoch:  684        7 Batch loss: 0.053579 Batch F1: 1.0
Epoch:  684        8 Batch loss: 0.091539 Batch F1: 0.9600000000000001
Epoch:  684        9 Batch loss: 0.059677 Batch F1: 0.9333333333333333
Epoch:  684       10 Batch loss: 0.047029 Batch F1: 0.7499999999999999
Epoch:  684       11 Batch loss: 0.073623 Batch F1: 0.5333333333333333
Epoch:  684       12 Batch loss: 0.075346 Batch F1: 0.3636363636363636
Train Avg Loss  684: 0.069486

Train Avg F1  684: 0.811523569023569

Val Avg Loss  684: 0.062160

Val Avg F1  684:  0.5869047619047619

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 685
--------------------------------------------------------------
Epoch:  685        1 Batch loss: 0.057246 Batch F1: 0.5
Epoch:  685        2 Batch loss: 0.071886 Batch F1: 0.6666666666666666
Epoch:  685        3 Batch loss: 0.067548 Batch F1: 0.5333333333333333
Epoch:  685        4 Batch loss: 0.064328 Batch F1: 0.9333333333333333
Epoch:  685        5 Batch loss: 0.057900 Batch F1: 0.8571428571428571
Epoch:  685        6 Batch loss: 0.075154 Batch F1: 0.7142857142857143
Epoch:  685        7 Batch loss: 0.072623 Batch F1: 1.0
Epoch:  685        8 Batch loss: 0.075080 Batch F1: 0.7692307692307693
Epoch:  685        9 Batch loss: 0.059367 Batch F1: 0.9411764705882353
Epoch:  685       10 Batch loss: 0.074787 Batch F1: 0.8333333333333333
Epoch:  685       11 Batch loss: 0.063483 Batch F1: 1.0
Epoch:  685       12 Batch loss: 0.070876 Batch F1: 0.9411764705882353
Train Avg Loss  685: 0.067523

Train Avg F1  685: 0.8074732457085397

Val Avg Loss  685: 0.061322

Val Avg F1  685:  0.9232034412955465

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 686
--------------------------------------------------------------
Epoch:  686        1 Batch loss: 0.070240 Batch F1: 0.8750000000000001
Epoch:  686        2 Batch loss: 0.075889 Batch F1: 0.9
Epoch:  686        3 Batch loss: 0.060722 Batch F1: 0.923076923076923
Epoch:  686        4 Batch loss: 0.062829 Batch F1: 1.0
Epoch:  686        5 Batch loss: 0.060251 Batch F1: 0.923076923076923
Epoch:  686        6 Batch loss: 0.057978 Batch F1: 0.9333333333333333
Epoch:  686        7 Batch loss: 0.090934 Batch F1: 0.4444444444444445
Epoch:  686        8 Batch loss: 0.070844 Batch F1: 0.8571428571428571
Epoch:  686        9 Batch loss: 0.038977 Batch F1: 1.0
Epoch:  686       10 Batch loss: 0.063057 Batch F1: 0.9411764705882353
Epoch:  686       11 Batch loss: 0.075716 Batch F1: 0.9
Epoch:  686       12 Batch loss: 0.079971 Batch F1: 0.888888888888889
Train Avg Loss  686: 0.067284

Train Avg F1  686: 0.8821783200459672

Val Avg Loss  686: 0.060894

Val Avg F1  686:  0.9209600706311232

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 687
--------------------------------------------------------------
Epoch:  687        1 Batch loss: 0.045581 Batch F1: 0.8
Epoch:  687        2 Batch loss: 0.044514 Batch F1: 1.0
Epoch:  687        3 Batch loss: 0.074668 Batch F1: 0.9565217391304348
Epoch:  687        4 Batch loss: 0.064118 Batch F1: 0.9411764705882353
Epoch:  687        5 Batch loss: 0.079427 Batch F1: 0.9565217391304348
Epoch:  687        6 Batch loss: 0.066600 Batch F1: 0.9333333333333333
Epoch:  687        7 Batch loss: 0.054619 Batch F1: 1.0
Epoch:  687        8 Batch loss: 0.088786 Batch F1: 0.8421052631578948
Epoch:  687        9 Batch loss: 0.081564 Batch F1: 0.8571428571428571
Epoch:  687       10 Batch loss: 0.051931 Batch F1: 0.8571428571428571
Epoch:  687       11 Batch loss: 0.083231 Batch F1: 0.8235294117647058
Epoch:  687       12 Batch loss: 0.067920 Batch F1: 0.9411764705882353
Train Avg Loss  687: 0.066913

Train Avg F1  687: 0.9090541784982492

Val Avg Loss  687: 0.060862

Val Avg F1  687:  0.9221362229102168

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 688
--------------------------------------------------------------
Epoch:  688        1 Batch loss: 0.067144 Batch F1: 0.8333333333333333
Epoch:  688        2 Batch loss: 0.061092 Batch F1: 0.9411764705882353
Epoch:  688        3 Batch loss: 0.081454 Batch F1: 0.8421052631578948
Epoch:  688        4 Batch loss: 0.068779 Batch F1: 0.9333333333333333
Epoch:  688        5 Batch loss: 0.062098 Batch F1: 0.9411764705882353
Epoch:  688        6 Batch loss: 0.078191 Batch F1: 0.33333333333333337
Epoch:  688        7 Batch loss: 0.060533 Batch F1: 0.6153846153846153
Epoch:  688        8 Batch loss: 0.051322 Batch F1: 0.6
Epoch:  688        9 Batch loss: 0.070078 Batch F1: 0.19999999999999998
Epoch:  688       10 Batch loss: 0.069567 Batch F1: 0.5882352941176471
Epoch:  688       11 Batch loss: 0.059449 Batch F1: 0.0
Epoch:  688       12 Batch loss: 0.076213 Batch F1: 0.9473684210526316
Train Avg Loss  688: 0.067160

Train Avg F1  688: 0.6479538779074382

Val Avg Loss  688: 0.060699

Val Avg F1  688:  0.9240507299717826

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 689
--------------------------------------------------------------
Epoch:  689        1 Batch loss: 0.066086 Batch F1: 1.0
Epoch:  689        2 Batch loss: 0.099650 Batch F1: 0.9444444444444444
Epoch:  689        3 Batch loss: 0.051234 Batch F1: 0.9090909090909091
Epoch:  689        4 Batch loss: 0.064493 Batch F1: 0.923076923076923
Epoch:  689        5 Batch loss: 0.063590 Batch F1: 0.9333333333333333
Epoch:  689        6 Batch loss: 0.050932 Batch F1: 1.0
Epoch:  689        7 Batch loss: 0.079861 Batch F1: 0.8
Epoch:  689        8 Batch loss: 0.057880 Batch F1: 0.7692307692307693
Epoch:  689        9 Batch loss: 0.071414 Batch F1: 1.0
Epoch:  689       10 Batch loss: 0.050618 Batch F1: 0.8
Epoch:  689       11 Batch loss: 0.052968 Batch F1: 1.0
Epoch:  689       12 Batch loss: 0.106750 Batch F1: 0.88
Train Avg Loss  689: 0.067957

Train Avg F1  689: 0.9132646982646984

Val Avg Loss  689: 0.060745

Val Avg F1  689:  0.9156746031746031

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 690
--------------------------------------------------------------
Epoch:  690        1 Batch loss: 0.065270 Batch F1: 0.9333333333333333
Epoch:  690        2 Batch loss: 0.063237 Batch F1: 1.0
Epoch:  690        3 Batch loss: 0.057308 Batch F1: 0.888888888888889
Epoch:  690        4 Batch loss: 0.073124 Batch F1: 0.9600000000000001
Epoch:  690        5 Batch loss: 0.073715 Batch F1: 0.5454545454545454
Epoch:  690        6 Batch loss: 0.069811 Batch F1: 1.0
Epoch:  690        7 Batch loss: 0.075060 Batch F1: 0.888888888888889
Epoch:  690        8 Batch loss: 0.059244 Batch F1: 1.0
Epoch:  690        9 Batch loss: 0.055751 Batch F1: 1.0
Epoch:  690       10 Batch loss: 0.072937 Batch F1: 0.9
Epoch:  690       11 Batch loss: 0.063991 Batch F1: 0.923076923076923
Epoch:  690       12 Batch loss: 0.076735 Batch F1: 0.8235294117647058
Train Avg Loss  690: 0.067182

Train Avg F1  690: 0.9052643326172739

Val Avg Loss  690: 0.060976

Val Avg F1  690:  0.9173116615067081

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 691
--------------------------------------------------------------
Epoch:  691        1 Batch loss: 0.062917 Batch F1: 1.0
Epoch:  691        2 Batch loss: 0.061595 Batch F1: 1.0
Epoch:  691        3 Batch loss: 0.090327 Batch F1: 0.15384615384615385
Epoch:  691        4 Batch loss: 0.066783 Batch F1: 0.6153846153846153
Epoch:  691        5 Batch loss: 0.049529 Batch F1: 0.7499999999999999
Epoch:  691        6 Batch loss: 0.076873 Batch F1: 0.9090909090909091
Epoch:  691        7 Batch loss: 0.061829 Batch F1: 0.9523809523809523
Epoch:  691        8 Batch loss: 0.049758 Batch F1: 0.888888888888889
Epoch:  691        9 Batch loss: 0.073968 Batch F1: 1.0
Epoch:  691       10 Batch loss: 0.061342 Batch F1: 0.8571428571428571
Epoch:  691       11 Batch loss: 0.065382 Batch F1: 1.0
Epoch:  691       12 Batch loss: 0.091107 Batch F1: 0.8
Train Avg Loss  691: 0.067618

Train Avg F1  691: 0.8272278647278649

Val Avg Loss  691: 0.061632

Val Avg F1  691:  0.9147714604236343

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 692
--------------------------------------------------------------
Epoch:  692        1 Batch loss: 0.057976 Batch F1: 0.9090909090909091
Epoch:  692        2 Batch loss: 0.081672 Batch F1: 0.7777777777777778
Epoch:  692        3 Batch loss: 0.065613 Batch F1: 0.9411764705882353
Epoch:  692        4 Batch loss: 0.052594 Batch F1: 1.0
Epoch:  692        5 Batch loss: 0.055228 Batch F1: 0.7272727272727273
Epoch:  692        6 Batch loss: 0.084208 Batch F1: 0.47058823529411764
Epoch:  692        7 Batch loss: 0.052122 Batch F1: 0.5
Epoch:  692        8 Batch loss: 0.063078 Batch F1: 0.5454545454545454
Epoch:  692        9 Batch loss: 0.090800 Batch F1: 0.5714285714285715
Epoch:  692       10 Batch loss: 0.064435 Batch F1: 0.6153846153846153
Epoch:  692       11 Batch loss: 0.077791 Batch F1: 0.5882352941176471
Epoch:  692       12 Batch loss: 0.075937 Batch F1: 0.8571428571428571
Train Avg Loss  692: 0.068455

Train Avg F1  692: 0.7086293336293337

Val Avg Loss  692: 0.062843

Val Avg F1  692:  0.930102657004831

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 693
--------------------------------------------------------------
Epoch:  693        1 Batch loss: 0.054281 Batch F1: 1.0
Epoch:  693        2 Batch loss: 0.062274 Batch F1: 0.9411764705882353
Epoch:  693        3 Batch loss: 0.091614 Batch F1: 0.9166666666666666
Epoch:  693        4 Batch loss: 0.057220 Batch F1: 0.9473684210526316
Epoch:  693        5 Batch loss: 0.059056 Batch F1: 0.8571428571428571
Epoch:  693        6 Batch loss: 0.050185 Batch F1: 1.0
Epoch:  693        7 Batch loss: 0.076789 Batch F1: 0.9166666666666666
Epoch:  693        8 Batch loss: 0.081296 Batch F1: 0.888888888888889
Epoch:  693        9 Batch loss: 0.067147 Batch F1: 0.7692307692307693
Epoch:  693       10 Batch loss: 0.075411 Batch F1: 0.9473684210526316
Epoch:  693       11 Batch loss: 0.068617 Batch F1: 0.9333333333333333
Epoch:  693       12 Batch loss: 0.066244 Batch F1: 0.9090909090909091
Train Avg Loss  693: 0.067511

Train Avg F1  693: 0.9189111169761325

Val Avg Loss  693: 0.062927

Val Avg F1  693:  0.9054818744473916

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 694
--------------------------------------------------------------
Epoch:  694        1 Batch loss: 0.078116 Batch F1: 0.9523809523809523
Epoch:  694        2 Batch loss: 0.113636 Batch F1: 0.6086956521739131
Epoch:  694        3 Batch loss: 0.060714 Batch F1: 0.8
Epoch:  694        4 Batch loss: 0.059814 Batch F1: 0.8571428571428571
Epoch:  694        5 Batch loss: 0.065866 Batch F1: 0.9473684210526316
Epoch:  694        6 Batch loss: 0.060746 Batch F1: 0.9090909090909091
Epoch:  694        7 Batch loss: 0.066005 Batch F1: 0.9473684210526316
Epoch:  694        8 Batch loss: 0.069506 Batch F1: 1.0
Epoch:  694        9 Batch loss: 0.057021 Batch F1: 1.0
Epoch:  694       10 Batch loss: 0.049801 Batch F1: 0.8
Epoch:  694       11 Batch loss: 0.058001 Batch F1: 1.0
Epoch:  694       12 Batch loss: 0.083605 Batch F1: 0.5333333333333333
Train Avg Loss  694: 0.068569

Train Avg F1  694: 0.862948378852269

Val Avg Loss  694: 0.061297

Val Avg F1  694:  0.5489203778677463

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 695
--------------------------------------------------------------
Epoch:  695        1 Batch loss: 0.054571 Batch F1: 0.8421052631578948
Epoch:  695        2 Batch loss: 0.079942 Batch F1: 0.4
Epoch:  695        3 Batch loss: 0.056278 Batch F1: 0.6
Epoch:  695        4 Batch loss: 0.086676 Batch F1: 0.4
Epoch:  695        5 Batch loss: 0.082111 Batch F1: 0.9166666666666666
Epoch:  695        6 Batch loss: 0.065896 Batch F1: 1.0
Epoch:  695        7 Batch loss: 0.074549 Batch F1: 0.7272727272727273
Epoch:  695        8 Batch loss: 0.074316 Batch F1: 1.0
Epoch:  695        9 Batch loss: 0.033528 Batch F1: 1.0
Epoch:  695       10 Batch loss: 0.065918 Batch F1: 0.9333333333333333
Epoch:  695       11 Batch loss: 0.088022 Batch F1: 0.9166666666666666
Epoch:  695       12 Batch loss: 0.058227 Batch F1: 0.9090909090909091
Train Avg Loss  695: 0.068336

Train Avg F1  695: 0.8037612971823497

Val Avg Loss  695: 0.062120

Val Avg F1  695:  0.917436974789916

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 696
--------------------------------------------------------------
Epoch:  696        1 Batch loss: 0.074884 Batch F1: 0.8750000000000001
Epoch:  696        2 Batch loss: 0.058491 Batch F1: 0.0
Epoch:  696        3 Batch loss: 0.087992 Batch F1: 0.5882352941176471
Epoch:  696        4 Batch loss: 0.055872 Batch F1: 0.5
Epoch:  696        5 Batch loss: 0.080430 Batch F1: 0.42857142857142855
Epoch:  696        6 Batch loss: 0.040313 Batch F1: 0.888888888888889
Epoch:  696        7 Batch loss: 0.086276 Batch F1: 0.9090909090909091
Epoch:  696        8 Batch loss: 0.071493 Batch F1: 0.9523809523809523
Epoch:  696        9 Batch loss: 0.076701 Batch F1: 0.9
Epoch:  696       10 Batch loss: 0.066892 Batch F1: 0.5714285714285715
Epoch:  696       11 Batch loss: 0.063954 Batch F1: 0.4444444444444445
Epoch:  696       12 Batch loss: 0.077276 Batch F1: 0.3636363636363636
Train Avg Loss  696: 0.070048

Train Avg F1  696: 0.6184730710466004

Val Avg Loss  696: 0.062439

Val Avg F1  696:  0.9360187553282182

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 697
--------------------------------------------------------------
Epoch:  697        1 Batch loss: 0.071441 Batch F1: 0.8235294117647058
Epoch:  697        2 Batch loss: 0.069598 Batch F1: 1.0
Epoch:  697        3 Batch loss: 0.057233 Batch F1: 1.0
Epoch:  697        4 Batch loss: 0.079085 Batch F1: 0.47058823529411764
Epoch:  697        5 Batch loss: 0.048349 Batch F1: 0.33333333333333337
Epoch:  697        6 Batch loss: 0.093969 Batch F1: 0.5263157894736842
Epoch:  697        7 Batch loss: 0.068024 Batch F1: 0.9411764705882353
Epoch:  697        8 Batch loss: 0.071690 Batch F1: 0.6666666666666666
Epoch:  697        9 Batch loss: 0.086714 Batch F1: 0.4615384615384615
Epoch:  697       10 Batch loss: 0.079924 Batch F1: 0.823529411764706
Epoch:  697       11 Batch loss: 0.069248 Batch F1: 0.8
Epoch:  697       12 Batch loss: 0.070101 Batch F1: 1.0
Train Avg Loss  697: 0.072115

Train Avg F1  697: 0.7372231483686592

Val Avg Loss  697: 0.065529

Val Avg F1  697:  0.9268525592055004

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 698
--------------------------------------------------------------
Epoch:  698        1 Batch loss: 0.075867 Batch F1: 0.9600000000000001
Epoch:  698        2 Batch loss: 0.079214 Batch F1: 0.8571428571428571
Epoch:  698        3 Batch loss: 0.070001 Batch F1: 0.9090909090909091
Epoch:  698        4 Batch loss: 0.060360 Batch F1: 0.5454545454545454
Epoch:  698        5 Batch loss: 0.084976 Batch F1: 0.5882352941176471
Epoch:  698        6 Batch loss: 0.073234 Batch F1: 0.9090909090909091
Epoch:  698        7 Batch loss: 0.076715 Batch F1: 0.9090909090909091
Epoch:  698        8 Batch loss: 0.071410 Batch F1: 0.6
Epoch:  698        9 Batch loss: 0.035139 Batch F1: 0.6666666666666666
Epoch:  698       10 Batch loss: 0.106636 Batch F1: 0.5882352941176471
Epoch:  698       11 Batch loss: 0.070914 Batch F1: 0.6666666666666666
Epoch:  698       12 Batch loss: 0.101037 Batch F1: 0.7999999999999999
Train Avg Loss  698: 0.075459

Train Avg F1  698: 0.7499728376198965

Val Avg Loss  698: 0.066498

Val Avg F1  698:  0.9262663398692811

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 699
--------------------------------------------------------------
Epoch:  699        1 Batch loss: 0.064687 Batch F1: 0.888888888888889
Epoch:  699        2 Batch loss: 0.063791 Batch F1: 0.8
Epoch:  699        3 Batch loss: 0.064861 Batch F1: 0.7272727272727273
Epoch:  699        4 Batch loss: 0.089944 Batch F1: 0.0
Epoch:  699        5 Batch loss: 0.070666 Batch F1: 0.7272727272727273
Epoch:  699        6 Batch loss: 0.061428 Batch F1: 0.7272727272727273
Epoch:  699        7 Batch loss: 0.067791 Batch F1: 0.5454545454545454
Epoch:  699        8 Batch loss: 0.104783 Batch F1: 0.6086956521739131
Epoch:  699        9 Batch loss: 0.091215 Batch F1: 0.8750000000000001
Epoch:  699       10 Batch loss: 0.081540 Batch F1: 0.7058823529411764
Epoch:  699       11 Batch loss: 0.059376 Batch F1: 0.4
Epoch:  699       12 Batch loss: 0.077040 Batch F1: 0.0
Train Avg Loss  699: 0.074760

Train Avg F1  699: 0.5838116351063922

Val Avg Loss  699: 0.065209

Val Avg F1  699:  0.9326625386996904

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 700
--------------------------------------------------------------
Epoch:  700        1 Batch loss: 0.078698 Batch F1: 0.8750000000000001
Epoch:  700        2 Batch loss: 0.049438 Batch F1: 1.0
Epoch:  700        3 Batch loss: 0.088493 Batch F1: 0.47058823529411764
Epoch:  700        4 Batch loss: 0.072252 Batch F1: 0.9411764705882353
Epoch:  700        5 Batch loss: 0.061441 Batch F1: 0.9411764705882353
Epoch:  700        6 Batch loss: 0.055598 Batch F1: 0.5714285714285715
Epoch:  700        7 Batch loss: 0.070788 Batch F1: 0.4615384615384615
Epoch:  700        8 Batch loss: 0.068587 Batch F1: 0.7058823529411764
Epoch:  700        9 Batch loss: 0.068697 Batch F1: 0.9411764705882353
Epoch:  700       10 Batch loss: 0.085336 Batch F1: 0.888888888888889
Epoch:  700       11 Batch loss: 0.066520 Batch F1: 1.0
Epoch:  700       12 Batch loss: 0.078417 Batch F1: 0.888888888888889
Train Avg Loss  700: 0.070355

Train Avg F1  700: 0.807145400895401

Val Avg Loss  700: 0.062071

Val Avg F1  700:  0.9313168449197862

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 701
--------------------------------------------------------------
Epoch:  701        1 Batch loss: 0.062736 Batch F1: 0.9473684210526316
Epoch:  701        2 Batch loss: 0.071265 Batch F1: 0.9
Epoch:  701        3 Batch loss: 0.051685 Batch F1: 0.9090909090909091
Epoch:  701        4 Batch loss: 0.071208 Batch F1: 1.0
Epoch:  701        5 Batch loss: 0.071756 Batch F1: 0.9565217391304348
Epoch:  701        6 Batch loss: 0.080353 Batch F1: 0.9090909090909091
Epoch:  701        7 Batch loss: 0.060624 Batch F1: 0.8333333333333333
Epoch:  701        8 Batch loss: 0.093695 Batch F1: 0.8
Epoch:  701        9 Batch loss: 0.067758 Batch F1: 0.7272727272727273
Epoch:  701       10 Batch loss: 0.055225 Batch F1: 1.0
Epoch:  701       11 Batch loss: 0.067645 Batch F1: 0.7777777777777778
Epoch:  701       12 Batch loss: 0.072673 Batch F1: 0.5454545454545454
Train Avg Loss  701: 0.068885

Train Avg F1  701: 0.8588258635169391

Val Avg Loss  701: 0.061819

Val Avg F1  701:  0.7395833333333333

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 702
--------------------------------------------------------------
Epoch:  702        1 Batch loss: 0.070485 Batch F1: 0.7000000000000001
Epoch:  702        2 Batch loss: 0.057585 Batch F1: 0.9333333333333333
Epoch:  702        3 Batch loss: 0.055489 Batch F1: 0.9090909090909091
Epoch:  702        4 Batch loss: 0.063456 Batch F1: 0.923076923076923
Epoch:  702        5 Batch loss: 0.075699 Batch F1: 0.5454545454545454
Epoch:  702        6 Batch loss: 0.048488 Batch F1: 0.8333333333333333
Epoch:  702        7 Batch loss: 0.069966 Batch F1: 0.7499999999999999
Epoch:  702        8 Batch loss: 0.093247 Batch F1: 0.9166666666666666
Epoch:  702        9 Batch loss: 0.060362 Batch F1: 0.8333333333333333
Epoch:  702       10 Batch loss: 0.092497 Batch F1: 0.923076923076923
Epoch:  702       11 Batch loss: 0.066144 Batch F1: 1.0
Epoch:  702       12 Batch loss: 0.069416 Batch F1: 0.923076923076923
Train Avg Loss  702: 0.068569

Train Avg F1  702: 0.8492035742035742

Val Avg Loss  702: 0.061540

Val Avg F1  702:  0.9186274509803921

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 703
--------------------------------------------------------------
Epoch:  703        1 Batch loss: 0.099664 Batch F1: 0.7058823529411764
Epoch:  703        2 Batch loss: 0.060246 Batch F1: 0.7777777777777778
Epoch:  703        3 Batch loss: 0.061075 Batch F1: 0.2857142857142857
Epoch:  703        4 Batch loss: 0.071077 Batch F1: 0.5333333333333333
Epoch:  703        5 Batch loss: 0.076433 Batch F1: 0.4615384615384615
Epoch:  703        6 Batch loss: 0.047071 Batch F1: 0.888888888888889
Epoch:  703        7 Batch loss: 0.072315 Batch F1: 0.625
Epoch:  703        8 Batch loss: 0.056891 Batch F1: 0.7142857142857143
Epoch:  703        9 Batch loss: 0.071322 Batch F1: 0.4615384615384615
Epoch:  703       10 Batch loss: 0.084254 Batch F1: 0.9600000000000001
Epoch:  703       11 Batch loss: 0.066053 Batch F1: 0.8571428571428571
Epoch:  703       12 Batch loss: 0.053068 Batch F1: 1.0
Train Avg Loss  703: 0.068289

Train Avg F1  703: 0.6892585110967463

Val Avg Loss  703: 0.062341

Val Avg F1  703:  0.7339015151515151

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 704
--------------------------------------------------------------
Epoch:  704        1 Batch loss: 0.040622 Batch F1: 0.0
Epoch:  704        2 Batch loss: 0.062405 Batch F1: 0.6666666666666666
Epoch:  704        3 Batch loss: 0.063451 Batch F1: 0.4444444444444445
Epoch:  704        4 Batch loss: 0.063850 Batch F1: 0.7142857142857143
Epoch:  704        5 Batch loss: 0.096031 Batch F1: 0.42857142857142855
Epoch:  704        6 Batch loss: 0.080075 Batch F1: 0.42857142857142855
Epoch:  704        7 Batch loss: 0.074947 Batch F1: 0.888888888888889
Epoch:  704        8 Batch loss: 0.090783 Batch F1: 0.8695652173913044
Epoch:  704        9 Batch loss: 0.063381 Batch F1: 0.923076923076923
Epoch:  704       10 Batch loss: 0.069828 Batch F1: 1.0
Epoch:  704       11 Batch loss: 0.075969 Batch F1: 1.0
Epoch:  704       12 Batch loss: 0.068288 Batch F1: 0.9411764705882353
Train Avg Loss  704: 0.070803

Train Avg F1  704: 0.6921039318737529

Val Avg Loss  704: 0.063023

Val Avg F1  704:  0.9249373433583961

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 705
--------------------------------------------------------------
Epoch:  705        1 Batch loss: 0.073245 Batch F1: 0.9565217391304348
Epoch:  705        2 Batch loss: 0.063290 Batch F1: 0.8750000000000001
Epoch:  705        3 Batch loss: 0.062656 Batch F1: 0.8333333333333333
Epoch:  705        4 Batch loss: 0.057998 Batch F1: 0.7499999999999999
Epoch:  705        5 Batch loss: 0.056536 Batch F1: 0.7142857142857143
Epoch:  705        6 Batch loss: 0.083391 Batch F1: 0.3076923076923077
Epoch:  705        7 Batch loss: 0.067211 Batch F1: 0.6666666666666666
Epoch:  705        8 Batch loss: 0.067091 Batch F1: 0.19999999999999998
Epoch:  705        9 Batch loss: 0.082419 Batch F1: 0.19999999999999998
Epoch:  705       10 Batch loss: 0.062507 Batch F1: 0.9333333333333333
Epoch:  705       11 Batch loss: 0.077642 Batch F1: 0.888888888888889
Epoch:  705       12 Batch loss: 0.071277 Batch F1: 0.9411764705882353
Train Avg Loss  705: 0.068772

Train Avg F1  705: 0.688908204493243

Val Avg Loss  705: 0.061447

Val Avg F1  705:  0.9080952380952381

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 706
--------------------------------------------------------------
Epoch:  706        1 Batch loss: 0.054026 Batch F1: 0.8333333333333333
Epoch:  706        2 Batch loss: 0.078978 Batch F1: 1.0
Epoch:  706        3 Batch loss: 0.057445 Batch F1: 1.0
Epoch:  706        4 Batch loss: 0.070266 Batch F1: 0.8750000000000001
Epoch:  706        5 Batch loss: 0.049148 Batch F1: 0.5714285714285715
Epoch:  706        6 Batch loss: 0.086350 Batch F1: 0.42857142857142855
Epoch:  706        7 Batch loss: 0.076393 Batch F1: 0.5
Epoch:  706        8 Batch loss: 0.076915 Batch F1: 0.18181818181818182
Epoch:  706        9 Batch loss: 0.077677 Batch F1: 0.33333333333333337
Epoch:  706       10 Batch loss: 0.073710 Batch F1: 0.8750000000000001
Epoch:  706       11 Batch loss: 0.060379 Batch F1: 0.8333333333333333
Epoch:  706       12 Batch loss: 0.062257 Batch F1: 1.0
Train Avg Loss  706: 0.068629

Train Avg F1  706: 0.702651515151515

Val Avg Loss  706: 0.062141

Val Avg F1  706:  0.9269607843137254

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 707
--------------------------------------------------------------
Epoch:  707        1 Batch loss: 0.094057 Batch F1: 0.896551724137931
Epoch:  707        2 Batch loss: 0.057040 Batch F1: 0.9333333333333333
Epoch:  707        3 Batch loss: 0.071773 Batch F1: 0.9411764705882353
Epoch:  707        4 Batch loss: 0.073550 Batch F1: 0.9473684210526316
Epoch:  707        5 Batch loss: 0.074186 Batch F1: 0.888888888888889
Epoch:  707        6 Batch loss: 0.050862 Batch F1: 1.0
Epoch:  707        7 Batch loss: 0.088908 Batch F1: 0.8
Epoch:  707        8 Batch loss: 0.063886 Batch F1: 1.0
Epoch:  707        9 Batch loss: 0.055405 Batch F1: 0.8
Epoch:  707       10 Batch loss: 0.056214 Batch F1: 1.0
Epoch:  707       11 Batch loss: 0.063855 Batch F1: 0.8571428571428571
Epoch:  707       12 Batch loss: 0.048055 Batch F1: 0.0
Train Avg Loss  707: 0.066482

Train Avg F1  707: 0.8387051412619898

Val Avg Loss  707: 0.064948

Val Avg F1  707:  0.560994560994561

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 708
--------------------------------------------------------------
Epoch:  708        1 Batch loss: 0.059211 Batch F1: 0.2857142857142857
Epoch:  708        2 Batch loss: 0.118092 Batch F1: 0.5217391304347826
Epoch:  708        3 Batch loss: 0.056011 Batch F1: 0.4444444444444445
Epoch:  708        4 Batch loss: 0.078451 Batch F1: 0.4615384615384615
Epoch:  708        5 Batch loss: 0.081261 Batch F1: 0.8571428571428571
Epoch:  708        6 Batch loss: 0.082325 Batch F1: 0.7692307692307693
Epoch:  708        7 Batch loss: 0.072295 Batch F1: 0.8571428571428571
Epoch:  708        8 Batch loss: 0.070749 Batch F1: 0.7777777777777778
Epoch:  708        9 Batch loss: 0.051429 Batch F1: 1.0
Epoch:  708       10 Batch loss: 0.068974 Batch F1: 0.9333333333333333
Epoch:  708       11 Batch loss: 0.092394 Batch F1: 0.16666666666666669
Epoch:  708       12 Batch loss: 0.096835 Batch F1: 0.8571428571428571
Train Avg Loss  708: 0.077336

Train Avg F1  708: 0.6609894533807578

Val Avg Loss  708: 0.071287

Val Avg F1  708:  0.9206115779645191

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 709
--------------------------------------------------------------
Epoch:  709        1 Batch loss: 0.106686 Batch F1: 0.846153846153846
Epoch:  709        2 Batch loss: 0.076005 Batch F1: 1.0
Epoch:  709        3 Batch loss: 0.077618 Batch F1: 0.4615384615384615
Epoch:  709        4 Batch loss: 0.065758 Batch F1: 0.8421052631578948
Epoch:  709        5 Batch loss: 0.079251 Batch F1: 0.2222222222222222
Epoch:  709        6 Batch loss: 0.066013 Batch F1: 0.7499999999999999
Epoch:  709        7 Batch loss: 0.072409 Batch F1: 0.25
Epoch:  709        8 Batch loss: 0.064973 Batch F1: 0.7142857142857143
Epoch:  709        9 Batch loss: 0.095433 Batch F1: 0.47058823529411764
Epoch:  709       10 Batch loss: 0.064323 Batch F1: 0.8
Epoch:  709       11 Batch loss: 0.063475 Batch F1: 0.5454545454545454
Epoch:  709       12 Batch loss: 0.049097 Batch F1: 0.4
Train Avg Loss  709: 0.073420

Train Avg F1  709: 0.6085290240089002

Val Avg Loss  709: 0.074038

Val Avg F1  709:  0.304004329004329

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 710
--------------------------------------------------------------
Epoch:  710        1 Batch loss: 0.084588 Batch F1: 0.19999999999999998
Epoch:  710        2 Batch loss: 0.070783 Batch F1: 0.0
Epoch:  710        3 Batch loss: 0.082630 Batch F1: 0.19999999999999998
Epoch:  710        4 Batch loss: 0.082585 Batch F1: 0.7368421052631579
Epoch:  710        5 Batch loss: 0.058768 Batch F1: 0.888888888888889
Epoch:  710        6 Batch loss: 0.068696 Batch F1: 0.9411764705882353
Epoch:  710        7 Batch loss: 0.069553 Batch F1: 0.6666666666666666
Epoch:  710        8 Batch loss: 0.069842 Batch F1: 0.5
Epoch:  710        9 Batch loss: 0.088653 Batch F1: 0.375
Epoch:  710       10 Batch loss: 0.072075 Batch F1: 0.5
Epoch:  710       11 Batch loss: 0.070993 Batch F1: 0.9473684210526316
Epoch:  710       12 Batch loss: 0.063098 Batch F1: 0.9090909090909091
Train Avg Loss  710: 0.073522

Train Avg F1  710: 0.5720861217958741

Val Avg Loss  710: 0.062976

Val Avg F1  710:  0.9152356902356903

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 711
--------------------------------------------------------------
Epoch:  711        1 Batch loss: 0.067766 Batch F1: 0.8750000000000001
Epoch:  711        2 Batch loss: 0.064561 Batch F1: 1.0
Epoch:  711        3 Batch loss: 0.054791 Batch F1: 0.0
Epoch:  711        4 Batch loss: 0.072692 Batch F1: 0.4615384615384615
Epoch:  711        5 Batch loss: 0.061252 Batch F1: 0.9411764705882353
Epoch:  711        6 Batch loss: 0.080655 Batch F1: 0.7142857142857143
Epoch:  711        7 Batch loss: 0.078511 Batch F1: 0.5
Epoch:  711        8 Batch loss: 0.077260 Batch F1: 0.7058823529411764
Epoch:  711        9 Batch loss: 0.058313 Batch F1: 0.9411764705882353
Epoch:  711       10 Batch loss: 0.070495 Batch F1: 0.9411764705882353
Epoch:  711       11 Batch loss: 0.070218 Batch F1: 0.9333333333333333
Epoch:  711       12 Batch loss: 0.072627 Batch F1: 0.888888888888889
Train Avg Loss  711: 0.069095

Train Avg F1  711: 0.7418715135626902

Val Avg Loss  711: 0.062069

Val Avg F1  711:  0.9122073578595318

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 712
--------------------------------------------------------------
Epoch:  712        1 Batch loss: 0.065081 Batch F1: 1.0
Epoch:  712        2 Batch loss: 0.092531 Batch F1: 0.9285714285714286
Epoch:  712        3 Batch loss: 0.061063 Batch F1: 0.9523809523809523
Epoch:  712        4 Batch loss: 0.056247 Batch F1: 0.888888888888889
Epoch:  712        5 Batch loss: 0.058547 Batch F1: 0.9333333333333333
Epoch:  712        6 Batch loss: 0.063426 Batch F1: 0.923076923076923
Epoch:  712        7 Batch loss: 0.056261 Batch F1: 1.0
Epoch:  712        8 Batch loss: 0.072199 Batch F1: 0.9565217391304348
Epoch:  712        9 Batch loss: 0.087753 Batch F1: 0.8235294117647058
Epoch:  712       10 Batch loss: 0.066607 Batch F1: 0.7499999999999999
Epoch:  712       11 Batch loss: 0.078924 Batch F1: 0.8235294117647058
Epoch:  712       12 Batch loss: 0.064583 Batch F1: 0.923076923076923
Train Avg Loss  712: 0.068602

Train Avg F1  712: 0.9085757509990248

Val Avg Loss  712: 0.061381

Val Avg F1  712:  0.9206115779645191

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 713
--------------------------------------------------------------
Epoch:  713        1 Batch loss: 0.050140 Batch F1: 1.0
Epoch:  713        2 Batch loss: 0.057274 Batch F1: 0.7692307692307693
Epoch:  713        3 Batch loss: 0.080260 Batch F1: 0.6153846153846153
Epoch:  713        4 Batch loss: 0.059142 Batch F1: 0.8
Epoch:  713        5 Batch loss: 0.079795 Batch F1: 0.47058823529411764
Epoch:  713        6 Batch loss: 0.061775 Batch F1: 0.5454545454545454
Epoch:  713        7 Batch loss: 0.063099 Batch F1: 1.0
Epoch:  713        8 Batch loss: 0.079738 Batch F1: 0.7777777777777778
Epoch:  713        9 Batch loss: 0.063934 Batch F1: 0.923076923076923
Epoch:  713       10 Batch loss: 0.084426 Batch F1: 0.9166666666666666
Epoch:  713       11 Batch loss: 0.065101 Batch F1: 0.9411764705882353
Epoch:  713       12 Batch loss: 0.068908 Batch F1: 0.923076923076923
Train Avg Loss  713: 0.067799

Train Avg F1  713: 0.8068694105458812

Val Avg Loss  713: 0.061691

Val Avg F1  713:  0.9353146853146853

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 714
--------------------------------------------------------------
Epoch:  714        1 Batch loss: 0.067953 Batch F1: 1.0
Epoch:  714        2 Batch loss: 0.067138 Batch F1: 1.0
Epoch:  714        3 Batch loss: 0.057241 Batch F1: 0.923076923076923
Epoch:  714        4 Batch loss: 0.060092 Batch F1: 0.9473684210526316
Epoch:  714        5 Batch loss: 0.063257 Batch F1: 0.5454545454545454
Epoch:  714        6 Batch loss: 0.056544 Batch F1: 0.5
Epoch:  714        7 Batch loss: 0.083578 Batch F1: 0.5882352941176471
Epoch:  714        8 Batch loss: 0.073477 Batch F1: 0.2222222222222222
Epoch:  714        9 Batch loss: 0.090175 Batch F1: 0.8235294117647058
Epoch:  714       10 Batch loss: 0.050214 Batch F1: 0.8571428571428571
Epoch:  714       11 Batch loss: 0.067999 Batch F1: 0.6666666666666666
Epoch:  714       12 Batch loss: 0.080109 Batch F1: 0.6666666666666666
Train Avg Loss  714: 0.068148

Train Avg F1  714: 0.7283635840137387

Val Avg Loss  714: 0.061449

Val Avg F1  714:  0.9246288798920378

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 715
--------------------------------------------------------------
Epoch:  715        1 Batch loss: 0.065002 Batch F1: 0.9333333333333333
Epoch:  715        2 Batch loss: 0.048793 Batch F1: 1.0
Epoch:  715        3 Batch loss: 0.075241 Batch F1: 0.8571428571428571
Epoch:  715        4 Batch loss: 0.079329 Batch F1: 0.9600000000000001
Epoch:  715        5 Batch loss: 0.061488 Batch F1: 0.7499999999999999
Epoch:  715        6 Batch loss: 0.070716 Batch F1: 1.0
Epoch:  715        7 Batch loss: 0.086972 Batch F1: 0.9333333333333333
Epoch:  715        8 Batch loss: 0.057965 Batch F1: 0.9333333333333333
Epoch:  715        9 Batch loss: 0.056114 Batch F1: 0.8333333333333333
Epoch:  715       10 Batch loss: 0.071099 Batch F1: 0.888888888888889
Epoch:  715       11 Batch loss: 0.075987 Batch F1: 0.8235294117647058
Epoch:  715       12 Batch loss: 0.059072 Batch F1: 1.0
Train Avg Loss  715: 0.067315

Train Avg F1  715: 0.9094078742608156

Val Avg Loss  715: 0.061027

Val Avg F1  715:  0.9133500417710945

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 716
--------------------------------------------------------------
Epoch:  716        1 Batch loss: 0.070194 Batch F1: 1.0
Epoch:  716        2 Batch loss: 0.060483 Batch F1: 1.0
Epoch:  716        3 Batch loss: 0.057502 Batch F1: 0.25
Epoch:  716        4 Batch loss: 0.079667 Batch F1: 0.5555555555555556
Epoch:  716        5 Batch loss: 0.067656 Batch F1: 0.3636363636363636
Epoch:  716        6 Batch loss: 0.066944 Batch F1: 0.7499999999999999
Epoch:  716        7 Batch loss: 0.058523 Batch F1: 0.25
Epoch:  716        8 Batch loss: 0.076210 Batch F1: 0.33333333333333337
Epoch:  716        9 Batch loss: 0.090602 Batch F1: 0.7777777777777778
Epoch:  716       10 Batch loss: 0.068476 Batch F1: 0.7272727272727273
Epoch:  716       11 Batch loss: 0.060341 Batch F1: 0.8750000000000001
Epoch:  716       12 Batch loss: 0.059863 Batch F1: 0.9333333333333333
Train Avg Loss  716: 0.068038

Train Avg F1  716: 0.6513257575757575

Val Avg Loss  716: 0.063542

Val Avg F1  716:  0.936421937195931

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 717
--------------------------------------------------------------
Epoch:  717        1 Batch loss: 0.058653 Batch F1: 1.0
Epoch:  717        2 Batch loss: 0.083848 Batch F1: 0.8571428571428571
Epoch:  717        3 Batch loss: 0.072824 Batch F1: 0.9333333333333333
Epoch:  717        4 Batch loss: 0.076245 Batch F1: 0.9600000000000001
Epoch:  717        5 Batch loss: 0.050571 Batch F1: 0.7499999999999999
Epoch:  717        6 Batch loss: 0.070391 Batch F1: 0.9473684210526316
Epoch:  717        7 Batch loss: 0.058120 Batch F1: 1.0
Epoch:  717        8 Batch loss: 0.064110 Batch F1: 0.4444444444444445
Epoch:  717        9 Batch loss: 0.068543 Batch F1: 0.4
Epoch:  717       10 Batch loss: 0.067051 Batch F1: 0.6153846153846153
Epoch:  717       11 Batch loss: 0.079176 Batch F1: 0.0
Epoch:  717       12 Batch loss: 0.074419 Batch F1: 0.3636363636363636
Train Avg Loss  717: 0.068663

Train Avg F1  717: 0.6892758362495205

Val Avg Loss  717: 0.063009

Val Avg F1  717:  0.564712918660287

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 718
--------------------------------------------------------------
Epoch:  718        1 Batch loss: 0.070749 Batch F1: 0.5333333333333333
Epoch:  718        2 Batch loss: 0.051023 Batch F1: 0.5714285714285715
Epoch:  718        3 Batch loss: 0.084742 Batch F1: 0.9473684210526316
Epoch:  718        4 Batch loss: 0.060711 Batch F1: 0.9333333333333333
Epoch:  718        5 Batch loss: 0.088116 Batch F1: 0.8181818181818181
Epoch:  718        6 Batch loss: 0.084160 Batch F1: 0.8571428571428571
Epoch:  718        7 Batch loss: 0.062938 Batch F1: 0.9411764705882353
Epoch:  718        8 Batch loss: 0.070136 Batch F1: 0.9473684210526316
Epoch:  718        9 Batch loss: 0.057879 Batch F1: 1.0
Epoch:  718       10 Batch loss: 0.068567 Batch F1: 0.8571428571428571
Epoch:  718       11 Batch loss: 0.071363 Batch F1: 0.9411764705882353
Epoch:  718       12 Batch loss: 0.054257 Batch F1: 1.0
Train Avg Loss  718: 0.068720

Train Avg F1  718: 0.8623043794870421

Val Avg Loss  718: 0.061892

Val Avg F1  718:  0.5810064935064935

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 719
--------------------------------------------------------------
Epoch:  719        1 Batch loss: 0.068745 Batch F1: 0.5333333333333333
Epoch:  719        2 Batch loss: 0.061080 Batch F1: 0.6153846153846153
Epoch:  719        3 Batch loss: 0.043163 Batch F1: 0.9090909090909091
Epoch:  719        4 Batch loss: 0.079909 Batch F1: 0.3636363636363636
Epoch:  719        5 Batch loss: 0.043039 Batch F1: 0.6666666666666666
Epoch:  719        6 Batch loss: 0.086075 Batch F1: 0.33333333333333337
Epoch:  719        7 Batch loss: 0.085768 Batch F1: 0.33333333333333337
Epoch:  719        8 Batch loss: 0.049608 Batch F1: 0.5
Epoch:  719        9 Batch loss: 0.072698 Batch F1: 0.5
Epoch:  719       10 Batch loss: 0.093923 Batch F1: 0.375
Epoch:  719       11 Batch loss: 0.085786 Batch F1: 0.8695652173913044
Epoch:  719       12 Batch loss: 0.060783 Batch F1: 1.0
Train Avg Loss  719: 0.069215

Train Avg F1  719: 0.5832786476808217

Val Avg Loss  719: 0.065284

Val Avg F1  719:  0.9142857142857143

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 720
--------------------------------------------------------------
Epoch:  720        1 Batch loss: 0.070918 Batch F1: 1.0
Epoch:  720        2 Batch loss: 0.072141 Batch F1: 0.923076923076923
Epoch:  720        3 Batch loss: 0.057045 Batch F1: 0.923076923076923
Epoch:  720        4 Batch loss: 0.076051 Batch F1: 0.9523809523809523
Epoch:  720        5 Batch loss: 0.071951 Batch F1: 0.6
Epoch:  720        6 Batch loss: 0.072998 Batch F1: 0.2222222222222222
Epoch:  720        7 Batch loss: 0.085206 Batch F1: 0.5882352941176471
Epoch:  720        8 Batch loss: 0.095934 Batch F1: 0.375
Epoch:  720        9 Batch loss: 0.063032 Batch F1: 0.9411764705882353
Epoch:  720       10 Batch loss: 0.063062 Batch F1: 0.9473684210526316
Epoch:  720       11 Batch loss: 0.082823 Batch F1: 0.9600000000000001
Epoch:  720       12 Batch loss: 0.072686 Batch F1: 1.0
Train Avg Loss  720: 0.073654

Train Avg F1  720: 0.7860447672096279

Val Avg Loss  720: 0.066599

Val Avg F1  720:  0.7014451192082771

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 721
--------------------------------------------------------------
Epoch:  721        1 Batch loss: 0.064593 Batch F1: 0.7692307692307693
Epoch:  721        2 Batch loss: 0.073747 Batch F1: 0.4
Epoch:  721        3 Batch loss: 0.105336 Batch F1: 0.42857142857142855
Epoch:  721        4 Batch loss: 0.058629 Batch F1: 1.0
Epoch:  721        5 Batch loss: 0.073825 Batch F1: 1.0
Epoch:  721        6 Batch loss: 0.055090 Batch F1: 0.9090909090909091
Epoch:  721        7 Batch loss: 0.066903 Batch F1: 0.8
Epoch:  721        8 Batch loss: 0.085517 Batch F1: 0.4
Epoch:  721        9 Batch loss: 0.105122 Batch F1: 0.5714285714285715
Epoch:  721       10 Batch loss: 0.061541 Batch F1: 1.0
Epoch:  721       11 Batch loss: 0.070750 Batch F1: 0.8333333333333333
Epoch:  721       12 Batch loss: 0.067465 Batch F1: 0.8333333333333333
Train Avg Loss  721: 0.074043

Train Avg F1  721: 0.7454156954156955

Val Avg Loss  721: 0.063151

Val Avg F1  721:  0.9149466804265567

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 722
--------------------------------------------------------------
Epoch:  722        1 Batch loss: 0.047483 Batch F1: 1.0
Epoch:  722        2 Batch loss: 0.087283 Batch F1: 0.3636363636363636
Epoch:  722        3 Batch loss: 0.067293 Batch F1: 0.25
Epoch:  722        4 Batch loss: 0.064802 Batch F1: 0.6666666666666666
Epoch:  722        5 Batch loss: 0.067563 Batch F1: 0.7499999999999999
Epoch:  722        6 Batch loss: 0.064202 Batch F1: 0.9333333333333333
Epoch:  722        7 Batch loss: 0.068331 Batch F1: 0.8750000000000001
Epoch:  722        8 Batch loss: 0.070145 Batch F1: 0.8750000000000001
Epoch:  722        9 Batch loss: 0.067302 Batch F1: 0.5
Epoch:  722       10 Batch loss: 0.077934 Batch F1: 0.5882352941176471
Epoch:  722       11 Batch loss: 0.092718 Batch F1: 0.33333333333333337
Epoch:  722       12 Batch loss: 0.069838 Batch F1: 0.9333333333333333
Train Avg Loss  722: 0.070408

Train Avg F1  722: 0.6723781937017231

Val Avg Loss  722: 0.063086

Val Avg F1  722:  0.9267676767676768

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 723
--------------------------------------------------------------
Epoch:  723        1 Batch loss: 0.077376 Batch F1: 0.9
Epoch:  723        2 Batch loss: 0.056386 Batch F1: 1.0
Epoch:  723        3 Batch loss: 0.073338 Batch F1: 0.8
Epoch:  723        4 Batch loss: 0.067753 Batch F1: 0.8333333333333333
Epoch:  723        5 Batch loss: 0.080180 Batch F1: 0.2857142857142857
Epoch:  723        6 Batch loss: 0.058478 Batch F1: 0.6666666666666666
Epoch:  723        7 Batch loss: 0.055124 Batch F1: 0.9411764705882353
Epoch:  723        8 Batch loss: 0.069977 Batch F1: 0.625
Epoch:  723        9 Batch loss: 0.058661 Batch F1: 0.6666666666666666
Epoch:  723       10 Batch loss: 0.083496 Batch F1: 0.18181818181818182
Epoch:  723       11 Batch loss: 0.075302 Batch F1: 0.42857142857142855
Epoch:  723       12 Batch loss: 0.060050 Batch F1: 0.4444444444444445
Train Avg Loss  723: 0.068010

Train Avg F1  723: 0.6477826231502702

Val Avg Loss  723: 0.061619

Val Avg F1  723:  0.9267676767676768

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 724
--------------------------------------------------------------
Epoch:  724        1 Batch loss: 0.080298 Batch F1: 0.8
Epoch:  724        2 Batch loss: 0.071160 Batch F1: 1.0
Epoch:  724        3 Batch loss: 0.066125 Batch F1: 0.9473684210526316
Epoch:  724        4 Batch loss: 0.080499 Batch F1: 0.9565217391304348
Epoch:  724        5 Batch loss: 0.073651 Batch F1: 0.8
Epoch:  724        6 Batch loss: 0.057919 Batch F1: 0.8
Epoch:  724        7 Batch loss: 0.070181 Batch F1: 0.8750000000000001
Epoch:  724        8 Batch loss: 0.075223 Batch F1: 0.8750000000000001
Epoch:  724        9 Batch loss: 0.076934 Batch F1: 0.9523809523809523
Epoch:  724       10 Batch loss: 0.067782 Batch F1: 0.9473684210526316
Epoch:  724       11 Batch loss: 0.039880 Batch F1: 1.0
Epoch:  724       12 Batch loss: 0.053597 Batch F1: 1.0
Train Avg Loss  724: 0.067771

Train Avg F1  724: 0.9128032944680542

Val Avg Loss  724: 0.063429

Val Avg F1  724:  0.5466628959276019

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 725
--------------------------------------------------------------
Epoch:  725        1 Batch loss: 0.068616 Batch F1: 0.0
Epoch:  725        2 Batch loss: 0.087166 Batch F1: 0.4444444444444445
Epoch:  725        3 Batch loss: 0.062013 Batch F1: 0.7272727272727273
Epoch:  725        4 Batch loss: 0.056047 Batch F1: 0.6153846153846153
Epoch:  725        5 Batch loss: 0.055938 Batch F1: 1.0
Epoch:  725        6 Batch loss: 0.056883 Batch F1: 0.9333333333333333
Epoch:  725        7 Batch loss: 0.065415 Batch F1: 0.8333333333333333
Epoch:  725        8 Batch loss: 0.073349 Batch F1: 0.7692307692307693
Epoch:  725        9 Batch loss: 0.073218 Batch F1: 0.9473684210526316
Epoch:  725       10 Batch loss: 0.061017 Batch F1: 0.9090909090909091
Epoch:  725       11 Batch loss: 0.078719 Batch F1: 0.8421052631578948
Epoch:  725       12 Batch loss: 0.082607 Batch F1: 0.9523809523809523
Train Avg Loss  725: 0.068416

Train Avg F1  725: 0.7478287307234677

Val Avg Loss  725: 0.061881

Val Avg F1  725:  0.924579831932773

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 726
--------------------------------------------------------------
Epoch:  726        1 Batch loss: 0.059782 Batch F1: 0.8333333333333333
Epoch:  726        2 Batch loss: 0.070227 Batch F1: 1.0
Epoch:  726        3 Batch loss: 0.085047 Batch F1: 0.7142857142857143
Epoch:  726        4 Batch loss: 0.066799 Batch F1: 0.9333333333333333
Epoch:  726        5 Batch loss: 0.049013 Batch F1: 1.0
Epoch:  726        6 Batch loss: 0.079577 Batch F1: 0.8421052631578948
Epoch:  726        7 Batch loss: 0.081444 Batch F1: 0.7058823529411764
Epoch:  726        8 Batch loss: 0.056793 Batch F1: 0.6
Epoch:  726        9 Batch loss: 0.056507 Batch F1: 0.888888888888889
Epoch:  726       10 Batch loss: 0.084485 Batch F1: 0.5882352941176471
Epoch:  726       11 Batch loss: 0.052296 Batch F1: 1.0
Epoch:  726       12 Batch loss: 0.077465 Batch F1: 1.0
Train Avg Loss  726: 0.068286

Train Avg F1  726: 0.8421720150048323

Val Avg Loss  726: 0.061851

Val Avg F1  726:  0.9316770186335405

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 727
--------------------------------------------------------------
Epoch:  727        1 Batch loss: 0.067682 Batch F1: 0.9411764705882353
Epoch:  727        2 Batch loss: 0.055379 Batch F1: 0.2857142857142857
Epoch:  727        3 Batch loss: 0.057643 Batch F1: 0.4444444444444445
Epoch:  727        4 Batch loss: 0.073016 Batch F1: 0.2222222222222222
Epoch:  727        5 Batch loss: 0.071076 Batch F1: 0.5714285714285715
Epoch:  727        6 Batch loss: 0.086097 Batch F1: 0.15384615384615385
Epoch:  727        7 Batch loss: 0.050526 Batch F1: 0.888888888888889
Epoch:  727        8 Batch loss: 0.068096 Batch F1: 0.8333333333333333
Epoch:  727        9 Batch loss: 0.057552 Batch F1: 1.0
Epoch:  727       10 Batch loss: 0.068747 Batch F1: 0.9473684210526316
Epoch:  727       11 Batch loss: 0.094124 Batch F1: 0.9375
Epoch:  727       12 Batch loss: 0.062588 Batch F1: 0.923076923076923
Train Avg Loss  727: 0.067711

Train Avg F1  727: 0.6790833095496408

Val Avg Loss  727: 0.061595

Val Avg F1  727:  0.9355263157894738

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 728
--------------------------------------------------------------
Epoch:  728        1 Batch loss: 0.069513 Batch F1: 1.0
Epoch:  728        2 Batch loss: 0.069679 Batch F1: 0.9
Epoch:  728        3 Batch loss: 0.063399 Batch F1: 1.0
Epoch:  728        4 Batch loss: 0.067046 Batch F1: 1.0
Epoch:  728        5 Batch loss: 0.067172 Batch F1: 0.8571428571428571
Epoch:  728        6 Batch loss: 0.061157 Batch F1: 1.0
Epoch:  728        7 Batch loss: 0.106858 Batch F1: 0.846153846153846
Epoch:  728        8 Batch loss: 0.062161 Batch F1: 0.8333333333333333
Epoch:  728        9 Batch loss: 0.055281 Batch F1: 0.9411764705882353
Epoch:  728       10 Batch loss: 0.086675 Batch F1: 0.6666666666666666
Epoch:  728       11 Batch loss: 0.063826 Batch F1: 1.0
Epoch:  728       12 Batch loss: 0.045199 Batch F1: 1.0
Train Avg Loss  728: 0.068164

Train Avg F1  728: 0.9203727644904114

Val Avg Loss  728: 0.061813

Val Avg F1  728:  0.93125

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 729
--------------------------------------------------------------
Epoch:  729        1 Batch loss: 0.085854 Batch F1: 0.888888888888889
Epoch:  729        2 Batch loss: 0.056636 Batch F1: 1.0
Epoch:  729        3 Batch loss: 0.068690 Batch F1: 0.888888888888889
Epoch:  729        4 Batch loss: 0.049087 Batch F1: 0.5
Epoch:  729        5 Batch loss: 0.084583 Batch F1: 0.5263157894736842
Epoch:  729        6 Batch loss: 0.070767 Batch F1: 0.6666666666666666
Epoch:  729        7 Batch loss: 0.050758 Batch F1: 0.7272727272727273
Epoch:  729        8 Batch loss: 0.061203 Batch F1: 0.4444444444444445
Epoch:  729        9 Batch loss: 0.068949 Batch F1: 0.4
Epoch:  729       10 Batch loss: 0.072306 Batch F1: 0.2222222222222222
Epoch:  729       11 Batch loss: 0.098051 Batch F1: 0.5833333333333334
Epoch:  729       12 Batch loss: 0.053074 Batch F1: 0.5
Train Avg Loss  729: 0.068330

Train Avg F1  729: 0.612336080099238

Val Avg Loss  729: 0.062387

Val Avg F1  729:  0.9342857142857143

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 730
--------------------------------------------------------------
Epoch:  730        1 Batch loss: 0.056008 Batch F1: 1.0
Epoch:  730        2 Batch loss: 0.060824 Batch F1: 0.9090909090909091
Epoch:  730        3 Batch loss: 0.077026 Batch F1: 0.8571428571428571
Epoch:  730        4 Batch loss: 0.068835 Batch F1: 0.5882352941176471
Epoch:  730        5 Batch loss: 0.069956 Batch F1: 0.2222222222222222
Epoch:  730        6 Batch loss: 0.076181 Batch F1: 0.625
Epoch:  730        7 Batch loss: 0.059557 Batch F1: 0.5454545454545454
Epoch:  730        8 Batch loss: 0.067177 Batch F1: 0.4
Epoch:  730        9 Batch loss: 0.065227 Batch F1: 0.5714285714285715
Epoch:  730       10 Batch loss: 0.066710 Batch F1: 0.3636363636363636
Epoch:  730       11 Batch loss: 0.072531 Batch F1: 0.0
Epoch:  730       12 Batch loss: 0.083246 Batch F1: 0.7368421052631579
Train Avg Loss  730: 0.068606

Train Avg F1  730: 0.5682544056963561

Val Avg Loss  730: 0.062332

Val Avg F1  730:  0.9261437908496731

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 731
--------------------------------------------------------------
Epoch:  731        1 Batch loss: 0.060133 Batch F1: 0.9333333333333333
Epoch:  731        2 Batch loss: 0.071586 Batch F1: 0.8750000000000001
Epoch:  731        3 Batch loss: 0.070420 Batch F1: 0.9523809523809523
Epoch:  731        4 Batch loss: 0.051659 Batch F1: 1.0
Epoch:  731        5 Batch loss: 0.065790 Batch F1: 0.7692307692307693
Epoch:  731        6 Batch loss: 0.060441 Batch F1: 0.8333333333333333
Epoch:  731        7 Batch loss: 0.067332 Batch F1: 1.0
Epoch:  731        8 Batch loss: 0.077239 Batch F1: 0.9411764705882353
Epoch:  731        9 Batch loss: 0.085745 Batch F1: 0.9565217391304348
Epoch:  731       10 Batch loss: 0.067999 Batch F1: 0.9
Epoch:  731       11 Batch loss: 0.059221 Batch F1: 0.9411764705882353
Epoch:  731       12 Batch loss: 0.080770 Batch F1: 0.8750000000000001
Train Avg Loss  731: 0.068195

Train Avg F1  731: 0.9147627557154413

Val Avg Loss  731: 0.061388

Val Avg F1  731:  0.9396135265700483

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 732
--------------------------------------------------------------
Epoch:  732        1 Batch loss: 0.047223 Batch F1: 0.8
Epoch:  732        2 Batch loss: 0.055531 Batch F1: 1.0
Epoch:  732        3 Batch loss: 0.067687 Batch F1: 0.4
Epoch:  732        4 Batch loss: 0.086581 Batch F1: 0.5555555555555556
Epoch:  732        5 Batch loss: 0.071589 Batch F1: 0.9473684210526316
Epoch:  732        6 Batch loss: 0.061266 Batch F1: 0.9523809523809523
Epoch:  732        7 Batch loss: 0.082962 Batch F1: 0.923076923076923
Epoch:  732        8 Batch loss: 0.079270 Batch F1: 1.0
Epoch:  732        9 Batch loss: 0.095772 Batch F1: 0.782608695652174
Epoch:  732       10 Batch loss: 0.065399 Batch F1: 0.8333333333333333
Epoch:  732       11 Batch loss: 0.063918 Batch F1: 1.0
Epoch:  732       12 Batch loss: 0.051352 Batch F1: 1.0
Train Avg Loss  732: 0.069046

Train Avg F1  732: 0.8495269900876309

Val Avg Loss  732: 0.066610

Val Avg F1  732:  0.7123188405797102

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 733
--------------------------------------------------------------
Epoch:  733        1 Batch loss: 0.084897 Batch F1: 0.4615384615384615
Epoch:  733        2 Batch loss: 0.067759 Batch F1: 0.5454545454545454
Epoch:  733        3 Batch loss: 0.066766 Batch F1: 0.2857142857142857
Epoch:  733        4 Batch loss: 0.035453 Batch F1: 0.8571428571428571
Epoch:  733        5 Batch loss: 0.091598 Batch F1: 0.6666666666666666
Epoch:  733        6 Batch loss: 0.065372 Batch F1: 0.6153846153846153
Epoch:  733        7 Batch loss: 0.075360 Batch F1: 0.5
Epoch:  733        8 Batch loss: 0.058232 Batch F1: 0.8
Epoch:  733        9 Batch loss: 0.059472 Batch F1: 1.0
Epoch:  733       10 Batch loss: 0.091018 Batch F1: 0.8695652173913044
Epoch:  733       11 Batch loss: 0.065213 Batch F1: 1.0
Epoch:  733       12 Batch loss: 0.090635 Batch F1: 0.9090909090909091
Train Avg Loss  733: 0.070981

Train Avg F1  733: 0.7092131298653038

Val Avg Loss  733: 0.063105

Val Avg F1  733:  0.9201388888888888

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 734
--------------------------------------------------------------
Epoch:  734        1 Batch loss: 0.065283 Batch F1: 0.8333333333333333
Epoch:  734        2 Batch loss: 0.066831 Batch F1: 0.9523809523809523
Epoch:  734        3 Batch loss: 0.060749 Batch F1: 0.8
Epoch:  734        4 Batch loss: 0.053185 Batch F1: 1.0
Epoch:  734        5 Batch loss: 0.063986 Batch F1: 1.0
Epoch:  734        6 Batch loss: 0.070516 Batch F1: 0.0
Epoch:  734        7 Batch loss: 0.104511 Batch F1: 0.6
Epoch:  734        8 Batch loss: 0.076256 Batch F1: 0.9473684210526316
Epoch:  734        9 Batch loss: 0.077201 Batch F1: 0.8
Epoch:  734       10 Batch loss: 0.070776 Batch F1: 0.888888888888889
Epoch:  734       11 Batch loss: 0.056712 Batch F1: 0.923076923076923
Epoch:  734       12 Batch loss: 0.073817 Batch F1: 1.0
Train Avg Loss  734: 0.069985

Train Avg F1  734: 0.8120873765610607

Val Avg Loss  734: 0.062121

Val Avg F1  734:  0.9166666666666666

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 735
--------------------------------------------------------------
Epoch:  735        1 Batch loss: 0.057556 Batch F1: 0.923076923076923
Epoch:  735        2 Batch loss: 0.083273 Batch F1: 0.8421052631578948
Epoch:  735        3 Batch loss: 0.059413 Batch F1: 1.0
Epoch:  735        4 Batch loss: 0.071887 Batch F1: 0.8750000000000001
Epoch:  735        5 Batch loss: 0.064953 Batch F1: 0.9473684210526316
Epoch:  735        6 Batch loss: 0.049529 Batch F1: 0.6
Epoch:  735        7 Batch loss: 0.054602 Batch F1: 0.4444444444444445
Epoch:  735        8 Batch loss: 0.099723 Batch F1: 0.4444444444444445
Epoch:  735        9 Batch loss: 0.059084 Batch F1: 0.6666666666666666
Epoch:  735       10 Batch loss: 0.070096 Batch F1: 0.9
Epoch:  735       11 Batch loss: 0.095827 Batch F1: 0.888888888888889
Epoch:  735       12 Batch loss: 0.060415 Batch F1: 1.0
Train Avg Loss  735: 0.068863

Train Avg F1  735: 0.794332920977658

Val Avg Loss  735: 0.062522

Val Avg F1  735:  0.9279914529914529

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 736
--------------------------------------------------------------
Epoch:  736        1 Batch loss: 0.063912 Batch F1: 0.8571428571428571
Epoch:  736        2 Batch loss: 0.079595 Batch F1: 0.9090909090909091
Epoch:  736        3 Batch loss: 0.055618 Batch F1: 1.0
Epoch:  736        4 Batch loss: 0.063979 Batch F1: 0.9090909090909091
Epoch:  736        5 Batch loss: 0.068778 Batch F1: 0.8333333333333333
Epoch:  736        6 Batch loss: 0.078803 Batch F1: 0.9166666666666666
Epoch:  736        7 Batch loss: 0.066483 Batch F1: 0.923076923076923
Epoch:  736        8 Batch loss: 0.067162 Batch F1: 0.8333333333333333
Epoch:  736        9 Batch loss: 0.075854 Batch F1: 1.0
Epoch:  736       10 Batch loss: 0.072072 Batch F1: 0.8571428571428571
Epoch:  736       11 Batch loss: 0.047684 Batch F1: 0.7692307692307693
Epoch:  736       12 Batch loss: 0.079620 Batch F1: 0.19999999999999998
Train Avg Loss  736: 0.068297

Train Avg F1  736: 0.8340090465090465

Val Avg Loss  736: 0.062048

Val Avg F1  736:  0.5707013574660633

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 737
--------------------------------------------------------------
Epoch:  737        1 Batch loss: 0.067821 Batch F1: 0.761904761904762
Epoch:  737        2 Batch loss: 0.072856 Batch F1: 1.0
Epoch:  737        3 Batch loss: 0.062701 Batch F1: 0.9473684210526316
Epoch:  737        4 Batch loss: 0.076935 Batch F1: 0.0
Epoch:  737        5 Batch loss: 0.059502 Batch F1: 0.9411764705882353
Epoch:  737        6 Batch loss: 0.080390 Batch F1: 0.7692307692307693
Epoch:  737        7 Batch loss: 0.064925 Batch F1: 1.0
Epoch:  737        8 Batch loss: 0.062912 Batch F1: 0.4444444444444445
Epoch:  737        9 Batch loss: 0.078839 Batch F1: 0.631578947368421
Epoch:  737       10 Batch loss: 0.076983 Batch F1: 0.888888888888889
Epoch:  737       11 Batch loss: 0.064601 Batch F1: 0.9333333333333333
Epoch:  737       12 Batch loss: 0.063573 Batch F1: 0.9090909090909091
Train Avg Loss  737: 0.069336

Train Avg F1  737: 0.7689180788251996

Val Avg Loss  737: 0.061870

Val Avg F1  737:  0.9261278195488721

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 738
--------------------------------------------------------------
Epoch:  738        1 Batch loss: 0.041292 Batch F1: 1.0
Epoch:  738        2 Batch loss: 0.073118 Batch F1: 0.3636363636363636
Epoch:  738        3 Batch loss: 0.060480 Batch F1: 0.6153846153846153
Epoch:  738        4 Batch loss: 0.051053 Batch F1: 0.5
Epoch:  738        5 Batch loss: 0.053851 Batch F1: 0.5454545454545454
Epoch:  738        6 Batch loss: 0.094824 Batch F1: 0.5454545454545454
Epoch:  738        7 Batch loss: 0.064337 Batch F1: 0.8571428571428571
Epoch:  738        8 Batch loss: 0.074935 Batch F1: 0.7692307692307693
Epoch:  738        9 Batch loss: 0.065616 Batch F1: 0.9473684210526316
Epoch:  738       10 Batch loss: 0.083107 Batch F1: 0.9565217391304348
Epoch:  738       11 Batch loss: 0.088323 Batch F1: 0.8695652173913044
Epoch:  738       12 Batch loss: 0.071162 Batch F1: 0.8
Train Avg Loss  738: 0.068508

Train Avg F1  738: 0.7308132561565056

Val Avg Loss  738: 0.061552

Val Avg F1  738:  0.9362557732122949

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 739
--------------------------------------------------------------
Epoch:  739        1 Batch loss: 0.064152 Batch F1: 1.0
Epoch:  739        2 Batch loss: 0.047204 Batch F1: 0.923076923076923
Epoch:  739        3 Batch loss: 0.056421 Batch F1: 0.5714285714285715
Epoch:  739        4 Batch loss: 0.048649 Batch F1: 0.7272727272727273
Epoch:  739        5 Batch loss: 0.106267 Batch F1: 0.2857142857142857
Epoch:  739        6 Batch loss: 0.076835 Batch F1: 0.5
Epoch:  739        7 Batch loss: 0.080635 Batch F1: 0.8421052631578948
Epoch:  739        8 Batch loss: 0.070450 Batch F1: 1.0
Epoch:  739        9 Batch loss: 0.087555 Batch F1: 0.8421052631578948
Epoch:  739       10 Batch loss: 0.069895 Batch F1: 0.9411764705882353
Epoch:  739       11 Batch loss: 0.060105 Batch F1: 0.4444444444444445
Epoch:  739       12 Batch loss: 0.082411 Batch F1: 0.0
Train Avg Loss  739: 0.070882

Train Avg F1  739: 0.6731103290700814

Val Avg Loss  739: 0.065408

Val Avg F1  739:  0.6104166666666667

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 740
--------------------------------------------------------------
Epoch:  740        1 Batch loss: 0.098607 Batch F1: 0.5454545454545454
Epoch:  740        2 Batch loss: 0.061616 Batch F1: 0.9090909090909091
Epoch:  740        3 Batch loss: 0.082466 Batch F1: 0.9166666666666666
Epoch:  740        4 Batch loss: 0.063355 Batch F1: 1.0
Epoch:  740        5 Batch loss: 0.070545 Batch F1: 0.8235294117647058
Epoch:  740        6 Batch loss: 0.072639 Batch F1: 0.7499999999999999
Epoch:  740        7 Batch loss: 0.063633 Batch F1: 0.6666666666666666
Epoch:  740        8 Batch loss: 0.077891 Batch F1: 0.5333333333333333
Epoch:  740        9 Batch loss: 0.063911 Batch F1: 0.8571428571428571
Epoch:  740       10 Batch loss: 0.068235 Batch F1: 0.9333333333333333
Epoch:  740       11 Batch loss: 0.072550 Batch F1: 0.0
Epoch:  740       12 Batch loss: 0.063574 Batch F1: 0.33333333333333337
Train Avg Loss  740: 0.071585

Train Avg F1  740: 0.6890459213988626

Val Avg Loss  740: 0.066125

Val Avg F1  740:  0.5820512820512821

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 741
--------------------------------------------------------------
Epoch:  741        1 Batch loss: 0.095934 Batch F1: 0.2857142857142857
Epoch:  741        2 Batch loss: 0.053579 Batch F1: 0.4444444444444445
Epoch:  741        3 Batch loss: 0.057589 Batch F1: 0.7692307692307693
Epoch:  741        4 Batch loss: 0.084381 Batch F1: 0.9166666666666666
Epoch:  741        5 Batch loss: 0.068280 Batch F1: 0.8571428571428571
Epoch:  741        6 Batch loss: 0.069451 Batch F1: 0.8750000000000001
Epoch:  741        7 Batch loss: 0.046418 Batch F1: 0.7692307692307693
Epoch:  741        8 Batch loss: 0.072115 Batch F1: 0.2222222222222222
Epoch:  741        9 Batch loss: 0.079390 Batch F1: 0.5333333333333333
Epoch:  741       10 Batch loss: 0.055608 Batch F1: 0.5
Epoch:  741       11 Batch loss: 0.086638 Batch F1: 0.9
Epoch:  741       12 Batch loss: 0.062785 Batch F1: 1.0
Train Avg Loss  741: 0.069347

Train Avg F1  741: 0.672748778998779

Val Avg Loss  741: 0.061126

Val Avg F1  741:  0.9217160548429899

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 742
--------------------------------------------------------------
Epoch:  742        1 Batch loss: 0.052909 Batch F1: 0.9090909090909091
Epoch:  742        2 Batch loss: 0.074673 Batch F1: 1.0
Epoch:  742        3 Batch loss: 0.063448 Batch F1: 0.888888888888889
Epoch:  742        4 Batch loss: 0.079553 Batch F1: 0.9565217391304348
Epoch:  742        5 Batch loss: 0.049128 Batch F1: 1.0
Epoch:  742        6 Batch loss: 0.099773 Batch F1: 0.8
Epoch:  742        7 Batch loss: 0.068020 Batch F1: 0.8750000000000001
Epoch:  742        8 Batch loss: 0.056625 Batch F1: 0.9090909090909091
Epoch:  742        9 Batch loss: 0.075309 Batch F1: 0.8235294117647058
Epoch:  742       10 Batch loss: 0.068253 Batch F1: 0.9411764705882353
Epoch:  742       11 Batch loss: 0.077559 Batch F1: 0.888888888888889
Epoch:  742       12 Batch loss: 0.039125 Batch F1: 1.0
Train Avg Loss  742: 0.067031

Train Avg F1  742: 0.9160156014535811

Val Avg Loss  742: 0.061659

Val Avg F1  742:  0.5388965201465201

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 743
--------------------------------------------------------------
Epoch:  743        1 Batch loss: 0.070219 Batch F1: 0.4
Epoch:  743        2 Batch loss: 0.073071 Batch F1: 0.5714285714285715
Epoch:  743        3 Batch loss: 0.078913 Batch F1: 0.33333333333333337
Epoch:  743        4 Batch loss: 0.060388 Batch F1: 0.4
Epoch:  743        5 Batch loss: 0.069873 Batch F1: 0.5
Epoch:  743        6 Batch loss: 0.067574 Batch F1: 0.5333333333333333
Epoch:  743        7 Batch loss: 0.067596 Batch F1: 0.8750000000000001
Epoch:  743        8 Batch loss: 0.061753 Batch F1: 0.8333333333333333
Epoch:  743        9 Batch loss: 0.065231 Batch F1: 1.0
Epoch:  743       10 Batch loss: 0.078805 Batch F1: 0.923076923076923
Epoch:  743       11 Batch loss: 0.066886 Batch F1: 0.9090909090909091
Epoch:  743       12 Batch loss: 0.052829 Batch F1: 1.0
Train Avg Loss  743: 0.067762

Train Avg F1  743: 0.6898830336330336

Val Avg Loss  743: 0.061035

Val Avg F1  743:  0.9286616161616161

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 744
--------------------------------------------------------------
Epoch:  744        1 Batch loss: 0.074795 Batch F1: 0.7692307692307693
Epoch:  744        2 Batch loss: 0.055698 Batch F1: 0.0
Epoch:  744        3 Batch loss: 0.076709 Batch F1: 0.19999999999999998
Epoch:  744        4 Batch loss: 0.030364 Batch F1: 1.0
Epoch:  744        5 Batch loss: 0.066644 Batch F1: 0.6666666666666666
Epoch:  744        6 Batch loss: 0.101050 Batch F1: 0.35294117647058826
Epoch:  744        7 Batch loss: 0.074124 Batch F1: 0.5
Epoch:  744        8 Batch loss: 0.078993 Batch F1: 0.9600000000000001
Epoch:  744        9 Batch loss: 0.063522 Batch F1: 0.9333333333333333
Epoch:  744       10 Batch loss: 0.071483 Batch F1: 1.0
Epoch:  744       11 Batch loss: 0.073468 Batch F1: 0.9600000000000001
Epoch:  744       12 Batch loss: 0.065379 Batch F1: 1.0
Train Avg Loss  744: 0.069352

Train Avg F1  744: 0.6951809954751131

Val Avg Loss  744: 0.062228

Val Avg F1  744:  0.9182692307692307

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 745
--------------------------------------------------------------
Epoch:  745        1 Batch loss: 0.069813 Batch F1: 1.0
Epoch:  745        2 Batch loss: 0.056734 Batch F1: 0.9333333333333333
Epoch:  745        3 Batch loss: 0.060726 Batch F1: 0.9090909090909091
Epoch:  745        4 Batch loss: 0.071874 Batch F1: 0.9411764705882353
Epoch:  745        5 Batch loss: 0.064113 Batch F1: 0.923076923076923
Epoch:  745        6 Batch loss: 0.071920 Batch F1: 0.8750000000000001
Epoch:  745        7 Batch loss: 0.075847 Batch F1: 0.5
Epoch:  745        8 Batch loss: 0.076184 Batch F1: 0.5333333333333333
Epoch:  745        9 Batch loss: 0.079570 Batch F1: 0.888888888888889
Epoch:  745       10 Batch loss: 0.053326 Batch F1: 0.8
Epoch:  745       11 Batch loss: 0.062217 Batch F1: 0.8333333333333333
Epoch:  745       12 Batch loss: 0.081401 Batch F1: 0.9090909090909091
Train Avg Loss  745: 0.068644

Train Avg F1  745: 0.8371936750613221

Val Avg Loss  745: 0.061096

Val Avg F1  745:  0.9193560606060607

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 746
--------------------------------------------------------------
Epoch:  746        1 Batch loss: 0.047510 Batch F1: 1.0
Epoch:  746        2 Batch loss: 0.074120 Batch F1: 0.9565217391304348
Epoch:  746        3 Batch loss: 0.092742 Batch F1: 0.923076923076923
Epoch:  746        4 Batch loss: 0.066111 Batch F1: 0.9333333333333333
Epoch:  746        5 Batch loss: 0.075920 Batch F1: 0.8333333333333333
Epoch:  746        6 Batch loss: 0.071531 Batch F1: 0.9411764705882353
Epoch:  746        7 Batch loss: 0.051874 Batch F1: 0.7499999999999999
Epoch:  746        8 Batch loss: 0.076695 Batch F1: 0.8
Epoch:  746        9 Batch loss: 0.054673 Batch F1: 0.5
Epoch:  746       10 Batch loss: 0.065466 Batch F1: 0.625
Epoch:  746       11 Batch loss: 0.064258 Batch F1: 0.7058823529411764
Epoch:  746       12 Batch loss: 0.071450 Batch F1: 0.7142857142857143
Train Avg Loss  746: 0.067696

Train Avg F1  746: 0.806884155557429

Val Avg Loss  746: 0.061113

Val Avg F1  746:  0.8888888888888888

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 747
--------------------------------------------------------------
Epoch:  747        1 Batch loss: 0.063008 Batch F1: 0.9333333333333333
Epoch:  747        2 Batch loss: 0.082829 Batch F1: 0.9565217391304348
Epoch:  747        3 Batch loss: 0.067480 Batch F1: 0.888888888888889
Epoch:  747        4 Batch loss: 0.072726 Batch F1: 0.8750000000000001
Epoch:  747        5 Batch loss: 0.064518 Batch F1: 0.923076923076923
Epoch:  747        6 Batch loss: 0.065480 Batch F1: 0.8750000000000001
Epoch:  747        7 Batch loss: 0.074615 Batch F1: 0.888888888888889
Epoch:  747        8 Batch loss: 0.057902 Batch F1: 0.9333333333333333
Epoch:  747        9 Batch loss: 0.056209 Batch F1: 1.0
Epoch:  747       10 Batch loss: 0.049490 Batch F1: 0.8571428571428571
Epoch:  747       11 Batch loss: 0.065478 Batch F1: 0.6666666666666666
Epoch:  747       12 Batch loss: 0.092406 Batch F1: 0.16666666666666669
Train Avg Loss  747: 0.067678

Train Avg F1  747: 0.8303766080939994

Val Avg Loss  747: 0.061128

Val Avg F1  747:  0.9199849170437405

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 748
--------------------------------------------------------------
Epoch:  748        1 Batch loss: 0.079275 Batch F1: 0.8235294117647058
Epoch:  748        2 Batch loss: 0.036887 Batch F1: 1.0
Epoch:  748        3 Batch loss: 0.076541 Batch F1: 0.9166666666666666
Epoch:  748        4 Batch loss: 0.079337 Batch F1: 0.8695652173913044
Epoch:  748        5 Batch loss: 0.072654 Batch F1: 0.7692307692307693
Epoch:  748        6 Batch loss: 0.076477 Batch F1: 0.923076923076923
Epoch:  748        7 Batch loss: 0.053427 Batch F1: 1.0
Epoch:  748        8 Batch loss: 0.076079 Batch F1: 0.9523809523809523
Epoch:  748        9 Batch loss: 0.075413 Batch F1: 0.9523809523809523
Epoch:  748       10 Batch loss: 0.067524 Batch F1: 1.0
Epoch:  748       11 Batch loss: 0.060263 Batch F1: 0.4444444444444445
Epoch:  748       12 Batch loss: 0.066093 Batch F1: 0.7142857142857143
Train Avg Loss  748: 0.068331

Train Avg F1  748: 0.8637967543018693

Val Avg Loss  748: 0.062964

Val Avg F1  748:  0.5570622188269247

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 749
--------------------------------------------------------------
Epoch:  749        1 Batch loss: 0.062517 Batch F1: 0.2857142857142857
Epoch:  749        2 Batch loss: 0.080638 Batch F1: 0.3636363636363636
Epoch:  749        3 Batch loss: 0.063598 Batch F1: 0.6153846153846153
Epoch:  749        4 Batch loss: 0.060906 Batch F1: 1.0
Epoch:  749        5 Batch loss: 0.067553 Batch F1: 0.8750000000000001
Epoch:  749        6 Batch loss: 0.064107 Batch F1: 0.9523809523809523
Epoch:  749        7 Batch loss: 0.059962 Batch F1: 1.0
Epoch:  749        8 Batch loss: 0.075015 Batch F1: 0.9523809523809523
Epoch:  749        9 Batch loss: 0.069659 Batch F1: 0.9523809523809523
Epoch:  749       10 Batch loss: 0.065193 Batch F1: 0.8750000000000001
Epoch:  749       11 Batch loss: 0.063039 Batch F1: 0.8571428571428571
Epoch:  749       12 Batch loss: 0.072448 Batch F1: 0.9333333333333333
Train Avg Loss  749: 0.067053

Train Avg F1  749: 0.8051961926961928

Val Avg Loss  749: 0.061063

Val Avg F1  749:  0.9333333333333333

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 750
--------------------------------------------------------------
Epoch:  750        1 Batch loss: 0.070923 Batch F1: 0.9333333333333333
Epoch:  750        2 Batch loss: 0.064658 Batch F1: 0.923076923076923
Epoch:  750        3 Batch loss: 0.081344 Batch F1: 0.9
Epoch:  750        4 Batch loss: 0.068952 Batch F1: 0.9411764705882353
Epoch:  750        5 Batch loss: 0.063941 Batch F1: 0.8571428571428571
Epoch:  750        6 Batch loss: 0.047931 Batch F1: 0.9090909090909091
Epoch:  750        7 Batch loss: 0.082283 Batch F1: 0.9166666666666666
Epoch:  750        8 Batch loss: 0.074470 Batch F1: 0.9166666666666666
Epoch:  750        9 Batch loss: 0.053277 Batch F1: 0.888888888888889
Epoch:  750       10 Batch loss: 0.071736 Batch F1: 0.8750000000000001
Epoch:  750       11 Batch loss: 0.060672 Batch F1: 1.0
Epoch:  750       12 Batch loss: 0.067604 Batch F1: 0.9473684210526316
Train Avg Loss  750: 0.067316

Train Avg F1  750: 0.917367594708926

Val Avg Loss  750: 0.061129

Val Avg F1  750:  0.9105263157894736

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 751
--------------------------------------------------------------
Epoch:  751        1 Batch loss: 0.070047 Batch F1: 0.8
Epoch:  751        2 Batch loss: 0.085658 Batch F1: 0.8333333333333333
Epoch:  751        3 Batch loss: 0.056396 Batch F1: 0.8571428571428571
Epoch:  751        4 Batch loss: 0.058294 Batch F1: 1.0
Epoch:  751        5 Batch loss: 0.069520 Batch F1: 0.9411764705882353
Epoch:  751        6 Batch loss: 0.065497 Batch F1: 0.9090909090909091
Epoch:  751        7 Batch loss: 0.054877 Batch F1: 1.0
Epoch:  751        8 Batch loss: 0.067867 Batch F1: 0.3636363636363636
Epoch:  751        9 Batch loss: 0.082206 Batch F1: 0.3076923076923077
Epoch:  751       10 Batch loss: 0.073504 Batch F1: 0.6666666666666666
Epoch:  751       11 Batch loss: 0.057125 Batch F1: 0.9
Epoch:  751       12 Batch loss: 0.084134 Batch F1: 0.8333333333333333
Train Avg Loss  751: 0.068760

Train Avg F1  751: 0.7843393534570006

Val Avg Loss  751: 0.062282

Val Avg F1  751:  0.9251276759016697

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 752
--------------------------------------------------------------
Epoch:  752        1 Batch loss: 0.088567 Batch F1: 0.8695652173913044
Epoch:  752        2 Batch loss: 0.078051 Batch F1: 0.8421052631578948
Epoch:  752        3 Batch loss: 0.071147 Batch F1: 0.8333333333333333
Epoch:  752        4 Batch loss: 0.054625 Batch F1: 0.9090909090909091
Epoch:  752        5 Batch loss: 0.071004 Batch F1: 0.9473684210526316
Epoch:  752        6 Batch loss: 0.084652 Batch F1: 0.7000000000000001
Epoch:  752        7 Batch loss: 0.063733 Batch F1: 0.9090909090909091
Epoch:  752        8 Batch loss: 0.071853 Batch F1: 0.9333333333333333
Epoch:  752        9 Batch loss: 0.067131 Batch F1: 0.923076923076923
Epoch:  752       10 Batch loss: 0.067689 Batch F1: 0.9473684210526316
Epoch:  752       11 Batch loss: 0.073292 Batch F1: 0.16666666666666669
Epoch:  752       12 Batch loss: 0.048058 Batch F1: 0.6666666666666666
Train Avg Loss  752: 0.069983

Train Avg F1  752: 0.8039721719927669

Val Avg Loss  752: 0.062895

Val Avg F1  752:  0.7230158730158731

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 753
--------------------------------------------------------------
Epoch:  753        1 Batch loss: 0.058852 Batch F1: 0.5
Epoch:  753        2 Batch loss: 0.047666 Batch F1: 0.5714285714285715
Epoch:  753        3 Batch loss: 0.045206 Batch F1: 0.7499999999999999
Epoch:  753        4 Batch loss: 0.096150 Batch F1: 0.375
Epoch:  753        5 Batch loss: 0.071933 Batch F1: 0.7058823529411764
Epoch:  753        6 Batch loss: 0.068362 Batch F1: 0.5454545454545454
Epoch:  753        7 Batch loss: 0.074793 Batch F1: 0.7142857142857143
Epoch:  753        8 Batch loss: 0.049883 Batch F1: 1.0
Epoch:  753        9 Batch loss: 0.076676 Batch F1: 0.47058823529411764
Epoch:  753       10 Batch loss: 0.077051 Batch F1: 0.19999999999999998
Epoch:  753       11 Batch loss: 0.083225 Batch F1: 0.8181818181818181
Epoch:  753       12 Batch loss: 0.083486 Batch F1: 0.9
Train Avg Loss  753: 0.069440

Train Avg F1  753: 0.629235103132162

Val Avg Loss  753: 0.064944

Val Avg F1  753:  0.9226190476190476

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 754
--------------------------------------------------------------
Epoch:  754        1 Batch loss: 0.060574 Batch F1: 0.9090909090909091
Epoch:  754        2 Batch loss: 0.074656 Batch F1: 0.8750000000000001
Epoch:  754        3 Batch loss: 0.046399 Batch F1: 1.0
Epoch:  754        4 Batch loss: 0.087302 Batch F1: 0.5263157894736842
Epoch:  754        5 Batch loss: 0.065903 Batch F1: 0.5
Epoch:  754        6 Batch loss: 0.057614 Batch F1: 0.7692307692307693
Epoch:  754        7 Batch loss: 0.053636 Batch F1: 0.7499999999999999
Epoch:  754        8 Batch loss: 0.080577 Batch F1: 0.4444444444444445
Epoch:  754        9 Batch loss: 0.082342 Batch F1: 0.5714285714285715
Epoch:  754       10 Batch loss: 0.091698 Batch F1: 0.7777777777777778
Epoch:  754       11 Batch loss: 0.072576 Batch F1: 0.8333333333333333
Epoch:  754       12 Batch loss: 0.069252 Batch F1: 0.9090909090909091
Train Avg Loss  754: 0.070211

Train Avg F1  754: 0.7388093753225332

Val Avg Loss  754: 0.062204

Val Avg F1  754:  0.9328525641025642

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 755
--------------------------------------------------------------
Epoch:  755        1 Batch loss: 0.071474 Batch F1: 0.8333333333333333
Epoch:  755        2 Batch loss: 0.048010 Batch F1: 0.9090909090909091
Epoch:  755        3 Batch loss: 0.071995 Batch F1: 0.9523809523809523
Epoch:  755        4 Batch loss: 0.083062 Batch F1: 0.8235294117647058
Epoch:  755        5 Batch loss: 0.055487 Batch F1: 0.8
Epoch:  755        6 Batch loss: 0.072318 Batch F1: 1.0
Epoch:  755        7 Batch loss: 0.062047 Batch F1: 0.9090909090909091
Epoch:  755        8 Batch loss: 0.070661 Batch F1: 1.0
Epoch:  755        9 Batch loss: 0.100802 Batch F1: 0.8571428571428571
Epoch:  755       10 Batch loss: 0.063216 Batch F1: 0.9411764705882353
Epoch:  755       11 Batch loss: 0.063827 Batch F1: 0.8571428571428571
Epoch:  755       12 Batch loss: 0.068878 Batch F1: 0.6666666666666666
Train Avg Loss  755: 0.069315

Train Avg F1  755: 0.8791295306001188

Val Avg Loss  755: 0.067585

Val Avg F1  755:  0.589935064935065

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 756
--------------------------------------------------------------
Epoch:  756        1 Batch loss: 0.069536 Batch F1: 0.6153846153846153
Epoch:  756        2 Batch loss: 0.065669 Batch F1: 0.7142857142857143
Epoch:  756        3 Batch loss: 0.084100 Batch F1: 0.9565217391304348
Epoch:  756        4 Batch loss: 0.062429 Batch F1: 0.9333333333333333
Epoch:  756        5 Batch loss: 0.064767 Batch F1: 1.0
Epoch:  756        6 Batch loss: 0.084055 Batch F1: 0.8235294117647058
Epoch:  756        7 Batch loss: 0.058969 Batch F1: 1.0
Epoch:  756        8 Batch loss: 0.060456 Batch F1: 0.7272727272727273
Epoch:  756        9 Batch loss: 0.064705 Batch F1: 0.6153846153846153
Epoch:  756       10 Batch loss: 0.093334 Batch F1: 0.8695652173913044
Epoch:  756       11 Batch loss: 0.059686 Batch F1: 0.9411764705882353
Epoch:  756       12 Batch loss: 0.070690 Batch F1: 0.8333333333333333
Train Avg Loss  756: 0.069866

Train Avg F1  756: 0.8358155981557517

Val Avg Loss  756: 0.061296

Val Avg F1  756:  0.9234099234099233

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 757
--------------------------------------------------------------
Epoch:  757        1 Batch loss: 0.077342 Batch F1: 0.9523809523809523
Epoch:  757        2 Batch loss: 0.046671 Batch F1: 0.8571428571428571
Epoch:  757        3 Batch loss: 0.065334 Batch F1: 0.5454545454545454
Epoch:  757        4 Batch loss: 0.045442 Batch F1: 0.6666666666666666
Epoch:  757        5 Batch loss: 0.068775 Batch F1: 0.5714285714285715
Epoch:  757        6 Batch loss: 0.074857 Batch F1: 1.0
Epoch:  757        7 Batch loss: 0.081087 Batch F1: 0.8421052631578948
Epoch:  757        8 Batch loss: 0.072499 Batch F1: 0.6666666666666666
Epoch:  757        9 Batch loss: 0.099101 Batch F1: 0.8333333333333333
Epoch:  757       10 Batch loss: 0.078229 Batch F1: 0.9411764705882353
Epoch:  757       11 Batch loss: 0.054532 Batch F1: 0.6
Epoch:  757       12 Batch loss: 0.075109 Batch F1: 0.6153846153846153
Train Avg Loss  757: 0.069915

Train Avg F1  757: 0.7576449951836949

Val Avg Loss  757: 0.063196

Val Avg F1  757:  0.7414148351648352

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 758
--------------------------------------------------------------
Epoch:  758        1 Batch loss: 0.083277 Batch F1: 0.5333333333333333
Epoch:  758        2 Batch loss: 0.068398 Batch F1: 0.9411764705882353
Epoch:  758        3 Batch loss: 0.060500 Batch F1: 0.923076923076923
Epoch:  758        4 Batch loss: 0.056348 Batch F1: 0.923076923076923
Epoch:  758        5 Batch loss: 0.085886 Batch F1: 0.5555555555555556
Epoch:  758        6 Batch loss: 0.067639 Batch F1: 0.9411764705882353
Epoch:  758        7 Batch loss: 0.069901 Batch F1: 0.8571428571428571
Epoch:  758        8 Batch loss: 0.065260 Batch F1: 0.9333333333333333
Epoch:  758        9 Batch loss: 0.075610 Batch F1: 1.0
Epoch:  758       10 Batch loss: 0.069529 Batch F1: 0.7058823529411764
Epoch:  758       11 Batch loss: 0.072950 Batch F1: 0.5714285714285715
Epoch:  758       12 Batch loss: 0.054515 Batch F1: 0.7499999999999999
Train Avg Loss  758: 0.069151

Train Avg F1  758: 0.8029318992554285

Val Avg Loss  758: 0.062298

Val Avg F1  758:  0.5720361509835195

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 759
--------------------------------------------------------------
Epoch:  759        1 Batch loss: 0.064122 Batch F1: 0.5
Epoch:  759        2 Batch loss: 0.056747 Batch F1: 0.6153846153846153
Epoch:  759        3 Batch loss: 0.062518 Batch F1: 0.7058823529411764
Epoch:  759        4 Batch loss: 0.085532 Batch F1: 0.3076923076923077
Epoch:  759        5 Batch loss: 0.088774 Batch F1: 0.8421052631578948
Epoch:  759        6 Batch loss: 0.075564 Batch F1: 0.888888888888889
Epoch:  759        7 Batch loss: 0.066758 Batch F1: 0.923076923076923
Epoch:  759        8 Batch loss: 0.074044 Batch F1: 0.9333333333333333
Epoch:  759        9 Batch loss: 0.091522 Batch F1: 0.88
Epoch:  759       10 Batch loss: 0.049267 Batch F1: 1.0
Epoch:  759       11 Batch loss: 0.057568 Batch F1: 0.9090909090909091
Epoch:  759       12 Batch loss: 0.054296 Batch F1: 1.0
Train Avg Loss  759: 0.068893

Train Avg F1  759: 0.792121216130504

Val Avg Loss  759: 0.062222

Val Avg F1  759:  0.5897435897435896

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 760
--------------------------------------------------------------
Epoch:  760        1 Batch loss: 0.049284 Batch F1: 0.7692307692307693
Epoch:  760        2 Batch loss: 0.055828 Batch F1: 0.7692307692307693
Epoch:  760        3 Batch loss: 0.069318 Batch F1: 0.4615384615384615
Epoch:  760        4 Batch loss: 0.067547 Batch F1: 0.6153846153846153
Epoch:  760        5 Batch loss: 0.048003 Batch F1: 0.5714285714285715
Epoch:  760        6 Batch loss: 0.046531 Batch F1: 0.5
Epoch:  760        7 Batch loss: 0.069047 Batch F1: 0.5
Epoch:  760        8 Batch loss: 0.106370 Batch F1: 0.4444444444444445
Epoch:  760        9 Batch loss: 0.092721 Batch F1: 0.375
Epoch:  760       10 Batch loss: 0.060666 Batch F1: 0.923076923076923
Epoch:  760       11 Batch loss: 0.079015 Batch F1: 0.8571428571428571
Epoch:  760       12 Batch loss: 0.090261 Batch F1: 0.8421052631578948
Train Avg Loss  760: 0.069549

Train Avg F1  760: 0.6357152228862756

Val Avg Loss  760: 0.062018

Val Avg F1  760:  0.9142156862745098

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 761
--------------------------------------------------------------
Epoch:  761        1 Batch loss: 0.067022 Batch F1: 0.8571428571428571
Epoch:  761        2 Batch loss: 0.061797 Batch F1: 1.0
Epoch:  761        3 Batch loss: 0.070112 Batch F1: 0.8750000000000001
Epoch:  761        4 Batch loss: 0.065224 Batch F1: 1.0
Epoch:  761        5 Batch loss: 0.076452 Batch F1: 0.9473684210526316
Epoch:  761        6 Batch loss: 0.081139 Batch F1: 0.9090909090909091
Epoch:  761        7 Batch loss: 0.061550 Batch F1: 0.9090909090909091
Epoch:  761        8 Batch loss: 0.064518 Batch F1: 0.9411764705882353
Epoch:  761        9 Batch loss: 0.082729 Batch F1: 0.7058823529411764
Epoch:  761       10 Batch loss: 0.071666 Batch F1: 0.5
Epoch:  761       11 Batch loss: 0.068616 Batch F1: 0.4
Epoch:  761       12 Batch loss: 0.052156 Batch F1: 0.8333333333333333
Train Avg Loss  761: 0.068582

Train Avg F1  761: 0.8231737711033378

Val Avg Loss  761: 0.065405

Val Avg F1  761:  0.7368601986249046

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 762
--------------------------------------------------------------
Epoch:  762        1 Batch loss: 0.072849 Batch F1: 0.7499999999999999
Epoch:  762        2 Batch loss: 0.122724 Batch F1: 0.4
Epoch:  762        3 Batch loss: 0.055748 Batch F1: 0.5
Epoch:  762        4 Batch loss: 0.058381 Batch F1: 0.0
Epoch:  762        5 Batch loss: 0.098438 Batch F1: 0.0
Epoch:  762        6 Batch loss: 0.059484 Batch F1: 0.25
Epoch:  762        7 Batch loss: 0.077611 Batch F1: 0.7777777777777778
Epoch:  762        8 Batch loss: 0.079628 Batch F1: 0.8333333333333333
Epoch:  762        9 Batch loss: 0.051683 Batch F1: 0.6666666666666666
Epoch:  762       10 Batch loss: 0.106240 Batch F1: 0.0
Epoch:  762       11 Batch loss: 0.069599 Batch F1: 1.0
Epoch:  762       12 Batch loss: 0.071714 Batch F1: 0.9600000000000001
Train Avg Loss  762: 0.077008

Train Avg F1  762: 0.5114814814814815

Val Avg Loss  762: 0.087454

Val Avg F1  762:  0.816820276497696

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 763
--------------------------------------------------------------
Epoch:  763        1 Batch loss: 0.089997 Batch F1: 0.8695652173913043
Epoch:  763        2 Batch loss: 0.060830 Batch F1: 1.0
Epoch:  763        3 Batch loss: 0.077269 Batch F1: 0.9333333333333333
Epoch:  763        4 Batch loss: 0.059659 Batch F1: 0.0
Epoch:  763        5 Batch loss: 0.099513 Batch F1: 0.0
Epoch:  763        6 Batch loss: 0.071532 Batch F1: 1.0
Epoch:  763        7 Batch loss: 0.035525 Batch F1: 1.0
Epoch:  763        8 Batch loss: 0.056021 Batch F1: 0.9090909090909091
Epoch:  763        9 Batch loss: 0.118835 Batch F1: 0.0
Epoch:  763       10 Batch loss: 0.089946 Batch F1: 0.9166666666666666
Epoch:  763       11 Batch loss: 0.080054 Batch F1: 0.7777777777777778
Epoch:  763       12 Batch loss: 0.102442 Batch F1: 0.8421052631578948
Train Avg Loss  763: 0.078468

Train Avg F1  763: 0.6873782639514906

Val Avg Loss  763: 0.064656

Val Avg F1  763:  0.9126190476190477

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 764
--------------------------------------------------------------
Epoch:  764        1 Batch loss: 0.062769 Batch F1: 1.0
Epoch:  764        2 Batch loss: 0.051046 Batch F1: 0.888888888888889
Epoch:  764        3 Batch loss: 0.101006 Batch F1: 0.375
Epoch:  764        4 Batch loss: 0.063988 Batch F1: 0.7692307692307693
Epoch:  764        5 Batch loss: 0.072542 Batch F1: 0.6666666666666666
Epoch:  764        6 Batch loss: 0.065572 Batch F1: 0.7142857142857143
Epoch:  764        7 Batch loss: 0.072220 Batch F1: 0.2222222222222222
Epoch:  764        8 Batch loss: 0.056430 Batch F1: 0.7272727272727273
Epoch:  764        9 Batch loss: 0.071245 Batch F1: 0.6153846153846153
Epoch:  764       10 Batch loss: 0.075484 Batch F1: 0.0
Epoch:  764       11 Batch loss: 0.094731 Batch F1: 0.35294117647058826
Epoch:  764       12 Batch loss: 0.075540 Batch F1: 0.4
Train Avg Loss  764: 0.071881

Train Avg F1  764: 0.5609910650351827

Val Avg Loss  764: 0.064710

Val Avg F1  764:  0.9166666666666667

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 765
--------------------------------------------------------------
Epoch:  765        1 Batch loss: 0.093116 Batch F1: 0.7368421052631579
Epoch:  765        2 Batch loss: 0.080350 Batch F1: 0.8421052631578948
Epoch:  765        3 Batch loss: 0.062120 Batch F1: 1.0
Epoch:  765        4 Batch loss: 0.077930 Batch F1: 0.8571428571428571
Epoch:  765        5 Batch loss: 0.070486 Batch F1: 0.3636363636363636
Epoch:  765        6 Batch loss: 0.110073 Batch F1: 0.0
Epoch:  765        7 Batch loss: 0.076057 Batch F1: 0.9333333333333333
Epoch:  765        8 Batch loss: 0.054679 Batch F1: 1.0
Epoch:  765        9 Batch loss: 0.086575 Batch F1: 0.888888888888889
Epoch:  765       10 Batch loss: 0.066000 Batch F1: 1.0
Epoch:  765       11 Batch loss: 0.061828 Batch F1: 0.5
Epoch:  765       12 Batch loss: 0.099759 Batch F1: 0.0
Train Avg Loss  765: 0.078248

Train Avg F1  765: 0.6768290676185412

Val Avg Loss  765: 0.071935

Val Avg F1  765:  0.6160714285714285

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 766
--------------------------------------------------------------
Epoch:  766        1 Batch loss: 0.077466 Batch F1: 0.4
Epoch:  766        2 Batch loss: 0.065585 Batch F1: 0.5
Epoch:  766        3 Batch loss: 0.087739 Batch F1: 0.5
Epoch:  766        4 Batch loss: 0.067952 Batch F1: 0.923076923076923
Epoch:  766        5 Batch loss: 0.068973 Batch F1: 0.8571428571428571
Epoch:  766        6 Batch loss: 0.060548 Batch F1: 0.7499999999999999
Epoch:  766        7 Batch loss: 0.091894 Batch F1: 0.16666666666666669
Epoch:  766        8 Batch loss: 0.076707 Batch F1: 0.6153846153846153
Epoch:  766        9 Batch loss: 0.055655 Batch F1: 0.8571428571428571
Epoch:  766       10 Batch loss: 0.072316 Batch F1: 0.8
Epoch:  766       11 Batch loss: 0.065071 Batch F1: 1.0
Epoch:  766       12 Batch loss: 0.067238 Batch F1: 0.9333333333333333
Train Avg Loss  766: 0.071429

Train Avg F1  766: 0.6918956043956043

Val Avg Loss  766: 0.063451

Val Avg F1  766:  0.9032467532467532

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 767
--------------------------------------------------------------
Epoch:  767        1 Batch loss: 0.066693 Batch F1: 0.923076923076923
Epoch:  767        2 Batch loss: 0.072915 Batch F1: 0.888888888888889
Epoch:  767        3 Batch loss: 0.068549 Batch F1: 0.8750000000000001
Epoch:  767        4 Batch loss: 0.066544 Batch F1: 0.9523809523809523
Epoch:  767        5 Batch loss: 0.067393 Batch F1: 0.9411764705882353
Epoch:  767        6 Batch loss: 0.076332 Batch F1: 0.888888888888889
Epoch:  767        7 Batch loss: 0.060151 Batch F1: 0.9333333333333333
Epoch:  767        8 Batch loss: 0.055343 Batch F1: 1.0
Epoch:  767        9 Batch loss: 0.074633 Batch F1: 0.888888888888889
Epoch:  767       10 Batch loss: 0.061404 Batch F1: 0.6
Epoch:  767       11 Batch loss: 0.071642 Batch F1: 0.25
Epoch:  767       12 Batch loss: 0.086330 Batch F1: 0.7000000000000001
Train Avg Loss  767: 0.068994

Train Avg F1  767: 0.8201361955038425

Val Avg Loss  767: 0.062357

Val Avg F1  767:  0.695022624434389

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 768
--------------------------------------------------------------
Epoch:  768        1 Batch loss: 0.078372 Batch F1: 0.625
Epoch:  768        2 Batch loss: 0.043224 Batch F1: 1.0
Epoch:  768        3 Batch loss: 0.040342 Batch F1: 1.0
Epoch:  768        4 Batch loss: 0.090203 Batch F1: 0.8695652173913044
Epoch:  768        5 Batch loss: 0.066228 Batch F1: 0.9090909090909091
Epoch:  768        6 Batch loss: 0.061612 Batch F1: 0.4
Epoch:  768        7 Batch loss: 0.083148 Batch F1: 0.18181818181818182
Epoch:  768        8 Batch loss: 0.090689 Batch F1: 0.2857142857142857
Epoch:  768        9 Batch loss: 0.064528 Batch F1: 0.6666666666666666
Epoch:  768       10 Batch loss: 0.070280 Batch F1: 0.9090909090909091
Epoch:  768       11 Batch loss: 0.064804 Batch F1: 1.0
Epoch:  768       12 Batch loss: 0.069784 Batch F1: 0.9090909090909091
Train Avg Loss  768: 0.068601

Train Avg F1  768: 0.7296697565719305

Val Avg Loss  768: 0.062719

Val Avg F1  768:  0.9198412698412699

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 769
--------------------------------------------------------------
Epoch:  769        1 Batch loss: 0.085462 Batch F1: 0.9600000000000001
Epoch:  769        2 Batch loss: 0.067268 Batch F1: 0.7692307692307693
Epoch:  769        3 Batch loss: 0.054968 Batch F1: 1.0
Epoch:  769        4 Batch loss: 0.066569 Batch F1: 0.888888888888889
Epoch:  769        5 Batch loss: 0.068742 Batch F1: 0.9473684210526316
Epoch:  769        6 Batch loss: 0.058955 Batch F1: 0.9090909090909091
Epoch:  769        7 Batch loss: 0.064155 Batch F1: 0.8571428571428571
Epoch:  769        8 Batch loss: 0.052822 Batch F1: 1.0
Epoch:  769        9 Batch loss: 0.067836 Batch F1: 0.9411764705882353
Epoch:  769       10 Batch loss: 0.095739 Batch F1: 0.888888888888889
Epoch:  769       11 Batch loss: 0.067685 Batch F1: 0.923076923076923
Epoch:  769       12 Batch loss: 0.067908 Batch F1: 0.923076923076923
Train Avg Loss  769: 0.068176

Train Avg F1  769: 0.9173284209197522

Val Avg Loss  769: 0.063854

Val Avg F1  769:  0.9133597883597884

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 770
--------------------------------------------------------------
Epoch:  770        1 Batch loss: 0.090204 Batch F1: 0.88
Epoch:  770        2 Batch loss: 0.061277 Batch F1: 0.923076923076923
Epoch:  770        3 Batch loss: 0.064325 Batch F1: 0.9411764705882353
Epoch:  770        4 Batch loss: 0.069603 Batch F1: 0.4615384615384615
Epoch:  770        5 Batch loss: 0.058618 Batch F1: 0.9090909090909091
Epoch:  770        6 Batch loss: 0.075027 Batch F1: 0.5714285714285715
Epoch:  770        7 Batch loss: 0.058349 Batch F1: 1.0
Epoch:  770        8 Batch loss: 0.067565 Batch F1: 0.4444444444444445
Epoch:  770        9 Batch loss: 0.068642 Batch F1: 0.5714285714285715
Epoch:  770       10 Batch loss: 0.083961 Batch F1: 0.631578947368421
Epoch:  770       11 Batch loss: 0.070212 Batch F1: 0.888888888888889
Epoch:  770       12 Batch loss: 0.052273 Batch F1: 1.0
Train Avg Loss  770: 0.068338

Train Avg F1  770: 0.7685543489877854

Val Avg Loss  770: 0.060952

Val Avg F1  770:  0.9264556318332062

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 771
--------------------------------------------------------------
Epoch:  771        1 Batch loss: 0.058457 Batch F1: 1.0
Epoch:  771        2 Batch loss: 0.070929 Batch F1: 0.8571428571428571
Epoch:  771        3 Batch loss: 0.077629 Batch F1: 0.8421052631578948
Epoch:  771        4 Batch loss: 0.071148 Batch F1: 0.9523809523809523
Epoch:  771        5 Batch loss: 0.080499 Batch F1: 0.9565217391304348
Epoch:  771        6 Batch loss: 0.070421 Batch F1: 0.9
Epoch:  771        7 Batch loss: 0.060671 Batch F1: 1.0
Epoch:  771        8 Batch loss: 0.058255 Batch F1: 1.0
Epoch:  771        9 Batch loss: 0.081510 Batch F1: 0.7777777777777778
Epoch:  771       10 Batch loss: 0.073677 Batch F1: 0.888888888888889
Epoch:  771       11 Batch loss: 0.061943 Batch F1: 0.9333333333333333
Epoch:  771       12 Batch loss: 0.042450 Batch F1: 1.0
Train Avg Loss  771: 0.067299

Train Avg F1  771: 0.9256792343176783

Val Avg Loss  771: 0.061096

Val Avg F1  771:  0.9198778195488723

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 772
--------------------------------------------------------------
Epoch:  772        1 Batch loss: 0.086761 Batch F1: 0.9655172413793104
Epoch:  772        2 Batch loss: 0.087722 Batch F1: 0.8571428571428571
Epoch:  772        3 Batch loss: 0.062861 Batch F1: 0.9090909090909091
Epoch:  772        4 Batch loss: 0.061249 Batch F1: 1.0
Epoch:  772        5 Batch loss: 0.068052 Batch F1: 0.888888888888889
Epoch:  772        6 Batch loss: 0.071481 Batch F1: 0.9600000000000001
Epoch:  772        7 Batch loss: 0.064894 Batch F1: 1.0
Epoch:  772        8 Batch loss: 0.065705 Batch F1: 0.7692307692307693
Epoch:  772        9 Batch loss: 0.053683 Batch F1: 0.8571428571428571
Epoch:  772       10 Batch loss: 0.071285 Batch F1: 0.9
Epoch:  772       11 Batch loss: 0.044871 Batch F1: 1.0
Epoch:  772       12 Batch loss: 0.068720 Batch F1: 0.6666666666666666
Train Avg Loss  772: 0.067274

Train Avg F1  772: 0.8978066824618548

Val Avg Loss  772: 0.063369

Val Avg F1  772:  0.5929462694168577

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 773
--------------------------------------------------------------
Epoch:  773        1 Batch loss: 0.071444 Batch F1: 0.19999999999999998
Epoch:  773        2 Batch loss: 0.060761 Batch F1: 0.7692307692307693
Epoch:  773        3 Batch loss: 0.052520 Batch F1: 0.8
Epoch:  773        4 Batch loss: 0.056521 Batch F1: 0.5454545454545454
Epoch:  773        5 Batch loss: 0.078339 Batch F1: 0.3076923076923077
Epoch:  773        6 Batch loss: 0.084669 Batch F1: 0.7272727272727273
Epoch:  773        7 Batch loss: 0.073883 Batch F1: 0.9
Epoch:  773        8 Batch loss: 0.068130 Batch F1: 0.8571428571428571
Epoch:  773        9 Batch loss: 0.067005 Batch F1: 0.9090909090909091
Epoch:  773       10 Batch loss: 0.065454 Batch F1: 1.0
Epoch:  773       11 Batch loss: 0.075754 Batch F1: 0.9411764705882353
Epoch:  773       12 Batch loss: 0.067584 Batch F1: 1.0
Train Avg Loss  773: 0.068505

Train Avg F1  773: 0.7464217155393627

Val Avg Loss  773: 0.062599

Val Avg F1  773:  0.6734262125902992

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 774
--------------------------------------------------------------
Epoch:  774        1 Batch loss: 0.060867 Batch F1: 0.5
Epoch:  774        2 Batch loss: 0.077388 Batch F1: 0.3636363636363636
Epoch:  774        3 Batch loss: 0.058591 Batch F1: 0.6
Epoch:  774        4 Batch loss: 0.078126 Batch F1: 0.5
Epoch:  774        5 Batch loss: 0.052953 Batch F1: 0.6
Epoch:  774        6 Batch loss: 0.076280 Batch F1: 0.19999999999999998
Epoch:  774        7 Batch loss: 0.059032 Batch F1: 0.4444444444444445
Epoch:  774        8 Batch loss: 0.093631 Batch F1: 0.7272727272727273
Epoch:  774        9 Batch loss: 0.064553 Batch F1: 0.4444444444444445
Epoch:  774       10 Batch loss: 0.062468 Batch F1: 0.9523809523809523
Epoch:  774       11 Batch loss: 0.067104 Batch F1: 0.9523809523809523
Epoch:  774       12 Batch loss: 0.076113 Batch F1: 0.7692307692307693
Train Avg Loss  774: 0.068926

Train Avg F1  774: 0.5878158878158879

Val Avg Loss  774: 0.061842

Val Avg F1  774:  0.9293907846539424

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 775
--------------------------------------------------------------
Epoch:  775        1 Batch loss: 0.088857 Batch F1: 0.8695652173913044
Epoch:  775        2 Batch loss: 0.061208 Batch F1: 1.0
Epoch:  775        3 Batch loss: 0.069919 Batch F1: 0.923076923076923
Epoch:  775        4 Batch loss: 0.086339 Batch F1: 0.9166666666666666
Epoch:  775        5 Batch loss: 0.053435 Batch F1: 0.9333333333333333
Epoch:  775        6 Batch loss: 0.071210 Batch F1: 1.0
Epoch:  775        7 Batch loss: 0.081104 Batch F1: 0.8421052631578948
Epoch:  775        8 Batch loss: 0.059341 Batch F1: 0.8571428571428571
Epoch:  775        9 Batch loss: 0.065789 Batch F1: 0.8571428571428571
Epoch:  775       10 Batch loss: 0.052145 Batch F1: 1.0
Epoch:  775       11 Batch loss: 0.052993 Batch F1: 0.923076923076923
Epoch:  775       12 Batch loss: 0.076005 Batch F1: 0.923076923076923
Train Avg Loss  775: 0.068195

Train Avg F1  775: 0.9204322470054737

Val Avg Loss  775: 0.063326

Val Avg F1  775:  0.5925324675324676

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 776
--------------------------------------------------------------
Epoch:  776        1 Batch loss: 0.041336 Batch F1: 0.4
Epoch:  776        2 Batch loss: 0.059138 Batch F1: 0.0
Epoch:  776        3 Batch loss: 0.072950 Batch F1: 0.7368421052631579
Epoch:  776        4 Batch loss: 0.078281 Batch F1: 0.631578947368421
Epoch:  776        5 Batch loss: 0.093605 Batch F1: 0.4615384615384615
Epoch:  776        6 Batch loss: 0.065209 Batch F1: 0.9473684210526316
Epoch:  776        7 Batch loss: 0.065392 Batch F1: 0.923076923076923
Epoch:  776        8 Batch loss: 0.065073 Batch F1: 1.0
Epoch:  776        9 Batch loss: 0.082592 Batch F1: 0.9523809523809523
Epoch:  776       10 Batch loss: 0.085078 Batch F1: 0.8421052631578948
Epoch:  776       11 Batch loss: 0.074124 Batch F1: 1.0
Epoch:  776       12 Batch loss: 0.064628 Batch F1: 0.7692307692307693
Train Avg Loss  776: 0.070617

Train Avg F1  776: 0.722010153589101

Val Avg Loss  776: 0.064039

Val Avg F1  776:  0.9307017543859649

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 777
--------------------------------------------------------------
Epoch:  777        1 Batch loss: 0.057586 Batch F1: 0.8571428571428571
Epoch:  777        2 Batch loss: 0.061402 Batch F1: 0.9411764705882353
Epoch:  777        3 Batch loss: 0.070458 Batch F1: 1.0
Epoch:  777        4 Batch loss: 0.065912 Batch F1: 0.923076923076923
Epoch:  777        5 Batch loss: 0.073989 Batch F1: 0.9
Epoch:  777        6 Batch loss: 0.070672 Batch F1: 0.6666666666666666
Epoch:  777        7 Batch loss: 0.066216 Batch F1: 0.2222222222222222
Epoch:  777        8 Batch loss: 0.067093 Batch F1: 0.2222222222222222
Epoch:  777        9 Batch loss: 0.117630 Batch F1: 0.5925925925925926
Epoch:  777       10 Batch loss: 0.081227 Batch F1: 0.7142857142857143
Epoch:  777       11 Batch loss: 0.067577 Batch F1: 1.0
Epoch:  777       12 Batch loss: 0.052176 Batch F1: 1.0
Train Avg Loss  777: 0.070995

Train Avg F1  777: 0.7532821390664527

Val Avg Loss  777: 0.067663

Val Avg F1  777:  0.7164786967418547

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 778
--------------------------------------------------------------
Epoch:  778        1 Batch loss: 0.068127 Batch F1: 0.6666666666666666
Epoch:  778        2 Batch loss: 0.082435 Batch F1: 0.33333333333333337
Epoch:  778        3 Batch loss: 0.093456 Batch F1: 0.4
Epoch:  778        4 Batch loss: 0.071932 Batch F1: 0.4
Epoch:  778        5 Batch loss: 0.077643 Batch F1: 0.6666666666666666
Epoch:  778        6 Batch loss: 0.066878 Batch F1: 0.9090909090909091
Epoch:  778        7 Batch loss: 0.076493 Batch F1: 1.0
Epoch:  778        8 Batch loss: 0.064679 Batch F1: 0.9333333333333333
Epoch:  778        9 Batch loss: 0.061186 Batch F1: 0.9333333333333333
Epoch:  778       10 Batch loss: 0.073192 Batch F1: 0.19999999999999998
Epoch:  778       11 Batch loss: 0.057665 Batch F1: 0.4444444444444445
Epoch:  778       12 Batch loss: 0.097030 Batch F1: 0.33333333333333337
Train Avg Loss  778: 0.074226

Train Avg F1  778: 0.6016835016835017

Val Avg Loss  778: 0.064097

Val Avg F1  778:  0.7287081339712919

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 779
--------------------------------------------------------------
Epoch:  779        1 Batch loss: 0.061061 Batch F1: 0.7142857142857143
Epoch:  779        2 Batch loss: 0.041163 Batch F1: 1.0
Epoch:  779        3 Batch loss: 0.051607 Batch F1: 1.0
Epoch:  779        4 Batch loss: 0.087897 Batch F1: 1.0
Epoch:  779        5 Batch loss: 0.066792 Batch F1: 0.7272727272727273
Epoch:  779        6 Batch loss: 0.094261 Batch F1: 0.8
Epoch:  779        7 Batch loss: 0.072176 Batch F1: 0.7692307692307693
Epoch:  779        8 Batch loss: 0.092069 Batch F1: 0.8571428571428571
Epoch:  779        9 Batch loss: 0.056605 Batch F1: 1.0
Epoch:  779       10 Batch loss: 0.068260 Batch F1: 0.9523809523809523
Epoch:  779       11 Batch loss: 0.080675 Batch F1: 0.8333333333333333
Epoch:  779       12 Batch loss: 0.078804 Batch F1: 1.0
Train Avg Loss  779: 0.070947

Train Avg F1  779: 0.8878038628038628

Val Avg Loss  779: 0.065855

Val Avg F1  779:  0.5804924242424242

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 780
--------------------------------------------------------------
Epoch:  780        1 Batch loss: 0.080197 Batch F1: 0.5882352941176471
Epoch:  780        2 Batch loss: 0.088330 Batch F1: 0.6
Epoch:  780        3 Batch loss: 0.060622 Batch F1: 0.8333333333333333
Epoch:  780        4 Batch loss: 0.061026 Batch F1: 0.5
Epoch:  780        5 Batch loss: 0.054719 Batch F1: 0.6666666666666666
Epoch:  780        6 Batch loss: 0.064060 Batch F1: 0.25
Epoch:  780        7 Batch loss: 0.061533 Batch F1: 0.2222222222222222
Epoch:  780        8 Batch loss: 0.074458 Batch F1: 0.5
Epoch:  780        9 Batch loss: 0.076564 Batch F1: 0.19999999999999998
Epoch:  780       10 Batch loss: 0.075067 Batch F1: 0.6666666666666666
Epoch:  780       11 Batch loss: 0.074153 Batch F1: 0.6666666666666666
Epoch:  780       12 Batch loss: 0.073004 Batch F1: 0.7499999999999999
Train Avg Loss  780: 0.070311

Train Avg F1  780: 0.5369825708061003

Val Avg Loss  780: 0.062263

Val Avg F1  780:  0.9244200244200245

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 781
--------------------------------------------------------------
Epoch:  781        1 Batch loss: 0.038627 Batch F1: 1.0
Epoch:  781        2 Batch loss: 0.061245 Batch F1: 0.6153846153846153
Epoch:  781        3 Batch loss: 0.065242 Batch F1: 0.761904761904762
Epoch:  781        4 Batch loss: 0.071445 Batch F1: 0.8750000000000001
Epoch:  781        5 Batch loss: 0.074959 Batch F1: 0.9523809523809523
Epoch:  781        6 Batch loss: 0.080751 Batch F1: 0.8750000000000001
Epoch:  781        7 Batch loss: 0.057833 Batch F1: 0.9411764705882353
Epoch:  781        8 Batch loss: 0.040979 Batch F1: 1.0
Epoch:  781        9 Batch loss: 0.071348 Batch F1: 0.4615384615384615
Epoch:  781       10 Batch loss: 0.084674 Batch F1: 0.4615384615384615
Epoch:  781       11 Batch loss: 0.108338 Batch F1: 0.2666666666666667
Epoch:  781       12 Batch loss: 0.081267 Batch F1: 0.18181818181818182
Train Avg Loss  781: 0.069726

Train Avg F1  781: 0.699367380985028

Val Avg Loss  781: 0.061687

Val Avg F1  781:  0.9173116615067081

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 782
--------------------------------------------------------------
Epoch:  782        1 Batch loss: 0.052786 Batch F1: 0.923076923076923
Epoch:  782        2 Batch loss: 0.086004 Batch F1: 0.9
Epoch:  782        3 Batch loss: 0.060048 Batch F1: 0.9333333333333333
Epoch:  782        4 Batch loss: 0.070400 Batch F1: 1.0
Epoch:  782        5 Batch loss: 0.072228 Batch F1: 0.9
Epoch:  782        6 Batch loss: 0.057335 Batch F1: 1.0
Epoch:  782        7 Batch loss: 0.064902 Batch F1: 0.923076923076923
Epoch:  782        8 Batch loss: 0.075183 Batch F1: 0.8235294117647058
Epoch:  782        9 Batch loss: 0.079185 Batch F1: 0.8235294117647058
Epoch:  782       10 Batch loss: 0.070775 Batch F1: 0.9473684210526316
Epoch:  782       11 Batch loss: 0.070464 Batch F1: 0.888888888888889
Epoch:  782       12 Batch loss: 0.056292 Batch F1: 1.0
Train Avg Loss  782: 0.067967

Train Avg F1  782: 0.9219002760798428

Val Avg Loss  782: 0.061633

Val Avg F1  782:  0.9303490627020039

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 783
--------------------------------------------------------------
Epoch:  783        1 Batch loss: 0.069653 Batch F1: 0.9411764705882353
Epoch:  783        2 Batch loss: 0.071187 Batch F1: 0.8571428571428571
Epoch:  783        3 Batch loss: 0.076387 Batch F1: 0.8235294117647058
Epoch:  783        4 Batch loss: 0.072815 Batch F1: 0.8235294117647058
Epoch:  783        5 Batch loss: 0.061417 Batch F1: 0.9090909090909091
Epoch:  783        6 Batch loss: 0.073370 Batch F1: 1.0
Epoch:  783        7 Batch loss: 0.073118 Batch F1: 1.0
Epoch:  783        8 Batch loss: 0.056161 Batch F1: 0.9411764705882353
Epoch:  783        9 Batch loss: 0.067723 Batch F1: 0.9411764705882353
Epoch:  783       10 Batch loss: 0.050946 Batch F1: 1.0
Epoch:  783       11 Batch loss: 0.066468 Batch F1: 0.8750000000000001
Epoch:  783       12 Batch loss: 0.072663 Batch F1: 0.9090909090909091
Train Avg Loss  783: 0.067659

Train Avg F1  783: 0.9184094092182327

Val Avg Loss  783: 0.061718

Val Avg F1  783:  0.6027243589743589

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 784
--------------------------------------------------------------
Epoch:  784        1 Batch loss: 0.057167 Batch F1: 0.5454545454545454
Epoch:  784        2 Batch loss: 0.067747 Batch F1: 0.5714285714285715
Epoch:  784        3 Batch loss: 0.054656 Batch F1: 0.6
Epoch:  784        4 Batch loss: 0.114060 Batch F1: 0.2666666666666667
Epoch:  784        5 Batch loss: 0.055141 Batch F1: 0.4
Epoch:  784        6 Batch loss: 0.075579 Batch F1: 0.33333333333333337
Epoch:  784        7 Batch loss: 0.058005 Batch F1: 0.9411764705882353
Epoch:  784        8 Batch loss: 0.062009 Batch F1: 1.0
Epoch:  784        9 Batch loss: 0.070808 Batch F1: 0.9473684210526316
Epoch:  784       10 Batch loss: 0.049854 Batch F1: 1.0
Epoch:  784       11 Batch loss: 0.057890 Batch F1: 1.0
Epoch:  784       12 Batch loss: 0.102132 Batch F1: 0.7058823529411764
Train Avg Loss  784: 0.068754

Train Avg F1  784: 0.6926091967887634

Val Avg Loss  784: 0.060871

Val Avg F1  784:  0.9159722222222223

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 785
--------------------------------------------------------------
Epoch:  785        1 Batch loss: 0.060976 Batch F1: 0.8333333333333333
Epoch:  785        2 Batch loss: 0.085074 Batch F1: 0.8421052631578948
Epoch:  785        3 Batch loss: 0.072862 Batch F1: 0.8571428571428571
Epoch:  785        4 Batch loss: 0.069836 Batch F1: 0.9473684210526316
Epoch:  785        5 Batch loss: 0.069856 Batch F1: 0.9
Epoch:  785        6 Batch loss: 0.067386 Batch F1: 0.9
Epoch:  785        7 Batch loss: 0.058857 Batch F1: 0.9090909090909091
Epoch:  785        8 Batch loss: 0.068130 Batch F1: 0.9523809523809523
Epoch:  785        9 Batch loss: 0.051131 Batch F1: 1.0
Epoch:  785       10 Batch loss: 0.066270 Batch F1: 0.7272727272727273
Epoch:  785       11 Batch loss: 0.074129 Batch F1: 0.5714285714285715
Epoch:  785       12 Batch loss: 0.065694 Batch F1: 0.8571428571428571
Train Avg Loss  785: 0.067517

Train Avg F1  785: 0.858105491000228

Val Avg Loss  785: 0.061455

Val Avg F1  785:  0.5383838383838384

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 786
--------------------------------------------------------------
Epoch:  786        1 Batch loss: 0.050317 Batch F1: 0.5714285714285715
Epoch:  786        2 Batch loss: 0.070161 Batch F1: 0.0
Epoch:  786        3 Batch loss: 0.078906 Batch F1: 0.5882352941176471
Epoch:  786        4 Batch loss: 0.073151 Batch F1: 0.7000000000000001
Epoch:  786        5 Batch loss: 0.065379 Batch F1: 0.5
Epoch:  786        6 Batch loss: 0.048557 Batch F1: 0.5
Epoch:  786        7 Batch loss: 0.088999 Batch F1: 0.88
Epoch:  786        8 Batch loss: 0.071894 Batch F1: 0.9523809523809523
Epoch:  786        9 Batch loss: 0.068261 Batch F1: 1.0
Epoch:  786       10 Batch loss: 0.068509 Batch F1: 0.8571428571428571
Epoch:  786       11 Batch loss: 0.066886 Batch F1: 0.8571428571428571
Epoch:  786       12 Batch loss: 0.072831 Batch F1: 0.923076923076923
Train Avg Loss  786: 0.068654

Train Avg F1  786: 0.6941172879408173

Val Avg Loss  786: 0.061175

Val Avg F1  786:  0.9352941176470588

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 787
--------------------------------------------------------------
Epoch:  787        1 Batch loss: 0.068482 Batch F1: 0.9
Epoch:  787        2 Batch loss: 0.065612 Batch F1: 0.9565217391304348
Epoch:  787        3 Batch loss: 0.049293 Batch F1: 1.0
Epoch:  787        4 Batch loss: 0.073373 Batch F1: 0.9523809523809523
Epoch:  787        5 Batch loss: 0.064537 Batch F1: 0.9333333333333333
Epoch:  787        6 Batch loss: 0.060213 Batch F1: 0.9333333333333333
Epoch:  787        7 Batch loss: 0.082609 Batch F1: 0.8
Epoch:  787        8 Batch loss: 0.083228 Batch F1: 0.9090909090909091
Epoch:  787        9 Batch loss: 0.075685 Batch F1: 0.888888888888889
Epoch:  787       10 Batch loss: 0.048749 Batch F1: 1.0
Epoch:  787       11 Batch loss: 0.079598 Batch F1: 0.888888888888889
Epoch:  787       12 Batch loss: 0.045671 Batch F1: 0.8
Train Avg Loss  787: 0.066421

Train Avg F1  787: 0.9135365037538952

Val Avg Loss  787: 0.061819

Val Avg F1  787:  0.5383771929824561

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 788
--------------------------------------------------------------
Epoch:  788        1 Batch loss: 0.055590 Batch F1: 0.888888888888889
Epoch:  788        2 Batch loss: 0.081100 Batch F1: 0.18181818181818182
Epoch:  788        3 Batch loss: 0.059628 Batch F1: 0.6
Epoch:  788        4 Batch loss: 0.059255 Batch F1: 0.5454545454545454
Epoch:  788        5 Batch loss: 0.086954 Batch F1: 0.2666666666666667
Epoch:  788        6 Batch loss: 0.052851 Batch F1: 0.7272727272727273
Epoch:  788        7 Batch loss: 0.078473 Batch F1: 0.888888888888889
Epoch:  788        8 Batch loss: 0.052361 Batch F1: 1.0
Epoch:  788        9 Batch loss: 0.058736 Batch F1: 1.0
Epoch:  788       10 Batch loss: 0.076321 Batch F1: 0.8750000000000001
Epoch:  788       11 Batch loss: 0.065978 Batch F1: 1.0
Epoch:  788       12 Batch loss: 0.089087 Batch F1: 0.8421052631578948
Train Avg Loss  788: 0.068028

Train Avg F1  788: 0.7346745968456495

Val Avg Loss  788: 0.061037

Val Avg F1  788:  0.9247468218056454

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 789
--------------------------------------------------------------
Epoch:  789        1 Batch loss: 0.072414 Batch F1: 0.9473684210526316
Epoch:  789        2 Batch loss: 0.075051 Batch F1: 0.9
Epoch:  789        3 Batch loss: 0.054201 Batch F1: 1.0
Epoch:  789        4 Batch loss: 0.066359 Batch F1: 0.8333333333333333
Epoch:  789        5 Batch loss: 0.060789 Batch F1: 0.9411764705882353
Epoch:  789        6 Batch loss: 0.071093 Batch F1: 0.8333333333333333
Epoch:  789        7 Batch loss: 0.059670 Batch F1: 0.9411764705882353
Epoch:  789        8 Batch loss: 0.062741 Batch F1: 0.8333333333333333
Epoch:  789        9 Batch loss: 0.070566 Batch F1: 1.0
Epoch:  789       10 Batch loss: 0.063745 Batch F1: 0.8
Epoch:  789       11 Batch loss: 0.076371 Batch F1: 0.5
Epoch:  789       12 Batch loss: 0.072369 Batch F1: 0.5333333333333333
Train Avg Loss  789: 0.067114

Train Avg F1  789: 0.8385878912968697

Val Avg Loss  789: 0.061361

Val Avg F1  789:  0.9154135338345866

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 790
--------------------------------------------------------------
Epoch:  790        1 Batch loss: 0.067067 Batch F1: 0.9473684210526316
Epoch:  790        2 Batch loss: 0.048268 Batch F1: 0.8571428571428571
Epoch:  790        3 Batch loss: 0.071170 Batch F1: 0.9523809523809523
Epoch:  790        4 Batch loss: 0.090736 Batch F1: 0.6666666666666666
Epoch:  790        5 Batch loss: 0.064320 Batch F1: 0.9411764705882353
Epoch:  790        6 Batch loss: 0.087475 Batch F1: 0.967741935483871
Epoch:  790        7 Batch loss: 0.080760 Batch F1: 0.8421052631578948
Epoch:  790        8 Batch loss: 0.076173 Batch F1: 0.9600000000000001
Epoch:  790        9 Batch loss: 0.074008 Batch F1: 0.9523809523809523
Epoch:  790       10 Batch loss: 0.050732 Batch F1: 1.0
Epoch:  790       11 Batch loss: 0.054343 Batch F1: 1.0
Epoch:  790       12 Batch loss: 0.047779 Batch F1: 0.9090909090909091
Train Avg Loss  790: 0.067736

Train Avg F1  790: 0.9163378689954141

Val Avg Loss  790: 0.061004

Val Avg F1  790:  0.924342105263158

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 791
--------------------------------------------------------------
Epoch:  791        1 Batch loss: 0.080960 Batch F1: 0.888888888888889
Epoch:  791        2 Batch loss: 0.045295 Batch F1: 0.888888888888889
Epoch:  791        3 Batch loss: 0.084007 Batch F1: 0.5
Epoch:  791        4 Batch loss: 0.063441 Batch F1: 0.0
Epoch:  791        5 Batch loss: 0.075646 Batch F1: 0.3076923076923077
Epoch:  791        6 Batch loss: 0.073556 Batch F1: 0.7000000000000001
Epoch:  791        7 Batch loss: 0.070391 Batch F1: 0.8333333333333333
Epoch:  791        8 Batch loss: 0.064171 Batch F1: 1.0
Epoch:  791        9 Batch loss: 0.057699 Batch F1: 0.8
Epoch:  791       10 Batch loss: 0.061543 Batch F1: 0.9333333333333333
Epoch:  791       11 Batch loss: 0.061116 Batch F1: 0.9090909090909091
Epoch:  791       12 Batch loss: 0.078972 Batch F1: 0.888888888888889
Train Avg Loss  791: 0.068066

Train Avg F1  791: 0.7208430458430458

Val Avg Loss  791: 0.061957

Val Avg F1  791:  0.9209001782531194

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 792
--------------------------------------------------------------
Epoch:  792        1 Batch loss: 0.069559 Batch F1: 0.9523809523809523
Epoch:  792        2 Batch loss: 0.057383 Batch F1: 0.923076923076923
Epoch:  792        3 Batch loss: 0.053948 Batch F1: 1.0
Epoch:  792        4 Batch loss: 0.081725 Batch F1: 1.0
Epoch:  792        5 Batch loss: 0.073167 Batch F1: 0.9523809523809523
Epoch:  792        6 Batch loss: 0.063998 Batch F1: 0.9600000000000001
Epoch:  792        7 Batch loss: 0.084272 Batch F1: 0.8
Epoch:  792        8 Batch loss: 0.066166 Batch F1: 0.923076923076923
Epoch:  792        9 Batch loss: 0.056419 Batch F1: 0.923076923076923
Epoch:  792       10 Batch loss: 0.090128 Batch F1: 0.7058823529411764
Epoch:  792       11 Batch loss: 0.061699 Batch F1: 0.8333333333333333
Epoch:  792       12 Batch loss: 0.054637 Batch F1: 1.0
Train Avg Loss  792: 0.067759

Train Avg F1  792: 0.9144340300222652

Val Avg Loss  792: 0.061261

Val Avg F1  792:  0.9173116615067081

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 793
--------------------------------------------------------------
Epoch:  793        1 Batch loss: 0.075360 Batch F1: 0.9600000000000001
Epoch:  793        2 Batch loss: 0.065469 Batch F1: 0.9411764705882353
Epoch:  793        3 Batch loss: 0.069113 Batch F1: 0.9523809523809523
Epoch:  793        4 Batch loss: 0.075580 Batch F1: 0.888888888888889
Epoch:  793        5 Batch loss: 0.059105 Batch F1: 0.923076923076923
Epoch:  793        6 Batch loss: 0.064757 Batch F1: 1.0
Epoch:  793        7 Batch loss: 0.057162 Batch F1: 1.0
Epoch:  793        8 Batch loss: 0.068215 Batch F1: 0.9333333333333333
Epoch:  793        9 Batch loss: 0.059818 Batch F1: 0.9333333333333333
Epoch:  793       10 Batch loss: 0.088949 Batch F1: 0.7058823529411764
Epoch:  793       11 Batch loss: 0.054220 Batch F1: 1.0
Epoch:  793       12 Batch loss: 0.070629 Batch F1: 0.5714285714285715
Train Avg Loss  793: 0.067365

Train Avg F1  793: 0.9007917354976178

Val Avg Loss  793: 0.061148

Val Avg F1  793:  0.7419467787114846

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 794
--------------------------------------------------------------
Epoch:  794        1 Batch loss: 0.049831 Batch F1: 0.888888888888889
Epoch:  794        2 Batch loss: 0.079236 Batch F1: 0.42857142857142855
Epoch:  794        3 Batch loss: 0.084913 Batch F1: 0.6
Epoch:  794        4 Batch loss: 0.077696 Batch F1: 0.6666666666666666
Epoch:  794        5 Batch loss: 0.074615 Batch F1: 1.0
Epoch:  794        6 Batch loss: 0.075527 Batch F1: 0.9411764705882353
Epoch:  794        7 Batch loss: 0.065243 Batch F1: 0.923076923076923
Epoch:  794        8 Batch loss: 0.048743 Batch F1: 0.5714285714285715
Epoch:  794        9 Batch loss: 0.044860 Batch F1: 0.888888888888889
Epoch:  794       10 Batch loss: 0.100740 Batch F1: 0.0
Epoch:  794       11 Batch loss: 0.074845 Batch F1: 0.6666666666666666
Epoch:  794       12 Batch loss: 0.071904 Batch F1: 0.4
Train Avg Loss  794: 0.070679

Train Avg F1  794: 0.6646137087313558

Val Avg Loss  794: 0.065811

Val Avg F1  794:  0.9079949036470776

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 795
--------------------------------------------------------------
Epoch:  795        1 Batch loss: 0.061214 Batch F1: 0.888888888888889
Epoch:  795        2 Batch loss: 0.081609 Batch F1: 0.5333333333333333
Epoch:  795        3 Batch loss: 0.065318 Batch F1: 0.7499999999999999
Epoch:  795        4 Batch loss: 0.093305 Batch F1: 0.2857142857142857
Epoch:  795        5 Batch loss: 0.057911 Batch F1: 0.8
Epoch:  795        6 Batch loss: 0.086475 Batch F1: 0.5555555555555556
Epoch:  795        7 Batch loss: 0.062876 Batch F1: 1.0
Epoch:  795        8 Batch loss: 0.094376 Batch F1: 0.8571428571428571
Epoch:  795        9 Batch loss: 0.074400 Batch F1: 1.0
Epoch:  795       10 Batch loss: 0.055641 Batch F1: 0.8571428571428571
Epoch:  795       11 Batch loss: 0.064757 Batch F1: 0.2222222222222222
Epoch:  795       12 Batch loss: 0.055686 Batch F1: 0.888888888888889
Train Avg Loss  795: 0.071131

Train Avg F1  795: 0.7199074074074073

Val Avg Loss  795: 0.068391

Val Avg F1  795:  0.5865384615384616

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 796
--------------------------------------------------------------
Epoch:  796        1 Batch loss: 0.064792 Batch F1: 0.7272727272727273
Epoch:  796        2 Batch loss: 0.078085 Batch F1: 0.0
Epoch:  796        3 Batch loss: 0.043739 Batch F1: 0.7499999999999999
Epoch:  796        4 Batch loss: 0.108098 Batch F1: 0.5714285714285715
Epoch:  796        5 Batch loss: 0.092478 Batch F1: 0.5263157894736842
Epoch:  796        6 Batch loss: 0.076004 Batch F1: 0.9473684210526316
Epoch:  796        7 Batch loss: 0.075913 Batch F1: 0.8571428571428571
Epoch:  796        8 Batch loss: 0.062170 Batch F1: 1.0
Epoch:  796        9 Batch loss: 0.073234 Batch F1: 0.9333333333333333
Epoch:  796       10 Batch loss: 0.056859 Batch F1: 0.6666666666666666
Epoch:  796       11 Batch loss: 0.079583 Batch F1: 0.5333333333333333
Epoch:  796       12 Batch loss: 0.055187 Batch F1: 0.6666666666666666
Train Avg Loss  796: 0.072179

Train Avg F1  796: 0.681627363864206

Val Avg Loss  796: 0.063618

Val Avg F1  796:  0.4773755656108597

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 797
--------------------------------------------------------------
Epoch:  797        1 Batch loss: 0.092040 Batch F1: 0.4
Epoch:  797        2 Batch loss: 0.059401 Batch F1: 0.6666666666666666
Epoch:  797        3 Batch loss: 0.068886 Batch F1: 0.9473684210526316
Epoch:  797        4 Batch loss: 0.079020 Batch F1: 0.888888888888889
Epoch:  797        5 Batch loss: 0.054509 Batch F1: 0.2857142857142857
Epoch:  797        6 Batch loss: 0.079848 Batch F1: 0.42857142857142855
Epoch:  797        7 Batch loss: 0.077267 Batch F1: 0.5333333333333333
Epoch:  797        8 Batch loss: 0.040322 Batch F1: 1.0
Epoch:  797        9 Batch loss: 0.069056 Batch F1: 0.3636363636363636
Epoch:  797       10 Batch loss: 0.078499 Batch F1: 0.33333333333333337
Epoch:  797       11 Batch loss: 0.058000 Batch F1: 0.4444444444444445
Epoch:  797       12 Batch loss: 0.076375 Batch F1: 0.9473684210526316
Train Avg Loss  797: 0.069435

Train Avg F1  797: 0.6032771322245006

Val Avg Loss  797: 0.060994

Val Avg F1  797:  0.9333333333333333

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 798
--------------------------------------------------------------
Epoch:  798        1 Batch loss: 0.075319 Batch F1: 0.9523809523809523
Epoch:  798        2 Batch loss: 0.054151 Batch F1: 1.0
Epoch:  798        3 Batch loss: 0.060399 Batch F1: 0.923076923076923
Epoch:  798        4 Batch loss: 0.038037 Batch F1: 1.0
Epoch:  798        5 Batch loss: 0.085496 Batch F1: 0.7272727272727273
Epoch:  798        6 Batch loss: 0.068629 Batch F1: 1.0
Epoch:  798        7 Batch loss: 0.038339 Batch F1: 1.0
Epoch:  798        8 Batch loss: 0.118474 Batch F1: 0.0
Epoch:  798        9 Batch loss: 0.074545 Batch F1: 0.8235294117647058
Epoch:  798       10 Batch loss: 0.098077 Batch F1: 0.8695652173913044
Epoch:  798       11 Batch loss: 0.083532 Batch F1: 0.8571428571428572
Epoch:  798       12 Batch loss: 0.072755 Batch F1: 0.9333333333333333
Train Avg Loss  798: 0.072313

Train Avg F1  798: 0.8405251185302336

Val Avg Loss  798: 0.065757

Val Avg F1  798:  0.9308823529411765

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 799
--------------------------------------------------------------
Epoch:  799        1 Batch loss: 0.079455 Batch F1: 0.9473684210526316
Epoch:  799        2 Batch loss: 0.087554 Batch F1: 0.0
Epoch:  799        3 Batch loss: 0.065117 Batch F1: 0.8571428571428571
Epoch:  799        4 Batch loss: 0.066751 Batch F1: 0.9473684210526316
Epoch:  799        5 Batch loss: 0.068149 Batch F1: 0.9333333333333333
Epoch:  799        6 Batch loss: 0.090472 Batch F1: 0.8421052631578948
Epoch:  799        7 Batch loss: 0.063861 Batch F1: 0.6666666666666666
Epoch:  799        8 Batch loss: 0.067259 Batch F1: 0.3636363636363636
Epoch:  799        9 Batch loss: 0.053087 Batch F1: 0.7272727272727273
Epoch:  799       10 Batch loss: 0.058751 Batch F1: 0.6
Epoch:  799       11 Batch loss: 0.062642 Batch F1: 0.5454545454545454
Epoch:  799       12 Batch loss: 0.105203 Batch F1: 0.3076923076923077
Train Avg Loss  799: 0.072358

Train Avg F1  799: 0.6448367422051632

Val Avg Loss  799: 0.063772

Val Avg F1  799:  0.9199849170437406

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 800
--------------------------------------------------------------
Epoch:  800        1 Batch loss: 0.066872 Batch F1: 0.8750000000000001
Epoch:  800        2 Batch loss: 0.070996 Batch F1: 0.6
Epoch:  800        3 Batch loss: 0.085161 Batch F1: 0.42857142857142855
Epoch:  800        4 Batch loss: 0.053891 Batch F1: 0.5
Epoch:  800        5 Batch loss: 0.064820 Batch F1: 0.6666666666666666
Epoch:  800        6 Batch loss: 0.069588 Batch F1: 0.5714285714285715
Epoch:  800        7 Batch loss: 0.060120 Batch F1: 0.2857142857142857
Epoch:  800        8 Batch loss: 0.079305 Batch F1: 0.16666666666666669
Epoch:  800        9 Batch loss: 0.055586 Batch F1: 0.9411764705882353
Epoch:  800       10 Batch loss: 0.081387 Batch F1: 1.0
Epoch:  800       11 Batch loss: 0.086870 Batch F1: 0.8333333333333333
Epoch:  800       12 Batch loss: 0.058549 Batch F1: 1.0
Train Avg Loss  800: 0.069429

Train Avg F1  800: 0.6557131185807656

Val Avg Loss  800: 0.062411

Val Avg F1  800:  0.929044117647059

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 801
--------------------------------------------------------------
Epoch:  801        1 Batch loss: 0.081415 Batch F1: 0.7499999999999999
Epoch:  801        2 Batch loss: 0.070738 Batch F1: 1.0
Epoch:  801        3 Batch loss: 0.076739 Batch F1: 0.9
Epoch:  801        4 Batch loss: 0.077543 Batch F1: 0.9600000000000001
Epoch:  801        5 Batch loss: 0.051969 Batch F1: 0.923076923076923
Epoch:  801        6 Batch loss: 0.061637 Batch F1: 0.9333333333333333
Epoch:  801        7 Batch loss: 0.052961 Batch F1: 0.9090909090909091
Epoch:  801        8 Batch loss: 0.064284 Batch F1: 1.0
Epoch:  801        9 Batch loss: 0.083834 Batch F1: 0.5
Epoch:  801       10 Batch loss: 0.057997 Batch F1: 1.0
Epoch:  801       11 Batch loss: 0.070115 Batch F1: 0.7692307692307693
Epoch:  801       12 Batch loss: 0.061441 Batch F1: 0.8
Train Avg Loss  801: 0.067556

Train Avg F1  801: 0.8703943278943281

Val Avg Loss  801: 0.061644

Val Avg F1  801:  0.9244200244200244

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 802
--------------------------------------------------------------
Epoch:  802        1 Batch loss: 0.058414 Batch F1: 1.0
Epoch:  802        2 Batch loss: 0.064088 Batch F1: 0.8333333333333333
Epoch:  802        3 Batch loss: 0.073057 Batch F1: 0.888888888888889
Epoch:  802        4 Batch loss: 0.058700 Batch F1: 0.8
Epoch:  802        5 Batch loss: 0.077677 Batch F1: 0.8235294117647058
Epoch:  802        6 Batch loss: 0.060024 Batch F1: 0.8333333333333333
Epoch:  802        7 Batch loss: 0.075196 Batch F1: 0.9523809523809523
Epoch:  802        8 Batch loss: 0.060909 Batch F1: 0.923076923076923
Epoch:  802        9 Batch loss: 0.065445 Batch F1: 0.9473684210526316
Epoch:  802       10 Batch loss: 0.050816 Batch F1: 1.0
Epoch:  802       11 Batch loss: 0.065015 Batch F1: 1.0
Epoch:  802       12 Batch loss: 0.100240 Batch F1: 0.9
Train Avg Loss  802: 0.067465

Train Avg F1  802: 0.9084926053192307

Val Avg Loss  802: 0.061285

Val Avg F1  802:  0.9086507936507937

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 803
--------------------------------------------------------------
Epoch:  803        1 Batch loss: 0.065542 Batch F1: 0.9
Epoch:  803        2 Batch loss: 0.078191 Batch F1: 0.9411764705882353
Epoch:  803        3 Batch loss: 0.066327 Batch F1: 0.9333333333333333
Epoch:  803        4 Batch loss: 0.082794 Batch F1: 0.9655172413793104
Epoch:  803        5 Batch loss: 0.046409 Batch F1: 0.888888888888889
Epoch:  803        6 Batch loss: 0.085873 Batch F1: 0.8
Epoch:  803        7 Batch loss: 0.054513 Batch F1: 0.9473684210526316
Epoch:  803        8 Batch loss: 0.073469 Batch F1: 1.0
Epoch:  803        9 Batch loss: 0.054069 Batch F1: 0.8
Epoch:  803       10 Batch loss: 0.075515 Batch F1: 0.9411764705882353
Epoch:  803       11 Batch loss: 0.053961 Batch F1: 0.7692307692307693
Epoch:  803       12 Batch loss: 0.070001 Batch F1: 0.0
Train Avg Loss  803: 0.067222

Train Avg F1  803: 0.8238909662551172

Val Avg Loss  803: 0.061392

Val Avg F1  803:  0.5567014684661744

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 804
--------------------------------------------------------------
Epoch:  804        1 Batch loss: 0.091423 Batch F1: 0.2666666666666667
Epoch:  804        2 Batch loss: 0.039274 Batch F1: 1.0
Epoch:  804        3 Batch loss: 0.068784 Batch F1: 0.8571428571428571
Epoch:  804        4 Batch loss: 0.063706 Batch F1: 1.0
Epoch:  804        5 Batch loss: 0.073458 Batch F1: 0.8
Epoch:  804        6 Batch loss: 0.061525 Batch F1: 1.0
Epoch:  804        7 Batch loss: 0.040385 Batch F1: 1.0
Epoch:  804        8 Batch loss: 0.055674 Batch F1: 1.0
Epoch:  804        9 Batch loss: 0.043332 Batch F1: 0.8
Epoch:  804       10 Batch loss: 0.114763 Batch F1: 0.47619047619047616
Epoch:  804       11 Batch loss: 0.085595 Batch F1: 0.8571428571428571
Epoch:  804       12 Batch loss: 0.075672 Batch F1: 0.9473684210526316
Train Avg Loss  804: 0.067799

Train Avg F1  804: 0.8337092731829574

Val Avg Loss  804: 0.061455

Val Avg F1  804:  0.9249373433583961

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 805
--------------------------------------------------------------
Epoch:  805        1 Batch loss: 0.076811 Batch F1: 0.9600000000000001
Epoch:  805        2 Batch loss: 0.066734 Batch F1: 1.0
Epoch:  805        3 Batch loss: 0.060890 Batch F1: 0.9090909090909091
Epoch:  805        4 Batch loss: 0.086296 Batch F1: 0.8
Epoch:  805        5 Batch loss: 0.064662 Batch F1: 1.0
Epoch:  805        6 Batch loss: 0.071541 Batch F1: 1.0
Epoch:  805        7 Batch loss: 0.077767 Batch F1: 0.8750000000000001
Epoch:  805        8 Batch loss: 0.069798 Batch F1: 0.9411764705882353
Epoch:  805        9 Batch loss: 0.072939 Batch F1: 0.8571428571428571
Epoch:  805       10 Batch loss: 0.068198 Batch F1: 0.8750000000000001
Epoch:  805       11 Batch loss: 0.062828 Batch F1: 0.8571428571428571
Epoch:  805       12 Batch loss: 0.032225 Batch F1: 1.0
Train Avg Loss  805: 0.067557

Train Avg F1  805: 0.9228794244970716

Val Avg Loss  805: 0.068220

Val Avg F1  805:  0.5481913919413919

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 806
--------------------------------------------------------------
Epoch:  806        1 Batch loss: 0.098667 Batch F1: 0.47058823529411764
Epoch:  806        2 Batch loss: 0.064319 Batch F1: 0.7142857142857143
Epoch:  806        3 Batch loss: 0.096364 Batch F1: 0.4444444444444445
Epoch:  806        4 Batch loss: 0.072546 Batch F1: 0.6666666666666666
Epoch:  806        5 Batch loss: 0.068953 Batch F1: 0.888888888888889
Epoch:  806        6 Batch loss: 0.072896 Batch F1: 0.923076923076923
Epoch:  806        7 Batch loss: 0.046712 Batch F1: 1.0
Epoch:  806        8 Batch loss: 0.073866 Batch F1: 0.4615384615384615
Epoch:  806        9 Batch loss: 0.085845 Batch F1: 0.0
Epoch:  806       10 Batch loss: 0.076611 Batch F1: 0.19999999999999998
Epoch:  806       11 Batch loss: 0.065772 Batch F1: 0.7692307692307693
Epoch:  806       12 Batch loss: 0.072291 Batch F1: 0.8571428571428571
Train Avg Loss  806: 0.074570

Train Avg F1  806: 0.6163219133807368

Val Avg Loss  806: 0.062777

Val Avg F1  806:  0.5757305194805195

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 807
--------------------------------------------------------------
Epoch:  807        1 Batch loss: 0.059640 Batch F1: 0.6153846153846153
Epoch:  807        2 Batch loss: 0.072961 Batch F1: 0.4615384615384615
Epoch:  807        3 Batch loss: 0.091293 Batch F1: 0.5
Epoch:  807        4 Batch loss: 0.063699 Batch F1: 0.8750000000000001
Epoch:  807        5 Batch loss: 0.097211 Batch F1: 0.42857142857142855
Epoch:  807        6 Batch loss: 0.069726 Batch F1: 0.33333333333333337
Epoch:  807        7 Batch loss: 0.052553 Batch F1: 0.6
Epoch:  807        8 Batch loss: 0.077349 Batch F1: 0.5
Epoch:  807        9 Batch loss: 0.069128 Batch F1: 0.6666666666666666
Epoch:  807       10 Batch loss: 0.063166 Batch F1: 0.8333333333333333
Epoch:  807       11 Batch loss: 0.070241 Batch F1: 0.3636363636363636
Epoch:  807       12 Batch loss: 0.107428 Batch F1: 0.47058823529411764
Train Avg Loss  807: 0.074533

Train Avg F1  807: 0.5540043698131933

Val Avg Loss  807: 0.063208

Val Avg F1  807:  0.9183425506954919

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 808
--------------------------------------------------------------
Epoch:  808        1 Batch loss: 0.058939 Batch F1: 1.0
Epoch:  808        2 Batch loss: 0.087631 Batch F1: 0.631578947368421
Epoch:  808        3 Batch loss: 0.073300 Batch F1: 0.9523809523809523
Epoch:  808        4 Batch loss: 0.056171 Batch F1: 1.0
Epoch:  808        5 Batch loss: 0.075223 Batch F1: 0.9565217391304348
Epoch:  808        6 Batch loss: 0.076950 Batch F1: 0.9090909090909091
Epoch:  808        7 Batch loss: 0.058701 Batch F1: 1.0
Epoch:  808        8 Batch loss: 0.061784 Batch F1: 0.7499999999999999
Epoch:  808        9 Batch loss: 0.049626 Batch F1: 0.888888888888889
Epoch:  808       10 Batch loss: 0.075127 Batch F1: 0.5714285714285715
Epoch:  808       11 Batch loss: 0.067565 Batch F1: 0.4
Epoch:  808       12 Batch loss: 0.086920 Batch F1: 0.5333333333333333
Train Avg Loss  808: 0.068995

Train Avg F1  808: 0.7994352784684593

Val Avg Loss  808: 0.061795

Val Avg F1  808:  0.91289592760181

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 809
--------------------------------------------------------------
Epoch:  809        1 Batch loss: 0.072123 Batch F1: 0.9473684210526316
Epoch:  809        2 Batch loss: 0.084141 Batch F1: 0.8571428571428571
Epoch:  809        3 Batch loss: 0.080461 Batch F1: 0.9523809523809523
Epoch:  809        4 Batch loss: 0.067657 Batch F1: 1.0
Epoch:  809        5 Batch loss: 0.057675 Batch F1: 0.9473684210526316
Epoch:  809        6 Batch loss: 0.076848 Batch F1: 0.6153846153846153
Epoch:  809        7 Batch loss: 0.053404 Batch F1: 1.0
Epoch:  809        8 Batch loss: 0.055694 Batch F1: 0.888888888888889
Epoch:  809        9 Batch loss: 0.073966 Batch F1: 0.9600000000000001
Epoch:  809       10 Batch loss: 0.054576 Batch F1: 0.9090909090909091
Epoch:  809       11 Batch loss: 0.059454 Batch F1: 1.0
Epoch:  809       12 Batch loss: 0.080394 Batch F1: 0.4
Train Avg Loss  809: 0.068033

Train Avg F1  809: 0.8731354220827905

Val Avg Loss  809: 0.063132

Val Avg F1  809:  0.5375465178096757

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 810
--------------------------------------------------------------
Epoch:  810        1 Batch loss: 0.058136 Batch F1: 0.6
Epoch:  810        2 Batch loss: 0.073737 Batch F1: 0.42857142857142855
Epoch:  810        3 Batch loss: 0.089062 Batch F1: 0.42857142857142855
Epoch:  810        4 Batch loss: 0.055479 Batch F1: 0.888888888888889
Epoch:  810        5 Batch loss: 0.054519 Batch F1: 0.923076923076923
Epoch:  810        6 Batch loss: 0.076019 Batch F1: 0.4
Epoch:  810        7 Batch loss: 0.068086 Batch F1: 0.9411764705882353
Epoch:  810        8 Batch loss: 0.054251 Batch F1: 0.8
Epoch:  810        9 Batch loss: 0.070741 Batch F1: 0.7692307692307693
Epoch:  810       10 Batch loss: 0.070819 Batch F1: 0.9600000000000001
Epoch:  810       11 Batch loss: 0.073249 Batch F1: 1.0
Epoch:  810       12 Batch loss: 0.065424 Batch F1: 0.9333333333333333
Train Avg Loss  810: 0.067460

Train Avg F1  810: 0.7560707701884173

Val Avg Loss  810: 0.061352

Val Avg F1  810:  0.9236842105263159

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 811
--------------------------------------------------------------
Epoch:  811        1 Batch loss: 0.067401 Batch F1: 0.8571428571428571
Epoch:  811        2 Batch loss: 0.072183 Batch F1: 0.9473684210526316
Epoch:  811        3 Batch loss: 0.067548 Batch F1: 0.9090909090909091
Epoch:  811        4 Batch loss: 0.075643 Batch F1: 0.9166666666666666
Epoch:  811        5 Batch loss: 0.058789 Batch F1: 0.9411764705882353
Epoch:  811        6 Batch loss: 0.067646 Batch F1: 0.9333333333333333
Epoch:  811        7 Batch loss: 0.072022 Batch F1: 1.0
Epoch:  811        8 Batch loss: 0.043662 Batch F1: 1.0
Epoch:  811        9 Batch loss: 0.068026 Batch F1: 0.5
Epoch:  811       10 Batch loss: 0.076178 Batch F1: 0.33333333333333337
Epoch:  811       11 Batch loss: 0.076736 Batch F1: 0.8
Epoch:  811       12 Batch loss: 0.060991 Batch F1: 0.923076923076923
Train Avg Loss  811: 0.067236

Train Avg F1  811: 0.8384324095237409

Val Avg Loss  811: 0.060864

Val Avg F1  811:  0.9252941176470588

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 812
--------------------------------------------------------------
Epoch:  812        1 Batch loss: 0.097832 Batch F1: 0.8571428571428571
Epoch:  812        2 Batch loss: 0.057228 Batch F1: 0.9090909090909091
Epoch:  812        3 Batch loss: 0.057411 Batch F1: 1.0
Epoch:  812        4 Batch loss: 0.060168 Batch F1: 0.9333333333333333
Epoch:  812        5 Batch loss: 0.068923 Batch F1: 0.9
Epoch:  812        6 Batch loss: 0.064365 Batch F1: 0.8571428571428571
Epoch:  812        7 Batch loss: 0.058747 Batch F1: 1.0
Epoch:  812        8 Batch loss: 0.065597 Batch F1: 0.9473684210526316
Epoch:  812        9 Batch loss: 0.080299 Batch F1: 0.8235294117647058
Epoch:  812       10 Batch loss: 0.053908 Batch F1: 0.4444444444444445
Epoch:  812       11 Batch loss: 0.064737 Batch F1: 0.5714285714285715
Epoch:  812       12 Batch loss: 0.097006 Batch F1: 0.15384615384615385
Train Avg Loss  812: 0.068852

Train Avg F1  812: 0.7831105799372052

Val Avg Loss  812: 0.062045

Val Avg F1  812:  0.5841658341658341

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 813
--------------------------------------------------------------
Epoch:  813        1 Batch loss: 0.056978 Batch F1: 0.5454545454545454
Epoch:  813        2 Batch loss: 0.078473 Batch F1: 0.33333333333333337
Epoch:  813        3 Batch loss: 0.053042 Batch F1: 0.5714285714285715
Epoch:  813        4 Batch loss: 0.058765 Batch F1: 0.8333333333333333
Epoch:  813        5 Batch loss: 0.058913 Batch F1: 0.7272727272727273
Epoch:  813        6 Batch loss: 0.068884 Batch F1: 0.4
Epoch:  813        7 Batch loss: 0.071532 Batch F1: 0.7000000000000001
Epoch:  813        8 Batch loss: 0.080292 Batch F1: 0.4615384615384615
Epoch:  813        9 Batch loss: 0.069001 Batch F1: 0.9473684210526316
Epoch:  813       10 Batch loss: 0.061210 Batch F1: 1.0
Epoch:  813       11 Batch loss: 0.085520 Batch F1: 0.8
Epoch:  813       12 Batch loss: 0.059430 Batch F1: 0.9333333333333333
Train Avg Loss  813: 0.066837

Train Avg F1  813: 0.6877552272289114

Val Avg Loss  813: 0.061514

Val Avg F1  813:  0.9102314610054547

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 814
--------------------------------------------------------------
Epoch:  814        1 Batch loss: 0.063344 Batch F1: 1.0
Epoch:  814        2 Batch loss: 0.048317 Batch F1: 1.0
Epoch:  814        3 Batch loss: 0.073320 Batch F1: 0.9166666666666666
Epoch:  814        4 Batch loss: 0.074710 Batch F1: 0.9473684210526316
Epoch:  814        5 Batch loss: 0.077854 Batch F1: 0.9655172413793104
Epoch:  814        6 Batch loss: 0.053434 Batch F1: 1.0
Epoch:  814        7 Batch loss: 0.082222 Batch F1: 0.8571428571428571
Epoch:  814        8 Batch loss: 0.070696 Batch F1: 0.9333333333333333
Epoch:  814        9 Batch loss: 0.040848 Batch F1: 1.0
Epoch:  814       10 Batch loss: 0.063283 Batch F1: 0.9090909090909091
Epoch:  814       11 Batch loss: 0.108353 Batch F1: 0.2666666666666667
Epoch:  814       12 Batch loss: 0.064131 Batch F1: 0.6666666666666666
Train Avg Loss  814: 0.068376

Train Avg F1  814: 0.87187106349992

Val Avg Loss  814: 0.061890

Val Avg F1  814:  0.6041125541125542

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 815
--------------------------------------------------------------
Epoch:  815        1 Batch loss: 0.104396 Batch F1: 0.14285714285714288
Epoch:  815        2 Batch loss: 0.083296 Batch F1: 0.9166666666666666
Epoch:  815        3 Batch loss: 0.047434 Batch F1: 1.0
Epoch:  815        4 Batch loss: 0.050868 Batch F1: 1.0
Epoch:  815        5 Batch loss: 0.069903 Batch F1: 0.888888888888889
Epoch:  815        6 Batch loss: 0.068105 Batch F1: 0.8
Epoch:  815        7 Batch loss: 0.075178 Batch F1: 0.9523809523809523
Epoch:  815        8 Batch loss: 0.067800 Batch F1: 0.923076923076923
Epoch:  815        9 Batch loss: 0.060108 Batch F1: 1.0
Epoch:  815       10 Batch loss: 0.041337 Batch F1: 0.923076923076923
Epoch:  815       11 Batch loss: 0.084644 Batch F1: 0.4
Epoch:  815       12 Batch loss: 0.071028 Batch F1: 0.5454545454545454
Train Avg Loss  815: 0.068675

Train Avg F1  815: 0.7910335035335035

Val Avg Loss  815: 0.062071

Val Avg F1  815:  0.5702020202020203

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 816
--------------------------------------------------------------
Epoch:  816        1 Batch loss: 0.065214 Batch F1: 0.4444444444444445
Epoch:  816        2 Batch loss: 0.052737 Batch F1: 0.5
Epoch:  816        3 Batch loss: 0.077796 Batch F1: 0.33333333333333337
Epoch:  816        4 Batch loss: 0.070848 Batch F1: 0.5714285714285715
Epoch:  816        5 Batch loss: 0.059563 Batch F1: 0.5454545454545454
Epoch:  816        6 Batch loss: 0.086807 Batch F1: 0.4
Epoch:  816        7 Batch loss: 0.062064 Batch F1: 0.4
Epoch:  816        8 Batch loss: 0.078490 Batch F1: 0.7000000000000001
Epoch:  816        9 Batch loss: 0.075986 Batch F1: 0.5333333333333333
Epoch:  816       10 Batch loss: 0.044321 Batch F1: 0.8571428571428571
Epoch:  816       11 Batch loss: 0.065900 Batch F1: 0.9333333333333333
Epoch:  816       12 Batch loss: 0.075709 Batch F1: 0.9523809523809523
Train Avg Loss  816: 0.067953

Train Avg F1  816: 0.5975709475709475

Val Avg Loss  816: 0.061629

Val Avg F1  816:  0.924812030075188

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 817
--------------------------------------------------------------
Epoch:  817        1 Batch loss: 0.080815 Batch F1: 0.9
Epoch:  817        2 Batch loss: 0.086490 Batch F1: 0.9655172413793104
Epoch:  817        3 Batch loss: 0.073364 Batch F1: 1.0
Epoch:  817        4 Batch loss: 0.070693 Batch F1: 0.7272727272727273
Epoch:  817        5 Batch loss: 0.063261 Batch F1: 0.8333333333333333
Epoch:  817        6 Batch loss: 0.071085 Batch F1: 0.9333333333333333
Epoch:  817        7 Batch loss: 0.064825 Batch F1: 0.8571428571428571
Epoch:  817        8 Batch loss: 0.053874 Batch F1: 0.6666666666666666
Epoch:  817        9 Batch loss: 0.057282 Batch F1: 0.7142857142857143
Epoch:  817       10 Batch loss: 0.076568 Batch F1: 0.18181818181818182
Epoch:  817       11 Batch loss: 0.049909 Batch F1: 0.2857142857142857
Epoch:  817       12 Batch loss: 0.076763 Batch F1: 0.7058823529411764
Train Avg Loss  817: 0.068744

Train Avg F1  817: 0.7309138911572988

Val Avg Loss  817: 0.063906

Val Avg F1  817:  0.9329131652661065

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 818
--------------------------------------------------------------
Epoch:  818        1 Batch loss: 0.056004 Batch F1: 1.0
Epoch:  818        2 Batch loss: 0.084028 Batch F1: 1.0
Epoch:  818        3 Batch loss: 0.088514 Batch F1: 0.7499999999999999
Epoch:  818        4 Batch loss: 0.052634 Batch F1: 0.923076923076923
Epoch:  818        5 Batch loss: 0.064392 Batch F1: 0.5
Epoch:  818        6 Batch loss: 0.057450 Batch F1: 0.0
Epoch:  818        7 Batch loss: 0.107795 Batch F1: 0.0
Epoch:  818        8 Batch loss: 0.061653 Batch F1: 0.9411764705882353
Epoch:  818        9 Batch loss: 0.084271 Batch F1: 0.9600000000000001
Epoch:  818       10 Batch loss: 0.075038 Batch F1: 0.7692307692307692
Epoch:  818       11 Batch loss: 0.071398 Batch F1: 0.8235294117647058
Epoch:  818       12 Batch loss: 0.083343 Batch F1: 0.5454545454545454
Train Avg Loss  818: 0.073877

Train Avg F1  818: 0.6843723433429316

Val Avg Loss  818: 0.063323

Val Avg F1  818:  0.7680555555555555

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 819
--------------------------------------------------------------
Epoch:  819        1 Batch loss: 0.050319 Batch F1: 0.888888888888889
Epoch:  819        2 Batch loss: 0.062231 Batch F1: 0.2857142857142857
Epoch:  819        3 Batch loss: 0.075647 Batch F1: 0.4615384615384615
Epoch:  819        4 Batch loss: 0.085552 Batch F1: 0.4615384615384615
Epoch:  819        5 Batch loss: 0.083865 Batch F1: 0.18181818181818182
Epoch:  819        6 Batch loss: 0.087192 Batch F1: 0.923076923076923
Epoch:  819        7 Batch loss: 0.053221 Batch F1: 1.0
Epoch:  819        8 Batch loss: 0.084294 Batch F1: 0.47058823529411764
Epoch:  819        9 Batch loss: 0.065433 Batch F1: 0.5
Epoch:  819       10 Batch loss: 0.073334 Batch F1: 0.8571428571428571
Epoch:  819       11 Batch loss: 0.069934 Batch F1: 0.9523809523809523
Epoch:  819       12 Batch loss: 0.052124 Batch F1: 0.888888888888889
Train Avg Loss  819: 0.070262

Train Avg F1  819: 0.6559646780235016

Val Avg Loss  819: 0.063319

Val Avg F1  819:  0.9160912190963342

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 820
--------------------------------------------------------------
Epoch:  820        1 Batch loss: 0.073755 Batch F1: 0.8750000000000001
Epoch:  820        2 Batch loss: 0.045481 Batch F1: 1.0
Epoch:  820        3 Batch loss: 0.049543 Batch F1: 0.7272727272727273
Epoch:  820        4 Batch loss: 0.069144 Batch F1: 0.4444444444444445
Epoch:  820        5 Batch loss: 0.084513 Batch F1: 0.4615384615384615
Epoch:  820        6 Batch loss: 0.075746 Batch F1: 0.33333333333333337
Epoch:  820        7 Batch loss: 0.078488 Batch F1: 0.888888888888889
Epoch:  820        8 Batch loss: 0.071356 Batch F1: 0.9565217391304348
Epoch:  820        9 Batch loss: 0.070620 Batch F1: 0.8421052631578948
Epoch:  820       10 Batch loss: 0.064387 Batch F1: 1.0
Epoch:  820       11 Batch loss: 0.077858 Batch F1: 0.9523809523809523
Epoch:  820       12 Batch loss: 0.069632 Batch F1: 0.9333333333333333
Train Avg Loss  820: 0.069210

Train Avg F1  820: 0.7845682619567059

Val Avg Loss  820: 0.062401

Val Avg F1  820:  0.9354636591478697

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 821
--------------------------------------------------------------
Epoch:  821        1 Batch loss: 0.035403 Batch F1: 1.0
Epoch:  821        2 Batch loss: 0.066436 Batch F1: 0.2857142857142857
Epoch:  821        3 Batch loss: 0.090746 Batch F1: 0.2857142857142857
Epoch:  821        4 Batch loss: 0.062243 Batch F1: 0.6666666666666666
Epoch:  821        5 Batch loss: 0.060133 Batch F1: 0.7058823529411764
Epoch:  821        6 Batch loss: 0.064829 Batch F1: 1.0
Epoch:  821        7 Batch loss: 0.083103 Batch F1: 0.9090909090909091
Epoch:  821        8 Batch loss: 0.066827 Batch F1: 0.9090909090909091
Epoch:  821        9 Batch loss: 0.063056 Batch F1: 0.7692307692307693
Epoch:  821       10 Batch loss: 0.091263 Batch F1: 0.5555555555555556
Epoch:  821       11 Batch loss: 0.075966 Batch F1: 1.0
Epoch:  821       12 Batch loss: 0.078793 Batch F1: 0.7272727272727273
Train Avg Loss  821: 0.069900

Train Avg F1  821: 0.7345182051064403

Val Avg Loss  821: 0.062713

Val Avg F1  821:  0.9160912190963342

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 822
--------------------------------------------------------------
Epoch:  822        1 Batch loss: 0.068608 Batch F1: 0.8750000000000001
Epoch:  822        2 Batch loss: 0.080675 Batch F1: 0.9523809523809523
Epoch:  822        3 Batch loss: 0.068162 Batch F1: 0.8750000000000001
Epoch:  822        4 Batch loss: 0.075226 Batch F1: 0.9
Epoch:  822        5 Batch loss: 0.074102 Batch F1: 0.9333333333333333
Epoch:  822        6 Batch loss: 0.042854 Batch F1: 1.0
Epoch:  822        7 Batch loss: 0.065099 Batch F1: 1.0
Epoch:  822        8 Batch loss: 0.083063 Batch F1: 0.4615384615384615
Epoch:  822        9 Batch loss: 0.068506 Batch F1: 0.8750000000000001
Epoch:  822       10 Batch loss: 0.055426 Batch F1: 1.0
Epoch:  822       11 Batch loss: 0.079952 Batch F1: 0.8235294117647058
Epoch:  822       12 Batch loss: 0.070169 Batch F1: 0.9411764705882353
Train Avg Loss  822: 0.069320

Train Avg F1  822: 0.8864132191338076

Val Avg Loss  822: 0.061750

Val Avg F1  822:  0.8946886446886447

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 823
--------------------------------------------------------------
Epoch:  823        1 Batch loss: 0.052183 Batch F1: 0.9090909090909091
Epoch:  823        2 Batch loss: 0.077421 Batch F1: 0.5
Epoch:  823        3 Batch loss: 0.050260 Batch F1: 0.7499999999999999
Epoch:  823        4 Batch loss: 0.061499 Batch F1: 0.33333333333333337
Epoch:  823        5 Batch loss: 0.078870 Batch F1: 0.0
Epoch:  823        6 Batch loss: 0.072472 Batch F1: 0.3636363636363636
Epoch:  823        7 Batch loss: 0.087489 Batch F1: 0.19999999999999998
Epoch:  823        8 Batch loss: 0.064013 Batch F1: 0.5
Epoch:  823        9 Batch loss: 0.090101 Batch F1: 0.6666666666666666
Epoch:  823       10 Batch loss: 0.061024 Batch F1: 0.888888888888889
Epoch:  823       11 Batch loss: 0.092302 Batch F1: 0.7368421052631579
Epoch:  823       12 Batch loss: 0.096329 Batch F1: 0.42857142857142855
Train Avg Loss  823: 0.073664

Train Avg F1  823: 0.5230858079542291

Val Avg Loss  823: 0.071961

Val Avg F1  823:  0.5864661654135338

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 824
--------------------------------------------------------------
Epoch:  824        1 Batch loss: 0.121858 Batch F1: 0.47619047619047616
Epoch:  824        2 Batch loss: 0.060675 Batch F1: 1.0
Epoch:  824        3 Batch loss: 0.056594 Batch F1: 0.9090909090909091
Epoch:  824        4 Batch loss: 0.075280 Batch F1: 0.5
Epoch:  824        5 Batch loss: 0.091811 Batch F1: 0.5714285714285715
Epoch:  824        6 Batch loss: 0.068709 Batch F1: 0.4
Epoch:  824        7 Batch loss: 0.060151 Batch F1: 0.6666666666666666
Epoch:  824        8 Batch loss: 0.059858 Batch F1: 0.6
Epoch:  824        9 Batch loss: 0.080350 Batch F1: 0.5
Epoch:  824       10 Batch loss: 0.077125 Batch F1: 0.5714285714285715
Epoch:  824       11 Batch loss: 0.077375 Batch F1: 0.6666666666666666
Epoch:  824       12 Batch loss: 0.068392 Batch F1: 0.9411764705882353
Train Avg Loss  824: 0.074848

Train Avg F1  824: 0.6502206943383414

Val Avg Loss  824: 0.065037

Val Avg F1  824:  0.9039667229322401

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 825
--------------------------------------------------------------
Epoch:  825        1 Batch loss: 0.075714 Batch F1: 0.9090909090909091
Epoch:  825        2 Batch loss: 0.052856 Batch F1: 1.0
Epoch:  825        3 Batch loss: 0.077598 Batch F1: 0.8750000000000001
Epoch:  825        4 Batch loss: 0.075722 Batch F1: 0.5
Epoch:  825        5 Batch loss: 0.101874 Batch F1: 0.5555555555555556
Epoch:  825        6 Batch loss: 0.064190 Batch F1: 1.0
Epoch:  825        7 Batch loss: 0.089066 Batch F1: 0.9523809523809523
Epoch:  825        8 Batch loss: 0.080046 Batch F1: 0.8421052631578948
Epoch:  825        9 Batch loss: 0.073884 Batch F1: 0.7499999999999999
Epoch:  825       10 Batch loss: 0.067976 Batch F1: 0.6666666666666666
Epoch:  825       11 Batch loss: 0.049300 Batch F1: 0.6666666666666666
Epoch:  825       12 Batch loss: 0.058532 Batch F1: 0.7272727272727273
Train Avg Loss  825: 0.072230

Train Avg F1  825: 0.7870615617326142

Val Avg Loss  825: 0.063730

Val Avg F1  825:  0.5888694638694638

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 826
--------------------------------------------------------------
Epoch:  826        1 Batch loss: 0.068962 Batch F1: 0.0
Epoch:  826        2 Batch loss: 0.036087 Batch F1: 0.4
Epoch:  826        3 Batch loss: 0.090735 Batch F1: 0.5882352941176471
Epoch:  826        4 Batch loss: 0.058286 Batch F1: 1.0
Epoch:  826        5 Batch loss: 0.042290 Batch F1: 1.0
Epoch:  826        6 Batch loss: 0.069854 Batch F1: 0.8750000000000001
Epoch:  826        7 Batch loss: 0.075253 Batch F1: 0.9
Epoch:  826        8 Batch loss: 0.089436 Batch F1: 0.7142857142857143
Epoch:  826        9 Batch loss: 0.088853 Batch F1: 0.8695652173913044
Epoch:  826       10 Batch loss: 0.082760 Batch F1: 0.8750000000000001
Epoch:  826       11 Batch loss: 0.087987 Batch F1: 0.923076923076923
Epoch:  826       12 Batch loss: 0.055101 Batch F1: 1.0
Train Avg Loss  826: 0.070467

Train Avg F1  826: 0.7620969290726324

Val Avg Loss  826: 0.063763

Val Avg F1  826:  0.9318970503181029

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 827
--------------------------------------------------------------
Epoch:  827        1 Batch loss: 0.084902 Batch F1: 0.9166666666666666
Epoch:  827        2 Batch loss: 0.068937 Batch F1: 0.5
Epoch:  827        3 Batch loss: 0.090985 Batch F1: 0.375
Epoch:  827        4 Batch loss: 0.059070 Batch F1: 0.7272727272727273
Epoch:  827        5 Batch loss: 0.047436 Batch F1: 0.5714285714285715
Epoch:  827        6 Batch loss: 0.069917 Batch F1: 0.5
Epoch:  827        7 Batch loss: 0.046203 Batch F1: 0.5714285714285715
Epoch:  827        8 Batch loss: 0.095150 Batch F1: 0.5
Epoch:  827        9 Batch loss: 0.046657 Batch F1: 0.4
Epoch:  827       10 Batch loss: 0.084958 Batch F1: 0.16666666666666669
Epoch:  827       11 Batch loss: 0.064285 Batch F1: 0.6153846153846153
Epoch:  827       12 Batch loss: 0.086925 Batch F1: 0.9523809523809523
Train Avg Loss  827: 0.070452

Train Avg F1  827: 0.5663523976023976

Val Avg Loss  827: 0.065340

Val Avg F1  827:  0.9297385620915033

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 828
--------------------------------------------------------------
Epoch:  828        1 Batch loss: 0.065028 Batch F1: 1.0
Epoch:  828        2 Batch loss: 0.065606 Batch F1: 1.0
Epoch:  828        3 Batch loss: 0.075668 Batch F1: 0.888888888888889
Epoch:  828        4 Batch loss: 0.061412 Batch F1: 0.923076923076923
Epoch:  828        5 Batch loss: 0.069872 Batch F1: 0.888888888888889
Epoch:  828        6 Batch loss: 0.062297 Batch F1: 1.0
Epoch:  828        7 Batch loss: 0.070965 Batch F1: 0.9523809523809523
Epoch:  828        8 Batch loss: 0.098137 Batch F1: 0.3076923076923077
Epoch:  828        9 Batch loss: 0.096095 Batch F1: 0.8
Epoch:  828       10 Batch loss: 0.057207 Batch F1: 0.9411764705882353
Epoch:  828       11 Batch loss: 0.061999 Batch F1: 0.923076923076923
Epoch:  828       12 Batch loss: 0.055489 Batch F1: 0.8
Train Avg Loss  828: 0.069981

Train Avg F1  828: 0.8687651128827599

Val Avg Loss  828: 0.064110

Val Avg F1  828:  0.6787612971823498

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 829
--------------------------------------------------------------
Epoch:  829        1 Batch loss: 0.052576 Batch F1: 0.6666666666666666
Epoch:  829        2 Batch loss: 0.082998 Batch F1: 0.19999999999999998
Epoch:  829        3 Batch loss: 0.056446 Batch F1: 0.4444444444444445
Epoch:  829        4 Batch loss: 0.082434 Batch F1: 0.8
Epoch:  829        5 Batch loss: 0.064514 Batch F1: 0.6153846153846153
Epoch:  829        6 Batch loss: 0.058187 Batch F1: 0.9333333333333333
Epoch:  829        7 Batch loss: 0.077584 Batch F1: 0.8
Epoch:  829        8 Batch loss: 0.079491 Batch F1: 0.9
Epoch:  829        9 Batch loss: 0.068033 Batch F1: 0.8333333333333333
Epoch:  829       10 Batch loss: 0.080719 Batch F1: 0.5
Epoch:  829       11 Batch loss: 0.069606 Batch F1: 0.9411764705882353
Epoch:  829       12 Batch loss: 0.060851 Batch F1: 0.9411764705882353
Train Avg Loss  829: 0.069453

Train Avg F1  829: 0.714626277861572

Val Avg Loss  829: 0.061723

Val Avg F1  829:  0.9341148325358852

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 830
--------------------------------------------------------------
Epoch:  830        1 Batch loss: 0.062489 Batch F1: 1.0
Epoch:  830        2 Batch loss: 0.082653 Batch F1: 0.47058823529411764
Epoch:  830        3 Batch loss: 0.068124 Batch F1: 0.7142857142857143
Epoch:  830        4 Batch loss: 0.066646 Batch F1: 0.9411764705882353
Epoch:  830        5 Batch loss: 0.069096 Batch F1: 0.888888888888889
Epoch:  830        6 Batch loss: 0.077259 Batch F1: 0.3636363636363636
Epoch:  830        7 Batch loss: 0.047110 Batch F1: 0.0
Epoch:  830        8 Batch loss: 0.055674 Batch F1: 0.6666666666666666
Epoch:  830        9 Batch loss: 0.078444 Batch F1: 0.42857142857142855
Epoch:  830       10 Batch loss: 0.057636 Batch F1: 0.25
Epoch:  830       11 Batch loss: 0.068653 Batch F1: 0.5
Epoch:  830       12 Batch loss: 0.085309 Batch F1: 0.631578947368421
Train Avg Loss  830: 0.068258

Train Avg F1  830: 0.5712827262749864

Val Avg Loss  830: 0.062184

Val Avg F1  830:  0.9267857142857142

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 831
--------------------------------------------------------------
Epoch:  831        1 Batch loss: 0.069432 Batch F1: 0.9565217391304348
Epoch:  831        2 Batch loss: 0.066373 Batch F1: 0.8333333333333333
Epoch:  831        3 Batch loss: 0.070623 Batch F1: 0.9565217391304348
Epoch:  831        4 Batch loss: 0.054524 Batch F1: 0.923076923076923
Epoch:  831        5 Batch loss: 0.075804 Batch F1: 0.9090909090909091
Epoch:  831        6 Batch loss: 0.061799 Batch F1: 0.9333333333333333
Epoch:  831        7 Batch loss: 0.084964 Batch F1: 0.923076923076923
Epoch:  831        8 Batch loss: 0.057875 Batch F1: 0.8571428571428571
Epoch:  831        9 Batch loss: 0.076041 Batch F1: 0.8571428571428571
Epoch:  831       10 Batch loss: 0.063309 Batch F1: 0.7499999999999999
Epoch:  831       11 Batch loss: 0.082151 Batch F1: 0.9600000000000001
Epoch:  831       12 Batch loss: 0.055034 Batch F1: 1.0
Train Avg Loss  831: 0.068161

Train Avg F1  831: 0.9049367178715005

Val Avg Loss  831: 0.062167

Val Avg F1  831:  0.573489010989011

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 832
--------------------------------------------------------------
Epoch:  832        1 Batch loss: 0.050659 Batch F1: 0.2857142857142857
Epoch:  832        2 Batch loss: 0.073531 Batch F1: 0.7000000000000001
Epoch:  832        3 Batch loss: 0.067335 Batch F1: 0.5
Epoch:  832        4 Batch loss: 0.079704 Batch F1: 0.7000000000000001
Epoch:  832        5 Batch loss: 0.062824 Batch F1: 0.4
Epoch:  832        6 Batch loss: 0.058304 Batch F1: 0.9411764705882353
Epoch:  832        7 Batch loss: 0.057720 Batch F1: 0.9333333333333333
Epoch:  832        8 Batch loss: 0.063659 Batch F1: 0.9333333333333333
Epoch:  832        9 Batch loss: 0.069152 Batch F1: 0.923076923076923
Epoch:  832       10 Batch loss: 0.103574 Batch F1: 0.9333333333333333
Epoch:  832       11 Batch loss: 0.053623 Batch F1: 0.8333333333333333
Epoch:  832       12 Batch loss: 0.070804 Batch F1: 0.8333333333333333
Train Avg Loss  832: 0.067574

Train Avg F1  832: 0.7430528621705094

Val Avg Loss  832: 0.061330

Val Avg F1  832:  0.920054945054945

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 833
--------------------------------------------------------------
Epoch:  833        1 Batch loss: 0.064302 Batch F1: 0.9473684210526316
Epoch:  833        2 Batch loss: 0.075891 Batch F1: 0.9523809523809523
Epoch:  833        3 Batch loss: 0.052743 Batch F1: 1.0
Epoch:  833        4 Batch loss: 0.049845 Batch F1: 0.888888888888889
Epoch:  833        5 Batch loss: 0.076644 Batch F1: 0.5714285714285715
Epoch:  833        6 Batch loss: 0.079382 Batch F1: 0.18181818181818182
Epoch:  833        7 Batch loss: 0.061695 Batch F1: 0.9333333333333333
Epoch:  833        8 Batch loss: 0.071332 Batch F1: 0.8750000000000001
Epoch:  833        9 Batch loss: 0.072494 Batch F1: 0.9
Epoch:  833       10 Batch loss: 0.058689 Batch F1: 1.0
Epoch:  833       11 Batch loss: 0.080141 Batch F1: 0.8421052631578948
Epoch:  833       12 Batch loss: 0.067021 Batch F1: 1.0
Train Avg Loss  833: 0.067515

Train Avg F1  833: 0.8410269676717047

Val Avg Loss  833: 0.061161

Val Avg F1  833:  0.9040404040404041

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 834
--------------------------------------------------------------
Epoch:  834        1 Batch loss: 0.073846 Batch F1: 0.9523809523809523
Epoch:  834        2 Batch loss: 0.077722 Batch F1: 0.9166666666666666
Epoch:  834        3 Batch loss: 0.061751 Batch F1: 0.8333333333333333
Epoch:  834        4 Batch loss: 0.063475 Batch F1: 0.8333333333333333
Epoch:  834        5 Batch loss: 0.070851 Batch F1: 0.9523809523809523
Epoch:  834        6 Batch loss: 0.060387 Batch F1: 0.9411764705882353
Epoch:  834        7 Batch loss: 0.070593 Batch F1: 0.9473684210526316
Epoch:  834        8 Batch loss: 0.066702 Batch F1: 0.9411764705882353
Epoch:  834        9 Batch loss: 0.049153 Batch F1: 1.0
Epoch:  834       10 Batch loss: 0.082596 Batch F1: 0.5
Epoch:  834       11 Batch loss: 0.071809 Batch F1: 0.18181818181818182
Epoch:  834       12 Batch loss: 0.052435 Batch F1: 0.7272727272727273
Train Avg Loss  834: 0.066777

Train Avg F1  834: 0.8105756257846042

Val Avg Loss  834: 0.061621

Val Avg F1  834:  0.5888694638694638

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 835
--------------------------------------------------------------
Epoch:  835        1 Batch loss: 0.062092 Batch F1: 0.6666666666666666
Epoch:  835        2 Batch loss: 0.074085 Batch F1: 0.3636363636363636
Epoch:  835        3 Batch loss: 0.058462 Batch F1: 0.6666666666666666
Epoch:  835        4 Batch loss: 0.078454 Batch F1: 0.9565217391304348
Epoch:  835        5 Batch loss: 0.077746 Batch F1: 0.9090909090909091
Epoch:  835        6 Batch loss: 0.082487 Batch F1: 0.923076923076923
Epoch:  835        7 Batch loss: 0.076919 Batch F1: 1.0
Epoch:  835        8 Batch loss: 0.067885 Batch F1: 1.0
Epoch:  835        9 Batch loss: 0.064101 Batch F1: 0.8571428571428571
Epoch:  835       10 Batch loss: 0.053219 Batch F1: 0.923076923076923
Epoch:  835       11 Batch loss: 0.070024 Batch F1: 0.8
Epoch:  835       12 Batch loss: 0.052029 Batch F1: 0.8571428571428571
Train Avg Loss  835: 0.068125

Train Avg F1  835: 0.8269184921358835

Val Avg Loss  835: 0.061072

Val Avg F1  835:  0.9293907846539425

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 836
--------------------------------------------------------------
Epoch:  836        1 Batch loss: 0.069749 Batch F1: 0.888888888888889
Epoch:  836        2 Batch loss: 0.053439 Batch F1: 0.0
Epoch:  836        3 Batch loss: 0.057546 Batch F1: 0.25
Epoch:  836        4 Batch loss: 0.092662 Batch F1: 0.6
Epoch:  836        5 Batch loss: 0.080547 Batch F1: 0.5
Epoch:  836        6 Batch loss: 0.085569 Batch F1: 0.7777777777777778
Epoch:  836        7 Batch loss: 0.069699 Batch F1: 0.9411764705882353
Epoch:  836        8 Batch loss: 0.081065 Batch F1: 0.8750000000000001
Epoch:  836        9 Batch loss: 0.064954 Batch F1: 1.0
Epoch:  836       10 Batch loss: 0.072236 Batch F1: 0.9565217391304348
Epoch:  836       11 Batch loss: 0.053373 Batch F1: 0.8
Epoch:  836       12 Batch loss: 0.060964 Batch F1: 0.6
Train Avg Loss  836: 0.070150

Train Avg F1  836: 0.6824470730321114

Val Avg Loss  836: 0.068559

Val Avg F1  836:  0.5797619047619047

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 837
--------------------------------------------------------------
Epoch:  837        1 Batch loss: 0.077460 Batch F1: 0.7368421052631579
Epoch:  837        2 Batch loss: 0.074644 Batch F1: 0.6
Epoch:  837        3 Batch loss: 0.048453 Batch F1: 1.0
Epoch:  837        4 Batch loss: 0.053376 Batch F1: 0.8
Epoch:  837        5 Batch loss: 0.088682 Batch F1: 0.0
Epoch:  837        6 Batch loss: 0.072296 Batch F1: 0.5714285714285715
Epoch:  837        7 Batch loss: 0.053871 Batch F1: 0.6
Epoch:  837        8 Batch loss: 0.062569 Batch F1: 0.25
Epoch:  837        9 Batch loss: 0.091783 Batch F1: 0.5
Epoch:  837       10 Batch loss: 0.066355 Batch F1: 0.625
Epoch:  837       11 Batch loss: 0.077330 Batch F1: 0.8571428571428571
Epoch:  837       12 Batch loss: 0.070675 Batch F1: 0.9333333333333333
Train Avg Loss  837: 0.069791

Train Avg F1  837: 0.62281223893066

Val Avg Loss  837: 0.063207

Val Avg F1  837:  0.9267676767676768

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 838
--------------------------------------------------------------
Epoch:  838        1 Batch loss: 0.065434 Batch F1: 1.0
Epoch:  838        2 Batch loss: 0.058301 Batch F1: 1.0
Epoch:  838        3 Batch loss: 0.085235 Batch F1: 0.923076923076923
Epoch:  838        4 Batch loss: 0.079118 Batch F1: 0.7499999999999999
Epoch:  838        5 Batch loss: 0.061637 Batch F1: 1.0
Epoch:  838        6 Batch loss: 0.056559 Batch F1: 1.0
Epoch:  838        7 Batch loss: 0.104277 Batch F1: 0.8571428571428571
Epoch:  838        8 Batch loss: 0.060245 Batch F1: 1.0
Epoch:  838        9 Batch loss: 0.058165 Batch F1: 0.0
Epoch:  838       10 Batch loss: 0.042944 Batch F1: 0.888888888888889
Epoch:  838       11 Batch loss: 0.088876 Batch F1: 0.16666666666666669
Epoch:  838       12 Batch loss: 0.060663 Batch F1: 0.5454545454545454
Train Avg Loss  838: 0.068454

Train Avg F1  838: 0.7609358234358233

Val Avg Loss  838: 0.061831

Val Avg F1  838:  0.5753968253968255

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 839
--------------------------------------------------------------
Epoch:  839        1 Batch loss: 0.073246 Batch F1: 0.33333333333333337
Epoch:  839        2 Batch loss: 0.056453 Batch F1: 0.9333333333333333
Epoch:  839        3 Batch loss: 0.072421 Batch F1: 0.9
Epoch:  839        4 Batch loss: 0.069422 Batch F1: 1.0
Epoch:  839        5 Batch loss: 0.074078 Batch F1: 0.8
Epoch:  839        6 Batch loss: 0.070741 Batch F1: 0.9
Epoch:  839        7 Batch loss: 0.055637 Batch F1: 1.0
Epoch:  839        8 Batch loss: 0.064468 Batch F1: 0.9333333333333333
Epoch:  839        9 Batch loss: 0.066964 Batch F1: 0.9411764705882353
Epoch:  839       10 Batch loss: 0.060509 Batch F1: 0.9411764705882353
Epoch:  839       11 Batch loss: 0.093045 Batch F1: 0.846153846153846
Epoch:  839       12 Batch loss: 0.053190 Batch F1: 1.0
Train Avg Loss  839: 0.067514

Train Avg F1  839: 0.8773755656108598

Val Avg Loss  839: 0.061544

Val Avg F1  839:  0.922463768115942

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 840
--------------------------------------------------------------
Epoch:  840        1 Batch loss: 0.068128 Batch F1: 0.9
Epoch:  840        2 Batch loss: 0.076763 Batch F1: 1.0
Epoch:  840        3 Batch loss: 0.055509 Batch F1: 0.8
Epoch:  840        4 Batch loss: 0.085927 Batch F1: 0.8571428571428571
Epoch:  840        5 Batch loss: 0.074386 Batch F1: 0.9473684210526316
Epoch:  840        6 Batch loss: 0.067015 Batch F1: 0.9333333333333333
Epoch:  840        7 Batch loss: 0.062212 Batch F1: 0.9411764705882353
Epoch:  840        8 Batch loss: 0.077711 Batch F1: 0.8695652173913044
Epoch:  840        9 Batch loss: 0.062411 Batch F1: 0.8
Epoch:  840       10 Batch loss: 0.059123 Batch F1: 1.0
Epoch:  840       11 Batch loss: 0.049429 Batch F1: 1.0
Epoch:  840       12 Batch loss: 0.074742 Batch F1: 0.25
Train Avg Loss  840: 0.067780

Train Avg F1  840: 0.8582155249590303

Val Avg Loss  840: 0.063516

Val Avg F1  840:  0.5157211209842789

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 841
--------------------------------------------------------------
Epoch:  841        1 Batch loss: 0.058556 Batch F1: 0.7142857142857143
Epoch:  841        2 Batch loss: 0.071394 Batch F1: 0.4615384615384615
Epoch:  841        3 Batch loss: 0.081677 Batch F1: 0.3076923076923077
Epoch:  841        4 Batch loss: 0.070092 Batch F1: 0.3636363636363636
Epoch:  841        5 Batch loss: 0.055052 Batch F1: 0.888888888888889
Epoch:  841        6 Batch loss: 0.068963 Batch F1: 0.8750000000000001
Epoch:  841        7 Batch loss: 0.065352 Batch F1: 1.0
Epoch:  841        8 Batch loss: 0.056585 Batch F1: 1.0
Epoch:  841        9 Batch loss: 0.061277 Batch F1: 0.9411764705882353
Epoch:  841       10 Batch loss: 0.096827 Batch F1: 0.8181818181818181
Epoch:  841       11 Batch loss: 0.062917 Batch F1: 0.9411764705882353
Epoch:  841       12 Batch loss: 0.074472 Batch F1: 0.9411764705882353
Train Avg Loss  841: 0.068597

Train Avg F1  841: 0.7710627471656885

Val Avg Loss  841: 0.062021

Val Avg F1  841:  0.9328648325358853

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 842
--------------------------------------------------------------
Epoch:  842        1 Batch loss: 0.079346 Batch F1: 0.8235294117647058
Epoch:  842        2 Batch loss: 0.073746 Batch F1: 1.0
Epoch:  842        3 Batch loss: 0.076007 Batch F1: 0.9
Epoch:  842        4 Batch loss: 0.077656 Batch F1: 0.8
Epoch:  842        5 Batch loss: 0.061716 Batch F1: 1.0
Epoch:  842        6 Batch loss: 0.085639 Batch F1: 0.6363636363636364
Epoch:  842        7 Batch loss: 0.043114 Batch F1: 0.33333333333333337
Epoch:  842        8 Batch loss: 0.064114 Batch F1: 0.33333333333333337
Epoch:  842        9 Batch loss: 0.059936 Batch F1: 0.4444444444444445
Epoch:  842       10 Batch loss: 0.056681 Batch F1: 0.923076923076923
Epoch:  842       11 Batch loss: 0.056874 Batch F1: 0.9090909090909091
Epoch:  842       12 Batch loss: 0.077498 Batch F1: 0.888888888888889
Train Avg Loss  842: 0.067694

Train Avg F1  842: 0.7493384066913479

Val Avg Loss  842: 0.061771

Val Avg F1  842:  0.8809523809523809

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 843
--------------------------------------------------------------
Epoch:  843        1 Batch loss: 0.059684 Batch F1: 0.923076923076923
Epoch:  843        2 Batch loss: 0.053989 Batch F1: 0.7499999999999999
Epoch:  843        3 Batch loss: 0.070114 Batch F1: 0.9523809523809523
Epoch:  843        4 Batch loss: 0.069444 Batch F1: 0.9090909090909091
Epoch:  843        5 Batch loss: 0.073131 Batch F1: 0.9473684210526316
Epoch:  843        6 Batch loss: 0.055010 Batch F1: 0.8571428571428571
Epoch:  843        7 Batch loss: 0.072356 Batch F1: 0.8750000000000001
Epoch:  843        8 Batch loss: 0.076924 Batch F1: 0.9
Epoch:  843        9 Batch loss: 0.072841 Batch F1: 1.0
Epoch:  843       10 Batch loss: 0.069092 Batch F1: 0.8571428571428571
Epoch:  843       11 Batch loss: 0.062860 Batch F1: 1.0
Epoch:  843       12 Batch loss: 0.072917 Batch F1: 0.7692307692307693
Train Avg Loss  843: 0.067363

Train Avg F1  843: 0.895036140759825

Val Avg Loss  843: 0.062298

Val Avg F1  843:  0.7426739926739926

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 844
--------------------------------------------------------------
Epoch:  844        1 Batch loss: 0.074503 Batch F1: 0.625
Epoch:  844        2 Batch loss: 0.066288 Batch F1: 0.6666666666666666
Epoch:  844        3 Batch loss: 0.065639 Batch F1: 1.0
Epoch:  844        4 Batch loss: 0.063488 Batch F1: 0.9333333333333333
Epoch:  844        5 Batch loss: 0.059820 Batch F1: 0.9333333333333333
Epoch:  844        6 Batch loss: 0.073233 Batch F1: 0.8750000000000001
Epoch:  844        7 Batch loss: 0.081723 Batch F1: 0.0
Epoch:  844        8 Batch loss: 0.046474 Batch F1: 0.5714285714285715
Epoch:  844        9 Batch loss: 0.069736 Batch F1: 0.3636363636363636
Epoch:  844       10 Batch loss: 0.069427 Batch F1: 0.6666666666666666
Epoch:  844       11 Batch loss: 0.061400 Batch F1: 0.7499999999999999
Epoch:  844       12 Batch loss: 0.082292 Batch F1: 0.9523809523809523
Train Avg Loss  844: 0.067835

Train Avg F1  844: 0.6947871572871572

Val Avg Loss  844: 0.061019

Val Avg F1  844:  0.9415584415584416

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 845
--------------------------------------------------------------
Epoch:  845        1 Batch loss: 0.059961 Batch F1: 1.0
Epoch:  845        2 Batch loss: 0.073922 Batch F1: 0.9090909090909091
Epoch:  845        3 Batch loss: 0.084929 Batch F1: 0.6666666666666666
Epoch:  845        4 Batch loss: 0.068393 Batch F1: 0.9
Epoch:  845        5 Batch loss: 0.065622 Batch F1: 0.8
Epoch:  845        6 Batch loss: 0.070281 Batch F1: 0.9565217391304348
Epoch:  845        7 Batch loss: 0.066142 Batch F1: 0.8750000000000001
Epoch:  845        8 Batch loss: 0.065824 Batch F1: 0.923076923076923
Epoch:  845        9 Batch loss: 0.061071 Batch F1: 1.0
Epoch:  845       10 Batch loss: 0.071541 Batch F1: 1.0
Epoch:  845       11 Batch loss: 0.060647 Batch F1: 0.5454545454545454
Epoch:  845       12 Batch loss: 0.076133 Batch F1: 0.5
Train Avg Loss  845: 0.068706

Train Avg F1  845: 0.8396508986182899

Val Avg Loss  845: 0.062266

Val Avg F1  845:  0.5520833333333333

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 846
--------------------------------------------------------------
Epoch:  846        1 Batch loss: 0.063991 Batch F1: 0.6666666666666666
Epoch:  846        2 Batch loss: 0.094707 Batch F1: 0.16666666666666669
Epoch:  846        3 Batch loss: 0.071007 Batch F1: 0.9333333333333333
Epoch:  846        4 Batch loss: 0.072842 Batch F1: 0.8571428571428571
Epoch:  846        5 Batch loss: 0.051892 Batch F1: 0.6666666666666666
Epoch:  846        6 Batch loss: 0.059016 Batch F1: 0.7692307692307693
Epoch:  846        7 Batch loss: 0.051989 Batch F1: 0.5454545454545454
Epoch:  846        8 Batch loss: 0.073422 Batch F1: 0.5714285714285715
Epoch:  846        9 Batch loss: 0.051850 Batch F1: 1.0
Epoch:  846       10 Batch loss: 0.047945 Batch F1: 1.0
Epoch:  846       11 Batch loss: 0.081548 Batch F1: 0.5
Epoch:  846       12 Batch loss: 0.102521 Batch F1: 0.4
Train Avg Loss  846: 0.068561

Train Avg F1  846: 0.673049173049173

Val Avg Loss  846: 0.062177

Val Avg F1  846:  0.9079131652661064

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 847
--------------------------------------------------------------
Epoch:  847        1 Batch loss: 0.054713 Batch F1: 1.0
Epoch:  847        2 Batch loss: 0.070863 Batch F1: 0.9523809523809523
Epoch:  847        3 Batch loss: 0.053908 Batch F1: 0.8
Epoch:  847        4 Batch loss: 0.069063 Batch F1: 0.8
Epoch:  847        5 Batch loss: 0.066742 Batch F1: 1.0
Epoch:  847        6 Batch loss: 0.087939 Batch F1: 0.631578947368421
Epoch:  847        7 Batch loss: 0.088384 Batch F1: 0.5882352941176471
Epoch:  847        8 Batch loss: 0.072030 Batch F1: 0.8750000000000001
Epoch:  847        9 Batch loss: 0.077502 Batch F1: 0.9600000000000001
Epoch:  847       10 Batch loss: 0.067842 Batch F1: 1.0
Epoch:  847       11 Batch loss: 0.079764 Batch F1: 0.4
Epoch:  847       12 Batch loss: 0.059734 Batch F1: 1.0
Train Avg Loss  847: 0.070707

Train Avg F1  847: 0.8339329328222518

Val Avg Loss  847: 0.065709

Val Avg F1  847:  0.569551282051282

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 848
--------------------------------------------------------------
Epoch:  848        1 Batch loss: 0.084310 Batch F1: 0.25
Epoch:  848        2 Batch loss: 0.074603 Batch F1: 0.33333333333333337
Epoch:  848        3 Batch loss: 0.071145 Batch F1: 0.9411764705882353
Epoch:  848        4 Batch loss: 0.080147 Batch F1: 1.0
Epoch:  848        5 Batch loss: 0.065881 Batch F1: 0.9333333333333333
Epoch:  848        6 Batch loss: 0.076998 Batch F1: 0.6153846153846153
Epoch:  848        7 Batch loss: 0.069861 Batch F1: 0.25
Epoch:  848        8 Batch loss: 0.050611 Batch F1: 0.5
Epoch:  848        9 Batch loss: 0.110637 Batch F1: 0.375
Epoch:  848       10 Batch loss: 0.064548 Batch F1: 0.9473684210526316
Epoch:  848       11 Batch loss: 0.079634 Batch F1: 1.0
Epoch:  848       12 Batch loss: 0.050394 Batch F1: 0.888888888888889
Train Avg Loss  848: 0.073231

Train Avg F1  848: 0.6695404218817531

Val Avg Loss  848: 0.070869

Val Avg F1  848:  0.7435897435897435

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 849
--------------------------------------------------------------
Epoch:  849        1 Batch loss: 0.053118 Batch F1: 0.8571428571428571
Epoch:  849        2 Batch loss: 0.130598 Batch F1: 0.0
Epoch:  849        3 Batch loss: 0.063843 Batch F1: 0.4444444444444445
Epoch:  849        4 Batch loss: 0.084255 Batch F1: 0.42857142857142855
Epoch:  849        5 Batch loss: 0.078390 Batch F1: 0.888888888888889
Epoch:  849        6 Batch loss: 0.069973 Batch F1: 0.8750000000000001
Epoch:  849        7 Batch loss: 0.086335 Batch F1: 0.9090909090909091
Epoch:  849        8 Batch loss: 0.057341 Batch F1: 1.0
Epoch:  849        9 Batch loss: 0.072818 Batch F1: 1.0
Epoch:  849       10 Batch loss: 0.064582 Batch F1: 0.9
Epoch:  849       11 Batch loss: 0.050313 Batch F1: 0.888888888888889
Epoch:  849       12 Batch loss: 0.071821 Batch F1: 0.923076923076923
Train Avg Loss  849: 0.073616

Train Avg F1  849: 0.7595920283420283

Val Avg Loss  849: 0.062358

Val Avg F1  849:  0.9341179653679653

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 850
--------------------------------------------------------------
Epoch:  850        1 Batch loss: 0.082941 Batch F1: 0.8235294117647058
Epoch:  850        2 Batch loss: 0.069650 Batch F1: 0.9473684210526316
Epoch:  850        3 Batch loss: 0.070971 Batch F1: 1.0
Epoch:  850        4 Batch loss: 0.051562 Batch F1: 0.923076923076923
Epoch:  850        5 Batch loss: 0.068799 Batch F1: 1.0
Epoch:  850        6 Batch loss: 0.048251 Batch F1: 1.0
Epoch:  850        7 Batch loss: 0.078543 Batch F1: 0.888888888888889
Epoch:  850        8 Batch loss: 0.077269 Batch F1: 0.9333333333333333
Epoch:  850        9 Batch loss: 0.066575 Batch F1: 0.8571428571428571
Epoch:  850       10 Batch loss: 0.072261 Batch F1: 0.8750000000000001
Epoch:  850       11 Batch loss: 0.069983 Batch F1: 0.8235294117647058
Epoch:  850       12 Batch loss: 0.061572 Batch F1: 0.888888888888889
Train Avg Loss  850: 0.068198

Train Avg F1  850: 0.913396511326078

Val Avg Loss  850: 0.061509

Val Avg F1  850:  0.8987666576928255

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 851
--------------------------------------------------------------
Epoch:  851        1 Batch loss: 0.072689 Batch F1: 0.9523809523809523
Epoch:  851        2 Batch loss: 0.065047 Batch F1: 0.8750000000000001
Epoch:  851        3 Batch loss: 0.060194 Batch F1: 0.888888888888889
Epoch:  851        4 Batch loss: 0.080256 Batch F1: 0.8421052631578948
Epoch:  851        5 Batch loss: 0.054709 Batch F1: 0.6666666666666666
Epoch:  851        6 Batch loss: 0.065550 Batch F1: 0.2857142857142857
Epoch:  851        7 Batch loss: 0.078672 Batch F1: 0.4615384615384615
Epoch:  851        8 Batch loss: 0.069080 Batch F1: 0.4615384615384615
Epoch:  851        9 Batch loss: 0.078911 Batch F1: 0.3076923076923077
Epoch:  851       10 Batch loss: 0.073385 Batch F1: 0.4615384615384615
Epoch:  851       11 Batch loss: 0.069374 Batch F1: 0.625
Epoch:  851       12 Batch loss: 0.049979 Batch F1: 1.0
Train Avg Loss  851: 0.068154

Train Avg F1  851: 0.6523386457596984

Val Avg Loss  851: 0.062352

Val Avg F1  851:  0.914396681749623

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 852
--------------------------------------------------------------
Epoch:  852        1 Batch loss: 0.054095 Batch F1: 0.8571428571428571
Epoch:  852        2 Batch loss: 0.072806 Batch F1: 0.9
Epoch:  852        3 Batch loss: 0.068463 Batch F1: 0.8571428571428571
Epoch:  852        4 Batch loss: 0.082532 Batch F1: 0.9166666666666666
Epoch:  852        5 Batch loss: 0.083651 Batch F1: 0.9565217391304348
Epoch:  852        6 Batch loss: 0.086925 Batch F1: 0.9090909090909091
Epoch:  852        7 Batch loss: 0.060986 Batch F1: 0.9333333333333333
Epoch:  852        8 Batch loss: 0.055146 Batch F1: 0.8333333333333333
Epoch:  852        9 Batch loss: 0.070390 Batch F1: 1.0
Epoch:  852       10 Batch loss: 0.060358 Batch F1: 0.9090909090909091
Epoch:  852       11 Batch loss: 0.048681 Batch F1: 0.9090909090909091
Epoch:  852       12 Batch loss: 0.057026 Batch F1: 0.2857142857142857
Train Avg Loss  852: 0.066755

Train Avg F1  852: 0.8555939833113745

Val Avg Loss  852: 0.064346

Val Avg F1  852:  0.5668650793650793

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 853
--------------------------------------------------------------
Epoch:  853        1 Batch loss: 0.074299 Batch F1: 0.4
Epoch:  853        2 Batch loss: 0.071992 Batch F1: 0.5
Epoch:  853        3 Batch loss: 0.054767 Batch F1: 0.4444444444444445
Epoch:  853        4 Batch loss: 0.055191 Batch F1: 0.6666666666666666
Epoch:  853        5 Batch loss: 0.078196 Batch F1: 0.5
Epoch:  853        6 Batch loss: 0.044657 Batch F1: 0.5
Epoch:  853        7 Batch loss: 0.118254 Batch F1: 0.33333333333333337
Epoch:  853        8 Batch loss: 0.061879 Batch F1: 0.8
Epoch:  853        9 Batch loss: 0.080591 Batch F1: 0.923076923076923
Epoch:  853       10 Batch loss: 0.057835 Batch F1: 1.0
Epoch:  853       11 Batch loss: 0.052295 Batch F1: 1.0
Epoch:  853       12 Batch loss: 0.075320 Batch F1: 0.9473684210526316
Train Avg Loss  853: 0.068773

Train Avg F1  853: 0.6679074823811666

Val Avg Loss  853: 0.063057

Val Avg F1  853:  0.936421937195931

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 854
--------------------------------------------------------------
Epoch:  854        1 Batch loss: 0.062983 Batch F1: 0.9473684210526316
Epoch:  854        2 Batch loss: 0.058104 Batch F1: 1.0
Epoch:  854        3 Batch loss: 0.108411 Batch F1: 0.8823529411764706
Epoch:  854        4 Batch loss: 0.045945 Batch F1: 1.0
Epoch:  854        5 Batch loss: 0.064194 Batch F1: 0.923076923076923
Epoch:  854        6 Batch loss: 0.063208 Batch F1: 0.8750000000000001
Epoch:  854        7 Batch loss: 0.087419 Batch F1: 0.9655172413793104
Epoch:  854        8 Batch loss: 0.063631 Batch F1: 0.9411764705882353
Epoch:  854        9 Batch loss: 0.065500 Batch F1: 0.8750000000000001
Epoch:  854       10 Batch loss: 0.063290 Batch F1: 1.0
Epoch:  854       11 Batch loss: 0.075540 Batch F1: 0.6
Epoch:  854       12 Batch loss: 0.050922 Batch F1: 0.4
Train Avg Loss  854: 0.067429

Train Avg F1  854: 0.8674576664394643

Val Avg Loss  854: 0.065918

Val Avg F1  854:  0.5753968253968255

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 855
--------------------------------------------------------------
Epoch:  855        1 Batch loss: 0.056221 Batch F1: 0.4444444444444445
Epoch:  855        2 Batch loss: 0.067084 Batch F1: 0.25
Epoch:  855        3 Batch loss: 0.070547 Batch F1: 0.6666666666666666
Epoch:  855        4 Batch loss: 0.042044 Batch F1: 0.5
Epoch:  855        5 Batch loss: 0.073979 Batch F1: 0.625
Epoch:  855        6 Batch loss: 0.059537 Batch F1: 0.5454545454545454
Epoch:  855        7 Batch loss: 0.057957 Batch F1: 0.6
Epoch:  855        8 Batch loss: 0.070527 Batch F1: 0.2222222222222222
Epoch:  855        9 Batch loss: 0.073244 Batch F1: 0.5882352941176471
Epoch:  855       10 Batch loss: 0.089815 Batch F1: 0.4444444444444445
Epoch:  855       11 Batch loss: 0.068117 Batch F1: 0.923076923076923
Epoch:  855       12 Batch loss: 0.087169 Batch F1: 0.8571428571428571
Train Avg Loss  855: 0.068020

Train Avg F1  855: 0.5555572831308125

Val Avg Loss  855: 0.061530

Val Avg F1  855:  0.931845238095238

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 856
--------------------------------------------------------------
Epoch:  856        1 Batch loss: 0.058196 Batch F1: 0.923076923076923
Epoch:  856        2 Batch loss: 0.083776 Batch F1: 0.9
Epoch:  856        3 Batch loss: 0.066675 Batch F1: 0.9473684210526316
Epoch:  856        4 Batch loss: 0.072477 Batch F1: 0.9523809523809523
Epoch:  856        5 Batch loss: 0.049695 Batch F1: 0.9333333333333333
Epoch:  856        6 Batch loss: 0.062604 Batch F1: 0.9523809523809523
Epoch:  856        7 Batch loss: 0.062745 Batch F1: 1.0
Epoch:  856        8 Batch loss: 0.055228 Batch F1: 1.0
Epoch:  856        9 Batch loss: 0.087609 Batch F1: 0.7777777777777778
Epoch:  856       10 Batch loss: 0.066405 Batch F1: 0.9411764705882353
Epoch:  856       11 Batch loss: 0.083143 Batch F1: 0.9090909090909091
Epoch:  856       12 Batch loss: 0.068048 Batch F1: 0.6666666666666666
Train Avg Loss  856: 0.068050

Train Avg F1  856: 0.9086043671956984

Val Avg Loss  856: 0.061964

Val Avg F1  856:  0.9182449494949495

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 857
--------------------------------------------------------------
Epoch:  857        1 Batch loss: 0.060845 Batch F1: 1.0
Epoch:  857        2 Batch loss: 0.073037 Batch F1: 0.625
Epoch:  857        3 Batch loss: 0.058993 Batch F1: 0.7692307692307693
Epoch:  857        4 Batch loss: 0.086714 Batch F1: 0.3076923076923077
Epoch:  857        5 Batch loss: 0.057802 Batch F1: 0.6666666666666666
Epoch:  857        6 Batch loss: 0.055568 Batch F1: 0.6666666666666666
Epoch:  857        7 Batch loss: 0.077324 Batch F1: 0.6666666666666666
Epoch:  857        8 Batch loss: 0.073015 Batch F1: 0.9473684210526316
Epoch:  857        9 Batch loss: 0.084457 Batch F1: 0.9090909090909091
Epoch:  857       10 Batch loss: 0.066483 Batch F1: 1.0
Epoch:  857       11 Batch loss: 0.052533 Batch F1: 1.0
Epoch:  857       12 Batch loss: 0.078175 Batch F1: 0.5714285714285715
Train Avg Loss  857: 0.068745

Train Avg F1  857: 0.7608175815412657

Val Avg Loss  857: 0.061698

Val Avg F1  857:  0.9269607843137255

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 858
--------------------------------------------------------------
Epoch:  858        1 Batch loss: 0.071161 Batch F1: 1.0
Epoch:  858        2 Batch loss: 0.075070 Batch F1: 0.8750000000000001
Epoch:  858        3 Batch loss: 0.077119 Batch F1: 0.9
Epoch:  858        4 Batch loss: 0.061157 Batch F1: 0.6666666666666666
Epoch:  858        5 Batch loss: 0.060357 Batch F1: 0.9090909090909091
Epoch:  858        6 Batch loss: 0.067575 Batch F1: 1.0
Epoch:  858        7 Batch loss: 0.073356 Batch F1: 0.8750000000000001
Epoch:  858        8 Batch loss: 0.068638 Batch F1: 0.9565217391304348
Epoch:  858        9 Batch loss: 0.073905 Batch F1: 0.9
Epoch:  858       10 Batch loss: 0.047226 Batch F1: 1.0
Epoch:  858       11 Batch loss: 0.066488 Batch F1: 0.9411764705882353
Epoch:  858       12 Batch loss: 0.067476 Batch F1: 0.8333333333333333
Train Avg Loss  858: 0.067461

Train Avg F1  858: 0.904732426567465

Val Avg Loss  858: 0.061245

Val Avg F1  858:  0.9219367588932806

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 859
--------------------------------------------------------------
Epoch:  859        1 Batch loss: 0.055082 Batch F1: 0.8
Epoch:  859        2 Batch loss: 0.059469 Batch F1: 0.7142857142857143
Epoch:  859        3 Batch loss: 0.072103 Batch F1: 0.3636363636363636
Epoch:  859        4 Batch loss: 0.083659 Batch F1: 0.3076923076923077
Epoch:  859        5 Batch loss: 0.085259 Batch F1: 0.2857142857142857
Epoch:  859        6 Batch loss: 0.067273 Batch F1: 1.0
Epoch:  859        7 Batch loss: 0.072937 Batch F1: 0.888888888888889
Epoch:  859        8 Batch loss: 0.053005 Batch F1: 0.9411764705882353
Epoch:  859        9 Batch loss: 0.053134 Batch F1: 0.9090909090909091
Epoch:  859       10 Batch loss: 0.053310 Batch F1: 0.888888888888889
Epoch:  859       11 Batch loss: 0.090152 Batch F1: 0.88
Epoch:  859       12 Batch loss: 0.063923 Batch F1: 0.923076923076923
Train Avg Loss  859: 0.067442

Train Avg F1  859: 0.741870895988543

Val Avg Loss  859: 0.061278

Val Avg F1  859:  0.9329131652661065

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 860
--------------------------------------------------------------
Epoch:  860        1 Batch loss: 0.088849 Batch F1: 0.962962962962963
Epoch:  860        2 Batch loss: 0.066012 Batch F1: 0.9333333333333333
Epoch:  860        3 Batch loss: 0.061822 Batch F1: 0.8333333333333333
Epoch:  860        4 Batch loss: 0.066162 Batch F1: 0.8571428571428571
Epoch:  860        5 Batch loss: 0.050161 Batch F1: 1.0
Epoch:  860        6 Batch loss: 0.059486 Batch F1: 0.9411764705882353
Epoch:  860        7 Batch loss: 0.053386 Batch F1: 1.0
Epoch:  860        8 Batch loss: 0.071263 Batch F1: 0.5882352941176471
Epoch:  860        9 Batch loss: 0.054447 Batch F1: 0.9333333333333333
Epoch:  860       10 Batch loss: 0.073485 Batch F1: 0.9411764705882353
Epoch:  860       11 Batch loss: 0.099699 Batch F1: 0.8
Epoch:  860       12 Batch loss: 0.067847 Batch F1: 0.7499999999999999
Train Avg Loss  860: 0.067718

Train Avg F1  860: 0.8783911712833282

Val Avg Loss  860: 0.061927

Val Avg F1  860:  0.9313168449197862

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 861
--------------------------------------------------------------
Epoch:  861        1 Batch loss: 0.072856 Batch F1: 0.9565217391304348
Epoch:  861        2 Batch loss: 0.077249 Batch F1: 0.9166666666666666
Epoch:  861        3 Batch loss: 0.059761 Batch F1: 0.923076923076923
Epoch:  861        4 Batch loss: 0.077688 Batch F1: 1.0
Epoch:  861        5 Batch loss: 0.053940 Batch F1: 0.9333333333333333
Epoch:  861        6 Batch loss: 0.076218 Batch F1: 0.7692307692307693
Epoch:  861        7 Batch loss: 0.067738 Batch F1: 0.6666666666666666
Epoch:  861        8 Batch loss: 0.066584 Batch F1: 0.6666666666666666
Epoch:  861        9 Batch loss: 0.055908 Batch F1: 0.0
Epoch:  861       10 Batch loss: 0.080024 Batch F1: 0.4
Epoch:  861       11 Batch loss: 0.058771 Batch F1: 0.4444444444444445
Epoch:  861       12 Batch loss: 0.070223 Batch F1: 0.4
Train Avg Loss  861: 0.068080

Train Avg F1  861: 0.6730506007679922

Val Avg Loss  861: 0.062439

Val Avg F1  861:  0.5365800865800866

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 862
--------------------------------------------------------------
Epoch:  862        1 Batch loss: 0.059614 Batch F1: 0.6
Epoch:  862        2 Batch loss: 0.069625 Batch F1: 0.5454545454545454
Epoch:  862        3 Batch loss: 0.066818 Batch F1: 0.4444444444444445
Epoch:  862        4 Batch loss: 0.046139 Batch F1: 0.6666666666666666
Epoch:  862        5 Batch loss: 0.059045 Batch F1: 0.4
Epoch:  862        6 Batch loss: 0.075327 Batch F1: 0.33333333333333337
Epoch:  862        7 Batch loss: 0.077631 Batch F1: 0.19999999999999998
Epoch:  862        8 Batch loss: 0.076190 Batch F1: 0.625
Epoch:  862        9 Batch loss: 0.072491 Batch F1: 0.9090909090909091
Epoch:  862       10 Batch loss: 0.068258 Batch F1: 0.9523809523809523
Epoch:  862       11 Batch loss: 0.074628 Batch F1: 0.9
Epoch:  862       12 Batch loss: 0.066462 Batch F1: 0.9333333333333333
Train Avg Loss  862: 0.067686

Train Avg F1  862: 0.6258086820586821

Val Avg Loss  862: 0.063501

Val Avg F1  862:  0.9246288798920378

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 863
--------------------------------------------------------------
Epoch:  863        1 Batch loss: 0.075784 Batch F1: 0.7777777777777778
Epoch:  863        2 Batch loss: 0.077771 Batch F1: 0.888888888888889
Epoch:  863        3 Batch loss: 0.079205 Batch F1: 1.0
Epoch:  863        4 Batch loss: 0.060157 Batch F1: 1.0
Epoch:  863        5 Batch loss: 0.059572 Batch F1: 0.8571428571428571
Epoch:  863        6 Batch loss: 0.071221 Batch F1: 0.4
Epoch:  863        7 Batch loss: 0.071339 Batch F1: 0.5714285714285715
Epoch:  863        8 Batch loss: 0.094024 Batch F1: 0.2666666666666667
Epoch:  863        9 Batch loss: 0.075333 Batch F1: 0.33333333333333337
Epoch:  863       10 Batch loss: 0.059030 Batch F1: 0.8571428571428571
Epoch:  863       11 Batch loss: 0.071146 Batch F1: 0.7499999999999999
Epoch:  863       12 Batch loss: 0.057316 Batch F1: 1.0
Train Avg Loss  863: 0.070992

Train Avg F1  863: 0.7251984126984127

Val Avg Loss  863: 0.061922

Val Avg F1  863:  0.8757309941520468

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 864
--------------------------------------------------------------
Epoch:  864        1 Batch loss: 0.067659 Batch F1: 0.9523809523809523
Epoch:  864        2 Batch loss: 0.059152 Batch F1: 0.8571428571428571
Epoch:  864        3 Batch loss: 0.061998 Batch F1: 1.0
Epoch:  864        4 Batch loss: 0.063974 Batch F1: 1.0
Epoch:  864        5 Batch loss: 0.078594 Batch F1: 0.7058823529411764
Epoch:  864        6 Batch loss: 0.072635 Batch F1: 0.4615384615384615
Epoch:  864        7 Batch loss: 0.064098 Batch F1: 0.3636363636363636
Epoch:  864        8 Batch loss: 0.071712 Batch F1: 0.5454545454545454
Epoch:  864        9 Batch loss: 0.069878 Batch F1: 0.9
Epoch:  864       10 Batch loss: 0.090142 Batch F1: 0.8181818181818181
Epoch:  864       11 Batch loss: 0.064996 Batch F1: 0.923076923076923
Epoch:  864       12 Batch loss: 0.061792 Batch F1: 0.8571428571428571
Train Avg Loss  864: 0.068886

Train Avg F1  864: 0.782036427624663

Val Avg Loss  864: 0.066115

Val Avg F1  864:  0.7326388888888888

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 865
--------------------------------------------------------------
Epoch:  865        1 Batch loss: 0.061280 Batch F1: 0.8
Epoch:  865        2 Batch loss: 0.060326 Batch F1: 0.2857142857142857
Epoch:  865        3 Batch loss: 0.121765 Batch F1: 0.0
Epoch:  865        4 Batch loss: 0.055670 Batch F1: 0.7692307692307693
Epoch:  865        5 Batch loss: 0.053226 Batch F1: 1.0
Epoch:  865        6 Batch loss: 0.080492 Batch F1: 0.8571428571428571
Epoch:  865        7 Batch loss: 0.088493 Batch F1: 0.7692307692307693
Epoch:  865        8 Batch loss: 0.071724 Batch F1: 1.0
Epoch:  865        9 Batch loss: 0.079203 Batch F1: 0.6666666666666666
Epoch:  865       10 Batch loss: 0.066621 Batch F1: 0.8571428571428571
Epoch:  865       11 Batch loss: 0.072174 Batch F1: 1.0
Epoch:  865       12 Batch loss: 0.069170 Batch F1: 0.7272727272727273
Train Avg Loss  865: 0.073345

Train Avg F1  865: 0.7277000777000776

Val Avg Loss  865: 0.063052

Val Avg F1  865:  0.902991452991453

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 866
--------------------------------------------------------------
Epoch:  866        1 Batch loss: 0.073240 Batch F1: 0.9600000000000001
Epoch:  866        2 Batch loss: 0.074139 Batch F1: 0.9166666666666666
Epoch:  866        3 Batch loss: 0.053956 Batch F1: 1.0
Epoch:  866        4 Batch loss: 0.072155 Batch F1: 0.6
Epoch:  866        5 Batch loss: 0.069436 Batch F1: 0.25
Epoch:  866        6 Batch loss: 0.081078 Batch F1: 0.4615384615384615
Epoch:  866        7 Batch loss: 0.064664 Batch F1: 1.0
Epoch:  866        8 Batch loss: 0.068673 Batch F1: 0.888888888888889
Epoch:  866        9 Batch loss: 0.068211 Batch F1: 0.8750000000000001
Epoch:  866       10 Batch loss: 0.071329 Batch F1: 0.9473684210526316
Epoch:  866       11 Batch loss: 0.054332 Batch F1: 1.0
Epoch:  866       12 Batch loss: 0.085875 Batch F1: 0.8750000000000001
Train Avg Loss  866: 0.069757

Train Avg F1  866: 0.8145385365122207

Val Avg Loss  866: 0.062716

Val Avg F1  866:  0.5520676691729324

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 867
--------------------------------------------------------------
Epoch:  867        1 Batch loss: 0.067717 Batch F1: 0.3636363636363636
Epoch:  867        2 Batch loss: 0.056206 Batch F1: 0.7499999999999999
Epoch:  867        3 Batch loss: 0.069997 Batch F1: 0.9565217391304348
Epoch:  867        4 Batch loss: 0.060511 Batch F1: 0.9333333333333333
Epoch:  867        5 Batch loss: 0.068313 Batch F1: 0.8750000000000001
Epoch:  867        6 Batch loss: 0.081135 Batch F1: 0.9
Epoch:  867        7 Batch loss: 0.072147 Batch F1: 0.7692307692307693
Epoch:  867        8 Batch loss: 0.066601 Batch F1: 0.9473684210526316
Epoch:  867        9 Batch loss: 0.079293 Batch F1: 0.8
Epoch:  867       10 Batch loss: 0.075273 Batch F1: 0.9523809523809523
Epoch:  867       11 Batch loss: 0.055242 Batch F1: 0.923076923076923
Epoch:  867       12 Batch loss: 0.062449 Batch F1: 0.4
Train Avg Loss  867: 0.067907

Train Avg F1  867: 0.797545708486784

Val Avg Loss  867: 0.072868

Val Avg F1  867:  0.0

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 868
--------------------------------------------------------------
Epoch:  868        1 Batch loss: 0.073113 Batch F1: 0.0
Epoch:  868        2 Batch loss: 0.088993 Batch F1: 0.5333333333333333
Epoch:  868        3 Batch loss: 0.087870 Batch F1: 0.5555555555555556
Epoch:  868        4 Batch loss: 0.083213 Batch F1: 0.9
Epoch:  868        5 Batch loss: 0.075788 Batch F1: 1.0
Epoch:  868        6 Batch loss: 0.067174 Batch F1: 0.9090909090909091
Epoch:  868        7 Batch loss: 0.060246 Batch F1: 0.6666666666666666
Epoch:  868        8 Batch loss: 0.050284 Batch F1: 0.5714285714285715
Epoch:  868        9 Batch loss: 0.078506 Batch F1: 0.5333333333333333
Epoch:  868       10 Batch loss: 0.073302 Batch F1: 0.5882352941176471
Epoch:  868       11 Batch loss: 0.058643 Batch F1: 0.7499999999999999
Epoch:  868       12 Batch loss: 0.067489 Batch F1: 0.33333333333333337
Train Avg Loss  868: 0.072052

Train Avg F1  868: 0.6117480830716124

Val Avg Loss  868: 0.066191

Val Avg F1  868:  0.5725108225108225

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 869
--------------------------------------------------------------
Epoch:  869        1 Batch loss: 0.064193 Batch F1: 0.6153846153846153
Epoch:  869        2 Batch loss: 0.082266 Batch F1: 0.5
Epoch:  869        3 Batch loss: 0.067093 Batch F1: 0.5
Epoch:  869        4 Batch loss: 0.051812 Batch F1: 1.0
Epoch:  869        5 Batch loss: 0.067347 Batch F1: 0.7142857142857143
Epoch:  869        6 Batch loss: 0.075980 Batch F1: 0.2222222222222222
Epoch:  869        7 Batch loss: 0.067656 Batch F1: 0.2857142857142857
Epoch:  869        8 Batch loss: 0.073247 Batch F1: 0.4615384615384615
Epoch:  869        9 Batch loss: 0.066296 Batch F1: 0.8
Epoch:  869       10 Batch loss: 0.093836 Batch F1: 0.4444444444444445
Epoch:  869       11 Batch loss: 0.071683 Batch F1: 0.9523809523809523
Epoch:  869       12 Batch loss: 0.075613 Batch F1: 0.8000000000000002
Train Avg Loss  869: 0.071418

Train Avg F1  869: 0.607997557997558

Val Avg Loss  869: 0.062650

Val Avg F1  869:  0.9083333333333332

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 870
--------------------------------------------------------------
Epoch:  870        1 Batch loss: 0.076702 Batch F1: 0.9411764705882353
Epoch:  870        2 Batch loss: 0.062470 Batch F1: 0.33333333333333337
Epoch:  870        3 Batch loss: 0.059009 Batch F1: 0.2857142857142857
Epoch:  870        4 Batch loss: 0.078245 Batch F1: 0.4615384615384615
Epoch:  870        5 Batch loss: 0.060888 Batch F1: 0.7272727272727273
Epoch:  870        6 Batch loss: 0.065904 Batch F1: 0.6666666666666666
Epoch:  870        7 Batch loss: 0.094161 Batch F1: 0.8181818181818181
Epoch:  870        8 Batch loss: 0.072473 Batch F1: 0.9473684210526316
Epoch:  870        9 Batch loss: 0.059719 Batch F1: 1.0
Epoch:  870       10 Batch loss: 0.076001 Batch F1: 0.8750000000000001
Epoch:  870       11 Batch loss: 0.081796 Batch F1: 0.888888888888889
Epoch:  870       12 Batch loss: 0.056542 Batch F1: 0.9090909090909091
Train Avg Loss  870: 0.070326

Train Avg F1  870: 0.7378526651939965

Val Avg Loss  870: 0.062409

Val Avg F1  870:  0.9251276759016697

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 871
--------------------------------------------------------------
Epoch:  871        1 Batch loss: 0.061337 Batch F1: 0.9473684210526316
Epoch:  871        2 Batch loss: 0.067427 Batch F1: 0.888888888888889
Epoch:  871        3 Batch loss: 0.062471 Batch F1: 0.8333333333333333
Epoch:  871        4 Batch loss: 0.063596 Batch F1: 0.9333333333333333
Epoch:  871        5 Batch loss: 0.076138 Batch F1: 0.8
Epoch:  871        6 Batch loss: 0.045281 Batch F1: 0.0
Epoch:  871        7 Batch loss: 0.083123 Batch F1: 0.4615384615384615
Epoch:  871        8 Batch loss: 0.071782 Batch F1: 0.3636363636363636
Epoch:  871        9 Batch loss: 0.098560 Batch F1: 0.5454545454545454
Epoch:  871       10 Batch loss: 0.068722 Batch F1: 0.9473684210526316
Epoch:  871       11 Batch loss: 0.073416 Batch F1: 0.8750000000000001
Epoch:  871       12 Batch loss: 0.067457 Batch F1: 1.0
Train Avg Loss  871: 0.069942

Train Avg F1  871: 0.7163268140241824

Val Avg Loss  871: 0.064225

Val Avg F1  871:  0.9342857142857143

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 872
--------------------------------------------------------------
Epoch:  872        1 Batch loss: 0.073698 Batch F1: 0.9565217391304348
Epoch:  872        2 Batch loss: 0.067897 Batch F1: 0.9473684210526316
Epoch:  872        3 Batch loss: 0.076874 Batch F1: 1.0
Epoch:  872        4 Batch loss: 0.076653 Batch F1: 0.9
Epoch:  872        5 Batch loss: 0.056193 Batch F1: 0.923076923076923
Epoch:  872        6 Batch loss: 0.069938 Batch F1: 0.8571428571428571
Epoch:  872        7 Batch loss: 0.075305 Batch F1: 0.5882352941176471
Epoch:  872        8 Batch loss: 0.057717 Batch F1: 0.5
Epoch:  872        9 Batch loss: 0.077734 Batch F1: 0.6153846153846153
Epoch:  872       10 Batch loss: 0.064627 Batch F1: 0.3636363636363636
Epoch:  872       11 Batch loss: 0.065376 Batch F1: 0.4
Epoch:  872       12 Batch loss: 0.058906 Batch F1: 0.6666666666666666
Train Avg Loss  872: 0.068410

Train Avg F1  872: 0.7265027400173447

Val Avg Loss  872: 0.061808

Val Avg F1  872:  0.6055513114336644

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 873
--------------------------------------------------------------
Epoch:  873        1 Batch loss: 0.073042 Batch F1: 0.5333333333333333
Epoch:  873        2 Batch loss: 0.050318 Batch F1: 1.0
Epoch:  873        3 Batch loss: 0.062418 Batch F1: 0.923076923076923
Epoch:  873        4 Batch loss: 0.062034 Batch F1: 0.5
Epoch:  873        5 Batch loss: 0.080632 Batch F1: 0.3076923076923077
Epoch:  873        6 Batch loss: 0.085318 Batch F1: 0.9
Epoch:  873        7 Batch loss: 0.065479 Batch F1: 0.9473684210526316
Epoch:  873        8 Batch loss: 0.066252 Batch F1: 0.8750000000000001
Epoch:  873        9 Batch loss: 0.091164 Batch F1: 0.8181818181818181
Epoch:  873       10 Batch loss: 0.075358 Batch F1: 0.8235294117647058
Epoch:  873       11 Batch loss: 0.053158 Batch F1: 1.0
Epoch:  873       12 Batch loss: 0.047467 Batch F1: 1.0
Train Avg Loss  873: 0.067720

Train Avg F1  873: 0.8023485179251434

Val Avg Loss  873: 0.061333

Val Avg F1  873:  0.9186274509803922

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 874
--------------------------------------------------------------
Epoch:  874        1 Batch loss: 0.080705 Batch F1: 0.6153846153846153
Epoch:  874        2 Batch loss: 0.065513 Batch F1: 0.9473684210526316
Epoch:  874        3 Batch loss: 0.083571 Batch F1: 0.9523809523809523
Epoch:  874        4 Batch loss: 0.061535 Batch F1: 0.9411764705882353
Epoch:  874        5 Batch loss: 0.067099 Batch F1: 1.0
Epoch:  874        6 Batch loss: 0.061511 Batch F1: 1.0
Epoch:  874        7 Batch loss: 0.053276 Batch F1: 0.9090909090909091
Epoch:  874        8 Batch loss: 0.057482 Batch F1: 1.0
Epoch:  874        9 Batch loss: 0.054954 Batch F1: 0.5
Epoch:  874       10 Batch loss: 0.078263 Batch F1: 0.6153846153846153
Epoch:  874       11 Batch loss: 0.065433 Batch F1: 0.6666666666666666
Epoch:  874       12 Batch loss: 0.089641 Batch F1: 0.4
Train Avg Loss  874: 0.068249

Train Avg F1  874: 0.7956210542123855

Val Avg Loss  874: 0.062836

Val Avg F1  874:  0.8929941428807128

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 875
--------------------------------------------------------------
Epoch:  875        1 Batch loss: 0.035296 Batch F1: 1.0
Epoch:  875        2 Batch loss: 0.041253 Batch F1: 0.7499999999999999
Epoch:  875        3 Batch loss: 0.085421 Batch F1: 0.6666666666666666
Epoch:  875        4 Batch loss: 0.049457 Batch F1: 0.5714285714285715
Epoch:  875        5 Batch loss: 0.060209 Batch F1: 0.5454545454545454
Epoch:  875        6 Batch loss: 0.082889 Batch F1: 0.4
Epoch:  875        7 Batch loss: 0.070469 Batch F1: 0.625
Epoch:  875        8 Batch loss: 0.101481 Batch F1: 0.8695652173913044
Epoch:  875        9 Batch loss: 0.087768 Batch F1: 1.0
Epoch:  875       10 Batch loss: 0.067791 Batch F1: 0.8333333333333333
Epoch:  875       11 Batch loss: 0.084755 Batch F1: 0.7499999999999999
Epoch:  875       12 Batch loss: 0.090202 Batch F1: 0.5333333333333333
Train Avg Loss  875: 0.071416

Train Avg F1  875: 0.7120651389673128

Val Avg Loss  875: 0.062672

Val Avg F1  875:  0.9246323529411765

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 876
--------------------------------------------------------------
Epoch:  876        1 Batch loss: 0.076391 Batch F1: 0.9600000000000001
Epoch:  876        2 Batch loss: 0.062496 Batch F1: 0.4
Epoch:  876        3 Batch loss: 0.076874 Batch F1: 0.8571428571428571
Epoch:  876        4 Batch loss: 0.096099 Batch F1: 0.782608695652174
Epoch:  876        5 Batch loss: 0.074831 Batch F1: 0.625
Epoch:  876        6 Batch loss: 0.080269 Batch F1: 0.6666666666666666
Epoch:  876        7 Batch loss: 0.071521 Batch F1: 0.923076923076923
Epoch:  876        8 Batch loss: 0.047254 Batch F1: 1.0
Epoch:  876        9 Batch loss: 0.036176 Batch F1: 0.8
Epoch:  876       10 Batch loss: 0.101110 Batch F1: 0.0
Epoch:  876       11 Batch loss: 0.110167 Batch F1: 0.25
Epoch:  876       12 Batch loss: 0.073870 Batch F1: 0.5714285714285715
Train Avg Loss  876: 0.075588

Train Avg F1  876: 0.6529936428305994

Val Avg Loss  876: 0.067790

Val Avg F1  876:  0.7377819548872181

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 877
--------------------------------------------------------------
Epoch:  877        1 Batch loss: 0.082541 Batch F1: 0.5
Epoch:  877        2 Batch loss: 0.065334 Batch F1: 1.0
Epoch:  877        3 Batch loss: 0.092269 Batch F1: 0.5882352941176471
Epoch:  877        4 Batch loss: 0.075212 Batch F1: 0.6666666666666666
Epoch:  877        5 Batch loss: 0.053651 Batch F1: 0.5
Epoch:  877        6 Batch loss: 0.076701 Batch F1: 0.8
Epoch:  877        7 Batch loss: 0.062571 Batch F1: 0.9333333333333333
Epoch:  877        8 Batch loss: 0.069330 Batch F1: 0.9411764705882353
Epoch:  877        9 Batch loss: 0.059195 Batch F1: 0.9090909090909091
Epoch:  877       10 Batch loss: 0.077819 Batch F1: 0.2222222222222222
Epoch:  877       11 Batch loss: 0.068488 Batch F1: 0.25
Epoch:  877       12 Batch loss: 0.092910 Batch F1: 0.4615384615384615
Train Avg Loss  877: 0.073002

Train Avg F1  877: 0.6476886131297896

Val Avg Loss  877: 0.062823

Val Avg F1  877:  0.5888278388278388

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 878
--------------------------------------------------------------
Epoch:  878        1 Batch loss: 0.064534 Batch F1: 0.4444444444444445
Epoch:  878        2 Batch loss: 0.052158 Batch F1: 0.5714285714285715
Epoch:  878        3 Batch loss: 0.070296 Batch F1: 0.33333333333333337
Epoch:  878        4 Batch loss: 0.063544 Batch F1: 0.5714285714285715
Epoch:  878        5 Batch loss: 0.060165 Batch F1: 0.9333333333333333
Epoch:  878        6 Batch loss: 0.087113 Batch F1: 0.8421052631578948
Epoch:  878        7 Batch loss: 0.060026 Batch F1: 1.0
Epoch:  878        8 Batch loss: 0.075367 Batch F1: 0.9
Epoch:  878        9 Batch loss: 0.068761 Batch F1: 0.9523809523809523
Epoch:  878       10 Batch loss: 0.079114 Batch F1: 0.8235294117647058
Epoch:  878       11 Batch loss: 0.078953 Batch F1: 0.9090909090909091
Epoch:  878       12 Batch loss: 0.058021 Batch F1: 0.9090909090909091
Train Avg Loss  878: 0.068171

Train Avg F1  878: 0.7658471416211353

Val Avg Loss  878: 0.061870

Val Avg F1  878:  0.9284005468215994

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 879
--------------------------------------------------------------
Epoch:  879        1 Batch loss: 0.068939 Batch F1: 0.9473684210526316
Epoch:  879        2 Batch loss: 0.047652 Batch F1: 1.0
Epoch:  879        3 Batch loss: 0.062847 Batch F1: 1.0
Epoch:  879        4 Batch loss: 0.097447 Batch F1: 0.5
Epoch:  879        5 Batch loss: 0.088916 Batch F1: 0.8695652173913044
Epoch:  879        6 Batch loss: 0.064773 Batch F1: 0.8571428571428571
Epoch:  879        7 Batch loss: 0.057916 Batch F1: 0.923076923076923
Epoch:  879        8 Batch loss: 0.065790 Batch F1: 0.9411764705882353
Epoch:  879        9 Batch loss: 0.075336 Batch F1: 0.9565217391304348
Epoch:  879       10 Batch loss: 0.066007 Batch F1: 0.8750000000000001
Epoch:  879       11 Batch loss: 0.059361 Batch F1: 0.8
Epoch:  879       12 Batch loss: 0.059291 Batch F1: 1.0
Train Avg Loss  879: 0.067856

Train Avg F1  879: 0.889154302365199

Val Avg Loss  879: 0.063342

Val Avg F1  879:  0.7404411764705883

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 880
--------------------------------------------------------------
Epoch:  880        1 Batch loss: 0.061000 Batch F1: 0.8235294117647058
Epoch:  880        2 Batch loss: 0.061013 Batch F1: 0.6666666666666666
Epoch:  880        3 Batch loss: 0.052400 Batch F1: 0.2857142857142857
Epoch:  880        4 Batch loss: 0.068301 Batch F1: 0.625
Epoch:  880        5 Batch loss: 0.095356 Batch F1: 0.4
Epoch:  880        6 Batch loss: 0.083136 Batch F1: 0.16666666666666669
Epoch:  880        7 Batch loss: 0.061242 Batch F1: 0.9090909090909091
Epoch:  880        8 Batch loss: 0.051008 Batch F1: 0.7499999999999999
Epoch:  880        9 Batch loss: 0.059943 Batch F1: 0.7499999999999999
Epoch:  880       10 Batch loss: 0.082195 Batch F1: 0.962962962962963
Epoch:  880       11 Batch loss: 0.080584 Batch F1: 0.8695652173913044
Epoch:  880       12 Batch loss: 0.065849 Batch F1: 1.0
Train Avg Loss  880: 0.068502

Train Avg F1  880: 0.6840996766881252

Val Avg Loss  880: 0.061430

Val Avg F1  880:  0.9137362637362638

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 881
--------------------------------------------------------------
Epoch:  881        1 Batch loss: 0.072531 Batch F1: 0.9333333333333333
Epoch:  881        2 Batch loss: 0.050062 Batch F1: 1.0
Epoch:  881        3 Batch loss: 0.055603 Batch F1: 0.923076923076923
Epoch:  881        4 Batch loss: 0.099298 Batch F1: 0.9696969696969697
Epoch:  881        5 Batch loss: 0.087038 Batch F1: 0.8571428571428571
Epoch:  881        6 Batch loss: 0.060951 Batch F1: 0.9523809523809523
Epoch:  881        7 Batch loss: 0.064008 Batch F1: 0.9411764705882353
Epoch:  881        8 Batch loss: 0.060667 Batch F1: 1.0
Epoch:  881        9 Batch loss: 0.077878 Batch F1: 0.7692307692307693
Epoch:  881       10 Batch loss: 0.064249 Batch F1: 0.7499999999999999
Epoch:  881       11 Batch loss: 0.049250 Batch F1: 0.9333333333333333
Epoch:  881       12 Batch loss: 0.074788 Batch F1: 0.8571428571428571
Train Avg Loss  881: 0.068027

Train Avg F1  881: 0.907209538827186

Val Avg Loss  881: 0.061437

Val Avg F1  881:  0.9188311688311688

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 882
--------------------------------------------------------------
Epoch:  882        1 Batch loss: 0.058733 Batch F1: 0.9411764705882353
Epoch:  882        2 Batch loss: 0.064213 Batch F1: 0.2857142857142857
Epoch:  882        3 Batch loss: 0.054232 Batch F1: 0.5
Epoch:  882        4 Batch loss: 0.064128 Batch F1: 0.2857142857142857
Epoch:  882        5 Batch loss: 0.076795 Batch F1: 0.33333333333333337
Epoch:  882        6 Batch loss: 0.058576 Batch F1: 0.7142857142857143
Epoch:  882        7 Batch loss: 0.060130 Batch F1: 0.4
Epoch:  882        8 Batch loss: 0.056515 Batch F1: 0.6
Epoch:  882        9 Batch loss: 0.088174 Batch F1: 0.5714285714285715
Epoch:  882       10 Batch loss: 0.061209 Batch F1: 0.5714285714285715
Epoch:  882       11 Batch loss: 0.084402 Batch F1: 0.8571428571428571
Epoch:  882       12 Batch loss: 0.079933 Batch F1: 0.7499999999999999
Train Avg Loss  882: 0.067253

Train Avg F1  882: 0.5675186741363211

Val Avg Loss  882: 0.063463

Val Avg F1  882:  0.9325163398692811

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 883
--------------------------------------------------------------
Epoch:  883        1 Batch loss: 0.069122 Batch F1: 0.888888888888889
Epoch:  883        2 Batch loss: 0.080986 Batch F1: 0.9333333333333333
Epoch:  883        3 Batch loss: 0.066451 Batch F1: 1.0
Epoch:  883        4 Batch loss: 0.071760 Batch F1: 0.9333333333333333
Epoch:  883        5 Batch loss: 0.072752 Batch F1: 0.9411764705882353
Epoch:  883        6 Batch loss: 0.096480 Batch F1: 0.846153846153846
Epoch:  883        7 Batch loss: 0.072415 Batch F1: 0.7272727272727273
Epoch:  883        8 Batch loss: 0.062832 Batch F1: 1.0
Epoch:  883        9 Batch loss: 0.051786 Batch F1: 0.8
Epoch:  883       10 Batch loss: 0.065275 Batch F1: 0.7058823529411764
Epoch:  883       11 Batch loss: 0.085212 Batch F1: 0.5
Epoch:  883       12 Batch loss: 0.070505 Batch F1: 0.5454545454545454
Train Avg Loss  883: 0.072131

Train Avg F1  883: 0.8184579581638404

Val Avg Loss  883: 0.062313

Val Avg F1  883:  0.7345513963161021

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 884
--------------------------------------------------------------
Epoch:  884        1 Batch loss: 0.076413 Batch F1: 0.5333333333333333
Epoch:  884        2 Batch loss: 0.050342 Batch F1: 1.0
Epoch:  884        3 Batch loss: 0.071294 Batch F1: 0.9333333333333333
Epoch:  884        4 Batch loss: 0.063695 Batch F1: 1.0
Epoch:  884        5 Batch loss: 0.097469 Batch F1: 0.3076923076923077
Epoch:  884        6 Batch loss: 0.055441 Batch F1: 0.7272727272727273
Epoch:  884        7 Batch loss: 0.079227 Batch F1: 0.5882352941176471
Epoch:  884        8 Batch loss: 0.078808 Batch F1: 0.888888888888889
Epoch:  884        9 Batch loss: 0.062820 Batch F1: 0.8571428571428571
Epoch:  884       10 Batch loss: 0.072238 Batch F1: 0.8421052631578948
Epoch:  884       11 Batch loss: 0.074890 Batch F1: 0.9
Epoch:  884       12 Batch loss: 0.050793 Batch F1: 1.0
Train Avg Loss  884: 0.069453

Train Avg F1  884: 0.7981670004115825

Val Avg Loss  884: 0.062667

Val Avg F1  884:  0.9246031746031746

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 885
--------------------------------------------------------------
Epoch:  885        1 Batch loss: 0.046259 Batch F1: 0.8571428571428571
Epoch:  885        2 Batch loss: 0.063399 Batch F1: 0.0
Epoch:  885        3 Batch loss: 0.094097 Batch F1: 0.0
Epoch:  885        4 Batch loss: 0.102036 Batch F1: 0.375
Epoch:  885        5 Batch loss: 0.061609 Batch F1: 0.8750000000000001
Epoch:  885        6 Batch loss: 0.076642 Batch F1: 0.8571428571428571
Epoch:  885        7 Batch loss: 0.082295 Batch F1: 0.8461538461538461
Epoch:  885        8 Batch loss: 0.074536 Batch F1: 0.9411764705882353
Epoch:  885        9 Batch loss: 0.074320 Batch F1: 1.0
Epoch:  885       10 Batch loss: 0.064323 Batch F1: 0.8571428571428571
Epoch:  885       11 Batch loss: 0.079169 Batch F1: 0.9473684210526316
Epoch:  885       12 Batch loss: 0.047773 Batch F1: 0.8571428571428571
Train Avg Loss  885: 0.072205

Train Avg F1  885: 0.7011058471971784

Val Avg Loss  885: 0.066447

Val Avg F1  885:  0.5729166666666666

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 886
--------------------------------------------------------------
Epoch:  886        1 Batch loss: 0.076093 Batch F1: 0.6666666666666666
Epoch:  886        2 Batch loss: 0.066734 Batch F1: 0.4
Epoch:  886        3 Batch loss: 0.099025 Batch F1: 0.4
Epoch:  886        4 Batch loss: 0.068408 Batch F1: 0.7499999999999999
Epoch:  886        5 Batch loss: 0.050607 Batch F1: 0.888888888888889
Epoch:  886        6 Batch loss: 0.076011 Batch F1: 0.19999999999999998
Epoch:  886        7 Batch loss: 0.078045 Batch F1: 0.5333333333333333
Epoch:  886        8 Batch loss: 0.068985 Batch F1: 0.888888888888889
Epoch:  886        9 Batch loss: 0.059063 Batch F1: 0.8
Epoch:  886       10 Batch loss: 0.082360 Batch F1: 0.9
Epoch:  886       11 Batch loss: 0.071544 Batch F1: 0.8
Epoch:  886       12 Batch loss: 0.079718 Batch F1: 0.3636363636363636
Train Avg Loss  886: 0.073049

Train Avg F1  886: 0.6326178451178451

Val Avg Loss  886: 0.066523

Val Avg F1  886:  0.5598290598290598

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 887
--------------------------------------------------------------
Epoch:  887        1 Batch loss: 0.056198 Batch F1: 0.6
Epoch:  887        2 Batch loss: 0.094245 Batch F1: 0.15384615384615385
Epoch:  887        3 Batch loss: 0.077725 Batch F1: 0.8421052631578948
Epoch:  887        4 Batch loss: 0.083764 Batch F1: 0.9
Epoch:  887        5 Batch loss: 0.071790 Batch F1: 0.962962962962963
Epoch:  887        6 Batch loss: 0.078396 Batch F1: 0.9411764705882353
Epoch:  887        7 Batch loss: 0.059219 Batch F1: 0.8333333333333333
Epoch:  887        8 Batch loss: 0.071283 Batch F1: 0.9411764705882353
Epoch:  887        9 Batch loss: 0.051787 Batch F1: 0.5714285714285715
Epoch:  887       10 Batch loss: 0.053516 Batch F1: 0.5
Epoch:  887       11 Batch loss: 0.069267 Batch F1: 0.5714285714285715
Epoch:  887       12 Batch loss: 0.071368 Batch F1: 0.6
Train Avg Loss  887: 0.069880

Train Avg F1  887: 0.7014548164444965

Val Avg Loss  887: 0.062382

Val Avg F1  887:  0.49789915966386555

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 888
--------------------------------------------------------------
Epoch:  888        1 Batch loss: 0.092910 Batch F1: 0.5263157894736842
Epoch:  888        2 Batch loss: 0.058066 Batch F1: 0.2857142857142857
Epoch:  888        3 Batch loss: 0.054239 Batch F1: 1.0
Epoch:  888        4 Batch loss: 0.050855 Batch F1: 1.0
Epoch:  888        5 Batch loss: 0.050213 Batch F1: 0.8
Epoch:  888        6 Batch loss: 0.082228 Batch F1: 0.0
Epoch:  888        7 Batch loss: 0.076792 Batch F1: 0.7368421052631579
Epoch:  888        8 Batch loss: 0.053105 Batch F1: 0.8571428571428571
Epoch:  888        9 Batch loss: 0.093410 Batch F1: 0.888888888888889
Epoch:  888       10 Batch loss: 0.068717 Batch F1: 1.0
Epoch:  888       11 Batch loss: 0.090116 Batch F1: 0.8421052631578948
Epoch:  888       12 Batch loss: 0.078323 Batch F1: 0.8750000000000001
Train Avg Loss  888: 0.070748

Train Avg F1  888: 0.7343340991367308

Val Avg Loss  888: 0.062178

Val Avg F1  888:  0.9199849170437406

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 889
--------------------------------------------------------------
Epoch:  889        1 Batch loss: 0.080388 Batch F1: 0.9
Epoch:  889        2 Batch loss: 0.103874 Batch F1: 0.8333333333333333
Epoch:  889        3 Batch loss: 0.079774 Batch F1: 0.9090909090909091
Epoch:  889        4 Batch loss: 0.059606 Batch F1: 0.9090909090909091
Epoch:  889        5 Batch loss: 0.071404 Batch F1: 0.9090909090909091
Epoch:  889        6 Batch loss: 0.067894 Batch F1: 0.9523809523809523
Epoch:  889        7 Batch loss: 0.066755 Batch F1: 0.9411764705882353
Epoch:  889        8 Batch loss: 0.065403 Batch F1: 1.0
Epoch:  889        9 Batch loss: 0.061133 Batch F1: 0.9333333333333333
Epoch:  889       10 Batch loss: 0.091199 Batch F1: 0.88
Epoch:  889       11 Batch loss: 0.035203 Batch F1: 1.0
Epoch:  889       12 Batch loss: 0.029288 Batch F1: 0.6666666666666666
Train Avg Loss  889: 0.067660

Train Avg F1  889: 0.9028469569646042

Val Avg Loss  889: 0.066319

Val Avg F1  889:  0.553968253968254

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 890
--------------------------------------------------------------
Epoch:  890        1 Batch loss: 0.076138 Batch F1: 0.19999999999999998
Epoch:  890        2 Batch loss: 0.085518 Batch F1: 0.6666666666666666
Epoch:  890        3 Batch loss: 0.054819 Batch F1: 0.33333333333333337
Epoch:  890        4 Batch loss: 0.064984 Batch F1: 0.5714285714285715
Epoch:  890        5 Batch loss: 0.074442 Batch F1: 0.42857142857142855
Epoch:  890        6 Batch loss: 0.046162 Batch F1: 1.0
Epoch:  890        7 Batch loss: 0.063517 Batch F1: 0.8571428571428571
Epoch:  890        8 Batch loss: 0.073046 Batch F1: 0.888888888888889
Epoch:  890        9 Batch loss: 0.068183 Batch F1: 0.8750000000000001
Epoch:  890       10 Batch loss: 0.071104 Batch F1: 0.9333333333333333
Epoch:  890       11 Batch loss: 0.076267 Batch F1: 0.9473684210526316
Epoch:  890       12 Batch loss: 0.077717 Batch F1: 0.7692307692307693
Train Avg Loss  890: 0.069325

Train Avg F1  890: 0.7059136891373735

Val Avg Loss  890: 0.061022

Val Avg F1  890:  0.9257309941520468

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 891
--------------------------------------------------------------
Epoch:  891        1 Batch loss: 0.074187 Batch F1: 0.888888888888889
Epoch:  891        2 Batch loss: 0.062660 Batch F1: 0.9333333333333333
Epoch:  891        3 Batch loss: 0.055755 Batch F1: 0.9090909090909091
Epoch:  891        4 Batch loss: 0.060187 Batch F1: 0.8750000000000001
Epoch:  891        5 Batch loss: 0.054913 Batch F1: 0.7692307692307693
Epoch:  891        6 Batch loss: 0.062116 Batch F1: 0.4444444444444445
Epoch:  891        7 Batch loss: 0.076060 Batch F1: 0.3636363636363636
Epoch:  891        8 Batch loss: 0.081889 Batch F1: 0.9600000000000001
Epoch:  891        9 Batch loss: 0.078607 Batch F1: 0.9
Epoch:  891       10 Batch loss: 0.069977 Batch F1: 1.0
Epoch:  891       11 Batch loss: 0.066807 Batch F1: 0.9523809523809523
Epoch:  891       12 Batch loss: 0.074363 Batch F1: 0.888888888888889
Train Avg Loss  891: 0.068127

Train Avg F1  891: 0.8237412124912126

Val Avg Loss  891: 0.061990

Val Avg F1  891:  0.9141148325358852

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 892
--------------------------------------------------------------
Epoch:  892        1 Batch loss: 0.083284 Batch F1: 0.8571428571428571
Epoch:  892        2 Batch loss: 0.060114 Batch F1: 0.9090909090909091
Epoch:  892        3 Batch loss: 0.084329 Batch F1: 0.8695652173913044
Epoch:  892        4 Batch loss: 0.076259 Batch F1: 0.888888888888889
Epoch:  892        5 Batch loss: 0.091781 Batch F1: 0.9090909090909091
Epoch:  892        6 Batch loss: 0.063069 Batch F1: 0.9333333333333333
Epoch:  892        7 Batch loss: 0.065526 Batch F1: 1.0
Epoch:  892        8 Batch loss: 0.060809 Batch F1: 0.9333333333333333
Epoch:  892        9 Batch loss: 0.055750 Batch F1: 1.0
Epoch:  892       10 Batch loss: 0.057522 Batch F1: 0.9090909090909091
Epoch:  892       11 Batch loss: 0.051026 Batch F1: 0.0
Epoch:  892       12 Batch loss: 0.056641 Batch F1: 0.6
Train Avg Loss  892: 0.067176

Train Avg F1  892: 0.8174613631135369

Val Avg Loss  892: 0.064627

Val Avg F1  892:  0.5949754901960784

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 893
--------------------------------------------------------------
Epoch:  893        1 Batch loss: 0.075997 Batch F1: 0.5714285714285715
Epoch:  893        2 Batch loss: 0.065989 Batch F1: 0.6153846153846153
Epoch:  893        3 Batch loss: 0.070337 Batch F1: 0.3636363636363636
Epoch:  893        4 Batch loss: 0.077168 Batch F1: 0.19999999999999998
Epoch:  893        5 Batch loss: 0.047118 Batch F1: 0.33333333333333337
Epoch:  893        6 Batch loss: 0.090667 Batch F1: 0.6956521739130436
Epoch:  893        7 Batch loss: 0.062794 Batch F1: 0.923076923076923
Epoch:  893        8 Batch loss: 0.052262 Batch F1: 0.923076923076923
Epoch:  893        9 Batch loss: 0.075783 Batch F1: 1.0
Epoch:  893       10 Batch loss: 0.065218 Batch F1: 0.9473684210526316
Epoch:  893       11 Batch loss: 0.067855 Batch F1: 0.9
Epoch:  893       12 Batch loss: 0.073323 Batch F1: 0.923076923076923
Train Avg Loss  893: 0.068709

Train Avg F1  893: 0.699669520664944

Val Avg Loss  893: 0.061076

Val Avg F1  893:  0.9350490196078431

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 894
--------------------------------------------------------------
Epoch:  894        1 Batch loss: 0.054678 Batch F1: 0.9473684210526316
Epoch:  894        2 Batch loss: 0.066846 Batch F1: 1.0
Epoch:  894        3 Batch loss: 0.054319 Batch F1: 0.8
Epoch:  894        4 Batch loss: 0.074154 Batch F1: 0.0
Epoch:  894        5 Batch loss: 0.074982 Batch F1: 0.42857142857142855
Epoch:  894        6 Batch loss: 0.064852 Batch F1: 0.5
Epoch:  894        7 Batch loss: 0.055425 Batch F1: 0.6
Epoch:  894        8 Batch loss: 0.074517 Batch F1: 0.4615384615384615
Epoch:  894        9 Batch loss: 0.065307 Batch F1: 0.9333333333333333
Epoch:  894       10 Batch loss: 0.069112 Batch F1: 0.6666666666666666
Epoch:  894       11 Batch loss: 0.082272 Batch F1: 0.9090909090909091
Epoch:  894       12 Batch loss: 0.069751 Batch F1: 0.9411764705882353
Train Avg Loss  894: 0.067185

Train Avg F1  894: 0.6823121409034721

Val Avg Loss  894: 0.061306

Val Avg F1  894:  0.932852564102564

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 895
--------------------------------------------------------------
Epoch:  895        1 Batch loss: 0.079605 Batch F1: 0.7777777777777778
Epoch:  895        2 Batch loss: 0.077834 Batch F1: 0.9090909090909091
Epoch:  895        3 Batch loss: 0.067860 Batch F1: 1.0
Epoch:  895        4 Batch loss: 0.069705 Batch F1: 0.8750000000000001
Epoch:  895        5 Batch loss: 0.070940 Batch F1: 0.9565217391304348
Epoch:  895        6 Batch loss: 0.073226 Batch F1: 0.9411764705882353
Epoch:  895        7 Batch loss: 0.058308 Batch F1: 0.888888888888889
Epoch:  895        8 Batch loss: 0.081922 Batch F1: 0.9600000000000001
Epoch:  895        9 Batch loss: 0.065564 Batch F1: 0.9
Epoch:  895       10 Batch loss: 0.059678 Batch F1: 1.0
Epoch:  895       11 Batch loss: 0.055570 Batch F1: 0.923076923076923
Epoch:  895       12 Batch loss: 0.043730 Batch F1: 0.6666666666666666
Train Avg Loss  895: 0.066995

Train Avg F1  895: 0.8998499479349863

Val Avg Loss  895: 0.062559

Val Avg F1  895:  0.587004662004662

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 896
--------------------------------------------------------------
Epoch:  896        1 Batch loss: 0.074668 Batch F1: 0.625
Epoch:  896        2 Batch loss: 0.059753 Batch F1: 0.7058823529411764
Epoch:  896        3 Batch loss: 0.075630 Batch F1: 0.42857142857142855
Epoch:  896        4 Batch loss: 0.060318 Batch F1: 0.5
Epoch:  896        5 Batch loss: 0.069884 Batch F1: 0.42857142857142855
Epoch:  896        6 Batch loss: 0.072989 Batch F1: 0.5333333333333333
Epoch:  896        7 Batch loss: 0.073861 Batch F1: 0.8750000000000001
Epoch:  896        8 Batch loss: 0.059152 Batch F1: 0.8571428571428571
Epoch:  896        9 Batch loss: 0.049884 Batch F1: 1.0
Epoch:  896       10 Batch loss: 0.068225 Batch F1: 0.923076923076923
Epoch:  896       11 Batch loss: 0.071487 Batch F1: 0.8571428571428571
Epoch:  896       12 Batch loss: 0.083784 Batch F1: 0.8235294117647058
Train Avg Loss  896: 0.068303

Train Avg F1  896: 0.7131042160453925

Val Avg Loss  896: 0.060961

Val Avg F1  896:  0.9218020541549953

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 897
--------------------------------------------------------------
Epoch:  897        1 Batch loss: 0.059796 Batch F1: 1.0
Epoch:  897        2 Batch loss: 0.075856 Batch F1: 0.8750000000000001
Epoch:  897        3 Batch loss: 0.057677 Batch F1: 1.0
Epoch:  897        4 Batch loss: 0.048350 Batch F1: 0.9090909090909091
Epoch:  897        5 Batch loss: 0.048377 Batch F1: 1.0
Epoch:  897        6 Batch loss: 0.061071 Batch F1: 0.8571428571428571
Epoch:  897        7 Batch loss: 0.075678 Batch F1: 0.5333333333333333
Epoch:  897        8 Batch loss: 0.058032 Batch F1: 0.5454545454545454
Epoch:  897        9 Batch loss: 0.095010 Batch F1: 0.5263157894736842
Epoch:  897       10 Batch loss: 0.055702 Batch F1: 0.25
Epoch:  897       11 Batch loss: 0.082604 Batch F1: 0.5
Epoch:  897       12 Batch loss: 0.095420 Batch F1: 0.7777777777777778
Train Avg Loss  897: 0.067798

Train Avg F1  897: 0.7311762676894255

Val Avg Loss  897: 0.061439

Val Avg F1  897:  0.9232034412955465

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 898
--------------------------------------------------------------
Epoch:  898        1 Batch loss: 0.065886 Batch F1: 1.0
Epoch:  898        2 Batch loss: 0.075159 Batch F1: 0.9523809523809523
Epoch:  898        3 Batch loss: 0.077805 Batch F1: 0.6666666666666666
Epoch:  898        4 Batch loss: 0.057950 Batch F1: 0.9333333333333333
Epoch:  898        5 Batch loss: 0.064454 Batch F1: 0.9333333333333333
Epoch:  898        6 Batch loss: 0.080774 Batch F1: 0.9523809523809523
Epoch:  898        7 Batch loss: 0.050228 Batch F1: 0.888888888888889
Epoch:  898        8 Batch loss: 0.041671 Batch F1: 1.0
Epoch:  898        9 Batch loss: 0.069268 Batch F1: 0.8
Epoch:  898       10 Batch loss: 0.069422 Batch F1: 0.0
Epoch:  898       11 Batch loss: 0.096863 Batch F1: 0.6153846153846153
Epoch:  898       12 Batch loss: 0.076831 Batch F1: 0.6153846153846153
Train Avg Loss  898: 0.068859

Train Avg F1  898: 0.7798127798127799

Val Avg Loss  898: 0.062075

Val Avg F1  898:  0.5591346153846154

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 899
--------------------------------------------------------------
Epoch:  899        1 Batch loss: 0.092542 Batch F1: 0.2666666666666667
Epoch:  899        2 Batch loss: 0.066989 Batch F1: 0.8
Epoch:  899        3 Batch loss: 0.052441 Batch F1: 0.923076923076923
Epoch:  899        4 Batch loss: 0.063071 Batch F1: 0.8333333333333333
Epoch:  899        5 Batch loss: 0.055802 Batch F1: 0.888888888888889
Epoch:  899        6 Batch loss: 0.078000 Batch F1: 1.0
Epoch:  899        7 Batch loss: 0.074080 Batch F1: 1.0
Epoch:  899        8 Batch loss: 0.084057 Batch F1: 0.4
Epoch:  899        9 Batch loss: 0.080533 Batch F1: 0.42857142857142855
Epoch:  899       10 Batch loss: 0.045503 Batch F1: 0.7272727272727273
Epoch:  899       11 Batch loss: 0.062912 Batch F1: 0.7692307692307693
Epoch:  899       12 Batch loss: 0.070706 Batch F1: 0.5
Train Avg Loss  899: 0.068886

Train Avg F1  899: 0.7114200614200614

Val Avg Loss  899: 0.061878

Val Avg F1  899:  0.5456349206349207

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 900
--------------------------------------------------------------
Epoch:  900        1 Batch loss: 0.078359 Batch F1: 0.42857142857142855
Epoch:  900        2 Batch loss: 0.075557 Batch F1: 0.42857142857142855
Epoch:  900        3 Batch loss: 0.056313 Batch F1: 0.923076923076923
Epoch:  900        4 Batch loss: 0.072826 Batch F1: 0.9565217391304348
Epoch:  900        5 Batch loss: 0.059359 Batch F1: 0.923076923076923
Epoch:  900        6 Batch loss: 0.074368 Batch F1: 0.9333333333333333
Epoch:  900        7 Batch loss: 0.060737 Batch F1: 0.9411764705882353
Epoch:  900        8 Batch loss: 0.077086 Batch F1: 0.8
Epoch:  900        9 Batch loss: 0.074949 Batch F1: 0.9473684210526316
Epoch:  900       10 Batch loss: 0.067644 Batch F1: 0.9523809523809523
Epoch:  900       11 Batch loss: 0.053849 Batch F1: 0.888888888888889
Epoch:  900       12 Batch loss: 0.057743 Batch F1: 0.9333333333333333
Train Avg Loss  900: 0.067399

Train Avg F1  900: 0.8380249868337094

Val Avg Loss  900: 0.061238

Val Avg F1  900:  0.9340643274853802

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 901
--------------------------------------------------------------
Epoch:  901        1 Batch loss: 0.042236 Batch F1: 1.0
Epoch:  901        2 Batch loss: 0.076630 Batch F1: 0.761904761904762
Epoch:  901        3 Batch loss: 0.074202 Batch F1: 0.2857142857142857
Epoch:  901        4 Batch loss: 0.061624 Batch F1: 0.0
Epoch:  901        5 Batch loss: 0.060058 Batch F1: 0.6666666666666666
Epoch:  901        6 Batch loss: 0.085656 Batch F1: 0.5882352941176471
Epoch:  901        7 Batch loss: 0.060361 Batch F1: 0.4
Epoch:  901        8 Batch loss: 0.072217 Batch F1: 0.6153846153846153
Epoch:  901        9 Batch loss: 0.071798 Batch F1: 0.9166666666666666
Epoch:  901       10 Batch loss: 0.069897 Batch F1: 0.923076923076923
Epoch:  901       11 Batch loss: 0.084396 Batch F1: 0.9600000000000001
Epoch:  901       12 Batch loss: 0.056124 Batch F1: 0.923076923076923
Train Avg Loss  901: 0.067933

Train Avg F1  901: 0.6700605113840408

Val Avg Loss  901: 0.062455

Val Avg F1  901:  0.9229085865115276

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 902
--------------------------------------------------------------
Epoch:  902        1 Batch loss: 0.066782 Batch F1: 0.6666666666666666
Epoch:  902        2 Batch loss: 0.090310 Batch F1: 1.0
Epoch:  902        3 Batch loss: 0.070979 Batch F1: 0.9333333333333333
Epoch:  902        4 Batch loss: 0.056742 Batch F1: 1.0
Epoch:  902        5 Batch loss: 0.080798 Batch F1: 0.8421052631578948
Epoch:  902        6 Batch loss: 0.047946 Batch F1: 0.923076923076923
Epoch:  902        7 Batch loss: 0.078696 Batch F1: 0.9
Epoch:  902        8 Batch loss: 0.066116 Batch F1: 0.25
Epoch:  902        9 Batch loss: 0.058277 Batch F1: 0.4444444444444445
Epoch:  902       10 Batch loss: 0.061600 Batch F1: 0.4
Epoch:  902       11 Batch loss: 0.062632 Batch F1: 0.7058823529411764
Epoch:  902       12 Batch loss: 0.081768 Batch F1: 0.33333333333333337
Train Avg Loss  902: 0.068554

Train Avg F1  902: 0.6999035264128145

Val Avg Loss  902: 0.061734

Val Avg F1  902:  0.5380952380952381

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 903
--------------------------------------------------------------
Epoch:  903        1 Batch loss: 0.070619 Batch F1: 0.0
Epoch:  903        2 Batch loss: 0.075858 Batch F1: 0.8421052631578948
Epoch:  903        3 Batch loss: 0.067818 Batch F1: 0.9411764705882353
Epoch:  903        4 Batch loss: 0.080168 Batch F1: 0.9473684210526316
Epoch:  903        5 Batch loss: 0.047888 Batch F1: 1.0
Epoch:  903        6 Batch loss: 0.071988 Batch F1: 1.0
Epoch:  903        7 Batch loss: 0.070854 Batch F1: 0.8571428571428571
Epoch:  903        8 Batch loss: 0.077492 Batch F1: 0.8235294117647058
Epoch:  903        9 Batch loss: 0.070105 Batch F1: 0.7777777777777778
Epoch:  903       10 Batch loss: 0.066571 Batch F1: 0.9473684210526316
Epoch:  903       11 Batch loss: 0.059929 Batch F1: 0.923076923076923
Epoch:  903       12 Batch loss: 0.066753 Batch F1: 0.9411764705882353
Train Avg Loss  903: 0.068837

Train Avg F1  903: 0.8333935013501578

Val Avg Loss  903: 0.063451

Val Avg F1  903:  0.9347222222222222

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 904
--------------------------------------------------------------
Epoch:  904        1 Batch loss: 0.049622 Batch F1: 0.8
Epoch:  904        2 Batch loss: 0.077039 Batch F1: 0.8750000000000001
Epoch:  904        3 Batch loss: 0.058778 Batch F1: 0.7777777777777778
Epoch:  904        4 Batch loss: 0.073216 Batch F1: 0.888888888888889
Epoch:  904        5 Batch loss: 0.081582 Batch F1: 0.8421052631578948
Epoch:  904        6 Batch loss: 0.059309 Batch F1: 1.0
Epoch:  904        7 Batch loss: 0.054914 Batch F1: 0.923076923076923
Epoch:  904        8 Batch loss: 0.078514 Batch F1: 1.0
Epoch:  904        9 Batch loss: 0.066619 Batch F1: 0.8750000000000001
Epoch:  904       10 Batch loss: 0.073827 Batch F1: 0.9
Epoch:  904       11 Batch loss: 0.072626 Batch F1: 0.8750000000000001
Epoch:  904       12 Batch loss: 0.073719 Batch F1: 1.0
Train Avg Loss  904: 0.068314

Train Avg F1  904: 0.8964040710751237

Val Avg Loss  904: 0.061077

Val Avg F1  904:  0.9290441176470589

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 905
--------------------------------------------------------------
Epoch:  905        1 Batch loss: 0.060938 Batch F1: 0.9090909090909091
Epoch:  905        2 Batch loss: 0.069798 Batch F1: 0.9565217391304348
Epoch:  905        3 Batch loss: 0.047709 Batch F1: 1.0
Epoch:  905        4 Batch loss: 0.068724 Batch F1: 0.8571428571428571
Epoch:  905        5 Batch loss: 0.088543 Batch F1: 0.5714285714285715
Epoch:  905        6 Batch loss: 0.084948 Batch F1: 0.6666666666666666
Epoch:  905        7 Batch loss: 0.061749 Batch F1: 0.8571428571428571
Epoch:  905        8 Batch loss: 0.076195 Batch F1: 0.923076923076923
Epoch:  905        9 Batch loss: 0.067251 Batch F1: 0.9333333333333333
Epoch:  905       10 Batch loss: 0.073019 Batch F1: 1.0
Epoch:  905       11 Batch loss: 0.064324 Batch F1: 0.888888888888889
Epoch:  905       12 Batch loss: 0.054395 Batch F1: 0.888888888888889
Train Avg Loss  905: 0.068133

Train Avg F1  905: 0.8710151362325277

Val Avg Loss  905: 0.062733

Val Avg F1  905:  0.9261904761904762

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 906
--------------------------------------------------------------
Epoch:  906        1 Batch loss: 0.066519 Batch F1: 0.9411764705882353
Epoch:  906        2 Batch loss: 0.057959 Batch F1: 0.7692307692307693
Epoch:  906        3 Batch loss: 0.092200 Batch F1: 0.47058823529411764
Epoch:  906        4 Batch loss: 0.057725 Batch F1: 0.9333333333333333
Epoch:  906        5 Batch loss: 0.061323 Batch F1: 0.6
Epoch:  906        6 Batch loss: 0.055051 Batch F1: 0.33333333333333337
Epoch:  906        7 Batch loss: 0.079275 Batch F1: 0.4615384615384615
Epoch:  906        8 Batch loss: 0.097685 Batch F1: 0.7499999999999999
Epoch:  906        9 Batch loss: 0.066118 Batch F1: 0.6666666666666666
Epoch:  906       10 Batch loss: 0.061682 Batch F1: 0.5
Epoch:  906       11 Batch loss: 0.077994 Batch F1: 0.5
Epoch:  906       12 Batch loss: 0.071739 Batch F1: 0.7692307692307693
Train Avg Loss  906: 0.070439

Train Avg F1  906: 0.6412581699346406

Val Avg Loss  906: 0.067631

Val Avg F1  906:  0.6555978504254366

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 907
--------------------------------------------------------------
Epoch:  907        1 Batch loss: 0.085824 Batch F1: 0.7058823529411764
Epoch:  907        2 Batch loss: 0.069455 Batch F1: 0.5
Epoch:  907        3 Batch loss: 0.070009 Batch F1: 0.8235294117647058
Epoch:  907        4 Batch loss: 0.072137 Batch F1: 0.8571428571428571
Epoch:  907        5 Batch loss: 0.070468 Batch F1: 0.9523809523809523
Epoch:  907        6 Batch loss: 0.070466 Batch F1: 1.0
Epoch:  907        7 Batch loss: 0.071441 Batch F1: 0.7777777777777778
Epoch:  907        8 Batch loss: 0.082607 Batch F1: 0.3076923076923077
Epoch:  907        9 Batch loss: 0.070443 Batch F1: 0.5714285714285715
Epoch:  907       10 Batch loss: 0.037758 Batch F1: 0.8
Epoch:  907       11 Batch loss: 0.064838 Batch F1: 0.2222222222222222
Epoch:  907       12 Batch loss: 0.091410 Batch F1: 0.3636363636363636
Train Avg Loss  907: 0.071405

Train Avg F1  907: 0.6568077347489111

Val Avg Loss  907: 0.064185

Val Avg F1  907:  0.5910256410256409

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 908
--------------------------------------------------------------
Epoch:  908        1 Batch loss: 0.073732 Batch F1: 0.4
Epoch:  908        2 Batch loss: 0.072044 Batch F1: 0.5
Epoch:  908        3 Batch loss: 0.070190 Batch F1: 0.0
Epoch:  908        4 Batch loss: 0.068499 Batch F1: 1.0
Epoch:  908        5 Batch loss: 0.060181 Batch F1: 0.9333333333333333
Epoch:  908        6 Batch loss: 0.063406 Batch F1: 0.6666666666666666
Epoch:  908        7 Batch loss: 0.072664 Batch F1: 0.7058823529411764
Epoch:  908        8 Batch loss: 0.075426 Batch F1: 0.8421052631578948
Epoch:  908        9 Batch loss: 0.074410 Batch F1: 0.9166666666666666
Epoch:  908       10 Batch loss: 0.076591 Batch F1: 0.7272727272727273
Epoch:  908       11 Batch loss: 0.061297 Batch F1: 1.0
Epoch:  908       12 Batch loss: 0.066247 Batch F1: 0.9411764705882353
Train Avg Loss  908: 0.069557

Train Avg F1  908: 0.719425290052225

Val Avg Loss  908: 0.062268

Val Avg F1  908:  0.8983333333333334

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 909
--------------------------------------------------------------
Epoch:  909        1 Batch loss: 0.058888 Batch F1: 1.0
Epoch:  909        2 Batch loss: 0.053356 Batch F1: 0.2857142857142857
Epoch:  909        3 Batch loss: 0.082180 Batch F1: 0.625
Epoch:  909        4 Batch loss: 0.078610 Batch F1: 0.5333333333333333
Epoch:  909        5 Batch loss: 0.058315 Batch F1: 0.2857142857142857
Epoch:  909        6 Batch loss: 0.063048 Batch F1: 0.4
Epoch:  909        7 Batch loss: 0.069179 Batch F1: 0.0
Epoch:  909        8 Batch loss: 0.049960 Batch F1: 0.7499999999999999
Epoch:  909        9 Batch loss: 0.078913 Batch F1: 0.5714285714285715
Epoch:  909       10 Batch loss: 0.076369 Batch F1: 0.7368421052631579
Epoch:  909       11 Batch loss: 0.086411 Batch F1: 0.9565217391304348
Epoch:  909       12 Batch loss: 0.080585 Batch F1: 0.888888888888889
Train Avg Loss  909: 0.069651

Train Avg F1  909: 0.5861202674560798

Val Avg Loss  909: 0.062190

Val Avg F1  909:  0.937566844919786

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 910
--------------------------------------------------------------
Epoch:  910        1 Batch loss: 0.060933 Batch F1: 1.0
Epoch:  910        2 Batch loss: 0.060445 Batch F1: 1.0
Epoch:  910        3 Batch loss: 0.075523 Batch F1: 0.7777777777777778
Epoch:  910        4 Batch loss: 0.093759 Batch F1: 0.7058823529411764
Epoch:  910        5 Batch loss: 0.060972 Batch F1: 0.5
Epoch:  910        6 Batch loss: 0.065491 Batch F1: 0.9565217391304348
Epoch:  910        7 Batch loss: 0.080117 Batch F1: 0.9600000000000001
Epoch:  910        8 Batch loss: 0.073335 Batch F1: 0.888888888888889
Epoch:  910        9 Batch loss: 0.084002 Batch F1: 0.8571428571428571
Epoch:  910       10 Batch loss: 0.054999 Batch F1: 1.0
Epoch:  910       11 Batch loss: 0.069021 Batch F1: 0.8333333333333333
Epoch:  910       12 Batch loss: 0.067752 Batch F1: 0.9333333333333333
Train Avg Loss  910: 0.070529

Train Avg F1  910: 0.8677400235456502

Val Avg Loss  910: 0.063212

Val Avg F1  910:  0.74375

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 911
--------------------------------------------------------------
Epoch:  911        1 Batch loss: 0.070276 Batch F1: 0.7777777777777778
Epoch:  911        2 Batch loss: 0.077616 Batch F1: 0.9523809523809523
Epoch:  911        3 Batch loss: 0.054283 Batch F1: 0.9333333333333333
Epoch:  911        4 Batch loss: 0.074982 Batch F1: 0.8750000000000001
Epoch:  911        5 Batch loss: 0.059546 Batch F1: 0.7499999999999999
Epoch:  911        6 Batch loss: 0.104562 Batch F1: 0.846153846153846
Epoch:  911        7 Batch loss: 0.049611 Batch F1: 0.923076923076923
Epoch:  911        8 Batch loss: 0.048069 Batch F1: 1.0
Epoch:  911        9 Batch loss: 0.085085 Batch F1: 0.8421052631578948
Epoch:  911       10 Batch loss: 0.078482 Batch F1: 0.9600000000000001
Epoch:  911       11 Batch loss: 0.053490 Batch F1: 1.0
Epoch:  911       12 Batch loss: 0.073110 Batch F1: 1.0
Train Avg Loss  911: 0.069093

Train Avg F1  911: 0.9049856746567273

Val Avg Loss  911: 0.061604

Val Avg F1  911:  0.9232954545454546

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 912
--------------------------------------------------------------
Epoch:  912        1 Batch loss: 0.071910 Batch F1: 0.9565217391304348
Epoch:  912        2 Batch loss: 0.084367 Batch F1: 0.9166666666666666
Epoch:  912        3 Batch loss: 0.064073 Batch F1: 0.8750000000000001
Epoch:  912        4 Batch loss: 0.072980 Batch F1: 0.9523809523809523
Epoch:  912        5 Batch loss: 0.070501 Batch F1: 1.0
Epoch:  912        6 Batch loss: 0.054975 Batch F1: 0.9090909090909091
Epoch:  912        7 Batch loss: 0.056200 Batch F1: 0.5454545454545454
Epoch:  912        8 Batch loss: 0.054586 Batch F1: 0.5
Epoch:  912        9 Batch loss: 0.065269 Batch F1: 0.25
Epoch:  912       10 Batch loss: 0.090818 Batch F1: 0.631578947368421
Epoch:  912       11 Batch loss: 0.065424 Batch F1: 0.4444444444444445
Epoch:  912       12 Batch loss: 0.081242 Batch F1: 0.4
Train Avg Loss  912: 0.069362

Train Avg F1  912: 0.6984281837113646

Val Avg Loss  912: 0.062706

Val Avg F1  912:  0.9266694090223502

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 913
--------------------------------------------------------------
Epoch:  913        1 Batch loss: 0.070592 Batch F1: 0.7272727272727273
Epoch:  913        2 Batch loss: 0.047935 Batch F1: 1.0
Epoch:  913        3 Batch loss: 0.073200 Batch F1: 0.7692307692307693
Epoch:  913        4 Batch loss: 0.073639 Batch F1: 0.8750000000000001
Epoch:  913        5 Batch loss: 0.080810 Batch F1: 0.9
Epoch:  913        6 Batch loss: 0.078257 Batch F1: 0.9565217391304348
Epoch:  913        7 Batch loss: 0.060143 Batch F1: 0.888888888888889
Epoch:  913        8 Batch loss: 0.065393 Batch F1: 1.0
Epoch:  913        9 Batch loss: 0.056081 Batch F1: 1.0
Epoch:  913       10 Batch loss: 0.068878 Batch F1: 0.5
Epoch:  913       11 Batch loss: 0.101013 Batch F1: 0.5454545454545454
Epoch:  913       12 Batch loss: 0.060528 Batch F1: 0.7692307692307693
Train Avg Loss  913: 0.069706

Train Avg F1  913: 0.827633286600678

Val Avg Loss  913: 0.063542

Val Avg F1  913:  0.5911588411588411

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 914
--------------------------------------------------------------
Epoch:  914        1 Batch loss: 0.089328 Batch F1: 0.5
Epoch:  914        2 Batch loss: 0.069106 Batch F1: 0.923076923076923
Epoch:  914        3 Batch loss: 0.073148 Batch F1: 1.0
Epoch:  914        4 Batch loss: 0.060994 Batch F1: 0.7499999999999999
Epoch:  914        5 Batch loss: 0.072587 Batch F1: 0.9
Epoch:  914        6 Batch loss: 0.062775 Batch F1: 0.8333333333333333
Epoch:  914        7 Batch loss: 0.062685 Batch F1: 0.8
Epoch:  914        8 Batch loss: 0.070215 Batch F1: 0.5
Epoch:  914        9 Batch loss: 0.056154 Batch F1: 0.6
Epoch:  914       10 Batch loss: 0.067395 Batch F1: 0.625
Epoch:  914       11 Batch loss: 0.079152 Batch F1: 0.888888888888889
Epoch:  914       12 Batch loss: 0.072317 Batch F1: 0.888888888888889
Train Avg Loss  914: 0.069655

Train Avg F1  914: 0.7674323361823361

Val Avg Loss  914: 0.062854

Val Avg F1  914:  0.9302641802641802

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 915
--------------------------------------------------------------
Epoch:  915        1 Batch loss: 0.069269 Batch F1: 1.0
Epoch:  915        2 Batch loss: 0.073672 Batch F1: 0.8
Epoch:  915        3 Batch loss: 0.059244 Batch F1: 1.0
Epoch:  915        4 Batch loss: 0.081453 Batch F1: 0.631578947368421
Epoch:  915        5 Batch loss: 0.068831 Batch F1: 0.9473684210526316
Epoch:  915        6 Batch loss: 0.062652 Batch F1: 1.0
Epoch:  915        7 Batch loss: 0.087109 Batch F1: 0.7142857142857143
Epoch:  915        8 Batch loss: 0.069224 Batch F1: 0.9411764705882353
Epoch:  915        9 Batch loss: 0.069912 Batch F1: 0.8750000000000001
Epoch:  915       10 Batch loss: 0.059007 Batch F1: 0.8
Epoch:  915       11 Batch loss: 0.074435 Batch F1: 0.888888888888889
Epoch:  915       12 Batch loss: 0.046800 Batch F1: 1.0
Train Avg Loss  915: 0.068467

Train Avg F1  915: 0.8831915368486577

Val Avg Loss  915: 0.062430

Val Avg F1  915:  0.7177690730322309

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 916
--------------------------------------------------------------
Epoch:  916        1 Batch loss: 0.067022 Batch F1: 0.7499999999999999
Epoch:  916        2 Batch loss: 0.038839 Batch F1: 0.8
Epoch:  916        3 Batch loss: 0.060952 Batch F1: 0.5
Epoch:  916        4 Batch loss: 0.067292 Batch F1: 0.7142857142857143
Epoch:  916        5 Batch loss: 0.061016 Batch F1: 0.9090909090909091
Epoch:  916        6 Batch loss: 0.057682 Batch F1: 0.7142857142857143
Epoch:  916        7 Batch loss: 0.105502 Batch F1: 0.47619047619047616
Epoch:  916        8 Batch loss: 0.079907 Batch F1: 0.42857142857142855
Epoch:  916        9 Batch loss: 0.058532 Batch F1: 0.888888888888889
Epoch:  916       10 Batch loss: 0.082173 Batch F1: 0.8421052631578948
Epoch:  916       11 Batch loss: 0.079398 Batch F1: 0.8421052631578948
Epoch:  916       12 Batch loss: 0.058590 Batch F1: 0.888888888888889
Train Avg Loss  916: 0.068075

Train Avg F1  916: 0.7295343788764842

Val Avg Loss  916: 0.061306

Val Avg F1  916:  0.9220647773279352

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 917
--------------------------------------------------------------
Epoch:  917        1 Batch loss: 0.060277 Batch F1: 1.0
Epoch:  917        2 Batch loss: 0.070413 Batch F1: 0.888888888888889
Epoch:  917        3 Batch loss: 0.055101 Batch F1: 0.7499999999999999
Epoch:  917        4 Batch loss: 0.051552 Batch F1: 1.0
Epoch:  917        5 Batch loss: 0.100314 Batch F1: 0.5714285714285715
Epoch:  917        6 Batch loss: 0.035169 Batch F1: 1.0
Epoch:  917        7 Batch loss: 0.059333 Batch F1: 0.9333333333333333
Epoch:  917        8 Batch loss: 0.076159 Batch F1: 0.9523809523809523
Epoch:  917        9 Batch loss: 0.066083 Batch F1: 0.9333333333333333
Epoch:  917       10 Batch loss: 0.067251 Batch F1: 0.7272727272727273
Epoch:  917       11 Batch loss: 0.075342 Batch F1: 0.9411764705882353
Epoch:  917       12 Batch loss: 0.101718 Batch F1: 0.967741935483871
Train Avg Loss  917: 0.068226

Train Avg F1  917: 0.8887963510591593

Val Avg Loss  917: 0.061052

Val Avg F1  917:  0.9297385620915033

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 918
--------------------------------------------------------------
Epoch:  918        1 Batch loss: 0.070658 Batch F1: 0.9523809523809523
Epoch:  918        2 Batch loss: 0.077247 Batch F1: 0.6666666666666666
Epoch:  918        3 Batch loss: 0.071347 Batch F1: 0.9473684210526316
Epoch:  918        4 Batch loss: 0.055452 Batch F1: 0.8571428571428571
Epoch:  918        5 Batch loss: 0.079572 Batch F1: 1.0
Epoch:  918        6 Batch loss: 0.069963 Batch F1: 0.9565217391304348
Epoch:  918        7 Batch loss: 0.068264 Batch F1: 0.9473684210526316
Epoch:  918        8 Batch loss: 0.061926 Batch F1: 0.888888888888889
Epoch:  918        9 Batch loss: 0.063522 Batch F1: 1.0
Epoch:  918       10 Batch loss: 0.060658 Batch F1: 0.9333333333333333
Epoch:  918       11 Batch loss: 0.075652 Batch F1: 0.8235294117647058
Epoch:  918       12 Batch loss: 0.055407 Batch F1: 0.6666666666666666
Train Avg Loss  918: 0.067473

Train Avg F1  918: 0.8866556131733142

Val Avg Loss  918: 0.062875

Val Avg F1  918:  0.541971916971917

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 919
--------------------------------------------------------------
Epoch:  919        1 Batch loss: 0.087619 Batch F1: 0.33333333333333337
Epoch:  919        2 Batch loss: 0.066816 Batch F1: 0.4
Epoch:  919        3 Batch loss: 0.063348 Batch F1: 0.6666666666666666
Epoch:  919        4 Batch loss: 0.067896 Batch F1: 0.6153846153846153
Epoch:  919        5 Batch loss: 0.059393 Batch F1: 0.6153846153846153
Epoch:  919        6 Batch loss: 0.079290 Batch F1: 0.0
Epoch:  919        7 Batch loss: 0.059394 Batch F1: 0.6153846153846153
Epoch:  919        8 Batch loss: 0.068279 Batch F1: 0.33333333333333337
Epoch:  919        9 Batch loss: 0.047692 Batch F1: 1.0
Epoch:  919       10 Batch loss: 0.065417 Batch F1: 0.7368421052631579
Epoch:  919       11 Batch loss: 0.076423 Batch F1: 0.42857142857142855
Epoch:  919       12 Batch loss: 0.073444 Batch F1: 0.9473684210526316
Train Avg Loss  919: 0.067918

Train Avg F1  919: 0.5576890945311997

Val Avg Loss  919: 0.060937

Val Avg F1  919:  0.92421955624355

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 920
--------------------------------------------------------------
Epoch:  920        1 Batch loss: 0.052791 Batch F1: 1.0
Epoch:  920        2 Batch loss: 0.059906 Batch F1: 1.0
Epoch:  920        3 Batch loss: 0.076988 Batch F1: 1.0
Epoch:  920        4 Batch loss: 0.075034 Batch F1: 0.8235294117647058
Epoch:  920        5 Batch loss: 0.066583 Batch F1: 0.9
Epoch:  920        6 Batch loss: 0.084699 Batch F1: 0.8695652173913044
Epoch:  920        7 Batch loss: 0.061831 Batch F1: 0.8571428571428571
Epoch:  920        8 Batch loss: 0.059486 Batch F1: 1.0
Epoch:  920        9 Batch loss: 0.057420 Batch F1: 0.923076923076923
Epoch:  920       10 Batch loss: 0.068617 Batch F1: 0.888888888888889
Epoch:  920       11 Batch loss: 0.070890 Batch F1: 0.8333333333333333
Epoch:  920       12 Batch loss: 0.070654 Batch F1: 0.923076923076923
Train Avg Loss  920: 0.067075

Train Avg F1  920: 0.9182177962229114

Val Avg Loss  920: 0.060598

Val Avg F1  920:  0.9152426520847573

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 921
--------------------------------------------------------------
Epoch:  921        1 Batch loss: 0.057306 Batch F1: 0.8333333333333333
Epoch:  921        2 Batch loss: 0.083774 Batch F1: 0.8235294117647058
Epoch:  921        3 Batch loss: 0.058405 Batch F1: 1.0
Epoch:  921        4 Batch loss: 0.071794 Batch F1: 0.9600000000000001
Epoch:  921        5 Batch loss: 0.050196 Batch F1: 1.0
Epoch:  921        6 Batch loss: 0.065704 Batch F1: 1.0
Epoch:  921        7 Batch loss: 0.084397 Batch F1: 0.8421052631578948
Epoch:  921        8 Batch loss: 0.064620 Batch F1: 1.0
Epoch:  921        9 Batch loss: 0.067918 Batch F1: 0.9473684210526316
Epoch:  921       10 Batch loss: 0.061798 Batch F1: 0.9090909090909091
Epoch:  921       11 Batch loss: 0.084055 Batch F1: 0.7777777777777778
Epoch:  921       12 Batch loss: 0.052948 Batch F1: 0.8333333333333333
Train Avg Loss  921: 0.066910

Train Avg F1  921: 0.9105448707925489

Val Avg Loss  921: 0.061373

Val Avg F1  921:  0.9290441176470587

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 922
--------------------------------------------------------------
Epoch:  922        1 Batch loss: 0.084280 Batch F1: 0.9714285714285714
Epoch:  922        2 Batch loss: 0.072720 Batch F1: 1.0
Epoch:  922        3 Batch loss: 0.080034 Batch F1: 0.8421052631578948
Epoch:  922        4 Batch loss: 0.079760 Batch F1: 0.8571428571428571
Epoch:  922        5 Batch loss: 0.071026 Batch F1: 0.8333333333333333
Epoch:  922        6 Batch loss: 0.058986 Batch F1: 1.0
Epoch:  922        7 Batch loss: 0.054919 Batch F1: 1.0
Epoch:  922        8 Batch loss: 0.072595 Batch F1: 0.9411764705882353
Epoch:  922        9 Batch loss: 0.054834 Batch F1: 0.2857142857142857
Epoch:  922       10 Batch loss: 0.052092 Batch F1: 0.33333333333333337
Epoch:  922       11 Batch loss: 0.043403 Batch F1: 0.7499999999999999
Epoch:  922       12 Batch loss: 0.092296 Batch F1: 0.3636363636363636
Train Avg Loss  922: 0.068079

Train Avg F1  922: 0.7648225398612395

Val Avg Loss  922: 0.062867

Val Avg F1  922:  0.5925324675324676

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 923
--------------------------------------------------------------
Epoch:  923        1 Batch loss: 0.089526 Batch F1: 0.6086956521739131
Epoch:  923        2 Batch loss: 0.090680 Batch F1: 0.75
Epoch:  923        3 Batch loss: 0.066497 Batch F1: 0.6666666666666666
Epoch:  923        4 Batch loss: 0.061611 Batch F1: 0.2222222222222222
Epoch:  923        5 Batch loss: 0.058857 Batch F1: 0.4444444444444445
Epoch:  923        6 Batch loss: 0.117036 Batch F1: 0.5263157894736842
Epoch:  923        7 Batch loss: 0.064299 Batch F1: 0.9523809523809523
Epoch:  923        8 Batch loss: 0.078175 Batch F1: 0.7142857142857143
Epoch:  923        9 Batch loss: 0.062694 Batch F1: 0.5714285714285715
Epoch:  923       10 Batch loss: 0.095035 Batch F1: 0.5
Epoch:  923       11 Batch loss: 0.067247 Batch F1: 0.4
Epoch:  923       12 Batch loss: 0.053343 Batch F1: 0.0
Train Avg Loss  923: 0.075417

Train Avg F1  923: 0.5297033344230141

Val Avg Loss  923: 0.073122

Val Avg F1  923:  0.5701298701298702

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 924
--------------------------------------------------------------
Epoch:  924        1 Batch loss: 0.090145 Batch F1: 0.33333333333333337
Epoch:  924        2 Batch loss: 0.076195 Batch F1: 0.5714285714285715
Epoch:  924        3 Batch loss: 0.080369 Batch F1: 0.7368421052631579
Epoch:  924        4 Batch loss: 0.090684 Batch F1: 0.8333333333333333
Epoch:  924        5 Batch loss: 0.072392 Batch F1: 0.5333333333333333
Epoch:  924        6 Batch loss: 0.051217 Batch F1: 0.4
Epoch:  924        7 Batch loss: 0.109144 Batch F1: 0.0
Epoch:  924        8 Batch loss: 0.070874 Batch F1: 0.923076923076923
Epoch:  924        9 Batch loss: 0.056732 Batch F1: 0.923076923076923
Epoch:  924       10 Batch loss: 0.103897 Batch F1: 0.625
Epoch:  924       11 Batch loss: 0.058210 Batch F1: 0.7499999999999999
Epoch:  924       12 Batch loss: 0.112790 Batch F1: 0.3076923076923077
Train Avg Loss  924: 0.081054

Train Avg F1  924: 0.5780930692114902

Val Avg Loss  924: 0.084639

Val Avg F1  924:  0.7945532728141423

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 925
--------------------------------------------------------------
Epoch:  925        1 Batch loss: 0.093300 Batch F1: 0.8181818181818182
Epoch:  925        2 Batch loss: 0.124244 Batch F1: 0.14285714285714288
Epoch:  925        3 Batch loss: 0.071597 Batch F1: 0.8333333333333333
Epoch:  925        4 Batch loss: 0.087530 Batch F1: 0.3636363636363636
Epoch:  925        5 Batch loss: 0.080624 Batch F1: 0.6666666666666666
Epoch:  925        6 Batch loss: 0.075552 Batch F1: 0.7142857142857143
Epoch:  925        7 Batch loss: 0.090292 Batch F1: 0.6666666666666666
Epoch:  925        8 Batch loss: 0.059053 Batch F1: 0.7272727272727273
Epoch:  925        9 Batch loss: 0.064352 Batch F1: 0.25
Epoch:  925       10 Batch loss: 0.079435 Batch F1: 0.6666666666666666
Epoch:  925       11 Batch loss: 0.072120 Batch F1: 0.5333333333333333
Epoch:  925       12 Batch loss: 0.078732 Batch F1: 0.25
Train Avg Loss  925: 0.081403

Train Avg F1  925: 0.5527417027417028

Val Avg Loss  925: 0.065881

Val Avg F1  925:  0.7553571428571428

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 926
--------------------------------------------------------------
Epoch:  926        1 Batch loss: 0.069113 Batch F1: 0.6666666666666666
Epoch:  926        2 Batch loss: 0.075823 Batch F1: 0.33333333333333337
Epoch:  926        3 Batch loss: 0.079405 Batch F1: 0.5333333333333333
Epoch:  926        4 Batch loss: 0.057753 Batch F1: 1.0
Epoch:  926        5 Batch loss: 0.058262 Batch F1: 1.0
Epoch:  926        6 Batch loss: 0.080392 Batch F1: 0.8181818181818181
Epoch:  926        7 Batch loss: 0.081611 Batch F1: 1.0
Epoch:  926        8 Batch loss: 0.055567 Batch F1: 0.888888888888889
Epoch:  926        9 Batch loss: 0.070014 Batch F1: 0.8333333333333333
Epoch:  926       10 Batch loss: 0.076025 Batch F1: 0.8
Epoch:  926       11 Batch loss: 0.096510 Batch F1: 0.5882352941176471
Epoch:  926       12 Batch loss: 0.053977 Batch F1: 0.0
Train Avg Loss  926: 0.071204

Train Avg F1  926: 0.7051643889879183

Val Avg Loss  926: 0.065735

Val Avg F1  926:  0.5239130434782608

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 927
--------------------------------------------------------------
Epoch:  927        1 Batch loss: 0.064746 Batch F1: 0.25
Epoch:  927        2 Batch loss: 0.052905 Batch F1: 0.2857142857142857
Epoch:  927        3 Batch loss: 0.036562 Batch F1: 0.8571428571428571
Epoch:  927        4 Batch loss: 0.071035 Batch F1: 0.7499999999999999
Epoch:  927        5 Batch loss: 0.097349 Batch F1: 0.4
Epoch:  927        6 Batch loss: 0.059378 Batch F1: 0.7142857142857143
Epoch:  927        7 Batch loss: 0.053540 Batch F1: 0.7499999999999999
Epoch:  927        8 Batch loss: 0.057425 Batch F1: 0.6666666666666666
Epoch:  927        9 Batch loss: 0.082822 Batch F1: 0.5333333333333333
Epoch:  927       10 Batch loss: 0.099676 Batch F1: 0.23529411764705882
Epoch:  927       11 Batch loss: 0.078095 Batch F1: 0.9166666666666666
Epoch:  927       12 Batch loss: 0.086298 Batch F1: 1.0
Train Avg Loss  927: 0.069986

Train Avg F1  927: 0.6132586367880486

Val Avg Loss  927: 0.065428

Val Avg F1  927:  0.9176018099547512

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 928
--------------------------------------------------------------
Epoch:  928        1 Batch loss: 0.064807 Batch F1: 1.0
Epoch:  928        2 Batch loss: 0.075694 Batch F1: 0.8421052631578948
Epoch:  928        3 Batch loss: 0.070270 Batch F1: 0.9
Epoch:  928        4 Batch loss: 0.076475 Batch F1: 0.9333333333333333
Epoch:  928        5 Batch loss: 0.071691 Batch F1: 0.888888888888889
Epoch:  928        6 Batch loss: 0.056528 Batch F1: 0.6
Epoch:  928        7 Batch loss: 0.078010 Batch F1: 0.19999999999999998
Epoch:  928        8 Batch loss: 0.071001 Batch F1: 0.3636363636363636
Epoch:  928        9 Batch loss: 0.054108 Batch F1: 0.5
Epoch:  928       10 Batch loss: 0.063717 Batch F1: 0.6666666666666666
Epoch:  928       11 Batch loss: 0.067626 Batch F1: 0.3636363636363636
Epoch:  928       12 Batch loss: 0.088827 Batch F1: 0.42857142857142855
Train Avg Loss  928: 0.069896

Train Avg F1  928: 0.6405698589909116

Val Avg Loss  928: 0.062865

Val Avg F1  928:  0.8919607843137254

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 929
--------------------------------------------------------------
Epoch:  929        1 Batch loss: 0.051175 Batch F1: 1.0
Epoch:  929        2 Batch loss: 0.054584 Batch F1: 1.0
Epoch:  929        3 Batch loss: 0.053715 Batch F1: 1.0
Epoch:  929        4 Batch loss: 0.083628 Batch F1: 0.8421052631578948
Epoch:  929        5 Batch loss: 0.055920 Batch F1: 1.0
Epoch:  929        6 Batch loss: 0.055537 Batch F1: 1.0
Epoch:  929        7 Batch loss: 0.069855 Batch F1: 1.0
Epoch:  929        8 Batch loss: 0.091746 Batch F1: 0.8235294117647058
Epoch:  929        9 Batch loss: 0.068765 Batch F1: 0.8571428571428571
Epoch:  929       10 Batch loss: 0.098623 Batch F1: 0.7368421052631579
Epoch:  929       11 Batch loss: 0.086486 Batch F1: 0.8421052631578948
Epoch:  929       12 Batch loss: 0.074039 Batch F1: 1.0
Train Avg Loss  929: 0.070339

Train Avg F1  929: 0.9251437417072093

Val Avg Loss  929: 0.063263

Val Avg F1  929:  0.9375

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 930
--------------------------------------------------------------
Epoch:  930        1 Batch loss: 0.060573 Batch F1: 0.9523809523809523
Epoch:  930        2 Batch loss: 0.056063 Batch F1: 1.0
Epoch:  930        3 Batch loss: 0.066298 Batch F1: 1.0
Epoch:  930        4 Batch loss: 0.067543 Batch F1: 0.9333333333333333
Epoch:  930        5 Batch loss: 0.056258 Batch F1: 0.7272727272727273
Epoch:  930        6 Batch loss: 0.099032 Batch F1: 0.5
Epoch:  930        7 Batch loss: 0.076078 Batch F1: 0.5
Epoch:  930        8 Batch loss: 0.056292 Batch F1: 0.7142857142857143
Epoch:  930        9 Batch loss: 0.065891 Batch F1: 0.3636363636363636
Epoch:  930       10 Batch loss: 0.095063 Batch F1: 0.375
Epoch:  930       11 Batch loss: 0.071562 Batch F1: 0.3636363636363636
Epoch:  930       12 Batch loss: 0.071697 Batch F1: 0.8333333333333333
Train Avg Loss  930: 0.070196

Train Avg F1  930: 0.6885732323232324

Val Avg Loss  930: 0.063353

Val Avg F1  930:  0.9305921052631579

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 931
--------------------------------------------------------------
Epoch:  931        1 Batch loss: 0.060735 Batch F1: 0.9090909090909091
Epoch:  931        2 Batch loss: 0.072944 Batch F1: 0.6153846153846153
Epoch:  931        3 Batch loss: 0.076960 Batch F1: 0.42857142857142855
Epoch:  931        4 Batch loss: 0.070415 Batch F1: 0.7142857142857143
Epoch:  931        5 Batch loss: 0.078187 Batch F1: 1.0
Epoch:  931        6 Batch loss: 0.086970 Batch F1: 0.7368421052631579
Epoch:  931        7 Batch loss: 0.049827 Batch F1: 1.0
Epoch:  931        8 Batch loss: 0.064864 Batch F1: 1.0
Epoch:  931        9 Batch loss: 0.058059 Batch F1: 0.9090909090909091
Epoch:  931       10 Batch loss: 0.069269 Batch F1: 0.9333333333333333
Epoch:  931       11 Batch loss: 0.076776 Batch F1: 0.888888888888889
Epoch:  931       12 Batch loss: 0.071532 Batch F1: 0.4
Train Avg Loss  931: 0.069711

Train Avg F1  931: 0.7946239919924131

Val Avg Loss  931: 0.063058

Val Avg F1  931:  0.5773809523809524

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 932
--------------------------------------------------------------
Epoch:  932        1 Batch loss: 0.055190 Batch F1: 0.4444444444444445
Epoch:  932        2 Batch loss: 0.074222 Batch F1: 0.25
Epoch:  932        3 Batch loss: 0.088273 Batch F1: 0.0
Epoch:  932        4 Batch loss: 0.082407 Batch F1: 0.5714285714285715
Epoch:  932        5 Batch loss: 0.060239 Batch F1: 0.6
Epoch:  932        6 Batch loss: 0.080348 Batch F1: 0.6
Epoch:  932        7 Batch loss: 0.055791 Batch F1: 0.5454545454545454
Epoch:  932        8 Batch loss: 0.076769 Batch F1: 0.8571428571428571
Epoch:  932        9 Batch loss: 0.051995 Batch F1: 1.0
Epoch:  932       10 Batch loss: 0.063124 Batch F1: 1.0
Epoch:  932       11 Batch loss: 0.069369 Batch F1: 0.923076923076923
Epoch:  932       12 Batch loss: 0.083584 Batch F1: 0.8421052631578948
Train Avg Loss  932: 0.070109

Train Avg F1  932: 0.6361377170587698

Val Avg Loss  932: 0.063928

Val Avg F1  932:  0.5702380952380952

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 933
--------------------------------------------------------------
Epoch:  933        1 Batch loss: 0.065237 Batch F1: 0.5714285714285715
Epoch:  933        2 Batch loss: 0.060805 Batch F1: 0.6
Epoch:  933        3 Batch loss: 0.074564 Batch F1: 0.8
Epoch:  933        4 Batch loss: 0.060615 Batch F1: 0.9411764705882353
Epoch:  933        5 Batch loss: 0.069769 Batch F1: 0.9
Epoch:  933        6 Batch loss: 0.062969 Batch F1: 0.7499999999999999
Epoch:  933        7 Batch loss: 0.061521 Batch F1: 1.0
Epoch:  933        8 Batch loss: 0.102160 Batch F1: 0.8
Epoch:  933        9 Batch loss: 0.075549 Batch F1: 1.0
Epoch:  933       10 Batch loss: 0.066296 Batch F1: 1.0
Epoch:  933       11 Batch loss: 0.059379 Batch F1: 0.923076923076923
Epoch:  933       12 Batch loss: 0.058955 Batch F1: 0.923076923076923
Train Avg Loss  933: 0.068152

Train Avg F1  933: 0.8507299073475544

Val Avg Loss  933: 0.061691

Val Avg F1  933:  0.9327592697157915

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 934
--------------------------------------------------------------
Epoch:  934        1 Batch loss: 0.066287 Batch F1: 0.9473684210526316
Epoch:  934        2 Batch loss: 0.070645 Batch F1: 0.9473684210526316
Epoch:  934        3 Batch loss: 0.054785 Batch F1: 0.8571428571428571
Epoch:  934        4 Batch loss: 0.063187 Batch F1: 0.923076923076923
Epoch:  934        5 Batch loss: 0.042813 Batch F1: 0.8571428571428571
Epoch:  934        6 Batch loss: 0.067535 Batch F1: 0.6666666666666666
Epoch:  934        7 Batch loss: 0.115695 Batch F1: 0.25
Epoch:  934        8 Batch loss: 0.072007 Batch F1: 0.5
Epoch:  934        9 Batch loss: 0.062670 Batch F1: 1.0
Epoch:  934       10 Batch loss: 0.061254 Batch F1: 0.8333333333333333
Epoch:  934       11 Batch loss: 0.085513 Batch F1: 0.9285714285714286
Epoch:  934       12 Batch loss: 0.060455 Batch F1: 1.0
Train Avg Loss  934: 0.068570

Train Avg F1  934: 0.8092225756699442

Val Avg Loss  934: 0.062231

Val Avg F1  934:  0.9260577915376678

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 935
--------------------------------------------------------------
Epoch:  935        1 Batch loss: 0.066897 Batch F1: 1.0
Epoch:  935        2 Batch loss: 0.090591 Batch F1: 0.8571428571428571
Epoch:  935        3 Batch loss: 0.068772 Batch F1: 0.923076923076923
Epoch:  935        4 Batch loss: 0.064931 Batch F1: 0.9333333333333333
Epoch:  935        5 Batch loss: 0.069789 Batch F1: 0.8571428571428571
Epoch:  935        6 Batch loss: 0.059114 Batch F1: 0.7142857142857143
Epoch:  935        7 Batch loss: 0.079828 Batch F1: 0.3076923076923077
Epoch:  935        8 Batch loss: 0.081312 Batch F1: 0.15384615384615385
Epoch:  935        9 Batch loss: 0.070940 Batch F1: 1.0
Epoch:  935       10 Batch loss: 0.057626 Batch F1: 0.7272727272727273
Epoch:  935       11 Batch loss: 0.045921 Batch F1: 0.923076923076923
Epoch:  935       12 Batch loss: 0.075031 Batch F1: 0.9333333333333333
Train Avg Loss  935: 0.069229

Train Avg F1  935: 0.7775169275169276

Val Avg Loss  935: 0.062172

Val Avg F1  935:  0.936421937195931

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 936
--------------------------------------------------------------
Epoch:  936        1 Batch loss: 0.062445 Batch F1: 0.923076923076923
Epoch:  936        2 Batch loss: 0.062923 Batch F1: 1.0
Epoch:  936        3 Batch loss: 0.047602 Batch F1: 0.8333333333333333
Epoch:  936        4 Batch loss: 0.029338 Batch F1: 0.0
Epoch:  936        5 Batch loss: 0.100200 Batch F1: 0.375
Epoch:  936        6 Batch loss: 0.073249 Batch F1: 0.625
Epoch:  936        7 Batch loss: 0.072586 Batch F1: 0.5714285714285715
Epoch:  936        8 Batch loss: 0.086729 Batch F1: 0.631578947368421
Epoch:  936        9 Batch loss: 0.092149 Batch F1: 0.8421052631578948
Epoch:  936       10 Batch loss: 0.070215 Batch F1: 0.8571428571428571
Epoch:  936       11 Batch loss: 0.062594 Batch F1: 0.9565217391304348
Epoch:  936       12 Batch loss: 0.072136 Batch F1: 0.9090909090909091
Train Avg Loss  936: 0.069347

Train Avg F1  936: 0.7103565453107786

Val Avg Loss  936: 0.062447

Val Avg F1  936:  0.9207692307692307

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 937
--------------------------------------------------------------
Epoch:  937        1 Batch loss: 0.078311 Batch F1: 0.888888888888889
Epoch:  937        2 Batch loss: 0.058375 Batch F1: 0.9411764705882353
Epoch:  937        3 Batch loss: 0.067808 Batch F1: 0.923076923076923
Epoch:  937        4 Batch loss: 0.067098 Batch F1: 0.9333333333333333
Epoch:  937        5 Batch loss: 0.095403 Batch F1: 0.6956521739130436
Epoch:  937        6 Batch loss: 0.061164 Batch F1: 0.6
Epoch:  937        7 Batch loss: 0.080759 Batch F1: 0.18181818181818182
Epoch:  937        8 Batch loss: 0.061018 Batch F1: 0.4
Epoch:  937        9 Batch loss: 0.071349 Batch F1: 0.3076923076923077
Epoch:  937       10 Batch loss: 0.061889 Batch F1: 0.9333333333333333
Epoch:  937       11 Batch loss: 0.062257 Batch F1: 0.8571428571428571
Epoch:  937       12 Batch loss: 0.058456 Batch F1: 0.923076923076923
Train Avg Loss  937: 0.068657

Train Avg F1  937: 0.7154326160720023

Val Avg Loss  937: 0.063069

Val Avg F1  937:  0.9183882783882784

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 938
--------------------------------------------------------------
Epoch:  938        1 Batch loss: 0.048992 Batch F1: 1.0
Epoch:  938        2 Batch loss: 0.058543 Batch F1: 0.9090909090909091
Epoch:  938        3 Batch loss: 0.074596 Batch F1: 0.9565217391304348
Epoch:  938        4 Batch loss: 0.068472 Batch F1: 1.0
Epoch:  938        5 Batch loss: 0.045252 Batch F1: 1.0
Epoch:  938        6 Batch loss: 0.104963 Batch F1: 0.8181818181818181
Epoch:  938        7 Batch loss: 0.090999 Batch F1: 0.8
Epoch:  938        8 Batch loss: 0.061319 Batch F1: 0.8333333333333333
Epoch:  938        9 Batch loss: 0.054428 Batch F1: 1.0
Epoch:  938       10 Batch loss: 0.060296 Batch F1: 0.9333333333333333
Epoch:  938       11 Batch loss: 0.084578 Batch F1: 0.9090909090909091
Epoch:  938       12 Batch loss: 0.070974 Batch F1: 0.9411764705882353
Train Avg Loss  938: 0.068618

Train Avg F1  938: 0.9250607093957477

Val Avg Loss  938: 0.061616

Val Avg F1  938:  0.9356060606060606

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 939
--------------------------------------------------------------
Epoch:  939        1 Batch loss: 0.052275 Batch F1: 1.0
Epoch:  939        2 Batch loss: 0.059850 Batch F1: 1.0
Epoch:  939        3 Batch loss: 0.084103 Batch F1: 0.8695652173913044
Epoch:  939        4 Batch loss: 0.066246 Batch F1: 0.9473684210526316
Epoch:  939        5 Batch loss: 0.077924 Batch F1: 0.8421052631578948
Epoch:  939        6 Batch loss: 0.075180 Batch F1: 0.9411764705882353
Epoch:  939        7 Batch loss: 0.073101 Batch F1: 0.9600000000000001
Epoch:  939        8 Batch loss: 0.040875 Batch F1: 1.0
Epoch:  939        9 Batch loss: 0.071801 Batch F1: 0.9473684210526316
Epoch:  939       10 Batch loss: 0.064426 Batch F1: 0.8
Epoch:  939       11 Batch loss: 0.074622 Batch F1: 0.0
Epoch:  939       12 Batch loss: 0.072147 Batch F1: 0.3636363636363636
Train Avg Loss  939: 0.067713

Train Avg F1  939: 0.8059350130732552

Val Avg Loss  939: 0.061995

Val Avg F1  939:  0.5637254901960784

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 940
--------------------------------------------------------------
Epoch:  940        1 Batch loss: 0.068984 Batch F1: 0.5
Epoch:  940        2 Batch loss: 0.064699 Batch F1: 0.7499999999999999
Epoch:  940        3 Batch loss: 0.066753 Batch F1: 0.3636363636363636
Epoch:  940        4 Batch loss: 0.091207 Batch F1: 0.375
Epoch:  940        5 Batch loss: 0.058450 Batch F1: 1.0
Epoch:  940        6 Batch loss: 0.064921 Batch F1: 0.8
Epoch:  940        7 Batch loss: 0.055442 Batch F1: 0.9333333333333333
Epoch:  940        8 Batch loss: 0.069688 Batch F1: 0.8333333333333333
Epoch:  940        9 Batch loss: 0.059721 Batch F1: 0.8571428571428571
Epoch:  940       10 Batch loss: 0.089188 Batch F1: 0.8571428571428571
Epoch:  940       11 Batch loss: 0.057915 Batch F1: 0.9333333333333333
Epoch:  940       12 Batch loss: 0.059353 Batch F1: 1.0
Train Avg Loss  940: 0.067193

Train Avg F1  940: 0.7669101731601731

Val Avg Loss  940: 0.061376

Val Avg F1  940:  0.9375901875901875

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 941
--------------------------------------------------------------
Epoch:  941        1 Batch loss: 0.071566 Batch F1: 0.9333333333333333
Epoch:  941        2 Batch loss: 0.040672 Batch F1: 1.0
Epoch:  941        3 Batch loss: 0.060675 Batch F1: 0.9411764705882353
Epoch:  941        4 Batch loss: 0.067425 Batch F1: 0.5
Epoch:  941        5 Batch loss: 0.056419 Batch F1: 0.4
Epoch:  941        6 Batch loss: 0.072954 Batch F1: 0.6666666666666666
Epoch:  941        7 Batch loss: 0.108547 Batch F1: 0.4
Epoch:  941        8 Batch loss: 0.068690 Batch F1: 0.3636363636363636
Epoch:  941        9 Batch loss: 0.086964 Batch F1: 0.42857142857142855
Epoch:  941       10 Batch loss: 0.072133 Batch F1: 0.9523809523809523
Epoch:  941       11 Batch loss: 0.056537 Batch F1: 0.8
Epoch:  941       12 Batch loss: 0.057416 Batch F1: 0.923076923076923
Train Avg Loss  941: 0.068333

Train Avg F1  941: 0.6924035115211585

Val Avg Loss  941: 0.062122

Val Avg F1  941:  0.9199922884133409

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 942
--------------------------------------------------------------
Epoch:  942        1 Batch loss: 0.068331 Batch F1: 0.8750000000000001
Epoch:  942        2 Batch loss: 0.069430 Batch F1: 0.9333333333333333
Epoch:  942        3 Batch loss: 0.055706 Batch F1: 0.9333333333333333
Epoch:  942        4 Batch loss: 0.068616 Batch F1: 0.8571428571428571
Epoch:  942        5 Batch loss: 0.056532 Batch F1: 1.0
Epoch:  942        6 Batch loss: 0.084183 Batch F1: 0.42857142857142855
Epoch:  942        7 Batch loss: 0.046801 Batch F1: 0.0
Epoch:  942        8 Batch loss: 0.063190 Batch F1: 0.7368421052631579
Epoch:  942        9 Batch loss: 0.088095 Batch F1: 0.47058823529411764
Epoch:  942       10 Batch loss: 0.057348 Batch F1: 1.0
Epoch:  942       11 Batch loss: 0.073920 Batch F1: 0.9473684210526316
Epoch:  942       12 Batch loss: 0.102313 Batch F1: 0.8571428571428571
Train Avg Loss  942: 0.069539

Train Avg F1  942: 0.7532768809278099

Val Avg Loss  942: 0.062644

Val Avg F1  942:  0.924342105263158

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 943
--------------------------------------------------------------
Epoch:  943        1 Batch loss: 0.081440 Batch F1: 0.9473684210526316
Epoch:  943        2 Batch loss: 0.048433 Batch F1: 1.0
Epoch:  943        3 Batch loss: 0.088048 Batch F1: 0.9166666666666666
Epoch:  943        4 Batch loss: 0.077315 Batch F1: 0.6666666666666666
Epoch:  943        5 Batch loss: 0.048126 Batch F1: 1.0
Epoch:  943        6 Batch loss: 0.091233 Batch F1: 0.9333333333333333
Epoch:  943        7 Batch loss: 0.051373 Batch F1: 0.8571428571428571
Epoch:  943        8 Batch loss: 0.087547 Batch F1: 0.8571428571428571
Epoch:  943        9 Batch loss: 0.074484 Batch F1: 0.9411764705882353
Epoch:  943       10 Batch loss: 0.051276 Batch F1: 0.923076923076923
Epoch:  943       11 Batch loss: 0.064176 Batch F1: 1.0
Epoch:  943       12 Batch loss: 0.056410 Batch F1: 1.0
Train Avg Loss  943: 0.068322

Train Avg F1  943: 0.9202145163058475

Val Avg Loss  943: 0.061102

Val Avg F1  943:  0.9392857142857143

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 944
--------------------------------------------------------------
Epoch:  944        1 Batch loss: 0.075535 Batch F1: 0.9166666666666666
Epoch:  944        2 Batch loss: 0.049225 Batch F1: 0.9090909090909091
Epoch:  944        3 Batch loss: 0.075404 Batch F1: 0.2222222222222222
Epoch:  944        4 Batch loss: 0.084373 Batch F1: 0.2222222222222222
Epoch:  944        5 Batch loss: 0.066043 Batch F1: 0.6666666666666666
Epoch:  944        6 Batch loss: 0.061310 Batch F1: 0.4
Epoch:  944        7 Batch loss: 0.070872 Batch F1: 0.18181818181818182
Epoch:  944        8 Batch loss: 0.062079 Batch F1: 0.5454545454545454
Epoch:  944        9 Batch loss: 0.058364 Batch F1: 0.6
Epoch:  944       10 Batch loss: 0.106599 Batch F1: 0.9473684210526316
Epoch:  944       11 Batch loss: 0.062741 Batch F1: 0.8333333333333333
Epoch:  944       12 Batch loss: 0.049625 Batch F1: 1.0
Train Avg Loss  944: 0.068514

Train Avg F1  944: 0.6204035973772816

Val Avg Loss  944: 0.063940

Val Avg F1  944:  0.9331550802139037

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 945
--------------------------------------------------------------
Epoch:  945        1 Batch loss: 0.069120 Batch F1: 0.9565217391304348
Epoch:  945        2 Batch loss: 0.062801 Batch F1: 0.9333333333333333
Epoch:  945        3 Batch loss: 0.066994 Batch F1: 0.7499999999999999
Epoch:  945        4 Batch loss: 0.083745 Batch F1: 0.9166666666666666
Epoch:  945        5 Batch loss: 0.075391 Batch F1: 0.8333333333333333
Epoch:  945        6 Batch loss: 0.066324 Batch F1: 0.8333333333333333
Epoch:  945        7 Batch loss: 0.056842 Batch F1: 0.8333333333333333
Epoch:  945        8 Batch loss: 0.060140 Batch F1: 0.6666666666666666
Epoch:  945        9 Batch loss: 0.093976 Batch F1: 0.5263157894736842
Epoch:  945       10 Batch loss: 0.082257 Batch F1: 0.4444444444444445
Epoch:  945       11 Batch loss: 0.057949 Batch F1: 0.6666666666666666
Epoch:  945       12 Batch loss: 0.066404 Batch F1: 0.4444444444444445
Train Avg Loss  945: 0.070162

Train Avg F1  945: 0.7337549792355285

Val Avg Loss  945: 0.068471

Val Avg F1  945:  0.7522281639928698

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 946
--------------------------------------------------------------
Epoch:  946        1 Batch loss: 0.063450 Batch F1: 0.7499999999999999
Epoch:  946        2 Batch loss: 0.070252 Batch F1: 0.9473684210526316
Epoch:  946        3 Batch loss: 0.069212 Batch F1: 0.9
Epoch:  946        4 Batch loss: 0.082642 Batch F1: 0.9523809523809523
Epoch:  946        5 Batch loss: 0.073560 Batch F1: 0.923076923076923
Epoch:  946        6 Batch loss: 0.075173 Batch F1: 0.8750000000000001
Epoch:  946        7 Batch loss: 0.055030 Batch F1: 0.888888888888889
Epoch:  946        8 Batch loss: 0.089377 Batch F1: 0.42857142857142855
Epoch:  946        9 Batch loss: 0.072421 Batch F1: 0.625
Epoch:  946       10 Batch loss: 0.081019 Batch F1: 0.9
Epoch:  946       11 Batch loss: 0.080352 Batch F1: 0.9411764705882353
Epoch:  946       12 Batch loss: 0.050302 Batch F1: 0.8
Train Avg Loss  946: 0.071899

Train Avg F1  946: 0.827621923713255

Val Avg Loss  946: 0.065533

Val Avg F1  946:  0.7292429792429792

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 947
--------------------------------------------------------------
Epoch:  947        1 Batch loss: 0.055170 Batch F1: 0.5714285714285715
Epoch:  947        2 Batch loss: 0.059566 Batch F1: 0.9090909090909091
Epoch:  947        3 Batch loss: 0.082192 Batch F1: 0.4615384615384615
Epoch:  947        4 Batch loss: 0.103713 Batch F1: 0.5
Epoch:  947        5 Batch loss: 0.039629 Batch F1: 0.5
Epoch:  947        6 Batch loss: 0.096055 Batch F1: 0.47058823529411764
Epoch:  947        7 Batch loss: 0.076362 Batch F1: 1.0
Epoch:  947        8 Batch loss: 0.076566 Batch F1: 0.9
Epoch:  947        9 Batch loss: 0.079159 Batch F1: 0.9
Epoch:  947       10 Batch loss: 0.084592 Batch F1: 0.9090909090909091
Epoch:  947       11 Batch loss: 0.065423 Batch F1: 0.9333333333333333
Epoch:  947       12 Batch loss: 0.055667 Batch F1: 0.9090909090909091
Train Avg Loss  947: 0.072841

Train Avg F1  947: 0.7470134440722677

Val Avg Loss  947: 0.066837

Val Avg F1  947:  0.9270833333333333

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 948
--------------------------------------------------------------
Epoch:  948        1 Batch loss: 0.073402 Batch F1: 0.888888888888889
Epoch:  948        2 Batch loss: 0.075743 Batch F1: 0.888888888888889
Epoch:  948        3 Batch loss: 0.053451 Batch F1: 1.0
Epoch:  948        4 Batch loss: 0.071419 Batch F1: 0.4
Epoch:  948        5 Batch loss: 0.044720 Batch F1: 0.6666666666666666
Epoch:  948        6 Batch loss: 0.079190 Batch F1: 0.33333333333333337
Epoch:  948        7 Batch loss: 0.059178 Batch F1: 0.5
Epoch:  948        8 Batch loss: 0.087090 Batch F1: 0.6
Epoch:  948        9 Batch loss: 0.072859 Batch F1: 0.5333333333333333
Epoch:  948       10 Batch loss: 0.064337 Batch F1: 0.923076923076923
Epoch:  948       11 Batch loss: 0.074614 Batch F1: 0.0
Epoch:  948       12 Batch loss: 0.083724 Batch F1: 0.625
Train Avg Loss  948: 0.069977

Train Avg F1  948: 0.6132656695156694

Val Avg Loss  948: 0.062534

Val Avg F1  948:  0.9303490627020039

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 949
--------------------------------------------------------------
Epoch:  949        1 Batch loss: 0.057316 Batch F1: 1.0
Epoch:  949        2 Batch loss: 0.086451 Batch F1: 0.9166666666666666
Epoch:  949        3 Batch loss: 0.071448 Batch F1: 0.9
Epoch:  949        4 Batch loss: 0.065951 Batch F1: 0.8333333333333333
Epoch:  949        5 Batch loss: 0.064714 Batch F1: 0.9473684210526316
Epoch:  949        6 Batch loss: 0.057787 Batch F1: 0.9333333333333333
Epoch:  949        7 Batch loss: 0.064892 Batch F1: 0.923076923076923
Epoch:  949        8 Batch loss: 0.066675 Batch F1: 0.9333333333333333
Epoch:  949        9 Batch loss: 0.064648 Batch F1: 0.9333333333333333
Epoch:  949       10 Batch loss: 0.093468 Batch F1: 0.5555555555555556
Epoch:  949       11 Batch loss: 0.062075 Batch F1: 0.9090909090909091
Epoch:  949       12 Batch loss: 0.063937 Batch F1: 0.923076923076923
Train Avg Loss  949: 0.068280

Train Avg F1  949: 0.8923473943210785

Val Avg Loss  949: 0.062616

Val Avg F1  949:  0.9283882783882783

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 950
--------------------------------------------------------------
Epoch:  950        1 Batch loss: 0.070717 Batch F1: 0.8750000000000001
Epoch:  950        2 Batch loss: 0.057046 Batch F1: 1.0
Epoch:  950        3 Batch loss: 0.055600 Batch F1: 0.7272727272727273
Epoch:  950        4 Batch loss: 0.051434 Batch F1: 0.5
Epoch:  950        5 Batch loss: 0.072833 Batch F1: 0.5
Epoch:  950        6 Batch loss: 0.074036 Batch F1: 0.4
Epoch:  950        7 Batch loss: 0.078034 Batch F1: 0.42857142857142855
Epoch:  950        8 Batch loss: 0.081764 Batch F1: 0.4
Epoch:  950        9 Batch loss: 0.065970 Batch F1: 0.9411764705882353
Epoch:  950       10 Batch loss: 0.073974 Batch F1: 0.9333333333333333
Epoch:  950       11 Batch loss: 0.070305 Batch F1: 0.8235294117647058
Epoch:  950       12 Batch loss: 0.071365 Batch F1: 0.9523809523809523
Train Avg Loss  950: 0.068590

Train Avg F1  950: 0.7067720269926153

Val Avg Loss  950: 0.062876

Val Avg F1  950:  0.9296536796536796

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 951
--------------------------------------------------------------
Epoch:  951        1 Batch loss: 0.080963 Batch F1: 0.8235294117647058
Epoch:  951        2 Batch loss: 0.072722 Batch F1: 0.9473684210526316
Epoch:  951        3 Batch loss: 0.056606 Batch F1: 0.9473684210526316
Epoch:  951        4 Batch loss: 0.063284 Batch F1: 0.923076923076923
Epoch:  951        5 Batch loss: 0.047751 Batch F1: 1.0
Epoch:  951        6 Batch loss: 0.081603 Batch F1: 0.9090909090909091
Epoch:  951        7 Batch loss: 0.080337 Batch F1: 0.9
Epoch:  951        8 Batch loss: 0.068235 Batch F1: 0.888888888888889
Epoch:  951        9 Batch loss: 0.059092 Batch F1: 0.8
Epoch:  951       10 Batch loss: 0.077721 Batch F1: 0.4
Epoch:  951       11 Batch loss: 0.073937 Batch F1: 0.3636363636363636
Epoch:  951       12 Batch loss: 0.067099 Batch F1: 0.6666666666666666
Train Avg Loss  951: 0.069112

Train Avg F1  951: 0.7974688337691433

Val Avg Loss  951: 0.061868

Val Avg F1  951:  0.5714285714285714

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 952
--------------------------------------------------------------
Epoch:  952        1 Batch loss: 0.031204 Batch F1: 1.0
Epoch:  952        2 Batch loss: 0.114273 Batch F1: 0.56
Epoch:  952        3 Batch loss: 0.076537 Batch F1: 0.16666666666666669
Epoch:  952        4 Batch loss: 0.052263 Batch F1: 1.0
Epoch:  952        5 Batch loss: 0.056494 Batch F1: 1.0
Epoch:  952        6 Batch loss: 0.078600 Batch F1: 0.923076923076923
Epoch:  952        7 Batch loss: 0.062627 Batch F1: 0.8333333333333333
Epoch:  952        8 Batch loss: 0.069629 Batch F1: 0.8333333333333333
Epoch:  952        9 Batch loss: 0.080885 Batch F1: 0.9473684210526316
Epoch:  952       10 Batch loss: 0.061310 Batch F1: 1.0
Epoch:  952       11 Batch loss: 0.076841 Batch F1: 0.8695652173913044
Epoch:  952       12 Batch loss: 0.065777 Batch F1: 0.9333333333333333
Train Avg Loss  952: 0.068870

Train Avg F1  952: 0.8388897690156272

Val Avg Loss  952: 0.061241

Val Avg F1  952:  0.9041666666666667

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 953
--------------------------------------------------------------
Epoch:  953        1 Batch loss: 0.059470 Batch F1: 0.8571428571428571
Epoch:  953        2 Batch loss: 0.072957 Batch F1: 0.888888888888889
Epoch:  953        3 Batch loss: 0.090037 Batch F1: 0.7000000000000001
Epoch:  953        4 Batch loss: 0.059452 Batch F1: 0.8235294117647058
Epoch:  953        5 Batch loss: 0.082277 Batch F1: 0.7499999999999999
Epoch:  953        6 Batch loss: 0.076558 Batch F1: 0.8421052631578948
Epoch:  953        7 Batch loss: 0.070286 Batch F1: 0.8750000000000001
Epoch:  953        8 Batch loss: 0.067217 Batch F1: 0.9473684210526316
Epoch:  953        9 Batch loss: 0.068921 Batch F1: 0.888888888888889
Epoch:  953       10 Batch loss: 0.044383 Batch F1: 1.0
Epoch:  953       11 Batch loss: 0.074538 Batch F1: 1.0
Epoch:  953       12 Batch loss: 0.052796 Batch F1: 0.8571428571428571
Train Avg Loss  953: 0.068241

Train Avg F1  953: 0.8691722156698938

Val Avg Loss  953: 0.062916

Val Avg F1  953:  0.724660633484163

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 954
--------------------------------------------------------------
Epoch:  954        1 Batch loss: 0.085088 Batch F1: 0.42857142857142855
Epoch:  954        2 Batch loss: 0.089193 Batch F1: 0.7058823529411764
Epoch:  954        3 Batch loss: 0.068184 Batch F1: 0.9473684210526316
Epoch:  954        4 Batch loss: 0.067604 Batch F1: 0.9333333333333333
Epoch:  954        5 Batch loss: 0.065429 Batch F1: 0.923076923076923
Epoch:  954        6 Batch loss: 0.042365 Batch F1: 0.8
Epoch:  954        7 Batch loss: 0.068804 Batch F1: 0.4615384615384615
Epoch:  954        8 Batch loss: 0.048368 Batch F1: 0.33333333333333337
Epoch:  954        9 Batch loss: 0.073020 Batch F1: 0.5
Epoch:  954       10 Batch loss: 0.106371 Batch F1: 0.25
Epoch:  954       11 Batch loss: 0.042498 Batch F1: 0.8333333333333333
Epoch:  954       12 Batch loss: 0.066771 Batch F1: 0.4444444444444445
Train Avg Loss  954: 0.068641

Train Avg F1  954: 0.6300735026354222

Val Avg Loss  954: 0.061683

Val Avg F1  954:  0.9211323763955344

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 955
--------------------------------------------------------------
Epoch:  955        1 Batch loss: 0.071095 Batch F1: 0.8571428571428571
Epoch:  955        2 Batch loss: 0.052697 Batch F1: 0.923076923076923
Epoch:  955        3 Batch loss: 0.056189 Batch F1: 0.8333333333333333
Epoch:  955        4 Batch loss: 0.083129 Batch F1: 0.5
Epoch:  955        5 Batch loss: 0.055601 Batch F1: 0.9090909090909091
Epoch:  955        6 Batch loss: 0.071557 Batch F1: 1.0
Epoch:  955        7 Batch loss: 0.076213 Batch F1: 0.9473684210526316
Epoch:  955        8 Batch loss: 0.053929 Batch F1: 0.9333333333333333
Epoch:  955        9 Batch loss: 0.069665 Batch F1: 0.9
Epoch:  955       10 Batch loss: 0.074246 Batch F1: 0.9090909090909091
Epoch:  955       11 Batch loss: 0.070198 Batch F1: 0.9411764705882353
Epoch:  955       12 Batch loss: 0.073702 Batch F1: 0.9333333333333333
Train Avg Loss  955: 0.067352

Train Avg F1  955: 0.8822455408368722

Val Avg Loss  955: 0.061578

Val Avg F1  955:  0.9344611528822055

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 956
--------------------------------------------------------------
Epoch:  956        1 Batch loss: 0.051158 Batch F1: 1.0
Epoch:  956        2 Batch loss: 0.044740 Batch F1: 1.0
Epoch:  956        3 Batch loss: 0.091419 Batch F1: 0.5333333333333333
Epoch:  956        4 Batch loss: 0.076744 Batch F1: 0.8235294117647058
Epoch:  956        5 Batch loss: 0.064574 Batch F1: 0.7692307692307693
Epoch:  956        6 Batch loss: 0.070623 Batch F1: 0.923076923076923
Epoch:  956        7 Batch loss: 0.067713 Batch F1: 1.0
Epoch:  956        8 Batch loss: 0.083691 Batch F1: 0.9090909090909091
Epoch:  956        9 Batch loss: 0.068972 Batch F1: 1.0
Epoch:  956       10 Batch loss: 0.054501 Batch F1: 1.0
Epoch:  956       11 Batch loss: 0.083684 Batch F1: 0.9090909090909091
Epoch:  956       12 Batch loss: 0.060587 Batch F1: 0.8571428571428571
Train Avg Loss  956: 0.068200

Train Avg F1  956: 0.8937079260608672

Val Avg Loss  956: 0.061155

Val Avg F1  956:  0.9283882783882783

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 957
--------------------------------------------------------------
Epoch:  957        1 Batch loss: 0.105697 Batch F1: 0.8571428571428571
Epoch:  957        2 Batch loss: 0.052194 Batch F1: 1.0
Epoch:  957        3 Batch loss: 0.063939 Batch F1: 0.9473684210526316
Epoch:  957        4 Batch loss: 0.063737 Batch F1: 0.4
Epoch:  957        5 Batch loss: 0.056431 Batch F1: 0.4444444444444445
Epoch:  957        6 Batch loss: 0.100728 Batch F1: 0.4
Epoch:  957        7 Batch loss: 0.078433 Batch F1: 0.42857142857142855
Epoch:  957        8 Batch loss: 0.062043 Batch F1: 0.8333333333333333
Epoch:  957        9 Batch loss: 0.068615 Batch F1: 0.9565217391304348
Epoch:  957       10 Batch loss: 0.062003 Batch F1: 0.8333333333333333
Epoch:  957       11 Batch loss: 0.052723 Batch F1: 1.0
Epoch:  957       12 Batch loss: 0.054992 Batch F1: 1.0
Train Avg Loss  957: 0.068461

Train Avg F1  957: 0.7583929630840386

Val Avg Loss  957: 0.061286

Val Avg F1  957:  0.9160912190963342

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 958
--------------------------------------------------------------
Epoch:  958        1 Batch loss: 0.063323 Batch F1: 0.9333333333333333
Epoch:  958        2 Batch loss: 0.055983 Batch F1: 0.7272727272727273
Epoch:  958        3 Batch loss: 0.081449 Batch F1: 0.5882352941176471
Epoch:  958        4 Batch loss: 0.077074 Batch F1: 0.6
Epoch:  958        5 Batch loss: 0.065501 Batch F1: 0.5714285714285715
Epoch:  958        6 Batch loss: 0.078827 Batch F1: 0.8750000000000001
Epoch:  958        7 Batch loss: 0.072431 Batch F1: 0.7692307692307693
Epoch:  958        8 Batch loss: 0.065337 Batch F1: 0.9473684210526316
Epoch:  958        9 Batch loss: 0.069587 Batch F1: 0.8
Epoch:  958       10 Batch loss: 0.052814 Batch F1: 0.923076923076923
Epoch:  958       11 Batch loss: 0.047953 Batch F1: 0.888888888888889
Epoch:  958       12 Batch loss: 0.086210 Batch F1: 0.8750000000000001
Train Avg Loss  958: 0.068041

Train Avg F1  958: 0.7915695773667911

Val Avg Loss  958: 0.061382

Val Avg F1  958:  0.9261437908496732

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 959
--------------------------------------------------------------
Epoch:  959        1 Batch loss: 0.059807 Batch F1: 0.9333333333333333
Epoch:  959        2 Batch loss: 0.061201 Batch F1: 0.9473684210526316
Epoch:  959        3 Batch loss: 0.062981 Batch F1: 0.923076923076923
Epoch:  959        4 Batch loss: 0.076311 Batch F1: 0.9523809523809523
Epoch:  959        5 Batch loss: 0.097382 Batch F1: 0.8571428571428571
Epoch:  959        6 Batch loss: 0.075621 Batch F1: 0.8750000000000001
Epoch:  959        7 Batch loss: 0.068514 Batch F1: 0.9473684210526316
Epoch:  959        8 Batch loss: 0.062627 Batch F1: 0.9333333333333333
Epoch:  959        9 Batch loss: 0.066537 Batch F1: 0.8333333333333333
Epoch:  959       10 Batch loss: 0.066994 Batch F1: 1.0
Epoch:  959       11 Batch loss: 0.075771 Batch F1: 0.8750000000000001
Epoch:  959       12 Batch loss: 0.029817 Batch F1: 0.6666666666666666
Train Avg Loss  959: 0.066964

Train Avg F1  959: 0.8953336867810552

Val Avg Loss  959: 0.062758

Val Avg F1  959:  0.5934343434343434

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 960
--------------------------------------------------------------
Epoch:  960        1 Batch loss: 0.059559 Batch F1: 0.7142857142857143
Epoch:  960        2 Batch loss: 0.068957 Batch F1: 0.4
Epoch:  960        3 Batch loss: 0.077815 Batch F1: 0.3636363636363636
Epoch:  960        4 Batch loss: 0.052607 Batch F1: 0.5
Epoch:  960        5 Batch loss: 0.082643 Batch F1: 0.18181818181818182
Epoch:  960        6 Batch loss: 0.041947 Batch F1: 0.6666666666666666
Epoch:  960        7 Batch loss: 0.052721 Batch F1: 0.8571428571428571
Epoch:  960        8 Batch loss: 0.079583 Batch F1: 0.42857142857142855
Epoch:  960        9 Batch loss: 0.064961 Batch F1: 0.5
Epoch:  960       10 Batch loss: 0.075524 Batch F1: 0.9523809523809523
Epoch:  960       11 Batch loss: 0.095965 Batch F1: 0.9285714285714286
Epoch:  960       12 Batch loss: 0.060881 Batch F1: 0.8
Train Avg Loss  960: 0.067764

Train Avg F1  960: 0.6077561327561328

Val Avg Loss  960: 0.062505

Val Avg F1  960:  0.9262663398692811

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 961
--------------------------------------------------------------
Epoch:  961        1 Batch loss: 0.071890 Batch F1: 0.8333333333333333
Epoch:  961        2 Batch loss: 0.064876 Batch F1: 0.8333333333333333
Epoch:  961        3 Batch loss: 0.069060 Batch F1: 0.9411764705882353
Epoch:  961        4 Batch loss: 0.079550 Batch F1: 0.5714285714285715
Epoch:  961        5 Batch loss: 0.036032 Batch F1: 0.6666666666666666
Epoch:  961        6 Batch loss: 0.073333 Batch F1: 0.6666666666666666
Epoch:  961        7 Batch loss: 0.060955 Batch F1: 0.5454545454545454
Epoch:  961        8 Batch loss: 0.055943 Batch F1: 0.7499999999999999
Epoch:  961        9 Batch loss: 0.124444 Batch F1: 0.11764705882352941
Epoch:  961       10 Batch loss: 0.073946 Batch F1: 0.3636363636363636
Epoch:  961       11 Batch loss: 0.078594 Batch F1: 0.9090909090909091
Epoch:  961       12 Batch loss: 0.062910 Batch F1: 1.0
Train Avg Loss  961: 0.070961

Train Avg F1  961: 0.6832028265851795

Val Avg Loss  961: 0.065068

Val Avg F1  961:  0.9068181818181817

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 962
--------------------------------------------------------------
Epoch:  962        1 Batch loss: 0.083961 Batch F1: 0.761904761904762
Epoch:  962        2 Batch loss: 0.066276 Batch F1: 0.9411764705882353
Epoch:  962        3 Batch loss: 0.072806 Batch F1: 0.7499999999999999
Epoch:  962        4 Batch loss: 0.068907 Batch F1: 0.7692307692307693
Epoch:  962        5 Batch loss: 0.062265 Batch F1: 0.9333333333333333
Epoch:  962        6 Batch loss: 0.083796 Batch F1: 0.4
Epoch:  962        7 Batch loss: 0.060604 Batch F1: 0.25
Epoch:  962        8 Batch loss: 0.062082 Batch F1: 0.7142857142857143
Epoch:  962        9 Batch loss: 0.056709 Batch F1: 0.5
Epoch:  962       10 Batch loss: 0.063176 Batch F1: 0.25
Epoch:  962       11 Batch loss: 0.062630 Batch F1: 0.6153846153846153
Epoch:  962       12 Batch loss: 0.080079 Batch F1: 0.5714285714285715
Train Avg Loss  962: 0.068608

Train Avg F1  962: 0.6213953530130001

Val Avg Loss  962: 0.062241

Val Avg F1  962:  0.5792207792207792

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 963
--------------------------------------------------------------
Epoch:  963        1 Batch loss: 0.076228 Batch F1: 0.3636363636363636
Epoch:  963        2 Batch loss: 0.061431 Batch F1: 0.923076923076923
Epoch:  963        3 Batch loss: 0.059095 Batch F1: 0.9090909090909091
Epoch:  963        4 Batch loss: 0.058820 Batch F1: 0.9523809523809523
Epoch:  963        5 Batch loss: 0.069652 Batch F1: 0.9411764705882353
Epoch:  963        6 Batch loss: 0.077193 Batch F1: 0.8235294117647058
Epoch:  963        7 Batch loss: 0.063067 Batch F1: 0.9411764705882353
Epoch:  963        8 Batch loss: 0.072376 Batch F1: 0.888888888888889
Epoch:  963        9 Batch loss: 0.083943 Batch F1: 0.8421052631578948
Epoch:  963       10 Batch loss: 0.071596 Batch F1: 0.9565217391304348
Epoch:  963       11 Batch loss: 0.054115 Batch F1: 1.0
Epoch:  963       12 Batch loss: 0.066000 Batch F1: 0.9090909090909091
Train Avg Loss  963: 0.067793

Train Avg F1  963: 0.8708895251162043

Val Avg Loss  963: 0.060875

Val Avg F1  963:  0.9468325791855203

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 964
--------------------------------------------------------------
Epoch:  964        1 Batch loss: 0.066213 Batch F1: 0.888888888888889
Epoch:  964        2 Batch loss: 0.068074 Batch F1: 0.9411764705882353
Epoch:  964        3 Batch loss: 0.085389 Batch F1: 0.7499999999999999
Epoch:  964        4 Batch loss: 0.079081 Batch F1: 0.8421052631578948
Epoch:  964        5 Batch loss: 0.086435 Batch F1: 0.967741935483871
Epoch:  964        6 Batch loss: 0.060621 Batch F1: 1.0
Epoch:  964        7 Batch loss: 0.071508 Batch F1: 0.9600000000000001
Epoch:  964        8 Batch loss: 0.067532 Batch F1: 0.923076923076923
Epoch:  964        9 Batch loss: 0.069122 Batch F1: 1.0
Epoch:  964       10 Batch loss: 0.055894 Batch F1: 0.4444444444444445
Epoch:  964       11 Batch loss: 0.051582 Batch F1: 0.5
Epoch:  964       12 Batch loss: 0.056081 Batch F1: 0.6666666666666666
Train Avg Loss  964: 0.068128

Train Avg F1  964: 0.8236750493589104

Val Avg Loss  964: 0.066547

Val Avg F1  964:  0.585081585081585

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 965
--------------------------------------------------------------
Epoch:  965        1 Batch loss: 0.066212 Batch F1: 0.5
Epoch:  965        2 Batch loss: 0.073742 Batch F1: 0.6666666666666666
Epoch:  965        3 Batch loss: 0.073794 Batch F1: 0.5882352941176471
Epoch:  965        4 Batch loss: 0.058489 Batch F1: 0.888888888888889
Epoch:  965        5 Batch loss: 0.059316 Batch F1: 0.4444444444444445
Epoch:  965        6 Batch loss: 0.075628 Batch F1: 0.5714285714285715
Epoch:  965        7 Batch loss: 0.068943 Batch F1: 0.9473684210526316
Epoch:  965        8 Batch loss: 0.091992 Batch F1: 0.8333333333333333
Epoch:  965        9 Batch loss: 0.066116 Batch F1: 0.888888888888889
Epoch:  965       10 Batch loss: 0.080773 Batch F1: 0.9
Epoch:  965       11 Batch loss: 0.064313 Batch F1: 1.0
Epoch:  965       12 Batch loss: 0.069372 Batch F1: 0.9333333333333333
Train Avg Loss  965: 0.070724

Train Avg F1  965: 0.7635489868462005

Val Avg Loss  965: 0.063782

Val Avg F1  965:  0.92421955624355

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 966
--------------------------------------------------------------
Epoch:  966        1 Batch loss: 0.068282 Batch F1: 0.8571428571428571
Epoch:  966        2 Batch loss: 0.088140 Batch F1: 0.5714285714285715
Epoch:  966        3 Batch loss: 0.071378 Batch F1: 0.4615384615384615
Epoch:  966        4 Batch loss: 0.085631 Batch F1: 0.8235294117647058
Epoch:  966        5 Batch loss: 0.053228 Batch F1: 0.9090909090909091
Epoch:  966        6 Batch loss: 0.075249 Batch F1: 0.8750000000000001
Epoch:  966        7 Batch loss: 0.073140 Batch F1: 0.9523809523809523
Epoch:  966        8 Batch loss: 0.061823 Batch F1: 1.0
Epoch:  966        9 Batch loss: 0.063979 Batch F1: 1.0
Epoch:  966       10 Batch loss: 0.053166 Batch F1: 1.0
Epoch:  966       11 Batch loss: 0.074871 Batch F1: 0.9523809523809523
Epoch:  966       12 Batch loss: 0.067921 Batch F1: 0.9090909090909091
Train Avg Loss  966: 0.069734

Train Avg F1  966: 0.8592985854015266

Val Avg Loss  966: 0.063154

Val Avg F1  966:  0.7466004583651642

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 967
--------------------------------------------------------------
Epoch:  967        1 Batch loss: 0.034716 Batch F1: 1.0
Epoch:  967        2 Batch loss: 0.076037 Batch F1: 0.4615384615384615
Epoch:  967        3 Batch loss: 0.071789 Batch F1: 0.5714285714285715
Epoch:  967        4 Batch loss: 0.101292 Batch F1: 0.5
Epoch:  967        5 Batch loss: 0.077310 Batch F1: 0.5333333333333333
Epoch:  967        6 Batch loss: 0.063046 Batch F1: 1.0
Epoch:  967        7 Batch loss: 0.063440 Batch F1: 1.0
Epoch:  967        8 Batch loss: 0.063824 Batch F1: 0.6
Epoch:  967        9 Batch loss: 0.091995 Batch F1: 0.7000000000000001
Epoch:  967       10 Batch loss: 0.066207 Batch F1: 0.7692307692307693
Epoch:  967       11 Batch loss: 0.079082 Batch F1: 0.9473684210526316
Epoch:  967       12 Batch loss: 0.077124 Batch F1: 1.0
Train Avg Loss  967: 0.072155

Train Avg F1  967: 0.7569082963819805

Val Avg Loss  967: 0.064473

Val Avg F1  967:  0.9284005468215994

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 968
--------------------------------------------------------------
Epoch:  968        1 Batch loss: 0.074186 Batch F1: 0.9565217391304348
Epoch:  968        2 Batch loss: 0.083322 Batch F1: 0.9
Epoch:  968        3 Batch loss: 0.054755 Batch F1: 0.888888888888889
Epoch:  968        4 Batch loss: 0.053447 Batch F1: 0.8571428571428571
Epoch:  968        5 Batch loss: 0.060947 Batch F1: 0.5
Epoch:  968        6 Batch loss: 0.063650 Batch F1: 0.4
Epoch:  968        7 Batch loss: 0.096943 Batch F1: 0.5
Epoch:  968        8 Batch loss: 0.092260 Batch F1: 0.6363636363636364
Epoch:  968        9 Batch loss: 0.051339 Batch F1: 0.5
Epoch:  968       10 Batch loss: 0.087476 Batch F1: 0.8571428571428571
Epoch:  968       11 Batch loss: 0.069266 Batch F1: 0.9411764705882353
Epoch:  968       12 Batch loss: 0.064878 Batch F1: 1.0
Train Avg Loss  968: 0.071039

Train Avg F1  968: 0.7447697041047426

Val Avg Loss  968: 0.063523

Val Avg F1  968:  0.8688296829029094

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 969
--------------------------------------------------------------
Epoch:  969        1 Batch loss: 0.061541 Batch F1: 0.8
Epoch:  969        2 Batch loss: 0.072403 Batch F1: 0.923076923076923
Epoch:  969        3 Batch loss: 0.069857 Batch F1: 0.888888888888889
Epoch:  969        4 Batch loss: 0.085631 Batch F1: 0.888888888888889
Epoch:  969        5 Batch loss: 0.058072 Batch F1: 0.9473684210526316
Epoch:  969        6 Batch loss: 0.059688 Batch F1: 1.0
Epoch:  969        7 Batch loss: 0.073161 Batch F1: 1.0
Epoch:  969        8 Batch loss: 0.070996 Batch F1: 0.5714285714285715
Epoch:  969        9 Batch loss: 0.049561 Batch F1: 1.0
Epoch:  969       10 Batch loss: 0.078441 Batch F1: 0.5555555555555556
Epoch:  969       11 Batch loss: 0.073588 Batch F1: 0.5714285714285715
Epoch:  969       12 Batch loss: 0.080573 Batch F1: 0.8750000000000001
Train Avg Loss  969: 0.069459

Train Avg F1  969: 0.8351363183600026

Val Avg Loss  969: 0.061760

Val Avg F1  969:  0.9273809523809524

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 970
--------------------------------------------------------------
Epoch:  970        1 Batch loss: 0.049635 Batch F1: 0.8
Epoch:  970        2 Batch loss: 0.072796 Batch F1: 0.4615384615384615
Epoch:  970        3 Batch loss: 0.077067 Batch F1: 0.5
Epoch:  970        4 Batch loss: 0.086882 Batch F1: 0.4
Epoch:  970        5 Batch loss: 0.072720 Batch F1: 0.8571428571428571
Epoch:  970        6 Batch loss: 0.056286 Batch F1: 0.9333333333333333
Epoch:  970        7 Batch loss: 0.056761 Batch F1: 1.0
Epoch:  970        8 Batch loss: 0.061716 Batch F1: 1.0
Epoch:  970        9 Batch loss: 0.078263 Batch F1: 0.9523809523809523
Epoch:  970       10 Batch loss: 0.051985 Batch F1: 0.9333333333333333
Epoch:  970       11 Batch loss: 0.083824 Batch F1: 0.375
Epoch:  970       12 Batch loss: 0.078740 Batch F1: 0.9411764705882353
Train Avg Loss  970: 0.068890

Train Avg F1  970: 0.7628254506930978

Val Avg Loss  970: 0.061286

Val Avg F1  970:  0.9257309941520467

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 971
--------------------------------------------------------------
Epoch:  971        1 Batch loss: 0.076216 Batch F1: 0.8
Epoch:  971        2 Batch loss: 0.050786 Batch F1: 0.8
Epoch:  971        3 Batch loss: 0.083940 Batch F1: 0.8
Epoch:  971        4 Batch loss: 0.075347 Batch F1: 0.9600000000000001
Epoch:  971        5 Batch loss: 0.075120 Batch F1: 0.9473684210526316
Epoch:  971        6 Batch loss: 0.078206 Batch F1: 0.9565217391304348
Epoch:  971        7 Batch loss: 0.071278 Batch F1: 0.9473684210526316
Epoch:  971        8 Batch loss: 0.068354 Batch F1: 0.9411764705882353
Epoch:  971        9 Batch loss: 0.054506 Batch F1: 1.0
Epoch:  971       10 Batch loss: 0.060546 Batch F1: 0.9411764705882353
Epoch:  971       11 Batch loss: 0.047969 Batch F1: 0.888888888888889
Epoch:  971       12 Batch loss: 0.068751 Batch F1: 0.6666666666666666
Train Avg Loss  971: 0.067585

Train Avg F1  971: 0.8874305898306437

Val Avg Loss  971: 0.062968

Val Avg F1  971:  0.5864527629233511

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 972
--------------------------------------------------------------
Epoch:  972        1 Batch loss: 0.082396 Batch F1: 0.4
Epoch:  972        2 Batch loss: 0.059671 Batch F1: 0.4
Epoch:  972        3 Batch loss: 0.090779 Batch F1: 0.5454545454545454
Epoch:  972        4 Batch loss: 0.052913 Batch F1: 0.923076923076923
Epoch:  972        5 Batch loss: 0.075011 Batch F1: 0.9090909090909091
Epoch:  972        6 Batch loss: 0.086201 Batch F1: 0.923076923076923
Epoch:  972        7 Batch loss: 0.069462 Batch F1: 0.923076923076923
Epoch:  972        8 Batch loss: 0.055068 Batch F1: 0.9090909090909091
Epoch:  972        9 Batch loss: 0.077850 Batch F1: 0.8
Epoch:  972       10 Batch loss: 0.050452 Batch F1: 1.0
Epoch:  972       11 Batch loss: 0.072655 Batch F1: 1.0
Epoch:  972       12 Batch loss: 0.054474 Batch F1: 0.6666666666666666
Train Avg Loss  972: 0.068911

Train Avg F1  972: 0.7832944832944833

Val Avg Loss  972: 0.063653

Val Avg F1  972:  0.5729603729603729

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 973
--------------------------------------------------------------
Epoch:  973        1 Batch loss: 0.054075 Batch F1: 0.4444444444444445
Epoch:  973        2 Batch loss: 0.070680 Batch F1: 0.33333333333333337
Epoch:  973        3 Batch loss: 0.057346 Batch F1: 1.0
Epoch:  973        4 Batch loss: 0.089706 Batch F1: 0.7142857142857143
Epoch:  973        5 Batch loss: 0.056732 Batch F1: 1.0
Epoch:  973        6 Batch loss: 0.062413 Batch F1: 0.7777777777777778
Epoch:  973        7 Batch loss: 0.077428 Batch F1: 0.4615384615384615
Epoch:  973        8 Batch loss: 0.077456 Batch F1: 0.3636363636363636
Epoch:  973        9 Batch loss: 0.080190 Batch F1: 0.7058823529411764
Epoch:  973       10 Batch loss: 0.062136 Batch F1: 1.0
Epoch:  973       11 Batch loss: 0.063901 Batch F1: 0.923076923076923
Epoch:  973       12 Batch loss: 0.064313 Batch F1: 0.9333333333333333
Train Avg Loss  973: 0.068031

Train Avg F1  973: 0.7214423920306273

Val Avg Loss  973: 0.061445

Val Avg F1  973:  0.9281045751633986

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 974
--------------------------------------------------------------
Epoch:  974        1 Batch loss: 0.069200 Batch F1: 0.9333333333333333
Epoch:  974        2 Batch loss: 0.065885 Batch F1: 1.0
Epoch:  974        3 Batch loss: 0.070536 Batch F1: 0.9473684210526316
Epoch:  974        4 Batch loss: 0.070192 Batch F1: 0.9
Epoch:  974        5 Batch loss: 0.075268 Batch F1: 0.8750000000000001
Epoch:  974        6 Batch loss: 0.049784 Batch F1: 0.888888888888889
Epoch:  974        7 Batch loss: 0.067176 Batch F1: 0.6666666666666666
Epoch:  974        8 Batch loss: 0.064193 Batch F1: 1.0
Epoch:  974        9 Batch loss: 0.048560 Batch F1: 0.6666666666666666
Epoch:  974       10 Batch loss: 0.074825 Batch F1: 0.19999999999999998
Epoch:  974       11 Batch loss: 0.079827 Batch F1: 0.47058823529411764
Epoch:  974       12 Batch loss: 0.076794 Batch F1: 0.4
Train Avg Loss  974: 0.067687

Train Avg F1  974: 0.7457093509918589

Val Avg Loss  974: 0.061021

Val Avg F1  974:  0.9011015325670498

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 975
--------------------------------------------------------------
Epoch:  975        1 Batch loss: 0.071482 Batch F1: 0.888888888888889
Epoch:  975        2 Batch loss: 0.064235 Batch F1: 1.0
Epoch:  975        3 Batch loss: 0.063613 Batch F1: 0.923076923076923
Epoch:  975        4 Batch loss: 0.070806 Batch F1: 0.9473684210526316
Epoch:  975        5 Batch loss: 0.060680 Batch F1: 0.8333333333333333
Epoch:  975        6 Batch loss: 0.068552 Batch F1: 0.8571428571428571
Epoch:  975        7 Batch loss: 0.074791 Batch F1: 1.0
Epoch:  975        8 Batch loss: 0.081285 Batch F1: 0.7499999999999999
Epoch:  975        9 Batch loss: 0.056207 Batch F1: 1.0
Epoch:  975       10 Batch loss: 0.063357 Batch F1: 0.9473684210526316
Epoch:  975       11 Batch loss: 0.066609 Batch F1: 0.8750000000000001
Epoch:  975       12 Batch loss: 0.062828 Batch F1: 0.9090909090909091
Train Avg Loss  975: 0.067037

Train Avg F1  975: 0.9109391461365144

Val Avg Loss  975: 0.061882

Val Avg F1  975:  0.9006410256410255

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 976
--------------------------------------------------------------
Epoch:  976        1 Batch loss: 0.059308 Batch F1: 1.0
Epoch:  976        2 Batch loss: 0.080235 Batch F1: 0.888888888888889
Epoch:  976        3 Batch loss: 0.058260 Batch F1: 0.923076923076923
Epoch:  976        4 Batch loss: 0.097657 Batch F1: 0.6086956521739131
Epoch:  976        5 Batch loss: 0.053958 Batch F1: 0.923076923076923
Epoch:  976        6 Batch loss: 0.052182 Batch F1: 0.9090909090909091
Epoch:  976        7 Batch loss: 0.051329 Batch F1: 0.6
Epoch:  976        8 Batch loss: 0.064994 Batch F1: 0.5454545454545454
Epoch:  976        9 Batch loss: 0.062454 Batch F1: 0.5454545454545454
Epoch:  976       10 Batch loss: 0.054951 Batch F1: 0.8
Epoch:  976       11 Batch loss: 0.077630 Batch F1: 0.5555555555555556
Epoch:  976       12 Batch loss: 0.107807 Batch F1: 0.2857142857142857
Train Avg Loss  976: 0.068397

Train Avg F1  976: 0.7154173523738742

Val Avg Loss  976: 0.060914

Val Avg F1  976:  0.9277777777777778

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 977
--------------------------------------------------------------
Epoch:  977        1 Batch loss: 0.050816 Batch F1: 0.9090909090909091
Epoch:  977        2 Batch loss: 0.057853 Batch F1: 0.9333333333333333
Epoch:  977        3 Batch loss: 0.065094 Batch F1: 0.8235294117647058
Epoch:  977        4 Batch loss: 0.073625 Batch F1: 0.9523809523809523
Epoch:  977        5 Batch loss: 0.082249 Batch F1: 0.888888888888889
Epoch:  977        6 Batch loss: 0.079097 Batch F1: 0.962962962962963
Epoch:  977        7 Batch loss: 0.067097 Batch F1: 0.923076923076923
Epoch:  977        8 Batch loss: 0.080037 Batch F1: 0.8
Epoch:  977        9 Batch loss: 0.056197 Batch F1: 1.0
Epoch:  977       10 Batch loss: 0.059309 Batch F1: 1.0
Epoch:  977       11 Batch loss: 0.058607 Batch F1: 0.4444444444444445
Epoch:  977       12 Batch loss: 0.085584 Batch F1: 0.33333333333333337
Train Avg Loss  977: 0.067964

Train Avg F1  977: 0.8309200966063712

Val Avg Loss  977: 0.062173

Val Avg F1  977:  0.5263082505729564

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 978
--------------------------------------------------------------
Epoch:  978        1 Batch loss: 0.074711 Batch F1: 0.4615384615384615
Epoch:  978        2 Batch loss: 0.051244 Batch F1: 0.6666666666666666
Epoch:  978        3 Batch loss: 0.066903 Batch F1: 0.5
Epoch:  978        4 Batch loss: 0.073965 Batch F1: 0.0
Epoch:  978        5 Batch loss: 0.067102 Batch F1: 0.9523809523809523
Epoch:  978        6 Batch loss: 0.060722 Batch F1: 0.9411764705882353
Epoch:  978        7 Batch loss: 0.064899 Batch F1: 0.8333333333333333
Epoch:  978        8 Batch loss: 0.071995 Batch F1: 0.9411764705882353
Epoch:  978        9 Batch loss: 0.080358 Batch F1: 0.888888888888889
Epoch:  978       10 Batch loss: 0.080493 Batch F1: 0.9166666666666666
Epoch:  978       11 Batch loss: 0.053693 Batch F1: 0.888888888888889
Epoch:  978       12 Batch loss: 0.064892 Batch F1: 0.8333333333333333
Train Avg Loss  978: 0.067581

Train Avg F1  978: 0.7353375110728053

Val Avg Loss  978: 0.060935

Val Avg F1  978:  0.9229085865115277

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 979
--------------------------------------------------------------
Epoch:  979        1 Batch loss: 0.055233 Batch F1: 0.8333333333333333
Epoch:  979        2 Batch loss: 0.078346 Batch F1: 0.9090909090909091
Epoch:  979        3 Batch loss: 0.070938 Batch F1: 0.9565217391304348
Epoch:  979        4 Batch loss: 0.065504 Batch F1: 0.8333333333333333
Epoch:  979        5 Batch loss: 0.059477 Batch F1: 0.8571428571428571
Epoch:  979        6 Batch loss: 0.063140 Batch F1: 0.25
Epoch:  979        7 Batch loss: 0.072651 Batch F1: 0.5
Epoch:  979        8 Batch loss: 0.062253 Batch F1: 0.7142857142857143
Epoch:  979        9 Batch loss: 0.078075 Batch F1: 0.42857142857142855
Epoch:  979       10 Batch loss: 0.070571 Batch F1: 0.5882352941176471
Epoch:  979       11 Batch loss: 0.062639 Batch F1: 0.25
Epoch:  979       12 Batch loss: 0.069912 Batch F1: 0.8333333333333333
Train Avg Loss  979: 0.067395

Train Avg F1  979: 0.6628206618615825

Val Avg Loss  979: 0.060850

Val Avg F1  979:  0.924812030075188

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 980
--------------------------------------------------------------
Epoch:  980        1 Batch loss: 0.069793 Batch F1: 0.888888888888889
Epoch:  980        2 Batch loss: 0.076218 Batch F1: 0.8571428571428571
Epoch:  980        3 Batch loss: 0.058885 Batch F1: 1.0
Epoch:  980        4 Batch loss: 0.078821 Batch F1: 0.8235294117647058
Epoch:  980        5 Batch loss: 0.059106 Batch F1: 0.9411764705882353
Epoch:  980        6 Batch loss: 0.056028 Batch F1: 0.8571428571428571
Epoch:  980        7 Batch loss: 0.069232 Batch F1: 0.8750000000000001
Epoch:  980        8 Batch loss: 0.050511 Batch F1: 1.0
Epoch:  980        9 Batch loss: 0.077690 Batch F1: 0.6666666666666666
Epoch:  980       10 Batch loss: 0.076441 Batch F1: 0.7058823529411764
Epoch:  980       11 Batch loss: 0.071552 Batch F1: 0.9565217391304348
Epoch:  980       12 Batch loss: 0.059615 Batch F1: 0.9333333333333333
Train Avg Loss  980: 0.066991

Train Avg F1  980: 0.8754403814665963

Val Avg Loss  980: 0.061559

Val Avg F1  980:  0.9326625386996904

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 981
--------------------------------------------------------------
Epoch:  981        1 Batch loss: 0.071509 Batch F1: 0.7692307692307693
Epoch:  981        2 Batch loss: 0.061602 Batch F1: 0.9473684210526316
Epoch:  981        3 Batch loss: 0.052797 Batch F1: 1.0
Epoch:  981        4 Batch loss: 0.060921 Batch F1: 0.888888888888889
Epoch:  981        5 Batch loss: 0.067785 Batch F1: 0.8750000000000001
Epoch:  981        6 Batch loss: 0.057244 Batch F1: 1.0
Epoch:  981        7 Batch loss: 0.088493 Batch F1: 0.8235294117647058
Epoch:  981        8 Batch loss: 0.061185 Batch F1: 1.0
Epoch:  981        9 Batch loss: 0.083863 Batch F1: 0.9600000000000001
Epoch:  981       10 Batch loss: 0.055322 Batch F1: 1.0
Epoch:  981       11 Batch loss: 0.078594 Batch F1: 0.7142857142857143
Epoch:  981       12 Batch loss: 0.067059 Batch F1: 1.0
Train Avg Loss  981: 0.067198

Train Avg F1  981: 0.9148586004352258

Val Avg Loss  981: 0.060747

Val Avg F1  981:  0.93406432748538

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 982
--------------------------------------------------------------
Epoch:  982        1 Batch loss: 0.072633 Batch F1: 0.9565217391304348
Epoch:  982        2 Batch loss: 0.067443 Batch F1: 0.888888888888889
Epoch:  982        3 Batch loss: 0.052792 Batch F1: 1.0
Epoch:  982        4 Batch loss: 0.088841 Batch F1: 0.88
Epoch:  982        5 Batch loss: 0.081420 Batch F1: 0.9090909090909091
Epoch:  982        6 Batch loss: 0.059089 Batch F1: 0.9333333333333333
Epoch:  982        7 Batch loss: 0.067251 Batch F1: 0.8
Epoch:  982        8 Batch loss: 0.064740 Batch F1: 0.9090909090909091
Epoch:  982        9 Batch loss: 0.045803 Batch F1: 0.9090909090909091
Epoch:  982       10 Batch loss: 0.054034 Batch F1: 0.9333333333333333
Epoch:  982       11 Batch loss: 0.075491 Batch F1: 0.9411764705882353
Epoch:  982       12 Batch loss: 0.074999 Batch F1: 0.9473684210526316
Train Avg Loss  982: 0.067045

Train Avg F1  982: 0.9173245761332988

Val Avg Loss  982: 0.060862

Val Avg F1  982:  0.9265079365079365

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 983
--------------------------------------------------------------
Epoch:  983        1 Batch loss: 0.079417 Batch F1: 0.8
Epoch:  983        2 Batch loss: 0.084880 Batch F1: 0.9166666666666666
Epoch:  983        3 Batch loss: 0.062415 Batch F1: 0.9333333333333333
Epoch:  983        4 Batch loss: 0.054162 Batch F1: 1.0
Epoch:  983        5 Batch loss: 0.058793 Batch F1: 0.25
Epoch:  983        6 Batch loss: 0.063823 Batch F1: 0.5454545454545454
Epoch:  983        7 Batch loss: 0.071997 Batch F1: 0.6666666666666666
Epoch:  983        8 Batch loss: 0.072019 Batch F1: 0.3636363636363636
Epoch:  983        9 Batch loss: 0.052697 Batch F1: 0.6666666666666666
Epoch:  983       10 Batch loss: 0.076117 Batch F1: 0.5333333333333333
Epoch:  983       11 Batch loss: 0.073496 Batch F1: 0.7058823529411764
Epoch:  983       12 Batch loss: 0.054587 Batch F1: 1.0
Train Avg Loss  983: 0.067034

Train Avg F1  983: 0.6984699940582294

Val Avg Loss  983: 0.060990

Val Avg F1  983:  0.9171626984126984

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 984
--------------------------------------------------------------
Epoch:  984        1 Batch loss: 0.092196 Batch F1: 0.8695652173913044
Epoch:  984        2 Batch loss: 0.053180 Batch F1: 0.9090909090909091
Epoch:  984        3 Batch loss: 0.075184 Batch F1: 0.888888888888889
Epoch:  984        4 Batch loss: 0.062187 Batch F1: 0.8571428571428571
Epoch:  984        5 Batch loss: 0.059485 Batch F1: 0.9411764705882353
Epoch:  984        6 Batch loss: 0.060531 Batch F1: 0.9411764705882353
Epoch:  984        7 Batch loss: 0.054368 Batch F1: 1.0
Epoch:  984        8 Batch loss: 0.064162 Batch F1: 0.9473684210526316
Epoch:  984        9 Batch loss: 0.059644 Batch F1: 1.0
Epoch:  984       10 Batch loss: 0.070776 Batch F1: 0.5714285714285715
Epoch:  984       11 Batch loss: 0.061640 Batch F1: 0.6666666666666666
Epoch:  984       12 Batch loss: 0.095691 Batch F1: 0.19999999999999998
Train Avg Loss  984: 0.067420

Train Avg F1  984: 0.8160420394031916

Val Avg Loss  984: 0.061891

Val Avg F1  984:  0.5899122807017543

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 985
--------------------------------------------------------------
Epoch:  985        1 Batch loss: 0.065478 Batch F1: 0.0
Epoch:  985        2 Batch loss: 0.064186 Batch F1: 0.9333333333333333
Epoch:  985        3 Batch loss: 0.043792 Batch F1: 1.0
Epoch:  985        4 Batch loss: 0.068477 Batch F1: 1.0
Epoch:  985        5 Batch loss: 0.057085 Batch F1: 0.9473684210526316
Epoch:  985        6 Batch loss: 0.066259 Batch F1: 0.8750000000000001
Epoch:  985        7 Batch loss: 0.075047 Batch F1: 0.888888888888889
Epoch:  985        8 Batch loss: 0.059989 Batch F1: 0.9090909090909091
Epoch:  985        9 Batch loss: 0.094373 Batch F1: 0.88
Epoch:  985       10 Batch loss: 0.081513 Batch F1: 0.9
Epoch:  985       11 Batch loss: 0.055855 Batch F1: 1.0
Epoch:  985       12 Batch loss: 0.071824 Batch F1: 0.8571428571428571
Train Avg Loss  985: 0.066990

Train Avg F1  985: 0.8492353674590518

Val Avg Loss  985: 0.060814

Val Avg F1  985:  0.906832298136646

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 986
--------------------------------------------------------------
Epoch:  986        1 Batch loss: 0.060713 Batch F1: 0.923076923076923
Epoch:  986        2 Batch loss: 0.088045 Batch F1: 1.0
Epoch:  986        3 Batch loss: 0.074328 Batch F1: 0.8750000000000001
Epoch:  986        4 Batch loss: 0.054620 Batch F1: 0.923076923076923
Epoch:  986        5 Batch loss: 0.046945 Batch F1: 0.9090909090909091
Epoch:  986        6 Batch loss: 0.089632 Batch F1: 0.8
Epoch:  986        7 Batch loss: 0.048667 Batch F1: 1.0
Epoch:  986        8 Batch loss: 0.051261 Batch F1: 1.0
Epoch:  986        9 Batch loss: 0.071282 Batch F1: 0.5333333333333333
Epoch:  986       10 Batch loss: 0.056902 Batch F1: 0.6153846153846153
Epoch:  986       11 Batch loss: 0.053366 Batch F1: 0.0
Epoch:  986       12 Batch loss: 0.118679 Batch F1: 0.16666666666666669
Train Avg Loss  986: 0.067870

Train Avg F1  986: 0.7288024475524475

Val Avg Loss  986: 0.060954

Val Avg F1  986:  0.9306888763410502

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 987
--------------------------------------------------------------
Epoch:  987        1 Batch loss: 0.067686 Batch F1: 1.0
Epoch:  987        2 Batch loss: 0.080416 Batch F1: 0.8235294117647058
Epoch:  987        3 Batch loss: 0.063243 Batch F1: 0.8571428571428571
Epoch:  987        4 Batch loss: 0.051100 Batch F1: 0.6666666666666666
Epoch:  987        5 Batch loss: 0.078750 Batch F1: 0.4615384615384615
Epoch:  987        6 Batch loss: 0.076582 Batch F1: 0.9600000000000001
Epoch:  987        7 Batch loss: 0.060739 Batch F1: 1.0
Epoch:  987        8 Batch loss: 0.045804 Batch F1: 1.0
Epoch:  987        9 Batch loss: 0.078980 Batch F1: 0.9565217391304348
Epoch:  987       10 Batch loss: 0.073315 Batch F1: 0.8571428571428571
Epoch:  987       11 Batch loss: 0.084844 Batch F1: 0.8571428571428571
Epoch:  987       12 Batch loss: 0.069466 Batch F1: 1.0
Train Avg Loss  987: 0.069244

Train Avg F1  987: 0.86997373754407

Val Avg Loss  987: 0.062015

Val Avg F1  987:  0.9263574660633483

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 988
--------------------------------------------------------------
Epoch:  988        1 Batch loss: 0.068266 Batch F1: 0.8
Epoch:  988        2 Batch loss: 0.070643 Batch F1: 0.5
Epoch:  988        3 Batch loss: 0.088143 Batch F1: 0.5
Epoch:  988        4 Batch loss: 0.054222 Batch F1: 0.4444444444444445
Epoch:  988        5 Batch loss: 0.073033 Batch F1: 0.0
Epoch:  988        6 Batch loss: 0.100469 Batch F1: 0.4
Epoch:  988        7 Batch loss: 0.069700 Batch F1: 0.8750000000000001
Epoch:  988        8 Batch loss: 0.059115 Batch F1: 0.9473684210526316
Epoch:  988        9 Batch loss: 0.061966 Batch F1: 0.6666666666666666
Epoch:  988       10 Batch loss: 0.047723 Batch F1: 0.888888888888889
Epoch:  988       11 Batch loss: 0.068891 Batch F1: 0.8235294117647058
Epoch:  988       12 Batch loss: 0.085655 Batch F1: 0.8181818181818181
Train Avg Loss  988: 0.070652

Train Avg F1  988: 0.6386733042499296

Val Avg Loss  988: 0.063446

Val Avg F1  988:  0.8681512605042017

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 989
--------------------------------------------------------------
Epoch:  989        1 Batch loss: 0.065913 Batch F1: 0.9523809523809523
Epoch:  989        2 Batch loss: 0.065544 Batch F1: 0.9090909090909091
Epoch:  989        3 Batch loss: 0.077885 Batch F1: 0.4615384615384615
Epoch:  989        4 Batch loss: 0.087297 Batch F1: 0.5
Epoch:  989        5 Batch loss: 0.070709 Batch F1: 0.6
Epoch:  989        6 Batch loss: 0.079614 Batch F1: 0.3636363636363636
Epoch:  989        7 Batch loss: 0.090848 Batch F1: 0.5882352941176471
Epoch:  989        8 Batch loss: 0.061004 Batch F1: 0.8571428571428571
Epoch:  989        9 Batch loss: 0.048722 Batch F1: 1.0
Epoch:  989       10 Batch loss: 0.081154 Batch F1: 0.625
Epoch:  989       11 Batch loss: 0.052962 Batch F1: 0.7692307692307693
Epoch:  989       12 Batch loss: 0.071514 Batch F1: 0.9473684210526316
Train Avg Loss  989: 0.071097

Train Avg F1  989: 0.7144686690158827

Val Avg Loss  989: 0.067171

Val Avg F1  989:  0.9290441176470589

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 990
--------------------------------------------------------------
Epoch:  990        1 Batch loss: 0.066445 Batch F1: 0.923076923076923
Epoch:  990        2 Batch loss: 0.093926 Batch F1: 0.88
Epoch:  990        3 Batch loss: 0.085857 Batch F1: 1.0
Epoch:  990        4 Batch loss: 0.055518 Batch F1: 0.7499999999999999
Epoch:  990        5 Batch loss: 0.068672 Batch F1: 1.0
Epoch:  990        6 Batch loss: 0.075079 Batch F1: 0.4
Epoch:  990        7 Batch loss: 0.066684 Batch F1: 1.0
Epoch:  990        8 Batch loss: 0.050248 Batch F1: 0.923076923076923
Epoch:  990        9 Batch loss: 0.046656 Batch F1: 0.8571428571428571
Epoch:  990       10 Batch loss: 0.082652 Batch F1: 0.5882352941176471
Epoch:  990       11 Batch loss: 0.082985 Batch F1: 0.5
Epoch:  990       12 Batch loss: 0.061538 Batch F1: 0.9333333333333333
Train Avg Loss  990: 0.069688

Train Avg F1  990: 0.8129054442289737

Val Avg Loss  990: 0.062168

Val Avg F1  990:  0.9257309941520468

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 991
--------------------------------------------------------------
Epoch:  991        1 Batch loss: 0.087835 Batch F1: 0.888888888888889
Epoch:  991        2 Batch loss: 0.071734 Batch F1: 0.9523809523809523
Epoch:  991        3 Batch loss: 0.075478 Batch F1: 0.8750000000000001
Epoch:  991        4 Batch loss: 0.049811 Batch F1: 1.0
Epoch:  991        5 Batch loss: 0.060474 Batch F1: 0.5714285714285715
Epoch:  991        6 Batch loss: 0.092018 Batch F1: 0.5333333333333333
Epoch:  991        7 Batch loss: 0.068831 Batch F1: 0.6153846153846153
Epoch:  991        8 Batch loss: 0.061173 Batch F1: 0.5
Epoch:  991        9 Batch loss: 0.085628 Batch F1: 0.6363636363636364
Epoch:  991       10 Batch loss: 0.073948 Batch F1: 0.5333333333333333
Epoch:  991       11 Batch loss: 0.066196 Batch F1: 0.4
Epoch:  991       12 Batch loss: 0.056587 Batch F1: 1.0
Train Avg Loss  991: 0.070809

Train Avg F1  991: 0.7088427775927776

Val Avg Loss  991: 0.065197

Val Avg F1  991:  0.7443181818181819

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 992
--------------------------------------------------------------
Epoch:  992        1 Batch loss: 0.083056 Batch F1: 0.7368421052631579
Epoch:  992        2 Batch loss: 0.065958 Batch F1: 0.5454545454545454
Epoch:  992        3 Batch loss: 0.088231 Batch F1: 0.5714285714285715
Epoch:  992        4 Batch loss: 0.072002 Batch F1: 1.0
Epoch:  992        5 Batch loss: 0.058923 Batch F1: 1.0
Epoch:  992        6 Batch loss: 0.062236 Batch F1: 0.923076923076923
Epoch:  992        7 Batch loss: 0.122124 Batch F1: 0.4444444444444445
Epoch:  992        8 Batch loss: 0.076629 Batch F1: 0.888888888888889
Epoch:  992        9 Batch loss: 0.066778 Batch F1: 1.0
Epoch:  992       10 Batch loss: 0.052992 Batch F1: 1.0
Epoch:  992       11 Batch loss: 0.087592 Batch F1: 0.19999999999999998
Epoch:  992       12 Batch loss: 0.081870 Batch F1: 0.0
Train Avg Loss  992: 0.076532

Train Avg F1  992: 0.692511289879711

Val Avg Loss  992: 0.066330

Val Avg F1  992:  0.5276785714285714

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 993
--------------------------------------------------------------
Epoch:  993        1 Batch loss: 0.096873 Batch F1: 0.4
Epoch:  993        2 Batch loss: 0.108111 Batch F1: 0.7142857142857143
Epoch:  993        3 Batch loss: 0.058944 Batch F1: 0.4444444444444445
Epoch:  993        4 Batch loss: 0.052943 Batch F1: 0.5714285714285715
Epoch:  993        5 Batch loss: 0.075154 Batch F1: 0.0
Epoch:  993        6 Batch loss: 0.060198 Batch F1: 0.4444444444444445
Epoch:  993        7 Batch loss: 0.086371 Batch F1: 0.5714285714285715
Epoch:  993        8 Batch loss: 0.060584 Batch F1: 0.8571428571428571
Epoch:  993        9 Batch loss: 0.062020 Batch F1: 0.888888888888889
Epoch:  993       10 Batch loss: 0.084353 Batch F1: 0.6666666666666666
Epoch:  993       11 Batch loss: 0.095987 Batch F1: 0.8695652173913044
Epoch:  993       12 Batch loss: 0.067537 Batch F1: 0.9090909090909091
Train Avg Loss  993: 0.075756

Train Avg F1  993: 0.6114488571010311

Val Avg Loss  993: 0.064736

Val Avg F1  993:  0.9166040100250628

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 994
--------------------------------------------------------------
Epoch:  994        1 Batch loss: 0.062262 Batch F1: 0.9090909090909091
Epoch:  994        2 Batch loss: 0.064544 Batch F1: 0.4
Epoch:  994        3 Batch loss: 0.097990 Batch F1: 0.5882352941176471
Epoch:  994        4 Batch loss: 0.055072 Batch F1: 1.0
Epoch:  994        5 Batch loss: 0.071958 Batch F1: 0.9
Epoch:  994        6 Batch loss: 0.088101 Batch F1: 0.875
Epoch:  994        7 Batch loss: 0.079740 Batch F1: 0.8571428571428571
Epoch:  994        8 Batch loss: 0.076180 Batch F1: 0.5454545454545454
Epoch:  994        9 Batch loss: 0.072439 Batch F1: 1.0
Epoch:  994       10 Batch loss: 0.056929 Batch F1: 0.5454545454545454
Epoch:  994       11 Batch loss: 0.082776 Batch F1: 0.5
Epoch:  994       12 Batch loss: 0.101833 Batch F1: 0.5333333333333333
Train Avg Loss  994: 0.075819

Train Avg F1  994: 0.721142623716153

Val Avg Loss  994: 0.062436

Val Avg F1  994:  0.8804029304029304

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 995
--------------------------------------------------------------
Epoch:  995        1 Batch loss: 0.050939 Batch F1: 0.9090909090909091
Epoch:  995        2 Batch loss: 0.082254 Batch F1: 0.7777777777777778
Epoch:  995        3 Batch loss: 0.073611 Batch F1: 0.7777777777777778
Epoch:  995        4 Batch loss: 0.062572 Batch F1: 0.6666666666666666
Epoch:  995        5 Batch loss: 0.066189 Batch F1: 0.6666666666666666
Epoch:  995        6 Batch loss: 0.077146 Batch F1: 0.6153846153846153
Epoch:  995        7 Batch loss: 0.078407 Batch F1: 0.33333333333333337
Epoch:  995        8 Batch loss: 0.092344 Batch F1: 0.9
Epoch:  995        9 Batch loss: 0.088483 Batch F1: 0.9600000000000001
Epoch:  995       10 Batch loss: 0.083255 Batch F1: 0.7499999999999999
Epoch:  995       11 Batch loss: 0.069620 Batch F1: 1.0
Epoch:  995       12 Batch loss: 0.090456 Batch F1: 0.5333333333333333
Train Avg Loss  995: 0.076273

Train Avg F1  995: 0.7408359233359233

Val Avg Loss  995: 0.064078

Val Avg F1  995:  0.5737179487179487

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 996
--------------------------------------------------------------
Epoch:  996        1 Batch loss: 0.077646 Batch F1: 0.4
Epoch:  996        2 Batch loss: 0.082715 Batch F1: 0.4615384615384615
Epoch:  996        3 Batch loss: 0.054032 Batch F1: 0.0
Epoch:  996        4 Batch loss: 0.064554 Batch F1: 0.6666666666666666
Epoch:  996        5 Batch loss: 0.060278 Batch F1: 0.4444444444444445
Epoch:  996        6 Batch loss: 0.075685 Batch F1: 0.5714285714285715
Epoch:  996        7 Batch loss: 0.066524 Batch F1: 0.7499999999999999
Epoch:  996        8 Batch loss: 0.069805 Batch F1: 0.3636363636363636
Epoch:  996        9 Batch loss: 0.083619 Batch F1: 0.5714285714285715
Epoch:  996       10 Batch loss: 0.085554 Batch F1: 0.9166666666666666
Epoch:  996       11 Batch loss: 0.072466 Batch F1: 1.0
Epoch:  996       12 Batch loss: 0.058996 Batch F1: 1.0
Train Avg Loss  996: 0.070989

Train Avg F1  996: 0.5954841454841455

Val Avg Loss  996: 0.063125

Val Avg F1  996:  0.9232034412955465

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 997
--------------------------------------------------------------
Epoch:  997        1 Batch loss: 0.065273 Batch F1: 1.0
Epoch:  997        2 Batch loss: 0.070040 Batch F1: 0.4615384615384615
Epoch:  997        3 Batch loss: 0.081562 Batch F1: 0.19999999999999998
Epoch:  997        4 Batch loss: 0.042154 Batch F1: 0.0
Epoch:  997        5 Batch loss: 0.090411 Batch F1: 0.4
Epoch:  997        6 Batch loss: 0.052919 Batch F1: 0.5
Epoch:  997        7 Batch loss: 0.091072 Batch F1: 0.5
Epoch:  997        8 Batch loss: 0.062062 Batch F1: 0.9411764705882353
Epoch:  997        9 Batch loss: 0.073061 Batch F1: 0.8695652173913044
Epoch:  997       10 Batch loss: 0.073324 Batch F1: 1.0
Epoch:  997       11 Batch loss: 0.072977 Batch F1: 0.9411764705882353
Epoch:  997       12 Batch loss: 0.059880 Batch F1: 1.0
Train Avg Loss  997: 0.069561

Train Avg F1  997: 0.6511213850088531

Val Avg Loss  997: 0.062866

Val Avg F1  997:  0.9068452380952381

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 998
--------------------------------------------------------------
Epoch:  998        1 Batch loss: 0.061485 Batch F1: 0.888888888888889
Epoch:  998        2 Batch loss: 0.070064 Batch F1: 0.9473684210526316
Epoch:  998        3 Batch loss: 0.068723 Batch F1: 0.888888888888889
Epoch:  998        4 Batch loss: 0.081278 Batch F1: 0.6666666666666666
Epoch:  998        5 Batch loss: 0.086560 Batch F1: 0.3076923076923077
Epoch:  998        6 Batch loss: 0.062832 Batch F1: 0.8333333333333333
Epoch:  998        7 Batch loss: 0.080639 Batch F1: 0.8
Epoch:  998        8 Batch loss: 0.068322 Batch F1: 0.888888888888889
Epoch:  998        9 Batch loss: 0.072241 Batch F1: 0.9411764705882353
Epoch:  998       10 Batch loss: 0.073674 Batch F1: 0.8
Epoch:  998       11 Batch loss: 0.056034 Batch F1: 1.0
Epoch:  998       12 Batch loss: 0.050873 Batch F1: 1.0
Train Avg Loss  998: 0.069394

Train Avg F1  998: 0.8302419888333201

Val Avg Loss  998: 0.062892

Val Avg F1  998:  0.9182692307692307

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 999
--------------------------------------------------------------
Epoch:  999        1 Batch loss: 0.106922 Batch F1: 0.9444444444444444
Epoch:  999        2 Batch loss: 0.064665 Batch F1: 0.9333333333333333
Epoch:  999        3 Batch loss: 0.068422 Batch F1: 0.8235294117647058
Epoch:  999        4 Batch loss: 0.058884 Batch F1: 0.9333333333333333
Epoch:  999        5 Batch loss: 0.053426 Batch F1: 1.0
Epoch:  999        6 Batch loss: 0.078976 Batch F1: 0.9523809523809523
Epoch:  999        7 Batch loss: 0.050950 Batch F1: 0.9333333333333333
Epoch:  999        8 Batch loss: 0.078170 Batch F1: 0.8750000000000001
Epoch:  999        9 Batch loss: 0.077329 Batch F1: 0.6666666666666666
Epoch:  999       10 Batch loss: 0.048334 Batch F1: 0.8
Epoch:  999       11 Batch loss: 0.079849 Batch F1: 0.5882352941176471
Epoch:  999       12 Batch loss: 0.054973 Batch F1: 0.5
Train Avg Loss  999: 0.068408

Train Avg F1  999: 0.8291880641145348

Val Avg Loss  999: 0.064381

Val Avg F1  999:  0.5251196172248804

Optimal Val loss (Epoch 448): 0.060577317140996456

Epoch 1000
--------------------------------------------------------------
Epoch: 1000        1 Batch loss: 0.066628 Batch F1: 0.625
Epoch: 1000        2 Batch loss: 0.075532 Batch F1: 0.5333333333333333
Epoch: 1000        3 Batch loss: 0.062953 Batch F1: 0.4444444444444445
Epoch: 1000        4 Batch loss: 0.045591 Batch F1: 1.0
Epoch: 1000        5 Batch loss: 0.087082 Batch F1: 0.19999999999999998
Epoch: 1000        6 Batch loss: 0.083123 Batch F1: 0.5333333333333333
Epoch: 1000        7 Batch loss: 0.058688 Batch F1: 0.9411764705882353
Epoch: 1000        8 Batch loss: 0.077721 Batch F1: 0.8
Epoch: 1000        9 Batch loss: 0.075524 Batch F1: 1.0
Epoch: 1000       10 Batch loss: 0.075430 Batch F1: 0.9473684210526316
Epoch: 1000       11 Batch loss: 0.051327 Batch F1: 1.0
Epoch: 1000       12 Batch loss: 0.070892 Batch F1: 0.6153846153846153
Train Avg Loss 1000: 0.069208

Train Avg F1 1000: 0.7200033848447162

Val Avg Loss 1000: 0.062390

Val Avg F1 1000:  0.5166666666666667

Optimal Val loss (Epoch 448): 0.060577317140996456

Done!
