Removed 3 of 595
Removed 0 of 198
Removed 0 of 198
Model with variable positions in join nodes
Loss function: MSELoss
Optimizer: LR [0.01] weight decay [0.0005]
Epoch 1
--------------------------------------------------------------
Epoch:    1        1 Batch loss: 0.249517 Batch F1: 0.0
Epoch:    1        2 Batch loss: 0.235462 Batch F1: 0.0
Epoch:    1        3 Batch loss: 0.258935 Batch F1: 0.0
Epoch:    1        4 Batch loss: 0.274569 Batch F1: 0.0
Epoch:    1        5 Batch loss: 0.251794 Batch F1: 0.0
Epoch:    1        6 Batch loss: 0.253113 Batch F1: 0.6111111111111112
Epoch:    1        7 Batch loss: 0.254401 Batch F1: 0.6111111111111112
Epoch:    1        8 Batch loss: 0.252047 Batch F1: 0.6111111111111112
Epoch:    1        9 Batch loss: 0.249399 Batch F1: 0.16
Epoch:    1       10 Batch loss: 0.248286 Batch F1: 0.0
Epoch:    1       11 Batch loss: 0.246337 Batch F1: 0.0
Epoch:    1       12 Batch loss: 0.247997 Batch F1: 0.0
Train Avg Loss    1: 0.251821

Train Avg F1    1: 0.16611111111111113

Val Avg Loss    1: 0.253274

Val Avg F1    1:  0.0

Optimal Val loss (Epoch 1): 0.2532743774354458

Epoch 2
--------------------------------------------------------------
Epoch:    2        1 Batch loss: 0.237664 Batch F1: 0.0
Epoch:    2        2 Batch loss: 0.254041 Batch F1: 0.0
Epoch:    2        3 Batch loss: 0.250729 Batch F1: 0.0
Epoch:    2        4 Batch loss: 0.233743 Batch F1: 0.0
Epoch:    2        5 Batch loss: 0.270110 Batch F1: 0.0
Epoch:    2        6 Batch loss: 0.238464 Batch F1: 0.0
Epoch:    2        7 Batch loss: 0.254435 Batch F1: 0.0
Epoch:    2        8 Batch loss: 0.247360 Batch F1: 0.0
Epoch:    2        9 Batch loss: 0.248431 Batch F1: 0.0
Epoch:    2       10 Batch loss: 0.249479 Batch F1: 0.07407407407407407
Epoch:    2       11 Batch loss: 0.247912 Batch F1: 0.7058823529411764
Epoch:    2       12 Batch loss: 0.272617 Batch F1: 0.32
Train Avg Loss    2: 0.250415

Train Avg F1    2: 0.0916630355846042

Val Avg Loss    2: 0.248424

Val Avg F1    2:  0.655981362344241

Optimal Val loss (Epoch 2): 0.2484239675104618

Epoch 3
--------------------------------------------------------------
Epoch:    3        1 Batch loss: 0.249271 Batch F1: 0.5185185185185185
Epoch:    3        2 Batch loss: 0.252895 Batch F1: 0.0
Epoch:    3        3 Batch loss: 0.232397 Batch F1: 0.0
Epoch:    3        4 Batch loss: 0.252813 Batch F1: 0.0
Epoch:    3        5 Batch loss: 0.258758 Batch F1: 0.0
Epoch:    3        6 Batch loss: 0.239477 Batch F1: 0.0
Epoch:    3        7 Batch loss: 0.287738 Batch F1: 0.0
Epoch:    3        8 Batch loss: 0.272728 Batch F1: 0.0
Epoch:    3        9 Batch loss: 0.261626 Batch F1: 0.0
Epoch:    3       10 Batch loss: 0.234554 Batch F1: 0.0
Epoch:    3       11 Batch loss: 0.240794 Batch F1: 0.0
Epoch:    3       12 Batch loss: 0.238113 Batch F1: 0.0
Train Avg Loss    3: 0.251764

Train Avg F1    3: 0.043209876543209874

Val Avg Loss    3: 0.250095

Val Avg F1    3:  0.0

Optimal Val loss (Epoch 2): 0.2484239675104618

Epoch 4
--------------------------------------------------------------
Epoch:    4        1 Batch loss: 0.249667 Batch F1: 0.0
Epoch:    4        2 Batch loss: 0.246661 Batch F1: 0.0
Epoch:    4        3 Batch loss: 0.254075 Batch F1: 0.0
Epoch:    4        4 Batch loss: 0.252217 Batch F1: 0.0
Epoch:    4        5 Batch loss: 0.252763 Batch F1: 0.0
Epoch:    4        6 Batch loss: 0.245347 Batch F1: 0.0
Epoch:    4        7 Batch loss: 0.245873 Batch F1: 0.0
Epoch:    4        8 Batch loss: 0.244750 Batch F1: 0.0
Epoch:    4        9 Batch loss: 0.251332 Batch F1: 0.0
Epoch:    4       10 Batch loss: 0.244410 Batch F1: 0.0
Epoch:    4       11 Batch loss: 0.243899 Batch F1: 0.0
Epoch:    4       12 Batch loss: 0.247436 Batch F1: 0.0
Train Avg Loss    4: 0.248202

Train Avg F1    4: 0.0

Val Avg Loss    4: 0.251067

Val Avg F1    4:  0.0

Optimal Val loss (Epoch 2): 0.2484239675104618

Epoch 5
--------------------------------------------------------------
Epoch:    5        1 Batch loss: 0.261246 Batch F1: 0.0
Epoch:    5        2 Batch loss: 0.246249 Batch F1: 0.0
Epoch:    5        3 Batch loss: 0.246134 Batch F1: 0.0
Epoch:    5        4 Batch loss: 0.250635 Batch F1: 0.0
Epoch:    5        5 Batch loss: 0.243800 Batch F1: 0.0
Epoch:    5        6 Batch loss: 0.223008 Batch F1: 0.0
Epoch:    5        7 Batch loss: 0.251477 Batch F1: 0.0
Epoch:    5        8 Batch loss: 0.254564 Batch F1: 0.0
Epoch:    5        9 Batch loss: 0.251863 Batch F1: 0.0
Epoch:    5       10 Batch loss: 0.251628 Batch F1: 0.0
Epoch:    5       11 Batch loss: 0.248251 Batch F1: 0.0
Epoch:    5       12 Batch loss: 0.240448 Batch F1: 0.0
Train Avg Loss    5: 0.247442

Train Avg F1    5: 0.0

Val Avg Loss    5: 0.250343

Val Avg F1    5:  0.0

Optimal Val loss (Epoch 2): 0.2484239675104618

Epoch 6
--------------------------------------------------------------
Epoch:    6        1 Batch loss: 0.244138 Batch F1: 0.0
Epoch:    6        2 Batch loss: 0.241009 Batch F1: 0.0
Epoch:    6        3 Batch loss: 0.239761 Batch F1: 0.0
Epoch:    6        4 Batch loss: 0.258065 Batch F1: 0.0
Epoch:    6        5 Batch loss: 0.243448 Batch F1: 0.08695652173913045
Epoch:    6        6 Batch loss: 0.242671 Batch F1: 0.6521739130434783
Epoch:    6        7 Batch loss: 0.243212 Batch F1: 0.41025641025641024
Epoch:    6        8 Batch loss: 0.247585 Batch F1: 0.48484848484848486
Epoch:    6        9 Batch loss: 0.236409 Batch F1: 0.3846153846153846
Epoch:    6       10 Batch loss: 0.250248 Batch F1: 0.14285714285714288
Epoch:    6       11 Batch loss: 0.247039 Batch F1: 0.4
Epoch:    6       12 Batch loss: 0.233967 Batch F1: 0.5217391304347826
Train Avg Loss    6: 0.243963

Train Avg F1    6: 0.2569539156495678

Val Avg Loss    6: 0.241774

Val Avg F1    6:  0.23384103125482436

Optimal Val loss (Epoch 6): 0.24177438765764236

Epoch 7
--------------------------------------------------------------
Epoch:    7        1 Batch loss: 0.239873 Batch F1: 0.3888888888888889
Epoch:    7        2 Batch loss: 0.234730 Batch F1: 0.42424242424242425
Epoch:    7        3 Batch loss: 0.240492 Batch F1: 0.47619047619047616
Epoch:    7        4 Batch loss: 0.226607 Batch F1: 0.611111111111111
Epoch:    7        5 Batch loss: 0.226649 Batch F1: 0.5
Epoch:    7        6 Batch loss: 0.243723 Batch F1: 0.6153846153846153
Epoch:    7        7 Batch loss: 0.239022 Batch F1: 0.3902439024390244
Epoch:    7        8 Batch loss: 0.240453 Batch F1: 0.5333333333333332
Epoch:    7        9 Batch loss: 0.242710 Batch F1: 0.380952380952381
Epoch:    7       10 Batch loss: 0.225547 Batch F1: 0.3846153846153846
Epoch:    7       11 Batch loss: 0.245283 Batch F1: 0.0
Epoch:    7       12 Batch loss: 0.256658 Batch F1: 0.29629629629629634
Train Avg Loss    7: 0.238479

Train Avg F1    7: 0.41677156778782803

Val Avg Loss    7: 0.239719

Val Avg F1    7:  0.5950961414376048

Optimal Val loss (Epoch 7): 0.23971917107701302

Epoch 8
--------------------------------------------------------------
Epoch:    8        1 Batch loss: 0.205746 Batch F1: 0.787878787878788
Epoch:    8        2 Batch loss: 0.245888 Batch F1: 0.35
Epoch:    8        3 Batch loss: 0.237911 Batch F1: 0.39999999999999997
Epoch:    8        4 Batch loss: 0.223088 Batch F1: 0.47368421052631576
Epoch:    8        5 Batch loss: 0.257336 Batch F1: 0.5405405405405406
Epoch:    8        6 Batch loss: 0.248427 Batch F1: 0.40909090909090917
Epoch:    8        7 Batch loss: 0.237081 Batch F1: 0.5660377358490566
Epoch:    8        8 Batch loss: 0.216409 Batch F1: 0.7450980392156863
Epoch:    8        9 Batch loss: 0.240791 Batch F1: 0.5116279069767442
Epoch:    8       10 Batch loss: 0.235695 Batch F1: 0.5454545454545454
Epoch:    8       11 Batch loss: 0.225758 Batch F1: 0.6153846153846153
Epoch:    8       12 Batch loss: 0.211804 Batch F1: 0.43749999999999994
Train Avg Loss    8: 0.232161

Train Avg F1    8: 0.5318581075764334

Val Avg Loss    8: 0.231265

Val Avg F1    8:  0.5286377708978328

Optimal Val loss (Epoch 8): 0.2312653549015522

Epoch 9
--------------------------------------------------------------
Epoch:    9        1 Batch loss: 0.212890 Batch F1: 0.5853658536585366
Epoch:    9        2 Batch loss: 0.244161 Batch F1: 0.45
Epoch:    9        3 Batch loss: 0.214229 Batch F1: 0.7419354838709677
Epoch:    9        4 Batch loss: 0.246598 Batch F1: 0.576923076923077
Epoch:    9        5 Batch loss: 0.233849 Batch F1: 0.6181818181818183
Epoch:    9        6 Batch loss: 0.227130 Batch F1: 0.6666666666666666
Epoch:    9        7 Batch loss: 0.221707 Batch F1: 0.5365853658536585
Epoch:    9        8 Batch loss: 0.223378 Batch F1: 0.3125
Epoch:    9        9 Batch loss: 0.233427 Batch F1: 0.5384615384615384
Epoch:    9       10 Batch loss: 0.247683 Batch F1: 0.0
Epoch:    9       11 Batch loss: 0.245349 Batch F1: 0.3076923076923077
Epoch:    9       12 Batch loss: 0.239440 Batch F1: 0.5161290322580645
Train Avg Loss    9: 0.232487

Train Avg F1    9: 0.4875367619638862

Val Avg Loss    9: 0.233405

Val Avg F1    9:  0.6067466413088531

Optimal Val loss (Epoch 8): 0.2312653549015522

Epoch 10
--------------------------------------------------------------
Epoch:   10        1 Batch loss: 0.224050 Batch F1: 0.608695652173913
Epoch:   10        2 Batch loss: 0.209299 Batch F1: 0.6086956521739131
Epoch:   10        3 Batch loss: 0.254506 Batch F1: 0.4897959183673469
Epoch:   10        4 Batch loss: 0.231162 Batch F1: 0.5777777777777778
Epoch:   10        5 Batch loss: 0.230686 Batch F1: 0.5777777777777778
Epoch:   10        6 Batch loss: 0.240040 Batch F1: 0.4186046511627907
Epoch:   10        7 Batch loss: 0.225278 Batch F1: 0.5263157894736841
Epoch:   10        8 Batch loss: 0.208649 Batch F1: 0.7843137254901961
Epoch:   10        9 Batch loss: 0.237957 Batch F1: 0.6086956521739131
Epoch:   10       10 Batch loss: 0.227235 Batch F1: 0.68
Epoch:   10       11 Batch loss: 0.225570 Batch F1: 0.6153846153846153
Epoch:   10       12 Batch loss: 0.225391 Batch F1: 0.5161290322580646
Train Avg Loss   10: 0.228319

Train Avg F1   10: 0.5843488536844994

Val Avg Loss   10: 0.240814

Val Avg F1   10:  0.23357954545454546

Optimal Val loss (Epoch 8): 0.2312653549015522

Epoch 11
--------------------------------------------------------------
Epoch:   11        1 Batch loss: 0.191570 Batch F1: 0.2608695652173913
Epoch:   11        2 Batch loss: 0.262152 Batch F1: 0.14285714285714288
Epoch:   11        3 Batch loss: 0.232250 Batch F1: 0.37499999999999994
Epoch:   11        4 Batch loss: 0.205345 Batch F1: 0.6976744186046512
Epoch:   11        5 Batch loss: 0.219318 Batch F1: 0.6956521739130435
Epoch:   11        6 Batch loss: 0.231288 Batch F1: 0.6122448979591836
Epoch:   11        7 Batch loss: 0.242130 Batch F1: 0.5882352941176471
Epoch:   11        8 Batch loss: 0.228800 Batch F1: 0.625
Epoch:   11        9 Batch loss: 0.251337 Batch F1: 0.42857142857142855
Epoch:   11       10 Batch loss: 0.212245 Batch F1: 0.6808510638297872
Epoch:   11       11 Batch loss: 0.228927 Batch F1: 0.553191489361702
Epoch:   11       12 Batch loss: 0.229084 Batch F1: 0.6
Train Avg Loss   11: 0.227870

Train Avg F1   11: 0.5216789562026648

Val Avg Loss   11: 0.225220

Val Avg F1   11:  0.65930555865511

Optimal Val loss (Epoch 11): 0.2252202033996582

Epoch 12
--------------------------------------------------------------
Epoch:   12        1 Batch loss: 0.247617 Batch F1: 0.56
Epoch:   12        2 Batch loss: 0.200202 Batch F1: 0.6666666666666666
Epoch:   12        3 Batch loss: 0.227064 Batch F1: 0.736842105263158
Epoch:   12        4 Batch loss: 0.222462 Batch F1: 0.6666666666666667
Epoch:   12        5 Batch loss: 0.221208 Batch F1: 0.7111111111111111
Epoch:   12        6 Batch loss: 0.220104 Batch F1: 0.6046511627906976
Epoch:   12        7 Batch loss: 0.212497 Batch F1: 0.3225806451612903
Epoch:   12        8 Batch loss: 0.222220 Batch F1: 0.2727272727272727
Epoch:   12        9 Batch loss: 0.318866 Batch F1: 0.0
Epoch:   12       10 Batch loss: 0.257233 Batch F1: 0.14285714285714288
Epoch:   12       11 Batch loss: 0.223674 Batch F1: 0.5
Epoch:   12       12 Batch loss: 0.229402 Batch F1: 0.6666666666666667
Train Avg Loss   12: 0.233546

Train Avg F1   12: 0.48756411999255606

Val Avg Loss   12: 0.248446

Val Avg F1   12:  0.6826950826950827

Optimal Val loss (Epoch 11): 0.2252202033996582

Epoch 13
--------------------------------------------------------------
Epoch:   13        1 Batch loss: 0.218232 Batch F1: 0.7466666666666666
Epoch:   13        2 Batch loss: 0.256179 Batch F1: 0.6229508196721312
Epoch:   13        3 Batch loss: 0.240580 Batch F1: 0.7384615384615385
Epoch:   13        4 Batch loss: 0.220220 Batch F1: 0.4615384615384615
Epoch:   13        5 Batch loss: 0.189200 Batch F1: 0.5185185185185186
Epoch:   13        6 Batch loss: 0.192561 Batch F1: 0.56
Epoch:   13        7 Batch loss: 0.240438 Batch F1: 0.0
Epoch:   13        8 Batch loss: 0.286899 Batch F1: 0.0
Epoch:   13        9 Batch loss: 0.263460 Batch F1: 0.3870967741935484
Epoch:   13       10 Batch loss: 0.252237 Batch F1: 0.358974358974359
Epoch:   13       11 Batch loss: 0.249536 Batch F1: 0.5454545454545454
Epoch:   13       12 Batch loss: 0.282997 Batch F1: 0.576271186440678
Train Avg Loss   13: 0.241045

Train Avg F1   13: 0.4596610724933705

Val Avg Loss   13: 0.250336

Val Avg F1   13:  0.6595318910459756

Optimal Val loss (Epoch 11): 0.2252202033996582

Epoch 14
--------------------------------------------------------------
Epoch:   14        1 Batch loss: 0.255507 Batch F1: 0.5882352941176471
Epoch:   14        2 Batch loss: 0.226707 Batch F1: 0.5714285714285715
Epoch:   14        3 Batch loss: 0.248518 Batch F1: 0.3
Epoch:   14        4 Batch loss: 0.221035 Batch F1: 0.6857142857142856
Epoch:   14        5 Batch loss: 0.245213 Batch F1: 0.07142857142857142
Epoch:   14        6 Batch loss: 0.248681 Batch F1: 0.0
Epoch:   14        7 Batch loss: 0.249018 Batch F1: 0.07407407407407407
Epoch:   14        8 Batch loss: 0.215632 Batch F1: 0.5925925925925926
Epoch:   14        9 Batch loss: 0.233389 Batch F1: 0.5333333333333333
Epoch:   14       10 Batch loss: 0.221574 Batch F1: 0.6190476190476191
Epoch:   14       11 Batch loss: 0.238318 Batch F1: 0.55
Epoch:   14       12 Batch loss: 0.226336 Batch F1: 0.41379310344827586
Train Avg Loss   14: 0.235827

Train Avg F1   14: 0.41663728709874753

Val Avg Loss   14: 0.232426

Val Avg F1   14:  0.47324173411129933

Optimal Val loss (Epoch 11): 0.2252202033996582

Epoch 15
--------------------------------------------------------------
Epoch:   15        1 Batch loss: 0.240655 Batch F1: 0.4444444444444444
Epoch:   15        2 Batch loss: 0.227038 Batch F1: 0.5263157894736842
Epoch:   15        3 Batch loss: 0.219633 Batch F1: 0.4761904761904762
Epoch:   15        4 Batch loss: 0.222889 Batch F1: 0.4878048780487805
Epoch:   15        5 Batch loss: 0.243680 Batch F1: 0.5499999999999999
Epoch:   15        6 Batch loss: 0.229629 Batch F1: 0.5789473684210527
Epoch:   15        7 Batch loss: 0.199865 Batch F1: 0.6829268292682927
Epoch:   15        8 Batch loss: 0.217118 Batch F1: 0.5405405405405406
Epoch:   15        9 Batch loss: 0.240773 Batch F1: 0.625
Epoch:   15       10 Batch loss: 0.227838 Batch F1: 0.6666666666666666
Epoch:   15       11 Batch loss: 0.250404 Batch F1: 0.425531914893617
Epoch:   15       12 Batch loss: 0.233439 Batch F1: 0.6341463414634146
Train Avg Loss   15: 0.229413

Train Avg F1   15: 0.5532096041175808

Val Avg Loss   15: 0.229881

Val Avg F1   15:  0.6793299373040751

Optimal Val loss (Epoch 11): 0.2252202033996582

Epoch 16
--------------------------------------------------------------
Epoch:   16        1 Batch loss: 0.210667 Batch F1: 0.7916666666666667
Epoch:   16        2 Batch loss: 0.237107 Batch F1: 0.6122448979591837
Epoch:   16        3 Batch loss: 0.214523 Batch F1: 0.3571428571428571
Epoch:   16        4 Batch loss: 0.215488 Batch F1: 0.4827586206896552
Epoch:   16        5 Batch loss: 0.235192 Batch F1: 0.2758620689655173
Epoch:   16        6 Batch loss: 0.239871 Batch F1: 0.0909090909090909
Epoch:   16        7 Batch loss: 0.259430 Batch F1: 0.5161290322580645
Epoch:   16        8 Batch loss: 0.241233 Batch F1: 0.47058823529411764
Epoch:   16        9 Batch loss: 0.201697 Batch F1: 0.606060606060606
Epoch:   16       10 Batch loss: 0.252580 Batch F1: 0.41666666666666663
Epoch:   16       11 Batch loss: 0.216131 Batch F1: 0.6521739130434783
Epoch:   16       12 Batch loss: 0.216614 Batch F1: 0.7659574468085107
Train Avg Loss   16: 0.228378

Train Avg F1   16: 0.5031800085387013

Val Avg Loss   16: 0.228072

Val Avg F1   16:  0.6724927371479095

Optimal Val loss (Epoch 11): 0.2252202033996582

Epoch 17
--------------------------------------------------------------
Epoch:   17        1 Batch loss: 0.226143 Batch F1: 0.6153846153846153
Epoch:   17        2 Batch loss: 0.216445 Batch F1: 0.6
Epoch:   17        3 Batch loss: 0.231367 Batch F1: 0.5957446808510638
Epoch:   17        4 Batch loss: 0.223069 Batch F1: 0.6363636363636364
Epoch:   17        5 Batch loss: 0.241482 Batch F1: 0.6382978723404256
Epoch:   17        6 Batch loss: 0.222937 Batch F1: 0.5116279069767442
Epoch:   17        7 Batch loss: 0.227596 Batch F1: 0.6206896551724138
Epoch:   17        8 Batch loss: 0.218025 Batch F1: 0.7142857142857142
Epoch:   17        9 Batch loss: 0.217617 Batch F1: 0.6785714285714286
Epoch:   17       10 Batch loss: 0.242925 Batch F1: 0.5531914893617021
Epoch:   17       11 Batch loss: 0.216432 Batch F1: 0.4375
Epoch:   17       12 Batch loss: 0.212811 Batch F1: 0.2727272727272727
Train Avg Loss   17: 0.224737

Train Avg F1   17: 0.5728653560029181

Val Avg Loss   17: 0.232685

Val Avg F1   17:  0.38083566760037346

Optimal Val loss (Epoch 11): 0.2252202033996582

Epoch 18
--------------------------------------------------------------
Epoch:   18        1 Batch loss: 0.203368 Batch F1: 0.4571428571428572
Epoch:   18        2 Batch loss: 0.219211 Batch F1: 0.5853658536585367
Epoch:   18        3 Batch loss: 0.259440 Batch F1: 0.42857142857142855
Epoch:   18        4 Batch loss: 0.231728 Batch F1: 0.625
Epoch:   18        5 Batch loss: 0.239636 Batch F1: 0.5777777777777778
Epoch:   18        6 Batch loss: 0.235704 Batch F1: 0.5652173913043479
Epoch:   18        7 Batch loss: 0.204689 Batch F1: 0.7307692307692307
Epoch:   18        8 Batch loss: 0.225764 Batch F1: 0.5833333333333334
Epoch:   18        9 Batch loss: 0.228595 Batch F1: 0.6153846153846153
Epoch:   18       10 Batch loss: 0.228620 Batch F1: 0.34285714285714286
Epoch:   18       11 Batch loss: 0.214537 Batch F1: 0.6511627906976745
Epoch:   18       12 Batch loss: 0.234103 Batch F1: 0.631578947368421
Train Avg Loss   18: 0.227116

Train Avg F1   18: 0.5661801140721138

Val Avg Loss   18: 0.227078

Val Avg F1   18:  0.49201105174942383

Optimal Val loss (Epoch 11): 0.2252202033996582

Epoch 19
--------------------------------------------------------------
Epoch:   19        1 Batch loss: 0.203583 Batch F1: 0.4666666666666667
Epoch:   19        2 Batch loss: 0.249550 Batch F1: 0.2285714285714286
Epoch:   19        3 Batch loss: 0.238755 Batch F1: 0.4324324324324324
Epoch:   19        4 Batch loss: 0.215249 Batch F1: 0.5555555555555556
Epoch:   19        5 Batch loss: 0.233500 Batch F1: 0.7547169811320755
Epoch:   19        6 Batch loss: 0.200828 Batch F1: 0.75
Epoch:   19        7 Batch loss: 0.242695 Batch F1: 0.5555555555555556
Epoch:   19        8 Batch loss: 0.236999 Batch F1: 0.6101694915254238
Epoch:   19        9 Batch loss: 0.206785 Batch F1: 0.6296296296296297
Epoch:   19       10 Batch loss: 0.199385 Batch F1: 0.6190476190476191
Epoch:   19       11 Batch loss: 0.218227 Batch F1: 0.5625000000000001
Epoch:   19       12 Batch loss: 0.221113 Batch F1: 0.6111111111111113
Train Avg Loss   19: 0.222222

Train Avg F1   19: 0.5646630392689581

Val Avg Loss   19: 0.224774

Val Avg F1   19:  0.4521464646464647

Optimal Val loss (Epoch 19): 0.22477355226874352

Epoch 20
--------------------------------------------------------------
Epoch:   20        1 Batch loss: 0.227941 Batch F1: 0.5116279069767441
Epoch:   20        2 Batch loss: 0.211364 Batch F1: 0.5
Epoch:   20        3 Batch loss: 0.241520 Batch F1: 0.56
Epoch:   20        4 Batch loss: 0.208278 Batch F1: 0.7222222222222222
Epoch:   20        5 Batch loss: 0.219374 Batch F1: 0.7142857142857143
Epoch:   20        6 Batch loss: 0.240467 Batch F1: 0.5116279069767442
Epoch:   20        7 Batch loss: 0.211364 Batch F1: 0.6938775510204083
Epoch:   20        8 Batch loss: 0.188357 Batch F1: 0.7317073170731708
Epoch:   20        9 Batch loss: 0.220522 Batch F1: 0.4571428571428571
Epoch:   20       10 Batch loss: 0.259853 Batch F1: 0.4888888888888889
Epoch:   20       11 Batch loss: 0.208354 Batch F1: 0.5
Epoch:   20       12 Batch loss: 0.203982 Batch F1: 0.5714285714285715
Train Avg Loss   20: 0.220115

Train Avg F1   20: 0.5802340780012768

Val Avg Loss   20: 0.218199

Val Avg F1   20:  0.6130197322057787

Optimal Val loss (Epoch 20): 0.21819939464330673

Epoch 21
--------------------------------------------------------------
Epoch:   21        1 Batch loss: 0.194269 Batch F1: 0.5
Epoch:   21        2 Batch loss: 0.248597 Batch F1: 0.41025641025641024
Epoch:   21        3 Batch loss: 0.205358 Batch F1: 0.5365853658536585
Epoch:   21        4 Batch loss: 0.220991 Batch F1: 0.5128205128205129
Epoch:   21        5 Batch loss: 0.242117 Batch F1: 0.38888888888888895
Epoch:   21        6 Batch loss: 0.215985 Batch F1: 0.6
Epoch:   21        7 Batch loss: 0.206813 Batch F1: 0.7499999999999999
Epoch:   21        8 Batch loss: 0.191143 Batch F1: 0.7843137254901961
Epoch:   21        9 Batch loss: 0.222670 Batch F1: 0.5714285714285715
Epoch:   21       10 Batch loss: 0.213638 Batch F1: 0.5957446808510638
Epoch:   21       11 Batch loss: 0.197600 Batch F1: 0.6829268292682927
Epoch:   21       12 Batch loss: 0.236739 Batch F1: 0.5405405405405406
Train Avg Loss   21: 0.216327

Train Avg F1   21: 0.5727921271165112

Val Avg Loss   21: 0.220838

Val Avg F1   21:  0.49617371130529025

Optimal Val loss (Epoch 20): 0.21819939464330673

Epoch 22
--------------------------------------------------------------
Epoch:   22        1 Batch loss: 0.178528 Batch F1: 0.6666666666666667
Epoch:   22        2 Batch loss: 0.215502 Batch F1: 0.3448275862068966
Epoch:   22        3 Batch loss: 0.223308 Batch F1: 0.4878048780487805
Epoch:   22        4 Batch loss: 0.220069 Batch F1: 0.5853658536585366
Epoch:   22        5 Batch loss: 0.214878 Batch F1: 0.6363636363636365
Epoch:   22        6 Batch loss: 0.217593 Batch F1: 0.5777777777777778
Epoch:   22        7 Batch loss: 0.206753 Batch F1: 0.72
Epoch:   22        8 Batch loss: 0.216293 Batch F1: 0.6666666666666666
Epoch:   22        9 Batch loss: 0.232124 Batch F1: 0.5142857142857142
Epoch:   22       10 Batch loss: 0.220892 Batch F1: 0.6363636363636364
Epoch:   22       11 Batch loss: 0.204339 Batch F1: 0.4848484848484848
Epoch:   22       12 Batch loss: 0.268936 Batch F1: 0.30303030303030304
Train Avg Loss   22: 0.218268

Train Avg F1   22: 0.552000100326425

Val Avg Loss   22: 0.216448

Val Avg F1   22:  0.5786638857390813

Optimal Val loss (Epoch 22): 0.21644805371761322

Epoch 23
--------------------------------------------------------------
Epoch:   23        1 Batch loss: 0.234752 Batch F1: 0.5499999999999999
Epoch:   23        2 Batch loss: 0.229360 Batch F1: 0.6341463414634146
Epoch:   23        3 Batch loss: 0.214052 Batch F1: 0.6
Epoch:   23        4 Batch loss: 0.227976 Batch F1: 0.6666666666666666
Epoch:   23        5 Batch loss: 0.221669 Batch F1: 0.653061224489796
Epoch:   23        6 Batch loss: 0.164820 Batch F1: 0.8636363636363636
Epoch:   23        7 Batch loss: 0.200632 Batch F1: 0.723404255319149
Epoch:   23        8 Batch loss: 0.205759 Batch F1: 0.7169811320754716
Epoch:   23        9 Batch loss: 0.251311 Batch F1: 0.56
Epoch:   23       10 Batch loss: 0.238405 Batch F1: 0.5
Epoch:   23       11 Batch loss: 0.171114 Batch F1: 0.6470588235294118
Epoch:   23       12 Batch loss: 0.231562 Batch F1: 0.25
Train Avg Loss   23: 0.215951

Train Avg F1   23: 0.6137462339316896

Val Avg Loss   23: 0.233423

Val Avg F1   23:  0.34135632885632883

Optimal Val loss (Epoch 22): 0.21644805371761322

Epoch 24
--------------------------------------------------------------
Epoch:   24        1 Batch loss: 0.195990 Batch F1: 0.3333333333333333
Epoch:   24        2 Batch loss: 0.199859 Batch F1: 0.48275862068965514
Epoch:   24        3 Batch loss: 0.152462 Batch F1: 0.8108108108108109
Epoch:   24        4 Batch loss: 0.198081 Batch F1: 0.6153846153846154
Epoch:   24        5 Batch loss: 0.245933 Batch F1: 0.48648648648648646
Epoch:   24        6 Batch loss: 0.231045 Batch F1: 0.5333333333333333
Epoch:   24        7 Batch loss: 0.204365 Batch F1: 0.7586206896551724
Epoch:   24        8 Batch loss: 0.250619 Batch F1: 0.6530612244897959
Epoch:   24        9 Batch loss: 0.233341 Batch F1: 0.6274509803921569
Epoch:   24       10 Batch loss: 0.214451 Batch F1: 0.6666666666666666
Epoch:   24       11 Batch loss: 0.204434 Batch F1: 0.5777777777777778
Epoch:   24       12 Batch loss: 0.199637 Batch F1: 0.7826086956521738
Train Avg Loss   24: 0.210851

Train Avg F1   24: 0.6106911028893315

Val Avg Loss   24: 0.211979

Val Avg F1   24:  0.6735944634350249

Optimal Val loss (Epoch 24): 0.2119785137474537

Epoch 25
--------------------------------------------------------------
Epoch:   25        1 Batch loss: 0.220704 Batch F1: 0.5714285714285714
Epoch:   25        2 Batch loss: 0.214710 Batch F1: 0.7017543859649122
Epoch:   25        3 Batch loss: 0.213372 Batch F1: 0.65
Epoch:   25        4 Batch loss: 0.200821 Batch F1: 0.6530612244897959
Epoch:   25        5 Batch loss: 0.219865 Batch F1: 0.5853658536585366
Epoch:   25        6 Batch loss: 0.235677 Batch F1: 0.6792452830188679
Epoch:   25        7 Batch loss: 0.217009 Batch F1: 0.6818181818181818
Epoch:   25        8 Batch loss: 0.203039 Batch F1: 0.7234042553191489
Epoch:   25        9 Batch loss: 0.210896 Batch F1: 0.5405405405405405
Epoch:   25       10 Batch loss: 0.182104 Batch F1: 0.6470588235294117
Epoch:   25       11 Batch loss: 0.212107 Batch F1: 0.4375
Epoch:   25       12 Batch loss: 0.207096 Batch F1: 0.4848484848484849
Train Avg Loss   25: 0.211450

Train Avg F1   25: 0.6130021337180376

Val Avg Loss   25: 0.218887

Val Avg F1   25:  0.47806158036337065

Optimal Val loss (Epoch 24): 0.2119785137474537

Epoch 26
--------------------------------------------------------------
Epoch:   26        1 Batch loss: 0.212333 Batch F1: 0.4736842105263159
Epoch:   26        2 Batch loss: 0.222802 Batch F1: 0.6666666666666666
Epoch:   26        3 Batch loss: 0.220964 Batch F1: 0.6538461538461537
Epoch:   26        4 Batch loss: 0.216027 Batch F1: 0.7169811320754716
Epoch:   26        5 Batch loss: 0.215552 Batch F1: 0.7058823529411765
Epoch:   26        6 Batch loss: 0.223054 Batch F1: 0.6545454545454545
Epoch:   26        7 Batch loss: 0.206981 Batch F1: 0.6666666666666666
Epoch:   26        8 Batch loss: 0.197323 Batch F1: 0.631578947368421
Epoch:   26        9 Batch loss: 0.207035 Batch F1: 0.6666666666666667
Epoch:   26       10 Batch loss: 0.194691 Batch F1: 0.5263157894736842
Epoch:   26       11 Batch loss: 0.208098 Batch F1: 0.5142857142857143
Epoch:   26       12 Batch loss: 0.174030 Batch F1: 0.689655172413793
Train Avg Loss   26: 0.208241

Train Avg F1   26: 0.6305645772896821

Val Avg Loss   26: 0.211968

Val Avg F1   26:  0.5976024556163929

Optimal Val loss (Epoch 26): 0.21196787059307098

Epoch 27
--------------------------------------------------------------
Epoch:   27        1 Batch loss: 0.225704 Batch F1: 0.5777777777777778
Epoch:   27        2 Batch loss: 0.197957 Batch F1: 0.5454545454545454
Epoch:   27        3 Batch loss: 0.189655 Batch F1: 0.6829268292682926
Epoch:   27        4 Batch loss: 0.168982 Batch F1: 0.7804878048780488
Epoch:   27        5 Batch loss: 0.196302 Batch F1: 0.6363636363636365
Epoch:   27        6 Batch loss: 0.212999 Batch F1: 0.5641025641025642
Epoch:   27        7 Batch loss: 0.220780 Batch F1: 0.5945945945945945
Epoch:   27        8 Batch loss: 0.221494 Batch F1: 0.6250000000000001
Epoch:   27        9 Batch loss: 0.227117 Batch F1: 0.5833333333333334
Epoch:   27       10 Batch loss: 0.224932 Batch F1: 0.7540983606557377
Epoch:   27       11 Batch loss: 0.234163 Batch F1: 0.5652173913043479
Epoch:   27       12 Batch loss: 0.200505 Batch F1: 0.6829268292682927
Train Avg Loss   27: 0.210049

Train Avg F1   27: 0.6326903055834309

Val Avg Loss   27: 0.219315

Val Avg F1   27:  0.4965009652509652

Optimal Val loss (Epoch 26): 0.21196787059307098

Epoch 28
--------------------------------------------------------------
Epoch:   28        1 Batch loss: 0.253004 Batch F1: 0.24242424242424243
Epoch:   28        2 Batch loss: 0.239872 Batch F1: 0.37499999999999994
Epoch:   28        3 Batch loss: 0.223432 Batch F1: 0.35294117647058826
Epoch:   28        4 Batch loss: 0.219721 Batch F1: 0.6086956521739131
Epoch:   28        5 Batch loss: 0.244440 Batch F1: 0.6545454545454545
Epoch:   28        6 Batch loss: 0.225447 Batch F1: 0.7017543859649124
Epoch:   28        7 Batch loss: 0.206438 Batch F1: 0.6938775510204083
Epoch:   28        8 Batch loss: 0.172557 Batch F1: 0.7906976744186046
Epoch:   28        9 Batch loss: 0.191939 Batch F1: 0.625
Epoch:   28       10 Batch loss: 0.217493 Batch F1: 0.6111111111111112
Epoch:   28       11 Batch loss: 0.183563 Batch F1: 0.75
Epoch:   28       12 Batch loss: 0.191294 Batch F1: 0.28571428571428575
Train Avg Loss   28: 0.214100

Train Avg F1   28: 0.55764679448696

Val Avg Loss   28: 0.212260

Val Avg F1   28:  0.6038706472956912

Optimal Val loss (Epoch 26): 0.21196787059307098

Epoch 29
--------------------------------------------------------------
Epoch:   29        1 Batch loss: 0.190164 Batch F1: 0.65
Epoch:   29        2 Batch loss: 0.206957 Batch F1: 0.693877551020408
Epoch:   29        3 Batch loss: 0.210995 Batch F1: 0.6923076923076923
Epoch:   29        4 Batch loss: 0.209785 Batch F1: 0.6382978723404255
Epoch:   29        5 Batch loss: 0.232109 Batch F1: 0.5500000000000002
Epoch:   29        6 Batch loss: 0.177626 Batch F1: 0.6206896551724138
Epoch:   29        7 Batch loss: 0.193557 Batch F1: 0.6285714285714286
Epoch:   29        8 Batch loss: 0.253717 Batch F1: 0.43243243243243246
Epoch:   29        9 Batch loss: 0.227536 Batch F1: 0.4210526315789474
Epoch:   29       10 Batch loss: 0.195206 Batch F1: 0.6956521739130435
Epoch:   29       11 Batch loss: 0.197906 Batch F1: 0.6808510638297872
Epoch:   29       12 Batch loss: 0.220695 Batch F1: 0.6249999999999999
Train Avg Loss   29: 0.209688

Train Avg F1   29: 0.6107277084305484

Val Avg Loss   29: 0.223616

Val Avg F1   29:  0.6554659498207885

Optimal Val loss (Epoch 26): 0.21196787059307098

Epoch 30
--------------------------------------------------------------
Epoch:   30        1 Batch loss: 0.224819 Batch F1: 0.6896551724137931
Epoch:   30        2 Batch loss: 0.218742 Batch F1: 0.5454545454545454
Epoch:   30        3 Batch loss: 0.178127 Batch F1: 0.6486486486486486
Epoch:   30        4 Batch loss: 0.199597 Batch F1: 0.3448275862068965
Epoch:   30        5 Batch loss: 0.198793 Batch F1: 0.41379310344827586
Epoch:   30        6 Batch loss: 0.220287 Batch F1: 0.4242424242424242
Epoch:   30        7 Batch loss: 0.265736 Batch F1: 0.4878048780487804
Epoch:   30        8 Batch loss: 0.237378 Batch F1: 0.4705882352941177
Epoch:   30        9 Batch loss: 0.224333 Batch F1: 0.6363636363636365
Epoch:   30       10 Batch loss: 0.184627 Batch F1: 0.7
Epoch:   30       11 Batch loss: 0.214041 Batch F1: 0.68
Epoch:   30       12 Batch loss: 0.189017 Batch F1: 0.7755102040816326
Train Avg Loss   30: 0.212958

Train Avg F1   30: 0.5680740361835626

Val Avg Loss   30: 0.211208

Val Avg F1   30:  0.6485605076900156

Optimal Val loss (Epoch 30): 0.21120774373412132

Epoch 31
--------------------------------------------------------------
Epoch:   31        1 Batch loss: 0.210877 Batch F1: 0.6222222222222222
Epoch:   31        2 Batch loss: 0.207468 Batch F1: 0.5777777777777778
Epoch:   31        3 Batch loss: 0.205503 Batch F1: 0.4848484848484849
Epoch:   31        4 Batch loss: 0.173043 Batch F1: 0.6428571428571429
Epoch:   31        5 Batch loss: 0.192212 Batch F1: 0.6
Epoch:   31        6 Batch loss: 0.237082 Batch F1: 0.5128205128205129
Epoch:   31        7 Batch loss: 0.202068 Batch F1: 0.6222222222222222
Epoch:   31        8 Batch loss: 0.234902 Batch F1: 0.6808510638297872
Epoch:   31        9 Batch loss: 0.219944 Batch F1: 0.7169811320754716
Epoch:   31       10 Batch loss: 0.194828 Batch F1: 0.6923076923076923
Epoch:   31       11 Batch loss: 0.190842 Batch F1: 0.7368421052631579
Epoch:   31       12 Batch loss: 0.229471 Batch F1: 0.5789473684210527
Train Avg Loss   31: 0.208186

Train Avg F1   31: 0.6223898103871272

Val Avg Loss   31: 0.207662

Val Avg F1   31:  0.6368824525763974

Optimal Val loss (Epoch 31): 0.20766210928559303

Epoch 32
--------------------------------------------------------------
Epoch:   32        1 Batch loss: 0.209411 Batch F1: 0.6909090909090909
Epoch:   32        2 Batch loss: 0.211660 Batch F1: 0.5454545454545454
Epoch:   32        3 Batch loss: 0.212388 Batch F1: 0.5714285714285713
Epoch:   32        4 Batch loss: 0.181590 Batch F1: 0.6842105263157895
Epoch:   32        5 Batch loss: 0.212067 Batch F1: 0.6222222222222223
Epoch:   32        6 Batch loss: 0.159226 Batch F1: 0.75
Epoch:   32        7 Batch loss: 0.214262 Batch F1: 0.5128205128205129
Epoch:   32        8 Batch loss: 0.191232 Batch F1: 0.6341463414634146
Epoch:   32        9 Batch loss: 0.232461 Batch F1: 0.5833333333333334
Epoch:   32       10 Batch loss: 0.177106 Batch F1: 0.7142857142857143
Epoch:   32       11 Batch loss: 0.206952 Batch F1: 0.6250000000000001
Epoch:   32       12 Batch loss: 0.232625 Batch F1: 0.5945945945945945
Train Avg Loss   32: 0.203415

Train Avg F1   32: 0.6273671210689824

Val Avg Loss   32: 0.207543

Val Avg F1   32:  0.6276094276094275

Optimal Val loss (Epoch 32): 0.2075432911515236

Epoch 33
--------------------------------------------------------------
Epoch:   33        1 Batch loss: 0.208656 Batch F1: 0.6399999999999999
Epoch:   33        2 Batch loss: 0.176217 Batch F1: 0.7755102040816326
Epoch:   33        3 Batch loss: 0.212435 Batch F1: 0.5
Epoch:   33        4 Batch loss: 0.203037 Batch F1: 0.6808510638297872
Epoch:   33        5 Batch loss: 0.184936 Batch F1: 0.6666666666666667
Epoch:   33        6 Batch loss: 0.242116 Batch F1: 0.6
Epoch:   33        7 Batch loss: 0.214696 Batch F1: 0.5555555555555555
Epoch:   33        8 Batch loss: 0.212461 Batch F1: 0.6153846153846153
Epoch:   33        9 Batch loss: 0.190616 Batch F1: 0.6666666666666665
Epoch:   33       10 Batch loss: 0.173056 Batch F1: 0.7659574468085107
Epoch:   33       11 Batch loss: 0.225788 Batch F1: 0.6
Epoch:   33       12 Batch loss: 0.199687 Batch F1: 0.7916666666666666
Train Avg Loss   33: 0.203642

Train Avg F1   33: 0.6548549071383417

Val Avg Loss   33: 0.206778

Val Avg F1   33:  0.6593221966205838

Optimal Val loss (Epoch 33): 0.2067784033715725

Epoch 34
--------------------------------------------------------------
Epoch:   34        1 Batch loss: 0.210054 Batch F1: 0.5641025641025642
Epoch:   34        2 Batch loss: 0.181463 Batch F1: 0.7058823529411765
Epoch:   34        3 Batch loss: 0.194991 Batch F1: 0.5777777777777778
Epoch:   34        4 Batch loss: 0.187583 Batch F1: 0.6500000000000001
Epoch:   34        5 Batch loss: 0.204985 Batch F1: 0.6190476190476191
Epoch:   34        6 Batch loss: 0.190213 Batch F1: 0.4705882352941176
Epoch:   34        7 Batch loss: 0.226114 Batch F1: 0.6521739130434783
Epoch:   34        8 Batch loss: 0.210768 Batch F1: 0.6530612244897959
Epoch:   34        9 Batch loss: 0.211130 Batch F1: 0.7540983606557377
Epoch:   34       10 Batch loss: 0.204591 Batch F1: 0.6666666666666666
Epoch:   34       11 Batch loss: 0.178479 Batch F1: 0.7599999999999999
Epoch:   34       12 Batch loss: 0.199946 Batch F1: 0.6153846153846153
Train Avg Loss   34: 0.200026

Train Avg F1   34: 0.6407319441169623

Val Avg Loss   34: 0.204008

Val Avg F1   34:  0.6455674242941323

Optimal Val loss (Epoch 34): 0.20400835201144218

Epoch 35
--------------------------------------------------------------
Epoch:   35        1 Batch loss: 0.175892 Batch F1: 0.7619047619047619
Epoch:   35        2 Batch loss: 0.201974 Batch F1: 0.6511627906976744
Epoch:   35        3 Batch loss: 0.196414 Batch F1: 0.6153846153846154
Epoch:   35        4 Batch loss: 0.193052 Batch F1: 0.7317073170731708
Epoch:   35        5 Batch loss: 0.204496 Batch F1: 0.7200000000000001
Epoch:   35        6 Batch loss: 0.183328 Batch F1: 0.6956521739130435
Epoch:   35        7 Batch loss: 0.219038 Batch F1: 0.5333333333333333
Epoch:   35        8 Batch loss: 0.208888 Batch F1: 0.6511627906976744
Epoch:   35        9 Batch loss: 0.191650 Batch F1: 0.7000000000000001
Epoch:   35       10 Batch loss: 0.215464 Batch F1: 0.6122448979591837
Epoch:   35       11 Batch loss: 0.176048 Batch F1: 0.8
Epoch:   35       12 Batch loss: 0.190811 Batch F1: 0.6808510638297872
Train Avg Loss   35: 0.196421

Train Avg F1   35: 0.6794503120661037

Val Avg Loss   35: 0.205980

Val Avg F1   35:  0.6369881915030164

Optimal Val loss (Epoch 34): 0.20400835201144218

Epoch 36
--------------------------------------------------------------
Epoch:   36        1 Batch loss: 0.245895 Batch F1: 0.39999999999999997
Epoch:   36        2 Batch loss: 0.209704 Batch F1: 0.6530612244897959
Epoch:   36        3 Batch loss: 0.195092 Batch F1: 0.7346938775510203
Epoch:   36        4 Batch loss: 0.194671 Batch F1: 0.7142857142857143
Epoch:   36        5 Batch loss: 0.171540 Batch F1: 0.7547169811320754
Epoch:   36        6 Batch loss: 0.198965 Batch F1: 0.7142857142857143
Epoch:   36        7 Batch loss: 0.195362 Batch F1: 0.7169811320754718
Epoch:   36        8 Batch loss: 0.177441 Batch F1: 0.6666666666666666
Epoch:   36        9 Batch loss: 0.204996 Batch F1: 0.7017543859649122
Epoch:   36       10 Batch loss: 0.208841 Batch F1: 0.6
Epoch:   36       11 Batch loss: 0.173857 Batch F1: 0.5454545454545454
Epoch:   36       12 Batch loss: 0.181046 Batch F1: 0.6842105263157895
Train Avg Loss   36: 0.196451

Train Avg F1   36: 0.6571758973518088

Val Avg Loss   36: 0.202441

Val Avg F1   36:  0.6529078014184397

Optimal Val loss (Epoch 36): 0.20244111493229866

Epoch 37
--------------------------------------------------------------
Epoch:   37        1 Batch loss: 0.175979 Batch F1: 0.76
Epoch:   37        2 Batch loss: 0.207408 Batch F1: 0.6666666666666666
Epoch:   37        3 Batch loss: 0.179588 Batch F1: 0.625
Epoch:   37        4 Batch loss: 0.185760 Batch F1: 0.6938775510204083
Epoch:   37        5 Batch loss: 0.186347 Batch F1: 0.7636363636363636
Epoch:   37        6 Batch loss: 0.195204 Batch F1: 0.6666666666666666
Epoch:   37        7 Batch loss: 0.179631 Batch F1: 0.711111111111111
Epoch:   37        8 Batch loss: 0.198630 Batch F1: 0.608695652173913
Epoch:   37        9 Batch loss: 0.179978 Batch F1: 0.7
Epoch:   37       10 Batch loss: 0.211808 Batch F1: 0.5405405405405406
Epoch:   37       11 Batch loss: 0.220894 Batch F1: 0.37499999999999994
Epoch:   37       12 Batch loss: 0.222894 Batch F1: 0.6511627906976745
Train Avg Loss   37: 0.195343

Train Avg F1   37: 0.6468631118761121

Val Avg Loss   37: 0.200215

Val Avg F1   37:  0.6431112790359018

Optimal Val loss (Epoch 37): 0.20021500438451767

Epoch 38
--------------------------------------------------------------
Epoch:   38        1 Batch loss: 0.204870 Batch F1: 0.6538461538461539
Epoch:   38        2 Batch loss: 0.200966 Batch F1: 0.6086956521739131
Epoch:   38        3 Batch loss: 0.171932 Batch F1: 0.76
Epoch:   38        4 Batch loss: 0.193067 Batch F1: 0.6938775510204083
Epoch:   38        5 Batch loss: 0.165663 Batch F1: 0.7441860465116279
Epoch:   38        6 Batch loss: 0.192483 Batch F1: 0.6818181818181819
Epoch:   38        7 Batch loss: 0.181484 Batch F1: 0.6842105263157895
Epoch:   38        8 Batch loss: 0.233501 Batch F1: 0.6046511627906976
Epoch:   38        9 Batch loss: 0.184322 Batch F1: 0.7843137254901961
Epoch:   38       10 Batch loss: 0.201250 Batch F1: 0.5777777777777778
Epoch:   38       11 Batch loss: 0.190754 Batch F1: 0.6938775510204083
Epoch:   38       12 Batch loss: 0.203489 Batch F1: 0.6486486486486486
Train Avg Loss   38: 0.193648

Train Avg F1   38: 0.6779919147844836

Val Avg Loss   38: 0.198789

Val Avg F1   38:  0.6744282447112636

Optimal Val loss (Epoch 38): 0.19878855347633362

Epoch 39
--------------------------------------------------------------
Epoch:   39        1 Batch loss: 0.188313 Batch F1: 0.6666666666666666
Epoch:   39        2 Batch loss: 0.204116 Batch F1: 0.7636363636363638
Epoch:   39        3 Batch loss: 0.213158 Batch F1: 0.5777777777777778
Epoch:   39        4 Batch loss: 0.176973 Batch F1: 0.7843137254901961
Epoch:   39        5 Batch loss: 0.182523 Batch F1: 0.75
Epoch:   39        6 Batch loss: 0.182139 Batch F1: 0.6956521739130435
Epoch:   39        7 Batch loss: 0.163878 Batch F1: 0.6857142857142857
Epoch:   39        8 Batch loss: 0.185414 Batch F1: 0.6808510638297872
Epoch:   39        9 Batch loss: 0.203561 Batch F1: 0.48780487804878053
Epoch:   39       10 Batch loss: 0.222585 Batch F1: 0.5581395348837209
Epoch:   39       11 Batch loss: 0.165315 Batch F1: 0.744186046511628
Epoch:   39       12 Batch loss: 0.196762 Batch F1: 0.7317073170731706
Train Avg Loss   39: 0.190395

Train Avg F1   39: 0.6772041527954519

Val Avg Loss   39: 0.199851

Val Avg F1   39:  0.6723993124731436

Optimal Val loss (Epoch 38): 0.19878855347633362

Epoch 40
--------------------------------------------------------------
Epoch:   40        1 Batch loss: 0.184184 Batch F1: 0.6956521739130435
Epoch:   40        2 Batch loss: 0.163455 Batch F1: 0.7659574468085107
Epoch:   40        3 Batch loss: 0.199844 Batch F1: 0.6792452830188679
Epoch:   40        4 Batch loss: 0.251581 Batch F1: 0.4390243902439024
Epoch:   40        5 Batch loss: 0.170318 Batch F1: 0.7441860465116279
Epoch:   40        6 Batch loss: 0.194714 Batch F1: 0.7058823529411765
Epoch:   40        7 Batch loss: 0.184124 Batch F1: 0.6938775510204083
Epoch:   40        8 Batch loss: 0.194261 Batch F1: 0.7450980392156864
Epoch:   40        9 Batch loss: 0.167782 Batch F1: 0.8070175438596492
Epoch:   40       10 Batch loss: 0.220964 Batch F1: 0.608695652173913
Epoch:   40       11 Batch loss: 0.190628 Batch F1: 0.5853658536585366
Epoch:   40       12 Batch loss: 0.200195 Batch F1: 0.6874999999999999
Train Avg Loss   40: 0.193504

Train Avg F1   40: 0.6797918611137769

Val Avg Loss   40: 0.215357

Val Avg F1   40:  0.4974527930763178

Optimal Val loss (Epoch 38): 0.19878855347633362

Epoch 41
--------------------------------------------------------------
Epoch:   41        1 Batch loss: 0.208778 Batch F1: 0.6666666666666667
Epoch:   41        2 Batch loss: 0.200688 Batch F1: 0.5454545454545454
Epoch:   41        3 Batch loss: 0.214024 Batch F1: 0.5454545454545454
Epoch:   41        4 Batch loss: 0.170181 Batch F1: 0.7000000000000001
Epoch:   41        5 Batch loss: 0.166408 Batch F1: 0.7346938775510204
Epoch:   41        6 Batch loss: 0.176964 Batch F1: 0.65
Epoch:   41        7 Batch loss: 0.200339 Batch F1: 0.6923076923076923
Epoch:   41        8 Batch loss: 0.206134 Batch F1: 0.6046511627906976
Epoch:   41        9 Batch loss: 0.174014 Batch F1: 0.6976744186046512
Epoch:   41       10 Batch loss: 0.183635 Batch F1: 0.7407407407407408
Epoch:   41       11 Batch loss: 0.187534 Batch F1: 0.7169811320754716
Epoch:   41       12 Batch loss: 0.185803 Batch F1: 0.6500000000000001
Train Avg Loss   41: 0.189542

Train Avg F1   41: 0.6620520651371694

Val Avg Loss   41: 0.197339

Val Avg F1   41:  0.6500128353228084

Optimal Val loss (Epoch 41): 0.19733906537294388

Epoch 42
--------------------------------------------------------------
Epoch:   42        1 Batch loss: 0.188008 Batch F1: 0.5128205128205129
Epoch:   42        2 Batch loss: 0.164617 Batch F1: 0.7391304347826088
Epoch:   42        3 Batch loss: 0.165187 Batch F1: 0.8076923076923077
Epoch:   42        4 Batch loss: 0.212704 Batch F1: 0.5769230769230769
Epoch:   42        5 Batch loss: 0.182355 Batch F1: 0.6153846153846153
Epoch:   42        6 Batch loss: 0.203055 Batch F1: 0.7307692307692307
Epoch:   42        7 Batch loss: 0.220524 Batch F1: 0.5581395348837208
Epoch:   42        8 Batch loss: 0.219952 Batch F1: 0.5909090909090909
Epoch:   42        9 Batch loss: 0.161217 Batch F1: 0.7567567567567567
Epoch:   42       10 Batch loss: 0.187340 Batch F1: 0.6500000000000001
Epoch:   42       11 Batch loss: 0.176174 Batch F1: 0.7272727272727273
Epoch:   42       12 Batch loss: 0.176151 Batch F1: 0.816326530612245
Train Avg Loss   42: 0.188107

Train Avg F1   42: 0.6735104015672412

Val Avg Loss   42: 0.199176

Val Avg F1   42:  0.6453001282480205

Optimal Val loss (Epoch 41): 0.19733906537294388

Epoch 43
--------------------------------------------------------------
Epoch:   43        1 Batch loss: 0.188261 Batch F1: 0.6511627906976744
Epoch:   43        2 Batch loss: 0.199097 Batch F1: 0.6382978723404256
Epoch:   43        3 Batch loss: 0.178835 Batch F1: 0.7931034482758621
Epoch:   43        4 Batch loss: 0.170381 Batch F1: 0.75
Epoch:   43        5 Batch loss: 0.159597 Batch F1: 0.8571428571428572
Epoch:   43        6 Batch loss: 0.208752 Batch F1: 0.6249999999999999
Epoch:   43        7 Batch loss: 0.211092 Batch F1: 0.5531914893617023
Epoch:   43        8 Batch loss: 0.181691 Batch F1: 0.6363636363636365
Epoch:   43        9 Batch loss: 0.199439 Batch F1: 0.6382978723404256
Epoch:   43       10 Batch loss: 0.210389 Batch F1: 0.5714285714285713
Epoch:   43       11 Batch loss: 0.156636 Batch F1: 0.7567567567567567
Epoch:   43       12 Batch loss: 0.192971 Batch F1: 0.7500000000000001
Train Avg Loss   43: 0.188095

Train Avg F1   43: 0.685062107892326

Val Avg Loss   43: 0.197147

Val Avg F1   43:  0.6468829470627444

Optimal Val loss (Epoch 43): 0.1971466951072216

Epoch 44
--------------------------------------------------------------
Epoch:   44        1 Batch loss: 0.175508 Batch F1: 0.8163265306122449
Epoch:   44        2 Batch loss: 0.183358 Batch F1: 0.6521739130434783
Epoch:   44        3 Batch loss: 0.192608 Batch F1: 0.7058823529411765
Epoch:   44        4 Batch loss: 0.170557 Batch F1: 0.8076923076923076
Epoch:   44        5 Batch loss: 0.176591 Batch F1: 0.7083333333333334
Epoch:   44        6 Batch loss: 0.227377 Batch F1: 0.5957446808510639
Epoch:   44        7 Batch loss: 0.170674 Batch F1: 0.7777777777777779
Epoch:   44        8 Batch loss: 0.164111 Batch F1: 0.7692307692307692
Epoch:   44        9 Batch loss: 0.196885 Batch F1: 0.5641025641025641
Epoch:   44       10 Batch loss: 0.180265 Batch F1: 0.7083333333333334
Epoch:   44       11 Batch loss: 0.187595 Batch F1: 0.6829268292682927
Epoch:   44       12 Batch loss: 0.194807 Batch F1: 0.4827586206896552
Train Avg Loss   44: 0.185028

Train Avg F1   44: 0.689273584406333

Val Avg Loss   44: 0.197306

Val Avg F1   44:  0.6806049626701801

Optimal Val loss (Epoch 43): 0.1971466951072216

Epoch 45
--------------------------------------------------------------
Epoch:   45        1 Batch loss: 0.161570 Batch F1: 0.7317073170731706
Epoch:   45        2 Batch loss: 0.199364 Batch F1: 0.6938775510204083
Epoch:   45        3 Batch loss: 0.220812 Batch F1: 0.52
Epoch:   45        4 Batch loss: 0.180447 Batch F1: 0.7037037037037038
Epoch:   45        5 Batch loss: 0.190140 Batch F1: 0.6538461538461539
Epoch:   45        6 Batch loss: 0.210292 Batch F1: 0.5777777777777778
Epoch:   45        7 Batch loss: 0.160290 Batch F1: 0.8095238095238095
Epoch:   45        8 Batch loss: 0.178478 Batch F1: 0.761904761904762
Epoch:   45        9 Batch loss: 0.183760 Batch F1: 0.48275862068965514
Epoch:   45       10 Batch loss: 0.199033 Batch F1: 0.33333333333333337
Epoch:   45       11 Batch loss: 0.188645 Batch F1: 0.65
Epoch:   45       12 Batch loss: 0.192808 Batch F1: 0.7000000000000001
Train Avg Loss   45: 0.188803

Train Avg F1   45: 0.6348694190727312

Val Avg Loss   45: 0.215658

Val Avg F1   45:  0.7236314588531338

Optimal Val loss (Epoch 43): 0.1971466951072216

Epoch 46
--------------------------------------------------------------
Epoch:   46        1 Batch loss: 0.217782 Batch F1: 0.6666666666666667
Epoch:   46        2 Batch loss: 0.210297 Batch F1: 0.6296296296296295
Epoch:   46        3 Batch loss: 0.168765 Batch F1: 0.7222222222222222
Epoch:   46        4 Batch loss: 0.159824 Batch F1: 0.5925925925925927
Epoch:   46        5 Batch loss: 0.211584 Batch F1: 0.5
Epoch:   46        6 Batch loss: 0.207540 Batch F1: 0.5
Epoch:   46        7 Batch loss: 0.214010 Batch F1: 0.6909090909090909
Epoch:   46        8 Batch loss: 0.224421 Batch F1: 0.7142857142857143
Epoch:   46        9 Batch loss: 0.197375 Batch F1: 0.7346938775510203
Epoch:   46       10 Batch loss: 0.204729 Batch F1: 0.6792452830188679
Epoch:   46       11 Batch loss: 0.196396 Batch F1: 0.5853658536585366
Epoch:   46       12 Batch loss: 0.182766 Batch F1: 0.7058823529411764
Train Avg Loss   46: 0.199624

Train Avg F1   46: 0.6434577736229597

Val Avg Loss   46: 0.199348

Val Avg F1   46:  0.6270501835985312

Optimal Val loss (Epoch 43): 0.1971466951072216

Epoch 47
--------------------------------------------------------------
Epoch:   47        1 Batch loss: 0.210851 Batch F1: 0.7441860465116279
Epoch:   47        2 Batch loss: 0.170623 Batch F1: 0.6285714285714287
Epoch:   47        3 Batch loss: 0.200191 Batch F1: 0.5
Epoch:   47        4 Batch loss: 0.183719 Batch F1: 0.8148148148148148
Epoch:   47        5 Batch loss: 0.181738 Batch F1: 0.8076923076923077
Epoch:   47        6 Batch loss: 0.222116 Batch F1: 0.7241379310344828
Epoch:   47        7 Batch loss: 0.228016 Batch F1: 0.6296296296296297
Epoch:   47        8 Batch loss: 0.189752 Batch F1: 0.7499999999999999
Epoch:   47        9 Batch loss: 0.165497 Batch F1: 0.7317073170731706
Epoch:   47       10 Batch loss: 0.174043 Batch F1: 0.761904761904762
Epoch:   47       11 Batch loss: 0.188197 Batch F1: 0.6808510638297872
Epoch:   47       12 Batch loss: 0.158603 Batch F1: 0.6842105263157896
Train Avg Loss   47: 0.189446

Train Avg F1   47: 0.7048088189481501

Val Avg Loss   47: 0.200096

Val Avg F1   47:  0.587816970847054

Optimal Val loss (Epoch 43): 0.1971466951072216

Epoch 48
--------------------------------------------------------------
Epoch:   48        1 Batch loss: 0.209975 Batch F1: 0.5263157894736842
Epoch:   48        2 Batch loss: 0.195937 Batch F1: 0.5263157894736842
Epoch:   48        3 Batch loss: 0.199907 Batch F1: 0.5945945945945945
Epoch:   48        4 Batch loss: 0.184763 Batch F1: 0.7058823529411765
Epoch:   48        5 Batch loss: 0.196977 Batch F1: 0.6111111111111112
Epoch:   48        6 Batch loss: 0.202370 Batch F1: 0.6808510638297872
Epoch:   48        7 Batch loss: 0.218898 Batch F1: 0.8
Epoch:   48        8 Batch loss: 0.185845 Batch F1: 0.8214285714285715
Epoch:   48        9 Batch loss: 0.196799 Batch F1: 0.6666666666666666
Epoch:   48       10 Batch loss: 0.177409 Batch F1: 0.6521739130434783
Epoch:   48       11 Batch loss: 0.200186 Batch F1: 0.64
Epoch:   48       12 Batch loss: 0.152120 Batch F1: 0.8936170212765958
Train Avg Loss   48: 0.193432

Train Avg F1   48: 0.6765797394866125

Val Avg Loss   48: 0.196376

Val Avg F1   48:  0.6627802036202902

Optimal Val loss (Epoch 48): 0.1963757909834385

Epoch 49
--------------------------------------------------------------
Epoch:   49        1 Batch loss: 0.192191 Batch F1: 0.693877551020408
Epoch:   49        2 Batch loss: 0.186371 Batch F1: 0.6956521739130435
Epoch:   49        3 Batch loss: 0.171735 Batch F1: 0.7272727272727272
Epoch:   49        4 Batch loss: 0.195409 Batch F1: 0.6190476190476191
Epoch:   49        5 Batch loss: 0.170769 Batch F1: 0.8076923076923076
Epoch:   49        6 Batch loss: 0.191102 Batch F1: 0.6923076923076923
Epoch:   49        7 Batch loss: 0.214084 Batch F1: 0.4615384615384615
Epoch:   49        8 Batch loss: 0.192761 Batch F1: 0.6222222222222222
Epoch:   49        9 Batch loss: 0.200279 Batch F1: 0.7118644067796609
Epoch:   49       10 Batch loss: 0.176789 Batch F1: 0.6976744186046512
Epoch:   49       11 Batch loss: 0.171030 Batch F1: 0.6829268292682926
Epoch:   49       12 Batch loss: 0.183369 Batch F1: 0.6842105263157895
Train Avg Loss   49: 0.187157

Train Avg F1   49: 0.674690577998573

Val Avg Loss   49: 0.199320

Val Avg F1   49:  0.7045991432068544

Optimal Val loss (Epoch 48): 0.1963757909834385

Epoch 50
--------------------------------------------------------------
Epoch:   50        1 Batch loss: 0.199193 Batch F1: 0.6486486486486486
Epoch:   50        2 Batch loss: 0.175467 Batch F1: 0.7142857142857143
Epoch:   50        3 Batch loss: 0.215226 Batch F1: 0.6818181818181818
Epoch:   50        4 Batch loss: 0.165131 Batch F1: 0.7272727272727273
Epoch:   50        5 Batch loss: 0.165220 Batch F1: 0.7659574468085107
Epoch:   50        6 Batch loss: 0.192164 Batch F1: 0.6363636363636365
Epoch:   50        7 Batch loss: 0.165886 Batch F1: 0.6511627906976745
Epoch:   50        8 Batch loss: 0.192294 Batch F1: 0.68
Epoch:   50        9 Batch loss: 0.187853 Batch F1: 0.6666666666666667
Epoch:   50       10 Batch loss: 0.189887 Batch F1: 0.6666666666666666
Epoch:   50       11 Batch loss: 0.219177 Batch F1: 0.6086956521739131
Epoch:   50       12 Batch loss: 0.183690 Batch F1: 0.7142857142857143
Train Avg Loss   50: 0.187599

Train Avg F1   50: 0.6801519871406713

Val Avg Loss   50: 0.196686

Val Avg F1   50:  0.6535726858953403

Optimal Val loss (Epoch 48): 0.1963757909834385

Epoch 51
--------------------------------------------------------------
Epoch:   51        1 Batch loss: 0.181413 Batch F1: 0.7058823529411765
Epoch:   51        2 Batch loss: 0.197941 Batch F1: 0.5833333333333334
Epoch:   51        3 Batch loss: 0.160581 Batch F1: 0.76
Epoch:   51        4 Batch loss: 0.197456 Batch F1: 0.6222222222222222
Epoch:   51        5 Batch loss: 0.169409 Batch F1: 0.761904761904762
Epoch:   51        6 Batch loss: 0.215992 Batch F1: 0.5581395348837209
Epoch:   51        7 Batch loss: 0.193657 Batch F1: 0.6956521739130435
Epoch:   51        8 Batch loss: 0.158857 Batch F1: 0.6857142857142857
Epoch:   51        9 Batch loss: 0.191287 Batch F1: 0.7111111111111111
Epoch:   51       10 Batch loss: 0.178964 Batch F1: 0.6976744186046512
Epoch:   51       11 Batch loss: 0.197781 Batch F1: 0.6530612244897959
Epoch:   51       12 Batch loss: 0.187237 Batch F1: 0.8333333333333333
Train Avg Loss   51: 0.185881

Train Avg F1   51: 0.6890023960376198

Val Avg Loss   51: 0.199835

Val Avg F1   51:  0.769453044375645

Optimal Val loss (Epoch 48): 0.1963757909834385

Epoch 52
--------------------------------------------------------------
Epoch:   52        1 Batch loss: 0.162057 Batch F1: 0.8627450980392156
Epoch:   52        2 Batch loss: 0.205686 Batch F1: 0.5957446808510638
Epoch:   52        3 Batch loss: 0.228280 Batch F1: 0.5217391304347826
Epoch:   52        4 Batch loss: 0.149550 Batch F1: 0.7499999999999999
Epoch:   52        5 Batch loss: 0.175956 Batch F1: 0.48275862068965514
Epoch:   52        6 Batch loss: 0.218311 Batch F1: 0.43750000000000006
Epoch:   52        7 Batch loss: 0.238707 Batch F1: 0.5581395348837208
Epoch:   52        8 Batch loss: 0.160384 Batch F1: 0.8181818181818182
Epoch:   52        9 Batch loss: 0.210127 Batch F1: 0.5454545454545454
Epoch:   52       10 Batch loss: 0.154315 Batch F1: 0.7999999999999999
Epoch:   52       11 Batch loss: 0.210585 Batch F1: 0.6551724137931035
Epoch:   52       12 Batch loss: 0.179954 Batch F1: 0.7272727272727272
Train Avg Loss   52: 0.191159

Train Avg F1   52: 0.646225714133386

Val Avg Loss   52: 0.195208

Val Avg F1   52:  0.6419302811354998

Optimal Val loss (Epoch 52): 0.19520848616957664

Epoch 53
--------------------------------------------------------------
Epoch:   53        1 Batch loss: 0.165490 Batch F1: 0.744186046511628
Epoch:   53        2 Batch loss: 0.164341 Batch F1: 0.7619047619047619
Epoch:   53        3 Batch loss: 0.196576 Batch F1: 0.6190476190476191
Epoch:   53        4 Batch loss: 0.184568 Batch F1: 0.7272727272727274
Epoch:   53        5 Batch loss: 0.199717 Batch F1: 0.7540983606557377
Epoch:   53        6 Batch loss: 0.229925 Batch F1: 0.5217391304347826
Epoch:   53        7 Batch loss: 0.201375 Batch F1: 0.6
Epoch:   53        8 Batch loss: 0.178627 Batch F1: 0.7391304347826085
Epoch:   53        9 Batch loss: 0.203546 Batch F1: 0.6
Epoch:   53       10 Batch loss: 0.188706 Batch F1: 0.7547169811320755
Epoch:   53       11 Batch loss: 0.183692 Batch F1: 0.7317073170731707
Epoch:   53       12 Batch loss: 0.159070 Batch F1: 0.7999999999999999
Train Avg Loss   53: 0.187969

Train Avg F1   53: 0.6961502815679258

Val Avg Loss   53: 0.193683

Val Avg F1   53:  0.6622407859177303

Optimal Val loss (Epoch 53): 0.1936834678053856

Epoch 54
--------------------------------------------------------------
Epoch:   54        1 Batch loss: 0.192823 Batch F1: 0.7083333333333334
Epoch:   54        2 Batch loss: 0.202985 Batch F1: 0.6785714285714286
Epoch:   54        3 Batch loss: 0.194942 Batch F1: 0.5263157894736842
Epoch:   54        4 Batch loss: 0.179510 Batch F1: 0.76
Epoch:   54        5 Batch loss: 0.181955 Batch F1: 0.5555555555555556
Epoch:   54        6 Batch loss: 0.162253 Batch F1: 0.6829268292682927
Epoch:   54        7 Batch loss: 0.189774 Batch F1: 0.7755102040816326
Epoch:   54        8 Batch loss: 0.159270 Batch F1: 0.7317073170731707
Epoch:   54        9 Batch loss: 0.211147 Batch F1: 0.5957446808510639
Epoch:   54       10 Batch loss: 0.176444 Batch F1: 0.7547169811320754
Epoch:   54       11 Batch loss: 0.171237 Batch F1: 0.7307692307692308
Epoch:   54       12 Batch loss: 0.213568 Batch F1: 0.5789473684210527
Train Avg Loss   54: 0.186326

Train Avg F1   54: 0.6732582265442101

Val Avg Loss   54: 0.194315

Val Avg F1   54:  0.635558328308881

Optimal Val loss (Epoch 53): 0.1936834678053856

Epoch 55
--------------------------------------------------------------
Epoch:   55        1 Batch loss: 0.206767 Batch F1: 0.6545454545454545
Epoch:   55        2 Batch loss: 0.227620 Batch F1: 0.4888888888888889
Epoch:   55        3 Batch loss: 0.165107 Batch F1: 0.6666666666666666
Epoch:   55        4 Batch loss: 0.199005 Batch F1: 0.6382978723404256
Epoch:   55        5 Batch loss: 0.169931 Batch F1: 0.8363636363636364
Epoch:   55        6 Batch loss: 0.197733 Batch F1: 0.6363636363636365
Epoch:   55        7 Batch loss: 0.174955 Batch F1: 0.7346938775510204
Epoch:   55        8 Batch loss: 0.177433 Batch F1: 0.7037037037037037
Epoch:   55        9 Batch loss: 0.180803 Batch F1: 0.6976744186046512
Epoch:   55       10 Batch loss: 0.180643 Batch F1: 0.631578947368421
Epoch:   55       11 Batch loss: 0.173910 Batch F1: 0.5333333333333333
Epoch:   55       12 Batch loss: 0.152223 Batch F1: 0.878048780487805
Train Avg Loss   55: 0.183844

Train Avg F1   55: 0.6750132680181369

Val Avg Loss   55: 0.201905

Val Avg F1   55:  0.5948021181716834

Optimal Val loss (Epoch 53): 0.1936834678053856

Epoch 56
--------------------------------------------------------------
Epoch:   56        1 Batch loss: 0.198398 Batch F1: 0.6222222222222223
Epoch:   56        2 Batch loss: 0.166047 Batch F1: 0.717948717948718
Epoch:   56        3 Batch loss: 0.167134 Batch F1: 0.7
Epoch:   56        4 Batch loss: 0.189233 Batch F1: 0.75
Epoch:   56        5 Batch loss: 0.166175 Batch F1: 0.6956521739130435
Epoch:   56        6 Batch loss: 0.195786 Batch F1: 0.6666666666666667
Epoch:   56        7 Batch loss: 0.219454 Batch F1: 0.5
Epoch:   56        8 Batch loss: 0.158022 Batch F1: 0.7391304347826089
Epoch:   56        9 Batch loss: 0.196658 Batch F1: 0.6190476190476191
Epoch:   56       10 Batch loss: 0.190592 Batch F1: 0.7058823529411765
Epoch:   56       11 Batch loss: 0.182079 Batch F1: 0.7659574468085107
Epoch:   56       12 Batch loss: 0.211586 Batch F1: 0.6976744186046512
Train Avg Loss   56: 0.186764

Train Avg F1   56: 0.6816818377446013

Val Avg Loss   56: 0.192142

Val Avg F1   56:  0.7108583055863854

Optimal Val loss (Epoch 56): 0.19214189425110817

Epoch 57
--------------------------------------------------------------
Epoch:   57        1 Batch loss: 0.198480 Batch F1: 0.721311475409836
Epoch:   57        2 Batch loss: 0.168764 Batch F1: 0.7547169811320754
Epoch:   57        3 Batch loss: 0.244087 Batch F1: 0.4545454545454545
Epoch:   57        4 Batch loss: 0.214935 Batch F1: 0.625
Epoch:   57        5 Batch loss: 0.190961 Batch F1: 0.75
Epoch:   57        6 Batch loss: 0.145328 Batch F1: 0.6666666666666667
Epoch:   57        7 Batch loss: 0.209393 Batch F1: 0.6818181818181819
Epoch:   57        8 Batch loss: 0.186996 Batch F1: 0.6511627906976745
Epoch:   57        9 Batch loss: 0.171761 Batch F1: 0.7500000000000001
Epoch:   57       10 Batch loss: 0.140256 Batch F1: 0.7368421052631579
Epoch:   57       11 Batch loss: 0.180505 Batch F1: 0.7407407407407407
Epoch:   57       12 Batch loss: 0.210828 Batch F1: 0.6363636363636365
Train Avg Loss   57: 0.188524

Train Avg F1   57: 0.6807640027197852

Val Avg Loss   57: 0.199260

Val Avg F1   57:  0.6393687909946587

Optimal Val loss (Epoch 56): 0.19214189425110817

Epoch 58
--------------------------------------------------------------
Epoch:   58        1 Batch loss: 0.195328 Batch F1: 0.5945945945945946
Epoch:   58        2 Batch loss: 0.177280 Batch F1: 0.7307692307692308
Epoch:   58        3 Batch loss: 0.223998 Batch F1: 0.5
Epoch:   58        4 Batch loss: 0.159649 Batch F1: 0.7878787878787877
Epoch:   58        5 Batch loss: 0.193134 Batch F1: 0.711111111111111
Epoch:   58        6 Batch loss: 0.178035 Batch F1: 0.6938775510204083
Epoch:   58        7 Batch loss: 0.194680 Batch F1: 0.6222222222222223
Epoch:   58        8 Batch loss: 0.186064 Batch F1: 0.7
Epoch:   58        9 Batch loss: 0.177133 Batch F1: 0.7234042553191489
Epoch:   58       10 Batch loss: 0.210874 Batch F1: 0.6538461538461539
Epoch:   58       11 Batch loss: 0.197505 Batch F1: 0.6382978723404255
Epoch:   58       12 Batch loss: 0.232918 Batch F1: 0.5714285714285714
Train Avg Loss   58: 0.193883

Train Avg F1   58: 0.6606191958775546

Val Avg Loss   58: 0.195474

Val Avg F1   58:  0.648043094471666

Optimal Val loss (Epoch 56): 0.19214189425110817

Epoch 59
--------------------------------------------------------------
Epoch:   59        1 Batch loss: 0.174282 Batch F1: 0.7692307692307692
Epoch:   59        2 Batch loss: 0.206590 Batch F1: 0.7333333333333334
Epoch:   59        3 Batch loss: 0.189234 Batch F1: 0.8076923076923077
Epoch:   59        4 Batch loss: 0.190274 Batch F1: 0.7407407407407407
Epoch:   59        5 Batch loss: 0.201456 Batch F1: 0.5641025641025642
Epoch:   59        6 Batch loss: 0.171666 Batch F1: 0.6666666666666667
Epoch:   59        7 Batch loss: 0.180309 Batch F1: 0.6666666666666667
Epoch:   59        8 Batch loss: 0.187991 Batch F1: 0.5945945945945945
Epoch:   59        9 Batch loss: 0.183524 Batch F1: 0.7999999999999999
Epoch:   59       10 Batch loss: 0.191033 Batch F1: 0.6666666666666666
Epoch:   59       11 Batch loss: 0.185637 Batch F1: 0.7111111111111111
Epoch:   59       12 Batch loss: 0.182126 Batch F1: 0.6111111111111112
Train Avg Loss   59: 0.187010

Train Avg F1   59: 0.694326377659711

Val Avg Loss   59: 0.193428

Val Avg F1   59:  0.6396683673469388

Optimal Val loss (Epoch 56): 0.19214189425110817

Epoch 60
--------------------------------------------------------------
Epoch:   60        1 Batch loss: 0.190429 Batch F1: 0.6222222222222222
Epoch:   60        2 Batch loss: 0.187608 Batch F1: 0.6382978723404256
Epoch:   60        3 Batch loss: 0.220875 Batch F1: 0.6181818181818182
Epoch:   60        4 Batch loss: 0.156411 Batch F1: 0.7368421052631577
Epoch:   60        5 Batch loss: 0.183068 Batch F1: 0.8307692307692308
Epoch:   60        6 Batch loss: 0.157406 Batch F1: 0.816326530612245
Epoch:   60        7 Batch loss: 0.165802 Batch F1: 0.76
Epoch:   60        8 Batch loss: 0.189782 Batch F1: 0.611111111111111
Epoch:   60        9 Batch loss: 0.191444 Batch F1: 0.6382978723404256
Epoch:   60       10 Batch loss: 0.206144 Batch F1: 0.4878048780487805
Epoch:   60       11 Batch loss: 0.182886 Batch F1: 0.6530612244897959
Epoch:   60       12 Batch loss: 0.168814 Batch F1: 0.6875
Train Avg Loss   60: 0.183389

Train Avg F1   60: 0.6750345721149342

Val Avg Loss   60: 0.194461

Val Avg F1   60:  0.6796172847638495

Optimal Val loss (Epoch 56): 0.19214189425110817

Epoch 61
--------------------------------------------------------------
Epoch:   61        1 Batch loss: 0.220837 Batch F1: 0.6399999999999999
Epoch:   61        2 Batch loss: 0.193195 Batch F1: 0.7450980392156864
Epoch:   61        3 Batch loss: 0.175721 Batch F1: 0.7317073170731707
Epoch:   61        4 Batch loss: 0.195974 Batch F1: 0.5714285714285715
Epoch:   61        5 Batch loss: 0.178610 Batch F1: 0.7857142857142857
Epoch:   61        6 Batch loss: 0.210073 Batch F1: 0.6666666666666666
Epoch:   61        7 Batch loss: 0.170197 Batch F1: 0.8
Epoch:   61        8 Batch loss: 0.176272 Batch F1: 0.7234042553191489
Epoch:   61        9 Batch loss: 0.168935 Batch F1: 0.823529411764706
Epoch:   61       10 Batch loss: 0.207206 Batch F1: 0.45
Epoch:   61       11 Batch loss: 0.182025 Batch F1: 0.7142857142857143
Epoch:   61       12 Batch loss: 0.183304 Batch F1: 0.380952380952381
Train Avg Loss   61: 0.188529

Train Avg F1   61: 0.6693988868683608

Val Avg Loss   61: 0.207616

Val Avg F1   61:  0.5622556269549844

Optimal Val loss (Epoch 56): 0.19214189425110817

Epoch 62
--------------------------------------------------------------
Epoch:   62        1 Batch loss: 0.189352 Batch F1: 0.6451612903225806
Epoch:   62        2 Batch loss: 0.206351 Batch F1: 0.4375
Epoch:   62        3 Batch loss: 0.181363 Batch F1: 0.5806451612903226
Epoch:   62        4 Batch loss: 0.197517 Batch F1: 0.7058823529411765
Epoch:   62        5 Batch loss: 0.183008 Batch F1: 0.7407407407407408
Epoch:   62        6 Batch loss: 0.196375 Batch F1: 0.68
Epoch:   62        7 Batch loss: 0.215189 Batch F1: 0.6399999999999999
Epoch:   62        8 Batch loss: 0.171467 Batch F1: 0.6818181818181818
Epoch:   62        9 Batch loss: 0.189799 Batch F1: 0.6666666666666667
Epoch:   62       10 Batch loss: 0.169545 Batch F1: 0.7727272727272727
Epoch:   62       11 Batch loss: 0.202558 Batch F1: 0.5116279069767442
Epoch:   62       12 Batch loss: 0.193401 Batch F1: 0.6153846153846153
Train Avg Loss   62: 0.191327

Train Avg F1   62: 0.6398461824056917

Val Avg Loss   62: 0.193601

Val Avg F1   62:  0.6469486531281914

Optimal Val loss (Epoch 56): 0.19214189425110817

Epoch 63
--------------------------------------------------------------
Epoch:   63        1 Batch loss: 0.180848 Batch F1: 0.6818181818181819
Epoch:   63        2 Batch loss: 0.155741 Batch F1: 0.717948717948718
Epoch:   63        3 Batch loss: 0.169648 Batch F1: 0.7142857142857143
Epoch:   63        4 Batch loss: 0.198159 Batch F1: 0.6551724137931035
Epoch:   63        5 Batch loss: 0.195080 Batch F1: 0.6521739130434783
Epoch:   63        6 Batch loss: 0.160181 Batch F1: 0.8085106382978723
Epoch:   63        7 Batch loss: 0.192919 Batch F1: 0.7333333333333334
Epoch:   63        8 Batch loss: 0.207316 Batch F1: 0.7457627118644068
Epoch:   63        9 Batch loss: 0.202495 Batch F1: 0.6190476190476191
Epoch:   63       10 Batch loss: 0.198199 Batch F1: 0.6486486486486486
Epoch:   63       11 Batch loss: 0.171440 Batch F1: 0.8181818181818182
Epoch:   63       12 Batch loss: 0.199945 Batch F1: 0.5714285714285715
Train Avg Loss   63: 0.185998

Train Avg F1   63: 0.6971926901409554

Val Avg Loss   63: 0.209279

Val Avg F1   63:  0.5580569727891156

Optimal Val loss (Epoch 56): 0.19214189425110817

Epoch 64
--------------------------------------------------------------
Epoch:   64        1 Batch loss: 0.192191 Batch F1: 0.6857142857142856
Epoch:   64        2 Batch loss: 0.199027 Batch F1: 0.631578947368421
Epoch:   64        3 Batch loss: 0.187610 Batch F1: 0.5945945945945946
Epoch:   64        4 Batch loss: 0.189633 Batch F1: 0.6808510638297872
Epoch:   64        5 Batch loss: 0.149109 Batch F1: 0.7
Epoch:   64        6 Batch loss: 0.162432 Batch F1: 0.7659574468085107
Epoch:   64        7 Batch loss: 0.177285 Batch F1: 0.7547169811320755
Epoch:   64        8 Batch loss: 0.195910 Batch F1: 0.6666666666666666
Epoch:   64        9 Batch loss: 0.170714 Batch F1: 0.6153846153846154
Epoch:   64       10 Batch loss: 0.199578 Batch F1: 0.6779661016949152
Epoch:   64       11 Batch loss: 0.208149 Batch F1: 0.6086956521739131
Epoch:   64       12 Batch loss: 0.175864 Batch F1: 0.7272727272727272
Train Avg Loss   64: 0.183958

Train Avg F1   64: 0.6757832568867094

Val Avg Loss   64: 0.192244

Val Avg F1   64:  0.6750607116460775

Optimal Val loss (Epoch 56): 0.19214189425110817

Epoch 65
--------------------------------------------------------------
Epoch:   65        1 Batch loss: 0.169291 Batch F1: 0.7272727272727274
Epoch:   65        2 Batch loss: 0.181960 Batch F1: 0.7499999999999999
Epoch:   65        3 Batch loss: 0.156214 Batch F1: 0.7647058823529412
Epoch:   65        4 Batch loss: 0.171955 Batch F1: 0.7555555555555555
Epoch:   65        5 Batch loss: 0.201712 Batch F1: 0.6363636363636364
Epoch:   65        6 Batch loss: 0.173716 Batch F1: 0.7843137254901961
Epoch:   65        7 Batch loss: 0.185074 Batch F1: 0.7346938775510203
Epoch:   65        8 Batch loss: 0.194151 Batch F1: 0.6511627906976744
Epoch:   65        9 Batch loss: 0.192170 Batch F1: 0.6382978723404256
Epoch:   65       10 Batch loss: 0.189320 Batch F1: 0.6382978723404256
Epoch:   65       11 Batch loss: 0.196032 Batch F1: 0.6249999999999999
Epoch:   65       12 Batch loss: 0.164035 Batch F1: 0.6666666666666667
Train Avg Loss   65: 0.181302

Train Avg F1   65: 0.6976942172192725

Val Avg Loss   65: 0.189908

Val Avg F1   65:  0.6867633298378639

Optimal Val loss (Epoch 65): 0.1899084746837616

Epoch 66
--------------------------------------------------------------
Epoch:   66        1 Batch loss: 0.209070 Batch F1: 0.5555555555555556
Epoch:   66        2 Batch loss: 0.179127 Batch F1: 0.6341463414634146
Epoch:   66        3 Batch loss: 0.187884 Batch F1: 0.7307692307692306
Epoch:   66        4 Batch loss: 0.172053 Batch F1: 0.7142857142857143
Epoch:   66        5 Batch loss: 0.196763 Batch F1: 0.6666666666666666
Epoch:   66        6 Batch loss: 0.190699 Batch F1: 0.6521739130434783
Epoch:   66        7 Batch loss: 0.187495 Batch F1: 0.7450980392156864
Epoch:   66        8 Batch loss: 0.173170 Batch F1: 0.7317073170731707
Epoch:   66        9 Batch loss: 0.173784 Batch F1: 0.7857142857142857
Epoch:   66       10 Batch loss: 0.173035 Batch F1: 0.8
Epoch:   66       11 Batch loss: 0.163959 Batch F1: 0.6500000000000001
Epoch:   66       12 Batch loss: 0.184895 Batch F1: 0.6666666666666667
Train Avg Loss   66: 0.182661

Train Avg F1   66: 0.694398644204489

Val Avg Loss   66: 0.190414

Val Avg F1   66:  0.6568026363688618

Optimal Val loss (Epoch 65): 0.1899084746837616

Epoch 67
--------------------------------------------------------------
Epoch:   67        1 Batch loss: 0.183524 Batch F1: 0.6666666666666666
Epoch:   67        2 Batch loss: 0.171939 Batch F1: 0.7391304347826088
Epoch:   67        3 Batch loss: 0.179747 Batch F1: 0.6666666666666666
Epoch:   67        4 Batch loss: 0.182725 Batch F1: 0.6666666666666666
Epoch:   67        5 Batch loss: 0.200656 Batch F1: 0.6779661016949152
Epoch:   67        6 Batch loss: 0.174058 Batch F1: 0.6842105263157895
Epoch:   67        7 Batch loss: 0.198555 Batch F1: 0.6511627906976745
Epoch:   67        8 Batch loss: 0.147736 Batch F1: 0.7804878048780488
Epoch:   67        9 Batch loss: 0.212565 Batch F1: 0.7169811320754716
Epoch:   67       10 Batch loss: 0.186215 Batch F1: 0.6956521739130435
Epoch:   67       11 Batch loss: 0.185761 Batch F1: 0.711111111111111
Epoch:   67       12 Batch loss: 0.143919 Batch F1: 0.8387096774193549
Train Avg Loss   67: 0.180617

Train Avg F1   67: 0.7079509794073348

Val Avg Loss   67: 0.192766

Val Avg F1   67:  0.6682562720298569

Optimal Val loss (Epoch 65): 0.1899084746837616

Epoch 68
--------------------------------------------------------------
Epoch:   68        1 Batch loss: 0.164690 Batch F1: 0.7999999999999999
Epoch:   68        2 Batch loss: 0.177003 Batch F1: 0.7272727272727272
Epoch:   68        3 Batch loss: 0.176463 Batch F1: 0.5789473684210527
Epoch:   68        4 Batch loss: 0.198376 Batch F1: 0.6122448979591837
Epoch:   68        5 Batch loss: 0.178548 Batch F1: 0.6
Epoch:   68        6 Batch loss: 0.170434 Batch F1: 0.6666666666666666
Epoch:   68        7 Batch loss: 0.184786 Batch F1: 0.6666666666666667
Epoch:   68        8 Batch loss: 0.201828 Batch F1: 0.7142857142857142
Epoch:   68        9 Batch loss: 0.166781 Batch F1: 0.6666666666666666
Epoch:   68       10 Batch loss: 0.157092 Batch F1: 0.8148148148148148
Epoch:   68       11 Batch loss: 0.232419 Batch F1: 0.4680851063829787
Epoch:   68       12 Batch loss: 0.179859 Batch F1: 0.7391304347826089
Train Avg Loss   68: 0.182357

Train Avg F1   68: 0.67123175532659

Val Avg Loss   68: 0.190672

Val Avg F1   68:  0.6354054989725721

Optimal Val loss (Epoch 65): 0.1899084746837616

Epoch 69
--------------------------------------------------------------
Epoch:   69        1 Batch loss: 0.167817 Batch F1: 0.7843137254901961
Epoch:   69        2 Batch loss: 0.212369 Batch F1: 0.6909090909090909
Epoch:   69        3 Batch loss: 0.165207 Batch F1: 0.7272727272727272
Epoch:   69        4 Batch loss: 0.189477 Batch F1: 0.7142857142857143
Epoch:   69        5 Batch loss: 0.178304 Batch F1: 0.7111111111111111
Epoch:   69        6 Batch loss: 0.160089 Batch F1: 0.7692307692307692
Epoch:   69        7 Batch loss: 0.187150 Batch F1: 0.7272727272727273
Epoch:   69        8 Batch loss: 0.218217 Batch F1: 0.5365853658536586
Epoch:   69        9 Batch loss: 0.192388 Batch F1: 0.7234042553191491
Epoch:   69       10 Batch loss: 0.171938 Batch F1: 0.7199999999999999
Epoch:   69       11 Batch loss: 0.256772 Batch F1: 0.5199999999999999
Epoch:   69       12 Batch loss: 0.176533 Batch F1: 0.7567567567567567
Train Avg Loss   69: 0.189689

Train Avg F1   69: 0.698428520291825

Val Avg Loss   69: 0.192922

Val Avg F1   69:  0.6714524702939336

Optimal Val loss (Epoch 65): 0.1899084746837616

Epoch 70
--------------------------------------------------------------
Epoch:   70        1 Batch loss: 0.162953 Batch F1: 0.7916666666666667
Epoch:   70        2 Batch loss: 0.186403 Batch F1: 0.6
Epoch:   70        3 Batch loss: 0.184511 Batch F1: 0.75
Epoch:   70        4 Batch loss: 0.184608 Batch F1: 0.6829268292682927
Epoch:   70        5 Batch loss: 0.207840 Batch F1: 0.5641025641025641
Epoch:   70        6 Batch loss: 0.194047 Batch F1: 0.6086956521739131
Epoch:   70        7 Batch loss: 0.199503 Batch F1: 0.7619047619047619
Epoch:   70        8 Batch loss: 0.192444 Batch F1: 0.6666666666666666
Epoch:   70        9 Batch loss: 0.180467 Batch F1: 0.6363636363636364
Epoch:   70       10 Batch loss: 0.196461 Batch F1: 0.6666666666666666
Epoch:   70       11 Batch loss: 0.160184 Batch F1: 0.8108108108108107
Epoch:   70       12 Batch loss: 0.223648 Batch F1: 0.6842105263157895
Train Avg Loss   70: 0.189422

Train Avg F1   70: 0.6853345650783141

Val Avg Loss   70: 0.191896

Val Avg F1   70:  0.6655487369773084

Optimal Val loss (Epoch 65): 0.1899084746837616

Epoch 71
--------------------------------------------------------------
Epoch:   71        1 Batch loss: 0.178550 Batch F1: 0.7692307692307693
Epoch:   71        2 Batch loss: 0.140775 Batch F1: 0.8260869565217391
Epoch:   71        3 Batch loss: 0.170122 Batch F1: 0.7924528301886793
Epoch:   71        4 Batch loss: 0.160909 Batch F1: 0.76
Epoch:   71        5 Batch loss: 0.181924 Batch F1: 0.6666666666666666
Epoch:   71        6 Batch loss: 0.197616 Batch F1: 0.5909090909090909
Epoch:   71        7 Batch loss: 0.213554 Batch F1: 0.6222222222222222
Epoch:   71        8 Batch loss: 0.194251 Batch F1: 0.6363636363636365
Epoch:   71        9 Batch loss: 0.190268 Batch F1: 0.6976744186046512
Epoch:   71       10 Batch loss: 0.203136 Batch F1: 0.6222222222222222
Epoch:   71       11 Batch loss: 0.176542 Batch F1: 0.7906976744186047
Epoch:   71       12 Batch loss: 0.208409 Batch F1: 0.5405405405405405
Train Avg Loss   71: 0.184671

Train Avg F1   71: 0.6929222523240686

Val Avg Loss   71: 0.189207

Val Avg F1   71:  0.6760114275967934

Optimal Val loss (Epoch 71): 0.18920686468482018

Epoch 72
--------------------------------------------------------------
Epoch:   72        1 Batch loss: 0.201491 Batch F1: 0.65
Epoch:   72        2 Batch loss: 0.182005 Batch F1: 0.6511627906976744
Epoch:   72        3 Batch loss: 0.190322 Batch F1: 0.6808510638297872
Epoch:   72        4 Batch loss: 0.148692 Batch F1: 0.8095238095238095
Epoch:   72        5 Batch loss: 0.182367 Batch F1: 0.6829268292682926
Epoch:   72        6 Batch loss: 0.196146 Batch F1: 0.5641025641025641
Epoch:   72        7 Batch loss: 0.173392 Batch F1: 0.711111111111111
Epoch:   72        8 Batch loss: 0.191093 Batch F1: 0.6
Epoch:   72        9 Batch loss: 0.196569 Batch F1: 0.6909090909090909
Epoch:   72       10 Batch loss: 0.164496 Batch F1: 0.75
Epoch:   72       11 Batch loss: 0.178101 Batch F1: 0.8571428571428571
Epoch:   72       12 Batch loss: 0.174369 Batch F1: 0.8571428571428571
Train Avg Loss   72: 0.181587

Train Avg F1   72: 0.7087394144773369

Val Avg Loss   72: 0.189314

Val Avg F1   72:  0.6885009282846164

Optimal Val loss (Epoch 71): 0.18920686468482018

Epoch 73
--------------------------------------------------------------
Epoch:   73        1 Batch loss: 0.193790 Batch F1: 0.6666666666666666
Epoch:   73        2 Batch loss: 0.193028 Batch F1: 0.72
Epoch:   73        3 Batch loss: 0.176098 Batch F1: 0.8000000000000002
Epoch:   73        4 Batch loss: 0.188403 Batch F1: 0.5555555555555556
Epoch:   73        5 Batch loss: 0.189849 Batch F1: 0.6666666666666666
Epoch:   73        6 Batch loss: 0.182677 Batch F1: 0.711111111111111
Epoch:   73        7 Batch loss: 0.188005 Batch F1: 0.7200000000000001
Epoch:   73        8 Batch loss: 0.170191 Batch F1: 0.7741935483870968
Epoch:   73        9 Batch loss: 0.205020 Batch F1: 0.6818181818181819
Epoch:   73       10 Batch loss: 0.175271 Batch F1: 0.7368421052631577
Epoch:   73       11 Batch loss: 0.165466 Batch F1: 0.7499999999999999
Epoch:   73       12 Batch loss: 0.189659 Batch F1: 0.7317073170731707
Train Avg Loss   73: 0.184788

Train Avg F1   73: 0.7095467627118005

Val Avg Loss   73: 0.192486

Val Avg F1   73:  0.6784937137330754

Optimal Val loss (Epoch 71): 0.18920686468482018

Epoch 74
--------------------------------------------------------------
Epoch:   74        1 Batch loss: 0.168942 Batch F1: 0.6486486486486486
Epoch:   74        2 Batch loss: 0.201273 Batch F1: 0.6382978723404256
Epoch:   74        3 Batch loss: 0.174909 Batch F1: 0.6923076923076923
Epoch:   74        4 Batch loss: 0.189296 Batch F1: 0.6666666666666666
Epoch:   74        5 Batch loss: 0.207646 Batch F1: 0.5957446808510638
Epoch:   74        6 Batch loss: 0.178261 Batch F1: 0.6046511627906976
Epoch:   74        7 Batch loss: 0.177393 Batch F1: 0.7450980392156864
Epoch:   74        8 Batch loss: 0.190058 Batch F1: 0.7017543859649122
Epoch:   74        9 Batch loss: 0.155539 Batch F1: 0.7727272727272727
Epoch:   74       10 Batch loss: 0.171419 Batch F1: 0.8076923076923077
Epoch:   74       11 Batch loss: 0.160801 Batch F1: 0.8292682926829269
Epoch:   74       12 Batch loss: 0.186949 Batch F1: 0.7058823529411765
Train Avg Loss   74: 0.180207

Train Avg F1   74: 0.7007282812357897

Val Avg Loss   74: 0.189697

Val Avg F1   74:  0.6692399267399268

Optimal Val loss (Epoch 71): 0.18920686468482018

Epoch 75
--------------------------------------------------------------
Epoch:   75        1 Batch loss: 0.206605 Batch F1: 0.6382978723404256
Epoch:   75        2 Batch loss: 0.156874 Batch F1: 0.7222222222222222
Epoch:   75        3 Batch loss: 0.180120 Batch F1: 0.7000000000000001
Epoch:   75        4 Batch loss: 0.192659 Batch F1: 0.6341463414634146
Epoch:   75        5 Batch loss: 0.141228 Batch F1: 0.8095238095238095
Epoch:   75        6 Batch loss: 0.186498 Batch F1: 0.6666666666666665
Epoch:   75        7 Batch loss: 0.203888 Batch F1: 0.689655172413793
Epoch:   75        8 Batch loss: 0.208254 Batch F1: 0.6666666666666667
Epoch:   75        9 Batch loss: 0.180593 Batch F1: 0.6666666666666666
Epoch:   75       10 Batch loss: 0.145044 Batch F1: 0.7804878048780487
Epoch:   75       11 Batch loss: 0.184435 Batch F1: 0.6818181818181818
Epoch:   75       12 Batch loss: 0.212312 Batch F1: 0.5294117647058824
Train Avg Loss   75: 0.183209

Train Avg F1   75: 0.6821302641138148

Val Avg Loss   75: 0.193535

Val Avg F1   75:  0.6660704781557498

Optimal Val loss (Epoch 71): 0.18920686468482018

Epoch 76
--------------------------------------------------------------
Epoch:   76        1 Batch loss: 0.186773 Batch F1: 0.6666666666666666
Epoch:   76        2 Batch loss: 0.191641 Batch F1: 0.6153846153846153
Epoch:   76        3 Batch loss: 0.185261 Batch F1: 0.631578947368421
Epoch:   76        4 Batch loss: 0.203703 Batch F1: 0.4375
Epoch:   76        5 Batch loss: 0.157131 Batch F1: 0.7555555555555555
Epoch:   76        6 Batch loss: 0.159638 Batch F1: 0.8461538461538461
Epoch:   76        7 Batch loss: 0.216279 Batch F1: 0.5714285714285715
Epoch:   76        8 Batch loss: 0.193207 Batch F1: 0.5957446808510638
Epoch:   76        9 Batch loss: 0.213440 Batch F1: 0.5365853658536586
Epoch:   76       10 Batch loss: 0.184060 Batch F1: 0.6923076923076923
Epoch:   76       11 Batch loss: 0.170254 Batch F1: 0.7200000000000001
Epoch:   76       12 Batch loss: 0.155212 Batch F1: 0.7222222222222223
Train Avg Loss   76: 0.184717

Train Avg F1   76: 0.6492606803160262

Val Avg Loss   76: 0.189934

Val Avg F1   76:  0.6785423316613467

Optimal Val loss (Epoch 71): 0.18920686468482018

Epoch 77
--------------------------------------------------------------
Epoch:   77        1 Batch loss: 0.174131 Batch F1: 0.723404255319149
Epoch:   77        2 Batch loss: 0.190121 Batch F1: 0.6666666666666666
Epoch:   77        3 Batch loss: 0.181194 Batch F1: 0.6956521739130435
Epoch:   77        4 Batch loss: 0.187963 Batch F1: 0.6
Epoch:   77        5 Batch loss: 0.159301 Batch F1: 0.7692307692307692
Epoch:   77        6 Batch loss: 0.173913 Batch F1: 0.717948717948718
Epoch:   77        7 Batch loss: 0.184291 Batch F1: 0.6956521739130435
Epoch:   77        8 Batch loss: 0.169526 Batch F1: 0.7555555555555556
Epoch:   77        9 Batch loss: 0.176226 Batch F1: 0.723404255319149
Epoch:   77       10 Batch loss: 0.159882 Batch F1: 0.8333333333333333
Epoch:   77       11 Batch loss: 0.185610 Batch F1: 0.7307692307692306
Epoch:   77       12 Batch loss: 0.213140 Batch F1: 0.5500000000000002
Train Avg Loss   77: 0.179608

Train Avg F1   77: 0.7051347609973883

Val Avg Loss   77: 0.191059

Val Avg F1   77:  0.6839445255858629

Optimal Val loss (Epoch 71): 0.18920686468482018

Epoch 78
--------------------------------------------------------------
Epoch:   78        1 Batch loss: 0.182551 Batch F1: 0.7924528301886793
Epoch:   78        2 Batch loss: 0.182740 Batch F1: 0.6808510638297872
Epoch:   78        3 Batch loss: 0.156733 Batch F1: 0.761904761904762
Epoch:   78        4 Batch loss: 0.172280 Batch F1: 0.8518518518518519
Epoch:   78        5 Batch loss: 0.175074 Batch F1: 0.6976744186046512
Epoch:   78        6 Batch loss: 0.187121 Batch F1: 0.6808510638297872
Epoch:   78        7 Batch loss: 0.216834 Batch F1: 0.5217391304347826
Epoch:   78        8 Batch loss: 0.157695 Batch F1: 0.7567567567567567
Epoch:   78        9 Batch loss: 0.153382 Batch F1: 0.8363636363636363
Epoch:   78       10 Batch loss: 0.207136 Batch F1: 0.6363636363636364
Epoch:   78       11 Batch loss: 0.179289 Batch F1: 0.6956521739130435
Epoch:   78       12 Batch loss: 0.174913 Batch F1: 0.5925925925925926
Train Avg Loss   78: 0.178812

Train Avg F1   78: 0.7087544930528304

Val Avg Loss   78: 0.189570

Val Avg F1   78:  0.6680855481727574

Optimal Val loss (Epoch 71): 0.18920686468482018

Epoch 79
--------------------------------------------------------------
Epoch:   79        1 Batch loss: 0.210971 Batch F1: 0.68
Epoch:   79        2 Batch loss: 0.164316 Batch F1: 0.7027027027027027
Epoch:   79        3 Batch loss: 0.187757 Batch F1: 0.6666666666666666
Epoch:   79        4 Batch loss: 0.177958 Batch F1: 0.5454545454545454
Epoch:   79        5 Batch loss: 0.185251 Batch F1: 0.8135593220338982
Epoch:   79        6 Batch loss: 0.153222 Batch F1: 0.7272727272727272
Epoch:   79        7 Batch loss: 0.173909 Batch F1: 0.7500000000000001
Epoch:   79        8 Batch loss: 0.192898 Batch F1: 0.6530612244897959
Epoch:   79        9 Batch loss: 0.161952 Batch F1: 0.7368421052631577
Epoch:   79       10 Batch loss: 0.188628 Batch F1: 0.6666666666666666
Epoch:   79       11 Batch loss: 0.179509 Batch F1: 0.6666666666666666
Epoch:   79       12 Batch loss: 0.185449 Batch F1: 0.6341463414634146
Train Avg Loss   79: 0.180152

Train Avg F1   79: 0.6869199140566868

Val Avg Loss   79: 0.192620

Val Avg F1   79:  0.655978835978836

Optimal Val loss (Epoch 71): 0.18920686468482018

Epoch 80
--------------------------------------------------------------
Epoch:   80        1 Batch loss: 0.206383 Batch F1: 0.6153846153846153
Epoch:   80        2 Batch loss: 0.205069 Batch F1: 0.5957446808510639
Epoch:   80        3 Batch loss: 0.192793 Batch F1: 0.6896551724137931
Epoch:   80        4 Batch loss: 0.179061 Batch F1: 0.6976744186046512
Epoch:   80        5 Batch loss: 0.188032 Batch F1: 0.711111111111111
Epoch:   80        6 Batch loss: 0.162193 Batch F1: 0.6818181818181819
Epoch:   80        7 Batch loss: 0.162236 Batch F1: 0.7826086956521738
Epoch:   80        8 Batch loss: 0.170437 Batch F1: 0.75
Epoch:   80        9 Batch loss: 0.191468 Batch F1: 0.6666666666666666
Epoch:   80       10 Batch loss: 0.188312 Batch F1: 0.6808510638297872
Epoch:   80       11 Batch loss: 0.156434 Batch F1: 0.6206896551724139
Epoch:   80       12 Batch loss: 0.186794 Batch F1: 0.7659574468085107
Train Avg Loss   80: 0.182434

Train Avg F1   80: 0.688180142359414

Val Avg Loss   80: 0.190584

Val Avg F1   80:  0.6716553287981859

Optimal Val loss (Epoch 71): 0.18920686468482018

Epoch 81
--------------------------------------------------------------
Epoch:   81        1 Batch loss: 0.164268 Batch F1: 0.7659574468085106
Epoch:   81        2 Batch loss: 0.196915 Batch F1: 0.5957446808510639
Epoch:   81        3 Batch loss: 0.177015 Batch F1: 0.7058823529411765
Epoch:   81        4 Batch loss: 0.171275 Batch F1: 0.7000000000000001
Epoch:   81        5 Batch loss: 0.180814 Batch F1: 0.6530612244897959
Epoch:   81        6 Batch loss: 0.167817 Batch F1: 0.761904761904762
Epoch:   81        7 Batch loss: 0.155163 Batch F1: 0.717948717948718
Epoch:   81        8 Batch loss: 0.175001 Batch F1: 0.723404255319149
Epoch:   81        9 Batch loss: 0.162494 Batch F1: 0.6842105263157895
Epoch:   81       10 Batch loss: 0.238435 Batch F1: 0.5909090909090909
Epoch:   81       11 Batch loss: 0.168683 Batch F1: 0.7619047619047619
Epoch:   81       12 Batch loss: 0.238059 Batch F1: 0.6249999999999999
Train Avg Loss   81: 0.182995

Train Avg F1   81: 0.6904939849494015

Val Avg Loss   81: 0.188566

Val Avg F1   81:  0.6872041214146476

Optimal Val loss (Epoch 81): 0.1885662078857422

Epoch 82
--------------------------------------------------------------
Epoch:   82        1 Batch loss: 0.167707 Batch F1: 0.7659574468085106
Epoch:   82        2 Batch loss: 0.181157 Batch F1: 0.7111111111111111
Epoch:   82        3 Batch loss: 0.158558 Batch F1: 0.6666666666666665
Epoch:   82        4 Batch loss: 0.203018 Batch F1: 0.4878048780487805
Epoch:   82        5 Batch loss: 0.160130 Batch F1: 0.8399999999999999
Epoch:   82        6 Batch loss: 0.171943 Batch F1: 0.7500000000000001
Epoch:   82        7 Batch loss: 0.187327 Batch F1: 0.6808510638297872
Epoch:   82        8 Batch loss: 0.164688 Batch F1: 0.7755102040816326
Epoch:   82        9 Batch loss: 0.187676 Batch F1: 0.7169811320754718
Epoch:   82       10 Batch loss: 0.177638 Batch F1: 0.7999999999999999
Epoch:   82       11 Batch loss: 0.193873 Batch F1: 0.8333333333333334
Epoch:   82       12 Batch loss: 0.195676 Batch F1: 0.8292682926829269
Train Avg Loss   82: 0.179116

Train Avg F1   82: 0.7381236773865184

Val Avg Loss   82: 0.192683

Val Avg F1   82:  0.7312073868503102

Optimal Val loss (Epoch 81): 0.1885662078857422

Epoch 83
--------------------------------------------------------------
Epoch:   83        1 Batch loss: 0.165039 Batch F1: 0.8085106382978724
Epoch:   83        2 Batch loss: 0.198678 Batch F1: 0.6808510638297872
Epoch:   83        3 Batch loss: 0.154733 Batch F1: 0.7804878048780488
Epoch:   83        4 Batch loss: 0.181979 Batch F1: 0.7924528301886793
Epoch:   83        5 Batch loss: 0.196113 Batch F1: 0.5641025641025641
Epoch:   83        6 Batch loss: 0.182506 Batch F1: 0.7843137254901961
Epoch:   83        7 Batch loss: 0.187580 Batch F1: 0.6511627906976744
Epoch:   83        8 Batch loss: 0.206728 Batch F1: 0.5957446808510638
Epoch:   83        9 Batch loss: 0.180909 Batch F1: 0.5405405405405405
Epoch:   83       10 Batch loss: 0.180390 Batch F1: 0.6808510638297872
Epoch:   83       11 Batch loss: 0.179202 Batch F1: 0.6511627906976744
Epoch:   83       12 Batch loss: 0.147073 Batch F1: 0.8292682926829269
Train Avg Loss   83: 0.180078

Train Avg F1   83: 0.6966207321739013

Val Avg Loss   83: 0.190904

Val Avg F1   83:  0.6678742065388028

Optimal Val loss (Epoch 81): 0.1885662078857422

Epoch 84
--------------------------------------------------------------
Epoch:   84        1 Batch loss: 0.184256 Batch F1: 0.7857142857142857
Epoch:   84        2 Batch loss: 0.182189 Batch F1: 0.6818181818181819
Epoch:   84        3 Batch loss: 0.174300 Batch F1: 0.7391304347826088
Epoch:   84        4 Batch loss: 0.164260 Batch F1: 0.8085106382978724
Epoch:   84        5 Batch loss: 0.211551 Batch F1: 0.6153846153846154
Epoch:   84        6 Batch loss: 0.184309 Batch F1: 0.6500000000000001
Epoch:   84        7 Batch loss: 0.198887 Batch F1: 0.5909090909090909
Epoch:   84        8 Batch loss: 0.174020 Batch F1: 0.7441860465116279
Epoch:   84        9 Batch loss: 0.178073 Batch F1: 0.4666666666666667
Epoch:   84       10 Batch loss: 0.156860 Batch F1: 0.8461538461538461
Epoch:   84       11 Batch loss: 0.178400 Batch F1: 0.7272727272727273
Epoch:   84       12 Batch loss: 0.146952 Batch F1: 0.7333333333333334
Train Avg Loss   84: 0.177838

Train Avg F1   84: 0.699089988903738

Val Avg Loss   84: 0.188240

Val Avg F1   84:  0.6679708281234645

Optimal Val loss (Epoch 84): 0.1882401406764984

Epoch 85
--------------------------------------------------------------
Epoch:   85        1 Batch loss: 0.191678 Batch F1: 0.6666666666666666
Epoch:   85        2 Batch loss: 0.179758 Batch F1: 0.6666666666666667
Epoch:   85        3 Batch loss: 0.180248 Batch F1: 0.6842105263157895
Epoch:   85        4 Batch loss: 0.153439 Batch F1: 0.8333333333333333
Epoch:   85        5 Batch loss: 0.146698 Batch F1: 0.8163265306122449
Epoch:   85        6 Batch loss: 0.185950 Batch F1: 0.6818181818181818
Epoch:   85        7 Batch loss: 0.157470 Batch F1: 0.8085106382978724
Epoch:   85        8 Batch loss: 0.188300 Batch F1: 0.72
Epoch:   85        9 Batch loss: 0.218639 Batch F1: 0.5818181818181818
Epoch:   85       10 Batch loss: 0.174693 Batch F1: 0.7307692307692308
Epoch:   85       11 Batch loss: 0.186401 Batch F1: 0.6046511627906976
Epoch:   85       12 Batch loss: 0.174644 Batch F1: 0.6315789473684211
Train Avg Loss   85: 0.178160

Train Avg F1   85: 0.7021958388714405

Val Avg Loss   85: 0.191396

Val Avg F1   85:  0.6690455096767389

Optimal Val loss (Epoch 84): 0.1882401406764984

Epoch 86
--------------------------------------------------------------
Epoch:   86        1 Batch loss: 0.204158 Batch F1: 0.5714285714285714
Epoch:   86        2 Batch loss: 0.198717 Batch F1: 0.6363636363636364
Epoch:   86        3 Batch loss: 0.199287 Batch F1: 0.7058823529411765
Epoch:   86        4 Batch loss: 0.165828 Batch F1: 0.7441860465116279
Epoch:   86        5 Batch loss: 0.145213 Batch F1: 0.8205128205128205
Epoch:   86        6 Batch loss: 0.164729 Batch F1: 0.7234042553191491
Epoch:   86        7 Batch loss: 0.172022 Batch F1: 0.6842105263157895
Epoch:   86        8 Batch loss: 0.181049 Batch F1: 0.5789473684210527
Epoch:   86        9 Batch loss: 0.177355 Batch F1: 0.7272727272727273
Epoch:   86       10 Batch loss: 0.178370 Batch F1: 0.7234042553191489
Epoch:   86       11 Batch loss: 0.199323 Batch F1: 0.736842105263158
Epoch:   86       12 Batch loss: 0.176636 Batch F1: 0.761904761904762
Train Avg Loss   86: 0.180224

Train Avg F1   86: 0.7011966189644684

Val Avg Loss   86: 0.191726

Val Avg F1   86:  0.6674161044801938

Optimal Val loss (Epoch 84): 0.1882401406764984

Epoch 87
--------------------------------------------------------------
Epoch:   87        1 Batch loss: 0.168832 Batch F1: 0.7555555555555555
Epoch:   87        2 Batch loss: 0.180023 Batch F1: 0.6666666666666666
Epoch:   87        3 Batch loss: 0.183151 Batch F1: 0.6666666666666666
Epoch:   87        4 Batch loss: 0.182605 Batch F1: 0.72
Epoch:   87        5 Batch loss: 0.187291 Batch F1: 0.6808510638297872
Epoch:   87        6 Batch loss: 0.203346 Batch F1: 0.47058823529411764
Epoch:   87        7 Batch loss: 0.190746 Batch F1: 0.6363636363636364
Epoch:   87        8 Batch loss: 0.129032 Batch F1: 0.8928571428571429
Epoch:   87        9 Batch loss: 0.174150 Batch F1: 0.723404255319149
Epoch:   87       10 Batch loss: 0.185423 Batch F1: 0.6666666666666666
Epoch:   87       11 Batch loss: 0.156452 Batch F1: 0.6666666666666667
Epoch:   87       12 Batch loss: 0.196754 Batch F1: 0.7272727272727273
Train Avg Loss   87: 0.178150

Train Avg F1   87: 0.6894632735965653

Val Avg Loss   87: 0.188142

Val Avg F1   87:  0.6671714452371338

Optimal Val loss (Epoch 87): 0.18814218416810036

Epoch 88
--------------------------------------------------------------
Epoch:   88        1 Batch loss: 0.144797 Batch F1: 0.8181818181818182
Epoch:   88        2 Batch loss: 0.169893 Batch F1: 0.8
Epoch:   88        3 Batch loss: 0.176466 Batch F1: 0.7659574468085107
Epoch:   88        4 Batch loss: 0.162243 Batch F1: 0.6486486486486486
Epoch:   88        5 Batch loss: 0.185715 Batch F1: 0.6808510638297872
Epoch:   88        6 Batch loss: 0.203731 Batch F1: 0.7118644067796611
Epoch:   88        7 Batch loss: 0.210896 Batch F1: 0.5263157894736842
Epoch:   88        8 Batch loss: 0.184060 Batch F1: 0.7234042553191491
Epoch:   88        9 Batch loss: 0.173708 Batch F1: 0.6829268292682926
Epoch:   88       10 Batch loss: 0.178888 Batch F1: 0.6818181818181818
Epoch:   88       11 Batch loss: 0.149519 Batch F1: 0.742857142857143
Epoch:   88       12 Batch loss: 0.187633 Batch F1: 0.6666666666666666
Train Avg Loss   88: 0.177296

Train Avg F1   88: 0.7041243541376286

Val Avg Loss   88: 0.192547

Val Avg F1   88:  0.6927968877968878

Optimal Val loss (Epoch 87): 0.18814218416810036

Epoch 89
--------------------------------------------------------------
Epoch:   89        1 Batch loss: 0.187256 Batch F1: 0.7317073170731708
Epoch:   89        2 Batch loss: 0.150262 Batch F1: 0.6842105263157895
Epoch:   89        3 Batch loss: 0.163055 Batch F1: 0.7169811320754716
Epoch:   89        4 Batch loss: 0.210382 Batch F1: 0.6122448979591837
Epoch:   89        5 Batch loss: 0.164800 Batch F1: 0.7111111111111111
Epoch:   89        6 Batch loss: 0.194877 Batch F1: 0.7636363636363636
Epoch:   89        7 Batch loss: 0.167551 Batch F1: 0.8148148148148148
Epoch:   89        8 Batch loss: 0.159718 Batch F1: 0.7906976744186046
Epoch:   89        9 Batch loss: 0.172559 Batch F1: 0.7272727272727273
Epoch:   89       10 Batch loss: 0.232024 Batch F1: 0.5
Epoch:   89       11 Batch loss: 0.193901 Batch F1: 0.5142857142857143
Epoch:   89       12 Batch loss: 0.197635 Batch F1: 0.6470588235294118
Train Avg Loss   89: 0.182835

Train Avg F1   89: 0.6845017585410303

Val Avg Loss   89: 0.193238

Val Avg F1   89:  0.6730895915678524

Optimal Val loss (Epoch 87): 0.18814218416810036

Epoch 90
--------------------------------------------------------------
Epoch:   90        1 Batch loss: 0.190768 Batch F1: 0.7547169811320754
Epoch:   90        2 Batch loss: 0.233337 Batch F1: 0.5185185185185185
Epoch:   90        3 Batch loss: 0.221965 Batch F1: 0.5128205128205129
Epoch:   90        4 Batch loss: 0.178955 Batch F1: 0.7441860465116279
Epoch:   90        5 Batch loss: 0.174238 Batch F1: 0.7906976744186046
Epoch:   90        6 Batch loss: 0.155933 Batch F1: 0.8846153846153846
Epoch:   90        7 Batch loss: 0.158767 Batch F1: 0.8260869565217391
Epoch:   90        8 Batch loss: 0.189518 Batch F1: 0.7692307692307692
Epoch:   90        9 Batch loss: 0.201193 Batch F1: 0.7407407407407408
Epoch:   90       10 Batch loss: 0.201160 Batch F1: 0.6808510638297872
Epoch:   90       11 Batch loss: 0.151016 Batch F1: 0.8085106382978723
Epoch:   90       12 Batch loss: 0.187571 Batch F1: 0.7317073170731708
Train Avg Loss   90: 0.187035

Train Avg F1   90: 0.7302235503092337

Val Avg Loss   90: 0.191059

Val Avg F1   90:  0.6755312950250022

Optimal Val loss (Epoch 87): 0.18814218416810036

Epoch 91
--------------------------------------------------------------
Epoch:   91        1 Batch loss: 0.188885 Batch F1: 0.5625
Epoch:   91        2 Batch loss: 0.161747 Batch F1: 0.6857142857142857
Epoch:   91        3 Batch loss: 0.197212 Batch F1: 0.6521739130434783
Epoch:   91        4 Batch loss: 0.216759 Batch F1: 0.5652173913043478
Epoch:   91        5 Batch loss: 0.231852 Batch F1: 0.7096774193548387
Epoch:   91        6 Batch loss: 0.157876 Batch F1: 0.7916666666666666
Epoch:   91        7 Batch loss: 0.176637 Batch F1: 0.7547169811320754
Epoch:   91        8 Batch loss: 0.186166 Batch F1: 0.6956521739130435
Epoch:   91        9 Batch loss: 0.146406 Batch F1: 0.7894736842105262
Epoch:   91       10 Batch loss: 0.170342 Batch F1: 0.7906976744186046
Epoch:   91       11 Batch loss: 0.173014 Batch F1: 0.7391304347826088
Epoch:   91       12 Batch loss: 0.189872 Batch F1: 0.6818181818181818
Train Avg Loss   91: 0.183064

Train Avg F1   91: 0.7015365671965547

Val Avg Loss   91: 0.191368

Val Avg F1   91:  0.7180766632894293

Optimal Val loss (Epoch 87): 0.18814218416810036

Epoch 92
--------------------------------------------------------------
Epoch:   92        1 Batch loss: 0.194393 Batch F1: 0.711111111111111
Epoch:   92        2 Batch loss: 0.197792 Batch F1: 0.8125000000000001
Epoch:   92        3 Batch loss: 0.186705 Batch F1: 0.8
Epoch:   92        4 Batch loss: 0.187951 Batch F1: 0.7555555555555556
Epoch:   92        5 Batch loss: 0.176677 Batch F1: 0.7142857142857143
Epoch:   92        6 Batch loss: 0.170943 Batch F1: 0.8085106382978724
Epoch:   92        7 Batch loss: 0.200855 Batch F1: 0.6222222222222222
Epoch:   92        8 Batch loss: 0.188719 Batch F1: 0.7368421052631579
Epoch:   92        9 Batch loss: 0.184025 Batch F1: 0.6382978723404256
Epoch:   92       10 Batch loss: 0.167906 Batch F1: 0.7450980392156864
Epoch:   92       11 Batch loss: 0.171851 Batch F1: 0.6976744186046512
Epoch:   92       12 Batch loss: 0.171714 Batch F1: 0.6451612903225806
Train Avg Loss   92: 0.183294

Train Avg F1   92: 0.7239382472682481

Val Avg Loss   92: 0.192898

Val Avg F1   92:  0.6742461946829248

Optimal Val loss (Epoch 87): 0.18814218416810036

Epoch 93
--------------------------------------------------------------
Epoch:   93        1 Batch loss: 0.172067 Batch F1: 0.7692307692307692
Epoch:   93        2 Batch loss: 0.182370 Batch F1: 0.72
Epoch:   93        3 Batch loss: 0.159709 Batch F1: 0.830188679245283
Epoch:   93        4 Batch loss: 0.216462 Batch F1: 0.6399999999999999
Epoch:   93        5 Batch loss: 0.196113 Batch F1: 0.6153846153846153
Epoch:   93        6 Batch loss: 0.184573 Batch F1: 0.6666666666666666
Epoch:   93        7 Batch loss: 0.166668 Batch F1: 0.7000000000000001
Epoch:   93        8 Batch loss: 0.210383 Batch F1: 0.7169811320754716
Epoch:   93        9 Batch loss: 0.206305 Batch F1: 0.5263157894736842
Epoch:   93       10 Batch loss: 0.174425 Batch F1: 0.6
Epoch:   93       11 Batch loss: 0.139825 Batch F1: 0.7804878048780488
Epoch:   93       12 Batch loss: 0.157290 Batch F1: 0.75
Train Avg Loss   93: 0.180516

Train Avg F1   93: 0.6929379547462116

Val Avg Loss   93: 0.191767

Val Avg F1   93:  0.6482829413960433

Optimal Val loss (Epoch 87): 0.18814218416810036

Epoch 94
--------------------------------------------------------------
Epoch:   94        1 Batch loss: 0.161786 Batch F1: 0.8461538461538461
Epoch:   94        2 Batch loss: 0.192132 Batch F1: 0.5641025641025641
Epoch:   94        3 Batch loss: 0.205817 Batch F1: 0.5909090909090908
Epoch:   94        4 Batch loss: 0.189016 Batch F1: 0.7200000000000001
Epoch:   94        5 Batch loss: 0.171494 Batch F1: 0.7755102040816326
Epoch:   94        6 Batch loss: 0.192394 Batch F1: 0.7083333333333333
Epoch:   94        7 Batch loss: 0.164442 Batch F1: 0.7555555555555555
Epoch:   94        8 Batch loss: 0.157313 Batch F1: 0.7906976744186046
Epoch:   94        9 Batch loss: 0.180978 Batch F1: 0.6341463414634146
Epoch:   94       10 Batch loss: 0.185359 Batch F1: 0.6530612244897959
Epoch:   94       11 Batch loss: 0.152374 Batch F1: 0.7058823529411765
Epoch:   94       12 Batch loss: 0.190537 Batch F1: 0.6857142857142857
Train Avg Loss   94: 0.178637

Train Avg F1   94: 0.7025055394302749

Val Avg Loss   94: 0.189504

Val Avg F1   94:  0.6737588652482269

Optimal Val loss (Epoch 87): 0.18814218416810036

Epoch 95
--------------------------------------------------------------
Epoch:   95        1 Batch loss: 0.175323 Batch F1: 0.7272727272727272
Epoch:   95        2 Batch loss: 0.189567 Batch F1: 0.6363636363636364
Epoch:   95        3 Batch loss: 0.197416 Batch F1: 0.6666666666666666
Epoch:   95        4 Batch loss: 0.163904 Batch F1: 0.7368421052631579
Epoch:   95        5 Batch loss: 0.176177 Batch F1: 0.7857142857142856
Epoch:   95        6 Batch loss: 0.184058 Batch F1: 0.7407407407407407
Epoch:   95        7 Batch loss: 0.209307 Batch F1: 0.72
Epoch:   95        8 Batch loss: 0.203101 Batch F1: 0.7058823529411764
Epoch:   95        9 Batch loss: 0.181450 Batch F1: 0.75
Epoch:   95       10 Batch loss: 0.178573 Batch F1: 0.6956521739130435
Epoch:   95       11 Batch loss: 0.162834 Batch F1: 0.7500000000000001
Epoch:   95       12 Batch loss: 0.175327 Batch F1: 0.761904761904762
Train Avg Loss   95: 0.183086

Train Avg F1   95: 0.7230866208983499

Val Avg Loss   95: 0.191273

Val Avg F1   95:  0.6714772727272728

Optimal Val loss (Epoch 87): 0.18814218416810036

Epoch 96
--------------------------------------------------------------
Epoch:   96        1 Batch loss: 0.148878 Batch F1: 0.7906976744186046
Epoch:   96        2 Batch loss: 0.206807 Batch F1: 0.6086956521739131
Epoch:   96        3 Batch loss: 0.202001 Batch F1: 0.5581395348837209
Epoch:   96        4 Batch loss: 0.166958 Batch F1: 0.7500000000000001
Epoch:   96        5 Batch loss: 0.182123 Batch F1: 0.6111111111111113
Epoch:   96        6 Batch loss: 0.175239 Batch F1: 0.7619047619047619
Epoch:   96        7 Batch loss: 0.199937 Batch F1: 0.7058823529411765
Epoch:   96        8 Batch loss: 0.155129 Batch F1: 0.7499999999999999
Epoch:   96        9 Batch loss: 0.167040 Batch F1: 0.7916666666666666
Epoch:   96       10 Batch loss: 0.170442 Batch F1: 0.7346938775510203
Epoch:   96       11 Batch loss: 0.196751 Batch F1: 0.6666666666666666
Epoch:   96       12 Batch loss: 0.172702 Batch F1: 0.7727272727272727
Train Avg Loss   96: 0.178667

Train Avg F1   96: 0.7085154642537429

Val Avg Loss   96: 0.186080

Val Avg F1   96:  0.6968218102652065

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 97
--------------------------------------------------------------
Epoch:   97        1 Batch loss: 0.188542 Batch F1: 0.6511627906976744
Epoch:   97        2 Batch loss: 0.178953 Batch F1: 0.65
Epoch:   97        3 Batch loss: 0.161413 Batch F1: 0.782608695652174
Epoch:   97        4 Batch loss: 0.198503 Batch F1: 0.6190476190476191
Epoch:   97        5 Batch loss: 0.179447 Batch F1: 0.6666666666666666
Epoch:   97        6 Batch loss: 0.173938 Batch F1: 0.7441860465116279
Epoch:   97        7 Batch loss: 0.182795 Batch F1: 0.711111111111111
Epoch:   97        8 Batch loss: 0.214439 Batch F1: 0.5
Epoch:   97        9 Batch loss: 0.134100 Batch F1: 0.912280701754386
Epoch:   97       10 Batch loss: 0.160971 Batch F1: 0.782608695652174
Epoch:   97       11 Batch loss: 0.172159 Batch F1: 0.6666666666666667
Epoch:   97       12 Batch loss: 0.170050 Batch F1: 0.7441860465116279
Train Avg Loss   97: 0.176276

Train Avg F1   97: 0.7025437533559774

Val Avg Loss   97: 0.187849

Val Avg F1   97:  0.6764135856729823

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 98
--------------------------------------------------------------
Epoch:   98        1 Batch loss: 0.178651 Batch F1: 0.6341463414634146
Epoch:   98        2 Batch loss: 0.173125 Batch F1: 0.6666666666666667
Epoch:   98        3 Batch loss: 0.171801 Batch F1: 0.7727272727272727
Epoch:   98        4 Batch loss: 0.169693 Batch F1: 0.7083333333333333
Epoch:   98        5 Batch loss: 0.212695 Batch F1: 0.6909090909090908
Epoch:   98        6 Batch loss: 0.186239 Batch F1: 0.6382978723404256
Epoch:   98        7 Batch loss: 0.155024 Batch F1: 0.7843137254901961
Epoch:   98        8 Batch loss: 0.157566 Batch F1: 0.8518518518518519
Epoch:   98        9 Batch loss: 0.179684 Batch F1: 0.6153846153846153
Epoch:   98       10 Batch loss: 0.198160 Batch F1: 0.6808510638297872
Epoch:   98       11 Batch loss: 0.170745 Batch F1: 0.5714285714285715
Epoch:   98       12 Batch loss: 0.180866 Batch F1: 0.6666666666666666
Train Avg Loss   98: 0.177854

Train Avg F1   98: 0.6901314226743244

Val Avg Loss   98: 0.189311

Val Avg F1   98:  0.6747986457455611

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 99
--------------------------------------------------------------
Epoch:   99        1 Batch loss: 0.148665 Batch F1: 0.8372093023255814
Epoch:   99        2 Batch loss: 0.192273 Batch F1: 0.7058823529411765
Epoch:   99        3 Batch loss: 0.217692 Batch F1: 0.47619047619047616
Epoch:   99        4 Batch loss: 0.225438 Batch F1: 0.5909090909090909
Epoch:   99        5 Batch loss: 0.165358 Batch F1: 0.761904761904762
Epoch:   99        6 Batch loss: 0.167674 Batch F1: 0.6666666666666666
Epoch:   99        7 Batch loss: 0.155827 Batch F1: 0.7906976744186046
Epoch:   99        8 Batch loss: 0.167473 Batch F1: 0.6829268292682927
Epoch:   99        9 Batch loss: 0.144497 Batch F1: 0.7368421052631577
Epoch:   99       10 Batch loss: 0.177421 Batch F1: 0.65
Epoch:   99       11 Batch loss: 0.182951 Batch F1: 0.8
Epoch:   99       12 Batch loss: 0.184475 Batch F1: 0.6666666666666666
Train Avg Loss   99: 0.177479

Train Avg F1   99: 0.6971579938795395

Val Avg Loss   99: 0.188138

Val Avg F1   99:  0.691063829787234

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 100
--------------------------------------------------------------
Epoch:  100        1 Batch loss: 0.159893 Batch F1: 0.7027027027027027
Epoch:  100        2 Batch loss: 0.163302 Batch F1: 0.7272727272727272
Epoch:  100        3 Batch loss: 0.171334 Batch F1: 0.7659574468085107
Epoch:  100        4 Batch loss: 0.175215 Batch F1: 0.8400000000000001
Epoch:  100        5 Batch loss: 0.159226 Batch F1: 0.8076923076923077
Epoch:  100        6 Batch loss: 0.198819 Batch F1: 0.5500000000000002
Epoch:  100        7 Batch loss: 0.207065 Batch F1: 0.5581395348837208
Epoch:  100        8 Batch loss: 0.199217 Batch F1: 0.6956521739130435
Epoch:  100        9 Batch loss: 0.197521 Batch F1: 0.6666666666666667
Epoch:  100       10 Batch loss: 0.169981 Batch F1: 0.6857142857142857
Epoch:  100       11 Batch loss: 0.184076 Batch F1: 0.7499999999999999
Epoch:  100       12 Batch loss: 0.162935 Batch F1: 0.782608695652174
Train Avg Loss  100: 0.179049

Train Avg F1  100: 0.7110338784421782

Val Avg Loss  100: 0.188774

Val Avg F1  100:  0.6356675553732568

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 101
--------------------------------------------------------------
Epoch:  101        1 Batch loss: 0.172003 Batch F1: 0.68
Epoch:  101        2 Batch loss: 0.195539 Batch F1: 0.6666666666666667
Epoch:  101        3 Batch loss: 0.212747 Batch F1: 0.6666666666666667
Epoch:  101        4 Batch loss: 0.193376 Batch F1: 0.6792452830188679
Epoch:  101        5 Batch loss: 0.162331 Batch F1: 0.6808510638297872
Epoch:  101        6 Batch loss: 0.203590 Batch F1: 0.693877551020408
Epoch:  101        7 Batch loss: 0.199785 Batch F1: 0.6222222222222223
Epoch:  101        8 Batch loss: 0.181452 Batch F1: 0.6486486486486486
Epoch:  101        9 Batch loss: 0.190079 Batch F1: 0.6511627906976745
Epoch:  101       10 Batch loss: 0.145059 Batch F1: 0.7999999999999999
Epoch:  101       11 Batch loss: 0.165240 Batch F1: 0.7441860465116279
Epoch:  101       12 Batch loss: 0.173295 Batch F1: 0.7555555555555556
Train Avg Loss  101: 0.182875

Train Avg F1  101: 0.6907568745698439

Val Avg Loss  101: 0.196264

Val Avg F1  101:  0.7302142935956243

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 102
--------------------------------------------------------------
Epoch:  102        1 Batch loss: 0.218362 Batch F1: 0.6274509803921569
Epoch:  102        2 Batch loss: 0.144866 Batch F1: 0.7906976744186046
Epoch:  102        3 Batch loss: 0.196474 Batch F1: 0.5641025641025642
Epoch:  102        4 Batch loss: 0.176154 Batch F1: 0.7234042553191489
Epoch:  102        5 Batch loss: 0.173302 Batch F1: 0.7027027027027027
Epoch:  102        6 Batch loss: 0.193120 Batch F1: 0.7200000000000001
Epoch:  102        7 Batch loss: 0.169712 Batch F1: 0.6829268292682926
Epoch:  102        8 Batch loss: 0.188719 Batch F1: 0.75
Epoch:  102        9 Batch loss: 0.194592 Batch F1: 0.5853658536585366
Epoch:  102       10 Batch loss: 0.169219 Batch F1: 0.8108108108108109
Epoch:  102       11 Batch loss: 0.186868 Batch F1: 0.75
Epoch:  102       12 Batch loss: 0.167948 Batch F1: 0.7500000000000001
Train Avg Loss  102: 0.181611

Train Avg F1  102: 0.7047884725560681

Val Avg Loss  102: 0.190149

Val Avg F1  102:  0.6355393558223748

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 103
--------------------------------------------------------------
Epoch:  103        1 Batch loss: 0.200441 Batch F1: 0.6666666666666666
Epoch:  103        2 Batch loss: 0.156786 Batch F1: 0.6666666666666667
Epoch:  103        3 Batch loss: 0.195620 Batch F1: 0.5581395348837209
Epoch:  103        4 Batch loss: 0.165728 Batch F1: 0.7450980392156864
Epoch:  103        5 Batch loss: 0.179241 Batch F1: 0.75
Epoch:  103        6 Batch loss: 0.172245 Batch F1: 0.6666666666666666
Epoch:  103        7 Batch loss: 0.171249 Batch F1: 0.7916666666666667
Epoch:  103        8 Batch loss: 0.165760 Batch F1: 0.6857142857142857
Epoch:  103        9 Batch loss: 0.182377 Batch F1: 0.6938775510204083
Epoch:  103       10 Batch loss: 0.187889 Batch F1: 0.7083333333333334
Epoch:  103       11 Batch loss: 0.177399 Batch F1: 0.7234042553191491
Epoch:  103       12 Batch loss: 0.179675 Batch F1: 0.631578947368421
Train Avg Loss  103: 0.177867

Train Avg F1  103: 0.6906510511268059

Val Avg Loss  103: 0.188114

Val Avg F1  103:  0.6800540906017579

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 104
--------------------------------------------------------------
Epoch:  104        1 Batch loss: 0.200918 Batch F1: 0.6086956521739131
Epoch:  104        2 Batch loss: 0.197854 Batch F1: 0.7796610169491526
Epoch:  104        3 Batch loss: 0.182361 Batch F1: 0.7058823529411765
Epoch:  104        4 Batch loss: 0.170939 Batch F1: 0.7391304347826088
Epoch:  104        5 Batch loss: 0.170039 Batch F1: 0.7555555555555556
Epoch:  104        6 Batch loss: 0.155133 Batch F1: 0.7894736842105263
Epoch:  104        7 Batch loss: 0.184831 Batch F1: 0.6666666666666666
Epoch:  104        8 Batch loss: 0.184295 Batch F1: 0.7450980392156863
Epoch:  104        9 Batch loss: 0.185225 Batch F1: 0.5454545454545454
Epoch:  104       10 Batch loss: 0.166244 Batch F1: 0.7317073170731706
Epoch:  104       11 Batch loss: 0.153539 Batch F1: 0.7916666666666666
Epoch:  104       12 Batch loss: 0.158160 Batch F1: 0.7428571428571428
Train Avg Loss  104: 0.175795

Train Avg F1  104: 0.7168207562122343

Val Avg Loss  104: 0.188456

Val Avg F1  104:  0.6653019472928288

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 105
--------------------------------------------------------------
Epoch:  105        1 Batch loss: 0.160378 Batch F1: 0.7843137254901961
Epoch:  105        2 Batch loss: 0.173267 Batch F1: 0.5945945945945946
Epoch:  105        3 Batch loss: 0.187105 Batch F1: 0.68
Epoch:  105        4 Batch loss: 0.160882 Batch F1: 0.8235294117647057
Epoch:  105        5 Batch loss: 0.170222 Batch F1: 0.7499999999999999
Epoch:  105        6 Batch loss: 0.163707 Batch F1: 0.8095238095238095
Epoch:  105        7 Batch loss: 0.200956 Batch F1: 0.6666666666666666
Epoch:  105        8 Batch loss: 0.177735 Batch F1: 0.7083333333333334
Epoch:  105        9 Batch loss: 0.195907 Batch F1: 0.6046511627906976
Epoch:  105       10 Batch loss: 0.220070 Batch F1: 0.4390243902439024
Epoch:  105       11 Batch loss: 0.176348 Batch F1: 0.76
Epoch:  105       12 Batch loss: 0.190590 Batch F1: 0.6060606060606061
Train Avg Loss  105: 0.181431

Train Avg F1  105: 0.6855581417057093

Val Avg Loss  105: 0.190804

Val Avg F1  105:  0.6638551996783705

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 106
--------------------------------------------------------------
Epoch:  106        1 Batch loss: 0.181125 Batch F1: 0.6666666666666666
Epoch:  106        2 Batch loss: 0.176703 Batch F1: 0.7755102040816326
Epoch:  106        3 Batch loss: 0.186861 Batch F1: 0.6500000000000001
Epoch:  106        4 Batch loss: 0.168451 Batch F1: 0.7499999999999999
Epoch:  106        5 Batch loss: 0.169016 Batch F1: 0.8421052631578948
Epoch:  106        6 Batch loss: 0.222551 Batch F1: 0.6382978723404255
Epoch:  106        7 Batch loss: 0.219517 Batch F1: 0.4117647058823529
Epoch:  106        8 Batch loss: 0.148473 Batch F1: 0.7894736842105262
Epoch:  106        9 Batch loss: 0.183856 Batch F1: 0.6666666666666666
Epoch:  106       10 Batch loss: 0.186066 Batch F1: 0.6341463414634146
Epoch:  106       11 Batch loss: 0.155780 Batch F1: 0.8461538461538461
Epoch:  106       12 Batch loss: 0.194931 Batch F1: 0.6976744186046512
Train Avg Loss  106: 0.182777

Train Avg F1  106: 0.6973716391023398

Val Avg Loss  106: 0.189542

Val Avg F1  106:  0.636499690785405

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 107
--------------------------------------------------------------
Epoch:  107        1 Batch loss: 0.160223 Batch F1: 0.7755102040816326
Epoch:  107        2 Batch loss: 0.209721 Batch F1: 0.5714285714285714
Epoch:  107        3 Batch loss: 0.198162 Batch F1: 0.5641025641025641
Epoch:  107        4 Batch loss: 0.176432 Batch F1: 0.7234042553191489
Epoch:  107        5 Batch loss: 0.185588 Batch F1: 0.6956521739130435
Epoch:  107        6 Batch loss: 0.188297 Batch F1: 0.7450980392156864
Epoch:  107        7 Batch loss: 0.180135 Batch F1: 0.7777777777777779
Epoch:  107        8 Batch loss: 0.178362 Batch F1: 0.65
Epoch:  107        9 Batch loss: 0.200924 Batch F1: 0.6363636363636365
Epoch:  107       10 Batch loss: 0.161190 Batch F1: 0.7272727272727272
Epoch:  107       11 Batch loss: 0.199115 Batch F1: 0.6956521739130435
Epoch:  107       12 Batch loss: 0.181389 Batch F1: 0.7179487179487181
Train Avg Loss  107: 0.184962

Train Avg F1  107: 0.6900175701113792

Val Avg Loss  107: 0.186564

Val Avg F1  107:  0.6847893687114883

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 108
--------------------------------------------------------------
Epoch:  108        1 Batch loss: 0.179402 Batch F1: 0.6666666666666666
Epoch:  108        2 Batch loss: 0.176409 Batch F1: 0.7083333333333334
Epoch:  108        3 Batch loss: 0.206887 Batch F1: 0.3870967741935484
Epoch:  108        4 Batch loss: 0.165852 Batch F1: 0.7441860465116279
Epoch:  108        5 Batch loss: 0.185697 Batch F1: 0.6956521739130435
Epoch:  108        6 Batch loss: 0.185277 Batch F1: 0.7857142857142857
Epoch:  108        7 Batch loss: 0.156163 Batch F1: 0.8695652173913043
Epoch:  108        8 Batch loss: 0.177800 Batch F1: 0.7317073170731707
Epoch:  108        9 Batch loss: 0.158228 Batch F1: 0.7826086956521738
Epoch:  108       10 Batch loss: 0.202057 Batch F1: 0.6923076923076923
Epoch:  108       11 Batch loss: 0.166578 Batch F1: 0.6842105263157895
Epoch:  108       12 Batch loss: 0.163834 Batch F1: 0.8444444444444444
Train Avg Loss  108: 0.177015

Train Avg F1  108: 0.7160410977930901

Val Avg Loss  108: 0.187759

Val Avg F1  108:  0.6737452039777622

Optimal Val loss (Epoch 96): 0.18608033284544945

Epoch 109
--------------------------------------------------------------
Epoch:  109        1 Batch loss: 0.170311 Batch F1: 0.8085106382978724
Epoch:  109        2 Batch loss: 0.163162 Batch F1: 0.6666666666666667
Epoch:  109        3 Batch loss: 0.139567 Batch F1: 0.8444444444444444
Epoch:  109        4 Batch loss: 0.189812 Batch F1: 0.6046511627906977
Epoch:  109        5 Batch loss: 0.187369 Batch F1: 0.72
Epoch:  109        6 Batch loss: 0.172071 Batch F1: 0.6666666666666667
Epoch:  109        7 Batch loss: 0.215306 Batch F1: 0.6666666666666666
Epoch:  109        8 Batch loss: 0.161563 Batch F1: 0.761904761904762
Epoch:  109        9 Batch loss: 0.185449 Batch F1: 0.5641025641025642
Epoch:  109       10 Batch loss: 0.173214 Batch F1: 0.6666666666666666
Epoch:  109       11 Batch loss: 0.149499 Batch F1: 0.8679245283018868
Epoch:  109       12 Batch loss: 0.178605 Batch F1: 0.6857142857142857
Train Avg Loss  109: 0.173827

Train Avg F1  109: 0.710326587685265

Val Avg Loss  109: 0.185595

Val Avg F1  109:  0.7033211500974659

Optimal Val loss (Epoch 109): 0.18559519574046135

Epoch 110
--------------------------------------------------------------
Epoch:  110        1 Batch loss: 0.146905 Batch F1: 0.7619047619047619
Epoch:  110        2 Batch loss: 0.159068 Batch F1: 0.7317073170731706
Epoch:  110        3 Batch loss: 0.138825 Batch F1: 0.8627450980392156
Epoch:  110        4 Batch loss: 0.170283 Batch F1: 0.76
Epoch:  110        5 Batch loss: 0.177937 Batch F1: 0.65
Epoch:  110        6 Batch loss: 0.176279 Batch F1: 0.7659574468085107
Epoch:  110        7 Batch loss: 0.174307 Batch F1: 0.6666666666666667
Epoch:  110        8 Batch loss: 0.181682 Batch F1: 0.7450980392156863
Epoch:  110        9 Batch loss: 0.190046 Batch F1: 0.6521739130434783
Epoch:  110       10 Batch loss: 0.193993 Batch F1: 0.7058823529411765
Epoch:  110       11 Batch loss: 0.161400 Batch F1: 0.7142857142857143
Epoch:  110       12 Batch loss: 0.200535 Batch F1: 0.5454545454545455
Train Avg Loss  110: 0.172605

Train Avg F1  110: 0.7134896546194106

Val Avg Loss  110: 0.185096

Val Avg F1  110:  0.6813656180040062

Optimal Val loss (Epoch 110): 0.1850963942706585

Epoch 111
--------------------------------------------------------------
Epoch:  111        1 Batch loss: 0.165144 Batch F1: 0.7924528301886793
Epoch:  111        2 Batch loss: 0.169946 Batch F1: 0.711111111111111
Epoch:  111        3 Batch loss: 0.172267 Batch F1: 0.711111111111111
Epoch:  111        4 Batch loss: 0.135582 Batch F1: 0.8333333333333334
Epoch:  111        5 Batch loss: 0.178048 Batch F1: 0.6808510638297872
Epoch:  111        6 Batch loss: 0.179049 Batch F1: 0.6818181818181819
Epoch:  111        7 Batch loss: 0.186402 Batch F1: 0.6666666666666666
Epoch:  111        8 Batch loss: 0.179622 Batch F1: 0.631578947368421
Epoch:  111        9 Batch loss: 0.174305 Batch F1: 0.6808510638297872
Epoch:  111       10 Batch loss: 0.191389 Batch F1: 0.6956521739130435
Epoch:  111       11 Batch loss: 0.174970 Batch F1: 0.7111111111111111
Epoch:  111       12 Batch loss: 0.185481 Batch F1: 0.625
Train Avg Loss  111: 0.174350

Train Avg F1  111: 0.701794799523436

Val Avg Loss  111: 0.192461

Val Avg F1  111:  0.6846576711644177

Optimal Val loss (Epoch 110): 0.1850963942706585

Epoch 112
--------------------------------------------------------------
Epoch:  112        1 Batch loss: 0.206833 Batch F1: 0.6666666666666666
Epoch:  112        2 Batch loss: 0.155577 Batch F1: 0.7999999999999999
Epoch:  112        3 Batch loss: 0.159986 Batch F1: 0.7234042553191491
Epoch:  112        4 Batch loss: 0.192015 Batch F1: 0.7555555555555555
Epoch:  112        5 Batch loss: 0.210375 Batch F1: 0.6
Epoch:  112        6 Batch loss: 0.180647 Batch F1: 0.6500000000000001
Epoch:  112        7 Batch loss: 0.158314 Batch F1: 0.7142857142857143
Epoch:  112        8 Batch loss: 0.178585 Batch F1: 0.5853658536585366
Epoch:  112        9 Batch loss: 0.166280 Batch F1: 0.761904761904762
Epoch:  112       10 Batch loss: 0.182184 Batch F1: 0.7111111111111111
Epoch:  112       11 Batch loss: 0.217477 Batch F1: 0.6363636363636364
Epoch:  112       12 Batch loss: 0.168228 Batch F1: 0.7222222222222222
Train Avg Loss  112: 0.181375

Train Avg F1  112: 0.6939066480906129

Val Avg Loss  112: 0.191911

Val Avg F1  112:  0.6549490667137726

Optimal Val loss (Epoch 110): 0.1850963942706585

Epoch 113
--------------------------------------------------------------
Epoch:  113        1 Batch loss: 0.196490 Batch F1: 0.6938775510204083
Epoch:  113        2 Batch loss: 0.178097 Batch F1: 0.6666666666666666
Epoch:  113        3 Batch loss: 0.184826 Batch F1: 0.6521739130434783
Epoch:  113        4 Batch loss: 0.182794 Batch F1: 0.7058823529411765
Epoch:  113        5 Batch loss: 0.189524 Batch F1: 0.6956521739130435
Epoch:  113        6 Batch loss: 0.205429 Batch F1: 0.6666666666666666
Epoch:  113        7 Batch loss: 0.167245 Batch F1: 0.8148148148148148
Epoch:  113        8 Batch loss: 0.186500 Batch F1: 0.6666666666666666
Epoch:  113        9 Batch loss: 0.166857 Batch F1: 0.7317073170731708
Epoch:  113       10 Batch loss: 0.192993 Batch F1: 0.64
Epoch:  113       11 Batch loss: 0.143480 Batch F1: 0.8679245283018868
Epoch:  113       12 Batch loss: 0.173401 Batch F1: 0.6829268292682927
Train Avg Loss  113: 0.180636

Train Avg F1  113: 0.7070799566980227

Val Avg Loss  113: 0.191904

Val Avg F1  113:  0.6310541310541311

Optimal Val loss (Epoch 110): 0.1850963942706585

Epoch 114
--------------------------------------------------------------
Epoch:  114        1 Batch loss: 0.186160 Batch F1: 0.5909090909090909
Epoch:  114        2 Batch loss: 0.152593 Batch F1: 0.8076923076923077
Epoch:  114        3 Batch loss: 0.172966 Batch F1: 0.6842105263157895
Epoch:  114        4 Batch loss: 0.240192 Batch F1: 0.56
Epoch:  114        5 Batch loss: 0.169261 Batch F1: 0.782608695652174
Epoch:  114        6 Batch loss: 0.157015 Batch F1: 0.7619047619047619
Epoch:  114        7 Batch loss: 0.178834 Batch F1: 0.7857142857142857
Epoch:  114        8 Batch loss: 0.177781 Batch F1: 0.7843137254901961
Epoch:  114        9 Batch loss: 0.165648 Batch F1: 0.7142857142857143
Epoch:  114       10 Batch loss: 0.152861 Batch F1: 0.7804878048780488
Epoch:  114       11 Batch loss: 0.199717 Batch F1: 0.5454545454545454
Epoch:  114       12 Batch loss: 0.193318 Batch F1: 0.5405405405405405
Train Avg Loss  114: 0.178862

Train Avg F1  114: 0.6948434999031212

Val Avg Loss  114: 0.188724

Val Avg F1  114:  0.6663450162673765

Optimal Val loss (Epoch 110): 0.1850963942706585

Epoch 115
--------------------------------------------------------------
Epoch:  115        1 Batch loss: 0.149559 Batch F1: 0.8181818181818182
Epoch:  115        2 Batch loss: 0.195438 Batch F1: 0.7058823529411765
Epoch:  115        3 Batch loss: 0.175550 Batch F1: 0.75
Epoch:  115        4 Batch loss: 0.155714 Batch F1: 0.7826086956521738
Epoch:  115        5 Batch loss: 0.201751 Batch F1: 0.5789473684210527
Epoch:  115        6 Batch loss: 0.175213 Batch F1: 0.6976744186046512
Epoch:  115        7 Batch loss: 0.203350 Batch F1: 0.6086956521739131
Epoch:  115        8 Batch loss: 0.142287 Batch F1: 0.7692307692307693
Epoch:  115        9 Batch loss: 0.181041 Batch F1: 0.6938775510204083
Epoch:  115       10 Batch loss: 0.158293 Batch F1: 0.7368421052631579
Epoch:  115       11 Batch loss: 0.174993 Batch F1: 0.6818181818181819
Epoch:  115       12 Batch loss: 0.197778 Batch F1: 0.7272727272727272
Train Avg Loss  115: 0.175914

Train Avg F1  115: 0.7125859700483358

Val Avg Loss  115: 0.181631

Val Avg F1  115:  0.6770875179340028

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 116
--------------------------------------------------------------
Epoch:  116        1 Batch loss: 0.174698 Batch F1: 0.5714285714285715
Epoch:  116        2 Batch loss: 0.178822 Batch F1: 0.7058823529411765
Epoch:  116        3 Batch loss: 0.175602 Batch F1: 0.6666666666666667
Epoch:  116        4 Batch loss: 0.166078 Batch F1: 0.7391304347826088
Epoch:  116        5 Batch loss: 0.191855 Batch F1: 0.6222222222222222
Epoch:  116        6 Batch loss: 0.178831 Batch F1: 0.7000000000000001
Epoch:  116        7 Batch loss: 0.153915 Batch F1: 0.7727272727272727
Epoch:  116        8 Batch loss: 0.178615 Batch F1: 0.6666666666666666
Epoch:  116        9 Batch loss: 0.162078 Batch F1: 0.7727272727272727
Epoch:  116       10 Batch loss: 0.160677 Batch F1: 0.7727272727272727
Epoch:  116       11 Batch loss: 0.163426 Batch F1: 0.8214285714285714
Epoch:  116       12 Batch loss: 0.181069 Batch F1: 0.6666666666666667
Train Avg Loss  116: 0.172139

Train Avg F1  116: 0.706522830915414

Val Avg Loss  116: 0.183861

Val Avg F1  116:  0.6960184819805542

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 117
--------------------------------------------------------------
Epoch:  117        1 Batch loss: 0.162943 Batch F1: 0.7916666666666666
Epoch:  117        2 Batch loss: 0.176206 Batch F1: 0.7547169811320755
Epoch:  117        3 Batch loss: 0.161562 Batch F1: 0.7
Epoch:  117        4 Batch loss: 0.153646 Batch F1: 0.7428571428571428
Epoch:  117        5 Batch loss: 0.201966 Batch F1: 0.619047619047619
Epoch:  117        6 Batch loss: 0.159269 Batch F1: 0.7843137254901961
Epoch:  117        7 Batch loss: 0.162981 Batch F1: 0.7755102040816326
Epoch:  117        8 Batch loss: 0.192800 Batch F1: 0.7037037037037037
Epoch:  117        9 Batch loss: 0.186047 Batch F1: 0.5405405405405405
Epoch:  117       10 Batch loss: 0.205701 Batch F1: 0.5714285714285715
Epoch:  117       11 Batch loss: 0.173898 Batch F1: 0.6976744186046512
Epoch:  117       12 Batch loss: 0.160524 Batch F1: 0.7428571428571428
Train Avg Loss  117: 0.174795

Train Avg F1  117: 0.702026393034162

Val Avg Loss  117: 0.187063

Val Avg F1  117:  0.6678167115902965

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 118
--------------------------------------------------------------
Epoch:  118        1 Batch loss: 0.169466 Batch F1: 0.6829268292682926
Epoch:  118        2 Batch loss: 0.153520 Batch F1: 0.7906976744186046
Epoch:  118        3 Batch loss: 0.189931 Batch F1: 0.7169811320754716
Epoch:  118        4 Batch loss: 0.138601 Batch F1: 0.7500000000000001
Epoch:  118        5 Batch loss: 0.138713 Batch F1: 0.8372093023255814
Epoch:  118        6 Batch loss: 0.166104 Batch F1: 0.8
Epoch:  118        7 Batch loss: 0.198777 Batch F1: 0.5714285714285713
Epoch:  118        8 Batch loss: 0.180156 Batch F1: 0.5714285714285714
Epoch:  118        9 Batch loss: 0.161865 Batch F1: 0.7391304347826085
Epoch:  118       10 Batch loss: 0.205886 Batch F1: 0.6808510638297872
Epoch:  118       11 Batch loss: 0.216438 Batch F1: 0.6666666666666666
Epoch:  118       12 Batch loss: 0.159660 Batch F1: 0.7906976744186046
Train Avg Loss  118: 0.173260

Train Avg F1  118: 0.7165014933868967

Val Avg Loss  118: 0.184838

Val Avg F1  118:  0.7034891645086547

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 119
--------------------------------------------------------------
Epoch:  119        1 Batch loss: 0.159009 Batch F1: 0.8085106382978724
Epoch:  119        2 Batch loss: 0.169147 Batch F1: 0.723404255319149
Epoch:  119        3 Batch loss: 0.174462 Batch F1: 0.6
Epoch:  119        4 Batch loss: 0.167041 Batch F1: 0.7111111111111111
Epoch:  119        5 Batch loss: 0.184715 Batch F1: 0.6666666666666666
Epoch:  119        6 Batch loss: 0.176614 Batch F1: 0.7037037037037037
Epoch:  119        7 Batch loss: 0.170787 Batch F1: 0.7142857142857142
Epoch:  119        8 Batch loss: 0.167286 Batch F1: 0.5294117647058824
Epoch:  119        9 Batch loss: 0.161777 Batch F1: 0.6470588235294118
Epoch:  119       10 Batch loss: 0.185944 Batch F1: 0.7307692307692307
Epoch:  119       11 Batch loss: 0.212520 Batch F1: 0.6545454545454545
Epoch:  119       12 Batch loss: 0.186518 Batch F1: 0.625
Train Avg Loss  119: 0.176318

Train Avg F1  119: 0.6762056135778497

Val Avg Loss  119: 0.187043

Val Avg F1  119:  0.6677474743512479

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 120
--------------------------------------------------------------
Epoch:  120        1 Batch loss: 0.170585 Batch F1: 0.6842105263157896
Epoch:  120        2 Batch loss: 0.187830 Batch F1: 0.7346938775510204
Epoch:  120        3 Batch loss: 0.208111 Batch F1: 0.5116279069767442
Epoch:  120        4 Batch loss: 0.163592 Batch F1: 0.6486486486486486
Epoch:  120        5 Batch loss: 0.194062 Batch F1: 0.6666666666666667
Epoch:  120        6 Batch loss: 0.187073 Batch F1: 0.7179487179487181
Epoch:  120        7 Batch loss: 0.166017 Batch F1: 0.7368421052631577
Epoch:  120        8 Batch loss: 0.183177 Batch F1: 0.7586206896551724
Epoch:  120        9 Batch loss: 0.168129 Batch F1: 0.7636363636363638
Epoch:  120       10 Batch loss: 0.224295 Batch F1: 0.7017543859649124
Epoch:  120       11 Batch loss: 0.178364 Batch F1: 0.7083333333333333
Epoch:  120       12 Batch loss: 0.171114 Batch F1: 0.717948717948718
Train Avg Loss  120: 0.183529

Train Avg F1  120: 0.695910994992437

Val Avg Loss  120: 0.188091

Val Avg F1  120:  0.6801906779661017

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 121
--------------------------------------------------------------
Epoch:  121        1 Batch loss: 0.163852 Batch F1: 0.7027027027027026
Epoch:  121        2 Batch loss: 0.187373 Batch F1: 0.6666666666666667
Epoch:  121        3 Batch loss: 0.200727 Batch F1: 0.6538461538461539
Epoch:  121        4 Batch loss: 0.220084 Batch F1: 0.5405405405405405
Epoch:  121        5 Batch loss: 0.145573 Batch F1: 0.7692307692307693
Epoch:  121        6 Batch loss: 0.166657 Batch F1: 0.7555555555555556
Epoch:  121        7 Batch loss: 0.201958 Batch F1: 0.7142857142857143
Epoch:  121        8 Batch loss: 0.166360 Batch F1: 0.8510638297872342
Epoch:  121        9 Batch loss: 0.203525 Batch F1: 0.7234042553191489
Epoch:  121       10 Batch loss: 0.175540 Batch F1: 0.8163265306122449
Epoch:  121       11 Batch loss: 0.172973 Batch F1: 0.6666666666666666
Epoch:  121       12 Batch loss: 0.167783 Batch F1: 0.8444444444444444
Train Avg Loss  121: 0.181034

Train Avg F1  121: 0.7253944858048204

Val Avg Loss  121: 0.190011

Val Avg F1  121:  0.6843389529724935

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 122
--------------------------------------------------------------
Epoch:  122        1 Batch loss: 0.197757 Batch F1: 0.7346938775510203
Epoch:  122        2 Batch loss: 0.225018 Batch F1: 0.7241379310344828
Epoch:  122        3 Batch loss: 0.191030 Batch F1: 0.6086956521739131
Epoch:  122        4 Batch loss: 0.153624 Batch F1: 0.7368421052631577
Epoch:  122        5 Batch loss: 0.146345 Batch F1: 0.8205128205128205
Epoch:  122        6 Batch loss: 0.235963 Batch F1: 0.6046511627906976
Epoch:  122        7 Batch loss: 0.147961 Batch F1: 0.742857142857143
Epoch:  122        8 Batch loss: 0.194578 Batch F1: 0.7037037037037037
Epoch:  122        9 Batch loss: 0.155052 Batch F1: 0.7719298245614034
Epoch:  122       10 Batch loss: 0.223667 Batch F1: 0.5957446808510639
Epoch:  122       11 Batch loss: 0.153699 Batch F1: 0.7058823529411765
Epoch:  122       12 Batch loss: 0.209818 Batch F1: 0.6956521739130435
Train Avg Loss  122: 0.186209

Train Avg F1  122: 0.7037752856794688

Val Avg Loss  122: 0.188571

Val Avg F1  122:  0.6984551373657252

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 123
--------------------------------------------------------------
Epoch:  123        1 Batch loss: 0.218093 Batch F1: 0.6666666666666666
Epoch:  123        2 Batch loss: 0.234624 Batch F1: 0.625
Epoch:  123        3 Batch loss: 0.213658 Batch F1: 0.5581395348837208
Epoch:  123        4 Batch loss: 0.172227 Batch F1: 0.6666666666666666
Epoch:  123        5 Batch loss: 0.206495 Batch F1: 0.64
Epoch:  123        6 Batch loss: 0.175900 Batch F1: 0.56
Epoch:  123        7 Batch loss: 0.193052 Batch F1: 0.6190476190476191
Epoch:  123        8 Batch loss: 0.159272 Batch F1: 0.5294117647058824
Epoch:  123        9 Batch loss: 0.175485 Batch F1: 0.711111111111111
Epoch:  123       10 Batch loss: 0.204325 Batch F1: 0.6415094339622641
Epoch:  123       11 Batch loss: 0.186532 Batch F1: 0.6666666666666666
Epoch:  123       12 Batch loss: 0.160588 Batch F1: 0.8372093023255814
Train Avg Loss  123: 0.191688

Train Avg F1  123: 0.6434523971696816

Val Avg Loss  123: 0.194504

Val Avg F1  123:  0.6801503917705624

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 124
--------------------------------------------------------------
Epoch:  124        1 Batch loss: 0.185487 Batch F1: 0.7868852459016394
Epoch:  124        2 Batch loss: 0.212818 Batch F1: 0.7037037037037037
Epoch:  124        3 Batch loss: 0.179142 Batch F1: 0.7027027027027026
Epoch:  124        4 Batch loss: 0.205790 Batch F1: 0.7777777777777777
Epoch:  124        5 Batch loss: 0.197710 Batch F1: 0.6511627906976744
Epoch:  124        6 Batch loss: 0.192130 Batch F1: 0.7407407407407408
Epoch:  124        7 Batch loss: 0.181053 Batch F1: 0.7272727272727272
Epoch:  124        8 Batch loss: 0.185302 Batch F1: 0.6285714285714286
Epoch:  124        9 Batch loss: 0.174593 Batch F1: 0.5555555555555556
Epoch:  124       10 Batch loss: 0.168253 Batch F1: 0.7555555555555555
Epoch:  124       11 Batch loss: 0.177499 Batch F1: 0.6153846153846154
Epoch:  124       12 Batch loss: 0.161592 Batch F1: 0.7096774193548386
Train Avg Loss  124: 0.185114

Train Avg F1  124: 0.6962491886015799

Val Avg Loss  124: 0.192504

Val Avg F1  124:  0.6421254355400697

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 125
--------------------------------------------------------------
Epoch:  125        1 Batch loss: 0.164631 Batch F1: 0.7272727272727272
Epoch:  125        2 Batch loss: 0.166914 Batch F1: 0.6
Epoch:  125        3 Batch loss: 0.167972 Batch F1: 0.6470588235294118
Epoch:  125        4 Batch loss: 0.193653 Batch F1: 0.7234042553191491
Epoch:  125        5 Batch loss: 0.154876 Batch F1: 0.8275862068965517
Epoch:  125        6 Batch loss: 0.146802 Batch F1: 0.8656716417910448
Epoch:  125        7 Batch loss: 0.236339 Batch F1: 0.6785714285714285
Epoch:  125        8 Batch loss: 0.186053 Batch F1: 0.6976744186046512
Epoch:  125        9 Batch loss: 0.227706 Batch F1: 0.5217391304347826
Epoch:  125       10 Batch loss: 0.162759 Batch F1: 0.625
Epoch:  125       11 Batch loss: 0.190888 Batch F1: 0.6956521739130435
Epoch:  125       12 Batch loss: 0.183544 Batch F1: 0.7
Train Avg Loss  125: 0.181845

Train Avg F1  125: 0.6924692338610657

Val Avg Loss  125: 0.189958

Val Avg F1  125:  0.673173076923077

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 126
--------------------------------------------------------------
Epoch:  126        1 Batch loss: 0.185311 Batch F1: 0.6842105263157895
Epoch:  126        2 Batch loss: 0.197775 Batch F1: 0.6222222222222223
Epoch:  126        3 Batch loss: 0.185597 Batch F1: 0.6938775510204083
Epoch:  126        4 Batch loss: 0.149227 Batch F1: 0.8333333333333334
Epoch:  126        5 Batch loss: 0.175973 Batch F1: 0.6666666666666667
Epoch:  126        6 Batch loss: 0.163472 Batch F1: 0.717948717948718
Epoch:  126        7 Batch loss: 0.168249 Batch F1: 0.7142857142857143
Epoch:  126        8 Batch loss: 0.176818 Batch F1: 0.7547169811320755
Epoch:  126        9 Batch loss: 0.167472 Batch F1: 0.7317073170731706
Epoch:  126       10 Batch loss: 0.208156 Batch F1: 0.5652173913043478
Epoch:  126       11 Batch loss: 0.190758 Batch F1: 0.6530612244897959
Epoch:  126       12 Batch loss: 0.178998 Batch F1: 0.7555555555555555
Train Avg Loss  126: 0.178984

Train Avg F1  126: 0.6994002667789831

Val Avg Loss  126: 0.189638

Val Avg F1  126:  0.6731403781403782

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 127
--------------------------------------------------------------
Epoch:  127        1 Batch loss: 0.168493 Batch F1: 0.6486486486486486
Epoch:  127        2 Batch loss: 0.194873 Batch F1: 0.6500000000000001
Epoch:  127        3 Batch loss: 0.149292 Batch F1: 0.7272727272727272
Epoch:  127        4 Batch loss: 0.168708 Batch F1: 0.7441860465116279
Epoch:  127        5 Batch loss: 0.169708 Batch F1: 0.8400000000000001
Epoch:  127        6 Batch loss: 0.198328 Batch F1: 0.6666666666666666
Epoch:  127        7 Batch loss: 0.164725 Batch F1: 0.7441860465116279
Epoch:  127        8 Batch loss: 0.178587 Batch F1: 0.7307692307692308
Epoch:  127        9 Batch loss: 0.167263 Batch F1: 0.6666666666666666
Epoch:  127       10 Batch loss: 0.180666 Batch F1: 0.7843137254901961
Epoch:  127       11 Batch loss: 0.186486 Batch F1: 0.8
Epoch:  127       12 Batch loss: 0.197808 Batch F1: 0.6818181818181819
Train Avg Loss  127: 0.177078

Train Avg F1  127: 0.7237106616962978

Val Avg Loss  127: 0.185676

Val Avg F1  127:  0.6806439125982577

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 128
--------------------------------------------------------------
Epoch:  128        1 Batch loss: 0.158562 Batch F1: 0.8095238095238095
Epoch:  128        2 Batch loss: 0.174740 Batch F1: 0.7755102040816326
Epoch:  128        3 Batch loss: 0.158862 Batch F1: 0.7058823529411765
Epoch:  128        4 Batch loss: 0.186519 Batch F1: 0.6341463414634146
Epoch:  128        5 Batch loss: 0.189289 Batch F1: 0.6511627906976744
Epoch:  128        6 Batch loss: 0.164890 Batch F1: 0.7916666666666667
Epoch:  128        7 Batch loss: 0.192792 Batch F1: 0.6521739130434783
Epoch:  128        8 Batch loss: 0.183464 Batch F1: 0.6153846153846153
Epoch:  128        9 Batch loss: 0.165041 Batch F1: 0.7272727272727272
Epoch:  128       10 Batch loss: 0.172009 Batch F1: 0.6818181818181819
Epoch:  128       11 Batch loss: 0.182509 Batch F1: 0.6511627906976745
Epoch:  128       12 Batch loss: 0.186968 Batch F1: 0.6818181818181818
Train Avg Loss  128: 0.176304

Train Avg F1  128: 0.6981268812841028

Val Avg Loss  128: 0.188280

Val Avg F1  128:  0.7090083787652177

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 129
--------------------------------------------------------------
Epoch:  129        1 Batch loss: 0.179640 Batch F1: 0.6956521739130435
Epoch:  129        2 Batch loss: 0.201830 Batch F1: 0.5714285714285713
Epoch:  129        3 Batch loss: 0.177582 Batch F1: 0.7555555555555555
Epoch:  129        4 Batch loss: 0.188529 Batch F1: 0.7450980392156864
Epoch:  129        5 Batch loss: 0.181409 Batch F1: 0.711111111111111
Epoch:  129        6 Batch loss: 0.158228 Batch F1: 0.606060606060606
Epoch:  129        7 Batch loss: 0.175711 Batch F1: 0.7391304347826085
Epoch:  129        8 Batch loss: 0.188235 Batch F1: 0.723404255319149
Epoch:  129        9 Batch loss: 0.151985 Batch F1: 0.7692307692307692
Epoch:  129       10 Batch loss: 0.179991 Batch F1: 0.7777777777777778
Epoch:  129       11 Batch loss: 0.169590 Batch F1: 0.75
Epoch:  129       12 Batch loss: 0.178883 Batch F1: 0.7027027027027026
Train Avg Loss  129: 0.177635

Train Avg F1  129: 0.7122626664247984

Val Avg Loss  129: 0.187252

Val Avg F1  129:  0.6745833333333333

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 130
--------------------------------------------------------------
Epoch:  130        1 Batch loss: 0.203598 Batch F1: 0.6222222222222223
Epoch:  130        2 Batch loss: 0.192207 Batch F1: 0.6
Epoch:  130        3 Batch loss: 0.173236 Batch F1: 0.6818181818181819
Epoch:  130        4 Batch loss: 0.179801 Batch F1: 0.723404255319149
Epoch:  130        5 Batch loss: 0.166205 Batch F1: 0.7441860465116279
Epoch:  130        6 Batch loss: 0.168594 Batch F1: 0.7368421052631579
Epoch:  130        7 Batch loss: 0.158177 Batch F1: 0.7500000000000001
Epoch:  130        8 Batch loss: 0.173463 Batch F1: 0.7346938775510203
Epoch:  130        9 Batch loss: 0.157152 Batch F1: 0.7368421052631577
Epoch:  130       10 Batch loss: 0.187459 Batch F1: 0.76
Epoch:  130       11 Batch loss: 0.177660 Batch F1: 0.6666666666666666
Epoch:  130       12 Batch loss: 0.187899 Batch F1: 0.7755102040816326
Train Avg Loss  130: 0.177121

Train Avg F1  130: 0.711015472058068

Val Avg Loss  130: 0.187860

Val Avg F1  130:  0.6858316481294237

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 131
--------------------------------------------------------------
Epoch:  131        1 Batch loss: 0.185705 Batch F1: 0.6511627906976745
Epoch:  131        2 Batch loss: 0.168746 Batch F1: 0.6842105263157895
Epoch:  131        3 Batch loss: 0.165888 Batch F1: 0.7111111111111111
Epoch:  131        4 Batch loss: 0.152313 Batch F1: 0.8
Epoch:  131        5 Batch loss: 0.151045 Batch F1: 0.8163265306122449
Epoch:  131        6 Batch loss: 0.192676 Batch F1: 0.7586206896551724
Epoch:  131        7 Batch loss: 0.186583 Batch F1: 0.7234042553191491
Epoch:  131        8 Batch loss: 0.172378 Batch F1: 0.7999999999999999
Epoch:  131        9 Batch loss: 0.172383 Batch F1: 0.6666666666666667
Epoch:  131       10 Batch loss: 0.203423 Batch F1: 0.5581395348837208
Epoch:  131       11 Batch loss: 0.183377 Batch F1: 0.5454545454545454
Epoch:  131       12 Batch loss: 0.180743 Batch F1: 0.7906976744186046
Train Avg Loss  131: 0.176272

Train Avg F1  131: 0.7088161937612233

Val Avg Loss  131: 0.192855

Val Avg F1  131:  0.6634247378856544

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 132
--------------------------------------------------------------
Epoch:  132        1 Batch loss: 0.172936 Batch F1: 0.7391304347826089
Epoch:  132        2 Batch loss: 0.154116 Batch F1: 0.7567567567567567
Epoch:  132        3 Batch loss: 0.187871 Batch F1: 0.7199999999999999
Epoch:  132        4 Batch loss: 0.176630 Batch F1: 0.7
Epoch:  132        5 Batch loss: 0.205209 Batch F1: 0.6122448979591837
Epoch:  132        6 Batch loss: 0.156592 Batch F1: 0.782608695652174
Epoch:  132        7 Batch loss: 0.199694 Batch F1: 0.6382978723404256
Epoch:  132        8 Batch loss: 0.179518 Batch F1: 0.6521739130434783
Epoch:  132        9 Batch loss: 0.166897 Batch F1: 0.782608695652174
Epoch:  132       10 Batch loss: 0.163494 Batch F1: 0.7916666666666666
Epoch:  132       11 Batch loss: 0.182017 Batch F1: 0.65
Epoch:  132       12 Batch loss: 0.152703 Batch F1: 0.7272727272727272
Train Avg Loss  132: 0.174806

Train Avg F1  132: 0.7127300550105162

Val Avg Loss  132: 0.185793

Val Avg F1  132:  0.677092576160899

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 133
--------------------------------------------------------------
Epoch:  133        1 Batch loss: 0.194266 Batch F1: 0.6530612244897959
Epoch:  133        2 Batch loss: 0.175525 Batch F1: 0.6666666666666667
Epoch:  133        3 Batch loss: 0.172374 Batch F1: 0.7999999999999999
Epoch:  133        4 Batch loss: 0.163451 Batch F1: 0.7142857142857143
Epoch:  133        5 Batch loss: 0.193084 Batch F1: 0.6046511627906977
Epoch:  133        6 Batch loss: 0.158756 Batch F1: 0.7441860465116279
Epoch:  133        7 Batch loss: 0.147143 Batch F1: 0.8571428571428572
Epoch:  133        8 Batch loss: 0.168641 Batch F1: 0.7272727272727273
Epoch:  133        9 Batch loss: 0.164419 Batch F1: 0.6470588235294118
Epoch:  133       10 Batch loss: 0.180679 Batch F1: 0.6956521739130435
Epoch:  133       11 Batch loss: 0.170545 Batch F1: 0.76
Epoch:  133       12 Batch loss: 0.178730 Batch F1: 0.6
Train Avg Loss  133: 0.172301

Train Avg F1  133: 0.7058314497168786

Val Avg Loss  133: 0.183746

Val Avg F1  133:  0.6866200620619922

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 134
--------------------------------------------------------------
Epoch:  134        1 Batch loss: 0.160895 Batch F1: 0.7659574468085106
Epoch:  134        2 Batch loss: 0.192494 Batch F1: 0.6521739130434783
Epoch:  134        3 Batch loss: 0.193096 Batch F1: 0.6521739130434783
Epoch:  134        4 Batch loss: 0.162908 Batch F1: 0.7
Epoch:  134        5 Batch loss: 0.153385 Batch F1: 0.8181818181818182
Epoch:  134        6 Batch loss: 0.151297 Batch F1: 0.8085106382978724
Epoch:  134        7 Batch loss: 0.144278 Batch F1: 0.8399999999999999
Epoch:  134        8 Batch loss: 0.171835 Batch F1: 0.76
Epoch:  134        9 Batch loss: 0.180399 Batch F1: 0.6500000000000001
Epoch:  134       10 Batch loss: 0.181929 Batch F1: 0.6666666666666665
Epoch:  134       11 Batch loss: 0.195457 Batch F1: 0.6046511627906977
Epoch:  134       12 Batch loss: 0.160502 Batch F1: 0.5925925925925926
Train Avg Loss  134: 0.170706

Train Avg F1  134: 0.7092423459520929

Val Avg Loss  134: 0.183065

Val Avg F1  134:  0.6730769230769231

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 135
--------------------------------------------------------------
Epoch:  135        1 Batch loss: 0.167731 Batch F1: 0.7234042553191491
Epoch:  135        2 Batch loss: 0.158107 Batch F1: 0.761904761904762
Epoch:  135        3 Batch loss: 0.189446 Batch F1: 0.736842105263158
Epoch:  135        4 Batch loss: 0.156375 Batch F1: 0.7441860465116279
Epoch:  135        5 Batch loss: 0.141784 Batch F1: 0.7916666666666666
Epoch:  135        6 Batch loss: 0.133351 Batch F1: 0.8333333333333333
Epoch:  135        7 Batch loss: 0.199073 Batch F1: 0.6521739130434783
Epoch:  135        8 Batch loss: 0.170253 Batch F1: 0.65
Epoch:  135        9 Batch loss: 0.184409 Batch F1: 0.7391304347826088
Epoch:  135       10 Batch loss: 0.209587 Batch F1: 0.6363636363636364
Epoch:  135       11 Batch loss: 0.183853 Batch F1: 0.711111111111111
Epoch:  135       12 Batch loss: 0.180949 Batch F1: 0.6486486486486486
Train Avg Loss  135: 0.172910

Train Avg F1  135: 0.7190637427456817

Val Avg Loss  135: 0.184052

Val Avg F1  135:  0.6822266204849086

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 136
--------------------------------------------------------------
Epoch:  136        1 Batch loss: 0.145931 Batch F1: 0.6896551724137931
Epoch:  136        2 Batch loss: 0.170112 Batch F1: 0.7450980392156864
Epoch:  136        3 Batch loss: 0.170996 Batch F1: 0.6976744186046512
Epoch:  136        4 Batch loss: 0.165392 Batch F1: 0.8275862068965518
Epoch:  136        5 Batch loss: 0.161233 Batch F1: 0.6842105263157895
Epoch:  136        6 Batch loss: 0.206496 Batch F1: 0.6382978723404256
Epoch:  136        7 Batch loss: 0.179235 Batch F1: 0.7346938775510204
Epoch:  136        8 Batch loss: 0.198881 Batch F1: 0.5853658536585366
Epoch:  136        9 Batch loss: 0.171907 Batch F1: 0.7499999999999999
Epoch:  136       10 Batch loss: 0.172175 Batch F1: 0.72
Epoch:  136       11 Batch loss: 0.164318 Batch F1: 0.7555555555555555
Epoch:  136       12 Batch loss: 0.170945 Batch F1: 0.6666666666666667
Train Avg Loss  136: 0.173135

Train Avg F1  136: 0.7079003491015562

Val Avg Loss  136: 0.184253

Val Avg F1  136:  0.686945088087094

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 137
--------------------------------------------------------------
Epoch:  137        1 Batch loss: 0.191979 Batch F1: 0.6341463414634148
Epoch:  137        2 Batch loss: 0.184441 Batch F1: 0.6363636363636365
Epoch:  137        3 Batch loss: 0.158516 Batch F1: 0.761904761904762
Epoch:  137        4 Batch loss: 0.145647 Batch F1: 0.8095238095238095
Epoch:  137        5 Batch loss: 0.197014 Batch F1: 0.6521739130434783
Epoch:  137        6 Batch loss: 0.194462 Batch F1: 0.6938775510204083
Epoch:  137        7 Batch loss: 0.191058 Batch F1: 0.6808510638297872
Epoch:  137        8 Batch loss: 0.140127 Batch F1: 0.8292682926829269
Epoch:  137        9 Batch loss: 0.182510 Batch F1: 0.6666666666666666
Epoch:  137       10 Batch loss: 0.152406 Batch F1: 0.7924528301886792
Epoch:  137       11 Batch loss: 0.163864 Batch F1: 0.7441860465116279
Epoch:  137       12 Batch loss: 0.205101 Batch F1: 0.5161290322580646
Train Avg Loss  137: 0.175594

Train Avg F1  137: 0.701461995454772

Val Avg Loss  137: 0.187886

Val Avg F1  137:  0.6369679579148733

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 138
--------------------------------------------------------------
Epoch:  138        1 Batch loss: 0.152631 Batch F1: 0.8181818181818181
Epoch:  138        2 Batch loss: 0.174622 Batch F1: 0.6666666666666667
Epoch:  138        3 Batch loss: 0.165823 Batch F1: 0.6666666666666666
Epoch:  138        4 Batch loss: 0.195821 Batch F1: 0.6666666666666666
Epoch:  138        5 Batch loss: 0.179384 Batch F1: 0.6341463414634148
Epoch:  138        6 Batch loss: 0.162860 Batch F1: 0.7843137254901961
Epoch:  138        7 Batch loss: 0.194633 Batch F1: 0.5454545454545454
Epoch:  138        8 Batch loss: 0.191724 Batch F1: 0.5957446808510639
Epoch:  138        9 Batch loss: 0.192796 Batch F1: 0.6222222222222222
Epoch:  138       10 Batch loss: 0.156115 Batch F1: 0.8400000000000001
Epoch:  138       11 Batch loss: 0.209770 Batch F1: 0.6
Epoch:  138       12 Batch loss: 0.185740 Batch F1: 0.7391304347826088
Train Avg Loss  138: 0.180160

Train Avg F1  138: 0.6815994807038224

Val Avg Loss  138: 0.189731

Val Avg F1  138:  0.6792846130126425

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 139
--------------------------------------------------------------
Epoch:  139        1 Batch loss: 0.159661 Batch F1: 0.782608695652174
Epoch:  139        2 Batch loss: 0.205424 Batch F1: 0.7142857142857143
Epoch:  139        3 Batch loss: 0.132269 Batch F1: 0.8888888888888888
Epoch:  139        4 Batch loss: 0.184446 Batch F1: 0.6818181818181818
Epoch:  139        5 Batch loss: 0.189525 Batch F1: 0.6666666666666667
Epoch:  139        6 Batch loss: 0.174009 Batch F1: 0.7450980392156864
Epoch:  139        7 Batch loss: 0.199783 Batch F1: 0.42424242424242425
Epoch:  139        8 Batch loss: 0.164234 Batch F1: 0.7755102040816326
Epoch:  139        9 Batch loss: 0.172206 Batch F1: 0.6666666666666666
Epoch:  139       10 Batch loss: 0.173196 Batch F1: 0.6666666666666667
Epoch:  139       11 Batch loss: 0.178940 Batch F1: 0.7272727272727272
Epoch:  139       12 Batch loss: 0.177744 Batch F1: 0.7317073170731706
Train Avg Loss  139: 0.175953

Train Avg F1  139: 0.7059526827108833

Val Avg Loss  139: 0.186641

Val Avg F1  139:  0.6769165071101263

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 140
--------------------------------------------------------------
Epoch:  140        1 Batch loss: 0.161169 Batch F1: 0.7727272727272727
Epoch:  140        2 Batch loss: 0.162805 Batch F1: 0.7391304347826088
Epoch:  140        3 Batch loss: 0.164216 Batch F1: 0.8000000000000002
Epoch:  140        4 Batch loss: 0.159421 Batch F1: 0.5517241379310345
Epoch:  140        5 Batch loss: 0.177856 Batch F1: 0.6666666666666666
Epoch:  140        6 Batch loss: 0.168747 Batch F1: 0.7777777777777779
Epoch:  140        7 Batch loss: 0.174803 Batch F1: 0.6315789473684211
Epoch:  140        8 Batch loss: 0.164063 Batch F1: 0.7692307692307692
Epoch:  140        9 Batch loss: 0.171425 Batch F1: 0.6511627906976745
Epoch:  140       10 Batch loss: 0.177358 Batch F1: 0.7142857142857143
Epoch:  140       11 Batch loss: 0.185639 Batch F1: 0.7083333333333334
Epoch:  140       12 Batch loss: 0.183891 Batch F1: 0.7142857142857143
Train Avg Loss  140: 0.170949

Train Avg F1  140: 0.7080752965905823

Val Avg Loss  140: 0.184425

Val Avg F1  140:  0.6743517599029019

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 141
--------------------------------------------------------------
Epoch:  141        1 Batch loss: 0.172430 Batch F1: 0.6956521739130435
Epoch:  141        2 Batch loss: 0.168166 Batch F1: 0.7450980392156864
Epoch:  141        3 Batch loss: 0.154249 Batch F1: 0.8333333333333333
Epoch:  141        4 Batch loss: 0.137379 Batch F1: 0.7500000000000001
Epoch:  141        5 Batch loss: 0.193189 Batch F1: 0.6923076923076923
Epoch:  141        6 Batch loss: 0.148389 Batch F1: 0.8510638297872342
Epoch:  141        7 Batch loss: 0.172856 Batch F1: 0.7441860465116279
Epoch:  141        8 Batch loss: 0.188298 Batch F1: 0.6341463414634146
Epoch:  141        9 Batch loss: 0.155804 Batch F1: 0.8
Epoch:  141       10 Batch loss: 0.205132 Batch F1: 0.6222222222222222
Epoch:  141       11 Batch loss: 0.166114 Batch F1: 0.711111111111111
Epoch:  141       12 Batch loss: 0.200723 Batch F1: 0.6486486486486486
Train Avg Loss  141: 0.171894

Train Avg F1  141: 0.7273141198761678

Val Avg Loss  141: 0.184309

Val Avg F1  141:  0.6925602968460111

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 142
--------------------------------------------------------------
Epoch:  142        1 Batch loss: 0.151889 Batch F1: 0.7692307692307692
Epoch:  142        2 Batch loss: 0.156918 Batch F1: 0.7906976744186046
Epoch:  142        3 Batch loss: 0.176054 Batch F1: 0.6511627906976744
Epoch:  142        4 Batch loss: 0.212159 Batch F1: 0.6274509803921569
Epoch:  142        5 Batch loss: 0.155410 Batch F1: 0.7692307692307693
Epoch:  142        6 Batch loss: 0.166806 Batch F1: 0.4999999999999999
Epoch:  142        7 Batch loss: 0.182490 Batch F1: 0.7083333333333334
Epoch:  142        8 Batch loss: 0.152557 Batch F1: 0.8260869565217391
Epoch:  142        9 Batch loss: 0.189928 Batch F1: 0.7857142857142856
Epoch:  142       10 Batch loss: 0.202503 Batch F1: 0.6666666666666667
Epoch:  142       11 Batch loss: 0.188815 Batch F1: 0.6046511627906976
Epoch:  142       12 Batch loss: 0.175458 Batch F1: 0.7222222222222223
Train Avg Loss  142: 0.175916

Train Avg F1  142: 0.7017873009349099

Val Avg Loss  142: 0.186542

Val Avg F1  142:  0.6724569713700149

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 143
--------------------------------------------------------------
Epoch:  143        1 Batch loss: 0.169171 Batch F1: 0.7499999999999999
Epoch:  143        2 Batch loss: 0.165630 Batch F1: 0.7555555555555555
Epoch:  143        3 Batch loss: 0.171687 Batch F1: 0.6829268292682926
Epoch:  143        4 Batch loss: 0.172401 Batch F1: 0.711111111111111
Epoch:  143        5 Batch loss: 0.144882 Batch F1: 0.8181818181818182
Epoch:  143        6 Batch loss: 0.208186 Batch F1: 0.6046511627906977
Epoch:  143        7 Batch loss: 0.176314 Batch F1: 0.6666666666666666
Epoch:  143        8 Batch loss: 0.175662 Batch F1: 0.65
Epoch:  143        9 Batch loss: 0.201316 Batch F1: 0.5294117647058825
Epoch:  143       10 Batch loss: 0.166784 Batch F1: 0.8085106382978724
Epoch:  143       11 Batch loss: 0.166812 Batch F1: 0.6829268292682927
Epoch:  143       12 Batch loss: 0.199934 Batch F1: 0.6190476190476191
Train Avg Loss  143: 0.176565

Train Avg F1  143: 0.6899158329078174

Val Avg Loss  143: 0.185294

Val Avg F1  143:  0.7081471631205674

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 144
--------------------------------------------------------------
Epoch:  144        1 Batch loss: 0.191339 Batch F1: 0.6666666666666666
Epoch:  144        2 Batch loss: 0.173968 Batch F1: 0.7346938775510204
Epoch:  144        3 Batch loss: 0.169017 Batch F1: 0.7755102040816326
Epoch:  144        4 Batch loss: 0.154280 Batch F1: 0.761904761904762
Epoch:  144        5 Batch loss: 0.163998 Batch F1: 0.7027027027027026
Epoch:  144        6 Batch loss: 0.195929 Batch F1: 0.6086956521739131
Epoch:  144        7 Batch loss: 0.167603 Batch F1: 0.7450980392156864
Epoch:  144        8 Batch loss: 0.179767 Batch F1: 0.6363636363636365
Epoch:  144        9 Batch loss: 0.169707 Batch F1: 0.7777777777777777
Epoch:  144       10 Batch loss: 0.176425 Batch F1: 0.6666666666666667
Epoch:  144       11 Batch loss: 0.177152 Batch F1: 0.7200000000000001
Epoch:  144       12 Batch loss: 0.175735 Batch F1: 0.7368421052631577
Train Avg Loss  144: 0.174577

Train Avg F1  144: 0.7110768408639685

Val Avg Loss  144: 0.193012

Val Avg F1  144:  0.6689936203614015

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 145
--------------------------------------------------------------
Epoch:  145        1 Batch loss: 0.158201 Batch F1: 0.717948717948718
Epoch:  145        2 Batch loss: 0.168260 Batch F1: 0.7142857142857143
Epoch:  145        3 Batch loss: 0.188059 Batch F1: 0.7906976744186046
Epoch:  145        4 Batch loss: 0.174089 Batch F1: 0.7450980392156863
Epoch:  145        5 Batch loss: 0.163557 Batch F1: 0.6842105263157895
Epoch:  145        6 Batch loss: 0.183076 Batch F1: 0.6274509803921569
Epoch:  145        7 Batch loss: 0.144695 Batch F1: 0.8085106382978724
Epoch:  145        8 Batch loss: 0.175047 Batch F1: 0.7
Epoch:  145        9 Batch loss: 0.193746 Batch F1: 0.7058823529411765
Epoch:  145       10 Batch loss: 0.228639 Batch F1: 0.5581395348837209
Epoch:  145       11 Batch loss: 0.155531 Batch F1: 0.8461538461538461
Epoch:  145       12 Batch loss: 0.190995 Batch F1: 0.7111111111111111
Train Avg Loss  145: 0.176991

Train Avg F1  145: 0.717457427997033

Val Avg Loss  145: 0.188045

Val Avg F1  145:  0.7065583093683006

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 146
--------------------------------------------------------------
Epoch:  146        1 Batch loss: 0.159867 Batch F1: 0.8260869565217391
Epoch:  146        2 Batch loss: 0.173309 Batch F1: 0.7931034482758621
Epoch:  146        3 Batch loss: 0.194321 Batch F1: 0.7599999999999999
Epoch:  146        4 Batch loss: 0.193761 Batch F1: 0.8148148148148148
Epoch:  146        5 Batch loss: 0.163445 Batch F1: 0.8771929824561403
Epoch:  146        6 Batch loss: 0.174733 Batch F1: 0.7826086956521738
Epoch:  146        7 Batch loss: 0.156168 Batch F1: 0.7333333333333333
Epoch:  146        8 Batch loss: 0.175453 Batch F1: 0.7027027027027027
Epoch:  146        9 Batch loss: 0.185768 Batch F1: 0.5945945945945945
Epoch:  146       10 Batch loss: 0.216307 Batch F1: 0.5853658536585366
Epoch:  146       11 Batch loss: 0.187647 Batch F1: 0.6808510638297872
Epoch:  146       12 Batch loss: 0.177895 Batch F1: 0.6315789473684211
Train Avg Loss  146: 0.179889

Train Avg F1  146: 0.7318527827673421

Val Avg Loss  146: 0.187525

Val Avg F1  146:  0.6497567327203737

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 147
--------------------------------------------------------------
Epoch:  147        1 Batch loss: 0.196078 Batch F1: 0.558139534883721
Epoch:  147        2 Batch loss: 0.175592 Batch F1: 0.5789473684210527
Epoch:  147        3 Batch loss: 0.174873 Batch F1: 0.7000000000000001
Epoch:  147        4 Batch loss: 0.198562 Batch F1: 0.6956521739130435
Epoch:  147        5 Batch loss: 0.184390 Batch F1: 0.6511627906976744
Epoch:  147        6 Batch loss: 0.173102 Batch F1: 0.7499999999999999
Epoch:  147        7 Batch loss: 0.212378 Batch F1: 0.6666666666666666
Epoch:  147        8 Batch loss: 0.189930 Batch F1: 0.7586206896551725
Epoch:  147        9 Batch loss: 0.191468 Batch F1: 0.619047619047619
Epoch:  147       10 Batch loss: 0.156047 Batch F1: 0.8372093023255814
Epoch:  147       11 Batch loss: 0.159574 Batch F1: 0.8085106382978724
Epoch:  147       12 Batch loss: 0.183041 Batch F1: 0.7111111111111111
Train Avg Loss  147: 0.182920

Train Avg F1  147: 0.6945889912516261

Val Avg Loss  147: 0.186245

Val Avg F1  147:  0.6753210398559236

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 148
--------------------------------------------------------------
Epoch:  148        1 Batch loss: 0.193870 Batch F1: 0.693877551020408
Epoch:  148        2 Batch loss: 0.162881 Batch F1: 0.6486486486486486
Epoch:  148        3 Batch loss: 0.166156 Batch F1: 0.7317073170731707
Epoch:  148        4 Batch loss: 0.176329 Batch F1: 0.711111111111111
Epoch:  148        5 Batch loss: 0.163628 Batch F1: 0.7692307692307693
Epoch:  148        6 Batch loss: 0.175273 Batch F1: 0.6666666666666667
Epoch:  148        7 Batch loss: 0.209005 Batch F1: 0.6545454545454545
Epoch:  148        8 Batch loss: 0.179266 Batch F1: 0.7272727272727272
Epoch:  148        9 Batch loss: 0.170374 Batch F1: 0.7555555555555556
Epoch:  148       10 Batch loss: 0.158794 Batch F1: 0.8
Epoch:  148       11 Batch loss: 0.186642 Batch F1: 0.6938775510204083
Epoch:  148       12 Batch loss: 0.193801 Batch F1: 0.7083333333333334
Train Avg Loss  148: 0.178002

Train Avg F1  148: 0.7134022237898545

Val Avg Loss  148: 0.198240

Val Avg F1  148:  0.7217160826594788

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 149
--------------------------------------------------------------
Epoch:  149        1 Batch loss: 0.159100 Batch F1: 0.7636363636363638
Epoch:  149        2 Batch loss: 0.197965 Batch F1: 0.7142857142857142
Epoch:  149        3 Batch loss: 0.168635 Batch F1: 0.6976744186046512
Epoch:  149        4 Batch loss: 0.206367 Batch F1: 0.6666666666666666
Epoch:  149        5 Batch loss: 0.179522 Batch F1: 0.7755102040816326
Epoch:  149        6 Batch loss: 0.172366 Batch F1: 0.7755102040816326
Epoch:  149        7 Batch loss: 0.160311 Batch F1: 0.8
Epoch:  149        8 Batch loss: 0.165270 Batch F1: 0.7441860465116279
Epoch:  149        9 Batch loss: 0.183971 Batch F1: 0.6666666666666666
Epoch:  149       10 Batch loss: 0.182068 Batch F1: 0.6190476190476191
Epoch:  149       11 Batch loss: 0.170547 Batch F1: 0.6666666666666666
Epoch:  149       12 Batch loss: 0.175909 Batch F1: 0.6206896551724137
Train Avg Loss  149: 0.176836

Train Avg F1  149: 0.7092116854518046

Val Avg Loss  149: 0.191765

Val Avg F1  149:  0.6363330066160254

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 150
--------------------------------------------------------------
Epoch:  150        1 Batch loss: 0.190508 Batch F1: 0.6382978723404256
Epoch:  150        2 Batch loss: 0.162426 Batch F1: 0.8
Epoch:  150        3 Batch loss: 0.155667 Batch F1: 0.7659574468085107
Epoch:  150        4 Batch loss: 0.158444 Batch F1: 0.717948717948718
Epoch:  150        5 Batch loss: 0.207374 Batch F1: 0.5714285714285715
Epoch:  150        6 Batch loss: 0.170417 Batch F1: 0.717948717948718
Epoch:  150        7 Batch loss: 0.169237 Batch F1: 0.6842105263157895
Epoch:  150        8 Batch loss: 0.178603 Batch F1: 0.6818181818181819
Epoch:  150        9 Batch loss: 0.172061 Batch F1: 0.7234042553191489
Epoch:  150       10 Batch loss: 0.157832 Batch F1: 0.7916666666666667
Epoch:  150       11 Batch loss: 0.205096 Batch F1: 0.6382978723404256
Epoch:  150       12 Batch loss: 0.180989 Batch F1: 0.6666666666666667
Train Avg Loss  150: 0.175721

Train Avg F1  150: 0.6998037913001519

Val Avg Loss  150: 0.188238

Val Avg F1  150:  0.6736713286713287

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 151
--------------------------------------------------------------
Epoch:  151        1 Batch loss: 0.159259 Batch F1: 0.8461538461538461
Epoch:  151        2 Batch loss: 0.191476 Batch F1: 0.7200000000000001
Epoch:  151        3 Batch loss: 0.181014 Batch F1: 0.6976744186046512
Epoch:  151        4 Batch loss: 0.192345 Batch F1: 0.6190476190476191
Epoch:  151        5 Batch loss: 0.164971 Batch F1: 0.7727272727272727
Epoch:  151        6 Batch loss: 0.156015 Batch F1: 0.7317073170731707
Epoch:  151        7 Batch loss: 0.166053 Batch F1: 0.7142857142857143
Epoch:  151        8 Batch loss: 0.142525 Batch F1: 0.7272727272727272
Epoch:  151        9 Batch loss: 0.217537 Batch F1: 0.6296296296296297
Epoch:  151       10 Batch loss: 0.146547 Batch F1: 0.7272727272727272
Epoch:  151       11 Batch loss: 0.205122 Batch F1: 0.6545454545454545
Epoch:  151       12 Batch loss: 0.167782 Batch F1: 0.7222222222222223
Train Avg Loss  151: 0.174221

Train Avg F1  151: 0.7135449124029196

Val Avg Loss  151: 0.187911

Val Avg F1  151:  0.6553250763328329

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 152
--------------------------------------------------------------
Epoch:  152        1 Batch loss: 0.170790 Batch F1: 0.7234042553191491
Epoch:  152        2 Batch loss: 0.160419 Batch F1: 0.7441860465116279
Epoch:  152        3 Batch loss: 0.151067 Batch F1: 0.7659574468085107
Epoch:  152        4 Batch loss: 0.163265 Batch F1: 0.7916666666666667
Epoch:  152        5 Batch loss: 0.189469 Batch F1: 0.6111111111111113
Epoch:  152        6 Batch loss: 0.155521 Batch F1: 0.761904761904762
Epoch:  152        7 Batch loss: 0.203406 Batch F1: 0.6792452830188679
Epoch:  152        8 Batch loss: 0.178335 Batch F1: 0.5714285714285714
Epoch:  152        9 Batch loss: 0.166951 Batch F1: 0.6829268292682926
Epoch:  152       10 Batch loss: 0.151174 Batch F1: 0.7692307692307693
Epoch:  152       11 Batch loss: 0.198608 Batch F1: 0.6909090909090909
Epoch:  152       12 Batch loss: 0.178941 Batch F1: 0.717948717948718
Train Avg Loss  152: 0.172329

Train Avg F1  152: 0.7091599625105114

Val Avg Loss  152: 0.183191

Val Avg F1  152:  0.6913942701816456

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 153
--------------------------------------------------------------
Epoch:  153        1 Batch loss: 0.169618 Batch F1: 0.7500000000000001
Epoch:  153        2 Batch loss: 0.163937 Batch F1: 0.7391304347826089
Epoch:  153        3 Batch loss: 0.170814 Batch F1: 0.7659574468085107
Epoch:  153        4 Batch loss: 0.178885 Batch F1: 0.6153846153846154
Epoch:  153        5 Batch loss: 0.173368 Batch F1: 0.6818181818181819
Epoch:  153        6 Batch loss: 0.186317 Batch F1: 0.6363636363636365
Epoch:  153        7 Batch loss: 0.150719 Batch F1: 0.8085106382978724
Epoch:  153        8 Batch loss: 0.185568 Batch F1: 0.6956521739130435
Epoch:  153        9 Batch loss: 0.177724 Batch F1: 0.711111111111111
Epoch:  153       10 Batch loss: 0.163174 Batch F1: 0.7906976744186046
Epoch:  153       11 Batch loss: 0.167749 Batch F1: 0.7727272727272727
Epoch:  153       12 Batch loss: 0.176277 Batch F1: 0.7755102040816326
Train Avg Loss  153: 0.172012

Train Avg F1  153: 0.7285719491422574

Val Avg Loss  153: 0.182496

Val Avg F1  153:  0.7123731674337694

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 154
--------------------------------------------------------------
Epoch:  154        1 Batch loss: 0.167504 Batch F1: 0.7843137254901961
Epoch:  154        2 Batch loss: 0.163549 Batch F1: 0.6315789473684211
Epoch:  154        3 Batch loss: 0.179661 Batch F1: 0.6956521739130435
Epoch:  154        4 Batch loss: 0.159307 Batch F1: 0.6470588235294117
Epoch:  154        5 Batch loss: 0.220750 Batch F1: 0.5531914893617021
Epoch:  154        6 Batch loss: 0.185357 Batch F1: 0.7777777777777778
Epoch:  154        7 Batch loss: 0.198261 Batch F1: 0.5789473684210527
Epoch:  154        8 Batch loss: 0.154778 Batch F1: 0.7916666666666666
Epoch:  154        9 Batch loss: 0.138522 Batch F1: 0.8181818181818182
Epoch:  154       10 Batch loss: 0.166393 Batch F1: 0.6829268292682926
Epoch:  154       11 Batch loss: 0.162542 Batch F1: 0.7857142857142857
Epoch:  154       12 Batch loss: 0.168185 Batch F1: 0.7058823529411765
Train Avg Loss  154: 0.172068

Train Avg F1  154: 0.7044076882194871

Val Avg Loss  154: 0.185304

Val Avg F1  154:  0.6642507002801121

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 155
--------------------------------------------------------------
Epoch:  155        1 Batch loss: 0.162403 Batch F1: 0.7555555555555556
Epoch:  155        2 Batch loss: 0.149837 Batch F1: 0.7906976744186046
Epoch:  155        3 Batch loss: 0.161621 Batch F1: 0.7555555555555556
Epoch:  155        4 Batch loss: 0.152178 Batch F1: 0.782608695652174
Epoch:  155        5 Batch loss: 0.160198 Batch F1: 0.7027027027027026
Epoch:  155        6 Batch loss: 0.184105 Batch F1: 0.6666666666666666
Epoch:  155        7 Batch loss: 0.179185 Batch F1: 0.6818181818181818
Epoch:  155        8 Batch loss: 0.196916 Batch F1: 0.6086956521739131
Epoch:  155        9 Batch loss: 0.162157 Batch F1: 0.8363636363636363
Epoch:  155       10 Batch loss: 0.191385 Batch F1: 0.5853658536585366
Epoch:  155       11 Batch loss: 0.167876 Batch F1: 0.7391304347826088
Epoch:  155       12 Batch loss: 0.188181 Batch F1: 0.5714285714285715
Train Avg Loss  155: 0.171337

Train Avg F1  155: 0.7063824317313921

Val Avg Loss  155: 0.182472

Val Avg F1  155:  0.6908873158873158

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 156
--------------------------------------------------------------
Epoch:  156        1 Batch loss: 0.154666 Batch F1: 0.7826086956521738
Epoch:  156        2 Batch loss: 0.151934 Batch F1: 0.8095238095238095
Epoch:  156        3 Batch loss: 0.171995 Batch F1: 0.7407407407407408
Epoch:  156        4 Batch loss: 0.171288 Batch F1: 0.7659574468085107
Epoch:  156        5 Batch loss: 0.184912 Batch F1: 0.6111111111111112
Epoch:  156        6 Batch loss: 0.179994 Batch F1: 0.6666666666666666
Epoch:  156        7 Batch loss: 0.168328 Batch F1: 0.8135593220338982
Epoch:  156        8 Batch loss: 0.164962 Batch F1: 0.723404255319149
Epoch:  156        9 Batch loss: 0.151599 Batch F1: 0.6857142857142856
Epoch:  156       10 Batch loss: 0.195061 Batch F1: 0.6190476190476191
Epoch:  156       11 Batch loss: 0.219442 Batch F1: 0.653061224489796
Epoch:  156       12 Batch loss: 0.154049 Batch F1: 0.8
Train Avg Loss  156: 0.172352

Train Avg F1  156: 0.72261626475898

Val Avg Loss  156: 0.186825

Val Avg F1  156:  0.6630134768445662

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 157
--------------------------------------------------------------
Epoch:  157        1 Batch loss: 0.191118 Batch F1: 0.6341463414634148
Epoch:  157        2 Batch loss: 0.194558 Batch F1: 0.6842105263157895
Epoch:  157        3 Batch loss: 0.143417 Batch F1: 0.7500000000000001
Epoch:  157        4 Batch loss: 0.175219 Batch F1: 0.5161290322580646
Epoch:  157        5 Batch loss: 0.206846 Batch F1: 0.64
Epoch:  157        6 Batch loss: 0.168496 Batch F1: 0.7659574468085107
Epoch:  157        7 Batch loss: 0.153851 Batch F1: 0.8095238095238095
Epoch:  157        8 Batch loss: 0.193034 Batch F1: 0.7586206896551724
Epoch:  157        9 Batch loss: 0.181415 Batch F1: 0.723404255319149
Epoch:  157       10 Batch loss: 0.220345 Batch F1: 0.5957446808510639
Epoch:  157       11 Batch loss: 0.177021 Batch F1: 0.7111111111111111
Epoch:  157       12 Batch loss: 0.162168 Batch F1: 0.7058823529411765
Train Avg Loss  157: 0.180624

Train Avg F1  157: 0.6912275205206052

Val Avg Loss  157: 0.188290

Val Avg F1  157:  0.6720264367094786

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 158
--------------------------------------------------------------
Epoch:  158        1 Batch loss: 0.176201 Batch F1: 0.7499999999999999
Epoch:  158        2 Batch loss: 0.171974 Batch F1: 0.7317073170731707
Epoch:  158        3 Batch loss: 0.186754 Batch F1: 0.6976744186046512
Epoch:  158        4 Batch loss: 0.182403 Batch F1: 0.6938775510204083
Epoch:  158        5 Batch loss: 0.171783 Batch F1: 0.744186046511628
Epoch:  158        6 Batch loss: 0.175529 Batch F1: 0.7
Epoch:  158        7 Batch loss: 0.187837 Batch F1: 0.711111111111111
Epoch:  158        8 Batch loss: 0.178897 Batch F1: 0.7200000000000001
Epoch:  158        9 Batch loss: 0.185292 Batch F1: 0.6190476190476191
Epoch:  158       10 Batch loss: 0.191481 Batch F1: 0.7058823529411765
Epoch:  158       11 Batch loss: 0.214237 Batch F1: 0.4761904761904762
Epoch:  158       12 Batch loss: 0.150205 Batch F1: 0.7878787878787878
Train Avg Loss  158: 0.181049

Train Avg F1  158: 0.6947963066982523

Val Avg Loss  158: 0.191322

Val Avg F1  158:  0.680351505207945

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 159
--------------------------------------------------------------
Epoch:  159        1 Batch loss: 0.167820 Batch F1: 0.7843137254901961
Epoch:  159        2 Batch loss: 0.153473 Batch F1: 0.8399999999999999
Epoch:  159        3 Batch loss: 0.204477 Batch F1: 0.6938775510204083
Epoch:  159        4 Batch loss: 0.170766 Batch F1: 0.6666666666666667
Epoch:  159        5 Batch loss: 0.159085 Batch F1: 0.7142857142857143
Epoch:  159        6 Batch loss: 0.187224 Batch F1: 0.6666666666666667
Epoch:  159        7 Batch loss: 0.181130 Batch F1: 0.8
Epoch:  159        8 Batch loss: 0.249786 Batch F1: 0.576923076923077
Epoch:  159        9 Batch loss: 0.218677 Batch F1: 0.6666666666666666
Epoch:  159       10 Batch loss: 0.168490 Batch F1: 0.7368421052631579
Epoch:  159       11 Batch loss: 0.155516 Batch F1: 0.7428571428571429
Epoch:  159       12 Batch loss: 0.193730 Batch F1: 0.7391304347826085
Train Avg Loss  159: 0.184181

Train Avg F1  159: 0.7190191458851921

Val Avg Loss  159: 0.190754

Val Avg F1  159:  0.674898564183858

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 160
--------------------------------------------------------------
Epoch:  160        1 Batch loss: 0.155433 Batch F1: 0.7368421052631577
Epoch:  160        2 Batch loss: 0.202768 Batch F1: 0.6250000000000001
Epoch:  160        3 Batch loss: 0.174370 Batch F1: 0.75
Epoch:  160        4 Batch loss: 0.170658 Batch F1: 0.7317073170731707
Epoch:  160        5 Batch loss: 0.177134 Batch F1: 0.7142857142857143
Epoch:  160        6 Batch loss: 0.185796 Batch F1: 0.7692307692307692
Epoch:  160        7 Batch loss: 0.174356 Batch F1: 0.6470588235294117
Epoch:  160        8 Batch loss: 0.214887 Batch F1: 0.6415094339622641
Epoch:  160        9 Batch loss: 0.181628 Batch F1: 0.6829268292682927
Epoch:  160       10 Batch loss: 0.158419 Batch F1: 0.7368421052631577
Epoch:  160       11 Batch loss: 0.187864 Batch F1: 0.7307692307692307
Epoch:  160       12 Batch loss: 0.177904 Batch F1: 0.7500000000000001
Train Avg Loss  160: 0.180102

Train Avg F1  160: 0.7096810273870974

Val Avg Loss  160: 0.189332

Val Avg F1  160:  0.6770154870458822

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 161
--------------------------------------------------------------
Epoch:  161        1 Batch loss: 0.225399 Batch F1: 0.6037735849056605
Epoch:  161        2 Batch loss: 0.172366 Batch F1: 0.6976744186046512
Epoch:  161        3 Batch loss: 0.141613 Batch F1: 0.7272727272727272
Epoch:  161        4 Batch loss: 0.162476 Batch F1: 0.7317073170731706
Epoch:  161        5 Batch loss: 0.213644 Batch F1: 0.6296296296296295
Epoch:  161        6 Batch loss: 0.155156 Batch F1: 0.717948717948718
Epoch:  161        7 Batch loss: 0.150726 Batch F1: 0.7924528301886793
Epoch:  161        8 Batch loss: 0.179877 Batch F1: 0.6363636363636365
Epoch:  161        9 Batch loss: 0.190257 Batch F1: 0.6530612244897959
Epoch:  161       10 Batch loss: 0.200355 Batch F1: 0.7058823529411765
Epoch:  161       11 Batch loss: 0.191277 Batch F1: 0.6808510638297872
Epoch:  161       12 Batch loss: 0.147160 Batch F1: 0.75
Train Avg Loss  161: 0.177526

Train Avg F1  161: 0.6938847919373027

Val Avg Loss  161: 0.184523

Val Avg F1  161:  0.6751931502942624

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 162
--------------------------------------------------------------
Epoch:  162        1 Batch loss: 0.167388 Batch F1: 0.7619047619047619
Epoch:  162        2 Batch loss: 0.184405 Batch F1: 0.6521739130434783
Epoch:  162        3 Batch loss: 0.174340 Batch F1: 0.7234042553191491
Epoch:  162        4 Batch loss: 0.155351 Batch F1: 0.816326530612245
Epoch:  162        5 Batch loss: 0.193766 Batch F1: 0.42424242424242425
Epoch:  162        6 Batch loss: 0.160185 Batch F1: 0.742857142857143
Epoch:  162        7 Batch loss: 0.170567 Batch F1: 0.7234042553191491
Epoch:  162        8 Batch loss: 0.180258 Batch F1: 0.7199999999999999
Epoch:  162        9 Batch loss: 0.146885 Batch F1: 0.7999999999999999
Epoch:  162       10 Batch loss: 0.151113 Batch F1: 0.8444444444444444
Epoch:  162       11 Batch loss: 0.214776 Batch F1: 0.5777777777777778
Epoch:  162       12 Batch loss: 0.193829 Batch F1: 0.6976744186046512
Train Avg Loss  162: 0.174405

Train Avg F1  162: 0.7070174936771019

Val Avg Loss  162: 0.185321

Val Avg F1  162:  0.673697423798536

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 163
--------------------------------------------------------------
Epoch:  163        1 Batch loss: 0.189291 Batch F1: 0.6808510638297872
Epoch:  163        2 Batch loss: 0.153038 Batch F1: 0.8
Epoch:  163        3 Batch loss: 0.191550 Batch F1: 0.6938775510204083
Epoch:  163        4 Batch loss: 0.140142 Batch F1: 0.8928571428571429
Epoch:  163        5 Batch loss: 0.179677 Batch F1: 0.6818181818181818
Epoch:  163        6 Batch loss: 0.203585 Batch F1: 0.6792452830188679
Epoch:  163        7 Batch loss: 0.184503 Batch F1: 0.6
Epoch:  163        8 Batch loss: 0.169091 Batch F1: 0.6666666666666667
Epoch:  163        9 Batch loss: 0.138444 Batch F1: 0.7906976744186047
Epoch:  163       10 Batch loss: 0.173442 Batch F1: 0.6666666666666666
Epoch:  163       11 Batch loss: 0.171220 Batch F1: 0.717948717948718
Epoch:  163       12 Batch loss: 0.174021 Batch F1: 0.6
Train Avg Loss  163: 0.172334

Train Avg F1  163: 0.7058857456870871

Val Avg Loss  163: 0.183049

Val Avg F1  163:  0.6692103109656301

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 164
--------------------------------------------------------------
Epoch:  164        1 Batch loss: 0.160880 Batch F1: 0.8
Epoch:  164        2 Batch loss: 0.164956 Batch F1: 0.7727272727272727
Epoch:  164        3 Batch loss: 0.185090 Batch F1: 0.6190476190476191
Epoch:  164        4 Batch loss: 0.186349 Batch F1: 0.7083333333333334
Epoch:  164        5 Batch loss: 0.164438 Batch F1: 0.7843137254901961
Epoch:  164        6 Batch loss: 0.189377 Batch F1: 0.6222222222222222
Epoch:  164        7 Batch loss: 0.164786 Batch F1: 0.7500000000000001
Epoch:  164        8 Batch loss: 0.195097 Batch F1: 0.6363636363636364
Epoch:  164        9 Batch loss: 0.181371 Batch F1: 0.6521739130434783
Epoch:  164       10 Batch loss: 0.160421 Batch F1: 0.761904761904762
Epoch:  164       11 Batch loss: 0.180833 Batch F1: 0.5806451612903225
Epoch:  164       12 Batch loss: 0.121259 Batch F1: 0.8484848484848485
Train Avg Loss  164: 0.171238

Train Avg F1  164: 0.7113513744923076

Val Avg Loss  164: 0.181999

Val Avg F1  164:  0.6790886873333682

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 165
--------------------------------------------------------------
Epoch:  165        1 Batch loss: 0.178287 Batch F1: 0.6666666666666666
Epoch:  165        2 Batch loss: 0.137661 Batch F1: 0.8181818181818182
Epoch:  165        3 Batch loss: 0.171259 Batch F1: 0.7111111111111111
Epoch:  165        4 Batch loss: 0.167225 Batch F1: 0.7499999999999999
Epoch:  165        5 Batch loss: 0.184736 Batch F1: 0.6382978723404255
Epoch:  165        6 Batch loss: 0.225863 Batch F1: 0.45454545454545453
Epoch:  165        7 Batch loss: 0.185610 Batch F1: 0.7407407407407408
Epoch:  165        8 Batch loss: 0.165470 Batch F1: 0.6976744186046512
Epoch:  165        9 Batch loss: 0.156704 Batch F1: 0.8260869565217391
Epoch:  165       10 Batch loss: 0.150575 Batch F1: 0.8333333333333333
Epoch:  165       11 Batch loss: 0.168913 Batch F1: 0.7391304347826088
Epoch:  165       12 Batch loss: 0.160731 Batch F1: 0.608695652173913
Train Avg Loss  165: 0.171086

Train Avg F1  165: 0.7070387049168718

Val Avg Loss  165: 0.182560

Val Avg F1  165:  0.6796953993933267

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 166
--------------------------------------------------------------
Epoch:  166        1 Batch loss: 0.184478 Batch F1: 0.6363636363636365
Epoch:  166        2 Batch loss: 0.179045 Batch F1: 0.7111111111111111
Epoch:  166        3 Batch loss: 0.155050 Batch F1: 0.7906976744186046
Epoch:  166        4 Batch loss: 0.179737 Batch F1: 0.6486486486486486
Epoch:  166        5 Batch loss: 0.169909 Batch F1: 0.7916666666666666
Epoch:  166        6 Batch loss: 0.172482 Batch F1: 0.723404255319149
Epoch:  166        7 Batch loss: 0.173588 Batch F1: 0.6818181818181818
Epoch:  166        8 Batch loss: 0.175954 Batch F1: 0.5882352941176471
Epoch:  166        9 Batch loss: 0.183390 Batch F1: 0.75
Epoch:  166       10 Batch loss: 0.162167 Batch F1: 0.7142857142857143
Epoch:  166       11 Batch loss: 0.188043 Batch F1: 0.6341463414634146
Epoch:  166       12 Batch loss: 0.161332 Batch F1: 0.7906976744186046
Train Avg Loss  166: 0.173765

Train Avg F1  166: 0.7050895998859482

Val Avg Loss  166: 0.183797

Val Avg F1  166:  0.6772834512976069

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 167
--------------------------------------------------------------
Epoch:  167        1 Batch loss: 0.158123 Batch F1: 0.8363636363636363
Epoch:  167        2 Batch loss: 0.188023 Batch F1: 0.6666666666666666
Epoch:  167        3 Batch loss: 0.178994 Batch F1: 0.6382978723404256
Epoch:  167        4 Batch loss: 0.182846 Batch F1: 0.6976744186046512
Epoch:  167        5 Batch loss: 0.187453 Batch F1: 0.6956521739130435
Epoch:  167        6 Batch loss: 0.159044 Batch F1: 0.7755102040816326
Epoch:  167        7 Batch loss: 0.159079 Batch F1: 0.7555555555555555
Epoch:  167        8 Batch loss: 0.227575 Batch F1: 0.5306122448979592
Epoch:  167        9 Batch loss: 0.155129 Batch F1: 0.7804878048780488
Epoch:  167       10 Batch loss: 0.168070 Batch F1: 0.6976744186046512
Epoch:  167       11 Batch loss: 0.133016 Batch F1: 0.8636363636363636
Epoch:  167       12 Batch loss: 0.186847 Batch F1: 0.6250000000000001
Train Avg Loss  167: 0.173683

Train Avg F1  167: 0.7135942799618862

Val Avg Loss  167: 0.184402

Val Avg F1  167:  0.6719678945820466

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 168
--------------------------------------------------------------
Epoch:  168        1 Batch loss: 0.176822 Batch F1: 0.5789473684210527
Epoch:  168        2 Batch loss: 0.147336 Batch F1: 0.7428571428571428
Epoch:  168        3 Batch loss: 0.171949 Batch F1: 0.6486486486486486
Epoch:  168        4 Batch loss: 0.169042 Batch F1: 0.717948717948718
Epoch:  168        5 Batch loss: 0.167046 Batch F1: 0.6060606060606061
Epoch:  168        6 Batch loss: 0.166313 Batch F1: 0.8000000000000002
Epoch:  168        7 Batch loss: 0.179808 Batch F1: 0.7307692307692308
Epoch:  168        8 Batch loss: 0.174021 Batch F1: 0.6938775510204083
Epoch:  168        9 Batch loss: 0.211774 Batch F1: 0.6206896551724138
Epoch:  168       10 Batch loss: 0.178980 Batch F1: 0.7272727272727272
Epoch:  168       11 Batch loss: 0.204916 Batch F1: 0.6530612244897959
Epoch:  168       12 Batch loss: 0.154035 Batch F1: 0.717948717948718
Train Avg Loss  168: 0.175170

Train Avg F1  168: 0.6865067992174553

Val Avg Loss  168: 0.188122

Val Avg F1  168:  0.6903782300588615

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 169
--------------------------------------------------------------
Epoch:  169        1 Batch loss: 0.144842 Batch F1: 0.7499999999999999
Epoch:  169        2 Batch loss: 0.166952 Batch F1: 0.723404255319149
Epoch:  169        3 Batch loss: 0.179064 Batch F1: 0.6666666666666666
Epoch:  169        4 Batch loss: 0.207685 Batch F1: 0.5652173913043478
Epoch:  169        5 Batch loss: 0.182707 Batch F1: 0.7391304347826088
Epoch:  169        6 Batch loss: 0.161473 Batch F1: 0.7391304347826089
Epoch:  169        7 Batch loss: 0.172039 Batch F1: 0.7391304347826088
Epoch:  169        8 Batch loss: 0.204556 Batch F1: 0.5581395348837209
Epoch:  169        9 Batch loss: 0.179860 Batch F1: 0.7142857142857143
Epoch:  169       10 Batch loss: 0.189258 Batch F1: 0.711111111111111
Epoch:  169       11 Batch loss: 0.185129 Batch F1: 0.7692307692307693
Epoch:  169       12 Batch loss: 0.161060 Batch F1: 0.7777777777777778
Train Avg Loss  169: 0.177885

Train Avg F1  169: 0.704435377077257

Val Avg Loss  169: 0.189315

Val Avg F1  169:  0.6840013851317761

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 170
--------------------------------------------------------------
Epoch:  170        1 Batch loss: 0.183188 Batch F1: 0.5555555555555556
Epoch:  170        2 Batch loss: 0.183152 Batch F1: 0.6976744186046512
Epoch:  170        3 Batch loss: 0.165920 Batch F1: 0.744186046511628
Epoch:  170        4 Batch loss: 0.164672 Batch F1: 0.7441860465116279
Epoch:  170        5 Batch loss: 0.179309 Batch F1: 0.7234042553191489
Epoch:  170        6 Batch loss: 0.171006 Batch F1: 0.76
Epoch:  170        7 Batch loss: 0.192229 Batch F1: 0.6222222222222222
Epoch:  170        8 Batch loss: 0.191319 Batch F1: 0.7547169811320754
Epoch:  170        9 Batch loss: 0.142908 Batch F1: 0.75
Epoch:  170       10 Batch loss: 0.194875 Batch F1: 0.6341463414634146
Epoch:  170       11 Batch loss: 0.177082 Batch F1: 0.6666666666666666
Epoch:  170       12 Batch loss: 0.157051 Batch F1: 0.8333333333333333
Train Avg Loss  170: 0.175226

Train Avg F1  170: 0.7071743222766936

Val Avg Loss  170: 0.184405

Val Avg F1  170:  0.6665967365967366

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 171
--------------------------------------------------------------
Epoch:  171        1 Batch loss: 0.170788 Batch F1: 0.6666666666666667
Epoch:  171        2 Batch loss: 0.180237 Batch F1: 0.6511627906976744
Epoch:  171        3 Batch loss: 0.153044 Batch F1: 0.7317073170731707
Epoch:  171        4 Batch loss: 0.178008 Batch F1: 0.6666666666666665
Epoch:  171        5 Batch loss: 0.174546 Batch F1: 0.711111111111111
Epoch:  171        6 Batch loss: 0.191489 Batch F1: 0.7111111111111111
Epoch:  171        7 Batch loss: 0.207713 Batch F1: 0.6122448979591836
Epoch:  171        8 Batch loss: 0.148189 Batch F1: 0.8372093023255814
Epoch:  171        9 Batch loss: 0.179794 Batch F1: 0.72
Epoch:  171       10 Batch loss: 0.165688 Batch F1: 0.7272727272727273
Epoch:  171       11 Batch loss: 0.166854 Batch F1: 0.8148148148148148
Epoch:  171       12 Batch loss: 0.147322 Batch F1: 0.7999999999999999
Train Avg Loss  171: 0.171973

Train Avg F1  171: 0.720830617141559

Val Avg Loss  171: 0.188391

Val Avg F1  171:  0.6389717425431711

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 172
--------------------------------------------------------------
Epoch:  172        1 Batch loss: 0.158503 Batch F1: 0.7796610169491527
Epoch:  172        2 Batch loss: 0.195363 Batch F1: 0.6666666666666666
Epoch:  172        3 Batch loss: 0.155134 Batch F1: 0.7317073170731706
Epoch:  172        4 Batch loss: 0.171165 Batch F1: 0.6956521739130435
Epoch:  172        5 Batch loss: 0.188362 Batch F1: 0.55
Epoch:  172        6 Batch loss: 0.193711 Batch F1: 0.6545454545454545
Epoch:  172        7 Batch loss: 0.179195 Batch F1: 0.65
Epoch:  172        8 Batch loss: 0.182009 Batch F1: 0.7111111111111111
Epoch:  172        9 Batch loss: 0.167128 Batch F1: 0.6486486486486486
Epoch:  172       10 Batch loss: 0.178900 Batch F1: 0.6976744186046512
Epoch:  172       11 Batch loss: 0.175061 Batch F1: 0.7659574468085107
Epoch:  172       12 Batch loss: 0.173749 Batch F1: 0.6666666666666665
Train Avg Loss  172: 0.176523

Train Avg F1  172: 0.684857576748923

Val Avg Loss  172: 0.189942

Val Avg F1  172:  0.6726394378568292

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 173
--------------------------------------------------------------
Epoch:  173        1 Batch loss: 0.181620 Batch F1: 0.6956521739130435
Epoch:  173        2 Batch loss: 0.204993 Batch F1: 0.55
Epoch:  173        3 Batch loss: 0.154486 Batch F1: 0.830188679245283
Epoch:  173        4 Batch loss: 0.201177 Batch F1: 0.6530612244897959
Epoch:  173        5 Batch loss: 0.146986 Batch F1: 0.7222222222222223
Epoch:  173        6 Batch loss: 0.174082 Batch F1: 0.7
Epoch:  173        7 Batch loss: 0.189332 Batch F1: 0.7169811320754716
Epoch:  173        8 Batch loss: 0.166754 Batch F1: 0.7567567567567567
Epoch:  173        9 Batch loss: 0.170202 Batch F1: 0.6666666666666666
Epoch:  173       10 Batch loss: 0.165077 Batch F1: 0.7692307692307692
Epoch:  173       11 Batch loss: 0.169291 Batch F1: 0.76
Epoch:  173       12 Batch loss: 0.205385 Batch F1: 0.5714285714285715
Train Avg Loss  173: 0.177449

Train Avg F1  173: 0.6993490163357151

Val Avg Loss  173: 0.191284

Val Avg F1  173:  0.678476097614948

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 174
--------------------------------------------------------------
Epoch:  174        1 Batch loss: 0.157903 Batch F1: 0.8181818181818182
Epoch:  174        2 Batch loss: 0.172071 Batch F1: 0.7499999999999999
Epoch:  174        3 Batch loss: 0.184319 Batch F1: 0.6976744186046512
Epoch:  174        4 Batch loss: 0.183575 Batch F1: 0.6511627906976744
Epoch:  174        5 Batch loss: 0.159611 Batch F1: 0.7619047619047619
Epoch:  174        6 Batch loss: 0.161305 Batch F1: 0.7555555555555556
Epoch:  174        7 Batch loss: 0.173451 Batch F1: 0.7346938775510203
Epoch:  174        8 Batch loss: 0.203028 Batch F1: 0.5833333333333334
Epoch:  174        9 Batch loss: 0.158973 Batch F1: 0.8095238095238095
Epoch:  174       10 Batch loss: 0.190776 Batch F1: 0.6808510638297872
Epoch:  174       11 Batch loss: 0.188999 Batch F1: 0.5789473684210527
Epoch:  174       12 Batch loss: 0.165809 Batch F1: 0.7804878048780488
Train Avg Loss  174: 0.174985

Train Avg F1  174: 0.7168597168734595

Val Avg Loss  174: 0.185569

Val Avg F1  174:  0.674867724867725

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 175
--------------------------------------------------------------
Epoch:  175        1 Batch loss: 0.174719 Batch F1: 0.7692307692307692
Epoch:  175        2 Batch loss: 0.163921 Batch F1: 0.8214285714285714
Epoch:  175        3 Batch loss: 0.198162 Batch F1: 0.6222222222222223
Epoch:  175        4 Batch loss: 0.166823 Batch F1: 0.7346938775510203
Epoch:  175        5 Batch loss: 0.185840 Batch F1: 0.6511627906976744
Epoch:  175        6 Batch loss: 0.204088 Batch F1: 0.48484848484848486
Epoch:  175        7 Batch loss: 0.131923 Batch F1: 0.7999999999999999
Epoch:  175        8 Batch loss: 0.177136 Batch F1: 0.7692307692307692
Epoch:  175        9 Batch loss: 0.168321 Batch F1: 0.7441860465116279
Epoch:  175       10 Batch loss: 0.171708 Batch F1: 0.6666666666666667
Epoch:  175       11 Batch loss: 0.174980 Batch F1: 0.7391304347826088
Epoch:  175       12 Batch loss: 0.157250 Batch F1: 0.7272727272727272
Train Avg Loss  175: 0.172906

Train Avg F1  175: 0.7108394467035951

Val Avg Loss  175: 0.183243

Val Avg F1  175:  0.687885594489368

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 176
--------------------------------------------------------------
Epoch:  176        1 Batch loss: 0.170156 Batch F1: 0.7
Epoch:  176        2 Batch loss: 0.154992 Batch F1: 0.8
Epoch:  176        3 Batch loss: 0.189411 Batch F1: 0.6222222222222223
Epoch:  176        4 Batch loss: 0.160286 Batch F1: 0.823529411764706
Epoch:  176        5 Batch loss: 0.197537 Batch F1: 0.5789473684210527
Epoch:  176        6 Batch loss: 0.160022 Batch F1: 0.6470588235294117
Epoch:  176        7 Batch loss: 0.189292 Batch F1: 0.6
Epoch:  176        8 Batch loss: 0.199257 Batch F1: 0.6222222222222222
Epoch:  176        9 Batch loss: 0.152441 Batch F1: 0.7272727272727274
Epoch:  176       10 Batch loss: 0.184591 Batch F1: 0.7692307692307692
Epoch:  176       11 Batch loss: 0.168073 Batch F1: 0.7272727272727272
Epoch:  176       12 Batch loss: 0.146811 Batch F1: 0.8444444444444444
Train Avg Loss  176: 0.172739

Train Avg F1  176: 0.7051833930316902

Val Avg Loss  176: 0.194445

Val Avg F1  176:  0.6753061413244543

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 177
--------------------------------------------------------------
Epoch:  177        1 Batch loss: 0.173138 Batch F1: 0.6521739130434783
Epoch:  177        2 Batch loss: 0.191686 Batch F1: 0.64
Epoch:  177        3 Batch loss: 0.159977 Batch F1: 0.7441860465116279
Epoch:  177        4 Batch loss: 0.164279 Batch F1: 0.7826086956521738
Epoch:  177        5 Batch loss: 0.170953 Batch F1: 0.6976744186046512
Epoch:  177        6 Batch loss: 0.169694 Batch F1: 0.6976744186046512
Epoch:  177        7 Batch loss: 0.176333 Batch F1: 0.6666666666666666
Epoch:  177        8 Batch loss: 0.144398 Batch F1: 0.8444444444444444
Epoch:  177        9 Batch loss: 0.188880 Batch F1: 0.7083333333333334
Epoch:  177       10 Batch loss: 0.189071 Batch F1: 0.6666666666666666
Epoch:  177       11 Batch loss: 0.165943 Batch F1: 0.761904761904762
Epoch:  177       12 Batch loss: 0.199474 Batch F1: 0.5555555555555555
Train Avg Loss  177: 0.174485

Train Avg F1  177: 0.7014907434156675

Val Avg Loss  177: 0.184314

Val Avg F1  177:  0.6585539027399493

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 178
--------------------------------------------------------------
Epoch:  178        1 Batch loss: 0.162777 Batch F1: 0.7272727272727272
Epoch:  178        2 Batch loss: 0.181208 Batch F1: 0.6190476190476191
Epoch:  178        3 Batch loss: 0.166878 Batch F1: 0.76
Epoch:  178        4 Batch loss: 0.185076 Batch F1: 0.6153846153846154
Epoch:  178        5 Batch loss: 0.156904 Batch F1: 0.8163265306122449
Epoch:  178        6 Batch loss: 0.171754 Batch F1: 0.7843137254901961
Epoch:  178        7 Batch loss: 0.158496 Batch F1: 0.75
Epoch:  178        8 Batch loss: 0.200486 Batch F1: 0.68
Epoch:  178        9 Batch loss: 0.152983 Batch F1: 0.8181818181818181
Epoch:  178       10 Batch loss: 0.144956 Batch F1: 0.8444444444444444
Epoch:  178       11 Batch loss: 0.183509 Batch F1: 0.7368421052631577
Epoch:  178       12 Batch loss: 0.203515 Batch F1: 0.32
Train Avg Loss  178: 0.172378

Train Avg F1  178: 0.7059844654747353

Val Avg Loss  178: 0.185819

Val Avg F1  178:  0.6880782672477025

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 179
--------------------------------------------------------------
Epoch:  179        1 Batch loss: 0.177687 Batch F1: 0.7391304347826088
Epoch:  179        2 Batch loss: 0.173166 Batch F1: 0.5161290322580646
Epoch:  179        3 Batch loss: 0.158738 Batch F1: 0.782608695652174
Epoch:  179        4 Batch loss: 0.176105 Batch F1: 0.7234042553191491
Epoch:  179        5 Batch loss: 0.181235 Batch F1: 0.6190476190476191
Epoch:  179        6 Batch loss: 0.171307 Batch F1: 0.7391304347826085
Epoch:  179        7 Batch loss: 0.166481 Batch F1: 0.75
Epoch:  179        8 Batch loss: 0.148493 Batch F1: 0.761904761904762
Epoch:  179        9 Batch loss: 0.195143 Batch F1: 0.6938775510204083
Epoch:  179       10 Batch loss: 0.161534 Batch F1: 0.7083333333333334
Epoch:  179       11 Batch loss: 0.220374 Batch F1: 0.6181818181818182
Epoch:  179       12 Batch loss: 0.156542 Batch F1: 0.717948717948718
Train Avg Loss  179: 0.173900

Train Avg F1  179: 0.6974747211859387

Val Avg Loss  179: 0.186499

Val Avg F1  179:  0.6659340659340659

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 180
--------------------------------------------------------------
Epoch:  180        1 Batch loss: 0.191511 Batch F1: 0.7037037037037038
Epoch:  180        2 Batch loss: 0.192956 Batch F1: 0.5789473684210527
Epoch:  180        3 Batch loss: 0.160608 Batch F1: 0.717948717948718
Epoch:  180        4 Batch loss: 0.166839 Batch F1: 0.8076923076923077
Epoch:  180        5 Batch loss: 0.156463 Batch F1: 0.6842105263157896
Epoch:  180        6 Batch loss: 0.164946 Batch F1: 0.8
Epoch:  180        7 Batch loss: 0.163837 Batch F1: 0.7755102040816326
Epoch:  180        8 Batch loss: 0.175140 Batch F1: 0.6666666666666666
Epoch:  180        9 Batch loss: 0.183762 Batch F1: 0.6666666666666665
Epoch:  180       10 Batch loss: 0.193132 Batch F1: 0.7058823529411765
Epoch:  180       11 Batch loss: 0.163575 Batch F1: 0.7906976744186046
Epoch:  180       12 Batch loss: 0.171368 Batch F1: 0.717948717948718
Train Avg Loss  180: 0.173678

Train Avg F1  180: 0.7179895755670863

Val Avg Loss  180: 0.183353

Val Avg F1  180:  0.7282101930586474

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 181
--------------------------------------------------------------
Epoch:  181        1 Batch loss: 0.159718 Batch F1: 0.7567567567567567
Epoch:  181        2 Batch loss: 0.148007 Batch F1: 0.717948717948718
Epoch:  181        3 Batch loss: 0.171458 Batch F1: 0.7796610169491527
Epoch:  181        4 Batch loss: 0.147978 Batch F1: 0.8333333333333334
Epoch:  181        5 Batch loss: 0.163660 Batch F1: 0.6829268292682926
Epoch:  181        6 Batch loss: 0.191005 Batch F1: 0.6666666666666666
Epoch:  181        7 Batch loss: 0.186761 Batch F1: 0.6956521739130435
Epoch:  181        8 Batch loss: 0.205308 Batch F1: 0.5789473684210527
Epoch:  181        9 Batch loss: 0.212937 Batch F1: 0.5714285714285714
Epoch:  181       10 Batch loss: 0.191505 Batch F1: 0.6
Epoch:  181       11 Batch loss: 0.163327 Batch F1: 0.7659574468085107
Epoch:  181       12 Batch loss: 0.152050 Batch F1: 0.8372093023255814
Train Avg Loss  181: 0.174476

Train Avg F1  181: 0.7072073486516399

Val Avg Loss  181: 0.184902

Val Avg F1  181:  0.7440288478171196

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 182
--------------------------------------------------------------
Epoch:  182        1 Batch loss: 0.201334 Batch F1: 0.7391304347826088
Epoch:  182        2 Batch loss: 0.160028 Batch F1: 0.8679245283018867
Epoch:  182        3 Batch loss: 0.159106 Batch F1: 0.7
Epoch:  182        4 Batch loss: 0.177079 Batch F1: 0.6153846153846154
Epoch:  182        5 Batch loss: 0.140621 Batch F1: 0.8400000000000001
Epoch:  182        6 Batch loss: 0.159614 Batch F1: 0.7391304347826088
Epoch:  182        7 Batch loss: 0.201624 Batch F1: 0.6222222222222222
Epoch:  182        8 Batch loss: 0.203745 Batch F1: 0.5555555555555555
Epoch:  182        9 Batch loss: 0.154425 Batch F1: 0.7804878048780488
Epoch:  182       10 Batch loss: 0.187464 Batch F1: 0.693877551020408
Epoch:  182       11 Batch loss: 0.170462 Batch F1: 0.7636363636363636
Epoch:  182       12 Batch loss: 0.186468 Batch F1: 0.6842105263157895
Train Avg Loss  182: 0.175164

Train Avg F1  182: 0.7167966697400089

Val Avg Loss  182: 0.183374

Val Avg F1  182:  0.6805602300890371

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 183
--------------------------------------------------------------
Epoch:  183        1 Batch loss: 0.178139 Batch F1: 0.7058823529411765
Epoch:  183        2 Batch loss: 0.193634 Batch F1: 0.5789473684210527
Epoch:  183        3 Batch loss: 0.187889 Batch F1: 0.6808510638297872
Epoch:  183        4 Batch loss: 0.188363 Batch F1: 0.72
Epoch:  183        5 Batch loss: 0.163395 Batch F1: 0.6976744186046512
Epoch:  183        6 Batch loss: 0.163530 Batch F1: 0.7027027027027026
Epoch:  183        7 Batch loss: 0.162549 Batch F1: 0.8085106382978724
Epoch:  183        8 Batch loss: 0.196702 Batch F1: 0.6382978723404256
Epoch:  183        9 Batch loss: 0.140063 Batch F1: 0.8095238095238095
Epoch:  183       10 Batch loss: 0.152592 Batch F1: 0.7727272727272727
Epoch:  183       11 Batch loss: 0.194101 Batch F1: 0.7169811320754716
Epoch:  183       12 Batch loss: 0.163446 Batch F1: 0.75
Train Avg Loss  183: 0.173700

Train Avg F1  183: 0.7151748859553518

Val Avg Loss  183: 0.184184

Val Avg F1  183:  0.6776328006552907

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 184
--------------------------------------------------------------
Epoch:  184        1 Batch loss: 0.177510 Batch F1: 0.6666666666666666
Epoch:  184        2 Batch loss: 0.184279 Batch F1: 0.6222222222222222
Epoch:  184        3 Batch loss: 0.187646 Batch F1: 0.7407407407407408
Epoch:  184        4 Batch loss: 0.164108 Batch F1: 0.7391304347826088
Epoch:  184        5 Batch loss: 0.163478 Batch F1: 0.7999999999999999
Epoch:  184        6 Batch loss: 0.178155 Batch F1: 0.7307692307692307
Epoch:  184        7 Batch loss: 0.164507 Batch F1: 0.7368421052631577
Epoch:  184        8 Batch loss: 0.171265 Batch F1: 0.711111111111111
Epoch:  184        9 Batch loss: 0.160568 Batch F1: 0.816326530612245
Epoch:  184       10 Batch loss: 0.168401 Batch F1: 0.717948717948718
Epoch:  184       11 Batch loss: 0.179253 Batch F1: 0.5
Epoch:  184       12 Batch loss: 0.187876 Batch F1: 0.7368421052631579
Train Avg Loss  184: 0.173920

Train Avg F1  184: 0.7098833221149882

Val Avg Loss  184: 0.185524

Val Avg F1  184:  0.6654678763397252

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 185
--------------------------------------------------------------
Epoch:  185        1 Batch loss: 0.180773 Batch F1: 0.7719298245614035
Epoch:  185        2 Batch loss: 0.206933 Batch F1: 0.6521739130434783
Epoch:  185        3 Batch loss: 0.146802 Batch F1: 0.8095238095238095
Epoch:  185        4 Batch loss: 0.160660 Batch F1: 0.7727272727272727
Epoch:  185        5 Batch loss: 0.196174 Batch F1: 0.5853658536585366
Epoch:  185        6 Batch loss: 0.176616 Batch F1: 0.5882352941176471
Epoch:  185        7 Batch loss: 0.146432 Batch F1: 0.7826086956521738
Epoch:  185        8 Batch loss: 0.154124 Batch F1: 0.75
Epoch:  185        9 Batch loss: 0.134713 Batch F1: 0.7894736842105262
Epoch:  185       10 Batch loss: 0.193623 Batch F1: 0.7307692307692307
Epoch:  185       11 Batch loss: 0.190007 Batch F1: 0.7037037037037038
Epoch:  185       12 Batch loss: 0.199946 Batch F1: 0.6190476190476191
Train Avg Loss  185: 0.173900

Train Avg F1  185: 0.7129632417512836

Val Avg Loss  185: 0.188552

Val Avg F1  185:  0.6607293758413996

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 186
--------------------------------------------------------------
Epoch:  186        1 Batch loss: 0.169165 Batch F1: 0.6829268292682927
Epoch:  186        2 Batch loss: 0.168529 Batch F1: 0.7692307692307692
Epoch:  186        3 Batch loss: 0.160701 Batch F1: 0.6666666666666667
Epoch:  186        4 Batch loss: 0.158846 Batch F1: 0.7894736842105262
Epoch:  186        5 Batch loss: 0.195680 Batch F1: 0.7307692307692306
Epoch:  186        6 Batch loss: 0.168369 Batch F1: 0.7659574468085107
Epoch:  186        7 Batch loss: 0.174900 Batch F1: 0.7346938775510203
Epoch:  186        8 Batch loss: 0.202197 Batch F1: 0.6545454545454545
Epoch:  186        9 Batch loss: 0.190728 Batch F1: 0.7916666666666666
Epoch:  186       10 Batch loss: 0.171200 Batch F1: 0.7241379310344829
Epoch:  186       11 Batch loss: 0.198022 Batch F1: 0.6222222222222222
Epoch:  186       12 Batch loss: 0.180916 Batch F1: 0.41666666666666663
Train Avg Loss  186: 0.178271

Train Avg F1  186: 0.6957464538033756

Val Avg Loss  186: 0.188507

Val Avg F1  186:  0.6733075435203094

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 187
--------------------------------------------------------------
Epoch:  187        1 Batch loss: 0.201971 Batch F1: 0.6666666666666666
Epoch:  187        2 Batch loss: 0.189746 Batch F1: 0.6190476190476191
Epoch:  187        3 Batch loss: 0.179778 Batch F1: 0.6956521739130435
Epoch:  187        4 Batch loss: 0.175490 Batch F1: 0.7843137254901961
Epoch:  187        5 Batch loss: 0.166524 Batch F1: 0.761904761904762
Epoch:  187        6 Batch loss: 0.188594 Batch F1: 0.7346938775510204
Epoch:  187        7 Batch loss: 0.169047 Batch F1: 0.7804878048780488
Epoch:  187        8 Batch loss: 0.175374 Batch F1: 0.7000000000000001
Epoch:  187        9 Batch loss: 0.187068 Batch F1: 0.6222222222222222
Epoch:  187       10 Batch loss: 0.155558 Batch F1: 0.8679245283018867
Epoch:  187       11 Batch loss: 0.161267 Batch F1: 0.7555555555555555
Epoch:  187       12 Batch loss: 0.154157 Batch F1: 0.5925925925925927
Train Avg Loss  187: 0.175381

Train Avg F1  187: 0.7150884606769679

Val Avg Loss  187: 0.191371

Val Avg F1  187:  0.6667821822003006

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 188
--------------------------------------------------------------
Epoch:  188        1 Batch loss: 0.172063 Batch F1: 0.625
Epoch:  188        2 Batch loss: 0.183836 Batch F1: 0.7346938775510203
Epoch:  188        3 Batch loss: 0.212065 Batch F1: 0.5454545454545454
Epoch:  188        4 Batch loss: 0.169502 Batch F1: 0.65
Epoch:  188        5 Batch loss: 0.180245 Batch F1: 0.6666666666666666
Epoch:  188        6 Batch loss: 0.162944 Batch F1: 0.7500000000000001
Epoch:  188        7 Batch loss: 0.169071 Batch F1: 0.7999999999999999
Epoch:  188        8 Batch loss: 0.172994 Batch F1: 0.7999999999999999
Epoch:  188        9 Batch loss: 0.176944 Batch F1: 0.7659574468085107
Epoch:  188       10 Batch loss: 0.151372 Batch F1: 0.8800000000000001
Epoch:  188       11 Batch loss: 0.155537 Batch F1: 0.7222222222222223
Epoch:  188       12 Batch loss: 0.203493 Batch F1: 0.6666666666666666
Train Avg Loss  188: 0.175839

Train Avg F1  188: 0.7172217854474693

Val Avg Loss  188: 0.186509

Val Avg F1  188:  0.6738345441965058

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 189
--------------------------------------------------------------
Epoch:  189        1 Batch loss: 0.167141 Batch F1: 0.7499999999999999
Epoch:  189        2 Batch loss: 0.156397 Batch F1: 0.816326530612245
Epoch:  189        3 Batch loss: 0.155594 Batch F1: 0.8163265306122449
Epoch:  189        4 Batch loss: 0.142127 Batch F1: 0.7777777777777777
Epoch:  189        5 Batch loss: 0.190137 Batch F1: 0.5789473684210527
Epoch:  189        6 Batch loss: 0.189811 Batch F1: 0.5853658536585366
Epoch:  189        7 Batch loss: 0.218686 Batch F1: 0.6296296296296297
Epoch:  189        8 Batch loss: 0.175358 Batch F1: 0.6818181818181819
Epoch:  189        9 Batch loss: 0.173442 Batch F1: 0.7272727272727272
Epoch:  189       10 Batch loss: 0.141662 Batch F1: 0.8679245283018868
Epoch:  189       11 Batch loss: 0.172807 Batch F1: 0.6818181818181818
Epoch:  189       12 Batch loss: 0.168273 Batch F1: 0.6666666666666666
Train Avg Loss  189: 0.170953

Train Avg F1  189: 0.7149894980490942

Val Avg Loss  189: 0.183200

Val Avg F1  189:  0.674033293598511

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 190
--------------------------------------------------------------
Epoch:  190        1 Batch loss: 0.200605 Batch F1: 0.55
Epoch:  190        2 Batch loss: 0.180247 Batch F1: 0.723404255319149
Epoch:  190        3 Batch loss: 0.150930 Batch F1: 0.8461538461538461
Epoch:  190        4 Batch loss: 0.193888 Batch F1: 0.5500000000000002
Epoch:  190        5 Batch loss: 0.177161 Batch F1: 0.6341463414634146
Epoch:  190        6 Batch loss: 0.155773 Batch F1: 0.8076923076923077
Epoch:  190        7 Batch loss: 0.177870 Batch F1: 0.7307692307692307
Epoch:  190        8 Batch loss: 0.151462 Batch F1: 0.8163265306122449
Epoch:  190        9 Batch loss: 0.181027 Batch F1: 0.7000000000000001
Epoch:  190       10 Batch loss: 0.168690 Batch F1: 0.6956521739130435
Epoch:  190       11 Batch loss: 0.180626 Batch F1: 0.5882352941176471
Epoch:  190       12 Batch loss: 0.219040 Batch F1: 0.6511627906976745
Train Avg Loss  190: 0.178110

Train Avg F1  190: 0.6911285642282131

Val Avg Loss  190: 0.186593

Val Avg F1  190:  0.6689755335104173

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 191
--------------------------------------------------------------
Epoch:  191        1 Batch loss: 0.192952 Batch F1: 0.7169811320754718
Epoch:  191        2 Batch loss: 0.163089 Batch F1: 0.7027027027027027
Epoch:  191        3 Batch loss: 0.190737 Batch F1: 0.6808510638297872
Epoch:  191        4 Batch loss: 0.186934 Batch F1: 0.6956521739130435
Epoch:  191        5 Batch loss: 0.180481 Batch F1: 0.7272727272727272
Epoch:  191        6 Batch loss: 0.157233 Batch F1: 0.7222222222222222
Epoch:  191        7 Batch loss: 0.174346 Batch F1: 0.7000000000000001
Epoch:  191        8 Batch loss: 0.179839 Batch F1: 0.711111111111111
Epoch:  191        9 Batch loss: 0.178236 Batch F1: 0.7083333333333333
Epoch:  191       10 Batch loss: 0.173392 Batch F1: 0.7755102040816326
Epoch:  191       11 Batch loss: 0.168503 Batch F1: 0.75
Epoch:  191       12 Batch loss: 0.181460 Batch F1: 0.7659574468085107
Train Avg Loss  191: 0.177267

Train Avg F1  191: 0.7213828431125452

Val Avg Loss  191: 0.187137

Val Avg F1  191:  0.7035586515909966

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 192
--------------------------------------------------------------
Epoch:  192        1 Batch loss: 0.177266 Batch F1: 0.7636363636363636
Epoch:  192        2 Batch loss: 0.199767 Batch F1: 0.6666666666666666
Epoch:  192        3 Batch loss: 0.147461 Batch F1: 0.8095238095238095
Epoch:  192        4 Batch loss: 0.210195 Batch F1: 0.5454545454545455
Epoch:  192        5 Batch loss: 0.156742 Batch F1: 0.8
Epoch:  192        6 Batch loss: 0.178262 Batch F1: 0.7083333333333334
Epoch:  192        7 Batch loss: 0.198087 Batch F1: 0.6538461538461539
Epoch:  192        8 Batch loss: 0.205644 Batch F1: 0.5957446808510638
Epoch:  192        9 Batch loss: 0.182374 Batch F1: 0.7058823529411765
Epoch:  192       10 Batch loss: 0.184429 Batch F1: 0.5405405405405405
Epoch:  192       11 Batch loss: 0.161164 Batch F1: 0.7659574468085107
Epoch:  192       12 Batch loss: 0.146682 Batch F1: 0.7999999999999999
Train Avg Loss  192: 0.179006

Train Avg F1  192: 0.696298824466847

Val Avg Loss  192: 0.185537

Val Avg F1  192:  0.6748335123523094

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 193
--------------------------------------------------------------
Epoch:  193        1 Batch loss: 0.192689 Batch F1: 0.6363636363636365
Epoch:  193        2 Batch loss: 0.171713 Batch F1: 0.7727272727272727
Epoch:  193        3 Batch loss: 0.149306 Batch F1: 0.6875
Epoch:  193        4 Batch loss: 0.181492 Batch F1: 0.7083333333333333
Epoch:  193        5 Batch loss: 0.167607 Batch F1: 0.7
Epoch:  193        6 Batch loss: 0.194815 Batch F1: 0.6086956521739131
Epoch:  193        7 Batch loss: 0.164725 Batch F1: 0.7272727272727273
Epoch:  193        8 Batch loss: 0.165634 Batch F1: 0.7000000000000001
Epoch:  193        9 Batch loss: 0.166498 Batch F1: 0.7441860465116279
Epoch:  193       10 Batch loss: 0.178364 Batch F1: 0.6938775510204083
Epoch:  193       11 Batch loss: 0.175636 Batch F1: 0.75
Epoch:  193       12 Batch loss: 0.157783 Batch F1: 0.8260869565217391
Train Avg Loss  193: 0.172189

Train Avg F1  193: 0.7129202646603882

Val Avg Loss  193: 0.186170

Val Avg F1  193:  0.7038760407030528

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 194
--------------------------------------------------------------
Epoch:  194        1 Batch loss: 0.178880 Batch F1: 0.7555555555555555
Epoch:  194        2 Batch loss: 0.168634 Batch F1: 0.6315789473684211
Epoch:  194        3 Batch loss: 0.165253 Batch F1: 0.7391304347826088
Epoch:  194        4 Batch loss: 0.189966 Batch F1: 0.6222222222222223
Epoch:  194        5 Batch loss: 0.178403 Batch F1: 0.7692307692307693
Epoch:  194        6 Batch loss: 0.158354 Batch F1: 0.7368421052631579
Epoch:  194        7 Batch loss: 0.159331 Batch F1: 0.6857142857142857
Epoch:  194        8 Batch loss: 0.195081 Batch F1: 0.6808510638297872
Epoch:  194        9 Batch loss: 0.137100 Batch F1: 0.8095238095238095
Epoch:  194       10 Batch loss: 0.208173 Batch F1: 0.6530612244897959
Epoch:  194       11 Batch loss: 0.194667 Batch F1: 0.6382978723404256
Epoch:  194       12 Batch loss: 0.174046 Batch F1: 0.7317073170731706
Train Avg Loss  194: 0.175657

Train Avg F1  194: 0.7044763006161675

Val Avg Loss  194: 0.187327

Val Avg F1  194:  0.7077900665028611

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 195
--------------------------------------------------------------
Epoch:  195        1 Batch loss: 0.150782 Batch F1: 0.7727272727272727
Epoch:  195        2 Batch loss: 0.182779 Batch F1: 0.6808510638297872
Epoch:  195        3 Batch loss: 0.183413 Batch F1: 0.7346938775510204
Epoch:  195        4 Batch loss: 0.164496 Batch F1: 0.7555555555555556
Epoch:  195        5 Batch loss: 0.179016 Batch F1: 0.7307692307692308
Epoch:  195        6 Batch loss: 0.189254 Batch F1: 0.68
Epoch:  195        7 Batch loss: 0.190635 Batch F1: 0.6341463414634146
Epoch:  195        8 Batch loss: 0.155341 Batch F1: 0.8571428571428572
Epoch:  195        9 Batch loss: 0.170631 Batch F1: 0.631578947368421
Epoch:  195       10 Batch loss: 0.160515 Batch F1: 0.7317073170731706
Epoch:  195       11 Batch loss: 0.177534 Batch F1: 0.7272727272727272
Epoch:  195       12 Batch loss: 0.196228 Batch F1: 0.5945945945945946
Train Avg Loss  195: 0.175052

Train Avg F1  195: 0.7109199821123376

Val Avg Loss  195: 0.185179

Val Avg F1  195:  0.6766674968571361

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 196
--------------------------------------------------------------
Epoch:  196        1 Batch loss: 0.156559 Batch F1: 0.7317073170731707
Epoch:  196        2 Batch loss: 0.180690 Batch F1: 0.6
Epoch:  196        3 Batch loss: 0.155665 Batch F1: 0.75
Epoch:  196        4 Batch loss: 0.187832 Batch F1: 0.6956521739130435
Epoch:  196        5 Batch loss: 0.173869 Batch F1: 0.744186046511628
Epoch:  196        6 Batch loss: 0.189868 Batch F1: 0.6666666666666666
Epoch:  196        7 Batch loss: 0.138650 Batch F1: 0.8181818181818182
Epoch:  196        8 Batch loss: 0.196883 Batch F1: 0.6792452830188679
Epoch:  196        9 Batch loss: 0.148415 Batch F1: 0.851063829787234
Epoch:  196       10 Batch loss: 0.196774 Batch F1: 0.5853658536585366
Epoch:  196       11 Batch loss: 0.159270 Batch F1: 0.7727272727272727
Epoch:  196       12 Batch loss: 0.178436 Batch F1: 0.6842105263157896
Train Avg Loss  196: 0.171909

Train Avg F1  196: 0.7149172323211689

Val Avg Loss  196: 0.183169

Val Avg F1  196:  0.6774851832624942

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 197
--------------------------------------------------------------
Epoch:  197        1 Batch loss: 0.154295 Batch F1: 0.7906976744186046
Epoch:  197        2 Batch loss: 0.158366 Batch F1: 0.7317073170731706
Epoch:  197        3 Batch loss: 0.207021 Batch F1: 0.6428571428571428
Epoch:  197        4 Batch loss: 0.185284 Batch F1: 0.6046511627906976
Epoch:  197        5 Batch loss: 0.181071 Batch F1: 0.7307692307692307
Epoch:  197        6 Batch loss: 0.159154 Batch F1: 0.8421052631578947
Epoch:  197        7 Batch loss: 0.195273 Batch F1: 0.6521739130434783
Epoch:  197        8 Batch loss: 0.185337 Batch F1: 0.6956521739130435
Epoch:  197        9 Batch loss: 0.177618 Batch F1: 0.6976744186046512
Epoch:  197       10 Batch loss: 0.134441 Batch F1: 0.7777777777777778
Epoch:  197       11 Batch loss: 0.152301 Batch F1: 0.7058823529411765
Epoch:  197       12 Batch loss: 0.161850 Batch F1: 0.7567567567567567
Train Avg Loss  197: 0.171001

Train Avg F1  197: 0.7190587653419689

Val Avg Loss  197: 0.183680

Val Avg F1  197:  0.6734575569358179

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 198
--------------------------------------------------------------
Epoch:  198        1 Batch loss: 0.181109 Batch F1: 0.6829268292682926
Epoch:  198        2 Batch loss: 0.179134 Batch F1: 0.7450980392156864
Epoch:  198        3 Batch loss: 0.174874 Batch F1: 0.6829268292682926
Epoch:  198        4 Batch loss: 0.179022 Batch F1: 0.6956521739130435
Epoch:  198        5 Batch loss: 0.173626 Batch F1: 0.7547169811320756
Epoch:  198        6 Batch loss: 0.153733 Batch F1: 0.7555555555555556
Epoch:  198        7 Batch loss: 0.222066 Batch F1: 0.5531914893617023
Epoch:  198        8 Batch loss: 0.190294 Batch F1: 0.6938775510204083
Epoch:  198        9 Batch loss: 0.134883 Batch F1: 0.7692307692307692
Epoch:  198       10 Batch loss: 0.167030 Batch F1: 0.7391304347826088
Epoch:  198       11 Batch loss: 0.145923 Batch F1: 0.6923076923076923
Epoch:  198       12 Batch loss: 0.164656 Batch F1: 0.8260869565217391
Train Avg Loss  198: 0.172196

Train Avg F1  198: 0.7158917751314888

Val Avg Loss  198: 0.182295

Val Avg F1  198:  0.6890315320189582

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 199
--------------------------------------------------------------
Epoch:  199        1 Batch loss: 0.176354 Batch F1: 0.6153846153846153
Epoch:  199        2 Batch loss: 0.168896 Batch F1: 0.7999999999999999
Epoch:  199        3 Batch loss: 0.177990 Batch F1: 0.6382978723404256
Epoch:  199        4 Batch loss: 0.160964 Batch F1: 0.7636363636363636
Epoch:  199        5 Batch loss: 0.161266 Batch F1: 0.7346938775510203
Epoch:  199        6 Batch loss: 0.132858 Batch F1: 0.8372093023255814
Epoch:  199        7 Batch loss: 0.168912 Batch F1: 0.7755102040816326
Epoch:  199        8 Batch loss: 0.198003 Batch F1: 0.6666666666666666
Epoch:  199        9 Batch loss: 0.179221 Batch F1: 0.6829268292682926
Epoch:  199       10 Batch loss: 0.195838 Batch F1: 0.6818181818181818
Epoch:  199       11 Batch loss: 0.192183 Batch F1: 0.6153846153846153
Epoch:  199       12 Batch loss: 0.158230 Batch F1: 0.7058823529411765
Train Avg Loss  199: 0.172560

Train Avg F1  199: 0.7097842401165475

Val Avg Loss  199: 0.184128

Val Avg F1  199:  0.6949583718778909

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 200
--------------------------------------------------------------
Epoch:  200        1 Batch loss: 0.206903 Batch F1: 0.5581395348837209
Epoch:  200        2 Batch loss: 0.141434 Batch F1: 0.7222222222222223
Epoch:  200        3 Batch loss: 0.158300 Batch F1: 0.7727272727272727
Epoch:  200        4 Batch loss: 0.178585 Batch F1: 0.7083333333333334
Epoch:  200        5 Batch loss: 0.141873 Batch F1: 0.7826086956521738
Epoch:  200        6 Batch loss: 0.219020 Batch F1: 0.5333333333333333
Epoch:  200        7 Batch loss: 0.192364 Batch F1: 0.7333333333333333
Epoch:  200        8 Batch loss: 0.154773 Batch F1: 0.7692307692307692
Epoch:  200        9 Batch loss: 0.150138 Batch F1: 0.761904761904762
Epoch:  200       10 Batch loss: 0.180522 Batch F1: 0.7083333333333334
Epoch:  200       11 Batch loss: 0.174008 Batch F1: 0.8085106382978724
Epoch:  200       12 Batch loss: 0.174524 Batch F1: 0.7222222222222222
Train Avg Loss  200: 0.172704

Train Avg F1  200: 0.7150749542061957

Val Avg Loss  200: 0.184696

Val Avg F1  200:  0.6650818065809863

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 201
--------------------------------------------------------------
Epoch:  201        1 Batch loss: 0.176797 Batch F1: 0.6341463414634146
Epoch:  201        2 Batch loss: 0.164296 Batch F1: 0.7391304347826088
Epoch:  201        3 Batch loss: 0.212527 Batch F1: 0.6785714285714286
Epoch:  201        4 Batch loss: 0.182710 Batch F1: 0.6046511627906977
Epoch:  201        5 Batch loss: 0.174343 Batch F1: 0.8076923076923077
Epoch:  201        6 Batch loss: 0.142120 Batch F1: 0.8571428571428571
Epoch:  201        7 Batch loss: 0.174510 Batch F1: 0.6511627906976745
Epoch:  201        8 Batch loss: 0.146841 Batch F1: 0.6666666666666667
Epoch:  201        9 Batch loss: 0.201211 Batch F1: 0.6363636363636365
Epoch:  201       10 Batch loss: 0.190703 Batch F1: 0.6511627906976745
Epoch:  201       11 Batch loss: 0.173309 Batch F1: 0.8148148148148148
Epoch:  201       12 Batch loss: 0.209708 Batch F1: 0.75
Train Avg Loss  201: 0.179090

Train Avg F1  201: 0.7076254359736485

Val Avg Loss  201: 0.190083

Val Avg F1  201:  0.7647729833017709

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 202
--------------------------------------------------------------
Epoch:  202        1 Batch loss: 0.155524 Batch F1: 0.8
Epoch:  202        2 Batch loss: 0.150891 Batch F1: 0.717948717948718
Epoch:  202        3 Batch loss: 0.195569 Batch F1: 0.5853658536585366
Epoch:  202        4 Batch loss: 0.157616 Batch F1: 0.782608695652174
Epoch:  202        5 Batch loss: 0.159878 Batch F1: 0.7999999999999999
Epoch:  202        6 Batch loss: 0.189728 Batch F1: 0.5945945945945946
Epoch:  202        7 Batch loss: 0.167508 Batch F1: 0.6829268292682926
Epoch:  202        8 Batch loss: 0.170640 Batch F1: 0.723404255319149
Epoch:  202        9 Batch loss: 0.179938 Batch F1: 0.6153846153846153
Epoch:  202       10 Batch loss: 0.209309 Batch F1: 0.6909090909090909
Epoch:  202       11 Batch loss: 0.178039 Batch F1: 0.7307692307692308
Epoch:  202       12 Batch loss: 0.190838 Batch F1: 0.6976744186046512
Train Avg Loss  202: 0.175457

Train Avg F1  202: 0.7017988585090876

Val Avg Loss  202: 0.184435

Val Avg F1  202:  0.6764797551983381

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 203
--------------------------------------------------------------
Epoch:  203        1 Batch loss: 0.144643 Batch F1: 0.7500000000000001
Epoch:  203        2 Batch loss: 0.152867 Batch F1: 0.782608695652174
Epoch:  203        3 Batch loss: 0.156552 Batch F1: 0.7843137254901961
Epoch:  203        4 Batch loss: 0.193819 Batch F1: 0.6511627906976744
Epoch:  203        5 Batch loss: 0.159469 Batch F1: 0.8253968253968254
Epoch:  203        6 Batch loss: 0.162326 Batch F1: 0.6896551724137931
Epoch:  203        7 Batch loss: 0.231488 Batch F1: 0.5531914893617021
Epoch:  203        8 Batch loss: 0.210669 Batch F1: 0.6
Epoch:  203        9 Batch loss: 0.151939 Batch F1: 0.7804878048780488
Epoch:  203       10 Batch loss: 0.196164 Batch F1: 0.6363636363636365
Epoch:  203       11 Batch loss: 0.187994 Batch F1: 0.6511627906976744
Epoch:  203       12 Batch loss: 0.139295 Batch F1: 0.8421052631578947
Train Avg Loss  203: 0.173935

Train Avg F1  203: 0.7122040161758015

Val Avg Loss  203: 0.185595

Val Avg F1  203:  0.6946524064171122

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 204
--------------------------------------------------------------
Epoch:  204        1 Batch loss: 0.148398 Batch F1: 0.7567567567567567
Epoch:  204        2 Batch loss: 0.176645 Batch F1: 0.6538461538461539
Epoch:  204        3 Batch loss: 0.217960 Batch F1: 0.6296296296296297
Epoch:  204        4 Batch loss: 0.171711 Batch F1: 0.7692307692307693
Epoch:  204        5 Batch loss: 0.170375 Batch F1: 0.7234042553191489
Epoch:  204        6 Batch loss: 0.176929 Batch F1: 0.6976744186046512
Epoch:  204        7 Batch loss: 0.200953 Batch F1: 0.7142857142857143
Epoch:  204        8 Batch loss: 0.160333 Batch F1: 0.7027027027027026
Epoch:  204        9 Batch loss: 0.182728 Batch F1: 0.7391304347826088
Epoch:  204       10 Batch loss: 0.159301 Batch F1: 0.7368421052631577
Epoch:  204       11 Batch loss: 0.214089 Batch F1: 0.64
Epoch:  204       12 Batch loss: 0.161456 Batch F1: 0.7567567567567567
Train Avg Loss  204: 0.178406

Train Avg F1  204: 0.710021641431504

Val Avg Loss  204: 0.186809

Val Avg F1  204:  0.6983965920725463

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 205
--------------------------------------------------------------
Epoch:  205        1 Batch loss: 0.198430 Batch F1: 0.6530612244897959
Epoch:  205        2 Batch loss: 0.180871 Batch F1: 0.6666666666666667
Epoch:  205        3 Batch loss: 0.178854 Batch F1: 0.6976744186046512
Epoch:  205        4 Batch loss: 0.204710 Batch F1: 0.6382978723404256
Epoch:  205        5 Batch loss: 0.180276 Batch F1: 0.7346938775510204
Epoch:  205        6 Batch loss: 0.155861 Batch F1: 0.7027027027027029
Epoch:  205        7 Batch loss: 0.199033 Batch F1: 0.6511627906976744
Epoch:  205        8 Batch loss: 0.167359 Batch F1: 0.7111111111111111
Epoch:  205        9 Batch loss: 0.148904 Batch F1: 0.8679245283018868
Epoch:  205       10 Batch loss: 0.134859 Batch F1: 0.9056603773584904
Epoch:  205       11 Batch loss: 0.146851 Batch F1: 0.8095238095238095
Epoch:  205       12 Batch loss: 0.192150 Batch F1: 0.6470588235294117
Train Avg Loss  205: 0.174013

Train Avg F1  205: 0.7237948502398038

Val Avg Loss  205: 0.186813

Val Avg F1  205:  0.6884581075723536

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 206
--------------------------------------------------------------
Epoch:  206        1 Batch loss: 0.152994 Batch F1: 0.7317073170731706
Epoch:  206        2 Batch loss: 0.197879 Batch F1: 0.5789473684210527
Epoch:  206        3 Batch loss: 0.173648 Batch F1: 0.76
Epoch:  206        4 Batch loss: 0.171292 Batch F1: 0.782608695652174
Epoch:  206        5 Batch loss: 0.196092 Batch F1: 0.6666666666666666
Epoch:  206        6 Batch loss: 0.177863 Batch F1: 0.7346938775510203
Epoch:  206        7 Batch loss: 0.182910 Batch F1: 0.7083333333333333
Epoch:  206        8 Batch loss: 0.161864 Batch F1: 0.7555555555555556
Epoch:  206        9 Batch loss: 0.163071 Batch F1: 0.7692307692307692
Epoch:  206       10 Batch loss: 0.173683 Batch F1: 0.723404255319149
Epoch:  206       11 Batch loss: 0.176156 Batch F1: 0.6842105263157896
Epoch:  206       12 Batch loss: 0.171887 Batch F1: 0.7500000000000001
Train Avg Loss  206: 0.174945

Train Avg F1  206: 0.7204465304265568

Val Avg Loss  206: 0.190692

Val Avg F1  206:  0.6428585423854134

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 207
--------------------------------------------------------------
Epoch:  207        1 Batch loss: 0.158147 Batch F1: 0.7441860465116279
Epoch:  207        2 Batch loss: 0.159719 Batch F1: 0.7222222222222223
Epoch:  207        3 Batch loss: 0.157793 Batch F1: 0.606060606060606
Epoch:  207        4 Batch loss: 0.186764 Batch F1: 0.5500000000000002
Epoch:  207        5 Batch loss: 0.177926 Batch F1: 0.6818181818181818
Epoch:  207        6 Batch loss: 0.199018 Batch F1: 0.6363636363636365
Epoch:  207        7 Batch loss: 0.202829 Batch F1: 0.72
Epoch:  207        8 Batch loss: 0.181533 Batch F1: 0.7272727272727272
Epoch:  207        9 Batch loss: 0.181507 Batch F1: 0.6938775510204083
Epoch:  207       10 Batch loss: 0.182070 Batch F1: 0.7058823529411765
Epoch:  207       11 Batch loss: 0.186906 Batch F1: 0.68
Epoch:  207       12 Batch loss: 0.174637 Batch F1: 0.7368421052631577
Train Avg Loss  207: 0.179071

Train Avg F1  207: 0.6837104524561454

Val Avg Loss  207: 0.188232

Val Avg F1  207:  0.7187867667889866

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 208
--------------------------------------------------------------
Epoch:  208        1 Batch loss: 0.187149 Batch F1: 0.631578947368421
Epoch:  208        2 Batch loss: 0.170298 Batch F1: 0.7727272727272727
Epoch:  208        3 Batch loss: 0.174479 Batch F1: 0.6842105263157895
Epoch:  208        4 Batch loss: 0.179300 Batch F1: 0.7000000000000001
Epoch:  208        5 Batch loss: 0.179301 Batch F1: 0.7317073170731707
Epoch:  208        6 Batch loss: 0.178432 Batch F1: 0.8
Epoch:  208        7 Batch loss: 0.179156 Batch F1: 0.8085106382978723
Epoch:  208        8 Batch loss: 0.195511 Batch F1: 0.693877551020408
Epoch:  208        9 Batch loss: 0.170454 Batch F1: 0.7450980392156864
Epoch:  208       10 Batch loss: 0.162039 Batch F1: 0.7500000000000001
Epoch:  208       11 Batch loss: 0.211988 Batch F1: 0.6274509803921569
Epoch:  208       12 Batch loss: 0.164139 Batch F1: 0.7222222222222222
Train Avg Loss  208: 0.179354

Train Avg F1  208: 0.7222819578860832

Val Avg Loss  208: 0.185190

Val Avg F1  208:  0.6762861259428765

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 209
--------------------------------------------------------------
Epoch:  209        1 Batch loss: 0.176067 Batch F1: 0.6666666666666666
Epoch:  209        2 Batch loss: 0.149167 Batch F1: 0.7692307692307692
Epoch:  209        3 Batch loss: 0.159627 Batch F1: 0.7659574468085107
Epoch:  209        4 Batch loss: 0.183894 Batch F1: 0.7058823529411765
Epoch:  209        5 Batch loss: 0.170480 Batch F1: 0.7636363636363638
Epoch:  209        6 Batch loss: 0.179486 Batch F1: 0.5806451612903225
Epoch:  209        7 Batch loss: 0.210410 Batch F1: 0.55
Epoch:  209        8 Batch loss: 0.159546 Batch F1: 0.8163265306122449
Epoch:  209        9 Batch loss: 0.160656 Batch F1: 0.7441860465116279
Epoch:  209       10 Batch loss: 0.198474 Batch F1: 0.6666666666666666
Epoch:  209       11 Batch loss: 0.189566 Batch F1: 0.6923076923076923
Epoch:  209       12 Batch loss: 0.157977 Batch F1: 0.7272727272727272
Train Avg Loss  209: 0.174612

Train Avg F1  209: 0.704064868662064

Val Avg Loss  209: 0.184497

Val Avg F1  209:  0.6781949934123847

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 210
--------------------------------------------------------------
Epoch:  210        1 Batch loss: 0.185463 Batch F1: 0.5789473684210527
Epoch:  210        2 Batch loss: 0.157504 Batch F1: 0.782608695652174
Epoch:  210        3 Batch loss: 0.170569 Batch F1: 0.6285714285714287
Epoch:  210        4 Batch loss: 0.143871 Batch F1: 0.8571428571428572
Epoch:  210        5 Batch loss: 0.147608 Batch F1: 0.8095238095238095
Epoch:  210        6 Batch loss: 0.178644 Batch F1: 0.6666666666666666
Epoch:  210        7 Batch loss: 0.167879 Batch F1: 0.7599999999999999
Epoch:  210        8 Batch loss: 0.165263 Batch F1: 0.7727272727272727
Epoch:  210        9 Batch loss: 0.174129 Batch F1: 0.631578947368421
Epoch:  210       10 Batch loss: 0.179558 Batch F1: 0.6666666666666666
Epoch:  210       11 Batch loss: 0.205567 Batch F1: 0.6666666666666666
Epoch:  210       12 Batch loss: 0.190736 Batch F1: 0.7111111111111111
Train Avg Loss  210: 0.172233

Train Avg F1  210: 0.7110176242098439

Val Avg Loss  210: 0.183043

Val Avg F1  210:  0.6972789115646258

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 211
--------------------------------------------------------------
Epoch:  211        1 Batch loss: 0.193972 Batch F1: 0.5365853658536586
Epoch:  211        2 Batch loss: 0.142065 Batch F1: 0.7142857142857143
Epoch:  211        3 Batch loss: 0.205656 Batch F1: 0.625
Epoch:  211        4 Batch loss: 0.166400 Batch F1: 0.7727272727272727
Epoch:  211        5 Batch loss: 0.154326 Batch F1: 0.8627450980392156
Epoch:  211        6 Batch loss: 0.180079 Batch F1: 0.7457627118644068
Epoch:  211        7 Batch loss: 0.195752 Batch F1: 0.631578947368421
Epoch:  211        8 Batch loss: 0.165902 Batch F1: 0.6486486486486486
Epoch:  211        9 Batch loss: 0.150075 Batch F1: 0.7222222222222222
Epoch:  211       10 Batch loss: 0.180047 Batch F1: 0.7083333333333334
Epoch:  211       11 Batch loss: 0.171988 Batch F1: 0.6666666666666666
Epoch:  211       12 Batch loss: 0.137027 Batch F1: 0.888888888888889
Train Avg Loss  211: 0.170274

Train Avg F1  211: 0.7102870724915374

Val Avg Loss  211: 0.183162

Val Avg F1  211:  0.6621212121212121

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 212
--------------------------------------------------------------
Epoch:  212        1 Batch loss: 0.160189 Batch F1: 0.606060606060606
Epoch:  212        2 Batch loss: 0.167739 Batch F1: 0.7636363636363638
Epoch:  212        3 Batch loss: 0.135113 Batch F1: 0.8095238095238095
Epoch:  212        4 Batch loss: 0.168768 Batch F1: 0.6829268292682926
Epoch:  212        5 Batch loss: 0.184282 Batch F1: 0.6511627906976744
Epoch:  212        6 Batch loss: 0.183201 Batch F1: 0.72
Epoch:  212        7 Batch loss: 0.154008 Batch F1: 0.7272727272727273
Epoch:  212        8 Batch loss: 0.191992 Batch F1: 0.6666666666666665
Epoch:  212        9 Batch loss: 0.171856 Batch F1: 0.7727272727272727
Epoch:  212       10 Batch loss: 0.176660 Batch F1: 0.76
Epoch:  212       11 Batch loss: 0.190252 Batch F1: 0.6382978723404255
Epoch:  212       12 Batch loss: 0.162712 Batch F1: 0.6666666666666667
Train Avg Loss  212: 0.170564

Train Avg F1  212: 0.705411800405042

Val Avg Loss  212: 0.184570

Val Avg F1  212:  0.6893528578479445

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 213
--------------------------------------------------------------
Epoch:  213        1 Batch loss: 0.144615 Batch F1: 0.8095238095238095
Epoch:  213        2 Batch loss: 0.157648 Batch F1: 0.8363636363636363
Epoch:  213        3 Batch loss: 0.204841 Batch F1: 0.5957446808510638
Epoch:  213        4 Batch loss: 0.175278 Batch F1: 0.6842105263157895
Epoch:  213        5 Batch loss: 0.172858 Batch F1: 0.7346938775510203
Epoch:  213        6 Batch loss: 0.164033 Batch F1: 0.8363636363636363
Epoch:  213        7 Batch loss: 0.159447 Batch F1: 0.7441860465116279
Epoch:  213        8 Batch loss: 0.182683 Batch F1: 0.6060606060606061
Epoch:  213        9 Batch loss: 0.190087 Batch F1: 0.6382978723404256
Epoch:  213       10 Batch loss: 0.184352 Batch F1: 0.6666666666666666
Epoch:  213       11 Batch loss: 0.171929 Batch F1: 0.6976744186046512
Epoch:  213       12 Batch loss: 0.156082 Batch F1: 0.7499999999999999
Train Avg Loss  213: 0.171988

Train Avg F1  213: 0.7166488147627444

Val Avg Loss  213: 0.184802

Val Avg F1  213:  0.6827913823096481

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 214
--------------------------------------------------------------
Epoch:  214        1 Batch loss: 0.189679 Batch F1: 0.6666666666666666
Epoch:  214        2 Batch loss: 0.171473 Batch F1: 0.6818181818181819
Epoch:  214        3 Batch loss: 0.196279 Batch F1: 0.608695652173913
Epoch:  214        4 Batch loss: 0.185010 Batch F1: 0.6511627906976744
Epoch:  214        5 Batch loss: 0.164849 Batch F1: 0.711111111111111
Epoch:  214        6 Batch loss: 0.172733 Batch F1: 0.76
Epoch:  214        7 Batch loss: 0.163225 Batch F1: 0.7826086956521738
Epoch:  214        8 Batch loss: 0.171415 Batch F1: 0.6976744186046512
Epoch:  214        9 Batch loss: 0.168914 Batch F1: 0.6666666666666666
Epoch:  214       10 Batch loss: 0.153841 Batch F1: 0.8181818181818182
Epoch:  214       11 Batch loss: 0.171205 Batch F1: 0.7659574468085106
Epoch:  214       12 Batch loss: 0.191844 Batch F1: 0.6829268292682927
Train Avg Loss  214: 0.175039

Train Avg F1  214: 0.7077891898041383

Val Avg Loss  214: 0.182237

Val Avg F1  214:  0.6828460187155839

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 215
--------------------------------------------------------------
Epoch:  215        1 Batch loss: 0.153502 Batch F1: 0.8518518518518519
Epoch:  215        2 Batch loss: 0.163688 Batch F1: 0.6666666666666666
Epoch:  215        3 Batch loss: 0.162038 Batch F1: 0.6857142857142857
Epoch:  215        4 Batch loss: 0.220592 Batch F1: 0.4615384615384615
Epoch:  215        5 Batch loss: 0.162042 Batch F1: 0.7843137254901961
Epoch:  215        6 Batch loss: 0.167748 Batch F1: 0.6818181818181818
Epoch:  215        7 Batch loss: 0.166071 Batch F1: 0.7317073170731706
Epoch:  215        8 Batch loss: 0.200174 Batch F1: 0.679245283018868
Epoch:  215        9 Batch loss: 0.186313 Batch F1: 0.6956521739130435
Epoch:  215       10 Batch loss: 0.154745 Batch F1: 0.8085106382978724
Epoch:  215       11 Batch loss: 0.176800 Batch F1: 0.5454545454545455
Epoch:  215       12 Batch loss: 0.144645 Batch F1: 0.8636363636363635
Train Avg Loss  215: 0.171530

Train Avg F1  215: 0.7046757912061256

Val Avg Loss  215: 0.184490

Val Avg F1  215:  0.707157622739018

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 216
--------------------------------------------------------------
Epoch:  216        1 Batch loss: 0.163909 Batch F1: 0.782608695652174
Epoch:  216        2 Batch loss: 0.159615 Batch F1: 0.8135593220338982
Epoch:  216        3 Batch loss: 0.147080 Batch F1: 0.7317073170731708
Epoch:  216        4 Batch loss: 0.175415 Batch F1: 0.7
Epoch:  216        5 Batch loss: 0.172615 Batch F1: 0.75
Epoch:  216        6 Batch loss: 0.210366 Batch F1: 0.5128205128205129
Epoch:  216        7 Batch loss: 0.175106 Batch F1: 0.7450980392156864
Epoch:  216        8 Batch loss: 0.158417 Batch F1: 0.7555555555555555
Epoch:  216        9 Batch loss: 0.169700 Batch F1: 0.7272727272727272
Epoch:  216       10 Batch loss: 0.155104 Batch F1: 0.7
Epoch:  216       11 Batch loss: 0.219346 Batch F1: 0.6545454545454545
Epoch:  216       12 Batch loss: 0.155402 Batch F1: 0.7368421052631579
Train Avg Loss  216: 0.171840

Train Avg F1  216: 0.7175008107860282

Val Avg Loss  216: 0.182966

Val Avg F1  216:  0.6882189239332097

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 217
--------------------------------------------------------------
Epoch:  217        1 Batch loss: 0.129011 Batch F1: 0.8695652173913043
Epoch:  217        2 Batch loss: 0.154956 Batch F1: 0.8
Epoch:  217        3 Batch loss: 0.194110 Batch F1: 0.7199999999999999
Epoch:  217        4 Batch loss: 0.152935 Batch F1: 0.717948717948718
Epoch:  217        5 Batch loss: 0.189919 Batch F1: 0.5
Epoch:  217        6 Batch loss: 0.195898 Batch F1: 0.7169811320754716
Epoch:  217        7 Batch loss: 0.159927 Batch F1: 0.7000000000000001
Epoch:  217        8 Batch loss: 0.165015 Batch F1: 0.8214285714285715
Epoch:  217        9 Batch loss: 0.195952 Batch F1: 0.6666666666666666
Epoch:  217       10 Batch loss: 0.174405 Batch F1: 0.76
Epoch:  217       11 Batch loss: 0.184925 Batch F1: 0.631578947368421
Epoch:  217       12 Batch loss: 0.175362 Batch F1: 0.6470588235294117
Train Avg Loss  217: 0.172701

Train Avg F1  217: 0.7126023397007137

Val Avg Loss  217: 0.184866

Val Avg F1  217:  0.6776752264488181

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 218
--------------------------------------------------------------
Epoch:  218        1 Batch loss: 0.176866 Batch F1: 0.6666666666666666
Epoch:  218        2 Batch loss: 0.168634 Batch F1: 0.7777777777777777
Epoch:  218        3 Batch loss: 0.161984 Batch F1: 0.7555555555555555
Epoch:  218        4 Batch loss: 0.166529 Batch F1: 0.6976744186046512
Epoch:  218        5 Batch loss: 0.196677 Batch F1: 0.6
Epoch:  218        6 Batch loss: 0.186040 Batch F1: 0.6666666666666666
Epoch:  218        7 Batch loss: 0.150729 Batch F1: 0.7428571428571429
Epoch:  218        8 Batch loss: 0.175448 Batch F1: 0.75
Epoch:  218        9 Batch loss: 0.171114 Batch F1: 0.7391304347826088
Epoch:  218       10 Batch loss: 0.145660 Batch F1: 0.7692307692307692
Epoch:  218       11 Batch loss: 0.178628 Batch F1: 0.7058823529411765
Epoch:  218       12 Batch loss: 0.170705 Batch F1: 0.744186046511628
Train Avg Loss  218: 0.170751

Train Avg F1  218: 0.7179689859662202

Val Avg Loss  218: 0.182842

Val Avg F1  218:  0.6897222222222221

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 219
--------------------------------------------------------------
Epoch:  219        1 Batch loss: 0.164705 Batch F1: 0.76
Epoch:  219        2 Batch loss: 0.187128 Batch F1: 0.7407407407407407
Epoch:  219        3 Batch loss: 0.180064 Batch F1: 0.723404255319149
Epoch:  219        4 Batch loss: 0.186596 Batch F1: 0.6511627906976744
Epoch:  219        5 Batch loss: 0.165936 Batch F1: 0.7692307692307692
Epoch:  219        6 Batch loss: 0.166037 Batch F1: 0.7826086956521738
Epoch:  219        7 Batch loss: 0.165693 Batch F1: 0.7272727272727272
Epoch:  219        8 Batch loss: 0.171859 Batch F1: 0.6857142857142857
Epoch:  219        9 Batch loss: 0.174243 Batch F1: 0.7636363636363636
Epoch:  219       10 Batch loss: 0.166417 Batch F1: 0.6818181818181819
Epoch:  219       11 Batch loss: 0.155920 Batch F1: 0.6842105263157895
Epoch:  219       12 Batch loss: 0.163480 Batch F1: 0.7804878048780488
Train Avg Loss  219: 0.170673

Train Avg F1  219: 0.7291905951063254

Val Avg Loss  219: 0.183719

Val Avg F1  219:  0.6797992577597841

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 220
--------------------------------------------------------------
Epoch:  220        1 Batch loss: 0.166806 Batch F1: 0.7142857142857143
Epoch:  220        2 Batch loss: 0.165884 Batch F1: 0.7
Epoch:  220        3 Batch loss: 0.138838 Batch F1: 0.6666666666666666
Epoch:  220        4 Batch loss: 0.196614 Batch F1: 0.5625000000000001
Epoch:  220        5 Batch loss: 0.194909 Batch F1: 0.588235294117647
Epoch:  220        6 Batch loss: 0.180187 Batch F1: 0.6818181818181819
Epoch:  220        7 Batch loss: 0.154416 Batch F1: 0.823529411764706
Epoch:  220        8 Batch loss: 0.176456 Batch F1: 0.7666666666666667
Epoch:  220        9 Batch loss: 0.194745 Batch F1: 0.693877551020408
Epoch:  220       10 Batch loss: 0.192147 Batch F1: 0.6792452830188679
Epoch:  220       11 Batch loss: 0.188350 Batch F1: 0.7586206896551724
Epoch:  220       12 Batch loss: 0.178793 Batch F1: 0.6857142857142857
Train Avg Loss  220: 0.177345

Train Avg F1  220: 0.6934299787273597

Val Avg Loss  220: 0.188775

Val Avg F1  220:  0.6889872549810439

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 221
--------------------------------------------------------------
Epoch:  221        1 Batch loss: 0.172528 Batch F1: 0.6666666666666666
Epoch:  221        2 Batch loss: 0.175684 Batch F1: 0.7234042553191491
Epoch:  221        3 Batch loss: 0.156794 Batch F1: 0.7692307692307692
Epoch:  221        4 Batch loss: 0.192374 Batch F1: 0.5365853658536586
Epoch:  221        5 Batch loss: 0.176484 Batch F1: 0.6190476190476191
Epoch:  221        6 Batch loss: 0.191756 Batch F1: 0.6666666666666666
Epoch:  221        7 Batch loss: 0.184911 Batch F1: 0.6511627906976744
Epoch:  221        8 Batch loss: 0.178495 Batch F1: 0.75
Epoch:  221        9 Batch loss: 0.184106 Batch F1: 0.7199999999999999
Epoch:  221       10 Batch loss: 0.165454 Batch F1: 0.7391304347826088
Epoch:  221       11 Batch loss: 0.181220 Batch F1: 0.7083333333333334
Epoch:  221       12 Batch loss: 0.193396 Batch F1: 0.7906976744186047
Train Avg Loss  221: 0.179434

Train Avg F1  221: 0.6950771313347291

Val Avg Loss  221: 0.187617

Val Avg F1  221:  0.6883389865351013

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 222
--------------------------------------------------------------
Epoch:  222        1 Batch loss: 0.176183 Batch F1: 0.6486486486486486
Epoch:  222        2 Batch loss: 0.191731 Batch F1: 0.6666666666666666
Epoch:  222        3 Batch loss: 0.193968 Batch F1: 0.6666666666666666
Epoch:  222        4 Batch loss: 0.178293 Batch F1: 0.5294117647058824
Epoch:  222        5 Batch loss: 0.165338 Batch F1: 0.7755102040816326
Epoch:  222        6 Batch loss: 0.154434 Batch F1: 0.7428571428571428
Epoch:  222        7 Batch loss: 0.190925 Batch F1: 0.6923076923076924
Epoch:  222        8 Batch loss: 0.153656 Batch F1: 0.7916666666666666
Epoch:  222        9 Batch loss: 0.168805 Batch F1: 0.7499999999999999
Epoch:  222       10 Batch loss: 0.154731 Batch F1: 0.8510638297872342
Epoch:  222       11 Batch loss: 0.195389 Batch F1: 0.5789473684210527
Epoch:  222       12 Batch loss: 0.169963 Batch F1: 0.8085106382978724
Train Avg Loss  222: 0.174451

Train Avg F1  222: 0.70852144075893

Val Avg Loss  222: 0.186824

Val Avg F1  222:  0.6718108420344695

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 223
--------------------------------------------------------------
Epoch:  223        1 Batch loss: 0.213256 Batch F1: 0.5500000000000002
Epoch:  223        2 Batch loss: 0.206344 Batch F1: 0.5714285714285713
Epoch:  223        3 Batch loss: 0.168382 Batch F1: 0.6486486486486486
Epoch:  223        4 Batch loss: 0.207351 Batch F1: 0.6909090909090909
Epoch:  223        5 Batch loss: 0.175481 Batch F1: 0.7083333333333334
Epoch:  223        6 Batch loss: 0.148036 Batch F1: 0.7906976744186046
Epoch:  223        7 Batch loss: 0.174935 Batch F1: 0.7692307692307693
Epoch:  223        8 Batch loss: 0.137904 Batch F1: 0.7777777777777778
Epoch:  223        9 Batch loss: 0.157561 Batch F1: 0.8
Epoch:  223       10 Batch loss: 0.163664 Batch F1: 0.7317073170731706
Epoch:  223       11 Batch loss: 0.182395 Batch F1: 0.7391304347826089
Epoch:  223       12 Batch loss: 0.176782 Batch F1: 0.7659574468085107
Train Avg Loss  223: 0.176008

Train Avg F1  223: 0.7119850887009238

Val Avg Loss  223: 0.184863

Val Avg F1  223:  0.7005812921730876

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 224
--------------------------------------------------------------
Epoch:  224        1 Batch loss: 0.178678 Batch F1: 0.6470588235294117
Epoch:  224        2 Batch loss: 0.145604 Batch F1: 0.8260869565217391
Epoch:  224        3 Batch loss: 0.142720 Batch F1: 0.8461538461538461
Epoch:  224        4 Batch loss: 0.184053 Batch F1: 0.7200000000000001
Epoch:  224        5 Batch loss: 0.154112 Batch F1: 0.7826086956521738
Epoch:  224        6 Batch loss: 0.171611 Batch F1: 0.7
Epoch:  224        7 Batch loss: 0.209071 Batch F1: 0.6399999999999999
Epoch:  224        8 Batch loss: 0.175330 Batch F1: 0.5625
Epoch:  224        9 Batch loss: 0.169743 Batch F1: 0.6666666666666666
Epoch:  224       10 Batch loss: 0.194818 Batch F1: 0.6923076923076924
Epoch:  224       11 Batch loss: 0.172456 Batch F1: 0.7142857142857143
Epoch:  224       12 Batch loss: 0.188744 Batch F1: 0.7111111111111111
Train Avg Loss  224: 0.173912

Train Avg F1  224: 0.709064958852363

Val Avg Loss  224: 0.182662

Val Avg F1  224:  0.7086447951273532

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 225
--------------------------------------------------------------
Epoch:  225        1 Batch loss: 0.170366 Batch F1: 0.7547169811320756
Epoch:  225        2 Batch loss: 0.198977 Batch F1: 0.6829268292682927
Epoch:  225        3 Batch loss: 0.162891 Batch F1: 0.7692307692307693
Epoch:  225        4 Batch loss: 0.190525 Batch F1: 0.5
Epoch:  225        5 Batch loss: 0.170504 Batch F1: 0.6829268292682926
Epoch:  225        6 Batch loss: 0.168621 Batch F1: 0.6666666666666667
Epoch:  225        7 Batch loss: 0.170682 Batch F1: 0.75
Epoch:  225        8 Batch loss: 0.170355 Batch F1: 0.7727272727272727
Epoch:  225        9 Batch loss: 0.164458 Batch F1: 0.7234042553191491
Epoch:  225       10 Batch loss: 0.150930 Batch F1: 0.8627450980392156
Epoch:  225       11 Batch loss: 0.206060 Batch F1: 0.6341463414634146
Epoch:  225       12 Batch loss: 0.175208 Batch F1: 0.7317073170731706
Train Avg Loss  225: 0.174965

Train Avg F1  225: 0.71093319668236

Val Avg Loss  225: 0.182334

Val Avg F1  225:  0.6898990941405803

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 226
--------------------------------------------------------------
Epoch:  226        1 Batch loss: 0.155976 Batch F1: 0.7441860465116279
Epoch:  226        2 Batch loss: 0.137824 Batch F1: 0.7894736842105263
Epoch:  226        3 Batch loss: 0.163713 Batch F1: 0.7755102040816326
Epoch:  226        4 Batch loss: 0.192758 Batch F1: 0.68
Epoch:  226        5 Batch loss: 0.190523 Batch F1: 0.6956521739130435
Epoch:  226        6 Batch loss: 0.148916 Batch F1: 0.7368421052631577
Epoch:  226        7 Batch loss: 0.175093 Batch F1: 0.7234042553191489
Epoch:  226        8 Batch loss: 0.189725 Batch F1: 0.7083333333333334
Epoch:  226        9 Batch loss: 0.162150 Batch F1: 0.6857142857142857
Epoch:  226       10 Batch loss: 0.203575 Batch F1: 0.6538461538461539
Epoch:  226       11 Batch loss: 0.158186 Batch F1: 0.7755102040816326
Epoch:  226       12 Batch loss: 0.193229 Batch F1: 0.5161290322580646
Train Avg Loss  226: 0.172639

Train Avg F1  226: 0.7070501232110505

Val Avg Loss  226: 0.190440

Val Avg F1  226:  0.7232428555665894

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 227
--------------------------------------------------------------
Epoch:  227        1 Batch loss: 0.160665 Batch F1: 0.76
Epoch:  227        2 Batch loss: 0.205760 Batch F1: 0.6363636363636365
Epoch:  227        3 Batch loss: 0.166412 Batch F1: 0.7924528301886792
Epoch:  227        4 Batch loss: 0.150700 Batch F1: 0.8444444444444444
Epoch:  227        5 Batch loss: 0.143384 Batch F1: 0.7999999999999999
Epoch:  227        6 Batch loss: 0.175594 Batch F1: 0.7924528301886793
Epoch:  227        7 Batch loss: 0.189092 Batch F1: 0.5714285714285715
Epoch:  227        8 Batch loss: 0.199932 Batch F1: 0.7083333333333333
Epoch:  227        9 Batch loss: 0.208875 Batch F1: 0.5909090909090909
Epoch:  227       10 Batch loss: 0.151908 Batch F1: 0.7804878048780488
Epoch:  227       11 Batch loss: 0.187278 Batch F1: 0.6190476190476191
Epoch:  227       12 Batch loss: 0.167109 Batch F1: 0.625
Train Avg Loss  227: 0.175559

Train Avg F1  227: 0.7100766800651752

Val Avg Loss  227: 0.188276

Val Avg F1  227:  0.6628278448131389

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 228
--------------------------------------------------------------
Epoch:  228        1 Batch loss: 0.228476 Batch F1: 0.5306122448979592
Epoch:  228        2 Batch loss: 0.177660 Batch F1: 0.6341463414634146
Epoch:  228        3 Batch loss: 0.190841 Batch F1: 0.6153846153846153
Epoch:  228        4 Batch loss: 0.147874 Batch F1: 0.8363636363636364
Epoch:  228        5 Batch loss: 0.142031 Batch F1: 0.8333333333333333
Epoch:  228        6 Batch loss: 0.203907 Batch F1: 0.6779661016949152
Epoch:  228        7 Batch loss: 0.177619 Batch F1: 0.6060606060606061
Epoch:  228        8 Batch loss: 0.169612 Batch F1: 0.7659574468085107
Epoch:  228        9 Batch loss: 0.180325 Batch F1: 0.6341463414634146
Epoch:  228       10 Batch loss: 0.179441 Batch F1: 0.6818181818181818
Epoch:  228       11 Batch loss: 0.174617 Batch F1: 0.6829268292682927
Epoch:  228       12 Batch loss: 0.168568 Batch F1: 0.7999999999999999
Train Avg Loss  228: 0.178414

Train Avg F1  228: 0.69155963987974

Val Avg Loss  228: 0.189618

Val Avg F1  228:  0.7149724192277384

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 229
--------------------------------------------------------------
Epoch:  229        1 Batch loss: 0.169907 Batch F1: 0.8205128205128205
Epoch:  229        2 Batch loss: 0.225699 Batch F1: 0.5909090909090908
Epoch:  229        3 Batch loss: 0.155107 Batch F1: 0.76
Epoch:  229        4 Batch loss: 0.174667 Batch F1: 0.7346938775510203
Epoch:  229        5 Batch loss: 0.154860 Batch F1: 0.8
Epoch:  229        6 Batch loss: 0.145945 Batch F1: 0.8461538461538461
Epoch:  229        7 Batch loss: 0.180776 Batch F1: 0.7
Epoch:  229        8 Batch loss: 0.180088 Batch F1: 0.6521739130434783
Epoch:  229        9 Batch loss: 0.188854 Batch F1: 0.6363636363636364
Epoch:  229       10 Batch loss: 0.155059 Batch F1: 0.7058823529411764
Epoch:  229       11 Batch loss: 0.184957 Batch F1: 0.6511627906976744
Epoch:  229       12 Batch loss: 0.180020 Batch F1: 0.717948717948718
Train Avg Loss  229: 0.174662

Train Avg F1  229: 0.7179834205101218

Val Avg Loss  229: 0.184813

Val Avg F1  229:  0.6767120181405897

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 230
--------------------------------------------------------------
Epoch:  230        1 Batch loss: 0.171684 Batch F1: 0.6842105263157895
Epoch:  230        2 Batch loss: 0.160104 Batch F1: 0.7727272727272727
Epoch:  230        3 Batch loss: 0.177915 Batch F1: 0.6666666666666666
Epoch:  230        4 Batch loss: 0.183389 Batch F1: 0.6938775510204083
Epoch:  230        5 Batch loss: 0.151956 Batch F1: 0.6857142857142857
Epoch:  230        6 Batch loss: 0.199484 Batch F1: 0.6363636363636365
Epoch:  230        7 Batch loss: 0.203545 Batch F1: 0.7169811320754716
Epoch:  230        8 Batch loss: 0.161076 Batch F1: 0.7916666666666666
Epoch:  230        9 Batch loss: 0.153679 Batch F1: 0.8148148148148148
Epoch:  230       10 Batch loss: 0.168273 Batch F1: 0.7317073170731706
Epoch:  230       11 Batch loss: 0.180891 Batch F1: 0.7169811320754716
Epoch:  230       12 Batch loss: 0.168298 Batch F1: 0.6875
Train Avg Loss  230: 0.173358

Train Avg F1  230: 0.7166009167928046

Val Avg Loss  230: 0.184989

Val Avg F1  230:  0.7059996689837803

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 231
--------------------------------------------------------------
Epoch:  231        1 Batch loss: 0.155378 Batch F1: 0.7368421052631577
Epoch:  231        2 Batch loss: 0.158170 Batch F1: 0.782608695652174
Epoch:  231        3 Batch loss: 0.176279 Batch F1: 0.6818181818181819
Epoch:  231        4 Batch loss: 0.181627 Batch F1: 0.6341463414634148
Epoch:  231        5 Batch loss: 0.140491 Batch F1: 0.8333333333333334
Epoch:  231        6 Batch loss: 0.164272 Batch F1: 0.75
Epoch:  231        7 Batch loss: 0.191640 Batch F1: 0.6666666666666666
Epoch:  231        8 Batch loss: 0.185978 Batch F1: 0.7199999999999999
Epoch:  231        9 Batch loss: 0.170924 Batch F1: 0.6956521739130435
Epoch:  231       10 Batch loss: 0.224371 Batch F1: 0.5217391304347826
Epoch:  231       11 Batch loss: 0.167469 Batch F1: 0.7346938775510204
Epoch:  231       12 Batch loss: 0.170879 Batch F1: 0.7058823529411765
Train Avg Loss  231: 0.173957

Train Avg F1  231: 0.705281904919746

Val Avg Loss  231: 0.185757

Val Avg F1  231:  0.6956170367778243

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 232
--------------------------------------------------------------
Epoch:  232        1 Batch loss: 0.214689 Batch F1: 0.5652173913043478
Epoch:  232        2 Batch loss: 0.176716 Batch F1: 0.6956521739130435
Epoch:  232        3 Batch loss: 0.152507 Batch F1: 0.7692307692307692
Epoch:  232        4 Batch loss: 0.173541 Batch F1: 0.7058823529411765
Epoch:  232        5 Batch loss: 0.180072 Batch F1: 0.7142857142857143
Epoch:  232        6 Batch loss: 0.158146 Batch F1: 0.7027027027027027
Epoch:  232        7 Batch loss: 0.160478 Batch F1: 0.8076923076923077
Epoch:  232        8 Batch loss: 0.168819 Batch F1: 0.723404255319149
Epoch:  232        9 Batch loss: 0.158666 Batch F1: 0.8163265306122449
Epoch:  232       10 Batch loss: 0.173591 Batch F1: 0.7555555555555555
Epoch:  232       11 Batch loss: 0.194924 Batch F1: 0.5500000000000002
Epoch:  232       12 Batch loss: 0.151465 Batch F1: 0.7804878048780488
Train Avg Loss  232: 0.171968

Train Avg F1  232: 0.7155364632029216

Val Avg Loss  232: 0.185874

Val Avg F1  232:  0.6755071059431526

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 233
--------------------------------------------------------------
Epoch:  233        1 Batch loss: 0.152650 Batch F1: 0.782608695652174
Epoch:  233        2 Batch loss: 0.166363 Batch F1: 0.8275862068965518
Epoch:  233        3 Batch loss: 0.178552 Batch F1: 0.6153846153846154
Epoch:  233        4 Batch loss: 0.141292 Batch F1: 0.7999999999999999
Epoch:  233        5 Batch loss: 0.175184 Batch F1: 0.631578947368421
Epoch:  233        6 Batch loss: 0.176270 Batch F1: 0.6500000000000001
Epoch:  233        7 Batch loss: 0.185890 Batch F1: 0.6829268292682926
Epoch:  233        8 Batch loss: 0.193201 Batch F1: 0.6
Epoch:  233        9 Batch loss: 0.156236 Batch F1: 0.7555555555555555
Epoch:  233       10 Batch loss: 0.183419 Batch F1: 0.6666666666666666
Epoch:  233       11 Batch loss: 0.198721 Batch F1: 0.6666666666666667
Epoch:  233       12 Batch loss: 0.167434 Batch F1: 0.7906976744186046
Train Avg Loss  233: 0.172934

Train Avg F1  233: 0.7058059881564623

Val Avg Loss  233: 0.184586

Val Avg F1  233:  0.6662018047579984

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 234
--------------------------------------------------------------
Epoch:  234        1 Batch loss: 0.193410 Batch F1: 0.6521739130434783
Epoch:  234        2 Batch loss: 0.179520 Batch F1: 0.7346938775510204
Epoch:  234        3 Batch loss: 0.144476 Batch F1: 0.8260869565217391
Epoch:  234        4 Batch loss: 0.199567 Batch F1: 0.6666666666666666
Epoch:  234        5 Batch loss: 0.143320 Batch F1: 0.8235294117647058
Epoch:  234        6 Batch loss: 0.192692 Batch F1: 0.5789473684210527
Epoch:  234        7 Batch loss: 0.156099 Batch F1: 0.782608695652174
Epoch:  234        8 Batch loss: 0.159363 Batch F1: 0.8000000000000002
Epoch:  234        9 Batch loss: 0.199616 Batch F1: 0.5777777777777778
Epoch:  234       10 Batch loss: 0.176248 Batch F1: 0.6666666666666666
Epoch:  234       11 Batch loss: 0.142107 Batch F1: 0.7058823529411764
Epoch:  234       12 Batch loss: 0.159142 Batch F1: 0.7777777777777778
Train Avg Loss  234: 0.170463

Train Avg F1  234: 0.7160676220653529

Val Avg Loss  234: 0.186373

Val Avg F1  234:  0.6640912626393569

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 235
--------------------------------------------------------------
Epoch:  235        1 Batch loss: 0.136028 Batch F1: 0.8571428571428571
Epoch:  235        2 Batch loss: 0.176612 Batch F1: 0.711111111111111
Epoch:  235        3 Batch loss: 0.159364 Batch F1: 0.7727272727272727
Epoch:  235        4 Batch loss: 0.207985 Batch F1: 0.5581395348837208
Epoch:  235        5 Batch loss: 0.187174 Batch F1: 0.6792452830188679
Epoch:  235        6 Batch loss: 0.177092 Batch F1: 0.8076923076923076
Epoch:  235        7 Batch loss: 0.133781 Batch F1: 0.8181818181818182
Epoch:  235        8 Batch loss: 0.186190 Batch F1: 0.6
Epoch:  235        9 Batch loss: 0.183826 Batch F1: 0.5945945945945945
Epoch:  235       10 Batch loss: 0.159579 Batch F1: 0.7555555555555555
Epoch:  235       11 Batch loss: 0.179570 Batch F1: 0.6666666666666666
Epoch:  235       12 Batch loss: 0.172408 Batch F1: 0.717948717948718
Train Avg Loss  235: 0.171634

Train Avg F1  235: 0.7115838099602908

Val Avg Loss  235: 0.183765

Val Avg F1  235:  0.6920797720797721

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 236
--------------------------------------------------------------
Epoch:  236        1 Batch loss: 0.171828 Batch F1: 0.6285714285714286
Epoch:  236        2 Batch loss: 0.183697 Batch F1: 0.7058823529411765
Epoch:  236        3 Batch loss: 0.161956 Batch F1: 0.717948717948718
Epoch:  236        4 Batch loss: 0.178420 Batch F1: 0.7636363636363638
Epoch:  236        5 Batch loss: 0.204938 Batch F1: 0.6511627906976744
Epoch:  236        6 Batch loss: 0.132864 Batch F1: 0.8421052631578947
Epoch:  236        7 Batch loss: 0.144098 Batch F1: 0.7916666666666666
Epoch:  236        8 Batch loss: 0.171514 Batch F1: 0.6842105263157895
Epoch:  236        9 Batch loss: 0.172234 Batch F1: 0.7450980392156864
Epoch:  236       10 Batch loss: 0.179638 Batch F1: 0.6666666666666666
Epoch:  236       11 Batch loss: 0.178218 Batch F1: 0.76
Epoch:  236       12 Batch loss: 0.170761 Batch F1: 0.7441860465116279
Train Avg Loss  236: 0.170847

Train Avg F1  236: 0.7250945718608078

Val Avg Loss  236: 0.183561

Val Avg F1  236:  0.6898846495119788

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 237
--------------------------------------------------------------
Epoch:  237        1 Batch loss: 0.141313 Batch F1: 0.8163265306122449
Epoch:  237        2 Batch loss: 0.195084 Batch F1: 0.5714285714285713
Epoch:  237        3 Batch loss: 0.189036 Batch F1: 0.7741935483870969
Epoch:  237        4 Batch loss: 0.144933 Batch F1: 0.8
Epoch:  237        5 Batch loss: 0.178012 Batch F1: 0.7924528301886793
Epoch:  237        6 Batch loss: 0.180378 Batch F1: 0.7272727272727272
Epoch:  237        7 Batch loss: 0.176319 Batch F1: 0.65
Epoch:  237        8 Batch loss: 0.159875 Batch F1: 0.8
Epoch:  237        9 Batch loss: 0.194440 Batch F1: 0.5909090909090909
Epoch:  237       10 Batch loss: 0.166392 Batch F1: 0.4615384615384615
Epoch:  237       11 Batch loss: 0.198886 Batch F1: 0.6086956521739131
Epoch:  237       12 Batch loss: 0.132261 Batch F1: 0.7999999999999999
Train Avg Loss  237: 0.171411

Train Avg F1  237: 0.6994014510425655

Val Avg Loss  237: 0.183708

Val Avg F1  237:  0.6740311276025561

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 238
--------------------------------------------------------------
Epoch:  238        1 Batch loss: 0.164828 Batch F1: 0.65
Epoch:  238        2 Batch loss: 0.204321 Batch F1: 0.5853658536585366
Epoch:  238        3 Batch loss: 0.164603 Batch F1: 0.6666666666666666
Epoch:  238        4 Batch loss: 0.162111 Batch F1: 0.7317073170731706
Epoch:  238        5 Batch loss: 0.178522 Batch F1: 0.6818181818181819
Epoch:  238        6 Batch loss: 0.179698 Batch F1: 0.7547169811320754
Epoch:  238        7 Batch loss: 0.169214 Batch F1: 0.7391304347826088
Epoch:  238        8 Batch loss: 0.167679 Batch F1: 0.7391304347826085
Epoch:  238        9 Batch loss: 0.171102 Batch F1: 0.6666666666666666
Epoch:  238       10 Batch loss: 0.148960 Batch F1: 0.7826086956521738
Epoch:  238       11 Batch loss: 0.167636 Batch F1: 0.7924528301886792
Epoch:  238       12 Batch loss: 0.177778 Batch F1: 0.7727272727272727
Train Avg Loss  238: 0.171371

Train Avg F1  238: 0.7135826112623868

Val Avg Loss  238: 0.184151

Val Avg F1  238:  0.6891785198928055

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 239
--------------------------------------------------------------
Epoch:  239        1 Batch loss: 0.176802 Batch F1: 0.7659574468085107
Epoch:  239        2 Batch loss: 0.166971 Batch F1: 0.75
Epoch:  239        3 Batch loss: 0.185452 Batch F1: 0.6808510638297872
Epoch:  239        4 Batch loss: 0.148600 Batch F1: 0.6666666666666667
Epoch:  239        5 Batch loss: 0.189536 Batch F1: 0.6363636363636365
Epoch:  239        6 Batch loss: 0.190964 Batch F1: 0.6808510638297872
Epoch:  239        7 Batch loss: 0.177792 Batch F1: 0.6818181818181818
Epoch:  239        8 Batch loss: 0.164241 Batch F1: 0.7234042553191491
Epoch:  239        9 Batch loss: 0.153208 Batch F1: 0.8399999999999999
Epoch:  239       10 Batch loss: 0.150568 Batch F1: 0.8163265306122449
Epoch:  239       11 Batch loss: 0.191538 Batch F1: 0.5853658536585366
Epoch:  239       12 Batch loss: 0.159020 Batch F1: 0.7647058823529411
Train Avg Loss  239: 0.171224

Train Avg F1  239: 0.7160258817716202

Val Avg Loss  239: 0.183888

Val Avg F1  239:  0.7203555384417918

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 240
--------------------------------------------------------------
Epoch:  240        1 Batch loss: 0.149210 Batch F1: 0.7826086956521738
Epoch:  240        2 Batch loss: 0.193526 Batch F1: 0.68
Epoch:  240        3 Batch loss: 0.138213 Batch F1: 0.8333333333333334
Epoch:  240        4 Batch loss: 0.169271 Batch F1: 0.8148148148148148
Epoch:  240        5 Batch loss: 0.161051 Batch F1: 0.7727272727272727
Epoch:  240        6 Batch loss: 0.159942 Batch F1: 0.8163265306122449
Epoch:  240        7 Batch loss: 0.197713 Batch F1: 0.6666666666666666
Epoch:  240        8 Batch loss: 0.163170 Batch F1: 0.6486486486486486
Epoch:  240        9 Batch loss: 0.178010 Batch F1: 0.6341463414634146
Epoch:  240       10 Batch loss: 0.172391 Batch F1: 0.5333333333333333
Epoch:  240       11 Batch loss: 0.194953 Batch F1: 0.5641025641025642
Epoch:  240       12 Batch loss: 0.164695 Batch F1: 0.8181818181818182
Train Avg Loss  240: 0.170179

Train Avg F1  240: 0.713740834961357

Val Avg Loss  240: 0.183631

Val Avg F1  240:  0.6575834879406307

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 241
--------------------------------------------------------------
Epoch:  241        1 Batch loss: 0.180349 Batch F1: 0.5945945945945946
Epoch:  241        2 Batch loss: 0.152030 Batch F1: 0.7924528301886793
Epoch:  241        3 Batch loss: 0.153272 Batch F1: 0.782608695652174
Epoch:  241        4 Batch loss: 0.162104 Batch F1: 0.75
Epoch:  241        5 Batch loss: 0.180744 Batch F1: 0.711111111111111
Epoch:  241        6 Batch loss: 0.191893 Batch F1: 0.6249999999999999
Epoch:  241        7 Batch loss: 0.172642 Batch F1: 0.7547169811320755
Epoch:  241        8 Batch loss: 0.162272 Batch F1: 0.7826086956521738
Epoch:  241        9 Batch loss: 0.168322 Batch F1: 0.6857142857142857
Epoch:  241       10 Batch loss: 0.175178 Batch F1: 0.72
Epoch:  241       11 Batch loss: 0.157678 Batch F1: 0.7317073170731707
Epoch:  241       12 Batch loss: 0.180163 Batch F1: 0.5806451612903225
Train Avg Loss  241: 0.169721

Train Avg F1  241: 0.7092633060340489

Val Avg Loss  241: 0.183500

Val Avg F1  241:  0.6772856934006759

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 242
--------------------------------------------------------------
Epoch:  242        1 Batch loss: 0.151440 Batch F1: 0.5925925925925926
Epoch:  242        2 Batch loss: 0.187297 Batch F1: 0.6521739130434783
Epoch:  242        3 Batch loss: 0.134676 Batch F1: 0.8421052631578948
Epoch:  242        4 Batch loss: 0.163516 Batch F1: 0.8163265306122449
Epoch:  242        5 Batch loss: 0.145632 Batch F1: 0.7916666666666667
Epoch:  242        6 Batch loss: 0.170588 Batch F1: 0.6666666666666666
Epoch:  242        7 Batch loss: 0.171311 Batch F1: 0.7058823529411765
Epoch:  242        8 Batch loss: 0.192621 Batch F1: 0.6415094339622641
Epoch:  242        9 Batch loss: 0.198471 Batch F1: 0.588235294117647
Epoch:  242       10 Batch loss: 0.191951 Batch F1: 0.6923076923076923
Epoch:  242       11 Batch loss: 0.171179 Batch F1: 0.723404255319149
Epoch:  242       12 Batch loss: 0.192257 Batch F1: 0.6111111111111112
Train Avg Loss  242: 0.172578

Train Avg F1  242: 0.6936651477082155

Val Avg Loss  242: 0.185493

Val Avg F1  242:  0.6784677164588953

Optimal Val loss (Epoch 115): 0.1816314496099949

Epoch 243
--------------------------------------------------------------
Epoch:  243        1 Batch loss: 0.157408 Batch F1: 0.8363636363636363
Epoch:  243        2 Batch loss: 0.162418 Batch F1: 0.7027027027027026
Epoch:  243        3 Batch loss: 0.142466 Batch F1: 0.8727272727272727
Epoch:  243        4 Batch loss: 0.190001 Batch F1: 0.6222222222222223
Epoch:  243        5 Batch loss: 0.154183 Batch F1: 0.84375
Epoch:  243        6 Batch loss: 0.201664 Batch F1: 0.6511627906976745
Epoch:  243        7 Batch loss: 0.195152 Batch F1: 0.6341463414634146
Epoch:  243        8 Batch loss: 0.147385 Batch F1: 0.761904761904762
Epoch:  243        9 Batch loss: 0.210766 Batch F1: 0.4864864864864865
Epoch:  243       10 Batch loss: 0.189221 Batch F1: 0.6818181818181819
Epoch:  243       11 Batch loss: 0.160819 Batch F1: 0.717948717948718
Epoch:  243       12 Batch loss: 0.163446 Batch F1: 0.6857142857142857
Train Avg Loss  243: 0.172911

Train Avg F1  243: 0.708078950004113

Val Avg Loss  243: 0.181249

Val Avg F1  243:  0.698806671741748

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 244
--------------------------------------------------------------
Epoch:  244        1 Batch loss: 0.172713 Batch F1: 0.6976744186046512
Epoch:  244        2 Batch loss: 0.168001 Batch F1: 0.7
Epoch:  244        3 Batch loss: 0.175704 Batch F1: 0.7586206896551724
Epoch:  244        4 Batch loss: 0.184257 Batch F1: 0.6521739130434783
Epoch:  244        5 Batch loss: 0.155673 Batch F1: 0.8148148148148148
Epoch:  244        6 Batch loss: 0.182682 Batch F1: 0.6666666666666666
Epoch:  244        7 Batch loss: 0.177811 Batch F1: 0.7272727272727272
Epoch:  244        8 Batch loss: 0.203998 Batch F1: 0.6382978723404256
Epoch:  244        9 Batch loss: 0.178063 Batch F1: 0.711111111111111
Epoch:  244       10 Batch loss: 0.146927 Batch F1: 0.8749999999999999
Epoch:  244       11 Batch loss: 0.178668 Batch F1: 0.65
Epoch:  244       12 Batch loss: 0.153486 Batch F1: 0.7142857142857143
Train Avg Loss  244: 0.173165

Train Avg F1  244: 0.7171598273162302

Val Avg Loss  244: 0.185045

Val Avg F1  244:  0.6712116327229529

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 245
--------------------------------------------------------------
Epoch:  245        1 Batch loss: 0.194258 Batch F1: 0.5909090909090909
Epoch:  245        2 Batch loss: 0.188397 Batch F1: 0.7234042553191491
Epoch:  245        3 Batch loss: 0.165466 Batch F1: 0.6666666666666666
Epoch:  245        4 Batch loss: 0.163318 Batch F1: 0.7272727272727272
Epoch:  245        5 Batch loss: 0.179914 Batch F1: 0.6666666666666666
Epoch:  245        6 Batch loss: 0.160989 Batch F1: 0.8627450980392156
Epoch:  245        7 Batch loss: 0.175013 Batch F1: 0.6363636363636365
Epoch:  245        8 Batch loss: 0.159691 Batch F1: 0.7727272727272727
Epoch:  245        9 Batch loss: 0.162150 Batch F1: 0.6451612903225806
Epoch:  245       10 Batch loss: 0.191740 Batch F1: 0.7272727272727273
Epoch:  245       11 Batch loss: 0.163617 Batch F1: 0.7391304347826088
Epoch:  245       12 Batch loss: 0.180606 Batch F1: 0.7272727272727272
Train Avg Loss  245: 0.173763

Train Avg F1  245: 0.7071327161345891

Val Avg Loss  245: 0.186874

Val Avg F1  245:  0.7251102056270227

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 246
--------------------------------------------------------------
Epoch:  246        1 Batch loss: 0.178084 Batch F1: 0.7692307692307692
Epoch:  246        2 Batch loss: 0.150229 Batch F1: 0.8
Epoch:  246        3 Batch loss: 0.174798 Batch F1: 0.7272727272727272
Epoch:  246        4 Batch loss: 0.138080 Batch F1: 0.8333333333333334
Epoch:  246        5 Batch loss: 0.183325 Batch F1: 0.6818181818181819
Epoch:  246        6 Batch loss: 0.176393 Batch F1: 0.6666666666666666
Epoch:  246        7 Batch loss: 0.182553 Batch F1: 0.6363636363636364
Epoch:  246        8 Batch loss: 0.191261 Batch F1: 0.6363636363636365
Epoch:  246        9 Batch loss: 0.185931 Batch F1: 0.7083333333333333
Epoch:  246       10 Batch loss: 0.137093 Batch F1: 0.7999999999999999
Epoch:  246       11 Batch loss: 0.198603 Batch F1: 0.6190476190476191
Epoch:  246       12 Batch loss: 0.188743 Batch F1: 0.7027027027027026
Train Avg Loss  246: 0.173758

Train Avg F1  246: 0.7150943838443838

Val Avg Loss  246: 0.181760

Val Avg F1  246:  0.6738535196687371

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 247
--------------------------------------------------------------
Epoch:  247        1 Batch loss: 0.159679 Batch F1: 0.7777777777777777
Epoch:  247        2 Batch loss: 0.182999 Batch F1: 0.7346938775510203
Epoch:  247        3 Batch loss: 0.156780 Batch F1: 0.7843137254901961
Epoch:  247        4 Batch loss: 0.152513 Batch F1: 0.7692307692307692
Epoch:  247        5 Batch loss: 0.168208 Batch F1: 0.8085106382978724
Epoch:  247        6 Batch loss: 0.208425 Batch F1: 0.5263157894736842
Epoch:  247        7 Batch loss: 0.186827 Batch F1: 0.6511627906976744
Epoch:  247        8 Batch loss: 0.157220 Batch F1: 0.7441860465116279
Epoch:  247        9 Batch loss: 0.171830 Batch F1: 0.8000000000000002
Epoch:  247       10 Batch loss: 0.160949 Batch F1: 0.5882352941176471
Epoch:  247       11 Batch loss: 0.180449 Batch F1: 0.5714285714285714
Epoch:  247       12 Batch loss: 0.170463 Batch F1: 0.7727272727272727
Train Avg Loss  247: 0.171362

Train Avg F1  247: 0.7107152127753427

Val Avg Loss  247: 0.181633

Val Avg F1  247:  0.676665773251139

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 248
--------------------------------------------------------------
Epoch:  248        1 Batch loss: 0.165852 Batch F1: 0.6111111111111112
Epoch:  248        2 Batch loss: 0.174080 Batch F1: 0.7346938775510203
Epoch:  248        3 Batch loss: 0.185647 Batch F1: 0.6808510638297872
Epoch:  248        4 Batch loss: 0.185571 Batch F1: 0.6829268292682927
Epoch:  248        5 Batch loss: 0.166842 Batch F1: 0.7659574468085107
Epoch:  248        6 Batch loss: 0.136825 Batch F1: 0.8333333333333334
Epoch:  248        7 Batch loss: 0.175953 Batch F1: 0.6842105263157895
Epoch:  248        8 Batch loss: 0.181196 Batch F1: 0.6923076923076923
Epoch:  248        9 Batch loss: 0.202981 Batch F1: 0.64
Epoch:  248       10 Batch loss: 0.170183 Batch F1: 0.7272727272727272
Epoch:  248       11 Batch loss: 0.172022 Batch F1: 0.76
Epoch:  248       12 Batch loss: 0.153231 Batch F1: 0.7777777777777778
Train Avg Loss  248: 0.172532

Train Avg F1  248: 0.7158701987980036

Val Avg Loss  248: 0.183907

Val Avg F1  248:  0.6732231838447418

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 249
--------------------------------------------------------------
Epoch:  249        1 Batch loss: 0.156714 Batch F1: 0.7555555555555556
Epoch:  249        2 Batch loss: 0.175424 Batch F1: 0.6829268292682927
Epoch:  249        3 Batch loss: 0.149083 Batch F1: 0.7391304347826088
Epoch:  249        4 Batch loss: 0.158311 Batch F1: 0.7555555555555556
Epoch:  249        5 Batch loss: 0.191326 Batch F1: 0.619047619047619
Epoch:  249        6 Batch loss: 0.164075 Batch F1: 0.7659574468085107
Epoch:  249        7 Batch loss: 0.172628 Batch F1: 0.7727272727272727
Epoch:  249        8 Batch loss: 0.177016 Batch F1: 0.7755102040816326
Epoch:  249        9 Batch loss: 0.159447 Batch F1: 0.7567567567567567
Epoch:  249       10 Batch loss: 0.181744 Batch F1: 0.5454545454545455
Epoch:  249       11 Batch loss: 0.179472 Batch F1: 0.7777777777777778
Epoch:  249       12 Batch loss: 0.201894 Batch F1: 0.7083333333333334
Train Avg Loss  249: 0.172261

Train Avg F1  249: 0.7212277775957885

Val Avg Loss  249: 0.185318

Val Avg F1  249:  0.6928309785452643

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 250
--------------------------------------------------------------
Epoch:  250        1 Batch loss: 0.157309 Batch F1: 0.7804878048780488
Epoch:  250        2 Batch loss: 0.177822 Batch F1: 0.7540983606557378
Epoch:  250        3 Batch loss: 0.165091 Batch F1: 0.6976744186046512
Epoch:  250        4 Batch loss: 0.163152 Batch F1: 0.7441860465116279
Epoch:  250        5 Batch loss: 0.154696 Batch F1: 0.761904761904762
Epoch:  250        6 Batch loss: 0.164930 Batch F1: 0.7234042553191491
Epoch:  250        7 Batch loss: 0.200823 Batch F1: 0.6274509803921569
Epoch:  250        8 Batch loss: 0.153137 Batch F1: 0.7999999999999999
Epoch:  250        9 Batch loss: 0.181690 Batch F1: 0.6341463414634146
Epoch:  250       10 Batch loss: 0.198689 Batch F1: 0.48648648648648646
Epoch:  250       11 Batch loss: 0.199850 Batch F1: 0.6538461538461537
Epoch:  250       12 Batch loss: 0.193717 Batch F1: 0.625
Train Avg Loss  250: 0.175909

Train Avg F1  250: 0.6907238008385157

Val Avg Loss  250: 0.186268

Val Avg F1  250:  0.677590753187018

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 251
--------------------------------------------------------------
Epoch:  251        1 Batch loss: 0.163241 Batch F1: 0.7272727272727272
Epoch:  251        2 Batch loss: 0.192145 Batch F1: 0.6
Epoch:  251        3 Batch loss: 0.194999 Batch F1: 0.5714285714285715
Epoch:  251        4 Batch loss: 0.186385 Batch F1: 0.7547169811320754
Epoch:  251        5 Batch loss: 0.170431 Batch F1: 0.7000000000000001
Epoch:  251        6 Batch loss: 0.155313 Batch F1: 0.7999999999999999
Epoch:  251        7 Batch loss: 0.196640 Batch F1: 0.7037037037037038
Epoch:  251        8 Batch loss: 0.159609 Batch F1: 0.7727272727272727
Epoch:  251        9 Batch loss: 0.179743 Batch F1: 0.6956521739130435
Epoch:  251       10 Batch loss: 0.159843 Batch F1: 0.7659574468085107
Epoch:  251       11 Batch loss: 0.202055 Batch F1: 0.7234042553191489
Epoch:  251       12 Batch loss: 0.128481 Batch F1: 0.8108108108108107
Train Avg Loss  251: 0.174074

Train Avg F1  251: 0.7188061619263221

Val Avg Loss  251: 0.186950

Val Avg F1  251:  0.6703271562571493

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 252
--------------------------------------------------------------
Epoch:  252        1 Batch loss: 0.172135 Batch F1: 0.7111111111111111
Epoch:  252        2 Batch loss: 0.197058 Batch F1: 0.5641025641025642
Epoch:  252        3 Batch loss: 0.144846 Batch F1: 0.8
Epoch:  252        4 Batch loss: 0.153641 Batch F1: 0.7999999999999999
Epoch:  252        5 Batch loss: 0.176758 Batch F1: 0.6829268292682926
Epoch:  252        6 Batch loss: 0.151038 Batch F1: 0.7499999999999999
Epoch:  252        7 Batch loss: 0.180946 Batch F1: 0.5789473684210527
Epoch:  252        8 Batch loss: 0.182522 Batch F1: 0.7083333333333334
Epoch:  252        9 Batch loss: 0.186285 Batch F1: 0.6
Epoch:  252       10 Batch loss: 0.164611 Batch F1: 0.7999999999999999
Epoch:  252       11 Batch loss: 0.205875 Batch F1: 0.6086956521739131
Epoch:  252       12 Batch loss: 0.180520 Batch F1: 0.8214285714285714
Train Avg Loss  252: 0.174686

Train Avg F1  252: 0.7021287858199031

Val Avg Loss  252: 0.195228

Val Avg F1  252:  0.7804819508448539

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 253
--------------------------------------------------------------
Epoch:  253        1 Batch loss: 0.167749 Batch F1: 0.8275862068965517
Epoch:  253        2 Batch loss: 0.242564 Batch F1: 0.5652173913043479
Epoch:  253        3 Batch loss: 0.168812 Batch F1: 0.6956521739130435
Epoch:  253        4 Batch loss: 0.166866 Batch F1: 0.761904761904762
Epoch:  253        5 Batch loss: 0.145067 Batch F1: 0.8095238095238095
Epoch:  253        6 Batch loss: 0.169100 Batch F1: 0.6000000000000001
Epoch:  253        7 Batch loss: 0.189740 Batch F1: 0.7083333333333333
Epoch:  253        8 Batch loss: 0.200794 Batch F1: 0.6086956521739131
Epoch:  253        9 Batch loss: 0.180739 Batch F1: 0.6666666666666667
Epoch:  253       10 Batch loss: 0.205749 Batch F1: 0.6521739130434783
Epoch:  253       11 Batch loss: 0.198523 Batch F1: 0.72
Epoch:  253       12 Batch loss: 0.159658 Batch F1: 0.7804878048780488
Train Avg Loss  253: 0.182947

Train Avg F1  253: 0.6996868094698296

Val Avg Loss  253: 0.191947

Val Avg F1  253:  0.6550925925925927

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 254
--------------------------------------------------------------
Epoch:  254        1 Batch loss: 0.198824 Batch F1: 0.68
Epoch:  254        2 Batch loss: 0.192100 Batch F1: 0.5128205128205129
Epoch:  254        3 Batch loss: 0.183387 Batch F1: 0.7586206896551724
Epoch:  254        4 Batch loss: 0.190510 Batch F1: 0.6666666666666666
Epoch:  254        5 Batch loss: 0.172756 Batch F1: 0.6666666666666667
Epoch:  254        6 Batch loss: 0.159052 Batch F1: 0.6842105263157895
Epoch:  254        7 Batch loss: 0.179576 Batch F1: 0.7346938775510204
Epoch:  254        8 Batch loss: 0.197137 Batch F1: 0.5365853658536585
Epoch:  254        9 Batch loss: 0.175938 Batch F1: 0.7916666666666666
Epoch:  254       10 Batch loss: 0.157976 Batch F1: 0.7727272727272727
Epoch:  254       11 Batch loss: 0.170024 Batch F1: 0.7441860465116279
Epoch:  254       12 Batch loss: 0.176930 Batch F1: 0.7804878048780488
Train Avg Loss  254: 0.179518

Train Avg F1  254: 0.694111008026092

Val Avg Loss  254: 0.182825

Val Avg F1  254:  0.6773765698866082

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 255
--------------------------------------------------------------
Epoch:  255        1 Batch loss: 0.149222 Batch F1: 0.6666666666666665
Epoch:  255        2 Batch loss: 0.157311 Batch F1: 0.8
Epoch:  255        3 Batch loss: 0.160017 Batch F1: 0.8421052631578947
Epoch:  255        4 Batch loss: 0.195501 Batch F1: 0.6808510638297872
Epoch:  255        5 Batch loss: 0.203579 Batch F1: 0.6923076923076923
Epoch:  255        6 Batch loss: 0.175573 Batch F1: 0.7391304347826085
Epoch:  255        7 Batch loss: 0.181071 Batch F1: 0.6956521739130435
Epoch:  255        8 Batch loss: 0.181777 Batch F1: 0.7777777777777779
Epoch:  255        9 Batch loss: 0.182135 Batch F1: 0.631578947368421
Epoch:  255       10 Batch loss: 0.172487 Batch F1: 0.6666666666666666
Epoch:  255       11 Batch loss: 0.174673 Batch F1: 0.6666666666666667
Epoch:  255       12 Batch loss: 0.136028 Batch F1: 0.8125000000000001
Train Avg Loss  255: 0.172448

Train Avg F1  255: 0.7226586127614355

Val Avg Loss  255: 0.186317

Val Avg F1  255:  0.6763888888888888

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 256
--------------------------------------------------------------
Epoch:  256        1 Batch loss: 0.194657 Batch F1: 0.6382978723404256
Epoch:  256        2 Batch loss: 0.223230 Batch F1: 0.6296296296296297
Epoch:  256        3 Batch loss: 0.156549 Batch F1: 0.7441860465116279
Epoch:  256        4 Batch loss: 0.147558 Batch F1: 0.8333333333333333
Epoch:  256        5 Batch loss: 0.177740 Batch F1: 0.7083333333333333
Epoch:  256        6 Batch loss: 0.164721 Batch F1: 0.6666666666666666
Epoch:  256        7 Batch loss: 0.191223 Batch F1: 0.6511627906976744
Epoch:  256        8 Batch loss: 0.147220 Batch F1: 0.8260869565217391
Epoch:  256        9 Batch loss: 0.162405 Batch F1: 0.7391304347826088
Epoch:  256       10 Batch loss: 0.182350 Batch F1: 0.6153846153846153
Epoch:  256       11 Batch loss: 0.160204 Batch F1: 0.7058823529411765
Epoch:  256       12 Batch loss: 0.154227 Batch F1: 0.7777777777777777
Train Avg Loss  256: 0.171840

Train Avg F1  256: 0.7113226508267173

Val Avg Loss  256: 0.185020

Val Avg F1  256:  0.6741943685481776

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 257
--------------------------------------------------------------
Epoch:  257        1 Batch loss: 0.148208 Batch F1: 0.8181818181818182
Epoch:  257        2 Batch loss: 0.183561 Batch F1: 0.5294117647058824
Epoch:  257        3 Batch loss: 0.176308 Batch F1: 0.6500000000000001
Epoch:  257        4 Batch loss: 0.181979 Batch F1: 0.6808510638297872
Epoch:  257        5 Batch loss: 0.188557 Batch F1: 0.6956521739130435
Epoch:  257        6 Batch loss: 0.221600 Batch F1: 0.5333333333333332
Epoch:  257        7 Batch loss: 0.143403 Batch F1: 0.8333333333333334
Epoch:  257        8 Batch loss: 0.172801 Batch F1: 0.7755102040816326
Epoch:  257        9 Batch loss: 0.151024 Batch F1: 0.761904761904762
Epoch:  257       10 Batch loss: 0.161178 Batch F1: 0.7843137254901961
Epoch:  257       11 Batch loss: 0.149912 Batch F1: 0.8095238095238095
Epoch:  257       12 Batch loss: 0.195303 Batch F1: 0.65
Train Avg Loss  257: 0.172819

Train Avg F1  257: 0.7101679990247997

Val Avg Loss  257: 0.184859

Val Avg F1  257:  0.694620624853183

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 258
--------------------------------------------------------------
Epoch:  258        1 Batch loss: 0.206429 Batch F1: 0.7000000000000001
Epoch:  258        2 Batch loss: 0.161059 Batch F1: 0.7027027027027027
Epoch:  258        3 Batch loss: 0.164989 Batch F1: 0.7391304347826089
Epoch:  258        4 Batch loss: 0.151337 Batch F1: 0.7368421052631577
Epoch:  258        5 Batch loss: 0.183010 Batch F1: 0.6938775510204083
Epoch:  258        6 Batch loss: 0.182714 Batch F1: 0.5454545454545455
Epoch:  258        7 Batch loss: 0.147731 Batch F1: 0.8771929824561403
Epoch:  258        8 Batch loss: 0.166477 Batch F1: 0.6829268292682926
Epoch:  258        9 Batch loss: 0.181362 Batch F1: 0.6808510638297872
Epoch:  258       10 Batch loss: 0.150651 Batch F1: 0.7368421052631577
Epoch:  258       11 Batch loss: 0.175754 Batch F1: 0.8070175438596492
Epoch:  258       12 Batch loss: 0.178977 Batch F1: 0.6
Train Avg Loss  258: 0.170874

Train Avg F1  258: 0.7085698219917043

Val Avg Loss  258: 0.184364

Val Avg F1  258:  0.6622739018087855

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 259
--------------------------------------------------------------
Epoch:  259        1 Batch loss: 0.173551 Batch F1: 0.6829268292682927
Epoch:  259        2 Batch loss: 0.210403 Batch F1: 0.6666666666666666
Epoch:  259        3 Batch loss: 0.143478 Batch F1: 0.742857142857143
Epoch:  259        4 Batch loss: 0.169783 Batch F1: 0.6500000000000001
Epoch:  259        5 Batch loss: 0.162414 Batch F1: 0.8148148148148148
Epoch:  259        6 Batch loss: 0.212665 Batch F1: 0.6363636363636365
Epoch:  259        7 Batch loss: 0.206441 Batch F1: 0.6428571428571429
Epoch:  259        8 Batch loss: 0.159980 Batch F1: 0.6666666666666667
Epoch:  259        9 Batch loss: 0.170824 Batch F1: 0.7441860465116279
Epoch:  259       10 Batch loss: 0.169841 Batch F1: 0.7727272727272727
Epoch:  259       11 Batch loss: 0.184454 Batch F1: 0.6
Epoch:  259       12 Batch loss: 0.175377 Batch F1: 0.7804878048780488
Train Avg Loss  259: 0.178268

Train Avg F1  259: 0.7000461686342762

Val Avg Loss  259: 0.193370

Val Avg F1  259:  0.6848195661243222

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 260
--------------------------------------------------------------
Epoch:  260        1 Batch loss: 0.215247 Batch F1: 0.46153846153846156
Epoch:  260        2 Batch loss: 0.214751 Batch F1: 0.7058823529411765
Epoch:  260        3 Batch loss: 0.167698 Batch F1: 0.6857142857142857
Epoch:  260        4 Batch loss: 0.154480 Batch F1: 0.8399999999999999
Epoch:  260        5 Batch loss: 0.177433 Batch F1: 0.8181818181818182
Epoch:  260        6 Batch loss: 0.153028 Batch F1: 0.782608695652174
Epoch:  260        7 Batch loss: 0.181867 Batch F1: 0.711111111111111
Epoch:  260        8 Batch loss: 0.184457 Batch F1: 0.8275862068965517
Epoch:  260        9 Batch loss: 0.177728 Batch F1: 0.8148148148148148
Epoch:  260       10 Batch loss: 0.170119 Batch F1: 0.7317073170731706
Epoch:  260       11 Batch loss: 0.190704 Batch F1: 0.6818181818181819
Epoch:  260       12 Batch loss: 0.177157 Batch F1: 0.7222222222222222
Train Avg Loss  260: 0.180389

Train Avg F1  260: 0.7319321223303307

Val Avg Loss  260: 0.188982

Val Avg F1  260:  0.6765346050379065

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 261
--------------------------------------------------------------
Epoch:  261        1 Batch loss: 0.187147 Batch F1: 0.6666666666666667
Epoch:  261        2 Batch loss: 0.179007 Batch F1: 0.7111111111111111
Epoch:  261        3 Batch loss: 0.170540 Batch F1: 0.7826086956521738
Epoch:  261        4 Batch loss: 0.148595 Batch F1: 0.7999999999999999
Epoch:  261        5 Batch loss: 0.181649 Batch F1: 0.7547169811320754
Epoch:  261        6 Batch loss: 0.155918 Batch F1: 0.7500000000000001
Epoch:  261        7 Batch loss: 0.175412 Batch F1: 0.8095238095238095
Epoch:  261        8 Batch loss: 0.197517 Batch F1: 0.7906976744186047
Epoch:  261        9 Batch loss: 0.196980 Batch F1: 0.6046511627906977
Epoch:  261       10 Batch loss: 0.188248 Batch F1: 0.7547169811320756
Epoch:  261       11 Batch loss: 0.202114 Batch F1: 0.6909090909090909
Epoch:  261       12 Batch loss: 0.174750 Batch F1: 0.6857142857142857
Train Avg Loss  261: 0.179823

Train Avg F1  261: 0.7334430382542158

Val Avg Loss  261: 0.187591

Val Avg F1  261:  0.6499049820236261

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 262
--------------------------------------------------------------
Epoch:  262        1 Batch loss: 0.169466 Batch F1: 0.5714285714285714
Epoch:  262        2 Batch loss: 0.179394 Batch F1: 0.7
Epoch:  262        3 Batch loss: 0.209494 Batch F1: 0.6250000000000001
Epoch:  262        4 Batch loss: 0.149820 Batch F1: 0.7619047619047619
Epoch:  262        5 Batch loss: 0.154306 Batch F1: 0.8085106382978724
Epoch:  262        6 Batch loss: 0.210157 Batch F1: 0.6222222222222222
Epoch:  262        7 Batch loss: 0.158476 Batch F1: 0.8518518518518519
Epoch:  262        8 Batch loss: 0.182480 Batch F1: 0.6666666666666666
Epoch:  262        9 Batch loss: 0.157374 Batch F1: 0.6470588235294118
Epoch:  262       10 Batch loss: 0.165198 Batch F1: 0.8148148148148148
Epoch:  262       11 Batch loss: 0.186162 Batch F1: 0.6511627906976744
Epoch:  262       12 Batch loss: 0.154258 Batch F1: 0.7692307692307692
Train Avg Loss  262: 0.173049

Train Avg F1  262: 0.7074876592203848

Val Avg Loss  262: 0.182790

Val Avg F1  262:  0.6798846213818963

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 263
--------------------------------------------------------------
Epoch:  263        1 Batch loss: 0.210469 Batch F1: 0.5833333333333334
Epoch:  263        2 Batch loss: 0.154291 Batch F1: 0.7500000000000001
Epoch:  263        3 Batch loss: 0.190218 Batch F1: 0.6363636363636365
Epoch:  263        4 Batch loss: 0.132174 Batch F1: 0.8205128205128205
Epoch:  263        5 Batch loss: 0.168936 Batch F1: 0.7317073170731706
Epoch:  263        6 Batch loss: 0.176585 Batch F1: 0.6818181818181818
Epoch:  263        7 Batch loss: 0.199384 Batch F1: 0.6666666666666666
Epoch:  263        8 Batch loss: 0.144067 Batch F1: 0.7894736842105263
Epoch:  263        9 Batch loss: 0.179677 Batch F1: 0.7391304347826088
Epoch:  263       10 Batch loss: 0.153015 Batch F1: 0.8461538461538461
Epoch:  263       11 Batch loss: 0.178198 Batch F1: 0.6666666666666666
Epoch:  263       12 Batch loss: 0.172011 Batch F1: 0.6842105263157895
Train Avg Loss  263: 0.171585

Train Avg F1  263: 0.716336426158104

Val Avg Loss  263: 0.184651

Val Avg F1  263:  0.6762057850025495

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 264
--------------------------------------------------------------
Epoch:  264        1 Batch loss: 0.179898 Batch F1: 0.7450980392156864
Epoch:  264        2 Batch loss: 0.207519 Batch F1: 0.5365853658536585
Epoch:  264        3 Batch loss: 0.168571 Batch F1: 0.6829268292682926
Epoch:  264        4 Batch loss: 0.147551 Batch F1: 0.8627450980392156
Epoch:  264        5 Batch loss: 0.180635 Batch F1: 0.7083333333333334
Epoch:  264        6 Batch loss: 0.179552 Batch F1: 0.711111111111111
Epoch:  264        7 Batch loss: 0.188795 Batch F1: 0.7058823529411765
Epoch:  264        8 Batch loss: 0.166389 Batch F1: 0.6829268292682926
Epoch:  264        9 Batch loss: 0.171756 Batch F1: 0.6666666666666667
Epoch:  264       10 Batch loss: 0.148821 Batch F1: 0.7727272727272727
Epoch:  264       11 Batch loss: 0.151215 Batch F1: 0.7567567567567567
Epoch:  264       12 Batch loss: 0.181673 Batch F1: 0.6486486486486486
Train Avg Loss  264: 0.172698

Train Avg F1  264: 0.7067006919858426

Val Avg Loss  264: 0.182164

Val Avg F1  264:  0.6683705829054666

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 265
--------------------------------------------------------------
Epoch:  265        1 Batch loss: 0.177712 Batch F1: 0.6976744186046512
Epoch:  265        2 Batch loss: 0.193424 Batch F1: 0.5499999999999999
Epoch:  265        3 Batch loss: 0.181157 Batch F1: 0.6511627906976744
Epoch:  265        4 Batch loss: 0.162519 Batch F1: 0.830188679245283
Epoch:  265        5 Batch loss: 0.162503 Batch F1: 0.7272727272727272
Epoch:  265        6 Batch loss: 0.175382 Batch F1: 0.7083333333333334
Epoch:  265        7 Batch loss: 0.147539 Batch F1: 0.742857142857143
Epoch:  265        8 Batch loss: 0.176294 Batch F1: 0.6666666666666667
Epoch:  265        9 Batch loss: 0.161745 Batch F1: 0.7272727272727272
Epoch:  265       10 Batch loss: 0.169937 Batch F1: 0.7777777777777778
Epoch:  265       11 Batch loss: 0.185467 Batch F1: 0.7058823529411765
Epoch:  265       12 Batch loss: 0.151761 Batch F1: 0.6875
Train Avg Loss  265: 0.170453

Train Avg F1  265: 0.7060490513890967

Val Avg Loss  265: 0.181705

Val Avg F1  265:  0.6699911347517731

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 266
--------------------------------------------------------------
Epoch:  266        1 Batch loss: 0.171843 Batch F1: 0.7199999999999999
Epoch:  266        2 Batch loss: 0.181901 Batch F1: 0.72
Epoch:  266        3 Batch loss: 0.161207 Batch F1: 0.7142857142857143
Epoch:  266        4 Batch loss: 0.185952 Batch F1: 0.64
Epoch:  266        5 Batch loss: 0.148173 Batch F1: 0.8444444444444444
Epoch:  266        6 Batch loss: 0.159870 Batch F1: 0.8333333333333333
Epoch:  266        7 Batch loss: 0.178238 Batch F1: 0.7111111111111111
Epoch:  266        8 Batch loss: 0.158204 Batch F1: 0.8085106382978724
Epoch:  266        9 Batch loss: 0.182152 Batch F1: 0.6341463414634148
Epoch:  266       10 Batch loss: 0.185477 Batch F1: 0.7142857142857143
Epoch:  266       11 Batch loss: 0.152552 Batch F1: 0.7567567567567567
Epoch:  266       12 Batch loss: 0.195686 Batch F1: 0.6666666666666667
Train Avg Loss  266: 0.171771

Train Avg F1  266: 0.7302950600537524

Val Avg Loss  266: 0.188171

Val Avg F1  266:  0.6537646198830409

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 267
--------------------------------------------------------------
Epoch:  267        1 Batch loss: 0.163776 Batch F1: 0.6829268292682927
Epoch:  267        2 Batch loss: 0.170056 Batch F1: 0.7916666666666667
Epoch:  267        3 Batch loss: 0.180225 Batch F1: 0.6666666666666666
Epoch:  267        4 Batch loss: 0.165914 Batch F1: 0.723404255319149
Epoch:  267        5 Batch loss: 0.177170 Batch F1: 0.7692307692307692
Epoch:  267        6 Batch loss: 0.197210 Batch F1: 0.47368421052631576
Epoch:  267        7 Batch loss: 0.176449 Batch F1: 0.6451612903225806
Epoch:  267        8 Batch loss: 0.146580 Batch F1: 0.75
Epoch:  267        9 Batch loss: 0.200001 Batch F1: 0.5853658536585366
Epoch:  267       10 Batch loss: 0.170640 Batch F1: 0.7924528301886793
Epoch:  267       11 Batch loss: 0.150027 Batch F1: 0.830188679245283
Epoch:  267       12 Batch loss: 0.179106 Batch F1: 0.5806451612903226
Train Avg Loss  267: 0.173096

Train Avg F1  267: 0.6909494343652719

Val Avg Loss  267: 0.184855

Val Avg F1  267:  0.705155658233601

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 268
--------------------------------------------------------------
Epoch:  268        1 Batch loss: 0.176736 Batch F1: 0.6666666666666666
Epoch:  268        2 Batch loss: 0.171138 Batch F1: 0.7
Epoch:  268        3 Batch loss: 0.194281 Batch F1: 0.6923076923076923
Epoch:  268        4 Batch loss: 0.184505 Batch F1: 0.6046511627906976
Epoch:  268        5 Batch loss: 0.169738 Batch F1: 0.6976744186046512
Epoch:  268        6 Batch loss: 0.155812 Batch F1: 0.8235294117647058
Epoch:  268        7 Batch loss: 0.145891 Batch F1: 0.8636363636363636
Epoch:  268        8 Batch loss: 0.167129 Batch F1: 0.7659574468085106
Epoch:  268        9 Batch loss: 0.185947 Batch F1: 0.6190476190476191
Epoch:  268       10 Batch loss: 0.168903 Batch F1: 0.7441860465116279
Epoch:  268       11 Batch loss: 0.159027 Batch F1: 0.7777777777777777
Epoch:  268       12 Batch loss: 0.194314 Batch F1: 0.3846153846153846
Train Avg Loss  268: 0.172785

Train Avg F1  268: 0.6950041658776414

Val Avg Loss  268: 0.181937

Val Avg F1  268:  0.6839427437641723

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 269
--------------------------------------------------------------
Epoch:  269        1 Batch loss: 0.152027 Batch F1: 0.7619047619047619
Epoch:  269        2 Batch loss: 0.175095 Batch F1: 0.6956521739130435
Epoch:  269        3 Batch loss: 0.193986 Batch F1: 0.5777777777777778
Epoch:  269        4 Batch loss: 0.199020 Batch F1: 0.5263157894736842
Epoch:  269        5 Batch loss: 0.154963 Batch F1: 0.7727272727272727
Epoch:  269        6 Batch loss: 0.133966 Batch F1: 0.8181818181818182
Epoch:  269        7 Batch loss: 0.160923 Batch F1: 0.7692307692307693
Epoch:  269        8 Batch loss: 0.157860 Batch F1: 0.7906976744186046
Epoch:  269        9 Batch loss: 0.199447 Batch F1: 0.7368421052631577
Epoch:  269       10 Batch loss: 0.172883 Batch F1: 0.7659574468085107
Epoch:  269       11 Batch loss: 0.161887 Batch F1: 0.7027027027027027
Epoch:  269       12 Batch loss: 0.182981 Batch F1: 0.6666666666666667
Train Avg Loss  269: 0.170420

Train Avg F1  269: 0.7153880799223974

Val Avg Loss  269: 0.182722

Val Avg F1  269:  0.665064722511531

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 270
--------------------------------------------------------------
Epoch:  270        1 Batch loss: 0.180651 Batch F1: 0.6341463414634146
Epoch:  270        2 Batch loss: 0.163360 Batch F1: 0.6829268292682926
Epoch:  270        3 Batch loss: 0.187715 Batch F1: 0.6
Epoch:  270        4 Batch loss: 0.133488 Batch F1: 0.8292682926829269
Epoch:  270        5 Batch loss: 0.179819 Batch F1: 0.7450980392156863
Epoch:  270        6 Batch loss: 0.158873 Batch F1: 0.7727272727272727
Epoch:  270        7 Batch loss: 0.188128 Batch F1: 0.6511627906976744
Epoch:  270        8 Batch loss: 0.158688 Batch F1: 0.7317073170731706
Epoch:  270        9 Batch loss: 0.178493 Batch F1: 0.7083333333333334
Epoch:  270       10 Batch loss: 0.197468 Batch F1: 0.6666666666666666
Epoch:  270       11 Batch loss: 0.151148 Batch F1: 0.761904761904762
Epoch:  270       12 Batch loss: 0.172828 Batch F1: 0.761904761904762
Train Avg Loss  270: 0.170888

Train Avg F1  270: 0.7121538672448301

Val Avg Loss  270: 0.183709

Val Avg F1  270:  0.6783131467418196

Optimal Val loss (Epoch 243): 0.18124937266111374

Epoch 271
--------------------------------------------------------------
Epoch:  271        1 Batch loss: 0.180823 Batch F1: 0.6829268292682926
Epoch:  271        2 Batch loss: 0.162780 Batch F1: 0.7826086956521738
Epoch:  271        3 Batch loss: 0.146746 Batch F1: 0.7058823529411765
Epoch:  271        4 Batch loss: 0.167107 Batch F1: 0.7234042553191491
Epoch:  271        5 Batch loss: 0.160148 Batch F1: 0.7555555555555555
Epoch:  271        6 Batch loss: 0.189133 Batch F1: 0.68
Epoch:  271        7 Batch loss: 0.189024 Batch F1: 0.68
Epoch:  271        8 Batch loss: 0.169843 Batch F1: 0.7391304347826085
Epoch:  271        9 Batch loss: 0.198454 Batch F1: 0.6222222222222223
Epoch:  271       10 Batch loss: 0.142037 Batch F1: 0.7916666666666667
Epoch:  271       11 Batch loss: 0.166997 Batch F1: 0.6818181818181819
Epoch:  271       12 Batch loss: 0.171324 Batch F1: 0.6875
Train Avg Loss  271: 0.170368

Train Avg F1  271: 0.7110595995188356

Val Avg Loss  271: 0.180257

Val Avg F1  271:  0.6862747463051415

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 272
--------------------------------------------------------------
Epoch:  272        1 Batch loss: 0.186945 Batch F1: 0.6046511627906976
Epoch:  272        2 Batch loss: 0.169712 Batch F1: 0.6153846153846153
Epoch:  272        3 Batch loss: 0.195902 Batch F1: 0.6190476190476191
Epoch:  272        4 Batch loss: 0.163554 Batch F1: 0.6428571428571429
Epoch:  272        5 Batch loss: 0.147225 Batch F1: 0.7894736842105262
Epoch:  272        6 Batch loss: 0.178949 Batch F1: 0.7234042553191489
Epoch:  272        7 Batch loss: 0.163029 Batch F1: 0.6153846153846153
Epoch:  272        8 Batch loss: 0.205563 Batch F1: 0.6779661016949152
Epoch:  272        9 Batch loss: 0.192037 Batch F1: 0.679245283018868
Epoch:  272       10 Batch loss: 0.179569 Batch F1: 0.6382978723404256
Epoch:  272       11 Batch loss: 0.176424 Batch F1: 0.7450980392156863
Epoch:  272       12 Batch loss: 0.187978 Batch F1: 0.6666666666666666
Train Avg Loss  272: 0.178907

Train Avg F1  272: 0.6681230881609105

Val Avg Loss  272: 0.187224

Val Avg F1  272:  0.6874943316827193

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 273
--------------------------------------------------------------
Epoch:  273        1 Batch loss: 0.169895 Batch F1: 0.6666666666666667
Epoch:  273        2 Batch loss: 0.185788 Batch F1: 0.6500000000000001
Epoch:  273        3 Batch loss: 0.159477 Batch F1: 0.830188679245283
Epoch:  273        4 Batch loss: 0.135067 Batch F1: 0.8181818181818182
Epoch:  273        5 Batch loss: 0.191740 Batch F1: 0.7058823529411765
Epoch:  273        6 Batch loss: 0.159664 Batch F1: 0.72
Epoch:  273        7 Batch loss: 0.175474 Batch F1: 0.7450980392156864
Epoch:  273        8 Batch loss: 0.186823 Batch F1: 0.7272727272727273
Epoch:  273        9 Batch loss: 0.166398 Batch F1: 0.7916666666666667
Epoch:  273       10 Batch loss: 0.157890 Batch F1: 0.7727272727272727
Epoch:  273       11 Batch loss: 0.190312 Batch F1: 0.6341463414634146
Epoch:  273       12 Batch loss: 0.184270 Batch F1: 0.36363636363636365
Train Avg Loss  273: 0.171900

Train Avg F1  273: 0.7021222440014231

Val Avg Loss  273: 0.211274

Val Avg F1  273:  0.5401170938097932

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 274
--------------------------------------------------------------
Epoch:  274        1 Batch loss: 0.218560 Batch F1: 0.22222222222222218
Epoch:  274        2 Batch loss: 0.189322 Batch F1: 0.6341463414634146
Epoch:  274        3 Batch loss: 0.151871 Batch F1: 0.7272727272727272
Epoch:  274        4 Batch loss: 0.180212 Batch F1: 0.7272727272727273
Epoch:  274        5 Batch loss: 0.165027 Batch F1: 0.6842105263157895
Epoch:  274        6 Batch loss: 0.160351 Batch F1: 0.723404255319149
Epoch:  274        7 Batch loss: 0.205568 Batch F1: 0.6909090909090909
Epoch:  274        8 Batch loss: 0.154278 Batch F1: 0.7924528301886793
Epoch:  274        9 Batch loss: 0.169670 Batch F1: 0.6666666666666666
Epoch:  274       10 Batch loss: 0.181492 Batch F1: 0.6938775510204083
Epoch:  274       11 Batch loss: 0.172039 Batch F1: 0.7499999999999999
Epoch:  274       12 Batch loss: 0.176188 Batch F1: 0.7567567567567567
Train Avg Loss  274: 0.177048

Train Avg F1  274: 0.6724326412839693

Val Avg Loss  274: 0.188085

Val Avg F1  274:  0.6789964658143898

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 275
--------------------------------------------------------------
Epoch:  275        1 Batch loss: 0.192513 Batch F1: 0.6222222222222222
Epoch:  275        2 Batch loss: 0.156643 Batch F1: 0.8163265306122449
Epoch:  275        3 Batch loss: 0.150006 Batch F1: 0.8461538461538461
Epoch:  275        4 Batch loss: 0.174387 Batch F1: 0.6976744186046512
Epoch:  275        5 Batch loss: 0.179646 Batch F1: 0.8571428571428571
Epoch:  275        6 Batch loss: 0.169228 Batch F1: 0.8510638297872339
Epoch:  275        7 Batch loss: 0.200535 Batch F1: 0.6153846153846153
Epoch:  275        8 Batch loss: 0.157477 Batch F1: 0.7368421052631577
Epoch:  275        9 Batch loss: 0.183197 Batch F1: 0.7234042553191491
Epoch:  275       10 Batch loss: 0.187994 Batch F1: 0.7547169811320755
Epoch:  275       11 Batch loss: 0.180579 Batch F1: 0.5714285714285714
Epoch:  275       12 Batch loss: 0.194873 Batch F1: 0.5882352941176471
Train Avg Loss  275: 0.177257

Train Avg F1  275: 0.7233829605973559

Val Avg Loss  275: 0.188979

Val Avg F1  275:  0.677823402088108

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 276
--------------------------------------------------------------
Epoch:  276        1 Batch loss: 0.145175 Batch F1: 0.85
Epoch:  276        2 Batch loss: 0.212514 Batch F1: 0.625
Epoch:  276        3 Batch loss: 0.165175 Batch F1: 0.723404255319149
Epoch:  276        4 Batch loss: 0.167872 Batch F1: 0.7441860465116279
Epoch:  276        5 Batch loss: 0.178981 Batch F1: 0.7407407407407408
Epoch:  276        6 Batch loss: 0.193064 Batch F1: 0.6
Epoch:  276        7 Batch loss: 0.170190 Batch F1: 0.6666666666666666
Epoch:  276        8 Batch loss: 0.177580 Batch F1: 0.723404255319149
Epoch:  276        9 Batch loss: 0.202137 Batch F1: 0.6382978723404256
Epoch:  276       10 Batch loss: 0.155792 Batch F1: 0.7804878048780488
Epoch:  276       11 Batch loss: 0.176242 Batch F1: 0.6976744186046512
Epoch:  276       12 Batch loss: 0.170669 Batch F1: 0.7222222222222222
Train Avg Loss  276: 0.176283

Train Avg F1  276: 0.7093403568835567

Val Avg Loss  276: 0.183820

Val Avg F1  276:  0.6880952380952381

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 277
--------------------------------------------------------------
Epoch:  277        1 Batch loss: 0.184337 Batch F1: 0.7058823529411765
Epoch:  277        2 Batch loss: 0.156600 Batch F1: 0.7222222222222222
Epoch:  277        3 Batch loss: 0.160753 Batch F1: 0.7058823529411765
Epoch:  277        4 Batch loss: 0.170427 Batch F1: 0.7272727272727273
Epoch:  277        5 Batch loss: 0.178714 Batch F1: 0.761904761904762
Epoch:  277        6 Batch loss: 0.158269 Batch F1: 0.782608695652174
Epoch:  277        7 Batch loss: 0.199453 Batch F1: 0.64
Epoch:  277        8 Batch loss: 0.184819 Batch F1: 0.7272727272727274
Epoch:  277        9 Batch loss: 0.180508 Batch F1: 0.7083333333333334
Epoch:  277       10 Batch loss: 0.174591 Batch F1: 0.7272727272727272
Epoch:  277       11 Batch loss: 0.168319 Batch F1: 0.7346938775510204
Epoch:  277       12 Batch loss: 0.181088 Batch F1: 0.6842105263157895
Train Avg Loss  277: 0.174823

Train Avg F1  277: 0.7189630253899862

Val Avg Loss  277: 0.185448

Val Avg F1  277:  0.6750500090925623

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 278
--------------------------------------------------------------
Epoch:  278        1 Batch loss: 0.155557 Batch F1: 0.7755102040816326
Epoch:  278        2 Batch loss: 0.164825 Batch F1: 0.7317073170731706
Epoch:  278        3 Batch loss: 0.188584 Batch F1: 0.68
Epoch:  278        4 Batch loss: 0.185773 Batch F1: 0.6363636363636364
Epoch:  278        5 Batch loss: 0.154539 Batch F1: 0.7999999999999999
Epoch:  278        6 Batch loss: 0.161524 Batch F1: 0.75
Epoch:  278        7 Batch loss: 0.169303 Batch F1: 0.7317073170731707
Epoch:  278        8 Batch loss: 0.137588 Batch F1: 0.8695652173913043
Epoch:  278        9 Batch loss: 0.187117 Batch F1: 0.7083333333333333
Epoch:  278       10 Batch loss: 0.213139 Batch F1: 0.5714285714285714
Epoch:  278       11 Batch loss: 0.187498 Batch F1: 0.72
Epoch:  278       12 Batch loss: 0.187401 Batch F1: 0.5714285714285715
Train Avg Loss  278: 0.174404

Train Avg F1  278: 0.7121703473477825

Val Avg Loss  278: 0.186511

Val Avg F1  278:  0.6808715348627223

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 279
--------------------------------------------------------------
Epoch:  279        1 Batch loss: 0.132332 Batch F1: 0.8108108108108109
Epoch:  279        2 Batch loss: 0.183452 Batch F1: 0.5294117647058824
Epoch:  279        3 Batch loss: 0.143329 Batch F1: 0.8
Epoch:  279        4 Batch loss: 0.187337 Batch F1: 0.5714285714285714
Epoch:  279        5 Batch loss: 0.192340 Batch F1: 0.6818181818181818
Epoch:  279        6 Batch loss: 0.153735 Batch F1: 0.7804878048780488
Epoch:  279        7 Batch loss: 0.181114 Batch F1: 0.7636363636363638
Epoch:  279        8 Batch loss: 0.157385 Batch F1: 0.7755102040816326
Epoch:  279        9 Batch loss: 0.193410 Batch F1: 0.7199999999999999
Epoch:  279       10 Batch loss: 0.197849 Batch F1: 0.6521739130434783
Epoch:  279       11 Batch loss: 0.198899 Batch F1: 0.7142857142857142
Epoch:  279       12 Batch loss: 0.176845 Batch F1: 0.717948717948718
Train Avg Loss  279: 0.174836

Train Avg F1  279: 0.7097926705531168

Val Avg Loss  279: 0.182489

Val Avg F1  279:  0.6965385235332044

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 280
--------------------------------------------------------------
Epoch:  280        1 Batch loss: 0.188149 Batch F1: 0.6666666666666666
Epoch:  280        2 Batch loss: 0.168791 Batch F1: 0.7692307692307692
Epoch:  280        3 Batch loss: 0.180432 Batch F1: 0.6829268292682926
Epoch:  280        4 Batch loss: 0.177320 Batch F1: 0.7659574468085107
Epoch:  280        5 Batch loss: 0.185873 Batch F1: 0.7111111111111111
Epoch:  280        6 Batch loss: 0.183365 Batch F1: 0.7450980392156864
Epoch:  280        7 Batch loss: 0.160296 Batch F1: 0.7727272727272727
Epoch:  280        8 Batch loss: 0.170066 Batch F1: 0.7500000000000001
Epoch:  280        9 Batch loss: 0.166993 Batch F1: 0.7727272727272727
Epoch:  280       10 Batch loss: 0.182947 Batch F1: 0.5555555555555556
Epoch:  280       11 Batch loss: 0.128767 Batch F1: 0.9166666666666666
Epoch:  280       12 Batch loss: 0.234744 Batch F1: 0.5263157894736842
Train Avg Loss  280: 0.177312

Train Avg F1  280: 0.7195819516209574

Val Avg Loss  280: 0.184604

Val Avg F1  280:  0.6912980372752762

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 281
--------------------------------------------------------------
Epoch:  281        1 Batch loss: 0.174634 Batch F1: 0.7346938775510204
Epoch:  281        2 Batch loss: 0.157488 Batch F1: 0.7755102040816326
Epoch:  281        3 Batch loss: 0.159180 Batch F1: 0.7804878048780488
Epoch:  281        4 Batch loss: 0.177311 Batch F1: 0.6808510638297872
Epoch:  281        5 Batch loss: 0.143093 Batch F1: 0.8444444444444444
Epoch:  281        6 Batch loss: 0.178290 Batch F1: 0.7346938775510204
Epoch:  281        7 Batch loss: 0.195085 Batch F1: 0.6666666666666666
Epoch:  281        8 Batch loss: 0.175330 Batch F1: 0.631578947368421
Epoch:  281        9 Batch loss: 0.176797 Batch F1: 0.6666666666666666
Epoch:  281       10 Batch loss: 0.149724 Batch F1: 0.7906976744186046
Epoch:  281       11 Batch loss: 0.221467 Batch F1: 0.5777777777777778
Epoch:  281       12 Batch loss: 0.169238 Batch F1: 0.6470588235294117
Train Avg Loss  281: 0.173136

Train Avg F1  281: 0.7109273190636253

Val Avg Loss  281: 0.185501

Val Avg F1  281:  0.6816076311044836

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 282
--------------------------------------------------------------
Epoch:  282        1 Batch loss: 0.197739 Batch F1: 0.6538461538461539
Epoch:  282        2 Batch loss: 0.159857 Batch F1: 0.8181818181818182
Epoch:  282        3 Batch loss: 0.143352 Batch F1: 0.8108108108108109
Epoch:  282        4 Batch loss: 0.198669 Batch F1: 0.5142857142857143
Epoch:  282        5 Batch loss: 0.177511 Batch F1: 0.75
Epoch:  282        6 Batch loss: 0.171829 Batch F1: 0.7234042553191489
Epoch:  282        7 Batch loss: 0.170374 Batch F1: 0.6818181818181818
Epoch:  282        8 Batch loss: 0.151648 Batch F1: 0.8518518518518519
Epoch:  282        9 Batch loss: 0.182256 Batch F1: 0.5625000000000001
Epoch:  282       10 Batch loss: 0.182430 Batch F1: 0.7407407407407408
Epoch:  282       11 Batch loss: 0.177013 Batch F1: 0.6153846153846153
Epoch:  282       12 Batch loss: 0.196708 Batch F1: 0.7142857142857143
Train Avg Loss  282: 0.175782

Train Avg F1  282: 0.7030924880437291

Val Avg Loss  282: 0.184973

Val Avg F1  282:  0.6609927300188638

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 283
--------------------------------------------------------------
Epoch:  283        1 Batch loss: 0.146745 Batch F1: 0.7500000000000001
Epoch:  283        2 Batch loss: 0.170712 Batch F1: 0.711111111111111
Epoch:  283        3 Batch loss: 0.201493 Batch F1: 0.7118644067796611
Epoch:  283        4 Batch loss: 0.158156 Batch F1: 0.7755102040816326
Epoch:  283        5 Batch loss: 0.161119 Batch F1: 0.7727272727272727
Epoch:  283        6 Batch loss: 0.170064 Batch F1: 0.6818181818181819
Epoch:  283        7 Batch loss: 0.193518 Batch F1: 0.5500000000000002
Epoch:  283        8 Batch loss: 0.160922 Batch F1: 0.6842105263157895
Epoch:  283        9 Batch loss: 0.188543 Batch F1: 0.6382978723404256
Epoch:  283       10 Batch loss: 0.159295 Batch F1: 0.7804878048780488
Epoch:  283       11 Batch loss: 0.187282 Batch F1: 0.7346938775510203
Epoch:  283       12 Batch loss: 0.162328 Batch F1: 0.7222222222222223
Train Avg Loss  283: 0.171681

Train Avg F1  283: 0.7094119566521138

Val Avg Loss  283: 0.182276

Val Avg F1  283:  0.6754346981921733

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 284
--------------------------------------------------------------
Epoch:  284        1 Batch loss: 0.178593 Batch F1: 0.6818181818181818
Epoch:  284        2 Batch loss: 0.165153 Batch F1: 0.7000000000000001
Epoch:  284        3 Batch loss: 0.182246 Batch F1: 0.7586206896551724
Epoch:  284        4 Batch loss: 0.144822 Batch F1: 0.7804878048780488
Epoch:  284        5 Batch loss: 0.156077 Batch F1: 0.7368421052631577
Epoch:  284        6 Batch loss: 0.167753 Batch F1: 0.7692307692307692
Epoch:  284        7 Batch loss: 0.190738 Batch F1: 0.6190476190476191
Epoch:  284        8 Batch loss: 0.171937 Batch F1: 0.7142857142857143
Epoch:  284        9 Batch loss: 0.167410 Batch F1: 0.723404255319149
Epoch:  284       10 Batch loss: 0.176707 Batch F1: 0.6666666666666666
Epoch:  284       11 Batch loss: 0.195547 Batch F1: 0.6382978723404256
Epoch:  284       12 Batch loss: 0.160695 Batch F1: 0.7272727272727273
Train Avg Loss  284: 0.171473

Train Avg F1  284: 0.7096645338148027

Val Avg Loss  284: 0.186498

Val Avg F1  284:  0.6761426850949132

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 285
--------------------------------------------------------------
Epoch:  285        1 Batch loss: 0.159380 Batch F1: 0.625
Epoch:  285        2 Batch loss: 0.185994 Batch F1: 0.6666666666666666
Epoch:  285        3 Batch loss: 0.150229 Batch F1: 0.8363636363636364
Epoch:  285        4 Batch loss: 0.202163 Batch F1: 0.64
Epoch:  285        5 Batch loss: 0.187802 Batch F1: 0.7169811320754718
Epoch:  285        6 Batch loss: 0.152790 Batch F1: 0.8085106382978724
Epoch:  285        7 Batch loss: 0.150357 Batch F1: 0.84
Epoch:  285        8 Batch loss: 0.163303 Batch F1: 0.7111111111111111
Epoch:  285        9 Batch loss: 0.180171 Batch F1: 0.6956521739130435
Epoch:  285       10 Batch loss: 0.171711 Batch F1: 0.6470588235294118
Epoch:  285       11 Batch loss: 0.204207 Batch F1: 0.5909090909090908
Epoch:  285       12 Batch loss: 0.157664 Batch F1: 0.7567567567567567
Train Avg Loss  285: 0.172148

Train Avg F1  285: 0.7112508358019217

Val Avg Loss  285: 0.183933

Val Avg F1  285:  0.6769725557461406

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 286
--------------------------------------------------------------
Epoch:  286        1 Batch loss: 0.190845 Batch F1: 0.6666666666666665
Epoch:  286        2 Batch loss: 0.177071 Batch F1: 0.5945945945945946
Epoch:  286        3 Batch loss: 0.138350 Batch F1: 0.7894736842105263
Epoch:  286        4 Batch loss: 0.177798 Batch F1: 0.6341463414634146
Epoch:  286        5 Batch loss: 0.170351 Batch F1: 0.7659574468085107
Epoch:  286        6 Batch loss: 0.184863 Batch F1: 0.68
Epoch:  286        7 Batch loss: 0.148966 Batch F1: 0.7567567567567567
Epoch:  286        8 Batch loss: 0.157826 Batch F1: 0.7391304347826089
Epoch:  286        9 Batch loss: 0.186927 Batch F1: 0.6956521739130435
Epoch:  286       10 Batch loss: 0.176783 Batch F1: 0.7555555555555555
Epoch:  286       11 Batch loss: 0.166035 Batch F1: 0.782608695652174
Epoch:  286       12 Batch loss: 0.161103 Batch F1: 0.7804878048780488
Train Avg Loss  286: 0.169743

Train Avg F1  286: 0.7200858462734917

Val Avg Loss  286: 0.181834

Val Avg F1  286:  0.7128757485900343

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 287
--------------------------------------------------------------
Epoch:  287        1 Batch loss: 0.143633 Batch F1: 0.8421052631578947
Epoch:  287        2 Batch loss: 0.194806 Batch F1: 0.55
Epoch:  287        3 Batch loss: 0.175243 Batch F1: 0.7567567567567567
Epoch:  287        4 Batch loss: 0.164355 Batch F1: 0.7272727272727272
Epoch:  287        5 Batch loss: 0.196883 Batch F1: 0.64
Epoch:  287        6 Batch loss: 0.185387 Batch F1: 0.6190476190476191
Epoch:  287        7 Batch loss: 0.195595 Batch F1: 0.6511627906976744
Epoch:  287        8 Batch loss: 0.171196 Batch F1: 0.7272727272727272
Epoch:  287        9 Batch loss: 0.183273 Batch F1: 0.6666666666666666
Epoch:  287       10 Batch loss: 0.163953 Batch F1: 0.7391304347826089
Epoch:  287       11 Batch loss: 0.179737 Batch F1: 0.7555555555555555
Epoch:  287       12 Batch loss: 0.127442 Batch F1: 0.8648648648648649
Train Avg Loss  287: 0.173458

Train Avg F1  287: 0.711652950506258

Val Avg Loss  287: 0.187032

Val Avg F1  287:  0.7002896586791467

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 288
--------------------------------------------------------------
Epoch:  288        1 Batch loss: 0.191822 Batch F1: 0.7391304347826088
Epoch:  288        2 Batch loss: 0.187071 Batch F1: 0.6909090909090909
Epoch:  288        3 Batch loss: 0.169318 Batch F1: 0.7499999999999999
Epoch:  288        4 Batch loss: 0.165674 Batch F1: 0.7317073170731707
Epoch:  288        5 Batch loss: 0.183684 Batch F1: 0.7407407407407408
Epoch:  288        6 Batch loss: 0.171739 Batch F1: 0.6666666666666667
Epoch:  288        7 Batch loss: 0.159901 Batch F1: 0.7272727272727272
Epoch:  288        8 Batch loss: 0.180981 Batch F1: 0.6666666666666666
Epoch:  288        9 Batch loss: 0.160880 Batch F1: 0.75
Epoch:  288       10 Batch loss: 0.184998 Batch F1: 0.6666666666666666
Epoch:  288       11 Batch loss: 0.153210 Batch F1: 0.7317073170731706
Epoch:  288       12 Batch loss: 0.151983 Batch F1: 0.7692307692307692
Train Avg Loss  288: 0.171772

Train Avg F1  288: 0.7192248664235232

Val Avg Loss  288: 0.184908

Val Avg F1  288:  0.6759853738243264

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 289
--------------------------------------------------------------
Epoch:  289        1 Batch loss: 0.184922 Batch F1: 0.6956521739130435
Epoch:  289        2 Batch loss: 0.155027 Batch F1: 0.7555555555555555
Epoch:  289        3 Batch loss: 0.162612 Batch F1: 0.6486486486486486
Epoch:  289        4 Batch loss: 0.171352 Batch F1: 0.6285714285714286
Epoch:  289        5 Batch loss: 0.175028 Batch F1: 0.7234042553191491
Epoch:  289        6 Batch loss: 0.160842 Batch F1: 0.76
Epoch:  289        7 Batch loss: 0.152353 Batch F1: 0.782608695652174
Epoch:  289        8 Batch loss: 0.175843 Batch F1: 0.76
Epoch:  289        9 Batch loss: 0.186840 Batch F1: 0.7407407407407408
Epoch:  289       10 Batch loss: 0.151156 Batch F1: 0.8260869565217391
Epoch:  289       11 Batch loss: 0.171389 Batch F1: 0.6976744186046512
Epoch:  289       12 Batch loss: 0.194642 Batch F1: 0.6486486486486486
Train Avg Loss  289: 0.170167

Train Avg F1  289: 0.7222992935146482

Val Avg Loss  289: 0.189758

Val Avg F1  289:  0.6610387978381193

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 290
--------------------------------------------------------------
Epoch:  290        1 Batch loss: 0.199190 Batch F1: 0.6222222222222222
Epoch:  290        2 Batch loss: 0.196106 Batch F1: 0.6521739130434783
Epoch:  290        3 Batch loss: 0.148039 Batch F1: 0.7804878048780488
Epoch:  290        4 Batch loss: 0.210755 Batch F1: 0.5909090909090908
Epoch:  290        5 Batch loss: 0.160213 Batch F1: 0.7142857142857143
Epoch:  290        6 Batch loss: 0.158421 Batch F1: 0.7317073170731706
Epoch:  290        7 Batch loss: 0.151823 Batch F1: 0.7906976744186046
Epoch:  290        8 Batch loss: 0.181850 Batch F1: 0.7307692307692308
Epoch:  290        9 Batch loss: 0.137750 Batch F1: 0.8627450980392156
Epoch:  290       10 Batch loss: 0.198743 Batch F1: 0.5263157894736841
Epoch:  290       11 Batch loss: 0.173558 Batch F1: 0.711111111111111
Epoch:  290       12 Batch loss: 0.149042 Batch F1: 0.8421052631578947
Train Avg Loss  290: 0.172124

Train Avg F1  290: 0.7129608524484555

Val Avg Loss  290: 0.182648

Val Avg F1  290:  0.6955544455544456

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 291
--------------------------------------------------------------
Epoch:  291        1 Batch loss: 0.176131 Batch F1: 0.6666666666666666
Epoch:  291        2 Batch loss: 0.136229 Batch F1: 0.8292682926829269
Epoch:  291        3 Batch loss: 0.187822 Batch F1: 0.75
Epoch:  291        4 Batch loss: 0.169787 Batch F1: 0.7692307692307692
Epoch:  291        5 Batch loss: 0.197545 Batch F1: 0.5853658536585366
Epoch:  291        6 Batch loss: 0.172685 Batch F1: 0.6511627906976744
Epoch:  291        7 Batch loss: 0.179597 Batch F1: 0.6666666666666666
Epoch:  291        8 Batch loss: 0.172950 Batch F1: 0.6341463414634146
Epoch:  291        9 Batch loss: 0.152266 Batch F1: 0.84
Epoch:  291       10 Batch loss: 0.171645 Batch F1: 0.6829268292682927
Epoch:  291       11 Batch loss: 0.192755 Batch F1: 0.6666666666666665
Epoch:  291       12 Batch loss: 0.150658 Batch F1: 0.7878787878787878
Train Avg Loss  291: 0.171672

Train Avg F1  291: 0.7108316387400334

Val Avg Loss  291: 0.182506

Val Avg F1  291:  0.6903233743033492

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 292
--------------------------------------------------------------
Epoch:  292        1 Batch loss: 0.171512 Batch F1: 0.6486486486486486
Epoch:  292        2 Batch loss: 0.186820 Batch F1: 0.7169811320754716
Epoch:  292        3 Batch loss: 0.159651 Batch F1: 0.7555555555555555
Epoch:  292        4 Batch loss: 0.191123 Batch F1: 0.7391304347826088
Epoch:  292        5 Batch loss: 0.176820 Batch F1: 0.7547169811320754
Epoch:  292        6 Batch loss: 0.161864 Batch F1: 0.7755102040816326
Epoch:  292        7 Batch loss: 0.153341 Batch F1: 0.711111111111111
Epoch:  292        8 Batch loss: 0.183323 Batch F1: 0.6666666666666665
Epoch:  292        9 Batch loss: 0.176334 Batch F1: 0.7692307692307692
Epoch:  292       10 Batch loss: 0.201849 Batch F1: 0.5957446808510638
Epoch:  292       11 Batch loss: 0.157858 Batch F1: 0.6666666666666667
Epoch:  292       12 Batch loss: 0.171872 Batch F1: 0.6666666666666667
Train Avg Loss  292: 0.174364

Train Avg F1  292: 0.705552459789078

Val Avg Loss  292: 0.187194

Val Avg F1  292:  0.6703050509334528

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 293
--------------------------------------------------------------
Epoch:  293        1 Batch loss: 0.158806 Batch F1: 0.8085106382978724
Epoch:  293        2 Batch loss: 0.201069 Batch F1: 0.6222222222222222
Epoch:  293        3 Batch loss: 0.175034 Batch F1: 0.6521739130434783
Epoch:  293        4 Batch loss: 0.151697 Batch F1: 0.761904761904762
Epoch:  293        5 Batch loss: 0.187631 Batch F1: 0.68
Epoch:  293        6 Batch loss: 0.129899 Batch F1: 0.8108108108108109
Epoch:  293        7 Batch loss: 0.185631 Batch F1: 0.7346938775510203
Epoch:  293        8 Batch loss: 0.202945 Batch F1: 0.6521739130434783
Epoch:  293        9 Batch loss: 0.136256 Batch F1: 0.8292682926829269
Epoch:  293       10 Batch loss: 0.194713 Batch F1: 0.7037037037037038
Epoch:  293       11 Batch loss: 0.165793 Batch F1: 0.7027027027027027
Epoch:  293       12 Batch loss: 0.191163 Batch F1: 0.5882352941176471
Train Avg Loss  293: 0.173386

Train Avg F1  293: 0.7122000108400521

Val Avg Loss  293: 0.184697

Val Avg F1  293:  0.6732962213225371

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 294
--------------------------------------------------------------
Epoch:  294        1 Batch loss: 0.184044 Batch F1: 0.7083333333333334
Epoch:  294        2 Batch loss: 0.146926 Batch F1: 0.782608695652174
Epoch:  294        3 Batch loss: 0.161681 Batch F1: 0.7843137254901961
Epoch:  294        4 Batch loss: 0.204756 Batch F1: 0.6190476190476191
Epoch:  294        5 Batch loss: 0.174288 Batch F1: 0.7659574468085107
Epoch:  294        6 Batch loss: 0.164529 Batch F1: 0.7317073170731708
Epoch:  294        7 Batch loss: 0.175942 Batch F1: 0.5714285714285715
Epoch:  294        8 Batch loss: 0.153792 Batch F1: 0.7222222222222222
Epoch:  294        9 Batch loss: 0.185872 Batch F1: 0.7547169811320756
Epoch:  294       10 Batch loss: 0.185218 Batch F1: 0.7234042553191489
Epoch:  294       11 Batch loss: 0.171606 Batch F1: 0.7755102040816326
Epoch:  294       12 Batch loss: 0.169812 Batch F1: 0.6285714285714286
Train Avg Loss  294: 0.173206

Train Avg F1  294: 0.7139851500133402

Val Avg Loss  294: 0.186646

Val Avg F1  294:  0.7159036443238207

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 295
--------------------------------------------------------------
Epoch:  295        1 Batch loss: 0.195623 Batch F1: 0.6363636363636364
Epoch:  295        2 Batch loss: 0.155805 Batch F1: 0.8260869565217391
Epoch:  295        3 Batch loss: 0.159495 Batch F1: 0.8
Epoch:  295        4 Batch loss: 0.141634 Batch F1: 0.8571428571428572
Epoch:  295        5 Batch loss: 0.188184 Batch F1: 0.6382978723404256
Epoch:  295        6 Batch loss: 0.202422 Batch F1: 0.6382978723404256
Epoch:  295        7 Batch loss: 0.179048 Batch F1: 0.6285714285714286
Epoch:  295        8 Batch loss: 0.202046 Batch F1: 0.5128205128205128
Epoch:  295        9 Batch loss: 0.201164 Batch F1: 0.41176470588235287
Epoch:  295       10 Batch loss: 0.179068 Batch F1: 0.7234042553191489
Epoch:  295       11 Batch loss: 0.167477 Batch F1: 0.9
Epoch:  295       12 Batch loss: 0.179678 Batch F1: 0.8301886792452831
Train Avg Loss  295: 0.179304

Train Avg F1  295: 0.7002448980456509

Val Avg Loss  295: 0.194455

Val Avg F1  295:  0.6474194117589849

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 296
--------------------------------------------------------------
Epoch:  296        1 Batch loss: 0.153149 Batch F1: 0.7692307692307693
Epoch:  296        2 Batch loss: 0.182973 Batch F1: 0.6808510638297872
Epoch:  296        3 Batch loss: 0.169537 Batch F1: 0.7234042553191489
Epoch:  296        4 Batch loss: 0.211517 Batch F1: 0.4390243902439024
Epoch:  296        5 Batch loss: 0.177468 Batch F1: 0.6511627906976744
Epoch:  296        6 Batch loss: 0.157707 Batch F1: 0.7906976744186046
Epoch:  296        7 Batch loss: 0.202559 Batch F1: 0.47368421052631576
Epoch:  296        8 Batch loss: 0.191693 Batch F1: 0.6976744186046512
Epoch:  296        9 Batch loss: 0.203886 Batch F1: 0.7450980392156864
Epoch:  296       10 Batch loss: 0.163294 Batch F1: 0.8
Epoch:  296       11 Batch loss: 0.167708 Batch F1: 0.8260869565217391
Epoch:  296       12 Batch loss: 0.168521 Batch F1: 0.742857142857143
Train Avg Loss  296: 0.179168

Train Avg F1  296: 0.6949809759554518

Val Avg Loss  296: 0.193094

Val Avg F1  296:  0.6945424026169369

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 297
--------------------------------------------------------------
Epoch:  297        1 Batch loss: 0.179637 Batch F1: 0.7857142857142856
Epoch:  297        2 Batch loss: 0.200879 Batch F1: 0.6785714285714285
Epoch:  297        3 Batch loss: 0.201339 Batch F1: 0.6799999999999999
Epoch:  297        4 Batch loss: 0.179793 Batch F1: 0.6956521739130435
Epoch:  297        5 Batch loss: 0.167411 Batch F1: 0.7755102040816326
Epoch:  297        6 Batch loss: 0.151917 Batch F1: 0.7368421052631577
Epoch:  297        7 Batch loss: 0.190917 Batch F1: 0.5789473684210527
Epoch:  297        8 Batch loss: 0.159705 Batch F1: 0.7619047619047621
Epoch:  297        9 Batch loss: 0.163323 Batch F1: 0.7499999999999999
Epoch:  297       10 Batch loss: 0.207207 Batch F1: 0.55
Epoch:  297       11 Batch loss: 0.155717 Batch F1: 0.7272727272727272
Epoch:  297       12 Batch loss: 0.173934 Batch F1: 0.7272727272727272
Train Avg Loss  297: 0.177648

Train Avg F1  297: 0.7039739818679015

Val Avg Loss  297: 0.187261

Val Avg F1  297:  0.6526647893199833

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 298
--------------------------------------------------------------
Epoch:  298        1 Batch loss: 0.166614 Batch F1: 0.7441860465116279
Epoch:  298        2 Batch loss: 0.153248 Batch F1: 0.8510638297872342
Epoch:  298        3 Batch loss: 0.212099 Batch F1: 0.6122448979591837
Epoch:  298        4 Batch loss: 0.167729 Batch F1: 0.75
Epoch:  298        5 Batch loss: 0.150555 Batch F1: 0.7727272727272727
Epoch:  298        6 Batch loss: 0.156930 Batch F1: 0.7317073170731706
Epoch:  298        7 Batch loss: 0.160870 Batch F1: 0.7692307692307692
Epoch:  298        8 Batch loss: 0.170399 Batch F1: 0.6818181818181819
Epoch:  298        9 Batch loss: 0.176700 Batch F1: 0.6486486486486486
Epoch:  298       10 Batch loss: 0.194748 Batch F1: 0.6086956521739131
Epoch:  298       11 Batch loss: 0.175580 Batch F1: 0.6818181818181818
Epoch:  298       12 Batch loss: 0.198842 Batch F1: 0.5789473684210527
Train Avg Loss  298: 0.173693

Train Avg F1  298: 0.702590680514103

Val Avg Loss  298: 0.190742

Val Avg F1  298:  0.5836946329276859

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 299
--------------------------------------------------------------
Epoch:  299        1 Batch loss: 0.195677 Batch F1: 0.5365853658536586
Epoch:  299        2 Batch loss: 0.181631 Batch F1: 0.6976744186046512
Epoch:  299        3 Batch loss: 0.141024 Batch F1: 0.8333333333333334
Epoch:  299        4 Batch loss: 0.155769 Batch F1: 0.75
Epoch:  299        5 Batch loss: 0.156374 Batch F1: 0.8214285714285715
Epoch:  299        6 Batch loss: 0.229621 Batch F1: 0.6666666666666666
Epoch:  299        7 Batch loss: 0.178692 Batch F1: 0.7843137254901961
Epoch:  299        8 Batch loss: 0.174155 Batch F1: 0.6486486486486486
Epoch:  299        9 Batch loss: 0.177996 Batch F1: 0.6976744186046512
Epoch:  299       10 Batch loss: 0.157491 Batch F1: 0.6486486486486486
Epoch:  299       11 Batch loss: 0.203959 Batch F1: 0.5405405405405405
Epoch:  299       12 Batch loss: 0.210949 Batch F1: 0.6808510638297872
Train Avg Loss  299: 0.180278

Train Avg F1  299: 0.6921971168041128

Val Avg Loss  299: 0.182379

Val Avg F1  299:  0.6781295255132463

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 300
--------------------------------------------------------------
Epoch:  300        1 Batch loss: 0.166488 Batch F1: 0.6111111111111113
Epoch:  300        2 Batch loss: 0.174744 Batch F1: 0.7083333333333334
Epoch:  300        3 Batch loss: 0.178244 Batch F1: 0.7234042553191489
Epoch:  300        4 Batch loss: 0.169743 Batch F1: 0.7906976744186046
Epoch:  300        5 Batch loss: 0.171331 Batch F1: 0.5945945945945946
Epoch:  300        6 Batch loss: 0.165625 Batch F1: 0.7317073170731706
Epoch:  300        7 Batch loss: 0.153082 Batch F1: 0.8400000000000001
Epoch:  300        8 Batch loss: 0.197620 Batch F1: 0.7058823529411765
Epoch:  300        9 Batch loss: 0.186071 Batch F1: 0.711111111111111
Epoch:  300       10 Batch loss: 0.205313 Batch F1: 0.6222222222222222
Epoch:  300       11 Batch loss: 0.169328 Batch F1: 0.723404255319149
Epoch:  300       12 Batch loss: 0.189339 Batch F1: 0.7
Train Avg Loss  300: 0.177244

Train Avg F1  300: 0.7052056856203018

Val Avg Loss  300: 0.185961

Val Avg F1  300:  0.676562287038299

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 301
--------------------------------------------------------------
Epoch:  301        1 Batch loss: 0.161099 Batch F1: 0.7441860465116279
Epoch:  301        2 Batch loss: 0.202255 Batch F1: 0.6382978723404256
Epoch:  301        3 Batch loss: 0.167196 Batch F1: 0.717948717948718
Epoch:  301        4 Batch loss: 0.180780 Batch F1: 0.7857142857142857
Epoch:  301        5 Batch loss: 0.177512 Batch F1: 0.65
Epoch:  301        6 Batch loss: 0.161998 Batch F1: 0.7659574468085107
Epoch:  301        7 Batch loss: 0.201576 Batch F1: 0.6046511627906976
Epoch:  301        8 Batch loss: 0.192182 Batch F1: 0.6111111111111112
Epoch:  301        9 Batch loss: 0.165478 Batch F1: 0.7
Epoch:  301       10 Batch loss: 0.152937 Batch F1: 0.8085106382978724
Epoch:  301       11 Batch loss: 0.184362 Batch F1: 0.7083333333333333
Epoch:  301       12 Batch loss: 0.157563 Batch F1: 0.7804878048780488
Train Avg Loss  301: 0.175412

Train Avg F1  301: 0.7095998683112192

Val Avg Loss  301: 0.183760

Val Avg F1  301:  0.6822183418822074

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 302
--------------------------------------------------------------
Epoch:  302        1 Batch loss: 0.178575 Batch F1: 0.7199999999999999
Epoch:  302        2 Batch loss: 0.159123 Batch F1: 0.8076923076923077
Epoch:  302        3 Batch loss: 0.171798 Batch F1: 0.6956521739130435
Epoch:  302        4 Batch loss: 0.188135 Batch F1: 0.723404255319149
Epoch:  302        5 Batch loss: 0.140896 Batch F1: 0.8181818181818182
Epoch:  302        6 Batch loss: 0.170549 Batch F1: 0.6956521739130435
Epoch:  302        7 Batch loss: 0.187423 Batch F1: 0.6153846153846153
Epoch:  302        8 Batch loss: 0.195034 Batch F1: 0.6341463414634148
Epoch:  302        9 Batch loss: 0.193290 Batch F1: 0.6808510638297872
Epoch:  302       10 Batch loss: 0.150730 Batch F1: 0.7619047619047619
Epoch:  302       11 Batch loss: 0.155307 Batch F1: 0.7906976744186046
Epoch:  302       12 Batch loss: 0.172547 Batch F1: 0.6060606060606061
Train Avg Loss  302: 0.171951

Train Avg F1  302: 0.7124689826734292

Val Avg Loss  302: 0.182275

Val Avg F1  302:  0.6901669758812616

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 303
--------------------------------------------------------------
Epoch:  303        1 Batch loss: 0.168992 Batch F1: 0.7111111111111111
Epoch:  303        2 Batch loss: 0.198771 Batch F1: 0.7142857142857143
Epoch:  303        3 Batch loss: 0.153787 Batch F1: 0.7499999999999999
Epoch:  303        4 Batch loss: 0.168641 Batch F1: 0.7755102040816326
Epoch:  303        5 Batch loss: 0.177428 Batch F1: 0.6829268292682926
Epoch:  303        6 Batch loss: 0.213469 Batch F1: 0.5238095238095238
Epoch:  303        7 Batch loss: 0.150157 Batch F1: 0.7222222222222222
Epoch:  303        8 Batch loss: 0.164115 Batch F1: 0.7000000000000001
Epoch:  303        9 Batch loss: 0.176866 Batch F1: 0.6818181818181819
Epoch:  303       10 Batch loss: 0.172753 Batch F1: 0.6818181818181818
Epoch:  303       11 Batch loss: 0.167431 Batch F1: 0.7857142857142857
Epoch:  303       12 Batch loss: 0.143974 Batch F1: 0.7999999999999999
Train Avg Loss  303: 0.171365

Train Avg F1  303: 0.7107680211774289

Val Avg Loss  303: 0.182616

Val Avg F1  303:  0.6661040427206337

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 304
--------------------------------------------------------------
Epoch:  304        1 Batch loss: 0.195477 Batch F1: 0.68
Epoch:  304        2 Batch loss: 0.154683 Batch F1: 0.7755102040816326
Epoch:  304        3 Batch loss: 0.146783 Batch F1: 0.761904761904762
Epoch:  304        4 Batch loss: 0.174128 Batch F1: 0.6111111111111112
Epoch:  304        5 Batch loss: 0.167081 Batch F1: 0.8076923076923077
Epoch:  304        6 Batch loss: 0.176990 Batch F1: 0.7083333333333333
Epoch:  304        7 Batch loss: 0.197252 Batch F1: 0.6190476190476191
Epoch:  304        8 Batch loss: 0.169201 Batch F1: 0.6666666666666666
Epoch:  304        9 Batch loss: 0.164786 Batch F1: 0.6976744186046512
Epoch:  304       10 Batch loss: 0.159856 Batch F1: 0.8085106382978724
Epoch:  304       11 Batch loss: 0.196408 Batch F1: 0.6363636363636364
Epoch:  304       12 Batch loss: 0.138104 Batch F1: 0.8421052631578947
Train Avg Loss  304: 0.170062

Train Avg F1  304: 0.7179099966884573

Val Avg Loss  304: 0.182186

Val Avg F1  304:  0.6984434328773951

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 305
--------------------------------------------------------------
Epoch:  305        1 Batch loss: 0.153877 Batch F1: 0.7777777777777777
Epoch:  305        2 Batch loss: 0.170635 Batch F1: 0.7555555555555555
Epoch:  305        3 Batch loss: 0.187894 Batch F1: 0.7272727272727272
Epoch:  305        4 Batch loss: 0.190012 Batch F1: 0.6341463414634146
Epoch:  305        5 Batch loss: 0.199895 Batch F1: 0.68
Epoch:  305        6 Batch loss: 0.173854 Batch F1: 0.7142857142857143
Epoch:  305        7 Batch loss: 0.163829 Batch F1: 0.7428571428571428
Epoch:  305        8 Batch loss: 0.175892 Batch F1: 0.6666666666666666
Epoch:  305        9 Batch loss: 0.184605 Batch F1: 0.6500000000000001
Epoch:  305       10 Batch loss: 0.143223 Batch F1: 0.8095238095238095
Epoch:  305       11 Batch loss: 0.203610 Batch F1: 0.7169811320754716
Epoch:  305       12 Batch loss: 0.147117 Batch F1: 0.8205128205128205
Train Avg Loss  305: 0.174537

Train Avg F1  305: 0.7246316406659251

Val Avg Loss  305: 0.186892

Val Avg F1  305:  0.692422232050715

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 306
--------------------------------------------------------------
Epoch:  306        1 Batch loss: 0.160246 Batch F1: 0.7272727272727272
Epoch:  306        2 Batch loss: 0.144983 Batch F1: 0.8292682926829269
Epoch:  306        3 Batch loss: 0.190121 Batch F1: 0.7083333333333334
Epoch:  306        4 Batch loss: 0.170848 Batch F1: 0.7391304347826088
Epoch:  306        5 Batch loss: 0.161254 Batch F1: 0.8235294117647058
Epoch:  306        6 Batch loss: 0.161579 Batch F1: 0.7619047619047619
Epoch:  306        7 Batch loss: 0.194406 Batch F1: 0.6923076923076923
Epoch:  306        8 Batch loss: 0.184039 Batch F1: 0.6666666666666665
Epoch:  306        9 Batch loss: 0.186234 Batch F1: 0.6
Epoch:  306       10 Batch loss: 0.172803 Batch F1: 0.5714285714285715
Epoch:  306       11 Batch loss: 0.179041 Batch F1: 0.7407407407407407
Epoch:  306       12 Batch loss: 0.221580 Batch F1: 0.65
Train Avg Loss  306: 0.177261

Train Avg F1  306: 0.7092152194070612

Val Avg Loss  306: 0.183136

Val Avg F1  306:  0.680959595959596

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 307
--------------------------------------------------------------
Epoch:  307        1 Batch loss: 0.187347 Batch F1: 0.6666666666666666
Epoch:  307        2 Batch loss: 0.180158 Batch F1: 0.72
Epoch:  307        3 Batch loss: 0.168817 Batch F1: 0.6842105263157896
Epoch:  307        4 Batch loss: 0.156081 Batch F1: 0.7317073170731707
Epoch:  307        5 Batch loss: 0.152540 Batch F1: 0.6666666666666667
Epoch:  307        6 Batch loss: 0.182210 Batch F1: 0.76
Epoch:  307        7 Batch loss: 0.186887 Batch F1: 0.6792452830188678
Epoch:  307        8 Batch loss: 0.174380 Batch F1: 0.6666666666666666
Epoch:  307        9 Batch loss: 0.178236 Batch F1: 0.7083333333333334
Epoch:  307       10 Batch loss: 0.184773 Batch F1: 0.6808510638297872
Epoch:  307       11 Batch loss: 0.155410 Batch F1: 0.7916666666666667
Epoch:  307       12 Batch loss: 0.163964 Batch F1: 0.8235294117647058
Train Avg Loss  307: 0.172567

Train Avg F1  307: 0.7149619668335268

Val Avg Loss  307: 0.183799

Val Avg F1  307:  0.6857720178372352

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 308
--------------------------------------------------------------
Epoch:  308        1 Batch loss: 0.185783 Batch F1: 0.7083333333333334
Epoch:  308        2 Batch loss: 0.163907 Batch F1: 0.7916666666666666
Epoch:  308        3 Batch loss: 0.157509 Batch F1: 0.8
Epoch:  308        4 Batch loss: 0.164223 Batch F1: 0.8214285714285715
Epoch:  308        5 Batch loss: 0.160810 Batch F1: 0.717948717948718
Epoch:  308        6 Batch loss: 0.188776 Batch F1: 0.6666666666666666
Epoch:  308        7 Batch loss: 0.148391 Batch F1: 0.8
Epoch:  308        8 Batch loss: 0.212753 Batch F1: 0.6250000000000001
Epoch:  308        9 Batch loss: 0.141180 Batch F1: 0.7906976744186046
Epoch:  308       10 Batch loss: 0.210015 Batch F1: 0.6122448979591836
Epoch:  308       11 Batch loss: 0.152793 Batch F1: 0.7692307692307692
Epoch:  308       12 Batch loss: 0.171347 Batch F1: 0.717948717948718
Train Avg Loss  308: 0.171457

Train Avg F1  308: 0.7350971679667692

Val Avg Loss  308: 0.182140

Val Avg F1  308:  0.6745162070633768

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 309
--------------------------------------------------------------
Epoch:  309        1 Batch loss: 0.162688 Batch F1: 0.6111111111111112
Epoch:  309        2 Batch loss: 0.165290 Batch F1: 0.7916666666666666
Epoch:  309        3 Batch loss: 0.174199 Batch F1: 0.6666666666666666
Epoch:  309        4 Batch loss: 0.197605 Batch F1: 0.6666666666666666
Epoch:  309        5 Batch loss: 0.161596 Batch F1: 0.761904761904762
Epoch:  309        6 Batch loss: 0.170359 Batch F1: 0.7346938775510204
Epoch:  309        7 Batch loss: 0.183323 Batch F1: 0.6666666666666666
Epoch:  309        8 Batch loss: 0.172546 Batch F1: 0.693877551020408
Epoch:  309        9 Batch loss: 0.170493 Batch F1: 0.76
Epoch:  309       10 Batch loss: 0.168653 Batch F1: 0.6976744186046512
Epoch:  309       11 Batch loss: 0.188932 Batch F1: 0.7450980392156864
Epoch:  309       12 Batch loss: 0.134106 Batch F1: 0.8000000000000002
Train Avg Loss  309: 0.170816

Train Avg F1  309: 0.7163355355061922

Val Avg Loss  309: 0.182829

Val Avg F1  309:  0.6806076130824668

Optimal Val loss (Epoch 271): 0.18025681376457214

Epoch 310
--------------------------------------------------------------
Epoch:  310        1 Batch loss: 0.156036 Batch F1: 0.761904761904762
Epoch:  310        2 Batch loss: 0.154861 Batch F1: 0.7916666666666667
Epoch:  310        3 Batch loss: 0.168591 Batch F1: 0.7111111111111111
Epoch:  310        4 Batch loss: 0.190270 Batch F1: 0.5555555555555555
Epoch:  310        5 Batch loss: 0.154672 Batch F1: 0.7924528301886792
Epoch:  310        6 Batch loss: 0.159813 Batch F1: 0.761904761904762
Epoch:  310        7 Batch loss: 0.195821 Batch F1: 0.5909090909090909
Epoch:  310        8 Batch loss: 0.206235 Batch F1: 0.5365853658536586
Epoch:  310        9 Batch loss: 0.161456 Batch F1: 0.6666666666666665
Epoch:  310       10 Batch loss: 0.165659 Batch F1: 0.7083333333333333
Epoch:  310       11 Batch loss: 0.165356 Batch F1: 0.8076923076923077
Epoch:  310       12 Batch loss: 0.155485 Batch F1: 0.7999999999999999
Train Avg Loss  310: 0.169521

Train Avg F1  310: 0.7070652043155494

Val Avg Loss  310: 0.180003

Val Avg F1  310:  0.7043981481481482

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 311
--------------------------------------------------------------
Epoch:  311        1 Batch loss: 0.182193 Batch F1: 0.6
Epoch:  311        2 Batch loss: 0.148678 Batch F1: 0.8095238095238095
Epoch:  311        3 Batch loss: 0.154938 Batch F1: 0.742857142857143
Epoch:  311        4 Batch loss: 0.177588 Batch F1: 0.7083333333333334
Epoch:  311        5 Batch loss: 0.162829 Batch F1: 0.6111111111111112
Epoch:  311        6 Batch loss: 0.206122 Batch F1: 0.5777777777777778
Epoch:  311        7 Batch loss: 0.162182 Batch F1: 0.6976744186046512
Epoch:  311        8 Batch loss: 0.173341 Batch F1: 0.7346938775510204
Epoch:  311        9 Batch loss: 0.158411 Batch F1: 0.830188679245283
Epoch:  311       10 Batch loss: 0.151830 Batch F1: 0.8095238095238095
Epoch:  311       11 Batch loss: 0.199680 Batch F1: 0.6666666666666666
Epoch:  311       12 Batch loss: 0.152238 Batch F1: 0.7906976744186046
Train Avg Loss  311: 0.169169

Train Avg F1  311: 0.7149206917177676

Val Avg Loss  311: 0.182863

Val Avg F1  311:  0.7027903297458021

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 312
--------------------------------------------------------------
Epoch:  312        1 Batch loss: 0.121184 Batch F1: 0.8837209302325583
Epoch:  312        2 Batch loss: 0.178999 Batch F1: 0.782608695652174
Epoch:  312        3 Batch loss: 0.147815 Batch F1: 0.8510638297872342
Epoch:  312        4 Batch loss: 0.157068 Batch F1: 0.761904761904762
Epoch:  312        5 Batch loss: 0.185479 Batch F1: 0.7083333333333334
Epoch:  312        6 Batch loss: 0.174185 Batch F1: 0.7346938775510204
Epoch:  312        7 Batch loss: 0.158998 Batch F1: 0.76
Epoch:  312        8 Batch loss: 0.147471 Batch F1: 0.6896551724137931
Epoch:  312        9 Batch loss: 0.180337 Batch F1: 0.7
Epoch:  312       10 Batch loss: 0.220998 Batch F1: 0.5714285714285715
Epoch:  312       11 Batch loss: 0.189563 Batch F1: 0.6666666666666666
Epoch:  312       12 Batch loss: 0.201692 Batch F1: 0.5714285714285715
Train Avg Loss  312: 0.171982

Train Avg F1  312: 0.7234587008665571

Val Avg Loss  312: 0.183396

Val Avg F1  312:  0.7246268502799187

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 313
--------------------------------------------------------------
Epoch:  313        1 Batch loss: 0.159796 Batch F1: 0.8214285714285714
Epoch:  313        2 Batch loss: 0.189919 Batch F1: 0.8275862068965517
Epoch:  313        3 Batch loss: 0.150711 Batch F1: 0.787878787878788
Epoch:  313        4 Batch loss: 0.174282 Batch F1: 0.6938775510204083
Epoch:  313        5 Batch loss: 0.184804 Batch F1: 0.6666666666666666
Epoch:  313        6 Batch loss: 0.170060 Batch F1: 0.588235294117647
Epoch:  313        7 Batch loss: 0.200962 Batch F1: 0.6382978723404256
Epoch:  313        8 Batch loss: 0.189026 Batch F1: 0.6190476190476191
Epoch:  313        9 Batch loss: 0.175305 Batch F1: 0.6153846153846154
Epoch:  313       10 Batch loss: 0.163769 Batch F1: 0.782608695652174
Epoch:  313       11 Batch loss: 0.176239 Batch F1: 0.65
Epoch:  313       12 Batch loss: 0.146033 Batch F1: 0.8837209302325582
Train Avg Loss  313: 0.173409

Train Avg F1  313: 0.714561067555502

Val Avg Loss  313: 0.186839

Val Avg F1  313:  0.6642142142142142

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 314
--------------------------------------------------------------
Epoch:  314        1 Batch loss: 0.159099 Batch F1: 0.823529411764706
Epoch:  314        2 Batch loss: 0.212876 Batch F1: 0.689655172413793
Epoch:  314        3 Batch loss: 0.203163 Batch F1: 0.4571428571428572
Epoch:  314        4 Batch loss: 0.165749 Batch F1: 0.7317073170731706
Epoch:  314        5 Batch loss: 0.150255 Batch F1: 0.7999999999999999
Epoch:  314        6 Batch loss: 0.167564 Batch F1: 0.7142857142857143
Epoch:  314        7 Batch loss: 0.185524 Batch F1: 0.6808510638297872
Epoch:  314        8 Batch loss: 0.201847 Batch F1: 0.6086956521739131
Epoch:  314        9 Batch loss: 0.168499 Batch F1: 0.7916666666666666
Epoch:  314       10 Batch loss: 0.140535 Batch F1: 0.7999999999999999
Epoch:  314       11 Batch loss: 0.170157 Batch F1: 0.6842105263157896
Epoch:  314       12 Batch loss: 0.146105 Batch F1: 0.689655172413793
Train Avg Loss  314: 0.172614

Train Avg F1  314: 0.7059499628400158

Val Avg Loss  314: 0.184263

Val Avg F1  314:  0.688115282928634

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 315
--------------------------------------------------------------
Epoch:  315        1 Batch loss: 0.177388 Batch F1: 0.6666666666666666
Epoch:  315        2 Batch loss: 0.162161 Batch F1: 0.7555555555555555
Epoch:  315        3 Batch loss: 0.183618 Batch F1: 0.7111111111111111
Epoch:  315        4 Batch loss: 0.195427 Batch F1: 0.6222222222222223
Epoch:  315        5 Batch loss: 0.181475 Batch F1: 0.6153846153846153
Epoch:  315        6 Batch loss: 0.168938 Batch F1: 0.6808510638297872
Epoch:  315        7 Batch loss: 0.176471 Batch F1: 0.6923076923076923
Epoch:  315        8 Batch loss: 0.147304 Batch F1: 0.7027027027027027
Epoch:  315        9 Batch loss: 0.172757 Batch F1: 0.7391304347826088
Epoch:  315       10 Batch loss: 0.168866 Batch F1: 0.8214285714285715
Epoch:  315       11 Batch loss: 0.163300 Batch F1: 0.6976744186046512
Epoch:  315       12 Batch loss: 0.166180 Batch F1: 0.7567567567567567
Train Avg Loss  315: 0.171990

Train Avg F1  315: 0.705149317612745

Val Avg Loss  315: 0.180759

Val Avg F1  315:  0.6781974315634046

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 316
--------------------------------------------------------------
Epoch:  316        1 Batch loss: 0.151660 Batch F1: 0.7441860465116279
Epoch:  316        2 Batch loss: 0.162751 Batch F1: 0.7272727272727272
Epoch:  316        3 Batch loss: 0.179976 Batch F1: 0.6829268292682926
Epoch:  316        4 Batch loss: 0.176285 Batch F1: 0.72
Epoch:  316        5 Batch loss: 0.179738 Batch F1: 0.7169811320754718
Epoch:  316        6 Batch loss: 0.164632 Batch F1: 0.6451612903225806
Epoch:  316        7 Batch loss: 0.182608 Batch F1: 0.6666666666666666
Epoch:  316        8 Batch loss: 0.160001 Batch F1: 0.7272727272727273
Epoch:  316        9 Batch loss: 0.188354 Batch F1: 0.6
Epoch:  316       10 Batch loss: 0.141281 Batch F1: 0.8181818181818182
Epoch:  316       11 Batch loss: 0.190072 Batch F1: 0.72
Epoch:  316       12 Batch loss: 0.157121 Batch F1: 0.8333333333333334
Train Avg Loss  316: 0.169540

Train Avg F1  316: 0.7168318809087705

Val Avg Loss  316: 0.181650

Val Avg F1  316:  0.6778812974465148

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 317
--------------------------------------------------------------
Epoch:  317        1 Batch loss: 0.154006 Batch F1: 0.6857142857142857
Epoch:  317        2 Batch loss: 0.191479 Batch F1: 0.6923076923076923
Epoch:  317        3 Batch loss: 0.152933 Batch F1: 0.717948717948718
Epoch:  317        4 Batch loss: 0.151532 Batch F1: 0.7441860465116279
Epoch:  317        5 Batch loss: 0.180511 Batch F1: 0.7083333333333334
Epoch:  317        6 Batch loss: 0.154122 Batch F1: 0.7619047619047619
Epoch:  317        7 Batch loss: 0.167143 Batch F1: 0.711111111111111
Epoch:  317        8 Batch loss: 0.135603 Batch F1: 0.8205128205128205
Epoch:  317        9 Batch loss: 0.184859 Batch F1: 0.6666666666666666
Epoch:  317       10 Batch loss: 0.194189 Batch F1: 0.7307692307692306
Epoch:  317       11 Batch loss: 0.189204 Batch F1: 0.6923076923076923
Epoch:  317       12 Batch loss: 0.178678 Batch F1: 0.6842105263157895
Train Avg Loss  317: 0.169522

Train Avg F1  317: 0.717997740450311

Val Avg Loss  317: 0.181631

Val Avg F1  317:  0.7015802031854705

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 318
--------------------------------------------------------------
Epoch:  318        1 Batch loss: 0.163134 Batch F1: 0.8235294117647058
Epoch:  318        2 Batch loss: 0.131197 Batch F1: 0.8292682926829269
Epoch:  318        3 Batch loss: 0.163940 Batch F1: 0.7142857142857143
Epoch:  318        4 Batch loss: 0.165132 Batch F1: 0.5945945945945946
Epoch:  318        5 Batch loss: 0.180012 Batch F1: 0.6842105263157895
Epoch:  318        6 Batch loss: 0.175666 Batch F1: 0.6486486486486486
Epoch:  318        7 Batch loss: 0.176749 Batch F1: 0.6938775510204083
Epoch:  318        8 Batch loss: 0.192050 Batch F1: 0.6190476190476191
Epoch:  318        9 Batch loss: 0.187170 Batch F1: 0.6808510638297872
Epoch:  318       10 Batch loss: 0.142681 Batch F1: 0.8363636363636364
Epoch:  318       11 Batch loss: 0.172884 Batch F1: 0.7450980392156864
Epoch:  318       12 Batch loss: 0.175609 Batch F1: 0.7142857142857143
Train Avg Loss  318: 0.168852

Train Avg F1  318: 0.7153384010046028

Val Avg Loss  318: 0.180052

Val Avg F1  318:  0.6838434739330597

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 319
--------------------------------------------------------------
Epoch:  319        1 Batch loss: 0.179811 Batch F1: 0.631578947368421
Epoch:  319        2 Batch loss: 0.165503 Batch F1: 0.6511627906976744
Epoch:  319        3 Batch loss: 0.176136 Batch F1: 0.7931034482758621
Epoch:  319        4 Batch loss: 0.181715 Batch F1: 0.6842105263157895
Epoch:  319        5 Batch loss: 0.155447 Batch F1: 0.7916666666666666
Epoch:  319        6 Batch loss: 0.181228 Batch F1: 0.693877551020408
Epoch:  319        7 Batch loss: 0.165345 Batch F1: 0.76
Epoch:  319        8 Batch loss: 0.147622 Batch F1: 0.8085106382978724
Epoch:  319        9 Batch loss: 0.165828 Batch F1: 0.6829268292682926
Epoch:  319       10 Batch loss: 0.207290 Batch F1: 0.4878048780487805
Epoch:  319       11 Batch loss: 0.162229 Batch F1: 0.7317073170731706
Epoch:  319       12 Batch loss: 0.180546 Batch F1: 0.7222222222222222
Train Avg Loss  319: 0.172392

Train Avg F1  319: 0.7032309846045967

Val Avg Loss  319: 0.183684

Val Avg F1  319:  0.6918853194292602

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 320
--------------------------------------------------------------
Epoch:  320        1 Batch loss: 0.196823 Batch F1: 0.6190476190476191
Epoch:  320        2 Batch loss: 0.174913 Batch F1: 0.6808510638297872
Epoch:  320        3 Batch loss: 0.157226 Batch F1: 0.7692307692307692
Epoch:  320        4 Batch loss: 0.158535 Batch F1: 0.8636363636363636
Epoch:  320        5 Batch loss: 0.140332 Batch F1: 0.9259259259259259
Epoch:  320        6 Batch loss: 0.170897 Batch F1: 0.8095238095238095
Epoch:  320        7 Batch loss: 0.155024 Batch F1: 0.8
Epoch:  320        8 Batch loss: 0.181626 Batch F1: 0.76
Epoch:  320        9 Batch loss: 0.156003 Batch F1: 0.7843137254901961
Epoch:  320       10 Batch loss: 0.238017 Batch F1: 0.5454545454545454
Epoch:  320       11 Batch loss: 0.170832 Batch F1: 0.7555555555555555
Epoch:  320       12 Batch loss: 0.194554 Batch F1: 0.6666666666666666
Train Avg Loss  320: 0.174565

Train Avg F1  320: 0.7483505036967698

Val Avg Loss  320: 0.186583

Val Avg F1  320:  0.6639914054600606

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 321
--------------------------------------------------------------
Epoch:  321        1 Batch loss: 0.151987 Batch F1: 0.8163265306122449
Epoch:  321        2 Batch loss: 0.170858 Batch F1: 0.6486486486486486
Epoch:  321        3 Batch loss: 0.173601 Batch F1: 0.7547169811320755
Epoch:  321        4 Batch loss: 0.191264 Batch F1: 0.5789473684210527
Epoch:  321        5 Batch loss: 0.197561 Batch F1: 0.5714285714285713
Epoch:  321        6 Batch loss: 0.168599 Batch F1: 0.7924528301886793
Epoch:  321        7 Batch loss: 0.183258 Batch F1: 0.631578947368421
Epoch:  321        8 Batch loss: 0.141317 Batch F1: 0.8421052631578947
Epoch:  321        9 Batch loss: 0.192669 Batch F1: 0.7037037037037037
Epoch:  321       10 Batch loss: 0.174018 Batch F1: 0.6976744186046512
Epoch:  321       11 Batch loss: 0.189677 Batch F1: 0.6976744186046512
Epoch:  321       12 Batch loss: 0.159216 Batch F1: 0.7999999999999999
Train Avg Loss  321: 0.174502

Train Avg F1  321: 0.7112714734892163

Val Avg Loss  321: 0.182246

Val Avg F1  321:  0.7083420411006618

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 322
--------------------------------------------------------------
Epoch:  322        1 Batch loss: 0.177619 Batch F1: 0.7142857142857143
Epoch:  322        2 Batch loss: 0.151569 Batch F1: 0.761904761904762
Epoch:  322        3 Batch loss: 0.163306 Batch F1: 0.7547169811320755
Epoch:  322        4 Batch loss: 0.135028 Batch F1: 0.8372093023255814
Epoch:  322        5 Batch loss: 0.195320 Batch F1: 0.68
Epoch:  322        6 Batch loss: 0.224408 Batch F1: 0.4210526315789474
Epoch:  322        7 Batch loss: 0.185978 Batch F1: 0.693877551020408
Epoch:  322        8 Batch loss: 0.154692 Batch F1: 0.625
Epoch:  322        9 Batch loss: 0.165198 Batch F1: 0.7826086956521738
Epoch:  322       10 Batch loss: 0.161172 Batch F1: 0.8214285714285715
Epoch:  322       11 Batch loss: 0.195370 Batch F1: 0.6956521739130435
Epoch:  322       12 Batch loss: 0.186770 Batch F1: 0.606060606060606
Train Avg Loss  322: 0.174702

Train Avg F1  322: 0.6994830824418236

Val Avg Loss  322: 0.183375

Val Avg F1  322:  0.6830331618067468

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 323
--------------------------------------------------------------
Epoch:  323        1 Batch loss: 0.162942 Batch F1: 0.7441860465116279
Epoch:  323        2 Batch loss: 0.172140 Batch F1: 0.8163265306122449
Epoch:  323        3 Batch loss: 0.170181 Batch F1: 0.7391304347826088
Epoch:  323        4 Batch loss: 0.192360 Batch F1: 0.6666666666666666
Epoch:  323        5 Batch loss: 0.128110 Batch F1: 0.8500000000000001
Epoch:  323        6 Batch loss: 0.157897 Batch F1: 0.7391304347826085
Epoch:  323        7 Batch loss: 0.181191 Batch F1: 0.65
Epoch:  323        8 Batch loss: 0.164794 Batch F1: 0.6666666666666666
Epoch:  323        9 Batch loss: 0.172803 Batch F1: 0.6666666666666666
Epoch:  323       10 Batch loss: 0.198867 Batch F1: 0.6530612244897959
Epoch:  323       11 Batch loss: 0.168710 Batch F1: 0.7083333333333333
Epoch:  323       12 Batch loss: 0.189897 Batch F1: 0.6060606060606061
Train Avg Loss  323: 0.171658

Train Avg F1  323: 0.7088523842144022

Val Avg Loss  323: 0.182385

Val Avg F1  323:  0.71041132212735

Optimal Val loss (Epoch 310): 0.18000267446041107

Epoch 324
--------------------------------------------------------------
Epoch:  324        1 Batch loss: 0.182938 Batch F1: 0.6956521739130435
Epoch:  324        2 Batch loss: 0.172078 Batch F1: 0.7407407407407408
Epoch:  324        3 Batch loss: 0.153939 Batch F1: 0.7368421052631577
Epoch:  324        4 Batch loss: 0.164214 Batch F1: 0.7142857142857143
Epoch:  324        5 Batch loss: 0.165500 Batch F1: 0.7499999999999999
Epoch:  324        6 Batch loss: 0.141432 Batch F1: 0.7692307692307692
Epoch:  324        7 Batch loss: 0.186246 Batch F1: 0.7586206896551724
Epoch:  324        8 Batch loss: 0.184683 Batch F1: 0.6
Epoch:  324        9 Batch loss: 0.162881 Batch F1: 0.7027027027027026
Epoch:  324       10 Batch loss: 0.182453 Batch F1: 0.6
Epoch:  324       11 Batch loss: 0.158067 Batch F1: 0.7692307692307692
Epoch:  324       12 Batch loss: 0.175984 Batch F1: 0.8372093023255814
Train Avg Loss  324: 0.169201

Train Avg F1  324: 0.7228762472789709

Val Avg Loss  324: 0.179668

Val Avg F1  324:  0.6988503439798569

Optimal Val loss (Epoch 324): 0.17966831475496292

Epoch 325
--------------------------------------------------------------
Epoch:  325        1 Batch loss: 0.183852 Batch F1: 0.6666666666666666
Epoch:  325        2 Batch loss: 0.172762 Batch F1: 0.7755102040816326
Epoch:  325        3 Batch loss: 0.177886 Batch F1: 0.7547169811320754
Epoch:  325        4 Batch loss: 0.217457 Batch F1: 0.6530612244897959
Epoch:  325        5 Batch loss: 0.181932 Batch F1: 0.6666666666666667
Epoch:  325        6 Batch loss: 0.169069 Batch F1: 0.7555555555555555
Epoch:  325        7 Batch loss: 0.175178 Batch F1: 0.6666666666666666
Epoch:  325        8 Batch loss: 0.190575 Batch F1: 0.6341463414634146
Epoch:  325        9 Batch loss: 0.154228 Batch F1: 0.782608695652174
Epoch:  325       10 Batch loss: 0.165433 Batch F1: 0.7826086956521738
Epoch:  325       11 Batch loss: 0.158151 Batch F1: 0.7027027027027027
Epoch:  325       12 Batch loss: 0.152255 Batch F1: 0.8108108108108107
Train Avg Loss  325: 0.174898

Train Avg F1  325: 0.7209767676283613

Val Avg Loss  325: 0.185529

Val Avg F1  325:  0.6874770843296669

Optimal Val loss (Epoch 324): 0.17966831475496292

Epoch 326
--------------------------------------------------------------
Epoch:  326        1 Batch loss: 0.158776 Batch F1: 0.7755102040816326
Epoch:  326        2 Batch loss: 0.166111 Batch F1: 0.6666666666666666
Epoch:  326        3 Batch loss: 0.160853 Batch F1: 0.7999999999999999
Epoch:  326        4 Batch loss: 0.181367 Batch F1: 0.5714285714285715
Epoch:  326        5 Batch loss: 0.157184 Batch F1: 0.76
Epoch:  326        6 Batch loss: 0.181793 Batch F1: 0.8148148148148148
Epoch:  326        7 Batch loss: 0.166867 Batch F1: 0.8
Epoch:  326        8 Batch loss: 0.178551 Batch F1: 0.711111111111111
Epoch:  326        9 Batch loss: 0.172661 Batch F1: 0.6818181818181818
Epoch:  326       10 Batch loss: 0.217747 Batch F1: 0.5365853658536585
Epoch:  326       11 Batch loss: 0.183536 Batch F1: 0.6341463414634146
Epoch:  326       12 Batch loss: 0.164677 Batch F1: 0.7647058823529413
Train Avg Loss  326: 0.174177

Train Avg F1  326: 0.7097322616325826

Val Avg Loss  326: 0.185273

Val Avg F1  326:  0.670572450805009

Optimal Val loss (Epoch 324): 0.17966831475496292

Epoch 327
--------------------------------------------------------------
Epoch:  327        1 Batch loss: 0.152486 Batch F1: 0.7142857142857143
Epoch:  327        2 Batch loss: 0.162044 Batch F1: 0.7499999999999999
Epoch:  327        3 Batch loss: 0.177047 Batch F1: 0.6666666666666666
Epoch:  327        4 Batch loss: 0.201690 Batch F1: 0.6046511627906977
Epoch:  327        5 Batch loss: 0.163599 Batch F1: 0.7659574468085107
Epoch:  327        6 Batch loss: 0.154305 Batch F1: 0.782608695652174
Epoch:  327        7 Batch loss: 0.196963 Batch F1: 0.6521739130434783
Epoch:  327        8 Batch loss: 0.156518 Batch F1: 0.7027027027027027
Epoch:  327        9 Batch loss: 0.150398 Batch F1: 0.7906976744186046
Epoch:  327       10 Batch loss: 0.162974 Batch F1: 0.6842105263157895
Epoch:  327       11 Batch loss: 0.209150 Batch F1: 0.7241379310344829
Epoch:  327       12 Batch loss: 0.168562 Batch F1: 0.7317073170731708
Train Avg Loss  327: 0.171311

Train Avg F1  327: 0.714149979232666

Val Avg Loss  327: 0.182322

Val Avg F1  327:  0.6957312925170067

Optimal Val loss (Epoch 324): 0.17966831475496292

Epoch 328
--------------------------------------------------------------
Epoch:  328        1 Batch loss: 0.177680 Batch F1: 0.7199999999999999
Epoch:  328        2 Batch loss: 0.198188 Batch F1: 0.6808510638297872
Epoch:  328        3 Batch loss: 0.161792 Batch F1: 0.7500000000000001
Epoch:  328        4 Batch loss: 0.169693 Batch F1: 0.8
Epoch:  328        5 Batch loss: 0.185871 Batch F1: 0.6363636363636364
Epoch:  328        6 Batch loss: 0.151572 Batch F1: 0.742857142857143
Epoch:  328        7 Batch loss: 0.169823 Batch F1: 0.6829268292682927
Epoch:  328        8 Batch loss: 0.172662 Batch F1: 0.6500000000000001
Epoch:  328        9 Batch loss: 0.186069 Batch F1: 0.7169811320754718
Epoch:  328       10 Batch loss: 0.150079 Batch F1: 0.7999999999999999
Epoch:  328       11 Batch loss: 0.170841 Batch F1: 0.7272727272727273
Epoch:  328       12 Batch loss: 0.164371 Batch F1: 0.689655172413793
Train Avg Loss  328: 0.171553

Train Avg F1  328: 0.716408975340071

Val Avg Loss  328: 0.181660

Val Avg F1  328:  0.6859259259259259

Optimal Val loss (Epoch 324): 0.17966831475496292

Epoch 329
--------------------------------------------------------------
Epoch:  329        1 Batch loss: 0.144022 Batch F1: 0.8399999999999999
Epoch:  329        2 Batch loss: 0.155515 Batch F1: 0.75
Epoch:  329        3 Batch loss: 0.162258 Batch F1: 0.6976744186046512
Epoch:  329        4 Batch loss: 0.169784 Batch F1: 0.7659574468085107
Epoch:  329        5 Batch loss: 0.187782 Batch F1: 0.6341463414634146
Epoch:  329        6 Batch loss: 0.174748 Batch F1: 0.7234042553191489
Epoch:  329        7 Batch loss: 0.161145 Batch F1: 0.7
Epoch:  329        8 Batch loss: 0.167672 Batch F1: 0.6976744186046512
Epoch:  329        9 Batch loss: 0.220355 Batch F1: 0.5116279069767442
Epoch:  329       10 Batch loss: 0.183473 Batch F1: 0.693877551020408
Epoch:  329       11 Batch loss: 0.166007 Batch F1: 0.7200000000000001
Epoch:  329       12 Batch loss: 0.144662 Batch F1: 0.8125
Train Avg Loss  329: 0.169785

Train Avg F1  329: 0.7122385282331273

Val Avg Loss  329: 0.183324

Val Avg F1  329:  0.6854139391605699

Optimal Val loss (Epoch 324): 0.17966831475496292

Epoch 330
--------------------------------------------------------------
Epoch:  330        1 Batch loss: 0.156135 Batch F1: 0.7755102040816326
Epoch:  330        2 Batch loss: 0.184178 Batch F1: 0.7692307692307693
Epoch:  330        3 Batch loss: 0.164666 Batch F1: 0.7450980392156864
Epoch:  330        4 Batch loss: 0.167469 Batch F1: 0.6976744186046512
Epoch:  330        5 Batch loss: 0.177643 Batch F1: 0.6829268292682926
Epoch:  330        6 Batch loss: 0.166508 Batch F1: 0.7368421052631579
Epoch:  330        7 Batch loss: 0.152292 Batch F1: 0.7916666666666666
Epoch:  330        8 Batch loss: 0.199631 Batch F1: 0.693877551020408
Epoch:  330        9 Batch loss: 0.165343 Batch F1: 0.7142857142857143
Epoch:  330       10 Batch loss: 0.204129 Batch F1: 0.64
Epoch:  330       11 Batch loss: 0.139618 Batch F1: 0.742857142857143
Epoch:  330       12 Batch loss: 0.180576 Batch F1: 0.6857142857142857
Train Avg Loss  330: 0.171516

Train Avg F1  330: 0.7229736438507005

Val Avg Loss  330: 0.179544

Val Avg F1  330:  0.6640466997609854

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 331
--------------------------------------------------------------
Epoch:  331        1 Batch loss: 0.135292 Batch F1: 0.7906976744186046
Epoch:  331        2 Batch loss: 0.186108 Batch F1: 0.7142857142857143
Epoch:  331        3 Batch loss: 0.194386 Batch F1: 0.6363636363636364
Epoch:  331        4 Batch loss: 0.190261 Batch F1: 0.7450980392156864
Epoch:  331        5 Batch loss: 0.162725 Batch F1: 0.8771929824561403
Epoch:  331        6 Batch loss: 0.188895 Batch F1: 0.7755102040816326
Epoch:  331        7 Batch loss: 0.181241 Batch F1: 0.7058823529411765
Epoch:  331        8 Batch loss: 0.173922 Batch F1: 0.7391304347826088
Epoch:  331        9 Batch loss: 0.173485 Batch F1: 0.6842105263157895
Epoch:  331       10 Batch loss: 0.145417 Batch F1: 0.7692307692307692
Epoch:  331       11 Batch loss: 0.201724 Batch F1: 0.6666666666666666
Epoch:  331       12 Batch loss: 0.142572 Batch F1: 0.7857142857142856
Train Avg Loss  331: 0.173003

Train Avg F1  331: 0.7408319405393925

Val Avg Loss  331: 0.184163

Val Avg F1  331:  0.693279340721796

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 332
--------------------------------------------------------------
Epoch:  332        1 Batch loss: 0.165408 Batch F1: 0.7924528301886792
Epoch:  332        2 Batch loss: 0.190543 Batch F1: 0.4375
Epoch:  332        3 Batch loss: 0.169297 Batch F1: 0.7555555555555555
Epoch:  332        4 Batch loss: 0.195918 Batch F1: 0.6666666666666667
Epoch:  332        5 Batch loss: 0.137726 Batch F1: 0.8510638297872339
Epoch:  332        6 Batch loss: 0.187326 Batch F1: 0.6060606060606061
Epoch:  332        7 Batch loss: 0.149172 Batch F1: 0.6896551724137931
Epoch:  332        8 Batch loss: 0.182863 Batch F1: 0.6111111111111112
Epoch:  332        9 Batch loss: 0.193653 Batch F1: 0.6511627906976744
Epoch:  332       10 Batch loss: 0.192436 Batch F1: 0.7457627118644068
Epoch:  332       11 Batch loss: 0.180647 Batch F1: 0.6363636363636364
Epoch:  332       12 Batch loss: 0.181222 Batch F1: 0.7916666666666666
Train Avg Loss  332: 0.177184

Train Avg F1  332: 0.6862517981146691

Val Avg Loss  332: 0.192533

Val Avg F1  332:  0.7201816911250873

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 333
--------------------------------------------------------------
Epoch:  333        1 Batch loss: 0.162521 Batch F1: 0.7843137254901961
Epoch:  333        2 Batch loss: 0.171803 Batch F1: 0.8444444444444444
Epoch:  333        3 Batch loss: 0.155786 Batch F1: 0.7096774193548386
Epoch:  333        4 Batch loss: 0.180617 Batch F1: 0.7346938775510203
Epoch:  333        5 Batch loss: 0.201258 Batch F1: 0.6250000000000001
Epoch:  333        6 Batch loss: 0.206049 Batch F1: 0.6363636363636364
Epoch:  333        7 Batch loss: 0.175357 Batch F1: 0.7142857142857143
Epoch:  333        8 Batch loss: 0.196974 Batch F1: 0.6829268292682927
Epoch:  333        9 Batch loss: 0.150593 Batch F1: 0.761904761904762
Epoch:  333       10 Batch loss: 0.177071 Batch F1: 0.7924528301886793
Epoch:  333       11 Batch loss: 0.195833 Batch F1: 0.6538461538461539
Epoch:  333       12 Batch loss: 0.179815 Batch F1: 0.631578947368421
Train Avg Loss  333: 0.179473

Train Avg F1  333: 0.7142906950055132

Val Avg Loss  333: 0.187152

Val Avg F1  333:  0.6446318719828938

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 334
--------------------------------------------------------------
Epoch:  334        1 Batch loss: 0.162823 Batch F1: 0.8
Epoch:  334        2 Batch loss: 0.199948 Batch F1: 0.6415094339622641
Epoch:  334        3 Batch loss: 0.175047 Batch F1: 0.6666666666666667
Epoch:  334        4 Batch loss: 0.187742 Batch F1: 0.711864406779661
Epoch:  334        5 Batch loss: 0.204680 Batch F1: 0.7719298245614035
Epoch:  334        6 Batch loss: 0.179422 Batch F1: 0.7441860465116279
Epoch:  334        7 Batch loss: 0.173609 Batch F1: 0.45161290322580644
Epoch:  334        8 Batch loss: 0.189463 Batch F1: 0.611111111111111
Epoch:  334        9 Batch loss: 0.163291 Batch F1: 0.7027027027027027
Epoch:  334       10 Batch loss: 0.174271 Batch F1: 0.7391304347826085
Epoch:  334       11 Batch loss: 0.179812 Batch F1: 0.7142857142857143
Epoch:  334       12 Batch loss: 0.192138 Batch F1: 0.7027027027027027
Train Avg Loss  334: 0.181854

Train Avg F1  334: 0.6881418289410224

Val Avg Loss  334: 0.191645

Val Avg F1  334:  0.6758744358478401

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 335
--------------------------------------------------------------
Epoch:  335        1 Batch loss: 0.193750 Batch F1: 0.6341463414634146
Epoch:  335        2 Batch loss: 0.177510 Batch F1: 0.7
Epoch:  335        3 Batch loss: 0.161885 Batch F1: 0.8749999999999999
Epoch:  335        4 Batch loss: 0.201923 Batch F1: 0.65
Epoch:  335        5 Batch loss: 0.159476 Batch F1: 0.8095238095238095
Epoch:  335        6 Batch loss: 0.189799 Batch F1: 0.7457627118644068
Epoch:  335        7 Batch loss: 0.172148 Batch F1: 0.7111111111111111
Epoch:  335        8 Batch loss: 0.162857 Batch F1: 0.717948717948718
Epoch:  335        9 Batch loss: 0.216448 Batch F1: 0.5116279069767442
Epoch:  335       10 Batch loss: 0.179561 Batch F1: 0.793103448275862
Epoch:  335       11 Batch loss: 0.170448 Batch F1: 0.7272727272727272
Epoch:  335       12 Batch loss: 0.198442 Batch F1: 0.5454545454545455
Train Avg Loss  335: 0.182021

Train Avg F1  335: 0.7017459433242782

Val Avg Loss  335: 0.186793

Val Avg F1  335:  0.6673202614379085

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 336
--------------------------------------------------------------
Epoch:  336        1 Batch loss: 0.165182 Batch F1: 0.7500000000000001
Epoch:  336        2 Batch loss: 0.179907 Batch F1: 0.6818181818181818
Epoch:  336        3 Batch loss: 0.143445 Batch F1: 0.8
Epoch:  336        4 Batch loss: 0.180862 Batch F1: 0.5789473684210527
Epoch:  336        5 Batch loss: 0.196152 Batch F1: 0.6399999999999999
Epoch:  336        6 Batch loss: 0.168842 Batch F1: 0.68
Epoch:  336        7 Batch loss: 0.203347 Batch F1: 0.7719298245614036
Epoch:  336        8 Batch loss: 0.170947 Batch F1: 0.6818181818181818
Epoch:  336        9 Batch loss: 0.173519 Batch F1: 0.7142857142857143
Epoch:  336       10 Batch loss: 0.199100 Batch F1: 0.6521739130434783
Epoch:  336       11 Batch loss: 0.173963 Batch F1: 0.6666666666666666
Epoch:  336       12 Batch loss: 0.157303 Batch F1: 0.7804878048780488
Train Avg Loss  336: 0.176047

Train Avg F1  336: 0.6998439712910606

Val Avg Loss  336: 0.184381

Val Avg F1  336:  0.6783824640967498

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 337
--------------------------------------------------------------
Epoch:  337        1 Batch loss: 0.205040 Batch F1: 0.5909090909090908
Epoch:  337        2 Batch loss: 0.176413 Batch F1: 0.6829268292682926
Epoch:  337        3 Batch loss: 0.152268 Batch F1: 0.761904761904762
Epoch:  337        4 Batch loss: 0.162847 Batch F1: 0.7499999999999999
Epoch:  337        5 Batch loss: 0.196948 Batch F1: 0.7058823529411765
Epoch:  337        6 Batch loss: 0.194661 Batch F1: 0.6923076923076923
Epoch:  337        7 Batch loss: 0.198362 Batch F1: 0.711864406779661
Epoch:  337        8 Batch loss: 0.180456 Batch F1: 0.7441860465116279
Epoch:  337        9 Batch loss: 0.167845 Batch F1: 0.7317073170731707
Epoch:  337       10 Batch loss: 0.148555 Batch F1: 0.7727272727272727
Epoch:  337       11 Batch loss: 0.138739 Batch F1: 0.7647058823529411
Epoch:  337       12 Batch loss: 0.147938 Batch F1: 0.8108108108108109
Train Avg Loss  337: 0.172506

Train Avg F1  337: 0.7266610386322082

Val Avg Loss  337: 0.185481

Val Avg F1  337:  0.6665897177865263

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 338
--------------------------------------------------------------
Epoch:  338        1 Batch loss: 0.178369 Batch F1: 0.6829268292682926
Epoch:  338        2 Batch loss: 0.163787 Batch F1: 0.8
Epoch:  338        3 Batch loss: 0.155553 Batch F1: 0.75
Epoch:  338        4 Batch loss: 0.173469 Batch F1: 0.7111111111111111
Epoch:  338        5 Batch loss: 0.175132 Batch F1: 0.7796610169491526
Epoch:  338        6 Batch loss: 0.222780 Batch F1: 0.4878048780487805
Epoch:  338        7 Batch loss: 0.172411 Batch F1: 0.6666666666666666
Epoch:  338        8 Batch loss: 0.158843 Batch F1: 0.7027027027027027
Epoch:  338        9 Batch loss: 0.160423 Batch F1: 0.7499999999999999
Epoch:  338       10 Batch loss: 0.160369 Batch F1: 0.761904761904762
Epoch:  338       11 Batch loss: 0.184269 Batch F1: 0.7111111111111111
Epoch:  338       12 Batch loss: 0.156918 Batch F1: 0.7222222222222223
Train Avg Loss  338: 0.171860

Train Avg F1  338: 0.7105092749987335

Val Avg Loss  338: 0.185134

Val Avg F1  338:  0.672239033085518

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 339
--------------------------------------------------------------
Epoch:  339        1 Batch loss: 0.159710 Batch F1: 0.8085106382978723
Epoch:  339        2 Batch loss: 0.134285 Batch F1: 0.875
Epoch:  339        3 Batch loss: 0.169671 Batch F1: 0.6666666666666667
Epoch:  339        4 Batch loss: 0.188768 Batch F1: 0.68
Epoch:  339        5 Batch loss: 0.178600 Batch F1: 0.6341463414634146
Epoch:  339        6 Batch loss: 0.181216 Batch F1: 0.7083333333333334
Epoch:  339        7 Batch loss: 0.142734 Batch F1: 0.8936170212765957
Epoch:  339        8 Batch loss: 0.169556 Batch F1: 0.7441860465116279
Epoch:  339        9 Batch loss: 0.171794 Batch F1: 0.6666666666666666
Epoch:  339       10 Batch loss: 0.201700 Batch F1: 0.5128205128205129
Epoch:  339       11 Batch loss: 0.178868 Batch F1: 0.6
Epoch:  339       12 Batch loss: 0.176734 Batch F1: 0.7555555555555555
Train Avg Loss  339: 0.171136

Train Avg F1  339: 0.7121252318826872

Val Avg Loss  339: 0.185126

Val Avg F1  339:  0.6698560182880741

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 340
--------------------------------------------------------------
Epoch:  340        1 Batch loss: 0.175604 Batch F1: 0.631578947368421
Epoch:  340        2 Batch loss: 0.167646 Batch F1: 0.7142857142857143
Epoch:  340        3 Batch loss: 0.155883 Batch F1: 0.7499999999999999
Epoch:  340        4 Batch loss: 0.147968 Batch F1: 0.7999999999999999
Epoch:  340        5 Batch loss: 0.163749 Batch F1: 0.7692307692307692
Epoch:  340        6 Batch loss: 0.225217 Batch F1: 0.5531914893617021
Epoch:  340        7 Batch loss: 0.166569 Batch F1: 0.6829268292682926
Epoch:  340        8 Batch loss: 0.169948 Batch F1: 0.6666666666666666
Epoch:  340        9 Batch loss: 0.150648 Batch F1: 0.761904761904762
Epoch:  340       10 Batch loss: 0.201207 Batch F1: 0.6666666666666666
Epoch:  340       11 Batch loss: 0.172942 Batch F1: 0.6666666666666666
Epoch:  340       12 Batch loss: 0.148269 Batch F1: 0.8695652173913043
Train Avg Loss  340: 0.170471

Train Avg F1  340: 0.7110569774009138

Val Avg Loss  340: 0.180963

Val Avg F1  340:  0.7077670278637771

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 341
--------------------------------------------------------------
Epoch:  341        1 Batch loss: 0.170024 Batch F1: 0.7346938775510203
Epoch:  341        2 Batch loss: 0.181676 Batch F1: 0.7307692307692306
Epoch:  341        3 Batch loss: 0.199182 Batch F1: 0.6341463414634146
Epoch:  341        4 Batch loss: 0.174544 Batch F1: 0.631578947368421
Epoch:  341        5 Batch loss: 0.131083 Batch F1: 0.851063829787234
Epoch:  341        6 Batch loss: 0.173083 Batch F1: 0.7555555555555555
Epoch:  341        7 Batch loss: 0.164632 Batch F1: 0.711111111111111
Epoch:  341        8 Batch loss: 0.152879 Batch F1: 0.7058823529411765
Epoch:  341        9 Batch loss: 0.152740 Batch F1: 0.8620689655172413
Epoch:  341       10 Batch loss: 0.192053 Batch F1: 0.6
Epoch:  341       11 Batch loss: 0.179744 Batch F1: 0.7346938775510204
Epoch:  341       12 Batch loss: 0.178131 Batch F1: 0.5882352941176471
Train Avg Loss  341: 0.170814

Train Avg F1  341: 0.7116499486444227

Val Avg Loss  341: 0.181260

Val Avg F1  341:  0.6799953095684803

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 342
--------------------------------------------------------------
Epoch:  342        1 Batch loss: 0.194133 Batch F1: 0.6829268292682927
Epoch:  342        2 Batch loss: 0.195735 Batch F1: 0.5128205128205129
Epoch:  342        3 Batch loss: 0.170905 Batch F1: 0.6956521739130435
Epoch:  342        4 Batch loss: 0.134563 Batch F1: 0.8108108108108107
Epoch:  342        5 Batch loss: 0.189812 Batch F1: 0.6521739130434783
Epoch:  342        6 Batch loss: 0.141757 Batch F1: 0.8000000000000002
Epoch:  342        7 Batch loss: 0.166642 Batch F1: 0.8148148148148148
Epoch:  342        8 Batch loss: 0.186981 Batch F1: 0.68
Epoch:  342        9 Batch loss: 0.164485 Batch F1: 0.8
Epoch:  342       10 Batch loss: 0.139641 Batch F1: 0.7368421052631577
Epoch:  342       11 Batch loss: 0.197140 Batch F1: 0.7234042553191489
Epoch:  342       12 Batch loss: 0.183575 Batch F1: 0.7368421052631577
Train Avg Loss  342: 0.172114

Train Avg F1  342: 0.7205239600430348

Val Avg Loss  342: 0.184959

Val Avg F1  342:  0.6852797202797203

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 343
--------------------------------------------------------------
Epoch:  343        1 Batch loss: 0.169704 Batch F1: 0.7547169811320756
Epoch:  343        2 Batch loss: 0.163480 Batch F1: 0.625
Epoch:  343        3 Batch loss: 0.187034 Batch F1: 0.5405405405405405
Epoch:  343        4 Batch loss: 0.215469 Batch F1: 0.6046511627906976
Epoch:  343        5 Batch loss: 0.167272 Batch F1: 0.7567567567567568
Epoch:  343        6 Batch loss: 0.150607 Batch F1: 0.7804878048780488
Epoch:  343        7 Batch loss: 0.195669 Batch F1: 0.5789473684210527
Epoch:  343        8 Batch loss: 0.137350 Batch F1: 0.9
Epoch:  343        9 Batch loss: 0.184109 Batch F1: 0.76
Epoch:  343       10 Batch loss: 0.189298 Batch F1: 0.6792452830188679
Epoch:  343       11 Batch loss: 0.202476 Batch F1: 0.6415094339622641
Epoch:  343       12 Batch loss: 0.186229 Batch F1: 0.6666666666666666
Train Avg Loss  343: 0.179058

Train Avg F1  343: 0.6907101665139143

Val Avg Loss  343: 0.186715

Val Avg F1  343:  0.692894900109293

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 344
--------------------------------------------------------------
Epoch:  344        1 Batch loss: 0.176639 Batch F1: 0.7234042553191491
Epoch:  344        2 Batch loss: 0.170699 Batch F1: 0.7692307692307692
Epoch:  344        3 Batch loss: 0.176375 Batch F1: 0.7692307692307692
Epoch:  344        4 Batch loss: 0.170276 Batch F1: 0.7391304347826088
Epoch:  344        5 Batch loss: 0.179589 Batch F1: 0.7692307692307693
Epoch:  344        6 Batch loss: 0.155543 Batch F1: 0.8571428571428572
Epoch:  344        7 Batch loss: 0.187626 Batch F1: 0.7111111111111111
Epoch:  344        8 Batch loss: 0.178784 Batch F1: 0.6666666666666667
Epoch:  344        9 Batch loss: 0.204740 Batch F1: 0.5714285714285713
Epoch:  344       10 Batch loss: 0.182986 Batch F1: 0.5714285714285715
Epoch:  344       11 Batch loss: 0.147557 Batch F1: 0.7999999999999999
Epoch:  344       12 Batch loss: 0.165252 Batch F1: 0.6206896551724139
Train Avg Loss  344: 0.174672

Train Avg F1  344: 0.7140578692286881

Val Avg Loss  344: 0.185522

Val Avg F1  344:  0.6675070028011204

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 345
--------------------------------------------------------------
Epoch:  345        1 Batch loss: 0.147606 Batch F1: 0.851063829787234
Epoch:  345        2 Batch loss: 0.175001 Batch F1: 0.6976744186046512
Epoch:  345        3 Batch loss: 0.168468 Batch F1: 0.6111111111111112
Epoch:  345        4 Batch loss: 0.159234 Batch F1: 0.7999999999999999
Epoch:  345        5 Batch loss: 0.176810 Batch F1: 0.7083333333333334
Epoch:  345        6 Batch loss: 0.196876 Batch F1: 0.4137931034482759
Epoch:  345        7 Batch loss: 0.167909 Batch F1: 0.7659574468085107
Epoch:  345        8 Batch loss: 0.168674 Batch F1: 0.6976744186046512
Epoch:  345        9 Batch loss: 0.183185 Batch F1: 0.6666666666666666
Epoch:  345       10 Batch loss: 0.151073 Batch F1: 0.7894736842105262
Epoch:  345       11 Batch loss: 0.160428 Batch F1: 0.7999999999999999
Epoch:  345       12 Batch loss: 0.204400 Batch F1: 0.5714285714285714
Train Avg Loss  345: 0.171639

Train Avg F1  345: 0.6977647153336277

Val Avg Loss  345: 0.184159

Val Avg F1  345:  0.6821670606776989

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 346
--------------------------------------------------------------
Epoch:  346        1 Batch loss: 0.172806 Batch F1: 0.6666666666666666
Epoch:  346        2 Batch loss: 0.200439 Batch F1: 0.5365853658536585
Epoch:  346        3 Batch loss: 0.174874 Batch F1: 0.7924528301886793
Epoch:  346        4 Batch loss: 0.188960 Batch F1: 0.5333333333333333
Epoch:  346        5 Batch loss: 0.169320 Batch F1: 0.7142857142857143
Epoch:  346        6 Batch loss: 0.154521 Batch F1: 0.7441860465116279
Epoch:  346        7 Batch loss: 0.161821 Batch F1: 0.7272727272727273
Epoch:  346        8 Batch loss: 0.183527 Batch F1: 0.6818181818181818
Epoch:  346        9 Batch loss: 0.188274 Batch F1: 0.7796610169491526
Epoch:  346       10 Batch loss: 0.150467 Batch F1: 0.7142857142857143
Epoch:  346       11 Batch loss: 0.175888 Batch F1: 0.7692307692307692
Epoch:  346       12 Batch loss: 0.150662 Batch F1: 0.7692307692307692
Train Avg Loss  346: 0.172630

Train Avg F1  346: 0.7024174279689163

Val Avg Loss  346: 0.183253

Val Avg F1  346:  0.6873339780786589

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 347
--------------------------------------------------------------
Epoch:  347        1 Batch loss: 0.151819 Batch F1: 0.6666666666666667
Epoch:  347        2 Batch loss: 0.157389 Batch F1: 0.75
Epoch:  347        3 Batch loss: 0.167420 Batch F1: 0.7272727272727272
Epoch:  347        4 Batch loss: 0.214633 Batch F1: 0.5833333333333334
Epoch:  347        5 Batch loss: 0.168347 Batch F1: 0.7659574468085107
Epoch:  347        6 Batch loss: 0.191478 Batch F1: 0.75
Epoch:  347        7 Batch loss: 0.138010 Batch F1: 0.8846153846153846
Epoch:  347        8 Batch loss: 0.175860 Batch F1: 0.5789473684210527
Epoch:  347        9 Batch loss: 0.180300 Batch F1: 0.7843137254901961
Epoch:  347       10 Batch loss: 0.181115 Batch F1: 0.717948717948718
Epoch:  347       11 Batch loss: 0.161183 Batch F1: 0.7555555555555556
Epoch:  347       12 Batch loss: 0.171400 Batch F1: 0.7058823529411765
Train Avg Loss  347: 0.171580

Train Avg F1  347: 0.7225411065877769

Val Avg Loss  347: 0.183379

Val Avg F1  347:  0.6809444708115804

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 348
--------------------------------------------------------------
Epoch:  348        1 Batch loss: 0.187856 Batch F1: 0.5641025641025642
Epoch:  348        2 Batch loss: 0.183431 Batch F1: 0.76
Epoch:  348        3 Batch loss: 0.151806 Batch F1: 0.7567567567567567
Epoch:  348        4 Batch loss: 0.161609 Batch F1: 0.8235294117647058
Epoch:  348        5 Batch loss: 0.161324 Batch F1: 0.6511627906976744
Epoch:  348        6 Batch loss: 0.173380 Batch F1: 0.8474576271186441
Epoch:  348        7 Batch loss: 0.228213 Batch F1: 0.72
Epoch:  348        8 Batch loss: 0.167279 Batch F1: 0.8108108108108107
Epoch:  348        9 Batch loss: 0.174928 Batch F1: 0.6976744186046512
Epoch:  348       10 Batch loss: 0.170306 Batch F1: 0.7
Epoch:  348       11 Batch loss: 0.153465 Batch F1: 0.8399999999999999
Epoch:  348       12 Batch loss: 0.191306 Batch F1: 0.6976744186046512
Train Avg Loss  348: 0.175409

Train Avg F1  348: 0.7390973998717048

Val Avg Loss  348: 0.186370

Val Avg F1  348:  0.6652214245381947

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 349
--------------------------------------------------------------
Epoch:  349        1 Batch loss: 0.147378 Batch F1: 0.8095238095238095
Epoch:  349        2 Batch loss: 0.163374 Batch F1: 0.7441860465116279
Epoch:  349        3 Batch loss: 0.164127 Batch F1: 0.7692307692307692
Epoch:  349        4 Batch loss: 0.186089 Batch F1: 0.7169811320754716
Epoch:  349        5 Batch loss: 0.199159 Batch F1: 0.7058823529411765
Epoch:  349        6 Batch loss: 0.165506 Batch F1: 0.7999999999999999
Epoch:  349        7 Batch loss: 0.175891 Batch F1: 0.6486486486486486
Epoch:  349        8 Batch loss: 0.192070 Batch F1: 0.6666666666666666
Epoch:  349        9 Batch loss: 0.178974 Batch F1: 0.7346938775510204
Epoch:  349       10 Batch loss: 0.174066 Batch F1: 0.6829268292682927
Epoch:  349       11 Batch loss: 0.188960 Batch F1: 0.5641025641025641
Epoch:  349       12 Batch loss: 0.149579 Batch F1: 0.7878787878787877
Train Avg Loss  349: 0.173765

Train Avg F1  349: 0.7192267903665696

Val Avg Loss  349: 0.185928

Val Avg F1  349:  0.6681217941722144

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 350
--------------------------------------------------------------
Epoch:  350        1 Batch loss: 0.191517 Batch F1: 0.7241379310344827
Epoch:  350        2 Batch loss: 0.159329 Batch F1: 0.7755102040816326
Epoch:  350        3 Batch loss: 0.198083 Batch F1: 0.6666666666666667
Epoch:  350        4 Batch loss: 0.166227 Batch F1: 0.7272727272727273
Epoch:  350        5 Batch loss: 0.176118 Batch F1: 0.5555555555555555
Epoch:  350        6 Batch loss: 0.161822 Batch F1: 0.7
Epoch:  350        7 Batch loss: 0.189361 Batch F1: 0.7083333333333333
Epoch:  350        8 Batch loss: 0.181271 Batch F1: 0.45161290322580644
Epoch:  350        9 Batch loss: 0.201064 Batch F1: 0.6222222222222222
Epoch:  350       10 Batch loss: 0.195556 Batch F1: 0.6511627906976744
Epoch:  350       11 Batch loss: 0.152381 Batch F1: 0.8235294117647058
Epoch:  350       12 Batch loss: 0.160276 Batch F1: 0.8181818181818182
Train Avg Loss  350: 0.177750

Train Avg F1  350: 0.6853487970030522

Val Avg Loss  350: 0.187373

Val Avg F1  350:  0.6634259259259259

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 351
--------------------------------------------------------------
Epoch:  351        1 Batch loss: 0.178122 Batch F1: 0.6976744186046512
Epoch:  351        2 Batch loss: 0.179203 Batch F1: 0.7450980392156863
Epoch:  351        3 Batch loss: 0.180844 Batch F1: 0.6511627906976744
Epoch:  351        4 Batch loss: 0.165139 Batch F1: 0.7272727272727272
Epoch:  351        5 Batch loss: 0.188698 Batch F1: 0.6923076923076923
Epoch:  351        6 Batch loss: 0.182352 Batch F1: 0.7307692307692308
Epoch:  351        7 Batch loss: 0.185536 Batch F1: 0.6666666666666666
Epoch:  351        8 Batch loss: 0.167503 Batch F1: 0.6976744186046512
Epoch:  351        9 Batch loss: 0.161193 Batch F1: 0.7
Epoch:  351       10 Batch loss: 0.182967 Batch F1: 0.76
Epoch:  351       11 Batch loss: 0.170929 Batch F1: 0.7391304347826085
Epoch:  351       12 Batch loss: 0.131357 Batch F1: 0.8
Train Avg Loss  351: 0.172820

Train Avg F1  351: 0.7173130349101324

Val Avg Loss  351: 0.184848

Val Avg F1  351:  0.7048340548340548

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 352
--------------------------------------------------------------
Epoch:  352        1 Batch loss: 0.202281 Batch F1: 0.6666666666666666
Epoch:  352        2 Batch loss: 0.173756 Batch F1: 0.5517241379310345
Epoch:  352        3 Batch loss: 0.202616 Batch F1: 0.6046511627906976
Epoch:  352        4 Batch loss: 0.156030 Batch F1: 0.6470588235294117
Epoch:  352        5 Batch loss: 0.173440 Batch F1: 0.7200000000000001
Epoch:  352        6 Batch loss: 0.162401 Batch F1: 0.8076923076923077
Epoch:  352        7 Batch loss: 0.163101 Batch F1: 0.7555555555555556
Epoch:  352        8 Batch loss: 0.185101 Batch F1: 0.7857142857142857
Epoch:  352        9 Batch loss: 0.158704 Batch F1: 0.7755102040816326
Epoch:  352       10 Batch loss: 0.155645 Batch F1: 0.7727272727272727
Epoch:  352       11 Batch loss: 0.169093 Batch F1: 0.7843137254901961
Epoch:  352       12 Batch loss: 0.186640 Batch F1: 0.6666666666666667
Train Avg Loss  352: 0.174067

Train Avg F1  352: 0.7115234007371439

Val Avg Loss  352: 0.183493

Val Avg F1  352:  0.6823583851045504

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 353
--------------------------------------------------------------
Epoch:  353        1 Batch loss: 0.178796 Batch F1: 0.7636363636363638
Epoch:  353        2 Batch loss: 0.154952 Batch F1: 0.830188679245283
Epoch:  353        3 Batch loss: 0.178864 Batch F1: 0.6153846153846153
Epoch:  353        4 Batch loss: 0.162078 Batch F1: 0.8076923076923077
Epoch:  353        5 Batch loss: 0.189481 Batch F1: 0.6938775510204083
Epoch:  353        6 Batch loss: 0.164143 Batch F1: 0.7142857142857143
Epoch:  353        7 Batch loss: 0.174306 Batch F1: 0.6976744186046512
Epoch:  353        8 Batch loss: 0.169197 Batch F1: 0.65
Epoch:  353        9 Batch loss: 0.179400 Batch F1: 0.5454545454545454
Epoch:  353       10 Batch loss: 0.142724 Batch F1: 0.7058823529411765
Epoch:  353       11 Batch loss: 0.180324 Batch F1: 0.6956521739130435
Epoch:  353       12 Batch loss: 0.167685 Batch F1: 0.75
Train Avg Loss  353: 0.170162

Train Avg F1  353: 0.7058107268481759

Val Avg Loss  353: 0.183616

Val Avg F1  353:  0.6742827093968613

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 354
--------------------------------------------------------------
Epoch:  354        1 Batch loss: 0.171459 Batch F1: 0.7111111111111111
Epoch:  354        2 Batch loss: 0.171838 Batch F1: 0.5161290322580646
Epoch:  354        3 Batch loss: 0.204722 Batch F1: 0.5777777777777778
Epoch:  354        4 Batch loss: 0.164694 Batch F1: 0.7857142857142857
Epoch:  354        5 Batch loss: 0.163286 Batch F1: 0.7272727272727272
Epoch:  354        6 Batch loss: 0.149355 Batch F1: 0.8333333333333334
Epoch:  354        7 Batch loss: 0.199856 Batch F1: 0.6249999999999999
Epoch:  354        8 Batch loss: 0.154711 Batch F1: 0.7500000000000001
Epoch:  354        9 Batch loss: 0.170977 Batch F1: 0.6470588235294117
Epoch:  354       10 Batch loss: 0.165914 Batch F1: 0.7391304347826088
Epoch:  354       11 Batch loss: 0.185889 Batch F1: 0.6956521739130435
Epoch:  354       12 Batch loss: 0.131403 Batch F1: 0.8780487804878048
Train Avg Loss  354: 0.169509

Train Avg F1  354: 0.7071857066816808

Val Avg Loss  354: 0.182549

Val Avg F1  354:  0.698723649538867

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 355
--------------------------------------------------------------
Epoch:  355        1 Batch loss: 0.186149 Batch F1: 0.6500000000000001
Epoch:  355        2 Batch loss: 0.129683 Batch F1: 0.8636363636363636
Epoch:  355        3 Batch loss: 0.181397 Batch F1: 0.6222222222222222
Epoch:  355        4 Batch loss: 0.190943 Batch F1: 0.6521739130434783
Epoch:  355        5 Batch loss: 0.197408 Batch F1: 0.5714285714285713
Epoch:  355        6 Batch loss: 0.135709 Batch F1: 0.8695652173913043
Epoch:  355        7 Batch loss: 0.156890 Batch F1: 0.7368421052631579
Epoch:  355        8 Batch loss: 0.164898 Batch F1: 0.7843137254901961
Epoch:  355        9 Batch loss: 0.191234 Batch F1: 0.7037037037037037
Epoch:  355       10 Batch loss: 0.163801 Batch F1: 0.7499999999999999
Epoch:  355       11 Batch loss: 0.158116 Batch F1: 0.744186046511628
Epoch:  355       12 Batch loss: 0.191500 Batch F1: 0.6153846153846154
Train Avg Loss  355: 0.170644

Train Avg F1  355: 0.7136213736729368

Val Avg Loss  355: 0.183119

Val Avg F1  355:  0.6979587346292152

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 356
--------------------------------------------------------------
Epoch:  356        1 Batch loss: 0.166464 Batch F1: 0.6486486486486486
Epoch:  356        2 Batch loss: 0.147632 Batch F1: 0.7916666666666666
Epoch:  356        3 Batch loss: 0.167612 Batch F1: 0.6315789473684211
Epoch:  356        4 Batch loss: 0.169098 Batch F1: 0.6956521739130435
Epoch:  356        5 Batch loss: 0.168387 Batch F1: 0.723404255319149
Epoch:  356        6 Batch loss: 0.164055 Batch F1: 0.7555555555555555
Epoch:  356        7 Batch loss: 0.174212 Batch F1: 0.6818181818181819
Epoch:  356        8 Batch loss: 0.182685 Batch F1: 0.6470588235294117
Epoch:  356        9 Batch loss: 0.160831 Batch F1: 0.8363636363636364
Epoch:  356       10 Batch loss: 0.177928 Batch F1: 0.7547169811320755
Epoch:  356       11 Batch loss: 0.196647 Batch F1: 0.6046511627906977
Epoch:  356       12 Batch loss: 0.178914 Batch F1: 0.6842105263157895
Train Avg Loss  356: 0.171205

Train Avg F1  356: 0.7046104632851065

Val Avg Loss  356: 0.182852

Val Avg F1  356:  0.6817967746539175

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 357
--------------------------------------------------------------
Epoch:  357        1 Batch loss: 0.158588 Batch F1: 0.830188679245283
Epoch:  357        2 Batch loss: 0.165531 Batch F1: 0.782608695652174
Epoch:  357        3 Batch loss: 0.182578 Batch F1: 0.6976744186046512
Epoch:  357        4 Batch loss: 0.165918 Batch F1: 0.5882352941176471
Epoch:  357        5 Batch loss: 0.172551 Batch F1: 0.75
Epoch:  357        6 Batch loss: 0.154510 Batch F1: 0.6451612903225806
Epoch:  357        7 Batch loss: 0.153293 Batch F1: 0.7555555555555556
Epoch:  357        8 Batch loss: 0.198340 Batch F1: 0.7368421052631577
Epoch:  357        9 Batch loss: 0.198687 Batch F1: 0.6046511627906977
Epoch:  357       10 Batch loss: 0.156347 Batch F1: 0.7567567567567567
Epoch:  357       11 Batch loss: 0.185060 Batch F1: 0.7083333333333333
Epoch:  357       12 Batch loss: 0.174800 Batch F1: 0.7555555555555555
Train Avg Loss  357: 0.172184

Train Avg F1  357: 0.7176302372664494

Val Avg Loss  357: 0.182202

Val Avg F1  357:  0.69783764309215

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 358
--------------------------------------------------------------
Epoch:  358        1 Batch loss: 0.144365 Batch F1: 0.7692307692307693
Epoch:  358        2 Batch loss: 0.176245 Batch F1: 0.7027027027027026
Epoch:  358        3 Batch loss: 0.180258 Batch F1: 0.6341463414634146
Epoch:  358        4 Batch loss: 0.163906 Batch F1: 0.7727272727272727
Epoch:  358        5 Batch loss: 0.167051 Batch F1: 0.6486486486486486
Epoch:  358        6 Batch loss: 0.195881 Batch F1: 0.5263157894736842
Epoch:  358        7 Batch loss: 0.174533 Batch F1: 0.6818181818181818
Epoch:  358        8 Batch loss: 0.180360 Batch F1: 0.7636363636363636
Epoch:  358        9 Batch loss: 0.161669 Batch F1: 0.7499999999999999
Epoch:  358       10 Batch loss: 0.151325 Batch F1: 0.7317073170731707
Epoch:  358       11 Batch loss: 0.153053 Batch F1: 0.8461538461538461
Epoch:  358       12 Batch loss: 0.195386 Batch F1: 0.693877551020408
Train Avg Loss  358: 0.170336

Train Avg F1  358: 0.7100803986623719

Val Avg Loss  358: 0.183126

Val Avg F1  358:  0.723322420826292

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 359
--------------------------------------------------------------
Epoch:  359        1 Batch loss: 0.202990 Batch F1: 0.7142857142857143
Epoch:  359        2 Batch loss: 0.186345 Batch F1: 0.7450980392156864
Epoch:  359        3 Batch loss: 0.162315 Batch F1: 0.6285714285714287
Epoch:  359        4 Batch loss: 0.193665 Batch F1: 0.6666666666666665
Epoch:  359        5 Batch loss: 0.151458 Batch F1: 0.7999999999999999
Epoch:  359        6 Batch loss: 0.149546 Batch F1: 0.7058823529411765
Epoch:  359        7 Batch loss: 0.176294 Batch F1: 0.6060606060606061
Epoch:  359        8 Batch loss: 0.182697 Batch F1: 0.65
Epoch:  359        9 Batch loss: 0.218679 Batch F1: 0.6829268292682927
Epoch:  359       10 Batch loss: 0.223855 Batch F1: 0.6153846153846153
Epoch:  359       11 Batch loss: 0.154959 Batch F1: 0.819672131147541
Epoch:  359       12 Batch loss: 0.160274 Batch F1: 0.8399999999999999
Train Avg Loss  359: 0.180256

Train Avg F1  359: 0.7062123652951439

Val Avg Loss  359: 0.185896

Val Avg F1  359:  0.7251493888960197

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 360
--------------------------------------------------------------
Epoch:  360        1 Batch loss: 0.177032 Batch F1: 0.7719298245614034
Epoch:  360        2 Batch loss: 0.155702 Batch F1: 0.8372093023255814
Epoch:  360        3 Batch loss: 0.192407 Batch F1: 0.6
Epoch:  360        4 Batch loss: 0.181480 Batch F1: 0.6363636363636364
Epoch:  360        5 Batch loss: 0.165111 Batch F1: 0.7659574468085107
Epoch:  360        6 Batch loss: 0.155676 Batch F1: 0.7727272727272727
Epoch:  360        7 Batch loss: 0.200207 Batch F1: 0.5365853658536585
Epoch:  360        8 Batch loss: 0.184744 Batch F1: 0.6956521739130435
Epoch:  360        9 Batch loss: 0.157119 Batch F1: 0.8571428571428572
Epoch:  360       10 Batch loss: 0.177895 Batch F1: 0.7659574468085107
Epoch:  360       11 Batch loss: 0.184690 Batch F1: 0.5789473684210527
Epoch:  360       12 Batch loss: 0.193770 Batch F1: 0.7
Train Avg Loss  360: 0.177153

Train Avg F1  360: 0.7098727245771271

Val Avg Loss  360: 0.184585

Val Avg F1  360:  0.6807894486465915

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 361
--------------------------------------------------------------
Epoch:  361        1 Batch loss: 0.182102 Batch F1: 0.6829268292682927
Epoch:  361        2 Batch loss: 0.184123 Batch F1: 0.6808510638297872
Epoch:  361        3 Batch loss: 0.164868 Batch F1: 0.7142857142857143
Epoch:  361        4 Batch loss: 0.166145 Batch F1: 0.7755102040816326
Epoch:  361        5 Batch loss: 0.165186 Batch F1: 0.7346938775510203
Epoch:  361        6 Batch loss: 0.175379 Batch F1: 0.7272727272727274
Epoch:  361        7 Batch loss: 0.164270 Batch F1: 0.75
Epoch:  361        8 Batch loss: 0.184811 Batch F1: 0.6818181818181819
Epoch:  361        9 Batch loss: 0.185446 Batch F1: 0.6808510638297872
Epoch:  361       10 Batch loss: 0.193353 Batch F1: 0.5909090909090909
Epoch:  361       11 Batch loss: 0.156898 Batch F1: 0.8085106382978724
Epoch:  361       12 Batch loss: 0.173437 Batch F1: 0.742857142857143
Train Avg Loss  361: 0.174668

Train Avg F1  361: 0.7142072111667708

Val Avg Loss  361: 0.187822

Val Avg F1  361:  0.6739123167694596

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 362
--------------------------------------------------------------
Epoch:  362        1 Batch loss: 0.159501 Batch F1: 0.782608695652174
Epoch:  362        2 Batch loss: 0.164351 Batch F1: 0.7142857142857143
Epoch:  362        3 Batch loss: 0.161069 Batch F1: 0.6857142857142857
Epoch:  362        4 Batch loss: 0.169516 Batch F1: 0.76
Epoch:  362        5 Batch loss: 0.151527 Batch F1: 0.8275862068965518
Epoch:  362        6 Batch loss: 0.164517 Batch F1: 0.6818181818181819
Epoch:  362        7 Batch loss: 0.217354 Batch F1: 0.5531914893617021
Epoch:  362        8 Batch loss: 0.178351 Batch F1: 0.6666666666666666
Epoch:  362        9 Batch loss: 0.195839 Batch F1: 0.6666666666666666
Epoch:  362       10 Batch loss: 0.178514 Batch F1: 0.7450980392156864
Epoch:  362       11 Batch loss: 0.181742 Batch F1: 0.619047619047619
Epoch:  362       12 Batch loss: 0.174275 Batch F1: 0.7027027027027027
Train Avg Loss  362: 0.174713

Train Avg F1  362: 0.700448855668996

Val Avg Loss  362: 0.185322

Val Avg F1  362:  0.680290594498669

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 363
--------------------------------------------------------------
Epoch:  363        1 Batch loss: 0.177460 Batch F1: 0.6956521739130435
Epoch:  363        2 Batch loss: 0.185390 Batch F1: 0.68
Epoch:  363        3 Batch loss: 0.194595 Batch F1: 0.6938775510204083
Epoch:  363        4 Batch loss: 0.194972 Batch F1: 0.6923076923076923
Epoch:  363        5 Batch loss: 0.144553 Batch F1: 0.88
Epoch:  363        6 Batch loss: 0.162202 Batch F1: 0.8372093023255814
Epoch:  363        7 Batch loss: 0.159521 Batch F1: 0.7500000000000001
Epoch:  363        8 Batch loss: 0.158466 Batch F1: 0.8
Epoch:  363        9 Batch loss: 0.154041 Batch F1: 0.7
Epoch:  363       10 Batch loss: 0.146814 Batch F1: 0.7894736842105263
Epoch:  363       11 Batch loss: 0.190861 Batch F1: 0.47058823529411764
Epoch:  363       12 Batch loss: 0.210532 Batch F1: 0.717948717948718
Train Avg Loss  363: 0.173284

Train Avg F1  363: 0.7255881130850073

Val Avg Loss  363: 0.191210

Val Avg F1  363:  0.6979952830188679

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 364
--------------------------------------------------------------
Epoch:  364        1 Batch loss: 0.157698 Batch F1: 0.8571428571428572
Epoch:  364        2 Batch loss: 0.144533 Batch F1: 0.8695652173913043
Epoch:  364        3 Batch loss: 0.172924 Batch F1: 0.7659574468085107
Epoch:  364        4 Batch loss: 0.170440 Batch F1: 0.6842105263157895
Epoch:  364        5 Batch loss: 0.180366 Batch F1: 0.6956521739130435
Epoch:  364        6 Batch loss: 0.163397 Batch F1: 0.7142857142857143
Epoch:  364        7 Batch loss: 0.198653 Batch F1: 0.6363636363636365
Epoch:  364        8 Batch loss: 0.176709 Batch F1: 0.7692307692307693
Epoch:  364        9 Batch loss: 0.180821 Batch F1: 0.6976744186046512
Epoch:  364       10 Batch loss: 0.189456 Batch F1: 0.6341463414634146
Epoch:  364       11 Batch loss: 0.182074 Batch F1: 0.6363636363636365
Epoch:  364       12 Batch loss: 0.194454 Batch F1: 0.7317073170731707
Train Avg Loss  364: 0.175960

Train Avg F1  364: 0.7243583379130416

Val Avg Loss  364: 0.186275

Val Avg F1  364:  0.677359781121751

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 365
--------------------------------------------------------------
Epoch:  365        1 Batch loss: 0.165587 Batch F1: 0.7692307692307692
Epoch:  365        2 Batch loss: 0.154061 Batch F1: 0.8444444444444443
Epoch:  365        3 Batch loss: 0.190716 Batch F1: 0.7272727272727273
Epoch:  365        4 Batch loss: 0.187048 Batch F1: 0.7169811320754718
Epoch:  365        5 Batch loss: 0.186527 Batch F1: 0.6666666666666666
Epoch:  365        6 Batch loss: 0.155296 Batch F1: 0.7555555555555555
Epoch:  365        7 Batch loss: 0.162843 Batch F1: 0.7999999999999999
Epoch:  365        8 Batch loss: 0.152258 Batch F1: 0.7441860465116279
Epoch:  365        9 Batch loss: 0.183021 Batch F1: 0.5454545454545455
Epoch:  365       10 Batch loss: 0.166953 Batch F1: 0.6666666666666667
Epoch:  365       11 Batch loss: 0.185371 Batch F1: 0.5945945945945946
Epoch:  365       12 Batch loss: 0.196235 Batch F1: 0.6666666666666666
Train Avg Loss  365: 0.173826

Train Avg F1  365: 0.7081433179283114

Val Avg Loss  365: 0.183138

Val Avg F1  365:  0.6715652074783403

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 366
--------------------------------------------------------------
Epoch:  366        1 Batch loss: 0.176937 Batch F1: 0.7719298245614036
Epoch:  366        2 Batch loss: 0.172401 Batch F1: 0.6666666666666666
Epoch:  366        3 Batch loss: 0.164643 Batch F1: 0.7450980392156863
Epoch:  366        4 Batch loss: 0.157435 Batch F1: 0.7368421052631579
Epoch:  366        5 Batch loss: 0.148080 Batch F1: 0.7906976744186046
Epoch:  366        6 Batch loss: 0.195142 Batch F1: 0.6808510638297872
Epoch:  366        7 Batch loss: 0.205203 Batch F1: 0.5581395348837208
Epoch:  366        8 Batch loss: 0.176929 Batch F1: 0.7777777777777778
Epoch:  366        9 Batch loss: 0.167576 Batch F1: 0.7317073170731706
Epoch:  366       10 Batch loss: 0.158767 Batch F1: 0.717948717948718
Epoch:  366       11 Batch loss: 0.170629 Batch F1: 0.6829268292682926
Epoch:  366       12 Batch loss: 0.156809 Batch F1: 0.6206896551724138
Train Avg Loss  366: 0.170879

Train Avg F1  366: 0.7067729338399501

Val Avg Loss  366: 0.183777

Val Avg F1  366:  0.6741021151364193

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 367
--------------------------------------------------------------
Epoch:  367        1 Batch loss: 0.161266 Batch F1: 0.7441860465116279
Epoch:  367        2 Batch loss: 0.156553 Batch F1: 0.75
Epoch:  367        3 Batch loss: 0.167329 Batch F1: 0.7619047619047619
Epoch:  367        4 Batch loss: 0.193016 Batch F1: 0.6222222222222223
Epoch:  367        5 Batch loss: 0.160430 Batch F1: 0.7999999999999999
Epoch:  367        6 Batch loss: 0.190208 Batch F1: 0.6190476190476191
Epoch:  367        7 Batch loss: 0.154885 Batch F1: 0.7500000000000001
Epoch:  367        8 Batch loss: 0.174531 Batch F1: 0.7346938775510203
Epoch:  367        9 Batch loss: 0.179068 Batch F1: 0.693877551020408
Epoch:  367       10 Batch loss: 0.190378 Batch F1: 0.693877551020408
Epoch:  367       11 Batch loss: 0.136013 Batch F1: 0.7567567567567567
Epoch:  367       12 Batch loss: 0.173790 Batch F1: 0.6666666666666665
Train Avg Loss  367: 0.169789

Train Avg F1  367: 0.716102754391791

Val Avg Loss  367: 0.181538

Val Avg F1  367:  0.7095300834431268

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 368
--------------------------------------------------------------
Epoch:  368        1 Batch loss: 0.155149 Batch F1: 0.7804878048780488
Epoch:  368        2 Batch loss: 0.171587 Batch F1: 0.6829268292682926
Epoch:  368        3 Batch loss: 0.137953 Batch F1: 0.875
Epoch:  368        4 Batch loss: 0.167588 Batch F1: 0.7083333333333334
Epoch:  368        5 Batch loss: 0.175594 Batch F1: 0.7555555555555555
Epoch:  368        6 Batch loss: 0.164560 Batch F1: 0.7027027027027027
Epoch:  368        7 Batch loss: 0.197707 Batch F1: 0.7037037037037037
Epoch:  368        8 Batch loss: 0.157683 Batch F1: 0.7999999999999999
Epoch:  368        9 Batch loss: 0.195026 Batch F1: 0.6666666666666666
Epoch:  368       10 Batch loss: 0.170258 Batch F1: 0.7346938775510204
Epoch:  368       11 Batch loss: 0.163012 Batch F1: 0.7843137254901961
Epoch:  368       12 Batch loss: 0.179750 Batch F1: 0.717948717948718
Train Avg Loss  368: 0.169656

Train Avg F1  368: 0.7426944097581866

Val Avg Loss  368: 0.180622

Val Avg F1  368:  0.6879249902921

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 369
--------------------------------------------------------------
Epoch:  369        1 Batch loss: 0.164473 Batch F1: 0.7857142857142857
Epoch:  369        2 Batch loss: 0.167204 Batch F1: 0.7755102040816326
Epoch:  369        3 Batch loss: 0.153893 Batch F1: 0.7567567567567567
Epoch:  369        4 Batch loss: 0.172293 Batch F1: 0.7317073170731708
Epoch:  369        5 Batch loss: 0.193749 Batch F1: 0.679245283018868
Epoch:  369        6 Batch loss: 0.150308 Batch F1: 0.7916666666666666
Epoch:  369        7 Batch loss: 0.164011 Batch F1: 0.7659574468085107
Epoch:  369        8 Batch loss: 0.151744 Batch F1: 0.7368421052631577
Epoch:  369        9 Batch loss: 0.178927 Batch F1: 0.6808510638297872
Epoch:  369       10 Batch loss: 0.188535 Batch F1: 0.6046511627906976
Epoch:  369       11 Batch loss: 0.209304 Batch F1: 0.6046511627906976
Epoch:  369       12 Batch loss: 0.161323 Batch F1: 0.6451612903225806
Train Avg Loss  369: 0.171314

Train Avg F1  369: 0.7132262287597344

Val Avg Loss  369: 0.184115

Val Avg F1  369:  0.66235074286756

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 370
--------------------------------------------------------------
Epoch:  370        1 Batch loss: 0.211504 Batch F1: 0.6428571428571429
Epoch:  370        2 Batch loss: 0.174699 Batch F1: 0.7599999999999999
Epoch:  370        3 Batch loss: 0.159272 Batch F1: 0.64
Epoch:  370        4 Batch loss: 0.168142 Batch F1: 0.7027027027027027
Epoch:  370        5 Batch loss: 0.194688 Batch F1: 0.6666666666666665
Epoch:  370        6 Batch loss: 0.154650 Batch F1: 0.7499999999999999
Epoch:  370        7 Batch loss: 0.197833 Batch F1: 0.6222222222222222
Epoch:  370        8 Batch loss: 0.159766 Batch F1: 0.7142857142857143
Epoch:  370        9 Batch loss: 0.175786 Batch F1: 0.7346938775510203
Epoch:  370       10 Batch loss: 0.155947 Batch F1: 0.8421052631578947
Epoch:  370       11 Batch loss: 0.165752 Batch F1: 0.7234042553191489
Epoch:  370       12 Batch loss: 0.163348 Batch F1: 0.8108108108108107
Train Avg Loss  370: 0.173449

Train Avg F1  370: 0.7174790546311103

Val Avg Loss  370: 0.185058

Val Avg F1  370:  0.7264437064133831

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 371
--------------------------------------------------------------
Epoch:  371        1 Batch loss: 0.163526 Batch F1: 0.76
Epoch:  371        2 Batch loss: 0.146716 Batch F1: 0.7368421052631579
Epoch:  371        3 Batch loss: 0.173870 Batch F1: 0.6818181818181818
Epoch:  371        4 Batch loss: 0.180170 Batch F1: 0.6511627906976744
Epoch:  371        5 Batch loss: 0.187413 Batch F1: 0.7234042553191491
Epoch:  371        6 Batch loss: 0.190291 Batch F1: 0.6511627906976745
Epoch:  371        7 Batch loss: 0.162103 Batch F1: 0.7916666666666667
Epoch:  371        8 Batch loss: 0.154895 Batch F1: 0.7027027027027027
Epoch:  371        9 Batch loss: 0.189824 Batch F1: 0.693877551020408
Epoch:  371       10 Batch loss: 0.166359 Batch F1: 0.7555555555555555
Epoch:  371       11 Batch loss: 0.164248 Batch F1: 0.7441860465116279
Epoch:  371       12 Batch loss: 0.179028 Batch F1: 0.7499999999999999
Train Avg Loss  371: 0.171537

Train Avg F1  371: 0.7201982205210666

Val Avg Loss  371: 0.184964

Val Avg F1  371:  0.6684066637407651

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 372
--------------------------------------------------------------
Epoch:  372        1 Batch loss: 0.153611 Batch F1: 0.7555555555555556
Epoch:  372        2 Batch loss: 0.195987 Batch F1: 0.6086956521739131
Epoch:  372        3 Batch loss: 0.167630 Batch F1: 0.6976744186046512
Epoch:  372        4 Batch loss: 0.155933 Batch F1: 0.7317073170731708
Epoch:  372        5 Batch loss: 0.179879 Batch F1: 0.6938775510204083
Epoch:  372        6 Batch loss: 0.216323 Batch F1: 0.64
Epoch:  372        7 Batch loss: 0.182914 Batch F1: 0.6190476190476191
Epoch:  372        8 Batch loss: 0.142205 Batch F1: 0.7500000000000001
Epoch:  372        9 Batch loss: 0.166684 Batch F1: 0.7555555555555556
Epoch:  372       10 Batch loss: 0.179824 Batch F1: 0.6285714285714286
Epoch:  372       11 Batch loss: 0.178816 Batch F1: 0.6341463414634146
Epoch:  372       12 Batch loss: 0.143673 Batch F1: 0.9047619047619047
Train Avg Loss  372: 0.171957

Train Avg F1  372: 0.7016327786523018

Val Avg Loss  372: 0.183035

Val Avg F1  372:  0.7321042607607335

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 373
--------------------------------------------------------------
Epoch:  373        1 Batch loss: 0.172570 Batch F1: 0.7826086956521738
Epoch:  373        2 Batch loss: 0.165264 Batch F1: 0.8253968253968254
Epoch:  373        3 Batch loss: 0.182211 Batch F1: 0.7111111111111111
Epoch:  373        4 Batch loss: 0.167108 Batch F1: 0.717948717948718
Epoch:  373        5 Batch loss: 0.131140 Batch F1: 0.8679245283018867
Epoch:  373        6 Batch loss: 0.182614 Batch F1: 0.6046511627906976
Epoch:  373        7 Batch loss: 0.190190 Batch F1: 0.6222222222222223
Epoch:  373        8 Batch loss: 0.166010 Batch F1: 0.6486486486486486
Epoch:  373        9 Batch loss: 0.151789 Batch F1: 0.6842105263157895
Epoch:  373       10 Batch loss: 0.189607 Batch F1: 0.6875000000000001
Epoch:  373       11 Batch loss: 0.185988 Batch F1: 0.5625
Epoch:  373       12 Batch loss: 0.219876 Batch F1: 0.6829268292682927
Train Avg Loss  373: 0.175364

Train Avg F1  373: 0.6998041056380305

Val Avg Loss  373: 0.182020

Val Avg F1  373:  0.6854493337200771

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 374
--------------------------------------------------------------
Epoch:  374        1 Batch loss: 0.196480 Batch F1: 0.6
Epoch:  374        2 Batch loss: 0.191006 Batch F1: 0.7346938775510204
Epoch:  374        3 Batch loss: 0.148771 Batch F1: 0.9333333333333333
Epoch:  374        4 Batch loss: 0.186951 Batch F1: 0.7450980392156863
Epoch:  374        5 Batch loss: 0.163224 Batch F1: 0.7727272727272727
Epoch:  374        6 Batch loss: 0.166856 Batch F1: 0.7555555555555555
Epoch:  374        7 Batch loss: 0.193081 Batch F1: 0.6046511627906976
Epoch:  374        8 Batch loss: 0.203054 Batch F1: 0.6666666666666667
Epoch:  374        9 Batch loss: 0.194946 Batch F1: 0.6315789473684211
Epoch:  374       10 Batch loss: 0.167759 Batch F1: 0.7
Epoch:  374       11 Batch loss: 0.173388 Batch F1: 0.7234042553191489
Epoch:  374       12 Batch loss: 0.204924 Batch F1: 0.7547169811320755
Train Avg Loss  374: 0.182537

Train Avg F1  374: 0.7185355076383232

Val Avg Loss  374: 0.189580

Val Avg F1  374:  0.6596971761677644

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 375
--------------------------------------------------------------
Epoch:  375        1 Batch loss: 0.150722 Batch F1: 0.830188679245283
Epoch:  375        2 Batch loss: 0.137565 Batch F1: 0.7804878048780488
Epoch:  375        3 Batch loss: 0.170723 Batch F1: 0.7346938775510204
Epoch:  375        4 Batch loss: 0.158504 Batch F1: 0.8400000000000001
Epoch:  375        5 Batch loss: 0.172905 Batch F1: 0.7272727272727273
Epoch:  375        6 Batch loss: 0.155943 Batch F1: 0.7755102040816326
Epoch:  375        7 Batch loss: 0.193717 Batch F1: 0.5454545454545455
Epoch:  375        8 Batch loss: 0.169645 Batch F1: 0.8000000000000002
Epoch:  375        9 Batch loss: 0.201419 Batch F1: 0.5853658536585366
Epoch:  375       10 Batch loss: 0.196333 Batch F1: 0.5405405405405405
Epoch:  375       11 Batch loss: 0.196324 Batch F1: 0.55
Epoch:  375       12 Batch loss: 0.182002 Batch F1: 0.6842105263157895
Train Avg Loss  375: 0.173817

Train Avg F1  375: 0.6994770632498436

Val Avg Loss  375: 0.183419

Val Avg F1  375:  0.6840986394557823

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 376
--------------------------------------------------------------
Epoch:  376        1 Batch loss: 0.179397 Batch F1: 0.5945945945945946
Epoch:  376        2 Batch loss: 0.154248 Batch F1: 0.7924528301886793
Epoch:  376        3 Batch loss: 0.194204 Batch F1: 0.711111111111111
Epoch:  376        4 Batch loss: 0.154349 Batch F1: 0.7727272727272727
Epoch:  376        5 Batch loss: 0.152444 Batch F1: 0.7804878048780488
Epoch:  376        6 Batch loss: 0.197582 Batch F1: 0.5714285714285715
Epoch:  376        7 Batch loss: 0.164326 Batch F1: 0.7916666666666667
Epoch:  376        8 Batch loss: 0.173161 Batch F1: 0.6666666666666667
Epoch:  376        9 Batch loss: 0.161917 Batch F1: 0.761904761904762
Epoch:  376       10 Batch loss: 0.170727 Batch F1: 0.6818181818181819
Epoch:  376       11 Batch loss: 0.210063 Batch F1: 0.6785714285714286
Epoch:  376       12 Batch loss: 0.146479 Batch F1: 0.8108108108108109
Train Avg Loss  376: 0.171575

Train Avg F1  376: 0.7178533917805662

Val Avg Loss  376: 0.183539

Val Avg F1  376:  0.6791388437565545

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 377
--------------------------------------------------------------
Epoch:  377        1 Batch loss: 0.181369 Batch F1: 0.6938775510204083
Epoch:  377        2 Batch loss: 0.191062 Batch F1: 0.55
Epoch:  377        3 Batch loss: 0.153176 Batch F1: 0.7567567567567567
Epoch:  377        4 Batch loss: 0.171107 Batch F1: 0.76
Epoch:  377        5 Batch loss: 0.183236 Batch F1: 0.6341463414634148
Epoch:  377        6 Batch loss: 0.136637 Batch F1: 0.8571428571428572
Epoch:  377        7 Batch loss: 0.182241 Batch F1: 0.6666666666666666
Epoch:  377        8 Batch loss: 0.172392 Batch F1: 0.7692307692307692
Epoch:  377        9 Batch loss: 0.168316 Batch F1: 0.7555555555555556
Epoch:  377       10 Batch loss: 0.157077 Batch F1: 0.8400000000000001
Epoch:  377       11 Batch loss: 0.162320 Batch F1: 0.7142857142857143
Epoch:  377       12 Batch loss: 0.186718 Batch F1: 0.4
Train Avg Loss  377: 0.170471

Train Avg F1  377: 0.6998051843435119

Val Avg Loss  377: 0.180319

Val Avg F1  377:  0.6859716349541931

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 378
--------------------------------------------------------------
Epoch:  378        1 Batch loss: 0.159310 Batch F1: 0.8214285714285715
Epoch:  378        2 Batch loss: 0.162268 Batch F1: 0.7499999999999999
Epoch:  378        3 Batch loss: 0.153309 Batch F1: 0.7027027027027027
Epoch:  378        4 Batch loss: 0.184358 Batch F1: 0.6363636363636365
Epoch:  378        5 Batch loss: 0.176070 Batch F1: 0.7142857142857143
Epoch:  378        6 Batch loss: 0.193415 Batch F1: 0.6
Epoch:  378        7 Batch loss: 0.169947 Batch F1: 0.7857142857142857
Epoch:  378        8 Batch loss: 0.165449 Batch F1: 0.6842105263157895
Epoch:  378        9 Batch loss: 0.148007 Batch F1: 0.7755102040816326
Epoch:  378       10 Batch loss: 0.190623 Batch F1: 0.6666666666666666
Epoch:  378       11 Batch loss: 0.195073 Batch F1: 0.6382978723404256
Epoch:  378       12 Batch loss: 0.149366 Batch F1: 0.6923076923076923
Train Avg Loss  378: 0.170600

Train Avg F1  378: 0.7056239893505931

Val Avg Loss  378: 0.183373

Val Avg F1  378:  0.6995483992706435

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 379
--------------------------------------------------------------
Epoch:  379        1 Batch loss: 0.161465 Batch F1: 0.625
Epoch:  379        2 Batch loss: 0.178300 Batch F1: 0.7500000000000001
Epoch:  379        3 Batch loss: 0.178425 Batch F1: 0.7111111111111111
Epoch:  379        4 Batch loss: 0.180573 Batch F1: 0.7083333333333333
Epoch:  379        5 Batch loss: 0.179694 Batch F1: 0.6500000000000001
Epoch:  379        6 Batch loss: 0.179036 Batch F1: 0.6666666666666666
Epoch:  379        7 Batch loss: 0.158228 Batch F1: 0.7142857142857143
Epoch:  379        8 Batch loss: 0.155650 Batch F1: 0.8076923076923076
Epoch:  379        9 Batch loss: 0.167835 Batch F1: 0.7777777777777779
Epoch:  379       10 Batch loss: 0.175431 Batch F1: 0.6666666666666666
Epoch:  379       11 Batch loss: 0.164801 Batch F1: 0.6818181818181819
Epoch:  379       12 Batch loss: 0.178785 Batch F1: 0.7222222222222222
Train Avg Loss  379: 0.171519

Train Avg F1  379: 0.7067978317978318

Val Avg Loss  379: 0.182673

Val Avg F1  379:  0.6724613860553603

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 380
--------------------------------------------------------------
Epoch:  380        1 Batch loss: 0.157627 Batch F1: 0.7368421052631577
Epoch:  380        2 Batch loss: 0.189269 Batch F1: 0.6666666666666666
Epoch:  380        3 Batch loss: 0.164234 Batch F1: 0.7142857142857143
Epoch:  380        4 Batch loss: 0.163176 Batch F1: 0.8076923076923077
Epoch:  380        5 Batch loss: 0.206827 Batch F1: 0.5652173913043478
Epoch:  380        6 Batch loss: 0.155703 Batch F1: 0.8085106382978724
Epoch:  380        7 Batch loss: 0.143891 Batch F1: 0.7804878048780488
Epoch:  380        8 Batch loss: 0.157246 Batch F1: 0.7317073170731707
Epoch:  380        9 Batch loss: 0.182372 Batch F1: 0.6808510638297872
Epoch:  380       10 Batch loss: 0.159615 Batch F1: 0.7142857142857143
Epoch:  380       11 Batch loss: 0.181678 Batch F1: 0.7111111111111111
Epoch:  380       12 Batch loss: 0.177693 Batch F1: 0.6285714285714287
Train Avg Loss  380: 0.169944

Train Avg F1  380: 0.7121857719382773

Val Avg Loss  380: 0.181538

Val Avg F1  380:  0.6935080988917307

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 381
--------------------------------------------------------------
Epoch:  381        1 Batch loss: 0.179967 Batch F1: 0.5806451612903226
Epoch:  381        2 Batch loss: 0.179511 Batch F1: 0.7346938775510203
Epoch:  381        3 Batch loss: 0.154181 Batch F1: 0.7916666666666667
Epoch:  381        4 Batch loss: 0.172634 Batch F1: 0.6956521739130435
Epoch:  381        5 Batch loss: 0.179262 Batch F1: 0.7083333333333334
Epoch:  381        6 Batch loss: 0.167465 Batch F1: 0.75
Epoch:  381        7 Batch loss: 0.162674 Batch F1: 0.7826086956521738
Epoch:  381        8 Batch loss: 0.125639 Batch F1: 0.888888888888889
Epoch:  381        9 Batch loss: 0.164618 Batch F1: 0.7843137254901961
Epoch:  381       10 Batch loss: 0.205750 Batch F1: 0.48648648648648646
Epoch:  381       11 Batch loss: 0.178236 Batch F1: 0.7636363636363636
Epoch:  381       12 Batch loss: 0.184106 Batch F1: 0.625
Train Avg Loss  381: 0.171170

Train Avg F1  381: 0.7159937810757079

Val Avg Loss  381: 0.181144

Val Avg F1  381:  0.6809645232815964

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 382
--------------------------------------------------------------
Epoch:  382        1 Batch loss: 0.183544 Batch F1: 0.7719298245614034
Epoch:  382        2 Batch loss: 0.195427 Batch F1: 0.6808510638297872
Epoch:  382        3 Batch loss: 0.151429 Batch F1: 0.7441860465116279
Epoch:  382        4 Batch loss: 0.179982 Batch F1: 0.6500000000000001
Epoch:  382        5 Batch loss: 0.161881 Batch F1: 0.7142857142857143
Epoch:  382        6 Batch loss: 0.171023 Batch F1: 0.7
Epoch:  382        7 Batch loss: 0.164166 Batch F1: 0.7727272727272727
Epoch:  382        8 Batch loss: 0.152956 Batch F1: 0.7142857142857143
Epoch:  382        9 Batch loss: 0.173974 Batch F1: 0.7441860465116279
Epoch:  382       10 Batch loss: 0.207017 Batch F1: 0.5833333333333334
Epoch:  382       11 Batch loss: 0.146999 Batch F1: 0.7692307692307692
Epoch:  382       12 Batch loss: 0.176306 Batch F1: 0.717948717948718
Train Avg Loss  382: 0.172059

Train Avg F1  382: 0.7135803752688306

Val Avg Loss  382: 0.180944

Val Avg F1  382:  0.7089982269503546

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 383
--------------------------------------------------------------
Epoch:  383        1 Batch loss: 0.180913 Batch F1: 0.6829268292682926
Epoch:  383        2 Batch loss: 0.144744 Batch F1: 0.8620689655172413
Epoch:  383        3 Batch loss: 0.171868 Batch F1: 0.6976744186046512
Epoch:  383        4 Batch loss: 0.161750 Batch F1: 0.7727272727272727
Epoch:  383        5 Batch loss: 0.190737 Batch F1: 0.5555555555555556
Epoch:  383        6 Batch loss: 0.165090 Batch F1: 0.7083333333333333
Epoch:  383        7 Batch loss: 0.155206 Batch F1: 0.7027027027027027
Epoch:  383        8 Batch loss: 0.166846 Batch F1: 0.7111111111111111
Epoch:  383        9 Batch loss: 0.181112 Batch F1: 0.7719298245614034
Epoch:  383       10 Batch loss: 0.179538 Batch F1: 0.7391304347826088
Epoch:  383       11 Batch loss: 0.150825 Batch F1: 0.7727272727272727
Epoch:  383       12 Batch loss: 0.219575 Batch F1: 0.5555555555555556
Train Avg Loss  383: 0.172350

Train Avg F1  383: 0.7110369397039166

Val Avg Loss  383: 0.181991

Val Avg F1  383:  0.6782859078590786

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 384
--------------------------------------------------------------
Epoch:  384        1 Batch loss: 0.191206 Batch F1: 0.653061224489796
Epoch:  384        2 Batch loss: 0.179365 Batch F1: 0.6976744186046512
Epoch:  384        3 Batch loss: 0.166929 Batch F1: 0.6666666666666667
Epoch:  384        4 Batch loss: 0.138350 Batch F1: 0.8510638297872339
Epoch:  384        5 Batch loss: 0.175626 Batch F1: 0.5714285714285715
Epoch:  384        6 Batch loss: 0.149182 Batch F1: 0.7567567567567567
Epoch:  384        7 Batch loss: 0.184366 Batch F1: 0.5581395348837208
Epoch:  384        8 Batch loss: 0.167774 Batch F1: 0.6666666666666665
Epoch:  384        9 Batch loss: 0.216718 Batch F1: 0.6122448979591836
Epoch:  384       10 Batch loss: 0.164029 Batch F1: 0.7441860465116279
Epoch:  384       11 Batch loss: 0.157922 Batch F1: 0.8400000000000001
Epoch:  384       12 Batch loss: 0.177499 Batch F1: 0.7391304347826085
Train Avg Loss  384: 0.172414

Train Avg F1  384: 0.6964182540447905

Val Avg Loss  384: 0.181790

Val Avg F1  384:  0.6814500955049585

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 385
--------------------------------------------------------------
Epoch:  385        1 Batch loss: 0.181771 Batch F1: 0.65
Epoch:  385        2 Batch loss: 0.171821 Batch F1: 0.7500000000000001
Epoch:  385        3 Batch loss: 0.214004 Batch F1: 0.6
Epoch:  385        4 Batch loss: 0.191874 Batch F1: 0.7272727272727272
Epoch:  385        5 Batch loss: 0.147969 Batch F1: 0.7727272727272727
Epoch:  385        6 Batch loss: 0.179057 Batch F1: 0.7346938775510203
Epoch:  385        7 Batch loss: 0.138436 Batch F1: 0.8571428571428572
Epoch:  385        8 Batch loss: 0.152042 Batch F1: 0.7804878048780488
Epoch:  385        9 Batch loss: 0.194465 Batch F1: 0.6222222222222222
Epoch:  385       10 Batch loss: 0.170232 Batch F1: 0.7111111111111111
Epoch:  385       11 Batch loss: 0.169760 Batch F1: 0.7272727272727272
Epoch:  385       12 Batch loss: 0.143645 Batch F1: 0.8125
Train Avg Loss  385: 0.171256

Train Avg F1  385: 0.7287858833481656

Val Avg Loss  385: 0.184313

Val Avg F1  385:  0.6747019220886011

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 386
--------------------------------------------------------------
Epoch:  386        1 Batch loss: 0.142177 Batch F1: 0.8679245283018867
Epoch:  386        2 Batch loss: 0.159208 Batch F1: 0.8275862068965518
Epoch:  386        3 Batch loss: 0.199053 Batch F1: 0.5714285714285715
Epoch:  386        4 Batch loss: 0.179519 Batch F1: 0.6666666666666666
Epoch:  386        5 Batch loss: 0.149839 Batch F1: 0.7804878048780488
Epoch:  386        6 Batch loss: 0.177675 Batch F1: 0.6363636363636365
Epoch:  386        7 Batch loss: 0.187310 Batch F1: 0.6666666666666666
Epoch:  386        8 Batch loss: 0.161230 Batch F1: 0.7222222222222222
Epoch:  386        9 Batch loss: 0.152328 Batch F1: 0.761904761904762
Epoch:  386       10 Batch loss: 0.161512 Batch F1: 0.7317073170731706
Epoch:  386       11 Batch loss: 0.191786 Batch F1: 0.6521739130434783
Epoch:  386       12 Batch loss: 0.226858 Batch F1: 0.5365853658536585
Train Avg Loss  386: 0.174041

Train Avg F1  386: 0.7018098051082767

Val Avg Loss  386: 0.188524

Val Avg F1  386:  0.6395427307883752

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 387
--------------------------------------------------------------
Epoch:  387        1 Batch loss: 0.172597 Batch F1: 0.7272727272727273
Epoch:  387        2 Batch loss: 0.181892 Batch F1: 0.5500000000000002
Epoch:  387        3 Batch loss: 0.210579 Batch F1: 0.6315789473684211
Epoch:  387        4 Batch loss: 0.155952 Batch F1: 0.7777777777777777
Epoch:  387        5 Batch loss: 0.205561 Batch F1: 0.625
Epoch:  387        6 Batch loss: 0.150575 Batch F1: 0.8181818181818182
Epoch:  387        7 Batch loss: 0.167683 Batch F1: 0.823529411764706
Epoch:  387        8 Batch loss: 0.182802 Batch F1: 0.6818181818181819
Epoch:  387        9 Batch loss: 0.154816 Batch F1: 0.6451612903225806
Epoch:  387       10 Batch loss: 0.202895 Batch F1: 0.5853658536585366
Epoch:  387       11 Batch loss: 0.151751 Batch F1: 0.7222222222222222
Epoch:  387       12 Batch loss: 0.152474 Batch F1: 0.7567567567567567
Train Avg Loss  387: 0.174131

Train Avg F1  387: 0.695388748928644

Val Avg Loss  387: 0.184932

Val Avg F1  387:  0.6943839703273665

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 388
--------------------------------------------------------------
Epoch:  388        1 Batch loss: 0.161242 Batch F1: 0.7391304347826085
Epoch:  388        2 Batch loss: 0.176695 Batch F1: 0.7142857142857143
Epoch:  388        3 Batch loss: 0.173688 Batch F1: 0.5625
Epoch:  388        4 Batch loss: 0.188114 Batch F1: 0.7200000000000001
Epoch:  388        5 Batch loss: 0.159111 Batch F1: 0.7727272727272727
Epoch:  388        6 Batch loss: 0.168002 Batch F1: 0.723404255319149
Epoch:  388        7 Batch loss: 0.195133 Batch F1: 0.6511627906976745
Epoch:  388        8 Batch loss: 0.143248 Batch F1: 0.8260869565217391
Epoch:  388        9 Batch loss: 0.166572 Batch F1: 0.7391304347826089
Epoch:  388       10 Batch loss: 0.166581 Batch F1: 0.611111111111111
Epoch:  388       11 Batch loss: 0.194335 Batch F1: 0.6909090909090909
Epoch:  388       12 Batch loss: 0.199691 Batch F1: 0.6818181818181819
Train Avg Loss  388: 0.174368

Train Avg F1  388: 0.702688853579596

Val Avg Loss  388: 0.184018

Val Avg F1  388:  0.727627206935685

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 389
--------------------------------------------------------------
Epoch:  389        1 Batch loss: 0.175682 Batch F1: 0.7916666666666666
Epoch:  389        2 Batch loss: 0.127809 Batch F1: 0.8695652173913043
Epoch:  389        3 Batch loss: 0.164487 Batch F1: 0.7999999999999999
Epoch:  389        4 Batch loss: 0.158244 Batch F1: 0.7428571428571428
Epoch:  389        5 Batch loss: 0.192275 Batch F1: 0.5142857142857143
Epoch:  389        6 Batch loss: 0.172941 Batch F1: 0.7346938775510203
Epoch:  389        7 Batch loss: 0.188093 Batch F1: 0.6938775510204083
Epoch:  389        8 Batch loss: 0.166405 Batch F1: 0.7441860465116279
Epoch:  389        9 Batch loss: 0.180690 Batch F1: 0.7346938775510204
Epoch:  389       10 Batch loss: 0.163503 Batch F1: 0.7727272727272727
Epoch:  389       11 Batch loss: 0.180633 Batch F1: 0.7307692307692308
Epoch:  389       12 Batch loss: 0.225482 Batch F1: 0.7755102040816326
Train Avg Loss  389: 0.174687

Train Avg F1  389: 0.7420694001177534

Val Avg Loss  389: 0.186763

Val Avg F1  389:  0.7971556084856577

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 390
--------------------------------------------------------------
Epoch:  390        1 Batch loss: 0.179431 Batch F1: 0.8421052631578947
Epoch:  390        2 Batch loss: 0.205922 Batch F1: 0.6511627906976745
Epoch:  390        3 Batch loss: 0.186139 Batch F1: 0.7692307692307692
Epoch:  390        4 Batch loss: 0.154256 Batch F1: 0.8085106382978724
Epoch:  390        5 Batch loss: 0.172139 Batch F1: 0.8076923076923077
Epoch:  390        6 Batch loss: 0.160675 Batch F1: 0.7272727272727274
Epoch:  390        7 Batch loss: 0.195122 Batch F1: 0.47368421052631576
Epoch:  390        8 Batch loss: 0.187488 Batch F1: 0.6538461538461539
Epoch:  390        9 Batch loss: 0.177185 Batch F1: 0.5853658536585366
Epoch:  390       10 Batch loss: 0.190393 Batch F1: 0.631578947368421
Epoch:  390       11 Batch loss: 0.157487 Batch F1: 0.7555555555555555
Epoch:  390       12 Batch loss: 0.175596 Batch F1: 0.6666666666666665
Train Avg Loss  390: 0.178486

Train Avg F1  390: 0.6977226569975746

Val Avg Loss  390: 0.188958

Val Avg F1  390:  0.6693729939528259

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 391
--------------------------------------------------------------
Epoch:  391        1 Batch loss: 0.174745 Batch F1: 0.711111111111111
Epoch:  391        2 Batch loss: 0.179353 Batch F1: 0.6956521739130435
Epoch:  391        3 Batch loss: 0.161595 Batch F1: 0.7916666666666667
Epoch:  391        4 Batch loss: 0.171528 Batch F1: 0.7450980392156863
Epoch:  391        5 Batch loss: 0.192656 Batch F1: 0.6666666666666666
Epoch:  391        6 Batch loss: 0.146580 Batch F1: 0.8444444444444444
Epoch:  391        7 Batch loss: 0.186842 Batch F1: 0.6153846153846153
Epoch:  391        8 Batch loss: 0.195446 Batch F1: 0.6222222222222223
Epoch:  391        9 Batch loss: 0.156480 Batch F1: 0.7027027027027027
Epoch:  391       10 Batch loss: 0.169700 Batch F1: 0.6666666666666667
Epoch:  391       11 Batch loss: 0.181364 Batch F1: 0.6341463414634146
Epoch:  391       12 Batch loss: 0.176433 Batch F1: 0.8181818181818182
Train Avg Loss  391: 0.174393

Train Avg F1  391: 0.7094952890532548

Val Avg Loss  391: 0.184883

Val Avg F1  391:  0.6770833333333333

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 392
--------------------------------------------------------------
Epoch:  392        1 Batch loss: 0.180890 Batch F1: 0.6222222222222223
Epoch:  392        2 Batch loss: 0.206333 Batch F1: 0.6538461538461539
Epoch:  392        3 Batch loss: 0.177693 Batch F1: 0.5882352941176471
Epoch:  392        4 Batch loss: 0.166891 Batch F1: 0.6666666666666666
Epoch:  392        5 Batch loss: 0.163180 Batch F1: 0.761904761904762
Epoch:  392        6 Batch loss: 0.161524 Batch F1: 0.7843137254901961
Epoch:  392        7 Batch loss: 0.155197 Batch F1: 0.7659574468085107
Epoch:  392        8 Batch loss: 0.162194 Batch F1: 0.8181818181818182
Epoch:  392        9 Batch loss: 0.194553 Batch F1: 0.6382978723404256
Epoch:  392       10 Batch loss: 0.172344 Batch F1: 0.7234042553191491
Epoch:  392       11 Batch loss: 0.169572 Batch F1: 0.7368421052631577
Epoch:  392       12 Batch loss: 0.157763 Batch F1: 0.8444444444444444
Train Avg Loss  392: 0.172344

Train Avg F1  392: 0.7170263972170962

Val Avg Loss  392: 0.187463

Val Avg F1  392:  0.6798868568988828

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 393
--------------------------------------------------------------
Epoch:  393        1 Batch loss: 0.181138 Batch F1: 0.6829268292682926
Epoch:  393        2 Batch loss: 0.182597 Batch F1: 0.7857142857142856
Epoch:  393        3 Batch loss: 0.182673 Batch F1: 0.7200000000000001
Epoch:  393        4 Batch loss: 0.167820 Batch F1: 0.7692307692307692
Epoch:  393        5 Batch loss: 0.157063 Batch F1: 0.8205128205128205
Epoch:  393        6 Batch loss: 0.151881 Batch F1: 0.8095238095238095
Epoch:  393        7 Batch loss: 0.165294 Batch F1: 0.75
Epoch:  393        8 Batch loss: 0.193184 Batch F1: 0.6250000000000001
Epoch:  393        9 Batch loss: 0.179348 Batch F1: 0.6956521739130435
Epoch:  393       10 Batch loss: 0.137660 Batch F1: 0.8108108108108109
Epoch:  393       11 Batch loss: 0.212129 Batch F1: 0.6779661016949152
Epoch:  393       12 Batch loss: 0.197284 Batch F1: 0.6486486486486486
Train Avg Loss  393: 0.175673

Train Avg F1  393: 0.732998854109783

Val Avg Loss  393: 0.184610

Val Avg F1  393:  0.7107446276861569

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 394
--------------------------------------------------------------
Epoch:  394        1 Batch loss: 0.155577 Batch F1: 0.8363636363636364
Epoch:  394        2 Batch loss: 0.181676 Batch F1: 0.7727272727272727
Epoch:  394        3 Batch loss: 0.186558 Batch F1: 0.7142857142857143
Epoch:  394        4 Batch loss: 0.188112 Batch F1: 0.736842105263158
Epoch:  394        5 Batch loss: 0.162532 Batch F1: 0.711111111111111
Epoch:  394        6 Batch loss: 0.192868 Batch F1: 0.5555555555555556
Epoch:  394        7 Batch loss: 0.191361 Batch F1: 0.7719298245614035
Epoch:  394        8 Batch loss: 0.141416 Batch F1: 0.8571428571428571
Epoch:  394        9 Batch loss: 0.161309 Batch F1: 0.6470588235294118
Epoch:  394       10 Batch loss: 0.200209 Batch F1: 0.6382978723404256
Epoch:  394       11 Batch loss: 0.157707 Batch F1: 0.7499999999999999
Epoch:  394       12 Batch loss: 0.169842 Batch F1: 0.6451612903225806
Train Avg Loss  394: 0.174097

Train Avg F1  394: 0.7197063386002606

Val Avg Loss  394: 0.182371

Val Avg F1  394:  0.6817871081611853

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 395
--------------------------------------------------------------
Epoch:  395        1 Batch loss: 0.174941 Batch F1: 0.7307692307692308
Epoch:  395        2 Batch loss: 0.154690 Batch F1: 0.7916666666666666
Epoch:  395        3 Batch loss: 0.185141 Batch F1: 0.7307692307692306
Epoch:  395        4 Batch loss: 0.188432 Batch F1: 0.6285714285714286
Epoch:  395        5 Batch loss: 0.163812 Batch F1: 0.7083333333333334
Epoch:  395        6 Batch loss: 0.163085 Batch F1: 0.723404255319149
Epoch:  395        7 Batch loss: 0.181677 Batch F1: 0.6470588235294118
Epoch:  395        8 Batch loss: 0.216396 Batch F1: 0.7599999999999999
Epoch:  395        9 Batch loss: 0.147210 Batch F1: 0.7428571428571428
Epoch:  395       10 Batch loss: 0.178974 Batch F1: 0.6111111111111112
Epoch:  395       11 Batch loss: 0.147945 Batch F1: 0.830188679245283
Epoch:  395       12 Batch loss: 0.194433 Batch F1: 0.606060606060606
Train Avg Loss  395: 0.174728

Train Avg F1  395: 0.7092325423527162

Val Avg Loss  395: 0.186308

Val Avg F1  395:  0.6690823224307012

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 396
--------------------------------------------------------------
Epoch:  396        1 Batch loss: 0.156327 Batch F1: 0.7500000000000001
Epoch:  396        2 Batch loss: 0.171824 Batch F1: 0.6666666666666666
Epoch:  396        3 Batch loss: 0.198722 Batch F1: 0.7272727272727274
Epoch:  396        4 Batch loss: 0.164751 Batch F1: 0.7142857142857143
Epoch:  396        5 Batch loss: 0.172613 Batch F1: 0.7111111111111111
Epoch:  396        6 Batch loss: 0.183879 Batch F1: 0.6666666666666666
Epoch:  396        7 Batch loss: 0.175044 Batch F1: 0.6829268292682926
Epoch:  396        8 Batch loss: 0.142493 Batch F1: 0.8000000000000002
Epoch:  396        9 Batch loss: 0.197035 Batch F1: 0.68
Epoch:  396       10 Batch loss: 0.154175 Batch F1: 0.8085106382978724
Epoch:  396       11 Batch loss: 0.208096 Batch F1: 0.5581395348837209
Epoch:  396       12 Batch loss: 0.161162 Batch F1: 0.7804878048780488
Train Avg Loss  396: 0.173843

Train Avg F1  396: 0.7121723077775685

Val Avg Loss  396: 0.183688

Val Avg F1  396:  0.6772926941251728

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 397
--------------------------------------------------------------
Epoch:  397        1 Batch loss: 0.199077 Batch F1: 0.6190476190476191
Epoch:  397        2 Batch loss: 0.165480 Batch F1: 0.7272727272727272
Epoch:  397        3 Batch loss: 0.182182 Batch F1: 0.7199999999999999
Epoch:  397        4 Batch loss: 0.161153 Batch F1: 0.6842105263157895
Epoch:  397        5 Batch loss: 0.148552 Batch F1: 0.8085106382978723
Epoch:  397        6 Batch loss: 0.183159 Batch F1: 0.6666666666666665
Epoch:  397        7 Batch loss: 0.182482 Batch F1: 0.7307692307692308
Epoch:  397        8 Batch loss: 0.157235 Batch F1: 0.7727272727272727
Epoch:  397        9 Batch loss: 0.164599 Batch F1: 0.6829268292682926
Epoch:  397       10 Batch loss: 0.170732 Batch F1: 0.7719298245614036
Epoch:  397       11 Batch loss: 0.172323 Batch F1: 0.6857142857142857
Epoch:  397       12 Batch loss: 0.166619 Batch F1: 0.6
Train Avg Loss  397: 0.171133

Train Avg F1  397: 0.70581463505343

Val Avg Loss  397: 0.187028

Val Avg F1  397:  0.6692115727409845

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 398
--------------------------------------------------------------
Epoch:  398        1 Batch loss: 0.145796 Batch F1: 0.8205128205128205
Epoch:  398        2 Batch loss: 0.173172 Batch F1: 0.6666666666666667
Epoch:  398        3 Batch loss: 0.179666 Batch F1: 0.6511627906976745
Epoch:  398        4 Batch loss: 0.153763 Batch F1: 0.8333333333333334
Epoch:  398        5 Batch loss: 0.159950 Batch F1: 0.8571428571428572
Epoch:  398        6 Batch loss: 0.164928 Batch F1: 0.7843137254901961
Epoch:  398        7 Batch loss: 0.170098 Batch F1: 0.7692307692307692
Epoch:  398        8 Batch loss: 0.191041 Batch F1: 0.7346938775510204
Epoch:  398        9 Batch loss: 0.190050 Batch F1: 0.6530612244897959
Epoch:  398       10 Batch loss: 0.207098 Batch F1: 0.6666666666666666
Epoch:  398       11 Batch loss: 0.181293 Batch F1: 0.6190476190476191
Epoch:  398       12 Batch loss: 0.181983 Batch F1: 0.625
Train Avg Loss  398: 0.174903

Train Avg F1  398: 0.7234026959024517

Val Avg Loss  398: 0.188890

Val Avg F1  398:  0.6713813668600903

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 399
--------------------------------------------------------------
Epoch:  399        1 Batch loss: 0.162107 Batch F1: 0.717948717948718
Epoch:  399        2 Batch loss: 0.161807 Batch F1: 0.7619047619047619
Epoch:  399        3 Batch loss: 0.185744 Batch F1: 0.7083333333333333
Epoch:  399        4 Batch loss: 0.157360 Batch F1: 0.6842105263157896
Epoch:  399        5 Batch loss: 0.174051 Batch F1: 0.6956521739130435
Epoch:  399        6 Batch loss: 0.177720 Batch F1: 0.6486486486486486
Epoch:  399        7 Batch loss: 0.190124 Batch F1: 0.5945945945945946
Epoch:  399        8 Batch loss: 0.140247 Batch F1: 0.8928571428571429
Epoch:  399        9 Batch loss: 0.193351 Batch F1: 0.6222222222222222
Epoch:  399       10 Batch loss: 0.165185 Batch F1: 0.8
Epoch:  399       11 Batch loss: 0.200532 Batch F1: 0.7058823529411765
Epoch:  399       12 Batch loss: 0.178367 Batch F1: 0.6666666666666667
Train Avg Loss  399: 0.173883

Train Avg F1  399: 0.708243428445508

Val Avg Loss  399: 0.186196

Val Avg F1  399:  0.6892712550607287

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 400
--------------------------------------------------------------
Epoch:  400        1 Batch loss: 0.185401 Batch F1: 0.6046511627906976
Epoch:  400        2 Batch loss: 0.188840 Batch F1: 0.6938775510204083
Epoch:  400        3 Batch loss: 0.162341 Batch F1: 0.7547169811320756
Epoch:  400        4 Batch loss: 0.173822 Batch F1: 0.6829268292682927
Epoch:  400        5 Batch loss: 0.224705 Batch F1: 0.576923076923077
Epoch:  400        6 Batch loss: 0.135492 Batch F1: 0.8095238095238095
Epoch:  400        7 Batch loss: 0.240630 Batch F1: 0.4736842105263157
Epoch:  400        8 Batch loss: 0.193687 Batch F1: 0.6
Epoch:  400        9 Batch loss: 0.155681 Batch F1: 0.6341463414634148
Epoch:  400       10 Batch loss: 0.153269 Batch F1: 0.8214285714285715
Epoch:  400       11 Batch loss: 0.162483 Batch F1: 0.7083333333333334
Epoch:  400       12 Batch loss: 0.157015 Batch F1: 0.7894736842105262
Train Avg Loss  400: 0.177781

Train Avg F1  400: 0.6791404626350435

Val Avg Loss  400: 0.193228

Val Avg F1  400:  0.679909983633388

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 401
--------------------------------------------------------------
Epoch:  401        1 Batch loss: 0.170958 Batch F1: 0.717948717948718
Epoch:  401        2 Batch loss: 0.195604 Batch F1: 0.6511627906976744
Epoch:  401        3 Batch loss: 0.168365 Batch F1: 0.7826086956521738
Epoch:  401        4 Batch loss: 0.124832 Batch F1: 0.7999999999999999
Epoch:  401        5 Batch loss: 0.182632 Batch F1: 0.6666666666666666
Epoch:  401        6 Batch loss: 0.186663 Batch F1: 0.6
Epoch:  401        7 Batch loss: 0.171316 Batch F1: 0.7555555555555556
Epoch:  401        8 Batch loss: 0.168878 Batch F1: 0.7391304347826088
Epoch:  401        9 Batch loss: 0.190157 Batch F1: 0.7659574468085106
Epoch:  401       10 Batch loss: 0.213368 Batch F1: 0.6551724137931035
Epoch:  401       11 Batch loss: 0.151039 Batch F1: 0.6666666666666667
Epoch:  401       12 Batch loss: 0.198116 Batch F1: 0.7346938775510203
Train Avg Loss  401: 0.176827

Train Avg F1  401: 0.711296938843558

Val Avg Loss  401: 0.190937

Val Avg F1  401:  0.664501810246491

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 402
--------------------------------------------------------------
Epoch:  402        1 Batch loss: 0.147129 Batch F1: 0.7924528301886792
Epoch:  402        2 Batch loss: 0.154858 Batch F1: 0.7555555555555556
Epoch:  402        3 Batch loss: 0.197599 Batch F1: 0.64
Epoch:  402        4 Batch loss: 0.165511 Batch F1: 0.76
Epoch:  402        5 Batch loss: 0.159891 Batch F1: 0.5714285714285715
Epoch:  402        6 Batch loss: 0.180286 Batch F1: 0.6500000000000001
Epoch:  402        7 Batch loss: 0.222538 Batch F1: 0.6382978723404256
Epoch:  402        8 Batch loss: 0.177528 Batch F1: 0.8148148148148148
Epoch:  402        9 Batch loss: 0.178011 Batch F1: 0.5882352941176471
Epoch:  402       10 Batch loss: 0.183194 Batch F1: 0.6511627906976744
Epoch:  402       11 Batch loss: 0.186927 Batch F1: 0.6521739130434783
Epoch:  402       12 Batch loss: 0.160632 Batch F1: 0.7500000000000001
Train Avg Loss  402: 0.176175

Train Avg F1  402: 0.6886768035155706

Val Avg Loss  402: 0.185205

Val Avg F1  402:  0.7011120330982669

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 403
--------------------------------------------------------------
Epoch:  403        1 Batch loss: 0.175627 Batch F1: 0.693877551020408
Epoch:  403        2 Batch loss: 0.180975 Batch F1: 0.7843137254901961
Epoch:  403        3 Batch loss: 0.158603 Batch F1: 0.782608695652174
Epoch:  403        4 Batch loss: 0.197261 Batch F1: 0.6222222222222223
Epoch:  403        5 Batch loss: 0.145659 Batch F1: 0.7777777777777778
Epoch:  403        6 Batch loss: 0.184484 Batch F1: 0.6341463414634146
Epoch:  403        7 Batch loss: 0.174667 Batch F1: 0.6818181818181818
Epoch:  403        8 Batch loss: 0.170820 Batch F1: 0.6818181818181819
Epoch:  403        9 Batch loss: 0.178705 Batch F1: 0.7111111111111111
Epoch:  403       10 Batch loss: 0.166403 Batch F1: 0.7755102040816326
Epoch:  403       11 Batch loss: 0.175900 Batch F1: 0.7727272727272727
Epoch:  403       12 Batch loss: 0.186934 Batch F1: 0.6666666666666666
Train Avg Loss  403: 0.174670

Train Avg F1  403: 0.7153831609874365

Val Avg Loss  403: 0.186995

Val Avg F1  403:  0.6674998062466093

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 404
--------------------------------------------------------------
Epoch:  404        1 Batch loss: 0.162605 Batch F1: 0.606060606060606
Epoch:  404        2 Batch loss: 0.182176 Batch F1: 0.7234042553191489
Epoch:  404        3 Batch loss: 0.188944 Batch F1: 0.5789473684210527
Epoch:  404        4 Batch loss: 0.173940 Batch F1: 0.8163265306122449
Epoch:  404        5 Batch loss: 0.179483 Batch F1: 0.6
Epoch:  404        6 Batch loss: 0.164026 Batch F1: 0.8000000000000002
Epoch:  404        7 Batch loss: 0.161423 Batch F1: 0.723404255319149
Epoch:  404        8 Batch loss: 0.161133 Batch F1: 0.8444444444444444
Epoch:  404        9 Batch loss: 0.190260 Batch F1: 0.6808510638297872
Epoch:  404       10 Batch loss: 0.199704 Batch F1: 0.6785714285714285
Epoch:  404       11 Batch loss: 0.157416 Batch F1: 0.851063829787234
Epoch:  404       12 Batch loss: 0.174414 Batch F1: 0.7777777777777777
Train Avg Loss  404: 0.174627

Train Avg F1  404: 0.7234042966785728

Val Avg Loss  404: 0.186307

Val Avg F1  404:  0.696703942138064

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 405
--------------------------------------------------------------
Epoch:  405        1 Batch loss: 0.180361 Batch F1: 0.7346938775510203
Epoch:  405        2 Batch loss: 0.171063 Batch F1: 0.5882352941176471
Epoch:  405        3 Batch loss: 0.164514 Batch F1: 0.7755102040816326
Epoch:  405        4 Batch loss: 0.201510 Batch F1: 0.6923076923076923
Epoch:  405        5 Batch loss: 0.190202 Batch F1: 0.6666666666666666
Epoch:  405        6 Batch loss: 0.179985 Batch F1: 0.6500000000000001
Epoch:  405        7 Batch loss: 0.194463 Batch F1: 0.6530612244897959
Epoch:  405        8 Batch loss: 0.172215 Batch F1: 0.7659574468085107
Epoch:  405        9 Batch loss: 0.146019 Batch F1: 0.8571428571428571
Epoch:  405       10 Batch loss: 0.155293 Batch F1: 0.8085106382978724
Epoch:  405       11 Batch loss: 0.185559 Batch F1: 0.6511627906976744
Epoch:  405       12 Batch loss: 0.162364 Batch F1: 0.6206896551724138
Train Avg Loss  405: 0.175296

Train Avg F1  405: 0.7053281956111487

Val Avg Loss  405: 0.184781

Val Avg F1  405:  0.6745833333333333

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 406
--------------------------------------------------------------
Epoch:  406        1 Batch loss: 0.161170 Batch F1: 0.75
Epoch:  406        2 Batch loss: 0.178608 Batch F1: 0.6500000000000001
Epoch:  406        3 Batch loss: 0.172605 Batch F1: 0.7142857142857143
Epoch:  406        4 Batch loss: 0.170167 Batch F1: 0.76
Epoch:  406        5 Batch loss: 0.177232 Batch F1: 0.7346938775510203
Epoch:  406        6 Batch loss: 0.155936 Batch F1: 0.7916666666666667
Epoch:  406        7 Batch loss: 0.167850 Batch F1: 0.7692307692307693
Epoch:  406        8 Batch loss: 0.154093 Batch F1: 0.7999999999999999
Epoch:  406        9 Batch loss: 0.211240 Batch F1: 0.4864864864864864
Epoch:  406       10 Batch loss: 0.190707 Batch F1: 0.6046511627906976
Epoch:  406       11 Batch loss: 0.154126 Batch F1: 0.7222222222222222
Epoch:  406       12 Batch loss: 0.176160 Batch F1: 0.7272727272727273
Train Avg Loss  406: 0.172491

Train Avg F1  406: 0.709209135542192

Val Avg Loss  406: 0.182801

Val Avg F1  406:  0.6752410777494386

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 407
--------------------------------------------------------------
Epoch:  407        1 Batch loss: 0.161354 Batch F1: 0.7317073170731708
Epoch:  407        2 Batch loss: 0.217171 Batch F1: 0.5652173913043479
Epoch:  407        3 Batch loss: 0.169667 Batch F1: 0.6666666666666666
Epoch:  407        4 Batch loss: 0.172292 Batch F1: 0.7555555555555555
Epoch:  407        5 Batch loss: 0.170928 Batch F1: 0.7111111111111111
Epoch:  407        6 Batch loss: 0.175513 Batch F1: 0.6666666666666666
Epoch:  407        7 Batch loss: 0.168113 Batch F1: 0.7826086956521738
Epoch:  407        8 Batch loss: 0.162926 Batch F1: 0.7391304347826088
Epoch:  407        9 Batch loss: 0.134953 Batch F1: 0.8928571428571429
Epoch:  407       10 Batch loss: 0.179624 Batch F1: 0.6666666666666666
Epoch:  407       11 Batch loss: 0.172913 Batch F1: 0.7317073170731708
Epoch:  407       12 Batch loss: 0.185579 Batch F1: 0.6666666666666666
Train Avg Loss  407: 0.172586

Train Avg F1  407: 0.7147134693396624

Val Avg Loss  407: 0.184359

Val Avg F1  407:  0.6781937384733031

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 408
--------------------------------------------------------------
Epoch:  408        1 Batch loss: 0.154042 Batch F1: 0.761904761904762
Epoch:  408        2 Batch loss: 0.161728 Batch F1: 0.7142857142857143
Epoch:  408        3 Batch loss: 0.172846 Batch F1: 0.7450980392156864
Epoch:  408        4 Batch loss: 0.183336 Batch F1: 0.6363636363636365
Epoch:  408        5 Batch loss: 0.178836 Batch F1: 0.6
Epoch:  408        6 Batch loss: 0.146281 Batch F1: 0.7368421052631577
Epoch:  408        7 Batch loss: 0.176537 Batch F1: 0.744186046511628
Epoch:  408        8 Batch loss: 0.249773 Batch F1: 0.6086956521739131
Epoch:  408        9 Batch loss: 0.166202 Batch F1: 0.7391304347826089
Epoch:  408       10 Batch loss: 0.160714 Batch F1: 0.7692307692307692
Epoch:  408       11 Batch loss: 0.199397 Batch F1: 0.7916666666666667
Epoch:  408       12 Batch loss: 0.174381 Batch F1: 0.8095238095238095
Train Avg Loss  408: 0.177006

Train Avg F1  408: 0.7214106363268629

Val Avg Loss  408: 0.181358

Val Avg F1  408:  0.7363152476531779

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 409
--------------------------------------------------------------
Epoch:  409        1 Batch loss: 0.182121 Batch F1: 0.7407407407407407
Epoch:  409        2 Batch loss: 0.164181 Batch F1: 0.8000000000000002
Epoch:  409        3 Batch loss: 0.169858 Batch F1: 0.606060606060606
Epoch:  409        4 Batch loss: 0.179422 Batch F1: 0.7272727272727272
Epoch:  409        5 Batch loss: 0.189410 Batch F1: 0.6666666666666666
Epoch:  409        6 Batch loss: 0.194386 Batch F1: 0.7407407407407407
Epoch:  409        7 Batch loss: 0.190295 Batch F1: 0.6363636363636365
Epoch:  409        8 Batch loss: 0.174232 Batch F1: 0.7
Epoch:  409        9 Batch loss: 0.152568 Batch F1: 0.7727272727272727
Epoch:  409       10 Batch loss: 0.202880 Batch F1: 0.5500000000000002
Epoch:  409       11 Batch loss: 0.165353 Batch F1: 0.8076923076923077
Epoch:  409       12 Batch loss: 0.148079 Batch F1: 0.7741935483870969
Train Avg Loss  409: 0.176065

Train Avg F1  409: 0.7102048538876495

Val Avg Loss  409: 0.184131

Val Avg F1  409:  0.6840986394557822

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 410
--------------------------------------------------------------
Epoch:  410        1 Batch loss: 0.148536 Batch F1: 0.7222222222222223
Epoch:  410        2 Batch loss: 0.162212 Batch F1: 0.7222222222222223
Epoch:  410        3 Batch loss: 0.178415 Batch F1: 0.7346938775510203
Epoch:  410        4 Batch loss: 0.149032 Batch F1: 0.888888888888889
Epoch:  410        5 Batch loss: 0.178415 Batch F1: 0.6875
Epoch:  410        6 Batch loss: 0.162499 Batch F1: 0.7307692307692306
Epoch:  410        7 Batch loss: 0.177753 Batch F1: 0.76
Epoch:  410        8 Batch loss: 0.149669 Batch F1: 0.7804878048780488
Epoch:  410        9 Batch loss: 0.219829 Batch F1: 0.6274509803921569
Epoch:  410       10 Batch loss: 0.209234 Batch F1: 0.7058823529411765
Epoch:  410       11 Batch loss: 0.157031 Batch F1: 0.7727272727272727
Epoch:  410       12 Batch loss: 0.177820 Batch F1: 0.6829268292682927
Train Avg Loss  410: 0.172537

Train Avg F1  410: 0.7346476401550444

Val Avg Loss  410: 0.184669

Val Avg F1  410:  0.7224985348547245

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 411
--------------------------------------------------------------
Epoch:  411        1 Batch loss: 0.139842 Batch F1: 0.8627450980392156
Epoch:  411        2 Batch loss: 0.161098 Batch F1: 0.8695652173913043
Epoch:  411        3 Batch loss: 0.179729 Batch F1: 0.7692307692307692
Epoch:  411        4 Batch loss: 0.201696 Batch F1: 0.625
Epoch:  411        5 Batch loss: 0.167287 Batch F1: 0.7777777777777777
Epoch:  411        6 Batch loss: 0.172925 Batch F1: 0.6500000000000001
Epoch:  411        7 Batch loss: 0.187066 Batch F1: 0.6666666666666666
Epoch:  411        8 Batch loss: 0.184315 Batch F1: 0.611111111111111
Epoch:  411        9 Batch loss: 0.190373 Batch F1: 0.7111111111111111
Epoch:  411       10 Batch loss: 0.180973 Batch F1: 0.6956521739130435
Epoch:  411       11 Batch loss: 0.179025 Batch F1: 0.6222222222222223
Epoch:  411       12 Batch loss: 0.174043 Batch F1: 0.8085106382978723
Train Avg Loss  411: 0.176531

Train Avg F1  411: 0.7224660654800913

Val Avg Loss  411: 0.189307

Val Avg F1  411:  0.6721660497728026

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 412
--------------------------------------------------------------
Epoch:  412        1 Batch loss: 0.155796 Batch F1: 0.819672131147541
Epoch:  412        2 Batch loss: 0.159219 Batch F1: 0.8
Epoch:  412        3 Batch loss: 0.172804 Batch F1: 0.6956521739130435
Epoch:  412        4 Batch loss: 0.198062 Batch F1: 0.6046511627906976
Epoch:  412        5 Batch loss: 0.184200 Batch F1: 0.6909090909090909
Epoch:  412        6 Batch loss: 0.205423 Batch F1: 0.6153846153846154
Epoch:  412        7 Batch loss: 0.144806 Batch F1: 0.7272727272727272
Epoch:  412        8 Batch loss: 0.175317 Batch F1: 0.5263157894736842
Epoch:  412        9 Batch loss: 0.177744 Batch F1: 0.6315789473684211
Epoch:  412       10 Batch loss: 0.179424 Batch F1: 0.6842105263157895
Epoch:  412       11 Batch loss: 0.168032 Batch F1: 0.7727272727272727
Epoch:  412       12 Batch loss: 0.215382 Batch F1: 0.6
Train Avg Loss  412: 0.178017

Train Avg F1  412: 0.6806978697752403

Val Avg Loss  412: 0.194509

Val Avg F1  412:  0.6682620781457991

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 413
--------------------------------------------------------------
Epoch:  413        1 Batch loss: 0.168128 Batch F1: 0.7317073170731706
Epoch:  413        2 Batch loss: 0.177586 Batch F1: 0.7272727272727272
Epoch:  413        3 Batch loss: 0.156430 Batch F1: 0.7999999999999999
Epoch:  413        4 Batch loss: 0.182303 Batch F1: 0.65
Epoch:  413        5 Batch loss: 0.157569 Batch F1: 0.6842105263157895
Epoch:  413        6 Batch loss: 0.184556 Batch F1: 0.723404255319149
Epoch:  413        7 Batch loss: 0.212321 Batch F1: 0.5909090909090908
Epoch:  413        8 Batch loss: 0.144788 Batch F1: 0.8205128205128205
Epoch:  413        9 Batch loss: 0.164970 Batch F1: 0.7272727272727273
Epoch:  413       10 Batch loss: 0.183686 Batch F1: 0.6666666666666665
Epoch:  413       11 Batch loss: 0.185998 Batch F1: 0.7586206896551724
Epoch:  413       12 Batch loss: 0.191958 Batch F1: 0.6500000000000001
Train Avg Loss  413: 0.175858

Train Avg F1  413: 0.7108814017497762

Val Avg Loss  413: 0.186099

Val Avg F1  413:  0.6752346760474156

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 414
--------------------------------------------------------------
Epoch:  414        1 Batch loss: 0.158244 Batch F1: 0.8000000000000002
Epoch:  414        2 Batch loss: 0.179160 Batch F1: 0.6666666666666666
Epoch:  414        3 Batch loss: 0.160942 Batch F1: 0.8235294117647058
Epoch:  414        4 Batch loss: 0.172381 Batch F1: 0.5882352941176471
Epoch:  414        5 Batch loss: 0.172640 Batch F1: 0.6976744186046512
Epoch:  414        6 Batch loss: 0.192161 Batch F1: 0.6530612244897959
Epoch:  414        7 Batch loss: 0.177186 Batch F1: 0.7407407407407408
Epoch:  414        8 Batch loss: 0.176836 Batch F1: 0.5625
Epoch:  414        9 Batch loss: 0.161034 Batch F1: 0.8
Epoch:  414       10 Batch loss: 0.168741 Batch F1: 0.7111111111111111
Epoch:  414       11 Batch loss: 0.160896 Batch F1: 0.7826086956521738
Epoch:  414       12 Batch loss: 0.183675 Batch F1: 0.5806451612903226
Train Avg Loss  414: 0.171991

Train Avg F1  414: 0.7005643937031513

Val Avg Loss  414: 0.182530

Val Avg F1  414:  0.6855188884064265

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 415
--------------------------------------------------------------
Epoch:  415        1 Batch loss: 0.169719 Batch F1: 0.7777777777777777
Epoch:  415        2 Batch loss: 0.173502 Batch F1: 0.7307692307692308
Epoch:  415        3 Batch loss: 0.175448 Batch F1: 0.6511627906976744
Epoch:  415        4 Batch loss: 0.163679 Batch F1: 0.7222222222222222
Epoch:  415        5 Batch loss: 0.175909 Batch F1: 0.6956521739130435
Epoch:  415        6 Batch loss: 0.141607 Batch F1: 0.7804878048780488
Epoch:  415        7 Batch loss: 0.189293 Batch F1: 0.6818181818181818
Epoch:  415        8 Batch loss: 0.185835 Batch F1: 0.6956521739130435
Epoch:  415        9 Batch loss: 0.153836 Batch F1: 0.7727272727272727
Epoch:  415       10 Batch loss: 0.169325 Batch F1: 0.7441860465116279
Epoch:  415       11 Batch loss: 0.172031 Batch F1: 0.6829268292682926
Epoch:  415       12 Batch loss: 0.180742 Batch F1: 0.7906976744186046
Train Avg Loss  415: 0.170910

Train Avg F1  415: 0.7271733482429185

Val Avg Loss  415: 0.183461

Val Avg F1  415:  0.6697332458482285

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 416
--------------------------------------------------------------
Epoch:  416        1 Batch loss: 0.177017 Batch F1: 0.65
Epoch:  416        2 Batch loss: 0.164153 Batch F1: 0.7
Epoch:  416        3 Batch loss: 0.152123 Batch F1: 0.816326530612245
Epoch:  416        4 Batch loss: 0.148932 Batch F1: 0.7368421052631577
Epoch:  416        5 Batch loss: 0.225293 Batch F1: 0.5714285714285715
Epoch:  416        6 Batch loss: 0.167651 Batch F1: 0.723404255319149
Epoch:  416        7 Batch loss: 0.197523 Batch F1: 0.6666666666666666
Epoch:  416        8 Batch loss: 0.144145 Batch F1: 0.8636363636363635
Epoch:  416        9 Batch loss: 0.169682 Batch F1: 0.6829268292682926
Epoch:  416       10 Batch loss: 0.200121 Batch F1: 0.6086956521739131
Epoch:  416       11 Batch loss: 0.151187 Batch F1: 0.7692307692307692
Epoch:  416       12 Batch loss: 0.143522 Batch F1: 0.8372093023255813
Train Avg Loss  416: 0.170112

Train Avg F1  416: 0.7188639204937258

Val Avg Loss  416: 0.183220

Val Avg F1  416:  0.6755977169815773

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 417
--------------------------------------------------------------
Epoch:  417        1 Batch loss: 0.194194 Batch F1: 0.6249999999999999
Epoch:  417        2 Batch loss: 0.157278 Batch F1: 0.84
Epoch:  417        3 Batch loss: 0.157263 Batch F1: 0.7999999999999999
Epoch:  417        4 Batch loss: 0.138198 Batch F1: 0.8085106382978724
Epoch:  417        5 Batch loss: 0.160217 Batch F1: 0.7843137254901961
Epoch:  417        6 Batch loss: 0.205290 Batch F1: 0.5128205128205129
Epoch:  417        7 Batch loss: 0.151559 Batch F1: 0.6666666666666665
Epoch:  417        8 Batch loss: 0.149758 Batch F1: 0.7916666666666667
Epoch:  417        9 Batch loss: 0.178448 Batch F1: 0.6666666666666665
Epoch:  417       10 Batch loss: 0.229697 Batch F1: 0.5777777777777778
Epoch:  417       11 Batch loss: 0.173640 Batch F1: 0.723404255319149
Epoch:  417       12 Batch loss: 0.156143 Batch F1: 0.8372093023255814
Train Avg Loss  417: 0.170974

Train Avg F1  417: 0.7195030176692575

Val Avg Loss  417: 0.181312

Val Avg F1  417:  0.7058574879227053

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 418
--------------------------------------------------------------
Epoch:  418        1 Batch loss: 0.130753 Batch F1: 0.8372093023255814
Epoch:  418        2 Batch loss: 0.158608 Batch F1: 0.8163265306122449
Epoch:  418        3 Batch loss: 0.193739 Batch F1: 0.6153846153846154
Epoch:  418        4 Batch loss: 0.216653 Batch F1: 0.576923076923077
Epoch:  418        5 Batch loss: 0.170749 Batch F1: 0.6808510638297872
Epoch:  418        6 Batch loss: 0.180117 Batch F1: 0.7272727272727272
Epoch:  418        7 Batch loss: 0.170124 Batch F1: 0.7346938775510203
Epoch:  418        8 Batch loss: 0.171662 Batch F1: 0.7441860465116279
Epoch:  418        9 Batch loss: 0.156893 Batch F1: 0.7441860465116279
Epoch:  418       10 Batch loss: 0.163352 Batch F1: 0.7272727272727273
Epoch:  418       11 Batch loss: 0.177272 Batch F1: 0.7777777777777778
Epoch:  418       12 Batch loss: 0.156579 Batch F1: 0.6153846153846153
Train Avg Loss  418: 0.170542

Train Avg F1  418: 0.716455700613119

Val Avg Loss  418: 0.183987

Val Avg F1  418:  0.6741291271580379

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 419
--------------------------------------------------------------
Epoch:  419        1 Batch loss: 0.152533 Batch F1: 0.7727272727272727
Epoch:  419        2 Batch loss: 0.177274 Batch F1: 0.6666666666666666
Epoch:  419        3 Batch loss: 0.157809 Batch F1: 0.7222222222222222
Epoch:  419        4 Batch loss: 0.170758 Batch F1: 0.6818181818181818
Epoch:  419        5 Batch loss: 0.142013 Batch F1: 0.8372093023255814
Epoch:  419        6 Batch loss: 0.230584 Batch F1: 0.6153846153846154
Epoch:  419        7 Batch loss: 0.139949 Batch F1: 0.7999999999999999
Epoch:  419        8 Batch loss: 0.184209 Batch F1: 0.6363636363636365
Epoch:  419        9 Batch loss: 0.174533 Batch F1: 0.76
Epoch:  419       10 Batch loss: 0.186537 Batch F1: 0.7307692307692308
Epoch:  419       11 Batch loss: 0.186335 Batch F1: 0.7000000000000001
Epoch:  419       12 Batch loss: 0.195154 Batch F1: 0.7142857142857143
Train Avg Loss  419: 0.174807

Train Avg F1  419: 0.7197872368802601

Val Avg Loss  419: 0.185314

Val Avg F1  419:  0.6821730720713145

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 420
--------------------------------------------------------------
Epoch:  420        1 Batch loss: 0.178192 Batch F1: 0.65
Epoch:  420        2 Batch loss: 0.192601 Batch F1: 0.6956521739130435
Epoch:  420        3 Batch loss: 0.155380 Batch F1: 0.8333333333333334
Epoch:  420        4 Batch loss: 0.189511 Batch F1: 0.6938775510204083
Epoch:  420        5 Batch loss: 0.182186 Batch F1: 0.5625
Epoch:  420        6 Batch loss: 0.139416 Batch F1: 0.8181818181818182
Epoch:  420        7 Batch loss: 0.198880 Batch F1: 0.4571428571428571
Epoch:  420        8 Batch loss: 0.175070 Batch F1: 0.65
Epoch:  420        9 Batch loss: 0.172925 Batch F1: 0.7346938775510204
Epoch:  420       10 Batch loss: 0.152874 Batch F1: 0.7727272727272727
Epoch:  420       11 Batch loss: 0.169242 Batch F1: 0.7931034482758621
Epoch:  420       12 Batch loss: 0.168814 Batch F1: 0.7441860465116279
Train Avg Loss  420: 0.172924

Train Avg F1  420: 0.7004498648881037

Val Avg Loss  420: 0.184502

Val Avg F1  420:  0.7055256064690028

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 421
--------------------------------------------------------------
Epoch:  421        1 Batch loss: 0.168391 Batch F1: 0.6341463414634148
Epoch:  421        2 Batch loss: 0.178396 Batch F1: 0.6808510638297872
Epoch:  421        3 Batch loss: 0.211660 Batch F1: 0.6415094339622641
Epoch:  421        4 Batch loss: 0.165614 Batch F1: 0.8260869565217391
Epoch:  421        5 Batch loss: 0.176050 Batch F1: 0.7450980392156864
Epoch:  421        6 Batch loss: 0.166348 Batch F1: 0.8260869565217391
Epoch:  421        7 Batch loss: 0.139788 Batch F1: 0.7777777777777777
Epoch:  421        8 Batch loss: 0.185394 Batch F1: 0.6363636363636365
Epoch:  421        9 Batch loss: 0.174421 Batch F1: 0.6976744186046512
Epoch:  421       10 Batch loss: 0.169077 Batch F1: 0.7916666666666666
Epoch:  421       11 Batch loss: 0.174375 Batch F1: 0.7391304347826088
Epoch:  421       12 Batch loss: 0.154496 Batch F1: 0.7777777777777777
Train Avg Loss  421: 0.172001

Train Avg F1  421: 0.7311807919573124

Val Avg Loss  421: 0.183886

Val Avg F1  421:  0.6608452950558213

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 422
--------------------------------------------------------------
Epoch:  422        1 Batch loss: 0.146026 Batch F1: 0.8163265306122449
Epoch:  422        2 Batch loss: 0.149470 Batch F1: 0.6470588235294117
Epoch:  422        3 Batch loss: 0.164317 Batch F1: 0.7391304347826088
Epoch:  422        4 Batch loss: 0.208889 Batch F1: 0.5641025641025642
Epoch:  422        5 Batch loss: 0.143326 Batch F1: 0.8627450980392156
Epoch:  422        6 Batch loss: 0.159485 Batch F1: 0.8076923076923077
Epoch:  422        7 Batch loss: 0.195777 Batch F1: 0.7058823529411765
Epoch:  422        8 Batch loss: 0.178577 Batch F1: 0.7083333333333333
Epoch:  422        9 Batch loss: 0.177053 Batch F1: 0.6341463414634146
Epoch:  422       10 Batch loss: 0.202160 Batch F1: 0.55
Epoch:  422       11 Batch loss: 0.190541 Batch F1: 0.7083333333333334
Epoch:  422       12 Batch loss: 0.183675 Batch F1: 0.6451612903225806
Train Avg Loss  422: 0.174942

Train Avg F1  422: 0.6990760341793493

Val Avg Loss  422: 0.185193

Val Avg F1  422:  0.7286105738233398

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 423
--------------------------------------------------------------
Epoch:  423        1 Batch loss: 0.181472 Batch F1: 0.7083333333333334
Epoch:  423        2 Batch loss: 0.177540 Batch F1: 0.7083333333333333
Epoch:  423        3 Batch loss: 0.145030 Batch F1: 0.823529411764706
Epoch:  423        4 Batch loss: 0.173395 Batch F1: 0.7391304347826088
Epoch:  423        5 Batch loss: 0.158945 Batch F1: 0.7727272727272727
Epoch:  423        6 Batch loss: 0.180092 Batch F1: 0.723404255319149
Epoch:  423        7 Batch loss: 0.152216 Batch F1: 0.8163265306122449
Epoch:  423        8 Batch loss: 0.161434 Batch F1: 0.6666666666666666
Epoch:  423        9 Batch loss: 0.175797 Batch F1: 0.6341463414634146
Epoch:  423       10 Batch loss: 0.195869 Batch F1: 0.5714285714285713
Epoch:  423       11 Batch loss: 0.149855 Batch F1: 0.6875
Epoch:  423       12 Batch loss: 0.196578 Batch F1: 0.6666666666666666
Train Avg Loss  423: 0.170685

Train Avg F1  423: 0.7098494015081639

Val Avg Loss  423: 0.184067

Val Avg F1  423:  0.6739793281653745

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 424
--------------------------------------------------------------
Epoch:  424        1 Batch loss: 0.165622 Batch F1: 0.6829268292682926
Epoch:  424        2 Batch loss: 0.173284 Batch F1: 0.7169811320754716
Epoch:  424        3 Batch loss: 0.161049 Batch F1: 0.6875
Epoch:  424        4 Batch loss: 0.173559 Batch F1: 0.7199999999999999
Epoch:  424        5 Batch loss: 0.168118 Batch F1: 0.75
Epoch:  424        6 Batch loss: 0.174971 Batch F1: 0.6818181818181818
Epoch:  424        7 Batch loss: 0.171545 Batch F1: 0.6486486486486486
Epoch:  424        8 Batch loss: 0.152057 Batch F1: 0.8095238095238095
Epoch:  424        9 Batch loss: 0.156595 Batch F1: 0.7391304347826088
Epoch:  424       10 Batch loss: 0.194226 Batch F1: 0.6938775510204083
Epoch:  424       11 Batch loss: 0.165483 Batch F1: 0.7450980392156863
Epoch:  424       12 Batch loss: 0.177194 Batch F1: 0.625
Train Avg Loss  424: 0.169475

Train Avg F1  424: 0.7083753855294255

Val Avg Loss  424: 0.181267

Val Avg F1  424:  0.6978740594859365

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 425
--------------------------------------------------------------
Epoch:  425        1 Batch loss: 0.164968 Batch F1: 0.7441860465116279
Epoch:  425        2 Batch loss: 0.170869 Batch F1: 0.6285714285714286
Epoch:  425        3 Batch loss: 0.185713 Batch F1: 0.7924528301886793
Epoch:  425        4 Batch loss: 0.194155 Batch F1: 0.7058823529411765
Epoch:  425        5 Batch loss: 0.179052 Batch F1: 0.5294117647058824
Epoch:  425        6 Batch loss: 0.141620 Batch F1: 0.7441860465116279
Epoch:  425        7 Batch loss: 0.169552 Batch F1: 0.761904761904762
Epoch:  425        8 Batch loss: 0.161518 Batch F1: 0.7
Epoch:  425        9 Batch loss: 0.186591 Batch F1: 0.75
Epoch:  425       10 Batch loss: 0.206356 Batch F1: 0.6521739130434783
Epoch:  425       11 Batch loss: 0.152749 Batch F1: 0.8333333333333333
Epoch:  425       12 Batch loss: 0.183158 Batch F1: 0.744186046511628
Train Avg Loss  425: 0.174692

Train Avg F1  425: 0.715524043685302

Val Avg Loss  425: 0.184721

Val Avg F1  425:  0.6616977225672878

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 426
--------------------------------------------------------------
Epoch:  426        1 Batch loss: 0.169881 Batch F1: 0.7272727272727273
Epoch:  426        2 Batch loss: 0.186410 Batch F1: 0.68
Epoch:  426        3 Batch loss: 0.177496 Batch F1: 0.819672131147541
Epoch:  426        4 Batch loss: 0.181851 Batch F1: 0.6341463414634146
Epoch:  426        5 Batch loss: 0.153678 Batch F1: 0.7441860465116279
Epoch:  426        6 Batch loss: 0.212343 Batch F1: 0.55
Epoch:  426        7 Batch loss: 0.161792 Batch F1: 0.8095238095238095
Epoch:  426        8 Batch loss: 0.165624 Batch F1: 0.7555555555555556
Epoch:  426        9 Batch loss: 0.182476 Batch F1: 0.6666666666666666
Epoch:  426       10 Batch loss: 0.179022 Batch F1: 0.7307692307692307
Epoch:  426       11 Batch loss: 0.148689 Batch F1: 0.7499999999999999
Epoch:  426       12 Batch loss: 0.181645 Batch F1: 0.6451612903225806
Train Avg Loss  426: 0.175076

Train Avg F1  426: 0.7094128166027628

Val Avg Loss  426: 0.186055

Val Avg F1  426:  0.6831823671497584

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 427
--------------------------------------------------------------
Epoch:  427        1 Batch loss: 0.157729 Batch F1: 0.717948717948718
Epoch:  427        2 Batch loss: 0.204055 Batch F1: 0.6938775510204082
Epoch:  427        3 Batch loss: 0.130435 Batch F1: 0.8333333333333334
Epoch:  427        4 Batch loss: 0.193163 Batch F1: 0.6666666666666666
Epoch:  427        5 Batch loss: 0.191140 Batch F1: 0.6956521739130435
Epoch:  427        6 Batch loss: 0.148689 Batch F1: 0.7916666666666666
Epoch:  427        7 Batch loss: 0.184070 Batch F1: 0.72
Epoch:  427        8 Batch loss: 0.160883 Batch F1: 0.8
Epoch:  427        9 Batch loss: 0.163237 Batch F1: 0.7555555555555556
Epoch:  427       10 Batch loss: 0.181479 Batch F1: 0.6341463414634148
Epoch:  427       11 Batch loss: 0.189190 Batch F1: 0.6808510638297872
Epoch:  427       12 Batch loss: 0.189360 Batch F1: 0.6842105263157895
Train Avg Loss  427: 0.174453

Train Avg F1  427: 0.7228257163927819

Val Avg Loss  427: 0.186464

Val Avg F1  427:  0.6774275005172015

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 428
--------------------------------------------------------------
Epoch:  428        1 Batch loss: 0.183191 Batch F1: 0.6500000000000001
Epoch:  428        2 Batch loss: 0.180422 Batch F1: 0.7499999999999999
Epoch:  428        3 Batch loss: 0.182520 Batch F1: 0.5945945945945946
Epoch:  428        4 Batch loss: 0.159278 Batch F1: 0.717948717948718
Epoch:  428        5 Batch loss: 0.165723 Batch F1: 0.6818181818181818
Epoch:  428        6 Batch loss: 0.170805 Batch F1: 0.6818181818181819
Epoch:  428        7 Batch loss: 0.153604 Batch F1: 0.8
Epoch:  428        8 Batch loss: 0.145416 Batch F1: 0.8
Epoch:  428        9 Batch loss: 0.185389 Batch F1: 0.7636363636363636
Epoch:  428       10 Batch loss: 0.164957 Batch F1: 0.7692307692307692
Epoch:  428       11 Batch loss: 0.177788 Batch F1: 0.7111111111111111
Epoch:  428       12 Batch loss: 0.189442 Batch F1: 0.6060606060606061
Train Avg Loss  428: 0.171545

Train Avg F1  428: 0.7105182105182105

Val Avg Loss  428: 0.183284

Val Avg F1  428:  0.675337631845767

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 429
--------------------------------------------------------------
Epoch:  429        1 Batch loss: 0.220849 Batch F1: 0.5
Epoch:  429        2 Batch loss: 0.174725 Batch F1: 0.6341463414634146
Epoch:  429        3 Batch loss: 0.136620 Batch F1: 0.8571428571428572
Epoch:  429        4 Batch loss: 0.155803 Batch F1: 0.7777777777777778
Epoch:  429        5 Batch loss: 0.156347 Batch F1: 0.7
Epoch:  429        6 Batch loss: 0.168290 Batch F1: 0.8387096774193549
Epoch:  429        7 Batch loss: 0.168580 Batch F1: 0.7111111111111111
Epoch:  429        8 Batch loss: 0.188739 Batch F1: 0.6666666666666666
Epoch:  429        9 Batch loss: 0.179423 Batch F1: 0.6511627906976745
Epoch:  429       10 Batch loss: 0.176359 Batch F1: 0.6976744186046512
Epoch:  429       11 Batch loss: 0.159090 Batch F1: 0.76
Epoch:  429       12 Batch loss: 0.155632 Batch F1: 0.7777777777777777
Train Avg Loss  429: 0.170038

Train Avg F1  429: 0.7143474515551071

Val Avg Loss  429: 0.182258

Val Avg F1  429:  0.6980281901334532

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 430
--------------------------------------------------------------
Epoch:  430        1 Batch loss: 0.167654 Batch F1: 0.7547169811320754
Epoch:  430        2 Batch loss: 0.187128 Batch F1: 0.6153846153846154
Epoch:  430        3 Batch loss: 0.170430 Batch F1: 0.7450980392156863
Epoch:  430        4 Batch loss: 0.148548 Batch F1: 0.7777777777777778
Epoch:  430        5 Batch loss: 0.174422 Batch F1: 0.6666666666666666
Epoch:  430        6 Batch loss: 0.153248 Batch F1: 0.7916666666666667
Epoch:  430        7 Batch loss: 0.179699 Batch F1: 0.7083333333333334
Epoch:  430        8 Batch loss: 0.160664 Batch F1: 0.7727272727272727
Epoch:  430        9 Batch loss: 0.184807 Batch F1: 0.6521739130434783
Epoch:  430       10 Batch loss: 0.171067 Batch F1: 0.6956521739130435
Epoch:  430       11 Batch loss: 0.174732 Batch F1: 0.723404255319149
Epoch:  430       12 Batch loss: 0.149903 Batch F1: 0.7142857142857142
Train Avg Loss  430: 0.168525

Train Avg F1  430: 0.7181572841221232

Val Avg Loss  430: 0.180379

Val Avg F1  430:  0.6847826086956522

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 431
--------------------------------------------------------------
Epoch:  431        1 Batch loss: 0.153782 Batch F1: 0.8
Epoch:  431        2 Batch loss: 0.158010 Batch F1: 0.7727272727272727
Epoch:  431        3 Batch loss: 0.199844 Batch F1: 0.5365853658536585
Epoch:  431        4 Batch loss: 0.161339 Batch F1: 0.744186046511628
Epoch:  431        5 Batch loss: 0.221631 Batch F1: 0.6122448979591838
Epoch:  431        6 Batch loss: 0.187550 Batch F1: 0.6111111111111112
Epoch:  431        7 Batch loss: 0.179076 Batch F1: 0.8000000000000002
Epoch:  431        8 Batch loss: 0.194506 Batch F1: 0.6923076923076924
Epoch:  431        9 Batch loss: 0.188884 Batch F1: 0.6666666666666666
Epoch:  431       10 Batch loss: 0.164492 Batch F1: 0.7272727272727273
Epoch:  431       11 Batch loss: 0.144323 Batch F1: 0.7804878048780488
Epoch:  431       12 Batch loss: 0.171075 Batch F1: 0.7567567567567567
Train Avg Loss  431: 0.177043

Train Avg F1  431: 0.7083621951703956

Val Avg Loss  431: 0.185804

Val Avg F1  431:  0.6810451453308596

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 432
--------------------------------------------------------------
Epoch:  432        1 Batch loss: 0.156846 Batch F1: 0.7659574468085107
Epoch:  432        2 Batch loss: 0.188453 Batch F1: 0.7083333333333334
Epoch:  432        3 Batch loss: 0.119717 Batch F1: 0.9090909090909091
Epoch:  432        4 Batch loss: 0.163119 Batch F1: 0.711111111111111
Epoch:  432        5 Batch loss: 0.175720 Batch F1: 0.6808510638297872
Epoch:  432        6 Batch loss: 0.189747 Batch F1: 0.6
Epoch:  432        7 Batch loss: 0.193352 Batch F1: 0.5500000000000002
Epoch:  432        8 Batch loss: 0.184458 Batch F1: 0.65
Epoch:  432        9 Batch loss: 0.177051 Batch F1: 0.744186046511628
Epoch:  432       10 Batch loss: 0.162888 Batch F1: 0.7916666666666666
Epoch:  432       11 Batch loss: 0.179958 Batch F1: 0.6956521739130435
Epoch:  432       12 Batch loss: 0.177711 Batch F1: 0.7317073170731708
Train Avg Loss  432: 0.172418

Train Avg F1  432: 0.7115463390281801

Val Avg Loss  432: 0.183772

Val Avg F1  432:  0.6770921985815603

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 433
--------------------------------------------------------------
Epoch:  433        1 Batch loss: 0.172409 Batch F1: 0.7450980392156863
Epoch:  433        2 Batch loss: 0.166568 Batch F1: 0.7555555555555556
Epoch:  433        3 Batch loss: 0.192242 Batch F1: 0.5500000000000002
Epoch:  433        4 Batch loss: 0.197688 Batch F1: 0.5
Epoch:  433        5 Batch loss: 0.186801 Batch F1: 0.6923076923076923
Epoch:  433        6 Batch loss: 0.153876 Batch F1: 0.7826086956521738
Epoch:  433        7 Batch loss: 0.189253 Batch F1: 0.6666666666666666
Epoch:  433        8 Batch loss: 0.157600 Batch F1: 0.717948717948718
Epoch:  433        9 Batch loss: 0.157101 Batch F1: 0.7368421052631577
Epoch:  433       10 Batch loss: 0.155284 Batch F1: 0.8260869565217391
Epoch:  433       11 Batch loss: 0.141440 Batch F1: 0.7428571428571428
Epoch:  433       12 Batch loss: 0.167494 Batch F1: 0.8076923076923077
Train Avg Loss  433: 0.169813

Train Avg F1  433: 0.7103053233067368

Val Avg Loss  433: 0.181996

Val Avg F1  433:  0.6943311089468164

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 434
--------------------------------------------------------------
Epoch:  434        1 Batch loss: 0.190235 Batch F1: 0.6250000000000001
Epoch:  434        2 Batch loss: 0.153491 Batch F1: 0.830188679245283
Epoch:  434        3 Batch loss: 0.193282 Batch F1: 0.7058823529411764
Epoch:  434        4 Batch loss: 0.183588 Batch F1: 0.7659574468085107
Epoch:  434        5 Batch loss: 0.204970 Batch F1: 0.6808510638297872
Epoch:  434        6 Batch loss: 0.135718 Batch F1: 0.7777777777777777
Epoch:  434        7 Batch loss: 0.179506 Batch F1: 0.7111111111111111
Epoch:  434        8 Batch loss: 0.182505 Batch F1: 0.7659574468085107
Epoch:  434        9 Batch loss: 0.150653 Batch F1: 0.8
Epoch:  434       10 Batch loss: 0.175020 Batch F1: 0.7391304347826089
Epoch:  434       11 Batch loss: 0.154872 Batch F1: 0.7894736842105262
Epoch:  434       12 Batch loss: 0.179489 Batch F1: 0.6666666666666665
Train Avg Loss  434: 0.173611

Train Avg F1  434: 0.7381663886818298

Val Avg Loss  434: 0.184355

Val Avg F1  434:  0.681058787151224

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 435
--------------------------------------------------------------
Epoch:  435        1 Batch loss: 0.190975 Batch F1: 0.5789473684210527
Epoch:  435        2 Batch loss: 0.167220 Batch F1: 0.7916666666666667
Epoch:  435        3 Batch loss: 0.166607 Batch F1: 0.5625
Epoch:  435        4 Batch loss: 0.177226 Batch F1: 0.6666666666666666
Epoch:  435        5 Batch loss: 0.171884 Batch F1: 0.711111111111111
Epoch:  435        6 Batch loss: 0.165566 Batch F1: 0.8333333333333334
Epoch:  435        7 Batch loss: 0.185633 Batch F1: 0.7200000000000001
Epoch:  435        8 Batch loss: 0.158042 Batch F1: 0.8363636363636363
Epoch:  435        9 Batch loss: 0.149756 Batch F1: 0.8181818181818182
Epoch:  435       10 Batch loss: 0.223571 Batch F1: 0.6250000000000001
Epoch:  435       11 Batch loss: 0.155140 Batch F1: 0.75
Epoch:  435       12 Batch loss: 0.179096 Batch F1: 0.6666666666666665
Train Avg Loss  435: 0.174226

Train Avg F1  435: 0.7133697722842459

Val Avg Loss  435: 0.192698

Val Avg F1  435:  0.6797393708414943

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 436
--------------------------------------------------------------
Epoch:  436        1 Batch loss: 0.188150 Batch F1: 0.5142857142857143
Epoch:  436        2 Batch loss: 0.182189 Batch F1: 0.7659574468085107
Epoch:  436        3 Batch loss: 0.170635 Batch F1: 0.7499999999999999
Epoch:  436        4 Batch loss: 0.189674 Batch F1: 0.6521739130434783
Epoch:  436        5 Batch loss: 0.161406 Batch F1: 0.7441860465116279
Epoch:  436        6 Batch loss: 0.202649 Batch F1: 0.6909090909090909
Epoch:  436        7 Batch loss: 0.175785 Batch F1: 0.7307692307692306
Epoch:  436        8 Batch loss: 0.196506 Batch F1: 0.6666666666666666
Epoch:  436        9 Batch loss: 0.148921 Batch F1: 0.8108108108108109
Epoch:  436       10 Batch loss: 0.152613 Batch F1: 0.7368421052631577
Epoch:  436       11 Batch loss: 0.165734 Batch F1: 0.7826086956521738
Epoch:  436       12 Batch loss: 0.182174 Batch F1: 0.7142857142857143
Train Avg Loss  436: 0.176370

Train Avg F1  436: 0.7132912862505146

Val Avg Loss  436: 0.183087

Val Avg F1  436:  0.6726237217931571

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 437
--------------------------------------------------------------
Epoch:  437        1 Batch loss: 0.157133 Batch F1: 0.7142857142857143
Epoch:  437        2 Batch loss: 0.141996 Batch F1: 0.816326530612245
Epoch:  437        3 Batch loss: 0.172800 Batch F1: 0.7916666666666667
Epoch:  437        4 Batch loss: 0.138952 Batch F1: 0.8181818181818182
Epoch:  437        5 Batch loss: 0.205741 Batch F1: 0.5555555555555556
Epoch:  437        6 Batch loss: 0.187840 Batch F1: 0.7169811320754716
Epoch:  437        7 Batch loss: 0.174840 Batch F1: 0.7234042553191491
Epoch:  437        8 Batch loss: 0.217852 Batch F1: 0.5652173913043478
Epoch:  437        9 Batch loss: 0.193927 Batch F1: 0.7555555555555555
Epoch:  437       10 Batch loss: 0.183867 Batch F1: 0.6666666666666667
Epoch:  437       11 Batch loss: 0.145428 Batch F1: 0.7894736842105263
Epoch:  437       12 Batch loss: 0.174365 Batch F1: 0.6857142857142857
Train Avg Loss  437: 0.174562

Train Avg F1  437: 0.716585771345667

Val Avg Loss  437: 0.181488

Val Avg F1  437:  0.6958979328165376

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 438
--------------------------------------------------------------
Epoch:  438        1 Batch loss: 0.190431 Batch F1: 0.6923076923076924
Epoch:  438        2 Batch loss: 0.151719 Batch F1: 0.7500000000000001
Epoch:  438        3 Batch loss: 0.186194 Batch F1: 0.7450980392156863
Epoch:  438        4 Batch loss: 0.158177 Batch F1: 0.6285714285714286
Epoch:  438        5 Batch loss: 0.174057 Batch F1: 0.7924528301886793
Epoch:  438        6 Batch loss: 0.202092 Batch F1: 0.6666666666666666
Epoch:  438        7 Batch loss: 0.173326 Batch F1: 0.7142857142857143
Epoch:  438        8 Batch loss: 0.172661 Batch F1: 0.6511627906976744
Epoch:  438        9 Batch loss: 0.141245 Batch F1: 0.85
Epoch:  438       10 Batch loss: 0.190904 Batch F1: 0.68
Epoch:  438       11 Batch loss: 0.161018 Batch F1: 0.7000000000000001
Epoch:  438       12 Batch loss: 0.161717 Batch F1: 0.6666666666666667
Train Avg Loss  438: 0.171962

Train Avg F1  438: 0.7114343190500173

Val Avg Loss  438: 0.183558

Val Avg F1  438:  0.6732957892820035

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 439
--------------------------------------------------------------
Epoch:  439        1 Batch loss: 0.166657 Batch F1: 0.7692307692307693
Epoch:  439        2 Batch loss: 0.151700 Batch F1: 0.7058823529411765
Epoch:  439        3 Batch loss: 0.214659 Batch F1: 0.6
Epoch:  439        4 Batch loss: 0.151608 Batch F1: 0.7916666666666667
Epoch:  439        5 Batch loss: 0.180450 Batch F1: 0.7346938775510203
Epoch:  439        6 Batch loss: 0.168234 Batch F1: 0.6938775510204083
Epoch:  439        7 Batch loss: 0.180370 Batch F1: 0.76
Epoch:  439        8 Batch loss: 0.190175 Batch F1: 0.6666666666666666
Epoch:  439        9 Batch loss: 0.167043 Batch F1: 0.6666666666666665
Epoch:  439       10 Batch loss: 0.167173 Batch F1: 0.7916666666666667
Epoch:  439       11 Batch loss: 0.155053 Batch F1: 0.7027027027027027
Epoch:  439       12 Batch loss: 0.152835 Batch F1: 0.742857142857143
Train Avg Loss  439: 0.170497

Train Avg F1  439: 0.7188259219141573

Val Avg Loss  439: 0.184257

Val Avg F1  439:  0.6721230158730159

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 440
--------------------------------------------------------------
Epoch:  440        1 Batch loss: 0.178341 Batch F1: 0.6153846153846153
Epoch:  440        2 Batch loss: 0.174213 Batch F1: 0.6956521739130435
Epoch:  440        3 Batch loss: 0.158522 Batch F1: 0.7755102040816326
Epoch:  440        4 Batch loss: 0.188817 Batch F1: 0.7450980392156864
Epoch:  440        5 Batch loss: 0.155662 Batch F1: 0.7659574468085107
Epoch:  440        6 Batch loss: 0.156866 Batch F1: 0.7727272727272727
Epoch:  440        7 Batch loss: 0.170720 Batch F1: 0.7659574468085107
Epoch:  440        8 Batch loss: 0.169361 Batch F1: 0.7346938775510204
Epoch:  440        9 Batch loss: 0.163925 Batch F1: 0.7441860465116279
Epoch:  440       10 Batch loss: 0.191473 Batch F1: 0.5263157894736842
Epoch:  440       11 Batch loss: 0.168798 Batch F1: 0.6829268292682926
Epoch:  440       12 Batch loss: 0.191926 Batch F1: 0.6486486486486486
Train Avg Loss  440: 0.172385

Train Avg F1  440: 0.7060881991993787

Val Avg Loss  440: 0.186534

Val Avg F1  440:  0.6620841959972396

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 441
--------------------------------------------------------------
Epoch:  441        1 Batch loss: 0.153131 Batch F1: 0.7916666666666667
Epoch:  441        2 Batch loss: 0.211336 Batch F1: 0.5238095238095238
Epoch:  441        3 Batch loss: 0.160546 Batch F1: 0.625
Epoch:  441        4 Batch loss: 0.175541 Batch F1: 0.7346938775510204
Epoch:  441        5 Batch loss: 0.153992 Batch F1: 0.6666666666666667
Epoch:  441        6 Batch loss: 0.191819 Batch F1: 0.6222222222222223
Epoch:  441        7 Batch loss: 0.160059 Batch F1: 0.8333333333333334
Epoch:  441        8 Batch loss: 0.166048 Batch F1: 0.6486486486486486
Epoch:  441        9 Batch loss: 0.140113 Batch F1: 0.8095238095238095
Epoch:  441       10 Batch loss: 0.156924 Batch F1: 0.8076923076923077
Epoch:  441       11 Batch loss: 0.173459 Batch F1: 0.7636363636363638
Epoch:  441       12 Batch loss: 0.198435 Batch F1: 0.6666666666666666
Train Avg Loss  441: 0.170117

Train Avg F1  441: 0.7077966738681024

Val Avg Loss  441: 0.182366

Val Avg F1  441:  0.7083900226757369

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 442
--------------------------------------------------------------
Epoch:  442        1 Batch loss: 0.161983 Batch F1: 0.7111111111111111
Epoch:  442        2 Batch loss: 0.148448 Batch F1: 0.8510638297872342
Epoch:  442        3 Batch loss: 0.165676 Batch F1: 0.7441860465116279
Epoch:  442        4 Batch loss: 0.159877 Batch F1: 0.7843137254901961
Epoch:  442        5 Batch loss: 0.196760 Batch F1: 0.6530612244897959
Epoch:  442        6 Batch loss: 0.145685 Batch F1: 0.7500000000000001
Epoch:  442        7 Batch loss: 0.172205 Batch F1: 0.6976744186046512
Epoch:  442        8 Batch loss: 0.164716 Batch F1: 0.7499999999999999
Epoch:  442        9 Batch loss: 0.197569 Batch F1: 0.6222222222222222
Epoch:  442       10 Batch loss: 0.157746 Batch F1: 0.7659574468085107
Epoch:  442       11 Batch loss: 0.206888 Batch F1: 0.6666666666666667
Epoch:  442       12 Batch loss: 0.178921 Batch F1: 0.6000000000000001
Train Avg Loss  442: 0.171373

Train Avg F1  442: 0.716354724307668

Val Avg Loss  442: 0.181348

Val Avg F1  442:  0.6932631525890083

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 443
--------------------------------------------------------------
Epoch:  443        1 Batch loss: 0.164489 Batch F1: 0.6666666666666666
Epoch:  443        2 Batch loss: 0.178825 Batch F1: 0.7307692307692308
Epoch:  443        3 Batch loss: 0.152050 Batch F1: 0.7142857142857143
Epoch:  443        4 Batch loss: 0.172201 Batch F1: 0.8135593220338982
Epoch:  443        5 Batch loss: 0.173937 Batch F1: 0.6666666666666665
Epoch:  443        6 Batch loss: 0.161044 Batch F1: 0.717948717948718
Epoch:  443        7 Batch loss: 0.151574 Batch F1: 0.782608695652174
Epoch:  443        8 Batch loss: 0.206537 Batch F1: 0.5909090909090909
Epoch:  443        9 Batch loss: 0.180733 Batch F1: 0.6666666666666666
Epoch:  443       10 Batch loss: 0.148696 Batch F1: 0.7906976744186047
Epoch:  443       11 Batch loss: 0.170566 Batch F1: 0.6818181818181819
Epoch:  443       12 Batch loss: 0.189112 Batch F1: 0.6818181818181818
Train Avg Loss  443: 0.170813

Train Avg F1  443: 0.7087012341378162

Val Avg Loss  443: 0.184184

Val Avg F1  443:  0.6636105676112983

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 444
--------------------------------------------------------------
Epoch:  444        1 Batch loss: 0.163587 Batch F1: 0.717948717948718
Epoch:  444        2 Batch loss: 0.152114 Batch F1: 0.8085106382978723
Epoch:  444        3 Batch loss: 0.155879 Batch F1: 0.7659574468085107
Epoch:  444        4 Batch loss: 0.169950 Batch F1: 0.6956521739130435
Epoch:  444        5 Batch loss: 0.183894 Batch F1: 0.6363636363636365
Epoch:  444        6 Batch loss: 0.169277 Batch F1: 0.7391304347826085
Epoch:  444        7 Batch loss: 0.156981 Batch F1: 0.8363636363636363
Epoch:  444        8 Batch loss: 0.162933 Batch F1: 0.6285714285714286
Epoch:  444        9 Batch loss: 0.170293 Batch F1: 0.7636363636363638
Epoch:  444       10 Batch loss: 0.190898 Batch F1: 0.6341463414634148
Epoch:  444       11 Batch loss: 0.153795 Batch F1: 0.6857142857142857
Epoch:  444       12 Batch loss: 0.215432 Batch F1: 0.55
Train Avg Loss  444: 0.170419

Train Avg F1  444: 0.7051662586552933

Val Avg Loss  444: 0.180465

Val Avg F1  444:  0.7085293815336804

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 445
--------------------------------------------------------------
Epoch:  445        1 Batch loss: 0.162522 Batch F1: 0.8076923076923077
Epoch:  445        2 Batch loss: 0.168195 Batch F1: 0.6938775510204083
Epoch:  445        3 Batch loss: 0.166485 Batch F1: 0.625
Epoch:  445        4 Batch loss: 0.166492 Batch F1: 0.7555555555555556
Epoch:  445        5 Batch loss: 0.185283 Batch F1: 0.6818181818181819
Epoch:  445        6 Batch loss: 0.181041 Batch F1: 0.7346938775510203
Epoch:  445        7 Batch loss: 0.173371 Batch F1: 0.8163265306122449
Epoch:  445        8 Batch loss: 0.146609 Batch F1: 0.8292682926829269
Epoch:  445        9 Batch loss: 0.190447 Batch F1: 0.7058823529411765
Epoch:  445       10 Batch loss: 0.158956 Batch F1: 0.8275862068965518
Epoch:  445       11 Batch loss: 0.148897 Batch F1: 0.7428571428571428
Epoch:  445       12 Batch loss: 0.166285 Batch F1: 0.7499999999999999
Train Avg Loss  445: 0.167882

Train Avg F1  445: 0.7475464999689597

Val Avg Loss  445: 0.183215

Val Avg F1  445:  0.6848298587429021

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 446
--------------------------------------------------------------
Epoch:  446        1 Batch loss: 0.153964 Batch F1: 0.7567567567567567
Epoch:  446        2 Batch loss: 0.183467 Batch F1: 0.6829268292682927
Epoch:  446        3 Batch loss: 0.195370 Batch F1: 0.5641025641025642
Epoch:  446        4 Batch loss: 0.199350 Batch F1: 0.5263157894736842
Epoch:  446        5 Batch loss: 0.156349 Batch F1: 0.8333333333333334
Epoch:  446        6 Batch loss: 0.190104 Batch F1: 0.7241379310344827
Epoch:  446        7 Batch loss: 0.151794 Batch F1: 0.782608695652174
Epoch:  446        8 Batch loss: 0.187938 Batch F1: 0.7169811320754716
Epoch:  446        9 Batch loss: 0.189748 Batch F1: 0.6511627906976744
Epoch:  446       10 Batch loss: 0.172406 Batch F1: 0.6285714285714286
Epoch:  446       11 Batch loss: 0.189459 Batch F1: 0.6153846153846153
Epoch:  446       12 Batch loss: 0.167388 Batch F1: 0.8
Train Avg Loss  446: 0.178111

Train Avg F1  446: 0.6901901555292066

Val Avg Loss  446: 0.196078

Val Avg F1  446:  0.6598708716920366

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 447
--------------------------------------------------------------
Epoch:  447        1 Batch loss: 0.224319 Batch F1: 0.5833333333333334
Epoch:  447        2 Batch loss: 0.206193 Batch F1: 0.72
Epoch:  447        3 Batch loss: 0.209702 Batch F1: 0.619047619047619
Epoch:  447        4 Batch loss: 0.286287 Batch F1: 0.3870967741935484
Epoch:  447        5 Batch loss: 0.219093 Batch F1: 0.689655172413793
Epoch:  447        6 Batch loss: 0.204334 Batch F1: 0.6896551724137931
Epoch:  447        7 Batch loss: 0.186802 Batch F1: 0.7692307692307693
Epoch:  447        8 Batch loss: 0.186071 Batch F1: 0.5142857142857142
Epoch:  447        9 Batch loss: 0.175870 Batch F1: 0.8750000000000001
Epoch:  447       10 Batch loss: 0.179709 Batch F1: 0.7391304347826086
Epoch:  447       11 Batch loss: 0.155228 Batch F1: 0.7826086956521738
Epoch:  447       12 Batch loss: 0.188964 Batch F1: 0.6666666666666667
Train Avg Loss  447: 0.201881

Train Avg F1  447: 0.6696425293350017

Val Avg Loss  447: 0.198955

Val Avg F1  447:  0.6169175057410351

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 448
--------------------------------------------------------------
Epoch:  448        1 Batch loss: 0.177854 Batch F1: 0.7234042553191489
Epoch:  448        2 Batch loss: 0.161788 Batch F1: 0.7441860465116279
Epoch:  448        3 Batch loss: 0.182908 Batch F1: 0.6363636363636364
Epoch:  448        4 Batch loss: 0.177382 Batch F1: 0.6363636363636365
Epoch:  448        5 Batch loss: 0.158419 Batch F1: 0.7727272727272727
Epoch:  448        6 Batch loss: 0.216629 Batch F1: 0.6153846153846153
Epoch:  448        7 Batch loss: 0.174052 Batch F1: 0.7441860465116279
Epoch:  448        8 Batch loss: 0.215089 Batch F1: 0.5128205128205129
Epoch:  448        9 Batch loss: 0.191909 Batch F1: 0.6666666666666665
Epoch:  448       10 Batch loss: 0.149400 Batch F1: 0.8461538461538461
Epoch:  448       11 Batch loss: 0.162796 Batch F1: 0.7843137254901961
Epoch:  448       12 Batch loss: 0.177840 Batch F1: 0.6470588235294117
Train Avg Loss  448: 0.178839

Train Avg F1  448: 0.6941357569868497

Val Avg Loss  448: 0.183618

Val Avg F1  448:  0.6914190868291237

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 449
--------------------------------------------------------------
Epoch:  449        1 Batch loss: 0.155197 Batch F1: 0.7317073170731707
Epoch:  449        2 Batch loss: 0.183834 Batch F1: 0.7058823529411765
Epoch:  449        3 Batch loss: 0.151307 Batch F1: 0.7428571428571429
Epoch:  449        4 Batch loss: 0.167726 Batch F1: 0.6938775510204083
Epoch:  449        5 Batch loss: 0.217991 Batch F1: 0.5531914893617021
Epoch:  449        6 Batch loss: 0.211394 Batch F1: 0.5833333333333334
Epoch:  449        7 Batch loss: 0.167281 Batch F1: 0.6956521739130435
Epoch:  449        8 Batch loss: 0.195977 Batch F1: 0.6666666666666666
Epoch:  449        9 Batch loss: 0.183425 Batch F1: 0.7636363636363636
Epoch:  449       10 Batch loss: 0.146640 Batch F1: 0.7647058823529411
Epoch:  449       11 Batch loss: 0.155012 Batch F1: 0.8571428571428572
Epoch:  449       12 Batch loss: 0.166916 Batch F1: 0.7058823529411765
Train Avg Loss  449: 0.175225

Train Avg F1  449: 0.7053779569366653

Val Avg Loss  449: 0.184774

Val Avg F1  449:  0.6860087290730247

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 450
--------------------------------------------------------------
Epoch:  450        1 Batch loss: 0.181250 Batch F1: 0.7234042553191491
Epoch:  450        2 Batch loss: 0.169190 Batch F1: 0.7692307692307692
Epoch:  450        3 Batch loss: 0.155167 Batch F1: 0.7916666666666666
Epoch:  450        4 Batch loss: 0.157116 Batch F1: 0.7659574468085107
Epoch:  450        5 Batch loss: 0.177385 Batch F1: 0.6666666666666666
Epoch:  450        6 Batch loss: 0.157011 Batch F1: 0.8000000000000002
Epoch:  450        7 Batch loss: 0.165097 Batch F1: 0.7111111111111111
Epoch:  450        8 Batch loss: 0.193230 Batch F1: 0.6363636363636365
Epoch:  450        9 Batch loss: 0.177644 Batch F1: 0.72
Epoch:  450       10 Batch loss: 0.178136 Batch F1: 0.5882352941176471
Epoch:  450       11 Batch loss: 0.184563 Batch F1: 0.6363636363636365
Epoch:  450       12 Batch loss: 0.184090 Batch F1: 0.6206896551724138
Train Avg Loss  450: 0.173323

Train Avg F1  450: 0.7024740948183507

Val Avg Loss  450: 0.187653

Val Avg F1  450:  0.6816141194640635

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 451
--------------------------------------------------------------
Epoch:  451        1 Batch loss: 0.164295 Batch F1: 0.8235294117647058
Epoch:  451        2 Batch loss: 0.165954 Batch F1: 0.6818181818181819
Epoch:  451        3 Batch loss: 0.163091 Batch F1: 0.7111111111111111
Epoch:  451        4 Batch loss: 0.184134 Batch F1: 0.6363636363636364
Epoch:  451        5 Batch loss: 0.174311 Batch F1: 0.7755102040816326
Epoch:  451        6 Batch loss: 0.163493 Batch F1: 0.7619047619047619
Epoch:  451        7 Batch loss: 0.203187 Batch F1: 0.5581395348837208
Epoch:  451        8 Batch loss: 0.201614 Batch F1: 0.5500000000000002
Epoch:  451        9 Batch loss: 0.170654 Batch F1: 0.7857142857142856
Epoch:  451       10 Batch loss: 0.168317 Batch F1: 0.6666666666666667
Epoch:  451       11 Batch loss: 0.173084 Batch F1: 0.6829268292682926
Epoch:  451       12 Batch loss: 0.167980 Batch F1: 0.7368421052631577
Train Avg Loss  451: 0.175009

Train Avg F1  451: 0.6975438940700128

Val Avg Loss  451: 0.183120

Val Avg F1  451:  0.6786633969600566

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 452
--------------------------------------------------------------
Epoch:  452        1 Batch loss: 0.157584 Batch F1: 0.7500000000000001
Epoch:  452        2 Batch loss: 0.188117 Batch F1: 0.6530612244897959
Epoch:  452        3 Batch loss: 0.173728 Batch F1: 0.7083333333333333
Epoch:  452        4 Batch loss: 0.143826 Batch F1: 0.8
Epoch:  452        5 Batch loss: 0.172850 Batch F1: 0.7083333333333334
Epoch:  452        6 Batch loss: 0.161613 Batch F1: 0.7317073170731706
Epoch:  452        7 Batch loss: 0.163346 Batch F1: 0.7755102040816326
Epoch:  452        8 Batch loss: 0.157438 Batch F1: 0.816326530612245
Epoch:  452        9 Batch loss: 0.156523 Batch F1: 0.717948717948718
Epoch:  452       10 Batch loss: 0.224840 Batch F1: 0.5454545454545455
Epoch:  452       11 Batch loss: 0.178408 Batch F1: 0.6818181818181818
Epoch:  452       12 Batch loss: 0.174098 Batch F1: 0.7222222222222222
Train Avg Loss  452: 0.171031

Train Avg F1  452: 0.717559634197265

Val Avg Loss  452: 0.182240

Val Avg F1  452:  0.664428296953875

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 453
--------------------------------------------------------------
Epoch:  453        1 Batch loss: 0.179639 Batch F1: 0.6808510638297872
Epoch:  453        2 Batch loss: 0.175972 Batch F1: 0.7272727272727272
Epoch:  453        3 Batch loss: 0.160842 Batch F1: 0.7441860465116279
Epoch:  453        4 Batch loss: 0.168223 Batch F1: 0.6666666666666667
Epoch:  453        5 Batch loss: 0.177088 Batch F1: 0.7777777777777777
Epoch:  453        6 Batch loss: 0.152416 Batch F1: 0.7441860465116279
Epoch:  453        7 Batch loss: 0.159645 Batch F1: 0.8
Epoch:  453        8 Batch loss: 0.152688 Batch F1: 0.7368421052631577
Epoch:  453        9 Batch loss: 0.170909 Batch F1: 0.65
Epoch:  453       10 Batch loss: 0.210850 Batch F1: 0.5957446808510638
Epoch:  453       11 Batch loss: 0.188485 Batch F1: 0.7169811320754716
Epoch:  453       12 Batch loss: 0.158957 Batch F1: 0.6857142857142857
Train Avg Loss  453: 0.171310

Train Avg F1  453: 0.7105185443728494

Val Avg Loss  453: 0.183255

Val Avg F1  453:  0.6807079128272635

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 454
--------------------------------------------------------------
Epoch:  454        1 Batch loss: 0.165024 Batch F1: 0.6486486486486486
Epoch:  454        2 Batch loss: 0.174159 Batch F1: 0.6938775510204083
Epoch:  454        3 Batch loss: 0.185383 Batch F1: 0.6818181818181819
Epoch:  454        4 Batch loss: 0.174060 Batch F1: 0.7346938775510204
Epoch:  454        5 Batch loss: 0.180273 Batch F1: 0.7142857142857143
Epoch:  454        6 Batch loss: 0.183784 Batch F1: 0.7083333333333334
Epoch:  454        7 Batch loss: 0.158322 Batch F1: 0.6842105263157896
Epoch:  454        8 Batch loss: 0.161692 Batch F1: 0.7500000000000001
Epoch:  454        9 Batch loss: 0.161835 Batch F1: 0.6486486486486486
Epoch:  454       10 Batch loss: 0.149429 Batch F1: 0.761904761904762
Epoch:  454       11 Batch loss: 0.204188 Batch F1: 0.6545454545454545
Epoch:  454       12 Batch loss: 0.150039 Batch F1: 0.8444444444444444
Train Avg Loss  454: 0.170682

Train Avg F1  454: 0.7104509285430337

Val Avg Loss  454: 0.183782

Val Avg F1  454:  0.688115282928634

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 455
--------------------------------------------------------------
Epoch:  455        1 Batch loss: 0.183701 Batch F1: 0.7169811320754718
Epoch:  455        2 Batch loss: 0.165628 Batch F1: 0.7499999999999999
Epoch:  455        3 Batch loss: 0.186789 Batch F1: 0.68
Epoch:  455        4 Batch loss: 0.174750 Batch F1: 0.6666666666666667
Epoch:  455        5 Batch loss: 0.156629 Batch F1: 0.7555555555555556
Epoch:  455        6 Batch loss: 0.163382 Batch F1: 0.6829268292682926
Epoch:  455        7 Batch loss: 0.157500 Batch F1: 0.717948717948718
Epoch:  455        8 Batch loss: 0.185162 Batch F1: 0.6666666666666666
Epoch:  455        9 Batch loss: 0.195202 Batch F1: 0.4666666666666667
Epoch:  455       10 Batch loss: 0.160143 Batch F1: 0.7027027027027029
Epoch:  455       11 Batch loss: 0.186790 Batch F1: 0.7234042553191489
Epoch:  455       12 Batch loss: 0.192489 Batch F1: 0.8085106382978724
Train Avg Loss  455: 0.175680

Train Avg F1  455: 0.6948358192639802

Val Avg Loss  455: 0.192637

Val Avg F1  455:  0.7331418581418581

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 456
--------------------------------------------------------------
Epoch:  456        1 Batch loss: 0.160396 Batch F1: 0.7083333333333333
Epoch:  456        2 Batch loss: 0.212178 Batch F1: 0.6666666666666667
Epoch:  456        3 Batch loss: 0.179082 Batch F1: 0.6808510638297872
Epoch:  456        4 Batch loss: 0.169948 Batch F1: 0.8333333333333334
Epoch:  456        5 Batch loss: 0.176418 Batch F1: 0.7317073170731706
Epoch:  456        6 Batch loss: 0.192600 Batch F1: 0.5714285714285715
Epoch:  456        7 Batch loss: 0.185536 Batch F1: 0.6976744186046512
Epoch:  456        8 Batch loss: 0.176652 Batch F1: 0.7272727272727274
Epoch:  456        9 Batch loss: 0.206641 Batch F1: 0.6521739130434783
Epoch:  456       10 Batch loss: 0.166149 Batch F1: 0.7777777777777778
Epoch:  456       11 Batch loss: 0.166168 Batch F1: 0.7916666666666666
Epoch:  456       12 Batch loss: 0.219849 Batch F1: 0.6666666666666667
Train Avg Loss  456: 0.184301

Train Avg F1  456: 0.7087960379747359

Val Avg Loss  456: 0.184759

Val Avg F1  456:  0.7724557434309756

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 457
--------------------------------------------------------------
Epoch:  457        1 Batch loss: 0.173572 Batch F1: 0.8085106382978724
Epoch:  457        2 Batch loss: 0.181028 Batch F1: 0.7000000000000001
Epoch:  457        3 Batch loss: 0.194394 Batch F1: 0.7169811320754716
Epoch:  457        4 Batch loss: 0.171667 Batch F1: 0.75
Epoch:  457        5 Batch loss: 0.154566 Batch F1: 0.9333333333333333
Epoch:  457        6 Batch loss: 0.180325 Batch F1: 0.8260869565217391
Epoch:  457        7 Batch loss: 0.172153 Batch F1: 0.8163265306122449
Epoch:  457        8 Batch loss: 0.222858 Batch F1: 0.6666666666666667
Epoch:  457        9 Batch loss: 0.200679 Batch F1: 0.6222222222222223
Epoch:  457       10 Batch loss: 0.142823 Batch F1: 0.8571428571428571
Epoch:  457       11 Batch loss: 0.174152 Batch F1: 0.6500000000000001
Epoch:  457       12 Batch loss: 0.171942 Batch F1: 0.7222222222222222
Train Avg Loss  457: 0.178347

Train Avg F1  457: 0.7557910465912191

Val Avg Loss  457: 0.185134

Val Avg F1  457:  0.6743266463686807

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 458
--------------------------------------------------------------
Epoch:  458        1 Batch loss: 0.169951 Batch F1: 0.7843137254901961
Epoch:  458        2 Batch loss: 0.171426 Batch F1: 0.6818181818181819
Epoch:  458        3 Batch loss: 0.143621 Batch F1: 0.8
Epoch:  458        4 Batch loss: 0.181050 Batch F1: 0.75
Epoch:  458        5 Batch loss: 0.146708 Batch F1: 0.7368421052631577
Epoch:  458        6 Batch loss: 0.144702 Batch F1: 0.7999999999999999
Epoch:  458        7 Batch loss: 0.183112 Batch F1: 0.6666666666666667
Epoch:  458        8 Batch loss: 0.204394 Batch F1: 0.6808510638297872
Epoch:  458        9 Batch loss: 0.182737 Batch F1: 0.6938775510204083
Epoch:  458       10 Batch loss: 0.188545 Batch F1: 0.5714285714285715
Epoch:  458       11 Batch loss: 0.223801 Batch F1: 0.6511627906976744
Epoch:  458       12 Batch loss: 0.172825 Batch F1: 0.7368421052631579
Train Avg Loss  458: 0.176073

Train Avg F1  458: 0.7128168967898169

Val Avg Loss  458: 0.182462

Val Avg F1  458:  0.6799448384554767

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 459
--------------------------------------------------------------
Epoch:  459        1 Batch loss: 0.188777 Batch F1: 0.6956521739130435
Epoch:  459        2 Batch loss: 0.157676 Batch F1: 0.7659574468085107
Epoch:  459        3 Batch loss: 0.169213 Batch F1: 0.7
Epoch:  459        4 Batch loss: 0.146029 Batch F1: 0.782608695652174
Epoch:  459        5 Batch loss: 0.186068 Batch F1: 0.6818181818181818
Epoch:  459        6 Batch loss: 0.182404 Batch F1: 0.7636363636363638
Epoch:  459        7 Batch loss: 0.158046 Batch F1: 0.7499999999999999
Epoch:  459        8 Batch loss: 0.186159 Batch F1: 0.65
Epoch:  459        9 Batch loss: 0.212479 Batch F1: 0.5777777777777778
Epoch:  459       10 Batch loss: 0.182150 Batch F1: 0.6500000000000001
Epoch:  459       11 Batch loss: 0.134608 Batch F1: 0.8292682926829269
Epoch:  459       12 Batch loss: 0.185498 Batch F1: 0.6829268292682927
Train Avg Loss  459: 0.174092

Train Avg F1  459: 0.710803813463106

Val Avg Loss  459: 0.185693

Val Avg F1  459:  0.6672191281504093

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 460
--------------------------------------------------------------
Epoch:  460        1 Batch loss: 0.165572 Batch F1: 0.75
Epoch:  460        2 Batch loss: 0.164946 Batch F1: 0.7272727272727272
Epoch:  460        3 Batch loss: 0.151414 Batch F1: 0.8333333333333334
Epoch:  460        4 Batch loss: 0.140400 Batch F1: 0.7692307692307692
Epoch:  460        5 Batch loss: 0.177628 Batch F1: 0.6666666666666665
Epoch:  460        6 Batch loss: 0.156002 Batch F1: 0.8076923076923077
Epoch:  460        7 Batch loss: 0.163102 Batch F1: 0.7916666666666667
Epoch:  460        8 Batch loss: 0.196598 Batch F1: 0.4571428571428571
Epoch:  460        9 Batch loss: 0.169315 Batch F1: 0.7755102040816326
Epoch:  460       10 Batch loss: 0.179124 Batch F1: 0.7407407407407407
Epoch:  460       11 Batch loss: 0.200549 Batch F1: 0.48484848484848486
Epoch:  460       12 Batch loss: 0.183608 Batch F1: 0.5882352941176471
Train Avg Loss  460: 0.170688

Train Avg F1  460: 0.6993616709828193

Val Avg Loss  460: 0.182325

Val Avg F1  460:  0.6778966131907309

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 461
--------------------------------------------------------------
Epoch:  461        1 Batch loss: 0.159192 Batch F1: 0.7317073170731708
Epoch:  461        2 Batch loss: 0.171797 Batch F1: 0.7083333333333334
Epoch:  461        3 Batch loss: 0.186105 Batch F1: 0.6938775510204083
Epoch:  461        4 Batch loss: 0.183604 Batch F1: 0.6666666666666667
Epoch:  461        5 Batch loss: 0.179250 Batch F1: 0.7450980392156864
Epoch:  461        6 Batch loss: 0.174524 Batch F1: 0.7346938775510203
Epoch:  461        7 Batch loss: 0.181460 Batch F1: 0.6829268292682926
Epoch:  461        8 Batch loss: 0.150145 Batch F1: 0.7894736842105262
Epoch:  461        9 Batch loss: 0.168194 Batch F1: 0.6956521739130435
Epoch:  461       10 Batch loss: 0.163612 Batch F1: 0.723404255319149
Epoch:  461       11 Batch loss: 0.164318 Batch F1: 0.7999999999999999
Epoch:  461       12 Batch loss: 0.177365 Batch F1: 0.56
Train Avg Loss  461: 0.171631

Train Avg F1  461: 0.7109861439642747

Val Avg Loss  461: 0.181966

Val Avg F1  461:  0.6810824296014327

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 462
--------------------------------------------------------------
Epoch:  462        1 Batch loss: 0.172283 Batch F1: 0.6666666666666666
Epoch:  462        2 Batch loss: 0.156396 Batch F1: 0.7317073170731706
Epoch:  462        3 Batch loss: 0.164779 Batch F1: 0.7916666666666667
Epoch:  462        4 Batch loss: 0.152255 Batch F1: 0.7555555555555555
Epoch:  462        5 Batch loss: 0.177979 Batch F1: 0.7547169811320754
Epoch:  462        6 Batch loss: 0.174148 Batch F1: 0.5945945945945946
Epoch:  462        7 Batch loss: 0.165289 Batch F1: 0.7391304347826085
Epoch:  462        8 Batch loss: 0.216901 Batch F1: 0.7083333333333333
Epoch:  462        9 Batch loss: 0.158646 Batch F1: 0.76
Epoch:  462       10 Batch loss: 0.164198 Batch F1: 0.6829268292682927
Epoch:  462       11 Batch loss: 0.155958 Batch F1: 0.7727272727272727
Epoch:  462       12 Batch loss: 0.192807 Batch F1: 0.6250000000000001
Train Avg Loss  462: 0.170970

Train Avg F1  462: 0.7152521376500197

Val Avg Loss  462: 0.181340

Val Avg F1  462:  0.6903787206582237

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 463
--------------------------------------------------------------
Epoch:  463        1 Batch loss: 0.137892 Batch F1: 0.8461538461538461
Epoch:  463        2 Batch loss: 0.183986 Batch F1: 0.7169811320754718
Epoch:  463        3 Batch loss: 0.156529 Batch F1: 0.8
Epoch:  463        4 Batch loss: 0.171714 Batch F1: 0.7272727272727272
Epoch:  463        5 Batch loss: 0.174223 Batch F1: 0.711111111111111
Epoch:  463        6 Batch loss: 0.198353 Batch F1: 0.5500000000000002
Epoch:  463        7 Batch loss: 0.129175 Batch F1: 0.8837209302325583
Epoch:  463        8 Batch loss: 0.181506 Batch F1: 0.75
Epoch:  463        9 Batch loss: 0.191900 Batch F1: 0.6
Epoch:  463       10 Batch loss: 0.160655 Batch F1: 0.7441860465116279
Epoch:  463       11 Batch loss: 0.164676 Batch F1: 0.6842105263157895
Epoch:  463       12 Batch loss: 0.179629 Batch F1: 0.5882352941176471
Train Avg Loss  463: 0.169187

Train Avg F1  463: 0.7168226344825648

Val Avg Loss  463: 0.182114

Val Avg F1  463:  0.6801646903820817

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 464
--------------------------------------------------------------
Epoch:  464        1 Batch loss: 0.153648 Batch F1: 0.7916666666666666
Epoch:  464        2 Batch loss: 0.152840 Batch F1: 0.8400000000000001
Epoch:  464        3 Batch loss: 0.168461 Batch F1: 0.631578947368421
Epoch:  464        4 Batch loss: 0.193261 Batch F1: 0.6190476190476191
Epoch:  464        5 Batch loss: 0.194848 Batch F1: 0.6666666666666666
Epoch:  464        6 Batch loss: 0.182997 Batch F1: 0.6511627906976745
Epoch:  464        7 Batch loss: 0.165776 Batch F1: 0.761904761904762
Epoch:  464        8 Batch loss: 0.160568 Batch F1: 0.8163265306122449
Epoch:  464        9 Batch loss: 0.162540 Batch F1: 0.723404255319149
Epoch:  464       10 Batch loss: 0.167151 Batch F1: 0.6666666666666666
Epoch:  464       11 Batch loss: 0.147057 Batch F1: 0.8085106382978724
Epoch:  464       12 Batch loss: 0.216696 Batch F1: 0.5142857142857143
Train Avg Loss  464: 0.172154

Train Avg F1  464: 0.7076017714611216

Val Avg Loss  464: 0.181237

Val Avg F1  464:  0.6892156862745098

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 465
--------------------------------------------------------------
Epoch:  465        1 Batch loss: 0.175683 Batch F1: 0.5714285714285715
Epoch:  465        2 Batch loss: 0.198896 Batch F1: 0.6222222222222223
Epoch:  465        3 Batch loss: 0.175417 Batch F1: 0.7906976744186046
Epoch:  465        4 Batch loss: 0.179836 Batch F1: 0.6976744186046512
Epoch:  465        5 Batch loss: 0.169066 Batch F1: 0.5161290322580646
Epoch:  465        6 Batch loss: 0.157288 Batch F1: 0.7555555555555556
Epoch:  465        7 Batch loss: 0.162319 Batch F1: 0.7441860465116279
Epoch:  465        8 Batch loss: 0.195759 Batch F1: 0.6363636363636364
Epoch:  465        9 Batch loss: 0.139003 Batch F1: 0.8510638297872342
Epoch:  465       10 Batch loss: 0.153911 Batch F1: 0.8235294117647058
Epoch:  465       11 Batch loss: 0.186057 Batch F1: 0.736842105263158
Epoch:  465       12 Batch loss: 0.157154 Batch F1: 0.7777777777777778
Train Avg Loss  465: 0.170866

Train Avg F1  465: 0.7102891901629843

Val Avg Loss  465: 0.180604

Val Avg F1  465:  0.7211346523265966

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 466
--------------------------------------------------------------
Epoch:  466        1 Batch loss: 0.204606 Batch F1: 0.5
Epoch:  466        2 Batch loss: 0.160105 Batch F1: 0.76
Epoch:  466        3 Batch loss: 0.158238 Batch F1: 0.846153846153846
Epoch:  466        4 Batch loss: 0.184710 Batch F1: 0.7199999999999999
Epoch:  466        5 Batch loss: 0.184118 Batch F1: 0.7199999999999999
Epoch:  466        6 Batch loss: 0.173764 Batch F1: 0.6829268292682927
Epoch:  466        7 Batch loss: 0.165137 Batch F1: 0.711111111111111
Epoch:  466        8 Batch loss: 0.151248 Batch F1: 0.8163265306122449
Epoch:  466        9 Batch loss: 0.207647 Batch F1: 0.5263157894736842
Epoch:  466       10 Batch loss: 0.133477 Batch F1: 0.8695652173913043
Epoch:  466       11 Batch loss: 0.167764 Batch F1: 0.7
Epoch:  466       12 Batch loss: 0.168858 Batch F1: 0.7027027027027027
Train Avg Loss  466: 0.171639

Train Avg F1  466: 0.7129251688927655

Val Avg Loss  466: 0.180198

Val Avg F1  466:  0.6953276955602536

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 467
--------------------------------------------------------------
Epoch:  467        1 Batch loss: 0.226801 Batch F1: 0.4615384615384615
Epoch:  467        2 Batch loss: 0.189934 Batch F1: 0.5405405405405405
Epoch:  467        3 Batch loss: 0.161950 Batch F1: 0.76
Epoch:  467        4 Batch loss: 0.184782 Batch F1: 0.6938775510204083
Epoch:  467        5 Batch loss: 0.142697 Batch F1: 0.7428571428571429
Epoch:  467        6 Batch loss: 0.152468 Batch F1: 0.7222222222222222
Epoch:  467        7 Batch loss: 0.149591 Batch F1: 0.7906976744186046
Epoch:  467        8 Batch loss: 0.163446 Batch F1: 0.7924528301886792
Epoch:  467        9 Batch loss: 0.175238 Batch F1: 0.6976744186046512
Epoch:  467       10 Batch loss: 0.141036 Batch F1: 0.7906976744186046
Epoch:  467       11 Batch loss: 0.160504 Batch F1: 0.7999999999999999
Epoch:  467       12 Batch loss: 0.186118 Batch F1: 0.6829268292682926
Train Avg Loss  467: 0.169547

Train Avg F1  467: 0.706290445423134

Val Avg Loss  467: 0.182442

Val Avg F1  467:  0.6834150326797386

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 468
--------------------------------------------------------------
Epoch:  468        1 Batch loss: 0.160841 Batch F1: 0.7755102040816326
Epoch:  468        2 Batch loss: 0.167719 Batch F1: 0.7692307692307692
Epoch:  468        3 Batch loss: 0.197605 Batch F1: 0.6666666666666666
Epoch:  468        4 Batch loss: 0.122035 Batch F1: 0.9166666666666666
Epoch:  468        5 Batch loss: 0.177866 Batch F1: 0.5294117647058824
Epoch:  468        6 Batch loss: 0.189024 Batch F1: 0.6521739130434783
Epoch:  468        7 Batch loss: 0.163648 Batch F1: 0.7027027027027027
Epoch:  468        8 Batch loss: 0.157539 Batch F1: 0.7272727272727272
Epoch:  468        9 Batch loss: 0.158648 Batch F1: 0.7727272727272727
Epoch:  468       10 Batch loss: 0.201089 Batch F1: 0.6222222222222223
Epoch:  468       11 Batch loss: 0.159037 Batch F1: 0.7999999999999999
Epoch:  468       12 Batch loss: 0.185623 Batch F1: 0.6250000000000001
Train Avg Loss  468: 0.170056

Train Avg F1  468: 0.7132987424433351

Val Avg Loss  468: 0.181150

Val Avg F1  468:  0.7293325974936917

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 469
--------------------------------------------------------------
Epoch:  469        1 Batch loss: 0.137143 Batch F1: 0.8461538461538461
Epoch:  469        2 Batch loss: 0.158040 Batch F1: 0.75
Epoch:  469        3 Batch loss: 0.175563 Batch F1: 0.7391304347826088
Epoch:  469        4 Batch loss: 0.183604 Batch F1: 0.5641025641025642
Epoch:  469        5 Batch loss: 0.158627 Batch F1: 0.7346938775510203
Epoch:  469        6 Batch loss: 0.196675 Batch F1: 0.6666666666666666
Epoch:  469        7 Batch loss: 0.176450 Batch F1: 0.7346938775510203
Epoch:  469        8 Batch loss: 0.150641 Batch F1: 0.8510638297872339
Epoch:  469        9 Batch loss: 0.184380 Batch F1: 0.7083333333333334
Epoch:  469       10 Batch loss: 0.186730 Batch F1: 0.6511627906976745
Epoch:  469       11 Batch loss: 0.177828 Batch F1: 0.6666666666666667
Epoch:  469       12 Batch loss: 0.169610 Batch F1: 0.6666666666666666
Train Avg Loss  469: 0.171274

Train Avg F1  469: 0.7149445461632752

Val Avg Loss  469: 0.182687

Val Avg F1  469:  0.6819036954087345

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 470
--------------------------------------------------------------
Epoch:  470        1 Batch loss: 0.200597 Batch F1: 0.5500000000000002
Epoch:  470        2 Batch loss: 0.169087 Batch F1: 0.7843137254901961
Epoch:  470        3 Batch loss: 0.139068 Batch F1: 0.7647058823529412
Epoch:  470        4 Batch loss: 0.173719 Batch F1: 0.723404255319149
Epoch:  470        5 Batch loss: 0.191212 Batch F1: 0.6530612244897959
Epoch:  470        6 Batch loss: 0.150161 Batch F1: 0.6
Epoch:  470        7 Batch loss: 0.180886 Batch F1: 0.7391304347826088
Epoch:  470        8 Batch loss: 0.182466 Batch F1: 0.6938775510204083
Epoch:  470        9 Batch loss: 0.154428 Batch F1: 0.7916666666666666
Epoch:  470       10 Batch loss: 0.176045 Batch F1: 0.72
Epoch:  470       11 Batch loss: 0.159681 Batch F1: 0.7826086956521738
Epoch:  470       12 Batch loss: 0.148746 Batch F1: 0.7222222222222222
Train Avg Loss  470: 0.168841

Train Avg F1  470: 0.7104158881663468

Val Avg Loss  470: 0.183027

Val Avg F1  470:  0.6964613120269134

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 471
--------------------------------------------------------------
Epoch:  471        1 Batch loss: 0.183713 Batch F1: 0.6666666666666666
Epoch:  471        2 Batch loss: 0.168550 Batch F1: 0.711111111111111
Epoch:  471        3 Batch loss: 0.170408 Batch F1: 0.717948717948718
Epoch:  471        4 Batch loss: 0.176501 Batch F1: 0.7843137254901961
Epoch:  471        5 Batch loss: 0.186952 Batch F1: 0.7199999999999999
Epoch:  471        6 Batch loss: 0.158548 Batch F1: 0.7058823529411765
Epoch:  471        7 Batch loss: 0.182940 Batch F1: 0.5853658536585366
Epoch:  471        8 Batch loss: 0.179692 Batch F1: 0.7450980392156863
Epoch:  471        9 Batch loss: 0.184165 Batch F1: 0.65
Epoch:  471       10 Batch loss: 0.154317 Batch F1: 0.8
Epoch:  471       11 Batch loss: 0.157991 Batch F1: 0.8076923076923077
Epoch:  471       12 Batch loss: 0.183506 Batch F1: 0.7272727272727273
Train Avg Loss  471: 0.173940

Train Avg F1  471: 0.7184459584997605

Val Avg Loss  471: 0.181147

Val Avg F1  471:  0.7315842940842942

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 472
--------------------------------------------------------------
Epoch:  472        1 Batch loss: 0.149604 Batch F1: 0.85
Epoch:  472        2 Batch loss: 0.174564 Batch F1: 0.7547169811320756
Epoch:  472        3 Batch loss: 0.192109 Batch F1: 0.6530612244897959
Epoch:  472        4 Batch loss: 0.163095 Batch F1: 0.7441860465116279
Epoch:  472        5 Batch loss: 0.177056 Batch F1: 0.7111111111111111
Epoch:  472        6 Batch loss: 0.175740 Batch F1: 0.6666666666666666
Epoch:  472        7 Batch loss: 0.188280 Batch F1: 0.6521739130434783
Epoch:  472        8 Batch loss: 0.186015 Batch F1: 0.6808510638297872
Epoch:  472        9 Batch loss: 0.186599 Batch F1: 0.6046511627906976
Epoch:  472       10 Batch loss: 0.147138 Batch F1: 0.8518518518518519
Epoch:  472       11 Batch loss: 0.144885 Batch F1: 0.7647058823529411
Epoch:  472       12 Batch loss: 0.172653 Batch F1: 0.6470588235294118
Train Avg Loss  472: 0.171478

Train Avg F1  472: 0.7150862272757871

Val Avg Loss  472: 0.186350

Val Avg F1  472:  0.6719736612593755

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 473
--------------------------------------------------------------
Epoch:  473        1 Batch loss: 0.157478 Batch F1: 0.782608695652174
Epoch:  473        2 Batch loss: 0.166123 Batch F1: 0.7727272727272727
Epoch:  473        3 Batch loss: 0.194414 Batch F1: 0.5641025641025641
Epoch:  473        4 Batch loss: 0.198890 Batch F1: 0.64
Epoch:  473        5 Batch loss: 0.177357 Batch F1: 0.7499999999999999
Epoch:  473        6 Batch loss: 0.143965 Batch F1: 0.7272727272727272
Epoch:  473        7 Batch loss: 0.213425 Batch F1: 0.6984126984126984
Epoch:  473        8 Batch loss: 0.137539 Batch F1: 0.9285714285714286
Epoch:  473        9 Batch loss: 0.203425 Batch F1: 0.6363636363636364
Epoch:  473       10 Batch loss: 0.145264 Batch F1: 0.7647058823529412
Epoch:  473       11 Batch loss: 0.189101 Batch F1: 0.5405405405405405
Epoch:  473       12 Batch loss: 0.120696 Batch F1: 0.9230769230769231
Train Avg Loss  473: 0.170640

Train Avg F1  473: 0.7273651974227423

Val Avg Loss  473: 0.182788

Val Avg F1  473:  0.7155178672259417

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 474
--------------------------------------------------------------
Epoch:  474        1 Batch loss: 0.165239 Batch F1: 0.6976744186046512
Epoch:  474        2 Batch loss: 0.199993 Batch F1: 0.6511627906976745
Epoch:  474        3 Batch loss: 0.164311 Batch F1: 0.6666666666666667
Epoch:  474        4 Batch loss: 0.143771 Batch F1: 0.7727272727272727
Epoch:  474        5 Batch loss: 0.187343 Batch F1: 0.6808510638297872
Epoch:  474        6 Batch loss: 0.160640 Batch F1: 0.76
Epoch:  474        7 Batch loss: 0.196736 Batch F1: 0.6938775510204083
Epoch:  474        8 Batch loss: 0.163105 Batch F1: 0.7391304347826085
Epoch:  474        9 Batch loss: 0.165270 Batch F1: 0.7857142857142856
Epoch:  474       10 Batch loss: 0.183964 Batch F1: 0.6222222222222222
Epoch:  474       11 Batch loss: 0.187643 Batch F1: 0.5945945945945946
Epoch:  474       12 Batch loss: 0.146353 Batch F1: 0.823529411764706
Train Avg Loss  474: 0.172031

Train Avg F1  474: 0.7073458927187398

Val Avg Loss  474: 0.183291

Val Avg F1  474:  0.6933519965864978

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 475
--------------------------------------------------------------
Epoch:  475        1 Batch loss: 0.196454 Batch F1: 0.6666666666666666
Epoch:  475        2 Batch loss: 0.175205 Batch F1: 0.6976744186046512
Epoch:  475        3 Batch loss: 0.190191 Batch F1: 0.6818181818181818
Epoch:  475        4 Batch loss: 0.161572 Batch F1: 0.7272727272727273
Epoch:  475        5 Batch loss: 0.185021 Batch F1: 0.6521739130434783
Epoch:  475        6 Batch loss: 0.161695 Batch F1: 0.7999999999999999
Epoch:  475        7 Batch loss: 0.164382 Batch F1: 0.7450980392156864
Epoch:  475        8 Batch loss: 0.190814 Batch F1: 0.5555555555555555
Epoch:  475        9 Batch loss: 0.179264 Batch F1: 0.6818181818181819
Epoch:  475       10 Batch loss: 0.124792 Batch F1: 0.8260869565217391
Epoch:  475       11 Batch loss: 0.157611 Batch F1: 0.7619047619047619
Epoch:  475       12 Batch loss: 0.158770 Batch F1: 0.761904761904762
Train Avg Loss  475: 0.170481

Train Avg F1  475: 0.713164513693866

Val Avg Loss  475: 0.182275

Val Avg F1  475:  0.6808079022819213

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 476
--------------------------------------------------------------
Epoch:  476        1 Batch loss: 0.142017 Batch F1: 0.8095238095238095
Epoch:  476        2 Batch loss: 0.179145 Batch F1: 0.7407407407407408
Epoch:  476        3 Batch loss: 0.154069 Batch F1: 0.8461538461538461
Epoch:  476        4 Batch loss: 0.192412 Batch F1: 0.6521739130434783
Epoch:  476        5 Batch loss: 0.158365 Batch F1: 0.7499999999999999
Epoch:  476        6 Batch loss: 0.150316 Batch F1: 0.8085106382978724
Epoch:  476        7 Batch loss: 0.178077 Batch F1: 0.6818181818181819
Epoch:  476        8 Batch loss: 0.153792 Batch F1: 0.7027027027027026
Epoch:  476        9 Batch loss: 0.178531 Batch F1: 0.5945945945945946
Epoch:  476       10 Batch loss: 0.197569 Batch F1: 0.7234042553191489
Epoch:  476       11 Batch loss: 0.213659 Batch F1: 0.6153846153846153
Epoch:  476       12 Batch loss: 0.166713 Batch F1: 0.7894736842105263
Train Avg Loss  476: 0.172055

Train Avg F1  476: 0.7262067484824596

Val Avg Loss  476: 0.182070

Val Avg F1  476:  0.6884375977321106

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 477
--------------------------------------------------------------
Epoch:  477        1 Batch loss: 0.186832 Batch F1: 0.6666666666666667
Epoch:  477        2 Batch loss: 0.215442 Batch F1: 0.5714285714285714
Epoch:  477        3 Batch loss: 0.199944 Batch F1: 0.6222222222222223
Epoch:  477        4 Batch loss: 0.148156 Batch F1: 0.7804878048780488
Epoch:  477        5 Batch loss: 0.216566 Batch F1: 0.5454545454545454
Epoch:  477        6 Batch loss: 0.128627 Batch F1: 0.8648648648648648
Epoch:  477        7 Batch loss: 0.171802 Batch F1: 0.75
Epoch:  477        8 Batch loss: 0.153287 Batch F1: 0.8627450980392156
Epoch:  477        9 Batch loss: 0.180050 Batch F1: 0.7843137254901961
Epoch:  477       10 Batch loss: 0.138921 Batch F1: 0.896551724137931
Epoch:  477       11 Batch loss: 0.189659 Batch F1: 0.7916666666666666
Epoch:  477       12 Batch loss: 0.165430 Batch F1: 0.7368421052631579
Train Avg Loss  477: 0.174560

Train Avg F1  477: 0.7394369995926738

Val Avg Loss  477: 0.189430

Val Avg F1  477:  0.6873917615042059

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 478
--------------------------------------------------------------
Epoch:  478        1 Batch loss: 0.180671 Batch F1: 0.5945945945945946
Epoch:  478        2 Batch loss: 0.166344 Batch F1: 0.7916666666666667
Epoch:  478        3 Batch loss: 0.210174 Batch F1: 0.7037037037037038
Epoch:  478        4 Batch loss: 0.212608 Batch F1: 0.5652173913043478
Epoch:  478        5 Batch loss: 0.176860 Batch F1: 0.7843137254901961
Epoch:  478        6 Batch loss: 0.169497 Batch F1: 0.7755102040816326
Epoch:  478        7 Batch loss: 0.199431 Batch F1: 0.6521739130434783
Epoch:  478        8 Batch loss: 0.161501 Batch F1: 0.7727272727272727
Epoch:  478        9 Batch loss: 0.155570 Batch F1: 0.8181818181818182
Epoch:  478       10 Batch loss: 0.177413 Batch F1: 0.7027027027027027
Epoch:  478       11 Batch loss: 0.206325 Batch F1: 0.5294117647058825
Epoch:  478       12 Batch loss: 0.176507 Batch F1: 0.6666666666666666
Train Avg Loss  478: 0.182742

Train Avg F1  478: 0.6964058686557468

Val Avg Loss  478: 0.202101

Val Avg F1  478:  0.7893623676883363

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 479
--------------------------------------------------------------
Epoch:  479        1 Batch loss: 0.199968 Batch F1: 0.7499999999999999
Epoch:  479        2 Batch loss: 0.218838 Batch F1: 0.7391304347826088
Epoch:  479        3 Batch loss: 0.143510 Batch F1: 0.8333333333333334
Epoch:  479        4 Batch loss: 0.144835 Batch F1: 0.7567567567567567
Epoch:  479        5 Batch loss: 0.185557 Batch F1: 0.6511627906976744
Epoch:  479        6 Batch loss: 0.176683 Batch F1: 0.6818181818181819
Epoch:  479        7 Batch loss: 0.163901 Batch F1: 0.7317073170731706
Epoch:  479        8 Batch loss: 0.179657 Batch F1: 0.6818181818181818
Epoch:  479        9 Batch loss: 0.187313 Batch F1: 0.5945945945945946
Epoch:  479       10 Batch loss: 0.218288 Batch F1: 0.6415094339622641
Epoch:  479       11 Batch loss: 0.159806 Batch F1: 0.823529411764706
Epoch:  479       12 Batch loss: 0.225859 Batch F1: 0.7272727272727273
Train Avg Loss  479: 0.183685

Train Avg F1  479: 0.7177194303228499

Val Avg Loss  479: 0.183551

Val Avg F1  479:  0.6861482720178371

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 480
--------------------------------------------------------------
Epoch:  480        1 Batch loss: 0.163207 Batch F1: 0.7272727272727272
Epoch:  480        2 Batch loss: 0.153144 Batch F1: 0.8627450980392156
Epoch:  480        3 Batch loss: 0.178584 Batch F1: 0.65
Epoch:  480        4 Batch loss: 0.163874 Batch F1: 0.7826086956521738
Epoch:  480        5 Batch loss: 0.230650 Batch F1: 0.6341463414634146
Epoch:  480        6 Batch loss: 0.184813 Batch F1: 0.5714285714285715
Epoch:  480        7 Batch loss: 0.191640 Batch F1: 0.7555555555555556
Epoch:  480        8 Batch loss: 0.196709 Batch F1: 0.6
Epoch:  480        9 Batch loss: 0.192796 Batch F1: 0.6938775510204083
Epoch:  480       10 Batch loss: 0.184390 Batch F1: 0.6829268292682926
Epoch:  480       11 Batch loss: 0.156978 Batch F1: 0.7755102040816326
Epoch:  480       12 Batch loss: 0.157172 Batch F1: 0.7058823529411764
Train Avg Loss  480: 0.179497

Train Avg F1  480: 0.703496160560264

Val Avg Loss  480: 0.180949

Val Avg F1  480:  0.7058965424819084

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 481
--------------------------------------------------------------
Epoch:  481        1 Batch loss: 0.155251 Batch F1: 0.7755102040816326
Epoch:  481        2 Batch loss: 0.152393 Batch F1: 0.8648648648648649
Epoch:  481        3 Batch loss: 0.204549 Batch F1: 0.7169811320754716
Epoch:  481        4 Batch loss: 0.185791 Batch F1: 0.6829268292682926
Epoch:  481        5 Batch loss: 0.179804 Batch F1: 0.7450980392156863
Epoch:  481        6 Batch loss: 0.184709 Batch F1: 0.723404255319149
Epoch:  481        7 Batch loss: 0.189159 Batch F1: 0.6382978723404255
Epoch:  481        8 Batch loss: 0.159446 Batch F1: 0.7441860465116279
Epoch:  481        9 Batch loss: 0.199357 Batch F1: 0.6341463414634146
Epoch:  481       10 Batch loss: 0.151095 Batch F1: 0.7222222222222222
Epoch:  481       11 Batch loss: 0.177842 Batch F1: 0.7346938775510204
Epoch:  481       12 Batch loss: 0.152828 Batch F1: 0.7567567567567567
Train Avg Loss  481: 0.174352

Train Avg F1  481: 0.7282573701392137

Val Avg Loss  481: 0.185319

Val Avg F1  481:  0.6696054099551393

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 482
--------------------------------------------------------------
Epoch:  482        1 Batch loss: 0.181237 Batch F1: 0.6153846153846153
Epoch:  482        2 Batch loss: 0.152590 Batch F1: 0.6857142857142857
Epoch:  482        3 Batch loss: 0.155713 Batch F1: 0.717948717948718
Epoch:  482        4 Batch loss: 0.216679 Batch F1: 0.6545454545454547
Epoch:  482        5 Batch loss: 0.195364 Batch F1: 0.7234042553191489
Epoch:  482        6 Batch loss: 0.149582 Batch F1: 0.7027027027027026
Epoch:  482        7 Batch loss: 0.162558 Batch F1: 0.8
Epoch:  482        8 Batch loss: 0.234255 Batch F1: 0.6896551724137931
Epoch:  482        9 Batch loss: 0.192220 Batch F1: 0.6046511627906976
Epoch:  482       10 Batch loss: 0.153911 Batch F1: 0.7727272727272727
Epoch:  482       11 Batch loss: 0.195956 Batch F1: 0.6363636363636364
Epoch:  482       12 Batch loss: 0.160104 Batch F1: 0.8
Train Avg Loss  482: 0.179181

Train Avg F1  482: 0.7002581063258605

Val Avg Loss  482: 0.189333

Val Avg F1  482:  0.6711510570172607

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 483
--------------------------------------------------------------
Epoch:  483        1 Batch loss: 0.159626 Batch F1: 0.7916666666666666
Epoch:  483        2 Batch loss: 0.186317 Batch F1: 0.6666666666666667
Epoch:  483        3 Batch loss: 0.161836 Batch F1: 0.8085106382978724
Epoch:  483        4 Batch loss: 0.190120 Batch F1: 0.6363636363636364
Epoch:  483        5 Batch loss: 0.147474 Batch F1: 0.7906976744186046
Epoch:  483        6 Batch loss: 0.212580 Batch F1: 0.6666666666666666
Epoch:  483        7 Batch loss: 0.171892 Batch F1: 0.7555555555555556
Epoch:  483        8 Batch loss: 0.178914 Batch F1: 0.6666666666666667
Epoch:  483        9 Batch loss: 0.172954 Batch F1: 0.6500000000000001
Epoch:  483       10 Batch loss: 0.166943 Batch F1: 0.7142857142857143
Epoch:  483       11 Batch loss: 0.205048 Batch F1: 0.5777777777777778
Epoch:  483       12 Batch loss: 0.187827 Batch F1: 0.6666666666666666
Train Avg Loss  483: 0.178461

Train Avg F1  483: 0.6992936941693745

Val Avg Loss  483: 0.189125

Val Avg F1  483:  0.6619657645666962

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 484
--------------------------------------------------------------
Epoch:  484        1 Batch loss: 0.193774 Batch F1: 0.64
Epoch:  484        2 Batch loss: 0.174366 Batch F1: 0.6923076923076924
Epoch:  484        3 Batch loss: 0.163067 Batch F1: 0.7142857142857143
Epoch:  484        4 Batch loss: 0.169527 Batch F1: 0.7058823529411765
Epoch:  484        5 Batch loss: 0.171634 Batch F1: 0.7924528301886793
Epoch:  484        6 Batch loss: 0.193526 Batch F1: 0.6666666666666666
Epoch:  484        7 Batch loss: 0.178004 Batch F1: 0.7499999999999999
Epoch:  484        8 Batch loss: 0.173735 Batch F1: 0.7111111111111111
Epoch:  484        9 Batch loss: 0.156333 Batch F1: 0.7058823529411765
Epoch:  484       10 Batch loss: 0.168389 Batch F1: 0.6666666666666667
Epoch:  484       11 Batch loss: 0.179544 Batch F1: 0.5945945945945946
Epoch:  484       12 Batch loss: 0.207045 Batch F1: 0.6956521739130435
Train Avg Loss  484: 0.177412

Train Avg F1  484: 0.6946251796347102

Val Avg Loss  484: 0.189058

Val Avg F1  484:  0.6672113289760349

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 485
--------------------------------------------------------------
Epoch:  485        1 Batch loss: 0.142896 Batch F1: 0.8444444444444444
Epoch:  485        2 Batch loss: 0.167672 Batch F1: 0.6829268292682926
Epoch:  485        3 Batch loss: 0.194074 Batch F1: 0.7272727272727272
Epoch:  485        4 Batch loss: 0.154537 Batch F1: 0.782608695652174
Epoch:  485        5 Batch loss: 0.201017 Batch F1: 0.5581395348837209
Epoch:  485        6 Batch loss: 0.189096 Batch F1: 0.6938775510204082
Epoch:  485        7 Batch loss: 0.174424 Batch F1: 0.711111111111111
Epoch:  485        8 Batch loss: 0.163249 Batch F1: 0.625
Epoch:  485        9 Batch loss: 0.186748 Batch F1: 0.6808510638297872
Epoch:  485       10 Batch loss: 0.178765 Batch F1: 0.7272727272727272
Epoch:  485       11 Batch loss: 0.168502 Batch F1: 0.7317073170731706
Epoch:  485       12 Batch loss: 0.172091 Batch F1: 0.7368421052631577
Train Avg Loss  485: 0.174423

Train Avg F1  485: 0.7085045089243102

Val Avg Loss  485: 0.185344

Val Avg F1  485:  0.6847997981973591

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 486
--------------------------------------------------------------
Epoch:  486        1 Batch loss: 0.176582 Batch F1: 0.6486486486486486
Epoch:  486        2 Batch loss: 0.164956 Batch F1: 0.625
Epoch:  486        3 Batch loss: 0.161852 Batch F1: 0.7868852459016394
Epoch:  486        4 Batch loss: 0.183044 Batch F1: 0.5555555555555556
Epoch:  486        5 Batch loss: 0.149618 Batch F1: 0.7727272727272727
Epoch:  486        6 Batch loss: 0.142829 Batch F1: 0.8108108108108107
Epoch:  486        7 Batch loss: 0.202121 Batch F1: 0.6538461538461539
Epoch:  486        8 Batch loss: 0.168337 Batch F1: 0.7142857142857143
Epoch:  486        9 Batch loss: 0.150776 Batch F1: 0.7727272727272727
Epoch:  486       10 Batch loss: 0.180065 Batch F1: 0.7307692307692308
Epoch:  486       11 Batch loss: 0.213847 Batch F1: 0.6538461538461539
Epoch:  486       12 Batch loss: 0.174299 Batch F1: 0.7692307692307693
Train Avg Loss  486: 0.172361

Train Avg F1  486: 0.7078610690291018

Val Avg Loss  486: 0.182852

Val Avg F1  486:  0.6870873728662344

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 487
--------------------------------------------------------------
Epoch:  487        1 Batch loss: 0.167924 Batch F1: 0.723404255319149
Epoch:  487        2 Batch loss: 0.174934 Batch F1: 0.6153846153846153
Epoch:  487        3 Batch loss: 0.156148 Batch F1: 0.7692307692307692
Epoch:  487        4 Batch loss: 0.159386 Batch F1: 0.7843137254901961
Epoch:  487        5 Batch loss: 0.159915 Batch F1: 0.6666666666666666
Epoch:  487        6 Batch loss: 0.159048 Batch F1: 0.7826086956521738
Epoch:  487        7 Batch loss: 0.170259 Batch F1: 0.5882352941176471
Epoch:  487        8 Batch loss: 0.147029 Batch F1: 0.8085106382978724
Epoch:  487        9 Batch loss: 0.179585 Batch F1: 0.7307692307692306
Epoch:  487       10 Batch loss: 0.202363 Batch F1: 0.6666666666666667
Epoch:  487       11 Batch loss: 0.198169 Batch F1: 0.6249999999999999
Epoch:  487       12 Batch loss: 0.170712 Batch F1: 0.7058823529411765
Train Avg Loss  487: 0.170456

Train Avg F1  487: 0.7055560758780136

Val Avg Loss  487: 0.181798

Val Avg F1  487:  0.6952292299898684

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 488
--------------------------------------------------------------
Epoch:  488        1 Batch loss: 0.173452 Batch F1: 0.5945945945945946
Epoch:  488        2 Batch loss: 0.181716 Batch F1: 0.7307692307692307
Epoch:  488        3 Batch loss: 0.177105 Batch F1: 0.6666666666666666
Epoch:  488        4 Batch loss: 0.117760 Batch F1: 0.8484848484848485
Epoch:  488        5 Batch loss: 0.181587 Batch F1: 0.6808510638297872
Epoch:  488        6 Batch loss: 0.169064 Batch F1: 0.7272727272727272
Epoch:  488        7 Batch loss: 0.185189 Batch F1: 0.75
Epoch:  488        8 Batch loss: 0.189681 Batch F1: 0.7307692307692308
Epoch:  488        9 Batch loss: 0.183909 Batch F1: 0.6
Epoch:  488       10 Batch loss: 0.182169 Batch F1: 0.7234042553191489
Epoch:  488       11 Batch loss: 0.154023 Batch F1: 0.7567567567567567
Epoch:  488       12 Batch loss: 0.149487 Batch F1: 0.8181818181818182
Train Avg Loss  488: 0.170428

Train Avg F1  488: 0.7189792660537341

Val Avg Loss  488: 0.182657

Val Avg F1  488:  0.6910319917440662

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 489
--------------------------------------------------------------
Epoch:  489        1 Batch loss: 0.170888 Batch F1: 0.7000000000000001
Epoch:  489        2 Batch loss: 0.163024 Batch F1: 0.7499999999999999
Epoch:  489        3 Batch loss: 0.179081 Batch F1: 0.6666666666666666
Epoch:  489        4 Batch loss: 0.154493 Batch F1: 0.6666666666666666
Epoch:  489        5 Batch loss: 0.176807 Batch F1: 0.7924528301886793
Epoch:  489        6 Batch loss: 0.181451 Batch F1: 0.7200000000000001
Epoch:  489        7 Batch loss: 0.198865 Batch F1: 0.6956521739130435
Epoch:  489        8 Batch loss: 0.156959 Batch F1: 0.7368421052631577
Epoch:  489        9 Batch loss: 0.183907 Batch F1: 0.7317073170731707
Epoch:  489       10 Batch loss: 0.145701 Batch F1: 0.8
Epoch:  489       11 Batch loss: 0.160096 Batch F1: 0.7317073170731706
Epoch:  489       12 Batch loss: 0.202877 Batch F1: 0.6363636363636365
Train Avg Loss  489: 0.172846

Train Avg F1  489: 0.7190048927673492

Val Avg Loss  489: 0.185056

Val Avg F1  489:  0.6914820967146549

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 490
--------------------------------------------------------------
Epoch:  490        1 Batch loss: 0.156784 Batch F1: 0.7499999999999999
Epoch:  490        2 Batch loss: 0.183610 Batch F1: 0.7200000000000001
Epoch:  490        3 Batch loss: 0.162155 Batch F1: 0.7804878048780488
Epoch:  490        4 Batch loss: 0.192895 Batch F1: 0.6829268292682926
Epoch:  490        5 Batch loss: 0.213612 Batch F1: 0.6923076923076923
Epoch:  490        6 Batch loss: 0.166138 Batch F1: 0.8421052631578948
Epoch:  490        7 Batch loss: 0.160318 Batch F1: 0.6666666666666665
Epoch:  490        8 Batch loss: 0.200133 Batch F1: 0.6666666666666666
Epoch:  490        9 Batch loss: 0.174080 Batch F1: 0.711111111111111
Epoch:  490       10 Batch loss: 0.134371 Batch F1: 0.8
Epoch:  490       11 Batch loss: 0.194760 Batch F1: 0.6521739130434783
Epoch:  490       12 Batch loss: 0.162078 Batch F1: 0.7692307692307692
Train Avg Loss  490: 0.175078

Train Avg F1  490: 0.7278063930275517

Val Avg Loss  490: 0.183635

Val Avg F1  490:  0.6774734062469911

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 491
--------------------------------------------------------------
Epoch:  491        1 Batch loss: 0.148281 Batch F1: 0.8372093023255814
Epoch:  491        2 Batch loss: 0.187467 Batch F1: 0.6808510638297872
Epoch:  491        3 Batch loss: 0.173926 Batch F1: 0.6829268292682926
Epoch:  491        4 Batch loss: 0.196560 Batch F1: 0.6382978723404256
Epoch:  491        5 Batch loss: 0.176726 Batch F1: 0.6829268292682926
Epoch:  491        6 Batch loss: 0.157586 Batch F1: 0.7916666666666666
Epoch:  491        7 Batch loss: 0.171405 Batch F1: 0.631578947368421
Epoch:  491        8 Batch loss: 0.176661 Batch F1: 0.6666666666666666
Epoch:  491        9 Batch loss: 0.172742 Batch F1: 0.6956521739130435
Epoch:  491       10 Batch loss: 0.147238 Batch F1: 0.7619047619047619
Epoch:  491       11 Batch loss: 0.174803 Batch F1: 0.7450980392156864
Epoch:  491       12 Batch loss: 0.167208 Batch F1: 0.7368421052631577
Train Avg Loss  491: 0.170884

Train Avg F1  491: 0.7126351048358986

Val Avg Loss  491: 0.180408

Val Avg F1  491:  0.7234453993933265

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 492
--------------------------------------------------------------
Epoch:  492        1 Batch loss: 0.154547 Batch F1: 0.7906976744186046
Epoch:  492        2 Batch loss: 0.163549 Batch F1: 0.7346938775510203
Epoch:  492        3 Batch loss: 0.164245 Batch F1: 0.7843137254901961
Epoch:  492        4 Batch loss: 0.170464 Batch F1: 0.8148148148148148
Epoch:  492        5 Batch loss: 0.195284 Batch F1: 0.5945945945945945
Epoch:  492        6 Batch loss: 0.209935 Batch F1: 0.6538461538461539
Epoch:  492        7 Batch loss: 0.175805 Batch F1: 0.6341463414634146
Epoch:  492        8 Batch loss: 0.152213 Batch F1: 0.7222222222222222
Epoch:  492        9 Batch loss: 0.159078 Batch F1: 0.7317073170731708
Epoch:  492       10 Batch loss: 0.173323 Batch F1: 0.7843137254901961
Epoch:  492       11 Batch loss: 0.196806 Batch F1: 0.5777777777777778
Epoch:  492       12 Batch loss: 0.147345 Batch F1: 0.7096774193548386
Train Avg Loss  492: 0.171883

Train Avg F1  492: 0.7110671370080835

Val Avg Loss  492: 0.181162

Val Avg F1  492:  0.682642893169209

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 493
--------------------------------------------------------------
Epoch:  493        1 Batch loss: 0.166612 Batch F1: 0.717948717948718
Epoch:  493        2 Batch loss: 0.147318 Batch F1: 0.830188679245283
Epoch:  493        3 Batch loss: 0.144526 Batch F1: 0.7906976744186046
Epoch:  493        4 Batch loss: 0.183751 Batch F1: 0.72
Epoch:  493        5 Batch loss: 0.156357 Batch F1: 0.7000000000000001
Epoch:  493        6 Batch loss: 0.183583 Batch F1: 0.6956521739130435
Epoch:  493        7 Batch loss: 0.181064 Batch F1: 0.6666666666666666
Epoch:  493        8 Batch loss: 0.195850 Batch F1: 0.6046511627906977
Epoch:  493        9 Batch loss: 0.197327 Batch F1: 0.6923076923076923
Epoch:  493       10 Batch loss: 0.177711 Batch F1: 0.7083333333333334
Epoch:  493       11 Batch loss: 0.160444 Batch F1: 0.7906976744186046
Epoch:  493       12 Batch loss: 0.154075 Batch F1: 0.689655172413793
Train Avg Loss  493: 0.170718

Train Avg F1  493: 0.7172332456213698

Val Avg Loss  493: 0.180726

Val Avg F1  493:  0.6951026772455344

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 494
--------------------------------------------------------------
Epoch:  494        1 Batch loss: 0.201719 Batch F1: 0.6530612244897959
Epoch:  494        2 Batch loss: 0.147744 Batch F1: 0.8148148148148148
Epoch:  494        3 Batch loss: 0.160480 Batch F1: 0.7500000000000001
Epoch:  494        4 Batch loss: 0.175958 Batch F1: 0.6842105263157895
Epoch:  494        5 Batch loss: 0.205310 Batch F1: 0.6250000000000001
Epoch:  494        6 Batch loss: 0.161962 Batch F1: 0.830188679245283
Epoch:  494        7 Batch loss: 0.148705 Batch F1: 0.7804878048780488
Epoch:  494        8 Batch loss: 0.193608 Batch F1: 0.6923076923076923
Epoch:  494        9 Batch loss: 0.188077 Batch F1: 0.5641025641025641
Epoch:  494       10 Batch loss: 0.179716 Batch F1: 0.6956521739130435
Epoch:  494       11 Batch loss: 0.148177 Batch F1: 0.7368421052631577
Epoch:  494       12 Batch loss: 0.147371 Batch F1: 0.7586206896551724
Train Avg Loss  494: 0.171569

Train Avg F1  494: 0.7154406895821134

Val Avg Loss  494: 0.181578

Val Avg F1  494:  0.7026823049464559

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 495
--------------------------------------------------------------
Epoch:  495        1 Batch loss: 0.152276 Batch F1: 0.8148148148148148
Epoch:  495        2 Batch loss: 0.182418 Batch F1: 0.7083333333333334
Epoch:  495        3 Batch loss: 0.162382 Batch F1: 0.8125000000000001
Epoch:  495        4 Batch loss: 0.212038 Batch F1: 0.6122448979591838
Epoch:  495        5 Batch loss: 0.166474 Batch F1: 0.6829268292682926
Epoch:  495        6 Batch loss: 0.215404 Batch F1: 0.6122448979591837
Epoch:  495        7 Batch loss: 0.180083 Batch F1: 0.6341463414634146
Epoch:  495        8 Batch loss: 0.147314 Batch F1: 0.6666666666666666
Epoch:  495        9 Batch loss: 0.178963 Batch F1: 0.7083333333333333
Epoch:  495       10 Batch loss: 0.150294 Batch F1: 0.7567567567567567
Epoch:  495       11 Batch loss: 0.165610 Batch F1: 0.6486486486486486
Epoch:  495       12 Batch loss: 0.154229 Batch F1: 0.8333333333333333
Train Avg Loss  495: 0.172290

Train Avg F1  495: 0.7075791544614135

Val Avg Loss  495: 0.179976

Val Avg F1  495:  0.6958946637551104

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 496
--------------------------------------------------------------
Epoch:  496        1 Batch loss: 0.169243 Batch F1: 0.7346938775510204
Epoch:  496        2 Batch loss: 0.166249 Batch F1: 0.7441860465116279
Epoch:  496        3 Batch loss: 0.157661 Batch F1: 0.5714285714285715
Epoch:  496        4 Batch loss: 0.191243 Batch F1: 0.7142857142857143
Epoch:  496        5 Batch loss: 0.157714 Batch F1: 0.7272727272727273
Epoch:  496        6 Batch loss: 0.172787 Batch F1: 0.6315789473684211
Epoch:  496        7 Batch loss: 0.169067 Batch F1: 0.7
Epoch:  496        8 Batch loss: 0.158871 Batch F1: 0.8235294117647058
Epoch:  496        9 Batch loss: 0.182374 Batch F1: 0.6500000000000001
Epoch:  496       10 Batch loss: 0.188942 Batch F1: 0.6976744186046512
Epoch:  496       11 Batch loss: 0.172768 Batch F1: 0.72
Epoch:  496       12 Batch loss: 0.169669 Batch F1: 0.7659574468085107
Train Avg Loss  496: 0.171382

Train Avg F1  496: 0.7067172634663293

Val Avg Loss  496: 0.187154

Val Avg F1  496:  0.6672619047619048

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 497
--------------------------------------------------------------
Epoch:  497        1 Batch loss: 0.184313 Batch F1: 0.7111111111111111
Epoch:  497        2 Batch loss: 0.186631 Batch F1: 0.611111111111111
Epoch:  497        3 Batch loss: 0.177439 Batch F1: 0.6818181818181819
Epoch:  497        4 Batch loss: 0.169051 Batch F1: 0.7843137254901961
Epoch:  497        5 Batch loss: 0.183241 Batch F1: 0.75
Epoch:  497        6 Batch loss: 0.172391 Batch F1: 0.6666666666666666
Epoch:  497        7 Batch loss: 0.192769 Batch F1: 0.7777777777777777
Epoch:  497        8 Batch loss: 0.170629 Batch F1: 0.6666666666666665
Epoch:  497        9 Batch loss: 0.172719 Batch F1: 0.7999999999999999
Epoch:  497       10 Batch loss: 0.172821 Batch F1: 0.6486486486486486
Epoch:  497       11 Batch loss: 0.170750 Batch F1: 0.6511627906976744
Epoch:  497       12 Batch loss: 0.182064 Batch F1: 0.7916666666666667
Train Avg Loss  497: 0.177901

Train Avg F1  497: 0.7117452788878916

Val Avg Loss  497: 0.184989

Val Avg F1  497:  0.6680900621118012

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 498
--------------------------------------------------------------
Epoch:  498        1 Batch loss: 0.191447 Batch F1: 0.6938775510204083
Epoch:  498        2 Batch loss: 0.170343 Batch F1: 0.6956521739130435
Epoch:  498        3 Batch loss: 0.195986 Batch F1: 0.5945945945945945
Epoch:  498        4 Batch loss: 0.150145 Batch F1: 0.8085106382978724
Epoch:  498        5 Batch loss: 0.169718 Batch F1: 0.7000000000000001
Epoch:  498        6 Batch loss: 0.209856 Batch F1: 0.5294117647058824
Epoch:  498        7 Batch loss: 0.143123 Batch F1: 0.7777777777777778
Epoch:  498        8 Batch loss: 0.232119 Batch F1: 0.4210526315789474
Epoch:  498        9 Batch loss: 0.155883 Batch F1: 0.8163265306122449
Epoch:  498       10 Batch loss: 0.153165 Batch F1: 0.7441860465116279
Epoch:  498       11 Batch loss: 0.177255 Batch F1: 0.5945945945945945
Epoch:  498       12 Batch loss: 0.150964 Batch F1: 0.8679245283018868
Train Avg Loss  498: 0.175000

Train Avg F1  498: 0.6869924026590734

Val Avg Loss  498: 0.183459

Val Avg F1  498:  0.7306314946584762

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 499
--------------------------------------------------------------
Epoch:  499        1 Batch loss: 0.170473 Batch F1: 0.7450980392156864
Epoch:  499        2 Batch loss: 0.164497 Batch F1: 0.8333333333333333
Epoch:  499        3 Batch loss: 0.219831 Batch F1: 0.6938775510204082
Epoch:  499        4 Batch loss: 0.154430 Batch F1: 0.8400000000000001
Epoch:  499        5 Batch loss: 0.166181 Batch F1: 0.7777777777777779
Epoch:  499        6 Batch loss: 0.165616 Batch F1: 0.8571428571428572
Epoch:  499        7 Batch loss: 0.180860 Batch F1: 0.7755102040816326
Epoch:  499        8 Batch loss: 0.184787 Batch F1: 0.6341463414634146
Epoch:  499        9 Batch loss: 0.170528 Batch F1: 0.7111111111111111
Epoch:  499       10 Batch loss: 0.154102 Batch F1: 0.6666666666666667
Epoch:  499       11 Batch loss: 0.174412 Batch F1: 0.6976744186046512
Epoch:  499       12 Batch loss: 0.175244 Batch F1: 0.5714285714285714
Train Avg Loss  499: 0.173413

Train Avg F1  499: 0.7336472393205091

Val Avg Loss  499: 0.187865

Val Avg F1  499:  0.6581163401815575

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 500
--------------------------------------------------------------
Epoch:  500        1 Batch loss: 0.181415 Batch F1: 0.6808510638297872
Epoch:  500        2 Batch loss: 0.144061 Batch F1: 0.7804878048780488
Epoch:  500        3 Batch loss: 0.200997 Batch F1: 0.6086956521739131
Epoch:  500        4 Batch loss: 0.160546 Batch F1: 0.8235294117647058
Epoch:  500        5 Batch loss: 0.202915 Batch F1: 0.75
Epoch:  500        6 Batch loss: 0.151865 Batch F1: 0.8
Epoch:  500        7 Batch loss: 0.174314 Batch F1: 0.7346938775510204
Epoch:  500        8 Batch loss: 0.154582 Batch F1: 0.717948717948718
Epoch:  500        9 Batch loss: 0.177566 Batch F1: 0.6500000000000001
Epoch:  500       10 Batch loss: 0.147387 Batch F1: 0.8727272727272727
Epoch:  500       11 Batch loss: 0.192351 Batch F1: 0.6341463414634146
Epoch:  500       12 Batch loss: 0.174724 Batch F1: 0.6666666666666667
Train Avg Loss  500: 0.171894

Train Avg F1  500: 0.7266455674169623

Val Avg Loss  500: 0.181699

Val Avg F1  500:  0.7019229189960898

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 501
--------------------------------------------------------------
Epoch:  501        1 Batch loss: 0.147120 Batch F1: 0.8333333333333333
Epoch:  501        2 Batch loss: 0.179735 Batch F1: 0.7169811320754718
Epoch:  501        3 Batch loss: 0.167565 Batch F1: 0.7368421052631577
Epoch:  501        4 Batch loss: 0.180869 Batch F1: 0.7083333333333334
Epoch:  501        5 Batch loss: 0.151769 Batch F1: 0.7441860465116279
Epoch:  501        6 Batch loss: 0.185474 Batch F1: 0.6521739130434783
Epoch:  501        7 Batch loss: 0.161948 Batch F1: 0.7500000000000001
Epoch:  501        8 Batch loss: 0.154580 Batch F1: 0.8076923076923077
Epoch:  501        9 Batch loss: 0.155406 Batch F1: 0.7804878048780488
Epoch:  501       10 Batch loss: 0.175237 Batch F1: 0.65
Epoch:  501       11 Batch loss: 0.208597 Batch F1: 0.5777777777777778
Epoch:  501       12 Batch loss: 0.175560 Batch F1: 0.6829268292682926
Train Avg Loss  501: 0.170322

Train Avg F1  501: 0.7200612152647358

Val Avg Loss  501: 0.182404

Val Avg F1  501:  0.6961629001883239

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 502
--------------------------------------------------------------
Epoch:  502        1 Batch loss: 0.155713 Batch F1: 0.8000000000000002
Epoch:  502        2 Batch loss: 0.182727 Batch F1: 0.6976744186046512
Epoch:  502        3 Batch loss: 0.187405 Batch F1: 0.6511627906976744
Epoch:  502        4 Batch loss: 0.200094 Batch F1: 0.64
Epoch:  502        5 Batch loss: 0.156216 Batch F1: 0.8
Epoch:  502        6 Batch loss: 0.178058 Batch F1: 0.6511627906976745
Epoch:  502        7 Batch loss: 0.176844 Batch F1: 0.6956521739130435
Epoch:  502        8 Batch loss: 0.173662 Batch F1: 0.7111111111111111
Epoch:  502        9 Batch loss: 0.161779 Batch F1: 0.761904761904762
Epoch:  502       10 Batch loss: 0.155700 Batch F1: 0.8
Epoch:  502       11 Batch loss: 0.141764 Batch F1: 0.8
Epoch:  502       12 Batch loss: 0.188115 Batch F1: 0.6060606060606061
Train Avg Loss  502: 0.171506

Train Avg F1  502: 0.7178940544157935

Val Avg Loss  502: 0.180858

Val Avg F1  502:  0.6736949390538899

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 503
--------------------------------------------------------------
Epoch:  503        1 Batch loss: 0.149484 Batch F1: 0.7027027027027029
Epoch:  503        2 Batch loss: 0.161496 Batch F1: 0.7142857142857143
Epoch:  503        3 Batch loss: 0.178644 Batch F1: 0.72
Epoch:  503        4 Batch loss: 0.174452 Batch F1: 0.7916666666666667
Epoch:  503        5 Batch loss: 0.161002 Batch F1: 0.6875
Epoch:  503        6 Batch loss: 0.173509 Batch F1: 0.7499999999999999
Epoch:  503        7 Batch loss: 0.158573 Batch F1: 0.8235294117647057
Epoch:  503        8 Batch loss: 0.194893 Batch F1: 0.5365853658536586
Epoch:  503        9 Batch loss: 0.157970 Batch F1: 0.7272727272727272
Epoch:  503       10 Batch loss: 0.205972 Batch F1: 0.6382978723404255
Epoch:  503       11 Batch loss: 0.155484 Batch F1: 0.8235294117647058
Epoch:  503       12 Batch loss: 0.204484 Batch F1: 0.6486486486486486
Train Avg Loss  503: 0.172997

Train Avg F1  503: 0.7136682101083296

Val Avg Loss  503: 0.181829

Val Avg F1  503:  0.6658973145006444

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 504
--------------------------------------------------------------
Epoch:  504        1 Batch loss: 0.197767 Batch F1: 0.48484848484848486
Epoch:  504        2 Batch loss: 0.154742 Batch F1: 0.782608695652174
Epoch:  504        3 Batch loss: 0.141716 Batch F1: 0.8085106382978724
Epoch:  504        4 Batch loss: 0.158611 Batch F1: 0.7826086956521738
Epoch:  504        5 Batch loss: 0.188641 Batch F1: 0.7407407407407408
Epoch:  504        6 Batch loss: 0.162044 Batch F1: 0.8235294117647058
Epoch:  504        7 Batch loss: 0.182677 Batch F1: 0.6511627906976744
Epoch:  504        8 Batch loss: 0.160528 Batch F1: 0.7804878048780488
Epoch:  504        9 Batch loss: 0.158316 Batch F1: 0.7391304347826088
Epoch:  504       10 Batch loss: 0.208970 Batch F1: 0.5853658536585366
Epoch:  504       11 Batch loss: 0.181078 Batch F1: 0.7346938775510203
Epoch:  504       12 Batch loss: 0.162154 Batch F1: 0.7567567567567567
Train Avg Loss  504: 0.171437

Train Avg F1  504: 0.7225370154400664

Val Avg Loss  504: 0.182182

Val Avg F1  504:  0.6830967169476487

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 505
--------------------------------------------------------------
Epoch:  505        1 Batch loss: 0.161069 Batch F1: 0.7826086956521738
Epoch:  505        2 Batch loss: 0.156265 Batch F1: 0.7368421052631577
Epoch:  505        3 Batch loss: 0.193316 Batch F1: 0.6521739130434783
Epoch:  505        4 Batch loss: 0.202718 Batch F1: 0.64
Epoch:  505        5 Batch loss: 0.188893 Batch F1: 0.6666666666666666
Epoch:  505        6 Batch loss: 0.151563 Batch F1: 0.7692307692307692
Epoch:  505        7 Batch loss: 0.194700 Batch F1: 0.7142857142857143
Epoch:  505        8 Batch loss: 0.141294 Batch F1: 0.896551724137931
Epoch:  505        9 Batch loss: 0.178631 Batch F1: 0.717948717948718
Epoch:  505       10 Batch loss: 0.162605 Batch F1: 0.7659574468085106
Epoch:  505       11 Batch loss: 0.200168 Batch F1: 0.6666666666666666
Epoch:  505       12 Batch loss: 0.162925 Batch F1: 0.6875000000000001
Train Avg Loss  505: 0.174512

Train Avg F1  505: 0.7247027016419821

Val Avg Loss  505: 0.184374

Val Avg F1  505:  0.6808288610614193

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 506
--------------------------------------------------------------
Epoch:  506        1 Batch loss: 0.165323 Batch F1: 0.6842105263157895
Epoch:  506        2 Batch loss: 0.163779 Batch F1: 0.7755102040816326
Epoch:  506        3 Batch loss: 0.176753 Batch F1: 0.6818181818181819
Epoch:  506        4 Batch loss: 0.167776 Batch F1: 0.7391304347826088
Epoch:  506        5 Batch loss: 0.192951 Batch F1: 0.6363636363636365
Epoch:  506        6 Batch loss: 0.162321 Batch F1: 0.7027027027027027
Epoch:  506        7 Batch loss: 0.194072 Batch F1: 0.6382978723404256
Epoch:  506        8 Batch loss: 0.162747 Batch F1: 0.7727272727272727
Epoch:  506        9 Batch loss: 0.197510 Batch F1: 0.5909090909090909
Epoch:  506       10 Batch loss: 0.155457 Batch F1: 0.7317073170731708
Epoch:  506       11 Batch loss: 0.149524 Batch F1: 0.8400000000000001
Epoch:  506       12 Batch loss: 0.169771 Batch F1: 0.717948717948718
Train Avg Loss  506: 0.171499

Train Avg F1  506: 0.7092771630886023

Val Avg Loss  506: 0.182012

Val Avg F1  506:  0.734421768707483

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 507
--------------------------------------------------------------
Epoch:  507        1 Batch loss: 0.150554 Batch F1: 0.816326530612245
Epoch:  507        2 Batch loss: 0.158514 Batch F1: 0.8333333333333334
Epoch:  507        3 Batch loss: 0.168538 Batch F1: 0.8125
Epoch:  507        4 Batch loss: 0.172953 Batch F1: 0.736842105263158
Epoch:  507        5 Batch loss: 0.191850 Batch F1: 0.6938775510204082
Epoch:  507        6 Batch loss: 0.168384 Batch F1: 0.7999999999999999
Epoch:  507        7 Batch loss: 0.168437 Batch F1: 0.6829268292682927
Epoch:  507        8 Batch loss: 0.187749 Batch F1: 0.48275862068965514
Epoch:  507        9 Batch loss: 0.175015 Batch F1: 0.742857142857143
Epoch:  507       10 Batch loss: 0.169366 Batch F1: 0.7222222222222222
Epoch:  507       11 Batch loss: 0.186589 Batch F1: 0.75
Epoch:  507       12 Batch loss: 0.239722 Batch F1: 0.5
Train Avg Loss  507: 0.178139

Train Avg F1  507: 0.7144703612722049

Val Avg Loss  507: 0.188649

Val Avg F1  507:  0.6491564856116527

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 508
--------------------------------------------------------------
Epoch:  508        1 Batch loss: 0.155356 Batch F1: 0.7441860465116279
Epoch:  508        2 Batch loss: 0.153020 Batch F1: 0.717948717948718
Epoch:  508        3 Batch loss: 0.174294 Batch F1: 0.6000000000000001
Epoch:  508        4 Batch loss: 0.170910 Batch F1: 0.7843137254901961
Epoch:  508        5 Batch loss: 0.201459 Batch F1: 0.64
Epoch:  508        6 Batch loss: 0.199092 Batch F1: 0.6399999999999999
Epoch:  508        7 Batch loss: 0.170679 Batch F1: 0.7111111111111111
Epoch:  508        8 Batch loss: 0.176198 Batch F1: 0.7391304347826089
Epoch:  508        9 Batch loss: 0.184103 Batch F1: 0.6818181818181818
Epoch:  508       10 Batch loss: 0.164995 Batch F1: 0.8214285714285714
Epoch:  508       11 Batch loss: 0.169299 Batch F1: 0.6818181818181818
Epoch:  508       12 Batch loss: 0.176381 Batch F1: 0.717948717948718
Train Avg Loss  508: 0.174649

Train Avg F1  508: 0.7066419740714928

Val Avg Loss  508: 0.181785

Val Avg F1  508:  0.6814981806676159

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 509
--------------------------------------------------------------
Epoch:  509        1 Batch loss: 0.169006 Batch F1: 0.6666666666666667
Epoch:  509        2 Batch loss: 0.168772 Batch F1: 0.7346938775510203
Epoch:  509        3 Batch loss: 0.167463 Batch F1: 0.723404255319149
Epoch:  509        4 Batch loss: 0.172898 Batch F1: 0.7272727272727272
Epoch:  509        5 Batch loss: 0.174912 Batch F1: 0.6976744186046512
Epoch:  509        6 Batch loss: 0.214840 Batch F1: 0.5777777777777778
Epoch:  509        7 Batch loss: 0.162707 Batch F1: 0.7391304347826085
Epoch:  509        8 Batch loss: 0.175696 Batch F1: 0.606060606060606
Epoch:  509        9 Batch loss: 0.167938 Batch F1: 0.75
Epoch:  509       10 Batch loss: 0.176730 Batch F1: 0.6486486486486486
Epoch:  509       11 Batch loss: 0.178021 Batch F1: 0.7450980392156864
Epoch:  509       12 Batch loss: 0.127517 Batch F1: 0.9361702127659574
Train Avg Loss  509: 0.171375

Train Avg F1  509: 0.7127164720554582

Val Avg Loss  509: 0.188005

Val Avg F1  509:  0.708810173907284

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 510
--------------------------------------------------------------
Epoch:  510        1 Batch loss: 0.175829 Batch F1: 0.7391304347826088
Epoch:  510        2 Batch loss: 0.222263 Batch F1: 0.6666666666666665
Epoch:  510        3 Batch loss: 0.185916 Batch F1: 0.6363636363636365
Epoch:  510        4 Batch loss: 0.166009 Batch F1: 0.7272727272727272
Epoch:  510        5 Batch loss: 0.170533 Batch F1: 0.8085106382978724
Epoch:  510        6 Batch loss: 0.160841 Batch F1: 0.7
Epoch:  510        7 Batch loss: 0.153646 Batch F1: 0.7999999999999999
Epoch:  510        8 Batch loss: 0.168514 Batch F1: 0.7142857142857143
Epoch:  510        9 Batch loss: 0.197239 Batch F1: 0.6530612244897959
Epoch:  510       10 Batch loss: 0.178051 Batch F1: 0.693877551020408
Epoch:  510       11 Batch loss: 0.175562 Batch F1: 0.7142857142857143
Epoch:  510       12 Batch loss: 0.165441 Batch F1: 0.7500000000000001
Train Avg Loss  510: 0.176654

Train Avg F1  510: 0.7169545256220954

Val Avg Loss  510: 0.181917

Val Avg F1  510:  0.6887970833153558

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 511
--------------------------------------------------------------
Epoch:  511        1 Batch loss: 0.200109 Batch F1: 0.6363636363636364
Epoch:  511        2 Batch loss: 0.142980 Batch F1: 0.7428571428571428
Epoch:  511        3 Batch loss: 0.159853 Batch F1: 0.6842105263157895
Epoch:  511        4 Batch loss: 0.205952 Batch F1: 0.625
Epoch:  511        5 Batch loss: 0.168328 Batch F1: 0.7272727272727272
Epoch:  511        6 Batch loss: 0.156124 Batch F1: 0.75
Epoch:  511        7 Batch loss: 0.162825 Batch F1: 0.8064516129032258
Epoch:  511        8 Batch loss: 0.194351 Batch F1: 0.6666666666666666
Epoch:  511        9 Batch loss: 0.157822 Batch F1: 0.7727272727272727
Epoch:  511       10 Batch loss: 0.169077 Batch F1: 0.7317073170731707
Epoch:  511       11 Batch loss: 0.169172 Batch F1: 0.7142857142857143
Epoch:  511       12 Batch loss: 0.180790 Batch F1: 0.7272727272727272
Train Avg Loss  511: 0.172282

Train Avg F1  511: 0.7154012786448395

Val Avg Loss  511: 0.183833

Val Avg F1  511:  0.6819635462880804

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 512
--------------------------------------------------------------
Epoch:  512        1 Batch loss: 0.166872 Batch F1: 0.6976744186046512
Epoch:  512        2 Batch loss: 0.154878 Batch F1: 0.8363636363636363
Epoch:  512        3 Batch loss: 0.175699 Batch F1: 0.6818181818181818
Epoch:  512        4 Batch loss: 0.170812 Batch F1: 0.7555555555555556
Epoch:  512        5 Batch loss: 0.174884 Batch F1: 0.76
Epoch:  512        6 Batch loss: 0.170080 Batch F1: 0.6956521739130435
Epoch:  512        7 Batch loss: 0.167364 Batch F1: 0.6666666666666667
Epoch:  512        8 Batch loss: 0.162527 Batch F1: 0.8076923076923077
Epoch:  512        9 Batch loss: 0.176142 Batch F1: 0.606060606060606
Epoch:  512       10 Batch loss: 0.168045 Batch F1: 0.761904761904762
Epoch:  512       11 Batch loss: 0.216089 Batch F1: 0.5652173913043478
Epoch:  512       12 Batch loss: 0.157111 Batch F1: 0.7567567567567567
Train Avg Loss  512: 0.171709

Train Avg F1  512: 0.7159468713867095

Val Avg Loss  512: 0.184143

Val Avg F1  512:  0.6628358237978959

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 513
--------------------------------------------------------------
Epoch:  513        1 Batch loss: 0.171488 Batch F1: 0.7441860465116279
Epoch:  513        2 Batch loss: 0.156315 Batch F1: 0.7619047619047619
Epoch:  513        3 Batch loss: 0.175409 Batch F1: 0.7272727272727272
Epoch:  513        4 Batch loss: 0.175282 Batch F1: 0.7391304347826089
Epoch:  513        5 Batch loss: 0.173034 Batch F1: 0.7450980392156864
Epoch:  513        6 Batch loss: 0.145441 Batch F1: 0.8400000000000001
Epoch:  513        7 Batch loss: 0.187144 Batch F1: 0.7111111111111111
Epoch:  513        8 Batch loss: 0.167831 Batch F1: 0.65
Epoch:  513        9 Batch loss: 0.182814 Batch F1: 0.6808510638297872
Epoch:  513       10 Batch loss: 0.148846 Batch F1: 0.6875000000000001
Epoch:  513       11 Batch loss: 0.177869 Batch F1: 0.6511627906976744
Epoch:  513       12 Batch loss: 0.186103 Batch F1: 0.6842105263157895
Train Avg Loss  513: 0.170631

Train Avg F1  513: 0.7185356251368146

Val Avg Loss  513: 0.188954

Val Avg F1  513:  0.659182403747621

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 514
--------------------------------------------------------------
Epoch:  514        1 Batch loss: 0.198607 Batch F1: 0.7234042553191489
Epoch:  514        2 Batch loss: 0.156983 Batch F1: 0.7317073170731706
Epoch:  514        3 Batch loss: 0.200805 Batch F1: 0.6792452830188679
Epoch:  514        4 Batch loss: 0.151944 Batch F1: 0.782608695652174
Epoch:  514        5 Batch loss: 0.174714 Batch F1: 0.5714285714285714
Epoch:  514        6 Batch loss: 0.163426 Batch F1: 0.7499999999999999
Epoch:  514        7 Batch loss: 0.161782 Batch F1: 0.782608695652174
Epoch:  514        8 Batch loss: 0.190510 Batch F1: 0.6938775510204083
Epoch:  514        9 Batch loss: 0.168844 Batch F1: 0.7368421052631579
Epoch:  514       10 Batch loss: 0.190620 Batch F1: 0.6666666666666666
Epoch:  514       11 Batch loss: 0.177305 Batch F1: 0.6976744186046512
Epoch:  514       12 Batch loss: 0.153516 Batch F1: 0.8095238095238095
Train Avg Loss  514: 0.174088

Train Avg F1  514: 0.7187989474352334

Val Avg Loss  514: 0.181897

Val Avg F1  514:  0.682015306122449

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 515
--------------------------------------------------------------
Epoch:  515        1 Batch loss: 0.191436 Batch F1: 0.6382978723404255
Epoch:  515        2 Batch loss: 0.162228 Batch F1: 0.7599999999999999
Epoch:  515        3 Batch loss: 0.193085 Batch F1: 0.631578947368421
Epoch:  515        4 Batch loss: 0.173452 Batch F1: 0.7346938775510204
Epoch:  515        5 Batch loss: 0.157698 Batch F1: 0.76
Epoch:  515        6 Batch loss: 0.155889 Batch F1: 0.7659574468085107
Epoch:  515        7 Batch loss: 0.179580 Batch F1: 0.7058823529411765
Epoch:  515        8 Batch loss: 0.183593 Batch F1: 0.6818181818181818
Epoch:  515        9 Batch loss: 0.150611 Batch F1: 0.8085106382978724
Epoch:  515       10 Batch loss: 0.178052 Batch F1: 0.6666666666666665
Epoch:  515       11 Batch loss: 0.155962 Batch F1: 0.6666666666666666
Epoch:  515       12 Batch loss: 0.158331 Batch F1: 0.7647058823529413
Train Avg Loss  515: 0.169993

Train Avg F1  515: 0.7153982110676568

Val Avg Loss  515: 0.185965

Val Avg F1  515:  0.6662173202614379

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 516
--------------------------------------------------------------
Epoch:  516        1 Batch loss: 0.195994 Batch F1: 0.7058823529411765
Epoch:  516        2 Batch loss: 0.185945 Batch F1: 0.5555555555555556
Epoch:  516        3 Batch loss: 0.176472 Batch F1: 0.6956521739130435
Epoch:  516        4 Batch loss: 0.154405 Batch F1: 0.8461538461538461
Epoch:  516        5 Batch loss: 0.143859 Batch F1: 0.761904761904762
Epoch:  516        6 Batch loss: 0.172953 Batch F1: 0.6666666666666666
Epoch:  516        7 Batch loss: 0.149655 Batch F1: 0.8
Epoch:  516        8 Batch loss: 0.184687 Batch F1: 0.6956521739130435
Epoch:  516        9 Batch loss: 0.179106 Batch F1: 0.7058823529411765
Epoch:  516       10 Batch loss: 0.172342 Batch F1: 0.7346938775510204
Epoch:  516       11 Batch loss: 0.153875 Batch F1: 0.6060606060606061
Epoch:  516       12 Batch loss: 0.174487 Batch F1: 0.7317073170731708
Train Avg Loss  516: 0.170315

Train Avg F1  516: 0.7088176403895057

Val Avg Loss  516: 0.180778

Val Avg F1  516:  0.695062656641604

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 517
--------------------------------------------------------------
Epoch:  517        1 Batch loss: 0.169306 Batch F1: 0.7391304347826089
Epoch:  517        2 Batch loss: 0.151491 Batch F1: 0.7500000000000001
Epoch:  517        3 Batch loss: 0.196843 Batch F1: 0.6530612244897959
Epoch:  517        4 Batch loss: 0.159654 Batch F1: 0.7843137254901961
Epoch:  517        5 Batch loss: 0.161123 Batch F1: 0.7500000000000001
Epoch:  517        6 Batch loss: 0.144823 Batch F1: 0.8
Epoch:  517        7 Batch loss: 0.171769 Batch F1: 0.65
Epoch:  517        8 Batch loss: 0.160220 Batch F1: 0.7368421052631577
Epoch:  517        9 Batch loss: 0.197936 Batch F1: 0.6382978723404256
Epoch:  517       10 Batch loss: 0.163900 Batch F1: 0.7636363636363638
Epoch:  517       11 Batch loss: 0.162599 Batch F1: 0.6666666666666666
Epoch:  517       12 Batch loss: 0.182796 Batch F1: 0.7
Train Avg Loss  517: 0.168538

Train Avg F1  517: 0.7193290327224345

Val Avg Loss  517: 0.180778

Val Avg F1  517:  0.7019660213999837

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 518
--------------------------------------------------------------
Epoch:  518        1 Batch loss: 0.167218 Batch F1: 0.7777777777777778
Epoch:  518        2 Batch loss: 0.158394 Batch F1: 0.6875
Epoch:  518        3 Batch loss: 0.152731 Batch F1: 0.7
Epoch:  518        4 Batch loss: 0.164865 Batch F1: 0.7857142857142856
Epoch:  518        5 Batch loss: 0.156012 Batch F1: 0.8000000000000002
Epoch:  518        6 Batch loss: 0.169885 Batch F1: 0.7441860465116279
Epoch:  518        7 Batch loss: 0.192675 Batch F1: 0.6808510638297872
Epoch:  518        8 Batch loss: 0.166892 Batch F1: 0.6976744186046512
Epoch:  518        9 Batch loss: 0.165421 Batch F1: 0.717948717948718
Epoch:  518       10 Batch loss: 0.192283 Batch F1: 0.7083333333333334
Epoch:  518       11 Batch loss: 0.177928 Batch F1: 0.6976744186046512
Epoch:  518       12 Batch loss: 0.157534 Batch F1: 0.8095238095238095
Train Avg Loss  518: 0.168486

Train Avg F1  518: 0.7339319893207202

Val Avg Loss  518: 0.180920

Val Avg F1  518:  0.6934918086062205

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 519
--------------------------------------------------------------
Epoch:  519        1 Batch loss: 0.146388 Batch F1: 0.8846153846153846
Epoch:  519        2 Batch loss: 0.147425 Batch F1: 0.8235294117647058
Epoch:  519        3 Batch loss: 0.227072 Batch F1: 0.5531914893617023
Epoch:  519        4 Batch loss: 0.154669 Batch F1: 0.6829268292682927
Epoch:  519        5 Batch loss: 0.207510 Batch F1: 0.4571428571428572
Epoch:  519        6 Batch loss: 0.167553 Batch F1: 0.6976744186046512
Epoch:  519        7 Batch loss: 0.158248 Batch F1: 0.7317073170731707
Epoch:  519        8 Batch loss: 0.153207 Batch F1: 0.8148148148148148
Epoch:  519        9 Batch loss: 0.136346 Batch F1: 0.8292682926829269
Epoch:  519       10 Batch loss: 0.161066 Batch F1: 0.7
Epoch:  519       11 Batch loss: 0.158118 Batch F1: 0.717948717948718
Epoch:  519       12 Batch loss: 0.204481 Batch F1: 0.6666666666666666
Train Avg Loss  519: 0.168507

Train Avg F1  519: 0.7132905166619908

Val Avg Loss  519: 0.181960

Val Avg F1  519:  0.7074876343169026

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 520
--------------------------------------------------------------
Epoch:  520        1 Batch loss: 0.157955 Batch F1: 0.7317073170731708
Epoch:  520        2 Batch loss: 0.189042 Batch F1: 0.7307692307692308
Epoch:  520        3 Batch loss: 0.147159 Batch F1: 0.8333333333333333
Epoch:  520        4 Batch loss: 0.146782 Batch F1: 0.7906976744186046
Epoch:  520        5 Batch loss: 0.164036 Batch F1: 0.7450980392156864
Epoch:  520        6 Batch loss: 0.175564 Batch F1: 0.6341463414634148
Epoch:  520        7 Batch loss: 0.229366 Batch F1: 0.48780487804878053
Epoch:  520        8 Batch loss: 0.166625 Batch F1: 0.8135593220338982
Epoch:  520        9 Batch loss: 0.159650 Batch F1: 0.7027027027027027
Epoch:  520       10 Batch loss: 0.170879 Batch F1: 0.65
Epoch:  520       11 Batch loss: 0.150717 Batch F1: 0.7
Epoch:  520       12 Batch loss: 0.173997 Batch F1: 0.7027027027027027
Train Avg Loss  520: 0.169314

Train Avg F1  520: 0.7102101284801271

Val Avg Loss  520: 0.180335

Val Avg F1  520:  0.6871344222491997

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 521
--------------------------------------------------------------
Epoch:  521        1 Batch loss: 0.175374 Batch F1: 0.6842105263157895
Epoch:  521        2 Batch loss: 0.142226 Batch F1: 0.7906976744186046
Epoch:  521        3 Batch loss: 0.171774 Batch F1: 0.7083333333333334
Epoch:  521        4 Batch loss: 0.173661 Batch F1: 0.7407407407407408
Epoch:  521        5 Batch loss: 0.191104 Batch F1: 0.6521739130434783
Epoch:  521        6 Batch loss: 0.142680 Batch F1: 0.7428571428571428
Epoch:  521        7 Batch loss: 0.158508 Batch F1: 0.7924528301886793
Epoch:  521        8 Batch loss: 0.174186 Batch F1: 0.7450980392156864
Epoch:  521        9 Batch loss: 0.168980 Batch F1: 0.6285714285714286
Epoch:  521       10 Batch loss: 0.172600 Batch F1: 0.6956521739130435
Epoch:  521       11 Batch loss: 0.174380 Batch F1: 0.76
Epoch:  521       12 Batch loss: 0.182827 Batch F1: 0.5806451612903225
Train Avg Loss  521: 0.169025

Train Avg F1  521: 0.710119413657354

Val Avg Loss  521: 0.183036

Val Avg F1  521:  0.6871678775298391

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 522
--------------------------------------------------------------
Epoch:  522        1 Batch loss: 0.170682 Batch F1: 0.6976744186046512
Epoch:  522        2 Batch loss: 0.165731 Batch F1: 0.7111111111111111
Epoch:  522        3 Batch loss: 0.176132 Batch F1: 0.6
Epoch:  522        4 Batch loss: 0.196726 Batch F1: 0.5641025641025642
Epoch:  522        5 Batch loss: 0.156890 Batch F1: 0.7916666666666667
Epoch:  522        6 Batch loss: 0.165651 Batch F1: 0.7
Epoch:  522        7 Batch loss: 0.199871 Batch F1: 0.6222222222222223
Epoch:  522        8 Batch loss: 0.143554 Batch F1: 0.8852459016393444
Epoch:  522        9 Batch loss: 0.170938 Batch F1: 0.7555555555555555
Epoch:  522       10 Batch loss: 0.146726 Batch F1: 0.7906976744186046
Epoch:  522       11 Batch loss: 0.193596 Batch F1: 0.7234042553191489
Epoch:  522       12 Batch loss: 0.181102 Batch F1: 0.7368421052631577
Train Avg Loss  522: 0.172300

Train Avg F1  522: 0.7148768729085856

Val Avg Loss  522: 0.182522

Val Avg F1  522:  0.724580588493632

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 523
--------------------------------------------------------------
Epoch:  523        1 Batch loss: 0.165473 Batch F1: 0.76
Epoch:  523        2 Batch loss: 0.165847 Batch F1: 0.7272727272727272
Epoch:  523        3 Batch loss: 0.152194 Batch F1: 0.8135593220338982
Epoch:  523        4 Batch loss: 0.171281 Batch F1: 0.7368421052631577
Epoch:  523        5 Batch loss: 0.175989 Batch F1: 0.7916666666666666
Epoch:  523        6 Batch loss: 0.179299 Batch F1: 0.6111111111111113
Epoch:  523        7 Batch loss: 0.145659 Batch F1: 0.7916666666666667
Epoch:  523        8 Batch loss: 0.182769 Batch F1: 0.6341463414634148
Epoch:  523        9 Batch loss: 0.185652 Batch F1: 0.7083333333333333
Epoch:  523       10 Batch loss: 0.179079 Batch F1: 0.7555555555555555
Epoch:  523       11 Batch loss: 0.174990 Batch F1: 0.6829268292682927
Epoch:  523       12 Batch loss: 0.188305 Batch F1: 0.6315789473684211
Train Avg Loss  523: 0.172211

Train Avg F1  523: 0.7203883005002706

Val Avg Loss  523: 0.186738

Val Avg F1  523:  0.6607958604862629

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 524
--------------------------------------------------------------
Epoch:  524        1 Batch loss: 0.167669 Batch F1: 0.7727272727272727
Epoch:  524        2 Batch loss: 0.173184 Batch F1: 0.7272727272727272
Epoch:  524        3 Batch loss: 0.172706 Batch F1: 0.7346938775510203
Epoch:  524        4 Batch loss: 0.196103 Batch F1: 0.5853658536585366
Epoch:  524        5 Batch loss: 0.131100 Batch F1: 0.8800000000000001
Epoch:  524        6 Batch loss: 0.162807 Batch F1: 0.7272727272727273
Epoch:  524        7 Batch loss: 0.214589 Batch F1: 0.5925925925925926
Epoch:  524        8 Batch loss: 0.177217 Batch F1: 0.75
Epoch:  524        9 Batch loss: 0.188964 Batch F1: 0.7272727272727272
Epoch:  524       10 Batch loss: 0.158239 Batch F1: 0.717948717948718
Epoch:  524       11 Batch loss: 0.156931 Batch F1: 0.7
Epoch:  524       12 Batch loss: 0.171766 Batch F1: 0.7692307692307692
Train Avg Loss  524: 0.172606

Train Avg F1  524: 0.7236981054605911

Val Avg Loss  524: 0.182447

Val Avg F1  524:  0.6646883817936449

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 525
--------------------------------------------------------------
Epoch:  525        1 Batch loss: 0.177355 Batch F1: 0.631578947368421
Epoch:  525        2 Batch loss: 0.172550 Batch F1: 0.7692307692307692
Epoch:  525        3 Batch loss: 0.173427 Batch F1: 0.7346938775510204
Epoch:  525        4 Batch loss: 0.158010 Batch F1: 0.7924528301886793
Epoch:  525        5 Batch loss: 0.183661 Batch F1: 0.7142857142857143
Epoch:  525        6 Batch loss: 0.160769 Batch F1: 0.6666666666666666
Epoch:  525        7 Batch loss: 0.159762 Batch F1: 0.7555555555555555
Epoch:  525        8 Batch loss: 0.171657 Batch F1: 0.65
Epoch:  525        9 Batch loss: 0.173826 Batch F1: 0.6666666666666666
Epoch:  525       10 Batch loss: 0.157070 Batch F1: 0.723404255319149
Epoch:  525       11 Batch loss: 0.158799 Batch F1: 0.8163265306122449
Epoch:  525       12 Batch loss: 0.177321 Batch F1: 0.6666666666666666
Train Avg Loss  525: 0.168684

Train Avg F1  525: 0.7156273733426296

Val Avg Loss  525: 0.180369

Val Avg F1  525:  0.6894445979552363

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 526
--------------------------------------------------------------
Epoch:  526        1 Batch loss: 0.163785 Batch F1: 0.7916666666666666
Epoch:  526        2 Batch loss: 0.159350 Batch F1: 0.6666666666666667
Epoch:  526        3 Batch loss: 0.194380 Batch F1: 0.6250000000000001
Epoch:  526        4 Batch loss: 0.148431 Batch F1: 0.7368421052631577
Epoch:  526        5 Batch loss: 0.188281 Batch F1: 0.72
Epoch:  526        6 Batch loss: 0.171639 Batch F1: 0.631578947368421
Epoch:  526        7 Batch loss: 0.171313 Batch F1: 0.6486486486486486
Epoch:  526        8 Batch loss: 0.150504 Batch F1: 0.7142857142857143
Epoch:  526        9 Batch loss: 0.182750 Batch F1: 0.6829268292682926
Epoch:  526       10 Batch loss: 0.177949 Batch F1: 0.7142857142857143
Epoch:  526       11 Batch loss: 0.224884 Batch F1: 0.6909090909090909
Epoch:  526       12 Batch loss: 0.154302 Batch F1: 0.7999999999999999
Train Avg Loss  526: 0.173964

Train Avg F1  526: 0.7019008652801978

Val Avg Loss  526: 0.190763

Val Avg F1  526:  0.7638849759058066

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 527
--------------------------------------------------------------
Epoch:  527        1 Batch loss: 0.159946 Batch F1: 0.8363636363636363
Epoch:  527        2 Batch loss: 0.186649 Batch F1: 0.7599999999999999
Epoch:  527        3 Batch loss: 0.192894 Batch F1: 0.7272727272727272
Epoch:  527        4 Batch loss: 0.159294 Batch F1: 0.5806451612903226
Epoch:  527        5 Batch loss: 0.165735 Batch F1: 0.7692307692307693
Epoch:  527        6 Batch loss: 0.162720 Batch F1: 0.7272727272727272
Epoch:  527        7 Batch loss: 0.144882 Batch F1: 0.888888888888889
Epoch:  527        8 Batch loss: 0.185756 Batch F1: 0.7547169811320754
Epoch:  527        9 Batch loss: 0.180646 Batch F1: 0.6808510638297872
Epoch:  527       10 Batch loss: 0.148063 Batch F1: 0.76
Epoch:  527       11 Batch loss: 0.210050 Batch F1: 0.6415094339622641
Epoch:  527       12 Batch loss: 0.223460 Batch F1: 0.4848484848484848
Train Avg Loss  527: 0.176675

Train Avg F1  527: 0.7176333228409736

Val Avg Loss  527: 0.183701

Val Avg F1  527:  0.6931142452379019

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 528
--------------------------------------------------------------
Epoch:  528        1 Batch loss: 0.164002 Batch F1: 0.8148148148148148
Epoch:  528        2 Batch loss: 0.185810 Batch F1: 0.6808510638297872
Epoch:  528        3 Batch loss: 0.161627 Batch F1: 0.7142857142857143
Epoch:  528        4 Batch loss: 0.169662 Batch F1: 0.7999999999999999
Epoch:  528        5 Batch loss: 0.156676 Batch F1: 0.7647058823529412
Epoch:  528        6 Batch loss: 0.194017 Batch F1: 0.6909090909090909
Epoch:  528        7 Batch loss: 0.197973 Batch F1: 0.6060606060606061
Epoch:  528        8 Batch loss: 0.188895 Batch F1: 0.6
Epoch:  528        9 Batch loss: 0.166066 Batch F1: 0.7659574468085107
Epoch:  528       10 Batch loss: 0.175341 Batch F1: 0.6976744186046512
Epoch:  528       11 Batch loss: 0.170867 Batch F1: 0.6666666666666667
Epoch:  528       12 Batch loss: 0.179986 Batch F1: 0.7999999999999999
Train Avg Loss  528: 0.175910

Train Avg F1  528: 0.716827142027732

Val Avg Loss  528: 0.182191

Val Avg F1  528:  0.7049114331723026

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 529
--------------------------------------------------------------
Epoch:  529        1 Batch loss: 0.180752 Batch F1: 0.6956521739130435
Epoch:  529        2 Batch loss: 0.208580 Batch F1: 0.5909090909090908
Epoch:  529        3 Batch loss: 0.164833 Batch F1: 0.7659574468085107
Epoch:  529        4 Batch loss: 0.166245 Batch F1: 0.7924528301886792
Epoch:  529        5 Batch loss: 0.167782 Batch F1: 0.7142857142857143
Epoch:  529        6 Batch loss: 0.153098 Batch F1: 0.7317073170731706
Epoch:  529        7 Batch loss: 0.168111 Batch F1: 0.6486486486486486
Epoch:  529        8 Batch loss: 0.163855 Batch F1: 0.8
Epoch:  529        9 Batch loss: 0.176972 Batch F1: 0.6
Epoch:  529       10 Batch loss: 0.185113 Batch F1: 0.7111111111111111
Epoch:  529       11 Batch loss: 0.146577 Batch F1: 0.7499999999999999
Epoch:  529       12 Batch loss: 0.170764 Batch F1: 0.7000000000000001
Train Avg Loss  529: 0.171057

Train Avg F1  529: 0.7083936944114974

Val Avg Loss  529: 0.183427

Val Avg F1  529:  0.6740130014269858

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 530
--------------------------------------------------------------
Epoch:  530        1 Batch loss: 0.180285 Batch F1: 0.72
Epoch:  530        2 Batch loss: 0.157149 Batch F1: 0.7317073170731706
Epoch:  530        3 Batch loss: 0.166810 Batch F1: 0.6486486486486486
Epoch:  530        4 Batch loss: 0.173129 Batch F1: 0.7272727272727272
Epoch:  530        5 Batch loss: 0.158434 Batch F1: 0.6486486486486486
Epoch:  530        6 Batch loss: 0.169543 Batch F1: 0.7111111111111111
Epoch:  530        7 Batch loss: 0.168157 Batch F1: 0.7111111111111111
Epoch:  530        8 Batch loss: 0.180338 Batch F1: 0.68
Epoch:  530        9 Batch loss: 0.152383 Batch F1: 0.8363636363636364
Epoch:  530       10 Batch loss: 0.170047 Batch F1: 0.7142857142857143
Epoch:  530       11 Batch loss: 0.179977 Batch F1: 0.6976744186046512
Epoch:  530       12 Batch loss: 0.182445 Batch F1: 0.7272727272727273
Train Avg Loss  530: 0.169891

Train Avg F1  530: 0.7128413383660122

Val Avg Loss  530: 0.182925

Val Avg F1  530:  0.6686913930477053

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 531
--------------------------------------------------------------
Epoch:  531        1 Batch loss: 0.161175 Batch F1: 0.717948717948718
Epoch:  531        2 Batch loss: 0.159761 Batch F1: 0.717948717948718
Epoch:  531        3 Batch loss: 0.178898 Batch F1: 0.5405405405405405
Epoch:  531        4 Batch loss: 0.183260 Batch F1: 0.6511627906976744
Epoch:  531        5 Batch loss: 0.147176 Batch F1: 0.7894736842105262
Epoch:  531        6 Batch loss: 0.171047 Batch F1: 0.7547169811320754
Epoch:  531        7 Batch loss: 0.176598 Batch F1: 0.76
Epoch:  531        8 Batch loss: 0.188413 Batch F1: 0.6382978723404256
Epoch:  531        9 Batch loss: 0.207932 Batch F1: 0.5789473684210527
Epoch:  531       10 Batch loss: 0.165285 Batch F1: 0.7547169811320754
Epoch:  531       11 Batch loss: 0.117242 Batch F1: 0.9333333333333332
Epoch:  531       12 Batch loss: 0.175369 Batch F1: 0.7391304347826088
Train Avg Loss  531: 0.169346

Train Avg F1  531: 0.7146847852073123

Val Avg Loss  531: 0.181385

Val Avg F1  531:  0.6940819209039548

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 532
--------------------------------------------------------------
Epoch:  532        1 Batch loss: 0.164789 Batch F1: 0.7391304347826089
Epoch:  532        2 Batch loss: 0.164841 Batch F1: 0.76
Epoch:  532        3 Batch loss: 0.189828 Batch F1: 0.7796610169491526
Epoch:  532        4 Batch loss: 0.155711 Batch F1: 0.7692307692307693
Epoch:  532        5 Batch loss: 0.184469 Batch F1: 0.6808510638297872
Epoch:  532        6 Batch loss: 0.192384 Batch F1: 0.6190476190476191
Epoch:  532        7 Batch loss: 0.155828 Batch F1: 0.7000000000000001
Epoch:  532        8 Batch loss: 0.151971 Batch F1: 0.7999999999999999
Epoch:  532        9 Batch loss: 0.154944 Batch F1: 0.7755102040816326
Epoch:  532       10 Batch loss: 0.160814 Batch F1: 0.7441860465116279
Epoch:  532       11 Batch loss: 0.194730 Batch F1: 0.45161290322580644
Epoch:  532       12 Batch loss: 0.162325 Batch F1: 0.6428571428571429
Train Avg Loss  532: 0.169386

Train Avg F1  532: 0.7051739333763454

Val Avg Loss  532: 0.185792

Val Avg F1  532:  0.6318370865409193

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 533
--------------------------------------------------------------
Epoch:  533        1 Batch loss: 0.181083 Batch F1: 0.6153846153846153
Epoch:  533        2 Batch loss: 0.154257 Batch F1: 0.8085106382978724
Epoch:  533        3 Batch loss: 0.179866 Batch F1: 0.7083333333333333
Epoch:  533        4 Batch loss: 0.172895 Batch F1: 0.7547169811320756
Epoch:  533        5 Batch loss: 0.179747 Batch F1: 0.7407407407407408
Epoch:  533        6 Batch loss: 0.189897 Batch F1: 0.6046511627906977
Epoch:  533        7 Batch loss: 0.162812 Batch F1: 0.847457627118644
Epoch:  533        8 Batch loss: 0.185628 Batch F1: 0.3703703703703704
Epoch:  533        9 Batch loss: 0.181978 Batch F1: 0.711111111111111
Epoch:  533       10 Batch loss: 0.164628 Batch F1: 0.761904761904762
Epoch:  533       11 Batch loss: 0.164529 Batch F1: 0.7727272727272727
Epoch:  533       12 Batch loss: 0.169649 Batch F1: 0.6470588235294117
Train Avg Loss  533: 0.173914

Train Avg F1  533: 0.6952472865367424

Val Avg Loss  533: 0.192152

Val Avg F1  533:  0.627332108644401

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 534
--------------------------------------------------------------
Epoch:  534        1 Batch loss: 0.189964 Batch F1: 0.6111111111111112
Epoch:  534        2 Batch loss: 0.202716 Batch F1: 0.6190476190476191
Epoch:  534        3 Batch loss: 0.176126 Batch F1: 0.7346938775510204
Epoch:  534        4 Batch loss: 0.169239 Batch F1: 0.65
Epoch:  534        5 Batch loss: 0.263342 Batch F1: 0.43478260869565216
Epoch:  534        6 Batch loss: 0.150140 Batch F1: 0.7999999999999999
Epoch:  534        7 Batch loss: 0.172277 Batch F1: 0.6486486486486486
Epoch:  534        8 Batch loss: 0.209271 Batch F1: 0.5
Epoch:  534        9 Batch loss: 0.186713 Batch F1: 0.7906976744186047
Epoch:  534       10 Batch loss: 0.153331 Batch F1: 0.7027027027027026
Epoch:  534       11 Batch loss: 0.164576 Batch F1: 0.7457627118644068
Epoch:  534       12 Batch loss: 0.210214 Batch F1: 0.7547169811320755
Train Avg Loss  534: 0.187326

Train Avg F1  534: 0.66601366126432

Val Avg Loss  534: 0.204558

Val Avg F1  534:  0.7700404170129184

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 535
--------------------------------------------------------------
Epoch:  535        1 Batch loss: 0.206743 Batch F1: 0.75
Epoch:  535        2 Batch loss: 0.154222 Batch F1: 0.8627450980392156
Epoch:  535        3 Batch loss: 0.202654 Batch F1: 0.47058823529411764
Epoch:  535        4 Batch loss: 0.226681 Batch F1: 0.25
Epoch:  535        5 Batch loss: 0.189165 Batch F1: 0.5945945945945945
Epoch:  535        6 Batch loss: 0.191168 Batch F1: 0.7083333333333334
Epoch:  535        7 Batch loss: 0.150149 Batch F1: 0.9019607843137255
Epoch:  535        8 Batch loss: 0.156258 Batch F1: 0.8571428571428571
Epoch:  535        9 Batch loss: 0.195704 Batch F1: 0.7111111111111111
Epoch:  535       10 Batch loss: 0.205966 Batch F1: 0.6666666666666667
Epoch:  535       11 Batch loss: 0.176530 Batch F1: 0.5925925925925927
Epoch:  535       12 Batch loss: 0.191115 Batch F1: 0.6666666666666667
Train Avg Loss  535: 0.187196

Train Avg F1  535: 0.6693668283129067

Val Avg Loss  535: 0.183544

Val Avg F1  535:  0.6763876004150603

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 536
--------------------------------------------------------------
Epoch:  536        1 Batch loss: 0.152693 Batch F1: 0.7317073170731708
Epoch:  536        2 Batch loss: 0.157471 Batch F1: 0.8363636363636364
Epoch:  536        3 Batch loss: 0.187849 Batch F1: 0.7857142857142856
Epoch:  536        4 Batch loss: 0.203370 Batch F1: 0.6086956521739131
Epoch:  536        5 Batch loss: 0.152655 Batch F1: 0.7499999999999999
Epoch:  536        6 Batch loss: 0.197463 Batch F1: 0.6521739130434783
Epoch:  536        7 Batch loss: 0.172776 Batch F1: 0.6976744186046512
Epoch:  536        8 Batch loss: 0.194780 Batch F1: 0.5945945945945946
Epoch:  536        9 Batch loss: 0.173191 Batch F1: 0.6842105263157895
Epoch:  536       10 Batch loss: 0.152032 Batch F1: 0.8095238095238095
Epoch:  536       11 Batch loss: 0.175498 Batch F1: 0.76
Epoch:  536       12 Batch loss: 0.215243 Batch F1: 0.6
Train Avg Loss  536: 0.177918

Train Avg F1  536: 0.7092215127839441

Val Avg Loss  536: 0.186707

Val Avg F1  536:  0.6676269577598481

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 537
--------------------------------------------------------------
Epoch:  537        1 Batch loss: 0.168079 Batch F1: 0.7916666666666666
Epoch:  537        2 Batch loss: 0.162252 Batch F1: 0.717948717948718
Epoch:  537        3 Batch loss: 0.197143 Batch F1: 0.6190476190476191
Epoch:  537        4 Batch loss: 0.185885 Batch F1: 0.6666666666666666
Epoch:  537        5 Batch loss: 0.185745 Batch F1: 0.7083333333333334
Epoch:  537        6 Batch loss: 0.177027 Batch F1: 0.7500000000000001
Epoch:  537        7 Batch loss: 0.166201 Batch F1: 0.7391304347826089
Epoch:  537        8 Batch loss: 0.174052 Batch F1: 0.7346938775510203
Epoch:  537        9 Batch loss: 0.165755 Batch F1: 0.5882352941176471
Epoch:  537       10 Batch loss: 0.164642 Batch F1: 0.7999999999999999
Epoch:  537       11 Batch loss: 0.167907 Batch F1: 0.6818181818181819
Epoch:  537       12 Batch loss: 0.185683 Batch F1: 0.7027027027027027
Train Avg Loss  537: 0.175031

Train Avg F1  537: 0.7083536245529304

Val Avg Loss  537: 0.184003

Val Avg F1  537:  0.6707796317304259

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 538
--------------------------------------------------------------
Epoch:  538        1 Batch loss: 0.168307 Batch F1: 0.6842105263157895
Epoch:  538        2 Batch loss: 0.178376 Batch F1: 0.7692307692307692
Epoch:  538        3 Batch loss: 0.164809 Batch F1: 0.7500000000000001
Epoch:  538        4 Batch loss: 0.167681 Batch F1: 0.7391304347826085
Epoch:  538        5 Batch loss: 0.149888 Batch F1: 0.75
Epoch:  538        6 Batch loss: 0.179286 Batch F1: 0.5625000000000001
Epoch:  538        7 Batch loss: 0.187583 Batch F1: 0.6923076923076923
Epoch:  538        8 Batch loss: 0.162656 Batch F1: 0.7999999999999999
Epoch:  538        9 Batch loss: 0.185251 Batch F1: 0.7450980392156864
Epoch:  538       10 Batch loss: 0.190860 Batch F1: 0.7450980392156864
Epoch:  538       11 Batch loss: 0.177778 Batch F1: 0.6666666666666666
Epoch:  538       12 Batch loss: 0.151833 Batch F1: 0.5454545454545454
Train Avg Loss  538: 0.172026

Train Avg F1  538: 0.704141392765787

Val Avg Loss  538: 0.183081

Val Avg F1  538:  0.6793061045234958

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 539
--------------------------------------------------------------
Epoch:  539        1 Batch loss: 0.167151 Batch F1: 0.611111111111111
Epoch:  539        2 Batch loss: 0.190045 Batch F1: 0.6
Epoch:  539        3 Batch loss: 0.152167 Batch F1: 0.7692307692307692
Epoch:  539        4 Batch loss: 0.152583 Batch F1: 0.8
Epoch:  539        5 Batch loss: 0.176852 Batch F1: 0.6818181818181819
Epoch:  539        6 Batch loss: 0.177881 Batch F1: 0.5454545454545455
Epoch:  539        7 Batch loss: 0.167871 Batch F1: 0.8333333333333334
Epoch:  539        8 Batch loss: 0.201479 Batch F1: 0.6792452830188679
Epoch:  539        9 Batch loss: 0.174362 Batch F1: 0.7142857142857143
Epoch:  539       10 Batch loss: 0.180647 Batch F1: 0.6808510638297872
Epoch:  539       11 Batch loss: 0.174510 Batch F1: 0.7391304347826085
Epoch:  539       12 Batch loss: 0.168379 Batch F1: 0.7692307692307692
Train Avg Loss  539: 0.173660

Train Avg F1  539: 0.7019742671746406

Val Avg Loss  539: 0.185770

Val Avg F1  539:  0.7072583788587181

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 540
--------------------------------------------------------------
Epoch:  540        1 Batch loss: 0.213614 Batch F1: 0.6538461538461539
Epoch:  540        2 Batch loss: 0.169267 Batch F1: 0.7804878048780488
Epoch:  540        3 Batch loss: 0.205384 Batch F1: 0.5714285714285715
Epoch:  540        4 Batch loss: 0.183671 Batch F1: 0.6486486486486486
Epoch:  540        5 Batch loss: 0.159219 Batch F1: 0.7027027027027027
Epoch:  540        6 Batch loss: 0.176077 Batch F1: 0.7499999999999999
Epoch:  540        7 Batch loss: 0.158670 Batch F1: 0.7619047619047619
Epoch:  540        8 Batch loss: 0.183555 Batch F1: 0.7058823529411765
Epoch:  540        9 Batch loss: 0.152218 Batch F1: 0.8181818181818182
Epoch:  540       10 Batch loss: 0.166596 Batch F1: 0.7027027027027026
Epoch:  540       11 Batch loss: 0.186792 Batch F1: 0.7719298245614035
Epoch:  540       12 Batch loss: 0.174752 Batch F1: 0.717948717948718
Train Avg Loss  540: 0.177484

Train Avg F1  540: 0.7154720049787255

Val Avg Loss  540: 0.189062

Val Avg F1  540:  0.6929392446633825

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 541
--------------------------------------------------------------
Epoch:  541        1 Batch loss: 0.206131 Batch F1: 0.6538461538461539
Epoch:  541        2 Batch loss: 0.171530 Batch F1: 0.7142857142857142
Epoch:  541        3 Batch loss: 0.185295 Batch F1: 0.761904761904762
Epoch:  541        4 Batch loss: 0.178254 Batch F1: 0.7346938775510204
Epoch:  541        5 Batch loss: 0.167584 Batch F1: 0.6976744186046512
Epoch:  541        6 Batch loss: 0.155479 Batch F1: 0.830188679245283
Epoch:  541        7 Batch loss: 0.166452 Batch F1: 0.6857142857142857
Epoch:  541        8 Batch loss: 0.214339 Batch F1: 0.6896551724137931
Epoch:  541        9 Batch loss: 0.157219 Batch F1: 0.7804878048780488
Epoch:  541       10 Batch loss: 0.191851 Batch F1: 0.631578947368421
Epoch:  541       11 Batch loss: 0.186613 Batch F1: 0.631578947368421
Epoch:  541       12 Batch loss: 0.152782 Batch F1: 0.7692307692307693
Train Avg Loss  541: 0.177794

Train Avg F1  541: 0.7150699610342769

Val Avg Loss  541: 0.184598

Val Avg F1  541:  0.6710044420394652

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 542
--------------------------------------------------------------
Epoch:  542        1 Batch loss: 0.188745 Batch F1: 0.693877551020408
Epoch:  542        2 Batch loss: 0.212178 Batch F1: 0.5238095238095238
Epoch:  542        3 Batch loss: 0.192140 Batch F1: 0.6938775510204083
Epoch:  542        4 Batch loss: 0.160900 Batch F1: 0.7727272727272727
Epoch:  542        5 Batch loss: 0.162474 Batch F1: 0.7692307692307692
Epoch:  542        6 Batch loss: 0.172536 Batch F1: 0.7391304347826088
Epoch:  542        7 Batch loss: 0.149133 Batch F1: 0.7727272727272727
Epoch:  542        8 Batch loss: 0.164717 Batch F1: 0.7346938775510203
Epoch:  542        9 Batch loss: 0.188147 Batch F1: 0.6666666666666666
Epoch:  542       10 Batch loss: 0.148515 Batch F1: 0.7894736842105263
Epoch:  542       11 Batch loss: 0.148421 Batch F1: 0.7906976744186046
Epoch:  542       12 Batch loss: 0.194457 Batch F1: 0.6060606060606061
Train Avg Loss  542: 0.173530

Train Avg F1  542: 0.7127477403521406

Val Avg Loss  542: 0.185060

Val Avg F1  542:  0.6587191497027562

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 543
--------------------------------------------------------------
Epoch:  543        1 Batch loss: 0.153084 Batch F1: 0.7906976744186046
Epoch:  543        2 Batch loss: 0.157316 Batch F1: 0.7441860465116279
Epoch:  543        3 Batch loss: 0.162586 Batch F1: 0.717948717948718
Epoch:  543        4 Batch loss: 0.167971 Batch F1: 0.723404255319149
Epoch:  543        5 Batch loss: 0.173336 Batch F1: 0.588235294117647
Epoch:  543        6 Batch loss: 0.151422 Batch F1: 0.7368421052631577
Epoch:  543        7 Batch loss: 0.182920 Batch F1: 0.7346938775510204
Epoch:  543        8 Batch loss: 0.170104 Batch F1: 0.7027027027027027
Epoch:  543        9 Batch loss: 0.206592 Batch F1: 0.6382978723404256
Epoch:  543       10 Batch loss: 0.180408 Batch F1: 0.6808510638297872
Epoch:  543       11 Batch loss: 0.198704 Batch F1: 0.6666666666666665
Epoch:  543       12 Batch loss: 0.166356 Batch F1: 0.7647058823529411
Train Avg Loss  543: 0.172567

Train Avg F1  543: 0.7074360132518706

Val Avg Loss  543: 0.183614

Val Avg F1  543:  0.7055683979277328

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 544
--------------------------------------------------------------
Epoch:  544        1 Batch loss: 0.161598 Batch F1: 0.7368421052631579
Epoch:  544        2 Batch loss: 0.158570 Batch F1: 0.717948717948718
Epoch:  544        3 Batch loss: 0.183063 Batch F1: 0.6511627906976745
Epoch:  544        4 Batch loss: 0.161727 Batch F1: 0.8076923076923077
Epoch:  544        5 Batch loss: 0.167584 Batch F1: 0.6976744186046512
Epoch:  544        6 Batch loss: 0.159700 Batch F1: 0.7999999999999999
Epoch:  544        7 Batch loss: 0.183954 Batch F1: 0.6153846153846153
Epoch:  544        8 Batch loss: 0.188997 Batch F1: 0.6521739130434783
Epoch:  544        9 Batch loss: 0.161370 Batch F1: 0.8076923076923077
Epoch:  544       10 Batch loss: 0.195765 Batch F1: 0.6818181818181819
Epoch:  544       11 Batch loss: 0.196150 Batch F1: 0.7
Epoch:  544       12 Batch loss: 0.178436 Batch F1: 0.7906976744186046
Train Avg Loss  544: 0.174743

Train Avg F1  544: 0.7215905860469748

Val Avg Loss  544: 0.186107

Val Avg F1  544:  0.6787315043128996

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 545
--------------------------------------------------------------
Epoch:  545        1 Batch loss: 0.169318 Batch F1: 0.7999999999999999
Epoch:  545        2 Batch loss: 0.175021 Batch F1: 0.631578947368421
Epoch:  545        3 Batch loss: 0.193235 Batch F1: 0.6530612244897959
Epoch:  545        4 Batch loss: 0.147685 Batch F1: 0.7804878048780488
Epoch:  545        5 Batch loss: 0.183842 Batch F1: 0.5909090909090909
Epoch:  545        6 Batch loss: 0.191129 Batch F1: 0.6666666666666667
Epoch:  545        7 Batch loss: 0.166173 Batch F1: 0.625
Epoch:  545        8 Batch loss: 0.164581 Batch F1: 0.75
Epoch:  545        9 Batch loss: 0.170321 Batch F1: 0.7826086956521738
Epoch:  545       10 Batch loss: 0.199751 Batch F1: 0.6666666666666666
Epoch:  545       11 Batch loss: 0.186725 Batch F1: 0.6666666666666666
Epoch:  545       12 Batch loss: 0.200758 Batch F1: 0.7692307692307692
Train Avg Loss  545: 0.179045

Train Avg F1  545: 0.6985730443773583

Val Avg Loss  545: 0.189396

Val Avg F1  545:  0.6649019109125491

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 546
--------------------------------------------------------------
Epoch:  546        1 Batch loss: 0.147597 Batch F1: 0.8000000000000002
Epoch:  546        2 Batch loss: 0.183868 Batch F1: 0.5714285714285715
Epoch:  546        3 Batch loss: 0.217723 Batch F1: 0.5581395348837209
Epoch:  546        4 Batch loss: 0.170767 Batch F1: 0.7755102040816326
Epoch:  546        5 Batch loss: 0.134915 Batch F1: 0.875
Epoch:  546        6 Batch loss: 0.196980 Batch F1: 0.6046511627906976
Epoch:  546        7 Batch loss: 0.178309 Batch F1: 0.7391304347826089
Epoch:  546        8 Batch loss: 0.160063 Batch F1: 0.7916666666666667
Epoch:  546        9 Batch loss: 0.194177 Batch F1: 0.6190476190476191
Epoch:  546       10 Batch loss: 0.162319 Batch F1: 0.7843137254901961
Epoch:  546       11 Batch loss: 0.208102 Batch F1: 0.5777777777777778
Epoch:  546       12 Batch loss: 0.153138 Batch F1: 0.7692307692307692
Train Avg Loss  546: 0.175663

Train Avg F1  546: 0.7054913721816884

Val Avg Loss  546: 0.184029

Val Avg F1  546:  0.6938438567777874

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 547
--------------------------------------------------------------
Epoch:  547        1 Batch loss: 0.180586 Batch F1: 0.6956521739130435
Epoch:  547        2 Batch loss: 0.213744 Batch F1: 0.6415094339622641
Epoch:  547        3 Batch loss: 0.177439 Batch F1: 0.7234042553191491
Epoch:  547        4 Batch loss: 0.178965 Batch F1: 0.7111111111111111
Epoch:  547        5 Batch loss: 0.171572 Batch F1: 0.7391304347826088
Epoch:  547        6 Batch loss: 0.135350 Batch F1: 0.7894736842105263
Epoch:  547        7 Batch loss: 0.171127 Batch F1: 0.7346938775510203
Epoch:  547        8 Batch loss: 0.149415 Batch F1: 0.7727272727272727
Epoch:  547        9 Batch loss: 0.163987 Batch F1: 0.761904761904762
Epoch:  547       10 Batch loss: 0.196522 Batch F1: 0.5641025641025641
Epoch:  547       11 Batch loss: 0.191305 Batch F1: 0.6956521739130435
Epoch:  547       12 Batch loss: 0.147697 Batch F1: 0.7741935483870969
Train Avg Loss  547: 0.173142

Train Avg F1  547: 0.7169629409903718

Val Avg Loss  547: 0.183144

Val Avg F1  547:  0.6827140693219282

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 548
--------------------------------------------------------------
Epoch:  548        1 Batch loss: 0.192398 Batch F1: 0.6521739130434783
Epoch:  548        2 Batch loss: 0.159723 Batch F1: 0.7555555555555555
Epoch:  548        3 Batch loss: 0.161929 Batch F1: 0.7142857142857143
Epoch:  548        4 Batch loss: 0.141855 Batch F1: 0.7999999999999999
Epoch:  548        5 Batch loss: 0.175016 Batch F1: 0.7843137254901961
Epoch:  548        6 Batch loss: 0.182842 Batch F1: 0.72
Epoch:  548        7 Batch loss: 0.175482 Batch F1: 0.7
Epoch:  548        8 Batch loss: 0.191661 Batch F1: 0.6382978723404256
Epoch:  548        9 Batch loss: 0.185946 Batch F1: 0.6341463414634146
Epoch:  548       10 Batch loss: 0.158898 Batch F1: 0.7272727272727272
Epoch:  548       11 Batch loss: 0.151878 Batch F1: 0.8333333333333333
Epoch:  548       12 Batch loss: 0.187383 Batch F1: 0.5333333333333333
Train Avg Loss  548: 0.172084

Train Avg F1  548: 0.7077260430098482

Val Avg Loss  548: 0.181843

Val Avg F1  548:  0.6883586626139817

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 549
--------------------------------------------------------------
Epoch:  549        1 Batch loss: 0.186706 Batch F1: 0.7241379310344827
Epoch:  549        2 Batch loss: 0.163701 Batch F1: 0.7391304347826088
Epoch:  549        3 Batch loss: 0.155640 Batch F1: 0.7317073170731707
Epoch:  549        4 Batch loss: 0.160571 Batch F1: 0.6250000000000001
Epoch:  549        5 Batch loss: 0.174771 Batch F1: 0.7547169811320755
Epoch:  549        6 Batch loss: 0.172507 Batch F1: 0.7142857142857143
Epoch:  549        7 Batch loss: 0.178702 Batch F1: 0.6486486486486486
Epoch:  549        8 Batch loss: 0.186517 Batch F1: 0.6666666666666666
Epoch:  549        9 Batch loss: 0.178301 Batch F1: 0.7307692307692308
Epoch:  549       10 Batch loss: 0.167551 Batch F1: 0.7272727272727273
Epoch:  549       11 Batch loss: 0.173933 Batch F1: 0.7555555555555556
Epoch:  549       12 Batch loss: 0.166890 Batch F1: 0.7272727272727272
Train Avg Loss  549: 0.172149

Train Avg F1  549: 0.7120969945411341

Val Avg Loss  549: 0.186308

Val Avg F1  549:  0.7155117861097927

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 550
--------------------------------------------------------------
Epoch:  550        1 Batch loss: 0.189669 Batch F1: 0.7346938775510204
Epoch:  550        2 Batch loss: 0.176747 Batch F1: 0.7000000000000001
Epoch:  550        3 Batch loss: 0.151802 Batch F1: 0.8260869565217391
Epoch:  550        4 Batch loss: 0.186989 Batch F1: 0.6521739130434783
Epoch:  550        5 Batch loss: 0.187890 Batch F1: 0.7058823529411765
Epoch:  550        6 Batch loss: 0.177538 Batch F1: 0.7346938775510203
Epoch:  550        7 Batch loss: 0.165798 Batch F1: 0.8070175438596492
Epoch:  550        8 Batch loss: 0.188822 Batch F1: 0.68
Epoch:  550        9 Batch loss: 0.183125 Batch F1: 0.6153846153846153
Epoch:  550       10 Batch loss: 0.160343 Batch F1: 0.7027027027027027
Epoch:  550       11 Batch loss: 0.161989 Batch F1: 0.717948717948718
Epoch:  550       12 Batch loss: 0.149422 Batch F1: 0.7333333333333333
Train Avg Loss  550: 0.173344

Train Avg F1  550: 0.7174931575697877

Val Avg Loss  550: 0.186646

Val Avg F1  550:  0.6721423230857193

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 551
--------------------------------------------------------------
Epoch:  551        1 Batch loss: 0.163688 Batch F1: 0.7659574468085107
Epoch:  551        2 Batch loss: 0.176109 Batch F1: 0.7547169811320754
Epoch:  551        3 Batch loss: 0.175274 Batch F1: 0.6666666666666667
Epoch:  551        4 Batch loss: 0.196459 Batch F1: 0.6923076923076924
Epoch:  551        5 Batch loss: 0.177499 Batch F1: 0.6666666666666666
Epoch:  551        6 Batch loss: 0.165225 Batch F1: 0.76
Epoch:  551        7 Batch loss: 0.162112 Batch F1: 0.6829268292682926
Epoch:  551        8 Batch loss: 0.180796 Batch F1: 0.5882352941176471
Epoch:  551        9 Batch loss: 0.145470 Batch F1: 0.8095238095238095
Epoch:  551       10 Batch loss: 0.162484 Batch F1: 0.7
Epoch:  551       11 Batch loss: 0.201341 Batch F1: 0.6222222222222222
Epoch:  551       12 Batch loss: 0.177729 Batch F1: 0.8181818181818181
Train Avg Loss  551: 0.173682

Train Avg F1  551: 0.7106171189079501

Val Avg Loss  551: 0.183637

Val Avg F1  551:  0.6838451403668795

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 552
--------------------------------------------------------------
Epoch:  552        1 Batch loss: 0.166531 Batch F1: 0.7499999999999999
Epoch:  552        2 Batch loss: 0.185956 Batch F1: 0.6938775510204083
Epoch:  552        3 Batch loss: 0.182623 Batch F1: 0.7111111111111111
Epoch:  552        4 Batch loss: 0.208430 Batch F1: 0.5142857142857142
Epoch:  552        5 Batch loss: 0.157553 Batch F1: 0.8
Epoch:  552        6 Batch loss: 0.164752 Batch F1: 0.7500000000000001
Epoch:  552        7 Batch loss: 0.162864 Batch F1: 0.7692307692307692
Epoch:  552        8 Batch loss: 0.154650 Batch F1: 0.8
Epoch:  552        9 Batch loss: 0.168353 Batch F1: 0.6956521739130435
Epoch:  552       10 Batch loss: 0.185922 Batch F1: 0.6153846153846153
Epoch:  552       11 Batch loss: 0.197815 Batch F1: 0.7142857142857143
Epoch:  552       12 Batch loss: 0.148503 Batch F1: 0.7142857142857143
Train Avg Loss  552: 0.173663

Train Avg F1  552: 0.7106761136264241

Val Avg Loss  552: 0.183760

Val Avg F1  552:  0.6967962297749533

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 553
--------------------------------------------------------------
Epoch:  553        1 Batch loss: 0.158295 Batch F1: 0.7555555555555555
Epoch:  553        2 Batch loss: 0.168841 Batch F1: 0.7142857142857143
Epoch:  553        3 Batch loss: 0.148975 Batch F1: 0.8260869565217391
Epoch:  553        4 Batch loss: 0.144068 Batch F1: 0.8085106382978723
Epoch:  553        5 Batch loss: 0.163794 Batch F1: 0.7391304347826085
Epoch:  553        6 Batch loss: 0.195883 Batch F1: 0.5853658536585366
Epoch:  553        7 Batch loss: 0.166426 Batch F1: 0.7999999999999999
Epoch:  553        8 Batch loss: 0.171269 Batch F1: 0.5806451612903225
Epoch:  553        9 Batch loss: 0.167919 Batch F1: 0.7272727272727272
Epoch:  553       10 Batch loss: 0.186681 Batch F1: 0.7199999999999999
Epoch:  553       11 Batch loss: 0.191172 Batch F1: 0.6249999999999999
Epoch:  553       12 Batch loss: 0.176877 Batch F1: 0.606060606060606
Train Avg Loss  553: 0.170017

Train Avg F1  553: 0.7073261373104734

Val Avg Loss  553: 0.183015

Val Avg F1  553:  0.6737362637362637

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 554
--------------------------------------------------------------
Epoch:  554        1 Batch loss: 0.148007 Batch F1: 0.7727272727272727
Epoch:  554        2 Batch loss: 0.141057 Batch F1: 0.8108108108108107
Epoch:  554        3 Batch loss: 0.179366 Batch F1: 0.6666666666666666
Epoch:  554        4 Batch loss: 0.187941 Batch F1: 0.68
Epoch:  554        5 Batch loss: 0.171427 Batch F1: 0.7755102040816326
Epoch:  554        6 Batch loss: 0.171997 Batch F1: 0.711111111111111
Epoch:  554        7 Batch loss: 0.191277 Batch F1: 0.6938775510204083
Epoch:  554        8 Batch loss: 0.161084 Batch F1: 0.7142857142857143
Epoch:  554        9 Batch loss: 0.143760 Batch F1: 0.7500000000000001
Epoch:  554       10 Batch loss: 0.159694 Batch F1: 0.7555555555555556
Epoch:  554       11 Batch loss: 0.176864 Batch F1: 0.6511627906976745
Epoch:  554       12 Batch loss: 0.211444 Batch F1: 0.5641025641025641
Train Avg Loss  554: 0.170326

Train Avg F1  554: 0.7121508534216177

Val Avg Loss  554: 0.182624

Val Avg F1  554:  0.6960891812865497

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 555
--------------------------------------------------------------
Epoch:  555        1 Batch loss: 0.141883 Batch F1: 0.7368421052631577
Epoch:  555        2 Batch loss: 0.146620 Batch F1: 0.782608695652174
Epoch:  555        3 Batch loss: 0.163384 Batch F1: 0.6486486486486486
Epoch:  555        4 Batch loss: 0.199000 Batch F1: 0.6399999999999999
Epoch:  555        5 Batch loss: 0.201593 Batch F1: 0.6938775510204083
Epoch:  555        6 Batch loss: 0.177918 Batch F1: 0.6153846153846154
Epoch:  555        7 Batch loss: 0.174893 Batch F1: 0.6
Epoch:  555        8 Batch loss: 0.177037 Batch F1: 0.823529411764706
Epoch:  555        9 Batch loss: 0.176004 Batch F1: 0.7777777777777779
Epoch:  555       10 Batch loss: 0.149497 Batch F1: 0.7999999999999999
Epoch:  555       11 Batch loss: 0.199489 Batch F1: 0.6938775510204083
Epoch:  555       12 Batch loss: 0.183229 Batch F1: 0.7222222222222222
Train Avg Loss  555: 0.174212

Train Avg F1  555: 0.7112307148961765

Val Avg Loss  555: 0.182511

Val Avg F1  555:  0.6818832796276405

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 556
--------------------------------------------------------------
Epoch:  556        1 Batch loss: 0.197415 Batch F1: 0.5581395348837208
Epoch:  556        2 Batch loss: 0.152492 Batch F1: 0.8148148148148148
Epoch:  556        3 Batch loss: 0.174433 Batch F1: 0.8301886792452831
Epoch:  556        4 Batch loss: 0.163928 Batch F1: 0.7777777777777778
Epoch:  556        5 Batch loss: 0.171400 Batch F1: 0.7843137254901961
Epoch:  556        6 Batch loss: 0.192788 Batch F1: 0.6521739130434783
Epoch:  556        7 Batch loss: 0.131053 Batch F1: 0.7586206896551724
Epoch:  556        8 Batch loss: 0.167149 Batch F1: 0.7272727272727272
Epoch:  556        9 Batch loss: 0.222746 Batch F1: 0.5416666666666667
Epoch:  556       10 Batch loss: 0.164941 Batch F1: 0.6842105263157895
Epoch:  556       11 Batch loss: 0.158954 Batch F1: 0.7555555555555555
Epoch:  556       12 Batch loss: 0.164620 Batch F1: 0.7727272727272727
Train Avg Loss  556: 0.171827

Train Avg F1  556: 0.721455156954038

Val Avg Loss  556: 0.185343

Val Avg F1  556:  0.6431168831168832

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 557
--------------------------------------------------------------
Epoch:  557        1 Batch loss: 0.149706 Batch F1: 0.830188679245283
Epoch:  557        2 Batch loss: 0.217924 Batch F1: 0.6545454545454547
Epoch:  557        3 Batch loss: 0.171656 Batch F1: 0.8679245283018867
Epoch:  557        4 Batch loss: 0.174087 Batch F1: 0.7199999999999999
Epoch:  557        5 Batch loss: 0.146015 Batch F1: 0.8571428571428572
Epoch:  557        6 Batch loss: 0.157624 Batch F1: 0.7222222222222222
Epoch:  557        7 Batch loss: 0.174618 Batch F1: 0.723404255319149
Epoch:  557        8 Batch loss: 0.177683 Batch F1: 0.5333333333333333
Epoch:  557        9 Batch loss: 0.166503 Batch F1: 0.6666666666666666
Epoch:  557       10 Batch loss: 0.159142 Batch F1: 0.7916666666666666
Epoch:  557       11 Batch loss: 0.178312 Batch F1: 0.6829268292682926
Epoch:  557       12 Batch loss: 0.200721 Batch F1: 0.6818181818181818
Train Avg Loss  557: 0.172833

Train Avg F1  557: 0.7276533062108328

Val Avg Loss  557: 0.183866

Val Avg F1  557:  0.6737588652482269

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 558
--------------------------------------------------------------
Epoch:  558        1 Batch loss: 0.153480 Batch F1: 0.7826086956521738
Epoch:  558        2 Batch loss: 0.165542 Batch F1: 0.717948717948718
Epoch:  558        3 Batch loss: 0.185559 Batch F1: 0.7083333333333333
Epoch:  558        4 Batch loss: 0.150682 Batch F1: 0.7692307692307693
Epoch:  558        5 Batch loss: 0.160118 Batch F1: 0.7924528301886793
Epoch:  558        6 Batch loss: 0.154733 Batch F1: 0.7916666666666666
Epoch:  558        7 Batch loss: 0.165224 Batch F1: 0.761904761904762
Epoch:  558        8 Batch loss: 0.184369 Batch F1: 0.7307692307692307
Epoch:  558        9 Batch loss: 0.167039 Batch F1: 0.7234042553191491
Epoch:  558       10 Batch loss: 0.182623 Batch F1: 0.6315789473684211
Epoch:  558       11 Batch loss: 0.184941 Batch F1: 0.6808510638297872
Epoch:  558       12 Batch loss: 0.203093 Batch F1: 0.6060606060606061
Train Avg Loss  558: 0.171450

Train Avg F1  558: 0.7247341565226914

Val Avg Loss  558: 0.183008

Val Avg F1  558:  0.6785714285714286

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 559
--------------------------------------------------------------
Epoch:  559        1 Batch loss: 0.159541 Batch F1: 0.7555555555555556
Epoch:  559        2 Batch loss: 0.198496 Batch F1: 0.619047619047619
Epoch:  559        3 Batch loss: 0.155210 Batch F1: 0.782608695652174
Epoch:  559        4 Batch loss: 0.162044 Batch F1: 0.7999999999999999
Epoch:  559        5 Batch loss: 0.172490 Batch F1: 0.6486486486486486
Epoch:  559        6 Batch loss: 0.155774 Batch F1: 0.7804878048780488
Epoch:  559        7 Batch loss: 0.171859 Batch F1: 0.6111111111111112
Epoch:  559        8 Batch loss: 0.163476 Batch F1: 0.7
Epoch:  559        9 Batch loss: 0.216547 Batch F1: 0.5957446808510638
Epoch:  559       10 Batch loss: 0.174548 Batch F1: 0.7450980392156864
Epoch:  559       11 Batch loss: 0.154458 Batch F1: 0.7916666666666666
Epoch:  559       12 Batch loss: 0.178870 Batch F1: 0.6315789473684211
Train Avg Loss  559: 0.171943

Train Avg F1  559: 0.705128980749583

Val Avg Loss  559: 0.181971

Val Avg F1  559:  0.7035207700101317

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 560
--------------------------------------------------------------
Epoch:  560        1 Batch loss: 0.189806 Batch F1: 0.6938775510204083
Epoch:  560        2 Batch loss: 0.167136 Batch F1: 0.7
Epoch:  560        3 Batch loss: 0.145718 Batch F1: 0.8
Epoch:  560        4 Batch loss: 0.149155 Batch F1: 0.816326530612245
Epoch:  560        5 Batch loss: 0.220090 Batch F1: 0.6
Epoch:  560        6 Batch loss: 0.166893 Batch F1: 0.6500000000000001
Epoch:  560        7 Batch loss: 0.186843 Batch F1: 0.5714285714285715
Epoch:  560        8 Batch loss: 0.159658 Batch F1: 0.8
Epoch:  560        9 Batch loss: 0.151230 Batch F1: 0.7391304347826088
Epoch:  560       10 Batch loss: 0.178343 Batch F1: 0.6818181818181818
Epoch:  560       11 Batch loss: 0.189821 Batch F1: 0.75
Epoch:  560       12 Batch loss: 0.172055 Batch F1: 0.8181818181818182
Train Avg Loss  560: 0.173062

Train Avg F1  560: 0.718396923986986

Val Avg Loss  560: 0.185069

Val Avg F1  560:  0.7312406669985068

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 561
--------------------------------------------------------------
Epoch:  561        1 Batch loss: 0.120197 Batch F1: 0.909090909090909
Epoch:  561        2 Batch loss: 0.155402 Batch F1: 0.7692307692307692
Epoch:  561        3 Batch loss: 0.190769 Batch F1: 0.6153846153846153
Epoch:  561        4 Batch loss: 0.144059 Batch F1: 0.7999999999999999
Epoch:  561        5 Batch loss: 0.167689 Batch F1: 0.7391304347826085
Epoch:  561        6 Batch loss: 0.211183 Batch F1: 0.6363636363636364
Epoch:  561        7 Batch loss: 0.207515 Batch F1: 0.7777777777777779
Epoch:  561        8 Batch loss: 0.169064 Batch F1: 0.6818181818181818
Epoch:  561        9 Batch loss: 0.168938 Batch F1: 0.7555555555555556
Epoch:  561       10 Batch loss: 0.171199 Batch F1: 0.7659574468085107
Epoch:  561       11 Batch loss: 0.172709 Batch F1: 0.7346938775510203
Epoch:  561       12 Batch loss: 0.200214 Batch F1: 0.6
Train Avg Loss  561: 0.173245

Train Avg F1  561: 0.732083600363632

Val Avg Loss  561: 0.182697

Val Avg F1  561:  0.691738210775165

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 562
--------------------------------------------------------------
Epoch:  562        1 Batch loss: 0.200449 Batch F1: 0.6521739130434783
Epoch:  562        2 Batch loss: 0.166765 Batch F1: 0.5945945945945946
Epoch:  562        3 Batch loss: 0.158192 Batch F1: 0.7777777777777779
Epoch:  562        4 Batch loss: 0.202647 Batch F1: 0.6956521739130435
Epoch:  562        5 Batch loss: 0.147959 Batch F1: 0.7500000000000001
Epoch:  562        6 Batch loss: 0.156703 Batch F1: 0.782608695652174
Epoch:  562        7 Batch loss: 0.171818 Batch F1: 0.6285714285714286
Epoch:  562        8 Batch loss: 0.173108 Batch F1: 0.76
Epoch:  562        9 Batch loss: 0.161500 Batch F1: 0.6976744186046512
Epoch:  562       10 Batch loss: 0.161880 Batch F1: 0.8
Epoch:  562       11 Batch loss: 0.194574 Batch F1: 0.5405405405405405
Epoch:  562       12 Batch loss: 0.141849 Batch F1: 0.8372093023255814
Train Avg Loss  562: 0.169787

Train Avg F1  562: 0.7097335704186057

Val Avg Loss  562: 0.180518

Val Avg F1  562:  0.6817094017094016

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 563
--------------------------------------------------------------
Epoch:  563        1 Batch loss: 0.188306 Batch F1: 0.6666666666666666
Epoch:  563        2 Batch loss: 0.155676 Batch F1: 0.7804878048780488
Epoch:  563        3 Batch loss: 0.154391 Batch F1: 0.7727272727272727
Epoch:  563        4 Batch loss: 0.193676 Batch F1: 0.6511627906976744
Epoch:  563        5 Batch loss: 0.136645 Batch F1: 0.8571428571428572
Epoch:  563        6 Batch loss: 0.187368 Batch F1: 0.7058823529411765
Epoch:  563        7 Batch loss: 0.182176 Batch F1: 0.7457627118644068
Epoch:  563        8 Batch loss: 0.154739 Batch F1: 0.8571428571428571
Epoch:  563        9 Batch loss: 0.180459 Batch F1: 0.7727272727272727
Epoch:  563       10 Batch loss: 0.167542 Batch F1: 0.7222222222222222
Epoch:  563       11 Batch loss: 0.170446 Batch F1: 0.7555555555555555
Epoch:  563       12 Batch loss: 0.165803 Batch F1: 0.6206896551724139
Train Avg Loss  563: 0.169769

Train Avg F1  563: 0.7423475016448687

Val Avg Loss  563: 0.180707

Val Avg F1  563:  0.7071495171495172

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 564
--------------------------------------------------------------
Epoch:  564        1 Batch loss: 0.177367 Batch F1: 0.6976744186046512
Epoch:  564        2 Batch loss: 0.172544 Batch F1: 0.7450980392156863
Epoch:  564        3 Batch loss: 0.175473 Batch F1: 0.6341463414634148
Epoch:  564        4 Batch loss: 0.144359 Batch F1: 0.7894736842105263
Epoch:  564        5 Batch loss: 0.152897 Batch F1: 0.7441860465116279
Epoch:  564        6 Batch loss: 0.171938 Batch F1: 0.5454545454545455
Epoch:  564        7 Batch loss: 0.210683 Batch F1: 0.5909090909090909
Epoch:  564        8 Batch loss: 0.181666 Batch F1: 0.6511627906976745
Epoch:  564        9 Batch loss: 0.119662 Batch F1: 0.8648648648648649
Epoch:  564       10 Batch loss: 0.189632 Batch F1: 0.7169811320754718
Epoch:  564       11 Batch loss: 0.162206 Batch F1: 0.8214285714285715
Epoch:  564       12 Batch loss: 0.164717 Batch F1: 0.761904761904762
Train Avg Loss  564: 0.168595

Train Avg F1  564: 0.713607023945074

Val Avg Loss  564: 0.182400

Val Avg F1  564:  0.6808071947545633

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 565
--------------------------------------------------------------
Epoch:  565        1 Batch loss: 0.178516 Batch F1: 0.5945945945945946
Epoch:  565        2 Batch loss: 0.138407 Batch F1: 0.888888888888889
Epoch:  565        3 Batch loss: 0.135053 Batch F1: 0.7999999999999999
Epoch:  565        4 Batch loss: 0.177784 Batch F1: 0.6666666666666666
Epoch:  565        5 Batch loss: 0.146421 Batch F1: 0.717948717948718
Epoch:  565        6 Batch loss: 0.193565 Batch F1: 0.6500000000000001
Epoch:  565        7 Batch loss: 0.178910 Batch F1: 0.631578947368421
Epoch:  565        8 Batch loss: 0.154702 Batch F1: 0.6857142857142857
Epoch:  565        9 Batch loss: 0.190798 Batch F1: 0.68
Epoch:  565       10 Batch loss: 0.184932 Batch F1: 0.7083333333333334
Epoch:  565       11 Batch loss: 0.208830 Batch F1: 0.7213114754098361
Epoch:  565       12 Batch loss: 0.156061 Batch F1: 0.8
Train Avg Loss  565: 0.170332

Train Avg F1  565: 0.7120864091603955

Val Avg Loss  565: 0.181531

Val Avg F1  565:  0.6994899665551839

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 566
--------------------------------------------------------------
Epoch:  566        1 Batch loss: 0.167645 Batch F1: 0.7547169811320755
Epoch:  566        2 Batch loss: 0.174553 Batch F1: 0.7234042553191491
Epoch:  566        3 Batch loss: 0.161631 Batch F1: 0.7547169811320756
Epoch:  566        4 Batch loss: 0.145833 Batch F1: 0.8444444444444444
Epoch:  566        5 Batch loss: 0.184122 Batch F1: 0.6818181818181819
Epoch:  566        6 Batch loss: 0.182921 Batch F1: 0.6190476190476191
Epoch:  566        7 Batch loss: 0.193421 Batch F1: 0.7083333333333334
Epoch:  566        8 Batch loss: 0.201282 Batch F1: 0.6046511627906976
Epoch:  566        9 Batch loss: 0.167103 Batch F1: 0.6666666666666666
Epoch:  566       10 Batch loss: 0.188466 Batch F1: 0.7058823529411765
Epoch:  566       11 Batch loss: 0.158177 Batch F1: 0.7317073170731707
Epoch:  566       12 Batch loss: 0.155423 Batch F1: 0.7567567567567567
Train Avg Loss  566: 0.173381

Train Avg F1  566: 0.7126788377046123

Val Avg Loss  566: 0.180836

Val Avg F1  566:  0.7145412457912458

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 567
--------------------------------------------------------------
Epoch:  567        1 Batch loss: 0.165171 Batch F1: 0.7500000000000001
Epoch:  567        2 Batch loss: 0.131104 Batch F1: 0.875
Epoch:  567        3 Batch loss: 0.180081 Batch F1: 0.7142857142857143
Epoch:  567        4 Batch loss: 0.185043 Batch F1: 0.7391304347826088
Epoch:  567        5 Batch loss: 0.194105 Batch F1: 0.76
Epoch:  567        6 Batch loss: 0.193582 Batch F1: 0.6666666666666666
Epoch:  567        7 Batch loss: 0.165173 Batch F1: 0.8148148148148148
Epoch:  567        8 Batch loss: 0.153006 Batch F1: 0.830188679245283
Epoch:  567        9 Batch loss: 0.162290 Batch F1: 0.7142857142857143
Epoch:  567       10 Batch loss: 0.172568 Batch F1: 0.6818181818181818
Epoch:  567       11 Batch loss: 0.182011 Batch F1: 0.5625
Epoch:  567       12 Batch loss: 0.159554 Batch F1: 0.7647058823529413
Train Avg Loss  567: 0.170307

Train Avg F1  567: 0.7394496740209938

Val Avg Loss  567: 0.188853

Val Avg F1  567:  0.6785714285714285

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 568
--------------------------------------------------------------
Epoch:  568        1 Batch loss: 0.162563 Batch F1: 0.830188679245283
Epoch:  568        2 Batch loss: 0.161626 Batch F1: 0.6857142857142857
Epoch:  568        3 Batch loss: 0.153598 Batch F1: 0.8163265306122449
Epoch:  568        4 Batch loss: 0.173976 Batch F1: 0.7391304347826088
Epoch:  568        5 Batch loss: 0.165100 Batch F1: 0.7692307692307693
Epoch:  568        6 Batch loss: 0.207201 Batch F1: 0.6086956521739131
Epoch:  568        7 Batch loss: 0.148076 Batch F1: 0.7804878048780488
Epoch:  568        8 Batch loss: 0.191560 Batch F1: 0.6818181818181818
Epoch:  568        9 Batch loss: 0.162795 Batch F1: 0.761904761904762
Epoch:  568       10 Batch loss: 0.192664 Batch F1: 0.6
Epoch:  568       11 Batch loss: 0.169571 Batch F1: 0.7931034482758621
Epoch:  568       12 Batch loss: 0.172601 Batch F1: 0.6666666666666667
Train Avg Loss  568: 0.171777

Train Avg F1  568: 0.7277722679418853

Val Avg Loss  568: 0.182485

Val Avg F1  568:  0.6846358428805237

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 569
--------------------------------------------------------------
Epoch:  569        1 Batch loss: 0.186356 Batch F1: 0.6521739130434783
Epoch:  569        2 Batch loss: 0.196318 Batch F1: 0.7037037037037037
Epoch:  569        3 Batch loss: 0.166232 Batch F1: 0.65
Epoch:  569        4 Batch loss: 0.129728 Batch F1: 0.8000000000000002
Epoch:  569        5 Batch loss: 0.137437 Batch F1: 0.8679245283018868
Epoch:  569        6 Batch loss: 0.146556 Batch F1: 0.7500000000000001
Epoch:  569        7 Batch loss: 0.161146 Batch F1: 0.7924528301886793
Epoch:  569        8 Batch loss: 0.179783 Batch F1: 0.6341463414634146
Epoch:  569        9 Batch loss: 0.150065 Batch F1: 0.7368421052631577
Epoch:  569       10 Batch loss: 0.193378 Batch F1: 0.6
Epoch:  569       11 Batch loss: 0.184709 Batch F1: 0.6153846153846153
Epoch:  569       12 Batch loss: 0.190821 Batch F1: 0.6111111111111113
Train Avg Loss  569: 0.168544

Train Avg F1  569: 0.7011449290383371

Val Avg Loss  569: 0.190447

Val Avg F1  569:  0.5889784014784015

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 570
--------------------------------------------------------------
Epoch:  570        1 Batch loss: 0.209450 Batch F1: 0.5499999999999999
Epoch:  570        2 Batch loss: 0.150736 Batch F1: 0.8400000000000001
Epoch:  570        3 Batch loss: 0.154298 Batch F1: 0.7555555555555556
Epoch:  570        4 Batch loss: 0.125049 Batch F1: 0.8648648648648649
Epoch:  570        5 Batch loss: 0.190644 Batch F1: 0.6818181818181818
Epoch:  570        6 Batch loss: 0.180859 Batch F1: 0.7391304347826089
Epoch:  570        7 Batch loss: 0.151813 Batch F1: 0.8214285714285715
Epoch:  570        8 Batch loss: 0.197908 Batch F1: 0.6938775510204082
Epoch:  570        9 Batch loss: 0.146126 Batch F1: 0.7567567567567567
Epoch:  570       10 Batch loss: 0.205527 Batch F1: 0.4878048780487805
Epoch:  570       11 Batch loss: 0.182744 Batch F1: 0.6
Epoch:  570       12 Batch loss: 0.180764 Batch F1: 0.7
Train Avg Loss  570: 0.172993

Train Avg F1  570: 0.7076030661896439

Val Avg Loss  570: 0.183592

Val Avg F1  570:  0.680410901155582

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 571
--------------------------------------------------------------
Epoch:  571        1 Batch loss: 0.167879 Batch F1: 0.7111111111111111
Epoch:  571        2 Batch loss: 0.231567 Batch F1: 0.6296296296296295
Epoch:  571        3 Batch loss: 0.131434 Batch F1: 0.8627450980392156
Epoch:  571        4 Batch loss: 0.156728 Batch F1: 0.6875
Epoch:  571        5 Batch loss: 0.199364 Batch F1: 0.6222222222222223
Epoch:  571        6 Batch loss: 0.135818 Batch F1: 0.8372093023255814
Epoch:  571        7 Batch loss: 0.172278 Batch F1: 0.6666666666666667
Epoch:  571        8 Batch loss: 0.177391 Batch F1: 0.6666666666666666
Epoch:  571        9 Batch loss: 0.160894 Batch F1: 0.7843137254901961
Epoch:  571       10 Batch loss: 0.158475 Batch F1: 0.782608695652174
Epoch:  571       11 Batch loss: 0.190811 Batch F1: 0.6382978723404256
Epoch:  571       12 Batch loss: 0.165513 Batch F1: 0.7692307692307692
Train Avg Loss  571: 0.170679

Train Avg F1  571: 0.7215168132812216

Val Avg Loss  571: 0.182763

Val Avg F1  571:  0.6850291237803877

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 572
--------------------------------------------------------------
Epoch:  572        1 Batch loss: 0.190648 Batch F1: 0.6111111111111113
Epoch:  572        2 Batch loss: 0.185665 Batch F1: 0.6956521739130435
Epoch:  572        3 Batch loss: 0.174676 Batch F1: 0.7234042553191491
Epoch:  572        4 Batch loss: 0.124276 Batch F1: 0.9130434782608695
Epoch:  572        5 Batch loss: 0.162502 Batch F1: 0.7027027027027027
Epoch:  572        6 Batch loss: 0.179509 Batch F1: 0.5945945945945946
Epoch:  572        7 Batch loss: 0.159067 Batch F1: 0.7317073170731707
Epoch:  572        8 Batch loss: 0.184114 Batch F1: 0.5641025641025641
Epoch:  572        9 Batch loss: 0.160441 Batch F1: 0.847457627118644
Epoch:  572       10 Batch loss: 0.183747 Batch F1: 0.7272727272727274
Epoch:  572       11 Batch loss: 0.171634 Batch F1: 0.6956521739130435
Epoch:  572       12 Batch loss: 0.190843 Batch F1: 0.6470588235294118
Train Avg Loss  572: 0.172260

Train Avg F1  572: 0.7044799624092527

Val Avg Loss  572: 0.180001

Val Avg F1  572:  0.6743831589747856

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 573
--------------------------------------------------------------
Epoch:  573        1 Batch loss: 0.192943 Batch F1: 0.6190476190476191
Epoch:  573        2 Batch loss: 0.174948 Batch F1: 0.6521739130434783
Epoch:  573        3 Batch loss: 0.182439 Batch F1: 0.6666666666666667
Epoch:  573        4 Batch loss: 0.150526 Batch F1: 0.782608695652174
Epoch:  573        5 Batch loss: 0.179339 Batch F1: 0.6486486486486486
Epoch:  573        6 Batch loss: 0.185451 Batch F1: 0.7906976744186047
Epoch:  573        7 Batch loss: 0.154540 Batch F1: 0.8214285714285715
Epoch:  573        8 Batch loss: 0.202963 Batch F1: 0.6222222222222223
Epoch:  573        9 Batch loss: 0.173935 Batch F1: 0.76
Epoch:  573       10 Batch loss: 0.138911 Batch F1: 0.7894736842105262
Epoch:  573       11 Batch loss: 0.164590 Batch F1: 0.7659574468085107
Epoch:  573       12 Batch loss: 0.151251 Batch F1: 0.8
Train Avg Loss  573: 0.170986

Train Avg F1  573: 0.7265770951789184

Val Avg Loss  573: 0.181116

Val Avg F1  573:  0.6879432624113475

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 574
--------------------------------------------------------------
Epoch:  574        1 Batch loss: 0.162276 Batch F1: 0.8076923076923077
Epoch:  574        2 Batch loss: 0.154677 Batch F1: 0.8148148148148148
Epoch:  574        3 Batch loss: 0.182581 Batch F1: 0.7199999999999999
Epoch:  574        4 Batch loss: 0.183554 Batch F1: 0.6500000000000001
Epoch:  574        5 Batch loss: 0.145186 Batch F1: 0.84
Epoch:  574        6 Batch loss: 0.167427 Batch F1: 0.6666666666666667
Epoch:  574        7 Batch loss: 0.201991 Batch F1: 0.5294117647058824
Epoch:  574        8 Batch loss: 0.181778 Batch F1: 0.6666666666666667
Epoch:  574        9 Batch loss: 0.186506 Batch F1: 0.7346938775510203
Epoch:  574       10 Batch loss: 0.183104 Batch F1: 0.5714285714285715
Epoch:  574       11 Batch loss: 0.160102 Batch F1: 0.7058823529411764
Epoch:  574       12 Batch loss: 0.142734 Batch F1: 0.7777777777777778
Train Avg Loss  574: 0.170993

Train Avg F1  574: 0.7070862333537403

Val Avg Loss  574: 0.181325

Val Avg F1  574:  0.6925747389256707

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 575
--------------------------------------------------------------
Epoch:  575        1 Batch loss: 0.148292 Batch F1: 0.8205128205128205
Epoch:  575        2 Batch loss: 0.203811 Batch F1: 0.6086956521739131
Epoch:  575        3 Batch loss: 0.184915 Batch F1: 0.6808510638297872
Epoch:  575        4 Batch loss: 0.186386 Batch F1: 0.6153846153846153
Epoch:  575        5 Batch loss: 0.168197 Batch F1: 0.6285714285714286
Epoch:  575        6 Batch loss: 0.148997 Batch F1: 0.7916666666666666
Epoch:  575        7 Batch loss: 0.175095 Batch F1: 0.7199999999999999
Epoch:  575        8 Batch loss: 0.199651 Batch F1: 0.6521739130434783
Epoch:  575        9 Batch loss: 0.155233 Batch F1: 0.6842105263157895
Epoch:  575       10 Batch loss: 0.154823 Batch F1: 0.7555555555555555
Epoch:  575       11 Batch loss: 0.157035 Batch F1: 0.7755102040816326
Epoch:  575       12 Batch loss: 0.168571 Batch F1: 0.782608695652174
Train Avg Loss  575: 0.170917

Train Avg F1  575: 0.7096450951489884

Val Avg Loss  575: 0.183211

Val Avg F1  575:  0.676508097165992

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 576
--------------------------------------------------------------
Epoch:  576        1 Batch loss: 0.172842 Batch F1: 0.7843137254901961
Epoch:  576        2 Batch loss: 0.149759 Batch F1: 0.6428571428571429
Epoch:  576        3 Batch loss: 0.171827 Batch F1: 0.7636363636363638
Epoch:  576        4 Batch loss: 0.200308 Batch F1: 0.6122448979591838
Epoch:  576        5 Batch loss: 0.179091 Batch F1: 0.76
Epoch:  576        6 Batch loss: 0.156071 Batch F1: 0.761904761904762
Epoch:  576        7 Batch loss: 0.134514 Batch F1: 0.8
Epoch:  576        8 Batch loss: 0.169520 Batch F1: 0.830188679245283
Epoch:  576        9 Batch loss: 0.182063 Batch F1: 0.6521739130434783
Epoch:  576       10 Batch loss: 0.181329 Batch F1: 0.6111111111111113
Epoch:  576       11 Batch loss: 0.177389 Batch F1: 0.7111111111111111
Epoch:  576       12 Batch loss: 0.183829 Batch F1: 0.7317073170731708
Train Avg Loss  576: 0.171545

Train Avg F1  576: 0.7217707519526503

Val Avg Loss  576: 0.185708

Val Avg F1  576:  0.6676631639037653

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 577
--------------------------------------------------------------
Epoch:  577        1 Batch loss: 0.189041 Batch F1: 0.619047619047619
Epoch:  577        2 Batch loss: 0.161715 Batch F1: 0.717948717948718
Epoch:  577        3 Batch loss: 0.190688 Batch F1: 0.6521739130434783
Epoch:  577        4 Batch loss: 0.172859 Batch F1: 0.7111111111111111
Epoch:  577        5 Batch loss: 0.155661 Batch F1: 0.8095238095238095
Epoch:  577        6 Batch loss: 0.182461 Batch F1: 0.6666666666666667
Epoch:  577        7 Batch loss: 0.173723 Batch F1: 0.7307692307692308
Epoch:  577        8 Batch loss: 0.148698 Batch F1: 0.7924528301886792
Epoch:  577        9 Batch loss: 0.186267 Batch F1: 0.76
Epoch:  577       10 Batch loss: 0.157125 Batch F1: 0.7272727272727272
Epoch:  577       11 Batch loss: 0.173359 Batch F1: 0.7
Epoch:  577       12 Batch loss: 0.166829 Batch F1: 0.7692307692307692
Train Avg Loss  577: 0.171535

Train Avg F1  577: 0.7213497829002341

Val Avg Loss  577: 0.190432

Val Avg F1  577:  0.6823085279956848

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 578
--------------------------------------------------------------
Epoch:  578        1 Batch loss: 0.138441 Batch F1: 0.742857142857143
Epoch:  578        2 Batch loss: 0.170815 Batch F1: 0.782608695652174
Epoch:  578        3 Batch loss: 0.190832 Batch F1: 0.7441860465116279
Epoch:  578        4 Batch loss: 0.207742 Batch F1: 0.6666666666666666
Epoch:  578        5 Batch loss: 0.209941 Batch F1: 0.7457627118644068
Epoch:  578        6 Batch loss: 0.219516 Batch F1: 0.7241379310344829
Epoch:  578        7 Batch loss: 0.194175 Batch F1: 0.6808510638297872
Epoch:  578        8 Batch loss: 0.190837 Batch F1: 0.7391304347826089
Epoch:  578        9 Batch loss: 0.195980 Batch F1: 0.6818181818181818
Epoch:  578       10 Batch loss: 0.177174 Batch F1: 0.717948717948718
Epoch:  578       11 Batch loss: 0.171583 Batch F1: 0.6666666666666665
Epoch:  578       12 Batch loss: 0.187707 Batch F1: 0.6666666666666666
Train Avg Loss  578: 0.187895

Train Avg F1  578: 0.7132750771915942

Val Avg Loss  578: 0.191959

Val Avg F1  578:  0.6825865128660159

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 579
--------------------------------------------------------------
Epoch:  579        1 Batch loss: 0.185680 Batch F1: 0.6666666666666666
Epoch:  579        2 Batch loss: 0.166380 Batch F1: 0.7727272727272727
Epoch:  579        3 Batch loss: 0.184527 Batch F1: 0.55
Epoch:  579        4 Batch loss: 0.172774 Batch F1: 0.7659574468085107
Epoch:  579        5 Batch loss: 0.176507 Batch F1: 0.723404255319149
Epoch:  579        6 Batch loss: 0.167988 Batch F1: 0.7727272727272727
Epoch:  579        7 Batch loss: 0.200055 Batch F1: 0.7037037037037038
Epoch:  579        8 Batch loss: 0.162405 Batch F1: 0.8070175438596492
Epoch:  579        9 Batch loss: 0.189490 Batch F1: 0.7407407407407408
Epoch:  579       10 Batch loss: 0.164501 Batch F1: 0.7272727272727272
Epoch:  579       11 Batch loss: 0.171787 Batch F1: 0.723404255319149
Epoch:  579       12 Batch loss: 0.180181 Batch F1: 0.5714285714285715
Train Avg Loss  579: 0.176856

Train Avg F1  579: 0.7104208713811179

Val Avg Loss  579: 0.189969

Val Avg F1  579:  0.6827169892347184

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 580
--------------------------------------------------------------
Epoch:  580        1 Batch loss: 0.173243 Batch F1: 0.6285714285714286
Epoch:  580        2 Batch loss: 0.148399 Batch F1: 0.7894736842105262
Epoch:  580        3 Batch loss: 0.193973 Batch F1: 0.6046511627906976
Epoch:  580        4 Batch loss: 0.141498 Batch F1: 0.830188679245283
Epoch:  580        5 Batch loss: 0.204611 Batch F1: 0.6
Epoch:  580        6 Batch loss: 0.158687 Batch F1: 0.7307692307692307
Epoch:  580        7 Batch loss: 0.195205 Batch F1: 0.689655172413793
Epoch:  580        8 Batch loss: 0.184441 Batch F1: 0.7142857142857143
Epoch:  580        9 Batch loss: 0.208801 Batch F1: 0.608695652173913
Epoch:  580       10 Batch loss: 0.155717 Batch F1: 0.7567567567567567
Epoch:  580       11 Batch loss: 0.199996 Batch F1: 0.5
Epoch:  580       12 Batch loss: 0.154018 Batch F1: 0.787878787878788
Train Avg Loss  580: 0.176549

Train Avg F1  580: 0.6867438557580109

Val Avg Loss  580: 0.188306

Val Avg F1  580:  0.6775344180225282

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 581
--------------------------------------------------------------
Epoch:  581        1 Batch loss: 0.143583 Batch F1: 0.8205128205128205
Epoch:  581        2 Batch loss: 0.197252 Batch F1: 0.6
Epoch:  581        3 Batch loss: 0.215851 Batch F1: 0.5641025641025642
Epoch:  581        4 Batch loss: 0.195095 Batch F1: 0.6666666666666666
Epoch:  581        5 Batch loss: 0.168326 Batch F1: 0.7441860465116279
Epoch:  581        6 Batch loss: 0.163412 Batch F1: 0.75
Epoch:  581        7 Batch loss: 0.177550 Batch F1: 0.7659574468085107
Epoch:  581        8 Batch loss: 0.212776 Batch F1: 0.6538461538461539
Epoch:  581        9 Batch loss: 0.134665 Batch F1: 0.7692307692307693
Epoch:  581       10 Batch loss: 0.184447 Batch F1: 0.7199999999999999
Epoch:  581       11 Batch loss: 0.146326 Batch F1: 0.7659574468085107
Epoch:  581       12 Batch loss: 0.176539 Batch F1: 0.7027027027027027
Train Avg Loss  581: 0.176319

Train Avg F1  581: 0.7102635514325272

Val Avg Loss  581: 0.184219

Val Avg F1  581:  0.6776871707141162

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 582
--------------------------------------------------------------
Epoch:  582        1 Batch loss: 0.159808 Batch F1: 0.75
Epoch:  582        2 Batch loss: 0.186674 Batch F1: 0.6666666666666666
Epoch:  582        3 Batch loss: 0.196403 Batch F1: 0.6222222222222222
Epoch:  582        4 Batch loss: 0.168558 Batch F1: 0.7142857142857143
Epoch:  582        5 Batch loss: 0.184660 Batch F1: 0.7346938775510203
Epoch:  582        6 Batch loss: 0.160191 Batch F1: 0.8333333333333333
Epoch:  582        7 Batch loss: 0.168443 Batch F1: 0.8076923076923077
Epoch:  582        8 Batch loss: 0.191262 Batch F1: 0.5789473684210527
Epoch:  582        9 Batch loss: 0.174839 Batch F1: 0.6511627906976745
Epoch:  582       10 Batch loss: 0.160678 Batch F1: 0.711111111111111
Epoch:  582       11 Batch loss: 0.178300 Batch F1: 0.6315789473684211
Epoch:  582       12 Batch loss: 0.134880 Batch F1: 0.8333333333333334
Train Avg Loss  582: 0.172058

Train Avg F1  582: 0.7112523060569048

Val Avg Loss  582: 0.182700

Val Avg F1  582:  0.6696184287668556

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 583
--------------------------------------------------------------
Epoch:  583        1 Batch loss: 0.137680 Batch F1: 0.8
Epoch:  583        2 Batch loss: 0.151750 Batch F1: 0.7027027027027027
Epoch:  583        3 Batch loss: 0.182245 Batch F1: 0.7272727272727272
Epoch:  583        4 Batch loss: 0.161320 Batch F1: 0.606060606060606
Epoch:  583        5 Batch loss: 0.180401 Batch F1: 0.6976744186046512
Epoch:  583        6 Batch loss: 0.181534 Batch F1: 0.6111111111111113
Epoch:  583        7 Batch loss: 0.187511 Batch F1: 0.7868852459016393
Epoch:  583        8 Batch loss: 0.169773 Batch F1: 0.7317073170731707
Epoch:  583        9 Batch loss: 0.188011 Batch F1: 0.7083333333333334
Epoch:  583       10 Batch loss: 0.173849 Batch F1: 0.7692307692307693
Epoch:  583       11 Batch loss: 0.159351 Batch F1: 0.7111111111111111
Epoch:  583       12 Batch loss: 0.205065 Batch F1: 0.7083333333333334
Train Avg Loss  583: 0.173208

Train Avg F1  583: 0.713368556311263

Val Avg Loss  583: 0.184094

Val Avg F1  583:  0.6940996168582376

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 584
--------------------------------------------------------------
Epoch:  584        1 Batch loss: 0.182940 Batch F1: 0.6808510638297872
Epoch:  584        2 Batch loss: 0.151094 Batch F1: 0.8666666666666666
Epoch:  584        3 Batch loss: 0.180711 Batch F1: 0.7719298245614036
Epoch:  584        4 Batch loss: 0.184639 Batch F1: 0.6500000000000001
Epoch:  584        5 Batch loss: 0.158502 Batch F1: 0.7843137254901961
Epoch:  584        6 Batch loss: 0.163839 Batch F1: 0.7058823529411765
Epoch:  584        7 Batch loss: 0.166969 Batch F1: 0.7142857142857143
Epoch:  584        8 Batch loss: 0.180985 Batch F1: 0.6938775510204083
Epoch:  584        9 Batch loss: 0.189487 Batch F1: 0.5789473684210527
Epoch:  584       10 Batch loss: 0.173545 Batch F1: 0.7272727272727272
Epoch:  584       11 Batch loss: 0.153313 Batch F1: 0.717948717948718
Epoch:  584       12 Batch loss: 0.165048 Batch F1: 0.6666666666666666
Train Avg Loss  584: 0.170923

Train Avg F1  584: 0.7132201982587097

Val Avg Loss  584: 0.183489

Val Avg F1  584:  0.6715531726103946

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 585
--------------------------------------------------------------
Epoch:  585        1 Batch loss: 0.160334 Batch F1: 0.7755102040816326
Epoch:  585        2 Batch loss: 0.174559 Batch F1: 0.6976744186046512
Epoch:  585        3 Batch loss: 0.162940 Batch F1: 0.761904761904762
Epoch:  585        4 Batch loss: 0.159128 Batch F1: 0.7391304347826089
Epoch:  585        5 Batch loss: 0.195355 Batch F1: 0.5263157894736842
Epoch:  585        6 Batch loss: 0.154799 Batch F1: 0.7428571428571429
Epoch:  585        7 Batch loss: 0.174219 Batch F1: 0.7924528301886793
Epoch:  585        8 Batch loss: 0.176067 Batch F1: 0.588235294117647
Epoch:  585        9 Batch loss: 0.167505 Batch F1: 0.7391304347826088
Epoch:  585       10 Batch loss: 0.151992 Batch F1: 0.8076923076923077
Epoch:  585       11 Batch loss: 0.163210 Batch F1: 0.6956521739130435
Epoch:  585       12 Batch loss: 0.185452 Batch F1: 0.6829268292682926
Train Avg Loss  585: 0.168797

Train Avg F1  585: 0.7124568851389217

Val Avg Loss  585: 0.190759

Val Avg F1  585:  0.7155523237271486

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 586
--------------------------------------------------------------
Epoch:  586        1 Batch loss: 0.201603 Batch F1: 0.6808510638297872
Epoch:  586        2 Batch loss: 0.188924 Batch F1: 0.6530612244897959
Epoch:  586        3 Batch loss: 0.174996 Batch F1: 0.6829268292682926
Epoch:  586        4 Batch loss: 0.166250 Batch F1: 0.7555555555555555
Epoch:  586        5 Batch loss: 0.200546 Batch F1: 0.5405405405405405
Epoch:  586        6 Batch loss: 0.197525 Batch F1: 0.6111111111111112
Epoch:  586        7 Batch loss: 0.159237 Batch F1: 0.8205128205128205
Epoch:  586        8 Batch loss: 0.174488 Batch F1: 0.723404255319149
Epoch:  586        9 Batch loss: 0.171351 Batch F1: 0.7826086956521738
Epoch:  586       10 Batch loss: 0.197957 Batch F1: 0.7843137254901961
Epoch:  586       11 Batch loss: 0.159633 Batch F1: 0.8
Epoch:  586       12 Batch loss: 0.164458 Batch F1: 0.8571428571428572
Train Avg Loss  586: 0.179747

Train Avg F1  586: 0.72433572324269

Val Avg Loss  586: 0.186145

Val Avg F1  586:  0.6800583352908933

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 587
--------------------------------------------------------------
Epoch:  587        1 Batch loss: 0.163414 Batch F1: 0.7547169811320754
Epoch:  587        2 Batch loss: 0.152275 Batch F1: 0.7567567567567567
Epoch:  587        3 Batch loss: 0.162813 Batch F1: 0.5625000000000001
Epoch:  587        4 Batch loss: 0.165505 Batch F1: 0.7391304347826089
Epoch:  587        5 Batch loss: 0.187478 Batch F1: 0.6341463414634146
Epoch:  587        6 Batch loss: 0.176462 Batch F1: 0.7346938775510203
Epoch:  587        7 Batch loss: 0.185364 Batch F1: 0.6666666666666666
Epoch:  587        8 Batch loss: 0.188639 Batch F1: 0.7441860465116279
Epoch:  587        9 Batch loss: 0.157690 Batch F1: 0.8571428571428572
Epoch:  587       10 Batch loss: 0.187198 Batch F1: 0.68
Epoch:  587       11 Batch loss: 0.180343 Batch F1: 0.6956521739130435
Epoch:  587       12 Batch loss: 0.168005 Batch F1: 0.7567567567567567
Train Avg Loss  587: 0.172932

Train Avg F1  587: 0.7151957410564024

Val Avg Loss  587: 0.183608

Val Avg F1  587:  0.6866084746118779

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 588
--------------------------------------------------------------
Epoch:  588        1 Batch loss: 0.169106 Batch F1: 0.6842105263157895
Epoch:  588        2 Batch loss: 0.178133 Batch F1: 0.6341463414634146
Epoch:  588        3 Batch loss: 0.169867 Batch F1: 0.7199999999999999
Epoch:  588        4 Batch loss: 0.147267 Batch F1: 0.7894736842105263
Epoch:  588        5 Batch loss: 0.176192 Batch F1: 0.7083333333333334
Epoch:  588        6 Batch loss: 0.173509 Batch F1: 0.6666666666666666
Epoch:  588        7 Batch loss: 0.179433 Batch F1: 0.7111111111111111
Epoch:  588        8 Batch loss: 0.183779 Batch F1: 0.7037037037037037
Epoch:  588        9 Batch loss: 0.186294 Batch F1: 0.7111111111111111
Epoch:  588       10 Batch loss: 0.144311 Batch F1: 0.7500000000000001
Epoch:  588       11 Batch loss: 0.180082 Batch F1: 0.7857142857142856
Epoch:  588       12 Batch loss: 0.153270 Batch F1: 0.8205128205128205
Train Avg Loss  588: 0.170104

Train Avg F1  588: 0.723748632011897

Val Avg Loss  588: 0.183482

Val Avg F1  588:  0.6803120651957861

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 589
--------------------------------------------------------------
Epoch:  589        1 Batch loss: 0.177808 Batch F1: 0.7777777777777777
Epoch:  589        2 Batch loss: 0.154570 Batch F1: 0.823529411764706
Epoch:  589        3 Batch loss: 0.182924 Batch F1: 0.6956521739130435
Epoch:  589        4 Batch loss: 0.174282 Batch F1: 0.7391304347826089
Epoch:  589        5 Batch loss: 0.178175 Batch F1: 0.7111111111111111
Epoch:  589        6 Batch loss: 0.151113 Batch F1: 0.7368421052631577
Epoch:  589        7 Batch loss: 0.179050 Batch F1: 0.6
Epoch:  589        8 Batch loss: 0.165861 Batch F1: 0.7391304347826089
Epoch:  589        9 Batch loss: 0.165101 Batch F1: 0.7555555555555555
Epoch:  589       10 Batch loss: 0.181807 Batch F1: 0.6511627906976744
Epoch:  589       11 Batch loss: 0.166955 Batch F1: 0.6666666666666667
Epoch:  589       12 Batch loss: 0.173273 Batch F1: 0.6285714285714286
Train Avg Loss  589: 0.170910

Train Avg F1  589: 0.710427490907195

Val Avg Loss  589: 0.181736

Val Avg F1  589:  0.6832828282828283

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 590
--------------------------------------------------------------
Epoch:  590        1 Batch loss: 0.200980 Batch F1: 0.5294117647058824
Epoch:  590        2 Batch loss: 0.147510 Batch F1: 0.8095238095238095
Epoch:  590        3 Batch loss: 0.165126 Batch F1: 0.7
Epoch:  590        4 Batch loss: 0.201690 Batch F1: 0.68
Epoch:  590        5 Batch loss: 0.146345 Batch F1: 0.8260869565217391
Epoch:  590        6 Batch loss: 0.176441 Batch F1: 0.7200000000000001
Epoch:  590        7 Batch loss: 0.156956 Batch F1: 0.6976744186046512
Epoch:  590        8 Batch loss: 0.153098 Batch F1: 0.7619047619047619
Epoch:  590        9 Batch loss: 0.203108 Batch F1: 0.6530612244897959
Epoch:  590       10 Batch loss: 0.193602 Batch F1: 0.6511627906976745
Epoch:  590       11 Batch loss: 0.155692 Batch F1: 0.744186046511628
Epoch:  590       12 Batch loss: 0.170337 Batch F1: 0.7727272727272727
Train Avg Loss  590: 0.172574

Train Avg F1  590: 0.7121449204739347

Val Avg Loss  590: 0.181039

Val Avg F1  590:  0.6814414913252121

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 591
--------------------------------------------------------------
Epoch:  591        1 Batch loss: 0.144540 Batch F1: 0.7804878048780488
Epoch:  591        2 Batch loss: 0.153905 Batch F1: 0.8
Epoch:  591        3 Batch loss: 0.145825 Batch F1: 0.7916666666666667
Epoch:  591        4 Batch loss: 0.172548 Batch F1: 0.7272727272727272
Epoch:  591        5 Batch loss: 0.163046 Batch F1: 0.7843137254901961
Epoch:  591        6 Batch loss: 0.171259 Batch F1: 0.6666666666666666
Epoch:  591        7 Batch loss: 0.177540 Batch F1: 0.6808510638297872
Epoch:  591        8 Batch loss: 0.171828 Batch F1: 0.7391304347826085
Epoch:  591        9 Batch loss: 0.167957 Batch F1: 0.6666666666666666
Epoch:  591       10 Batch loss: 0.169595 Batch F1: 0.6842105263157895
Epoch:  591       11 Batch loss: 0.185084 Batch F1: 0.5853658536585366
Epoch:  591       12 Batch loss: 0.200427 Batch F1: 0.6111111111111112
Train Avg Loss  591: 0.168630

Train Avg F1  591: 0.7098119372782338

Val Avg Loss  591: 0.180118

Val Avg F1  591:  0.6834168755221386

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 592
--------------------------------------------------------------
Epoch:  592        1 Batch loss: 0.168170 Batch F1: 0.68
Epoch:  592        2 Batch loss: 0.155960 Batch F1: 0.8235294117647058
Epoch:  592        3 Batch loss: 0.200449 Batch F1: 0.679245283018868
Epoch:  592        4 Batch loss: 0.182138 Batch F1: 0.7000000000000001
Epoch:  592        5 Batch loss: 0.187058 Batch F1: 0.7916666666666666
Epoch:  592        6 Batch loss: 0.145676 Batch F1: 0.8571428571428572
Epoch:  592        7 Batch loss: 0.191852 Batch F1: 0.5806451612903225
Epoch:  592        8 Batch loss: 0.167029 Batch F1: 0.8620689655172414
Epoch:  592        9 Batch loss: 0.179129 Batch F1: 0.8076923076923077
Epoch:  592       10 Batch loss: 0.173066 Batch F1: 0.8636363636363636
Epoch:  592       11 Batch loss: 0.141846 Batch F1: 0.8292682926829269
Epoch:  592       12 Batch loss: 0.165681 Batch F1: 0.6875000000000001
Train Avg Loss  592: 0.171504

Train Avg F1  592: 0.7635329424510217

Val Avg Loss  592: 0.183585

Val Avg F1  592:  0.6834560780834072

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 593
--------------------------------------------------------------
Epoch:  593        1 Batch loss: 0.206597 Batch F1: 0.7142857142857142
Epoch:  593        2 Batch loss: 0.137549 Batch F1: 0.8444444444444443
Epoch:  593        3 Batch loss: 0.157271 Batch F1: 0.7804878048780488
Epoch:  593        4 Batch loss: 0.175282 Batch F1: 0.76
Epoch:  593        5 Batch loss: 0.152558 Batch F1: 0.7368421052631577
Epoch:  593        6 Batch loss: 0.191688 Batch F1: 0.7083333333333334
Epoch:  593        7 Batch loss: 0.180039 Batch F1: 0.6190476190476191
Epoch:  593        8 Batch loss: 0.156907 Batch F1: 0.7317073170731707
Epoch:  593        9 Batch loss: 0.154947 Batch F1: 0.7027027027027027
Epoch:  593       10 Batch loss: 0.176596 Batch F1: 0.6956521739130435
Epoch:  593       11 Batch loss: 0.172811 Batch F1: 0.6666666666666666
Epoch:  593       12 Batch loss: 0.215723 Batch F1: 0.7222222222222222
Train Avg Loss  593: 0.173164

Train Avg F1  593: 0.7235326753191768

Val Avg Loss  593: 0.180405

Val Avg F1  593:  0.6786747176041934

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 594
--------------------------------------------------------------
Epoch:  594        1 Batch loss: 0.158048 Batch F1: 0.6842105263157895
Epoch:  594        2 Batch loss: 0.156840 Batch F1: 0.7317073170731706
Epoch:  594        3 Batch loss: 0.145488 Batch F1: 0.8399999999999999
Epoch:  594        4 Batch loss: 0.156459 Batch F1: 0.75
Epoch:  594        5 Batch loss: 0.160151 Batch F1: 0.8076923076923077
Epoch:  594        6 Batch loss: 0.205219 Batch F1: 0.6046511627906977
Epoch:  594        7 Batch loss: 0.170264 Batch F1: 0.7450980392156864
Epoch:  594        8 Batch loss: 0.208033 Batch F1: 0.47058823529411764
Epoch:  594        9 Batch loss: 0.189448 Batch F1: 0.7931034482758621
Epoch:  594       10 Batch loss: 0.207997 Batch F1: 0.5957446808510639
Epoch:  594       11 Batch loss: 0.141292 Batch F1: 0.7586206896551724
Epoch:  594       12 Batch loss: 0.168516 Batch F1: 0.6842105263157895
Train Avg Loss  594: 0.172313

Train Avg F1  594: 0.7054689111233049

Val Avg Loss  594: 0.181612

Val Avg F1  594:  0.7030601279349912

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 595
--------------------------------------------------------------
Epoch:  595        1 Batch loss: 0.202972 Batch F1: 0.5853658536585366
Epoch:  595        2 Batch loss: 0.164006 Batch F1: 0.6470588235294118
Epoch:  595        3 Batch loss: 0.168975 Batch F1: 0.761904761904762
Epoch:  595        4 Batch loss: 0.177382 Batch F1: 0.6857142857142856
Epoch:  595        5 Batch loss: 0.171650 Batch F1: 0.7555555555555555
Epoch:  595        6 Batch loss: 0.182361 Batch F1: 0.6818181818181818
Epoch:  595        7 Batch loss: 0.174642 Batch F1: 0.7142857142857143
Epoch:  595        8 Batch loss: 0.168320 Batch F1: 0.7692307692307692
Epoch:  595        9 Batch loss: 0.195617 Batch F1: 0.7346938775510204
Epoch:  595       10 Batch loss: 0.191031 Batch F1: 0.5853658536585366
Epoch:  595       11 Batch loss: 0.164515 Batch F1: 0.7555555555555555
Epoch:  595       12 Batch loss: 0.132084 Batch F1: 0.8636363636363636
Train Avg Loss  595: 0.174463

Train Avg F1  595: 0.7116821330082245

Val Avg Loss  595: 0.198923

Val Avg F1  595:  0.7394364854864945

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 596
--------------------------------------------------------------
Epoch:  596        1 Batch loss: 0.178644 Batch F1: 0.7924528301886793
Epoch:  596        2 Batch loss: 0.168295 Batch F1: 0.7692307692307692
Epoch:  596        3 Batch loss: 0.164193 Batch F1: 0.711111111111111
Epoch:  596        4 Batch loss: 0.161622 Batch F1: 0.7391304347826085
Epoch:  596        5 Batch loss: 0.157220 Batch F1: 0.7777777777777778
Epoch:  596        6 Batch loss: 0.183389 Batch F1: 0.6666666666666666
Epoch:  596        7 Batch loss: 0.197415 Batch F1: 0.5714285714285714
Epoch:  596        8 Batch loss: 0.191148 Batch F1: 0.7037037037037037
Epoch:  596        9 Batch loss: 0.203586 Batch F1: 0.6250000000000001
Epoch:  596       10 Batch loss: 0.177702 Batch F1: 0.8085106382978724
Epoch:  596       11 Batch loss: 0.177896 Batch F1: 0.7142857142857143
Epoch:  596       12 Batch loss: 0.150493 Batch F1: 0.7741935483870968
Train Avg Loss  596: 0.175967

Train Avg F1  596: 0.7211243138217142

Val Avg Loss  596: 0.184093

Val Avg F1  596:  0.6747223170204537

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 597
--------------------------------------------------------------
Epoch:  597        1 Batch loss: 0.133268 Batch F1: 0.8108108108108107
Epoch:  597        2 Batch loss: 0.187978 Batch F1: 0.6923076923076924
Epoch:  597        3 Batch loss: 0.200433 Batch F1: 0.6046511627906976
Epoch:  597        4 Batch loss: 0.182616 Batch F1: 0.6153846153846154
Epoch:  597        5 Batch loss: 0.194512 Batch F1: 0.5853658536585366
Epoch:  597        6 Batch loss: 0.148345 Batch F1: 0.7692307692307692
Epoch:  597        7 Batch loss: 0.182815 Batch F1: 0.6818181818181818
Epoch:  597        8 Batch loss: 0.143841 Batch F1: 0.7999999999999999
Epoch:  597        9 Batch loss: 0.175765 Batch F1: 0.7272727272727272
Epoch:  597       10 Batch loss: 0.151914 Batch F1: 0.8
Epoch:  597       11 Batch loss: 0.179557 Batch F1: 0.7058823529411765
Epoch:  597       12 Batch loss: 0.155143 Batch F1: 0.7777777777777778
Train Avg Loss  597: 0.169682

Train Avg F1  597: 0.7142084953327488

Val Avg Loss  597: 0.179577

Val Avg F1  597:  0.6752722897669706

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 598
--------------------------------------------------------------
Epoch:  598        1 Batch loss: 0.192843 Batch F1: 0.6511627906976744
Epoch:  598        2 Batch loss: 0.131184 Batch F1: 0.823529411764706
Epoch:  598        3 Batch loss: 0.164264 Batch F1: 0.7727272727272727
Epoch:  598        4 Batch loss: 0.168978 Batch F1: 0.5945945945945946
Epoch:  598        5 Batch loss: 0.158884 Batch F1: 0.7659574468085107
Epoch:  598        6 Batch loss: 0.159038 Batch F1: 0.8333333333333334
Epoch:  598        7 Batch loss: 0.193194 Batch F1: 0.7272727272727272
Epoch:  598        8 Batch loss: 0.165255 Batch F1: 0.5882352941176471
Epoch:  598        9 Batch loss: 0.170032 Batch F1: 0.7234042553191491
Epoch:  598       10 Batch loss: 0.180842 Batch F1: 0.6046511627906976
Epoch:  598       11 Batch loss: 0.164860 Batch F1: 0.7692307692307693
Epoch:  598       12 Batch loss: 0.174408 Batch F1: 0.7142857142857143
Train Avg Loss  598: 0.168648

Train Avg F1  598: 0.7140320644118997

Val Avg Loss  598: 0.180012

Val Avg F1  598:  0.7048731726733246

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 599
--------------------------------------------------------------
Epoch:  599        1 Batch loss: 0.177064 Batch F1: 0.6938775510204083
Epoch:  599        2 Batch loss: 0.187345 Batch F1: 0.7555555555555556
Epoch:  599        3 Batch loss: 0.136983 Batch F1: 0.7894736842105263
Epoch:  599        4 Batch loss: 0.198336 Batch F1: 0.6382978723404256
Epoch:  599        5 Batch loss: 0.174898 Batch F1: 0.7391304347826085
Epoch:  599        6 Batch loss: 0.135003 Batch F1: 0.6874999999999999
Epoch:  599        7 Batch loss: 0.176688 Batch F1: 0.7058823529411765
Epoch:  599        8 Batch loss: 0.188948 Batch F1: 0.6382978723404256
Epoch:  599        9 Batch loss: 0.148570 Batch F1: 0.7500000000000001
Epoch:  599       10 Batch loss: 0.195390 Batch F1: 0.6792452830188679
Epoch:  599       11 Batch loss: 0.162163 Batch F1: 0.8363636363636364
Epoch:  599       12 Batch loss: 0.152597 Batch F1: 0.7857142857142856
Train Avg Loss  599: 0.169499

Train Avg F1  599: 0.7249448773573265

Val Avg Loss  599: 0.180123

Val Avg F1  599:  0.7105797101449275

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 600
--------------------------------------------------------------
Epoch:  600        1 Batch loss: 0.169903 Batch F1: 0.7272727272727272
Epoch:  600        2 Batch loss: 0.173834 Batch F1: 0.7142857142857143
Epoch:  600        3 Batch loss: 0.169678 Batch F1: 0.6842105263157895
Epoch:  600        4 Batch loss: 0.141631 Batch F1: 0.8260869565217391
Epoch:  600        5 Batch loss: 0.135923 Batch F1: 0.8679245283018868
Epoch:  600        6 Batch loss: 0.169478 Batch F1: 0.7500000000000001
Epoch:  600        7 Batch loss: 0.202595 Batch F1: 0.6530612244897959
Epoch:  600        8 Batch loss: 0.158531 Batch F1: 0.7272727272727272
Epoch:  600        9 Batch loss: 0.161817 Batch F1: 0.6666666666666666
Epoch:  600       10 Batch loss: 0.202247 Batch F1: 0.5365853658536585
Epoch:  600       11 Batch loss: 0.160605 Batch F1: 0.7272727272727272
Epoch:  600       12 Batch loss: 0.182775 Batch F1: 0.7
Train Avg Loss  600: 0.169085

Train Avg F1  600: 0.715053263687786

Val Avg Loss  600: 0.183769

Val Avg F1  600:  0.6560113202400437

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 601
--------------------------------------------------------------
Epoch:  601        1 Batch loss: 0.182720 Batch F1: 0.6666666666666666
Epoch:  601        2 Batch loss: 0.172913 Batch F1: 0.75
Epoch:  601        3 Batch loss: 0.155017 Batch F1: 0.7368421052631579
Epoch:  601        4 Batch loss: 0.140515 Batch F1: 0.782608695652174
Epoch:  601        5 Batch loss: 0.201361 Batch F1: 0.6511627906976744
Epoch:  601        6 Batch loss: 0.142752 Batch F1: 0.7500000000000001
Epoch:  601        7 Batch loss: 0.169773 Batch F1: 0.75
Epoch:  601        8 Batch loss: 0.169403 Batch F1: 0.7547169811320754
Epoch:  601        9 Batch loss: 0.154457 Batch F1: 0.8095238095238095
Epoch:  601       10 Batch loss: 0.213303 Batch F1: 0.5365853658536585
Epoch:  601       11 Batch loss: 0.169237 Batch F1: 0.7391304347826088
Epoch:  601       12 Batch loss: 0.164597 Batch F1: 0.6875000000000001
Train Avg Loss  601: 0.169671

Train Avg F1  601: 0.7178947374643188

Val Avg Loss  601: 0.181878

Val Avg F1  601:  0.6654834449636091

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 602
--------------------------------------------------------------
Epoch:  602        1 Batch loss: 0.154609 Batch F1: 0.7368421052631577
Epoch:  602        2 Batch loss: 0.169956 Batch F1: 0.5454545454545455
Epoch:  602        3 Batch loss: 0.176140 Batch F1: 0.7142857142857143
Epoch:  602        4 Batch loss: 0.139669 Batch F1: 0.7999999999999999
Epoch:  602        5 Batch loss: 0.160357 Batch F1: 0.6842105263157895
Epoch:  602        6 Batch loss: 0.233837 Batch F1: 0.5833333333333334
Epoch:  602        7 Batch loss: 0.154980 Batch F1: 0.847457627118644
Epoch:  602        8 Batch loss: 0.186554 Batch F1: 0.6818181818181818
Epoch:  602        9 Batch loss: 0.153163 Batch F1: 0.8095238095238095
Epoch:  602       10 Batch loss: 0.185144 Batch F1: 0.6938775510204083
Epoch:  602       11 Batch loss: 0.172850 Batch F1: 0.6842105263157895
Epoch:  602       12 Batch loss: 0.162631 Batch F1: 0.8771929824561403
Train Avg Loss  602: 0.170824

Train Avg F1  602: 0.7215172419087926

Val Avg Loss  602: 0.186146

Val Avg F1  602:  0.7020375457875457

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 603
--------------------------------------------------------------
Epoch:  603        1 Batch loss: 0.176638 Batch F1: 0.7450980392156864
Epoch:  603        2 Batch loss: 0.170310 Batch F1: 0.7346938775510204
Epoch:  603        3 Batch loss: 0.184048 Batch F1: 0.5454545454545455
Epoch:  603        4 Batch loss: 0.180126 Batch F1: 0.7111111111111111
Epoch:  603        5 Batch loss: 0.194005 Batch F1: 0.6808510638297872
Epoch:  603        6 Batch loss: 0.150929 Batch F1: 0.8333333333333334
Epoch:  603        7 Batch loss: 0.184698 Batch F1: 0.7692307692307693
Epoch:  603        8 Batch loss: 0.178601 Batch F1: 0.7307692307692308
Epoch:  603        9 Batch loss: 0.159171 Batch F1: 0.8636363636363636
Epoch:  603       10 Batch loss: 0.172080 Batch F1: 0.7692307692307692
Epoch:  603       11 Batch loss: 0.160570 Batch F1: 0.6470588235294118
Epoch:  603       12 Batch loss: 0.162540 Batch F1: 0.6896551724137931
Train Avg Loss  603: 0.172810

Train Avg F1  603: 0.7266769249421517

Val Avg Loss  603: 0.192986

Val Avg F1  603:  0.6654082861931698

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 604
--------------------------------------------------------------
Epoch:  604        1 Batch loss: 0.170113 Batch F1: 0.717948717948718
Epoch:  604        2 Batch loss: 0.180552 Batch F1: 0.6666666666666666
Epoch:  604        3 Batch loss: 0.173298 Batch F1: 0.7391304347826088
Epoch:  604        4 Batch loss: 0.173777 Batch F1: 0.6315789473684211
Epoch:  604        5 Batch loss: 0.183834 Batch F1: 0.5789473684210527
Epoch:  604        6 Batch loss: 0.158363 Batch F1: 0.7727272727272727
Epoch:  604        7 Batch loss: 0.143537 Batch F1: 0.8292682926829269
Epoch:  604        8 Batch loss: 0.151447 Batch F1: 0.7804878048780488
Epoch:  604        9 Batch loss: 0.217545 Batch F1: 0.5833333333333334
Epoch:  604       10 Batch loss: 0.156392 Batch F1: 0.7659574468085107
Epoch:  604       11 Batch loss: 0.186254 Batch F1: 0.7407407407407407
Epoch:  604       12 Batch loss: 0.182102 Batch F1: 0.7391304347826085
Train Avg Loss  604: 0.173101

Train Avg F1  604: 0.712159788428409

Val Avg Loss  604: 0.182000

Val Avg F1  604:  0.7014431710633271

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 605
--------------------------------------------------------------
Epoch:  605        1 Batch loss: 0.171368 Batch F1: 0.6666666666666667
Epoch:  605        2 Batch loss: 0.161262 Batch F1: 0.7142857142857143
Epoch:  605        3 Batch loss: 0.136077 Batch F1: 0.7647058823529412
Epoch:  605        4 Batch loss: 0.172317 Batch F1: 0.7346938775510204
Epoch:  605        5 Batch loss: 0.181874 Batch F1: 0.6153846153846154
Epoch:  605        6 Batch loss: 0.137874 Batch F1: 0.8260869565217391
Epoch:  605        7 Batch loss: 0.187740 Batch F1: 0.7241379310344828
Epoch:  605        8 Batch loss: 0.154269 Batch F1: 0.8363636363636364
Epoch:  605        9 Batch loss: 0.180938 Batch F1: 0.7391304347826089
Epoch:  605       10 Batch loss: 0.166380 Batch F1: 0.7272727272727272
Epoch:  605       11 Batch loss: 0.182675 Batch F1: 0.723404255319149
Epoch:  605       12 Batch loss: 0.249040 Batch F1: 0.3333333333333333
Train Avg Loss  605: 0.173484

Train Avg F1  605: 0.7004555025723863

Val Avg Loss  605: 0.184755

Val Avg F1  605:  0.6703056102823904

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 606
--------------------------------------------------------------
Epoch:  606        1 Batch loss: 0.211811 Batch F1: 0.5652173913043479
Epoch:  606        2 Batch loss: 0.175736 Batch F1: 0.625
Epoch:  606        3 Batch loss: 0.195114 Batch F1: 0.7692307692307692
Epoch:  606        4 Batch loss: 0.163431 Batch F1: 0.7499999999999999
Epoch:  606        5 Batch loss: 0.186639 Batch F1: 0.7692307692307692
Epoch:  606        6 Batch loss: 0.187023 Batch F1: 0.6363636363636365
Epoch:  606        7 Batch loss: 0.160267 Batch F1: 0.8421052631578947
Epoch:  606        8 Batch loss: 0.146396 Batch F1: 0.8
Epoch:  606        9 Batch loss: 0.150761 Batch F1: 0.7058823529411765
Epoch:  606       10 Batch loss: 0.138834 Batch F1: 0.8205128205128205
Epoch:  606       11 Batch loss: 0.201622 Batch F1: 0.6666666666666666
Epoch:  606       12 Batch loss: 0.166322 Batch F1: 0.7222222222222223
Train Avg Loss  606: 0.173663

Train Avg F1  606: 0.7227026576358586

Val Avg Loss  606: 0.181592

Val Avg F1  606:  0.6721362407616567

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 607
--------------------------------------------------------------
Epoch:  607        1 Batch loss: 0.192019 Batch F1: 0.6666666666666666
Epoch:  607        2 Batch loss: 0.144739 Batch F1: 0.7567567567567567
Epoch:  607        3 Batch loss: 0.164180 Batch F1: 0.8275862068965517
Epoch:  607        4 Batch loss: 0.182422 Batch F1: 0.693877551020408
Epoch:  607        5 Batch loss: 0.161983 Batch F1: 0.631578947368421
Epoch:  607        6 Batch loss: 0.188889 Batch F1: 0.5365853658536586
Epoch:  607        7 Batch loss: 0.157035 Batch F1: 0.7027027027027027
Epoch:  607        8 Batch loss: 0.168124 Batch F1: 0.6666666666666667
Epoch:  607        9 Batch loss: 0.186559 Batch F1: 0.7037037037037038
Epoch:  607       10 Batch loss: 0.171869 Batch F1: 0.723404255319149
Epoch:  607       11 Batch loss: 0.191170 Batch F1: 0.7200000000000001
Epoch:  607       12 Batch loss: 0.148140 Batch F1: 0.8484848484848485
Train Avg Loss  607: 0.171427

Train Avg F1  607: 0.7065011392866278

Val Avg Loss  607: 0.180001

Val Avg F1  607:  0.7130322259589021

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 608
--------------------------------------------------------------
Epoch:  608        1 Batch loss: 0.181418 Batch F1: 0.6486486486486486
Epoch:  608        2 Batch loss: 0.182981 Batch F1: 0.6666666666666666
Epoch:  608        3 Batch loss: 0.172924 Batch F1: 0.7142857142857143
Epoch:  608        4 Batch loss: 0.160967 Batch F1: 0.8571428571428571
Epoch:  608        5 Batch loss: 0.168145 Batch F1: 0.7234042553191491
Epoch:  608        6 Batch loss: 0.148720 Batch F1: 0.7906976744186046
Epoch:  608        7 Batch loss: 0.179979 Batch F1: 0.6666666666666666
Epoch:  608        8 Batch loss: 0.155460 Batch F1: 0.7555555555555555
Epoch:  608        9 Batch loss: 0.172022 Batch F1: 0.6470588235294117
Epoch:  608       10 Batch loss: 0.174380 Batch F1: 0.7346938775510204
Epoch:  608       11 Batch loss: 0.187952 Batch F1: 0.6909090909090909
Epoch:  608       12 Batch loss: 0.147639 Batch F1: 0.7894736842105262
Train Avg Loss  608: 0.169382

Train Avg F1  608: 0.7237669595753259

Val Avg Loss  608: 0.182215

Val Avg F1  608:  0.696890314532656

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 609
--------------------------------------------------------------
Epoch:  609        1 Batch loss: 0.199708 Batch F1: 0.6666666666666666
Epoch:  609        2 Batch loss: 0.180190 Batch F1: 0.5853658536585366
Epoch:  609        3 Batch loss: 0.171069 Batch F1: 0.72
Epoch:  609        4 Batch loss: 0.149309 Batch F1: 0.7058823529411765
Epoch:  609        5 Batch loss: 0.208378 Batch F1: 0.6222222222222222
Epoch:  609        6 Batch loss: 0.172729 Batch F1: 0.6829268292682926
Epoch:  609        7 Batch loss: 0.147442 Batch F1: 0.8260869565217391
Epoch:  609        8 Batch loss: 0.141558 Batch F1: 0.8571428571428572
Epoch:  609        9 Batch loss: 0.149026 Batch F1: 0.8
Epoch:  609       10 Batch loss: 0.165106 Batch F1: 0.7
Epoch:  609       11 Batch loss: 0.181790 Batch F1: 0.6938775510204083
Epoch:  609       12 Batch loss: 0.191363 Batch F1: 0.5714285714285715
Train Avg Loss  609: 0.171472

Train Avg F1  609: 0.7026333217392059

Val Avg Loss  609: 0.181402

Val Avg F1  609:  0.6771206132237735

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 610
--------------------------------------------------------------
Epoch:  610        1 Batch loss: 0.186078 Batch F1: 0.7199999999999999
Epoch:  610        2 Batch loss: 0.138841 Batch F1: 0.8372093023255814
Epoch:  610        3 Batch loss: 0.164933 Batch F1: 0.7692307692307692
Epoch:  610        4 Batch loss: 0.166871 Batch F1: 0.6956521739130435
Epoch:  610        5 Batch loss: 0.174292 Batch F1: 0.7307692307692308
Epoch:  610        6 Batch loss: 0.164263 Batch F1: 0.7317073170731706
Epoch:  610        7 Batch loss: 0.193683 Batch F1: 0.6
Epoch:  610        8 Batch loss: 0.183995 Batch F1: 0.6
Epoch:  610        9 Batch loss: 0.194123 Batch F1: 0.6046511627906977
Epoch:  610       10 Batch loss: 0.146572 Batch F1: 0.7804878048780488
Epoch:  610       11 Batch loss: 0.134580 Batch F1: 0.8095238095238095
Epoch:  610       12 Batch loss: 0.181749 Batch F1: 0.6666666666666665
Train Avg Loss  610: 0.169165

Train Avg F1  610: 0.712158186430918

Val Avg Loss  610: 0.179631

Val Avg F1  610:  0.6892965800746869

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 611
--------------------------------------------------------------
Epoch:  611        1 Batch loss: 0.153783 Batch F1: 0.8
Epoch:  611        2 Batch loss: 0.206704 Batch F1: 0.6415094339622641
Epoch:  611        3 Batch loss: 0.176266 Batch F1: 0.6500000000000001
Epoch:  611        4 Batch loss: 0.190085 Batch F1: 0.6511627906976744
Epoch:  611        5 Batch loss: 0.196956 Batch F1: 0.6666666666666666
Epoch:  611        6 Batch loss: 0.169985 Batch F1: 0.723404255319149
Epoch:  611        7 Batch loss: 0.138091 Batch F1: 0.8000000000000002
Epoch:  611        8 Batch loss: 0.133385 Batch F1: 0.8717948717948718
Epoch:  611        9 Batch loss: 0.152399 Batch F1: 0.7906976744186046
Epoch:  611       10 Batch loss: 0.155209 Batch F1: 0.7727272727272727
Epoch:  611       11 Batch loss: 0.182829 Batch F1: 0.6923076923076923
Epoch:  611       12 Batch loss: 0.177096 Batch F1: 0.7
Train Avg Loss  611: 0.169399

Train Avg F1  611: 0.7300225548245162

Val Avg Loss  611: 0.181792

Val Avg F1  611:  0.6865539376649794

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 612
--------------------------------------------------------------
Epoch:  612        1 Batch loss: 0.181714 Batch F1: 0.6808510638297872
Epoch:  612        2 Batch loss: 0.146410 Batch F1: 0.8333333333333334
Epoch:  612        3 Batch loss: 0.141795 Batch F1: 0.8333333333333334
Epoch:  612        4 Batch loss: 0.158704 Batch F1: 0.7692307692307692
Epoch:  612        5 Batch loss: 0.210701 Batch F1: 0.5714285714285715
Epoch:  612        6 Batch loss: 0.168782 Batch F1: 0.6976744186046512
Epoch:  612        7 Batch loss: 0.146478 Batch F1: 0.6666666666666666
Epoch:  612        8 Batch loss: 0.140220 Batch F1: 0.7567567567567567
Epoch:  612        9 Batch loss: 0.179311 Batch F1: 0.7450980392156864
Epoch:  612       10 Batch loss: 0.156672 Batch F1: 0.7000000000000001
Epoch:  612       11 Batch loss: 0.181425 Batch F1: 0.7083333333333334
Epoch:  612       12 Batch loss: 0.214910 Batch F1: 0.6511627906976744
Train Avg Loss  612: 0.168927

Train Avg F1  612: 0.7178224230358804

Val Avg Loss  612: 0.180074

Val Avg F1  612:  0.6795068027210884

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 613
--------------------------------------------------------------
Epoch:  613        1 Batch loss: 0.167452 Batch F1: 0.7692307692307692
Epoch:  613        2 Batch loss: 0.152398 Batch F1: 0.75
Epoch:  613        3 Batch loss: 0.201369 Batch F1: 0.5
Epoch:  613        4 Batch loss: 0.157567 Batch F1: 0.7755102040816326
Epoch:  613        5 Batch loss: 0.153556 Batch F1: 0.7499999999999999
Epoch:  613        6 Batch loss: 0.195883 Batch F1: 0.6521739130434783
Epoch:  613        7 Batch loss: 0.131827 Batch F1: 0.8799999999999999
Epoch:  613        8 Batch loss: 0.157975 Batch F1: 0.7317073170731706
Epoch:  613        9 Batch loss: 0.198670 Batch F1: 0.6222222222222222
Epoch:  613       10 Batch loss: 0.160496 Batch F1: 0.7317073170731707
Epoch:  613       11 Batch loss: 0.171062 Batch F1: 0.7346938775510203
Epoch:  613       12 Batch loss: 0.173887 Batch F1: 0.6666666666666667
Train Avg Loss  613: 0.168512

Train Avg F1  613: 0.7136593572451776

Val Avg Loss  613: 0.180346

Val Avg F1  613:  0.6742809364548494

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 614
--------------------------------------------------------------
Epoch:  614        1 Batch loss: 0.188930 Batch F1: 0.7307692307692306
Epoch:  614        2 Batch loss: 0.186317 Batch F1: 0.6923076923076923
Epoch:  614        3 Batch loss: 0.159440 Batch F1: 0.7659574468085107
Epoch:  614        4 Batch loss: 0.189517 Batch F1: 0.5789473684210527
Epoch:  614        5 Batch loss: 0.157495 Batch F1: 0.7346938775510204
Epoch:  614        6 Batch loss: 0.164622 Batch F1: 0.7843137254901961
Epoch:  614        7 Batch loss: 0.167974 Batch F1: 0.7083333333333334
Epoch:  614        8 Batch loss: 0.178976 Batch F1: 0.6666666666666666
Epoch:  614        9 Batch loss: 0.143842 Batch F1: 0.8205128205128205
Epoch:  614       10 Batch loss: 0.150123 Batch F1: 0.7804878048780488
Epoch:  614       11 Batch loss: 0.154327 Batch F1: 0.6666666666666665
Epoch:  614       12 Batch loss: 0.183034 Batch F1: 0.7
Train Avg Loss  614: 0.168716

Train Avg F1  614: 0.7191380527837699

Val Avg Loss  614: 0.181275

Val Avg F1  614:  0.6721385021385021

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 615
--------------------------------------------------------------
Epoch:  615        1 Batch loss: 0.152613 Batch F1: 0.7804878048780488
Epoch:  615        2 Batch loss: 0.163428 Batch F1: 0.75
Epoch:  615        3 Batch loss: 0.210942 Batch F1: 0.4736842105263158
Epoch:  615        4 Batch loss: 0.162737 Batch F1: 0.7
Epoch:  615        5 Batch loss: 0.170194 Batch F1: 0.7777777777777779
Epoch:  615        6 Batch loss: 0.196496 Batch F1: 0.6521739130434783
Epoch:  615        7 Batch loss: 0.145837 Batch F1: 0.7027027027027027
Epoch:  615        8 Batch loss: 0.159109 Batch F1: 0.7692307692307692
Epoch:  615        9 Batch loss: 0.148777 Batch F1: 0.8163265306122449
Epoch:  615       10 Batch loss: 0.160278 Batch F1: 0.7843137254901961
Epoch:  615       11 Batch loss: 0.167807 Batch F1: 0.7999999999999999
Epoch:  615       12 Batch loss: 0.191174 Batch F1: 0.5185185185185186
Train Avg Loss  615: 0.169116

Train Avg F1  615: 0.7104346627316711

Val Avg Loss  615: 0.180180

Val Avg F1  615:  0.6864685314685315

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 616
--------------------------------------------------------------
Epoch:  616        1 Batch loss: 0.159848 Batch F1: 0.8076923076923077
Epoch:  616        2 Batch loss: 0.164391 Batch F1: 0.7391304347826088
Epoch:  616        3 Batch loss: 0.191473 Batch F1: 0.717948717948718
Epoch:  616        4 Batch loss: 0.182026 Batch F1: 0.7200000000000001
Epoch:  616        5 Batch loss: 0.187884 Batch F1: 0.7111111111111111
Epoch:  616        6 Batch loss: 0.170782 Batch F1: 0.8235294117647058
Epoch:  616        7 Batch loss: 0.204202 Batch F1: 0.6153846153846153
Epoch:  616        8 Batch loss: 0.198849 Batch F1: 0.6818181818181818
Epoch:  616        9 Batch loss: 0.155804 Batch F1: 0.85
Epoch:  616       10 Batch loss: 0.213662 Batch F1: 0.6
Epoch:  616       11 Batch loss: 0.189306 Batch F1: 0.7719298245614035
Epoch:  616       12 Batch loss: 0.149864 Batch F1: 0.7586206896551724
Train Avg Loss  616: 0.180674

Train Avg F1  616: 0.7330971078932352

Val Avg Loss  616: 0.185254

Val Avg F1  616:  0.6762005974899529

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 617
--------------------------------------------------------------
Epoch:  617        1 Batch loss: 0.178309 Batch F1: 0.7547169811320754
Epoch:  617        2 Batch loss: 0.167692 Batch F1: 0.6842105263157895
Epoch:  617        3 Batch loss: 0.206747 Batch F1: 0.55
Epoch:  617        4 Batch loss: 0.186910 Batch F1: 0.7199999999999999
Epoch:  617        5 Batch loss: 0.173086 Batch F1: 0.8076923076923077
Epoch:  617        6 Batch loss: 0.168258 Batch F1: 0.7441860465116279
Epoch:  617        7 Batch loss: 0.193092 Batch F1: 0.7058823529411765
Epoch:  617        8 Batch loss: 0.159604 Batch F1: 0.7499999999999999
Epoch:  617        9 Batch loss: 0.179211 Batch F1: 0.6363636363636365
Epoch:  617       10 Batch loss: 0.149500 Batch F1: 0.6923076923076923
Epoch:  617       11 Batch loss: 0.204296 Batch F1: 0.5
Epoch:  617       12 Batch loss: 0.172851 Batch F1: 0.75
Train Avg Loss  617: 0.178296

Train Avg F1  617: 0.6912799619386921

Val Avg Loss  617: 0.180804

Val Avg F1  617:  0.6954509775938347

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 618
--------------------------------------------------------------
Epoch:  618        1 Batch loss: 0.178051 Batch F1: 0.7346938775510204
Epoch:  618        2 Batch loss: 0.198027 Batch F1: 0.6190476190476191
Epoch:  618        3 Batch loss: 0.180921 Batch F1: 0.6511627906976744
Epoch:  618        4 Batch loss: 0.117603 Batch F1: 0.9433962264150944
Epoch:  618        5 Batch loss: 0.170549 Batch F1: 0.6976744186046512
Epoch:  618        6 Batch loss: 0.159076 Batch F1: 0.7659574468085107
Epoch:  618        7 Batch loss: 0.191720 Batch F1: 0.7169811320754718
Epoch:  618        8 Batch loss: 0.155196 Batch F1: 0.8444444444444444
Epoch:  618        9 Batch loss: 0.146423 Batch F1: 0.8205128205128205
Epoch:  618       10 Batch loss: 0.183748 Batch F1: 0.7586206896551724
Epoch:  618       11 Batch loss: 0.189145 Batch F1: 0.6341463414634148
Epoch:  618       12 Batch loss: 0.200710 Batch F1: 0.4799999999999999
Train Avg Loss  618: 0.172597

Train Avg F1  618: 0.7222198172729911

Val Avg Loss  618: 0.180954

Val Avg F1  618:  0.6846029565672423

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 619
--------------------------------------------------------------
Epoch:  619        1 Batch loss: 0.172952 Batch F1: 0.8
Epoch:  619        2 Batch loss: 0.151240 Batch F1: 0.7916666666666667
Epoch:  619        3 Batch loss: 0.165009 Batch F1: 0.7
Epoch:  619        4 Batch loss: 0.157935 Batch F1: 0.7
Epoch:  619        5 Batch loss: 0.182205 Batch F1: 0.6666666666666666
Epoch:  619        6 Batch loss: 0.159111 Batch F1: 0.6666666666666666
Epoch:  619        7 Batch loss: 0.152420 Batch F1: 0.8461538461538461
Epoch:  619        8 Batch loss: 0.191460 Batch F1: 0.6190476190476191
Epoch:  619        9 Batch loss: 0.171085 Batch F1: 0.7391304347826089
Epoch:  619       10 Batch loss: 0.179770 Batch F1: 0.6666666666666665
Epoch:  619       11 Batch loss: 0.196456 Batch F1: 0.6530612244897959
Epoch:  619       12 Batch loss: 0.205903 Batch F1: 0.6486486486486486
Train Avg Loss  619: 0.173795

Train Avg F1  619: 0.708142369982432

Val Avg Loss  619: 0.183978

Val Avg F1  619:  0.6868314805597036

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 620
--------------------------------------------------------------
Epoch:  620        1 Batch loss: 0.182606 Batch F1: 0.7307692307692308
Epoch:  620        2 Batch loss: 0.169193 Batch F1: 0.6842105263157895
Epoch:  620        3 Batch loss: 0.175396 Batch F1: 0.7391304347826088
Epoch:  620        4 Batch loss: 0.157491 Batch F1: 0.8400000000000001
Epoch:  620        5 Batch loss: 0.153420 Batch F1: 0.7727272727272727
Epoch:  620        6 Batch loss: 0.207575 Batch F1: 0.6363636363636364
Epoch:  620        7 Batch loss: 0.221706 Batch F1: 0.5652173913043479
Epoch:  620        8 Batch loss: 0.151962 Batch F1: 0.7391304347826088
Epoch:  620        9 Batch loss: 0.173378 Batch F1: 0.6842105263157895
Epoch:  620       10 Batch loss: 0.119669 Batch F1: 0.923076923076923
Epoch:  620       11 Batch loss: 0.191080 Batch F1: 0.5641025641025641
Epoch:  620       12 Batch loss: 0.159029 Batch F1: 0.6875
Train Avg Loss  620: 0.171875

Train Avg F1  620: 0.7138699117117309

Val Avg Loss  620: 0.181355

Val Avg F1  620:  0.681827672789745

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 621
--------------------------------------------------------------
Epoch:  621        1 Batch loss: 0.154310 Batch F1: 0.7317073170731708
Epoch:  621        2 Batch loss: 0.170819 Batch F1: 0.6829268292682926
Epoch:  621        3 Batch loss: 0.147764 Batch F1: 0.8363636363636364
Epoch:  621        4 Batch loss: 0.191405 Batch F1: 0.6190476190476191
Epoch:  621        5 Batch loss: 0.177773 Batch F1: 0.6666666666666666
Epoch:  621        6 Batch loss: 0.162054 Batch F1: 0.7441860465116279
Epoch:  621        7 Batch loss: 0.175174 Batch F1: 0.6956521739130435
Epoch:  621        8 Batch loss: 0.148004 Batch F1: 0.7826086956521738
Epoch:  621        9 Batch loss: 0.170196 Batch F1: 0.7555555555555555
Epoch:  621       10 Batch loss: 0.180831 Batch F1: 0.7234042553191491
Epoch:  621       11 Batch loss: 0.162409 Batch F1: 0.7441860465116279
Epoch:  621       12 Batch loss: 0.181315 Batch F1: 0.5806451612903226
Train Avg Loss  621: 0.168504

Train Avg F1  621: 0.7135791669310737

Val Avg Loss  621: 0.179754

Val Avg F1  621:  0.6877304964539007

Optimal Val loss (Epoch 330): 0.17954357340931892

Epoch 622
--------------------------------------------------------------
Epoch:  622        1 Batch loss: 0.166419 Batch F1: 0.6500000000000001
Epoch:  622        2 Batch loss: 0.170783 Batch F1: 0.7659574468085107
Epoch:  622        3 Batch loss: 0.142548 Batch F1: 0.7222222222222222
Epoch:  622        4 Batch loss: 0.184726 Batch F1: 0.619047619047619
Epoch:  622        5 Batch loss: 0.155647 Batch F1: 0.8163265306122449
Epoch:  622        6 Batch loss: 0.197608 Batch F1: 0.5500000000000002
Epoch:  622        7 Batch loss: 0.193211 Batch F1: 0.7719298245614035
Epoch:  622        8 Batch loss: 0.183283 Batch F1: 0.6938775510204083
Epoch:  622        9 Batch loss: 0.150872 Batch F1: 0.8399999999999999
Epoch:  622       10 Batch loss: 0.148345 Batch F1: 0.7999999999999999
Epoch:  622       11 Batch loss: 0.154013 Batch F1: 0.7727272727272727
Epoch:  622       12 Batch loss: 0.167277 Batch F1: 0.6857142857142857
Train Avg Loss  622: 0.167894

Train Avg F1  622: 0.7239835627261639

Val Avg Loss  622: 0.179497

Val Avg F1  622:  0.710572710067149

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 623
--------------------------------------------------------------
Epoch:  623        1 Batch loss: 0.173847 Batch F1: 0.631578947368421
Epoch:  623        2 Batch loss: 0.181234 Batch F1: 0.7346938775510203
Epoch:  623        3 Batch loss: 0.160662 Batch F1: 0.7692307692307692
Epoch:  623        4 Batch loss: 0.155720 Batch F1: 0.7659574468085107
Epoch:  623        5 Batch loss: 0.157851 Batch F1: 0.7555555555555556
Epoch:  623        6 Batch loss: 0.212166 Batch F1: 0.627450980392157
Epoch:  623        7 Batch loss: 0.136663 Batch F1: 0.8292682926829269
Epoch:  623        8 Batch loss: 0.182147 Batch F1: 0.6486486486486486
Epoch:  623        9 Batch loss: 0.176910 Batch F1: 0.5945945945945946
Epoch:  623       10 Batch loss: 0.162243 Batch F1: 0.7555555555555555
Epoch:  623       11 Batch loss: 0.174788 Batch F1: 0.7346938775510203
Epoch:  623       12 Batch loss: 0.153305 Batch F1: 0.7567567567567567
Train Avg Loss  623: 0.168961

Train Avg F1  623: 0.7169987752246613

Val Avg Loss  623: 0.181599

Val Avg F1  623:  0.6784294871794871

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 624
--------------------------------------------------------------
Epoch:  624        1 Batch loss: 0.148503 Batch F1: 0.8444444444444444
Epoch:  624        2 Batch loss: 0.174380 Batch F1: 0.6153846153846154
Epoch:  624        3 Batch loss: 0.170244 Batch F1: 0.7083333333333334
Epoch:  624        4 Batch loss: 0.151932 Batch F1: 0.7916666666666667
Epoch:  624        5 Batch loss: 0.150367 Batch F1: 0.816326530612245
Epoch:  624        6 Batch loss: 0.168229 Batch F1: 0.7692307692307692
Epoch:  624        7 Batch loss: 0.196353 Batch F1: 0.6341463414634148
Epoch:  624        8 Batch loss: 0.191431 Batch F1: 0.7636363636363638
Epoch:  624        9 Batch loss: 0.183701 Batch F1: 0.6976744186046512
Epoch:  624       10 Batch loss: 0.164804 Batch F1: 0.7727272727272727
Epoch:  624       11 Batch loss: 0.152423 Batch F1: 0.7368421052631579
Epoch:  624       12 Batch loss: 0.173547 Batch F1: 0.6
Train Avg Loss  624: 0.168826

Train Avg F1  624: 0.7292010717805778

Val Avg Loss  624: 0.184215

Val Avg F1  624:  0.6602923976608187

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 625
--------------------------------------------------------------
Epoch:  625        1 Batch loss: 0.172824 Batch F1: 0.6829268292682927
Epoch:  625        2 Batch loss: 0.192791 Batch F1: 0.5853658536585366
Epoch:  625        3 Batch loss: 0.161146 Batch F1: 0.7317073170731707
Epoch:  625        4 Batch loss: 0.160056 Batch F1: 0.782608695652174
Epoch:  625        5 Batch loss: 0.187227 Batch F1: 0.6190476190476191
Epoch:  625        6 Batch loss: 0.195840 Batch F1: 0.6909090909090909
Epoch:  625        7 Batch loss: 0.211633 Batch F1: 0.6222222222222222
Epoch:  625        8 Batch loss: 0.151640 Batch F1: 0.8571428571428571
Epoch:  625        9 Batch loss: 0.141020 Batch F1: 0.8571428571428572
Epoch:  625       10 Batch loss: 0.175972 Batch F1: 0.7346938775510204
Epoch:  625       11 Batch loss: 0.154732 Batch F1: 0.6470588235294118
Epoch:  625       12 Batch loss: 0.153145 Batch F1: 0.8
Train Avg Loss  625: 0.171502

Train Avg F1  625: 0.7175688369331042

Val Avg Loss  625: 0.181334

Val Avg F1  625:  0.6633764616957895

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 626
--------------------------------------------------------------
Epoch:  626        1 Batch loss: 0.149690 Batch F1: 0.7906976744186047
Epoch:  626        2 Batch loss: 0.186179 Batch F1: 0.6808510638297872
Epoch:  626        3 Batch loss: 0.182478 Batch F1: 0.6808510638297872
Epoch:  626        4 Batch loss: 0.161851 Batch F1: 0.7755102040816326
Epoch:  626        5 Batch loss: 0.152652 Batch F1: 0.7027027027027026
Epoch:  626        6 Batch loss: 0.189953 Batch F1: 0.7037037037037038
Epoch:  626        7 Batch loss: 0.168527 Batch F1: 0.7
Epoch:  626        8 Batch loss: 0.205730 Batch F1: 0.619047619047619
Epoch:  626        9 Batch loss: 0.137782 Batch F1: 0.8085106382978724
Epoch:  626       10 Batch loss: 0.166903 Batch F1: 0.7441860465116279
Epoch:  626       11 Batch loss: 0.183954 Batch F1: 0.7346938775510203
Epoch:  626       12 Batch loss: 0.179526 Batch F1: 0.6486486486486486
Train Avg Loss  626: 0.172102

Train Avg F1  626: 0.7157836035519173

Val Avg Loss  626: 0.181633

Val Avg F1  626:  0.6811022458628841

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 627
--------------------------------------------------------------
Epoch:  627        1 Batch loss: 0.158232 Batch F1: 0.761904761904762
Epoch:  627        2 Batch loss: 0.164700 Batch F1: 0.611111111111111
Epoch:  627        3 Batch loss: 0.174397 Batch F1: 0.6153846153846154
Epoch:  627        4 Batch loss: 0.171167 Batch F1: 0.711111111111111
Epoch:  627        5 Batch loss: 0.143963 Batch F1: 0.6428571428571429
Epoch:  627        6 Batch loss: 0.175864 Batch F1: 0.6956521739130435
Epoch:  627        7 Batch loss: 0.163863 Batch F1: 0.7317073170731707
Epoch:  627        8 Batch loss: 0.156996 Batch F1: 0.8148148148148148
Epoch:  627        9 Batch loss: 0.168220 Batch F1: 0.7450980392156864
Epoch:  627       10 Batch loss: 0.147138 Batch F1: 0.7999999999999999
Epoch:  627       11 Batch loss: 0.201999 Batch F1: 0.7272727272727272
Epoch:  627       12 Batch loss: 0.206324 Batch F1: 0.6829268292682927
Train Avg Loss  627: 0.169405

Train Avg F1  627: 0.7116533869938731

Val Avg Loss  627: 0.181311

Val Avg F1  627:  0.6927558257345492

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 628
--------------------------------------------------------------
Epoch:  628        1 Batch loss: 0.144619 Batch F1: 0.6666666666666665
Epoch:  628        2 Batch loss: 0.187034 Batch F1: 0.7391304347826088
Epoch:  628        3 Batch loss: 0.172244 Batch F1: 0.6285714285714287
Epoch:  628        4 Batch loss: 0.195914 Batch F1: 0.6285714285714286
Epoch:  628        5 Batch loss: 0.202030 Batch F1: 0.6341463414634146
Epoch:  628        6 Batch loss: 0.152582 Batch F1: 0.8000000000000002
Epoch:  628        7 Batch loss: 0.195136 Batch F1: 0.7142857142857143
Epoch:  628        8 Batch loss: 0.233639 Batch F1: 0.6274509803921569
Epoch:  628        9 Batch loss: 0.173886 Batch F1: 0.7916666666666666
Epoch:  628       10 Batch loss: 0.192634 Batch F1: 0.6938775510204083
Epoch:  628       11 Batch loss: 0.167565 Batch F1: 0.782608695652174
Epoch:  628       12 Batch loss: 0.184262 Batch F1: 0.7272727272727274
Train Avg Loss  628: 0.183462

Train Avg F1  628: 0.7028540529454497

Val Avg Loss  628: 0.190365

Val Avg F1  628:  0.6694444444444444

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 629
--------------------------------------------------------------
Epoch:  629        1 Batch loss: 0.182393 Batch F1: 0.7719298245614035
Epoch:  629        2 Batch loss: 0.176334 Batch F1: 0.7
Epoch:  629        3 Batch loss: 0.187967 Batch F1: 0.6792452830188679
Epoch:  629        4 Batch loss: 0.170293 Batch F1: 0.7
Epoch:  629        5 Batch loss: 0.169065 Batch F1: 0.6470588235294117
Epoch:  629        6 Batch loss: 0.180193 Batch F1: 0.6341463414634146
Epoch:  629        7 Batch loss: 0.161498 Batch F1: 0.7916666666666666
Epoch:  629        8 Batch loss: 0.172386 Batch F1: 0.7450980392156864
Epoch:  629        9 Batch loss: 0.195034 Batch F1: 0.5263157894736842
Epoch:  629       10 Batch loss: 0.178736 Batch F1: 0.6808510638297872
Epoch:  629       11 Batch loss: 0.164179 Batch F1: 0.8163265306122449
Epoch:  629       12 Batch loss: 0.160327 Batch F1: 0.6875
Train Avg Loss  629: 0.174867

Train Avg F1  629: 0.6983448635309305

Val Avg Loss  629: 0.181593

Val Avg F1  629:  0.6875

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 630
--------------------------------------------------------------
Epoch:  630        1 Batch loss: 0.174929 Batch F1: 0.7083333333333334
Epoch:  630        2 Batch loss: 0.157485 Batch F1: 0.7826086956521738
Epoch:  630        3 Batch loss: 0.170090 Batch F1: 0.76
Epoch:  630        4 Batch loss: 0.166827 Batch F1: 0.7755102040816326
Epoch:  630        5 Batch loss: 0.154112 Batch F1: 0.7500000000000001
Epoch:  630        6 Batch loss: 0.149236 Batch F1: 0.8292682926829269
Epoch:  630        7 Batch loss: 0.150152 Batch F1: 0.7692307692307692
Epoch:  630        8 Batch loss: 0.183192 Batch F1: 0.6511627906976745
Epoch:  630        9 Batch loss: 0.158872 Batch F1: 0.8518518518518519
Epoch:  630       10 Batch loss: 0.173490 Batch F1: 0.7441860465116279
Epoch:  630       11 Batch loss: 0.202196 Batch F1: 0.6382978723404256
Epoch:  630       12 Batch loss: 0.193430 Batch F1: 0.6511627906976744
Train Avg Loss  630: 0.169501

Train Avg F1  630: 0.7426343872566742

Val Avg Loss  630: 0.180782

Val Avg F1  630:  0.7000399645278351

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 631
--------------------------------------------------------------
Epoch:  631        1 Batch loss: 0.183900 Batch F1: 0.6818181818181819
Epoch:  631        2 Batch loss: 0.183838 Batch F1: 0.5909090909090908
Epoch:  631        3 Batch loss: 0.188164 Batch F1: 0.693877551020408
Epoch:  631        4 Batch loss: 0.173838 Batch F1: 0.7142857142857143
Epoch:  631        5 Batch loss: 0.173576 Batch F1: 0.6829268292682926
Epoch:  631        6 Batch loss: 0.171214 Batch F1: 0.7391304347826088
Epoch:  631        7 Batch loss: 0.171846 Batch F1: 0.6486486486486486
Epoch:  631        8 Batch loss: 0.159244 Batch F1: 0.7659574468085107
Epoch:  631        9 Batch loss: 0.168482 Batch F1: 0.6842105263157895
Epoch:  631       10 Batch loss: 0.160675 Batch F1: 0.6829268292682927
Epoch:  631       11 Batch loss: 0.142346 Batch F1: 0.888888888888889
Epoch:  631       12 Batch loss: 0.176645 Batch F1: 0.7441860465116279
Train Avg Loss  631: 0.171147

Train Avg F1  631: 0.7098138490438378

Val Avg Loss  631: 0.181052

Val Avg F1  631:  0.7119218500797448

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 632
--------------------------------------------------------------
Epoch:  632        1 Batch loss: 0.168972 Batch F1: 0.6829268292682926
Epoch:  632        2 Batch loss: 0.182621 Batch F1: 0.7199999999999999
Epoch:  632        3 Batch loss: 0.160615 Batch F1: 0.7500000000000001
Epoch:  632        4 Batch loss: 0.154149 Batch F1: 0.7999999999999999
Epoch:  632        5 Batch loss: 0.163287 Batch F1: 0.7317073170731708
Epoch:  632        6 Batch loss: 0.198639 Batch F1: 0.55
Epoch:  632        7 Batch loss: 0.159529 Batch F1: 0.6842105263157895
Epoch:  632        8 Batch loss: 0.155509 Batch F1: 0.7441860465116279
Epoch:  632        9 Batch loss: 0.163479 Batch F1: 0.76
Epoch:  632       10 Batch loss: 0.160081 Batch F1: 0.76
Epoch:  632       11 Batch loss: 0.195260 Batch F1: 0.6222222222222223
Epoch:  632       12 Batch loss: 0.154789 Batch F1: 0.7894736842105263
Train Avg Loss  632: 0.168078

Train Avg F1  632: 0.7162272188001357

Val Avg Loss  632: 0.181117

Val Avg F1  632:  0.7066084182788986

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 633
--------------------------------------------------------------
Epoch:  633        1 Batch loss: 0.180811 Batch F1: 0.7391304347826089
Epoch:  633        2 Batch loss: 0.137077 Batch F1: 0.8571428571428572
Epoch:  633        3 Batch loss: 0.182939 Batch F1: 0.6829268292682926
Epoch:  633        4 Batch loss: 0.169606 Batch F1: 0.5806451612903226
Epoch:  633        5 Batch loss: 0.172808 Batch F1: 0.6666666666666666
Epoch:  633        6 Batch loss: 0.128684 Batch F1: 0.8372093023255814
Epoch:  633        7 Batch loss: 0.161261 Batch F1: 0.7391304347826089
Epoch:  633        8 Batch loss: 0.164905 Batch F1: 0.7450980392156864
Epoch:  633        9 Batch loss: 0.175013 Batch F1: 0.6363636363636365
Epoch:  633       10 Batch loss: 0.203319 Batch F1: 0.7142857142857143
Epoch:  633       11 Batch loss: 0.187029 Batch F1: 0.7111111111111111
Epoch:  633       12 Batch loss: 0.152341 Batch F1: 0.7222222222222222
Train Avg Loss  633: 0.167983

Train Avg F1  633: 0.719327700788109

Val Avg Loss  633: 0.181099

Val Avg F1  633:  0.7082827277252364

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 634
--------------------------------------------------------------
Epoch:  634        1 Batch loss: 0.147990 Batch F1: 0.7916666666666667
Epoch:  634        2 Batch loss: 0.152128 Batch F1: 0.8163265306122449
Epoch:  634        3 Batch loss: 0.171313 Batch F1: 0.6470588235294118
Epoch:  634        4 Batch loss: 0.146605 Batch F1: 0.8085106382978724
Epoch:  634        5 Batch loss: 0.175384 Batch F1: 0.65
Epoch:  634        6 Batch loss: 0.140781 Batch F1: 0.8372093023255814
Epoch:  634        7 Batch loss: 0.177399 Batch F1: 0.6521739130434783
Epoch:  634        8 Batch loss: 0.179724 Batch F1: 0.7058823529411765
Epoch:  634        9 Batch loss: 0.178397 Batch F1: 0.6666666666666666
Epoch:  634       10 Batch loss: 0.219980 Batch F1: 0.5531914893617021
Epoch:  634       11 Batch loss: 0.163280 Batch F1: 0.7391304347826088
Epoch:  634       12 Batch loss: 0.158576 Batch F1: 0.6875000000000001
Train Avg Loss  634: 0.167630

Train Avg F1  634: 0.7129430681856176

Val Avg Loss  634: 0.179955

Val Avg F1  634:  0.6825735729074238

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 635
--------------------------------------------------------------
Epoch:  635        1 Batch loss: 0.142373 Batch F1: 0.8108108108108109
Epoch:  635        2 Batch loss: 0.151135 Batch F1: 0.7368421052631577
Epoch:  635        3 Batch loss: 0.157044 Batch F1: 0.7924528301886792
Epoch:  635        4 Batch loss: 0.175643 Batch F1: 0.75
Epoch:  635        5 Batch loss: 0.155014 Batch F1: 0.6857142857142857
Epoch:  635        6 Batch loss: 0.172743 Batch F1: 0.6486486486486486
Epoch:  635        7 Batch loss: 0.172708 Batch F1: 0.6818181818181819
Epoch:  635        8 Batch loss: 0.161245 Batch F1: 0.7441860465116279
Epoch:  635        9 Batch loss: 0.178775 Batch F1: 0.6938775510204083
Epoch:  635       10 Batch loss: 0.178214 Batch F1: 0.723404255319149
Epoch:  635       11 Batch loss: 0.202417 Batch F1: 0.5909090909090909
Epoch:  635       12 Batch loss: 0.158556 Batch F1: 0.8181818181818182
Train Avg Loss  635: 0.167156

Train Avg F1  635: 0.7230704686988214

Val Avg Loss  635: 0.179689

Val Avg F1  635:  0.7062644222065196

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 636
--------------------------------------------------------------
Epoch:  636        1 Batch loss: 0.161227 Batch F1: 0.7843137254901961
Epoch:  636        2 Batch loss: 0.171611 Batch F1: 0.7272727272727273
Epoch:  636        3 Batch loss: 0.153384 Batch F1: 0.7659574468085107
Epoch:  636        4 Batch loss: 0.168173 Batch F1: 0.6818181818181818
Epoch:  636        5 Batch loss: 0.174778 Batch F1: 0.7857142857142857
Epoch:  636        6 Batch loss: 0.192834 Batch F1: 0.5641025641025642
Epoch:  636        7 Batch loss: 0.158300 Batch F1: 0.7272727272727272
Epoch:  636        8 Batch loss: 0.164123 Batch F1: 0.7391304347826085
Epoch:  636        9 Batch loss: 0.161082 Batch F1: 0.5625
Epoch:  636       10 Batch loss: 0.170057 Batch F1: 0.65
Epoch:  636       11 Batch loss: 0.155451 Batch F1: 0.7391304347826088
Epoch:  636       12 Batch loss: 0.169634 Batch F1: 0.7567567567567567
Train Avg Loss  636: 0.166721

Train Avg F1  636: 0.7069974404000973

Val Avg Loss  636: 0.181465

Val Avg F1  636:  0.672419982342269

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 637
--------------------------------------------------------------
Epoch:  637        1 Batch loss: 0.143735 Batch F1: 0.7999999999999999
Epoch:  637        2 Batch loss: 0.170086 Batch F1: 0.6829268292682926
Epoch:  637        3 Batch loss: 0.147037 Batch F1: 0.7692307692307693
Epoch:  637        4 Batch loss: 0.190473 Batch F1: 0.6222222222222222
Epoch:  637        5 Batch loss: 0.176776 Batch F1: 0.6486486486486486
Epoch:  637        6 Batch loss: 0.144923 Batch F1: 0.8235294117647058
Epoch:  637        7 Batch loss: 0.171591 Batch F1: 0.7843137254901961
Epoch:  637        8 Batch loss: 0.162499 Batch F1: 0.7499999999999999
Epoch:  637        9 Batch loss: 0.173210 Batch F1: 0.7843137254901961
Epoch:  637       10 Batch loss: 0.181195 Batch F1: 0.7307692307692308
Epoch:  637       11 Batch loss: 0.177449 Batch F1: 0.7142857142857143
Epoch:  637       12 Batch loss: 0.176056 Batch F1: 0.7142857142857143
Train Avg Loss  637: 0.167919

Train Avg F1  637: 0.7353771659546408

Val Avg Loss  637: 0.180649

Val Avg F1  637:  0.6985977831619512

Optimal Val loss (Epoch 622): 0.17949729040265083

Epoch 638
--------------------------------------------------------------
Epoch:  638        1 Batch loss: 0.170986 Batch F1: 0.6285714285714287
Epoch:  638        2 Batch loss: 0.167984 Batch F1: 0.75
Epoch:  638        3 Batch loss: 0.146353 Batch F1: 0.7567567567567567
Epoch:  638        4 Batch loss: 0.157327 Batch F1: 0.7727272727272727
Epoch:  638        5 Batch loss: 0.158965 Batch F1: 0.717948717948718
Epoch:  638        6 Batch loss: 0.163025 Batch F1: 0.7555555555555555
Epoch:  638        7 Batch loss: 0.176880 Batch F1: 0.7719298245614035
Epoch:  638        8 Batch loss: 0.168407 Batch F1: 0.7391304347826085
Epoch:  638        9 Batch loss: 0.195773 Batch F1: 0.6382978723404256
Epoch:  638       10 Batch loss: 0.181250 Batch F1: 0.6511627906976745
Epoch:  638       11 Batch loss: 0.165391 Batch F1: 0.7692307692307693
Epoch:  638       12 Batch loss: 0.169225 Batch F1: 0.6451612903225806
Train Avg Loss  638: 0.168464

Train Avg F1  638: 0.7163727261245993

Val Avg Loss  638: 0.179200

Val Avg F1  638:  0.6810070719434245

Optimal Val loss (Epoch 638): 0.17920036613941193

Epoch 639
--------------------------------------------------------------
Epoch:  639        1 Batch loss: 0.191338 Batch F1: 0.43750000000000006
Epoch:  639        2 Batch loss: 0.180780 Batch F1: 0.6190476190476191
Epoch:  639        3 Batch loss: 0.202165 Batch F1: 0.6382978723404255
Epoch:  639        4 Batch loss: 0.164508 Batch F1: 0.76
Epoch:  639        5 Batch loss: 0.161914 Batch F1: 0.7391304347826085
Epoch:  639        6 Batch loss: 0.154453 Batch F1: 0.823529411764706
Epoch:  639        7 Batch loss: 0.176193 Batch F1: 0.7391304347826089
Epoch:  639        8 Batch loss: 0.177365 Batch F1: 0.6511627906976744
Epoch:  639        9 Batch loss: 0.145125 Batch F1: 0.8000000000000002
Epoch:  639       10 Batch loss: 0.147512 Batch F1: 0.8085106382978724
Epoch:  639       11 Batch loss: 0.154766 Batch F1: 0.7317073170731708
Epoch:  639       12 Batch loss: 0.161087 Batch F1: 0.7999999999999999
Train Avg Loss  639: 0.168101

Train Avg F1  639: 0.7123347098988905

Val Avg Loss  639: 0.179636

Val Avg F1  639:  0.679362463376155

Optimal Val loss (Epoch 638): 0.17920036613941193

Epoch 640
--------------------------------------------------------------
Epoch:  640        1 Batch loss: 0.161316 Batch F1: 0.7317073170731706
Epoch:  640        2 Batch loss: 0.166218 Batch F1: 0.7391304347826085
Epoch:  640        3 Batch loss: 0.162232 Batch F1: 0.7272727272727272
Epoch:  640        4 Batch loss: 0.173376 Batch F1: 0.7083333333333334
Epoch:  640        5 Batch loss: 0.182387 Batch F1: 0.7307692307692306
Epoch:  640        6 Batch loss: 0.153793 Batch F1: 0.7916666666666667
Epoch:  640        7 Batch loss: 0.166045 Batch F1: 0.7391304347826089
Epoch:  640        8 Batch loss: 0.180381 Batch F1: 0.6808510638297872
Epoch:  640        9 Batch loss: 0.155202 Batch F1: 0.7441860465116279
Epoch:  640       10 Batch loss: 0.178724 Batch F1: 0.619047619047619
Epoch:  640       11 Batch loss: 0.157034 Batch F1: 0.7906976744186046
Epoch:  640       12 Batch loss: 0.163027 Batch F1: 0.7407407407407408
Train Avg Loss  640: 0.166644

Train Avg F1  640: 0.7286277741023938

Val Avg Loss  640: 0.178812

Val Avg F1  640:  0.7219295326826383

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 641
--------------------------------------------------------------
Epoch:  641        1 Batch loss: 0.165293 Batch F1: 0.7142857142857143
Epoch:  641        2 Batch loss: 0.167964 Batch F1: 0.6315789473684211
Epoch:  641        3 Batch loss: 0.172376 Batch F1: 0.7500000000000001
Epoch:  641        4 Batch loss: 0.162683 Batch F1: 0.7777777777777779
Epoch:  641        5 Batch loss: 0.158814 Batch F1: 0.7272727272727272
Epoch:  641        6 Batch loss: 0.163939 Batch F1: 0.7142857142857143
Epoch:  641        7 Batch loss: 0.149835 Batch F1: 0.8333333333333333
Epoch:  641        8 Batch loss: 0.186970 Batch F1: 0.6190476190476191
Epoch:  641        9 Batch loss: 0.170923 Batch F1: 0.6511627906976745
Epoch:  641       10 Batch loss: 0.173746 Batch F1: 0.65
Epoch:  641       11 Batch loss: 0.156044 Batch F1: 0.8076923076923077
Epoch:  641       12 Batch loss: 0.156741 Batch F1: 0.7058823529411765
Train Avg Loss  641: 0.165444

Train Avg F1  641: 0.7151932737252054

Val Avg Loss  641: 0.179778

Val Avg F1  641:  0.6850592885375494

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 642
--------------------------------------------------------------
Epoch:  642        1 Batch loss: 0.175664 Batch F1: 0.6666666666666666
Epoch:  642        2 Batch loss: 0.190244 Batch F1: 0.7346938775510203
Epoch:  642        3 Batch loss: 0.161182 Batch F1: 0.588235294117647
Epoch:  642        4 Batch loss: 0.162479 Batch F1: 0.6842105263157895
Epoch:  642        5 Batch loss: 0.176863 Batch F1: 0.6956521739130435
Epoch:  642        6 Batch loss: 0.149141 Batch F1: 0.6470588235294117
Epoch:  642        7 Batch loss: 0.158344 Batch F1: 0.7843137254901961
Epoch:  642        8 Batch loss: 0.167950 Batch F1: 0.6521739130434783
Epoch:  642        9 Batch loss: 0.156464 Batch F1: 0.7555555555555555
Epoch:  642       10 Batch loss: 0.168529 Batch F1: 0.7826086956521738
Epoch:  642       11 Batch loss: 0.151728 Batch F1: 0.8
Epoch:  642       12 Batch loss: 0.190972 Batch F1: 0.7391304347826088
Train Avg Loss  642: 0.167463

Train Avg F1  642: 0.7108583072181326

Val Avg Loss  642: 0.179802

Val Avg F1  642:  0.7152961980548187

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 643
--------------------------------------------------------------
Epoch:  643        1 Batch loss: 0.168659 Batch F1: 0.6666666666666667
Epoch:  643        2 Batch loss: 0.172775 Batch F1: 0.6829268292682926
Epoch:  643        3 Batch loss: 0.166941 Batch F1: 0.7111111111111111
Epoch:  643        4 Batch loss: 0.170423 Batch F1: 0.65
Epoch:  643        5 Batch loss: 0.177337 Batch F1: 0.76
Epoch:  643        6 Batch loss: 0.175083 Batch F1: 0.6111111111111112
Epoch:  643        7 Batch loss: 0.139965 Batch F1: 0.8
Epoch:  643        8 Batch loss: 0.196849 Batch F1: 0.6938775510204083
Epoch:  643        9 Batch loss: 0.172294 Batch F1: 0.7346938775510203
Epoch:  643       10 Batch loss: 0.160546 Batch F1: 0.7857142857142857
Epoch:  643       11 Batch loss: 0.174073 Batch F1: 0.6923076923076923
Epoch:  643       12 Batch loss: 0.141898 Batch F1: 0.7368421052631577
Train Avg Loss  643: 0.168070

Train Avg F1  643: 0.7104376025011456

Val Avg Loss  643: 0.184805

Val Avg F1  643:  0.6721312122527928

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 644
--------------------------------------------------------------
Epoch:  644        1 Batch loss: 0.164237 Batch F1: 0.693877551020408
Epoch:  644        2 Batch loss: 0.155584 Batch F1: 0.6341463414634148
Epoch:  644        3 Batch loss: 0.174577 Batch F1: 0.7169811320754716
Epoch:  644        4 Batch loss: 0.207109 Batch F1: 0.6046511627906976
Epoch:  644        5 Batch loss: 0.165137 Batch F1: 0.7272727272727273
Epoch:  644        6 Batch loss: 0.180235 Batch F1: 0.7391304347826089
Epoch:  644        7 Batch loss: 0.150650 Batch F1: 0.7317073170731707
Epoch:  644        8 Batch loss: 0.163905 Batch F1: 0.7692307692307693
Epoch:  644        9 Batch loss: 0.180544 Batch F1: 0.6500000000000001
Epoch:  644       10 Batch loss: 0.165132 Batch F1: 0.7111111111111111
Epoch:  644       11 Batch loss: 0.182226 Batch F1: 0.7083333333333334
Epoch:  644       12 Batch loss: 0.164152 Batch F1: 0.742857142857143
Train Avg Loss  644: 0.171124

Train Avg F1  644: 0.7024415852509046

Val Avg Loss  644: 0.180447

Val Avg F1  644:  0.7007930367504835

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 645
--------------------------------------------------------------
Epoch:  645        1 Batch loss: 0.158928 Batch F1: 0.7027027027027027
Epoch:  645        2 Batch loss: 0.218955 Batch F1: 0.45
Epoch:  645        3 Batch loss: 0.171911 Batch F1: 0.7547169811320754
Epoch:  645        4 Batch loss: 0.183126 Batch F1: 0.6
Epoch:  645        5 Batch loss: 0.156545 Batch F1: 0.7272727272727272
Epoch:  645        6 Batch loss: 0.145680 Batch F1: 0.8260869565217391
Epoch:  645        7 Batch loss: 0.167426 Batch F1: 0.7843137254901961
Epoch:  645        8 Batch loss: 0.149919 Batch F1: 0.8571428571428572
Epoch:  645        9 Batch loss: 0.163231 Batch F1: 0.8571428571428572
Epoch:  645       10 Batch loss: 0.187386 Batch F1: 0.6956521739130435
Epoch:  645       11 Batch loss: 0.142888 Batch F1: 0.8571428571428572
Epoch:  645       12 Batch loss: 0.152855 Batch F1: 0.8108108108108107
Train Avg Loss  645: 0.166571

Train Avg F1  645: 0.7435820541059889

Val Avg Loss  645: 0.181991

Val Avg F1  645:  0.6797589718321426

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 646
--------------------------------------------------------------
Epoch:  646        1 Batch loss: 0.206921 Batch F1: 0.6222222222222223
Epoch:  646        2 Batch loss: 0.182248 Batch F1: 0.7450980392156864
Epoch:  646        3 Batch loss: 0.196658 Batch F1: 0.6
Epoch:  646        4 Batch loss: 0.180686 Batch F1: 0.7843137254901961
Epoch:  646        5 Batch loss: 0.161555 Batch F1: 0.7441860465116279
Epoch:  646        6 Batch loss: 0.128518 Batch F1: 0.8571428571428572
Epoch:  646        7 Batch loss: 0.197138 Batch F1: 0.5
Epoch:  646        8 Batch loss: 0.181127 Batch F1: 0.7307692307692308
Epoch:  646        9 Batch loss: 0.137249 Batch F1: 0.7906976744186046
Epoch:  646       10 Batch loss: 0.172380 Batch F1: 0.6666666666666665
Epoch:  646       11 Batch loss: 0.142150 Batch F1: 0.7368421052631577
Epoch:  646       12 Batch loss: 0.147058 Batch F1: 0.7777777777777778
Train Avg Loss  646: 0.169474

Train Avg F1  646: 0.712976362123169

Val Avg Loss  646: 0.182098

Val Avg F1  646:  0.6752105406626829

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 647
--------------------------------------------------------------
Epoch:  647        1 Batch loss: 0.172003 Batch F1: 0.588235294117647
Epoch:  647        2 Batch loss: 0.167525 Batch F1: 0.7391304347826088
Epoch:  647        3 Batch loss: 0.202187 Batch F1: 0.6938775510204083
Epoch:  647        4 Batch loss: 0.160885 Batch F1: 0.7659574468085107
Epoch:  647        5 Batch loss: 0.166842 Batch F1: 0.7317073170731707
Epoch:  647        6 Batch loss: 0.185436 Batch F1: 0.5641025641025641
Epoch:  647        7 Batch loss: 0.174361 Batch F1: 0.6829268292682926
Epoch:  647        8 Batch loss: 0.175251 Batch F1: 0.6818181818181819
Epoch:  647        9 Batch loss: 0.152794 Batch F1: 0.8333333333333333
Epoch:  647       10 Batch loss: 0.152626 Batch F1: 0.8148148148148148
Epoch:  647       11 Batch loss: 0.158007 Batch F1: 0.7659574468085107
Epoch:  647       12 Batch loss: 0.184873 Batch F1: 0.6666666666666665
Train Avg Loss  647: 0.171066

Train Avg F1  647: 0.7107106567178924

Val Avg Loss  647: 0.181945

Val Avg F1  647:  0.6799593355128613

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 648
--------------------------------------------------------------
Epoch:  648        1 Batch loss: 0.213531 Batch F1: 0.6274509803921569
Epoch:  648        2 Batch loss: 0.153628 Batch F1: 0.7804878048780488
Epoch:  648        3 Batch loss: 0.138635 Batch F1: 0.8333333333333333
Epoch:  648        4 Batch loss: 0.168686 Batch F1: 0.7659574468085107
Epoch:  648        5 Batch loss: 0.196788 Batch F1: 0.5853658536585366
Epoch:  648        6 Batch loss: 0.164478 Batch F1: 0.6842105263157895
Epoch:  648        7 Batch loss: 0.157134 Batch F1: 0.7027027027027027
Epoch:  648        8 Batch loss: 0.187338 Batch F1: 0.76
Epoch:  648        9 Batch loss: 0.153423 Batch F1: 0.8181818181818182
Epoch:  648       10 Batch loss: 0.171615 Batch F1: 0.7659574468085107
Epoch:  648       11 Batch loss: 0.187039 Batch F1: 0.6341463414634148
Epoch:  648       12 Batch loss: 0.202433 Batch F1: 0.7777777777777779
Train Avg Loss  648: 0.174561

Train Avg F1  648: 0.7279643360267167

Val Avg Loss  648: 0.183953

Val Avg F1  648:  0.6926306241387594

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 649
--------------------------------------------------------------
Epoch:  649        1 Batch loss: 0.189659 Batch F1: 0.7407407407407408
Epoch:  649        2 Batch loss: 0.154735 Batch F1: 0.7619047619047621
Epoch:  649        3 Batch loss: 0.151960 Batch F1: 0.717948717948718
Epoch:  649        4 Batch loss: 0.176007 Batch F1: 0.7346938775510203
Epoch:  649        5 Batch loss: 0.183825 Batch F1: 0.6666666666666667
Epoch:  649        6 Batch loss: 0.156793 Batch F1: 0.76
Epoch:  649        7 Batch loss: 0.146291 Batch F1: 0.8085106382978723
Epoch:  649        8 Batch loss: 0.165229 Batch F1: 0.6111111111111112
Epoch:  649        9 Batch loss: 0.220135 Batch F1: 0.5909090909090909
Epoch:  649       10 Batch loss: 0.160826 Batch F1: 0.8260869565217391
Epoch:  649       11 Batch loss: 0.176762 Batch F1: 0.6666666666666667
Epoch:  649       12 Batch loss: 0.207841 Batch F1: 0.6666666666666666
Train Avg Loss  649: 0.174172

Train Avg F1  649: 0.7126588245820878

Val Avg Loss  649: 0.183178

Val Avg F1  649:  0.6853566426570629

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 650
--------------------------------------------------------------
Epoch:  650        1 Batch loss: 0.168366 Batch F1: 0.7777777777777778
Epoch:  650        2 Batch loss: 0.179412 Batch F1: 0.631578947368421
Epoch:  650        3 Batch loss: 0.173859 Batch F1: 0.72
Epoch:  650        4 Batch loss: 0.162505 Batch F1: 0.8076923076923077
Epoch:  650        5 Batch loss: 0.190061 Batch F1: 0.6363636363636365
Epoch:  650        6 Batch loss: 0.160592 Batch F1: 0.7647058823529412
Epoch:  650        7 Batch loss: 0.209760 Batch F1: 0.5238095238095238
Epoch:  650        8 Batch loss: 0.189635 Batch F1: 0.6808510638297872
Epoch:  650        9 Batch loss: 0.180150 Batch F1: 0.8214285714285714
Epoch:  650       10 Batch loss: 0.150378 Batch F1: 0.8444444444444444
Epoch:  650       11 Batch loss: 0.187018 Batch F1: 0.7391304347826089
Epoch:  650       12 Batch loss: 0.141621 Batch F1: 0.7741935483870969
Train Avg Loss  650: 0.174446

Train Avg F1  650: 0.726831344853093

Val Avg Loss  650: 0.183265

Val Avg F1  650:  0.6867491182519518

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 651
--------------------------------------------------------------
Epoch:  651        1 Batch loss: 0.177866 Batch F1: 0.5882352941176471
Epoch:  651        2 Batch loss: 0.170960 Batch F1: 0.8000000000000002
Epoch:  651        3 Batch loss: 0.175191 Batch F1: 0.7450980392156863
Epoch:  651        4 Batch loss: 0.174157 Batch F1: 0.7234042553191489
Epoch:  651        5 Batch loss: 0.157109 Batch F1: 0.7317073170731706
Epoch:  651        6 Batch loss: 0.182635 Batch F1: 0.7272727272727272
Epoch:  651        7 Batch loss: 0.199122 Batch F1: 0.7906976744186047
Epoch:  651        8 Batch loss: 0.189730 Batch F1: 0.7843137254901961
Epoch:  651        9 Batch loss: 0.172478 Batch F1: 0.7555555555555555
Epoch:  651       10 Batch loss: 0.179596 Batch F1: 0.6666666666666666
Epoch:  651       11 Batch loss: 0.153882 Batch F1: 0.7027027027027027
Epoch:  651       12 Batch loss: 0.147511 Batch F1: 0.8421052631578947
Train Avg Loss  651: 0.173353

Train Avg F1  651: 0.7381466017491668

Val Avg Loss  651: 0.190098

Val Avg F1  651:  0.678861681894027

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 652
--------------------------------------------------------------
Epoch:  652        1 Batch loss: 0.199254 Batch F1: 0.6666666666666666
Epoch:  652        2 Batch loss: 0.177875 Batch F1: 0.5789473684210527
Epoch:  652        3 Batch loss: 0.158667 Batch F1: 0.7555555555555556
Epoch:  652        4 Batch loss: 0.154981 Batch F1: 0.7826086956521738
Epoch:  652        5 Batch loss: 0.164571 Batch F1: 0.7843137254901961
Epoch:  652        6 Batch loss: 0.163957 Batch F1: 0.6956521739130435
Epoch:  652        7 Batch loss: 0.162808 Batch F1: 0.7391304347826088
Epoch:  652        8 Batch loss: 0.178916 Batch F1: 0.6666666666666666
Epoch:  652        9 Batch loss: 0.170115 Batch F1: 0.761904761904762
Epoch:  652       10 Batch loss: 0.177595 Batch F1: 0.6976744186046512
Epoch:  652       11 Batch loss: 0.193520 Batch F1: 0.6222222222222222
Epoch:  652       12 Batch loss: 0.183964 Batch F1: 0.7027027027027026
Train Avg Loss  652: 0.173852

Train Avg F1  652: 0.7045037827151918

Val Avg Loss  652: 0.183344

Val Avg F1  652:  0.6980529094947151

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 653
--------------------------------------------------------------
Epoch:  653        1 Batch loss: 0.181665 Batch F1: 0.6818181818181818
Epoch:  653        2 Batch loss: 0.140790 Batch F1: 0.8
Epoch:  653        3 Batch loss: 0.158106 Batch F1: 0.7499999999999999
Epoch:  653        4 Batch loss: 0.165117 Batch F1: 0.7777777777777777
Epoch:  653        5 Batch loss: 0.175562 Batch F1: 0.7547169811320755
Epoch:  653        6 Batch loss: 0.150440 Batch F1: 0.7755102040816326
Epoch:  653        7 Batch loss: 0.192565 Batch F1: 0.6
Epoch:  653        8 Batch loss: 0.210580 Batch F1: 0.5777777777777778
Epoch:  653        9 Batch loss: 0.149578 Batch F1: 0.8181818181818181
Epoch:  653       10 Batch loss: 0.195405 Batch F1: 0.5714285714285714
Epoch:  653       11 Batch loss: 0.158873 Batch F1: 0.7727272727272727
Epoch:  653       12 Batch loss: 0.169543 Batch F1: 0.625
Train Avg Loss  653: 0.170685

Train Avg F1  653: 0.7087448820770922

Val Avg Loss  653: 0.185835

Val Avg F1  653:  0.6640285382445662

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 654
--------------------------------------------------------------
Epoch:  654        1 Batch loss: 0.142972 Batch F1: 0.8095238095238095
Epoch:  654        2 Batch loss: 0.167520 Batch F1: 0.6842105263157895
Epoch:  654        3 Batch loss: 0.201023 Batch F1: 0.588235294117647
Epoch:  654        4 Batch loss: 0.158783 Batch F1: 0.8292682926829268
Epoch:  654        5 Batch loss: 0.196357 Batch F1: 0.5789473684210527
Epoch:  654        6 Batch loss: 0.205940 Batch F1: 0.6122448979591837
Epoch:  654        7 Batch loss: 0.179329 Batch F1: 0.8253968253968254
Epoch:  654        8 Batch loss: 0.156403 Batch F1: 0.9019607843137255
Epoch:  654        9 Batch loss: 0.185441 Batch F1: 0.6976744186046512
Epoch:  654       10 Batch loss: 0.139059 Batch F1: 0.7500000000000001
Epoch:  654       11 Batch loss: 0.189798 Batch F1: 0.5
Epoch:  654       12 Batch loss: 0.160184 Batch F1: 0.7894736842105263
Train Avg Loss  654: 0.173567

Train Avg F1  654: 0.7139113251288448

Val Avg Loss  654: 0.183835

Val Avg F1  654:  0.676858223909719

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 655
--------------------------------------------------------------
Epoch:  655        1 Batch loss: 0.174684 Batch F1: 0.5945945945945945
Epoch:  655        2 Batch loss: 0.182628 Batch F1: 0.8076923076923077
Epoch:  655        3 Batch loss: 0.151501 Batch F1: 0.9285714285714286
Epoch:  655        4 Batch loss: 0.139110 Batch F1: 0.8571428571428571
Epoch:  655        5 Batch loss: 0.170711 Batch F1: 0.7692307692307693
Epoch:  655        6 Batch loss: 0.192772 Batch F1: 0.5853658536585366
Epoch:  655        7 Batch loss: 0.167756 Batch F1: 0.7272727272727273
Epoch:  655        8 Batch loss: 0.177055 Batch F1: 0.7391304347826088
Epoch:  655        9 Batch loss: 0.152035 Batch F1: 0.816326530612245
Epoch:  655       10 Batch loss: 0.178594 Batch F1: 0.7547169811320754
Epoch:  655       11 Batch loss: 0.172827 Batch F1: 0.6153846153846153
Epoch:  655       12 Batch loss: 0.212904 Batch F1: 0.5294117647058824
Train Avg Loss  655: 0.172715

Train Avg F1  655: 0.7270700720650539

Val Avg Loss  655: 0.181196

Val Avg F1  655:  0.701198026779422

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 656
--------------------------------------------------------------
Epoch:  656        1 Batch loss: 0.173956 Batch F1: 0.6363636363636364
Epoch:  656        2 Batch loss: 0.172546 Batch F1: 0.8135593220338982
Epoch:  656        3 Batch loss: 0.167587 Batch F1: 0.8181818181818182
Epoch:  656        4 Batch loss: 0.152678 Batch F1: 0.8181818181818182
Epoch:  656        5 Batch loss: 0.202024 Batch F1: 0.5909090909090909
Epoch:  656        6 Batch loss: 0.155105 Batch F1: 0.8235294117647058
Epoch:  656        7 Batch loss: 0.179038 Batch F1: 0.7500000000000001
Epoch:  656        8 Batch loss: 0.157540 Batch F1: 0.7804878048780488
Epoch:  656        9 Batch loss: 0.181647 Batch F1: 0.5789473684210527
Epoch:  656       10 Batch loss: 0.159487 Batch F1: 0.7804878048780488
Epoch:  656       11 Batch loss: 0.173050 Batch F1: 0.6857142857142857
Epoch:  656       12 Batch loss: 0.190146 Batch F1: 0.5806451612903225
Train Avg Loss  656: 0.172067

Train Avg F1  656: 0.7214172935513937

Val Avg Loss  656: 0.185178

Val Avg F1  656:  0.6940489742815323

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 657
--------------------------------------------------------------
Epoch:  657        1 Batch loss: 0.170637 Batch F1: 0.7272727272727272
Epoch:  657        2 Batch loss: 0.177835 Batch F1: 0.6190476190476191
Epoch:  657        3 Batch loss: 0.179795 Batch F1: 0.75
Epoch:  657        4 Batch loss: 0.202183 Batch F1: 0.68
Epoch:  657        5 Batch loss: 0.172398 Batch F1: 0.7234042553191491
Epoch:  657        6 Batch loss: 0.185747 Batch F1: 0.6923076923076924
Epoch:  657        7 Batch loss: 0.176081 Batch F1: 0.6976744186046512
Epoch:  657        8 Batch loss: 0.181939 Batch F1: 0.7083333333333333
Epoch:  657        9 Batch loss: 0.154061 Batch F1: 0.8095238095238095
Epoch:  657       10 Batch loss: 0.146300 Batch F1: 0.7894736842105263
Epoch:  657       11 Batch loss: 0.183285 Batch F1: 0.5714285714285714
Epoch:  657       12 Batch loss: 0.162797 Batch F1: 0.8205128205128205
Train Avg Loss  657: 0.174421

Train Avg F1  657: 0.7157482442967417

Val Avg Loss  657: 0.187352

Val Avg F1  657:  0.6577683452683453

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 658
--------------------------------------------------------------
Epoch:  658        1 Batch loss: 0.170276 Batch F1: 0.6666666666666665
Epoch:  658        2 Batch loss: 0.176007 Batch F1: 0.711111111111111
Epoch:  658        3 Batch loss: 0.170146 Batch F1: 0.65
Epoch:  658        4 Batch loss: 0.166294 Batch F1: 0.6060606060606061
Epoch:  658        5 Batch loss: 0.208690 Batch F1: 0.6222222222222223
Epoch:  658        6 Batch loss: 0.158223 Batch F1: 0.7659574468085107
Epoch:  658        7 Batch loss: 0.176147 Batch F1: 0.6818181818181818
Epoch:  658        8 Batch loss: 0.144811 Batch F1: 0.7692307692307692
Epoch:  658        9 Batch loss: 0.154178 Batch F1: 0.8636363636363636
Epoch:  658       10 Batch loss: 0.188795 Batch F1: 0.7450980392156864
Epoch:  658       11 Batch loss: 0.197929 Batch F1: 0.6909090909090909
Epoch:  658       12 Batch loss: 0.143648 Batch F1: 0.7727272727272727
Train Avg Loss  658: 0.171262

Train Avg F1  658: 0.7121198142005402

Val Avg Loss  658: 0.190738

Val Avg F1  658:  0.7331352260928716

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 659
--------------------------------------------------------------
Epoch:  659        1 Batch loss: 0.136334 Batch F1: 0.8852459016393442
Epoch:  659        2 Batch loss: 0.158220 Batch F1: 0.7843137254901961
Epoch:  659        3 Batch loss: 0.179980 Batch F1: 0.6976744186046512
Epoch:  659        4 Batch loss: 0.183888 Batch F1: 0.5714285714285715
Epoch:  659        5 Batch loss: 0.176054 Batch F1: 0.5945945945945945
Epoch:  659        6 Batch loss: 0.170367 Batch F1: 0.761904761904762
Epoch:  659        7 Batch loss: 0.156915 Batch F1: 0.7619047619047619
Epoch:  659        8 Batch loss: 0.168355 Batch F1: 0.7346938775510203
Epoch:  659        9 Batch loss: 0.214526 Batch F1: 0.5833333333333334
Epoch:  659       10 Batch loss: 0.148802 Batch F1: 0.7222222222222223
Epoch:  659       11 Batch loss: 0.192508 Batch F1: 0.7058823529411765
Epoch:  659       12 Batch loss: 0.192423 Batch F1: 0.6818181818181818
Train Avg Loss  659: 0.173198

Train Avg F1  659: 0.707084725286068

Val Avg Loss  659: 0.185197

Val Avg F1  659:  0.6694120256620256

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 660
--------------------------------------------------------------
Epoch:  660        1 Batch loss: 0.180674 Batch F1: 0.6341463414634146
Epoch:  660        2 Batch loss: 0.164089 Batch F1: 0.7317073170731706
Epoch:  660        3 Batch loss: 0.187329 Batch F1: 0.6363636363636365
Epoch:  660        4 Batch loss: 0.173473 Batch F1: 0.72
Epoch:  660        5 Batch loss: 0.155942 Batch F1: 0.782608695652174
Epoch:  660        6 Batch loss: 0.176403 Batch F1: 0.7346938775510204
Epoch:  660        7 Batch loss: 0.165419 Batch F1: 0.7272727272727272
Epoch:  660        8 Batch loss: 0.168689 Batch F1: 0.6976744186046512
Epoch:  660        9 Batch loss: 0.185534 Batch F1: 0.7307692307692307
Epoch:  660       10 Batch loss: 0.175748 Batch F1: 0.6153846153846154
Epoch:  660       11 Batch loss: 0.160141 Batch F1: 0.7659574468085107
Epoch:  660       12 Batch loss: 0.142781 Batch F1: 0.7741935483870968
Train Avg Loss  660: 0.169685

Train Avg F1  660: 0.7125643212775206

Val Avg Loss  660: 0.181158

Val Avg F1  660:  0.6811572392319667

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 661
--------------------------------------------------------------
Epoch:  661        1 Batch loss: 0.189571 Batch F1: 0.68
Epoch:  661        2 Batch loss: 0.150677 Batch F1: 0.7999999999999999
Epoch:  661        3 Batch loss: 0.157402 Batch F1: 0.7659574468085107
Epoch:  661        4 Batch loss: 0.165857 Batch F1: 0.6829268292682926
Epoch:  661        5 Batch loss: 0.194238 Batch F1: 0.6153846153846154
Epoch:  661        6 Batch loss: 0.183588 Batch F1: 0.7450980392156864
Epoch:  661        7 Batch loss: 0.188282 Batch F1: 0.7058823529411765
Epoch:  661        8 Batch loss: 0.136680 Batch F1: 0.88
Epoch:  661        9 Batch loss: 0.167247 Batch F1: 0.631578947368421
Epoch:  661       10 Batch loss: 0.142002 Batch F1: 0.7777777777777778
Epoch:  661       11 Batch loss: 0.190915 Batch F1: 0.6341463414634148
Epoch:  661       12 Batch loss: 0.176163 Batch F1: 0.5185185185185185
Train Avg Loss  661: 0.170218

Train Avg F1  661: 0.7031059057288679

Val Avg Loss  661: 0.184508

Val Avg F1  661:  0.6422934704184705

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 662
--------------------------------------------------------------
Epoch:  662        1 Batch loss: 0.177091 Batch F1: 0.5806451612903226
Epoch:  662        2 Batch loss: 0.174609 Batch F1: 0.7000000000000001
Epoch:  662        3 Batch loss: 0.145083 Batch F1: 0.8636363636363635
Epoch:  662        4 Batch loss: 0.193338 Batch F1: 0.6666666666666666
Epoch:  662        5 Batch loss: 0.155556 Batch F1: 0.7906976744186046
Epoch:  662        6 Batch loss: 0.191018 Batch F1: 0.6341463414634146
Epoch:  662        7 Batch loss: 0.168488 Batch F1: 0.7083333333333333
Epoch:  662        8 Batch loss: 0.184936 Batch F1: 0.7037037037037037
Epoch:  662        9 Batch loss: 0.170230 Batch F1: 0.8000000000000002
Epoch:  662       10 Batch loss: 0.157493 Batch F1: 0.8205128205128205
Epoch:  662       11 Batch loss: 0.147496 Batch F1: 0.8571428571428572
Epoch:  662       12 Batch loss: 0.171700 Batch F1: 0.7999999999999999
Train Avg Loss  662: 0.169753

Train Avg F1  662: 0.7437904101806739

Val Avg Loss  662: 0.181222

Val Avg F1  662:  0.673003037488348

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 663
--------------------------------------------------------------
Epoch:  663        1 Batch loss: 0.157957 Batch F1: 0.7027027027027027
Epoch:  663        2 Batch loss: 0.179961 Batch F1: 0.6956521739130435
Epoch:  663        3 Batch loss: 0.154209 Batch F1: 0.8085106382978724
Epoch:  663        4 Batch loss: 0.177067 Batch F1: 0.5945945945945946
Epoch:  663        5 Batch loss: 0.206931 Batch F1: 0.5714285714285715
Epoch:  663        6 Batch loss: 0.173095 Batch F1: 0.6976744186046512
Epoch:  663        7 Batch loss: 0.167571 Batch F1: 0.7142857142857143
Epoch:  663        8 Batch loss: 0.174200 Batch F1: 0.7083333333333333
Epoch:  663        9 Batch loss: 0.150940 Batch F1: 0.7317073170731706
Epoch:  663       10 Batch loss: 0.174078 Batch F1: 0.7346938775510203
Epoch:  663       11 Batch loss: 0.152318 Batch F1: 0.7441860465116279
Epoch:  663       12 Batch loss: 0.146732 Batch F1: 0.8837209302325582
Train Avg Loss  663: 0.167922

Train Avg F1  663: 0.7156241932107384

Val Avg Loss  663: 0.180159

Val Avg F1  663:  0.6755021482277122

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 664
--------------------------------------------------------------
Epoch:  664        1 Batch loss: 0.203198 Batch F1: 0.64
Epoch:  664        2 Batch loss: 0.201128 Batch F1: 0.55
Epoch:  664        3 Batch loss: 0.155818 Batch F1: 0.6842105263157896
Epoch:  664        4 Batch loss: 0.151354 Batch F1: 0.816326530612245
Epoch:  664        5 Batch loss: 0.172649 Batch F1: 0.6046511627906976
Epoch:  664        6 Batch loss: 0.149375 Batch F1: 0.7906976744186046
Epoch:  664        7 Batch loss: 0.198214 Batch F1: 0.6363636363636364
Epoch:  664        8 Batch loss: 0.148648 Batch F1: 0.7804878048780488
Epoch:  664        9 Batch loss: 0.171997 Batch F1: 0.7450980392156863
Epoch:  664       10 Batch loss: 0.163342 Batch F1: 0.6829268292682926
Epoch:  664       11 Batch loss: 0.171283 Batch F1: 0.7547169811320754
Epoch:  664       12 Batch loss: 0.131734 Batch F1: 0.8749999999999999
Train Avg Loss  664: 0.168228

Train Avg F1  664: 0.7133732654162563

Val Avg Loss  664: 0.181013

Val Avg F1  664:  0.6820952771352444

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 665
--------------------------------------------------------------
Epoch:  665        1 Batch loss: 0.169675 Batch F1: 0.6511627906976745
Epoch:  665        2 Batch loss: 0.138219 Batch F1: 0.851063829787234
Epoch:  665        3 Batch loss: 0.125076 Batch F1: 0.8846153846153847
Epoch:  665        4 Batch loss: 0.161687 Batch F1: 0.7142857142857143
Epoch:  665        5 Batch loss: 0.165576 Batch F1: 0.7317073170731706
Epoch:  665        6 Batch loss: 0.186206 Batch F1: 0.6666666666666666
Epoch:  665        7 Batch loss: 0.146009 Batch F1: 0.823529411764706
Epoch:  665        8 Batch loss: 0.185292 Batch F1: 0.6046511627906976
Epoch:  665        9 Batch loss: 0.187662 Batch F1: 0.6938775510204083
Epoch:  665       10 Batch loss: 0.177302 Batch F1: 0.6500000000000001
Epoch:  665       11 Batch loss: 0.202687 Batch F1: 0.5641025641025642
Epoch:  665       12 Batch loss: 0.152083 Batch F1: 0.8108108108108109
Train Avg Loss  665: 0.166456

Train Avg F1  665: 0.7205394336345861

Val Avg Loss  665: 0.180166

Val Avg F1  665:  0.6899110908883299

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 666
--------------------------------------------------------------
Epoch:  666        1 Batch loss: 0.120058 Batch F1: 0.823529411764706
Epoch:  666        2 Batch loss: 0.158756 Batch F1: 0.761904761904762
Epoch:  666        3 Batch loss: 0.156201 Batch F1: 0.8181818181818182
Epoch:  666        4 Batch loss: 0.150243 Batch F1: 0.7906976744186046
Epoch:  666        5 Batch loss: 0.208887 Batch F1: 0.5454545454545454
Epoch:  666        6 Batch loss: 0.206903 Batch F1: 0.5833333333333334
Epoch:  666        7 Batch loss: 0.185482 Batch F1: 0.7368421052631577
Epoch:  666        8 Batch loss: 0.174923 Batch F1: 0.5625
Epoch:  666        9 Batch loss: 0.154698 Batch F1: 0.7317073170731706
Epoch:  666       10 Batch loss: 0.173939 Batch F1: 0.6956521739130435
Epoch:  666       11 Batch loss: 0.175410 Batch F1: 0.7777777777777779
Epoch:  666       12 Batch loss: 0.152681 Batch F1: 0.7567567567567567
Train Avg Loss  666: 0.168182

Train Avg F1  666: 0.7153614729868063

Val Avg Loss  666: 0.181535

Val Avg F1  666:  0.6694414607948442

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 667
--------------------------------------------------------------
Epoch:  667        1 Batch loss: 0.163641 Batch F1: 0.6666666666666667
Epoch:  667        2 Batch loss: 0.205144 Batch F1: 0.6399999999999999
Epoch:  667        3 Batch loss: 0.131209 Batch F1: 0.85
Epoch:  667        4 Batch loss: 0.168690 Batch F1: 0.7500000000000001
Epoch:  667        5 Batch loss: 0.173797 Batch F1: 0.7111111111111111
Epoch:  667        6 Batch loss: 0.168599 Batch F1: 0.6956521739130435
Epoch:  667        7 Batch loss: 0.177808 Batch F1: 0.5789473684210527
Epoch:  667        8 Batch loss: 0.160671 Batch F1: 0.7555555555555555
Epoch:  667        9 Batch loss: 0.157260 Batch F1: 0.7843137254901961
Epoch:  667       10 Batch loss: 0.166958 Batch F1: 0.6829268292682926
Epoch:  667       11 Batch loss: 0.163610 Batch F1: 0.7916666666666666
Epoch:  667       12 Batch loss: 0.172218 Batch F1: 0.6486486486486486
Train Avg Loss  667: 0.167467

Train Avg F1  667: 0.7129573954784362

Val Avg Loss  667: 0.178974

Val Avg F1  667:  0.6884142804408585

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 668
--------------------------------------------------------------
Epoch:  668        1 Batch loss: 0.148266 Batch F1: 0.8363636363636363
Epoch:  668        2 Batch loss: 0.161589 Batch F1: 0.6666666666666667
Epoch:  668        3 Batch loss: 0.149526 Batch F1: 0.7500000000000001
Epoch:  668        4 Batch loss: 0.152608 Batch F1: 0.7027027027027026
Epoch:  668        5 Batch loss: 0.179735 Batch F1: 0.7407407407407408
Epoch:  668        6 Batch loss: 0.198125 Batch F1: 0.6222222222222222
Epoch:  668        7 Batch loss: 0.166261 Batch F1: 0.7599999999999999
Epoch:  668        8 Batch loss: 0.180810 Batch F1: 0.6666666666666667
Epoch:  668        9 Batch loss: 0.173918 Batch F1: 0.6341463414634146
Epoch:  668       10 Batch loss: 0.157184 Batch F1: 0.7659574468085106
Epoch:  668       11 Batch loss: 0.179446 Batch F1: 0.68
Epoch:  668       12 Batch loss: 0.153588 Batch F1: 0.75
Train Avg Loss  668: 0.166755

Train Avg F1  668: 0.7146222019695466

Val Avg Loss  668: 0.179452

Val Avg F1  668:  0.7359965730203237

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 669
--------------------------------------------------------------
Epoch:  669        1 Batch loss: 0.167085 Batch F1: 0.7142857142857143
Epoch:  669        2 Batch loss: 0.170742 Batch F1: 0.6956521739130435
Epoch:  669        3 Batch loss: 0.185048 Batch F1: 0.75
Epoch:  669        4 Batch loss: 0.175777 Batch F1: 0.7857142857142857
Epoch:  669        5 Batch loss: 0.172711 Batch F1: 0.7916666666666667
Epoch:  669        6 Batch loss: 0.154029 Batch F1: 0.787878787878788
Epoch:  669        7 Batch loss: 0.141288 Batch F1: 0.8648648648648648
Epoch:  669        8 Batch loss: 0.184205 Batch F1: 0.6521739130434783
Epoch:  669        9 Batch loss: 0.144719 Batch F1: 0.7555555555555556
Epoch:  669       10 Batch loss: 0.177324 Batch F1: 0.6818181818181819
Epoch:  669       11 Batch loss: 0.185508 Batch F1: 0.6666666666666666
Epoch:  669       12 Batch loss: 0.165994 Batch F1: 0.7906976744186046
Train Avg Loss  669: 0.168703

Train Avg F1  669: 0.7447478737354875

Val Avg Loss  669: 0.179530

Val Avg F1  669:  0.6923153235653235

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 670
--------------------------------------------------------------
Epoch:  670        1 Batch loss: 0.172223 Batch F1: 0.6808510638297872
Epoch:  670        2 Batch loss: 0.184985 Batch F1: 0.7142857142857143
Epoch:  670        3 Batch loss: 0.145421 Batch F1: 0.851063829787234
Epoch:  670        4 Batch loss: 0.134923 Batch F1: 0.823529411764706
Epoch:  670        5 Batch loss: 0.140902 Batch F1: 0.8627450980392156
Epoch:  670        6 Batch loss: 0.167342 Batch F1: 0.6976744186046512
Epoch:  670        7 Batch loss: 0.207223 Batch F1: 0.6666666666666666
Epoch:  670        8 Batch loss: 0.211241 Batch F1: 0.6808510638297872
Epoch:  670        9 Batch loss: 0.183928 Batch F1: 0.6666666666666666
Epoch:  670       10 Batch loss: 0.170204 Batch F1: 0.7659574468085107
Epoch:  670       11 Batch loss: 0.159962 Batch F1: 0.7441860465116279
Epoch:  670       12 Batch loss: 0.169421 Batch F1: 0.7567567567567567
Train Avg Loss  670: 0.170648

Train Avg F1  670: 0.742602848629277

Val Avg Loss  670: 0.182807

Val Avg F1  670:  0.6734385110189167

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 671
--------------------------------------------------------------
Epoch:  671        1 Batch loss: 0.176548 Batch F1: 0.6956521739130435
Epoch:  671        2 Batch loss: 0.172516 Batch F1: 0.7
Epoch:  671        3 Batch loss: 0.160083 Batch F1: 0.5714285714285715
Epoch:  671        4 Batch loss: 0.172996 Batch F1: 0.6470588235294117
Epoch:  671        5 Batch loss: 0.181563 Batch F1: 0.6111111111111112
Epoch:  671        6 Batch loss: 0.160035 Batch F1: 0.7441860465116279
Epoch:  671        7 Batch loss: 0.177707 Batch F1: 0.7450980392156864
Epoch:  671        8 Batch loss: 0.165742 Batch F1: 0.7999999999999999
Epoch:  671        9 Batch loss: 0.168492 Batch F1: 0.7857142857142857
Epoch:  671       10 Batch loss: 0.173118 Batch F1: 0.7586206896551724
Epoch:  671       11 Batch loss: 0.181321 Batch F1: 0.6956521739130435
Epoch:  671       12 Batch loss: 0.205828 Batch F1: 0.6666666666666666
Train Avg Loss  671: 0.174662

Train Avg F1  671: 0.7017657151382183

Val Avg Loss  671: 0.183174

Val Avg F1  671:  0.7281683543823718

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 672
--------------------------------------------------------------
Epoch:  672        1 Batch loss: 0.190192 Batch F1: 0.7058823529411765
Epoch:  672        2 Batch loss: 0.153045 Batch F1: 0.8727272727272727
Epoch:  672        3 Batch loss: 0.195128 Batch F1: 0.6818181818181818
Epoch:  672        4 Batch loss: 0.155351 Batch F1: 0.7727272727272727
Epoch:  672        5 Batch loss: 0.141211 Batch F1: 0.8260869565217391
Epoch:  672        6 Batch loss: 0.178292 Batch F1: 0.7272727272727272
Epoch:  672        7 Batch loss: 0.176643 Batch F1: 0.7346938775510203
Epoch:  672        8 Batch loss: 0.163973 Batch F1: 0.782608695652174
Epoch:  672        9 Batch loss: 0.158890 Batch F1: 0.7
Epoch:  672       10 Batch loss: 0.180700 Batch F1: 0.6111111111111112
Epoch:  672       11 Batch loss: 0.159173 Batch F1: 0.717948717948718
Epoch:  672       12 Batch loss: 0.170050 Batch F1: 0.7368421052631577
Train Avg Loss  672: 0.168554

Train Avg F1  672: 0.7391432726278793

Val Avg Loss  672: 0.181157

Val Avg F1  672:  0.6761469924205774

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 673
--------------------------------------------------------------
Epoch:  673        1 Batch loss: 0.167437 Batch F1: 0.76
Epoch:  673        2 Batch loss: 0.207663 Batch F1: 0.6250000000000001
Epoch:  673        3 Batch loss: 0.138371 Batch F1: 0.7777777777777778
Epoch:  673        4 Batch loss: 0.176500 Batch F1: 0.5161290322580645
Epoch:  673        5 Batch loss: 0.141512 Batch F1: 0.7222222222222222
Epoch:  673        6 Batch loss: 0.186146 Batch F1: 0.7450980392156864
Epoch:  673        7 Batch loss: 0.176564 Batch F1: 0.75
Epoch:  673        8 Batch loss: 0.182997 Batch F1: 0.6666666666666666
Epoch:  673        9 Batch loss: 0.157372 Batch F1: 0.6842105263157895
Epoch:  673       10 Batch loss: 0.162100 Batch F1: 0.7346938775510203
Epoch:  673       11 Batch loss: 0.170012 Batch F1: 0.7111111111111111
Epoch:  673       12 Batch loss: 0.141814 Batch F1: 0.8749999999999999
Train Avg Loss  673: 0.167374

Train Avg F1  673: 0.7139924377598615

Val Avg Loss  673: 0.179129

Val Avg F1  673:  0.684735142118863

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 674
--------------------------------------------------------------
Epoch:  674        1 Batch loss: 0.159657 Batch F1: 0.6976744186046512
Epoch:  674        2 Batch loss: 0.205224 Batch F1: 0.6909090909090909
Epoch:  674        3 Batch loss: 0.140234 Batch F1: 0.8333333333333333
Epoch:  674        4 Batch loss: 0.164728 Batch F1: 0.8
Epoch:  674        5 Batch loss: 0.153882 Batch F1: 0.8333333333333333
Epoch:  674        6 Batch loss: 0.162111 Batch F1: 0.6829268292682927
Epoch:  674        7 Batch loss: 0.196068 Batch F1: 0.6399999999999999
Epoch:  674        8 Batch loss: 0.165218 Batch F1: 0.8333333333333334
Epoch:  674        9 Batch loss: 0.185125 Batch F1: 0.75
Epoch:  674       10 Batch loss: 0.160347 Batch F1: 0.7500000000000001
Epoch:  674       11 Batch loss: 0.152442 Batch F1: 0.7428571428571428
Epoch:  674       12 Batch loss: 0.165075 Batch F1: 0.782608695652174
Train Avg Loss  674: 0.167509

Train Avg F1  674: 0.7530813481076124

Val Avg Loss  674: 0.180865

Val Avg F1  674:  0.6884067152359836

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 675
--------------------------------------------------------------
Epoch:  675        1 Batch loss: 0.169231 Batch F1: 0.6111111111111112
Epoch:  675        2 Batch loss: 0.141156 Batch F1: 0.7804878048780488
Epoch:  675        3 Batch loss: 0.185806 Batch F1: 0.6938775510204083
Epoch:  675        4 Batch loss: 0.144737 Batch F1: 0.717948717948718
Epoch:  675        5 Batch loss: 0.161644 Batch F1: 0.7368421052631577
Epoch:  675        6 Batch loss: 0.184553 Batch F1: 0.7272727272727274
Epoch:  675        7 Batch loss: 0.195834 Batch F1: 0.7142857142857142
Epoch:  675        8 Batch loss: 0.170582 Batch F1: 0.6976744186046512
Epoch:  675        9 Batch loss: 0.173997 Batch F1: 0.711111111111111
Epoch:  675       10 Batch loss: 0.209238 Batch F1: 0.6909090909090909
Epoch:  675       11 Batch loss: 0.133331 Batch F1: 0.85
Epoch:  675       12 Batch loss: 0.144841 Batch F1: 0.7333333333333334
Train Avg Loss  675: 0.167913

Train Avg F1  675: 0.7220711404781728

Val Avg Loss  675: 0.180694

Val Avg F1  675:  0.6779568620593892

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 676
--------------------------------------------------------------
Epoch:  676        1 Batch loss: 0.170934 Batch F1: 0.6666666666666666
Epoch:  676        2 Batch loss: 0.178209 Batch F1: 0.6956521739130435
Epoch:  676        3 Batch loss: 0.146666 Batch F1: 0.7500000000000001
Epoch:  676        4 Batch loss: 0.147852 Batch F1: 0.744186046511628
Epoch:  676        5 Batch loss: 0.140253 Batch F1: 0.8292682926829269
Epoch:  676        6 Batch loss: 0.198581 Batch F1: 0.6382978723404256
Epoch:  676        7 Batch loss: 0.162530 Batch F1: 0.6829268292682926
Epoch:  676        8 Batch loss: 0.172930 Batch F1: 0.7307692307692308
Epoch:  676        9 Batch loss: 0.170436 Batch F1: 0.7083333333333333
Epoch:  676       10 Batch loss: 0.165985 Batch F1: 0.8085106382978724
Epoch:  676       11 Batch loss: 0.183302 Batch F1: 0.6666666666666665
Epoch:  676       12 Batch loss: 0.171179 Batch F1: 0.6666666666666667
Train Avg Loss  676: 0.167405

Train Avg F1  676: 0.7156620347597293

Val Avg Loss  676: 0.179773

Val Avg F1  676:  0.6867327117327118

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 677
--------------------------------------------------------------
Epoch:  677        1 Batch loss: 0.166963 Batch F1: 0.75
Epoch:  677        2 Batch loss: 0.176831 Batch F1: 0.6976744186046512
Epoch:  677        3 Batch loss: 0.162883 Batch F1: 0.65
Epoch:  677        4 Batch loss: 0.160051 Batch F1: 0.7000000000000001
Epoch:  677        5 Batch loss: 0.170593 Batch F1: 0.6842105263157895
Epoch:  677        6 Batch loss: 0.169161 Batch F1: 0.7450980392156863
Epoch:  677        7 Batch loss: 0.187449 Batch F1: 0.6046511627906977
Epoch:  677        8 Batch loss: 0.168066 Batch F1: 0.75
Epoch:  677        9 Batch loss: 0.155518 Batch F1: 0.7555555555555556
Epoch:  677       10 Batch loss: 0.189877 Batch F1: 0.6382978723404256
Epoch:  677       11 Batch loss: 0.144759 Batch F1: 0.8627450980392156
Epoch:  677       12 Batch loss: 0.156314 Batch F1: 0.7804878048780488
Train Avg Loss  677: 0.167372

Train Avg F1  677: 0.7182267064783391

Val Avg Loss  677: 0.179745

Val Avg F1  677:  0.7299899714017368

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 678
--------------------------------------------------------------
Epoch:  678        1 Batch loss: 0.159600 Batch F1: 0.7999999999999999
Epoch:  678        2 Batch loss: 0.189087 Batch F1: 0.7346938775510203
Epoch:  678        3 Batch loss: 0.166262 Batch F1: 0.7499999999999999
Epoch:  678        4 Batch loss: 0.170137 Batch F1: 0.7
Epoch:  678        5 Batch loss: 0.149866 Batch F1: 0.8
Epoch:  678        6 Batch loss: 0.164635 Batch F1: 0.65
Epoch:  678        7 Batch loss: 0.199477 Batch F1: 0.6511627906976744
Epoch:  678        8 Batch loss: 0.150163 Batch F1: 0.717948717948718
Epoch:  678        9 Batch loss: 0.153120 Batch F1: 0.8181818181818182
Epoch:  678       10 Batch loss: 0.167743 Batch F1: 0.7555555555555555
Epoch:  678       11 Batch loss: 0.179045 Batch F1: 0.7450980392156863
Epoch:  678       12 Batch loss: 0.186181 Batch F1: 0.6976744186046512
Train Avg Loss  678: 0.169610

Train Avg F1  678: 0.7350262681462604

Val Avg Loss  678: 0.181726

Val Avg F1  678:  0.7035984848484848

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 679
--------------------------------------------------------------
Epoch:  679        1 Batch loss: 0.151767 Batch F1: 0.6666666666666665
Epoch:  679        2 Batch loss: 0.192027 Batch F1: 0.7391304347826089
Epoch:  679        3 Batch loss: 0.133601 Batch F1: 0.888888888888889
Epoch:  679        4 Batch loss: 0.180352 Batch F1: 0.6956521739130435
Epoch:  679        5 Batch loss: 0.147418 Batch F1: 0.8333333333333334
Epoch:  679        6 Batch loss: 0.174859 Batch F1: 0.6976744186046512
Epoch:  679        7 Batch loss: 0.172487 Batch F1: 0.75
Epoch:  679        8 Batch loss: 0.201819 Batch F1: 0.6792452830188679
Epoch:  679        9 Batch loss: 0.168619 Batch F1: 0.5555555555555556
Epoch:  679       10 Batch loss: 0.187487 Batch F1: 0.711111111111111
Epoch:  679       11 Batch loss: 0.145973 Batch F1: 0.8000000000000002
Epoch:  679       12 Batch loss: 0.198097 Batch F1: 0.6315789473684211
Train Avg Loss  679: 0.171209

Train Avg F1  679: 0.7207364011035957

Val Avg Loss  679: 0.178985

Val Avg F1  679:  0.6892310478537449

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 680
--------------------------------------------------------------
Epoch:  680        1 Batch loss: 0.173227 Batch F1: 0.7083333333333334
Epoch:  680        2 Batch loss: 0.188288 Batch F1: 0.6666666666666665
Epoch:  680        3 Batch loss: 0.142464 Batch F1: 0.8510638297872342
Epoch:  680        4 Batch loss: 0.161025 Batch F1: 0.75
Epoch:  680        5 Batch loss: 0.141455 Batch F1: 0.8
Epoch:  680        6 Batch loss: 0.162228 Batch F1: 0.6486486486486486
Epoch:  680        7 Batch loss: 0.181006 Batch F1: 0.7083333333333333
Epoch:  680        8 Batch loss: 0.192175 Batch F1: 0.6666666666666666
Epoch:  680        9 Batch loss: 0.202008 Batch F1: 0.7037037037037037
Epoch:  680       10 Batch loss: 0.157147 Batch F1: 0.6451612903225806
Epoch:  680       11 Batch loss: 0.162740 Batch F1: 0.7777777777777777
Epoch:  680       12 Batch loss: 0.171829 Batch F1: 0.6666666666666666
Train Avg Loss  680: 0.169633

Train Avg F1  680: 0.7160851597422176

Val Avg Loss  680: 0.182140

Val Avg F1  680:  0.6854166666666666

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 681
--------------------------------------------------------------
Epoch:  681        1 Batch loss: 0.184311 Batch F1: 0.5945945945945946
Epoch:  681        2 Batch loss: 0.194097 Batch F1: 0.5789473684210527
Epoch:  681        3 Batch loss: 0.153162 Batch F1: 0.7368421052631577
Epoch:  681        4 Batch loss: 0.145411 Batch F1: 0.8085106382978724
Epoch:  681        5 Batch loss: 0.141443 Batch F1: 0.8085106382978724
Epoch:  681        6 Batch loss: 0.151134 Batch F1: 0.8363636363636363
Epoch:  681        7 Batch loss: 0.172855 Batch F1: 0.7714285714285715
Epoch:  681        8 Batch loss: 0.193929 Batch F1: 0.76
Epoch:  681        9 Batch loss: 0.199283 Batch F1: 0.5777777777777778
Epoch:  681       10 Batch loss: 0.182192 Batch F1: 0.6
Epoch:  681       11 Batch loss: 0.140086 Batch F1: 0.8372093023255814
Epoch:  681       12 Batch loss: 0.186087 Batch F1: 0.625
Train Avg Loss  681: 0.170332

Train Avg F1  681: 0.7112653860641762

Val Avg Loss  681: 0.186458

Val Avg F1  681:  0.6386089400795283

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 682
--------------------------------------------------------------
Epoch:  682        1 Batch loss: 0.157150 Batch F1: 0.7906976744186046
Epoch:  682        2 Batch loss: 0.165358 Batch F1: 0.7027027027027027
Epoch:  682        3 Batch loss: 0.200123 Batch F1: 0.68
Epoch:  682        4 Batch loss: 0.168125 Batch F1: 0.65
Epoch:  682        5 Batch loss: 0.158924 Batch F1: 0.8181818181818182
Epoch:  682        6 Batch loss: 0.164771 Batch F1: 0.8070175438596491
Epoch:  682        7 Batch loss: 0.167538 Batch F1: 0.8363636363636363
Epoch:  682        8 Batch loss: 0.201796 Batch F1: 0.6046511627906977
Epoch:  682        9 Batch loss: 0.182010 Batch F1: 0.6956521739130435
Epoch:  682       10 Batch loss: 0.167172 Batch F1: 0.6153846153846154
Epoch:  682       11 Batch loss: 0.141260 Batch F1: 0.8260869565217391
Epoch:  682       12 Batch loss: 0.167077 Batch F1: 0.6875000000000001
Train Avg Loss  682: 0.170109

Train Avg F1  682: 0.7261865236780422

Val Avg Loss  682: 0.183712

Val Avg F1  682:  0.682085932085932

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 683
--------------------------------------------------------------
Epoch:  683        1 Batch loss: 0.124852 Batch F1: 0.85
Epoch:  683        2 Batch loss: 0.131987 Batch F1: 0.8333333333333333
Epoch:  683        3 Batch loss: 0.179101 Batch F1: 0.6511627906976744
Epoch:  683        4 Batch loss: 0.182458 Batch F1: 0.6511627906976744
Epoch:  683        5 Batch loss: 0.191405 Batch F1: 0.6382978723404256
Epoch:  683        6 Batch loss: 0.141327 Batch F1: 0.8
Epoch:  683        7 Batch loss: 0.174049 Batch F1: 0.7391304347826089
Epoch:  683        8 Batch loss: 0.207539 Batch F1: 0.6382978723404256
Epoch:  683        9 Batch loss: 0.167672 Batch F1: 0.711111111111111
Epoch:  683       10 Batch loss: 0.166366 Batch F1: 0.7
Epoch:  683       11 Batch loss: 0.177433 Batch F1: 0.6341463414634146
Epoch:  683       12 Batch loss: 0.170097 Batch F1: 0.8260869565217391
Train Avg Loss  683: 0.167857

Train Avg F1  683: 0.7227274586073672

Val Avg Loss  683: 0.181377

Val Avg F1  683:  0.7122476682980885

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 684
--------------------------------------------------------------
Epoch:  684        1 Batch loss: 0.155245 Batch F1: 0.8085106382978724
Epoch:  684        2 Batch loss: 0.194956 Batch F1: 0.6923076923076924
Epoch:  684        3 Batch loss: 0.178341 Batch F1: 0.75
Epoch:  684        4 Batch loss: 0.184585 Batch F1: 0.6976744186046512
Epoch:  684        5 Batch loss: 0.169362 Batch F1: 0.7142857142857143
Epoch:  684        6 Batch loss: 0.185331 Batch F1: 0.6666666666666666
Epoch:  684        7 Batch loss: 0.153648 Batch F1: 0.7727272727272727
Epoch:  684        8 Batch loss: 0.141698 Batch F1: 0.8695652173913043
Epoch:  684        9 Batch loss: 0.156715 Batch F1: 0.8421052631578948
Epoch:  684       10 Batch loss: 0.161894 Batch F1: 0.7843137254901961
Epoch:  684       11 Batch loss: 0.179708 Batch F1: 0.7111111111111111
Epoch:  684       12 Batch loss: 0.187118 Batch F1: 0.4
Train Avg Loss  684: 0.170717

Train Avg F1  684: 0.7257723100033647

Val Avg Loss  684: 0.187821

Val Avg F1  684:  0.6738718244539199

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 685
--------------------------------------------------------------
Epoch:  685        1 Batch loss: 0.159355 Batch F1: 0.7441860465116279
Epoch:  685        2 Batch loss: 0.181938 Batch F1: 0.6341463414634146
Epoch:  685        3 Batch loss: 0.203807 Batch F1: 0.5957446808510638
Epoch:  685        4 Batch loss: 0.191512 Batch F1: 0.6190476190476191
Epoch:  685        5 Batch loss: 0.170938 Batch F1: 0.7346938775510203
Epoch:  685        6 Batch loss: 0.163356 Batch F1: 0.7234042553191489
Epoch:  685        7 Batch loss: 0.161955 Batch F1: 0.6829268292682926
Epoch:  685        8 Batch loss: 0.149897 Batch F1: 0.75
Epoch:  685        9 Batch loss: 0.176953 Batch F1: 0.6666666666666666
Epoch:  685       10 Batch loss: 0.160422 Batch F1: 0.6829268292682926
Epoch:  685       11 Batch loss: 0.193003 Batch F1: 0.7169811320754718
Epoch:  685       12 Batch loss: 0.172960 Batch F1: 0.7027027027027027
Train Avg Loss  685: 0.173841

Train Avg F1  685: 0.6877855817271102

Val Avg Loss  685: 0.183395

Val Avg F1  685:  0.6915775392193962

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 686
--------------------------------------------------------------
Epoch:  686        1 Batch loss: 0.161173 Batch F1: 0.6976744186046512
Epoch:  686        2 Batch loss: 0.168923 Batch F1: 0.7659574468085107
Epoch:  686        3 Batch loss: 0.203380 Batch F1: 0.6530612244897959
Epoch:  686        4 Batch loss: 0.180056 Batch F1: 0.7111111111111111
Epoch:  686        5 Batch loss: 0.199488 Batch F1: 0.6046511627906976
Epoch:  686        6 Batch loss: 0.162150 Batch F1: 0.7441860465116279
Epoch:  686        7 Batch loss: 0.167824 Batch F1: 0.6818181818181819
Epoch:  686        8 Batch loss: 0.183024 Batch F1: 0.6666666666666666
Epoch:  686        9 Batch loss: 0.159737 Batch F1: 0.742857142857143
Epoch:  686       10 Batch loss: 0.165852 Batch F1: 0.8363636363636364
Epoch:  686       11 Batch loss: 0.151329 Batch F1: 0.7368421052631577
Epoch:  686       12 Batch loss: 0.165150 Batch F1: 0.8372093023255814
Train Avg Loss  686: 0.172341

Train Avg F1  686: 0.7231998704675634

Val Avg Loss  686: 0.187271

Val Avg F1  686:  0.6841890310470221

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 687
--------------------------------------------------------------
Epoch:  687        1 Batch loss: 0.142133 Batch F1: 0.8260869565217391
Epoch:  687        2 Batch loss: 0.172355 Batch F1: 0.7391304347826085
Epoch:  687        3 Batch loss: 0.168570 Batch F1: 0.6818181818181818
Epoch:  687        4 Batch loss: 0.169145 Batch F1: 0.7000000000000001
Epoch:  687        5 Batch loss: 0.170822 Batch F1: 0.7307692307692307
Epoch:  687        6 Batch loss: 0.145901 Batch F1: 0.7906976744186046
Epoch:  687        7 Batch loss: 0.200079 Batch F1: 0.6086956521739131
Epoch:  687        8 Batch loss: 0.167441 Batch F1: 0.8076923076923077
Epoch:  687        9 Batch loss: 0.181977 Batch F1: 0.7111111111111111
Epoch:  687       10 Batch loss: 0.196386 Batch F1: 0.6363636363636365
Epoch:  687       11 Batch loss: 0.168334 Batch F1: 0.6666666666666667
Epoch:  687       12 Batch loss: 0.149126 Batch F1: 0.7272727272727272
Train Avg Loss  687: 0.169356

Train Avg F1  687: 0.7188587149658939

Val Avg Loss  687: 0.184020

Val Avg F1  687:  0.6635858611737377

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 688
--------------------------------------------------------------
Epoch:  688        1 Batch loss: 0.150968 Batch F1: 0.7499999999999999
Epoch:  688        2 Batch loss: 0.201715 Batch F1: 0.6666666666666667
Epoch:  688        3 Batch loss: 0.173538 Batch F1: 0.7916666666666666
Epoch:  688        4 Batch loss: 0.154132 Batch F1: 0.8333333333333334
Epoch:  688        5 Batch loss: 0.140071 Batch F1: 0.7692307692307692
Epoch:  688        6 Batch loss: 0.177637 Batch F1: 0.7547169811320755
Epoch:  688        7 Batch loss: 0.155970 Batch F1: 0.744186046511628
Epoch:  688        8 Batch loss: 0.188215 Batch F1: 0.723404255319149
Epoch:  688        9 Batch loss: 0.171585 Batch F1: 0.8372093023255814
Epoch:  688       10 Batch loss: 0.182502 Batch F1: 0.6829268292682927
Epoch:  688       11 Batch loss: 0.157847 Batch F1: 0.7142857142857143
Epoch:  688       12 Batch loss: 0.219924 Batch F1: 0.65
Train Avg Loss  688: 0.172842

Train Avg F1  688: 0.7431355470616564

Val Avg Loss  688: 0.185402

Val Avg F1  688:  0.6961619093694565

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 689
--------------------------------------------------------------
Epoch:  689        1 Batch loss: 0.163257 Batch F1: 0.782608695652174
Epoch:  689        2 Batch loss: 0.236852 Batch F1: 0.6666666666666666
Epoch:  689        3 Batch loss: 0.172448 Batch F1: 0.7659574468085107
Epoch:  689        4 Batch loss: 0.175845 Batch F1: 0.7692307692307693
Epoch:  689        5 Batch loss: 0.216723 Batch F1: 0.4571428571428571
Epoch:  689        6 Batch loss: 0.189540 Batch F1: 0.7027027027027029
Epoch:  689        7 Batch loss: 0.187178 Batch F1: 0.6363636363636365
Epoch:  689        8 Batch loss: 0.191073 Batch F1: 0.6818181818181818
Epoch:  689        9 Batch loss: 0.147768 Batch F1: 0.7916666666666667
Epoch:  689       10 Batch loss: 0.168404 Batch F1: 0.7555555555555555
Epoch:  689       11 Batch loss: 0.185358 Batch F1: 0.6521739130434783
Epoch:  689       12 Batch loss: 0.172828 Batch F1: 0.7
Train Avg Loss  689: 0.183939

Train Avg F1  689: 0.6968239243042667

Val Avg Loss  689: 0.187177

Val Avg F1  689:  0.6680636452617054

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 690
--------------------------------------------------------------
Epoch:  690        1 Batch loss: 0.152412 Batch F1: 0.7441860465116279
Epoch:  690        2 Batch loss: 0.174777 Batch F1: 0.7500000000000001
Epoch:  690        3 Batch loss: 0.156690 Batch F1: 0.8235294117647058
Epoch:  690        4 Batch loss: 0.176351 Batch F1: 0.7307692307692308
Epoch:  690        5 Batch loss: 0.148492 Batch F1: 0.7222222222222222
Epoch:  690        6 Batch loss: 0.203470 Batch F1: 0.6363636363636364
Epoch:  690        7 Batch loss: 0.151348 Batch F1: 0.7826086956521738
Epoch:  690        8 Batch loss: 0.215498 Batch F1: 0.6956521739130435
Epoch:  690        9 Batch loss: 0.189907 Batch F1: 0.6666666666666666
Epoch:  690       10 Batch loss: 0.170937 Batch F1: 0.7142857142857143
Epoch:  690       11 Batch loss: 0.144216 Batch F1: 0.8571428571428572
Epoch:  690       12 Batch loss: 0.221777 Batch F1: 0.6
Train Avg Loss  690: 0.175490

Train Avg F1  690: 0.7269522212743232

Val Avg Loss  690: 0.185831

Val Avg F1  690:  0.6602675303762261

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 691
--------------------------------------------------------------
Epoch:  691        1 Batch loss: 0.181122 Batch F1: 0.5454545454545455
Epoch:  691        2 Batch loss: 0.187032 Batch F1: 0.717948717948718
Epoch:  691        3 Batch loss: 0.166087 Batch F1: 0.7843137254901961
Epoch:  691        4 Batch loss: 0.177838 Batch F1: 0.6521739130434783
Epoch:  691        5 Batch loss: 0.177662 Batch F1: 0.7083333333333333
Epoch:  691        6 Batch loss: 0.151661 Batch F1: 0.8260869565217391
Epoch:  691        7 Batch loss: 0.163520 Batch F1: 0.7142857142857143
Epoch:  691        8 Batch loss: 0.198051 Batch F1: 0.6363636363636364
Epoch:  691        9 Batch loss: 0.139121 Batch F1: 0.8372093023255814
Epoch:  691       10 Batch loss: 0.180208 Batch F1: 0.6153846153846154
Epoch:  691       11 Batch loss: 0.169364 Batch F1: 0.7755102040816326
Epoch:  691       12 Batch loss: 0.199511 Batch F1: 0.7027027027027027
Train Avg Loss  691: 0.174265

Train Avg F1  691: 0.7096472805779911

Val Avg Loss  691: 0.181231

Val Avg F1  691:  0.6847146964005584

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 692
--------------------------------------------------------------
Epoch:  692        1 Batch loss: 0.193548 Batch F1: 0.7037037037037038
Epoch:  692        2 Batch loss: 0.182556 Batch F1: 0.7692307692307693
Epoch:  692        3 Batch loss: 0.154822 Batch F1: 0.8636363636363636
Epoch:  692        4 Batch loss: 0.142338 Batch F1: 0.8571428571428571
Epoch:  692        5 Batch loss: 0.199750 Batch F1: 0.7272727272727274
Epoch:  692        6 Batch loss: 0.160921 Batch F1: 0.7272727272727272
Epoch:  692        7 Batch loss: 0.162146 Batch F1: 0.6842105263157895
Epoch:  692        8 Batch loss: 0.180362 Batch F1: 0.5405405405405405
Epoch:  692        9 Batch loss: 0.175565 Batch F1: 0.6956521739130435
Epoch:  692       10 Batch loss: 0.162127 Batch F1: 0.7727272727272727
Epoch:  692       11 Batch loss: 0.171966 Batch F1: 0.7272727272727273
Epoch:  692       12 Batch loss: 0.167161 Batch F1: 0.7222222222222222
Train Avg Loss  692: 0.171105

Train Avg F1  692: 0.7325737176042285

Val Avg Loss  692: 0.184934

Val Avg F1  692:  0.6782136497260053

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 693
--------------------------------------------------------------
Epoch:  693        1 Batch loss: 0.191144 Batch F1: 0.6153846153846153
Epoch:  693        2 Batch loss: 0.178544 Batch F1: 0.72
Epoch:  693        3 Batch loss: 0.167881 Batch F1: 0.7391304347826085
Epoch:  693        4 Batch loss: 0.182432 Batch F1: 0.6190476190476191
Epoch:  693        5 Batch loss: 0.171305 Batch F1: 0.7272727272727272
Epoch:  693        6 Batch loss: 0.139145 Batch F1: 0.75
Epoch:  693        7 Batch loss: 0.171621 Batch F1: 0.6956521739130435
Epoch:  693        8 Batch loss: 0.159695 Batch F1: 0.7916666666666666
Epoch:  693        9 Batch loss: 0.158940 Batch F1: 0.7567567567567567
Epoch:  693       10 Batch loss: 0.191171 Batch F1: 0.7368421052631579
Epoch:  693       11 Batch loss: 0.184660 Batch F1: 0.6666666666666666
Epoch:  693       12 Batch loss: 0.162143 Batch F1: 0.7500000000000001
Train Avg Loss  693: 0.171557

Train Avg F1  693: 0.7140349804794885

Val Avg Loss  693: 0.183898

Val Avg F1  693:  0.6791432515035

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 694
--------------------------------------------------------------
Epoch:  694        1 Batch loss: 0.173046 Batch F1: 0.6341463414634146
Epoch:  694        2 Batch loss: 0.134128 Batch F1: 0.8205128205128205
Epoch:  694        3 Batch loss: 0.197134 Batch F1: 0.5909090909090909
Epoch:  694        4 Batch loss: 0.148032 Batch F1: 0.8292682926829269
Epoch:  694        5 Batch loss: 0.217122 Batch F1: 0.6521739130434783
Epoch:  694        6 Batch loss: 0.165443 Batch F1: 0.7777777777777778
Epoch:  694        7 Batch loss: 0.165790 Batch F1: 0.6486486486486486
Epoch:  694        8 Batch loss: 0.181004 Batch F1: 0.6666666666666666
Epoch:  694        9 Batch loss: 0.168379 Batch F1: 0.7450980392156864
Epoch:  694       10 Batch loss: 0.175715 Batch F1: 0.711111111111111
Epoch:  694       11 Batch loss: 0.163778 Batch F1: 0.7924528301886792
Epoch:  694       12 Batch loss: 0.132817 Batch F1: 0.8484848484848485
Train Avg Loss  694: 0.168532

Train Avg F1  694: 0.7264375317254291

Val Avg Loss  694: 0.179697

Val Avg F1  694:  0.7214296671268599

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 695
--------------------------------------------------------------
Epoch:  695        1 Batch loss: 0.161427 Batch F1: 0.7727272727272727
Epoch:  695        2 Batch loss: 0.163567 Batch F1: 0.7755102040816326
Epoch:  695        3 Batch loss: 0.155967 Batch F1: 0.7111111111111111
Epoch:  695        4 Batch loss: 0.193413 Batch F1: 0.5909090909090909
Epoch:  695        5 Batch loss: 0.199399 Batch F1: 0.6086956521739131
Epoch:  695        6 Batch loss: 0.170537 Batch F1: 0.7
Epoch:  695        7 Batch loss: 0.159255 Batch F1: 0.7555555555555555
Epoch:  695        8 Batch loss: 0.184625 Batch F1: 0.75
Epoch:  695        9 Batch loss: 0.162005 Batch F1: 0.6486486486486486
Epoch:  695       10 Batch loss: 0.160713 Batch F1: 0.7727272727272727
Epoch:  695       11 Batch loss: 0.171821 Batch F1: 0.7234042553191491
Epoch:  695       12 Batch loss: 0.132143 Batch F1: 0.823529411764706
Train Avg Loss  695: 0.167906

Train Avg F1  695: 0.7194015395848626

Val Avg Loss  695: 0.184067

Val Avg F1  695:  0.6736669857797475

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 696
--------------------------------------------------------------
Epoch:  696        1 Batch loss: 0.133220 Batch F1: 0.7586206896551724
Epoch:  696        2 Batch loss: 0.162005 Batch F1: 0.7755102040816326
Epoch:  696        3 Batch loss: 0.149373 Batch F1: 0.8181818181818182
Epoch:  696        4 Batch loss: 0.148966 Batch F1: 0.7692307692307692
Epoch:  696        5 Batch loss: 0.194178 Batch F1: 0.6521739130434783
Epoch:  696        6 Batch loss: 0.176640 Batch F1: 0.6808510638297872
Epoch:  696        7 Batch loss: 0.184314 Batch F1: 0.6511627906976744
Epoch:  696        8 Batch loss: 0.163184 Batch F1: 0.7659574468085107
Epoch:  696        9 Batch loss: 0.169174 Batch F1: 0.6976744186046512
Epoch:  696       10 Batch loss: 0.199873 Batch F1: 0.6792452830188679
Epoch:  696       11 Batch loss: 0.171048 Batch F1: 0.6956521739130435
Epoch:  696       12 Batch loss: 0.175941 Batch F1: 0.6315789473684211
Train Avg Loss  696: 0.168993

Train Avg F1  696: 0.714653293202819

Val Avg Loss  696: 0.180370

Val Avg F1  696:  0.6858421266409133

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 697
--------------------------------------------------------------
Epoch:  697        1 Batch loss: 0.144658 Batch F1: 0.7804878048780488
Epoch:  697        2 Batch loss: 0.161102 Batch F1: 0.7441860465116279
Epoch:  697        3 Batch loss: 0.187710 Batch F1: 0.6530612244897959
Epoch:  697        4 Batch loss: 0.178737 Batch F1: 0.7346938775510204
Epoch:  697        5 Batch loss: 0.152478 Batch F1: 0.7924528301886793
Epoch:  697        6 Batch loss: 0.159324 Batch F1: 0.7317073170731707
Epoch:  697        7 Batch loss: 0.131925 Batch F1: 0.851063829787234
Epoch:  697        8 Batch loss: 0.189688 Batch F1: 0.5
Epoch:  697        9 Batch loss: 0.176562 Batch F1: 0.6818181818181818
Epoch:  697       10 Batch loss: 0.179502 Batch F1: 0.7083333333333333
Epoch:  697       11 Batch loss: 0.176092 Batch F1: 0.5882352941176471
Epoch:  697       12 Batch loss: 0.162471 Batch F1: 0.7826086956521738
Train Avg Loss  697: 0.166687

Train Avg F1  697: 0.7123873696167428

Val Avg Loss  697: 0.180138

Val Avg F1  697:  0.6892119439315672

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 698
--------------------------------------------------------------
Epoch:  698        1 Batch loss: 0.137195 Batch F1: 0.7058823529411765
Epoch:  698        2 Batch loss: 0.227396 Batch F1: 0.6818181818181819
Epoch:  698        3 Batch loss: 0.175428 Batch F1: 0.7234042553191491
Epoch:  698        4 Batch loss: 0.144631 Batch F1: 0.8260869565217391
Epoch:  698        5 Batch loss: 0.159147 Batch F1: 0.7727272727272727
Epoch:  698        6 Batch loss: 0.126439 Batch F1: 0.8979591836734694
Epoch:  698        7 Batch loss: 0.162057 Batch F1: 0.7346938775510203
Epoch:  698        8 Batch loss: 0.189336 Batch F1: 0.6818181818181818
Epoch:  698        9 Batch loss: 0.186367 Batch F1: 0.7391304347826085
Epoch:  698       10 Batch loss: 0.165312 Batch F1: 0.7441860465116279
Epoch:  698       11 Batch loss: 0.175966 Batch F1: 0.7659574468085107
Epoch:  698       12 Batch loss: 0.195823 Batch F1: 0.6111111111111113
Train Avg Loss  698: 0.170425

Train Avg F1  698: 0.7403979417986707

Val Avg Loss  698: 0.179714

Val Avg F1  698:  0.7056617647058823

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 699
--------------------------------------------------------------
Epoch:  699        1 Batch loss: 0.140044 Batch F1: 0.8235294117647057
Epoch:  699        2 Batch loss: 0.192924 Batch F1: 0.5909090909090909
Epoch:  699        3 Batch loss: 0.166249 Batch F1: 0.7317073170731706
Epoch:  699        4 Batch loss: 0.131299 Batch F1: 0.875
Epoch:  699        5 Batch loss: 0.140475 Batch F1: 0.8292682926829269
Epoch:  699        6 Batch loss: 0.150141 Batch F1: 0.7727272727272727
Epoch:  699        7 Batch loss: 0.191645 Batch F1: 0.5641025641025641
Epoch:  699        8 Batch loss: 0.201445 Batch F1: 0.6086956521739131
Epoch:  699        9 Batch loss: 0.169972 Batch F1: 0.6956521739130435
Epoch:  699       10 Batch loss: 0.168331 Batch F1: 0.7346938775510204
Epoch:  699       11 Batch loss: 0.201362 Batch F1: 0.6250000000000001
Epoch:  699       12 Batch loss: 0.150494 Batch F1: 0.7199999999999999
Train Avg Loss  699: 0.167032

Train Avg F1  699: 0.7142738044081424

Val Avg Loss  699: 0.178908

Val Avg F1  699:  0.684981684981685

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 700
--------------------------------------------------------------
Epoch:  700        1 Batch loss: 0.143661 Batch F1: 0.7906976744186046
Epoch:  700        2 Batch loss: 0.166615 Batch F1: 0.6829268292682926
Epoch:  700        3 Batch loss: 0.156322 Batch F1: 0.782608695652174
Epoch:  700        4 Batch loss: 0.175056 Batch F1: 0.7234042553191491
Epoch:  700        5 Batch loss: 0.176811 Batch F1: 0.6666666666666666
Epoch:  700        6 Batch loss: 0.149476 Batch F1: 0.8400000000000001
Epoch:  700        7 Batch loss: 0.163416 Batch F1: 0.6666666666666666
Epoch:  700        8 Batch loss: 0.185669 Batch F1: 0.6363636363636365
Epoch:  700        9 Batch loss: 0.174640 Batch F1: 0.7391304347826089
Epoch:  700       10 Batch loss: 0.174530 Batch F1: 0.6976744186046512
Epoch:  700       11 Batch loss: 0.188641 Batch F1: 0.6976744186046512
Epoch:  700       12 Batch loss: 0.164788 Batch F1: 0.761904761904762
Train Avg Loss  700: 0.168302

Train Avg F1  700: 0.7238098715209887

Val Avg Loss  700: 0.184023

Val Avg F1  700:  0.6704600827242336

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 701
--------------------------------------------------------------
Epoch:  701        1 Batch loss: 0.184152 Batch F1: 0.6808510638297872
Epoch:  701        2 Batch loss: 0.173149 Batch F1: 0.7843137254901961
Epoch:  701        3 Batch loss: 0.181491 Batch F1: 0.5405405405405405
Epoch:  701        4 Batch loss: 0.171283 Batch F1: 0.6111111111111112
Epoch:  701        5 Batch loss: 0.152678 Batch F1: 0.6857142857142857
Epoch:  701        6 Batch loss: 0.173572 Batch F1: 0.7307692307692308
Epoch:  701        7 Batch loss: 0.194108 Batch F1: 0.619047619047619
Epoch:  701        8 Batch loss: 0.134657 Batch F1: 0.7692307692307692
Epoch:  701        9 Batch loss: 0.171197 Batch F1: 0.7450980392156864
Epoch:  701       10 Batch loss: 0.135587 Batch F1: 0.8181818181818182
Epoch:  701       11 Batch loss: 0.170797 Batch F1: 0.7391304347826088
Epoch:  701       12 Batch loss: 0.183934 Batch F1: 0.7727272727272727
Train Avg Loss  701: 0.168884

Train Avg F1  701: 0.7080596592200771

Val Avg Loss  701: 0.181112

Val Avg F1  701:  0.7131623931623933

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 702
--------------------------------------------------------------
Epoch:  702        1 Batch loss: 0.180368 Batch F1: 0.6818181818181819
Epoch:  702        2 Batch loss: 0.211160 Batch F1: 0.6086956521739131
Epoch:  702        3 Batch loss: 0.181943 Batch F1: 0.6923076923076924
Epoch:  702        4 Batch loss: 0.199424 Batch F1: 0.5777777777777778
Epoch:  702        5 Batch loss: 0.157849 Batch F1: 0.7692307692307693
Epoch:  702        6 Batch loss: 0.142092 Batch F1: 0.8444444444444444
Epoch:  702        7 Batch loss: 0.147498 Batch F1: 0.7999999999999999
Epoch:  702        8 Batch loss: 0.166005 Batch F1: 0.7346938775510203
Epoch:  702        9 Batch loss: 0.153435 Batch F1: 0.5999999999999999
Epoch:  702       10 Batch loss: 0.168037 Batch F1: 0.8
Epoch:  702       11 Batch loss: 0.163881 Batch F1: 0.6875
Epoch:  702       12 Batch loss: 0.180715 Batch F1: 0.7272727272727273
Train Avg Loss  702: 0.171034

Train Avg F1  702: 0.7103117602147105

Val Avg Loss  702: 0.181118

Val Avg F1  702:  0.725877036931616

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 703
--------------------------------------------------------------
Epoch:  703        1 Batch loss: 0.158875 Batch F1: 0.761904761904762
Epoch:  703        2 Batch loss: 0.165725 Batch F1: 0.7272727272727272
Epoch:  703        3 Batch loss: 0.186440 Batch F1: 0.5945945945945946
Epoch:  703        4 Batch loss: 0.196499 Batch F1: 0.6274509803921569
Epoch:  703        5 Batch loss: 0.147363 Batch F1: 0.830188679245283
Epoch:  703        6 Batch loss: 0.155319 Batch F1: 0.8372093023255814
Epoch:  703        7 Batch loss: 0.164598 Batch F1: 0.7142857142857143
Epoch:  703        8 Batch loss: 0.199046 Batch F1: 0.6382978723404256
Epoch:  703        9 Batch loss: 0.156338 Batch F1: 0.7916666666666667
Epoch:  703       10 Batch loss: 0.181160 Batch F1: 0.7391304347826089
Epoch:  703       11 Batch loss: 0.175976 Batch F1: 0.6666666666666666
Epoch:  703       12 Batch loss: 0.165348 Batch F1: 0.7368421052631577
Train Avg Loss  703: 0.171057

Train Avg F1  703: 0.722125875478362

Val Avg Loss  703: 0.182653

Val Avg F1  703:  0.7049319727891156

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 704
--------------------------------------------------------------
Epoch:  704        1 Batch loss: 0.147275 Batch F1: 0.7692307692307693
Epoch:  704        2 Batch loss: 0.176907 Batch F1: 0.6500000000000001
Epoch:  704        3 Batch loss: 0.166600 Batch F1: 0.7142857142857143
Epoch:  704        4 Batch loss: 0.190922 Batch F1: 0.6666666666666666
Epoch:  704        5 Batch loss: 0.193203 Batch F1: 0.6046511627906977
Epoch:  704        6 Batch loss: 0.180124 Batch F1: 0.7450980392156863
Epoch:  704        7 Batch loss: 0.147922 Batch F1: 0.7441860465116279
Epoch:  704        8 Batch loss: 0.134019 Batch F1: 0.8679245283018868
Epoch:  704        9 Batch loss: 0.186566 Batch F1: 0.7142857142857143
Epoch:  704       10 Batch loss: 0.174574 Batch F1: 0.6976744186046512
Epoch:  704       11 Batch loss: 0.164984 Batch F1: 0.782608695652174
Epoch:  704       12 Batch loss: 0.172282 Batch F1: 0.7368421052631577
Train Avg Loss  704: 0.169615

Train Avg F1  704: 0.7244544884007289

Val Avg Loss  704: 0.189734

Val Avg F1  704:  0.612385163855752

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 705
--------------------------------------------------------------
Epoch:  705        1 Batch loss: 0.190644 Batch F1: 0.5945945945945946
Epoch:  705        2 Batch loss: 0.216841 Batch F1: 0.65
Epoch:  705        3 Batch loss: 0.188512 Batch F1: 0.7111111111111111
Epoch:  705        4 Batch loss: 0.193091 Batch F1: 0.7636363636363636
Epoch:  705        5 Batch loss: 0.230444 Batch F1: 0.6666666666666667
Epoch:  705        6 Batch loss: 0.160785 Batch F1: 0.8
Epoch:  705        7 Batch loss: 0.121525 Batch F1: 0.9019607843137256
Epoch:  705        8 Batch loss: 0.170491 Batch F1: 0.7999999999999999
Epoch:  705        9 Batch loss: 0.130117 Batch F1: 0.88
Epoch:  705       10 Batch loss: 0.165730 Batch F1: 0.7142857142857143
Epoch:  705       11 Batch loss: 0.177870 Batch F1: 0.5945945945945946
Epoch:  705       12 Batch loss: 0.205272 Batch F1: 0.5161290322580646
Train Avg Loss  705: 0.179277

Train Avg F1  705: 0.7160815717884028

Val Avg Loss  705: 0.185891

Val Avg F1  705:  0.6615896358543417

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 706
--------------------------------------------------------------
Epoch:  706        1 Batch loss: 0.165183 Batch F1: 0.7826086956521738
Epoch:  706        2 Batch loss: 0.144296 Batch F1: 0.7368421052631577
Epoch:  706        3 Batch loss: 0.173650 Batch F1: 0.6315789473684211
Epoch:  706        4 Batch loss: 0.166733 Batch F1: 0.65
Epoch:  706        5 Batch loss: 0.191268 Batch F1: 0.744186046511628
Epoch:  706        6 Batch loss: 0.181021 Batch F1: 0.5555555555555556
Epoch:  706        7 Batch loss: 0.158883 Batch F1: 0.8148148148148148
Epoch:  706        8 Batch loss: 0.158504 Batch F1: 0.8333333333333333
Epoch:  706        9 Batch loss: 0.141297 Batch F1: 0.8
Epoch:  706       10 Batch loss: 0.180052 Batch F1: 0.6521739130434783
Epoch:  706       11 Batch loss: 0.180843 Batch F1: 0.7450980392156864
Epoch:  706       12 Batch loss: 0.203909 Batch F1: 0.5945945945945946
Train Avg Loss  706: 0.170470

Train Avg F1  706: 0.7117321704460702

Val Avg Loss  706: 0.184278

Val Avg F1  706:  0.6849962207105064

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 707
--------------------------------------------------------------
Epoch:  707        1 Batch loss: 0.190897 Batch F1: 0.6
Epoch:  707        2 Batch loss: 0.159304 Batch F1: 0.7500000000000001
Epoch:  707        3 Batch loss: 0.184746 Batch F1: 0.7586206896551724
Epoch:  707        4 Batch loss: 0.143729 Batch F1: 0.7368421052631579
Epoch:  707        5 Batch loss: 0.201834 Batch F1: 0.6666666666666666
Epoch:  707        6 Batch loss: 0.191530 Batch F1: 0.6341463414634148
Epoch:  707        7 Batch loss: 0.158717 Batch F1: 0.7843137254901961
Epoch:  707        8 Batch loss: 0.180144 Batch F1: 0.72
Epoch:  707        9 Batch loss: 0.167166 Batch F1: 0.6842105263157895
Epoch:  707       10 Batch loss: 0.180664 Batch F1: 0.6666666666666666
Epoch:  707       11 Batch loss: 0.131390 Batch F1: 0.8636363636363636
Epoch:  707       12 Batch loss: 0.171423 Batch F1: 0.6857142857142857
Train Avg Loss  707: 0.171795

Train Avg F1  707: 0.7125681142393093

Val Avg Loss  707: 0.182583

Val Avg F1  707:  0.6721998601114597

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 708
--------------------------------------------------------------
Epoch:  708        1 Batch loss: 0.163053 Batch F1: 0.761904761904762
Epoch:  708        2 Batch loss: 0.168826 Batch F1: 0.6666666666666666
Epoch:  708        3 Batch loss: 0.170118 Batch F1: 0.7924528301886793
Epoch:  708        4 Batch loss: 0.140654 Batch F1: 0.8372093023255814
Epoch:  708        5 Batch loss: 0.160809 Batch F1: 0.6666666666666666
Epoch:  708        6 Batch loss: 0.167507 Batch F1: 0.7777777777777778
Epoch:  708        7 Batch loss: 0.191292 Batch F1: 0.6666666666666666
Epoch:  708        8 Batch loss: 0.169503 Batch F1: 0.6842105263157895
Epoch:  708        9 Batch loss: 0.159272 Batch F1: 0.7555555555555555
Epoch:  708       10 Batch loss: 0.193842 Batch F1: 0.6923076923076923
Epoch:  708       11 Batch loss: 0.189994 Batch F1: 0.6086956521739131
Epoch:  708       12 Batch loss: 0.154127 Batch F1: 0.6666666666666666
Train Avg Loss  708: 0.169083

Train Avg F1  708: 0.7147317304347015

Val Avg Loss  708: 0.184299

Val Avg F1  708:  0.6799319727891158

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 709
--------------------------------------------------------------
Epoch:  709        1 Batch loss: 0.187333 Batch F1: 0.6666666666666666
Epoch:  709        2 Batch loss: 0.155127 Batch F1: 0.5925925925925926
Epoch:  709        3 Batch loss: 0.203448 Batch F1: 0.5500000000000002
Epoch:  709        4 Batch loss: 0.150624 Batch F1: 0.8163265306122449
Epoch:  709        5 Batch loss: 0.176963 Batch F1: 0.711111111111111
Epoch:  709        6 Batch loss: 0.167820 Batch F1: 0.7450980392156863
Epoch:  709        7 Batch loss: 0.176352 Batch F1: 0.65
Epoch:  709        8 Batch loss: 0.153820 Batch F1: 0.761904761904762
Epoch:  709        9 Batch loss: 0.153790 Batch F1: 0.7441860465116279
Epoch:  709       10 Batch loss: 0.167809 Batch F1: 0.7111111111111111
Epoch:  709       11 Batch loss: 0.159537 Batch F1: 0.8474576271186439
Epoch:  709       12 Batch loss: 0.173763 Batch F1: 0.6486486486486486
Train Avg Loss  709: 0.168866

Train Avg F1  709: 0.7037585946244246

Val Avg Loss  709: 0.182484

Val Avg F1  709:  0.7171305031446541

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 710
--------------------------------------------------------------
Epoch:  710        1 Batch loss: 0.140271 Batch F1: 0.9019607843137256
Epoch:  710        2 Batch loss: 0.136071 Batch F1: 0.8333333333333334
Epoch:  710        3 Batch loss: 0.175136 Batch F1: 0.631578947368421
Epoch:  710        4 Batch loss: 0.186626 Batch F1: 0.6956521739130435
Epoch:  710        5 Batch loss: 0.181369 Batch F1: 0.6818181818181819
Epoch:  710        6 Batch loss: 0.183484 Batch F1: 0.5789473684210527
Epoch:  710        7 Batch loss: 0.170558 Batch F1: 0.6486486486486486
Epoch:  710        8 Batch loss: 0.173505 Batch F1: 0.6341463414634146
Epoch:  710        9 Batch loss: 0.183058 Batch F1: 0.7407407407407408
Epoch:  710       10 Batch loss: 0.173719 Batch F1: 0.6111111111111112
Epoch:  710       11 Batch loss: 0.155416 Batch F1: 0.8571428571428571
Epoch:  710       12 Batch loss: 0.176949 Batch F1: 0.6666666666666667
Train Avg Loss  710: 0.169680

Train Avg F1  710: 0.7068122629117664

Val Avg Loss  710: 0.181792

Val Avg F1  710:  0.6876278274672609

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 711
--------------------------------------------------------------
Epoch:  711        1 Batch loss: 0.171498 Batch F1: 0.6285714285714287
Epoch:  711        2 Batch loss: 0.158277 Batch F1: 0.7
Epoch:  711        3 Batch loss: 0.169375 Batch F1: 0.7307692307692308
Epoch:  711        4 Batch loss: 0.174367 Batch F1: 0.7346938775510203
Epoch:  711        5 Batch loss: 0.207795 Batch F1: 0.6274509803921569
Epoch:  711        6 Batch loss: 0.169870 Batch F1: 0.7199999999999999
Epoch:  711        7 Batch loss: 0.146210 Batch F1: 0.7692307692307692
Epoch:  711        8 Batch loss: 0.174739 Batch F1: 0.742857142857143
Epoch:  711        9 Batch loss: 0.161496 Batch F1: 0.7391304347826085
Epoch:  711       10 Batch loss: 0.159095 Batch F1: 0.8
Epoch:  711       11 Batch loss: 0.166278 Batch F1: 0.723404255319149
Epoch:  711       12 Batch loss: 0.167537 Batch F1: 0.7000000000000001
Train Avg Loss  711: 0.168878

Train Avg F1  711: 0.7180090099561255

Val Avg Loss  711: 0.181200

Val Avg F1  711:  0.6868530020703933

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 712
--------------------------------------------------------------
Epoch:  712        1 Batch loss: 0.168573 Batch F1: 0.723404255319149
Epoch:  712        2 Batch loss: 0.165885 Batch F1: 0.7441860465116279
Epoch:  712        3 Batch loss: 0.138654 Batch F1: 0.7027027027027026
Epoch:  712        4 Batch loss: 0.154327 Batch F1: 0.7441860465116279
Epoch:  712        5 Batch loss: 0.175144 Batch F1: 0.5945945945945946
Epoch:  712        6 Batch loss: 0.209417 Batch F1: 0.6
Epoch:  712        7 Batch loss: 0.192830 Batch F1: 0.7234042553191489
Epoch:  712        8 Batch loss: 0.150130 Batch F1: 0.6976744186046512
Epoch:  712        9 Batch loss: 0.147889 Batch F1: 0.8085106382978724
Epoch:  712       10 Batch loss: 0.191731 Batch F1: 0.8070175438596491
Epoch:  712       11 Batch loss: 0.197141 Batch F1: 0.7692307692307693
Epoch:  712       12 Batch loss: 0.172288 Batch F1: 0.7058823529411765
Train Avg Loss  712: 0.172001

Train Avg F1  712: 0.7183994686577475

Val Avg Loss  712: 0.180792

Val Avg F1  712:  0.6804571268597025

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 713
--------------------------------------------------------------
Epoch:  713        1 Batch loss: 0.168826 Batch F1: 0.7391304347826089
Epoch:  713        2 Batch loss: 0.169643 Batch F1: 0.7692307692307693
Epoch:  713        3 Batch loss: 0.174727 Batch F1: 0.7692307692307692
Epoch:  713        4 Batch loss: 0.192099 Batch F1: 0.6666666666666666
Epoch:  713        5 Batch loss: 0.165501 Batch F1: 0.7826086956521738
Epoch:  713        6 Batch loss: 0.169322 Batch F1: 0.75
Epoch:  713        7 Batch loss: 0.188423 Batch F1: 0.6153846153846153
Epoch:  713        8 Batch loss: 0.153912 Batch F1: 0.6829268292682927
Epoch:  713        9 Batch loss: 0.159188 Batch F1: 0.7804878048780488
Epoch:  713       10 Batch loss: 0.158816 Batch F1: 0.6666666666666666
Epoch:  713       11 Batch loss: 0.169385 Batch F1: 0.7755102040816326
Epoch:  713       12 Batch loss: 0.158531 Batch F1: 0.6666666666666665
Train Avg Loss  713: 0.169031

Train Avg F1  713: 0.7220425102090758

Val Avg Loss  713: 0.183041

Val Avg F1  713:  0.6850786468433527

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 714
--------------------------------------------------------------
Epoch:  714        1 Batch loss: 0.166253 Batch F1: 0.7111111111111111
Epoch:  714        2 Batch loss: 0.181074 Batch F1: 0.7636363636363636
Epoch:  714        3 Batch loss: 0.164091 Batch F1: 0.7441860465116279
Epoch:  714        4 Batch loss: 0.137156 Batch F1: 0.7428571428571428
Epoch:  714        5 Batch loss: 0.167215 Batch F1: 0.6818181818181819
Epoch:  714        6 Batch loss: 0.179923 Batch F1: 0.7407407407407408
Epoch:  714        7 Batch loss: 0.178773 Batch F1: 0.7727272727272727
Epoch:  714        8 Batch loss: 0.172183 Batch F1: 0.7234042553191489
Epoch:  714        9 Batch loss: 0.161756 Batch F1: 0.5384615384615385
Epoch:  714       10 Batch loss: 0.171227 Batch F1: 0.7999999999999999
Epoch:  714       11 Batch loss: 0.154569 Batch F1: 0.7
Epoch:  714       12 Batch loss: 0.201459 Batch F1: 0.5789473684210527
Train Avg Loss  714: 0.169640

Train Avg F1  714: 0.7081575018003483

Val Avg Loss  714: 0.180404

Val Avg F1  714:  0.6899703557312252

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 715
--------------------------------------------------------------
Epoch:  715        1 Batch loss: 0.132231 Batch F1: 0.8444444444444444
Epoch:  715        2 Batch loss: 0.143793 Batch F1: 0.7906976744186046
Epoch:  715        3 Batch loss: 0.176344 Batch F1: 0.6666666666666666
Epoch:  715        4 Batch loss: 0.167936 Batch F1: 0.7659574468085107
Epoch:  715        5 Batch loss: 0.154703 Batch F1: 0.6818181818181818
Epoch:  715        6 Batch loss: 0.173847 Batch F1: 0.7441860465116279
Epoch:  715        7 Batch loss: 0.186475 Batch F1: 0.6341463414634148
Epoch:  715        8 Batch loss: 0.197194 Batch F1: 0.5555555555555555
Epoch:  715        9 Batch loss: 0.140703 Batch F1: 0.84
Epoch:  715       10 Batch loss: 0.184123 Batch F1: 0.6363636363636365
Epoch:  715       11 Batch loss: 0.167422 Batch F1: 0.6666666666666666
Epoch:  715       12 Batch loss: 0.172301 Batch F1: 0.7659574468085107
Train Avg Loss  715: 0.166423

Train Avg F1  715: 0.7160383422938185

Val Avg Loss  715: 0.181122

Val Avg F1  715:  0.6982579462937322

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 716
--------------------------------------------------------------
Epoch:  716        1 Batch loss: 0.184746 Batch F1: 0.6666666666666666
Epoch:  716        2 Batch loss: 0.142645 Batch F1: 0.8
Epoch:  716        3 Batch loss: 0.171414 Batch F1: 0.7
Epoch:  716        4 Batch loss: 0.172482 Batch F1: 0.7777777777777779
Epoch:  716        5 Batch loss: 0.176930 Batch F1: 0.7083333333333334
Epoch:  716        6 Batch loss: 0.147730 Batch F1: 0.7692307692307692
Epoch:  716        7 Batch loss: 0.194670 Batch F1: 0.6530612244897959
Epoch:  716        8 Batch loss: 0.160938 Batch F1: 0.7142857142857143
Epoch:  716        9 Batch loss: 0.172405 Batch F1: 0.6511627906976744
Epoch:  716       10 Batch loss: 0.170062 Batch F1: 0.6829268292682926
Epoch:  716       11 Batch loss: 0.138779 Batch F1: 0.8095238095238095
Epoch:  716       12 Batch loss: 0.195053 Batch F1: 0.6842105263157895
Train Avg Loss  716: 0.168988

Train Avg F1  716: 0.7180982867991353

Val Avg Loss  716: 0.180174

Val Avg F1  716:  0.6874644408995312

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 717
--------------------------------------------------------------
Epoch:  717        1 Batch loss: 0.147258 Batch F1: 0.6666666666666665
Epoch:  717        2 Batch loss: 0.173211 Batch F1: 0.7500000000000001
Epoch:  717        3 Batch loss: 0.147560 Batch F1: 0.8148148148148148
Epoch:  717        4 Batch loss: 0.185451 Batch F1: 0.5641025641025641
Epoch:  717        5 Batch loss: 0.179056 Batch F1: 0.6829268292682927
Epoch:  717        6 Batch loss: 0.182071 Batch F1: 0.7083333333333334
Epoch:  717        7 Batch loss: 0.144640 Batch F1: 0.7999999999999999
Epoch:  717        8 Batch loss: 0.162614 Batch F1: 0.7391304347826088
Epoch:  717        9 Batch loss: 0.195853 Batch F1: 0.6530612244897959
Epoch:  717       10 Batch loss: 0.165744 Batch F1: 0.6470588235294118
Epoch:  717       11 Batch loss: 0.150241 Batch F1: 0.7916666666666667
Epoch:  717       12 Batch loss: 0.168525 Batch F1: 0.7500000000000001
Train Avg Loss  717: 0.166852

Train Avg F1  717: 0.7139801131378464

Val Avg Loss  717: 0.180053

Val Avg F1  717:  0.6849453178400546

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 718
--------------------------------------------------------------
Epoch:  718        1 Batch loss: 0.144912 Batch F1: 0.8076923076923077
Epoch:  718        2 Batch loss: 0.156903 Batch F1: 0.6451612903225806
Epoch:  718        3 Batch loss: 0.131050 Batch F1: 0.8292682926829269
Epoch:  718        4 Batch loss: 0.198159 Batch F1: 0.6363636363636365
Epoch:  718        5 Batch loss: 0.182102 Batch F1: 0.7169811320754716
Epoch:  718        6 Batch loss: 0.158070 Batch F1: 0.7924528301886793
Epoch:  718        7 Batch loss: 0.166273 Batch F1: 0.76
Epoch:  718        8 Batch loss: 0.194672 Batch F1: 0.6382978723404256
Epoch:  718        9 Batch loss: 0.167414 Batch F1: 0.6666666666666667
Epoch:  718       10 Batch loss: 0.168365 Batch F1: 0.5945945945945945
Epoch:  718       11 Batch loss: 0.158380 Batch F1: 0.7272727272727272
Epoch:  718       12 Batch loss: 0.169894 Batch F1: 0.6842105263157895
Train Avg Loss  718: 0.166350

Train Avg F1  718: 0.7082468230429839

Val Avg Loss  718: 0.182775

Val Avg F1  718:  0.6877461343945612

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 719
--------------------------------------------------------------
Epoch:  719        1 Batch loss: 0.167824 Batch F1: 0.7857142857142857
Epoch:  719        2 Batch loss: 0.130989 Batch F1: 0.8205128205128205
Epoch:  719        3 Batch loss: 0.203838 Batch F1: 0.6046511627906976
Epoch:  719        4 Batch loss: 0.184818 Batch F1: 0.6956521739130435
Epoch:  719        5 Batch loss: 0.129049 Batch F1: 0.8780487804878048
Epoch:  719        6 Batch loss: 0.171607 Batch F1: 0.6829268292682926
Epoch:  719        7 Batch loss: 0.208086 Batch F1: 0.5
Epoch:  719        8 Batch loss: 0.163424 Batch F1: 0.7272727272727273
Epoch:  719        9 Batch loss: 0.172600 Batch F1: 0.7450980392156864
Epoch:  719       10 Batch loss: 0.172382 Batch F1: 0.7499999999999999
Epoch:  719       11 Batch loss: 0.156848 Batch F1: 0.7659574468085107
Epoch:  719       12 Batch loss: 0.175652 Batch F1: 0.6666666666666667
Train Avg Loss  719: 0.169760

Train Avg F1  719: 0.7185417443875446

Val Avg Loss  719: 0.180716

Val Avg F1  719:  0.7099574829931974

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 720
--------------------------------------------------------------
Epoch:  720        1 Batch loss: 0.182191 Batch F1: 0.6
Epoch:  720        2 Batch loss: 0.209481 Batch F1: 0.6666666666666667
Epoch:  720        3 Batch loss: 0.198004 Batch F1: 0.7796610169491526
Epoch:  720        4 Batch loss: 0.147548 Batch F1: 0.8727272727272727
Epoch:  720        5 Batch loss: 0.149353 Batch F1: 0.8571428571428572
Epoch:  720        6 Batch loss: 0.162024 Batch F1: 0.7906976744186046
Epoch:  720        7 Batch loss: 0.172131 Batch F1: 0.711111111111111
Epoch:  720        8 Batch loss: 0.165457 Batch F1: 0.793103448275862
Epoch:  720        9 Batch loss: 0.155209 Batch F1: 0.717948717948718
Epoch:  720       10 Batch loss: 0.247136 Batch F1: 0.6000000000000001
Epoch:  720       11 Batch loss: 0.167767 Batch F1: 0.6060606060606061
Epoch:  720       12 Batch loss: 0.159111 Batch F1: 0.7647058823529411
Train Avg Loss  720: 0.176284

Train Avg F1  720: 0.7299854378044827

Val Avg Loss  720: 0.180470

Val Avg F1  720:  0.6810064325917985

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 721
--------------------------------------------------------------
Epoch:  721        1 Batch loss: 0.197861 Batch F1: 0.7169811320754716
Epoch:  721        2 Batch loss: 0.186197 Batch F1: 0.7037037037037037
Epoch:  721        3 Batch loss: 0.185395 Batch F1: 0.6956521739130435
Epoch:  721        4 Batch loss: 0.150389 Batch F1: 0.7727272727272727
Epoch:  721        5 Batch loss: 0.193534 Batch F1: 0.68
Epoch:  721        6 Batch loss: 0.186654 Batch F1: 0.48484848484848486
Epoch:  721        7 Batch loss: 0.137557 Batch F1: 0.8444444444444444
Epoch:  721        8 Batch loss: 0.158126 Batch F1: 0.6857142857142857
Epoch:  721        9 Batch loss: 0.170668 Batch F1: 0.6818181818181818
Epoch:  721       10 Batch loss: 0.130279 Batch F1: 0.8636363636363636
Epoch:  721       11 Batch loss: 0.173795 Batch F1: 0.6956521739130435
Epoch:  721       12 Batch loss: 0.138936 Batch F1: 0.7096774193548387
Train Avg Loss  721: 0.167449

Train Avg F1  721: 0.7112379696790945

Val Avg Loss  721: 0.179975

Val Avg F1  721:  0.6870320855614974

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 722
--------------------------------------------------------------
Epoch:  722        1 Batch loss: 0.168813 Batch F1: 0.723404255319149
Epoch:  722        2 Batch loss: 0.187863 Batch F1: 0.6521739130434783
Epoch:  722        3 Batch loss: 0.187168 Batch F1: 0.7037037037037038
Epoch:  722        4 Batch loss: 0.156058 Batch F1: 0.7826086956521738
Epoch:  722        5 Batch loss: 0.172635 Batch F1: 0.6511627906976744
Epoch:  722        6 Batch loss: 0.176040 Batch F1: 0.6153846153846154
Epoch:  722        7 Batch loss: 0.160944 Batch F1: 0.7555555555555556
Epoch:  722        8 Batch loss: 0.156813 Batch F1: 0.7924528301886792
Epoch:  722        9 Batch loss: 0.142698 Batch F1: 0.8333333333333334
Epoch:  722       10 Batch loss: 0.175228 Batch F1: 0.7000000000000001
Epoch:  722       11 Batch loss: 0.148087 Batch F1: 0.7727272727272727
Epoch:  722       12 Batch loss: 0.165592 Batch F1: 0.7368421052631577
Train Avg Loss  722: 0.166495

Train Avg F1  722: 0.7266124225723994

Val Avg Loss  722: 0.180403

Val Avg F1  722:  0.6945986226744784

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 723
--------------------------------------------------------------
Epoch:  723        1 Batch loss: 0.155426 Batch F1: 0.761904761904762
Epoch:  723        2 Batch loss: 0.184359 Batch F1: 0.6956521739130435
Epoch:  723        3 Batch loss: 0.135371 Batch F1: 0.8444444444444444
Epoch:  723        4 Batch loss: 0.206699 Batch F1: 0.6046511627906976
Epoch:  723        5 Batch loss: 0.163680 Batch F1: 0.7083333333333334
Epoch:  723        6 Batch loss: 0.163060 Batch F1: 0.7500000000000001
Epoch:  723        7 Batch loss: 0.160256 Batch F1: 0.7659574468085107
Epoch:  723        8 Batch loss: 0.158438 Batch F1: 0.7500000000000001
Epoch:  723        9 Batch loss: 0.155382 Batch F1: 0.7222222222222222
Epoch:  723       10 Batch loss: 0.197883 Batch F1: 0.6923076923076924
Epoch:  723       11 Batch loss: 0.157029 Batch F1: 0.7142857142857143
Epoch:  723       12 Batch loss: 0.182954 Batch F1: 0.6666666666666667
Train Avg Loss  723: 0.168378

Train Avg F1  723: 0.7230354682230905

Val Avg Loss  723: 0.182875

Val Avg F1  723:  0.6655583972719523

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 724
--------------------------------------------------------------
Epoch:  724        1 Batch loss: 0.159954 Batch F1: 0.717948717948718
Epoch:  724        2 Batch loss: 0.149579 Batch F1: 0.8085106382978724
Epoch:  724        3 Batch loss: 0.155086 Batch F1: 0.7804878048780488
Epoch:  724        4 Batch loss: 0.166022 Batch F1: 0.75
Epoch:  724        5 Batch loss: 0.183434 Batch F1: 0.5142857142857142
Epoch:  724        6 Batch loss: 0.188983 Batch F1: 0.6086956521739131
Epoch:  724        7 Batch loss: 0.157665 Batch F1: 0.6666666666666666
Epoch:  724        8 Batch loss: 0.149006 Batch F1: 0.8333333333333334
Epoch:  724        9 Batch loss: 0.181462 Batch F1: 0.6956521739130435
Epoch:  724       10 Batch loss: 0.146942 Batch F1: 0.7906976744186046
Epoch:  724       11 Batch loss: 0.170465 Batch F1: 0.7234042553191489
Epoch:  724       12 Batch loss: 0.210883 Batch F1: 0.6500000000000001
Train Avg Loss  724: 0.168290

Train Avg F1  724: 0.7116402192695886

Val Avg Loss  724: 0.182398

Val Avg F1  724:  0.7212236514562096

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 725
--------------------------------------------------------------
Epoch:  725        1 Batch loss: 0.172252 Batch F1: 0.8
Epoch:  725        2 Batch loss: 0.158150 Batch F1: 0.7999999999999999
Epoch:  725        3 Batch loss: 0.192270 Batch F1: 0.5909090909090908
Epoch:  725        4 Batch loss: 0.180405 Batch F1: 0.5945945945945946
Epoch:  725        5 Batch loss: 0.148655 Batch F1: 0.6896551724137931
Epoch:  725        6 Batch loss: 0.182933 Batch F1: 0.6666666666666666
Epoch:  725        7 Batch loss: 0.135156 Batch F1: 0.8181818181818182
Epoch:  725        8 Batch loss: 0.204041 Batch F1: 0.68
Epoch:  725        9 Batch loss: 0.178555 Batch F1: 0.7407407407407407
Epoch:  725       10 Batch loss: 0.184273 Batch F1: 0.8
Epoch:  725       11 Batch loss: 0.139331 Batch F1: 0.8444444444444444
Epoch:  725       12 Batch loss: 0.194711 Batch F1: 0.6500000000000001
Train Avg Loss  725: 0.172561

Train Avg F1  725: 0.7229327106625957

Val Avg Loss  725: 0.190507

Val Avg F1  725:  0.6662306369753178

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 726
--------------------------------------------------------------
Epoch:  726        1 Batch loss: 0.182111 Batch F1: 0.7111111111111111
Epoch:  726        2 Batch loss: 0.188591 Batch F1: 0.7169811320754716
Epoch:  726        3 Batch loss: 0.179975 Batch F1: 0.6818181818181818
Epoch:  726        4 Batch loss: 0.168961 Batch F1: 0.7111111111111111
Epoch:  726        5 Batch loss: 0.156942 Batch F1: 0.6666666666666667
Epoch:  726        6 Batch loss: 0.159074 Batch F1: 0.7317073170731708
Epoch:  726        7 Batch loss: 0.187202 Batch F1: 0.5853658536585366
Epoch:  726        8 Batch loss: 0.152546 Batch F1: 0.761904761904762
Epoch:  726        9 Batch loss: 0.165741 Batch F1: 0.7317073170731706
Epoch:  726       10 Batch loss: 0.171623 Batch F1: 0.6976744186046512
Epoch:  726       11 Batch loss: 0.156346 Batch F1: 0.8275862068965517
Epoch:  726       12 Batch loss: 0.171984 Batch F1: 0.7222222222222222
Train Avg Loss  726: 0.170091

Train Avg F1  726: 0.7121546916846339

Val Avg Loss  726: 0.181325

Val Avg F1  726:  0.716231684981685

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 727
--------------------------------------------------------------
Epoch:  727        1 Batch loss: 0.156880 Batch F1: 0.8333333333333333
Epoch:  727        2 Batch loss: 0.167537 Batch F1: 0.7142857142857143
Epoch:  727        3 Batch loss: 0.178097 Batch F1: 0.7692307692307692
Epoch:  727        4 Batch loss: 0.174579 Batch F1: 0.782608695652174
Epoch:  727        5 Batch loss: 0.153462 Batch F1: 0.8000000000000002
Epoch:  727        6 Batch loss: 0.177865 Batch F1: 0.7142857142857143
Epoch:  727        7 Batch loss: 0.168341 Batch F1: 0.7755102040816326
Epoch:  727        8 Batch loss: 0.154764 Batch F1: 0.761904761904762
Epoch:  727        9 Batch loss: 0.175268 Batch F1: 0.7307692307692306
Epoch:  727       10 Batch loss: 0.176256 Batch F1: 0.7547169811320754
Epoch:  727       11 Batch loss: 0.154364 Batch F1: 0.6250000000000001
Epoch:  727       12 Batch loss: 0.202770 Batch F1: 0.6190476190476191
Train Avg Loss  727: 0.170015

Train Avg F1  727: 0.7400577519769187

Val Avg Loss  727: 0.181203

Val Avg F1  727:  0.6868902665799951

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 728
--------------------------------------------------------------
Epoch:  728        1 Batch loss: 0.152577 Batch F1: 0.7659574468085107
Epoch:  728        2 Batch loss: 0.161093 Batch F1: 0.6857142857142857
Epoch:  728        3 Batch loss: 0.192061 Batch F1: 0.7307692307692308
Epoch:  728        4 Batch loss: 0.191861 Batch F1: 0.6190476190476191
Epoch:  728        5 Batch loss: 0.163970 Batch F1: 0.7499999999999999
Epoch:  728        6 Batch loss: 0.169045 Batch F1: 0.6666666666666666
Epoch:  728        7 Batch loss: 0.144414 Batch F1: 0.8
Epoch:  728        8 Batch loss: 0.167877 Batch F1: 0.6976744186046512
Epoch:  728        9 Batch loss: 0.155136 Batch F1: 0.7999999999999999
Epoch:  728       10 Batch loss: 0.167293 Batch F1: 0.7142857142857143
Epoch:  728       11 Batch loss: 0.167256 Batch F1: 0.711111111111111
Epoch:  728       12 Batch loss: 0.181506 Batch F1: 0.6285714285714286
Train Avg Loss  728: 0.167841

Train Avg F1  728: 0.7141498267982681

Val Avg Loss  728: 0.179890

Val Avg F1  728:  0.687988325690482

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 729
--------------------------------------------------------------
Epoch:  729        1 Batch loss: 0.163794 Batch F1: 0.7391304347826088
Epoch:  729        2 Batch loss: 0.190969 Batch F1: 0.7017543859649122
Epoch:  729        3 Batch loss: 0.179850 Batch F1: 0.5555555555555555
Epoch:  729        4 Batch loss: 0.177458 Batch F1: 0.6956521739130435
Epoch:  729        5 Batch loss: 0.157421 Batch F1: 0.7
Epoch:  729        6 Batch loss: 0.160449 Batch F1: 0.7906976744186046
Epoch:  729        7 Batch loss: 0.158453 Batch F1: 0.7906976744186046
Epoch:  729        8 Batch loss: 0.154869 Batch F1: 0.7692307692307692
Epoch:  729        9 Batch loss: 0.142879 Batch F1: 0.7727272727272727
Epoch:  729       10 Batch loss: 0.164809 Batch F1: 0.6976744186046512
Epoch:  729       11 Batch loss: 0.168914 Batch F1: 0.8070175438596492
Epoch:  729       12 Batch loss: 0.184071 Batch F1: 0.611111111111111
Train Avg Loss  729: 0.166995

Train Avg F1  729: 0.7192707512155652

Val Avg Loss  729: 0.178967

Val Avg F1  729:  0.6882479374728615

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 730
--------------------------------------------------------------
Epoch:  730        1 Batch loss: 0.192638 Batch F1: 0.6521739130434783
Epoch:  730        2 Batch loss: 0.175257 Batch F1: 0.7272727272727273
Epoch:  730        3 Batch loss: 0.211977 Batch F1: 0.5365853658536585
Epoch:  730        4 Batch loss: 0.156545 Batch F1: 0.7916666666666667
Epoch:  730        5 Batch loss: 0.146177 Batch F1: 0.7906976744186046
Epoch:  730        6 Batch loss: 0.156656 Batch F1: 0.7142857142857143
Epoch:  730        7 Batch loss: 0.174567 Batch F1: 0.5945945945945946
Epoch:  730        8 Batch loss: 0.143920 Batch F1: 0.8571428571428572
Epoch:  730        9 Batch loss: 0.141534 Batch F1: 0.7428571428571428
Epoch:  730       10 Batch loss: 0.175061 Batch F1: 0.75
Epoch:  730       11 Batch loss: 0.142944 Batch F1: 0.8627450980392156
Epoch:  730       12 Batch loss: 0.170817 Batch F1: 0.6666666666666667
Train Avg Loss  730: 0.165674

Train Avg F1  730: 0.7238907017367772

Val Avg Loss  730: 0.179648

Val Avg F1  730:  0.6933704078193461

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 731
--------------------------------------------------------------
Epoch:  731        1 Batch loss: 0.166130 Batch F1: 0.6829268292682927
Epoch:  731        2 Batch loss: 0.177354 Batch F1: 0.68
Epoch:  731        3 Batch loss: 0.167408 Batch F1: 0.7692307692307693
Epoch:  731        4 Batch loss: 0.152649 Batch F1: 0.8181818181818182
Epoch:  731        5 Batch loss: 0.191376 Batch F1: 0.6190476190476191
Epoch:  731        6 Batch loss: 0.171066 Batch F1: 0.7027027027027026
Epoch:  731        7 Batch loss: 0.144105 Batch F1: 0.75
Epoch:  731        8 Batch loss: 0.177884 Batch F1: 0.6938775510204083
Epoch:  731        9 Batch loss: 0.156166 Batch F1: 0.7499999999999999
Epoch:  731       10 Batch loss: 0.219381 Batch F1: 0.6666666666666666
Epoch:  731       11 Batch loss: 0.152984 Batch F1: 0.8085106382978724
Epoch:  731       12 Batch loss: 0.157271 Batch F1: 0.6857142857142857
Train Avg Loss  731: 0.169481

Train Avg F1  731: 0.7189049066775363

Val Avg Loss  731: 0.182047

Val Avg F1  731:  0.7231836867943737

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 732
--------------------------------------------------------------
Epoch:  732        1 Batch loss: 0.137926 Batch F1: 0.88
Epoch:  732        2 Batch loss: 0.161325 Batch F1: 0.7727272727272727
Epoch:  732        3 Batch loss: 0.173375 Batch F1: 0.6808510638297872
Epoch:  732        4 Batch loss: 0.166986 Batch F1: 0.6486486486486486
Epoch:  732        5 Batch loss: 0.146838 Batch F1: 0.8085106382978724
Epoch:  732        6 Batch loss: 0.211285 Batch F1: 0.6122448979591837
Epoch:  732        7 Batch loss: 0.182048 Batch F1: 0.6666666666666666
Epoch:  732        8 Batch loss: 0.173472 Batch F1: 0.7450980392156863
Epoch:  732        9 Batch loss: 0.161450 Batch F1: 0.5806451612903225
Epoch:  732       10 Batch loss: 0.157791 Batch F1: 0.7441860465116279
Epoch:  732       11 Batch loss: 0.180058 Batch F1: 0.6341463414634146
Epoch:  732       12 Batch loss: 0.190626 Batch F1: 0.711111111111111
Train Avg Loss  732: 0.170265

Train Avg F1  732: 0.7070696573101328

Val Avg Loss  732: 0.181605

Val Avg F1  732:  0.6876235177865613

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 733
--------------------------------------------------------------
Epoch:  733        1 Batch loss: 0.173925 Batch F1: 0.7450980392156863
Epoch:  733        2 Batch loss: 0.166872 Batch F1: 0.7234042553191491
Epoch:  733        3 Batch loss: 0.175614 Batch F1: 0.65
Epoch:  733        4 Batch loss: 0.192034 Batch F1: 0.6086956521739131
Epoch:  733        5 Batch loss: 0.148696 Batch F1: 0.7692307692307692
Epoch:  733        6 Batch loss: 0.135888 Batch F1: 0.8444444444444444
Epoch:  733        7 Batch loss: 0.139520 Batch F1: 0.56
Epoch:  733        8 Batch loss: 0.185180 Batch F1: 0.72
Epoch:  733        9 Batch loss: 0.190189 Batch F1: 0.5909090909090909
Epoch:  733       10 Batch loss: 0.167140 Batch F1: 0.76
Epoch:  733       11 Batch loss: 0.148836 Batch F1: 0.7916666666666667
Epoch:  733       12 Batch loss: 0.151798 Batch F1: 0.7894736842105262
Train Avg Loss  733: 0.164641

Train Avg F1  733: 0.7127435501808539

Val Avg Loss  733: 0.178912

Val Avg F1  733:  0.6823216520650814

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 734
--------------------------------------------------------------
Epoch:  734        1 Batch loss: 0.169065 Batch F1: 0.723404255319149
Epoch:  734        2 Batch loss: 0.163313 Batch F1: 0.7272727272727272
Epoch:  734        3 Batch loss: 0.186005 Batch F1: 0.5714285714285715
Epoch:  734        4 Batch loss: 0.165568 Batch F1: 0.6829268292682926
Epoch:  734        5 Batch loss: 0.168457 Batch F1: 0.7
Epoch:  734        6 Batch loss: 0.189621 Batch F1: 0.68
Epoch:  734        7 Batch loss: 0.166368 Batch F1: 0.8333333333333334
Epoch:  734        8 Batch loss: 0.166202 Batch F1: 0.7142857142857143
Epoch:  734        9 Batch loss: 0.158403 Batch F1: 0.7916666666666667
Epoch:  734       10 Batch loss: 0.134025 Batch F1: 0.8181818181818182
Epoch:  734       11 Batch loss: 0.165255 Batch F1: 0.7142857142857143
Epoch:  734       12 Batch loss: 0.155231 Batch F1: 0.6428571428571429
Train Avg Loss  734: 0.165626

Train Avg F1  734: 0.7166368977415942

Val Avg Loss  734: 0.179004

Val Avg F1  734:  0.6905186575217631

Optimal Val loss (Epoch 640): 0.17881222069263458

Epoch 735
--------------------------------------------------------------
Epoch:  735        1 Batch loss: 0.190510 Batch F1: 0.631578947368421
Epoch:  735        2 Batch loss: 0.122820 Batch F1: 0.8421052631578948
Epoch:  735        3 Batch loss: 0.171575 Batch F1: 0.6666666666666667
Epoch:  735        4 Batch loss: 0.155792 Batch F1: 0.830188679245283
Epoch:  735        5 Batch loss: 0.135126 Batch F1: 0.8181818181818182
Epoch:  735        6 Batch loss: 0.150881 Batch F1: 0.717948717948718
Epoch:  735        7 Batch loss: 0.196901 Batch F1: 0.5454545454545454
Epoch:  735        8 Batch loss: 0.177475 Batch F1: 0.7083333333333334
Epoch:  735        9 Batch loss: 0.178543 Batch F1: 0.6923076923076923
Epoch:  735       10 Batch loss: 0.175329 Batch F1: 0.7083333333333334
Epoch:  735       11 Batch loss: 0.145901 Batch F1: 0.7692307692307693
Epoch:  735       12 Batch loss: 0.192589 Batch F1: 0.7391304347826088
Train Avg Loss  735: 0.166120

Train Avg F1  735: 0.7224550167509237

Val Avg Loss  735: 0.178797

Val Avg F1  735:  0.7083954806473263

Optimal Val loss (Epoch 735): 0.17879743501544

Epoch 736
--------------------------------------------------------------
Epoch:  736        1 Batch loss: 0.140722 Batch F1: 0.6666666666666667
Epoch:  736        2 Batch loss: 0.156543 Batch F1: 0.8
Epoch:  736        3 Batch loss: 0.181536 Batch F1: 0.6341463414634148
Epoch:  736        4 Batch loss: 0.175619 Batch F1: 0.7058823529411765
Epoch:  736        5 Batch loss: 0.162742 Batch F1: 0.6486486486486486
Epoch:  736        6 Batch loss: 0.145839 Batch F1: 0.6857142857142857
Epoch:  736        7 Batch loss: 0.180668 Batch F1: 0.6808510638297872
Epoch:  736        8 Batch loss: 0.182157 Batch F1: 0.7586206896551724
Epoch:  736        9 Batch loss: 0.168938 Batch F1: 0.723404255319149
Epoch:  736       10 Batch loss: 0.145026 Batch F1: 0.7916666666666666
Epoch:  736       11 Batch loss: 0.169673 Batch F1: 0.7083333333333334
Epoch:  736       12 Batch loss: 0.150299 Batch F1: 0.7567567567567567
Train Avg Loss  736: 0.163313

Train Avg F1  736: 0.7133909217495882

Val Avg Loss  736: 0.181334

Val Avg F1  736:  0.6821423039634688

Optimal Val loss (Epoch 735): 0.17879743501544

Epoch 737
--------------------------------------------------------------
Epoch:  737        1 Batch loss: 0.179262 Batch F1: 0.7083333333333333
Epoch:  737        2 Batch loss: 0.168976 Batch F1: 0.7499999999999999
Epoch:  737        3 Batch loss: 0.166935 Batch F1: 0.6666666666666666
Epoch:  737        4 Batch loss: 0.164692 Batch F1: 0.6666666666666666
Epoch:  737        5 Batch loss: 0.177722 Batch F1: 0.6829268292682927
Epoch:  737        6 Batch loss: 0.173561 Batch F1: 0.7499999999999999
Epoch:  737        7 Batch loss: 0.124800 Batch F1: 0.8421052631578948
Epoch:  737        8 Batch loss: 0.158255 Batch F1: 0.8444444444444444
Epoch:  737        9 Batch loss: 0.167973 Batch F1: 0.6829268292682927
Epoch:  737       10 Batch loss: 0.194778 Batch F1: 0.693877551020408
Epoch:  737       11 Batch loss: 0.165515 Batch F1: 0.76
Epoch:  737       12 Batch loss: 0.164346 Batch F1: 0.7692307692307692
Train Avg Loss  737: 0.167234

Train Avg F1  737: 0.7347648627547306

Val Avg Loss  737: 0.180436

Val Avg F1  737:  0.7279698039011433

Optimal Val loss (Epoch 735): 0.17879743501544

Epoch 738
--------------------------------------------------------------
Epoch:  738        1 Batch loss: 0.183376 Batch F1: 0.8064516129032258
Epoch:  738        2 Batch loss: 0.179363 Batch F1: 0.7234042553191491
Epoch:  738        3 Batch loss: 0.158020 Batch F1: 0.7727272727272727
Epoch:  738        4 Batch loss: 0.160547 Batch F1: 0.6842105263157895
Epoch:  738        5 Batch loss: 0.145619 Batch F1: 0.8333333333333334
Epoch:  738        6 Batch loss: 0.152692 Batch F1: 0.6470588235294117
Epoch:  738        7 Batch loss: 0.174476 Batch F1: 0.7777777777777778
Epoch:  738        8 Batch loss: 0.168082 Batch F1: 0.6818181818181819
Epoch:  738        9 Batch loss: 0.195864 Batch F1: 0.5909090909090909
Epoch:  738       10 Batch loss: 0.171192 Batch F1: 0.65
Epoch:  738       11 Batch loss: 0.150099 Batch F1: 0.7659574468085107
Epoch:  738       12 Batch loss: 0.156393 Batch F1: 0.7272727272727272
Train Avg Loss  738: 0.166310

Train Avg F1  738: 0.7217434207262059

Val Avg Loss  738: 0.179793

Val Avg F1  738:  0.6899551176878905

Optimal Val loss (Epoch 735): 0.17879743501544

Epoch 739
--------------------------------------------------------------
Epoch:  739        1 Batch loss: 0.138136 Batch F1: 0.7692307692307693
Epoch:  739        2 Batch loss: 0.190503 Batch F1: 0.5
Epoch:  739        3 Batch loss: 0.156946 Batch F1: 0.7317073170731706
Epoch:  739        4 Batch loss: 0.164788 Batch F1: 0.6153846153846153
Epoch:  739        5 Batch loss: 0.173530 Batch F1: 0.7391304347826088
Epoch:  739        6 Batch loss: 0.188641 Batch F1: 0.7058823529411765
Epoch:  739        7 Batch loss: 0.146263 Batch F1: 0.7906976744186046
Epoch:  739        8 Batch loss: 0.154704 Batch F1: 0.8571428571428571
Epoch:  739        9 Batch loss: 0.163199 Batch F1: 0.7441860465116279
Epoch:  739       10 Batch loss: 0.158729 Batch F1: 0.8070175438596492
Epoch:  739       11 Batch loss: 0.162773 Batch F1: 0.711111111111111
Epoch:  739       12 Batch loss: 0.174812 Batch F1: 0.7500000000000001
Train Avg Loss  739: 0.164419

Train Avg F1  739: 0.7267908935380158

Val Avg Loss  739: 0.181083

Val Avg F1  739:  0.671001880179621

Optimal Val loss (Epoch 735): 0.17879743501544

Epoch 740
--------------------------------------------------------------
Epoch:  740        1 Batch loss: 0.175974 Batch F1: 0.6046511627906976
Epoch:  740        2 Batch loss: 0.181145 Batch F1: 0.6511627906976745
Epoch:  740        3 Batch loss: 0.155666 Batch F1: 0.6857142857142857
Epoch:  740        4 Batch loss: 0.145723 Batch F1: 0.7727272727272727
Epoch:  740        5 Batch loss: 0.162975 Batch F1: 0.711111111111111
Epoch:  740        6 Batch loss: 0.167745 Batch F1: 0.7391304347826088
Epoch:  740        7 Batch loss: 0.169282 Batch F1: 0.7555555555555556
Epoch:  740        8 Batch loss: 0.177487 Batch F1: 0.6976744186046512
Epoch:  740        9 Batch loss: 0.182314 Batch F1: 0.6341463414634146
Epoch:  740       10 Batch loss: 0.161346 Batch F1: 0.7916666666666667
Epoch:  740       11 Batch loss: 0.155769 Batch F1: 0.7843137254901961
Epoch:  740       12 Batch loss: 0.153683 Batch F1: 0.7222222222222223
Train Avg Loss  740: 0.165759

Train Avg F1  740: 0.7125063323188631

Val Avg Loss  740: 0.182094

Val Avg F1  740:  0.69606274224065

Optimal Val loss (Epoch 735): 0.17879743501544

Epoch 741
--------------------------------------------------------------
Epoch:  741        1 Batch loss: 0.163461 Batch F1: 0.7272727272727272
Epoch:  741        2 Batch loss: 0.182196 Batch F1: 0.7142857142857142
Epoch:  741        3 Batch loss: 0.186591 Batch F1: 0.64
Epoch:  741        4 Batch loss: 0.155606 Batch F1: 0.761904761904762
Epoch:  741        5 Batch loss: 0.143152 Batch F1: 0.8085106382978724
Epoch:  741        6 Batch loss: 0.192954 Batch F1: 0.6222222222222223
Epoch:  741        7 Batch loss: 0.169441 Batch F1: 0.6956521739130435
Epoch:  741        8 Batch loss: 0.147736 Batch F1: 0.8292682926829269
Epoch:  741        9 Batch loss: 0.167800 Batch F1: 0.7234042553191491
Epoch:  741       10 Batch loss: 0.166269 Batch F1: 0.7
Epoch:  741       11 Batch loss: 0.164324 Batch F1: 0.7272727272727272
Epoch:  741       12 Batch loss: 0.169443 Batch F1: 0.5925925925925926
Train Avg Loss  741: 0.167414

Train Avg F1  741: 0.7118655088136449

Val Avg Loss  741: 0.178650

Val Avg F1  741:  0.6782876676169359

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 742
--------------------------------------------------------------
Epoch:  742        1 Batch loss: 0.192913 Batch F1: 0.5714285714285715
Epoch:  742        2 Batch loss: 0.144524 Batch F1: 0.6875000000000001
Epoch:  742        3 Batch loss: 0.168091 Batch F1: 0.72
Epoch:  742        4 Batch loss: 0.164928 Batch F1: 0.6250000000000001
Epoch:  742        5 Batch loss: 0.155906 Batch F1: 0.7142857142857143
Epoch:  742        6 Batch loss: 0.183893 Batch F1: 0.7058823529411765
Epoch:  742        7 Batch loss: 0.182674 Batch F1: 0.6
Epoch:  742        8 Batch loss: 0.153173 Batch F1: 0.761904761904762
Epoch:  742        9 Batch loss: 0.164736 Batch F1: 0.6829268292682926
Epoch:  742       10 Batch loss: 0.148257 Batch F1: 0.8524590163934426
Epoch:  742       11 Batch loss: 0.161497 Batch F1: 0.782608695652174
Epoch:  742       12 Batch loss: 0.174454 Batch F1: 0.7727272727272727
Train Avg Loss  742: 0.166254

Train Avg F1  742: 0.7063936012167839

Val Avg Loss  742: 0.180294

Val Avg F1  742:  0.7167283298097251

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 743
--------------------------------------------------------------
Epoch:  743        1 Batch loss: 0.176435 Batch F1: 0.7346938775510204
Epoch:  743        2 Batch loss: 0.178942 Batch F1: 0.7272727272727272
Epoch:  743        3 Batch loss: 0.160133 Batch F1: 0.6470588235294118
Epoch:  743        4 Batch loss: 0.159677 Batch F1: 0.744186046511628
Epoch:  743        5 Batch loss: 0.163396 Batch F1: 0.7391304347826088
Epoch:  743        6 Batch loss: 0.180203 Batch F1: 0.761904761904762
Epoch:  743        7 Batch loss: 0.136798 Batch F1: 0.8
Epoch:  743        8 Batch loss: 0.155788 Batch F1: 0.8148148148148148
Epoch:  743        9 Batch loss: 0.158567 Batch F1: 0.7368421052631577
Epoch:  743       10 Batch loss: 0.175432 Batch F1: 0.6382978723404256
Epoch:  743       11 Batch loss: 0.182060 Batch F1: 0.7142857142857143
Epoch:  743       12 Batch loss: 0.200520 Batch F1: 0.6666666666666666
Train Avg Loss  743: 0.168996

Train Avg F1  743: 0.7270961537435779

Val Avg Loss  743: 0.184772

Val Avg F1  743:  0.7566837665499299

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 744
--------------------------------------------------------------
Epoch:  744        1 Batch loss: 0.181201 Batch F1: 0.6818181818181818
Epoch:  744        2 Batch loss: 0.180836 Batch F1: 0.6808510638297872
Epoch:  744        3 Batch loss: 0.174109 Batch F1: 0.7441860465116279
Epoch:  744        4 Batch loss: 0.152249 Batch F1: 0.7826086956521738
Epoch:  744        5 Batch loss: 0.181270 Batch F1: 0.6511627906976744
Epoch:  744        6 Batch loss: 0.164562 Batch F1: 0.8275862068965517
Epoch:  744        7 Batch loss: 0.179762 Batch F1: 0.7200000000000001
Epoch:  744        8 Batch loss: 0.165043 Batch F1: 0.6842105263157895
Epoch:  744        9 Batch loss: 0.175774 Batch F1: 0.76
Epoch:  744       10 Batch loss: 0.154355 Batch F1: 0.8510638297872342
Epoch:  744       11 Batch loss: 0.166352 Batch F1: 0.6486486486486486
Epoch:  744       12 Batch loss: 0.165563 Batch F1: 0.6666666666666667
Train Avg Loss  744: 0.170090

Train Avg F1  744: 0.7249002214020278

Val Avg Loss  744: 0.189658

Val Avg F1  744:  0.5890560658853342

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 745
--------------------------------------------------------------
Epoch:  745        1 Batch loss: 0.206204 Batch F1: 0.6511627906976745
Epoch:  745        2 Batch loss: 0.146056 Batch F1: 0.8333333333333334
Epoch:  745        3 Batch loss: 0.169450 Batch F1: 0.851851851851852
Epoch:  745        4 Batch loss: 0.178623 Batch F1: 0.8421052631578948
Epoch:  745        5 Batch loss: 0.161443 Batch F1: 0.8333333333333333
Epoch:  745        6 Batch loss: 0.190405 Batch F1: 0.7441860465116279
Epoch:  745        7 Batch loss: 0.145360 Batch F1: 0.8260869565217391
Epoch:  745        8 Batch loss: 0.191540 Batch F1: 0.6938775510204083
Epoch:  745        9 Batch loss: 0.185132 Batch F1: 0.6190476190476191
Epoch:  745       10 Batch loss: 0.158376 Batch F1: 0.7000000000000001
Epoch:  745       11 Batch loss: 0.185094 Batch F1: 0.6486486486486486
Epoch:  745       12 Batch loss: 0.142079 Batch F1: 0.7741935483870968
Train Avg Loss  745: 0.171647

Train Avg F1  745: 0.7514855785426023

Val Avg Loss  745: 0.184933

Val Avg F1  745:  0.6876172607879926

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 746
--------------------------------------------------------------
Epoch:  746        1 Batch loss: 0.164239 Batch F1: 0.7142857142857143
Epoch:  746        2 Batch loss: 0.180876 Batch F1: 0.6808510638297872
Epoch:  746        3 Batch loss: 0.154315 Batch F1: 0.8813559322033899
Epoch:  746        4 Batch loss: 0.156597 Batch F1: 0.7272727272727272
Epoch:  746        5 Batch loss: 0.164398 Batch F1: 0.75
Epoch:  746        6 Batch loss: 0.151817 Batch F1: 0.8163265306122449
Epoch:  746        7 Batch loss: 0.167000 Batch F1: 0.7346938775510204
Epoch:  746        8 Batch loss: 0.192152 Batch F1: 0.6046511627906976
Epoch:  746        9 Batch loss: 0.162399 Batch F1: 0.6285714285714286
Epoch:  746       10 Batch loss: 0.164011 Batch F1: 0.6842105263157895
Epoch:  746       11 Batch loss: 0.173137 Batch F1: 0.6829268292682927
Epoch:  746       12 Batch loss: 0.187987 Batch F1: 0.5625
Train Avg Loss  746: 0.168244

Train Avg F1  746: 0.7056371493917576

Val Avg Loss  746: 0.181530

Val Avg F1  746:  0.6931088426271084

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 747
--------------------------------------------------------------
Epoch:  747        1 Batch loss: 0.185993 Batch F1: 0.6923076923076923
Epoch:  747        2 Batch loss: 0.176598 Batch F1: 0.6666666666666666
Epoch:  747        3 Batch loss: 0.177082 Batch F1: 0.6363636363636365
Epoch:  747        4 Batch loss: 0.185326 Batch F1: 0.8214285714285715
Epoch:  747        5 Batch loss: 0.152803 Batch F1: 0.7727272727272727
Epoch:  747        6 Batch loss: 0.163264 Batch F1: 0.7499999999999999
Epoch:  747        7 Batch loss: 0.192836 Batch F1: 0.627450980392157
Epoch:  747        8 Batch loss: 0.168066 Batch F1: 0.8461538461538461
Epoch:  747        9 Batch loss: 0.170404 Batch F1: 0.8750000000000001
Epoch:  747       10 Batch loss: 0.149206 Batch F1: 0.8846153846153847
Epoch:  747       11 Batch loss: 0.203142 Batch F1: 0.6808510638297872
Epoch:  747       12 Batch loss: 0.147107 Batch F1: 0.7500000000000001
Train Avg Loss  747: 0.172652

Train Avg F1  747: 0.7502970928737512

Val Avg Loss  747: 0.187054

Val Avg F1  747:  0.6766258741258742

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 748
--------------------------------------------------------------
Epoch:  748        1 Batch loss: 0.166402 Batch F1: 0.6829268292682926
Epoch:  748        2 Batch loss: 0.194205 Batch F1: 0.6666666666666667
Epoch:  748        3 Batch loss: 0.161117 Batch F1: 0.7222222222222222
Epoch:  748        4 Batch loss: 0.193011 Batch F1: 0.6
Epoch:  748        5 Batch loss: 0.171482 Batch F1: 0.6956521739130435
Epoch:  748        6 Batch loss: 0.178458 Batch F1: 0.8076923076923077
Epoch:  748        7 Batch loss: 0.193852 Batch F1: 0.4666666666666667
Epoch:  748        8 Batch loss: 0.194967 Batch F1: 0.6111111111111112
Epoch:  748        9 Batch loss: 0.172263 Batch F1: 0.7999999999999999
Epoch:  748       10 Batch loss: 0.161066 Batch F1: 0.7755102040816326
Epoch:  748       11 Batch loss: 0.145662 Batch F1: 0.8852459016393444
Epoch:  748       12 Batch loss: 0.159798 Batch F1: 0.8750000000000001
Train Avg Loss  748: 0.174357

Train Avg F1  748: 0.7157245069384407

Val Avg Loss  748: 0.186448

Val Avg F1  748:  0.744021587087075

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 749
--------------------------------------------------------------
Epoch:  749        1 Batch loss: 0.197205 Batch F1: 0.7083333333333333
Epoch:  749        2 Batch loss: 0.134841 Batch F1: 0.8695652173913043
Epoch:  749        3 Batch loss: 0.160861 Batch F1: 0.7692307692307692
Epoch:  749        4 Batch loss: 0.189146 Batch F1: 0.6341463414634148
Epoch:  749        5 Batch loss: 0.177190 Batch F1: 0.6190476190476191
Epoch:  749        6 Batch loss: 0.201314 Batch F1: 0.5853658536585366
Epoch:  749        7 Batch loss: 0.164305 Batch F1: 0.7755102040816326
Epoch:  749        8 Batch loss: 0.178110 Batch F1: 0.7111111111111111
Epoch:  749        9 Batch loss: 0.159406 Batch F1: 0.7555555555555555
Epoch:  749       10 Batch loss: 0.153835 Batch F1: 0.830188679245283
Epoch:  749       11 Batch loss: 0.162881 Batch F1: 0.7317073170731707
Epoch:  749       12 Batch loss: 0.171356 Batch F1: 0.7647058823529411
Train Avg Loss  749: 0.170871

Train Avg F1  749: 0.7295389902953892

Val Avg Loss  749: 0.182119

Val Avg F1  749:  0.7026148108996946

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 750
--------------------------------------------------------------
Epoch:  750        1 Batch loss: 0.137390 Batch F1: 0.8444444444444444
Epoch:  750        2 Batch loss: 0.184939 Batch F1: 0.7407407407407408
Epoch:  750        3 Batch loss: 0.167209 Batch F1: 0.7499999999999999
Epoch:  750        4 Batch loss: 0.193812 Batch F1: 0.6046511627906976
Epoch:  750        5 Batch loss: 0.154325 Batch F1: 0.8
Epoch:  750        6 Batch loss: 0.174851 Batch F1: 0.7916666666666666
Epoch:  750        7 Batch loss: 0.157134 Batch F1: 0.7441860465116279
Epoch:  750        8 Batch loss: 0.155111 Batch F1: 0.7619047619047619
Epoch:  750        9 Batch loss: 0.164134 Batch F1: 0.4827586206896552
Epoch:  750       10 Batch loss: 0.197101 Batch F1: 0.6250000000000001
Epoch:  750       11 Batch loss: 0.174716 Batch F1: 0.5714285714285715
Epoch:  750       12 Batch loss: 0.167381 Batch F1: 0.7804878048780488
Train Avg Loss  750: 0.169009

Train Avg F1  750: 0.7081057350046011

Val Avg Loss  750: 0.183563

Val Avg F1  750:  0.6880938027489751

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 751
--------------------------------------------------------------
Epoch:  751        1 Batch loss: 0.175572 Batch F1: 0.7450980392156864
Epoch:  751        2 Batch loss: 0.182298 Batch F1: 0.6829268292682927
Epoch:  751        3 Batch loss: 0.191613 Batch F1: 0.6086956521739131
Epoch:  751        4 Batch loss: 0.165057 Batch F1: 0.6842105263157895
Epoch:  751        5 Batch loss: 0.145023 Batch F1: 0.7804878048780488
Epoch:  751        6 Batch loss: 0.182075 Batch F1: 0.5789473684210527
Epoch:  751        7 Batch loss: 0.177733 Batch F1: 0.5714285714285715
Epoch:  751        8 Batch loss: 0.134145 Batch F1: 0.7878787878787877
Epoch:  751        9 Batch loss: 0.154651 Batch F1: 0.7999999999999999
Epoch:  751       10 Batch loss: 0.185071 Batch F1: 0.8301886792452831
Epoch:  751       11 Batch loss: 0.181727 Batch F1: 0.7450980392156864
Epoch:  751       12 Batch loss: 0.171760 Batch F1: 0.7317073170731706
Train Avg Loss  751: 0.170561

Train Avg F1  751: 0.7122223012595236

Val Avg Loss  751: 0.183726

Val Avg F1  751:  0.7105612087573234

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 752
--------------------------------------------------------------
Epoch:  752        1 Batch loss: 0.189407 Batch F1: 0.7083333333333333
Epoch:  752        2 Batch loss: 0.171092 Batch F1: 0.7272727272727272
Epoch:  752        3 Batch loss: 0.173402 Batch F1: 0.7346938775510204
Epoch:  752        4 Batch loss: 0.149722 Batch F1: 0.7906976744186046
Epoch:  752        5 Batch loss: 0.146775 Batch F1: 0.7317073170731706
Epoch:  752        6 Batch loss: 0.163601 Batch F1: 0.6976744186046512
Epoch:  752        7 Batch loss: 0.190356 Batch F1: 0.6808510638297872
Epoch:  752        8 Batch loss: 0.176713 Batch F1: 0.7346938775510203
Epoch:  752        9 Batch loss: 0.169294 Batch F1: 0.7
Epoch:  752       10 Batch loss: 0.185382 Batch F1: 0.6511627906976745
Epoch:  752       11 Batch loss: 0.178927 Batch F1: 0.7272727272727273
Epoch:  752       12 Batch loss: 0.171185 Batch F1: 0.7500000000000001
Train Avg Loss  752: 0.172155

Train Avg F1  752: 0.7195299839670598

Val Avg Loss  752: 0.185525

Val Avg F1  752:  0.7335475844909807

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 753
--------------------------------------------------------------
Epoch:  753        1 Batch loss: 0.147546 Batch F1: 0.8148148148148148
Epoch:  753        2 Batch loss: 0.185693 Batch F1: 0.7391304347826089
Epoch:  753        3 Batch loss: 0.167513 Batch F1: 0.6976744186046512
Epoch:  753        4 Batch loss: 0.147694 Batch F1: 0.8181818181818182
Epoch:  753        5 Batch loss: 0.172741 Batch F1: 0.6511627906976744
Epoch:  753        6 Batch loss: 0.217724 Batch F1: 0.5652173913043478
Epoch:  753        7 Batch loss: 0.184881 Batch F1: 0.7555555555555555
Epoch:  753        8 Batch loss: 0.147678 Batch F1: 0.7894736842105263
Epoch:  753        9 Batch loss: 0.180092 Batch F1: 0.7083333333333334
Epoch:  753       10 Batch loss: 0.170543 Batch F1: 0.7346938775510203
Epoch:  753       11 Batch loss: 0.155300 Batch F1: 0.7826086956521738
Epoch:  753       12 Batch loss: 0.162603 Batch F1: 0.7567567567567567
Train Avg Loss  753: 0.170001

Train Avg F1  753: 0.7344669642871068

Val Avg Loss  753: 0.182819

Val Avg F1  753:  0.699009009009009

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 754
--------------------------------------------------------------
Epoch:  754        1 Batch loss: 0.142590 Batch F1: 0.8292682926829269
Epoch:  754        2 Batch loss: 0.185695 Batch F1: 0.5806451612903226
Epoch:  754        3 Batch loss: 0.178620 Batch F1: 0.717948717948718
Epoch:  754        4 Batch loss: 0.170763 Batch F1: 0.6666666666666665
Epoch:  754        5 Batch loss: 0.197085 Batch F1: 0.5909090909090909
Epoch:  754        6 Batch loss: 0.172888 Batch F1: 0.6818181818181819
Epoch:  754        7 Batch loss: 0.154575 Batch F1: 0.819672131147541
Epoch:  754        8 Batch loss: 0.226022 Batch F1: 0.625
Epoch:  754        9 Batch loss: 0.168780 Batch F1: 0.7659574468085107
Epoch:  754       10 Batch loss: 0.165638 Batch F1: 0.6829268292682927
Epoch:  754       11 Batch loss: 0.138608 Batch F1: 0.8372093023255814
Epoch:  754       12 Batch loss: 0.170749 Batch F1: 0.782608695652174
Train Avg Loss  754: 0.172668

Train Avg F1  754: 0.7150525430431672

Val Avg Loss  754: 0.182205

Val Avg F1  754:  0.6878558947476616

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 755
--------------------------------------------------------------
Epoch:  755        1 Batch loss: 0.185676 Batch F1: 0.6363636363636365
Epoch:  755        2 Batch loss: 0.183150 Batch F1: 0.5789473684210527
Epoch:  755        3 Batch loss: 0.151133 Batch F1: 0.7826086956521738
Epoch:  755        4 Batch loss: 0.177801 Batch F1: 0.6666666666666666
Epoch:  755        5 Batch loss: 0.185191 Batch F1: 0.65
Epoch:  755        6 Batch loss: 0.152960 Batch F1: 0.6857142857142856
Epoch:  755        7 Batch loss: 0.141820 Batch F1: 0.7692307692307692
Epoch:  755        8 Batch loss: 0.169839 Batch F1: 0.7999999999999999
Epoch:  755        9 Batch loss: 0.159297 Batch F1: 0.7727272727272727
Epoch:  755       10 Batch loss: 0.166002 Batch F1: 0.8148148148148148
Epoch:  755       11 Batch loss: 0.182405 Batch F1: 0.6666666666666666
Epoch:  755       12 Batch loss: 0.175869 Batch F1: 0.6857142857142857
Train Avg Loss  755: 0.169262

Train Avg F1  755: 0.709121205164302

Val Avg Loss  755: 0.179671

Val Avg F1  755:  0.69145748738772

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 756
--------------------------------------------------------------
Epoch:  756        1 Batch loss: 0.173205 Batch F1: 0.7547169811320754
Epoch:  756        2 Batch loss: 0.152684 Batch F1: 0.6666666666666667
Epoch:  756        3 Batch loss: 0.155674 Batch F1: 0.7307692307692307
Epoch:  756        4 Batch loss: 0.193053 Batch F1: 0.6956521739130435
Epoch:  756        5 Batch loss: 0.168795 Batch F1: 0.7826086956521738
Epoch:  756        6 Batch loss: 0.198322 Batch F1: 0.6521739130434783
Epoch:  756        7 Batch loss: 0.164046 Batch F1: 0.631578947368421
Epoch:  756        8 Batch loss: 0.196048 Batch F1: 0.5714285714285715
Epoch:  756        9 Batch loss: 0.146633 Batch F1: 0.8444444444444444
Epoch:  756       10 Batch loss: 0.157905 Batch F1: 0.7142857142857143
Epoch:  756       11 Batch loss: 0.148475 Batch F1: 0.7906976744186046
Epoch:  756       12 Batch loss: 0.167043 Batch F1: 0.7727272727272727
Train Avg Loss  756: 0.168490

Train Avg F1  756: 0.7173125238208081

Val Avg Loss  756: 0.180335

Val Avg F1  756:  0.6848176333470452

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 757
--------------------------------------------------------------
Epoch:  757        1 Batch loss: 0.187519 Batch F1: 0.7142857142857143
Epoch:  757        2 Batch loss: 0.164242 Batch F1: 0.7692307692307692
Epoch:  757        3 Batch loss: 0.168755 Batch F1: 0.8085106382978723
Epoch:  757        4 Batch loss: 0.148659 Batch F1: 0.7804878048780488
Epoch:  757        5 Batch loss: 0.174139 Batch F1: 0.5161290322580646
Epoch:  757        6 Batch loss: 0.186327 Batch F1: 0.6666666666666666
Epoch:  757        7 Batch loss: 0.183525 Batch F1: 0.6666666666666667
Epoch:  757        8 Batch loss: 0.203987 Batch F1: 0.6666666666666667
Epoch:  757        9 Batch loss: 0.152376 Batch F1: 0.7727272727272727
Epoch:  757       10 Batch loss: 0.147754 Batch F1: 0.7567567567567567
Epoch:  757       11 Batch loss: 0.150940 Batch F1: 0.7659574468085107
Epoch:  757       12 Batch loss: 0.184326 Batch F1: 0.7000000000000001
Train Avg Loss  757: 0.171046

Train Avg F1  757: 0.7153404529369175

Val Avg Loss  757: 0.186846

Val Avg F1  757:  0.655

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 758
--------------------------------------------------------------
Epoch:  758        1 Batch loss: 0.172642 Batch F1: 0.6666666666666667
Epoch:  758        2 Batch loss: 0.152226 Batch F1: 0.761904761904762
Epoch:  758        3 Batch loss: 0.174758 Batch F1: 0.7272727272727273
Epoch:  758        4 Batch loss: 0.174763 Batch F1: 0.6511627906976744
Epoch:  758        5 Batch loss: 0.164615 Batch F1: 0.7555555555555555
Epoch:  758        6 Batch loss: 0.181897 Batch F1: 0.7027027027027026
Epoch:  758        7 Batch loss: 0.188017 Batch F1: 0.7346938775510203
Epoch:  758        8 Batch loss: 0.176674 Batch F1: 0.6666666666666666
Epoch:  758        9 Batch loss: 0.168422 Batch F1: 0.7916666666666666
Epoch:  758       10 Batch loss: 0.191062 Batch F1: 0.7547169811320756
Epoch:  758       11 Batch loss: 0.175910 Batch F1: 0.7547169811320754
Epoch:  758       12 Batch loss: 0.199700 Batch F1: 0.6857142857142857
Train Avg Loss  758: 0.176724

Train Avg F1  758: 0.7211200553052399

Val Avg Loss  758: 0.180376

Val Avg F1  758:  0.7283102518396636

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 759
--------------------------------------------------------------
Epoch:  759        1 Batch loss: 0.213590 Batch F1: 0.5945945945945946
Epoch:  759        2 Batch loss: 0.149144 Batch F1: 0.8333333333333333
Epoch:  759        3 Batch loss: 0.160041 Batch F1: 0.7234042553191489
Epoch:  759        4 Batch loss: 0.189484 Batch F1: 0.7727272727272727
Epoch:  759        5 Batch loss: 0.179411 Batch F1: 0.6829268292682926
Epoch:  759        6 Batch loss: 0.194925 Batch F1: 0.7391304347826086
Epoch:  759        7 Batch loss: 0.208480 Batch F1: 0.6285714285714286
Epoch:  759        8 Batch loss: 0.180071 Batch F1: 0.8064516129032259
Epoch:  759        9 Batch loss: 0.180311 Batch F1: 0.7999999999999999
Epoch:  759       10 Batch loss: 0.146927 Batch F1: 0.8571428571428572
Epoch:  759       11 Batch loss: 0.162592 Batch F1: 0.717948717948718
Epoch:  759       12 Batch loss: 0.166098 Batch F1: 0.6666666666666666
Train Avg Loss  759: 0.177589

Train Avg F1  759: 0.735241500271512

Val Avg Loss  759: 0.185044

Val Avg F1  759:  0.6422736512022226

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 760
--------------------------------------------------------------
Epoch:  760        1 Batch loss: 0.177647 Batch F1: 0.5641025641025642
Epoch:  760        2 Batch loss: 0.146433 Batch F1: 0.7804878048780488
Epoch:  760        3 Batch loss: 0.169130 Batch F1: 0.7924528301886792
Epoch:  760        4 Batch loss: 0.159289 Batch F1: 0.7727272727272727
Epoch:  760        5 Batch loss: 0.162752 Batch F1: 0.7111111111111111
Epoch:  760        6 Batch loss: 0.185100 Batch F1: 0.7441860465116279
Epoch:  760        7 Batch loss: 0.191103 Batch F1: 0.7843137254901961
Epoch:  760        8 Batch loss: 0.217091 Batch F1: 0.6382978723404256
Epoch:  760        9 Batch loss: 0.177910 Batch F1: 0.6500000000000001
Epoch:  760       10 Batch loss: 0.160173 Batch F1: 0.7555555555555555
Epoch:  760       11 Batch loss: 0.157889 Batch F1: 0.7000000000000001
Epoch:  760       12 Batch loss: 0.160554 Batch F1: 0.7906976744186046
Train Avg Loss  760: 0.172089

Train Avg F1  760: 0.7236610381103405

Val Avg Loss  760: 0.184732

Val Avg F1  760:  0.7395168323739753

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 761
--------------------------------------------------------------
Epoch:  761        1 Batch loss: 0.175244 Batch F1: 0.7999999999999999
Epoch:  761        2 Batch loss: 0.182401 Batch F1: 0.6829268292682926
Epoch:  761        3 Batch loss: 0.178660 Batch F1: 0.6808510638297872
Epoch:  761        4 Batch loss: 0.175047 Batch F1: 0.7843137254901961
Epoch:  761        5 Batch loss: 0.164667 Batch F1: 0.6285714285714287
Epoch:  761        6 Batch loss: 0.182651 Batch F1: 0.6111111111111113
Epoch:  761        7 Batch loss: 0.195706 Batch F1: 0.6808510638297872
Epoch:  761        8 Batch loss: 0.155106 Batch F1: 0.7441860465116279
Epoch:  761        9 Batch loss: 0.144776 Batch F1: 0.8095238095238095
Epoch:  761       10 Batch loss: 0.172104 Batch F1: 0.72
Epoch:  761       11 Batch loss: 0.180421 Batch F1: 0.6808510638297872
Epoch:  761       12 Batch loss: 0.177044 Batch F1: 0.6956521739130435
Train Avg Loss  761: 0.173652

Train Avg F1  761: 0.709903192989906

Val Avg Loss  761: 0.184261

Val Avg F1  761:  0.7024494055224951

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 762
--------------------------------------------------------------
Epoch:  762        1 Batch loss: 0.146153 Batch F1: 0.8148148148148148
Epoch:  762        2 Batch loss: 0.145288 Batch F1: 0.8181818181818182
Epoch:  762        3 Batch loss: 0.219976 Batch F1: 0.5333333333333332
Epoch:  762        4 Batch loss: 0.167744 Batch F1: 0.7619047619047619
Epoch:  762        5 Batch loss: 0.151244 Batch F1: 0.8444444444444444
Epoch:  762        6 Batch loss: 0.162089 Batch F1: 0.7368421052631579
Epoch:  762        7 Batch loss: 0.165489 Batch F1: 0.7555555555555556
Epoch:  762        8 Batch loss: 0.200899 Batch F1: 0.7111111111111111
Epoch:  762        9 Batch loss: 0.198338 Batch F1: 0.5
Epoch:  762       10 Batch loss: 0.170840 Batch F1: 0.7659574468085107
Epoch:  762       11 Batch loss: 0.178764 Batch F1: 0.6842105263157895
Epoch:  762       12 Batch loss: 0.180361 Batch F1: 0.6341463414634146
Train Avg Loss  762: 0.173932

Train Avg F1  762: 0.7133751882663927

Val Avg Loss  762: 0.180530

Val Avg F1  762:  0.7057785209959122

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 763
--------------------------------------------------------------
Epoch:  763        1 Batch loss: 0.173729 Batch F1: 0.6666666666666666
Epoch:  763        2 Batch loss: 0.148017 Batch F1: 0.8085106382978723
Epoch:  763        3 Batch loss: 0.154888 Batch F1: 0.7727272727272727
Epoch:  763        4 Batch loss: 0.156686 Batch F1: 0.761904761904762
Epoch:  763        5 Batch loss: 0.152540 Batch F1: 0.8461538461538461
Epoch:  763        6 Batch loss: 0.163678 Batch F1: 0.7755102040816326
Epoch:  763        7 Batch loss: 0.177506 Batch F1: 0.6666666666666666
Epoch:  763        8 Batch loss: 0.204518 Batch F1: 0.6415094339622641
Epoch:  763        9 Batch loss: 0.171606 Batch F1: 0.6500000000000001
Epoch:  763       10 Batch loss: 0.176784 Batch F1: 0.6829268292682926
Epoch:  763       11 Batch loss: 0.152539 Batch F1: 0.7428571428571428
Epoch:  763       12 Batch loss: 0.202562 Batch F1: 0.6153846153846153
Train Avg Loss  763: 0.169588

Train Avg F1  763: 0.7192348398309195

Val Avg Loss  763: 0.186654

Val Avg F1  763:  0.6677725558539511

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 764
--------------------------------------------------------------
Epoch:  764        1 Batch loss: 0.176550 Batch F1: 0.6666666666666666
Epoch:  764        2 Batch loss: 0.179937 Batch F1: 0.6285714285714286
Epoch:  764        3 Batch loss: 0.197583 Batch F1: 0.6956521739130435
Epoch:  764        4 Batch loss: 0.174712 Batch F1: 0.6818181818181818
Epoch:  764        5 Batch loss: 0.157071 Batch F1: 0.6285714285714287
Epoch:  764        6 Batch loss: 0.143131 Batch F1: 0.8095238095238095
Epoch:  764        7 Batch loss: 0.188453 Batch F1: 0.7169811320754716
Epoch:  764        8 Batch loss: 0.158794 Batch F1: 0.7272727272727273
Epoch:  764        9 Batch loss: 0.183288 Batch F1: 0.7346938775510204
Epoch:  764       10 Batch loss: 0.162699 Batch F1: 0.7272727272727272
Epoch:  764       11 Batch loss: 0.140866 Batch F1: 0.8372093023255814
Epoch:  764       12 Batch loss: 0.171279 Batch F1: 0.7317073170731707
Train Avg Loss  764: 0.169530

Train Avg F1  764: 0.7154950643862715

Val Avg Loss  764: 0.181343

Val Avg F1  764:  0.7019230769230769

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 765
--------------------------------------------------------------
Epoch:  765        1 Batch loss: 0.175694 Batch F1: 0.711111111111111
Epoch:  765        2 Batch loss: 0.167052 Batch F1: 0.7555555555555556
Epoch:  765        3 Batch loss: 0.149092 Batch F1: 0.7894736842105263
Epoch:  765        4 Batch loss: 0.152176 Batch F1: 0.7755102040816326
Epoch:  765        5 Batch loss: 0.194250 Batch F1: 0.6086956521739131
Epoch:  765        6 Batch loss: 0.162781 Batch F1: 0.6666666666666667
Epoch:  765        7 Batch loss: 0.165187 Batch F1: 0.7391304347826085
Epoch:  765        8 Batch loss: 0.199726 Batch F1: 0.4864864864864865
Epoch:  765        9 Batch loss: 0.160341 Batch F1: 0.7142857142857143
Epoch:  765       10 Batch loss: 0.157086 Batch F1: 0.761904761904762
Epoch:  765       11 Batch loss: 0.155675 Batch F1: 0.7804878048780488
Epoch:  765       12 Batch loss: 0.171165 Batch F1: 0.7916666666666666
Train Avg Loss  765: 0.167519

Train Avg F1  765: 0.7150812285669743

Val Avg Loss  765: 0.180215

Val Avg F1  765:  0.6876013037350247

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 766
--------------------------------------------------------------
Epoch:  766        1 Batch loss: 0.146208 Batch F1: 0.7272727272727272
Epoch:  766        2 Batch loss: 0.156829 Batch F1: 0.7804878048780488
Epoch:  766        3 Batch loss: 0.142565 Batch F1: 0.7804878048780487
Epoch:  766        4 Batch loss: 0.167086 Batch F1: 0.7692307692307693
Epoch:  766        5 Batch loss: 0.174793 Batch F1: 0.6956521739130435
Epoch:  766        6 Batch loss: 0.166736 Batch F1: 0.7111111111111111
Epoch:  766        7 Batch loss: 0.156716 Batch F1: 0.7555555555555555
Epoch:  766        8 Batch loss: 0.181782 Batch F1: 0.6808510638297872
Epoch:  766        9 Batch loss: 0.173077 Batch F1: 0.6486486486486486
Epoch:  766       10 Batch loss: 0.171077 Batch F1: 0.6153846153846153
Epoch:  766       11 Batch loss: 0.184906 Batch F1: 0.75
Epoch:  766       12 Batch loss: 0.182388 Batch F1: 0.6818181818181818
Train Avg Loss  766: 0.167013

Train Avg F1  766: 0.716375038043378

Val Avg Loss  766: 0.181642

Val Avg F1  766:  0.6804951134058639

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 767
--------------------------------------------------------------
Epoch:  767        1 Batch loss: 0.178381 Batch F1: 0.6666666666666667
Epoch:  767        2 Batch loss: 0.180175 Batch F1: 0.7169811320754718
Epoch:  767        3 Batch loss: 0.143980 Batch F1: 0.8095238095238095
Epoch:  767        4 Batch loss: 0.202709 Batch F1: 0.5405405405405405
Epoch:  767        5 Batch loss: 0.156147 Batch F1: 0.8363636363636363
Epoch:  767        6 Batch loss: 0.178933 Batch F1: 0.6829268292682926
Epoch:  767        7 Batch loss: 0.179331 Batch F1: 0.6818181818181819
Epoch:  767        8 Batch loss: 0.151856 Batch F1: 0.8000000000000002
Epoch:  767        9 Batch loss: 0.164070 Batch F1: 0.7499999999999999
Epoch:  767       10 Batch loss: 0.146608 Batch F1: 0.8444444444444443
Epoch:  767       11 Batch loss: 0.162371 Batch F1: 0.7916666666666667
Epoch:  767       12 Batch loss: 0.177276 Batch F1: 0.5714285714285714
Train Avg Loss  767: 0.168486

Train Avg F1  767: 0.7243633732330235

Val Avg Loss  767: 0.182776

Val Avg F1  767:  0.6880148040004678

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 768
--------------------------------------------------------------
Epoch:  768        1 Batch loss: 0.157313 Batch F1: 0.8
Epoch:  768        2 Batch loss: 0.159075 Batch F1: 0.7317073170731706
Epoch:  768        3 Batch loss: 0.146239 Batch F1: 0.7727272727272727
Epoch:  768        4 Batch loss: 0.192826 Batch F1: 0.7017543859649122
Epoch:  768        5 Batch loss: 0.179400 Batch F1: 0.6341463414634146
Epoch:  768        6 Batch loss: 0.180627 Batch F1: 0.6666666666666667
Epoch:  768        7 Batch loss: 0.166957 Batch F1: 0.7450980392156863
Epoch:  768        8 Batch loss: 0.174315 Batch F1: 0.6808510638297872
Epoch:  768        9 Batch loss: 0.157905 Batch F1: 0.7272727272727273
Epoch:  768       10 Batch loss: 0.141373 Batch F1: 0.761904761904762
Epoch:  768       11 Batch loss: 0.163074 Batch F1: 0.7499999999999999
Epoch:  768       12 Batch loss: 0.196220 Batch F1: 0.5625
Train Avg Loss  768: 0.167944

Train Avg F1  768: 0.7112190480098667

Val Avg Loss  768: 0.180006

Val Avg F1  768:  0.6793280370738166

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 769
--------------------------------------------------------------
Epoch:  769        1 Batch loss: 0.170941 Batch F1: 0.6153846153846154
Epoch:  769        2 Batch loss: 0.161334 Batch F1: 0.7
Epoch:  769        3 Batch loss: 0.168152 Batch F1: 0.7317073170731706
Epoch:  769        4 Batch loss: 0.168978 Batch F1: 0.761904761904762
Epoch:  769        5 Batch loss: 0.147578 Batch F1: 0.7777777777777778
Epoch:  769        6 Batch loss: 0.156373 Batch F1: 0.8260869565217391
Epoch:  769        7 Batch loss: 0.174700 Batch F1: 0.6808510638297872
Epoch:  769        8 Batch loss: 0.149964 Batch F1: 0.816326530612245
Epoch:  769        9 Batch loss: 0.180326 Batch F1: 0.7419354838709677
Epoch:  769       10 Batch loss: 0.181097 Batch F1: 0.7555555555555556
Epoch:  769       11 Batch loss: 0.173166 Batch F1: 0.7
Epoch:  769       12 Batch loss: 0.178420 Batch F1: 0.631578947368421
Train Avg Loss  769: 0.167586

Train Avg F1  769: 0.7282590841582534

Val Avg Loss  769: 0.180565

Val Avg F1  769:  0.6884153871348964

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 770
--------------------------------------------------------------
Epoch:  770        1 Batch loss: 0.172601 Batch F1: 0.6285714285714286
Epoch:  770        2 Batch loss: 0.166325 Batch F1: 0.7142857142857143
Epoch:  770        3 Batch loss: 0.177763 Batch F1: 0.6818181818181819
Epoch:  770        4 Batch loss: 0.158673 Batch F1: 0.7368421052631579
Epoch:  770        5 Batch loss: 0.146162 Batch F1: 0.8333333333333334
Epoch:  770        6 Batch loss: 0.158839 Batch F1: 0.6829268292682926
Epoch:  770        7 Batch loss: 0.173142 Batch F1: 0.6153846153846155
Epoch:  770        8 Batch loss: 0.155989 Batch F1: 0.6842105263157895
Epoch:  770        9 Batch loss: 0.156959 Batch F1: 0.823529411764706
Epoch:  770       10 Batch loss: 0.201913 Batch F1: 0.6274509803921569
Epoch:  770       11 Batch loss: 0.150558 Batch F1: 0.8275862068965517
Epoch:  770       12 Batch loss: 0.184780 Batch F1: 0.7317073170731708
Train Avg Loss  770: 0.166975

Train Avg F1  770: 0.715637220863925

Val Avg Loss  770: 0.183448

Val Avg F1  770:  0.6821742099738559

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 771
--------------------------------------------------------------
Epoch:  771        1 Batch loss: 0.174404 Batch F1: 0.7111111111111111
Epoch:  771        2 Batch loss: 0.186825 Batch F1: 0.5405405405405405
Epoch:  771        3 Batch loss: 0.179524 Batch F1: 0.8076923076923077
Epoch:  771        4 Batch loss: 0.147145 Batch F1: 0.8979591836734694
Epoch:  771        5 Batch loss: 0.192562 Batch F1: 0.8285714285714285
Epoch:  771        6 Batch loss: 0.158995 Batch F1: 0.8148148148148149
Epoch:  771        7 Batch loss: 0.164627 Batch F1: 0.7659574468085107
Epoch:  771        8 Batch loss: 0.175809 Batch F1: 0.5555555555555556
Epoch:  771        9 Batch loss: 0.166434 Batch F1: 0.6486486486486486
Epoch:  771       10 Batch loss: 0.169230 Batch F1: 0.6976744186046512
Epoch:  771       11 Batch loss: 0.157895 Batch F1: 0.8571428571428571
Epoch:  771       12 Batch loss: 0.166959 Batch F1: 0.6896551724137931
Train Avg Loss  771: 0.170034

Train Avg F1  771: 0.7346102904648073

Val Avg Loss  771: 0.181571

Val Avg F1  771:  0.6855674087816944

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 772
--------------------------------------------------------------
Epoch:  772        1 Batch loss: 0.149768 Batch F1: 0.7804878048780488
Epoch:  772        2 Batch loss: 0.157846 Batch F1: 0.6470588235294118
Epoch:  772        3 Batch loss: 0.162882 Batch F1: 0.7555555555555556
Epoch:  772        4 Batch loss: 0.202985 Batch F1: 0.5957446808510638
Epoch:  772        5 Batch loss: 0.144145 Batch F1: 0.742857142857143
Epoch:  772        6 Batch loss: 0.147547 Batch F1: 0.8085106382978724
Epoch:  772        7 Batch loss: 0.157806 Batch F1: 0.7924528301886793
Epoch:  772        8 Batch loss: 0.197608 Batch F1: 0.47058823529411764
Epoch:  772        9 Batch loss: 0.150260 Batch F1: 0.8148148148148148
Epoch:  772       10 Batch loss: 0.170559 Batch F1: 0.8253968253968254
Epoch:  772       11 Batch loss: 0.188235 Batch F1: 0.6486486486486486
Epoch:  772       12 Batch loss: 0.168005 Batch F1: 0.7804878048780488
Train Avg Loss  772: 0.166470

Train Avg F1  772: 0.7218836504325191

Val Avg Loss  772: 0.179218

Val Avg F1  772:  0.6874290191959365

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 773
--------------------------------------------------------------
Epoch:  773        1 Batch loss: 0.170077 Batch F1: 0.6486486486486486
Epoch:  773        2 Batch loss: 0.149593 Batch F1: 0.7500000000000001
Epoch:  773        3 Batch loss: 0.155137 Batch F1: 0.717948717948718
Epoch:  773        4 Batch loss: 0.161072 Batch F1: 0.823529411764706
Epoch:  773        5 Batch loss: 0.172443 Batch F1: 0.6111111111111113
Epoch:  773        6 Batch loss: 0.159708 Batch F1: 0.8333333333333334
Epoch:  773        7 Batch loss: 0.177239 Batch F1: 0.6666666666666667
Epoch:  773        8 Batch loss: 0.161431 Batch F1: 0.7441860465116279
Epoch:  773        9 Batch loss: 0.188089 Batch F1: 0.6
Epoch:  773       10 Batch loss: 0.141751 Batch F1: 0.8181818181818182
Epoch:  773       11 Batch loss: 0.196476 Batch F1: 0.6538461538461539
Epoch:  773       12 Batch loss: 0.183582 Batch F1: 0.5945945945945946
Train Avg Loss  773: 0.168050

Train Avg F1  773: 0.7051705418839482

Val Avg Loss  773: 0.181387

Val Avg F1  773:  0.6782540767503175

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 774
--------------------------------------------------------------
Epoch:  774        1 Batch loss: 0.168375 Batch F1: 0.6341463414634146
Epoch:  774        2 Batch loss: 0.153273 Batch F1: 0.717948717948718
Epoch:  774        3 Batch loss: 0.175424 Batch F1: 0.7272727272727273
Epoch:  774        4 Batch loss: 0.188462 Batch F1: 0.6938775510204082
Epoch:  774        5 Batch loss: 0.163386 Batch F1: 0.7317073170731706
Epoch:  774        6 Batch loss: 0.183824 Batch F1: 0.6511627906976745
Epoch:  774        7 Batch loss: 0.162713 Batch F1: 0.8214285714285714
Epoch:  774        8 Batch loss: 0.165448 Batch F1: 0.7142857142857143
Epoch:  774        9 Batch loss: 0.149005 Batch F1: 0.7906976744186046
Epoch:  774       10 Batch loss: 0.155838 Batch F1: 0.7222222222222222
Epoch:  774       11 Batch loss: 0.188775 Batch F1: 0.6938775510204083
Epoch:  774       12 Batch loss: 0.173406 Batch F1: 0.7272727272727274
Train Avg Loss  774: 0.168994

Train Avg F1  774: 0.71882499217703

Val Avg Loss  774: 0.180594

Val Avg F1  774:  0.6946235403682213

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 775
--------------------------------------------------------------
Epoch:  775        1 Batch loss: 0.180707 Batch F1: 0.5625
Epoch:  775        2 Batch loss: 0.168839 Batch F1: 0.6666666666666666
Epoch:  775        3 Batch loss: 0.164411 Batch F1: 0.6976744186046512
Epoch:  775        4 Batch loss: 0.139075 Batch F1: 0.8727272727272727
Epoch:  775        5 Batch loss: 0.178200 Batch F1: 0.7142857142857143
Epoch:  775        6 Batch loss: 0.171964 Batch F1: 0.7499999999999999
Epoch:  775        7 Batch loss: 0.188886 Batch F1: 0.6046511627906977
Epoch:  775        8 Batch loss: 0.173588 Batch F1: 0.6829268292682926
Epoch:  775        9 Batch loss: 0.158994 Batch F1: 0.7727272727272727
Epoch:  775       10 Batch loss: 0.149092 Batch F1: 0.8163265306122449
Epoch:  775       11 Batch loss: 0.174016 Batch F1: 0.6956521739130435
Epoch:  775       12 Batch loss: 0.180478 Batch F1: 0.7
Train Avg Loss  775: 0.169021

Train Avg F1  775: 0.7113448367996545

Val Avg Loss  775: 0.185436

Val Avg F1  775:  0.7000334448160535

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 776
--------------------------------------------------------------
Epoch:  776        1 Batch loss: 0.183687 Batch F1: 0.7555555555555555
Epoch:  776        2 Batch loss: 0.168128 Batch F1: 0.75
Epoch:  776        3 Batch loss: 0.177511 Batch F1: 0.6190476190476191
Epoch:  776        4 Batch loss: 0.176214 Batch F1: 0.7272727272727272
Epoch:  776        5 Batch loss: 0.186493 Batch F1: 0.7555555555555555
Epoch:  776        6 Batch loss: 0.181463 Batch F1: 0.6190476190476191
Epoch:  776        7 Batch loss: 0.170043 Batch F1: 0.6842105263157895
Epoch:  776        8 Batch loss: 0.190447 Batch F1: 0.5263157894736842
Epoch:  776        9 Batch loss: 0.149417 Batch F1: 0.7368421052631577
Epoch:  776       10 Batch loss: 0.170124 Batch F1: 0.7636363636363636
Epoch:  776       11 Batch loss: 0.141780 Batch F1: 0.8333333333333334
Epoch:  776       12 Batch loss: 0.154453 Batch F1: 0.7894736842105262
Train Avg Loss  776: 0.170813

Train Avg F1  776: 0.7133575732259941

Val Avg Loss  776: 0.181147

Val Avg F1  776:  0.7200419641540827

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 777
--------------------------------------------------------------
Epoch:  777        1 Batch loss: 0.158109 Batch F1: 0.7727272727272727
Epoch:  777        2 Batch loss: 0.133159 Batch F1: 0.8444444444444444
Epoch:  777        3 Batch loss: 0.202432 Batch F1: 0.6530612244897959
Epoch:  777        4 Batch loss: 0.171729 Batch F1: 0.6842105263157895
Epoch:  777        5 Batch loss: 0.156537 Batch F1: 0.7317073170731706
Epoch:  777        6 Batch loss: 0.189589 Batch F1: 0.6111111111111112
Epoch:  777        7 Batch loss: 0.183325 Batch F1: 0.6
Epoch:  777        8 Batch loss: 0.158546 Batch F1: 0.7999999999999999
Epoch:  777        9 Batch loss: 0.155800 Batch F1: 0.7916666666666666
Epoch:  777       10 Batch loss: 0.194772 Batch F1: 0.6530612244897959
Epoch:  777       11 Batch loss: 0.151341 Batch F1: 0.8235294117647058
Epoch:  777       12 Batch loss: 0.167953 Batch F1: 0.7804878048780488
Train Avg Loss  777: 0.168608

Train Avg F1  777: 0.7288339169967334

Val Avg Loss  777: 0.179750

Val Avg F1  777:  0.7146458066430708

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 778
--------------------------------------------------------------
Epoch:  778        1 Batch loss: 0.158791 Batch F1: 0.7804878048780488
Epoch:  778        2 Batch loss: 0.177097 Batch F1: 0.6818181818181818
Epoch:  778        3 Batch loss: 0.158427 Batch F1: 0.7659574468085107
Epoch:  778        4 Batch loss: 0.170925 Batch F1: 0.65
Epoch:  778        5 Batch loss: 0.173940 Batch F1: 0.7199999999999999
Epoch:  778        6 Batch loss: 0.124462 Batch F1: 0.875
Epoch:  778        7 Batch loss: 0.165957 Batch F1: 0.8085106382978724
Epoch:  778        8 Batch loss: 0.183622 Batch F1: 0.6976744186046512
Epoch:  778        9 Batch loss: 0.166864 Batch F1: 0.723404255319149
Epoch:  778       10 Batch loss: 0.181869 Batch F1: 0.7058823529411765
Epoch:  778       11 Batch loss: 0.161964 Batch F1: 0.7636363636363638
Epoch:  778       12 Batch loss: 0.175382 Batch F1: 0.7368421052631579
Train Avg Loss  778: 0.166608

Train Avg F1  778: 0.7424344639639261

Val Avg Loss  778: 0.179226

Val Avg F1  778:  0.6743678073655107

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 779
--------------------------------------------------------------
Epoch:  779        1 Batch loss: 0.144814 Batch F1: 0.717948717948718
Epoch:  779        2 Batch loss: 0.157157 Batch F1: 0.6470588235294117
Epoch:  779        3 Batch loss: 0.162171 Batch F1: 0.7272727272727272
Epoch:  779        4 Batch loss: 0.176013 Batch F1: 0.6511627906976745
Epoch:  779        5 Batch loss: 0.145877 Batch F1: 0.7826086956521738
Epoch:  779        6 Batch loss: 0.148657 Batch F1: 0.7317073170731706
Epoch:  779        7 Batch loss: 0.177016 Batch F1: 0.7307692307692306
Epoch:  779        8 Batch loss: 0.152575 Batch F1: 0.84
Epoch:  779        9 Batch loss: 0.188626 Batch F1: 0.6190476190476191
Epoch:  779       10 Batch loss: 0.188111 Batch F1: 0.6521739130434783
Epoch:  779       11 Batch loss: 0.169633 Batch F1: 0.7636363636363638
Epoch:  779       12 Batch loss: 0.161744 Batch F1: 0.7272727272727272
Train Avg Loss  779: 0.164366

Train Avg F1  779: 0.7158882438286079

Val Avg Loss  779: 0.180044

Val Avg F1  779:  0.6958793959312901

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 780
--------------------------------------------------------------
Epoch:  780        1 Batch loss: 0.157645 Batch F1: 0.830188679245283
Epoch:  780        2 Batch loss: 0.160553 Batch F1: 0.8372093023255814
Epoch:  780        3 Batch loss: 0.159139 Batch F1: 0.6818181818181818
Epoch:  780        4 Batch loss: 0.193783 Batch F1: 0.6046511627906976
Epoch:  780        5 Batch loss: 0.175505 Batch F1: 0.7111111111111111
Epoch:  780        6 Batch loss: 0.160282 Batch F1: 0.6829268292682926
Epoch:  780        7 Batch loss: 0.153177 Batch F1: 0.8
Epoch:  780        8 Batch loss: 0.131040 Batch F1: 0.8
Epoch:  780        9 Batch loss: 0.203954 Batch F1: 0.5581395348837208
Epoch:  780       10 Batch loss: 0.161499 Batch F1: 0.7924528301886792
Epoch:  780       11 Batch loss: 0.154521 Batch F1: 0.717948717948718
Epoch:  780       12 Batch loss: 0.184119 Batch F1: 0.6666666666666667
Train Avg Loss  780: 0.166268

Train Avg F1  780: 0.723592751353911

Val Avg Loss  780: 0.182649

Val Avg F1  780:  0.6736482471776589

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 781
--------------------------------------------------------------
Epoch:  781        1 Batch loss: 0.174988 Batch F1: 0.7450980392156864
Epoch:  781        2 Batch loss: 0.174264 Batch F1: 0.7199999999999999
Epoch:  781        3 Batch loss: 0.189560 Batch F1: 0.68
Epoch:  781        4 Batch loss: 0.171697 Batch F1: 0.6666666666666666
Epoch:  781        5 Batch loss: 0.158765 Batch F1: 0.717948717948718
Epoch:  781        6 Batch loss: 0.140691 Batch F1: 0.8695652173913043
Epoch:  781        7 Batch loss: 0.177850 Batch F1: 0.7307692307692307
Epoch:  781        8 Batch loss: 0.149202 Batch F1: 0.8260869565217391
Epoch:  781        9 Batch loss: 0.182619 Batch F1: 0.6046511627906976
Epoch:  781       10 Batch loss: 0.152732 Batch F1: 0.7000000000000001
Epoch:  781       11 Batch loss: 0.139749 Batch F1: 0.7096774193548386
Epoch:  781       12 Batch loss: 0.188351 Batch F1: 0.5517241379310345
Train Avg Loss  781: 0.166706

Train Avg F1  781: 0.7101822957158265

Val Avg Loss  781: 0.181468

Val Avg F1  781:  0.679933110367893

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 782
--------------------------------------------------------------
Epoch:  782        1 Batch loss: 0.182099 Batch F1: 0.6190476190476191
Epoch:  782        2 Batch loss: 0.174396 Batch F1: 0.6666666666666666
Epoch:  782        3 Batch loss: 0.194661 Batch F1: 0.5853658536585366
Epoch:  782        4 Batch loss: 0.147514 Batch F1: 0.7567567567567567
Epoch:  782        5 Batch loss: 0.150006 Batch F1: 0.816326530612245
Epoch:  782        6 Batch loss: 0.183173 Batch F1: 0.6521739130434783
Epoch:  782        7 Batch loss: 0.175220 Batch F1: 0.7450980392156864
Epoch:  782        8 Batch loss: 0.132035 Batch F1: 0.8163265306122449
Epoch:  782        9 Batch loss: 0.159400 Batch F1: 0.7755102040816326
Epoch:  782       10 Batch loss: 0.162477 Batch F1: 0.6666666666666666
Epoch:  782       11 Batch loss: 0.163768 Batch F1: 0.6666666666666667
Epoch:  782       12 Batch loss: 0.191724 Batch F1: 0.7111111111111111
Train Avg Loss  782: 0.168039

Train Avg F1  782: 0.7064763798449425

Val Avg Loss  782: 0.181863

Val Avg F1  782:  0.6877955727745644

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 783
--------------------------------------------------------------
Epoch:  783        1 Batch loss: 0.172195 Batch F1: 0.6666666666666666
Epoch:  783        2 Batch loss: 0.169349 Batch F1: 0.7659574468085107
Epoch:  783        3 Batch loss: 0.161096 Batch F1: 0.7843137254901961
Epoch:  783        4 Batch loss: 0.167052 Batch F1: 0.761904761904762
Epoch:  783        5 Batch loss: 0.164674 Batch F1: 0.6341463414634146
Epoch:  783        6 Batch loss: 0.147412 Batch F1: 0.8461538461538461
Epoch:  783        7 Batch loss: 0.199725 Batch F1: 0.6363636363636365
Epoch:  783        8 Batch loss: 0.155754 Batch F1: 0.7555555555555556
Epoch:  783        9 Batch loss: 0.152033 Batch F1: 0.7000000000000001
Epoch:  783       10 Batch loss: 0.171309 Batch F1: 0.7391304347826088
Epoch:  783       11 Batch loss: 0.156904 Batch F1: 0.7058823529411765
Epoch:  783       12 Batch loss: 0.187495 Batch F1: 0.7000000000000001
Train Avg Loss  783: 0.167083

Train Avg F1  783: 0.7246728973441977

Val Avg Loss  783: 0.181773

Val Avg F1  783:  0.6858843537414967

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 784
--------------------------------------------------------------
Epoch:  784        1 Batch loss: 0.159602 Batch F1: 0.8
Epoch:  784        2 Batch loss: 0.142730 Batch F1: 0.7567567567567567
Epoch:  784        3 Batch loss: 0.155524 Batch F1: 0.7659574468085107
Epoch:  784        4 Batch loss: 0.167300 Batch F1: 0.711111111111111
Epoch:  784        5 Batch loss: 0.162467 Batch F1: 0.7391304347826088
Epoch:  784        6 Batch loss: 0.170989 Batch F1: 0.6666666666666666
Epoch:  784        7 Batch loss: 0.186039 Batch F1: 0.6046511627906976
Epoch:  784        8 Batch loss: 0.175124 Batch F1: 0.8085106382978724
Epoch:  784        9 Batch loss: 0.210896 Batch F1: 0.4878048780487805
Epoch:  784       10 Batch loss: 0.139874 Batch F1: 0.8085106382978723
Epoch:  784       11 Batch loss: 0.170190 Batch F1: 0.6666666666666667
Epoch:  784       12 Batch loss: 0.148437 Batch F1: 0.7804878048780488
Train Avg Loss  784: 0.165764

Train Avg F1  784: 0.7163545170921327

Val Avg Loss  784: 0.181244

Val Avg F1  784:  0.6890645586297759

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 785
--------------------------------------------------------------
Epoch:  785        1 Batch loss: 0.177550 Batch F1: 0.6111111111111112
Epoch:  785        2 Batch loss: 0.159694 Batch F1: 0.8
Epoch:  785        3 Batch loss: 0.181109 Batch F1: 0.6190476190476191
Epoch:  785        4 Batch loss: 0.180176 Batch F1: 0.7317073170731706
Epoch:  785        5 Batch loss: 0.200168 Batch F1: 0.6
Epoch:  785        6 Batch loss: 0.187612 Batch F1: 0.5581395348837209
Epoch:  785        7 Batch loss: 0.174495 Batch F1: 0.6666666666666666
Epoch:  785        8 Batch loss: 0.152108 Batch F1: 0.7843137254901961
Epoch:  785        9 Batch loss: 0.157708 Batch F1: 0.7826086956521738
Epoch:  785       10 Batch loss: 0.169173 Batch F1: 0.7659574468085107
Epoch:  785       11 Batch loss: 0.131958 Batch F1: 0.8260869565217391
Epoch:  785       12 Batch loss: 0.156998 Batch F1: 0.7878787878787877
Train Avg Loss  785: 0.169062

Train Avg F1  785: 0.711126488427808

Val Avg Loss  785: 0.181866

Val Avg F1  785:  0.69381038647343

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 786
--------------------------------------------------------------
Epoch:  786        1 Batch loss: 0.183506 Batch F1: 0.5405405405405405
Epoch:  786        2 Batch loss: 0.159796 Batch F1: 0.7826086956521738
Epoch:  786        3 Batch loss: 0.142162 Batch F1: 0.7777777777777778
Epoch:  786        4 Batch loss: 0.150849 Batch F1: 0.8524590163934426
Epoch:  786        5 Batch loss: 0.160452 Batch F1: 0.7659574468085107
Epoch:  786        6 Batch loss: 0.217221 Batch F1: 0.6382978723404256
Epoch:  786        7 Batch loss: 0.160781 Batch F1: 0.76
Epoch:  786        8 Batch loss: 0.151968 Batch F1: 0.717948717948718
Epoch:  786        9 Batch loss: 0.157761 Batch F1: 0.7142857142857143
Epoch:  786       10 Batch loss: 0.195481 Batch F1: 0.5128205128205129
Epoch:  786       11 Batch loss: 0.196780 Batch F1: 0.6530612244897959
Epoch:  786       12 Batch loss: 0.129587 Batch F1: 0.8235294117647058
Train Avg Loss  786: 0.167195

Train Avg F1  786: 0.7116072442351932

Val Avg Loss  786: 0.179511

Val Avg F1  786:  0.7078282828282828

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 787
--------------------------------------------------------------
Epoch:  787        1 Batch loss: 0.161677 Batch F1: 0.6829268292682927
Epoch:  787        2 Batch loss: 0.168354 Batch F1: 0.7659574468085106
Epoch:  787        3 Batch loss: 0.165316 Batch F1: 0.8085106382978723
Epoch:  787        4 Batch loss: 0.185756 Batch F1: 0.6363636363636365
Epoch:  787        5 Batch loss: 0.119806 Batch F1: 0.8108108108108107
Epoch:  787        6 Batch loss: 0.184589 Batch F1: 0.693877551020408
Epoch:  787        7 Batch loss: 0.181681 Batch F1: 0.7586206896551724
Epoch:  787        8 Batch loss: 0.168626 Batch F1: 0.7
Epoch:  787        9 Batch loss: 0.146003 Batch F1: 0.7826086956521738
Epoch:  787       10 Batch loss: 0.169702 Batch F1: 0.7500000000000001
Epoch:  787       11 Batch loss: 0.166992 Batch F1: 0.6285714285714286
Epoch:  787       12 Batch loss: 0.167492 Batch F1: 0.7804878048780488
Train Avg Loss  787: 0.165499

Train Avg F1  787: 0.733227960943863

Val Avg Loss  787: 0.179625

Val Avg F1  787:  0.7100799803125385

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 788
--------------------------------------------------------------
Epoch:  788        1 Batch loss: 0.158127 Batch F1: 0.7555555555555556
Epoch:  788        2 Batch loss: 0.182111 Batch F1: 0.6938775510204083
Epoch:  788        3 Batch loss: 0.185480 Batch F1: 0.6808510638297872
Epoch:  788        4 Batch loss: 0.149618 Batch F1: 0.6875
Epoch:  788        5 Batch loss: 0.170794 Batch F1: 0.717948717948718
Epoch:  788        6 Batch loss: 0.175182 Batch F1: 0.6976744186046512
Epoch:  788        7 Batch loss: 0.169727 Batch F1: 0.6976744186046512
Epoch:  788        8 Batch loss: 0.189127 Batch F1: 0.7407407407407408
Epoch:  788        9 Batch loss: 0.187666 Batch F1: 0.8333333333333333
Epoch:  788       10 Batch loss: 0.150133 Batch F1: 0.7567567567567567
Epoch:  788       11 Batch loss: 0.140913 Batch F1: 0.8571428571428572
Epoch:  788       12 Batch loss: 0.163395 Batch F1: 0.5999999999999999
Train Avg Loss  788: 0.168523

Train Avg F1  788: 0.7265879511281216

Val Avg Loss  788: 0.180365

Val Avg F1  788:  0.6826038748832867

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 789
--------------------------------------------------------------
Epoch:  789        1 Batch loss: 0.169457 Batch F1: 0.7924528301886792
Epoch:  789        2 Batch loss: 0.187759 Batch F1: 0.6190476190476191
Epoch:  789        3 Batch loss: 0.136984 Batch F1: 0.7500000000000001
Epoch:  789        4 Batch loss: 0.147379 Batch F1: 0.8076923076923077
Epoch:  789        5 Batch loss: 0.154786 Batch F1: 0.6857142857142857
Epoch:  789        6 Batch loss: 0.178694 Batch F1: 0.6521739130434783
Epoch:  789        7 Batch loss: 0.141123 Batch F1: 0.7555555555555556
Epoch:  789        8 Batch loss: 0.127213 Batch F1: 0.8979591836734694
Epoch:  789        9 Batch loss: 0.168974 Batch F1: 0.819672131147541
Epoch:  789       10 Batch loss: 0.180460 Batch F1: 0.742857142857143
Epoch:  789       11 Batch loss: 0.221875 Batch F1: 0.5238095238095238
Epoch:  789       12 Batch loss: 0.191324 Batch F1: 0.5714285714285714
Train Avg Loss  789: 0.167169

Train Avg F1  789: 0.7181969220131812

Val Avg Loss  789: 0.188520

Val Avg F1  789:  0.6624385921908673

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 790
--------------------------------------------------------------
Epoch:  790        1 Batch loss: 0.203877 Batch F1: 0.5365853658536585
Epoch:  790        2 Batch loss: 0.162162 Batch F1: 0.6
Epoch:  790        3 Batch loss: 0.173684 Batch F1: 0.6956521739130435
Epoch:  790        4 Batch loss: 0.172926 Batch F1: 0.7142857142857143
Epoch:  790        5 Batch loss: 0.171027 Batch F1: 0.76
Epoch:  790        6 Batch loss: 0.185661 Batch F1: 0.6511627906976744
Epoch:  790        7 Batch loss: 0.161029 Batch F1: 0.7857142857142856
Epoch:  790        8 Batch loss: 0.170496 Batch F1: 0.7346938775510204
Epoch:  790        9 Batch loss: 0.155151 Batch F1: 0.7441860465116279
Epoch:  790       10 Batch loss: 0.167246 Batch F1: 0.7272727272727272
Epoch:  790       11 Batch loss: 0.164156 Batch F1: 0.6829268292682926
Epoch:  790       12 Batch loss: 0.167357 Batch F1: 0.7368421052631577
Train Avg Loss  790: 0.171231

Train Avg F1  790: 0.6974434930276

Val Avg Loss  790: 0.189000

Val Avg F1  790:  0.6299572055049841

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 791
--------------------------------------------------------------
Epoch:  791        1 Batch loss: 0.152410 Batch F1: 0.8
Epoch:  791        2 Batch loss: 0.168771 Batch F1: 0.6666666666666667
Epoch:  791        3 Batch loss: 0.193944 Batch F1: 0.6
Epoch:  791        4 Batch loss: 0.170222 Batch F1: 0.7826086956521738
Epoch:  791        5 Batch loss: 0.169765 Batch F1: 0.6666666666666666
Epoch:  791        6 Batch loss: 0.149509 Batch F1: 0.8085106382978724
Epoch:  791        7 Batch loss: 0.215626 Batch F1: 0.6363636363636365
Epoch:  791        8 Batch loss: 0.140317 Batch F1: 0.8571428571428572
Epoch:  791        9 Batch loss: 0.200853 Batch F1: 0.6341463414634146
Epoch:  791       10 Batch loss: 0.154297 Batch F1: 0.5517241379310345
Epoch:  791       11 Batch loss: 0.189982 Batch F1: 0.6666666666666666
Epoch:  791       12 Batch loss: 0.166750 Batch F1: 0.8
Train Avg Loss  791: 0.172704

Train Avg F1  791: 0.7058746922375825

Val Avg Loss  791: 0.186357

Val Avg F1  791:  0.7681334016860333

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 792
--------------------------------------------------------------
Epoch:  792        1 Batch loss: 0.167374 Batch F1: 0.7916666666666666
Epoch:  792        2 Batch loss: 0.170581 Batch F1: 0.8181818181818182
Epoch:  792        3 Batch loss: 0.206724 Batch F1: 0.5641025641025641
Epoch:  792        4 Batch loss: 0.160498 Batch F1: 0.7755102040816326
Epoch:  792        5 Batch loss: 0.153237 Batch F1: 0.8421052631578947
Epoch:  792        6 Batch loss: 0.193516 Batch F1: 0.6
Epoch:  792        7 Batch loss: 0.161857 Batch F1: 0.711111111111111
Epoch:  792        8 Batch loss: 0.174411 Batch F1: 0.6818181818181819
Epoch:  792        9 Batch loss: 0.178995 Batch F1: 0.6111111111111112
Epoch:  792       10 Batch loss: 0.195546 Batch F1: 0.6909090909090909
Epoch:  792       11 Batch loss: 0.149749 Batch F1: 0.7894736842105262
Epoch:  792       12 Batch loss: 0.168118 Batch F1: 0.761904761904762
Train Avg Loss  792: 0.173384

Train Avg F1  792: 0.7198245381046133

Val Avg Loss  792: 0.180564

Val Avg F1  792:  0.6835567560357476

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 793
--------------------------------------------------------------
Epoch:  793        1 Batch loss: 0.144596 Batch F1: 0.7894736842105262
Epoch:  793        2 Batch loss: 0.161580 Batch F1: 0.6285714285714287
Epoch:  793        3 Batch loss: 0.188387 Batch F1: 0.6521739130434783
Epoch:  793        4 Batch loss: 0.173678 Batch F1: 0.6486486486486486
Epoch:  793        5 Batch loss: 0.143233 Batch F1: 0.851063829787234
Epoch:  793        6 Batch loss: 0.186275 Batch F1: 0.7307692307692308
Epoch:  793        7 Batch loss: 0.198958 Batch F1: 0.6521739130434783
Epoch:  793        8 Batch loss: 0.233327 Batch F1: 0.5882352941176471
Epoch:  793        9 Batch loss: 0.204141 Batch F1: 0.5128205128205129
Epoch:  793       10 Batch loss: 0.230805 Batch F1: 0.6122448979591836
Epoch:  793       11 Batch loss: 0.154816 Batch F1: 0.816326530612245
Epoch:  793       12 Batch loss: 0.158157 Batch F1: 0.6428571428571429
Train Avg Loss  793: 0.181496

Train Avg F1  793: 0.6771132522033964

Val Avg Loss  793: 0.187485

Val Avg F1  793:  0.6559353766800575

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 794
--------------------------------------------------------------
Epoch:  794        1 Batch loss: 0.171302 Batch F1: 0.7083333333333333
Epoch:  794        2 Batch loss: 0.179575 Batch F1: 0.5945945945945946
Epoch:  794        3 Batch loss: 0.159506 Batch F1: 0.8076923076923077
Epoch:  794        4 Batch loss: 0.169232 Batch F1: 0.6486486486486486
Epoch:  794        5 Batch loss: 0.178743 Batch F1: 0.6956521739130435
Epoch:  794        6 Batch loss: 0.157876 Batch F1: 0.7441860465116279
Epoch:  794        7 Batch loss: 0.192829 Batch F1: 0.7169811320754716
Epoch:  794        8 Batch loss: 0.181174 Batch F1: 0.7083333333333334
Epoch:  794        9 Batch loss: 0.186020 Batch F1: 0.68
Epoch:  794       10 Batch loss: 0.155946 Batch F1: 0.8085106382978724
Epoch:  794       11 Batch loss: 0.159806 Batch F1: 0.7894736842105263
Epoch:  794       12 Batch loss: 0.206620 Batch F1: 0.5714285714285715
Train Avg Loss  794: 0.174886

Train Avg F1  794: 0.7061528720032775

Val Avg Loss  794: 0.184336

Val Avg F1  794:  0.6729249011857708

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 795
--------------------------------------------------------------
Epoch:  795        1 Batch loss: 0.167083 Batch F1: 0.7755102040816326
Epoch:  795        2 Batch loss: 0.158377 Batch F1: 0.7906976744186047
Epoch:  795        3 Batch loss: 0.150372 Batch F1: 0.7368421052631577
Epoch:  795        4 Batch loss: 0.154022 Batch F1: 0.7499999999999999
Epoch:  795        5 Batch loss: 0.191337 Batch F1: 0.6666666666666667
Epoch:  795        6 Batch loss: 0.193727 Batch F1: 0.5789473684210527
Epoch:  795        7 Batch loss: 0.171295 Batch F1: 0.6818181818181818
Epoch:  795        8 Batch loss: 0.179370 Batch F1: 0.7719298245614035
Epoch:  795        9 Batch loss: 0.183200 Batch F1: 0.6808510638297872
Epoch:  795       10 Batch loss: 0.162786 Batch F1: 0.7391304347826088
Epoch:  795       11 Batch loss: 0.156254 Batch F1: 0.888888888888889
Epoch:  795       12 Batch loss: 0.194125 Batch F1: 0.5882352941176471
Train Avg Loss  795: 0.171829

Train Avg F1  795: 0.7207931422374693

Val Avg Loss  795: 0.182461

Val Avg F1  795:  0.6842215586606981

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 796
--------------------------------------------------------------
Epoch:  796        1 Batch loss: 0.189432 Batch F1: 0.5853658536585366
Epoch:  796        2 Batch loss: 0.157182 Batch F1: 0.7906976744186046
Epoch:  796        3 Batch loss: 0.144578 Batch F1: 0.7906976744186046
Epoch:  796        4 Batch loss: 0.166549 Batch F1: 0.7272727272727273
Epoch:  796        5 Batch loss: 0.184322 Batch F1: 0.711111111111111
Epoch:  796        6 Batch loss: 0.175257 Batch F1: 0.7457627118644067
Epoch:  796        7 Batch loss: 0.175005 Batch F1: 0.6808510638297872
Epoch:  796        8 Batch loss: 0.196557 Batch F1: 0.5641025641025642
Epoch:  796        9 Batch loss: 0.145365 Batch F1: 0.7441860465116279
Epoch:  796       10 Batch loss: 0.154817 Batch F1: 0.7391304347826085
Epoch:  796       11 Batch loss: 0.156786 Batch F1: 0.7567567567567567
Epoch:  796       12 Batch loss: 0.182027 Batch F1: 0.6857142857142857
Train Avg Loss  796: 0.168990

Train Avg F1  796: 0.7101374087034684

Val Avg Loss  796: 0.184245

Val Avg F1  796:  0.6817934782608697

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 797
--------------------------------------------------------------
Epoch:  797        1 Batch loss: 0.142427 Batch F1: 0.8095238095238095
Epoch:  797        2 Batch loss: 0.160947 Batch F1: 0.717948717948718
Epoch:  797        3 Batch loss: 0.207852 Batch F1: 0.7547169811320755
Epoch:  797        4 Batch loss: 0.191143 Batch F1: 0.7083333333333334
Epoch:  797        5 Batch loss: 0.150324 Batch F1: 0.7777777777777778
Epoch:  797        6 Batch loss: 0.158093 Batch F1: 0.75
Epoch:  797        7 Batch loss: 0.189186 Batch F1: 0.7037037037037037
Epoch:  797        8 Batch loss: 0.189246 Batch F1: 0.5853658536585366
Epoch:  797        9 Batch loss: 0.129512 Batch F1: 0.8444444444444444
Epoch:  797       10 Batch loss: 0.160483 Batch F1: 0.7
Epoch:  797       11 Batch loss: 0.209664 Batch F1: 0.5833333333333334
Epoch:  797       12 Batch loss: 0.169126 Batch F1: 0.7058823529411765
Train Avg Loss  797: 0.171500

Train Avg F1  797: 0.7200858589830755

Val Avg Loss  797: 0.180389

Val Avg F1  797:  0.6931372549019608

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 798
--------------------------------------------------------------
Epoch:  798        1 Batch loss: 0.164788 Batch F1: 0.7391304347826085
Epoch:  798        2 Batch loss: 0.156070 Batch F1: 0.7999999999999999
Epoch:  798        3 Batch loss: 0.186513 Batch F1: 0.6511627906976744
Epoch:  798        4 Batch loss: 0.187028 Batch F1: 0.5405405405405405
Epoch:  798        5 Batch loss: 0.148043 Batch F1: 0.7999999999999999
Epoch:  798        6 Batch loss: 0.154165 Batch F1: 0.816326530612245
Epoch:  798        7 Batch loss: 0.164017 Batch F1: 0.7234042553191489
Epoch:  798        8 Batch loss: 0.179063 Batch F1: 0.6511627906976745
Epoch:  798        9 Batch loss: 0.177161 Batch F1: 0.6486486486486487
Epoch:  798       10 Batch loss: 0.196120 Batch F1: 0.6363636363636365
Epoch:  798       11 Batch loss: 0.155523 Batch F1: 0.7555555555555556
Epoch:  798       12 Batch loss: 0.150175 Batch F1: 0.7804878048780488
Train Avg Loss  798: 0.168222

Train Avg F1  798: 0.711898582341315

Val Avg Loss  798: 0.180812

Val Avg F1  798:  0.6886030018142834

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 799
--------------------------------------------------------------
Epoch:  799        1 Batch loss: 0.154884 Batch F1: 0.7804878048780488
Epoch:  799        2 Batch loss: 0.159540 Batch F1: 0.8000000000000002
Epoch:  799        3 Batch loss: 0.164041 Batch F1: 0.7636363636363636
Epoch:  799        4 Batch loss: 0.170304 Batch F1: 0.6486486486486486
Epoch:  799        5 Batch loss: 0.176759 Batch F1: 0.7111111111111111
Epoch:  799        6 Batch loss: 0.182140 Batch F1: 0.6521739130434783
Epoch:  799        7 Batch loss: 0.160533 Batch F1: 0.782608695652174
Epoch:  799        8 Batch loss: 0.182678 Batch F1: 0.6
Epoch:  799        9 Batch loss: 0.136543 Batch F1: 0.8695652173913043
Epoch:  799       10 Batch loss: 0.152947 Batch F1: 0.7317073170731706
Epoch:  799       11 Batch loss: 0.185599 Batch F1: 0.6046511627906976
Epoch:  799       12 Batch loss: 0.182788 Batch F1: 0.6486486486486486
Train Avg Loss  799: 0.167396

Train Avg F1  799: 0.7161032402394705

Val Avg Loss  799: 0.180177

Val Avg F1  799:  0.6940378632072984

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 800
--------------------------------------------------------------
Epoch:  800        1 Batch loss: 0.162471 Batch F1: 0.711111111111111
Epoch:  800        2 Batch loss: 0.165529 Batch F1: 0.6857142857142857
Epoch:  800        3 Batch loss: 0.196437 Batch F1: 0.6250000000000001
Epoch:  800        4 Batch loss: 0.161799 Batch F1: 0.7826086956521738
Epoch:  800        5 Batch loss: 0.184091 Batch F1: 0.75
Epoch:  800        6 Batch loss: 0.157475 Batch F1: 0.761904761904762
Epoch:  800        7 Batch loss: 0.159364 Batch F1: 0.8076923076923077
Epoch:  800        8 Batch loss: 0.162719 Batch F1: 0.7567567567567567
Epoch:  800        9 Batch loss: 0.154668 Batch F1: 0.7755102040816326
Epoch:  800       10 Batch loss: 0.197345 Batch F1: 0.6086956521739131
Epoch:  800       11 Batch loss: 0.161631 Batch F1: 0.7272727272727272
Epoch:  800       12 Batch loss: 0.142346 Batch F1: 0.7407407407407408
Train Avg Loss  800: 0.167156

Train Avg F1  800: 0.727750603591701

Val Avg Loss  800: 0.183858

Val Avg F1  800:  0.6744203469942962

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 801
--------------------------------------------------------------
Epoch:  801        1 Batch loss: 0.181153 Batch F1: 0.6666666666666666
Epoch:  801        2 Batch loss: 0.178250 Batch F1: 0.6511627906976744
Epoch:  801        3 Batch loss: 0.196804 Batch F1: 0.625
Epoch:  801        4 Batch loss: 0.176901 Batch F1: 0.631578947368421
Epoch:  801        5 Batch loss: 0.141332 Batch F1: 0.8205128205128205
Epoch:  801        6 Batch loss: 0.167687 Batch F1: 0.6829268292682926
Epoch:  801        7 Batch loss: 0.176164 Batch F1: 0.7547169811320754
Epoch:  801        8 Batch loss: 0.168977 Batch F1: 0.7083333333333334
Epoch:  801        9 Batch loss: 0.157350 Batch F1: 0.744186046511628
Epoch:  801       10 Batch loss: 0.161356 Batch F1: 0.7857142857142857
Epoch:  801       11 Batch loss: 0.142658 Batch F1: 0.7906976744186046
Epoch:  801       12 Batch loss: 0.164410 Batch F1: 0.6666666666666667
Train Avg Loss  801: 0.167754

Train Avg F1  801: 0.7106802535242056

Val Avg Loss  801: 0.183737

Val Avg F1  801:  0.6554800063158726

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 802
--------------------------------------------------------------
Epoch:  802        1 Batch loss: 0.173833 Batch F1: 0.6666666666666666
Epoch:  802        2 Batch loss: 0.168191 Batch F1: 0.6153846153846154
Epoch:  802        3 Batch loss: 0.150112 Batch F1: 0.8275862068965517
Epoch:  802        4 Batch loss: 0.210264 Batch F1: 0.6249999999999999
Epoch:  802        5 Batch loss: 0.154528 Batch F1: 0.6666666666666667
Epoch:  802        6 Batch loss: 0.173570 Batch F1: 0.7111111111111111
Epoch:  802        7 Batch loss: 0.201663 Batch F1: 0.64
Epoch:  802        8 Batch loss: 0.160225 Batch F1: 0.7
Epoch:  802        9 Batch loss: 0.143548 Batch F1: 0.8399999999999999
Epoch:  802       10 Batch loss: 0.157951 Batch F1: 0.7500000000000001
Epoch:  802       11 Batch loss: 0.157094 Batch F1: 0.7555555555555555
Epoch:  802       12 Batch loss: 0.147831 Batch F1: 0.6666666666666666
Train Avg Loss  802: 0.166568

Train Avg F1  802: 0.7053864574123194

Val Avg Loss  802: 0.180673

Val Avg F1  802:  0.6871249399406862

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 803
--------------------------------------------------------------
Epoch:  803        1 Batch loss: 0.163730 Batch F1: 0.7547169811320755
Epoch:  803        2 Batch loss: 0.168064 Batch F1: 0.7142857142857143
Epoch:  803        3 Batch loss: 0.149570 Batch F1: 0.75
Epoch:  803        4 Batch loss: 0.177771 Batch F1: 0.6818181818181818
Epoch:  803        5 Batch loss: 0.171930 Batch F1: 0.711111111111111
Epoch:  803        6 Batch loss: 0.125831 Batch F1: 0.7999999999999999
Epoch:  803        7 Batch loss: 0.157039 Batch F1: 0.7441860465116279
Epoch:  803        8 Batch loss: 0.172715 Batch F1: 0.6938775510204082
Epoch:  803        9 Batch loss: 0.134104 Batch F1: 0.8571428571428571
Epoch:  803       10 Batch loss: 0.198613 Batch F1: 0.7346938775510204
Epoch:  803       11 Batch loss: 0.191789 Batch F1: 0.6521739130434783
Epoch:  803       12 Batch loss: 0.193791 Batch F1: 0.6153846153846153
Train Avg Loss  803: 0.167079

Train Avg F1  803: 0.7257825707500908

Val Avg Loss  803: 0.185144

Val Avg F1  803:  0.6755952380952381

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 804
--------------------------------------------------------------
Epoch:  804        1 Batch loss: 0.170141 Batch F1: 0.6956521739130435
Epoch:  804        2 Batch loss: 0.175842 Batch F1: 0.7719298245614035
Epoch:  804        3 Batch loss: 0.155896 Batch F1: 0.717948717948718
Epoch:  804        4 Batch loss: 0.169276 Batch F1: 0.5882352941176471
Epoch:  804        5 Batch loss: 0.147427 Batch F1: 0.7804878048780488
Epoch:  804        6 Batch loss: 0.174886 Batch F1: 0.65
Epoch:  804        7 Batch loss: 0.160309 Batch F1: 0.6285714285714286
Epoch:  804        8 Batch loss: 0.160631 Batch F1: 0.782608695652174
Epoch:  804        9 Batch loss: 0.156715 Batch F1: 0.8085106382978724
Epoch:  804       10 Batch loss: 0.193144 Batch F1: 0.6666666666666666
Epoch:  804       11 Batch loss: 0.204482 Batch F1: 0.75
Epoch:  804       12 Batch loss: 0.145616 Batch F1: 0.8636363636363636
Train Avg Loss  804: 0.167864

Train Avg F1  804: 0.7253539673536138

Val Avg Loss  804: 0.182258

Val Avg F1  804:  0.715275358110724

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 805
--------------------------------------------------------------
Epoch:  805        1 Batch loss: 0.191679 Batch F1: 0.5909090909090909
Epoch:  805        2 Batch loss: 0.210763 Batch F1: 0.6
Epoch:  805        3 Batch loss: 0.137353 Batch F1: 0.7272727272727272
Epoch:  805        4 Batch loss: 0.142751 Batch F1: 0.875
Epoch:  805        5 Batch loss: 0.142828 Batch F1: 0.8000000000000002
Epoch:  805        6 Batch loss: 0.181466 Batch F1: 0.6666666666666665
Epoch:  805        7 Batch loss: 0.173922 Batch F1: 0.6363636363636365
Epoch:  805        8 Batch loss: 0.138795 Batch F1: 0.7894736842105263
Epoch:  805        9 Batch loss: 0.156301 Batch F1: 0.816326530612245
Epoch:  805       10 Batch loss: 0.154782 Batch F1: 0.7843137254901961
Epoch:  805       11 Batch loss: 0.197798 Batch F1: 0.6222222222222223
Epoch:  805       12 Batch loss: 0.157395 Batch F1: 0.7567567567567567
Train Avg Loss  805: 0.165486

Train Avg F1  805: 0.722108753375339

Val Avg Loss  805: 0.179231

Val Avg F1  805:  0.6887351778656127

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 806
--------------------------------------------------------------
Epoch:  806        1 Batch loss: 0.148339 Batch F1: 0.6875
Epoch:  806        2 Batch loss: 0.150260 Batch F1: 0.6451612903225806
Epoch:  806        3 Batch loss: 0.160948 Batch F1: 0.7142857142857143
Epoch:  806        4 Batch loss: 0.158193 Batch F1: 0.6842105263157895
Epoch:  806        5 Batch loss: 0.161502 Batch F1: 0.7727272727272727
Epoch:  806        6 Batch loss: 0.186924 Batch F1: 0.7272727272727273
Epoch:  806        7 Batch loss: 0.147738 Batch F1: 0.7999999999999999
Epoch:  806        8 Batch loss: 0.170733 Batch F1: 0.7200000000000001
Epoch:  806        9 Batch loss: 0.179103 Batch F1: 0.6341463414634146
Epoch:  806       10 Batch loss: 0.185861 Batch F1: 0.75
Epoch:  806       11 Batch loss: 0.173171 Batch F1: 0.7636363636363636
Epoch:  806       12 Batch loss: 0.155249 Batch F1: 0.8205128205128205
Train Avg Loss  806: 0.164835

Train Avg F1  806: 0.7266210880447236

Val Avg Loss  806: 0.180428

Val Avg F1  806:  0.7964360587002096

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 807
--------------------------------------------------------------
Epoch:  807        1 Batch loss: 0.130127 Batch F1: 0.9019607843137256
Epoch:  807        2 Batch loss: 0.191060 Batch F1: 0.7777777777777777
Epoch:  807        3 Batch loss: 0.137083 Batch F1: 0.7647058823529412
Epoch:  807        4 Batch loss: 0.157631 Batch F1: 0.6666666666666665
Epoch:  807        5 Batch loss: 0.181244 Batch F1: 0.6976744186046512
Epoch:  807        6 Batch loss: 0.154945 Batch F1: 0.782608695652174
Epoch:  807        7 Batch loss: 0.187294 Batch F1: 0.6382978723404256
Epoch:  807        8 Batch loss: 0.170949 Batch F1: 0.6153846153846153
Epoch:  807        9 Batch loss: 0.210115 Batch F1: 0.608695652173913
Epoch:  807       10 Batch loss: 0.169213 Batch F1: 0.7499999999999999
Epoch:  807       11 Batch loss: 0.155564 Batch F1: 0.7916666666666667
Epoch:  807       12 Batch loss: 0.154715 Batch F1: 0.7333333333333334
Train Avg Loss  807: 0.166662

Train Avg F1  807: 0.7273976971055741

Val Avg Loss  807: 0.178650

Val Avg F1  807:  0.6942314655080613

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 808
--------------------------------------------------------------
Epoch:  808        1 Batch loss: 0.145670 Batch F1: 0.7999999999999999
Epoch:  808        2 Batch loss: 0.141496 Batch F1: 0.8627450980392156
Epoch:  808        3 Batch loss: 0.143312 Batch F1: 0.7906976744186046
Epoch:  808        4 Batch loss: 0.160452 Batch F1: 0.7500000000000001
Epoch:  808        5 Batch loss: 0.158856 Batch F1: 0.7843137254901961
Epoch:  808        6 Batch loss: 0.188182 Batch F1: 0.6666666666666666
Epoch:  808        7 Batch loss: 0.156223 Batch F1: 0.7727272727272727
Epoch:  808        8 Batch loss: 0.163546 Batch F1: 0.6829268292682927
Epoch:  808        9 Batch loss: 0.201525 Batch F1: 0.6909090909090909
Epoch:  808       10 Batch loss: 0.222897 Batch F1: 0.7169811320754718
Epoch:  808       11 Batch loss: 0.190092 Batch F1: 0.6
Epoch:  808       12 Batch loss: 0.180826 Batch F1: 0.6470588235294117
Train Avg Loss  808: 0.171090

Train Avg F1  808: 0.7304188594270186

Val Avg Loss  808: 0.184107

Val Avg F1  808:  0.6764585529476727

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 809
--------------------------------------------------------------
Epoch:  809        1 Batch loss: 0.153637 Batch F1: 0.7916666666666667
Epoch:  809        2 Batch loss: 0.151766 Batch F1: 0.6896551724137931
Epoch:  809        3 Batch loss: 0.184535 Batch F1: 0.6521739130434783
Epoch:  809        4 Batch loss: 0.189449 Batch F1: 0.6666666666666665
Epoch:  809        5 Batch loss: 0.152072 Batch F1: 0.7999999999999999
Epoch:  809        6 Batch loss: 0.172678 Batch F1: 0.6666666666666667
Epoch:  809        7 Batch loss: 0.147343 Batch F1: 0.7999999999999999
Epoch:  809        8 Batch loss: 0.164906 Batch F1: 0.7719298245614034
Epoch:  809        9 Batch loss: 0.185149 Batch F1: 0.631578947368421
Epoch:  809       10 Batch loss: 0.158833 Batch F1: 0.6250000000000001
Epoch:  809       11 Batch loss: 0.203803 Batch F1: 0.6382978723404256
Epoch:  809       12 Batch loss: 0.167837 Batch F1: 0.8372093023255814
Train Avg Loss  809: 0.169334

Train Avg F1  809: 0.7142370860044251

Val Avg Loss  809: 0.188602

Val Avg F1  809:  0.6755969186093409

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 810
--------------------------------------------------------------
Epoch:  810        1 Batch loss: 0.159318 Batch F1: 0.6976744186046512
Epoch:  810        2 Batch loss: 0.161687 Batch F1: 0.6451612903225806
Epoch:  810        3 Batch loss: 0.178459 Batch F1: 0.631578947368421
Epoch:  810        4 Batch loss: 0.170597 Batch F1: 0.6486486486486486
Epoch:  810        5 Batch loss: 0.179379 Batch F1: 0.6818181818181818
Epoch:  810        6 Batch loss: 0.149792 Batch F1: 0.8085106382978724
Epoch:  810        7 Batch loss: 0.164533 Batch F1: 0.7719298245614036
Epoch:  810        8 Batch loss: 0.175310 Batch F1: 0.7868852459016393
Epoch:  810        9 Batch loss: 0.208235 Batch F1: 0.7636363636363637
Epoch:  810       10 Batch loss: 0.179602 Batch F1: 0.8214285714285715
Epoch:  810       11 Batch loss: 0.147476 Batch F1: 0.8571428571428571
Epoch:  810       12 Batch loss: 0.165902 Batch F1: 0.7567567567567567
Train Avg Loss  810: 0.170024

Train Avg F1  810: 0.7392643120406622

Val Avg Loss  810: 0.186911

Val Avg F1  810:  0.6692448680351906

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 811
--------------------------------------------------------------
Epoch:  811        1 Batch loss: 0.168134 Batch F1: 0.7391304347826088
Epoch:  811        2 Batch loss: 0.165312 Batch F1: 0.6
Epoch:  811        3 Batch loss: 0.194464 Batch F1: 0.6976744186046512
Epoch:  811        4 Batch loss: 0.141265 Batch F1: 0.7096774193548387
Epoch:  811        5 Batch loss: 0.194729 Batch F1: 0.5581395348837209
Epoch:  811        6 Batch loss: 0.140956 Batch F1: 0.8095238095238095
Epoch:  811        7 Batch loss: 0.192743 Batch F1: 0.6818181818181819
Epoch:  811        8 Batch loss: 0.158591 Batch F1: 0.7727272727272727
Epoch:  811        9 Batch loss: 0.162136 Batch F1: 0.6976744186046512
Epoch:  811       10 Batch loss: 0.152300 Batch F1: 0.7843137254901961
Epoch:  811       11 Batch loss: 0.178290 Batch F1: 0.7547169811320754
Epoch:  811       12 Batch loss: 0.186896 Batch F1: 0.7272727272727273
Train Avg Loss  811: 0.169651

Train Avg F1  811: 0.7110557436828944

Val Avg Loss  811: 0.179706

Val Avg F1  811:  0.6673629341932288

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 812
--------------------------------------------------------------
Epoch:  812        1 Batch loss: 0.158953 Batch F1: 0.6842105263157895
Epoch:  812        2 Batch loss: 0.141348 Batch F1: 0.7826086956521738
Epoch:  812        3 Batch loss: 0.154592 Batch F1: 0.7659574468085107
Epoch:  812        4 Batch loss: 0.143554 Batch F1: 0.7222222222222223
Epoch:  812        5 Batch loss: 0.177907 Batch F1: 0.8064516129032258
Epoch:  812        6 Batch loss: 0.159383 Batch F1: 0.7441860465116279
Epoch:  812        7 Batch loss: 0.167136 Batch F1: 0.6818181818181818
Epoch:  812        8 Batch loss: 0.170235 Batch F1: 0.6956521739130435
Epoch:  812        9 Batch loss: 0.167420 Batch F1: 0.7027027027027029
Epoch:  812       10 Batch loss: 0.178930 Batch F1: 0.6956521739130435
Epoch:  812       11 Batch loss: 0.200717 Batch F1: 0.68
Epoch:  812       12 Batch loss: 0.196637 Batch F1: 0.5625
Train Avg Loss  812: 0.168068

Train Avg F1  812: 0.7103301485633767

Val Avg Loss  812: 0.179592

Val Avg F1  812:  0.6973712737127371

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 813
--------------------------------------------------------------
Epoch:  813        1 Batch loss: 0.140284 Batch F1: 0.7804878048780488
Epoch:  813        2 Batch loss: 0.156695 Batch F1: 0.7916666666666666
Epoch:  813        3 Batch loss: 0.190126 Batch F1: 0.6500000000000001
Epoch:  813        4 Batch loss: 0.178369 Batch F1: 0.7200000000000001
Epoch:  813        5 Batch loss: 0.219453 Batch F1: 0.5882352941176471
Epoch:  813        6 Batch loss: 0.154165 Batch F1: 0.6666666666666665
Epoch:  813        7 Batch loss: 0.160494 Batch F1: 0.6666666666666667
Epoch:  813        8 Batch loss: 0.174673 Batch F1: 0.6808510638297872
Epoch:  813        9 Batch loss: 0.144066 Batch F1: 0.816326530612245
Epoch:  813       10 Batch loss: 0.153200 Batch F1: 0.8
Epoch:  813       11 Batch loss: 0.188249 Batch F1: 0.4848484848484848
Epoch:  813       12 Batch loss: 0.138231 Batch F1: 0.8636363636363636
Train Avg Loss  813: 0.166500

Train Avg F1  813: 0.7091154618268813

Val Avg Loss  813: 0.183108

Val Avg F1  813:  0.6776785714285714

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 814
--------------------------------------------------------------
Epoch:  814        1 Batch loss: 0.177490 Batch F1: 0.7547169811320756
Epoch:  814        2 Batch loss: 0.148955 Batch F1: 0.8148148148148148
Epoch:  814        3 Batch loss: 0.164458 Batch F1: 0.723404255319149
Epoch:  814        4 Batch loss: 0.147524 Batch F1: 0.8
Epoch:  814        5 Batch loss: 0.173408 Batch F1: 0.711111111111111
Epoch:  814        6 Batch loss: 0.170627 Batch F1: 0.7346938775510203
Epoch:  814        7 Batch loss: 0.200912 Batch F1: 0.5
Epoch:  814        8 Batch loss: 0.170563 Batch F1: 0.6111111111111113
Epoch:  814        9 Batch loss: 0.160884 Batch F1: 0.6486486486486486
Epoch:  814       10 Batch loss: 0.151155 Batch F1: 0.8
Epoch:  814       11 Batch loss: 0.159637 Batch F1: 0.782608695652174
Epoch:  814       12 Batch loss: 0.167765 Batch F1: 0.5384615384615384
Train Avg Loss  814: 0.166115

Train Avg F1  814: 0.7016309194834703

Val Avg Loss  814: 0.185068

Val Avg F1  814:  0.6691981390257252

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 815
--------------------------------------------------------------
Epoch:  815        1 Batch loss: 0.172729 Batch F1: 0.6666666666666667
Epoch:  815        2 Batch loss: 0.175214 Batch F1: 0.7083333333333334
Epoch:  815        3 Batch loss: 0.144380 Batch F1: 0.7272727272727272
Epoch:  815        4 Batch loss: 0.140618 Batch F1: 0.7333333333333334
Epoch:  815        5 Batch loss: 0.203280 Batch F1: 0.6818181818181818
Epoch:  815        6 Batch loss: 0.175303 Batch F1: 0.76
Epoch:  815        7 Batch loss: 0.200374 Batch F1: 0.6
Epoch:  815        8 Batch loss: 0.150225 Batch F1: 0.7843137254901961
Epoch:  815        9 Batch loss: 0.153544 Batch F1: 0.761904761904762
Epoch:  815       10 Batch loss: 0.221951 Batch F1: 0.5128205128205129
Epoch:  815       11 Batch loss: 0.141118 Batch F1: 0.8301886792452831
Epoch:  815       12 Batch loss: 0.182375 Batch F1: 0.65
Train Avg Loss  815: 0.171759

Train Avg F1  815: 0.7013876601570829

Val Avg Loss  815: 0.185702

Val Avg F1  815:  0.7042524566200157

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 816
--------------------------------------------------------------
Epoch:  816        1 Batch loss: 0.164514 Batch F1: 0.7777777777777777
Epoch:  816        2 Batch loss: 0.199917 Batch F1: 0.8421052631578948
Epoch:  816        3 Batch loss: 0.177434 Batch F1: 0.8333333333333333
Epoch:  816        4 Batch loss: 0.153884 Batch F1: 0.8727272727272727
Epoch:  816        5 Batch loss: 0.157253 Batch F1: 0.823529411764706
Epoch:  816        6 Batch loss: 0.198041 Batch F1: 0.6666666666666666
Epoch:  816        7 Batch loss: 0.172705 Batch F1: 0.6666666666666665
Epoch:  816        8 Batch loss: 0.182576 Batch F1: 0.5625000000000001
Epoch:  816        9 Batch loss: 0.166301 Batch F1: 0.6666666666666666
Epoch:  816       10 Batch loss: 0.153718 Batch F1: 0.6875
Epoch:  816       11 Batch loss: 0.205305 Batch F1: 0.5833333333333334
Epoch:  816       12 Batch loss: 0.164406 Batch F1: 0.6857142857142857
Train Avg Loss  816: 0.174671

Train Avg F1  816: 0.7223767231507169

Val Avg Loss  816: 0.184175

Val Avg F1  816:  0.6788939143348973

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 817
--------------------------------------------------------------
Epoch:  817        1 Batch loss: 0.154589 Batch F1: 0.8444444444444444
Epoch:  817        2 Batch loss: 0.204013 Batch F1: 0.6363636363636364
Epoch:  817        3 Batch loss: 0.154599 Batch F1: 0.8
Epoch:  817        4 Batch loss: 0.159060 Batch F1: 0.8275862068965517
Epoch:  817        5 Batch loss: 0.147769 Batch F1: 0.8500000000000001
Epoch:  817        6 Batch loss: 0.185738 Batch F1: 0.711111111111111
Epoch:  817        7 Batch loss: 0.175828 Batch F1: 0.6285714285714287
Epoch:  817        8 Batch loss: 0.201269 Batch F1: 0.6923076923076923
Epoch:  817        9 Batch loss: 0.126115 Batch F1: 0.8108108108108109
Epoch:  817       10 Batch loss: 0.184367 Batch F1: 0.7346938775510204
Epoch:  817       11 Batch loss: 0.169570 Batch F1: 0.7346938775510203
Epoch:  817       12 Batch loss: 0.212475 Batch F1: 0.45161290322580644
Train Avg Loss  817: 0.172949

Train Avg F1  817: 0.7268496657361267

Val Avg Loss  817: 0.180016

Val Avg F1  817:  0.707545263788354

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 818
--------------------------------------------------------------
Epoch:  818        1 Batch loss: 0.191127 Batch F1: 0.6363636363636365
Epoch:  818        2 Batch loss: 0.143180 Batch F1: 0.8
Epoch:  818        3 Batch loss: 0.171992 Batch F1: 0.7391304347826085
Epoch:  818        4 Batch loss: 0.169754 Batch F1: 0.7272727272727272
Epoch:  818        5 Batch loss: 0.166155 Batch F1: 0.7317073170731706
Epoch:  818        6 Batch loss: 0.158918 Batch F1: 0.7555555555555556
Epoch:  818        7 Batch loss: 0.160845 Batch F1: 0.7441860465116279
Epoch:  818        8 Batch loss: 0.164487 Batch F1: 0.6111111111111112
Epoch:  818        9 Batch loss: 0.185407 Batch F1: 0.6808510638297872
Epoch:  818       10 Batch loss: 0.187388 Batch F1: 0.6
Epoch:  818       11 Batch loss: 0.144665 Batch F1: 0.7924528301886792
Epoch:  818       12 Batch loss: 0.171464 Batch F1: 0.7500000000000001
Train Avg Loss  818: 0.167948

Train Avg F1  818: 0.7140525602240754

Val Avg Loss  818: 0.179678

Val Avg F1  818:  0.6910203783410384

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 819
--------------------------------------------------------------
Epoch:  819        1 Batch loss: 0.182624 Batch F1: 0.6666666666666666
Epoch:  819        2 Batch loss: 0.170194 Batch F1: 0.5789473684210525
Epoch:  819        3 Batch loss: 0.155117 Batch F1: 0.625
Epoch:  819        4 Batch loss: 0.175256 Batch F1: 0.7142857142857143
Epoch:  819        5 Batch loss: 0.160297 Batch F1: 0.7142857142857143
Epoch:  819        6 Batch loss: 0.145074 Batch F1: 0.8372093023255814
Epoch:  819        7 Batch loss: 0.186637 Batch F1: 0.6923076923076923
Epoch:  819        8 Batch loss: 0.150967 Batch F1: 0.7659574468085107
Epoch:  819        9 Batch loss: 0.143831 Batch F1: 0.7999999999999999
Epoch:  819       10 Batch loss: 0.153136 Batch F1: 0.7826086956521738
Epoch:  819       11 Batch loss: 0.180418 Batch F1: 0.7169811320754716
Epoch:  819       12 Batch loss: 0.180192 Batch F1: 0.6666666666666665
Train Avg Loss  819: 0.165312

Train Avg F1  819: 0.713409699957937

Val Avg Loss  819: 0.181053

Val Avg F1  819:  0.6867845362184984

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 820
--------------------------------------------------------------
Epoch:  820        1 Batch loss: 0.172853 Batch F1: 0.6976744186046512
Epoch:  820        2 Batch loss: 0.171159 Batch F1: 0.6363636363636364
Epoch:  820        3 Batch loss: 0.177373 Batch F1: 0.6976744186046512
Epoch:  820        4 Batch loss: 0.151098 Batch F1: 0.782608695652174
Epoch:  820        5 Batch loss: 0.158863 Batch F1: 0.761904761904762
Epoch:  820        6 Batch loss: 0.161714 Batch F1: 0.6976744186046512
Epoch:  820        7 Batch loss: 0.174438 Batch F1: 0.6666666666666666
Epoch:  820        8 Batch loss: 0.158184 Batch F1: 0.7755102040816326
Epoch:  820        9 Batch loss: 0.167072 Batch F1: 0.6666666666666666
Epoch:  820       10 Batch loss: 0.157568 Batch F1: 0.711111111111111
Epoch:  820       11 Batch loss: 0.173802 Batch F1: 0.6153846153846153
Epoch:  820       12 Batch loss: 0.157380 Batch F1: 0.8333333333333333
Train Avg Loss  820: 0.165125

Train Avg F1  820: 0.7118810789148794

Val Avg Loss  820: 0.180176

Val Avg F1  820:  0.6745148158604011

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 821
--------------------------------------------------------------
Epoch:  821        1 Batch loss: 0.143307 Batch F1: 0.7906976744186046
Epoch:  821        2 Batch loss: 0.151043 Batch F1: 0.7058823529411765
Epoch:  821        3 Batch loss: 0.175870 Batch F1: 0.7234042553191491
Epoch:  821        4 Batch loss: 0.178180 Batch F1: 0.693877551020408
Epoch:  821        5 Batch loss: 0.186852 Batch F1: 0.6808510638297872
Epoch:  821        6 Batch loss: 0.155240 Batch F1: 0.7441860465116279
Epoch:  821        7 Batch loss: 0.193827 Batch F1: 0.6538461538461539
Epoch:  821        8 Batch loss: 0.157553 Batch F1: 0.761904761904762
Epoch:  821        9 Batch loss: 0.156080 Batch F1: 0.7234042553191491
Epoch:  821       10 Batch loss: 0.149780 Batch F1: 0.7755102040816326
Epoch:  821       11 Batch loss: 0.155044 Batch F1: 0.6470588235294118
Epoch:  821       12 Batch loss: 0.199456 Batch F1: 0.6666666666666667
Train Avg Loss  821: 0.166853

Train Avg F1  821: 0.7139408174490441

Val Avg Loss  821: 0.180531

Val Avg F1  821:  0.6835897435897436

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 822
--------------------------------------------------------------
Epoch:  822        1 Batch loss: 0.178830 Batch F1: 0.6111111111111112
Epoch:  822        2 Batch loss: 0.151986 Batch F1: 0.7555555555555556
Epoch:  822        3 Batch loss: 0.167982 Batch F1: 0.7234042553191489
Epoch:  822        4 Batch loss: 0.168849 Batch F1: 0.6111111111111113
Epoch:  822        5 Batch loss: 0.124624 Batch F1: 0.8292682926829269
Epoch:  822        6 Batch loss: 0.180996 Batch F1: 0.7169811320754716
Epoch:  822        7 Batch loss: 0.145418 Batch F1: 0.8095238095238095
Epoch:  822        8 Batch loss: 0.175963 Batch F1: 0.7234042553191489
Epoch:  822        9 Batch loss: 0.167795 Batch F1: 0.7924528301886793
Epoch:  822       10 Batch loss: 0.188612 Batch F1: 0.6808510638297872
Epoch:  822       11 Batch loss: 0.205232 Batch F1: 0.6122448979591837
Epoch:  822       12 Batch loss: 0.154617 Batch F1: 0.7333333333333333
Train Avg Loss  822: 0.167575

Train Avg F1  822: 0.7166034706674389

Val Avg Loss  822: 0.181865

Val Avg F1  822:  0.6776274943976807

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 823
--------------------------------------------------------------
Epoch:  823        1 Batch loss: 0.174216 Batch F1: 0.711111111111111
Epoch:  823        2 Batch loss: 0.195112 Batch F1: 0.6382978723404256
Epoch:  823        3 Batch loss: 0.167152 Batch F1: 0.75
Epoch:  823        4 Batch loss: 0.151528 Batch F1: 0.7999999999999999
Epoch:  823        5 Batch loss: 0.154956 Batch F1: 0.7659574468085107
Epoch:  823        6 Batch loss: 0.162651 Batch F1: 0.7755102040816326
Epoch:  823        7 Batch loss: 0.175056 Batch F1: 0.6666666666666666
Epoch:  823        8 Batch loss: 0.163852 Batch F1: 0.7142857142857143
Epoch:  823        9 Batch loss: 0.139485 Batch F1: 0.8444444444444444
Epoch:  823       10 Batch loss: 0.186783 Batch F1: 0.6500000000000001
Epoch:  823       11 Batch loss: 0.164990 Batch F1: 0.711111111111111
Epoch:  823       12 Batch loss: 0.157687 Batch F1: 0.6428571428571429
Train Avg Loss  823: 0.166122

Train Avg F1  823: 0.7225201428088965

Val Avg Loss  823: 0.183685

Val Avg F1  823:  0.6875184856551315

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 824
--------------------------------------------------------------
Epoch:  824        1 Batch loss: 0.168767 Batch F1: 0.6666666666666666
Epoch:  824        2 Batch loss: 0.163449 Batch F1: 0.717948717948718
Epoch:  824        3 Batch loss: 0.172855 Batch F1: 0.76
Epoch:  824        4 Batch loss: 0.172823 Batch F1: 0.6341463414634146
Epoch:  824        5 Batch loss: 0.191311 Batch F1: 0.5714285714285715
Epoch:  824        6 Batch loss: 0.169635 Batch F1: 0.7000000000000001
Epoch:  824        7 Batch loss: 0.143679 Batch F1: 0.8085106382978724
Epoch:  824        8 Batch loss: 0.152591 Batch F1: 0.7346938775510204
Epoch:  824        9 Batch loss: 0.164906 Batch F1: 0.7391304347826085
Epoch:  824       10 Batch loss: 0.155668 Batch F1: 0.717948717948718
Epoch:  824       11 Batch loss: 0.189036 Batch F1: 0.72
Epoch:  824       12 Batch loss: 0.149226 Batch F1: 0.8500000000000001
Train Avg Loss  824: 0.166162

Train Avg F1  824: 0.7183728305072993

Val Avg Loss  824: 0.179534

Val Avg F1  824:  0.6887076639166305

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 825
--------------------------------------------------------------
Epoch:  825        1 Batch loss: 0.201401 Batch F1: 0.6923076923076923
Epoch:  825        2 Batch loss: 0.166241 Batch F1: 0.7547169811320754
Epoch:  825        3 Batch loss: 0.187709 Batch F1: 0.6818181818181819
Epoch:  825        4 Batch loss: 0.156382 Batch F1: 0.6666666666666666
Epoch:  825        5 Batch loss: 0.160484 Batch F1: 0.7843137254901961
Epoch:  825        6 Batch loss: 0.136238 Batch F1: 0.7567567567567567
Epoch:  825        7 Batch loss: 0.188130 Batch F1: 0.5641025641025642
Epoch:  825        8 Batch loss: 0.160670 Batch F1: 0.7755102040816326
Epoch:  825        9 Batch loss: 0.153862 Batch F1: 0.7027027027027027
Epoch:  825       10 Batch loss: 0.176007 Batch F1: 0.6666666666666667
Epoch:  825       11 Batch loss: 0.152254 Batch F1: 0.7391304347826088
Epoch:  825       12 Batch loss: 0.143537 Batch F1: 0.8095238095238095
Train Avg Loss  825: 0.165243

Train Avg F1  825: 0.7161846988359627

Val Avg Loss  825: 0.180652

Val Avg F1  825:  0.6903717481722597

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 826
--------------------------------------------------------------
Epoch:  826        1 Batch loss: 0.181624 Batch F1: 0.7457627118644067
Epoch:  826        2 Batch loss: 0.160015 Batch F1: 0.6470588235294118
Epoch:  826        3 Batch loss: 0.148789 Batch F1: 0.75
Epoch:  826        4 Batch loss: 0.161742 Batch F1: 0.7083333333333334
Epoch:  826        5 Batch loss: 0.154635 Batch F1: 0.7441860465116279
Epoch:  826        6 Batch loss: 0.179407 Batch F1: 0.7199999999999999
Epoch:  826        7 Batch loss: 0.155474 Batch F1: 0.7142857142857143
Epoch:  826        8 Batch loss: 0.145179 Batch F1: 0.742857142857143
Epoch:  826        9 Batch loss: 0.170693 Batch F1: 0.588235294117647
Epoch:  826       10 Batch loss: 0.151547 Batch F1: 0.7500000000000001
Epoch:  826       11 Batch loss: 0.179897 Batch F1: 0.7307692307692308
Epoch:  826       12 Batch loss: 0.183278 Batch F1: 0.711111111111111
Train Avg Loss  826: 0.164357

Train Avg F1  826: 0.7127166173649688

Val Avg Loss  826: 0.179044

Val Avg F1  826:  0.6842009531085161

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 827
--------------------------------------------------------------
Epoch:  827        1 Batch loss: 0.190720 Batch F1: 0.6666666666666666
Epoch:  827        2 Batch loss: 0.165347 Batch F1: 0.6486486486486486
Epoch:  827        3 Batch loss: 0.155069 Batch F1: 0.6666666666666666
Epoch:  827        4 Batch loss: 0.159537 Batch F1: 0.76
Epoch:  827        5 Batch loss: 0.139670 Batch F1: 0.6086956521739131
Epoch:  827        6 Batch loss: 0.157712 Batch F1: 0.76
Epoch:  827        7 Batch loss: 0.175018 Batch F1: 0.7346938775510203
Epoch:  827        8 Batch loss: 0.168745 Batch F1: 0.75
Epoch:  827        9 Batch loss: 0.140529 Batch F1: 0.7659574468085106
Epoch:  827       10 Batch loss: 0.180476 Batch F1: 0.7368421052631579
Epoch:  827       11 Batch loss: 0.179371 Batch F1: 0.6976744186046512
Epoch:  827       12 Batch loss: 0.150690 Batch F1: 0.7500000000000001
Train Avg Loss  827: 0.163574

Train Avg F1  827: 0.7121537901986029

Val Avg Loss  827: 0.178927

Val Avg F1  827:  0.689800175669741

Optimal Val loss (Epoch 741): 0.17865002155303955

Epoch 828
--------------------------------------------------------------
Epoch:  828        1 Batch loss: 0.186511 Batch F1: 0.7692307692307692
Epoch:  828        2 Batch loss: 0.168208 Batch F1: 0.6666666666666667
Epoch:  828        3 Batch loss: 0.157833 Batch F1: 0.7659574468085107
Epoch:  828        4 Batch loss: 0.157616 Batch F1: 0.7142857142857143
Epoch:  828        5 Batch loss: 0.146480 Batch F1: 0.6666666666666667
Epoch:  828        6 Batch loss: 0.187052 Batch F1: 0.7169811320754716
Epoch:  828        7 Batch loss: 0.141785 Batch F1: 0.782608695652174
Epoch:  828        8 Batch loss: 0.147389 Batch F1: 0.717948717948718
Epoch:  828        9 Batch loss: 0.171725 Batch F1: 0.5945945945945946
Epoch:  828       10 Batch loss: 0.194083 Batch F1: 0.7083333333333334
Epoch:  828       11 Batch loss: 0.163449 Batch F1: 0.6666666666666666
Epoch:  828       12 Batch loss: 0.147796 Batch F1: 0.8085106382978724
Train Avg Loss  828: 0.164161

Train Avg F1  828: 0.7148709201855965

Val Avg Loss  828: 0.178435

Val Avg F1  828:  0.6832675894088284

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 829
--------------------------------------------------------------
Epoch:  829        1 Batch loss: 0.133693 Batch F1: 0.7999999999999999
Epoch:  829        2 Batch loss: 0.195929 Batch F1: 0.68
Epoch:  829        3 Batch loss: 0.179918 Batch F1: 0.6666666666666666
Epoch:  829        4 Batch loss: 0.147494 Batch F1: 0.851063829787234
Epoch:  829        5 Batch loss: 0.146105 Batch F1: 0.761904761904762
Epoch:  829        6 Batch loss: 0.156495 Batch F1: 0.7659574468085106
Epoch:  829        7 Batch loss: 0.187657 Batch F1: 0.5263157894736842
Epoch:  829        8 Batch loss: 0.185019 Batch F1: 0.6818181818181818
Epoch:  829        9 Batch loss: 0.184649 Batch F1: 0.6341463414634146
Epoch:  829       10 Batch loss: 0.153563 Batch F1: 0.56
Epoch:  829       11 Batch loss: 0.147507 Batch F1: 0.8461538461538461
Epoch:  829       12 Batch loss: 0.167822 Batch F1: 0.8235294117647058
Train Avg Loss  829: 0.165488

Train Avg F1  829: 0.7164630229867504

Val Avg Loss  829: 0.181186

Val Avg F1  829:  0.7344824371690656

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 830
--------------------------------------------------------------
Epoch:  830        1 Batch loss: 0.182728 Batch F1: 0.6285714285714286
Epoch:  830        2 Batch loss: 0.148156 Batch F1: 0.8260869565217391
Epoch:  830        3 Batch loss: 0.172812 Batch F1: 0.7169811320754718
Epoch:  830        4 Batch loss: 0.139377 Batch F1: 0.8846153846153846
Epoch:  830        5 Batch loss: 0.205051 Batch F1: 0.6250000000000001
Epoch:  830        6 Batch loss: 0.155394 Batch F1: 0.7916666666666666
Epoch:  830        7 Batch loss: 0.151981 Batch F1: 0.7027027027027027
Epoch:  830        8 Batch loss: 0.180804 Batch F1: 0.7272727272727274
Epoch:  830        9 Batch loss: 0.168712 Batch F1: 0.7826086956521738
Epoch:  830       10 Batch loss: 0.182947 Batch F1: 0.6818181818181819
Epoch:  830       11 Batch loss: 0.172492 Batch F1: 0.72
Epoch:  830       12 Batch loss: 0.163759 Batch F1: 0.7272727272727272
Train Avg Loss  830: 0.168684

Train Avg F1  830: 0.734549716930767

Val Avg Loss  830: 0.183090

Val Avg F1  830:  0.6649441169245885

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 831
--------------------------------------------------------------
Epoch:  831        1 Batch loss: 0.153701 Batch F1: 0.7555555555555556
Epoch:  831        2 Batch loss: 0.175283 Batch F1: 0.7755102040816326
Epoch:  831        3 Batch loss: 0.152300 Batch F1: 0.8000000000000002
Epoch:  831        4 Batch loss: 0.198789 Batch F1: 0.5000000000000001
Epoch:  831        5 Batch loss: 0.175700 Batch F1: 0.7450980392156863
Epoch:  831        6 Batch loss: 0.193898 Batch F1: 0.6956521739130435
Epoch:  831        7 Batch loss: 0.153912 Batch F1: 0.8333333333333334
Epoch:  831        8 Batch loss: 0.170893 Batch F1: 0.6808510638297872
Epoch:  831        9 Batch loss: 0.147808 Batch F1: 0.7500000000000001
Epoch:  831       10 Batch loss: 0.159309 Batch F1: 0.7916666666666666
Epoch:  831       11 Batch loss: 0.144575 Batch F1: 0.8
Epoch:  831       12 Batch loss: 0.179476 Batch F1: 0.6666666666666666
Train Avg Loss  831: 0.167137

Train Avg F1  831: 0.7328611419385309

Val Avg Loss  831: 0.183774

Val Avg F1  831:  0.6893885213659933

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 832
--------------------------------------------------------------
Epoch:  832        1 Batch loss: 0.195296 Batch F1: 0.6046511627906976
Epoch:  832        2 Batch loss: 0.175938 Batch F1: 0.6511627906976744
Epoch:  832        3 Batch loss: 0.163213 Batch F1: 0.7317073170731706
Epoch:  832        4 Batch loss: 0.214107 Batch F1: 0.5833333333333334
Epoch:  832        5 Batch loss: 0.136302 Batch F1: 0.8292682926829269
Epoch:  832        6 Batch loss: 0.158428 Batch F1: 0.7500000000000001
Epoch:  832        7 Batch loss: 0.182965 Batch F1: 0.7058823529411765
Epoch:  832        8 Batch loss: 0.166760 Batch F1: 0.7307692307692307
Epoch:  832        9 Batch loss: 0.141119 Batch F1: 0.742857142857143
Epoch:  832       10 Batch loss: 0.131390 Batch F1: 0.8510638297872342
Epoch:  832       11 Batch loss: 0.160624 Batch F1: 0.6842105263157896
Epoch:  832       12 Batch loss: 0.145583 Batch F1: 0.7894736842105262
Train Avg Loss  832: 0.164310

Train Avg F1  832: 0.7211983052882419

Val Avg Loss  832: 0.179788

Val Avg F1  832:  0.6843317892369133

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 833
--------------------------------------------------------------
Epoch:  833        1 Batch loss: 0.168117 Batch F1: 0.7058823529411765
Epoch:  833        2 Batch loss: 0.172237 Batch F1: 0.6666666666666666
Epoch:  833        3 Batch loss: 0.188417 Batch F1: 0.68
Epoch:  833        4 Batch loss: 0.175998 Batch F1: 0.7272727272727272
Epoch:  833        5 Batch loss: 0.169045 Batch F1: 0.6153846153846154
Epoch:  833        6 Batch loss: 0.191718 Batch F1: 0.7017543859649122
Epoch:  833        7 Batch loss: 0.168268 Batch F1: 0.7272727272727272
Epoch:  833        8 Batch loss: 0.156816 Batch F1: 0.7027027027027027
Epoch:  833        9 Batch loss: 0.130650 Batch F1: 0.8235294117647058
Epoch:  833       10 Batch loss: 0.141754 Batch F1: 0.75
Epoch:  833       11 Batch loss: 0.154202 Batch F1: 0.823529411764706
Epoch:  833       12 Batch loss: 0.150027 Batch F1: 0.7567567567567567
Train Avg Loss  833: 0.163937

Train Avg F1  833: 0.7233959798743079

Val Avg Loss  833: 0.181305

Val Avg F1  833:  0.6870331219168428

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 834
--------------------------------------------------------------
Epoch:  834        1 Batch loss: 0.167418 Batch F1: 0.7500000000000001
Epoch:  834        2 Batch loss: 0.213355 Batch F1: 0.5531914893617023
Epoch:  834        3 Batch loss: 0.156079 Batch F1: 0.8095238095238095
Epoch:  834        4 Batch loss: 0.165068 Batch F1: 0.7843137254901961
Epoch:  834        5 Batch loss: 0.147204 Batch F1: 0.782608695652174
Epoch:  834        6 Batch loss: 0.153034 Batch F1: 0.7368421052631577
Epoch:  834        7 Batch loss: 0.151248 Batch F1: 0.6842105263157895
Epoch:  834        8 Batch loss: 0.188134 Batch F1: 0.5777777777777778
Epoch:  834        9 Batch loss: 0.151371 Batch F1: 0.7500000000000001
Epoch:  834       10 Batch loss: 0.159300 Batch F1: 0.7450980392156864
Epoch:  834       11 Batch loss: 0.136665 Batch F1: 0.8571428571428572
Epoch:  834       12 Batch loss: 0.200395 Batch F1: 0.4827586206896552
Train Avg Loss  834: 0.165773

Train Avg F1  834: 0.7094556372027337

Val Avg Loss  834: 0.180182

Val Avg F1  834:  0.6860626898313403

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 835
--------------------------------------------------------------
Epoch:  835        1 Batch loss: 0.152434 Batch F1: 0.75
Epoch:  835        2 Batch loss: 0.165939 Batch F1: 0.65
Epoch:  835        3 Batch loss: 0.181714 Batch F1: 0.5945945945945946
Epoch:  835        4 Batch loss: 0.175752 Batch F1: 0.7499999999999999
Epoch:  835        5 Batch loss: 0.151337 Batch F1: 0.7727272727272727
Epoch:  835        6 Batch loss: 0.178755 Batch F1: 0.6808510638297872
Epoch:  835        7 Batch loss: 0.157763 Batch F1: 0.7755102040816326
Epoch:  835        8 Batch loss: 0.152438 Batch F1: 0.823529411764706
Epoch:  835        9 Batch loss: 0.168637 Batch F1: 0.7272727272727272
Epoch:  835       10 Batch loss: 0.188137 Batch F1: 0.47058823529411764
Epoch:  835       11 Batch loss: 0.167582 Batch F1: 0.711111111111111
Epoch:  835       12 Batch loss: 0.151836 Batch F1: 0.7906976744186046
Train Avg Loss  835: 0.166027

Train Avg F1  835: 0.7080735245912129

Val Avg Loss  835: 0.178719

Val Avg F1  835:  0.6875816993464052

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 836
--------------------------------------------------------------
Epoch:  836        1 Batch loss: 0.193816 Batch F1: 0.6666666666666666
Epoch:  836        2 Batch loss: 0.166193 Batch F1: 0.6976744186046512
Epoch:  836        3 Batch loss: 0.148882 Batch F1: 0.7916666666666667
Epoch:  836        4 Batch loss: 0.191267 Batch F1: 0.6666666666666666
Epoch:  836        5 Batch loss: 0.146851 Batch F1: 0.7999999999999999
Epoch:  836        6 Batch loss: 0.152712 Batch F1: 0.6666666666666667
Epoch:  836        7 Batch loss: 0.168707 Batch F1: 0.7391304347826089
Epoch:  836        8 Batch loss: 0.170290 Batch F1: 0.6666666666666666
Epoch:  836        9 Batch loss: 0.155852 Batch F1: 0.7659574468085107
Epoch:  836       10 Batch loss: 0.151248 Batch F1: 0.7843137254901961
Epoch:  836       11 Batch loss: 0.179574 Batch F1: 0.5714285714285715
Epoch:  836       12 Batch loss: 0.161434 Batch F1: 0.76
Train Avg Loss  836: 0.165569

Train Avg F1  836: 0.7147364942039892

Val Avg Loss  836: 0.183844

Val Avg F1  836:  0.6501502419149479

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 837
--------------------------------------------------------------
Epoch:  837        1 Batch loss: 0.143196 Batch F1: 0.8235294117647057
Epoch:  837        2 Batch loss: 0.173878 Batch F1: 0.6250000000000001
Epoch:  837        3 Batch loss: 0.191842 Batch F1: 0.5957446808510638
Epoch:  837        4 Batch loss: 0.152672 Batch F1: 0.7931034482758621
Epoch:  837        5 Batch loss: 0.131557 Batch F1: 0.8571428571428572
Epoch:  837        6 Batch loss: 0.209264 Batch F1: 0.6153846153846153
Epoch:  837        7 Batch loss: 0.201810 Batch F1: 0.6428571428571429
Epoch:  837        8 Batch loss: 0.199567 Batch F1: 0.6122448979591836
Epoch:  837        9 Batch loss: 0.185181 Batch F1: 0.6341463414634146
Epoch:  837       10 Batch loss: 0.159647 Batch F1: 0.6486486486486486
Epoch:  837       11 Batch loss: 0.143749 Batch F1: 0.8
Epoch:  837       12 Batch loss: 0.161280 Batch F1: 0.5454545454545454
Train Avg Loss  837: 0.171137

Train Avg F1  837: 0.6827713824835033

Val Avg Loss  837: 0.202383

Val Avg F1  837:  0.5771296394065784

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 838
--------------------------------------------------------------
Epoch:  838        1 Batch loss: 0.221335 Batch F1: 0.6086956521739131
Epoch:  838        2 Batch loss: 0.184806 Batch F1: 0.6341463414634146
Epoch:  838        3 Batch loss: 0.171268 Batch F1: 0.7317073170731706
Epoch:  838        4 Batch loss: 0.183389 Batch F1: 0.6666666666666666
Epoch:  838        5 Batch loss: 0.158838 Batch F1: 0.7999999999999999
Epoch:  838        6 Batch loss: 0.140987 Batch F1: 0.7619047619047619
Epoch:  838        7 Batch loss: 0.146548 Batch F1: 0.761904761904762
Epoch:  838        8 Batch loss: 0.209583 Batch F1: 0.39999999999999997
Epoch:  838        9 Batch loss: 0.184763 Batch F1: 0.5625
Epoch:  838       10 Batch loss: 0.168160 Batch F1: 0.761904761904762
Epoch:  838       11 Batch loss: 0.178388 Batch F1: 0.6808510638297872
Epoch:  838       12 Batch loss: 0.162491 Batch F1: 0.8085106382978724
Train Avg Loss  838: 0.175880

Train Avg F1  838: 0.6815659971015925

Val Avg Loss  838: 0.191192

Val Avg F1  838:  0.690573980795355

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 839
--------------------------------------------------------------
Epoch:  839        1 Batch loss: 0.182468 Batch F1: 0.7111111111111111
Epoch:  839        2 Batch loss: 0.173805 Batch F1: 0.6511627906976744
Epoch:  839        3 Batch loss: 0.176341 Batch F1: 0.7199999999999999
Epoch:  839        4 Batch loss: 0.148028 Batch F1: 0.8095238095238095
Epoch:  839        5 Batch loss: 0.199197 Batch F1: 0.6363636363636365
Epoch:  839        6 Batch loss: 0.163565 Batch F1: 0.7272727272727272
Epoch:  839        7 Batch loss: 0.162847 Batch F1: 0.7555555555555556
Epoch:  839        8 Batch loss: 0.208833 Batch F1: 0.711864406779661
Epoch:  839        9 Batch loss: 0.133219 Batch F1: 0.8636363636363636
Epoch:  839       10 Batch loss: 0.161674 Batch F1: 0.6470588235294118
Epoch:  839       11 Batch loss: 0.143914 Batch F1: 0.851851851851852
Epoch:  839       12 Batch loss: 0.202051 Batch F1: 0.4666666666666667
Train Avg Loss  839: 0.171328

Train Avg F1  839: 0.7126723119157058

Val Avg Loss  839: 0.180777

Val Avg F1  839:  0.6877960404888189

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 840
--------------------------------------------------------------
Epoch:  840        1 Batch loss: 0.159725 Batch F1: 0.6666666666666665
Epoch:  840        2 Batch loss: 0.154439 Batch F1: 0.7555555555555556
Epoch:  840        3 Batch loss: 0.159625 Batch F1: 0.7659574468085107
Epoch:  840        4 Batch loss: 0.177382 Batch F1: 0.6153846153846154
Epoch:  840        5 Batch loss: 0.199162 Batch F1: 0.6785714285714286
Epoch:  840        6 Batch loss: 0.167698 Batch F1: 0.7272727272727272
Epoch:  840        7 Batch loss: 0.178769 Batch F1: 0.6511627906976744
Epoch:  840        8 Batch loss: 0.146258 Batch F1: 0.8076923076923077
Epoch:  840        9 Batch loss: 0.178831 Batch F1: 0.7450980392156864
Epoch:  840       10 Batch loss: 0.147633 Batch F1: 0.7428571428571428
Epoch:  840       11 Batch loss: 0.157701 Batch F1: 0.7317073170731706
Epoch:  840       12 Batch loss: 0.152824 Batch F1: 0.7999999999999999
Train Avg Loss  840: 0.165004

Train Avg F1  840: 0.7239938364829572

Val Avg Loss  840: 0.180712

Val Avg F1  840:  0.6766153269818566

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 841
--------------------------------------------------------------
Epoch:  841        1 Batch loss: 0.165133 Batch F1: 0.7391304347826088
Epoch:  841        2 Batch loss: 0.173032 Batch F1: 0.6956521739130435
Epoch:  841        3 Batch loss: 0.174869 Batch F1: 0.7111111111111111
Epoch:  841        4 Batch loss: 0.191398 Batch F1: 0.6382978723404256
Epoch:  841        5 Batch loss: 0.167414 Batch F1: 0.6829268292682926
Epoch:  841        6 Batch loss: 0.150120 Batch F1: 0.7317073170731707
Epoch:  841        7 Batch loss: 0.164241 Batch F1: 0.7346938775510204
Epoch:  841        8 Batch loss: 0.165168 Batch F1: 0.7659574468085106
Epoch:  841        9 Batch loss: 0.161001 Batch F1: 0.6842105263157895
Epoch:  841       10 Batch loss: 0.164560 Batch F1: 0.7843137254901961
Epoch:  841       11 Batch loss: 0.167396 Batch F1: 0.7142857142857143
Epoch:  841       12 Batch loss: 0.129844 Batch F1: 0.787878787878788
Train Avg Loss  841: 0.164515

Train Avg F1  841: 0.7225138180682226

Val Avg Loss  841: 0.183475

Val Avg F1  841:  0.6734478746121251

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 842
--------------------------------------------------------------
Epoch:  842        1 Batch loss: 0.193920 Batch F1: 0.5909090909090909
Epoch:  842        2 Batch loss: 0.180283 Batch F1: 0.6818181818181818
Epoch:  842        3 Batch loss: 0.171436 Batch F1: 0.7199999999999999
Epoch:  842        4 Batch loss: 0.149163 Batch F1: 0.8399999999999999
Epoch:  842        5 Batch loss: 0.157247 Batch F1: 0.6470588235294117
Epoch:  842        6 Batch loss: 0.171596 Batch F1: 0.7142857142857143
Epoch:  842        7 Batch loss: 0.187853 Batch F1: 0.6363636363636364
Epoch:  842        8 Batch loss: 0.146061 Batch F1: 0.8846153846153846
Epoch:  842        9 Batch loss: 0.163751 Batch F1: 0.7
Epoch:  842       10 Batch loss: 0.179782 Batch F1: 0.6341463414634146
Epoch:  842       11 Batch loss: 0.162339 Batch F1: 0.75
Epoch:  842       12 Batch loss: 0.146902 Batch F1: 0.7777777777777778
Train Avg Loss  842: 0.167528

Train Avg F1  842: 0.7147479125635511

Val Avg Loss  842: 0.182953

Val Avg F1  842:  0.6666666666666666

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 843
--------------------------------------------------------------
Epoch:  843        1 Batch loss: 0.175805 Batch F1: 0.5945945945945946
Epoch:  843        2 Batch loss: 0.165961 Batch F1: 0.7692307692307693
Epoch:  843        3 Batch loss: 0.149518 Batch F1: 0.830188679245283
Epoch:  843        4 Batch loss: 0.212919 Batch F1: 0.5714285714285714
Epoch:  843        5 Batch loss: 0.172747 Batch F1: 0.6666666666666666
Epoch:  843        6 Batch loss: 0.135312 Batch F1: 0.7804878048780488
Epoch:  843        7 Batch loss: 0.151535 Batch F1: 0.7027027027027029
Epoch:  843        8 Batch loss: 0.168111 Batch F1: 0.7142857142857143
Epoch:  843        9 Batch loss: 0.148239 Batch F1: 0.6842105263157895
Epoch:  843       10 Batch loss: 0.147177 Batch F1: 0.8085106382978724
Epoch:  843       11 Batch loss: 0.178327 Batch F1: 0.72
Epoch:  843       12 Batch loss: 0.189075 Batch F1: 0.65
Train Avg Loss  843: 0.166227

Train Avg F1  843: 0.7076922223038343

Val Avg Loss  843: 0.179800

Val Avg F1  843:  0.6983019019987106

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 844
--------------------------------------------------------------
Epoch:  844        1 Batch loss: 0.135493 Batch F1: 0.7567567567567567
Epoch:  844        2 Batch loss: 0.173597 Batch F1: 0.6511627906976744
Epoch:  844        3 Batch loss: 0.159402 Batch F1: 0.7142857142857143
Epoch:  844        4 Batch loss: 0.155126 Batch F1: 0.7619047619047619
Epoch:  844        5 Batch loss: 0.155525 Batch F1: 0.7555555555555556
Epoch:  844        6 Batch loss: 0.162003 Batch F1: 0.7450980392156864
Epoch:  844        7 Batch loss: 0.172940 Batch F1: 0.6666666666666666
Epoch:  844        8 Batch loss: 0.161310 Batch F1: 0.76
Epoch:  844        9 Batch loss: 0.160727 Batch F1: 0.7727272727272727
Epoch:  844       10 Batch loss: 0.180686 Batch F1: 0.6808510638297872
Epoch:  844       11 Batch loss: 0.176783 Batch F1: 0.7083333333333334
Epoch:  844       12 Batch loss: 0.166911 Batch F1: 0.7027027027027026
Train Avg Loss  844: 0.163375

Train Avg F1  844: 0.7230037214729926

Val Avg Loss  844: 0.183146

Val Avg F1  844:  0.6702898550724636

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 845
--------------------------------------------------------------
Epoch:  845        1 Batch loss: 0.193742 Batch F1: 0.6341463414634148
Epoch:  845        2 Batch loss: 0.175577 Batch F1: 0.631578947368421
Epoch:  845        3 Batch loss: 0.186107 Batch F1: 0.7555555555555556
Epoch:  845        4 Batch loss: 0.177771 Batch F1: 0.7755102040816326
Epoch:  845        5 Batch loss: 0.143501 Batch F1: 0.782608695652174
Epoch:  845        6 Batch loss: 0.138375 Batch F1: 0.8749999999999999
Epoch:  845        7 Batch loss: 0.147086 Batch F1: 0.8333333333333333
Epoch:  845        8 Batch loss: 0.185358 Batch F1: 0.6956521739130435
Epoch:  845        9 Batch loss: 0.155699 Batch F1: 0.7368421052631577
Epoch:  845       10 Batch loss: 0.160494 Batch F1: 0.7142857142857143
Epoch:  845       11 Batch loss: 0.175065 Batch F1: 0.6818181818181819
Epoch:  845       12 Batch loss: 0.195822 Batch F1: 0.6829268292682927
Train Avg Loss  845: 0.169550

Train Avg F1  845: 0.7332715068335768

Val Avg Loss  845: 0.182832

Val Avg F1  845:  0.684265010351967

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 846
--------------------------------------------------------------
Epoch:  846        1 Batch loss: 0.178513 Batch F1: 0.6808510638297872
Epoch:  846        2 Batch loss: 0.142930 Batch F1: 0.7894736842105262
Epoch:  846        3 Batch loss: 0.157211 Batch F1: 0.816326530612245
Epoch:  846        4 Batch loss: 0.177615 Batch F1: 0.7407407407407408
Epoch:  846        5 Batch loss: 0.183189 Batch F1: 0.7547169811320756
Epoch:  846        6 Batch loss: 0.150846 Batch F1: 0.8
Epoch:  846        7 Batch loss: 0.169396 Batch F1: 0.5882352941176471
Epoch:  846        8 Batch loss: 0.173325 Batch F1: 0.7391304347826085
Epoch:  846        9 Batch loss: 0.182356 Batch F1: 0.6923076923076923
Epoch:  846       10 Batch loss: 0.151020 Batch F1: 0.7234042553191491
Epoch:  846       11 Batch loss: 0.169369 Batch F1: 0.6666666666666665
Epoch:  846       12 Batch loss: 0.157169 Batch F1: 0.6451612903225806
Train Avg Loss  846: 0.166078

Train Avg F1  846: 0.7197512195034766

Val Avg Loss  846: 0.179808

Val Avg F1  846:  0.6864571765715883

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 847
--------------------------------------------------------------
Epoch:  847        1 Batch loss: 0.164613 Batch F1: 0.7500000000000001
Epoch:  847        2 Batch loss: 0.167542 Batch F1: 0.6976744186046512
Epoch:  847        3 Batch loss: 0.172559 Batch F1: 0.7111111111111111
Epoch:  847        4 Batch loss: 0.139844 Batch F1: 0.8095238095238095
Epoch:  847        5 Batch loss: 0.146374 Batch F1: 0.7317073170731708
Epoch:  847        6 Batch loss: 0.178491 Batch F1: 0.5945945945945946
Epoch:  847        7 Batch loss: 0.158571 Batch F1: 0.7755102040816326
Epoch:  847        8 Batch loss: 0.174645 Batch F1: 0.6315789473684211
Epoch:  847        9 Batch loss: 0.168515 Batch F1: 0.7083333333333334
Epoch:  847       10 Batch loss: 0.160728 Batch F1: 0.7692307692307692
Epoch:  847       11 Batch loss: 0.166906 Batch F1: 0.7234042553191489
Epoch:  847       12 Batch loss: 0.179673 Batch F1: 0.6060606060606061
Train Avg Loss  847: 0.164872

Train Avg F1  847: 0.709060780525104

Val Avg Loss  847: 0.179087

Val Avg F1  847:  0.6867669037311894

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 848
--------------------------------------------------------------
Epoch:  848        1 Batch loss: 0.201233 Batch F1: 0.6521739130434783
Epoch:  848        2 Batch loss: 0.151183 Batch F1: 0.7058823529411765
Epoch:  848        3 Batch loss: 0.192913 Batch F1: 0.5652173913043479
Epoch:  848        4 Batch loss: 0.164502 Batch F1: 0.7924528301886793
Epoch:  848        5 Batch loss: 0.161630 Batch F1: 0.7441860465116279
Epoch:  848        6 Batch loss: 0.154350 Batch F1: 0.7843137254901961
Epoch:  848        7 Batch loss: 0.133206 Batch F1: 0.7894736842105262
Epoch:  848        8 Batch loss: 0.180890 Batch F1: 0.6153846153846153
Epoch:  848        9 Batch loss: 0.161261 Batch F1: 0.7083333333333334
Epoch:  848       10 Batch loss: 0.167684 Batch F1: 0.6666666666666666
Epoch:  848       11 Batch loss: 0.173564 Batch F1: 0.6956521739130435
Epoch:  848       12 Batch loss: 0.113395 Batch F1: 0.9189189189189189
Train Avg Loss  848: 0.162984

Train Avg F1  848: 0.7198879709922176

Val Avg Loss  848: 0.178860

Val Avg F1  848:  0.6768849512069851

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 849
--------------------------------------------------------------
Epoch:  849        1 Batch loss: 0.149858 Batch F1: 0.717948717948718
Epoch:  849        2 Batch loss: 0.154143 Batch F1: 0.7916666666666666
Epoch:  849        3 Batch loss: 0.186262 Batch F1: 0.6341463414634148
Epoch:  849        4 Batch loss: 0.149430 Batch F1: 0.8333333333333333
Epoch:  849        5 Batch loss: 0.174947 Batch F1: 0.7450980392156864
Epoch:  849        6 Batch loss: 0.173967 Batch F1: 0.6222222222222223
Epoch:  849        7 Batch loss: 0.158786 Batch F1: 0.7272727272727273
Epoch:  849        8 Batch loss: 0.158567 Batch F1: 0.7555555555555555
Epoch:  849        9 Batch loss: 0.148314 Batch F1: 0.816326530612245
Epoch:  849       10 Batch loss: 0.154638 Batch F1: 0.8000000000000002
Epoch:  849       11 Batch loss: 0.170494 Batch F1: 0.6486486486486486
Epoch:  849       12 Batch loss: 0.192162 Batch F1: 0.5625000000000001
Train Avg Loss  849: 0.164297

Train Avg F1  849: 0.7212265652449349

Val Avg Loss  849: 0.179727

Val Avg F1  849:  0.6979895104895105

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 850
--------------------------------------------------------------
Epoch:  850        1 Batch loss: 0.157163 Batch F1: 0.717948717948718
Epoch:  850        2 Batch loss: 0.156934 Batch F1: 0.7391304347826085
Epoch:  850        3 Batch loss: 0.158135 Batch F1: 0.7777777777777778
Epoch:  850        4 Batch loss: 0.201856 Batch F1: 0.68
Epoch:  850        5 Batch loss: 0.163429 Batch F1: 0.7659574468085107
Epoch:  850        6 Batch loss: 0.159258 Batch F1: 0.7222222222222222
Epoch:  850        7 Batch loss: 0.136705 Batch F1: 0.7804878048780488
Epoch:  850        8 Batch loss: 0.189698 Batch F1: 0.6521739130434783
Epoch:  850        9 Batch loss: 0.161888 Batch F1: 0.7450980392156864
Epoch:  850       10 Batch loss: 0.179398 Batch F1: 0.6666666666666665
Epoch:  850       11 Batch loss: 0.151804 Batch F1: 0.7894736842105263
Epoch:  850       12 Batch loss: 0.174417 Batch F1: 0.6250000000000001
Train Avg Loss  850: 0.165890

Train Avg F1  850: 0.7218280589628536

Val Avg Loss  850: 0.183722

Val Avg F1  850:  0.6805422547283012

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 851
--------------------------------------------------------------
Epoch:  851        1 Batch loss: 0.189912 Batch F1: 0.68
Epoch:  851        2 Batch loss: 0.151414 Batch F1: 0.8095238095238095
Epoch:  851        3 Batch loss: 0.194230 Batch F1: 0.6818181818181818
Epoch:  851        4 Batch loss: 0.155340 Batch F1: 0.7428571428571428
Epoch:  851        5 Batch loss: 0.176476 Batch F1: 0.6666666666666665
Epoch:  851        6 Batch loss: 0.160737 Batch F1: 0.7659574468085107
Epoch:  851        7 Batch loss: 0.149856 Batch F1: 0.8333333333333333
Epoch:  851        8 Batch loss: 0.166184 Batch F1: 0.7000000000000001
Epoch:  851        9 Batch loss: 0.179816 Batch F1: 0.6829268292682927
Epoch:  851       10 Batch loss: 0.175069 Batch F1: 0.6666666666666666
Epoch:  851       11 Batch loss: 0.193515 Batch F1: 0.5777777777777778
Epoch:  851       12 Batch loss: 0.134000 Batch F1: 0.8500000000000001
Train Avg Loss  851: 0.168879

Train Avg F1  851: 0.7214606545600318

Val Avg Loss  851: 0.180337

Val Avg F1  851:  0.6849788930581614

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 852
--------------------------------------------------------------
Epoch:  852        1 Batch loss: 0.150678 Batch F1: 0.7222222222222222
Epoch:  852        2 Batch loss: 0.133145 Batch F1: 0.8571428571428572
Epoch:  852        3 Batch loss: 0.193094 Batch F1: 0.5909090909090909
Epoch:  852        4 Batch loss: 0.190345 Batch F1: 0.736842105263158
Epoch:  852        5 Batch loss: 0.138348 Batch F1: 0.8510638297872342
Epoch:  852        6 Batch loss: 0.168383 Batch F1: 0.65
Epoch:  852        7 Batch loss: 0.163758 Batch F1: 0.7906976744186046
Epoch:  852        8 Batch loss: 0.179167 Batch F1: 0.7200000000000001
Epoch:  852        9 Batch loss: 0.183983 Batch F1: 0.7391304347826089
Epoch:  852       10 Batch loss: 0.162136 Batch F1: 0.6666666666666667
Epoch:  852       11 Batch loss: 0.175847 Batch F1: 0.7083333333333333
Epoch:  852       12 Batch loss: 0.165890 Batch F1: 0.717948717948718
Train Avg Loss  852: 0.167065

Train Avg F1  852: 0.729246411039541

Val Avg Loss  852: 0.179151

Val Avg F1  852:  0.6931676047529707

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 853
--------------------------------------------------------------
Epoch:  853        1 Batch loss: 0.143646 Batch F1: 0.7999999999999999
Epoch:  853        2 Batch loss: 0.179085 Batch F1: 0.8135593220338982
Epoch:  853        3 Batch loss: 0.158830 Batch F1: 0.8181818181818182
Epoch:  853        4 Batch loss: 0.156416 Batch F1: 0.7368421052631579
Epoch:  853        5 Batch loss: 0.169006 Batch F1: 0.7000000000000001
Epoch:  853        6 Batch loss: 0.190156 Batch F1: 0.6222222222222223
Epoch:  853        7 Batch loss: 0.182544 Batch F1: 0.723404255319149
Epoch:  853        8 Batch loss: 0.179666 Batch F1: 0.7450980392156864
Epoch:  853        9 Batch loss: 0.149880 Batch F1: 0.7906976744186046
Epoch:  853       10 Batch loss: 0.157996 Batch F1: 0.7555555555555555
Epoch:  853       11 Batch loss: 0.172632 Batch F1: 0.6666666666666666
Epoch:  853       12 Batch loss: 0.184354 Batch F1: 0.6666666666666666
Train Avg Loss  853: 0.168684

Train Avg F1  853: 0.7365745271286187

Val Avg Loss  853: 0.180710

Val Avg F1  853:  0.6793632075471698

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 854
--------------------------------------------------------------
Epoch:  854        1 Batch loss: 0.152813 Batch F1: 0.6857142857142857
Epoch:  854        2 Batch loss: 0.159438 Batch F1: 0.7499999999999999
Epoch:  854        3 Batch loss: 0.127393 Batch F1: 0.787878787878788
Epoch:  854        4 Batch loss: 0.159059 Batch F1: 0.6829268292682926
Epoch:  854        5 Batch loss: 0.186426 Batch F1: 0.6818181818181819
Epoch:  854        6 Batch loss: 0.180412 Batch F1: 0.7058823529411764
Epoch:  854        7 Batch loss: 0.200671 Batch F1: 0.47058823529411764
Epoch:  854        8 Batch loss: 0.165207 Batch F1: 0.7272727272727272
Epoch:  854        9 Batch loss: 0.188988 Batch F1: 0.6521739130434783
Epoch:  854       10 Batch loss: 0.185557 Batch F1: 0.7037037037037037
Epoch:  854       11 Batch loss: 0.146391 Batch F1: 0.8510638297872342
Epoch:  854       12 Batch loss: 0.146275 Batch F1: 0.7567567567567567
Train Avg Loss  854: 0.166552

Train Avg F1  854: 0.7046483002898952

Val Avg Loss  854: 0.185253

Val Avg F1  854:  0.7324134199134198

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 855
--------------------------------------------------------------
Epoch:  855        1 Batch loss: 0.155971 Batch F1: 0.8181818181818182
Epoch:  855        2 Batch loss: 0.166059 Batch F1: 0.6829268292682926
Epoch:  855        3 Batch loss: 0.178397 Batch F1: 0.5555555555555555
Epoch:  855        4 Batch loss: 0.163519 Batch F1: 0.7755102040816326
Epoch:  855        5 Batch loss: 0.171488 Batch F1: 0.7200000000000001
Epoch:  855        6 Batch loss: 0.159260 Batch F1: 0.6470588235294118
Epoch:  855        7 Batch loss: 0.200121 Batch F1: 0.6341463414634148
Epoch:  855        8 Batch loss: 0.159164 Batch F1: 0.7555555555555555
Epoch:  855        9 Batch loss: 0.167946 Batch F1: 0.7083333333333334
Epoch:  855       10 Batch loss: 0.159542 Batch F1: 0.8
Epoch:  855       11 Batch loss: 0.160568 Batch F1: 0.8095238095238095
Epoch:  855       12 Batch loss: 0.184927 Batch F1: 0.761904761904762
Train Avg Loss  855: 0.168914

Train Avg F1  855: 0.7223914193664656

Val Avg Loss  855: 0.182622

Val Avg F1  855:  0.6786342229199372

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 856
--------------------------------------------------------------
Epoch:  856        1 Batch loss: 0.212554 Batch F1: 0.6046511627906976
Epoch:  856        2 Batch loss: 0.180052 Batch F1: 0.7407407407407408
Epoch:  856        3 Batch loss: 0.180787 Batch F1: 0.6486486486486486
Epoch:  856        4 Batch loss: 0.149815 Batch F1: 0.744186046511628
Epoch:  856        5 Batch loss: 0.169493 Batch F1: 0.7083333333333333
Epoch:  856        6 Batch loss: 0.172826 Batch F1: 0.6829268292682926
Epoch:  856        7 Batch loss: 0.150436 Batch F1: 0.8085106382978724
Epoch:  856        8 Batch loss: 0.164220 Batch F1: 0.7727272727272727
Epoch:  856        9 Batch loss: 0.182649 Batch F1: 0.7719298245614035
Epoch:  856       10 Batch loss: 0.136541 Batch F1: 0.8627450980392156
Epoch:  856       11 Batch loss: 0.148475 Batch F1: 0.787878787878788
Epoch:  856       12 Batch loss: 0.170211 Batch F1: 0.6060606060606061
Train Avg Loss  856: 0.168172

Train Avg F1  856: 0.7282782490715415

Val Avg Loss  856: 0.182803

Val Avg F1  856:  0.691376550620248

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 857
--------------------------------------------------------------
Epoch:  857        1 Batch loss: 0.181225 Batch F1: 0.7636363636363638
Epoch:  857        2 Batch loss: 0.163233 Batch F1: 0.75
Epoch:  857        3 Batch loss: 0.155142 Batch F1: 0.8800000000000001
Epoch:  857        4 Batch loss: 0.177872 Batch F1: 0.6808510638297872
Epoch:  857        5 Batch loss: 0.129388 Batch F1: 0.8421052631578947
Epoch:  857        6 Batch loss: 0.185269 Batch F1: 0.6153846153846153
Epoch:  857        7 Batch loss: 0.177140 Batch F1: 0.5714285714285714
Epoch:  857        8 Batch loss: 0.172289 Batch F1: 0.7
Epoch:  857        9 Batch loss: 0.144469 Batch F1: 0.8
Epoch:  857       10 Batch loss: 0.181749 Batch F1: 0.6666666666666666
Epoch:  857       11 Batch loss: 0.167458 Batch F1: 0.6486486486486486
Epoch:  857       12 Batch loss: 0.170688 Batch F1: 0.7999999999999999
Train Avg Loss  857: 0.167160

Train Avg F1  857: 0.7265600993960456

Val Avg Loss  857: 0.183261

Val Avg F1  857:  0.6787229207695804

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 858
--------------------------------------------------------------
Epoch:  858        1 Batch loss: 0.150324 Batch F1: 0.782608695652174
Epoch:  858        2 Batch loss: 0.150095 Batch F1: 0.7826086956521738
Epoch:  858        3 Batch loss: 0.151937 Batch F1: 0.782608695652174
Epoch:  858        4 Batch loss: 0.203117 Batch F1: 0.6415094339622641
Epoch:  858        5 Batch loss: 0.144706 Batch F1: 0.782608695652174
Epoch:  858        6 Batch loss: 0.162538 Batch F1: 0.717948717948718
Epoch:  858        7 Batch loss: 0.188169 Batch F1: 0.6046511627906976
Epoch:  858        8 Batch loss: 0.225592 Batch F1: 0.6037735849056604
Epoch:  858        9 Batch loss: 0.162034 Batch F1: 0.6842105263157895
Epoch:  858       10 Batch loss: 0.140163 Batch F1: 0.7692307692307692
Epoch:  858       11 Batch loss: 0.139203 Batch F1: 0.7692307692307693
Epoch:  858       12 Batch loss: 0.171521 Batch F1: 0.7317073170731706
Train Avg Loss  858: 0.165783

Train Avg F1  858: 0.7210580886722111

Val Avg Loss  858: 0.181096

Val Avg F1  858:  0.6730692276910764

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 859
--------------------------------------------------------------
Epoch:  859        1 Batch loss: 0.140704 Batch F1: 0.8292682926829269
Epoch:  859        2 Batch loss: 0.176221 Batch F1: 0.6666666666666666
Epoch:  859        3 Batch loss: 0.172056 Batch F1: 0.6666666666666666
Epoch:  859        4 Batch loss: 0.182160 Batch F1: 0.5853658536585366
Epoch:  859        5 Batch loss: 0.164684 Batch F1: 0.6829268292682926
Epoch:  859        6 Batch loss: 0.151862 Batch F1: 0.7499999999999999
Epoch:  859        7 Batch loss: 0.172185 Batch F1: 0.7692307692307693
Epoch:  859        8 Batch loss: 0.169259 Batch F1: 0.631578947368421
Epoch:  859        9 Batch loss: 0.141495 Batch F1: 0.8
Epoch:  859       10 Batch loss: 0.174717 Batch F1: 0.711111111111111
Epoch:  859       11 Batch loss: 0.139392 Batch F1: 0.8260869565217391
Epoch:  859       12 Batch loss: 0.177524 Batch F1: 0.6666666666666667
Train Avg Loss  859: 0.163521

Train Avg F1  859: 0.7154640633201498

Val Avg Loss  859: 0.179438

Val Avg F1  859:  0.7082950330591841

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 860
--------------------------------------------------------------
Epoch:  860        1 Batch loss: 0.164150 Batch F1: 0.7441860465116279
Epoch:  860        2 Batch loss: 0.139338 Batch F1: 0.7692307692307692
Epoch:  860        3 Batch loss: 0.179503 Batch F1: 0.7586206896551725
Epoch:  860        4 Batch loss: 0.136479 Batch F1: 0.7500000000000001
Epoch:  860        5 Batch loss: 0.171319 Batch F1: 0.6470588235294117
Epoch:  860        6 Batch loss: 0.172615 Batch F1: 0.6857142857142857
Epoch:  860        7 Batch loss: 0.190097 Batch F1: 0.4666666666666667
Epoch:  860        8 Batch loss: 0.195316 Batch F1: 0.68
Epoch:  860        9 Batch loss: 0.160181 Batch F1: 0.8085106382978724
Epoch:  860       10 Batch loss: 0.182965 Batch F1: 0.7307692307692307
Epoch:  860       11 Batch loss: 0.181864 Batch F1: 0.7586206896551724
Epoch:  860       12 Batch loss: 0.158858 Batch F1: 0.8372093023255814
Train Avg Loss  860: 0.169390

Train Avg F1  860: 0.719715595196316

Val Avg Loss  860: 0.185713

Val Avg F1  860:  0.7029001999711382

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 861
--------------------------------------------------------------
Epoch:  861        1 Batch loss: 0.173126 Batch F1: 0.7450980392156863
Epoch:  861        2 Batch loss: 0.169232 Batch F1: 0.6666666666666666
Epoch:  861        3 Batch loss: 0.144518 Batch F1: 0.8
Epoch:  861        4 Batch loss: 0.176527 Batch F1: 0.5161290322580645
Epoch:  861        5 Batch loss: 0.173309 Batch F1: 0.7441860465116279
Epoch:  861        6 Batch loss: 0.183444 Batch F1: 0.6190476190476191
Epoch:  861        7 Batch loss: 0.169365 Batch F1: 0.711111111111111
Epoch:  861        8 Batch loss: 0.198120 Batch F1: 0.6666666666666666
Epoch:  861        9 Batch loss: 0.168578 Batch F1: 0.75
Epoch:  861       10 Batch loss: 0.146844 Batch F1: 0.8148148148148148
Epoch:  861       11 Batch loss: 0.224655 Batch F1: 0.8
Epoch:  861       12 Batch loss: 0.172954 Batch F1: 0.7368421052631579
Train Avg Loss  861: 0.175056

Train Avg F1  861: 0.7142135084629513

Val Avg Loss  861: 0.186105

Val Avg F1  861:  0.6763468013468014

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 862
--------------------------------------------------------------
Epoch:  862        1 Batch loss: 0.166736 Batch F1: 0.7391304347826088
Epoch:  862        2 Batch loss: 0.183223 Batch F1: 0.723404255319149
Epoch:  862        3 Batch loss: 0.192872 Batch F1: 0.6808510638297872
Epoch:  862        4 Batch loss: 0.178275 Batch F1: 0.7843137254901961
Epoch:  862        5 Batch loss: 0.143281 Batch F1: 0.8484848484848485
Epoch:  862        6 Batch loss: 0.166160 Batch F1: 0.7692307692307692
Epoch:  862        7 Batch loss: 0.191534 Batch F1: 0.717948717948718
Epoch:  862        8 Batch loss: 0.164709 Batch F1: 0.76
Epoch:  862        9 Batch loss: 0.168958 Batch F1: 0.7
Epoch:  862       10 Batch loss: 0.137821 Batch F1: 0.8372093023255814
Epoch:  862       11 Batch loss: 0.175825 Batch F1: 0.7307692307692308
Epoch:  862       12 Batch loss: 0.177834 Batch F1: 0.7272727272727273
Train Avg Loss  862: 0.170602

Train Avg F1  862: 0.7515512562878013

Val Avg Loss  862: 0.183855

Val Avg F1  862:  0.7182877947505608

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 863
--------------------------------------------------------------
Epoch:  863        1 Batch loss: 0.160220 Batch F1: 0.8
Epoch:  863        2 Batch loss: 0.169611 Batch F1: 0.7234042553191489
Epoch:  863        3 Batch loss: 0.184676 Batch F1: 0.6818181818181818
Epoch:  863        4 Batch loss: 0.158025 Batch F1: 0.7368421052631577
Epoch:  863        5 Batch loss: 0.189576 Batch F1: 0.6363636363636365
Epoch:  863        6 Batch loss: 0.184520 Batch F1: 0.6923076923076924
Epoch:  863        7 Batch loss: 0.167318 Batch F1: 0.7111111111111111
Epoch:  863        8 Batch loss: 0.165420 Batch F1: 0.7272727272727272
Epoch:  863        9 Batch loss: 0.212446 Batch F1: 0.6666666666666666
Epoch:  863       10 Batch loss: 0.135319 Batch F1: 0.8000000000000002
Epoch:  863       11 Batch loss: 0.148259 Batch F1: 0.7727272727272727
Epoch:  863       12 Batch loss: 0.181508 Batch F1: 0.7222222222222222
Train Avg Loss  863: 0.171408

Train Avg F1  863: 0.7225613225893182

Val Avg Loss  863: 0.182637

Val Avg F1  863:  0.6705347091932458

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 864
--------------------------------------------------------------
Epoch:  864        1 Batch loss: 0.159009 Batch F1: 0.6842105263157895
Epoch:  864        2 Batch loss: 0.164076 Batch F1: 0.7272727272727272
Epoch:  864        3 Batch loss: 0.186649 Batch F1: 0.6938775510204083
Epoch:  864        4 Batch loss: 0.181638 Batch F1: 0.8076923076923076
Epoch:  864        5 Batch loss: 0.172335 Batch F1: 0.7407407407407407
Epoch:  864        6 Batch loss: 0.143615 Batch F1: 0.7777777777777778
Epoch:  864        7 Batch loss: 0.151410 Batch F1: 0.7619047619047619
Epoch:  864        8 Batch loss: 0.189846 Batch F1: 0.6086956521739131
Epoch:  864        9 Batch loss: 0.135607 Batch F1: 0.8333333333333333
Epoch:  864       10 Batch loss: 0.190360 Batch F1: 0.6818181818181818
Epoch:  864       11 Batch loss: 0.163697 Batch F1: 0.7843137254901961
Epoch:  864       12 Batch loss: 0.186224 Batch F1: 0.75
Train Avg Loss  864: 0.168705

Train Avg F1  864: 0.7376364404616781

Val Avg Loss  864: 0.179835

Val Avg F1  864:  0.6822596532702916

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 865
--------------------------------------------------------------
Epoch:  865        1 Batch loss: 0.164439 Batch F1: 0.717948717948718
Epoch:  865        2 Batch loss: 0.188128 Batch F1: 0.6363636363636365
Epoch:  865        3 Batch loss: 0.180019 Batch F1: 0.6666666666666667
Epoch:  865        4 Batch loss: 0.168056 Batch F1: 0.7234042553191491
Epoch:  865        5 Batch loss: 0.166470 Batch F1: 0.6153846153846155
Epoch:  865        6 Batch loss: 0.181123 Batch F1: 0.6938775510204083
Epoch:  865        7 Batch loss: 0.155569 Batch F1: 0.8333333333333333
Epoch:  865        8 Batch loss: 0.154714 Batch F1: 0.7857142857142856
Epoch:  865        9 Batch loss: 0.172642 Batch F1: 0.6808510638297872
Epoch:  865       10 Batch loss: 0.180229 Batch F1: 0.6666666666666666
Epoch:  865       11 Batch loss: 0.169151 Batch F1: 0.7000000000000001
Epoch:  865       12 Batch loss: 0.163677 Batch F1: 0.7692307692307692
Train Avg Loss  865: 0.170351

Train Avg F1  865: 0.707453463456503

Val Avg Loss  865: 0.186261

Val Avg F1  865:  0.6826992753623189

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 866
--------------------------------------------------------------
Epoch:  866        1 Batch loss: 0.154236 Batch F1: 0.7441860465116279
Epoch:  866        2 Batch loss: 0.166641 Batch F1: 0.6486486486486486
Epoch:  866        3 Batch loss: 0.168678 Batch F1: 0.7
Epoch:  866        4 Batch loss: 0.178302 Batch F1: 0.6808510638297872
Epoch:  866        5 Batch loss: 0.177286 Batch F1: 0.7307692307692308
Epoch:  866        6 Batch loss: 0.199524 Batch F1: 0.6521739130434783
Epoch:  866        7 Batch loss: 0.164980 Batch F1: 0.7843137254901961
Epoch:  866        8 Batch loss: 0.157635 Batch F1: 0.7916666666666667
Epoch:  866        9 Batch loss: 0.148322 Batch F1: 0.742857142857143
Epoch:  866       10 Batch loss: 0.176545 Batch F1: 0.611111111111111
Epoch:  866       11 Batch loss: 0.162815 Batch F1: 0.7
Epoch:  866       12 Batch loss: 0.175325 Batch F1: 0.7142857142857143
Train Avg Loss  866: 0.169191

Train Avg F1  866: 0.708405271934467

Val Avg Loss  866: 0.191083

Val Avg F1  866:  0.7783299327597932

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 867
--------------------------------------------------------------
Epoch:  867        1 Batch loss: 0.181540 Batch F1: 0.7916666666666667
Epoch:  867        2 Batch loss: 0.143216 Batch F1: 0.830188679245283
Epoch:  867        3 Batch loss: 0.186658 Batch F1: 0.6249999999999999
Epoch:  867        4 Batch loss: 0.184317 Batch F1: 0.7083333333333334
Epoch:  867        5 Batch loss: 0.177789 Batch F1: 0.717948717948718
Epoch:  867        6 Batch loss: 0.182489 Batch F1: 0.5641025641025642
Epoch:  867        7 Batch loss: 0.181450 Batch F1: 0.5853658536585366
Epoch:  867        8 Batch loss: 0.156395 Batch F1: 0.761904761904762
Epoch:  867        9 Batch loss: 0.172651 Batch F1: 0.6829268292682926
Epoch:  867       10 Batch loss: 0.165738 Batch F1: 0.744186046511628
Epoch:  867       11 Batch loss: 0.160621 Batch F1: 0.8627450980392156
Epoch:  867       12 Batch loss: 0.187744 Batch F1: 0.8148148148148149
Train Avg Loss  867: 0.173384

Train Avg F1  867: 0.7240986137911513

Val Avg Loss  867: 0.184919

Val Avg F1  867:  0.770004033545473

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 868
--------------------------------------------------------------
Epoch:  868        1 Batch loss: 0.168841 Batch F1: 0.8085106382978724
Epoch:  868        2 Batch loss: 0.155177 Batch F1: 0.8181818181818182
Epoch:  868        3 Batch loss: 0.183382 Batch F1: 0.6956521739130435
Epoch:  868        4 Batch loss: 0.197127 Batch F1: 0.68
Epoch:  868        5 Batch loss: 0.144895 Batch F1: 0.8000000000000002
Epoch:  868        6 Batch loss: 0.197219 Batch F1: 0.6500000000000001
Epoch:  868        7 Batch loss: 0.210767 Batch F1: 0.6
Epoch:  868        8 Batch loss: 0.150240 Batch F1: 0.8510638297872339
Epoch:  868        9 Batch loss: 0.161399 Batch F1: 0.7692307692307692
Epoch:  868       10 Batch loss: 0.191067 Batch F1: 0.7719298245614035
Epoch:  868       11 Batch loss: 0.172274 Batch F1: 0.723404255319149
Epoch:  868       12 Batch loss: 0.171676 Batch F1: 0.6875
Train Avg Loss  868: 0.175339

Train Avg F1  868: 0.7379561091076074

Val Avg Loss  868: 0.185797

Val Avg F1  868:  0.6714492753623188

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 869
--------------------------------------------------------------
Epoch:  869        1 Batch loss: 0.182020 Batch F1: 0.6511627906976744
Epoch:  869        2 Batch loss: 0.150088 Batch F1: 0.8333333333333333
Epoch:  869        3 Batch loss: 0.173601 Batch F1: 0.7659574468085107
Epoch:  869        4 Batch loss: 0.170669 Batch F1: 0.6956521739130435
Epoch:  869        5 Batch loss: 0.179072 Batch F1: 0.7
Epoch:  869        6 Batch loss: 0.195767 Batch F1: 0.7058823529411765
Epoch:  869        7 Batch loss: 0.157341 Batch F1: 0.7272727272727272
Epoch:  869        8 Batch loss: 0.151668 Batch F1: 0.8181818181818182
Epoch:  869        9 Batch loss: 0.181374 Batch F1: 0.5714285714285714
Epoch:  869       10 Batch loss: 0.193351 Batch F1: 0.6486486486486486
Epoch:  869       11 Batch loss: 0.223655 Batch F1: 0.5581395348837209
Epoch:  869       12 Batch loss: 0.142922 Batch F1: 0.8421052631578947
Train Avg Loss  869: 0.175127

Train Avg F1  869: 0.7098137217722599

Val Avg Loss  869: 0.180788

Val Avg F1  869:  0.6994406737053797

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 870
--------------------------------------------------------------
Epoch:  870        1 Batch loss: 0.147890 Batch F1: 0.7804878048780488
Epoch:  870        2 Batch loss: 0.190027 Batch F1: 0.6
Epoch:  870        3 Batch loss: 0.142233 Batch F1: 0.8666666666666666
Epoch:  870        4 Batch loss: 0.208922 Batch F1: 0.4848484848484849
Epoch:  870        5 Batch loss: 0.189755 Batch F1: 0.6956521739130435
Epoch:  870        6 Batch loss: 0.151880 Batch F1: 0.823529411764706
Epoch:  870        7 Batch loss: 0.178905 Batch F1: 0.693877551020408
Epoch:  870        8 Batch loss: 0.160244 Batch F1: 0.7692307692307692
Epoch:  870        9 Batch loss: 0.160845 Batch F1: 0.6829268292682926
Epoch:  870       10 Batch loss: 0.176962 Batch F1: 0.711111111111111
Epoch:  870       11 Batch loss: 0.157757 Batch F1: 0.76
Epoch:  870       12 Batch loss: 0.183765 Batch F1: 0.6486486486486486
Train Avg Loss  870: 0.170765

Train Avg F1  870: 0.7097482876125148

Val Avg Loss  870: 0.181941

Val Avg F1  870:  0.6773961853749088

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 871
--------------------------------------------------------------
Epoch:  871        1 Batch loss: 0.170365 Batch F1: 0.7407407407407408
Epoch:  871        2 Batch loss: 0.170475 Batch F1: 0.7234042553191491
Epoch:  871        3 Batch loss: 0.167505 Batch F1: 0.6976744186046512
Epoch:  871        4 Batch loss: 0.168877 Batch F1: 0.8085106382978724
Epoch:  871        5 Batch loss: 0.187823 Batch F1: 0.6511627906976745
Epoch:  871        6 Batch loss: 0.146118 Batch F1: 0.7777777777777778
Epoch:  871        7 Batch loss: 0.153810 Batch F1: 0.7906976744186046
Epoch:  871        8 Batch loss: 0.151089 Batch F1: 0.742857142857143
Epoch:  871        9 Batch loss: 0.195052 Batch F1: 0.6
Epoch:  871       10 Batch loss: 0.174712 Batch F1: 0.7857142857142857
Epoch:  871       11 Batch loss: 0.193680 Batch F1: 0.6
Epoch:  871       12 Batch loss: 0.172208 Batch F1: 0.75
Train Avg Loss  871: 0.170976

Train Avg F1  871: 0.7223783103689915

Val Avg Loss  871: 0.184937

Val Avg F1  871:  0.6847747662965055

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 872
--------------------------------------------------------------
Epoch:  872        1 Batch loss: 0.166848 Batch F1: 0.7407407407407408
Epoch:  872        2 Batch loss: 0.165664 Batch F1: 0.6500000000000001
Epoch:  872        3 Batch loss: 0.201320 Batch F1: 0.7058823529411765
Epoch:  872        4 Batch loss: 0.159126 Batch F1: 0.851851851851852
Epoch:  872        5 Batch loss: 0.156699 Batch F1: 0.7727272727272727
Epoch:  872        6 Batch loss: 0.144156 Batch F1: 0.7692307692307693
Epoch:  872        7 Batch loss: 0.175182 Batch F1: 0.65
Epoch:  872        8 Batch loss: 0.182404 Batch F1: 0.6976744186046512
Epoch:  872        9 Batch loss: 0.183400 Batch F1: 0.6829268292682927
Epoch:  872       10 Batch loss: 0.195984 Batch F1: 0.6521739130434783
Epoch:  872       11 Batch loss: 0.161070 Batch F1: 0.6470588235294117
Epoch:  872       12 Batch loss: 0.140204 Batch F1: 0.85
Train Avg Loss  872: 0.169338

Train Avg F1  872: 0.7225222476614704

Val Avg Loss  872: 0.181834

Val Avg F1  872:  0.6876111399411866

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 873
--------------------------------------------------------------
Epoch:  873        1 Batch loss: 0.164119 Batch F1: 0.6341463414634146
Epoch:  873        2 Batch loss: 0.153246 Batch F1: 0.8163265306122449
Epoch:  873        3 Batch loss: 0.169095 Batch F1: 0.8070175438596492
Epoch:  873        4 Batch loss: 0.179701 Batch F1: 0.8235294117647058
Epoch:  873        5 Batch loss: 0.164405 Batch F1: 0.8363636363636363
Epoch:  873        6 Batch loss: 0.194538 Batch F1: 0.6666666666666666
Epoch:  873        7 Batch loss: 0.196384 Batch F1: 0.6363636363636364
Epoch:  873        8 Batch loss: 0.134357 Batch F1: 0.8095238095238095
Epoch:  873        9 Batch loss: 0.183665 Batch F1: 0.588235294117647
Epoch:  873       10 Batch loss: 0.196849 Batch F1: 0.679245283018868
Epoch:  873       11 Batch loss: 0.161749 Batch F1: 0.6875
Epoch:  873       12 Batch loss: 0.154545 Batch F1: 0.8333333333333334
Train Avg Loss  873: 0.171055

Train Avg F1  873: 0.7348542905906342

Val Avg Loss  873: 0.183665

Val Avg F1  873:  0.6842812360053739

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 874
--------------------------------------------------------------
Epoch:  874        1 Batch loss: 0.148535 Batch F1: 0.7916666666666666
Epoch:  874        2 Batch loss: 0.178954 Batch F1: 0.6086956521739131
Epoch:  874        3 Batch loss: 0.164627 Batch F1: 0.6666666666666666
Epoch:  874        4 Batch loss: 0.166299 Batch F1: 0.7619047619047619
Epoch:  874        5 Batch loss: 0.175600 Batch F1: 0.6470588235294117
Epoch:  874        6 Batch loss: 0.183484 Batch F1: 0.7000000000000001
Epoch:  874        7 Batch loss: 0.192472 Batch F1: 0.6923076923076923
Epoch:  874        8 Batch loss: 0.178916 Batch F1: 0.6382978723404256
Epoch:  874        9 Batch loss: 0.177372 Batch F1: 0.7547169811320754
Epoch:  874       10 Batch loss: 0.176664 Batch F1: 0.6666666666666667
Epoch:  874       11 Batch loss: 0.142863 Batch F1: 0.8095238095238095
Epoch:  874       12 Batch loss: 0.161653 Batch F1: 0.7317073170731707
Train Avg Loss  874: 0.170620

Train Avg F1  874: 0.7057677424987716

Val Avg Loss  874: 0.185547

Val Avg F1  874:  0.6804649758454107

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 875
--------------------------------------------------------------
Epoch:  875        1 Batch loss: 0.162671 Batch F1: 0.7659574468085107
Epoch:  875        2 Batch loss: 0.156475 Batch F1: 0.7499999999999999
Epoch:  875        3 Batch loss: 0.127188 Batch F1: 0.8
Epoch:  875        4 Batch loss: 0.200950 Batch F1: 0.6
Epoch:  875        5 Batch loss: 0.202048 Batch F1: 0.6122448979591837
Epoch:  875        6 Batch loss: 0.163480 Batch F1: 0.761904761904762
Epoch:  875        7 Batch loss: 0.173378 Batch F1: 0.7083333333333333
Epoch:  875        8 Batch loss: 0.189211 Batch F1: 0.6521739130434783
Epoch:  875        9 Batch loss: 0.179722 Batch F1: 0.7199999999999999
Epoch:  875       10 Batch loss: 0.155909 Batch F1: 0.7346938775510204
Epoch:  875       11 Batch loss: 0.178321 Batch F1: 0.5789473684210527
Epoch:  875       12 Batch loss: 0.193142 Batch F1: 0.7317073170731707
Train Avg Loss  875: 0.173541

Train Avg F1  875: 0.701330243007876

Val Avg Loss  875: 0.191868

Val Avg F1  875:  0.6272275955518176

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 876
--------------------------------------------------------------
Epoch:  876        1 Batch loss: 0.162132 Batch F1: 0.7906976744186047
Epoch:  876        2 Batch loss: 0.154615 Batch F1: 0.6842105263157895
Epoch:  876        3 Batch loss: 0.197841 Batch F1: 0.5641025641025641
Epoch:  876        4 Batch loss: 0.162772 Batch F1: 0.6857142857142857
Epoch:  876        5 Batch loss: 0.162816 Batch F1: 0.8
Epoch:  876        6 Batch loss: 0.132839 Batch F1: 0.75
Epoch:  876        7 Batch loss: 0.153782 Batch F1: 0.8571428571428571
Epoch:  876        8 Batch loss: 0.196218 Batch F1: 0.6538461538461539
Epoch:  876        9 Batch loss: 0.167550 Batch F1: 0.7391304347826088
Epoch:  876       10 Batch loss: 0.176178 Batch F1: 0.6111111111111112
Epoch:  876       11 Batch loss: 0.160060 Batch F1: 0.7555555555555556
Epoch:  876       12 Batch loss: 0.190208 Batch F1: 0.6315789473684211
Train Avg Loss  876: 0.168084

Train Avg F1  876: 0.7102575091964959

Val Avg Loss  876: 0.179532

Val Avg F1  876:  0.7031546979331482

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 877
--------------------------------------------------------------
Epoch:  877        1 Batch loss: 0.160856 Batch F1: 0.6842105263157896
Epoch:  877        2 Batch loss: 0.146389 Batch F1: 0.8846153846153846
Epoch:  877        3 Batch loss: 0.144970 Batch F1: 0.8333333333333333
Epoch:  877        4 Batch loss: 0.193679 Batch F1: 0.6285714285714286
Epoch:  877        5 Batch loss: 0.179424 Batch F1: 0.7111111111111111
Epoch:  877        6 Batch loss: 0.199007 Batch F1: 0.6274509803921569
Epoch:  877        7 Batch loss: 0.154267 Batch F1: 0.7027027027027027
Epoch:  877        8 Batch loss: 0.167820 Batch F1: 0.7317073170731706
Epoch:  877        9 Batch loss: 0.179157 Batch F1: 0.7307692307692306
Epoch:  877       10 Batch loss: 0.150112 Batch F1: 0.7272727272727272
Epoch:  877       11 Batch loss: 0.177012 Batch F1: 0.6
Epoch:  877       12 Batch loss: 0.174522 Batch F1: 0.7727272727272727
Train Avg Loss  877: 0.168934

Train Avg F1  877: 0.7195393345736923

Val Avg Loss  877: 0.183371

Val Avg F1  877:  0.6744612992903006

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 878
--------------------------------------------------------------
Epoch:  878        1 Batch loss: 0.160201 Batch F1: 0.5714285714285715
Epoch:  878        2 Batch loss: 0.176073 Batch F1: 0.7391304347826089
Epoch:  878        3 Batch loss: 0.166128 Batch F1: 0.6000000000000001
Epoch:  878        4 Batch loss: 0.186945 Batch F1: 0.6818181818181818
Epoch:  878        5 Batch loss: 0.178178 Batch F1: 0.6938775510204083
Epoch:  878        6 Batch loss: 0.163092 Batch F1: 0.830188679245283
Epoch:  878        7 Batch loss: 0.191045 Batch F1: 0.7307692307692308
Epoch:  878        8 Batch loss: 0.160949 Batch F1: 0.7755102040816326
Epoch:  878        9 Batch loss: 0.183647 Batch F1: 0.7222222222222222
Epoch:  878       10 Batch loss: 0.140483 Batch F1: 0.8444444444444444
Epoch:  878       11 Batch loss: 0.171102 Batch F1: 0.723404255319149
Epoch:  878       12 Batch loss: 0.173687 Batch F1: 0.7317073170731706
Train Avg Loss  878: 0.170961

Train Avg F1  878: 0.7203750910170753

Val Avg Loss  878: 0.186569

Val Avg F1  878:  0.6758336057535141

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 879
--------------------------------------------------------------
Epoch:  879        1 Batch loss: 0.167945 Batch F1: 0.7272727272727273
Epoch:  879        2 Batch loss: 0.129442 Batch F1: 0.8780487804878048
Epoch:  879        3 Batch loss: 0.163670 Batch F1: 0.7142857142857143
Epoch:  879        4 Batch loss: 0.183766 Batch F1: 0.6521739130434783
Epoch:  879        5 Batch loss: 0.161476 Batch F1: 0.723404255319149
Epoch:  879        6 Batch loss: 0.196827 Batch F1: 0.6909090909090909
Epoch:  879        7 Batch loss: 0.191886 Batch F1: 0.7037037037037038
Epoch:  879        8 Batch loss: 0.181998 Batch F1: 0.625
Epoch:  879        9 Batch loss: 0.157401 Batch F1: 0.7142857142857143
Epoch:  879       10 Batch loss: 0.203179 Batch F1: 0.6
Epoch:  879       11 Batch loss: 0.141591 Batch F1: 0.8636363636363636
Epoch:  879       12 Batch loss: 0.167860 Batch F1: 0.8000000000000002
Train Avg Loss  879: 0.170587

Train Avg F1  879: 0.7243933552453122

Val Avg Loss  879: 0.187779

Val Avg F1  879:  0.6697836510137677

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 880
--------------------------------------------------------------
Epoch:  880        1 Batch loss: 0.182839 Batch F1: 0.6341463414634146
Epoch:  880        2 Batch loss: 0.166737 Batch F1: 0.7499999999999999
Epoch:  880        3 Batch loss: 0.181265 Batch F1: 0.6938775510204083
Epoch:  880        4 Batch loss: 0.161911 Batch F1: 0.8235294117647057
Epoch:  880        5 Batch loss: 0.159489 Batch F1: 0.7391304347826088
Epoch:  880        6 Batch loss: 0.183348 Batch F1: 0.6153846153846154
Epoch:  880        7 Batch loss: 0.155587 Batch F1: 0.7027027027027027
Epoch:  880        8 Batch loss: 0.180596 Batch F1: 0.65
Epoch:  880        9 Batch loss: 0.150132 Batch F1: 0.8
Epoch:  880       10 Batch loss: 0.169456 Batch F1: 0.631578947368421
Epoch:  880       11 Batch loss: 0.173879 Batch F1: 0.6818181818181818
Epoch:  880       12 Batch loss: 0.178888 Batch F1: 0.8372093023255813
Train Avg Loss  880: 0.170344

Train Avg F1  880: 0.7132814573858867

Val Avg Loss  880: 0.179756

Val Avg F1  880:  0.6865316642507511

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 881
--------------------------------------------------------------
Epoch:  881        1 Batch loss: 0.194115 Batch F1: 0.5641025641025641
Epoch:  881        2 Batch loss: 0.167600 Batch F1: 0.7391304347826089
Epoch:  881        3 Batch loss: 0.185360 Batch F1: 0.6956521739130435
Epoch:  881        4 Batch loss: 0.173178 Batch F1: 0.6976744186046512
Epoch:  881        5 Batch loss: 0.184504 Batch F1: 0.76
Epoch:  881        6 Batch loss: 0.170926 Batch F1: 0.7692307692307692
Epoch:  881        7 Batch loss: 0.147133 Batch F1: 0.7777777777777778
Epoch:  881        8 Batch loss: 0.191761 Batch F1: 0.6521739130434783
Epoch:  881        9 Batch loss: 0.126152 Batch F1: 0.8421052631578947
Epoch:  881       10 Batch loss: 0.160938 Batch F1: 0.7391304347826088
Epoch:  881       11 Batch loss: 0.167192 Batch F1: 0.7391304347826089
Epoch:  881       12 Batch loss: 0.162559 Batch F1: 0.7027027027027027
Train Avg Loss  881: 0.169285

Train Avg F1  881: 0.7232342405733924

Val Avg Loss  881: 0.180677

Val Avg F1  881:  0.6736642743221691

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 882
--------------------------------------------------------------
Epoch:  882        1 Batch loss: 0.149343 Batch F1: 0.8181818181818182
Epoch:  882        2 Batch loss: 0.197274 Batch F1: 0.7037037037037038
Epoch:  882        3 Batch loss: 0.141853 Batch F1: 0.7272727272727273
Epoch:  882        4 Batch loss: 0.183809 Batch F1: 0.619047619047619
Epoch:  882        5 Batch loss: 0.172733 Batch F1: 0.6808510638297872
Epoch:  882        6 Batch loss: 0.181780 Batch F1: 0.6511627906976745
Epoch:  882        7 Batch loss: 0.179624 Batch F1: 0.7450980392156864
Epoch:  882        8 Batch loss: 0.150590 Batch F1: 0.6857142857142857
Epoch:  882        9 Batch loss: 0.156303 Batch F1: 0.7142857142857143
Epoch:  882       10 Batch loss: 0.137008 Batch F1: 0.7906976744186046
Epoch:  882       11 Batch loss: 0.161370 Batch F1: 0.711111111111111
Epoch:  882       12 Batch loss: 0.171699 Batch F1: 0.7142857142857143
Train Avg Loss  882: 0.165282

Train Avg F1  882: 0.7134510218137038

Val Avg Loss  882: 0.179335

Val Avg F1  882:  0.6734086144463503

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 883
--------------------------------------------------------------
Epoch:  883        1 Batch loss: 0.170352 Batch F1: 0.7169811320754716
Epoch:  883        2 Batch loss: 0.149870 Batch F1: 0.7727272727272727
Epoch:  883        3 Batch loss: 0.185407 Batch F1: 0.7169811320754716
Epoch:  883        4 Batch loss: 0.177948 Batch F1: 0.6666666666666665
Epoch:  883        5 Batch loss: 0.198927 Batch F1: 0.5581395348837209
Epoch:  883        6 Batch loss: 0.175142 Batch F1: 0.7924528301886793
Epoch:  883        7 Batch loss: 0.172844 Batch F1: 0.5294117647058824
Epoch:  883        8 Batch loss: 0.174676 Batch F1: 0.7
Epoch:  883        9 Batch loss: 0.142163 Batch F1: 0.7096774193548386
Epoch:  883       10 Batch loss: 0.158521 Batch F1: 0.7142857142857143
Epoch:  883       11 Batch loss: 0.162730 Batch F1: 0.8076923076923077
Epoch:  883       12 Batch loss: 0.145001 Batch F1: 0.8181818181818182
Train Avg Loss  883: 0.167798

Train Avg F1  883: 0.7085997994031538

Val Avg Loss  883: 0.182319

Val Avg F1  883:  0.6866956802063184

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 884
--------------------------------------------------------------
Epoch:  884        1 Batch loss: 0.173423 Batch F1: 0.7636363636363638
Epoch:  884        2 Batch loss: 0.180267 Batch F1: 0.6382978723404255
Epoch:  884        3 Batch loss: 0.189496 Batch F1: 0.5833333333333334
Epoch:  884        4 Batch loss: 0.181401 Batch F1: 0.5714285714285714
Epoch:  884        5 Batch loss: 0.192046 Batch F1: 0.6792452830188679
Epoch:  884        6 Batch loss: 0.160382 Batch F1: 0.7843137254901961
Epoch:  884        7 Batch loss: 0.172460 Batch F1: 0.6111111111111113
Epoch:  884        8 Batch loss: 0.161701 Batch F1: 0.7500000000000001
Epoch:  884        9 Batch loss: 0.159591 Batch F1: 0.6666666666666667
Epoch:  884       10 Batch loss: 0.165129 Batch F1: 0.8076923076923077
Epoch:  884       11 Batch loss: 0.178564 Batch F1: 0.7391304347826088
Epoch:  884       12 Batch loss: 0.134229 Batch F1: 0.8235294117647058
Train Avg Loss  884: 0.170724

Train Avg F1  884: 0.7015320901054299

Val Avg Loss  884: 0.182065

Val Avg F1  884:  0.6796515414676509

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 885
--------------------------------------------------------------
Epoch:  885        1 Batch loss: 0.161182 Batch F1: 0.7
Epoch:  885        2 Batch loss: 0.167315 Batch F1: 0.6315789473684211
Epoch:  885        3 Batch loss: 0.175328 Batch F1: 0.7307692307692308
Epoch:  885        4 Batch loss: 0.149144 Batch F1: 0.7441860465116279
Epoch:  885        5 Batch loss: 0.136050 Batch F1: 0.7428571428571428
Epoch:  885        6 Batch loss: 0.164108 Batch F1: 0.7346938775510203
Epoch:  885        7 Batch loss: 0.184232 Batch F1: 0.6500000000000001
Epoch:  885        8 Batch loss: 0.163851 Batch F1: 0.7500000000000001
Epoch:  885        9 Batch loss: 0.186450 Batch F1: 0.6511627906976744
Epoch:  885       10 Batch loss: 0.182453 Batch F1: 0.7200000000000001
Epoch:  885       11 Batch loss: 0.190413 Batch F1: 0.6938775510204083
Epoch:  885       12 Batch loss: 0.152269 Batch F1: 0.7894736842105262
Train Avg Loss  885: 0.167733

Train Avg F1  885: 0.7115499392488377

Val Avg Loss  885: 0.181833

Val Avg F1  885:  0.6722334682860999

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 886
--------------------------------------------------------------
Epoch:  886        1 Batch loss: 0.159338 Batch F1: 0.7636363636363636
Epoch:  886        2 Batch loss: 0.203151 Batch F1: 0.6
Epoch:  886        3 Batch loss: 0.186017 Batch F1: 0.6363636363636364
Epoch:  886        4 Batch loss: 0.191153 Batch F1: 0.6521739130434783
Epoch:  886        5 Batch loss: 0.142395 Batch F1: 0.8333333333333333
Epoch:  886        6 Batch loss: 0.155409 Batch F1: 0.7
Epoch:  886        7 Batch loss: 0.175688 Batch F1: 0.7169811320754716
Epoch:  886        8 Batch loss: 0.179512 Batch F1: 0.6808510638297872
Epoch:  886        9 Batch loss: 0.160725 Batch F1: 0.6666666666666667
Epoch:  886       10 Batch loss: 0.152260 Batch F1: 0.8260869565217391
Epoch:  886       11 Batch loss: 0.176198 Batch F1: 0.6976744186046512
Epoch:  886       12 Batch loss: 0.149305 Batch F1: 0.7999999999999999
Train Avg Loss  886: 0.169263

Train Avg F1  886: 0.7144806236729274

Val Avg Loss  886: 0.180952

Val Avg F1  886:  0.690130023640662

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 887
--------------------------------------------------------------
Epoch:  887        1 Batch loss: 0.156890 Batch F1: 0.7317073170731707
Epoch:  887        2 Batch loss: 0.167872 Batch F1: 0.7111111111111111
Epoch:  887        3 Batch loss: 0.167744 Batch F1: 0.761904761904762
Epoch:  887        4 Batch loss: 0.158367 Batch F1: 0.761904761904762
Epoch:  887        5 Batch loss: 0.170926 Batch F1: 0.7450980392156864
Epoch:  887        6 Batch loss: 0.161848 Batch F1: 0.8214285714285715
Epoch:  887        7 Batch loss: 0.174795 Batch F1: 0.7450980392156864
Epoch:  887        8 Batch loss: 0.194581 Batch F1: 0.7037037037037038
Epoch:  887        9 Batch loss: 0.167021 Batch F1: 0.782608695652174
Epoch:  887       10 Batch loss: 0.173802 Batch F1: 0.6
Epoch:  887       11 Batch loss: 0.168490 Batch F1: 0.6486486486486486
Epoch:  887       12 Batch loss: 0.145292 Batch F1: 0.6923076923076924
Train Avg Loss  887: 0.167302

Train Avg F1  887: 0.725460111847164

Val Avg Loss  887: 0.189681

Val Avg F1  887:  0.6692656792892643

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 888
--------------------------------------------------------------
Epoch:  888        1 Batch loss: 0.170945 Batch F1: 0.7391304347826088
Epoch:  888        2 Batch loss: 0.177530 Batch F1: 0.7500000000000001
Epoch:  888        3 Batch loss: 0.142640 Batch F1: 0.7894736842105263
Epoch:  888        4 Batch loss: 0.191523 Batch F1: 0.6521739130434783
Epoch:  888        5 Batch loss: 0.170875 Batch F1: 0.6829268292682926
Epoch:  888        6 Batch loss: 0.190713 Batch F1: 0.6
Epoch:  888        7 Batch loss: 0.145273 Batch F1: 0.744186046511628
Epoch:  888        8 Batch loss: 0.177274 Batch F1: 0.7307692307692306
Epoch:  888        9 Batch loss: 0.159712 Batch F1: 0.7391304347826088
Epoch:  888       10 Batch loss: 0.164545 Batch F1: 0.75
Epoch:  888       11 Batch loss: 0.147416 Batch F1: 0.7368421052631577
Epoch:  888       12 Batch loss: 0.180755 Batch F1: 0.6842105263157895
Train Avg Loss  888: 0.168267

Train Avg F1  888: 0.7165702670789433

Val Avg Loss  888: 0.179128

Val Avg F1  888:  0.7011239278320024

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 889
--------------------------------------------------------------
Epoch:  889        1 Batch loss: 0.168833 Batch F1: 0.8076923076923077
Epoch:  889        2 Batch loss: 0.173362 Batch F1: 0.5454545454545455
Epoch:  889        3 Batch loss: 0.160347 Batch F1: 0.7755102040816326
Epoch:  889        4 Batch loss: 0.149914 Batch F1: 0.8
Epoch:  889        5 Batch loss: 0.202283 Batch F1: 0.5957446808510638
Epoch:  889        6 Batch loss: 0.145893 Batch F1: 0.75
Epoch:  889        7 Batch loss: 0.176880 Batch F1: 0.6666666666666666
Epoch:  889        8 Batch loss: 0.160498 Batch F1: 0.7368421052631579
Epoch:  889        9 Batch loss: 0.147283 Batch F1: 0.823529411764706
Epoch:  889       10 Batch loss: 0.170744 Batch F1: 0.7199999999999999
Epoch:  889       11 Batch loss: 0.155457 Batch F1: 0.6842105263157896
Epoch:  889       12 Batch loss: 0.176459 Batch F1: 0.65
Train Avg Loss  889: 0.165663

Train Avg F1  889: 0.7129708706741558

Val Avg Loss  889: 0.180427

Val Avg F1  889:  0.6886497868459016

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 890
--------------------------------------------------------------
Epoch:  890        1 Batch loss: 0.161508 Batch F1: 0.6486486486486486
Epoch:  890        2 Batch loss: 0.146504 Batch F1: 0.8181818181818182
Epoch:  890        3 Batch loss: 0.141471 Batch F1: 0.8333333333333334
Epoch:  890        4 Batch loss: 0.174643 Batch F1: 0.6666666666666666
Epoch:  890        5 Batch loss: 0.176206 Batch F1: 0.65
Epoch:  890        6 Batch loss: 0.149683 Batch F1: 0.7826086956521738
Epoch:  890        7 Batch loss: 0.158303 Batch F1: 0.7916666666666666
Epoch:  890        8 Batch loss: 0.155692 Batch F1: 0.717948717948718
Epoch:  890        9 Batch loss: 0.169825 Batch F1: 0.75
Epoch:  890       10 Batch loss: 0.198130 Batch F1: 0.6538461538461539
Epoch:  890       11 Batch loss: 0.176999 Batch F1: 0.7368421052631577
Epoch:  890       12 Batch loss: 0.174092 Batch F1: 0.5384615384615384
Train Avg Loss  890: 0.165255

Train Avg F1  890: 0.715683695389073

Val Avg Loss  890: 0.179685

Val Avg F1  890:  0.6867269635126778

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 891
--------------------------------------------------------------
Epoch:  891        1 Batch loss: 0.172588 Batch F1: 0.711111111111111
Epoch:  891        2 Batch loss: 0.141744 Batch F1: 0.7647058823529411
Epoch:  891        3 Batch loss: 0.165878 Batch F1: 0.5945945945945946
Epoch:  891        4 Batch loss: 0.166309 Batch F1: 0.7692307692307692
Epoch:  891        5 Batch loss: 0.190655 Batch F1: 0.6666666666666666
Epoch:  891        6 Batch loss: 0.171155 Batch F1: 0.6938775510204083
Epoch:  891        7 Batch loss: 0.159153 Batch F1: 0.6500000000000001
Epoch:  891        8 Batch loss: 0.180593 Batch F1: 0.7777777777777778
Epoch:  891        9 Batch loss: 0.152486 Batch F1: 0.8163265306122449
Epoch:  891       10 Batch loss: 0.174000 Batch F1: 0.6666666666666666
Epoch:  891       11 Batch loss: 0.150561 Batch F1: 0.7027027027027027
Epoch:  891       12 Batch loss: 0.155729 Batch F1: 0.7272727272727272
Train Avg Loss  891: 0.165071

Train Avg F1  891: 0.7117444150007176

Val Avg Loss  891: 0.178707

Val Avg F1  891:  0.680659645232816

Optimal Val loss (Epoch 828): 0.17843478173017502

Epoch 892
--------------------------------------------------------------
Epoch:  892        1 Batch loss: 0.143045 Batch F1: 0.75
Epoch:  892        2 Batch loss: 0.141906 Batch F1: 0.6470588235294117
Epoch:  892        3 Batch loss: 0.215575 Batch F1: 0.6
Epoch:  892        4 Batch loss: 0.169381 Batch F1: 0.631578947368421
Epoch:  892        5 Batch loss: 0.162024 Batch F1: 0.6818181818181818
Epoch:  892        6 Batch loss: 0.156905 Batch F1: 0.7391304347826088
Epoch:  892        7 Batch loss: 0.182865 Batch F1: 0.7346938775510204
Epoch:  892        8 Batch loss: 0.190053 Batch F1: 0.7169811320754716
Epoch:  892        9 Batch loss: 0.148933 Batch F1: 0.7727272727272727
Epoch:  892       10 Batch loss: 0.155183 Batch F1: 0.7755102040816326
Epoch:  892       11 Batch loss: 0.159335 Batch F1: 0.7755102040816326
Epoch:  892       12 Batch loss: 0.150531 Batch F1: 0.7894736842105262
Train Avg Loss  892: 0.164645

Train Avg F1  892: 0.7178735635188481

Val Avg Loss  892: 0.178044

Val Avg F1  892:  0.6936988693813769

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 893
--------------------------------------------------------------
Epoch:  893        1 Batch loss: 0.146012 Batch F1: 0.7999999999999999
Epoch:  893        2 Batch loss: 0.148500 Batch F1: 0.717948717948718
Epoch:  893        3 Batch loss: 0.212897 Batch F1: 0.6250000000000001
Epoch:  893        4 Batch loss: 0.155639 Batch F1: 0.7346938775510203
Epoch:  893        5 Batch loss: 0.182632 Batch F1: 0.6521739130434783
Epoch:  893        6 Batch loss: 0.166292 Batch F1: 0.7555555555555555
Epoch:  893        7 Batch loss: 0.203888 Batch F1: 0.5957446808510638
Epoch:  893        8 Batch loss: 0.154838 Batch F1: 0.7222222222222222
Epoch:  893        9 Batch loss: 0.160465 Batch F1: 0.6842105263157895
Epoch:  893       10 Batch loss: 0.213723 Batch F1: 0.6521739130434783
Epoch:  893       11 Batch loss: 0.133985 Batch F1: 0.888888888888889
Epoch:  893       12 Batch loss: 0.115664 Batch F1: 0.9444444444444444
Train Avg Loss  893: 0.166211

Train Avg F1  893: 0.7310880616553882

Val Avg Loss  893: 0.179664

Val Avg F1  893:  0.716138633403071

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 894
--------------------------------------------------------------
Epoch:  894        1 Batch loss: 0.194275 Batch F1: 0.6341463414634146
Epoch:  894        2 Batch loss: 0.147124 Batch F1: 0.8095238095238095
Epoch:  894        3 Batch loss: 0.164238 Batch F1: 0.7719298245614035
Epoch:  894        4 Batch loss: 0.157743 Batch F1: 0.7111111111111111
Epoch:  894        5 Batch loss: 0.136670 Batch F1: 0.8679245283018868
Epoch:  894        6 Batch loss: 0.194574 Batch F1: 0.7586206896551724
Epoch:  894        7 Batch loss: 0.189311 Batch F1: 0.5945945945945946
Epoch:  894        8 Batch loss: 0.159614 Batch F1: 0.7692307692307692
Epoch:  894        9 Batch loss: 0.171600 Batch F1: 0.6842105263157896
Epoch:  894       10 Batch loss: 0.171181 Batch F1: 0.6829268292682926
Epoch:  894       11 Batch loss: 0.160567 Batch F1: 0.7317073170731707
Epoch:  894       12 Batch loss: 0.185882 Batch F1: 0.5384615384615384
Train Avg Loss  894: 0.169398

Train Avg F1  894: 0.7128656566300795

Val Avg Loss  894: 0.197029

Val Avg F1  894:  0.5956718416938735

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 895
--------------------------------------------------------------
Epoch:  895        1 Batch loss: 0.175510 Batch F1: 0.6285714285714287
Epoch:  895        2 Batch loss: 0.158745 Batch F1: 0.8148148148148148
Epoch:  895        3 Batch loss: 0.169977 Batch F1: 0.5625
Epoch:  895        4 Batch loss: 0.180535 Batch F1: 0.6111111111111112
Epoch:  895        5 Batch loss: 0.156265 Batch F1: 0.8076923076923077
Epoch:  895        6 Batch loss: 0.176281 Batch F1: 0.6521739130434783
Epoch:  895        7 Batch loss: 0.178274 Batch F1: 0.7636363636363636
Epoch:  895        8 Batch loss: 0.182656 Batch F1: 0.6976744186046512
Epoch:  895        9 Batch loss: 0.141973 Batch F1: 0.8444444444444444
Epoch:  895       10 Batch loss: 0.165457 Batch F1: 0.6829268292682926
Epoch:  895       11 Batch loss: 0.194256 Batch F1: 0.7272727272727272
Epoch:  895       12 Batch loss: 0.168287 Batch F1: 0.7058823529411765
Train Avg Loss  895: 0.170685

Train Avg F1  895: 0.7082250592833996

Val Avg Loss  895: 0.182193

Val Avg F1  895:  0.6785527385399708

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 896
--------------------------------------------------------------
Epoch:  896        1 Batch loss: 0.155401 Batch F1: 0.7999999999999999
Epoch:  896        2 Batch loss: 0.139194 Batch F1: 0.8108108108108109
Epoch:  896        3 Batch loss: 0.207832 Batch F1: 0.6222222222222223
Epoch:  896        4 Batch loss: 0.161610 Batch F1: 0.7346938775510204
Epoch:  896        5 Batch loss: 0.188011 Batch F1: 0.6363636363636365
Epoch:  896        6 Batch loss: 0.169103 Batch F1: 0.5333333333333333
Epoch:  896        7 Batch loss: 0.164354 Batch F1: 0.6341463414634148
Epoch:  896        8 Batch loss: 0.170814 Batch F1: 0.7450980392156863
Epoch:  896        9 Batch loss: 0.148675 Batch F1: 0.7368421052631579
Epoch:  896       10 Batch loss: 0.182713 Batch F1: 0.6792452830188679
Epoch:  896       11 Batch loss: 0.153634 Batch F1: 0.816326530612245
Epoch:  896       12 Batch loss: 0.152708 Batch F1: 0.7777777777777778
Train Avg Loss  896: 0.166171

Train Avg F1  896: 0.7105716631360144

Val Avg Loss  896: 0.179327

Val Avg F1  896:  0.6855715259076604

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 897
--------------------------------------------------------------
Epoch:  897        1 Batch loss: 0.164897 Batch F1: 0.6956521739130435
Epoch:  897        2 Batch loss: 0.169240 Batch F1: 0.631578947368421
Epoch:  897        3 Batch loss: 0.142959 Batch F1: 0.8461538461538461
Epoch:  897        4 Batch loss: 0.153337 Batch F1: 0.7368421052631579
Epoch:  897        5 Batch loss: 0.166311 Batch F1: 0.6829268292682926
Epoch:  897        6 Batch loss: 0.186671 Batch F1: 0.6956521739130435
Epoch:  897        7 Batch loss: 0.161019 Batch F1: 0.7619047619047619
Epoch:  897        8 Batch loss: 0.189368 Batch F1: 0.6666666666666666
Epoch:  897        9 Batch loss: 0.154652 Batch F1: 0.7916666666666666
Epoch:  897       10 Batch loss: 0.184117 Batch F1: 0.6511627906976744
Epoch:  897       11 Batch loss: 0.134392 Batch F1: 0.8399999999999999
Epoch:  897       12 Batch loss: 0.169541 Batch F1: 0.6666666666666667
Train Avg Loss  897: 0.164708

Train Avg F1  897: 0.7222394690401868

Val Avg Loss  897: 0.178437

Val Avg F1  897:  0.6932942286191246

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 898
--------------------------------------------------------------
Epoch:  898        1 Batch loss: 0.189392 Batch F1: 0.6
Epoch:  898        2 Batch loss: 0.172894 Batch F1: 0.7407407407407408
Epoch:  898        3 Batch loss: 0.139142 Batch F1: 0.7096774193548386
Epoch:  898        4 Batch loss: 0.198242 Batch F1: 0.6538461538461539
Epoch:  898        5 Batch loss: 0.157479 Batch F1: 0.717948717948718
Epoch:  898        6 Batch loss: 0.167148 Batch F1: 0.6818181818181818
Epoch:  898        7 Batch loss: 0.152022 Batch F1: 0.7272727272727272
Epoch:  898        8 Batch loss: 0.153763 Batch F1: 0.761904761904762
Epoch:  898        9 Batch loss: 0.175020 Batch F1: 0.6956521739130435
Epoch:  898       10 Batch loss: 0.152517 Batch F1: 0.8163265306122449
Epoch:  898       11 Batch loss: 0.155096 Batch F1: 0.7843137254901961
Epoch:  898       12 Batch loss: 0.165445 Batch F1: 0.7647058823529413
Train Avg Loss  898: 0.164847

Train Avg F1  898: 0.7211839179378791

Val Avg Loss  898: 0.180046

Val Avg F1  898:  0.711602870813397

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 899
--------------------------------------------------------------
Epoch:  899        1 Batch loss: 0.169932 Batch F1: 0.5454545454545454
Epoch:  899        2 Batch loss: 0.181816 Batch F1: 0.6976744186046512
Epoch:  899        3 Batch loss: 0.160105 Batch F1: 0.7234042553191491
Epoch:  899        4 Batch loss: 0.165903 Batch F1: 0.76
Epoch:  899        5 Batch loss: 0.163353 Batch F1: 0.8085106382978723
Epoch:  899        6 Batch loss: 0.177675 Batch F1: 0.6341463414634146
Epoch:  899        7 Batch loss: 0.171123 Batch F1: 0.7391304347826088
Epoch:  899        8 Batch loss: 0.181847 Batch F1: 0.7692307692307692
Epoch:  899        9 Batch loss: 0.157108 Batch F1: 0.7391304347826089
Epoch:  899       10 Batch loss: 0.175103 Batch F1: 0.7727272727272727
Epoch:  899       11 Batch loss: 0.195942 Batch F1: 0.8
Epoch:  899       12 Batch loss: 0.171597 Batch F1: 0.6666666666666666
Train Avg Loss  899: 0.172625

Train Avg F1  899: 0.7213396481107964

Val Avg Loss  899: 0.184466

Val Avg F1  899:  0.7109778754239902

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 900
--------------------------------------------------------------
Epoch:  900        1 Batch loss: 0.172729 Batch F1: 0.75
Epoch:  900        2 Batch loss: 0.163702 Batch F1: 0.7500000000000001
Epoch:  900        3 Batch loss: 0.158642 Batch F1: 0.8085106382978724
Epoch:  900        4 Batch loss: 0.191727 Batch F1: 0.6382978723404256
Epoch:  900        5 Batch loss: 0.170467 Batch F1: 0.6666666666666666
Epoch:  900        6 Batch loss: 0.173886 Batch F1: 0.7000000000000001
Epoch:  900        7 Batch loss: 0.170335 Batch F1: 0.6500000000000001
Epoch:  900        8 Batch loss: 0.173780 Batch F1: 0.7916666666666667
Epoch:  900        9 Batch loss: 0.203091 Batch F1: 0.6666666666666666
Epoch:  900       10 Batch loss: 0.168903 Batch F1: 0.8163265306122449
Epoch:  900       11 Batch loss: 0.218037 Batch F1: 0.6956521739130435
Epoch:  900       12 Batch loss: 0.144337 Batch F1: 0.9047619047619047
Train Avg Loss  900: 0.175803

Train Avg F1  900: 0.736545759993791

Val Avg Loss  900: 0.189991

Val Avg F1  900:  0.6479954178603653

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 901
--------------------------------------------------------------
Epoch:  901        1 Batch loss: 0.191559 Batch F1: 0.7457627118644067
Epoch:  901        2 Batch loss: 0.169579 Batch F1: 0.6956521739130435
Epoch:  901        3 Batch loss: 0.144291 Batch F1: 0.782608695652174
Epoch:  901        4 Batch loss: 0.143779 Batch F1: 0.7500000000000001
Epoch:  901        5 Batch loss: 0.203848 Batch F1: 0.6153846153846154
Epoch:  901        6 Batch loss: 0.187412 Batch F1: 0.6666666666666667
Epoch:  901        7 Batch loss: 0.199189 Batch F1: 0.6666666666666665
Epoch:  901        8 Batch loss: 0.196714 Batch F1: 0.6666666666666666
Epoch:  901        9 Batch loss: 0.180230 Batch F1: 0.7692307692307692
Epoch:  901       10 Batch loss: 0.183624 Batch F1: 0.6363636363636364
Epoch:  901       11 Batch loss: 0.152787 Batch F1: 0.6875000000000001
Epoch:  901       12 Batch loss: 0.152995 Batch F1: 0.7272727272727273
Train Avg Loss  901: 0.175501

Train Avg F1  901: 0.700814610806781

Val Avg Loss  901: 0.186828

Val Avg F1  901:  0.6975709475709476

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 902
--------------------------------------------------------------
Epoch:  902        1 Batch loss: 0.191535 Batch F1: 0.6666666666666666
Epoch:  902        2 Batch loss: 0.209806 Batch F1: 0.6
Epoch:  902        3 Batch loss: 0.154895 Batch F1: 0.7500000000000001
Epoch:  902        4 Batch loss: 0.153503 Batch F1: 0.7906976744186046
Epoch:  902        5 Batch loss: 0.155154 Batch F1: 0.7555555555555555
Epoch:  902        6 Batch loss: 0.147849 Batch F1: 0.7906976744186046
Epoch:  902        7 Batch loss: 0.162616 Batch F1: 0.7142857142857143
Epoch:  902        8 Batch loss: 0.159163 Batch F1: 0.7142857142857143
Epoch:  902        9 Batch loss: 0.174220 Batch F1: 0.6666666666666665
Epoch:  902       10 Batch loss: 0.169930 Batch F1: 0.6976744186046512
Epoch:  902       11 Batch loss: 0.150055 Batch F1: 0.7368421052631577
Epoch:  902       12 Batch loss: 0.173435 Batch F1: 0.7391304347826088
Train Avg Loss  902: 0.166847

Train Avg F1  902: 0.7185418854123288

Val Avg Loss  902: 0.178942

Val Avg F1  902:  0.6795363063924756

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 903
--------------------------------------------------------------
Epoch:  903        1 Batch loss: 0.170318 Batch F1: 0.76
Epoch:  903        2 Batch loss: 0.179172 Batch F1: 0.6808510638297872
Epoch:  903        3 Batch loss: 0.165321 Batch F1: 0.7307692307692306
Epoch:  903        4 Batch loss: 0.172661 Batch F1: 0.6153846153846153
Epoch:  903        5 Batch loss: 0.155838 Batch F1: 0.76
Epoch:  903        6 Batch loss: 0.158233 Batch F1: 0.8
Epoch:  903        7 Batch loss: 0.152645 Batch F1: 0.7368421052631579
Epoch:  903        8 Batch loss: 0.157430 Batch F1: 0.7027027027027027
Epoch:  903        9 Batch loss: 0.212542 Batch F1: 0.6122448979591836
Epoch:  903       10 Batch loss: 0.155897 Batch F1: 0.7441860465116279
Epoch:  903       11 Batch loss: 0.155722 Batch F1: 0.7222222222222223
Epoch:  903       12 Batch loss: 0.144705 Batch F1: 0.7586206896551724
Train Avg Loss  903: 0.165040

Train Avg F1  903: 0.7186519645248083

Val Avg Loss  903: 0.181402

Val Avg F1  903:  0.6735223860223861

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 904
--------------------------------------------------------------
Epoch:  904        1 Batch loss: 0.143780 Batch F1: 0.7499999999999999
Epoch:  904        2 Batch loss: 0.186615 Batch F1: 0.6511627906976744
Epoch:  904        3 Batch loss: 0.152333 Batch F1: 0.7555555555555555
Epoch:  904        4 Batch loss: 0.157159 Batch F1: 0.7441860465116279
Epoch:  904        5 Batch loss: 0.156642 Batch F1: 0.7368421052631577
Epoch:  904        6 Batch loss: 0.200330 Batch F1: 0.721311475409836
Epoch:  904        7 Batch loss: 0.195315 Batch F1: 0.6382978723404256
Epoch:  904        8 Batch loss: 0.123218 Batch F1: 0.7999999999999999
Epoch:  904        9 Batch loss: 0.189581 Batch F1: 0.6
Epoch:  904       10 Batch loss: 0.141607 Batch F1: 0.8181818181818182
Epoch:  904       11 Batch loss: 0.191877 Batch F1: 0.5777777777777778
Epoch:  904       12 Batch loss: 0.159942 Batch F1: 0.742857142857143
Train Avg Loss  904: 0.166533

Train Avg F1  904: 0.7113477153829179

Val Avg Loss  904: 0.180940

Val Avg F1  904:  0.6844898470206882

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 905
--------------------------------------------------------------
Epoch:  905        1 Batch loss: 0.173297 Batch F1: 0.5333333333333333
Epoch:  905        2 Batch loss: 0.157336 Batch F1: 0.7916666666666666
Epoch:  905        3 Batch loss: 0.195305 Batch F1: 0.6250000000000001
Epoch:  905        4 Batch loss: 0.206352 Batch F1: 0.47368421052631576
Epoch:  905        5 Batch loss: 0.155446 Batch F1: 0.7555555555555556
Epoch:  905        6 Batch loss: 0.164984 Batch F1: 0.7272727272727272
Epoch:  905        7 Batch loss: 0.164278 Batch F1: 0.8
Epoch:  905        8 Batch loss: 0.172972 Batch F1: 0.6666666666666666
Epoch:  905        9 Batch loss: 0.152997 Batch F1: 0.8085106382978723
Epoch:  905       10 Batch loss: 0.129743 Batch F1: 0.8205128205128205
Epoch:  905       11 Batch loss: 0.150857 Batch F1: 0.6842105263157896
Epoch:  905       12 Batch loss: 0.159099 Batch F1: 0.7659574468085107
Train Avg Loss  905: 0.165222

Train Avg F1  905: 0.7043642159963549

Val Avg Loss  905: 0.180010

Val Avg F1  905:  0.688081484949699

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 906
--------------------------------------------------------------
Epoch:  906        1 Batch loss: 0.193027 Batch F1: 0.6341463414634146
Epoch:  906        2 Batch loss: 0.150270 Batch F1: 0.7142857142857143
Epoch:  906        3 Batch loss: 0.148725 Batch F1: 0.7755102040816326
Epoch:  906        4 Batch loss: 0.192106 Batch F1: 0.6341463414634146
Epoch:  906        5 Batch loss: 0.169165 Batch F1: 0.7272727272727273
Epoch:  906        6 Batch loss: 0.154797 Batch F1: 0.7826086956521738
Epoch:  906        7 Batch loss: 0.203103 Batch F1: 0.6792452830188679
Epoch:  906        8 Batch loss: 0.151118 Batch F1: 0.7027027027027027
Epoch:  906        9 Batch loss: 0.152626 Batch F1: 0.8163265306122449
Epoch:  906       10 Batch loss: 0.208703 Batch F1: 0.5777777777777778
Epoch:  906       11 Batch loss: 0.149041 Batch F1: 0.7826086956521738
Epoch:  906       12 Batch loss: 0.131922 Batch F1: 0.8235294117647058
Train Avg Loss  906: 0.167050

Train Avg F1  906: 0.7208467021456292

Val Avg Loss  906: 0.180046

Val Avg F1  906:  0.6870622439540109

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 907
--------------------------------------------------------------
Epoch:  907        1 Batch loss: 0.180034 Batch F1: 0.6363636363636365
Epoch:  907        2 Batch loss: 0.164773 Batch F1: 0.6976744186046512
Epoch:  907        3 Batch loss: 0.153907 Batch F1: 0.7659574468085107
Epoch:  907        4 Batch loss: 0.162845 Batch F1: 0.7555555555555556
Epoch:  907        5 Batch loss: 0.136482 Batch F1: 0.851063829787234
Epoch:  907        6 Batch loss: 0.142825 Batch F1: 0.7567567567567567
Epoch:  907        7 Batch loss: 0.163915 Batch F1: 0.7692307692307692
Epoch:  907        8 Batch loss: 0.206306 Batch F1: 0.6122448979591837
Epoch:  907        9 Batch loss: 0.147567 Batch F1: 0.7906976744186046
Epoch:  907       10 Batch loss: 0.164119 Batch F1: 0.6829268292682926
Epoch:  907       11 Batch loss: 0.196835 Batch F1: 0.5777777777777778
Epoch:  907       12 Batch loss: 0.147279 Batch F1: 0.7333333333333334
Train Avg Loss  907: 0.163907

Train Avg F1  907: 0.7191319104886921

Val Avg Loss  907: 0.181620

Val Avg F1  907:  0.6824127311743411

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 908
--------------------------------------------------------------
Epoch:  908        1 Batch loss: 0.185207 Batch F1: 0.6666666666666666
Epoch:  908        2 Batch loss: 0.189700 Batch F1: 0.6666666666666666
Epoch:  908        3 Batch loss: 0.154301 Batch F1: 0.6842105263157895
Epoch:  908        4 Batch loss: 0.158773 Batch F1: 0.7
Epoch:  908        5 Batch loss: 0.159328 Batch F1: 0.7317073170731706
Epoch:  908        6 Batch loss: 0.158990 Batch F1: 0.7555555555555556
Epoch:  908        7 Batch loss: 0.167177 Batch F1: 0.6486486486486486
Epoch:  908        8 Batch loss: 0.142998 Batch F1: 0.7567567567567567
Epoch:  908        9 Batch loss: 0.157519 Batch F1: 0.6976744186046512
Epoch:  908       10 Batch loss: 0.165335 Batch F1: 0.7555555555555556
Epoch:  908       11 Batch loss: 0.165018 Batch F1: 0.7234042553191491
Epoch:  908       12 Batch loss: 0.168009 Batch F1: 0.7916666666666667
Train Avg Loss  908: 0.164363

Train Avg F1  908: 0.7148760861524397

Val Avg Loss  908: 0.178629

Val Avg F1  908:  0.687293099057805

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 909
--------------------------------------------------------------
Epoch:  909        1 Batch loss: 0.151344 Batch F1: 0.7727272727272727
Epoch:  909        2 Batch loss: 0.142572 Batch F1: 0.8571428571428572
Epoch:  909        3 Batch loss: 0.159831 Batch F1: 0.6153846153846153
Epoch:  909        4 Batch loss: 0.158980 Batch F1: 0.7346938775510204
Epoch:  909        5 Batch loss: 0.150472 Batch F1: 0.7906976744186046
Epoch:  909        6 Batch loss: 0.173593 Batch F1: 0.7142857142857143
Epoch:  909        7 Batch loss: 0.183466 Batch F1: 0.7169811320754716
Epoch:  909        8 Batch loss: 0.164847 Batch F1: 0.7999999999999999
Epoch:  909        9 Batch loss: 0.185628 Batch F1: 0.6046511627906976
Epoch:  909       10 Batch loss: 0.205086 Batch F1: 0.5777777777777778
Epoch:  909       11 Batch loss: 0.142224 Batch F1: 0.7804878048780488
Epoch:  909       12 Batch loss: 0.161973 Batch F1: 0.5714285714285715
Train Avg Loss  909: 0.165001

Train Avg F1  909: 0.7113548717050543

Val Avg Loss  909: 0.182179

Val Avg F1  909:  0.67459324155194

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 910
--------------------------------------------------------------
Epoch:  910        1 Batch loss: 0.140509 Batch F1: 0.8076923076923077
Epoch:  910        2 Batch loss: 0.166382 Batch F1: 0.6818181818181819
Epoch:  910        3 Batch loss: 0.163857 Batch F1: 0.6486486486486486
Epoch:  910        4 Batch loss: 0.182598 Batch F1: 0.6341463414634146
Epoch:  910        5 Batch loss: 0.167454 Batch F1: 0.7
Epoch:  910        6 Batch loss: 0.183453 Batch F1: 0.6530612244897959
Epoch:  910        7 Batch loss: 0.169693 Batch F1: 0.6956521739130435
Epoch:  910        8 Batch loss: 0.156029 Batch F1: 0.7619047619047619
Epoch:  910        9 Batch loss: 0.175712 Batch F1: 0.76
Epoch:  910       10 Batch loss: 0.168004 Batch F1: 0.693877551020408
Epoch:  910       11 Batch loss: 0.125282 Batch F1: 0.8837209302325582
Epoch:  910       12 Batch loss: 0.168500 Batch F1: 0.742857142857143
Train Avg Loss  910: 0.163956

Train Avg F1  910: 0.7219482720033552

Val Avg Loss  910: 0.179928

Val Avg F1  910:  0.6799448384554767

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 911
--------------------------------------------------------------
Epoch:  911        1 Batch loss: 0.185447 Batch F1: 0.6530612244897959
Epoch:  911        2 Batch loss: 0.130564 Batch F1: 0.9310344827586207
Epoch:  911        3 Batch loss: 0.192248 Batch F1: 0.5714285714285713
Epoch:  911        4 Batch loss: 0.136397 Batch F1: 0.8085106382978724
Epoch:  911        5 Batch loss: 0.147501 Batch F1: 0.8461538461538461
Epoch:  911        6 Batch loss: 0.145374 Batch F1: 0.8333333333333333
Epoch:  911        7 Batch loss: 0.145338 Batch F1: 0.8205128205128205
Epoch:  911        8 Batch loss: 0.203471 Batch F1: 0.6341463414634146
Epoch:  911        9 Batch loss: 0.179632 Batch F1: 0.5641025641025642
Epoch:  911       10 Batch loss: 0.172246 Batch F1: 0.7391304347826088
Epoch:  911       11 Batch loss: 0.174305 Batch F1: 0.6341463414634146
Epoch:  911       12 Batch loss: 0.164183 Batch F1: 0.6206896551724138
Train Avg Loss  911: 0.164726

Train Avg F1  911: 0.7213541878299398

Val Avg Loss  911: 0.184736

Val Avg F1  911:  0.6762980413895049

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 912
--------------------------------------------------------------
Epoch:  912        1 Batch loss: 0.161855 Batch F1: 0.744186046511628
Epoch:  912        2 Batch loss: 0.151787 Batch F1: 0.7441860465116279
Epoch:  912        3 Batch loss: 0.185611 Batch F1: 0.5641025641025642
Epoch:  912        4 Batch loss: 0.171405 Batch F1: 0.619047619047619
Epoch:  912        5 Batch loss: 0.144142 Batch F1: 0.7058823529411765
Epoch:  912        6 Batch loss: 0.158117 Batch F1: 0.631578947368421
Epoch:  912        7 Batch loss: 0.146116 Batch F1: 0.7999999999999999
Epoch:  912        8 Batch loss: 0.147638 Batch F1: 0.8163265306122449
Epoch:  912        9 Batch loss: 0.160564 Batch F1: 0.8
Epoch:  912       10 Batch loss: 0.178065 Batch F1: 0.6666666666666666
Epoch:  912       11 Batch loss: 0.207458 Batch F1: 0.7058823529411764
Epoch:  912       12 Batch loss: 0.165502 Batch F1: 0.7368421052631577
Train Avg Loss  912: 0.164855

Train Avg F1  912: 0.7112251026638569

Val Avg Loss  912: 0.181252

Val Avg F1  912:  0.6845680765117568

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 913
--------------------------------------------------------------
Epoch:  913        1 Batch loss: 0.160021 Batch F1: 0.6666666666666666
Epoch:  913        2 Batch loss: 0.160415 Batch F1: 0.7317073170731708
Epoch:  913        3 Batch loss: 0.162101 Batch F1: 0.7755102040816326
Epoch:  913        4 Batch loss: 0.139063 Batch F1: 0.8372093023255814
Epoch:  913        5 Batch loss: 0.165183 Batch F1: 0.7391304347826088
Epoch:  913        6 Batch loss: 0.163086 Batch F1: 0.8
Epoch:  913        7 Batch loss: 0.185196 Batch F1: 0.6363636363636365
Epoch:  913        8 Batch loss: 0.146791 Batch F1: 0.8085106382978723
Epoch:  913        9 Batch loss: 0.198110 Batch F1: 0.5853658536585366
Epoch:  913       10 Batch loss: 0.170376 Batch F1: 0.6486486486486486
Epoch:  913       11 Batch loss: 0.158993 Batch F1: 0.7441860465116279
Epoch:  913       12 Batch loss: 0.200763 Batch F1: 0.6956521739130435
Train Avg Loss  913: 0.167508

Train Avg F1  913: 0.7224125768602522

Val Avg Loss  913: 0.183056

Val Avg F1  913:  0.6914119158781338

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 914
--------------------------------------------------------------
Epoch:  914        1 Batch loss: 0.198427 Batch F1: 0.6250000000000001
Epoch:  914        2 Batch loss: 0.160237 Batch F1: 0.75
Epoch:  914        3 Batch loss: 0.142543 Batch F1: 0.8095238095238095
Epoch:  914        4 Batch loss: 0.171938 Batch F1: 0.6666666666666666
Epoch:  914        5 Batch loss: 0.191929 Batch F1: 0.6
Epoch:  914        6 Batch loss: 0.184881 Batch F1: 0.6923076923076923
Epoch:  914        7 Batch loss: 0.130169 Batch F1: 0.8695652173913043
Epoch:  914        8 Batch loss: 0.157999 Batch F1: 0.7142857142857143
Epoch:  914        9 Batch loss: 0.172731 Batch F1: 0.7727272727272727
Epoch:  914       10 Batch loss: 0.171060 Batch F1: 0.6500000000000001
Epoch:  914       11 Batch loss: 0.163675 Batch F1: 0.7234042553191491
Epoch:  914       12 Batch loss: 0.184662 Batch F1: 0.6666666666666667
Train Avg Loss  914: 0.169187

Train Avg F1  914: 0.7116789412406898

Val Avg Loss  914: 0.183117

Val Avg F1  914:  0.6678520683635774

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 915
--------------------------------------------------------------
Epoch:  915        1 Batch loss: 0.142046 Batch F1: 0.8181818181818182
Epoch:  915        2 Batch loss: 0.146792 Batch F1: 0.7826086956521738
Epoch:  915        3 Batch loss: 0.181201 Batch F1: 0.5853658536585366
Epoch:  915        4 Batch loss: 0.181952 Batch F1: 0.6222222222222223
Epoch:  915        5 Batch loss: 0.154599 Batch F1: 0.8400000000000001
Epoch:  915        6 Batch loss: 0.163176 Batch F1: 0.75
Epoch:  915        7 Batch loss: 0.173664 Batch F1: 0.6808510638297872
Epoch:  915        8 Batch loss: 0.185463 Batch F1: 0.68
Epoch:  915        9 Batch loss: 0.171093 Batch F1: 0.7142857142857143
Epoch:  915       10 Batch loss: 0.166647 Batch F1: 0.7142857142857143
Epoch:  915       11 Batch loss: 0.135933 Batch F1: 0.823529411764706
Epoch:  915       12 Batch loss: 0.185475 Batch F1: 0.5714285714285714
Train Avg Loss  915: 0.165670

Train Avg F1  915: 0.7152299221091036

Val Avg Loss  915: 0.180742

Val Avg F1  915:  0.6818796992481203

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 916
--------------------------------------------------------------
Epoch:  916        1 Batch loss: 0.173209 Batch F1: 0.6938775510204083
Epoch:  916        2 Batch loss: 0.161421 Batch F1: 0.7727272727272727
Epoch:  916        3 Batch loss: 0.156177 Batch F1: 0.631578947368421
Epoch:  916        4 Batch loss: 0.187575 Batch F1: 0.6923076923076923
Epoch:  916        5 Batch loss: 0.167850 Batch F1: 0.7450980392156864
Epoch:  916        6 Batch loss: 0.156688 Batch F1: 0.7142857142857143
Epoch:  916        7 Batch loss: 0.158410 Batch F1: 0.8085106382978723
Epoch:  916        8 Batch loss: 0.157159 Batch F1: 0.782608695652174
Epoch:  916        9 Batch loss: 0.153663 Batch F1: 0.6842105263157895
Epoch:  916       10 Batch loss: 0.162419 Batch F1: 0.7317073170731706
Epoch:  916       11 Batch loss: 0.154572 Batch F1: 0.6666666666666667
Epoch:  916       12 Batch loss: 0.174429 Batch F1: 0.717948717948718
Train Avg Loss  916: 0.163631

Train Avg F1  916: 0.7201273149066322

Val Avg Loss  916: 0.181428

Val Avg F1  916:  0.6825004123371268

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 917
--------------------------------------------------------------
Epoch:  917        1 Batch loss: 0.147159 Batch F1: 0.7555555555555555
Epoch:  917        2 Batch loss: 0.168309 Batch F1: 0.7
Epoch:  917        3 Batch loss: 0.205579 Batch F1: 0.4878048780487805
Epoch:  917        4 Batch loss: 0.132236 Batch F1: 0.7058823529411765
Epoch:  917        5 Batch loss: 0.164914 Batch F1: 0.8
Epoch:  917        6 Batch loss: 0.153497 Batch F1: 0.6666666666666665
Epoch:  917        7 Batch loss: 0.171307 Batch F1: 0.5625000000000001
Epoch:  917        8 Batch loss: 0.169197 Batch F1: 0.7407407407407408
Epoch:  917        9 Batch loss: 0.179208 Batch F1: 0.7083333333333334
Epoch:  917       10 Batch loss: 0.169354 Batch F1: 0.723404255319149
Epoch:  917       11 Batch loss: 0.152295 Batch F1: 0.8363636363636364
Epoch:  917       12 Batch loss: 0.145092 Batch F1: 0.7999999999999999
Train Avg Loss  917: 0.163179

Train Avg F1  917: 0.7072709515807533

Val Avg Loss  917: 0.179066

Val Avg F1  917:  0.7022727272727272

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 918
--------------------------------------------------------------
Epoch:  918        1 Batch loss: 0.174004 Batch F1: 0.6153846153846153
Epoch:  918        2 Batch loss: 0.149962 Batch F1: 0.717948717948718
Epoch:  918        3 Batch loss: 0.197940 Batch F1: 0.5714285714285715
Epoch:  918        4 Batch loss: 0.146264 Batch F1: 0.7692307692307693
Epoch:  918        5 Batch loss: 0.147949 Batch F1: 0.8
Epoch:  918        6 Batch loss: 0.168614 Batch F1: 0.711111111111111
Epoch:  918        7 Batch loss: 0.175329 Batch F1: 0.7346938775510204
Epoch:  918        8 Batch loss: 0.167830 Batch F1: 0.7857142857142857
Epoch:  918        9 Batch loss: 0.154917 Batch F1: 0.7894736842105262
Epoch:  918       10 Batch loss: 0.183421 Batch F1: 0.6521739130434783
Epoch:  918       11 Batch loss: 0.168877 Batch F1: 0.72
Epoch:  918       12 Batch loss: 0.146974 Batch F1: 0.7894736842105262
Train Avg Loss  918: 0.165173

Train Avg F1  918: 0.7213861024861351

Val Avg Loss  918: 0.180680

Val Avg F1  918:  0.6792350548929497

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 919
--------------------------------------------------------------
Epoch:  919        1 Batch loss: 0.148781 Batch F1: 0.6875
Epoch:  919        2 Batch loss: 0.151622 Batch F1: 0.8260869565217391
Epoch:  919        3 Batch loss: 0.169068 Batch F1: 0.6818181818181819
Epoch:  919        4 Batch loss: 0.171477 Batch F1: 0.7142857142857143
Epoch:  919        5 Batch loss: 0.151097 Batch F1: 0.7659574468085106
Epoch:  919        6 Batch loss: 0.152200 Batch F1: 0.6666666666666666
Epoch:  919        7 Batch loss: 0.167221 Batch F1: 0.7307692307692308
Epoch:  919        8 Batch loss: 0.165498 Batch F1: 0.7307692307692307
Epoch:  919        9 Batch loss: 0.157889 Batch F1: 0.7916666666666666
Epoch:  919       10 Batch loss: 0.161464 Batch F1: 0.8076923076923077
Epoch:  919       11 Batch loss: 0.184284 Batch F1: 0.5142857142857142
Epoch:  919       12 Batch loss: 0.195571 Batch F1: 0.6
Train Avg Loss  919: 0.164681

Train Avg F1  919: 0.7097915096903303

Val Avg Loss  919: 0.189729

Val Avg F1  919:  0.6742763062671877

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 920
--------------------------------------------------------------
Epoch:  920        1 Batch loss: 0.165560 Batch F1: 0.7567567567567567
Epoch:  920        2 Batch loss: 0.164906 Batch F1: 0.7555555555555556
Epoch:  920        3 Batch loss: 0.171926 Batch F1: 0.6382978723404256
Epoch:  920        4 Batch loss: 0.168438 Batch F1: 0.7555555555555556
Epoch:  920        5 Batch loss: 0.153900 Batch F1: 0.7906976744186046
Epoch:  920        6 Batch loss: 0.156497 Batch F1: 0.7142857142857143
Epoch:  920        7 Batch loss: 0.189233 Batch F1: 0.6956521739130435
Epoch:  920        8 Batch loss: 0.174366 Batch F1: 0.7083333333333334
Epoch:  920        9 Batch loss: 0.146680 Batch F1: 0.7692307692307692
Epoch:  920       10 Batch loss: 0.193139 Batch F1: 0.6666666666666666
Epoch:  920       11 Batch loss: 0.167562 Batch F1: 0.7346938775510204
Epoch:  920       12 Batch loss: 0.169480 Batch F1: 0.6666666666666667
Train Avg Loss  920: 0.168474

Train Avg F1  920: 0.7210327180228426

Val Avg Loss  920: 0.182185

Val Avg F1  920:  0.6747798742138365

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 921
--------------------------------------------------------------
Epoch:  921        1 Batch loss: 0.169180 Batch F1: 0.7692307692307692
Epoch:  921        2 Batch loss: 0.163814 Batch F1: 0.7142857142857143
Epoch:  921        3 Batch loss: 0.158460 Batch F1: 0.7
Epoch:  921        4 Batch loss: 0.145100 Batch F1: 0.8148148148148148
Epoch:  921        5 Batch loss: 0.163027 Batch F1: 0.7317073170731707
Epoch:  921        6 Batch loss: 0.163510 Batch F1: 0.75
Epoch:  921        7 Batch loss: 0.151275 Batch F1: 0.8
Epoch:  921        8 Batch loss: 0.176535 Batch F1: 0.6666666666666666
Epoch:  921        9 Batch loss: 0.137974 Batch F1: 0.7058823529411765
Epoch:  921       10 Batch loss: 0.178603 Batch F1: 0.6808510638297872
Epoch:  921       11 Batch loss: 0.186365 Batch F1: 0.6190476190476191
Epoch:  921       12 Batch loss: 0.171730 Batch F1: 0.7027027027027027
Train Avg Loss  921: 0.163798

Train Avg F1  921: 0.7212657517160351

Val Avg Loss  921: 0.182788

Val Avg F1  921:  0.6780859947100356

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 922
--------------------------------------------------------------
Epoch:  922        1 Batch loss: 0.177926 Batch F1: 0.723404255319149
Epoch:  922        2 Batch loss: 0.175865 Batch F1: 0.6315789473684211
Epoch:  922        3 Batch loss: 0.154443 Batch F1: 0.7916666666666666
Epoch:  922        4 Batch loss: 0.165741 Batch F1: 0.7659574468085107
Epoch:  922        5 Batch loss: 0.188128 Batch F1: 0.6511627906976744
Epoch:  922        6 Batch loss: 0.153456 Batch F1: 0.7441860465116279
Epoch:  922        7 Batch loss: 0.169903 Batch F1: 0.7441860465116279
Epoch:  922        8 Batch loss: 0.180192 Batch F1: 0.7083333333333333
Epoch:  922        9 Batch loss: 0.132923 Batch F1: 0.742857142857143
Epoch:  922       10 Batch loss: 0.141570 Batch F1: 0.8399999999999999
Epoch:  922       11 Batch loss: 0.176951 Batch F1: 0.6976744186046512
Epoch:  922       12 Batch loss: 0.165587 Batch F1: 0.6666666666666665
Train Avg Loss  922: 0.165224

Train Avg F1  922: 0.7256394801121225

Val Avg Loss  922: 0.180472

Val Avg F1  922:  0.6886914774320159

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 923
--------------------------------------------------------------
Epoch:  923        1 Batch loss: 0.134687 Batch F1: 0.8695652173913043
Epoch:  923        2 Batch loss: 0.143615 Batch F1: 0.8444444444444444
Epoch:  923        3 Batch loss: 0.166375 Batch F1: 0.5294117647058824
Epoch:  923        4 Batch loss: 0.165413 Batch F1: 0.723404255319149
Epoch:  923        5 Batch loss: 0.170645 Batch F1: 0.6111111111111112
Epoch:  923        6 Batch loss: 0.185622 Batch F1: 0.6923076923076924
Epoch:  923        7 Batch loss: 0.164198 Batch F1: 0.7027027027027027
Epoch:  923        8 Batch loss: 0.177756 Batch F1: 0.6190476190476191
Epoch:  923        9 Batch loss: 0.157785 Batch F1: 0.744186046511628
Epoch:  923       10 Batch loss: 0.190713 Batch F1: 0.7307692307692306
Epoch:  923       11 Batch loss: 0.181153 Batch F1: 0.5853658536585366
Epoch:  923       12 Batch loss: 0.156375 Batch F1: 0.8260869565217391
Train Avg Loss  923: 0.166195

Train Avg F1  923: 0.70653357454092

Val Avg Loss  923: 0.184488

Val Avg F1  923:  0.6820265062546758

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 924
--------------------------------------------------------------
Epoch:  924        1 Batch loss: 0.183998 Batch F1: 0.5
Epoch:  924        2 Batch loss: 0.170921 Batch F1: 0.7234042553191491
Epoch:  924        3 Batch loss: 0.172029 Batch F1: 0.7317073170731707
Epoch:  924        4 Batch loss: 0.155317 Batch F1: 0.7368421052631577
Epoch:  924        5 Batch loss: 0.143629 Batch F1: 0.7999999999999999
Epoch:  924        6 Batch loss: 0.188026 Batch F1: 0.7636363636363638
Epoch:  924        7 Batch loss: 0.152138 Batch F1: 0.7916666666666666
Epoch:  924        8 Batch loss: 0.164929 Batch F1: 0.7272727272727272
Epoch:  924        9 Batch loss: 0.135032 Batch F1: 0.8
Epoch:  924       10 Batch loss: 0.188513 Batch F1: 0.6341463414634146
Epoch:  924       11 Batch loss: 0.173961 Batch F1: 0.75
Epoch:  924       12 Batch loss: 0.179509 Batch F1: 0.717948717948718
Train Avg Loss  924: 0.167334

Train Avg F1  924: 0.7230520412202806

Val Avg Loss  924: 0.180742

Val Avg F1  924:  0.7005095060621785

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 925
--------------------------------------------------------------
Epoch:  925        1 Batch loss: 0.159714 Batch F1: 0.7843137254901961
Epoch:  925        2 Batch loss: 0.162875 Batch F1: 0.6666666666666667
Epoch:  925        3 Batch loss: 0.171327 Batch F1: 0.7272727272727272
Epoch:  925        4 Batch loss: 0.152680 Batch F1: 0.7027027027027027
Epoch:  925        5 Batch loss: 0.144236 Batch F1: 0.7499999999999999
Epoch:  925        6 Batch loss: 0.183546 Batch F1: 0.6190476190476191
Epoch:  925        7 Batch loss: 0.172377 Batch F1: 0.711111111111111
Epoch:  925        8 Batch loss: 0.183222 Batch F1: 0.7777777777777779
Epoch:  925        9 Batch loss: 0.149691 Batch F1: 0.7272727272727272
Epoch:  925       10 Batch loss: 0.159663 Batch F1: 0.76
Epoch:  925       11 Batch loss: 0.184989 Batch F1: 0.7457627118644068
Epoch:  925       12 Batch loss: 0.201451 Batch F1: 0.6470588235294118
Train Avg Loss  925: 0.168814

Train Avg F1  925: 0.7182488827279455

Val Avg Loss  925: 0.185723

Val Avg F1  925:  0.675798319327731

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 926
--------------------------------------------------------------
Epoch:  926        1 Batch loss: 0.186608 Batch F1: 0.7058823529411765
Epoch:  926        2 Batch loss: 0.152011 Batch F1: 0.7368421052631579
Epoch:  926        3 Batch loss: 0.195895 Batch F1: 0.6
Epoch:  926        4 Batch loss: 0.135416 Batch F1: 0.8108108108108109
Epoch:  926        5 Batch loss: 0.160277 Batch F1: 0.7826086956521738
Epoch:  926        6 Batch loss: 0.164451 Batch F1: 0.7906976744186047
Epoch:  926        7 Batch loss: 0.177006 Batch F1: 0.6341463414634146
Epoch:  926        8 Batch loss: 0.158464 Batch F1: 0.7906976744186046
Epoch:  926        9 Batch loss: 0.154187 Batch F1: 0.7555555555555556
Epoch:  926       10 Batch loss: 0.179589 Batch F1: 0.8
Epoch:  926       11 Batch loss: 0.188962 Batch F1: 0.6222222222222223
Epoch:  926       12 Batch loss: 0.193193 Batch F1: 0.6341463414634146
Train Avg Loss  926: 0.170505

Train Avg F1  926: 0.7219674811840946

Val Avg Loss  926: 0.184665

Val Avg F1  926:  0.7021245760098673

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 927
--------------------------------------------------------------
Epoch:  927        1 Batch loss: 0.177733 Batch F1: 0.7142857142857143
Epoch:  927        2 Batch loss: 0.161177 Batch F1: 0.7500000000000001
Epoch:  927        3 Batch loss: 0.170758 Batch F1: 0.7272727272727272
Epoch:  927        4 Batch loss: 0.167870 Batch F1: 0.6976744186046512
Epoch:  927        5 Batch loss: 0.143684 Batch F1: 0.8627450980392156
Epoch:  927        6 Batch loss: 0.185996 Batch F1: 0.6521739130434783
Epoch:  927        7 Batch loss: 0.177127 Batch F1: 0.7368421052631577
Epoch:  927        8 Batch loss: 0.195494 Batch F1: 0.6222222222222222
Epoch:  927        9 Batch loss: 0.177197 Batch F1: 0.68
Epoch:  927       10 Batch loss: 0.152774 Batch F1: 0.7567567567567567
Epoch:  927       11 Batch loss: 0.149156 Batch F1: 0.7894736842105262
Epoch:  927       12 Batch loss: 0.173140 Batch F1: 0.7727272727272727
Train Avg Loss  927: 0.169342

Train Avg F1  927: 0.7301811593688102

Val Avg Loss  927: 0.182963

Val Avg F1  927:  0.6776102699144174

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 928
--------------------------------------------------------------
Epoch:  928        1 Batch loss: 0.151335 Batch F1: 0.7804878048780488
Epoch:  928        2 Batch loss: 0.163986 Batch F1: 0.6829268292682927
Epoch:  928        3 Batch loss: 0.150173 Batch F1: 0.6829268292682927
Epoch:  928        4 Batch loss: 0.160264 Batch F1: 0.8
Epoch:  928        5 Batch loss: 0.146542 Batch F1: 0.7058823529411765
Epoch:  928        6 Batch loss: 0.193274 Batch F1: 0.5853658536585366
Epoch:  928        7 Batch loss: 0.181402 Batch F1: 0.6808510638297872
Epoch:  928        8 Batch loss: 0.177475 Batch F1: 0.711111111111111
Epoch:  928        9 Batch loss: 0.164678 Batch F1: 0.7555555555555555
Epoch:  928       10 Batch loss: 0.151453 Batch F1: 0.8085106382978724
Epoch:  928       11 Batch loss: 0.197374 Batch F1: 0.6296296296296295
Epoch:  928       12 Batch loss: 0.177617 Batch F1: 0.6842105263157895
Train Avg Loss  928: 0.167964

Train Avg F1  928: 0.7089548495628412

Val Avg Loss  928: 0.181830

Val Avg F1  928:  0.6726791726791727

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 929
--------------------------------------------------------------
Epoch:  929        1 Batch loss: 0.165161 Batch F1: 0.6829268292682926
Epoch:  929        2 Batch loss: 0.139786 Batch F1: 0.8095238095238095
Epoch:  929        3 Batch loss: 0.131087 Batch F1: 0.8749999999999999
Epoch:  929        4 Batch loss: 0.190334 Batch F1: 0.5405405405405405
Epoch:  929        5 Batch loss: 0.208497 Batch F1: 0.5294117647058824
Epoch:  929        6 Batch loss: 0.156491 Batch F1: 0.7368421052631577
Epoch:  929        7 Batch loss: 0.168728 Batch F1: 0.7391304347826089
Epoch:  929        8 Batch loss: 0.152349 Batch F1: 0.816326530612245
Epoch:  929        9 Batch loss: 0.168371 Batch F1: 0.7234042553191489
Epoch:  929       10 Batch loss: 0.191121 Batch F1: 0.793103448275862
Epoch:  929       11 Batch loss: 0.173317 Batch F1: 0.7058823529411765
Epoch:  929       12 Batch loss: 0.177400 Batch F1: 0.6285714285714286
Train Avg Loss  929: 0.168554

Train Avg F1  929: 0.715055291650346

Val Avg Loss  929: 0.184147

Val Avg F1  929:  0.6749119097956306

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 930
--------------------------------------------------------------
Epoch:  930        1 Batch loss: 0.138463 Batch F1: 0.8695652173913043
Epoch:  930        2 Batch loss: 0.170451 Batch F1: 0.5882352941176471
Epoch:  930        3 Batch loss: 0.147244 Batch F1: 0.7804878048780488
Epoch:  930        4 Batch loss: 0.197193 Batch F1: 0.5777777777777778
Epoch:  930        5 Batch loss: 0.170252 Batch F1: 0.5294117647058824
Epoch:  930        6 Batch loss: 0.176564 Batch F1: 0.6666666666666666
Epoch:  930        7 Batch loss: 0.172028 Batch F1: 0.7391304347826088
Epoch:  930        8 Batch loss: 0.152758 Batch F1: 0.7567567567567567
Epoch:  930        9 Batch loss: 0.202208 Batch F1: 0.7037037037037037
Epoch:  930       10 Batch loss: 0.163628 Batch F1: 0.8771929824561403
Epoch:  930       11 Batch loss: 0.194865 Batch F1: 0.8
Epoch:  930       12 Batch loss: 0.183589 Batch F1: 0.7000000000000001
Train Avg Loss  930: 0.172437

Train Avg F1  930: 0.7157440336030447

Val Avg Loss  930: 0.184596

Val Avg F1  930:  0.6761727353608125

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 931
--------------------------------------------------------------
Epoch:  931        1 Batch loss: 0.205663 Batch F1: 0.5957446808510638
Epoch:  931        2 Batch loss: 0.166286 Batch F1: 0.6818181818181818
Epoch:  931        3 Batch loss: 0.167171 Batch F1: 0.8064516129032259
Epoch:  931        4 Batch loss: 0.207248 Batch F1: 0.7058823529411764
Epoch:  931        5 Batch loss: 0.143776 Batch F1: 0.7428571428571428
Epoch:  931        6 Batch loss: 0.149471 Batch F1: 0.7096774193548387
Epoch:  931        7 Batch loss: 0.197900 Batch F1: 0.55
Epoch:  931        8 Batch loss: 0.197218 Batch F1: 0.5714285714285714
Epoch:  931        9 Batch loss: 0.200384 Batch F1: 0.5
Epoch:  931       10 Batch loss: 0.183604 Batch F1: 0.711111111111111
Epoch:  931       11 Batch loss: 0.193800 Batch F1: 0.6808510638297872
Epoch:  931       12 Batch loss: 0.161314 Batch F1: 0.75
Train Avg Loss  931: 0.181153

Train Avg F1  931: 0.6671518447579249

Val Avg Loss  931: 0.188317

Val Avg F1  931:  0.6843068335173599

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 932
--------------------------------------------------------------
Epoch:  932        1 Batch loss: 0.188521 Batch F1: 0.6923076923076924
Epoch:  932        2 Batch loss: 0.199332 Batch F1: 0.608695652173913
Epoch:  932        3 Batch loss: 0.152045 Batch F1: 0.7906976744186046
Epoch:  932        4 Batch loss: 0.145768 Batch F1: 0.7906976744186046
Epoch:  932        5 Batch loss: 0.178810 Batch F1: 0.5185185185185185
Epoch:  932        6 Batch loss: 0.177961 Batch F1: 0.7142857142857143
Epoch:  932        7 Batch loss: 0.178711 Batch F1: 0.7272727272727272
Epoch:  932        8 Batch loss: 0.177020 Batch F1: 0.6808510638297872
Epoch:  932        9 Batch loss: 0.161581 Batch F1: 0.7547169811320755
Epoch:  932       10 Batch loss: 0.193694 Batch F1: 0.7636363636363638
Epoch:  932       11 Batch loss: 0.179689 Batch F1: 0.7058823529411765
Epoch:  932       12 Batch loss: 0.173349 Batch F1: 0.7777777777777778
Train Avg Loss  932: 0.175540

Train Avg F1  932: 0.710445016059413

Val Avg Loss  932: 0.180076

Val Avg F1  932:  0.7056623931623931

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 933
--------------------------------------------------------------
Epoch:  933        1 Batch loss: 0.159160 Batch F1: 0.717948717948718
Epoch:  933        2 Batch loss: 0.173902 Batch F1: 0.611111111111111
Epoch:  933        3 Batch loss: 0.159612 Batch F1: 0.7391304347826085
Epoch:  933        4 Batch loss: 0.190291 Batch F1: 0.6222222222222223
Epoch:  933        5 Batch loss: 0.169236 Batch F1: 0.7407407407407408
Epoch:  933        6 Batch loss: 0.158058 Batch F1: 0.717948717948718
Epoch:  933        7 Batch loss: 0.163336 Batch F1: 0.7659574468085107
Epoch:  933        8 Batch loss: 0.213430 Batch F1: 0.625
Epoch:  933        9 Batch loss: 0.148562 Batch F1: 0.6875
Epoch:  933       10 Batch loss: 0.169738 Batch F1: 0.8
Epoch:  933       11 Batch loss: 0.141334 Batch F1: 0.7500000000000001
Epoch:  933       12 Batch loss: 0.187505 Batch F1: 0.6829268292682926
Train Avg Loss  933: 0.169514

Train Avg F1  933: 0.7050405184025768

Val Avg Loss  933: 0.180074

Val Avg F1  933:  0.667498717446588

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 934
--------------------------------------------------------------
Epoch:  934        1 Batch loss: 0.170097 Batch F1: 0.5625000000000001
Epoch:  934        2 Batch loss: 0.134476 Batch F1: 0.8799999999999999
Epoch:  934        3 Batch loss: 0.174387 Batch F1: 0.7200000000000001
Epoch:  934        4 Batch loss: 0.178489 Batch F1: 0.6666666666666666
Epoch:  934        5 Batch loss: 0.176777 Batch F1: 0.65
Epoch:  934        6 Batch loss: 0.168855 Batch F1: 0.711111111111111
Epoch:  934        7 Batch loss: 0.167558 Batch F1: 0.6666666666666667
Epoch:  934        8 Batch loss: 0.165935 Batch F1: 0.7272727272727272
Epoch:  934        9 Batch loss: 0.192944 Batch F1: 0.6382978723404256
Epoch:  934       10 Batch loss: 0.159201 Batch F1: 0.7391304347826089
Epoch:  934       11 Batch loss: 0.166184 Batch F1: 0.7555555555555555
Epoch:  934       12 Batch loss: 0.151197 Batch F1: 0.8
Train Avg Loss  934: 0.167175

Train Avg F1  934: 0.7097667528663134

Val Avg Loss  934: 0.180798

Val Avg F1  934:  0.6756715287741113

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 935
--------------------------------------------------------------
Epoch:  935        1 Batch loss: 0.163625 Batch F1: 0.7843137254901961
Epoch:  935        2 Batch loss: 0.154425 Batch F1: 0.7659574468085107
Epoch:  935        3 Batch loss: 0.172587 Batch F1: 0.6808510638297872
Epoch:  935        4 Batch loss: 0.151106 Batch F1: 0.7906976744186046
Epoch:  935        5 Batch loss: 0.180383 Batch F1: 0.7111111111111111
Epoch:  935        6 Batch loss: 0.206933 Batch F1: 0.6046511627906976
Epoch:  935        7 Batch loss: 0.174621 Batch F1: 0.6486486486486486
Epoch:  935        8 Batch loss: 0.171251 Batch F1: 0.631578947368421
Epoch:  935        9 Batch loss: 0.158873 Batch F1: 0.8181818181818182
Epoch:  935       10 Batch loss: 0.168468 Batch F1: 0.7441860465116279
Epoch:  935       11 Batch loss: 0.163211 Batch F1: 0.76
Epoch:  935       12 Batch loss: 0.150957 Batch F1: 0.7428571428571428
Train Avg Loss  935: 0.168037

Train Avg F1  935: 0.7235862323347138

Val Avg Loss  935: 0.181469

Val Avg F1  935:  0.6704587324981577

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 936
--------------------------------------------------------------
Epoch:  936        1 Batch loss: 0.179549 Batch F1: 0.6222222222222222
Epoch:  936        2 Batch loss: 0.173463 Batch F1: 0.6486486486486486
Epoch:  936        3 Batch loss: 0.143860 Batch F1: 0.7999999999999999
Epoch:  936        4 Batch loss: 0.182318 Batch F1: 0.6341463414634148
Epoch:  936        5 Batch loss: 0.139580 Batch F1: 0.8695652173913043
Epoch:  936        6 Batch loss: 0.135010 Batch F1: 0.8205128205128205
Epoch:  936        7 Batch loss: 0.167484 Batch F1: 0.782608695652174
Epoch:  936        8 Batch loss: 0.195582 Batch F1: 0.6666666666666667
Epoch:  936        9 Batch loss: 0.202474 Batch F1: 0.5777777777777778
Epoch:  936       10 Batch loss: 0.177088 Batch F1: 0.7037037037037038
Epoch:  936       11 Batch loss: 0.128261 Batch F1: 0.8444444444444444
Epoch:  936       12 Batch loss: 0.184664 Batch F1: 0.5882352941176471
Train Avg Loss  936: 0.167444

Train Avg F1  936: 0.7132109860500687

Val Avg Loss  936: 0.181711

Val Avg F1  936:  0.6737460815047023

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 937
--------------------------------------------------------------
Epoch:  937        1 Batch loss: 0.161725 Batch F1: 0.7555555555555556
Epoch:  937        2 Batch loss: 0.178812 Batch F1: 0.7037037037037037
Epoch:  937        3 Batch loss: 0.160736 Batch F1: 0.7111111111111111
Epoch:  937        4 Batch loss: 0.160953 Batch F1: 0.8
Epoch:  937        5 Batch loss: 0.142502 Batch F1: 0.8372093023255814
Epoch:  937        6 Batch loss: 0.174895 Batch F1: 0.7272727272727273
Epoch:  937        7 Batch loss: 0.197998 Batch F1: 0.6808510638297872
Epoch:  937        8 Batch loss: 0.163327 Batch F1: 0.7317073170731706
Epoch:  937        9 Batch loss: 0.172164 Batch F1: 0.6956521739130435
Epoch:  937       10 Batch loss: 0.156271 Batch F1: 0.6842105263157895
Epoch:  937       11 Batch loss: 0.148436 Batch F1: 0.7428571428571429
Epoch:  937       12 Batch loss: 0.201617 Batch F1: 0.4615384615384615
Train Avg Loss  937: 0.168286

Train Avg F1  937: 0.7109724237913396

Val Avg Loss  937: 0.201253

Val Avg F1  937:  0.5705699233716476

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 938
--------------------------------------------------------------
Epoch:  938        1 Batch loss: 0.200082 Batch F1: 0.5405405405405406
Epoch:  938        2 Batch loss: 0.209642 Batch F1: 0.5853658536585366
Epoch:  938        3 Batch loss: 0.186397 Batch F1: 0.6829268292682926
Epoch:  938        4 Batch loss: 0.126019 Batch F1: 0.912280701754386
Epoch:  938        5 Batch loss: 0.164612 Batch F1: 0.8
Epoch:  938        6 Batch loss: 0.171220 Batch F1: 0.6486486486486486
Epoch:  938        7 Batch loss: 0.196930 Batch F1: 0.5
Epoch:  938        8 Batch loss: 0.178340 Batch F1: 0.65
Epoch:  938        9 Batch loss: 0.145479 Batch F1: 0.8399999999999999
Epoch:  938       10 Batch loss: 0.181143 Batch F1: 0.7555555555555556
Epoch:  938       11 Batch loss: 0.182157 Batch F1: 0.7547169811320754
Epoch:  938       12 Batch loss: 0.173662 Batch F1: 0.7222222222222222
Train Avg Loss  938: 0.176307

Train Avg F1  938: 0.6993547777316881

Val Avg Loss  938: 0.188353

Val Avg F1  938:  0.6500549285928293

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 939
--------------------------------------------------------------
Epoch:  939        1 Batch loss: 0.207114 Batch F1: 0.5263157894736842
Epoch:  939        2 Batch loss: 0.146251 Batch F1: 0.7317073170731706
Epoch:  939        3 Batch loss: 0.146319 Batch F1: 0.8085106382978724
Epoch:  939        4 Batch loss: 0.172301 Batch F1: 0.7407407407407408
Epoch:  939        5 Batch loss: 0.177145 Batch F1: 0.68
Epoch:  939        6 Batch loss: 0.164898 Batch F1: 0.7307692307692307
Epoch:  939        7 Batch loss: 0.190253 Batch F1: 0.7272727272727272
Epoch:  939        8 Batch loss: 0.174246 Batch F1: 0.7272727272727272
Epoch:  939        9 Batch loss: 0.154788 Batch F1: 0.7567567567567567
Epoch:  939       10 Batch loss: 0.184182 Batch F1: 0.6818181818181818
Epoch:  939       11 Batch loss: 0.149721 Batch F1: 0.6206896551724138
Epoch:  939       12 Batch loss: 0.195753 Batch F1: 0.6
Train Avg Loss  939: 0.171914

Train Avg F1  939: 0.6943211470539589

Val Avg Loss  939: 0.195912

Val Avg F1  939:  0.6112069424370591

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 940
--------------------------------------------------------------
Epoch:  940        1 Batch loss: 0.143765 Batch F1: 0.7142857142857143
Epoch:  940        2 Batch loss: 0.165207 Batch F1: 0.6206896551724139
Epoch:  940        3 Batch loss: 0.186472 Batch F1: 0.7199999999999999
Epoch:  940        4 Batch loss: 0.168389 Batch F1: 0.7450980392156863
Epoch:  940        5 Batch loss: 0.184624 Batch F1: 0.6511627906976744
Epoch:  940        6 Batch loss: 0.198305 Batch F1: 0.6511627906976745
Epoch:  940        7 Batch loss: 0.198208 Batch F1: 0.558139534883721
Epoch:  940        8 Batch loss: 0.146976 Batch F1: 0.8
Epoch:  940        9 Batch loss: 0.159824 Batch F1: 0.7317073170731707
Epoch:  940       10 Batch loss: 0.165751 Batch F1: 0.6976744186046512
Epoch:  940       11 Batch loss: 0.153148 Batch F1: 0.8148148148148148
Epoch:  940       12 Batch loss: 0.149324 Batch F1: 0.8095238095238095
Train Avg Loss  940: 0.168333

Train Avg F1  940: 0.7095215737474442

Val Avg Loss  940: 0.183249

Val Avg F1  940:  0.6880189651618223

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 941
--------------------------------------------------------------
Epoch:  941        1 Batch loss: 0.171219 Batch F1: 0.6976744186046512
Epoch:  941        2 Batch loss: 0.187781 Batch F1: 0.6521739130434783
Epoch:  941        3 Batch loss: 0.166552 Batch F1: 0.7142857142857143
Epoch:  941        4 Batch loss: 0.152727 Batch F1: 0.7368421052631577
Epoch:  941        5 Batch loss: 0.181071 Batch F1: 0.68
Epoch:  941        6 Batch loss: 0.162035 Batch F1: 0.7027027027027027
Epoch:  941        7 Batch loss: 0.178877 Batch F1: 0.7272727272727274
Epoch:  941        8 Batch loss: 0.167616 Batch F1: 0.75
Epoch:  941        9 Batch loss: 0.173350 Batch F1: 0.6938775510204083
Epoch:  941       10 Batch loss: 0.162778 Batch F1: 0.6976744186046512
Epoch:  941       11 Batch loss: 0.141958 Batch F1: 0.7999999999999999
Epoch:  941       12 Batch loss: 0.182190 Batch F1: 0.6666666666666667
Train Avg Loss  941: 0.169013

Train Avg F1  941: 0.7099308514553466

Val Avg Loss  941: 0.179182

Val Avg F1  941:  0.701936867590363

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 942
--------------------------------------------------------------
Epoch:  942        1 Batch loss: 0.135023 Batch F1: 0.8292682926829269
Epoch:  942        2 Batch loss: 0.178207 Batch F1: 0.6511627906976744
Epoch:  942        3 Batch loss: 0.175167 Batch F1: 0.7199999999999999
Epoch:  942        4 Batch loss: 0.189368 Batch F1: 0.6046511627906976
Epoch:  942        5 Batch loss: 0.158322 Batch F1: 0.7659574468085107
Epoch:  942        6 Batch loss: 0.170287 Batch F1: 0.6153846153846153
Epoch:  942        7 Batch loss: 0.153965 Batch F1: 0.7317073170731707
Epoch:  942        8 Batch loss: 0.158909 Batch F1: 0.7441860465116279
Epoch:  942        9 Batch loss: 0.141877 Batch F1: 0.8510638297872342
Epoch:  942       10 Batch loss: 0.166786 Batch F1: 0.6829268292682926
Epoch:  942       11 Batch loss: 0.172515 Batch F1: 0.6818181818181819
Epoch:  942       12 Batch loss: 0.184194 Batch F1: 0.7111111111111111
Train Avg Loss  942: 0.165385

Train Avg F1  942: 0.7157698019945036

Val Avg Loss  942: 0.180701

Val Avg F1  942:  0.6762276714404374

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 943
--------------------------------------------------------------
Epoch:  943        1 Batch loss: 0.153630 Batch F1: 0.7619047619047619
Epoch:  943        2 Batch loss: 0.186406 Batch F1: 0.6382978723404256
Epoch:  943        3 Batch loss: 0.166426 Batch F1: 0.6666666666666667
Epoch:  943        4 Batch loss: 0.107614 Batch F1: 0.9032258064516129
Epoch:  943        5 Batch loss: 0.167663 Batch F1: 0.7659574468085106
Epoch:  943        6 Batch loss: 0.192227 Batch F1: 0.5957446808510639
Epoch:  943        7 Batch loss: 0.191266 Batch F1: 0.6153846153846153
Epoch:  943        8 Batch loss: 0.167156 Batch F1: 0.7346938775510204
Epoch:  943        9 Batch loss: 0.178928 Batch F1: 0.6818181818181819
Epoch:  943       10 Batch loss: 0.156521 Batch F1: 0.7692307692307692
Epoch:  943       11 Batch loss: 0.154515 Batch F1: 0.7727272727272727
Epoch:  943       12 Batch loss: 0.174648 Batch F1: 0.7555555555555556
Train Avg Loss  943: 0.166417

Train Avg F1  943: 0.7217672922742047

Val Avg Loss  943: 0.182654

Val Avg F1  943:  0.6847532089661982

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 944
--------------------------------------------------------------
Epoch:  944        1 Batch loss: 0.177122 Batch F1: 0.7547169811320754
Epoch:  944        2 Batch loss: 0.160365 Batch F1: 0.7619047619047619
Epoch:  944        3 Batch loss: 0.159757 Batch F1: 0.7659574468085107
Epoch:  944        4 Batch loss: 0.155949 Batch F1: 0.7027027027027027
Epoch:  944        5 Batch loss: 0.157202 Batch F1: 0.6666666666666666
Epoch:  944        6 Batch loss: 0.159611 Batch F1: 0.6842105263157895
Epoch:  944        7 Batch loss: 0.178494 Batch F1: 0.72
Epoch:  944        8 Batch loss: 0.149232 Batch F1: 0.7755102040816326
Epoch:  944        9 Batch loss: 0.173995 Batch F1: 0.6153846153846153
Epoch:  944       10 Batch loss: 0.181851 Batch F1: 0.6
Epoch:  944       11 Batch loss: 0.157396 Batch F1: 0.7272727272727272
Epoch:  944       12 Batch loss: 0.172721 Batch F1: 0.6976744186046512
Train Avg Loss  944: 0.165308

Train Avg F1  944: 0.7060000875728444

Val Avg Loss  944: 0.182711

Val Avg F1  944:  0.6701869106135587

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 945
--------------------------------------------------------------
Epoch:  945        1 Batch loss: 0.149183 Batch F1: 0.7441860465116279
Epoch:  945        2 Batch loss: 0.167564 Batch F1: 0.7619047619047619
Epoch:  945        3 Batch loss: 0.156159 Batch F1: 0.8400000000000001
Epoch:  945        4 Batch loss: 0.174200 Batch F1: 0.711111111111111
Epoch:  945        5 Batch loss: 0.180020 Batch F1: 0.7058823529411765
Epoch:  945        6 Batch loss: 0.161038 Batch F1: 0.6666666666666667
Epoch:  945        7 Batch loss: 0.186159 Batch F1: 0.6046511627906976
Epoch:  945        8 Batch loss: 0.132691 Batch F1: 0.8444444444444444
Epoch:  945        9 Batch loss: 0.177252 Batch F1: 0.6382978723404256
Epoch:  945       10 Batch loss: 0.178800 Batch F1: 0.5714285714285714
Epoch:  945       11 Batch loss: 0.144262 Batch F1: 0.7916666666666667
Epoch:  945       12 Batch loss: 0.173005 Batch F1: 0.7027027027027026
Train Avg Loss  945: 0.165028

Train Avg F1  945: 0.7152451966257377

Val Avg Loss  945: 0.182470

Val Avg F1  945:  0.7143426520141817

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 946
--------------------------------------------------------------
Epoch:  946        1 Batch loss: 0.147136 Batch F1: 0.8148148148148148
Epoch:  946        2 Batch loss: 0.198770 Batch F1: 0.6666666666666665
Epoch:  946        3 Batch loss: 0.183173 Batch F1: 0.5499999999999999
Epoch:  946        4 Batch loss: 0.159607 Batch F1: 0.7111111111111111
Epoch:  946        5 Batch loss: 0.159321 Batch F1: 0.7441860465116279
Epoch:  946        6 Batch loss: 0.182465 Batch F1: 0.7755102040816326
Epoch:  946        7 Batch loss: 0.175176 Batch F1: 0.76
Epoch:  946        8 Batch loss: 0.176369 Batch F1: 0.6500000000000001
Epoch:  946        9 Batch loss: 0.167412 Batch F1: 0.7843137254901961
Epoch:  946       10 Batch loss: 0.160680 Batch F1: 0.7368421052631577
Epoch:  946       11 Batch loss: 0.139138 Batch F1: 0.7894736842105262
Epoch:  946       12 Batch loss: 0.154398 Batch F1: 0.7692307692307692
Train Avg Loss  946: 0.166970

Train Avg F1  946: 0.7293457606150419

Val Avg Loss  946: 0.183184

Val Avg F1  946:  0.6818169786349026

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 947
--------------------------------------------------------------
Epoch:  947        1 Batch loss: 0.175712 Batch F1: 0.6153846153846153
Epoch:  947        2 Batch loss: 0.181512 Batch F1: 0.7924528301886792
Epoch:  947        3 Batch loss: 0.162677 Batch F1: 0.7
Epoch:  947        4 Batch loss: 0.187851 Batch F1: 0.7241379310344829
Epoch:  947        5 Batch loss: 0.144349 Batch F1: 0.7804878048780488
Epoch:  947        6 Batch loss: 0.144540 Batch F1: 0.7272727272727272
Epoch:  947        7 Batch loss: 0.134142 Batch F1: 0.7999999999999999
Epoch:  947        8 Batch loss: 0.155190 Batch F1: 0.7317073170731708
Epoch:  947        9 Batch loss: 0.168932 Batch F1: 0.711111111111111
Epoch:  947       10 Batch loss: 0.185695 Batch F1: 0.631578947368421
Epoch:  947       11 Batch loss: 0.185734 Batch F1: 0.7058823529411765
Epoch:  947       12 Batch loss: 0.176749 Batch F1: 0.7142857142857143
Train Avg Loss  947: 0.166924

Train Avg F1  947: 0.7195251126281789

Val Avg Loss  947: 0.181435

Val Avg F1  947:  0.690219484020023

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 948
--------------------------------------------------------------
Epoch:  948        1 Batch loss: 0.165257 Batch F1: 0.7659574468085107
Epoch:  948        2 Batch loss: 0.176502 Batch F1: 0.6511627906976744
Epoch:  948        3 Batch loss: 0.153475 Batch F1: 0.7027027027027026
Epoch:  948        4 Batch loss: 0.147312 Batch F1: 0.7906976744186046
Epoch:  948        5 Batch loss: 0.189662 Batch F1: 0.6530612244897959
Epoch:  948        6 Batch loss: 0.138247 Batch F1: 0.8627450980392156
Epoch:  948        7 Batch loss: 0.138139 Batch F1: 0.8085106382978724
Epoch:  948        8 Batch loss: 0.131535 Batch F1: 0.8095238095238095
Epoch:  948        9 Batch loss: 0.201310 Batch F1: 0.5581395348837209
Epoch:  948       10 Batch loss: 0.180657 Batch F1: 0.6511627906976744
Epoch:  948       11 Batch loss: 0.178157 Batch F1: 0.6153846153846153
Epoch:  948       12 Batch loss: 0.180192 Batch F1: 0.717948717948718
Train Avg Loss  948: 0.165037

Train Avg F1  948: 0.7155830869910762

Val Avg Loss  948: 0.184344

Val Avg F1  948:  0.6837564294010288

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 949
--------------------------------------------------------------
Epoch:  949        1 Batch loss: 0.140008 Batch F1: 0.8181818181818182
Epoch:  949        2 Batch loss: 0.167904 Batch F1: 0.5925925925925926
Epoch:  949        3 Batch loss: 0.191260 Batch F1: 0.7659574468085107
Epoch:  949        4 Batch loss: 0.189231 Batch F1: 0.7083333333333334
Epoch:  949        5 Batch loss: 0.184426 Batch F1: 0.7272727272727274
Epoch:  949        6 Batch loss: 0.153158 Batch F1: 0.75
Epoch:  949        7 Batch loss: 0.162453 Batch F1: 0.7142857142857143
Epoch:  949        8 Batch loss: 0.166894 Batch F1: 0.7500000000000001
Epoch:  949        9 Batch loss: 0.151188 Batch F1: 0.816326530612245
Epoch:  949       10 Batch loss: 0.153498 Batch F1: 0.7317073170731706
Epoch:  949       11 Batch loss: 0.204187 Batch F1: 0.5581395348837209
Epoch:  949       12 Batch loss: 0.177507 Batch F1: 0.6666666666666667
Train Avg Loss  949: 0.170143

Train Avg F1  949: 0.716621973475875

Val Avg Loss  949: 0.182206

Val Avg F1  949:  0.7294560605798135

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 950
--------------------------------------------------------------
Epoch:  950        1 Batch loss: 0.168797 Batch F1: 0.7916666666666667
Epoch:  950        2 Batch loss: 0.145921 Batch F1: 0.8333333333333333
Epoch:  950        3 Batch loss: 0.180416 Batch F1: 0.68
Epoch:  950        4 Batch loss: 0.148939 Batch F1: 0.8461538461538461
Epoch:  950        5 Batch loss: 0.185593 Batch F1: 0.6956521739130435
Epoch:  950        6 Batch loss: 0.160603 Batch F1: 0.7317073170731706
Epoch:  950        7 Batch loss: 0.201572 Batch F1: 0.4444444444444445
Epoch:  950        8 Batch loss: 0.191661 Batch F1: 0.5142857142857143
Epoch:  950        9 Batch loss: 0.157190 Batch F1: 0.8
Epoch:  950       10 Batch loss: 0.171869 Batch F1: 0.6111111111111113
Epoch:  950       11 Batch loss: 0.151649 Batch F1: 0.7727272727272727
Epoch:  950       12 Batch loss: 0.136753 Batch F1: 0.8636363636363636
Train Avg Loss  950: 0.166747

Train Avg F1  950: 0.715393186945414

Val Avg Loss  950: 0.181144

Val Avg F1  950:  0.699476219306266

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 951
--------------------------------------------------------------
Epoch:  951        1 Batch loss: 0.211304 Batch F1: 0.6153846153846153
Epoch:  951        2 Batch loss: 0.163742 Batch F1: 0.7272727272727272
Epoch:  951        3 Batch loss: 0.183582 Batch F1: 0.6666666666666666
Epoch:  951        4 Batch loss: 0.162704 Batch F1: 0.7272727272727272
Epoch:  951        5 Batch loss: 0.218435 Batch F1: 0.6222222222222222
Epoch:  951        6 Batch loss: 0.167313 Batch F1: 0.7659574468085107
Epoch:  951        7 Batch loss: 0.143058 Batch F1: 0.7567567567567567
Epoch:  951        8 Batch loss: 0.173871 Batch F1: 0.6666666666666666
Epoch:  951        9 Batch loss: 0.162029 Batch F1: 0.7755102040816326
Epoch:  951       10 Batch loss: 0.179308 Batch F1: 0.6666666666666667
Epoch:  951       11 Batch loss: 0.172738 Batch F1: 0.8095238095238096
Epoch:  951       12 Batch loss: 0.180632 Batch F1: 0.7692307692307692
Train Avg Loss  951: 0.176560

Train Avg F1  951: 0.7140942732128144

Val Avg Loss  951: 0.188410

Val Avg F1  951:  0.6797472194135489

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 952
--------------------------------------------------------------
Epoch:  952        1 Batch loss: 0.158887 Batch F1: 0.761904761904762
Epoch:  952        2 Batch loss: 0.198045 Batch F1: 0.6521739130434783
Epoch:  952        3 Batch loss: 0.180488 Batch F1: 0.6666666666666666
Epoch:  952        4 Batch loss: 0.183976 Batch F1: 0.6500000000000001
Epoch:  952        5 Batch loss: 0.164310 Batch F1: 0.7272727272727272
Epoch:  952        6 Batch loss: 0.146562 Batch F1: 0.8571428571428571
Epoch:  952        7 Batch loss: 0.172368 Batch F1: 0.7272727272727272
Epoch:  952        8 Batch loss: 0.193493 Batch F1: 0.7037037037037038
Epoch:  952        9 Batch loss: 0.170810 Batch F1: 0.6153846153846154
Epoch:  952       10 Batch loss: 0.153782 Batch F1: 0.7567567567567567
Epoch:  952       11 Batch loss: 0.160878 Batch F1: 0.625
Epoch:  952       12 Batch loss: 0.190067 Batch F1: 0.7317073170731707
Train Avg Loss  952: 0.172805

Train Avg F1  952: 0.7062488371851221

Val Avg Loss  952: 0.182889

Val Avg F1  952:  0.6895532266960838

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 953
--------------------------------------------------------------
Epoch:  953        1 Batch loss: 0.172075 Batch F1: 0.5853658536585367
Epoch:  953        2 Batch loss: 0.182727 Batch F1: 0.6666666666666666
Epoch:  953        3 Batch loss: 0.157040 Batch F1: 0.8260869565217391
Epoch:  953        4 Batch loss: 0.159399 Batch F1: 0.7441860465116279
Epoch:  953        5 Batch loss: 0.175004 Batch F1: 0.7083333333333334
Epoch:  953        6 Batch loss: 0.164451 Batch F1: 0.65
Epoch:  953        7 Batch loss: 0.190684 Batch F1: 0.6363636363636364
Epoch:  953        8 Batch loss: 0.166786 Batch F1: 0.7234042553191489
Epoch:  953        9 Batch loss: 0.166872 Batch F1: 0.7727272727272727
Epoch:  953       10 Batch loss: 0.178265 Batch F1: 0.7636363636363638
Epoch:  953       11 Batch loss: 0.140973 Batch F1: 0.7647058823529411
Epoch:  953       12 Batch loss: 0.191806 Batch F1: 0.6956521739130435
Train Avg Loss  953: 0.170507

Train Avg F1  953: 0.7114273700836925

Val Avg Loss  953: 0.184985

Val Avg F1  953:  0.6690818911239255

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 954
--------------------------------------------------------------
Epoch:  954        1 Batch loss: 0.153732 Batch F1: 0.8260869565217391
Epoch:  954        2 Batch loss: 0.165320 Batch F1: 0.7346938775510204
Epoch:  954        3 Batch loss: 0.159733 Batch F1: 0.6285714285714286
Epoch:  954        4 Batch loss: 0.129089 Batch F1: 0.8292682926829269
Epoch:  954        5 Batch loss: 0.148968 Batch F1: 0.7906976744186046
Epoch:  954        6 Batch loss: 0.193138 Batch F1: 0.5714285714285714
Epoch:  954        7 Batch loss: 0.144100 Batch F1: 0.7804878048780488
Epoch:  954        8 Batch loss: 0.192837 Batch F1: 0.6341463414634146
Epoch:  954        9 Batch loss: 0.189194 Batch F1: 0.6923076923076924
Epoch:  954       10 Batch loss: 0.181934 Batch F1: 0.6956521739130435
Epoch:  954       11 Batch loss: 0.159530 Batch F1: 0.7555555555555555
Epoch:  954       12 Batch loss: 0.202579 Batch F1: 0.6500000000000001
Train Avg Loss  954: 0.168346

Train Avg F1  954: 0.7157413641076705

Val Avg Loss  954: 0.180082

Val Avg F1  954:  0.6839676885408593

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 955
--------------------------------------------------------------
Epoch:  955        1 Batch loss: 0.173405 Batch F1: 0.6153846153846154
Epoch:  955        2 Batch loss: 0.161418 Batch F1: 0.6976744186046512
Epoch:  955        3 Batch loss: 0.141797 Batch F1: 0.8181818181818181
Epoch:  955        4 Batch loss: 0.172231 Batch F1: 0.7692307692307692
Epoch:  955        5 Batch loss: 0.157630 Batch F1: 0.7441860465116279
Epoch:  955        6 Batch loss: 0.190818 Batch F1: 0.6086956521739131
Epoch:  955        7 Batch loss: 0.132834 Batch F1: 0.85
Epoch:  955        8 Batch loss: 0.123472 Batch F1: 0.8780487804878049
Epoch:  955        9 Batch loss: 0.166863 Batch F1: 0.7755102040816326
Epoch:  955       10 Batch loss: 0.181112 Batch F1: 0.6808510638297872
Epoch:  955       11 Batch loss: 0.199975 Batch F1: 0.5454545454545454
Epoch:  955       12 Batch loss: 0.181240 Batch F1: 0.6666666666666666
Train Avg Loss  955: 0.165233

Train Avg F1  955: 0.7208237150506527

Val Avg Loss  955: 0.179665

Val Avg F1  955:  0.6815459385335161

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 956
--------------------------------------------------------------
Epoch:  956        1 Batch loss: 0.135230 Batch F1: 0.8095238095238095
Epoch:  956        2 Batch loss: 0.157901 Batch F1: 0.7142857142857143
Epoch:  956        3 Batch loss: 0.160299 Batch F1: 0.6857142857142857
Epoch:  956        4 Batch loss: 0.158431 Batch F1: 0.7659574468085107
Epoch:  956        5 Batch loss: 0.194054 Batch F1: 0.5263157894736842
Epoch:  956        6 Batch loss: 0.179495 Batch F1: 0.7169811320754718
Epoch:  956        7 Batch loss: 0.162400 Batch F1: 0.75
Epoch:  956        8 Batch loss: 0.150675 Batch F1: 0.7555555555555556
Epoch:  956        9 Batch loss: 0.161894 Batch F1: 0.7777777777777779
Epoch:  956       10 Batch loss: 0.173034 Batch F1: 0.6938775510204083
Epoch:  956       11 Batch loss: 0.187833 Batch F1: 0.6666666666666666
Epoch:  956       12 Batch loss: 0.170814 Batch F1: 0.7058823529411765
Train Avg Loss  956: 0.166005

Train Avg F1  956: 0.7140448401535884

Val Avg Loss  956: 0.179315

Val Avg F1  956:  0.6905987135081644

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 957
--------------------------------------------------------------
Epoch:  957        1 Batch loss: 0.152947 Batch F1: 0.7999999999999999
Epoch:  957        2 Batch loss: 0.151526 Batch F1: 0.7826086956521738
Epoch:  957        3 Batch loss: 0.168757 Batch F1: 0.7111111111111111
Epoch:  957        4 Batch loss: 0.157649 Batch F1: 0.717948717948718
Epoch:  957        5 Batch loss: 0.142844 Batch F1: 0.7692307692307692
Epoch:  957        6 Batch loss: 0.165882 Batch F1: 0.7441860465116279
Epoch:  957        7 Batch loss: 0.144939 Batch F1: 0.75
Epoch:  957        8 Batch loss: 0.211867 Batch F1: 0.5833333333333334
Epoch:  957        9 Batch loss: 0.166569 Batch F1: 0.65
Epoch:  957       10 Batch loss: 0.165270 Batch F1: 0.6808510638297872
Epoch:  957       11 Batch loss: 0.188475 Batch F1: 0.7241379310344828
Epoch:  957       12 Batch loss: 0.160447 Batch F1: 0.7727272727272727
Train Avg Loss  957: 0.164764

Train Avg F1  957: 0.723844578448273

Val Avg Loss  957: 0.183376

Val Avg F1  957:  0.6771948662882855

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 958
--------------------------------------------------------------
Epoch:  958        1 Batch loss: 0.179006 Batch F1: 0.7307692307692306
Epoch:  958        2 Batch loss: 0.153667 Batch F1: 0.7272727272727272
Epoch:  958        3 Batch loss: 0.176936 Batch F1: 0.6923076923076923
Epoch:  958        4 Batch loss: 0.166320 Batch F1: 0.6818181818181819
Epoch:  958        5 Batch loss: 0.153397 Batch F1: 0.6976744186046512
Epoch:  958        6 Batch loss: 0.164683 Batch F1: 0.7142857142857143
Epoch:  958        7 Batch loss: 0.193158 Batch F1: 0.5365853658536586
Epoch:  958        8 Batch loss: 0.185299 Batch F1: 0.68
Epoch:  958        9 Batch loss: 0.149295 Batch F1: 0.8095238095238095
Epoch:  958       10 Batch loss: 0.188604 Batch F1: 0.7058823529411765
Epoch:  958       11 Batch loss: 0.160591 Batch F1: 0.7727272727272727
Epoch:  958       12 Batch loss: 0.179709 Batch F1: 0.6857142857142857
Train Avg Loss  958: 0.170889

Train Avg F1  958: 0.7028800876515332

Val Avg Loss  958: 0.183393

Val Avg F1  958:  0.6815250023454358

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 959
--------------------------------------------------------------
Epoch:  959        1 Batch loss: 0.182294 Batch F1: 0.72
Epoch:  959        2 Batch loss: 0.185575 Batch F1: 0.6315789473684211
Epoch:  959        3 Batch loss: 0.187736 Batch F1: 0.5714285714285715
Epoch:  959        4 Batch loss: 0.155044 Batch F1: 0.7142857142857143
Epoch:  959        5 Batch loss: 0.150686 Batch F1: 0.8
Epoch:  959        6 Batch loss: 0.154591 Batch F1: 0.7659574468085107
Epoch:  959        7 Batch loss: 0.158825 Batch F1: 0.7317073170731706
Epoch:  959        8 Batch loss: 0.160676 Batch F1: 0.7727272727272727
Epoch:  959        9 Batch loss: 0.151695 Batch F1: 0.7659574468085107
Epoch:  959       10 Batch loss: 0.192275 Batch F1: 0.5263157894736842
Epoch:  959       11 Batch loss: 0.163512 Batch F1: 0.75
Epoch:  959       12 Batch loss: 0.191403 Batch F1: 0.711111111111111
Train Avg Loss  959: 0.169526

Train Avg F1  959: 0.7050891347570806

Val Avg Loss  959: 0.185332

Val Avg F1  959:  0.6785794506481838

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 960
--------------------------------------------------------------
Epoch:  960        1 Batch loss: 0.159387 Batch F1: 0.7555555555555555
Epoch:  960        2 Batch loss: 0.168976 Batch F1: 0.6818181818181818
Epoch:  960        3 Batch loss: 0.152008 Batch F1: 0.7555555555555555
Epoch:  960        4 Batch loss: 0.170222 Batch F1: 0.7659574468085107
Epoch:  960        5 Batch loss: 0.175709 Batch F1: 0.5294117647058824
Epoch:  960        6 Batch loss: 0.143418 Batch F1: 0.8260869565217391
Epoch:  960        7 Batch loss: 0.128438 Batch F1: 0.8837209302325582
Epoch:  960        8 Batch loss: 0.158847 Batch F1: 0.7843137254901961
Epoch:  960        9 Batch loss: 0.197745 Batch F1: 0.6122448979591837
Epoch:  960       10 Batch loss: 0.201841 Batch F1: 0.5853658536585366
Epoch:  960       11 Batch loss: 0.168124 Batch F1: 0.7272727272727272
Epoch:  960       12 Batch loss: 0.173661 Batch F1: 0.6250000000000001
Train Avg Loss  960: 0.166531

Train Avg F1  960: 0.7110252996315523

Val Avg Loss  960: 0.179820

Val Avg F1  960:  0.6768488059321727

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 961
--------------------------------------------------------------
Epoch:  961        1 Batch loss: 0.155501 Batch F1: 0.6666666666666667
Epoch:  961        2 Batch loss: 0.204293 Batch F1: 0.6666666666666666
Epoch:  961        3 Batch loss: 0.176228 Batch F1: 0.6521739130434783
Epoch:  961        4 Batch loss: 0.159045 Batch F1: 0.717948717948718
Epoch:  961        5 Batch loss: 0.144226 Batch F1: 0.8372093023255814
Epoch:  961        6 Batch loss: 0.187770 Batch F1: 0.6363636363636364
Epoch:  961        7 Batch loss: 0.141491 Batch F1: 0.847457627118644
Epoch:  961        8 Batch loss: 0.166232 Batch F1: 0.7500000000000001
Epoch:  961        9 Batch loss: 0.163916 Batch F1: 0.7999999999999999
Epoch:  961       10 Batch loss: 0.168978 Batch F1: 0.6976744186046512
Epoch:  961       11 Batch loss: 0.167853 Batch F1: 0.6829268292682926
Epoch:  961       12 Batch loss: 0.144335 Batch F1: 0.7500000000000001
Train Avg Loss  961: 0.164989

Train Avg F1  961: 0.725423981500528

Val Avg Loss  961: 0.179314

Val Avg F1  961:  0.6869016094679754

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 962
--------------------------------------------------------------
Epoch:  962        1 Batch loss: 0.179444 Batch F1: 0.6363636363636365
Epoch:  962        2 Batch loss: 0.204721 Batch F1: 0.5
Epoch:  962        3 Batch loss: 0.165936 Batch F1: 0.7234042553191491
Epoch:  962        4 Batch loss: 0.131605 Batch F1: 0.7894736842105262
Epoch:  962        5 Batch loss: 0.177687 Batch F1: 0.7450980392156864
Epoch:  962        6 Batch loss: 0.174441 Batch F1: 0.7391304347826088
Epoch:  962        7 Batch loss: 0.172280 Batch F1: 0.7719298245614035
Epoch:  962        8 Batch loss: 0.144135 Batch F1: 0.7999999999999999
Epoch:  962        9 Batch loss: 0.155742 Batch F1: 0.8085106382978724
Epoch:  962       10 Batch loss: 0.131439 Batch F1: 0.7333333333333334
Epoch:  962       11 Batch loss: 0.179283 Batch F1: 0.6829268292682926
Epoch:  962       12 Batch loss: 0.166765 Batch F1: 0.6666666666666667
Train Avg Loss  962: 0.165290

Train Avg F1  962: 0.7164031118349312

Val Avg Loss  962: 0.178829

Val Avg F1  962:  0.7071518288737488

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 963
--------------------------------------------------------------
Epoch:  963        1 Batch loss: 0.154076 Batch F1: 0.6842105263157895
Epoch:  963        2 Batch loss: 0.186246 Batch F1: 0.7307692307692308
Epoch:  963        3 Batch loss: 0.135598 Batch F1: 0.7906976744186046
Epoch:  963        4 Batch loss: 0.161824 Batch F1: 0.7346938775510203
Epoch:  963        5 Batch loss: 0.164531 Batch F1: 0.7659574468085107
Epoch:  963        6 Batch loss: 0.173253 Batch F1: 0.7317073170731708
Epoch:  963        7 Batch loss: 0.164087 Batch F1: 0.7727272727272727
Epoch:  963        8 Batch loss: 0.162653 Batch F1: 0.7555555555555556
Epoch:  963        9 Batch loss: 0.168948 Batch F1: 0.7142857142857143
Epoch:  963       10 Batch loss: 0.159848 Batch F1: 0.782608695652174
Epoch:  963       11 Batch loss: 0.214560 Batch F1: 0.45
Epoch:  963       12 Batch loss: 0.153212 Batch F1: 0.7777777777777778
Train Avg Loss  963: 0.166570

Train Avg F1  963: 0.724249257411235

Val Avg Loss  963: 0.180357

Val Avg F1  963:  0.6845600541252715

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 964
--------------------------------------------------------------
Epoch:  964        1 Batch loss: 0.157447 Batch F1: 0.7272727272727272
Epoch:  964        2 Batch loss: 0.178628 Batch F1: 0.6818181818181819
Epoch:  964        3 Batch loss: 0.147145 Batch F1: 0.7916666666666667
Epoch:  964        4 Batch loss: 0.152649 Batch F1: 0.7
Epoch:  964        5 Batch loss: 0.159496 Batch F1: 0.5714285714285715
Epoch:  964        6 Batch loss: 0.158499 Batch F1: 0.7599999999999999
Epoch:  964        7 Batch loss: 0.130550 Batch F1: 0.7647058823529413
Epoch:  964        8 Batch loss: 0.174447 Batch F1: 0.7083333333333334
Epoch:  964        9 Batch loss: 0.183933 Batch F1: 0.7058823529411765
Epoch:  964       10 Batch loss: 0.185337 Batch F1: 0.7272727272727273
Epoch:  964       11 Batch loss: 0.159412 Batch F1: 0.782608695652174
Epoch:  964       12 Batch loss: 0.188627 Batch F1: 0.6486486486486486
Train Avg Loss  964: 0.164681

Train Avg F1  964: 0.7141364822822625

Val Avg Loss  964: 0.180703

Val Avg F1  964:  0.6796835296835296

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 965
--------------------------------------------------------------
Epoch:  965        1 Batch loss: 0.149476 Batch F1: 0.7317073170731707
Epoch:  965        2 Batch loss: 0.199478 Batch F1: 0.6274509803921569
Epoch:  965        3 Batch loss: 0.158724 Batch F1: 0.8148148148148148
Epoch:  965        4 Batch loss: 0.149308 Batch F1: 0.8095238095238095
Epoch:  965        5 Batch loss: 0.174980 Batch F1: 0.6341463414634146
Epoch:  965        6 Batch loss: 0.173895 Batch F1: 0.6842105263157895
Epoch:  965        7 Batch loss: 0.151447 Batch F1: 0.7843137254901961
Epoch:  965        8 Batch loss: 0.161127 Batch F1: 0.8076923076923077
Epoch:  965        9 Batch loss: 0.168478 Batch F1: 0.6111111111111112
Epoch:  965       10 Batch loss: 0.164864 Batch F1: 0.6842105263157896
Epoch:  965       11 Batch loss: 0.183047 Batch F1: 0.6666666666666666
Epoch:  965       12 Batch loss: 0.149816 Batch F1: 0.8292682926829269
Train Avg Loss  965: 0.165387

Train Avg F1  965: 0.7237597016285129

Val Avg Loss  965: 0.182251

Val Avg F1  965:  0.6752628848902141

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 966
--------------------------------------------------------------
Epoch:  966        1 Batch loss: 0.179818 Batch F1: 0.6818181818181818
Epoch:  966        2 Batch loss: 0.194630 Batch F1: 0.6222222222222223
Epoch:  966        3 Batch loss: 0.170540 Batch F1: 0.6666666666666667
Epoch:  966        4 Batch loss: 0.163492 Batch F1: 0.8070175438596491
Epoch:  966        5 Batch loss: 0.166365 Batch F1: 0.6956521739130435
Epoch:  966        6 Batch loss: 0.164798 Batch F1: 0.6857142857142857
Epoch:  966        7 Batch loss: 0.149804 Batch F1: 0.7058823529411765
Epoch:  966        8 Batch loss: 0.183246 Batch F1: 0.6666666666666667
Epoch:  966        9 Batch loss: 0.157531 Batch F1: 0.717948717948718
Epoch:  966       10 Batch loss: 0.144657 Batch F1: 0.7692307692307692
Epoch:  966       11 Batch loss: 0.142532 Batch F1: 0.7567567567567567
Epoch:  966       12 Batch loss: 0.153949 Batch F1: 0.8695652173913043
Train Avg Loss  966: 0.164280

Train Avg F1  966: 0.7204284629274534

Val Avg Loss  966: 0.181593

Val Avg F1  966:  0.6710081761352179

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 967
--------------------------------------------------------------
Epoch:  967        1 Batch loss: 0.149567 Batch F1: 0.7222222222222222
Epoch:  967        2 Batch loss: 0.168045 Batch F1: 0.6808510638297872
Epoch:  967        3 Batch loss: 0.144938 Batch F1: 0.7567567567567567
Epoch:  967        4 Batch loss: 0.170039 Batch F1: 0.6818181818181819
Epoch:  967        5 Batch loss: 0.170950 Batch F1: 0.7083333333333333
Epoch:  967        6 Batch loss: 0.173387 Batch F1: 0.6976744186046512
Epoch:  967        7 Batch loss: 0.180254 Batch F1: 0.6666666666666666
Epoch:  967        8 Batch loss: 0.159666 Batch F1: 0.7999999999999999
Epoch:  967        9 Batch loss: 0.176013 Batch F1: 0.7037037037037037
Epoch:  967       10 Batch loss: 0.146306 Batch F1: 0.7499999999999999
Epoch:  967       11 Batch loss: 0.154989 Batch F1: 0.816326530612245
Epoch:  967       12 Batch loss: 0.189716 Batch F1: 0.6874999999999999
Train Avg Loss  967: 0.165322

Train Avg F1  967: 0.7226544064622956

Val Avg Loss  967: 0.178447

Val Avg F1  967:  0.6855459196460207

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 968
--------------------------------------------------------------
Epoch:  968        1 Batch loss: 0.177185 Batch F1: 0.7199999999999999
Epoch:  968        2 Batch loss: 0.164563 Batch F1: 0.6111111111111112
Epoch:  968        3 Batch loss: 0.178862 Batch F1: 0.619047619047619
Epoch:  968        4 Batch loss: 0.153551 Batch F1: 0.7999999999999999
Epoch:  968        5 Batch loss: 0.155126 Batch F1: 0.7659574468085107
Epoch:  968        6 Batch loss: 0.145464 Batch F1: 0.7317073170731706
Epoch:  968        7 Batch loss: 0.152146 Batch F1: 0.7692307692307692
Epoch:  968        8 Batch loss: 0.211238 Batch F1: 0.7083333333333334
Epoch:  968        9 Batch loss: 0.155971 Batch F1: 0.8085106382978724
Epoch:  968       10 Batch loss: 0.208035 Batch F1: 0.6511627906976744
Epoch:  968       11 Batch loss: 0.132003 Batch F1: 0.8571428571428572
Epoch:  968       12 Batch loss: 0.179061 Batch F1: 0.7222222222222222
Train Avg Loss  968: 0.167767

Train Avg F1  968: 0.7303688420804283

Val Avg Loss  968: 0.181494

Val Avg F1  968:  0.6804388422035481

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 969
--------------------------------------------------------------
Epoch:  969        1 Batch loss: 0.174354 Batch F1: 0.7272727272727272
Epoch:  969        2 Batch loss: 0.177436 Batch F1: 0.5405405405405405
Epoch:  969        3 Batch loss: 0.174534 Batch F1: 0.7142857142857143
Epoch:  969        4 Batch loss: 0.145893 Batch F1: 0.8518518518518519
Epoch:  969        5 Batch loss: 0.166049 Batch F1: 0.7843137254901961
Epoch:  969        6 Batch loss: 0.176510 Batch F1: 0.6363636363636365
Epoch:  969        7 Batch loss: 0.170730 Batch F1: 0.7111111111111111
Epoch:  969        8 Batch loss: 0.176400 Batch F1: 0.5853658536585366
Epoch:  969        9 Batch loss: 0.185914 Batch F1: 0.6382978723404256
Epoch:  969       10 Batch loss: 0.147865 Batch F1: 0.7826086956521738
Epoch:  969       11 Batch loss: 0.171067 Batch F1: 0.6829268292682926
Epoch:  969       12 Batch loss: 0.164781 Batch F1: 0.7428571428571429
Train Avg Loss  969: 0.169294

Train Avg F1  969: 0.699816308391029

Val Avg Loss  969: 0.183296

Val Avg F1  969:  0.6820192307692308

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 970
--------------------------------------------------------------
Epoch:  970        1 Batch loss: 0.147095 Batch F1: 0.8260869565217391
Epoch:  970        2 Batch loss: 0.167233 Batch F1: 0.65
Epoch:  970        3 Batch loss: 0.161517 Batch F1: 0.8372093023255814
Epoch:  970        4 Batch loss: 0.185865 Batch F1: 0.6956521739130435
Epoch:  970        5 Batch loss: 0.191718 Batch F1: 0.6666666666666666
Epoch:  970        6 Batch loss: 0.164490 Batch F1: 0.7999999999999999
Epoch:  970        7 Batch loss: 0.174430 Batch F1: 0.5789473684210527
Epoch:  970        8 Batch loss: 0.190857 Batch F1: 0.761904761904762
Epoch:  970        9 Batch loss: 0.149595 Batch F1: 0.7391304347826088
Epoch:  970       10 Batch loss: 0.182566 Batch F1: 0.8076923076923076
Epoch:  970       11 Batch loss: 0.198517 Batch F1: 0.6666666666666665
Epoch:  970       12 Batch loss: 0.155769 Batch F1: 0.761904761904762
Train Avg Loss  970: 0.172471

Train Avg F1  970: 0.7326551167332659

Val Avg Loss  970: 0.187296

Val Avg F1  970:  0.6445165004487039

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 971
--------------------------------------------------------------
Epoch:  971        1 Batch loss: 0.178211 Batch F1: 0.5777777777777778
Epoch:  971        2 Batch loss: 0.182382 Batch F1: 0.7500000000000001
Epoch:  971        3 Batch loss: 0.148620 Batch F1: 0.7804878048780488
Epoch:  971        4 Batch loss: 0.182795 Batch F1: 0.7777777777777777
Epoch:  971        5 Batch loss: 0.172146 Batch F1: 0.7234042553191491
Epoch:  971        6 Batch loss: 0.154784 Batch F1: 0.7755102040816326
Epoch:  971        7 Batch loss: 0.208414 Batch F1: 0.43243243243243246
Epoch:  971        8 Batch loss: 0.261948 Batch F1: 0.35294117647058826
Epoch:  971        9 Batch loss: 0.190829 Batch F1: 0.7450980392156863
Epoch:  971       10 Batch loss: 0.220723 Batch F1: 0.7096774193548387
Epoch:  971       11 Batch loss: 0.186993 Batch F1: 0.7916666666666666
Epoch:  971       12 Batch loss: 0.188546 Batch F1: 0.6470588235294118
Train Avg Loss  971: 0.189699

Train Avg F1  971: 0.6719860314586676

Val Avg Loss  971: 0.244107

Val Avg F1  971:  0.2567460317460317

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 972
--------------------------------------------------------------
Epoch:  972        1 Batch loss: 0.230407 Batch F1: 0.24000000000000002
Epoch:  972        2 Batch loss: 0.243353 Batch F1: 0.16
Epoch:  972        3 Batch loss: 0.155972 Batch F1: 0.7916666666666667
Epoch:  972        4 Batch loss: 0.259884 Batch F1: 0.6470588235294118
Epoch:  972        5 Batch loss: 0.163758 Batch F1: 0.7906976744186046
Epoch:  972        6 Batch loss: 0.198397 Batch F1: 0.6363636363636364
Epoch:  972        7 Batch loss: 0.148561 Batch F1: 0.6857142857142857
Epoch:  972        8 Batch loss: 0.174539 Batch F1: 0.7317073170731707
Epoch:  972        9 Batch loss: 0.190570 Batch F1: 0.6896551724137931
Epoch:  972       10 Batch loss: 0.184502 Batch F1: 0.6818181818181819
Epoch:  972       11 Batch loss: 0.168258 Batch F1: 0.7391304347826088
Epoch:  972       12 Batch loss: 0.178296 Batch F1: 0.7755102040816326
Train Avg Loss  972: 0.191375

Train Avg F1  972: 0.630776866405166

Val Avg Loss  972: 0.182957

Val Avg F1  972:  0.6880287929125138

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 973
--------------------------------------------------------------
Epoch:  973        1 Batch loss: 0.191989 Batch F1: 0.7307692307692308
Epoch:  973        2 Batch loss: 0.168231 Batch F1: 0.75
Epoch:  973        3 Batch loss: 0.166315 Batch F1: 0.7027027027027027
Epoch:  973        4 Batch loss: 0.164388 Batch F1: 0.8070175438596492
Epoch:  973        5 Batch loss: 0.160359 Batch F1: 0.7499999999999999
Epoch:  973        6 Batch loss: 0.158274 Batch F1: 0.7826086956521738
Epoch:  973        7 Batch loss: 0.195470 Batch F1: 0.6382978723404256
Epoch:  973        8 Batch loss: 0.183148 Batch F1: 0.75
Epoch:  973        9 Batch loss: 0.139709 Batch F1: 0.7272727272727273
Epoch:  973       10 Batch loss: 0.154656 Batch F1: 0.7058823529411765
Epoch:  973       11 Batch loss: 0.185215 Batch F1: 0.7234042553191491
Epoch:  973       12 Batch loss: 0.166817 Batch F1: 0.6896551724137931
Train Avg Loss  973: 0.169548

Train Avg F1  973: 0.7298008794392524

Val Avg Loss  973: 0.188846

Val Avg F1  973:  0.6895347855454239

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 974
--------------------------------------------------------------
Epoch:  974        1 Batch loss: 0.178943 Batch F1: 0.7391304347826089
Epoch:  974        2 Batch loss: 0.136932 Batch F1: 0.7878787878787877
Epoch:  974        3 Batch loss: 0.177495 Batch F1: 0.7
Epoch:  974        4 Batch loss: 0.213596 Batch F1: 0.4761904761904762
Epoch:  974        5 Batch loss: 0.163748 Batch F1: 0.7317073170731707
Epoch:  974        6 Batch loss: 0.176201 Batch F1: 0.6808510638297872
Epoch:  974        7 Batch loss: 0.158776 Batch F1: 0.8000000000000002
Epoch:  974        8 Batch loss: 0.174263 Batch F1: 0.6666666666666665
Epoch:  974        9 Batch loss: 0.141677 Batch F1: 0.761904761904762
Epoch:  974       10 Batch loss: 0.138802 Batch F1: 0.7500000000000001
Epoch:  974       11 Batch loss: 0.176174 Batch F1: 0.7272727272727272
Epoch:  974       12 Batch loss: 0.222456 Batch F1: 0.723404255319149
Train Avg Loss  974: 0.171589

Train Avg F1  974: 0.712083874243178

Val Avg Loss  974: 0.179878

Val Avg F1  974:  0.6816048767008809

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 975
--------------------------------------------------------------
Epoch:  975        1 Batch loss: 0.177856 Batch F1: 0.6341463414634146
Epoch:  975        2 Batch loss: 0.177936 Batch F1: 0.7499999999999999
Epoch:  975        3 Batch loss: 0.145544 Batch F1: 0.742857142857143
Epoch:  975        4 Batch loss: 0.167140 Batch F1: 0.75
Epoch:  975        5 Batch loss: 0.153572 Batch F1: 0.7499999999999999
Epoch:  975        6 Batch loss: 0.186181 Batch F1: 0.6
Epoch:  975        7 Batch loss: 0.165307 Batch F1: 0.7272727272727272
Epoch:  975        8 Batch loss: 0.168221 Batch F1: 0.7659574468085107
Epoch:  975        9 Batch loss: 0.158841 Batch F1: 0.761904761904762
Epoch:  975       10 Batch loss: 0.177726 Batch F1: 0.7719298245614035
Epoch:  975       11 Batch loss: 0.173061 Batch F1: 0.6511627906976745
Epoch:  975       12 Batch loss: 0.184207 Batch F1: 0.7142857142857143
Train Avg Loss  975: 0.169633

Train Avg F1  975: 0.7182930624876125

Val Avg Loss  975: 0.181818

Val Avg F1  975:  0.6774121997500211

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 976
--------------------------------------------------------------
Epoch:  976        1 Batch loss: 0.142294 Batch F1: 0.7777777777777778
Epoch:  976        2 Batch loss: 0.175180 Batch F1: 0.6666666666666666
Epoch:  976        3 Batch loss: 0.180330 Batch F1: 0.6341463414634146
Epoch:  976        4 Batch loss: 0.157505 Batch F1: 0.7916666666666667
Epoch:  976        5 Batch loss: 0.170084 Batch F1: 0.711111111111111
Epoch:  976        6 Batch loss: 0.163235 Batch F1: 0.6315789473684211
Epoch:  976        7 Batch loss: 0.163065 Batch F1: 0.7083333333333334
Epoch:  976        8 Batch loss: 0.216559 Batch F1: 0.6382978723404256
Epoch:  976        9 Batch loss: 0.195609 Batch F1: 0.6341463414634146
Epoch:  976       10 Batch loss: 0.146674 Batch F1: 0.7727272727272727
Epoch:  976       11 Batch loss: 0.167051 Batch F1: 0.7555555555555555
Epoch:  976       12 Batch loss: 0.138527 Batch F1: 0.8510638297872342
Train Avg Loss  976: 0.168009

Train Avg F1  976: 0.7144226430217744

Val Avg Loss  976: 0.187143

Val Avg F1  976:  0.6942282568122433

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 977
--------------------------------------------------------------
Epoch:  977        1 Batch loss: 0.155624 Batch F1: 0.8214285714285715
Epoch:  977        2 Batch loss: 0.152293 Batch F1: 0.823529411764706
Epoch:  977        3 Batch loss: 0.177127 Batch F1: 0.7441860465116279
Epoch:  977        4 Batch loss: 0.187720 Batch F1: 0.6808510638297872
Epoch:  977        5 Batch loss: 0.195518 Batch F1: 0.72
Epoch:  977        6 Batch loss: 0.184631 Batch F1: 0.6111111111111112
Epoch:  977        7 Batch loss: 0.171685 Batch F1: 0.7346938775510203
Epoch:  977        8 Batch loss: 0.182683 Batch F1: 0.6341463414634148
Epoch:  977        9 Batch loss: 0.155584 Batch F1: 0.6451612903225806
Epoch:  977       10 Batch loss: 0.215087 Batch F1: 0.2758620689655173
Epoch:  977       11 Batch loss: 0.149296 Batch F1: 0.7916666666666666
Epoch:  977       12 Batch loss: 0.163796 Batch F1: 0.6875000000000001
Train Avg Loss  977: 0.174254

Train Avg F1  977: 0.6808447041345836

Val Avg Loss  977: 0.185322

Val Avg F1  977:  0.6512820512820513

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 978
--------------------------------------------------------------
Epoch:  978        1 Batch loss: 0.160218 Batch F1: 0.7499999999999999
Epoch:  978        2 Batch loss: 0.185998 Batch F1: 0.7659574468085107
Epoch:  978        3 Batch loss: 0.219169 Batch F1: 0.5652173913043478
Epoch:  978        4 Batch loss: 0.180969 Batch F1: 0.6808510638297872
Epoch:  978        5 Batch loss: 0.180705 Batch F1: 0.5789473684210527
Epoch:  978        6 Batch loss: 0.159154 Batch F1: 0.7391304347826089
Epoch:  978        7 Batch loss: 0.160792 Batch F1: 0.7346938775510203
Epoch:  978        8 Batch loss: 0.191090 Batch F1: 0.7142857142857142
Epoch:  978        9 Batch loss: 0.158019 Batch F1: 0.631578947368421
Epoch:  978       10 Batch loss: 0.187556 Batch F1: 0.7346938775510203
Epoch:  978       11 Batch loss: 0.190857 Batch F1: 0.6046511627906976
Epoch:  978       12 Batch loss: 0.142134 Batch F1: 0.7500000000000001
Train Avg Loss  978: 0.176388

Train Avg F1  978: 0.6875006070577651

Val Avg Loss  978: 0.190992

Val Avg F1  978:  0.6072405874073271

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 979
--------------------------------------------------------------
Epoch:  979        1 Batch loss: 0.182537 Batch F1: 0.5000000000000001
Epoch:  979        2 Batch loss: 0.152381 Batch F1: 0.7317073170731707
Epoch:  979        3 Batch loss: 0.171541 Batch F1: 0.7500000000000001
Epoch:  979        4 Batch loss: 0.191264 Batch F1: 0.7307692307692308
Epoch:  979        5 Batch loss: 0.201944 Batch F1: 0.7199999999999999
Epoch:  979        6 Batch loss: 0.154485 Batch F1: 0.8
Epoch:  979        7 Batch loss: 0.173929 Batch F1: 0.7307692307692307
Epoch:  979        8 Batch loss: 0.186051 Batch F1: 0.6538461538461539
Epoch:  979        9 Batch loss: 0.183304 Batch F1: 0.6666666666666666
Epoch:  979       10 Batch loss: 0.165759 Batch F1: 0.8
Epoch:  979       11 Batch loss: 0.179947 Batch F1: 0.723404255319149
Epoch:  979       12 Batch loss: 0.148972 Batch F1: 0.7586206896551724
Train Avg Loss  979: 0.174343

Train Avg F1  979: 0.7138152953415645

Val Avg Loss  979: 0.187664

Val Avg F1  979:  0.6759536541889483

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 980
--------------------------------------------------------------
Epoch:  980        1 Batch loss: 0.197074 Batch F1: 0.6808510638297872
Epoch:  980        2 Batch loss: 0.188738 Batch F1: 0.7083333333333334
Epoch:  980        3 Batch loss: 0.179099 Batch F1: 0.6818181818181818
Epoch:  980        4 Batch loss: 0.180777 Batch F1: 0.7200000000000001
Epoch:  980        5 Batch loss: 0.188920 Batch F1: 0.6818181818181818
Epoch:  980        6 Batch loss: 0.197561 Batch F1: 0.6
Epoch:  980        7 Batch loss: 0.118813 Batch F1: 0.8947368421052632
Epoch:  980        8 Batch loss: 0.160802 Batch F1: 0.7555555555555555
Epoch:  980        9 Batch loss: 0.140811 Batch F1: 0.7727272727272727
Epoch:  980       10 Batch loss: 0.165976 Batch F1: 0.7234042553191489
Epoch:  980       11 Batch loss: 0.195410 Batch F1: 0.5333333333333332
Epoch:  980       12 Batch loss: 0.134698 Batch F1: 0.8205128205128205
Train Avg Loss  980: 0.170723

Train Avg F1  980: 0.7144242366960731

Val Avg Loss  980: 0.182584

Val Avg F1  980:  0.6803758791652255

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 981
--------------------------------------------------------------
Epoch:  981        1 Batch loss: 0.154282 Batch F1: 0.7058823529411765
Epoch:  981        2 Batch loss: 0.142482 Batch F1: 0.7567567567567567
Epoch:  981        3 Batch loss: 0.146989 Batch F1: 0.8260869565217391
Epoch:  981        4 Batch loss: 0.168859 Batch F1: 0.7272727272727272
Epoch:  981        5 Batch loss: 0.221191 Batch F1: 0.5416666666666666
Epoch:  981        6 Batch loss: 0.186906 Batch F1: 0.6956521739130435
Epoch:  981        7 Batch loss: 0.177468 Batch F1: 0.6153846153846153
Epoch:  981        8 Batch loss: 0.155952 Batch F1: 0.7755102040816326
Epoch:  981        9 Batch loss: 0.172904 Batch F1: 0.75
Epoch:  981       10 Batch loss: 0.162926 Batch F1: 0.6842105263157895
Epoch:  981       11 Batch loss: 0.174055 Batch F1: 0.6666666666666666
Epoch:  981       12 Batch loss: 0.143655 Batch F1: 0.7906976744186046
Train Avg Loss  981: 0.167306

Train Avg F1  981: 0.7113156100782848

Val Avg Loss  981: 0.182804

Val Avg F1  981:  0.6701923076923078

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 982
--------------------------------------------------------------
Epoch:  982        1 Batch loss: 0.165494 Batch F1: 0.7142857142857143
Epoch:  982        2 Batch loss: 0.173177 Batch F1: 0.7058823529411765
Epoch:  982        3 Batch loss: 0.179057 Batch F1: 0.6666666666666665
Epoch:  982        4 Batch loss: 0.155830 Batch F1: 0.7027027027027026
Epoch:  982        5 Batch loss: 0.140371 Batch F1: 0.8181818181818182
Epoch:  982        6 Batch loss: 0.141110 Batch F1: 0.8260869565217391
Epoch:  982        7 Batch loss: 0.147964 Batch F1: 0.7906976744186046
Epoch:  982        8 Batch loss: 0.162509 Batch F1: 0.7142857142857143
Epoch:  982        9 Batch loss: 0.148218 Batch F1: 0.8421052631578947
Epoch:  982       10 Batch loss: 0.211669 Batch F1: 0.6956521739130435
Epoch:  982       11 Batch loss: 0.221760 Batch F1: 0.5714285714285715
Epoch:  982       12 Batch loss: 0.196263 Batch F1: 0.5555555555555555
Train Avg Loss  982: 0.170285

Train Avg F1  982: 0.7169609303382667

Val Avg Loss  982: 0.182080

Val Avg F1  982:  0.6845735785953176

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 983
--------------------------------------------------------------
Epoch:  983        1 Batch loss: 0.169605 Batch F1: 0.6956521739130435
Epoch:  983        2 Batch loss: 0.195731 Batch F1: 0.5853658536585366
Epoch:  983        3 Batch loss: 0.146821 Batch F1: 0.8095238095238095
Epoch:  983        4 Batch loss: 0.144038 Batch F1: 0.8108108108108107
Epoch:  983        5 Batch loss: 0.172473 Batch F1: 0.7307692307692308
Epoch:  983        6 Batch loss: 0.180218 Batch F1: 0.6046511627906976
Epoch:  983        7 Batch loss: 0.138229 Batch F1: 0.8181818181818182
Epoch:  983        8 Batch loss: 0.161230 Batch F1: 0.7142857142857143
Epoch:  983        9 Batch loss: 0.177381 Batch F1: 0.7719298245614034
Epoch:  983       10 Batch loss: 0.204047 Batch F1: 0.5853658536585366
Epoch:  983       11 Batch loss: 0.171654 Batch F1: 0.7083333333333334
Epoch:  983       12 Batch loss: 0.146814 Batch F1: 0.7333333333333334
Train Avg Loss  983: 0.167354

Train Avg F1  983: 0.714016909901689

Val Avg Loss  983: 0.182068

Val Avg F1  983:  0.6788530655391121

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 984
--------------------------------------------------------------
Epoch:  984        1 Batch loss: 0.174130 Batch F1: 0.7636363636363636
Epoch:  984        2 Batch loss: 0.191484 Batch F1: 0.5581395348837209
Epoch:  984        3 Batch loss: 0.152549 Batch F1: 0.7906976744186046
Epoch:  984        4 Batch loss: 0.153716 Batch F1: 0.7727272727272727
Epoch:  984        5 Batch loss: 0.180565 Batch F1: 0.6938775510204083
Epoch:  984        6 Batch loss: 0.169497 Batch F1: 0.7755102040816326
Epoch:  984        7 Batch loss: 0.178689 Batch F1: 0.6976744186046512
Epoch:  984        8 Batch loss: 0.131399 Batch F1: 0.8372093023255814
Epoch:  984        9 Batch loss: 0.178975 Batch F1: 0.6511627906976744
Epoch:  984       10 Batch loss: 0.168066 Batch F1: 0.631578947368421
Epoch:  984       11 Batch loss: 0.165971 Batch F1: 0.6829268292682926
Epoch:  984       12 Batch loss: 0.157357 Batch F1: 0.6875
Train Avg Loss  984: 0.166867

Train Avg F1  984: 0.7118867407527185

Val Avg Loss  984: 0.181429

Val Avg F1  984:  0.672437530768024

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 985
--------------------------------------------------------------
Epoch:  985        1 Batch loss: 0.172776 Batch F1: 0.7083333333333334
Epoch:  985        2 Batch loss: 0.159140 Batch F1: 0.7391304347826089
Epoch:  985        3 Batch loss: 0.179805 Batch F1: 0.6666666666666666
Epoch:  985        4 Batch loss: 0.147595 Batch F1: 0.8076923076923077
Epoch:  985        5 Batch loss: 0.167364 Batch F1: 0.6818181818181819
Epoch:  985        6 Batch loss: 0.192232 Batch F1: 0.6666666666666666
Epoch:  985        7 Batch loss: 0.162906 Batch F1: 0.6976744186046512
Epoch:  985        8 Batch loss: 0.159726 Batch F1: 0.7555555555555556
Epoch:  985        9 Batch loss: 0.173638 Batch F1: 0.6153846153846153
Epoch:  985       10 Batch loss: 0.176216 Batch F1: 0.6818181818181818
Epoch:  985       11 Batch loss: 0.174202 Batch F1: 0.7317073170731707
Epoch:  985       12 Batch loss: 0.115273 Batch F1: 0.896551724137931
Train Avg Loss  985: 0.165073

Train Avg F1  985: 0.7207499502944893

Val Avg Loss  985: 0.181285

Val Avg F1  985:  0.6826289164564098

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 986
--------------------------------------------------------------
Epoch:  986        1 Batch loss: 0.155426 Batch F1: 0.7659574468085107
Epoch:  986        2 Batch loss: 0.158608 Batch F1: 0.7500000000000001
Epoch:  986        3 Batch loss: 0.152465 Batch F1: 0.7500000000000001
Epoch:  986        4 Batch loss: 0.189602 Batch F1: 0.6521739130434783
Epoch:  986        5 Batch loss: 0.164196 Batch F1: 0.7499999999999999
Epoch:  986        6 Batch loss: 0.146344 Batch F1: 0.7096774193548386
Epoch:  986        7 Batch loss: 0.163961 Batch F1: 0.7272727272727272
Epoch:  986        8 Batch loss: 0.175235 Batch F1: 0.631578947368421
Epoch:  986        9 Batch loss: 0.151217 Batch F1: 0.76
Epoch:  986       10 Batch loss: 0.174870 Batch F1: 0.6666666666666666
Epoch:  986       11 Batch loss: 0.171105 Batch F1: 0.6808510638297872
Epoch:  986       12 Batch loss: 0.174042 Batch F1: 0.717948717948718
Train Avg Loss  986: 0.164756

Train Avg F1  986: 0.7135105751910956

Val Avg Loss  986: 0.179389

Val Avg F1  986:  0.6784015403201451

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 987
--------------------------------------------------------------
Epoch:  987        1 Batch loss: 0.176517 Batch F1: 0.7169811320754716
Epoch:  987        2 Batch loss: 0.155299 Batch F1: 0.782608695652174
Epoch:  987        3 Batch loss: 0.169466 Batch F1: 0.6829268292682926
Epoch:  987        4 Batch loss: 0.203171 Batch F1: 0.5777777777777778
Epoch:  987        5 Batch loss: 0.142048 Batch F1: 0.8727272727272727
Epoch:  987        6 Batch loss: 0.185567 Batch F1: 0.5263157894736842
Epoch:  987        7 Batch loss: 0.159333 Batch F1: 0.7659574468085107
Epoch:  987        8 Batch loss: 0.137163 Batch F1: 0.7894736842105262
Epoch:  987        9 Batch loss: 0.161449 Batch F1: 0.7391304347826085
Epoch:  987       10 Batch loss: 0.175654 Batch F1: 0.5454545454545454
Epoch:  987       11 Batch loss: 0.166110 Batch F1: 0.6486486486486486
Epoch:  987       12 Batch loss: 0.169003 Batch F1: 0.8181818181818182
Train Avg Loss  987: 0.166732

Train Avg F1  987: 0.7055153395884441

Val Avg Loss  987: 0.185384

Val Avg F1  987:  0.6742445750804413

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 988
--------------------------------------------------------------
Epoch:  988        1 Batch loss: 0.173630 Batch F1: 0.7391304347826088
Epoch:  988        2 Batch loss: 0.159573 Batch F1: 0.6842105263157895
Epoch:  988        3 Batch loss: 0.161913 Batch F1: 0.7916666666666666
Epoch:  988        4 Batch loss: 0.160824 Batch F1: 0.7000000000000001
Epoch:  988        5 Batch loss: 0.184174 Batch F1: 0.5789473684210527
Epoch:  988        6 Batch loss: 0.167991 Batch F1: 0.7272727272727272
Epoch:  988        7 Batch loss: 0.181342 Batch F1: 0.6363636363636365
Epoch:  988        8 Batch loss: 0.155356 Batch F1: 0.7916666666666667
Epoch:  988        9 Batch loss: 0.122844 Batch F1: 0.8695652173913043
Epoch:  988       10 Batch loss: 0.174382 Batch F1: 0.68
Epoch:  988       11 Batch loss: 0.187453 Batch F1: 0.7391304347826089
Epoch:  988       12 Batch loss: 0.185510 Batch F1: 0.7317073170731707
Train Avg Loss  988: 0.167916

Train Avg F1  988: 0.7224717496446861

Val Avg Loss  988: 0.182273

Val Avg F1  988:  0.6911500449236299

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 989
--------------------------------------------------------------
Epoch:  989        1 Batch loss: 0.181296 Batch F1: 0.6976744186046512
Epoch:  989        2 Batch loss: 0.170571 Batch F1: 0.7391304347826088
Epoch:  989        3 Batch loss: 0.165692 Batch F1: 0.7391304347826088
Epoch:  989        4 Batch loss: 0.175624 Batch F1: 0.6956521739130435
Epoch:  989        5 Batch loss: 0.178270 Batch F1: 0.6153846153846153
Epoch:  989        6 Batch loss: 0.160704 Batch F1: 0.7692307692307692
Epoch:  989        7 Batch loss: 0.133082 Batch F1: 0.875
Epoch:  989        8 Batch loss: 0.195209 Batch F1: 0.6122448979591836
Epoch:  989        9 Batch loss: 0.131167 Batch F1: 0.7999999999999999
Epoch:  989       10 Batch loss: 0.182192 Batch F1: 0.588235294117647
Epoch:  989       11 Batch loss: 0.161307 Batch F1: 0.7200000000000001
Epoch:  989       12 Batch loss: 0.191632 Batch F1: 0.68
Train Avg Loss  989: 0.168896

Train Avg F1  989: 0.710973586564594

Val Avg Loss  989: 0.183144

Val Avg F1  989:  0.6546328321538406

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 990
--------------------------------------------------------------
Epoch:  990        1 Batch loss: 0.180860 Batch F1: 0.6785714285714286
Epoch:  990        2 Batch loss: 0.164658 Batch F1: 0.8085106382978724
Epoch:  990        3 Batch loss: 0.166257 Batch F1: 0.7391304347826088
Epoch:  990        4 Batch loss: 0.138829 Batch F1: 0.8627450980392156
Epoch:  990        5 Batch loss: 0.163685 Batch F1: 0.7999999999999999
Epoch:  990        6 Batch loss: 0.164088 Batch F1: 0.7
Epoch:  990        7 Batch loss: 0.179667 Batch F1: 0.7777777777777779
Epoch:  990        8 Batch loss: 0.164972 Batch F1: 0.7142857142857143
Epoch:  990        9 Batch loss: 0.140683 Batch F1: 0.6666666666666666
Epoch:  990       10 Batch loss: 0.190819 Batch F1: 0.6521739130434783
Epoch:  990       11 Batch loss: 0.173075 Batch F1: 0.6363636363636364
Epoch:  990       12 Batch loss: 0.176299 Batch F1: 0.6666666666666667
Train Avg Loss  990: 0.166991

Train Avg F1  990: 0.7252409978745887

Val Avg Loss  990: 0.180897

Val Avg F1  990:  0.6801195932497968

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 991
--------------------------------------------------------------
Epoch:  991        1 Batch loss: 0.177408 Batch F1: 0.6956521739130435
Epoch:  991        2 Batch loss: 0.161884 Batch F1: 0.7272727272727273
Epoch:  991        3 Batch loss: 0.140317 Batch F1: 0.8
Epoch:  991        4 Batch loss: 0.162689 Batch F1: 0.7111111111111111
Epoch:  991        5 Batch loss: 0.149200 Batch F1: 0.6857142857142857
Epoch:  991        6 Batch loss: 0.168755 Batch F1: 0.7
Epoch:  991        7 Batch loss: 0.185761 Batch F1: 0.6666666666666666
Epoch:  991        8 Batch loss: 0.176661 Batch F1: 0.6976744186046512
Epoch:  991        9 Batch loss: 0.162748 Batch F1: 0.6956521739130435
Epoch:  991       10 Batch loss: 0.169518 Batch F1: 0.7272727272727272
Epoch:  991       11 Batch loss: 0.149060 Batch F1: 0.7826086956521738
Epoch:  991       12 Batch loss: 0.179816 Batch F1: 0.7317073170731707
Train Avg Loss  991: 0.165318

Train Avg F1  991: 0.7184443580994668

Val Avg Loss  991: 0.184191

Val Avg F1  991:  0.6666556203605514

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 992
--------------------------------------------------------------
Epoch:  992        1 Batch loss: 0.171591 Batch F1: 0.6818181818181818
Epoch:  992        2 Batch loss: 0.167690 Batch F1: 0.6341463414634148
Epoch:  992        3 Batch loss: 0.174777 Batch F1: 0.6938775510204083
Epoch:  992        4 Batch loss: 0.157200 Batch F1: 0.7441860465116279
Epoch:  992        5 Batch loss: 0.159897 Batch F1: 0.8076923076923077
Epoch:  992        6 Batch loss: 0.149740 Batch F1: 0.8292682926829269
Epoch:  992        7 Batch loss: 0.158224 Batch F1: 0.717948717948718
Epoch:  992        8 Batch loss: 0.162233 Batch F1: 0.75
Epoch:  992        9 Batch loss: 0.196816 Batch F1: 0.6222222222222222
Epoch:  992       10 Batch loss: 0.133622 Batch F1: 0.8333333333333334
Epoch:  992       11 Batch loss: 0.177049 Batch F1: 0.693877551020408
Epoch:  992       12 Batch loss: 0.182765 Batch F1: 0.5882352941176471
Train Avg Loss  992: 0.165967

Train Avg F1  992: 0.7163838199859329

Val Avg Loss  992: 0.182397

Val Avg F1  992:  0.6825340808260063

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 993
--------------------------------------------------------------
Epoch:  993        1 Batch loss: 0.166400 Batch F1: 0.7142857142857143
Epoch:  993        2 Batch loss: 0.143713 Batch F1: 0.7317073170731706
Epoch:  993        3 Batch loss: 0.137089 Batch F1: 0.7999999999999999
Epoch:  993        4 Batch loss: 0.183771 Batch F1: 0.7037037037037038
Epoch:  993        5 Batch loss: 0.127700 Batch F1: 0.7999999999999999
Epoch:  993        6 Batch loss: 0.186961 Batch F1: 0.68
Epoch:  993        7 Batch loss: 0.178544 Batch F1: 0.65
Epoch:  993        8 Batch loss: 0.150027 Batch F1: 0.761904761904762
Epoch:  993        9 Batch loss: 0.180289 Batch F1: 0.6666666666666666
Epoch:  993       10 Batch loss: 0.190995 Batch F1: 0.6666666666666666
Epoch:  993       11 Batch loss: 0.155561 Batch F1: 0.7391304347826089
Epoch:  993       12 Batch loss: 0.175316 Batch F1: 0.7368421052631579
Train Avg Loss  993: 0.164697

Train Avg F1  993: 0.7209089475288709

Val Avg Loss  993: 0.179045

Val Avg F1  993:  0.6892270531400967

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 994
--------------------------------------------------------------
Epoch:  994        1 Batch loss: 0.169252 Batch F1: 0.7142857142857143
Epoch:  994        2 Batch loss: 0.166625 Batch F1: 0.6511627906976745
Epoch:  994        3 Batch loss: 0.191196 Batch F1: 0.6382978723404256
Epoch:  994        4 Batch loss: 0.167563 Batch F1: 0.7450980392156864
Epoch:  994        5 Batch loss: 0.124733 Batch F1: 0.8095238095238095
Epoch:  994        6 Batch loss: 0.180276 Batch F1: 0.7083333333333333
Epoch:  994        7 Batch loss: 0.144295 Batch F1: 0.6857142857142857
Epoch:  994        8 Batch loss: 0.160762 Batch F1: 0.7692307692307692
Epoch:  994        9 Batch loss: 0.169960 Batch F1: 0.6666666666666666
Epoch:  994       10 Batch loss: 0.180796 Batch F1: 0.7169811320754716
Epoch:  994       11 Batch loss: 0.147187 Batch F1: 0.7222222222222222
Epoch:  994       12 Batch loss: 0.148851 Batch F1: 0.7647058823529412
Train Avg Loss  994: 0.162625

Train Avg F1  994: 0.7160185431382501

Val Avg Loss  994: 0.178934

Val Avg F1  994:  0.6791277502664076

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 995
--------------------------------------------------------------
Epoch:  995        1 Batch loss: 0.135208 Batch F1: 0.8571428571428572
Epoch:  995        2 Batch loss: 0.139615 Batch F1: 0.7906976744186046
Epoch:  995        3 Batch loss: 0.160891 Batch F1: 0.7000000000000001
Epoch:  995        4 Batch loss: 0.188716 Batch F1: 0.6222222222222222
Epoch:  995        5 Batch loss: 0.154241 Batch F1: 0.6666666666666667
Epoch:  995        6 Batch loss: 0.182121 Batch F1: 0.5641025641025641
Epoch:  995        7 Batch loss: 0.146519 Batch F1: 0.7317073170731707
Epoch:  995        8 Batch loss: 0.196020 Batch F1: 0.6666666666666667
Epoch:  995        9 Batch loss: 0.181339 Batch F1: 0.7407407407407408
Epoch:  995       10 Batch loss: 0.133093 Batch F1: 0.8095238095238095
Epoch:  995       11 Batch loss: 0.157397 Batch F1: 0.7441860465116279
Epoch:  995       12 Batch loss: 0.186769 Batch F1: 0.6666666666666666
Train Avg Loss  995: 0.163494

Train Avg F1  995: 0.7133602693112997

Val Avg Loss  995: 0.180860

Val Avg F1  995:  0.6819509107244955

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 996
--------------------------------------------------------------
Epoch:  996        1 Batch loss: 0.168689 Batch F1: 0.7755102040816326
Epoch:  996        2 Batch loss: 0.140924 Batch F1: 0.8181818181818182
Epoch:  996        3 Batch loss: 0.163732 Batch F1: 0.7659574468085107
Epoch:  996        4 Batch loss: 0.172492 Batch F1: 0.7391304347826089
Epoch:  996        5 Batch loss: 0.153575 Batch F1: 0.7272727272727272
Epoch:  996        6 Batch loss: 0.157771 Batch F1: 0.7894736842105262
Epoch:  996        7 Batch loss: 0.158876 Batch F1: 0.631578947368421
Epoch:  996        8 Batch loss: 0.191347 Batch F1: 0.64
Epoch:  996        9 Batch loss: 0.186892 Batch F1: 0.6521739130434783
Epoch:  996       10 Batch loss: 0.162020 Batch F1: 0.65
Epoch:  996       11 Batch loss: 0.180165 Batch F1: 0.7058823529411765
Epoch:  996       12 Batch loss: 0.154883 Batch F1: 0.7500000000000001
Train Avg Loss  996: 0.165947

Train Avg F1  996: 0.7204301273909084

Val Avg Loss  996: 0.183724

Val Avg F1  996:  0.6843914395026303

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 997
--------------------------------------------------------------
Epoch:  997        1 Batch loss: 0.184123 Batch F1: 0.6666666666666666
Epoch:  997        2 Batch loss: 0.160234 Batch F1: 0.711111111111111
Epoch:  997        3 Batch loss: 0.155949 Batch F1: 0.7
Epoch:  997        4 Batch loss: 0.176335 Batch F1: 0.6666666666666666
Epoch:  997        5 Batch loss: 0.156136 Batch F1: 0.7441860465116279
Epoch:  997        6 Batch loss: 0.183589 Batch F1: 0.619047619047619
Epoch:  997        7 Batch loss: 0.163887 Batch F1: 0.76
Epoch:  997        8 Batch loss: 0.142122 Batch F1: 0.8076923076923077
Epoch:  997        9 Batch loss: 0.167126 Batch F1: 0.6976744186046512
Epoch:  997       10 Batch loss: 0.165476 Batch F1: 0.7755102040816326
Epoch:  997       11 Batch loss: 0.159072 Batch F1: 0.6666666666666667
Epoch:  997       12 Batch loss: 0.165079 Batch F1: 0.7368421052631577
Train Avg Loss  997: 0.164927

Train Avg F1  997: 0.7126719843593423

Val Avg Loss  997: 0.180603

Val Avg F1  997:  0.6897971422611597

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 998
--------------------------------------------------------------
Epoch:  998        1 Batch loss: 0.160130 Batch F1: 0.7916666666666667
Epoch:  998        2 Batch loss: 0.164824 Batch F1: 0.606060606060606
Epoch:  998        3 Batch loss: 0.194009 Batch F1: 0.7017543859649122
Epoch:  998        4 Batch loss: 0.153400 Batch F1: 0.6250000000000001
Epoch:  998        5 Batch loss: 0.171370 Batch F1: 0.6956521739130435
Epoch:  998        6 Batch loss: 0.180435 Batch F1: 0.7083333333333334
Epoch:  998        7 Batch loss: 0.156288 Batch F1: 0.7317073170731706
Epoch:  998        8 Batch loss: 0.155127 Batch F1: 0.8275862068965518
Epoch:  998        9 Batch loss: 0.141534 Batch F1: 0.7804878048780488
Epoch:  998       10 Batch loss: 0.160074 Batch F1: 0.6666666666666666
Epoch:  998       11 Batch loss: 0.186522 Batch F1: 0.6530612244897959
Epoch:  998       12 Batch loss: 0.152541 Batch F1: 0.7272727272727272
Train Avg Loss  998: 0.164688

Train Avg F1  998: 0.7096040927679602

Val Avg Loss  998: 0.178874

Val Avg F1  998:  0.6981906661241631

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 999
--------------------------------------------------------------
Epoch:  999        1 Batch loss: 0.179359 Batch F1: 0.6923076923076923
Epoch:  999        2 Batch loss: 0.195202 Batch F1: 0.6521739130434783
Epoch:  999        3 Batch loss: 0.166384 Batch F1: 0.8387096774193549
Epoch:  999        4 Batch loss: 0.158443 Batch F1: 0.8260869565217391
Epoch:  999        5 Batch loss: 0.176204 Batch F1: 0.7857142857142857
Epoch:  999        6 Batch loss: 0.175742 Batch F1: 0.6818181818181819
Epoch:  999        7 Batch loss: 0.180725 Batch F1: 0.6363636363636364
Epoch:  999        8 Batch loss: 0.161175 Batch F1: 0.7
Epoch:  999        9 Batch loss: 0.142706 Batch F1: 0.7777777777777778
Epoch:  999       10 Batch loss: 0.126843 Batch F1: 0.787878787878788
Epoch:  999       11 Batch loss: 0.157439 Batch F1: 0.6842105263157895
Epoch:  999       12 Batch loss: 0.151370 Batch F1: 0.7647058823529413
Train Avg Loss  999: 0.164299

Train Avg F1  999: 0.7356456097928056

Val Avg Loss  999: 0.180663

Val Avg F1  999:  0.6767555568887422

Optimal Val loss (Epoch 892): 0.17804411426186562

Epoch 1000
--------------------------------------------------------------
Epoch: 1000        1 Batch loss: 0.159179 Batch F1: 0.7659574468085107
Epoch: 1000        2 Batch loss: 0.131906 Batch F1: 0.851063829787234
Epoch: 1000        3 Batch loss: 0.197824 Batch F1: 0.6521739130434783
Epoch: 1000        4 Batch loss: 0.150559 Batch F1: 0.6666666666666666
Epoch: 1000        5 Batch loss: 0.179691 Batch F1: 0.7272727272727274
Epoch: 1000        6 Batch loss: 0.167111 Batch F1: 0.7555555555555555
Epoch: 1000        7 Batch loss: 0.160058 Batch F1: 0.7272727272727272
Epoch: 1000        8 Batch loss: 0.166957 Batch F1: 0.7317073170731706
Epoch: 1000        9 Batch loss: 0.133871 Batch F1: 0.7906976744186046
Epoch: 1000       10 Batch loss: 0.181684 Batch F1: 0.7307692307692307
Epoch: 1000       11 Batch loss: 0.169458 Batch F1: 0.5161290322580646
Epoch: 1000       12 Batch loss: 0.176229 Batch F1: 0.6857142857142857
Train Avg Loss 1000: 0.164544

Train Avg F1 1000: 0.7167483672200213

Val Avg Loss 1000: 0.185834

Val Avg F1 1000:  0.6826442328594409

Optimal Val loss (Epoch 892): 0.17804411426186562

Done!
